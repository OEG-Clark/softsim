{"home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.main.make_parallel_env": [[20, 32], ["utils.env_wrappers.DummyVecEnv", "utils.env_wrappers.SubprocVecEnv", "utils.make_env.make_env", "utils.make_env.make_env.seed", "numpy.random.seed", "main.make_parallel_env.get_env_fn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed"], ["def", "make_parallel_env", "(", "env_id", ",", "n_rollout_threads", ",", "seed", ",", "discrete_action", ")", ":", "\n", "    ", "def", "get_env_fn", "(", "rank", ")", ":", "\n", "        ", "def", "init_env", "(", ")", ":", "\n", "            ", "env", "=", "make_env", "(", "env_id", ",", "discrete_action", "=", "discrete_action", ")", "\n", "env", ".", "seed", "(", "seed", "+", "rank", "*", "1000", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", "+", "rank", "*", "1000", ")", "\n", "return", "env", "\n", "", "return", "init_env", "\n", "", "if", "n_rollout_threads", "==", "1", ":", "\n", "        ", "return", "DummyVecEnv", "(", "[", "get_env_fn", "(", "0", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "SubprocVecEnv", "(", "[", "get_env_fn", "(", "i", ")", "for", "i", "in", "range", "(", "n_rollout_threads", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.main.create_intrinsic_motivators": [[34, 43], ["DummyEmpowerment", "modules.append", "modules.append", "modules.append", "VariationalJointEmpowerment.init_from_env", "VariationalTransferAllActionPiEmpowerment.init", "SocialInfluence.init"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.init_from_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.init", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.init"], ["", "", "def", "create_intrinsic_motivators", "(", "config", ",", "agents", ",", "env", ")", ":", "\n", "    ", "modules", "=", "[", "DummyEmpowerment", "(", "agents", ")", "]", "\n", "if", "config", ".", "variational_joint_empowerment", ":", "\n", "        ", "modules", ".", "append", "(", "VariationalJointEmpowerment", ".", "init_from_env", "(", "env", ")", ")", "\n", "", "if", "config", ".", "variational_transfer_all_action_pi_empowerment", ":", "\n", "        ", "modules", ".", "append", "(", "VariationalTransferAllActionPiEmpowerment", ".", "init", "(", "agents", ",", "env", ")", ")", "\n", "", "if", "config", ".", "social_influence", ":", "\n", "        ", "modules", ".", "append", "(", "SocialInfluence", ".", "init", "(", "agents", ",", "env", ")", ")", "\n", "", "return", "modules", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.main.create_neural_network": [[45, 51], ["module.add_to_nn_list"], "function", ["None"], ["", "def", "create_neural_network", "(", "modules", ")", ":", "\n", "    ", "nn", "=", "[", "]", "\n", "for", "module", "in", "modules", ":", "\n", "        ", "module", ".", "add_to_nn_list", "(", "nn", ")", "\n", "\n", "", "return", "nn", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.main.run": [[53, 171], ["os.makedirs", "tensorboardX.SummaryWriter", "torch.manual_seed", "numpy.random.seed", "main.make_parallel_env", "utils.buffer.ReplayBuffer", "main.create_intrinsic_motivators", "range", "MADDPG.init_from_env.save", "make_parallel_env.close", "tensorboardX.SummaryWriter.export_scalars_to_json", "tensorboardX.SummaryWriter.close", "model_dir.exists", "str", "torch.set_num_threads", "algorithms.maddpg.MADDPG.init_from_save", "algorithms.maddpg.MADDPG.init_from_env", "print", "make_parallel_env.reset", "MADDPG.init_from_env.prep_rollouts", "MADDPG.init_from_env.scale_noise", "MADDPG.init_from_env.reset_noise", "range", "utils.buffer.ReplayBuffer.get_average_rewards", "enumerate", "str", "pathlib.Path", "int", "len", "int", "numpy.sort", "im.prep_rollouts", "max", "time.time", "MADDPG.init_from_env.step", "make_parallel_env.step", "numpy.sum", "utils.buffer.ReplayBuffer.push", "tensorboardX.SummaryWriter.add_scalars", "os.makedirs", "MADDPG.init_from_env.save", "MADDPG.init_from_env.save", "model_dir.iterdir", "str().startswith", "models_dir.iterdir", "isinstance", "torch.autograd.Variable", "ac.data.numpy", "numpy.asarray", "range", "MADDPG.init_from_env.prep_rollouts", "print", "str().split", "max", "str().startswith", "str().endswith", "isinstance", "sum", "torch.Tensor", "range", "range", "len", "MADDPG.init_from_env.prep_training", "MADDPG.init_from_env.prep_training", "range", "MADDPG.init_from_env.update_all_targets", "im.prep_rollouts", "str", "str().split", "numpy.vstack", "im.compute", "im.prep_training", "im.prep_training", "utils.buffer.ReplayBuffer.sample", "MADDPG.init_from_env.update", "str", "str", "str", "im.update", "len", "str", "time.time"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.main.make_parallel_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.main.create_intrinsic_motivators", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.init_from_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.scale_noise", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.reset_noise", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.buffer.ReplayBuffer.get_average_rewards", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.buffer.ReplayBuffer.push", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.update_all_targets", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "run", "(", "config", ")", ":", "\n", "    ", "model_dir", "=", "Path", "(", "'./models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "\n", "if", "not", "model_dir", ".", "exists", "(", ")", ":", "\n", "        ", "curr_run", "=", "'run1'", "\n", "", "else", ":", "\n", "        ", "exst_run_nums", "=", "[", "int", "(", "str", "(", "folder", ".", "name", ")", ".", "split", "(", "'run'", ")", "[", "1", "]", ")", "for", "folder", "in", "\n", "model_dir", ".", "iterdir", "(", ")", "if", "\n", "str", "(", "folder", ".", "name", ")", ".", "startswith", "(", "'run'", ")", "]", "\n", "if", "len", "(", "exst_run_nums", ")", "==", "0", ":", "\n", "            ", "curr_run", "=", "'run1'", "\n", "", "else", ":", "\n", "            ", "curr_run", "=", "'run%i'", "%", "(", "max", "(", "exst_run_nums", ")", "+", "1", ")", "\n", "", "", "run_dir", "=", "model_dir", "/", "curr_run", "\n", "log_dir", "=", "run_dir", "/", "'logs'", "\n", "os", ".", "makedirs", "(", "log_dir", ")", "\n", "logger", "=", "SummaryWriter", "(", "str", "(", "log_dir", ")", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "config", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "config", ".", "seed", ")", "\n", "if", "not", "USE_CUDA", ":", "\n", "        ", "torch", ".", "set_num_threads", "(", "config", ".", "n_training_threads", ")", "\n", "", "env", "=", "make_parallel_env", "(", "config", ".", "env_id", ",", "config", ".", "n_rollout_threads", ",", "config", ".", "seed", ",", "\n", "config", ".", "discrete_action", ")", "\n", "\n", "if", "config", ".", "run_num", ":", "\n", "        ", "model_path", "=", "model_dir", "/", "f'run{config.run_num}'", "\n", "maddpg", "=", "MADDPG", ".", "init_from_save", "(", "model_path", "/", "'model.pt'", ")", "\n", "models_dir", "=", "model_path", "/", "'incremental'", "\n", "ext_mods", "=", "[", "int", "(", "str", "(", "folder", ".", "name", ")", ".", "split", "(", "'model_ep'", ")", "[", "1", "]", "[", ":", "-", "3", "]", ")", "for", "folder", "in", "\n", "models_dir", ".", "iterdir", "(", ")", "if", "\n", "str", "(", "folder", ".", "name", ")", ".", "startswith", "(", "'model_ep'", ")", "and", "str", "(", "folder", ".", "name", ")", ".", "endswith", "(", "'.pt'", ")", "]", "\n", "\n", "ep_st", "=", "np", ".", "sort", "(", "ext_mods", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "maddpg", "=", "MADDPG", ".", "init_from_env", "(", "env", ",", "agent_alg", "=", "config", ".", "agent_alg", ",", "\n", "adversary_alg", "=", "config", ".", "adversary_alg", ",", "\n", "tau", "=", "config", ".", "tau", ",", "\n", "lr", "=", "config", ".", "lr", ",", "\n", "hidden_dim", "=", "config", ".", "hidden_dim", ",", "\n", "recurrent", "=", "config", ".", "recurrent", ",", "\n", "convolutional", "=", "config", ".", "convolutional", ")", "\n", "ep_st", "=", "0", "\n", "\n", "", "replay_buffer", "=", "ReplayBuffer", "(", "config", ".", "buffer_length", ",", "maddpg", ".", "nagents", ",", "\n", "[", "obsp", ".", "shape", "[", "0", "]", "for", "obsp", "in", "env", ".", "observation_space", "]", "if", "not", "config", ".", "convolutional", "else", "\n", "[", "obsp", ".", "shape", "for", "obsp", "in", "env", ".", "observation_space", "]", ",", "\n", "[", "acsp", ".", "shape", "[", "0", "]", "if", "isinstance", "(", "acsp", ",", "Box", ")", "else", "acsp", ".", "n", "if", "isinstance", "(", "acsp", ",", "Discrete", ")", "else", "\n", "sum", "(", "acsp", ".", "high", "-", "acsp", ".", "low", "+", "1", ")", "for", "acsp", "in", "env", ".", "action_space", "]", ")", "\n", "t", "=", "0", "\n", "\n", "intrinsic_modules", "=", "create_intrinsic_motivators", "(", "config", ",", "maddpg", ".", "agents", ",", "env", ")", "\n", "\n", "for", "ep_i", "in", "range", "(", "ep_st", ",", "config", ".", "n_episodes", ",", "config", ".", "n_rollout_threads", ")", ":", "\n", "        ", "print", "(", "\"Episodes %i-%i of %i\"", "%", "(", "ep_i", "+", "1", ",", "\n", "ep_i", "+", "1", "+", "config", ".", "n_rollout_threads", ",", "\n", "config", ".", "n_episodes", ")", ")", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "# obs.shape = (n_rollout_threads, nagent)(nobs), nobs differs per agent so not tensor", "\n", "maddpg", ".", "prep_rollouts", "(", "device", "=", "'cpu'", ")", "\n", "[", "im", ".", "prep_rollouts", "(", "device", "=", "'cpu'", ")", "for", "im", "in", "intrinsic_modules", "]", "\n", "\n", "explr_pct_remaining", "=", "max", "(", "0", ",", "config", ".", "n_exploration_eps", "-", "ep_i", ")", "/", "config", ".", "n_exploration_eps", "\n", "maddpg", ".", "scale_noise", "(", "config", ".", "final_noise_scale", "+", "(", "config", ".", "init_noise_scale", "-", "config", ".", "final_noise_scale", ")", "*", "explr_pct_remaining", ")", "\n", "maddpg", ".", "reset_noise", "(", ")", "\n", "for", "et_i", "in", "range", "(", "config", ".", "episode_length", ")", ":", "\n", "            ", "start", "=", "time", ".", "time", "(", ")", "\n", "# rearrange observations to be per agent, and convert to torch Variable", "\n", "torch_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "vstack", "(", "obs", "[", ":", ",", "i", "]", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "maddpg", ".", "nagents", ")", "]", "\n", "# get actions as torch Variables", "\n", "torch_agent_actions", "=", "maddpg", ".", "step", "(", "torch_obs", ",", "explore", "=", "True", ")", "\n", "# convert actions to numpy arrays", "\n", "agent_actions", "=", "[", "ac", ".", "data", ".", "numpy", "(", ")", "for", "ac", "in", "torch_agent_actions", "]", "\n", "# rearrange actions to be per environment", "\n", "actions", "=", "[", "[", "ac", "[", "i", "]", "for", "ac", "in", "agent_actions", "]", "for", "i", "in", "range", "(", "config", ".", "n_rollout_threads", ")", "]", "\n", "next_obs", ",", "rewards", ",", "dones", ",", "infos", "=", "env", ".", "step", "(", "actions", ")", "\n", "\n", "emps", "=", "np", ".", "sum", "(", "np", ".", "asarray", "(", "[", "im", ".", "compute", "(", "rewards", ",", "next_obs", ")", "for", "im", "in", "intrinsic_modules", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "replay_buffer", ".", "push", "(", "obs", ",", "agent_actions", ",", "rewards", ",", "emps", ",", "next_obs", ",", "dones", ")", "\n", "obs", "=", "next_obs", "\n", "t", "+=", "config", ".", "n_rollout_threads", "\n", "if", "(", "len", "(", "replay_buffer", ")", ">=", "config", ".", "batch_size", "and", "\n", "(", "t", "%", "config", ".", "steps_per_update", ")", "<", "config", ".", "n_rollout_threads", ")", ":", "\n", "                ", "if", "USE_CUDA", ":", "\n", "                    ", "maddpg", ".", "prep_training", "(", "device", "=", "'gpu'", ")", "\n", "[", "im", ".", "prep_training", "(", "device", "=", "'gpu'", ")", "for", "im", "in", "intrinsic_modules", "]", "\n", "", "else", ":", "\n", "                    ", "maddpg", ".", "prep_training", "(", "device", "=", "'cpu'", ")", "\n", "[", "im", ".", "prep_training", "(", "device", "=", "'cpu'", ")", "for", "im", "in", "intrinsic_modules", "]", "\n", "", "for", "u_i", "in", "range", "(", "config", ".", "n_rollout_threads", ")", ":", "\n", "                    ", "for", "a_i", "in", "range", "(", "maddpg", ".", "nagents", ")", ":", "\n", "                        ", "sample", "=", "replay_buffer", ".", "sample", "(", "config", ".", "batch_size", ",", "\n", "to_gpu", "=", "USE_CUDA", ")", "\n", "maddpg", ".", "update", "(", "sample", ",", "a_i", ",", "logger", "=", "logger", ")", "\n", "[", "im", ".", "update", "(", "sample", ",", "logger", "=", "logger", ")", "for", "im", "in", "intrinsic_modules", "]", "\n", "", "maddpg", ".", "update_all_targets", "(", ")", "\n", "", "maddpg", ".", "prep_rollouts", "(", "device", "=", "'cpu'", ")", "\n", "[", "im", ".", "prep_rollouts", "(", "device", "=", "'cpu'", ")", "for", "im", "in", "intrinsic_modules", "]", "\n", "\n", "print", "(", "f'computation time = {time.time() - start:.3f}s buffer length = {len(replay_buffer)}'", ")", "\n", "", "", "ep_rews", "=", "replay_buffer", ".", "get_average_rewards", "(", "\n", "config", ".", "episode_length", "*", "config", ".", "n_rollout_threads", ")", "\n", "for", "a_i", ",", "a_ep_rew", "in", "enumerate", "(", "ep_rews", ")", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'agent%i/mean_episode_rewards'", "%", "a_i", ",", "\n", "{", "'rew_loss'", ":", "a_ep_rew", "}", ",", "\n", "ep_i", ")", "\n", "\n", "", "if", "ep_i", "%", "config", ".", "save_interval", "<", "config", ".", "n_rollout_threads", ":", "\n", "            ", "os", ".", "makedirs", "(", "run_dir", "/", "'incremental'", ",", "exist_ok", "=", "True", ")", "\n", "maddpg", ".", "save", "(", "run_dir", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "(", "ep_i", "+", "1", ")", ")", ")", "\n", "maddpg", ".", "save", "(", "run_dir", "/", "'model.pt'", ")", "\n", "\n", "", "", "maddpg", ".", "save", "(", "run_dir", "/", "'model.pt'", ")", "\n", "env", ".", "close", "(", ")", "\n", "logger", ".", "export_scalars_to_json", "(", "str", "(", "log_dir", "/", "'summary.json'", ")", ")", "\n", "logger", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment.estimate_empowerment_from_positions": [[12, 22], ["numpy.array().reshape", "numpy.array", "numpy.array", "estimate_empowerment._cells_in_collision", "estimate_empowerment._cells_outside_bounds", "estimate_empowerment._locations_in_collision", "multiagent.scenarios.transition_utils._location_to_index", "estimate_empowerment.empowerment", "multiagent.scenarios.transition_utils._cell_to_index", "estimate_empowerment._positions_to_cell"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._cells_in_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._cells_outside_bounds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._locations_in_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.transition_utils._location_to_index", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment.empowerment", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.transition_utils._cell_to_index", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._positions_to_cell"], ["def", "estimate_empowerment_from_positions", "(", "ps", ",", "Tn", ",", "locations", ",", "dims", "=", "(", "3", ",", "3", ")", ")", ":", "\n", "    ", "cells", "=", "np", ".", "array", "(", "[", "_positions_to_cell", "(", "pose", ",", "x_lim_out", "=", "(", "0", ",", "dims", "[", "0", "]", ")", ",", "y_lim_out", "=", "(", "0", ",", "dims", "[", "1", "]", ")", ")", "for", "pose", "in", "\n", "ps", "]", ")", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "\n", "if", "(", "not", "_cells_in_collision", "(", "cells", ")", ")", "and", "(", "not", "_cells_outside_bounds", "(", "cells", ",", "dims", ")", ")", ":", "\n", "        ", "ls", "=", "np", ".", "array", "(", "[", "_cell_to_index", "(", "c", ",", "dims", "=", "dims", ")", "for", "c", "in", "cells", "]", ")", "\n", "if", "not", "_locations_in_collision", "(", "ls", ")", ":", "\n", "            ", "ss", "=", "_location_to_index", "(", "locs", "=", "ls", ",", "locations", "=", "locations", ")", "\n", "return", "empowerment", "(", "Tn", ",", "det", "=", "1.", ",", "n_step", "=", "1", ",", "state", "=", "ss", ")", "\n", "", "", "return", "0.", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment.estimate_empowerment_from_landmark_positions": [[23, 32], ["estimate_empowerment.empowerment", "set", "range", "numpy.log2", "numpy.argmax", "set.add", "len", "functools.reduce"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment.empowerment", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce"], ["", "def", "estimate_empowerment_from_landmark_positions", "(", "config", ",", "T", ",", "n_step", "=", "1", ")", ":", "\n", "    ", "if", "n_step", "==", "1", ":", "\n", "        ", "tmap", "=", "lambda", "a", ":", "np", ".", "argmax", "(", "T", "[", ":", ",", "a", "]", ")", "\n", "seen", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "T", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "seen", ".", "add", "(", "reduce", "(", "tmap", ",", "[", "i", "]", ")", ")", "\n", "# empowerment = log # of reachable states", "\n", "", "return", "np", ".", "log2", "(", "len", "(", "seen", ")", ")", "\n", "", "return", "empowerment", "(", "T", ",", "det", "=", "1.", ",", "n_step", "=", "n_step", ",", "state", "=", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._positions_to_cell": [[34, 40], ["numpy.array", "int", "numpy.clip", "estimate_empowerment._positions_to_cell.transform"], "function", ["None"], ["", "def", "_positions_to_cell", "(", "ps", ",", "x_lim_in", "=", "(", "-", "1", ",", "1", ")", ",", "y_lim_in", "=", "(", "-", "1", ",", "1", ")", ",", "x_lim_out", "=", "(", "0", ",", "3", ")", ",", "y_lim_out", "=", "(", "0", ",", "3", ")", ")", ":", "\n", "    ", "def", "transform", "(", "p", ",", "lim_in", ",", "lim_out", ")", ":", "\n", "        ", "p_out", "=", "(", "p", "-", "lim_in", "[", "0", "]", ")", "/", "(", "lim_in", "[", "1", "]", "-", "lim_in", "[", "0", "]", ")", "\n", "return", "int", "(", "np", ".", "clip", "(", "p_out", "*", "(", "lim_out", "[", "1", "]", "-", "lim_out", "[", "0", "]", ")", "+", "lim_out", "[", "0", "]", ",", "a_min", "=", "lim_out", "[", "0", "]", ",", "a_max", "=", "lim_out", "[", "1", "]", ")", ")", "\n", "\n", "", "return", "np", ".", "array", "(", "[", "transform", "(", "ps", "[", "1", "]", ",", "y_lim_in", ",", "y_lim_out", ")", ",", "transform", "(", "ps", "[", "0", "]", ",", "x_lim_in", ",", "x_lim_out", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._cells_in_collision": [[41, 48], ["range", "len", "range", "len", "numpy.array_equal"], "function", ["None"], ["", "def", "_cells_in_collision", "(", "cells", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "cells", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "cells", ")", ")", ":", "\n", "            ", "if", "i", "==", "j", ":", "continue", "\n", "if", "np", ".", "array_equal", "(", "cells", "[", "i", "]", ",", "cells", "[", "j", "]", ")", ":", "\n", "                ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._locations_in_collision": [[49, 56], ["range", "len", "range", "len", "numpy.array_equal"], "function", ["None"], ["", "def", "_locations_in_collision", "(", "locations", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "locations", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "locations", ")", ")", ":", "\n", "            ", "if", "i", "==", "j", ":", "continue", "\n", "if", "np", ".", "array_equal", "(", "locations", "[", "i", "]", ",", "locations", "[", "j", "]", ")", ":", "\n", "                ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._cells_outside_bounds": [[57, 62], ["numpy.any", "numpy.any", "numpy.zeros"], "function", ["None"], ["", "def", "_cells_outside_bounds", "(", "cells", ",", "dims", ")", ":", "\n", "    ", "for", "cell", "in", "cells", ":", "\n", "        ", "if", "np", ".", "any", "(", "cell", "<", "np", ".", "zeros", "(", "2", ")", ")", "or", "np", ".", "any", "(", "cell", ">=", "dims", ")", ":", "\n", "            ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment.empowerment": [[65, 106], ["set", "range", "numpy.log2", "list", "numpy.zeros", "enumerate", "estimate_empowerment._rand_dist", "algorithms.info_theory.blahut_arimoto", "numpy.array", "numpy.random.randint", "numpy.argmax", "len", "set.add", "len", "itertools.product", "functools.reduce", "list", "functools.reduce", "range", "len", "map", "itertools.product", "numpy.dot", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._rand_dist", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.info_theory.blahut_arimoto", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce"], ["", "def", "empowerment", "(", "T", ",", "det", ",", "n_step", ",", "state", ",", "n_samples", "=", "1000", ",", "epsilon", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"\n    Compute the empowerment of a state in a grid world\n    T : numpy array, shape (n_states, n_actions, n_states)\n        Transition matrix describing the probabilistic dynamics of a markov decision process\n        (without rewards). Taking action a in state s, T describes a probability distribution\n        over the resulting state as T[:,a,s]. In other words, T[s',a,s] is the probability of\n        landing in state s' after taking action a in state s. The indices may seem \"backwards\"\n        because this allows for convenient matrix multiplication.\n    det : bool\n        True if the dynamics are deterministic.\n    n_step : int\n        Determines the \"time horizon\" of the empowerment computation. The computed empowerment is\n        the influence the agent has on the future over an n_step time horizon.\n    n_samples : int\n        Number of samples for approximating the empowerment in the deterministic case.\n    state : int\n        State for which to compute the empowerment.\n    \"\"\"", "\n", "n_states", ",", "n_actions", ",", "_", "=", "T", ".", "shape", "\n", "if", "det", "==", "1", ":", "\n", "# only sample if too many actions sequences to iterate through", "\n", "        ", "if", "n_actions", "**", "n_step", "<", "5000", ":", "\n", "            ", "nstep_samples", "=", "np", ".", "array", "(", "list", "(", "itertools", ".", "product", "(", "range", "(", "n_actions", ")", ",", "repeat", "=", "n_step", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "nstep_samples", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "n_actions", ",", "[", "n_samples", ",", "n_step", "]", ")", "\n", "# fold over each nstep actions, get unique end states", "\n", "", "tmap", "=", "lambda", "s", ",", "a", ":", "np", ".", "argmax", "(", "T", "[", ":", ",", "a", ",", "s", "]", ")", "\n", "seen", "=", "set", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "nstep_samples", ")", ")", ":", "\n", "            ", "aseq", "=", "nstep_samples", "[", "i", ",", ":", "]", "\n", "seen", ".", "add", "(", "reduce", "(", "tmap", ",", "[", "state", ",", "*", "aseq", "]", ")", ")", "\n", "# empowerment = log # of reachable states", "\n", "", "return", "np", ".", "log2", "(", "len", "(", "seen", ")", ")", "\n", "", "else", ":", "\n", "        ", "nstep_actions", "=", "list", "(", "itertools", ".", "product", "(", "range", "(", "n_actions", ")", ",", "repeat", "=", "n_step", ")", ")", "\n", "Bn", "=", "np", ".", "zeros", "(", "[", "n_states", ",", "len", "(", "nstep_actions", ")", ",", "n_states", "]", ")", "\n", "for", "i", ",", "an", "in", "enumerate", "(", "nstep_actions", ")", ":", "\n", "            ", "Bn", "[", ":", ",", "i", ",", ":", "]", "=", "reduce", "(", "(", "lambda", "x", ",", "y", ":", "np", ".", "dot", "(", "y", ",", "x", ")", ")", ",", "map", "(", "(", "lambda", "a", ":", "T", "[", ":", ",", "a", ",", ":", "]", ")", ",", "an", ")", ")", "\n", "", "q_x", "=", "_rand_dist", "(", "(", "Bn", ".", "shape", "[", "1", "]", ",", ")", ")", "\n", "return", "blahut_arimoto", "(", "Bn", "[", ":", ",", ":", ",", "state", "]", ",", "q_x", ",", "epsilon", "=", "epsilon", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._rand_dist": [[108, 112], ["numpy.random.rand", "estimate_empowerment._normalize"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.info_theory._normalize"], ["", "", "def", "_rand_dist", "(", "shape", ")", ":", "\n", "    ", "\"\"\" define a random probability distribution \"\"\"", "\n", "P", "=", "np", ".", "random", ".", "rand", "(", "*", "shape", ")", "\n", "return", "_normalize", "(", "P", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.None.estimate_empowerment._normalize": [[114, 120], ["sum", "ValueError"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "_normalize", "(", "P", ")", ":", "\n", "    ", "\"\"\" normalize probability distribution \"\"\"", "\n", "s", "=", "sum", "(", "P", ")", "\n", "if", "s", "==", "0.", ":", "\n", "        ", "raise", "ValueError", "(", "\"input distribution has sum zero\"", ")", "\n", "", "return", "P", "/", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.noise.OUNoise.__init__": [[6, 14], ["noise.OUNoise.reset", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["    ", "def", "__init__", "(", "self", ",", "action_dimension", ",", "scale", "=", "0.1", ",", "mu", "=", "0", ",", "theta", "=", "0.15", ",", "sigma", "=", "0.2", ")", ":", "\n", "        ", "self", ".", "action_dimension", "=", "action_dimension", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "mu", "=", "mu", "\n", "self", ".", "theta", "=", "theta", "\n", "self", ".", "sigma", "=", "sigma", "\n", "self", ".", "state", "=", "np", ".", "ones", "(", "self", ".", "action_dimension", ")", "*", "self", ".", "mu", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.noise.OUNoise.reset": [[15, 17], ["numpy.ones"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "=", "np", ".", "ones", "(", "self", ".", "action_dimension", ")", "*", "self", ".", "mu", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.noise.OUNoise.noise": [[18, 23], ["numpy.random.randn", "len"], "methods", ["None"], ["", "def", "noise", "(", "self", ")", ":", "\n", "        ", "x", "=", "self", ".", "state", "\n", "dx", "=", "self", ".", "theta", "*", "(", "self", ".", "mu", "-", "x", ")", "+", "self", ".", "sigma", "*", "np", ".", "random", ".", "randn", "(", "len", "(", "x", ")", ")", "\n", "self", ".", "state", "=", "x", "+", "dx", "\n", "return", "self", ".", "state", "*", "self", ".", "scale", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.buffer.ReplayBuffer.__init__": [[9, 40], ["zip", "buffer.ReplayBuffer.ac_buffs.append", "buffer.ReplayBuffer.rew_buffs.append", "buffer.ReplayBuffer.emp_buffs.append", "buffer.ReplayBuffer.done_buffs.append", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "type", "buffer.ReplayBuffer.next_obs_buffs.append", "buffer.ReplayBuffer.obs_buffs.append", "buffer.ReplayBuffer.next_obs_buffs.append", "buffer.ReplayBuffer.obs_buffs.append", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["def", "__init__", "(", "self", ",", "max_steps", ",", "num_agents", ",", "obs_dims", ",", "ac_dims", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            max_steps (int): Maximum number of timepoints to store in buffer\n            num_agents (int): Number of agents in environment\n            obs_dims (list of ints): number of obervation dimensions for each\n                                     agent\n            ac_dims (list of ints): number of action dimensions for each agent\n        \"\"\"", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "num_agents", "=", "num_agents", "\n", "self", ".", "obs_buffs", "=", "[", "]", "\n", "self", ".", "ac_buffs", "=", "[", "]", "\n", "self", ".", "rew_buffs", "=", "[", "]", "\n", "self", ".", "emp_buffs", "=", "[", "]", "\n", "self", ".", "next_obs_buffs", "=", "[", "]", "\n", "self", ".", "done_buffs", "=", "[", "]", "\n", "for", "odim", ",", "adim", "in", "zip", "(", "obs_dims", ",", "ac_dims", ")", ":", "\n", "            ", "self", ".", "ac_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "max_steps", ",", "adim", ")", ")", ")", "\n", "self", ".", "rew_buffs", ".", "append", "(", "np", ".", "zeros", "(", "max_steps", ")", ")", "\n", "self", ".", "emp_buffs", ".", "append", "(", "np", ".", "zeros", "(", "max_steps", ")", ")", "\n", "self", ".", "done_buffs", ".", "append", "(", "np", ".", "zeros", "(", "max_steps", ")", ")", "\n", "if", "type", "(", "odim", ")", "==", "int", ":", "\n", "                ", "self", ".", "next_obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "max_steps", ",", "odim", ")", ")", ")", "\n", "self", ".", "obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "max_steps", ",", "odim", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "next_obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "(", "max_steps", ",", ")", "+", "odim", ")", ")", ")", "\n", "self", ".", "obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "(", "max_steps", ",", ")", "+", "odim", ")", ")", ")", "\n", "\n", "", "", "self", ".", "filled_i", "=", "0", "# index of first empty location in buffer (last index when full)", "\n", "self", ".", "curr_i", "=", "0", "# current index to write to (ovewrite oldest data)", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.buffer.ReplayBuffer.__len__": [[41, 43], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "filled_i", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.buffer.ReplayBuffer.push": [[44, 78], ["range", "range", "numpy.vstack", "numpy.vstack", "numpy.roll", "numpy.roll", "numpy.roll", "numpy.roll", "numpy.roll", "numpy.roll"], "methods", ["None"], ["", "def", "push", "(", "self", ",", "observations", ",", "actions", ",", "rewards", ",", "emps", ",", "next_observations", ",", "dones", ")", ":", "\n", "        ", "nentries", "=", "observations", ".", "shape", "[", "0", "]", "# handle multiple parallel environments", "\n", "if", "self", ".", "curr_i", "+", "nentries", ">", "self", ".", "max_steps", ":", "\n", "            ", "rollover", "=", "self", ".", "max_steps", "-", "self", ".", "curr_i", "# num of indices to roll over", "\n", "for", "agent_i", "in", "range", "(", "self", ".", "num_agents", ")", ":", "\n", "                ", "self", ".", "obs_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "obs_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ",", "axis", "=", "0", ")", "\n", "self", ".", "ac_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "ac_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ",", "axis", "=", "0", ")", "\n", "self", ".", "rew_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "rew_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ")", "\n", "self", ".", "emp_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "emp_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ")", "\n", "self", ".", "next_obs_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "\n", "self", ".", "next_obs_buffs", "[", "agent_i", "]", ",", "rollover", ",", "axis", "=", "0", ")", "\n", "self", ".", "done_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "done_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ")", "\n", "", "self", ".", "curr_i", "=", "0", "\n", "self", ".", "filled_i", "=", "self", ".", "max_steps", "\n", "", "for", "agent_i", "in", "range", "(", "self", ".", "num_agents", ")", ":", "\n", "            ", "self", ".", "obs_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "np", ".", "vstack", "(", "\n", "observations", "[", ":", ",", "agent_i", "]", ")", "\n", "# actions are already batched by agent, so they are indexed differently", "\n", "self", ".", "ac_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "actions", "[", "agent_i", "]", "\n", "self", ".", "rew_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "rewards", "[", ":", ",", "agent_i", "]", "\n", "self", ".", "emp_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "emps", "[", ":", ",", "agent_i", "]", "\n", "self", ".", "next_obs_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "np", ".", "vstack", "(", "\n", "next_observations", "[", ":", ",", "agent_i", "]", ")", "\n", "self", ".", "done_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "dones", "[", ":", ",", "agent_i", "]", "\n", "", "self", ".", "curr_i", "+=", "nentries", "\n", "if", "self", ".", "filled_i", "<", "self", ".", "max_steps", ":", "\n", "            ", "self", ".", "filled_i", "+=", "nentries", "\n", "", "if", "self", ".", "curr_i", "==", "self", ".", "max_steps", ":", "\n", "            ", "self", ".", "curr_i", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.buffer.ReplayBuffer.sample": [[79, 106], ["numpy.random.choice", "numpy.arange", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "cast", "cast", "cast", "cast", "cast", "cast", "cast", "cast", "torch.Tensor", "range", "range", "range", "range", "range", "range", "range", "range", "torch.autograd.Variable", "[].std", "[].std", "torch.Tensor", "[].mean", "[].mean"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "def", "sample", "(", "self", ",", "N", ",", "to_gpu", "=", "False", ",", "norm_rews", "=", "True", ")", ":", "\n", "        ", "inds", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "filled_i", ")", ",", "size", "=", "N", ",", "\n", "replace", "=", "False", ")", "\n", "if", "to_gpu", ":", "\n", "            ", "cast", "=", "lambda", "x", ":", "Variable", "(", "Tensor", "(", "x", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "cast", "=", "lambda", "x", ":", "Variable", "(", "Tensor", "(", "x", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "if", "norm_rews", ":", "\n", "            ", "ret_rews", "=", "[", "cast", "(", "(", "self", ".", "rew_buffs", "[", "i", "]", "[", "inds", "]", "-", "\n", "self", ".", "rew_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "mean", "(", ")", ")", "/", "\n", "self", ".", "rew_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "std", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "ret_emps", "=", "[", "cast", "(", "(", "self", ".", "emp_buffs", "[", "i", "]", "[", "inds", "]", "-", "\n", "self", ".", "emp_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "mean", "(", ")", ")", "/", "\n", "self", ".", "emp_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "std", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "", "else", ":", "\n", "            ", "ret_rews", "=", "[", "cast", "(", "self", ".", "rew_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "ret_emps", "=", "[", "cast", "(", "self", ".", "emp_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "\n", "", "return", "(", "[", "cast", "(", "self", ".", "obs_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", ",", "\n", "[", "cast", "(", "self", ".", "ac_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", ",", "\n", "ret_rews", ",", "\n", "ret_emps", ",", "\n", "[", "cast", "(", "self", ".", "next_obs_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", ",", "\n", "[", "cast", "(", "self", ".", "done_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.buffer.ReplayBuffer.get_average_rewards": [[107, 113], ["numpy.arange", "numpy.arange", "[].mean", "max", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "get_average_rewards", "(", "self", ",", "N", ")", ":", "\n", "        ", "if", "self", ".", "filled_i", "==", "self", ".", "max_steps", ":", "\n", "            ", "inds", "=", "np", ".", "arange", "(", "self", ".", "curr_i", "-", "N", ",", "self", ".", "curr_i", ")", "# allow for negative indexing", "\n", "", "else", ":", "\n", "            ", "inds", "=", "np", ".", "arange", "(", "max", "(", "0", ",", "self", ".", "curr_i", "-", "N", ")", ",", "self", ".", "curr_i", ")", "\n", "", "return", "[", "self", ".", "rew_buffs", "[", "i", "]", "[", "inds", "]", ".", "mean", "(", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.MLPNetwork.__init__": [[9, 48], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "networks.ConvolutionalUnit", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "networks.MLPNetwork.in_fn.weight.data.fill_", "networks.MLPNetwork.in_fn.bias.data.fill_", "networks.RecurrentUnit", "torch.Linear", "torch.Linear", "torch.Linear", "networks.MLPNetwork.fc3.weight.data.uniform_"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "input_dim", ",", "out_dim", ",", "hidden_dim", "=", "64", ",", "nonlin", "=", "F", ".", "relu", ",", "\n", "constrain_out", "=", "False", ",", "norm_in", "=", "True", ",", "discrete_action", "=", "True", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            input_dim (int): Number of dimensions in input\n            out_dim (int): Number of dimensions in output\n            hidden_dim (int): Number of hidden dimensions\n            nonlin (PyTorch function): Nonlinearity to apply to hidden layers\n        \"\"\"", "\n", "super", "(", "MLPNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "convolutional", ":", "\n", "            ", "self", ".", "emb", "=", "ConvolutionalUnit", "(", "input_dim", "=", "4", ")", "\n", "input_dim", "=", "hidden_dim", "\n", "", "else", ":", "\n", "            ", "self", ".", "emb", "=", "lambda", "x", ":", "x", "\n", "\n", "", "if", "norm_in", ":", "# normalize inputs", "\n", "            ", "self", ".", "in_fn", "=", "nn", ".", "BatchNorm1d", "(", "input_dim", ")", "\n", "self", ".", "in_fn", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "in_fn", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "in_fn", "=", "lambda", "x", ":", "x", "\n", "\n", "", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", "\n", "\n", "if", "recurrent", ":", "\n", "            ", "self", ".", "fc2", "=", "RecurrentUnit", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "\n", "", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "out_dim", ")", "\n", "self", ".", "nonlin", "=", "nonlin", "\n", "if", "constrain_out", "and", "not", "discrete_action", ":", "\n", "# initialize small to prevent saturation", "\n", "            ", "self", ".", "fc3", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "3e-3", ",", "3e-3", ")", "\n", "self", ".", "out_fn", "=", "F", ".", "tanh", "\n", "", "else", ":", "# logits for discrete action (will softmax later)", "\n", "            ", "self", ".", "out_fn", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.MLPNetwork.forward": [[49, 61], ["networks.MLPNetwork.emb", "networks.MLPNetwork.nonlin", "networks.MLPNetwork.nonlin", "networks.MLPNetwork.out_fn", "networks.MLPNetwork.fc1", "networks.MLPNetwork.fc2", "networks.MLPNetwork.fc3", "networks.MLPNetwork.in_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "X", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            X (PyTorch Matrix): Batch of observations\n        Outputs:\n            out (PyTorch Matrix): Output of network (actions, values, etc)\n        \"\"\"", "\n", "X", "=", "self", ".", "emb", "(", "X", ")", "\n", "h1", "=", "self", ".", "nonlin", "(", "self", ".", "fc1", "(", "self", ".", "in_fn", "(", "X", ")", ")", ")", "\n", "h2", "=", "self", ".", "nonlin", "(", "self", ".", "fc2", "(", "h1", ")", ")", "\n", "out", "=", "self", ".", "out_fn", "(", "self", ".", "fc3", "(", "h2", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.DMLPNetwork.__init__": [[67, 109], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "networks.ConvolutionalUnit", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "networks.DMLPNetwork.in_fn.weight.data.fill_", "networks.DMLPNetwork.in_fn.bias.data.fill_", "networks.RecurrentUnit", "torch.Linear", "torch.Linear", "torch.Linear", "networks.DMLPNetwork.fc3.weight.data.uniform_"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "input_a_dim", ",", "input_x_dim", ",", "out_dim", ",", "hidden_dim", "=", "64", ",", "nonlin", "=", "F", ".", "relu", ",", "\n", "constrain_out", "=", "False", ",", "norm_in", "=", "True", ",", "discrete_action", "=", "True", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            input_dim (int): Number of dimensions in input\n            out_dim (int): Number of dimensions in output\n            hidden_dim (int): Number of hidden dimensions\n            nonlin (PyTorch function): Nonlinearity to apply to hidden layers\n        \"\"\"", "\n", "super", "(", "DMLPNetwork", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "convolutional", ":", "\n", "            ", "self", ".", "embS", "=", "ConvolutionalUnit", "(", "input_dim", "=", "input_x_dim", ")", "\n", "input_dim", "=", "hidden_dim", "+", "input_a_dim", "\n", "", "else", ":", "\n", "            ", "self", ".", "embS", "=", "nn", ".", "Linear", "(", "input_x_dim", ",", "hidden_dim", ")", "\n", "input_dim", "=", "hidden_dim", "+", "input_a_dim", "\n", "\n", "", "self", ".", "embA", "=", "nn", ".", "Linear", "(", "input_a_dim", ",", "input_a_dim", ")", "\n", "\n", "if", "norm_in", ":", "# normalize inputs", "\n", "            ", "self", ".", "in_fn", "=", "nn", ".", "BatchNorm1d", "(", "input_dim", ")", "\n", "self", ".", "in_fn", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "self", ".", "in_fn", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "in_fn", "=", "lambda", "x", ":", "x", "\n", "\n", "", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", "\n", "\n", "if", "recurrent", ":", "\n", "            ", "self", ".", "fc2", "=", "RecurrentUnit", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "\n", "", "self", ".", "fc3", "=", "nn", ".", "Linear", "(", "hidden_dim", ",", "out_dim", ")", "\n", "self", ".", "nonlin", "=", "nonlin", "\n", "if", "constrain_out", "and", "not", "discrete_action", ":", "\n", "# initialize small to prevent saturation", "\n", "            ", "self", ".", "fc3", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "3e-3", ",", "3e-3", ")", "\n", "self", ".", "out_fn", "=", "F", ".", "tanh", "\n", "", "else", ":", "# logits for discrete action (will softmax later)", "\n", "            ", "self", ".", "out_fn", "=", "lambda", "x", ":", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.DMLPNetwork.forward": [[110, 125], ["networks.DMLPNetwork.embS", "networks.DMLPNetwork.embA", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "networks.DMLPNetwork.nonlin", "networks.DMLPNetwork.nonlin", "networks.DMLPNetwork.out_fn", "networks.DMLPNetwork.fc1", "networks.DMLPNetwork.fc2", "networks.DMLPNetwork.fc3", "networks.DMLPNetwork.in_fn"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "I", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            X (PyTorch Matrix): Batch of observations\n        Outputs:\n            out (PyTorch Matrix): Output of network (actions, values, etc)\n        \"\"\"", "\n", "(", "S", ",", "A", ")", "=", "(", "I", "[", "0", "]", ",", "I", "[", "1", "]", ")", "\n", "S", "=", "self", ".", "embS", "(", "S", ")", "\n", "A", "=", "self", ".", "embA", "(", "A", ")", "\n", "X", "=", "torch", ".", "cat", "(", "(", "S", ",", "A", ")", ",", "dim", "=", "1", ")", "\n", "h1", "=", "self", ".", "nonlin", "(", "self", ".", "fc1", "(", "self", ".", "in_fn", "(", "X", ")", ")", ")", "\n", "h2", "=", "self", ".", "nonlin", "(", "self", ".", "fc2", "(", "h1", ")", ")", "\n", "out", "=", "self", ".", "out_fn", "(", "self", ".", "fc3", "(", "h2", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.RecurrentUnit.__init__": [[128, 133], ["torch.Module.__init__", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ",", "out_dim", ")", ":", "\n", "        ", "super", "(", "RecurrentUnit", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "input_dim", ",", "out_dim", ")", "\n", "self", ".", "h_0", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "input_dim", ")", ")", "\n", "self", ".", "c_0", "=", "nn", ".", "Parameter", "(", "torch", ".", "randn", "(", "input_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.RecurrentUnit.init_state": [[134, 138], ["networks.RecurrentUnit.h_0.repeat", "networks.RecurrentUnit.c_0.repeat"], "methods", ["None"], ["", "def", "init_state", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "h_0", "=", "self", ".", "h_0", ".", "repeat", "(", "1", ",", "batch_size", ",", "1", ")", "\n", "c_0", "=", "self", ".", "c_0", ".", "repeat", "(", "1", ",", "batch_size", ",", "1", ")", "\n", "return", "(", "h_0", ",", "c_0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.RecurrentUnit.forward": [[139, 144], ["networks.RecurrentUnit.init_state", "networks.RecurrentUnit.lstm", "x.view", "x.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.RecurrentUnit.init_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.lstm"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", ",", "feat_size", "=", "x", ".", "shape", "\n", "state", "=", "self", ".", "init_state", "(", "batch_size", ")", "\n", "x", ",", "_", "=", "self", ".", "lstm", "(", "x", ".", "unsqueeze", "(", "0", ")", ",", "state", ")", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "feat_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.ConvolutionalUnit.__init__": [[147, 165], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "networks.ConvolutionalUnit.apply", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_dim", ")", ":", "\n", "        ", "super", "(", "ConvolutionalUnit", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_dim", "=", "64", "\n", "self", ".", "out_dim", "=", "64", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "#layer_helper = lambda i, k, s: (i - k) / s + 1", "\n", "self", ".", "cnn", "=", "nn", ".", "Sequential", "(", "# input shape (4, 16, 16)", "\n", "nn", ".", "Conv2d", "(", "self", ".", "input_dim", ",", "8", ",", "kernel_size", "=", "4", ",", "stride", "=", "2", ")", ",", "# out  (8, 7, 7)", "\n", "nn", ".", "ReLU", "(", ")", ",", "# activation", "\n", "nn", ".", "Conv2d", "(", "8", ",", "16", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "# out  (16, 5, 5)", "\n", "nn", ".", "ReLU", "(", ")", ",", "# activation", "\n", "nn", ".", "Conv2d", "(", "16", ",", "32", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "# out (16, 3, 3)", "\n", "nn", ".", "ReLU", "(", ")", ",", "# activation", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ")", ",", "# out (64, 1, 1)", "\n", "nn", ".", "ReLU", "(", ")", ",", "# activation", "\n", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "nn", ".", "Linear", "(", "self", ".", "hidden_dim", ",", "self", ".", "out_dim", ")", ",", "nn", ".", "ReLU", "(", ")", ")", "\n", "self", ".", "apply", "(", "self", ".", "_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.ConvolutionalUnit._weights_init": [[166, 171], ["isinstance", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.constant_", "torch.init.constant_", "torch.init.constant_", "torch.init.calculate_gain", "torch.init.calculate_gain", "torch.init.calculate_gain"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_weights_init", "(", "m", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "nn", ".", "init", ".", "xavier_uniform_", "(", "m", ".", "weight", ",", "gain", "=", "nn", ".", "init", ".", "calculate_gain", "(", "'relu'", ")", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.networks.ConvolutionalUnit.forward": [[172, 177], ["networks.ConvolutionalUnit.cnn", "x.view.view.view", "networks.ConvolutionalUnit.fc", "x.view.view.view"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch", ",", "channels", ",", "w", ",", "h", "=", "x", ".", "shape", "\n", "x", "=", "self", ".", "cnn", "(", "x", ".", "view", "(", "batch", ",", "channels", ",", "w", ",", "h", ")", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_dim", ")", "\n", "return", "self", ".", "fc", "(", "x", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.make_env.make_env": [[15, 47], ["scenarios.load().Scenario", "scenarios.load().Scenario.make_world", "MultiAgentEnv", "MultiAgentEnv", "scenarios.load"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.make_world", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load"], ["def", "make_env", "(", "scenario_name", ",", "benchmark", "=", "False", ",", "discrete_action", "=", "False", ")", ":", "\n", "    ", "'''\n    Creates a MultiAgentEnv object as env. This can be used similar to a gym\n    environment by calling env.reset() and env.step().\n    Use env.render() to view the environment on the screen.\n\n    Input:\n        scenario_name   :   name of the scenario from ./scenarios/ to be Returns\n                            (without the .py extension)\n        benchmark       :   whether you want to produce benchmarking data\n                            (usually only done during evaluation)\n\n    Some useful env properties (see environment.py):\n        .observation_space  :   Returns the observation space for each agent\n        .action_space       :   Returns the action space for each agent\n        .n                  :   Returns the number of Agents\n    '''", "\n", "from", "multiagent", ".", "environment", "import", "MultiAgentEnv", "\n", "import", "multiagent", ".", "scenarios", "as", "scenarios", "\n", "\n", "# load scenario from script", "\n", "scenario", "=", "scenarios", ".", "load", "(", "scenario_name", "+", "\".py\"", ")", ".", "Scenario", "(", ")", "\n", "# create world", "\n", "world", "=", "scenario", ".", "make_world", "(", ")", "\n", "# create multiagent environment", "\n", "if", "benchmark", ":", "\n", "        ", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "\n", "scenario", ".", "observation", ",", "scenario", ".", "benchmark_data", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "MultiAgentEnv", "(", "world", ",", "scenario", ".", "reset_world", ",", "scenario", ".", "reward", ",", "\n", "scenario", ".", "observation", ")", "\n", "", "return", "env", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.soft_update": [[9, 20], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "function", ["None"], ["def", "soft_update", "(", "target", ",", "source", ",", "tau", ")", ":", "\n", "    ", "\"\"\"\n    Perform DDPG soft update (move target params toward source based on weight\n    factor tau)\n    Inputs:\n        target (torch.nn.Module): Net to copy parameters to\n        source (torch.nn.Module): Net whose parameters to copy\n        tau (float, 0 < x < 1): Weight factor for update\n    \"\"\"", "\n", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "target_param", ".", "data", ".", "copy_", "(", "target_param", ".", "data", "*", "(", "1.0", "-", "tau", ")", "+", "param", ".", "data", "*", "tau", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.hard_update": [[22, 31], ["zip", "target.parameters", "source.parameters", "target_param.data.copy_"], "function", ["None"], ["", "", "def", "hard_update", "(", "target", ",", "source", ")", ":", "\n", "    ", "\"\"\"\n    Copy network parameters from source to target\n    Inputs:\n        target (torch.nn.Module): Net to copy parameters to\n        source (torch.nn.Module): Net whose parameters to copy\n    \"\"\"", "\n", "for", "target_param", ",", "param", "in", "zip", "(", "target", ".", "parameters", "(", ")", ",", "source", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "target_param", ".", "data", ".", "copy_", "(", "param", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.average_gradients": [[33, 39], ["float", "model.parameters", "torch.get_world_size", "torch.all_reduce"], "function", ["None"], ["", "", "def", "average_gradients", "(", "model", ")", ":", "\n", "    ", "\"\"\" Gradient averaging. \"\"\"", "\n", "size", "=", "float", "(", "dist", ".", "get_world_size", "(", ")", ")", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "dist", ".", "all_reduce", "(", "param", ".", "grad", ".", "data", ",", "op", "=", "dist", ".", "reduce_op", ".", "SUM", ",", "group", "=", "0", ")", "\n", "param", ".", "grad", ".", "data", "/=", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.init_processes": [[41, 47], ["torch.init_process_group", "fn"], "function", ["None"], ["", "", "def", "init_processes", "(", "rank", ",", "size", ",", "fn", ",", "backend", "=", "'gloo'", ")", ":", "\n", "    ", "\"\"\" Initialize the distributed environment. \"\"\"", "\n", "os", ".", "environ", "[", "'MASTER_ADDR'", "]", "=", "'127.0.0.1'", "\n", "os", ".", "environ", "[", "'MASTER_PORT'", "]", "=", "'29500'", "\n", "dist", ".", "init_process_group", "(", "backend", ",", "rank", "=", "rank", ",", "world_size", "=", "size", ")", "\n", "fn", "(", "rank", ",", "size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits": [[48, 63], ["torch.autograd.Variable", "torch.stack", "torch.stack", "torch.stack", "torch.eye", "torch.eye", "torch.eye", "enumerate", "logits.max", "numpy.random.choice", "torch.rand", "torch.rand", "torch.rand", "range"], "function", ["None"], ["", "def", "onehot_from_logits", "(", "logits", ",", "eps", "=", "0.0", ")", ":", "\n", "    ", "\"\"\"\n    Given batch of logits, return one-hot sample using epsilon greedy strategy\n    (based on given epsilon)\n    \"\"\"", "\n", "# get best (according to current policy) actions in one-hot form", "\n", "argmax_acs", "=", "(", "logits", "==", "logits", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "[", "0", "]", ")", ".", "float", "(", ")", "\n", "if", "eps", "==", "0.0", ":", "\n", "        ", "return", "argmax_acs", "\n", "# get random actions in one-hot form", "\n", "", "rand_acs", "=", "Variable", "(", "torch", ".", "eye", "(", "logits", ".", "shape", "[", "1", "]", ")", "[", "[", "np", ".", "random", ".", "choice", "(", "\n", "range", "(", "logits", ".", "shape", "[", "1", "]", ")", ",", "size", "=", "logits", ".", "shape", "[", "0", "]", ")", "]", "]", ",", "requires_grad", "=", "False", ")", "\n", "# chooses between best and random actions using epsilon greedy", "\n", "return", "torch", ".", "stack", "(", "[", "argmax_acs", "[", "i", "]", "if", "r", ">", "eps", "else", "rand_acs", "[", "i", "]", "for", "i", ",", "r", "in", "\n", "enumerate", "(", "torch", ".", "rand", "(", "logits", ".", "shape", "[", "0", "]", ")", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.sample_gumbel": [[65, 69], ["torch.autograd.Variable", "tens_type().uniform_", "torch.log", "torch.log", "torch.log", "tens_type", "torch.log", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "sample_gumbel", "(", "shape", ",", "eps", "=", "1e-20", ",", "tens_type", "=", "torch", ".", "FloatTensor", ")", ":", "\n", "    ", "\"\"\"Sample from Gumbel(0, 1)\"\"\"", "\n", "U", "=", "Variable", "(", "tens_type", "(", "*", "shape", ")", ".", "uniform_", "(", ")", ",", "requires_grad", "=", "False", ")", "\n", "return", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "U", "+", "eps", ")", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax_sample": [[71, 78], ["torch.softmax", "misc.sample_gumbel", "sample_gumbel().cuda", "type", "misc.sample_gumbel", "type"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.sample_gumbel", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.sample_gumbel"], ["", "def", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "\"\"\" Draw a sample from the Gumbel-Softmax distribution\"\"\"", "\n", "if", "device", "==", "'cpu'", ":", "\n", "        ", "y", "=", "logits", "+", "sample_gumbel", "(", "logits", ".", "shape", ",", "tens_type", "=", "type", "(", "logits", ".", "data", ")", ")", "\n", "", "else", ":", "\n", "        ", "y", "=", "logits", "+", "sample_gumbel", "(", "logits", ".", "shape", ",", "tens_type", "=", "type", "(", "logits", ".", "data", ")", ")", ".", "cuda", "(", ")", "\n", "", "return", "F", ".", "softmax", "(", "y", "/", "temperature", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax": [[80, 96], ["misc.gumbel_softmax_sample", "misc.onehot_from_logits"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax_sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits"], ["", "def", "gumbel_softmax", "(", "logits", ",", "temperature", "=", "1.0", ",", "hard", "=", "False", ",", "device", "=", "'cpu'", ")", ":", "\n", "    ", "\"\"\"Sample from the Gumbel-Softmax distribution and optionally discretize.\n    Args:\n      logits: [batch_size, n_class] unnormalized log-probs\n      temperature: non-negative scalar\n      hard: if True, take argmax, but differentiate w.r.t. soft sample y\n    Returns:\n      [batch_size, n_class] sample from the Gumbel-Softmax distribution.\n      If hard=True, then the returned sample will be one-hot, otherwise it will\n      be a probabilitiy distribution that sums to 1 across classes\n    \"\"\"", "\n", "y", "=", "gumbel_softmax_sample", "(", "logits", ",", "temperature", ",", "device", ")", "\n", "if", "hard", ":", "\n", "        ", "y_hard", "=", "onehot_from_logits", "(", "y", ")", "\n", "y", "=", "(", "y_hard", "-", "y", ")", ".", "detach", "(", ")", "+", "y", "\n", "", "return", "y", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.__init__": [[50, 71], ["len", "zip", "env_wrappers.SubprocVecEnv.remotes[].send", "env_wrappers.SubprocVecEnv.remotes[].recv", "env_wrappers.SubprocVecEnv.remotes[].send", "env_wrappers.SubprocVecEnv.remotes[].recv", "baselines.common.vec_env.VecEnv.__init__", "multiprocessing.Process", "p.start", "remote.close", "len", "zip", "multiprocessing.Pipe", "range", "baselines.common.vec_env.CloudpickleWrapper"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["    ", "def", "__init__", "(", "self", ",", "env_fns", ",", "spaces", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        envs: list of gym environments to run in subprocesses\n        \"\"\"", "\n", "self", ".", "waiting", "=", "False", "\n", "self", ".", "closed", "=", "False", "\n", "nenvs", "=", "len", "(", "env_fns", ")", "\n", "self", ".", "remotes", ",", "self", ".", "work_remotes", "=", "zip", "(", "*", "[", "Pipe", "(", ")", "for", "_", "in", "range", "(", "nenvs", ")", "]", ")", "\n", "self", ".", "ps", "=", "[", "Process", "(", "target", "=", "worker", ",", "args", "=", "(", "work_remote", ",", "remote", ",", "CloudpickleWrapper", "(", "env_fn", ")", ")", ")", "\n", "for", "(", "work_remote", ",", "remote", ",", "env_fn", ")", "in", "zip", "(", "self", ".", "work_remotes", ",", "self", ".", "remotes", ",", "env_fns", ")", "]", "\n", "for", "p", "in", "self", ".", "ps", ":", "\n", "            ", "p", ".", "daemon", "=", "True", "# if the main process crashes, we should not cause things to hang", "\n", "p", ".", "start", "(", ")", "\n", "", "for", "remote", "in", "self", ".", "work_remotes", ":", "\n", "            ", "remote", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "remotes", "[", "0", "]", ".", "send", "(", "(", "'get_spaces'", ",", "None", ")", ")", "\n", "observation_space", ",", "action_space", "=", "self", ".", "remotes", "[", "0", "]", ".", "recv", "(", ")", "\n", "self", ".", "remotes", "[", "0", "]", ".", "send", "(", "(", "'get_agent_types'", ",", "None", ")", ")", "\n", "self", ".", "agent_types", "=", "self", ".", "remotes", "[", "0", "]", ".", "recv", "(", ")", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "observation_space", ",", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.step_async": [[72, 76], ["zip", "remote.send"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "for", "remote", ",", "action", "in", "zip", "(", "self", ".", "remotes", ",", "actions", ")", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'step'", ",", "action", ")", ")", "\n", "", "self", ".", "waiting", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.step_wait": [[77, 82], ["zip", "remote.recv", "numpy.stack", "numpy.stack", "numpy.stack"], "methods", ["None"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "results", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "self", ".", "waiting", "=", "False", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "zip", "(", "*", "results", ")", "\n", "return", "np", ".", "stack", "(", "obs", ")", ",", "np", ".", "stack", "(", "rews", ")", ",", "np", ".", "stack", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.reset": [[83, 87], ["numpy.stack", "remote.send", "remote.recv"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'reset'", ",", "None", ")", ")", "\n", "", "return", "np", ".", "stack", "(", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.reset_task": [[88, 92], ["numpy.stack", "remote.send", "remote.recv"], "methods", ["None"], ["", "def", "reset_task", "(", "self", ")", ":", "\n", "        ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'reset_task'", ",", "None", ")", ")", "\n", "", "return", "np", ".", "stack", "(", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.close": [[93, 104], ["remote.send", "p.join", "remote.recv"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "closed", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "waiting", ":", "\n", "            ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "                ", "remote", ".", "recv", "(", ")", "\n", "", "", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'close'", ",", "None", ")", ")", "\n", "", "for", "p", "in", "self", ".", "ps", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "", "self", ".", "closed", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.get_positions": [[105, 109], ["numpy.stack", "remote.send", "remote.recv"], "methods", ["None"], ["", "def", "get_positions", "(", "self", ")", ":", "\n", "        ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'get_positions'", ",", "None", ")", ")", "\n", "", "return", "np", ".", "stack", "(", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.get_landmark_positions": [[110, 114], ["numpy.stack", "remote.send", "remote.recv"], "methods", ["None"], ["", "def", "get_landmark_positions", "(", "self", ")", ":", "\n", "        ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'get_landmark_positions'", ",", "None", ")", ")", "\n", "", "return", "np", ".", "stack", "(", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.get_communications": [[115, 119], ["numpy.stack", "remote.send", "remote.recv"], "methods", ["None"], ["", "def", "get_communications", "(", "self", ")", ":", "\n", "        ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'get_communications'", ",", "None", ")", ")", "\n", "", "return", "np", ".", "stack", "(", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.__init__": [[122, 133], ["baselines.common.vec_env.VecEnv.__init__", "all", "numpy.zeros", "fn", "len", "len", "hasattr"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env_fns", ")", ":", "\n", "        ", "self", ".", "envs", "=", "[", "fn", "(", ")", "for", "fn", "in", "env_fns", "]", "\n", "env", "=", "self", ".", "envs", "[", "0", "]", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", "\n", "if", "all", "(", "[", "hasattr", "(", "a", ",", "'adversary'", ")", "for", "a", "in", "env", ".", "agents", "]", ")", ":", "\n", "            ", "self", ".", "agent_types", "=", "[", "'adversary'", "if", "a", ".", "adversary", "else", "'agent'", "for", "a", "in", "\n", "env", ".", "agents", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "agent_types", "=", "[", "'agent'", "for", "_", "in", "env", ".", "agents", "]", "\n", "", "self", ".", "ts", "=", "np", ".", "zeros", "(", "len", "(", "self", ".", "envs", ")", ",", "dtype", "=", "'int'", ")", "\n", "self", ".", "actions", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.step_async": [[134, 136], ["None"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "actions", "=", "actions", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.step_wait": [[137, 147], ["map", "enumerate", "env.step", "zip", "all", "numpy.array", "numpy.array", "numpy.array", "zip", "env_wrappers.DummyVecEnv.envs[].reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "results", "=", "[", "env", ".", "step", "(", "a", ")", "for", "(", "a", ",", "env", ")", "in", "zip", "(", "self", ".", "actions", ",", "self", ".", "envs", ")", "]", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "map", "(", "np", ".", "array", ",", "zip", "(", "*", "results", ")", ")", "\n", "self", ".", "ts", "+=", "1", "\n", "for", "(", "i", ",", "done", ")", "in", "enumerate", "(", "dones", ")", ":", "\n", "            ", "if", "all", "(", "done", ")", ":", "\n", "                ", "obs", "[", "i", "]", "=", "self", ".", "envs", "[", "i", "]", ".", "reset", "(", ")", "\n", "self", ".", "ts", "[", "i", "]", "=", "0", "\n", "", "", "self", ".", "actions", "=", "None", "\n", "return", "np", ".", "array", "(", "obs", ")", ",", "np", ".", "array", "(", "rews", ")", ",", "np", ".", "array", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.reset": [[148, 151], ["numpy.array", "env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "results", "=", "[", "env", ".", "reset", "(", ")", "for", "env", "in", "self", ".", "envs", "]", "\n", "return", "np", ".", "array", "(", "results", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.close": [[152, 154], ["None"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.get_positions": [[155, 157], ["numpy.array", "env.get_positions"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_positions"], ["", "def", "get_positions", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "env", ".", "get_positions", "(", ")", "for", "env", "in", "self", ".", "envs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.get_landmark_positions": [[158, 160], ["numpy.array", "env.get_landmark_positions"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_landmark_positions"], ["", "def", "get_landmark_positions", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "env", ".", "get_landmark_positions", "(", ")", "for", "env", "in", "self", ".", "envs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.DummyVecEnv.get_communications": [[161, 163], ["numpy.array", "env.get_communications"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_communications"], ["", "def", "get_communications", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "array", "(", "[", "env", ".", "get_communications", "(", ")", "for", "env", "in", "self", ".", "envs", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.worker": [[9, 47], ["parent_remote.close", "env_fn_wrapper.x", "remote.recv", "env_fn_wrapper.x.step", "all", "remote.send", "env_fn_wrapper.x.reset", "env_fn_wrapper.x.reset", "remote.send", "env_fn_wrapper.x.get_positions", "remote.send", "env_fn_wrapper.x.get_landmark_positions", "remote.send", "env_fn_wrapper.x.get_communications", "remote.send", "env_fn_wrapper.x.reset_task", "remote.send", "remote.close", "remote.send", "all", "remote.send", "remote.send", "hasattr"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_positions", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_landmark_positions", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_communications", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.env_wrappers.SubprocVecEnv.reset_task", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["def", "worker", "(", "remote", ",", "parent_remote", ",", "env_fn_wrapper", ")", ":", "\n", "    ", "parent_remote", ".", "close", "(", ")", "\n", "env", "=", "env_fn_wrapper", ".", "x", "(", ")", "\n", "while", "True", ":", "\n", "        ", "cmd", ",", "data", "=", "remote", ".", "recv", "(", ")", "\n", "if", "cmd", "==", "'step'", ":", "\n", "            ", "ob", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "data", ")", "\n", "if", "all", "(", "done", ")", ":", "\n", "                ", "ob", "=", "env", ".", "reset", "(", ")", "\n", "", "remote", ".", "send", "(", "(", "ob", ",", "reward", ",", "done", ",", "info", ")", ")", "\n", "", "elif", "cmd", "==", "'reset'", ":", "\n", "            ", "ob", "=", "env", ".", "reset", "(", ")", "\n", "remote", ".", "send", "(", "ob", ")", "\n", "", "elif", "cmd", "==", "'get_positions'", ":", "\n", "            ", "positions", "=", "env", ".", "get_positions", "(", ")", "\n", "remote", ".", "send", "(", "positions", ")", "\n", "", "elif", "cmd", "==", "'get_landmark_positions'", ":", "\n", "            ", "positions", "=", "env", ".", "get_landmark_positions", "(", ")", "\n", "remote", ".", "send", "(", "positions", ")", "\n", "", "elif", "cmd", "==", "'get_communications'", ":", "\n", "            ", "positions", "=", "env", ".", "get_communications", "(", ")", "\n", "remote", ".", "send", "(", "positions", ")", "\n", "", "elif", "cmd", "==", "'reset_task'", ":", "\n", "            ", "ob", "=", "env", ".", "reset_task", "(", ")", "\n", "remote", ".", "send", "(", "ob", ")", "\n", "", "elif", "cmd", "==", "'close'", ":", "\n", "            ", "remote", ".", "close", "(", ")", "\n", "break", "\n", "", "elif", "cmd", "==", "'get_spaces'", ":", "\n", "            ", "remote", ".", "send", "(", "(", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", ")", "\n", "", "elif", "cmd", "==", "'get_agent_types'", ":", "\n", "            ", "if", "all", "(", "[", "hasattr", "(", "a", ",", "'adversary'", ")", "for", "a", "in", "env", ".", "agents", "]", ")", ":", "\n", "                ", "remote", ".", "send", "(", "[", "'adversary'", "if", "a", ".", "adversary", "else", "'agent'", "for", "a", "in", "\n", "env", ".", "agents", "]", ")", "\n", "", "else", ":", "\n", "                ", "remote", ".", "send", "(", "[", "'agent'", "for", "_", "in", "env", ".", "agents", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.__init__": [[13, 68], ["networks.MLPNetwork", "networks.MLPNetwork", "misc.hard_update", "misc.hard_update", "torch.optim.Adam", "torch.optim.Adam", "networks.DMLPNetwork", "networks.DMLPNetwork", "networks.MLPNetwork", "networks.MLPNetwork", "agents.DDPGAgent.policy.parameters", "agents.DDPGAgent.critic.parameters", "noise.OUNoise"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.hard_update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.hard_update"], ["def", "__init__", "(", "self", ",", "num_in_pol", ",", "num_out_pol", ",", "num_in_critic", ",", "hidden_dim", "=", "64", ",", "\n", "lr", "=", "0.01", ",", "discrete_action", "=", "True", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            num_in_pol (int): number of dimensions for policy input\n            num_out_pol (int): number of dimensions for policy output\n            num_in_critic (int): number of dimensions for critic input\n        \"\"\"", "\n", "self", ".", "policy", "=", "MLPNetwork", "(", "num_in_pol", ",", "num_out_pol", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "constrain_out", "=", "True", ",", "\n", "discrete_action", "=", "discrete_action", ",", "\n", "recurrent", "=", "recurrent", ",", "\n", "convolutional", "=", "convolutional", ")", "\n", "self", ".", "target_policy", "=", "MLPNetwork", "(", "num_in_pol", ",", "num_out_pol", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "constrain_out", "=", "True", ",", "\n", "discrete_action", "=", "discrete_action", ",", "\n", "recurrent", "=", "recurrent", ",", "\n", "convolutional", "=", "convolutional", ")", "\n", "if", "convolutional", ":", "\n", "            ", "n_agents", "=", "num_in_critic", "//", "(", "num_in_pol", "+", "num_out_pol", ")", "\n", "num_in_a", "=", "num_out_pol", "*", "n_agents", "\n", "num_in_s", "=", "num_in_pol", "*", "n_agents", "\n", "\n", "self", ".", "critic", "=", "DMLPNetwork", "(", "num_in_a", ",", "num_in_s", ",", "1", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "constrain_out", "=", "False", ",", "\n", "recurrent", "=", "recurrent", ",", "\n", "convolutional", "=", "convolutional", ")", "\n", "self", ".", "target_critic", "=", "DMLPNetwork", "(", "num_in_a", ",", "num_in_s", ",", "1", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "constrain_out", "=", "False", ",", "\n", "recurrent", "=", "recurrent", ",", "\n", "convolutional", "=", "convolutional", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "critic", "=", "MLPNetwork", "(", "num_in_critic", ",", "1", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "constrain_out", "=", "False", ",", "\n", "recurrent", "=", "recurrent", ")", "\n", "self", ".", "target_critic", "=", "MLPNetwork", "(", "num_in_critic", ",", "1", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "\n", "constrain_out", "=", "False", ",", "\n", "recurrent", "=", "recurrent", ")", "\n", "\n", "\n", "", "hard_update", "(", "self", ".", "target_policy", ",", "self", ".", "policy", ")", "\n", "hard_update", "(", "self", ".", "target_critic", ",", "self", ".", "critic", ")", "\n", "self", ".", "policy_optimizer", "=", "Adam", "(", "self", ".", "policy", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "self", ".", "critic_optimizer", "=", "Adam", "(", "self", ".", "critic", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "if", "not", "discrete_action", ":", "\n", "            ", "self", ".", "exploration", "=", "OUNoise", "(", "num_out_pol", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "exploration", "=", "0.3", "# epsilon for eps-greedy", "\n", "", "self", ".", "discrete_action", "=", "discrete_action", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.reset_noise": [[69, 72], ["agents.DDPGAgent.exploration.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset_noise", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "discrete_action", ":", "\n", "            ", "self", ".", "exploration", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.scale_noise": [[73, 78], ["None"], "methods", ["None"], ["", "", "def", "scale_noise", "(", "self", ",", "scale", ")", ":", "\n", "        ", "if", "self", ".", "discrete_action", ":", "\n", "            ", "self", ".", "exploration", "=", "scale", "\n", "", "else", ":", "\n", "            ", "self", ".", "exploration", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.step": [[79, 100], ["agents.DDPGAgent.policy", "misc.onehot_from_logits.clamp", "misc.gumbel_softmax", "misc.onehot_from_logits", "torch.autograd.Variable", "torch.Tensor", "agents.DDPGAgent.exploration.noise"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.noise.OUNoise.noise"], ["", "", "def", "step", "(", "self", ",", "obs", ",", "explore", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Take a step forward in environment for a minibatch of observations\n        Inputs:\n            obs (PyTorch Variable): Observations for this agent\n            explore (boolean): Whether or not to add exploration noise\n        Outputs:\n            action (PyTorch Variable): Actions for this agent\n        \"\"\"", "\n", "action", "=", "self", ".", "policy", "(", "obs", ")", "\n", "if", "self", ".", "discrete_action", ":", "\n", "            ", "if", "explore", ":", "\n", "                ", "action", "=", "gumbel_softmax", "(", "action", ",", "hard", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "action", "=", "onehot_from_logits", "(", "action", ")", "\n", "", "", "else", ":", "# continuous action", "\n", "            ", "if", "explore", ":", "\n", "                ", "action", "+=", "Variable", "(", "Tensor", "(", "self", ".", "exploration", ".", "noise", "(", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "\n", "", "action", "=", "action", ".", "clamp", "(", "-", "1", ",", "1", ")", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.get_params": [[101, 108], ["agents.DDPGAgent.policy.state_dict", "agents.DDPGAgent.critic.state_dict", "agents.DDPGAgent.target_policy.state_dict", "agents.DDPGAgent.target_critic.state_dict", "agents.DDPGAgent.policy_optimizer.state_dict", "agents.DDPGAgent.critic_optimizer.state_dict"], "methods", ["None"], ["", "def", "get_params", "(", "self", ")", ":", "\n", "        ", "return", "{", "'policy'", ":", "self", ".", "policy", ".", "state_dict", "(", ")", ",", "\n", "'critic'", ":", "self", ".", "critic", ".", "state_dict", "(", ")", ",", "\n", "'target_policy'", ":", "self", ".", "target_policy", ".", "state_dict", "(", ")", ",", "\n", "'target_critic'", ":", "self", ".", "target_critic", ".", "state_dict", "(", ")", ",", "\n", "'policy_optimizer'", ":", "self", ".", "policy_optimizer", ".", "state_dict", "(", ")", ",", "\n", "'critic_optimizer'", ":", "self", ".", "critic_optimizer", ".", "state_dict", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.load_params": [[109, 116], ["agents.DDPGAgent.policy.load_state_dict", "agents.DDPGAgent.critic.load_state_dict", "agents.DDPGAgent.target_policy.load_state_dict", "agents.DDPGAgent.target_critic.load_state_dict", "agents.DDPGAgent.policy_optimizer.load_state_dict", "agents.DDPGAgent.critic_optimizer.load_state_dict"], "methods", ["None"], ["", "def", "load_params", "(", "self", ",", "params", ")", ":", "\n", "        ", "self", ".", "policy", ".", "load_state_dict", "(", "params", "[", "'policy'", "]", ")", "\n", "self", ".", "critic", ".", "load_state_dict", "(", "params", "[", "'critic'", "]", ")", "\n", "self", ".", "target_policy", ".", "load_state_dict", "(", "params", "[", "'target_policy'", "]", ")", "\n", "self", ".", "target_critic", ".", "load_state_dict", "(", "params", "[", "'target_critic'", "]", ")", "\n", "self", ".", "policy_optimizer", ".", "load_state_dict", "(", "params", "[", "'policy_optimizer'", "]", ")", "\n", "self", ".", "critic_optimizer", ".", "load_state_dict", "(", "params", "[", "'critic_optimizer'", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.EntityState.__init__": [[5, 10], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical position", "\n", "        ", "self", ".", "p_pos", "=", "None", "\n", "# physical velocity", "\n", "self", ".", "p_vel", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.AgentState.__init__": [[13, 17], ["core.EntityState.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "AgentState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# communication utterance", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.Action.__init__": [[20, 25], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# physical action", "\n", "        ", "self", ".", "u", "=", "None", "\n", "# communication action", "\n", "self", ".", "c", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.Entity.__init__": [[28, 48], ["core.EntityState"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# name ", "\n", "        ", "self", ".", "name", "=", "''", "\n", "# properties:", "\n", "self", ".", "size", "=", "0.050", "\n", "# entity can move / be pushed", "\n", "self", ".", "movable", "=", "False", "\n", "# entity collides with others", "\n", "self", ".", "collide", "=", "True", "\n", "# material density (affects mass)", "\n", "self", ".", "density", "=", "25.0", "\n", "# color", "\n", "self", ".", "color", "=", "None", "\n", "# max speed and accel", "\n", "self", ".", "max_speed", "=", "None", "\n", "self", ".", "accel", "=", "None", "\n", "# state", "\n", "self", ".", "state", "=", "EntityState", "(", ")", "\n", "# mass", "\n", "self", ".", "initial_mass", "=", "1.0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.Entity.mass": [[49, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mass", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "initial_mass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.Landmark.__init__": [[55, 57], ["core.Entity.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["     ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Landmark", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.Agent.__init__": [[60, 80], ["core.Entity.__init__", "core.AgentState", "core.Action"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Agent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# agents are movable by default", "\n", "self", ".", "movable", "=", "True", "\n", "# cannot send communication signals", "\n", "self", ".", "silent", "=", "False", "\n", "# cannot observe the world", "\n", "self", ".", "blind", "=", "False", "\n", "# physical motor noise amount", "\n", "self", ".", "u_noise", "=", "None", "\n", "# communication noise amount", "\n", "self", ".", "c_noise", "=", "None", "\n", "# control range", "\n", "self", ".", "u_range", "=", "1.0", "\n", "# state", "\n", "self", ".", "state", "=", "AgentState", "(", ")", "\n", "# action", "\n", "self", ".", "action", "=", "Action", "(", ")", "\n", "# script behavior to execute", "\n", "self", ".", "action_callback", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.Surface.__init__": [[82, 85], ["core.Entity.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Surface", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "v", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.__init__": [[89, 108], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "# list of agents and entities (can change at execution-time!)", "\n", "        ", "self", ".", "agents", "=", "[", "]", "\n", "self", ".", "landmarks", "=", "[", "]", "\n", "self", ".", "obstacles", "=", "[", "]", "\n", "self", ".", "surfaces", "=", "[", "]", "\n", "# communication channel dimensionality", "\n", "self", ".", "dim_c", "=", "0", "\n", "# position dimensionality", "\n", "self", ".", "dim_p", "=", "2", "\n", "# color dimensionality", "\n", "self", ".", "dim_color", "=", "3", "\n", "# simulation timestep", "\n", "self", ".", "dt", "=", "0.1", "\n", "# physical damping", "\n", "self", ".", "damping", "=", "0.25", "\n", "# contact response parameters", "\n", "self", ".", "contact_force", "=", "1e+2", "\n", "self", ".", "contact_margin", "=", "1e-3", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.entities": [[110, 113], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "entities", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "surfaces", "+", "self", ".", "agents", "+", "self", ".", "landmarks", "+", "self", ".", "obstacles", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.policy_agents": [[115, 118], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policy_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.scripted_agents": [[120, 123], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "scripted_agents", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "self", ".", "agents", "if", "agent", ".", "action_callback", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.step": [[125, 140], ["core.World.apply_action_force", "core.World.apply_environment_force", "core.World.integrate_state", "agent.action_callback", "len", "core.World.update_agent_state"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.apply_action_force", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.apply_environment_force", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.integrate_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.update_agent_state"], ["", "def", "step", "(", "self", ")", ":", "\n", "# set actions for scripted agents", "\n", "        ", "for", "agent", "in", "self", ".", "scripted_agents", ":", "\n", "            ", "agent", ".", "action", "=", "agent", ".", "action_callback", "(", "agent", ",", "self", ")", "\n", "# gather forces applied to entities", "\n", "", "p_force", "=", "[", "None", "]", "*", "len", "(", "self", ".", "entities", ")", "\n", "# apply agent physical controls", "\n", "p_force", "=", "self", ".", "apply_action_force", "(", "p_force", ")", "\n", "# apply environment forces", "\n", "p_force", "=", "self", ".", "apply_environment_force", "(", "p_force", ")", "\n", "# integrate physical state", "\n", "self", ".", "integrate_state", "(", "p_force", ")", "\n", "# update agent state", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "self", ".", "update_agent_state", "(", "agent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.apply_action_force": [[142, 149], ["enumerate", "numpy.random.randn"], "methods", ["None"], ["", "", "def", "apply_action_force", "(", "self", ",", "p_force", ")", ":", "\n", "# set applied forces", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "if", "agent", ".", "movable", ":", "\n", "                ", "noise", "=", "np", ".", "random", ".", "randn", "(", "*", "agent", ".", "action", ".", "u", ".", "shape", ")", "*", "agent", ".", "u_noise", "if", "agent", ".", "u_noise", "else", "0.0", "\n", "p_force", "[", "i", "]", "=", "agent", ".", "action", ".", "u", "+", "noise", "\n", "", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.apply_environment_force": [[151, 164], ["enumerate", "enumerate", "core.World.get_collision_force"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.get_collision_force"], ["", "def", "apply_environment_force", "(", "self", ",", "p_force", ")", ":", "\n", "# simple (but inefficient) collision response", "\n", "        ", "for", "a", ",", "entity_a", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "            ", "for", "b", ",", "entity_b", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "                ", "if", "(", "b", "<=", "a", ")", ":", "continue", "\n", "[", "f_a", ",", "f_b", "]", "=", "self", ".", "get_collision_force", "(", "entity_a", ",", "entity_b", ")", "\n", "if", "(", "f_a", "is", "not", "None", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "a", "]", "is", "None", ")", ":", "p_force", "[", "a", "]", "=", "0.0", "\n", "p_force", "[", "a", "]", "=", "f_a", "+", "p_force", "[", "a", "]", "\n", "", "if", "(", "f_b", "is", "not", "None", ")", ":", "\n", "                    ", "if", "(", "p_force", "[", "b", "]", "is", "None", ")", ":", "p_force", "[", "b", "]", "=", "0.0", "\n", "p_force", "[", "b", "]", "=", "f_b", "+", "p_force", "[", "b", "]", "\n", "", "", "", "return", "p_force", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.integrate_state": [[166, 178], ["enumerate", "numpy.sqrt", "numpy.square", "numpy.square", "numpy.sqrt", "numpy.square", "numpy.square"], "methods", ["None"], ["", "def", "integrate_state", "(", "self", ",", "p_force", ")", ":", "\n", "        ", "for", "i", ",", "entity", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "            ", "if", "not", "entity", ".", "movable", ":", "continue", "\n", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "*", "(", "1", "-", "self", ".", "damping", ")", "\n", "if", "(", "p_force", "[", "i", "]", "is", "not", "None", ")", ":", "\n", "                ", "entity", ".", "state", ".", "p_vel", "+=", "(", "p_force", "[", "i", "]", "/", "entity", ".", "mass", ")", "*", "self", ".", "dt", "\n", "", "if", "entity", ".", "max_speed", "is", "not", "None", ":", "\n", "                ", "speed", "=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "\n", "if", "speed", ">", "entity", ".", "max_speed", ":", "\n", "                    ", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "/", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "\n", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "*", "entity", ".", "max_speed", "\n", "", "", "entity", ".", "state", ".", "p_pos", "+=", "entity", ".", "state", ".", "p_vel", "*", "self", ".", "dt", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.update_agent_state": [[179, 186], ["numpy.zeros", "numpy.random.randn"], "methods", ["None"], ["", "", "def", "update_agent_state", "(", "self", ",", "agent", ")", ":", "\n", "# set communication state (directly for now)", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "dim_c", ")", "\n", "", "else", ":", "\n", "            ", "noise", "=", "np", ".", "random", ".", "randn", "(", "*", "agent", ".", "action", ".", "c", ".", "shape", ")", "*", "agent", ".", "c_noise", "if", "agent", ".", "c_noise", "else", "0.0", "\n", "agent", ".", "state", ".", "c", "=", "agent", ".", "action", ".", "c", "+", "noise", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.get_collision_force": [[188, 205], ["numpy.sqrt", "numpy.sum", "numpy.logaddexp", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "get_collision_force", "(", "self", ",", "entity_a", ",", "entity_b", ")", ":", "\n", "        ", "if", "(", "not", "entity_a", ".", "collide", ")", "or", "(", "not", "entity_b", ".", "collide", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# not a collider", "\n", "", "if", "(", "entity_a", "is", "entity_b", ")", ":", "\n", "            ", "return", "[", "None", ",", "None", "]", "# don't collide against itself", "\n", "# compute actual distance between entities", "\n", "", "delta_pos", "=", "entity_a", ".", "state", ".", "p_pos", "-", "entity_b", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "# minimum allowable distance", "\n", "dist_min", "=", "entity_a", ".", "size", "+", "entity_b", ".", "size", "\n", "# softmax penetration", "\n", "k", "=", "self", ".", "contact_margin", "\n", "penetration", "=", "np", ".", "logaddexp", "(", "0", ",", "-", "(", "dist", "-", "dist_min", ")", "/", "k", ")", "*", "k", "\n", "force", "=", "self", ".", "contact_force", "*", "delta_pos", "/", "dist", "*", "penetration", "\n", "force_a", "=", "+", "force", "if", "entity_a", ".", "movable", "else", "None", "\n", "force_b", "=", "-", "force", "if", "entity_b", ".", "movable", "else", "None", "\n", "return", "[", "force_a", ",", "force_b", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.__init__": [[37, 56], ["rendering.get_display", "pyglet.window.Window", "rendering.Transform", "glEnable", "glEnable", "glHint", "glLineWidth", "glBlendFunc"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.get_display"], ["    ", "def", "__init__", "(", "self", ",", "width", ",", "height", ",", "display", "=", "None", ")", ":", "\n", "        ", "display", "=", "get_display", "(", "display", ")", "\n", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "width", "=", "width", ",", "height", "=", "height", ",", "display", "=", "display", ")", "\n", "self", ".", "window", ".", "on_close", "=", "self", ".", "window_closed_by_user", "\n", "self", ".", "geoms", "=", "[", "]", "\n", "self", ".", "onetime_geoms", "=", "[", "]", "\n", "self", ".", "transform", "=", "Transform", "(", ")", "\n", "\n", "glEnable", "(", "GL_BLEND", ")", "\n", "# glEnable(GL_MULTISAMPLE)", "\n", "glEnable", "(", "GL_LINE_SMOOTH", ")", "\n", "# glHint(GL_LINE_SMOOTH_HINT, GL_DONT_CARE)", "\n", "glHint", "(", "GL_LINE_SMOOTH_HINT", ",", "GL_NICEST", ")", "\n", "glLineWidth", "(", "2.0", ")", "\n", "glBlendFunc", "(", "GL_SRC_ALPHA", ",", "GL_ONE_MINUS_SRC_ALPHA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.close": [[57, 59], ["rendering.Viewer.window.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.window_closed_by_user": [[60, 62], ["rendering.Viewer.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "window_closed_by_user", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.set_bounds": [[63, 70], ["rendering.Transform"], "methods", ["None"], ["", "def", "set_bounds", "(", "self", ",", "left", ",", "right", ",", "bottom", ",", "top", ")", ":", "\n", "        ", "assert", "right", ">", "left", "and", "top", ">", "bottom", "\n", "scalex", "=", "self", ".", "width", "/", "(", "right", "-", "left", ")", "\n", "scaley", "=", "self", ".", "height", "/", "(", "top", "-", "bottom", ")", "\n", "self", ".", "transform", "=", "Transform", "(", "\n", "translation", "=", "(", "-", "left", "*", "scalex", ",", "-", "bottom", "*", "scaley", ")", ",", "\n", "scale", "=", "(", "scalex", ",", "scaley", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_geom": [[71, 73], ["rendering.Viewer.geoms.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "add_geom", "(", "self", ",", "geom", ")", ":", "\n", "        ", "self", ".", "geoms", ".", "append", "(", "geom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_onetime": [[74, 76], ["rendering.Viewer.onetime_geoms.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "add_onetime", "(", "self", ",", "geom", ")", ":", "\n", "        ", "self", ".", "onetime_geoms", ".", "append", "(", "geom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.render": [[77, 104], ["glClearColor", "rendering.Viewer.window.clear", "rendering.Viewer.window.switch_to", "rendering.Viewer.window.dispatch_events", "rendering.Viewer.transform.enable", "rendering.Viewer.transform.disable", "rendering.Viewer.window.flip", "geom.render", "geom.render", "pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager().get_color_buffer.get_image_data", "numpy.fromstring", "arr.reshape.reshape.reshape", "pyglet.image.get_buffer_manager().get_color_buffer.get_image_data.get_data", "pyglet.image.get_buffer_manager"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineWidth.enable", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineStyle.disable", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["", "def", "render", "(", "self", ",", "return_rgb_array", "=", "False", ")", ":", "\n", "        ", "glClearColor", "(", "1", ",", "1", ",", "1", ",", "1", ")", "\n", "self", ".", "window", ".", "clear", "(", ")", "\n", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "self", ".", "transform", ".", "enable", "(", ")", "\n", "for", "geom", "in", "self", ".", "geoms", ":", "\n", "            ", "geom", ".", "render", "(", ")", "\n", "", "for", "geom", "in", "self", ".", "onetime_geoms", ":", "\n", "            ", "geom", ".", "render", "(", ")", "\n", "", "self", ".", "transform", ".", "disable", "(", ")", "\n", "arr", "=", "None", "\n", "if", "return_rgb_array", ":", "\n", "            ", "buffer", "=", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", "\n", "image_data", "=", "buffer", ".", "get_image_data", "(", ")", "\n", "arr", "=", "np", ".", "fromstring", "(", "image_data", ".", "get_data", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "''", ")", "\n", "# In https://github.com/openai/gym-http-api/issues/2, we", "\n", "# discovered that someone using Xmonad on Arch was having", "\n", "# a window of size 598 x 398, though a 600 x 400 window", "\n", "# was requested. (Guess Xmonad was preserving a pixel for", "\n", "# the boundary.) So we use the buffer height/width rather", "\n", "# than the requested one.", "\n", "arr", "=", "arr", ".", "reshape", "(", "buffer", ".", "height", ",", "buffer", ".", "width", ",", "4", ")", "\n", "arr", "=", "arr", "[", ":", ":", "-", "1", ",", ":", ",", "0", ":", "3", "]", "\n", "", "self", ".", "window", ".", "flip", "(", ")", "\n", "self", ".", "onetime_geoms", "=", "[", "]", "\n", "return", "arr", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.draw_circle": [[106, 111], ["rendering.make_circle", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_circle", "(", "self", ",", "radius", "=", "10", ",", "res", "=", "30", ",", "filled", "=", "True", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_circle", "(", "radius", "=", "radius", ",", "res", "=", "res", ",", "filled", "=", "filled", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.draw_polygon": [[112, 117], ["rendering.make_polygon", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polygon", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_polygon", "(", "self", ",", "v", ",", "filled", "=", "True", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_polygon", "(", "v", "=", "v", ",", "filled", "=", "filled", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.draw_polyline": [[118, 123], ["rendering.make_polyline", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polyline", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_polyline", "(", "self", ",", "v", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "make_polyline", "(", "v", "=", "v", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.draw_line": [[124, 129], ["rendering.Line", "rendering._add_attrs", "rendering.Viewer.add_onetime"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering._add_attrs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_onetime"], ["", "def", "draw_line", "(", "self", ",", "start", ",", "end", ",", "**", "attrs", ")", ":", "\n", "        ", "geom", "=", "Line", "(", "start", ",", "end", ")", "\n", "_add_attrs", "(", "geom", ",", "attrs", ")", "\n", "self", ".", "add_onetime", "(", "geom", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.get_array": [[130, 137], ["rendering.Viewer.window.flip", "pyglet.image.get_buffer_manager().get_color_buffer().get_image_data", "rendering.Viewer.window.flip", "numpy.fromstring", "arr.reshape.reshape.reshape", "pyglet.image.get_buffer_manager().get_color_buffer", "pyglet.image.get_buffer_manager"], "methods", ["None"], ["", "def", "get_array", "(", "self", ")", ":", "\n", "        ", "self", ".", "window", ".", "flip", "(", ")", "\n", "image_data", "=", "pyglet", ".", "image", ".", "get_buffer_manager", "(", ")", ".", "get_color_buffer", "(", ")", ".", "get_image_data", "(", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "arr", "=", "np", ".", "fromstring", "(", "image_data", ".", "data", ",", "dtype", "=", "np", ".", "uint8", ",", "sep", "=", "''", ")", "\n", "arr", "=", "arr", ".", "reshape", "(", "self", ".", "height", ",", "self", ".", "width", ",", "4", ")", "\n", "return", "arr", "[", ":", ":", "-", "1", ",", ":", ",", "0", ":", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.__init__": [[145, 148], ["rendering.Color"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "_color", "=", "Color", "(", "(", "0", ",", "0", ",", "0", ",", "1.0", ")", ")", "\n", "self", ".", "attrs", "=", "[", "self", ".", "_color", "]", "\n", "", "def", "render", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.render": [[148, 154], ["reversed", "rendering.Geom.render1", "attr.enable", "attr.disable"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Image.render1", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineWidth.enable", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineStyle.disable"], ["", "def", "render", "(", "self", ")", ":", "\n", "        ", "for", "attr", "in", "reversed", "(", "self", ".", "attrs", ")", ":", "\n", "            ", "attr", ".", "enable", "(", ")", "\n", "", "self", ".", "render1", "(", ")", "\n", "for", "attr", "in", "self", ".", "attrs", ":", "\n", "            ", "attr", ".", "disable", "(", ")", "\n", "", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.render1": [[154, 156], ["None"], "methods", ["None"], ["", "", "def", "render1", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "add_attr", "(", "self", ",", "attr", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.add_attr": [[156, 158], ["rendering.Geom.attrs.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "add_attr", "(", "self", ",", "attr", ")", ":", "\n", "        ", "self", ".", "attrs", ".", "append", "(", "attr", ")", "\n", "", "def", "set_color", "(", "self", ",", "r", ",", "g", ",", "b", ",", "alpha", "=", "1", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.set_color": [[158, 160], ["None"], "methods", ["None"], ["", "def", "set_color", "(", "self", ",", "r", ",", "g", ",", "b", ",", "alpha", "=", "1", ")", ":", "\n", "        ", "self", ".", "_color", ".", "vec4", "=", "(", "r", ",", "g", ",", "b", ",", "alpha", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Attr.enable": [[162, 164], ["None"], "methods", ["None"], ["    ", "def", "enable", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Attr.disable": [[164, 166], ["None"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.__init__": [[168, 172], ["rendering.Transform.set_translation", "rendering.Transform.set_rotation", "rendering.Transform.set_scale"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_rotation", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_scale"], ["    ", "def", "__init__", "(", "self", ",", "translation", "=", "(", "0.0", ",", "0.0", ")", ",", "rotation", "=", "0.0", ",", "scale", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "        ", "self", ".", "set_translation", "(", "*", "translation", ")", "\n", "self", ".", "set_rotation", "(", "rotation", ")", "\n", "self", ".", "set_scale", "(", "*", "scale", ")", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.enable": [[172, 177], ["glPushMatrix", "glTranslatef", "glRotatef", "glScalef"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glPushMatrix", "(", ")", "\n", "glTranslatef", "(", "self", ".", "translation", "[", "0", "]", ",", "self", ".", "translation", "[", "1", "]", ",", "0", ")", "# translate to GL loc ppint", "\n", "glRotatef", "(", "RAD2DEG", "*", "self", ".", "rotation", ",", "0", ",", "0", ",", "1.0", ")", "\n", "glScalef", "(", "self", ".", "scale", "[", "0", "]", ",", "self", ".", "scale", "[", "1", "]", ",", "1", ")", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.disable": [[177, 179], ["glPopMatrix"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "glPopMatrix", "(", ")", "\n", "", "def", "set_translation", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_translation": [[179, 181], ["float", "float"], "methods", ["None"], ["", "def", "set_translation", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n", "        ", "self", ".", "translation", "=", "(", "float", "(", "newx", ")", ",", "float", "(", "newy", ")", ")", "\n", "", "def", "set_rotation", "(", "self", ",", "new", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_rotation": [[181, 183], ["float"], "methods", ["None"], ["", "def", "set_rotation", "(", "self", ",", "new", ")", ":", "\n", "        ", "self", ".", "rotation", "=", "float", "(", "new", ")", "\n", "", "def", "set_scale", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_scale": [[183, 185], ["float", "float"], "methods", ["None"], ["", "def", "set_scale", "(", "self", ",", "newx", ",", "newy", ")", ":", "\n", "        ", "self", ".", "scale", "=", "(", "float", "(", "newx", ")", ",", "float", "(", "newy", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Color.__init__": [[187, 189], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vec4", ")", ":", "\n", "        ", "self", ".", "vec4", "=", "vec4", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Color.enable": [[189, 191], ["glColor4f"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glColor4f", "(", "*", "self", ".", "vec4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineStyle.__init__": [[193, 195], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "style", ")", ":", "\n", "        ", "self", ".", "style", "=", "style", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineStyle.enable": [[195, 198], ["glEnable", "glLineStipple"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glEnable", "(", "GL_LINE_STIPPLE", ")", "\n", "glLineStipple", "(", "1", ",", "self", ".", "style", ")", "\n", "", "def", "disable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineStyle.disable": [[198, 200], ["glDisable"], "methods", ["None"], ["", "def", "disable", "(", "self", ")", ":", "\n", "        ", "glDisable", "(", "GL_LINE_STIPPLE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineWidth.__init__": [[202, 204], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "stroke", ")", ":", "\n", "        ", "self", ".", "stroke", "=", "stroke", "\n", "", "def", "enable", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.LineWidth.enable": [[204, 206], ["glLineWidth"], "methods", ["None"], ["", "def", "enable", "(", "self", ")", ":", "\n", "        ", "glLineWidth", "(", "self", ".", "stroke", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Point.__init__": [[208, 210], ["rendering.Geom.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Point.render1": [[210, 214], ["glBegin", "glVertex3f", "glEnd"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_POINTS", ")", "# draw point", "\n", "glVertex3f", "(", "0.0", ",", "0.0", ",", "0.0", ")", "\n", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygon.__init__": [[216, 219], ["rendering.Geom.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "v", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "v", "=", "v", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygon.render1": [[219, 233], ["glEnd", "glColor4f", "glBegin", "glEnd", "len", "glBegin", "glVertex3f", "glVertex3f", "len", "glBegin", "glBegin"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "v", ")", "==", "4", ":", "glBegin", "(", "GL_QUADS", ")", "\n", "elif", "len", "(", "self", ".", "v", ")", ">", "4", ":", "glBegin", "(", "GL_POLYGON", ")", "\n", "else", ":", "glBegin", "(", "GL_TRIANGLES", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "\n", "color", "=", "(", "self", ".", "_color", ".", "vec4", "[", "0", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "1", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "2", "]", "*", "0.5", ",", "self", ".", "_color", ".", "vec4", "[", "3", "]", "*", "0.5", ")", "\n", "glColor4f", "(", "*", "color", ")", "\n", "glBegin", "(", "GL_LINE_LOOP", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.__init__": [[235, 238], ["rendering.Geom.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "poly", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "poly", "=", "poly", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color": [[239, 241], ["None"], "methods", ["None"], ["", "def", "set_color", "(", "self", ",", "colors", ")", ":", "\n", "        ", "self", ".", "colors", "=", "colors", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.render_background": [[242, 259], ["glBegin", "glColor4f", "glVertex3f", "glVertex3f", "glVertex3f", "glVertex3f", "glColor4f", "range", "glEnd", "range", "glVertex3f", "glVertex3f", "glVertex3f", "glVertex3f"], "methods", ["None"], ["", "def", "render_background", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_QUADS", ")", "\n", "glColor4f", "(", "0.4", ",", "0.8", ",", "0.4", ",", "1.0", ")", "\n", "glVertex3f", "(", "-", "1", ",", "+", "1", ",", "0", ")", "\n", "glVertex3f", "(", "+", "1", ",", "+", "1", ",", "0", ")", "\n", "glVertex3f", "(", "+", "1", ",", "-", "1", ",", "0", ")", "\n", "glVertex3f", "(", "-", "1", ",", "-", "1", ",", "0", ")", "\n", "\n", "glColor4f", "(", "0.4", ",", "0.9", ",", "0.4", ",", "1.0", ")", "\n", "k", "=", "2", "/", "20.0", "\n", "for", "x", "in", "range", "(", "-", "20", ",", "20", ",", "2", ")", ":", "\n", "            ", "for", "y", "in", "range", "(", "-", "20", ",", "20", ",", "2", ")", ":", "\n", "                ", "glVertex3f", "(", "k", "*", "x", "+", "k", ",", "k", "*", "y", "+", "0", ",", "0", ")", "\n", "glVertex3f", "(", "k", "*", "x", "+", "0", ",", "k", "*", "y", "+", "0", ",", "0", ")", "\n", "glVertex3f", "(", "k", "*", "x", "+", "0", ",", "k", "*", "y", "+", "k", ",", "0", ")", "\n", "glVertex3f", "(", "k", "*", "x", "+", "k", ",", "k", "*", "y", "+", "k", ",", "0", ")", "\n", "", "", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.render1": [[260, 269], ["glBegin", "zip", "glEnd", "glColor4f", "glVertex3f"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "#self.render_background()", "\n", "        ", "glBegin", "(", "GL_QUADS", ")", "\n", "\n", "for", "poly", ",", "color", "in", "zip", "(", "self", ".", "poly", ",", "self", ".", "colors", ")", ":", "\n", "            ", "glColor4f", "(", "color", "[", "0", "]", ",", "color", "[", "1", "]", ",", "color", "[", "2", "]", ",", "1.", ")", "\n", "for", "p", "in", "poly", ":", "\n", "                ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Compound.__init__": [[321, 326], ["rendering.Geom.__init__", "isinstance"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "gs", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "gs", "=", "gs", "\n", "for", "g", "in", "self", ".", "gs", ":", "\n", "            ", "g", ".", "attrs", "=", "[", "a", "for", "a", "in", "g", ".", "attrs", "if", "not", "isinstance", "(", "a", ",", "Color", ")", "]", "\n", "", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Compound.render1": [[326, 329], ["g.render"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["", "", "def", "render1", "(", "self", ")", ":", "\n", "        ", "for", "g", "in", "self", ".", "gs", ":", "\n", "            ", "g", ".", "render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.PolyLine.__init__": [[331, 337], ["rendering.Geom.__init__", "rendering.LineWidth", "rendering.PolyLine.add_attr"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.add_attr"], ["    ", "def", "__init__", "(", "self", ",", "v", ",", "close", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "v", "=", "v", "\n", "self", ".", "close", "=", "close", "\n", "self", ".", "linewidth", "=", "LineWidth", "(", "1", ")", "\n", "self", ".", "add_attr", "(", "self", ".", "linewidth", ")", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.PolyLine.render1": [[337, 342], ["glBegin", "glEnd", "glVertex3f"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_LINE_LOOP", "if", "self", ".", "close", "else", "GL_LINE_STRIP", ")", "\n", "for", "p", "in", "self", ".", "v", ":", "\n", "            ", "glVertex3f", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", ",", "0", ")", "# draw each vertex", "\n", "", "glEnd", "(", ")", "\n", "", "def", "set_linewidth", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.PolyLine.set_linewidth": [[342, 344], ["None"], "methods", ["None"], ["", "def", "set_linewidth", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "linewidth", ".", "stroke", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Line.__init__": [[346, 352], ["rendering.Geom.__init__", "rendering.LineWidth", "rendering.Line.add_attr"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.add_attr"], ["    ", "def", "__init__", "(", "self", ",", "start", "=", "(", "0.0", ",", "0.0", ")", ",", "end", "=", "(", "0.0", ",", "0.0", ")", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "self", ".", "linewidth", "=", "LineWidth", "(", "1", ")", "\n", "self", ".", "add_attr", "(", "self", ".", "linewidth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Line.render1": [[353, 358], ["glBegin", "glVertex2f", "glVertex2f", "glEnd"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "glBegin", "(", "GL_LINES", ")", "\n", "glVertex2f", "(", "*", "self", ".", "start", ")", "\n", "glVertex2f", "(", "*", "self", ".", "end", ")", "\n", "glEnd", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Image.__init__": [[360, 367], ["rendering.Geom.__init__", "pyglet.image.load"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load"], ["    ", "def", "__init__", "(", "self", ",", "fname", ",", "width", ",", "height", ")", ":", "\n", "        ", "Geom", ".", "__init__", "(", "self", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "img", "=", "pyglet", ".", "image", ".", "load", "(", "fname", ")", "\n", "self", ".", "img", "=", "img", "\n", "self", ".", "flip", "=", "False", "\n", "", "def", "render1", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Image.render1": [[367, 369], ["rendering.Image.img.blit"], "methods", ["None"], ["", "def", "render1", "(", "self", ")", ":", "\n", "        ", "self", ".", "img", ".", "blit", "(", "-", "self", ".", "width", "/", "2", ",", "-", "self", ".", "height", "/", "2", ",", "width", "=", "self", ".", "width", ",", "height", "=", "self", ".", "height", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.SimpleImageViewer.__init__": [[373, 377], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "display", "=", "None", ")", ":", "\n", "        ", "self", ".", "window", "=", "None", "\n", "self", ".", "isopen", "=", "False", "\n", "self", ".", "display", "=", "display", "\n", "", "def", "imshow", "(", "self", ",", "arr", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.SimpleImageViewer.imshow": [[377, 391], ["pyglet.image.ImageData", "rendering.SimpleImageViewer.window.clear", "rendering.SimpleImageViewer.window.switch_to", "rendering.SimpleImageViewer.window.dispatch_events", "pyglet.image.ImageData.blit", "rendering.SimpleImageViewer.window.flip", "pyglet.window.Window", "arr.tobytes"], "methods", ["None"], ["", "def", "imshow", "(", "self", ",", "arr", ")", ":", "\n", "        ", "if", "self", ".", "window", "is", "None", ":", "\n", "            ", "height", ",", "width", ",", "channels", "=", "arr", ".", "shape", "\n", "self", ".", "window", "=", "pyglet", ".", "window", ".", "Window", "(", "width", "=", "width", ",", "height", "=", "height", ",", "display", "=", "self", ".", "display", ")", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "isopen", "=", "True", "\n", "", "assert", "arr", ".", "shape", "==", "(", "self", ".", "height", ",", "self", ".", "width", ",", "3", ")", ",", "\"You passed in an image with the wrong number shape\"", "\n", "image", "=", "pyglet", ".", "image", ".", "ImageData", "(", "self", ".", "width", ",", "self", ".", "height", ",", "'RGB'", ",", "arr", ".", "tobytes", "(", ")", ",", "pitch", "=", "self", ".", "width", "*", "-", "3", ")", "\n", "self", ".", "window", ".", "clear", "(", ")", "\n", "self", ".", "window", ".", "switch_to", "(", ")", "\n", "self", ".", "window", ".", "dispatch_events", "(", ")", "\n", "image", ".", "blit", "(", "0", ",", "0", ")", "\n", "self", ".", "window", ".", "flip", "(", ")", "\n", "", "def", "close", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.SimpleImageViewer.close": [[391, 395], ["rendering.SimpleImageViewer.window.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "isopen", ":", "\n", "            ", "self", ".", "window", ".", "close", "(", ")", "\n", "self", ".", "isopen", "=", "False", "\n", "", "", "def", "__del__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.SimpleImageViewer.__del__": [[395, 397], ["rendering.SimpleImageViewer.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.get_display": [[23, 35], ["isinstance", "pyglet.canvas.Display", "gym.error.Error"], "function", ["None"], ["def", "get_display", "(", "spec", ")", ":", "\n", "    ", "\"\"\"Convert a display specification (such as :0) into an actual Display\n    object.\n\n    Pyglet only supports multiple Displays on Linux.\n    \"\"\"", "\n", "if", "spec", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "elif", "isinstance", "(", "spec", ",", "six", ".", "string_types", ")", ":", "\n", "        ", "return", "pyglet", ".", "canvas", ".", "Display", "(", "spec", ")", "\n", "", "else", ":", "\n", "        ", "raise", "error", ".", "Error", "(", "'Invalid display specification: {}. (Must be a string like :0 or None.)'", ".", "format", "(", "spec", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering._add_attrs": [[138, 143], ["geom.set_color", "geom.set_linewidth"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.PolyLine.set_linewidth"], ["", "", "def", "_add_attrs", "(", "geom", ",", "attrs", ")", ":", "\n", "    ", "if", "\"color\"", "in", "attrs", ":", "\n", "        ", "geom", ".", "set_color", "(", "*", "attrs", "[", "\"color\"", "]", ")", "\n", "", "if", "\"linewidth\"", "in", "attrs", ":", "\n", "        ", "geom", ".", "set_linewidth", "(", "attrs", "[", "\"linewidth\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_circle": [[271, 280], ["range", "points.append", "rendering.FilledPolygon", "rendering.PolyLine", "math.cos", "math.sin"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "def", "make_circle", "(", "radius", "=", "10", ",", "res", "=", "30", ",", "filled", "=", "True", ")", ":", "\n", "    ", "points", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "res", ")", ":", "\n", "        ", "ang", "=", "2", "*", "math", ".", "pi", "*", "i", "/", "res", "\n", "points", ".", "append", "(", "(", "math", ".", "cos", "(", "ang", ")", "*", "radius", ",", "math", ".", "sin", "(", "ang", ")", "*", "radius", ")", ")", "\n", "", "if", "filled", ":", "\n", "        ", "return", "FilledPolygon", "(", "points", ")", "\n", "", "else", ":", "\n", "        ", "return", "PolyLine", "(", "points", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_circle_dir": [[281, 293], ["range", "rendering.make_polygon", "rendering.Compound", "points.append", "rendering.FilledPolygon", "rendering.PolyLine", "math.cos", "math.sin"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polygon", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "def", "make_circle_dir", "(", "radius", "=", "10", ",", "res", "=", "30", ",", "filled", "=", "True", ")", ":", "\n", "    ", "points", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "res", ")", ":", "\n", "        ", "ang", "=", "2", "*", "math", ".", "pi", "*", "i", "/", "res", "\n", "points", ".", "append", "(", "(", "math", ".", "cos", "(", "ang", ")", "*", "radius", ",", "math", ".", "sin", "(", "ang", ")", "*", "radius", ")", ")", "\n", "", "if", "filled", ":", "\n", "        ", "circ", "=", "FilledPolygon", "(", "points", ")", "\n", "", "else", ":", "\n", "        ", "circ", "=", "PolyLine", "(", "points", ",", "True", ")", "\n", "", "triangle", "=", "make_polygon", "(", "[", "(", "-", "radius", ",", "0", ")", ",", "(", "0", ",", "radius", ")", ",", "(", "radius", ",", "0", ")", "]", ")", "\n", "geom", "=", "Compound", "(", "[", "circ", ",", "triangle", "]", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_compound": [[294, 300], ["rendering.Compound", "rendering.FilledPolygon", "comp.append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "make_compound", "(", "vs", ")", ":", "\n", "    ", "comp", "=", "[", "]", "\n", "for", "v", "in", "vs", ":", "\n", "        ", "geom", "=", "FilledPolygon", "(", "v", ")", "\n", "comp", ".", "append", "(", "geom", ")", "\n", "", "return", "Compound", "(", "comp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polygon": [[301, 304], ["rendering.FilledPolygon", "rendering.PolyLine"], "function", ["None"], ["", "def", "make_polygon", "(", "v", ",", "filled", "=", "True", ")", ":", "\n", "    ", "if", "filled", ":", "return", "FilledPolygon", "(", "v", ")", "\n", "else", ":", "return", "PolyLine", "(", "v", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polygon_with_hole": [[305, 307], ["rendering.FilledPolygonWithHole"], "function", ["None"], ["", "def", "make_polygon_with_hole", "(", "v", ")", ":", "\n", "    ", "return", "FilledPolygonWithHole", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polyline": [[308, 310], ["rendering.PolyLine"], "function", ["None"], ["", "def", "make_polyline", "(", "v", ")", ":", "\n", "    ", "return", "PolyLine", "(", "v", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_capsule": [[311, 319], ["rendering.make_polygon", "rendering.make_circle", "rendering.make_circle", "make_circle.add_attr", "rendering.Compound", "rendering.Transform"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polygon", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.add_attr"], ["", "def", "make_capsule", "(", "length", ",", "width", ")", ":", "\n", "    ", "l", ",", "r", ",", "t", ",", "b", "=", "0", ",", "length", ",", "width", "/", "2", ",", "-", "width", "/", "2", "\n", "box", "=", "make_polygon", "(", "[", "(", "l", ",", "b", ")", ",", "(", "l", ",", "t", ")", ",", "(", "r", ",", "t", ")", ",", "(", "r", ",", "b", ")", "]", ")", "\n", "circ0", "=", "make_circle", "(", "width", "/", "2", ")", "\n", "circ1", "=", "make_circle", "(", "width", "/", "2", ")", "\n", "circ1", ".", "add_attr", "(", "Transform", "(", "translation", "=", "(", "length", ",", "0", ")", ")", ")", "\n", "geom", "=", "Compound", "(", "[", "box", ",", "circ0", ",", "circ1", "]", ")", "\n", "return", "geom", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.multi_discrete.MultiDiscrete.__init__": [[25, 29], ["numpy.array", "numpy.array"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "array_of_param_array", ")", ":", "\n", "        ", "self", ".", "low", "=", "np", ".", "array", "(", "[", "x", "[", "0", "]", "for", "x", "in", "array_of_param_array", "]", ")", "\n", "self", ".", "high", "=", "np", ".", "array", "(", "[", "x", "[", "1", "]", "for", "x", "in", "array_of_param_array", "]", ")", "\n", "self", ".", "num_discrete_space", "=", "self", ".", "low", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.multi_discrete.MultiDiscrete.sample": [[30, 36], ["numpy.random.RandomState", "numpy.random.RandomState.rand", "int", "numpy.floor", "numpy.multiply"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "\"\"\" Returns a array with one sample from each discrete action space \"\"\"", "\n", "# For each row: round(random .* (max - min) + min, 0)", "\n", "np_random", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "random_array", "=", "np_random", ".", "rand", "(", "self", ".", "num_discrete_space", ")", "\n", "return", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "floor", "(", "np", ".", "multiply", "(", "(", "self", ".", "high", "-", "self", ".", "low", "+", "1.", ")", ",", "random_array", ")", "+", "self", ".", "low", ")", "]", "\n", "", "def", "contains", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.multi_discrete.MultiDiscrete.contains": [[36, 38], ["len", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "len", "(", "x", ")", "==", "self", ".", "num_discrete_space", "and", "(", "np", ".", "array", "(", "x", ")", ">=", "self", ".", "low", ")", ".", "all", "(", ")", "and", "(", "np", ".", "array", "(", "x", ")", "<=", "self", ".", "high", ")", ".", "all", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.multi_discrete.MultiDiscrete.shape": [[39, 42], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "num_discrete_space", "\n", "", "def", "__repr__", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.multi_discrete.MultiDiscrete.__repr__": [[42, 44], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"MultiDiscrete\"", "+", "str", "(", "self", ".", "num_discrete_space", ")", "\n", "", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.multi_discrete.MultiDiscrete.__eq__": [[44, 46], ["numpy.array_equal", "numpy.array_equal"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "np", ".", "array_equal", "(", "self", ".", "low", ",", "other", ".", "low", ")", "and", "np", ".", "array_equal", "(", "self", ".", "high", ",", "other", ".", "high", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.policy.Policy.__init__": [[6, 8], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "def", "action", "(", "self", ",", "obs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.policy.Policy.action": [[8, 10], ["NotImplementedError"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.policy.InteractivePolicy.__init__": [[14, 23], ["policy.Policy.__init__", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "agent_index", ")", ":", "\n", "        ", "super", "(", "InteractivePolicy", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "env", "=", "env", "\n", "# hard-coded keyboard events", "\n", "self", ".", "move", "=", "[", "False", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "self", ".", "comm", "=", "[", "False", "for", "i", "in", "range", "(", "env", ".", "world", ".", "dim_c", ")", "]", "\n", "# register keyboard events with this environment's window", "\n", "env", ".", "viewers", "[", "agent_index", "]", ".", "window", ".", "on_key_press", "=", "self", ".", "key_press", "\n", "env", ".", "viewers", "[", "agent_index", "]", ".", "window", ".", "on_key_release", "=", "self", ".", "key_release", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.policy.InteractivePolicy.action": [[24, 41], ["numpy.concatenate", "numpy.zeros", "numpy.zeros"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "obs", ")", ":", "\n", "# ignore observation and just act based on keyboard events", "\n", "        ", "if", "self", ".", "env", ".", "discrete_action_input", ":", "\n", "            ", "u", "=", "0", "\n", "if", "self", ".", "move", "[", "0", "]", ":", "u", "=", "1", "\n", "if", "self", ".", "move", "[", "1", "]", ":", "u", "=", "2", "\n", "if", "self", ".", "move", "[", "2", "]", ":", "u", "=", "4", "\n", "if", "self", ".", "move", "[", "3", "]", ":", "u", "=", "3", "\n", "", "else", ":", "\n", "            ", "u", "=", "np", ".", "zeros", "(", "5", ")", "# 5-d because of no-move action", "\n", "if", "self", ".", "move", "[", "0", "]", ":", "u", "[", "1", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "1", "]", ":", "u", "[", "2", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "3", "]", ":", "u", "[", "3", "]", "+=", "1.0", "\n", "if", "self", ".", "move", "[", "2", "]", ":", "u", "[", "4", "]", "+=", "1.0", "\n", "if", "True", "not", "in", "self", ".", "move", ":", "\n", "                ", "u", "[", "0", "]", "+=", "1.0", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "u", ",", "np", ".", "zeros", "(", "self", ".", "env", ".", "world", ".", "dim_c", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.policy.InteractivePolicy.key_press": [[43, 48], ["None"], "methods", ["None"], ["", "def", "key_press", "(", "self", ",", "k", ",", "mod", ")", ":", "\n", "        ", "if", "k", "==", "key", ".", "LEFT", ":", "self", ".", "move", "[", "0", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "RIGHT", ":", "self", ".", "move", "[", "1", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "UP", ":", "self", ".", "move", "[", "2", "]", "=", "True", "\n", "if", "k", "==", "key", ".", "DOWN", ":", "self", ".", "move", "[", "3", "]", "=", "True", "\n", "", "def", "key_release", "(", "self", ",", "k", ",", "mod", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.policy.InteractivePolicy.key_release": [[48, 53], ["None"], "methods", ["None"], ["", "def", "key_release", "(", "self", ",", "k", ",", "mod", ")", ":", "\n", "        ", "if", "k", "==", "key", ".", "LEFT", ":", "self", ".", "move", "[", "0", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "RIGHT", ":", "self", ".", "move", "[", "1", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "UP", ":", "self", ".", "move", "[", "2", "]", "=", "False", "\n", "if", "k", "==", "key", ".", "DOWN", ":", "self", ".", "move", "[", "3", "]", "=", "False", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicState.__init__": [[8, 11], ["multiagent.core.AgentState.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DynamicState", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "angle", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAction.__init__": [[14, 18], ["multiagent.core.Action.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DynamicAction", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "r", "=", "None", "\n", "self", ".", "v", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAgent.__init__": [[21, 32], ["multiagent.core.Agent.__init__", "dynamic_agent.DynamicState", "dynamic_agent.DynamicAction"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DynamicAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "body", "=", "None", "\n", "self", ".", "actions", "=", "{", "'Left'", ":", "[", "-", "1.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "'Right'", ":", "[", "+", "1.0", ",", "0.0", ",", "0.0", "]", ",", "\n", "'Brake'", ":", "[", "0.0", ",", "0.0", ",", "0.8", "]", ",", "\n", "'Accelerate'", ":", "[", "0.0", ",", "1.0", ",", "0.0", "]", ",", "\n", "'Nothing'", ":", "[", "0.0", ",", "2.0", ",", "0.0", "]", "}", "\n", "self", ".", "state", "=", "DynamicState", "(", ")", "\n", "self", ".", "action", "=", "DynamicAction", "(", ")", "\n", "self", ".", "scale", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAgent.update_state": [[33, 42], ["numpy.array"], "methods", ["None"], ["", "def", "update_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", ".", "p_pos", "[", "0", "]", "=", "self", ".", "body", ".", "hull", ".", "position", "[", "0", "]", "/", "self", ".", "scale", "\n", "self", ".", "state", ".", "p_pos", "[", "1", "]", "=", "self", ".", "body", ".", "hull", ".", "position", "[", "1", "]", "/", "self", ".", "scale", "\n", "self", ".", "state", ".", "angle", "=", "self", ".", "body", ".", "hull", ".", "angle", "\n", "vel", "=", "self", ".", "body", ".", "hull", ".", "linearVelocity", "\n", "#speed = np.linalg.norm(vel)", "\n", "#if speed > 0.5:", "\n", "#self.state.angle = math.atan2(vel[0], vel[1])", "\n", "self", ".", "state", ".", "p_vel", "=", "np", ".", "array", "(", "[", "vel", "[", "0", "]", ",", "vel", "[", "1", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAgent.transform_action": [[43, 50], ["None"], "methods", ["None"], ["", "def", "transform_action", "(", "self", ")", ":", "\n", "        ", "u", "=", "self", ".", "action", ".", "u", "\n", "if", "u", "[", "0", "]", "==", "0", "and", "u", "[", "1", "]", "==", "0", ":", "self", ".", "action", ".", "v", "=", "+", "self", ".", "max_speed", ";", "self", ".", "action", ".", "r", "=", "0", "\n", "elif", "u", "[", "0", "]", "==", "0", "and", "u", "[", "1", "]", "<", "0", ":", "self", ".", "action", ".", "v", "=", "+", "self", ".", "max_speed", ";", "self", ".", "action", ".", "r", "=", ".1", "\n", "elif", "u", "[", "0", "]", "==", "0", "and", "u", "[", "1", "]", ">", "0", ":", "self", ".", "action", ".", "v", "=", "+", "self", ".", "max_speed", ";", "self", ".", "action", ".", "r", "=", "-", ".1", "\n", "elif", "u", "[", "0", "]", "<", "0", "and", "u", "[", "1", "]", "==", "0", ":", "self", ".", "action", ".", "v", "=", "+", "2", "*", "self", ".", "max_speed", ";", "self", ".", "action", ".", "r", "=", ".1", "\n", "elif", "u", "[", "0", "]", ">", "0", "and", "u", "[", "1", "]", "==", "0", ":", "self", ".", "action", ".", "v", "=", "+", "2", "*", "self", ".", "max_speed", ";", "self", ".", "action", ".", "r", "=", "-", ".1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAgent.transform_action_car_input": [[51, 62], ["dynamic_agent.DynamicAgent.body.steer", "dynamic_agent.DynamicAgent.body.gas", "dynamic_agent.DynamicAgent.body.brake", "list", "dynamic_agent.DynamicAgent.actions.values", "list", "dynamic_agent.DynamicAgent.actions.values", "list", "dynamic_agent.DynamicAgent.actions.values", "list", "dynamic_agent.DynamicAgent.actions.values", "list", "dynamic_agent.DynamicAgent.actions.values"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.steer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.gas", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.brake"], ["", "def", "transform_action_car_input", "(", "self", ")", ":", "\n", "        ", "u", "=", "self", ".", "action", ".", "u", "\n", "if", "u", "[", "0", "]", "==", "0", "and", "u", "[", "1", "]", "==", "0", ":", "action", "=", "list", "(", "self", ".", "actions", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "elif", "u", "[", "0", "]", "==", "0", "and", "u", "[", "1", "]", "<", "0", ":", "action", "=", "list", "(", "self", ".", "actions", ".", "values", "(", ")", ")", "[", "1", "]", "\n", "elif", "u", "[", "0", "]", "==", "0", "and", "u", "[", "1", "]", ">", "0", ":", "action", "=", "list", "(", "self", ".", "actions", ".", "values", "(", ")", ")", "[", "2", "]", "\n", "elif", "u", "[", "0", "]", "<", "0", "and", "u", "[", "1", "]", "==", "0", ":", "action", "=", "list", "(", "self", ".", "actions", ".", "values", "(", ")", ")", "[", "3", "]", "\n", "elif", "u", "[", "0", "]", ">", "0", "and", "u", "[", "1", "]", "==", "0", ":", "action", "=", "list", "(", "self", ".", "actions", ".", "values", "(", ")", ")", "[", "4", "]", "\n", "if", "action", "is", "not", "None", ":", "\n", "            ", "self", ".", "body", ".", "steer", "(", "-", "action", "[", "0", "]", ")", "\n", "self", ".", "body", ".", "gas", "(", "action", "[", "1", "]", ")", "\n", "self", ".", "body", ".", "brake", "(", "action", "[", "2", "]", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.scenario.BaseScenario.make_world": [[6, 8], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "# create initial conditions of the world", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.scenario.BaseScenario.reset_world": [[9, 11], ["NotImplementedError"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.__init__": [[14, 85], ["len", "environment.MultiAgentEnv._reset_render", "hasattr", "hasattr", "observation_callback", "numpy.zeros", "gym.spaces.Discrete", "gym.spaces.Box", "total_action_space.append", "gym.spaces.Discrete", "gym.spaces.Box", "total_action_space.append", "len", "all", "environment.MultiAgentEnv.action_space.append", "environment.MultiAgentEnv.action_space.append", "environment.MultiAgentEnv.observation_space.append", "environment.MultiAgentEnv.observation_space.append", "multiagent.multi_discrete.MultiDiscrete", "gym.spaces.Tuple", "gym.spaces.Box", "gym.spaces.Box", "isinstance", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._reset_render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["def", "__init__", "(", "self", ",", "world", ",", "reset_callback", "=", "None", ",", "reward_callback", "=", "None", ",", "\n", "observation_callback", "=", "None", ",", "info_callback", "=", "None", ",", "\n", "done_callback", "=", "None", ",", "shared_viewer", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "world", "=", "world", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "# set required vectorized gym env property", "\n", "self", ".", "n", "=", "len", "(", "world", ".", "policy_agents", ")", "\n", "# scenario callbacks", "\n", "self", ".", "reset_callback", "=", "reset_callback", "\n", "self", ".", "reward_callback", "=", "reward_callback", "\n", "self", ".", "observation_callback", "=", "observation_callback", "\n", "self", ".", "info_callback", "=", "info_callback", "\n", "self", ".", "done_callback", "=", "done_callback", "\n", "# environment parameters", "\n", "self", ".", "discrete_action_space", "=", "True", "\n", "# if true, action is a number 0...N, otherwise action is a one-hot N-dimensional vector", "\n", "self", ".", "discrete_action_input", "=", "False", "\n", "# if true, even the action is continuous, action will be performed discretely", "\n", "self", ".", "force_discrete_action", "=", "world", ".", "discrete_action", "if", "hasattr", "(", "world", ",", "'discrete_action'", ")", "else", "False", "\n", "# if true, every agent has the same reward", "\n", "self", ".", "shared_reward", "=", "world", ".", "collaborative", "if", "hasattr", "(", "world", ",", "'collaborative'", ")", "else", "False", "\n", "self", ".", "time", "=", "0", "\n", "\n", "# configure spaces", "\n", "self", ".", "action_space", "=", "[", "]", "\n", "self", ".", "observation_space", "=", "[", "]", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "total_action_space", "=", "[", "]", "\n", "# physical action space", "\n", "if", "self", ".", "discrete_action_space", ":", "\n", "                ", "u_action_space", "=", "spaces", ".", "Discrete", "(", "world", ".", "dim_p", "*", "2", "+", "1", ")", "\n", "", "else", ":", "\n", "                ", "u_action_space", "=", "spaces", ".", "Box", "(", "low", "=", "-", "agent", ".", "u_range", ",", "high", "=", "+", "agent", ".", "u_range", ",", "shape", "=", "(", "world", ".", "dim_p", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "if", "agent", ".", "movable", ":", "\n", "                ", "total_action_space", ".", "append", "(", "u_action_space", ")", "\n", "# communication action space", "\n", "", "if", "self", ".", "discrete_action_space", ":", "\n", "                ", "c_action_space", "=", "spaces", ".", "Discrete", "(", "world", ".", "dim_c", ")", "\n", "", "else", ":", "\n", "                ", "c_action_space", "=", "spaces", ".", "Box", "(", "low", "=", "0.0", ",", "high", "=", "1.0", ",", "shape", "=", "(", "world", ".", "dim_c", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "if", "not", "agent", ".", "silent", ":", "\n", "                ", "total_action_space", ".", "append", "(", "c_action_space", ")", "\n", "# total action space", "\n", "", "if", "len", "(", "total_action_space", ")", ">", "1", ":", "\n", "# all action spaces are discrete, so simplify to MultiDiscrete action space", "\n", "                ", "if", "all", "(", "[", "isinstance", "(", "act_space", ",", "spaces", ".", "Discrete", ")", "for", "act_space", "in", "total_action_space", "]", ")", ":", "\n", "                    ", "act_space", "=", "MultiDiscrete", "(", "[", "[", "0", ",", "act_space", ".", "n", "-", "1", "]", "for", "act_space", "in", "total_action_space", "]", ")", "\n", "", "else", ":", "\n", "                    ", "act_space", "=", "spaces", ".", "Tuple", "(", "total_action_space", ")", "\n", "", "self", ".", "action_space", ".", "append", "(", "act_space", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "action_space", ".", "append", "(", "total_action_space", "[", "0", "]", ")", "\n", "# observation space", "\n", "", "obs", "=", "observation_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "if", "obs", ".", "ndim", "==", "4", ":", "\n", "                ", "self", ".", "observation_space", ".", "append", "(", "\n", "spaces", ".", "Box", "(", "low", "=", "-", "np", ".", "inf", ",", "high", "=", "+", "np", ".", "inf", ",", "shape", "=", "(", "obs", ".", "shape", "[", "1", "]", ",", "obs", ".", "shape", "[", "2", "]", ",", "obs", ".", "shape", "[", "3", "]", ")", ",", "\n", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "observation_space", ".", "append", "(", "\n", "spaces", ".", "Box", "(", "low", "=", "-", "np", ".", "inf", ",", "high", "=", "+", "np", ".", "inf", ",", "shape", "=", "(", "len", "(", "obs", ")", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", ")", "\n", "", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "\n", "# rendering", "\n", "", "self", ".", "shared_viewer", "=", "shared_viewer", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "*", "self", ".", "n", "\n", "", "self", ".", "_reset_render", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.step": [[86, 111], ["enumerate", "environment.MultiAgentEnv.world.step", "numpy.sum", "environment.MultiAgentEnv._set_action", "obs_n.append", "reward_n.append", "done_n.append", "info_n[].append", "environment.MultiAgentEnv._get_obs", "environment.MultiAgentEnv._get_reward", "environment.MultiAgentEnv._get_done", "environment.MultiAgentEnv._get_info"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._set_action", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_obs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._get_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_done", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_info"], ["", "def", "step", "(", "self", ",", "action_n", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "reward_n", "=", "[", "]", "\n", "done_n", "=", "[", "]", "\n", "info_n", "=", "{", "'n'", ":", "[", "]", "}", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "# set action for each agent", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "self", ".", "_set_action", "(", "action_n", "[", "i", "]", ",", "agent", ",", "self", ".", "action_space", "[", "i", "]", ")", "\n", "# advance world state", "\n", "", "self", ".", "world", ".", "step", "(", ")", "\n", "# record observation for each agent", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "obs_n", ".", "append", "(", "self", ".", "_get_obs", "(", "agent", ")", ")", "\n", "reward_n", ".", "append", "(", "self", ".", "_get_reward", "(", "agent", ")", ")", "\n", "done_n", ".", "append", "(", "self", ".", "_get_done", "(", "agent", ")", ")", "\n", "\n", "info_n", "[", "'n'", "]", ".", "append", "(", "self", ".", "_get_info", "(", "agent", ")", ")", "\n", "\n", "# all agents get total reward in cooperative case", "\n", "", "reward", "=", "np", ".", "sum", "(", "reward_n", ")", "\n", "if", "self", ".", "shared_reward", ":", "\n", "            ", "reward_n", "=", "[", "reward", "]", "*", "self", ".", "n", "\n", "\n", "", "return", "obs_n", ",", "reward_n", ",", "done_n", ",", "info_n", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.reset": [[112, 123], ["environment.MultiAgentEnv.reset_callback", "environment.MultiAgentEnv._reset_render", "obs_n.append", "environment.MultiAgentEnv._get_obs"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._reset_render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# reset world", "\n", "        ", "self", ".", "reset_callback", "(", "self", ".", "world", ")", "\n", "# reset renderer", "\n", "self", ".", "_reset_render", "(", ")", "\n", "# record observations for each agent", "\n", "obs_n", "=", "[", "]", "\n", "self", ".", "agents", "=", "self", ".", "world", ".", "policy_agents", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "obs_n", ".", "append", "(", "self", ".", "_get_obs", "(", "agent", ")", ")", "\n", "", "return", "obs_n", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_info": [[125, 129], ["environment.MultiAgentEnv.info_callback"], "methods", ["None"], ["", "def", "_get_info", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "info_callback", "is", "None", ":", "\n", "            ", "return", "{", "}", "\n", "", "return", "self", ".", "info_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_obs": [[131, 135], ["environment.MultiAgentEnv.observation_callback", "numpy.zeros"], "methods", ["None"], ["", "def", "_get_obs", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "observation_callback", "is", "None", ":", "\n", "            ", "return", "np", ".", "zeros", "(", "0", ")", "\n", "", "return", "self", ".", "observation_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_done": [[138, 142], ["environment.MultiAgentEnv.done_callback"], "methods", ["None"], ["", "def", "_get_done", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "done_callback", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "return", "self", ".", "done_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._get_reward": [[144, 148], ["environment.MultiAgentEnv.reward_callback"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "self", ".", "reward_callback", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "return", "self", ".", "reward_callback", "(", "agent", ",", "self", ".", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._set_action": [[150, 199], ["numpy.zeros", "numpy.zeros", "isinstance", "len", "act.append", "numpy.zeros", "numpy.zeros", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "_set_action", "(", "self", ",", "action", ",", "agent", ",", "action_space", ",", "time", "=", "None", ")", ":", "\n", "        ", "agent", ".", "action", ".", "u", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "# process action", "\n", "if", "isinstance", "(", "action_space", ",", "MultiDiscrete", ")", ":", "\n", "            ", "act", "=", "[", "]", "\n", "size", "=", "action_space", ".", "high", "-", "action_space", ".", "low", "+", "1", "\n", "index", "=", "0", "\n", "for", "s", "in", "size", ":", "\n", "                ", "act", ".", "append", "(", "action", "[", "index", ":", "(", "index", "+", "s", ")", "]", ")", "\n", "index", "+=", "s", "\n", "", "action", "=", "act", "\n", "", "else", ":", "\n", "            ", "action", "=", "[", "action", "]", "\n", "\n", "", "if", "agent", ".", "movable", ":", "\n", "# physical action", "\n", "            ", "if", "self", ".", "discrete_action_input", ":", "\n", "                ", "agent", ".", "action", ".", "u", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "# process discrete action", "\n", "if", "action", "[", "0", "]", "==", "1", ":", "agent", ".", "action", ".", "u", "[", "0", "]", "=", "-", "1.0", "\n", "if", "action", "[", "0", "]", "==", "2", ":", "agent", ".", "action", ".", "u", "[", "0", "]", "=", "+", "1.0", "\n", "if", "action", "[", "0", "]", "==", "3", ":", "agent", ".", "action", ".", "u", "[", "1", "]", "=", "-", "1.0", "\n", "if", "action", "[", "0", "]", "==", "4", ":", "agent", ".", "action", ".", "u", "[", "1", "]", "=", "+", "1.0", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "force_discrete_action", ":", "\n", "                    ", "d", "=", "np", ".", "argmax", "(", "action", "[", "0", "]", ")", "\n", "action", "[", "0", "]", "[", ":", "]", "=", "0.0", "\n", "action", "[", "0", "]", "[", "d", "]", "=", "1.0", "\n", "", "if", "self", ".", "discrete_action_space", ":", "\n", "                    ", "agent", ".", "action", ".", "u", "[", "0", "]", "+=", "action", "[", "0", "]", "[", "1", "]", "-", "action", "[", "0", "]", "[", "2", "]", "\n", "agent", ".", "action", ".", "u", "[", "1", "]", "+=", "action", "[", "0", "]", "[", "3", "]", "-", "action", "[", "0", "]", "[", "4", "]", "\n", "", "else", ":", "\n", "                    ", "agent", ".", "action", ".", "u", "=", "action", "[", "0", "]", "\n", "", "", "sensitivity", "=", "5.0", "\n", "if", "agent", ".", "accel", "is", "not", "None", ":", "\n", "                ", "sensitivity", "=", "agent", ".", "accel", "\n", "", "agent", ".", "action", ".", "u", "*=", "sensitivity", "\n", "action", "=", "action", "[", "1", ":", "]", "\n", "", "if", "not", "agent", ".", "silent", ":", "\n", "# communication action", "\n", "            ", "if", "self", ".", "discrete_action_input", ":", "\n", "                ", "agent", ".", "action", ".", "c", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_c", ")", "\n", "agent", ".", "action", ".", "c", "[", "action", "[", "0", "]", "]", "=", "1.0", "\n", "", "else", ":", "\n", "                ", "agent", ".", "action", ".", "c", "=", "action", "[", "0", "]", "\n", "", "action", "=", "action", "[", "1", ":", "]", "\n", "# make sure we used all elements of action", "\n", "", "assert", "len", "(", "action", ")", "==", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._reset_render": [[201, 204], ["None"], "methods", ["None"], ["", "def", "_reset_render", "(", "self", ")", ":", "\n", "        ", "self", ".", "render_geoms", "=", "None", "\n", "self", ".", "render_geoms_xform", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.render": [[206, 279], ["range", "range", "len", "len", "environment.MultiAgentEnv.viewers[].set_bounds", "enumerate", "results.append", "rendering.Viewer", "rendering.Transform", "rendering.make_circle.add_attr", "environment.MultiAgentEnv.render_geoms.append", "environment.MultiAgentEnv.render_geoms_xform.append", "numpy.zeros", "environment.MultiAgentEnv.render_geoms_xform[].set_translation", "hasattr", "environment.MultiAgentEnv.viewers[].render", "numpy.all", "rendering.make_polygon_with_hole", "rendering.make_circle.set_color", "viewer.add_geom", "environment.MultiAgentEnv.render_geoms_xform[].set_rotation", "rendering.make_compound", "rendering.make_circle", "rendering.make_circle.set_color", "rendering.make_circle.set_color", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.set_bounds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.add_attr", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polygon_with_hole", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_geom", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_rotation", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_compound", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "if", "mode", "==", "'human'", ":", "\n", "            ", "alphabet", "=", "'ABCDEFGHIJKLMNOPQRSTUVWXYZ'", "\n", "message", "=", "''", "\n", "for", "agent", "in", "self", ".", "world", ".", "agents", ":", "\n", "                ", "comm", "=", "[", "]", "\n", "for", "other", "in", "self", ".", "world", ".", "agents", ":", "\n", "                    ", "if", "other", "is", "agent", ":", "continue", "\n", "if", "np", ".", "all", "(", "other", ".", "state", ".", "c", "==", "0", ")", ":", "\n", "                        ", "word", "=", "'_'", "\n", "", "else", ":", "\n", "                        ", "word", "=", "alphabet", "[", "np", ".", "argmax", "(", "other", ".", "state", ".", "c", ")", "]", "\n", "", "message", "+=", "(", "other", ".", "name", "+", "' to '", "+", "agent", ".", "name", "+", "': '", "+", "word", "+", "'   '", ")", "\n", "#print(message)", "\n", "\n", "", "", "", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "# create viewers (if necessary)", "\n", "            ", "if", "self", ".", "viewers", "[", "i", "]", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "#from gym.envs.classic_control import rendering", "\n", "                ", "from", "multiagent", "import", "rendering", "\n", "self", ".", "viewers", "[", "i", "]", "=", "rendering", ".", "Viewer", "(", "700", ",", "700", ")", "\n", "\n", "# create rendering geometry", "\n", "", "", "if", "self", ".", "render_geoms", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "#from gym.envs.classic_control import rendering", "\n", "            ", "from", "multiagent", "import", "rendering", "\n", "self", ".", "render_geoms", "=", "[", "]", "\n", "self", ".", "render_geoms_xform", "=", "[", "]", "\n", "for", "entity", "in", "self", ".", "world", ".", "entities", ":", "\n", "                ", "if", "'surface'", "in", "entity", ".", "name", ":", "\n", "                    ", "geom", "=", "rendering", ".", "make_polygon_with_hole", "(", "entity", ".", "poly", ")", "\n", "", "elif", "'dynamic'", "in", "entity", ".", "name", ":", "\n", "                    ", "geom", "=", "rendering", ".", "make_compound", "(", "entity", ".", "shape", ")", "\n", "", "else", ":", "\n", "                    ", "geom", "=", "rendering", ".", "make_circle", "(", "entity", ".", "size", ")", "\n", "", "xform", "=", "rendering", ".", "Transform", "(", ")", "\n", "if", "'agent'", "in", "entity", ".", "name", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.5", ")", "\n", "", "elif", "'surface'", "in", "entity", ".", "name", ":", "\n", "                    ", "geom", ".", "set_color", "(", "entity", ".", "color", ")", "\n", "", "else", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ")", "\n", "", "geom", ".", "add_attr", "(", "xform", ")", "\n", "self", ".", "render_geoms", ".", "append", "(", "geom", ")", "\n", "self", ".", "render_geoms_xform", ".", "append", "(", "xform", ")", "\n", "\n", "# add geoms to viewer", "\n", "", "for", "viewer", "in", "self", ".", "viewers", ":", "\n", "                ", "viewer", ".", "geoms", "=", "[", "]", "\n", "for", "geom", "in", "self", ".", "render_geoms", ":", "\n", "                    ", "viewer", ".", "add_geom", "(", "geom", ")", "\n", "\n", "", "", "", "results", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "            ", "from", "multiagent", "import", "rendering", "\n", "# update bounds to center around agent", "\n", "cam_range", "=", "1", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "                ", "pos", "=", "np", ".", "zeros", "(", "self", ".", "world", ".", "dim_p", ")", "\n", "", "else", ":", "\n", "                ", "pos", "=", "self", ".", "agents", "[", "i", "]", ".", "state", ".", "p_pos", "\n", "", "self", ".", "viewers", "[", "i", "]", ".", "set_bounds", "(", "pos", "[", "0", "]", "-", "cam_range", ",", "pos", "[", "0", "]", "+", "cam_range", ",", "pos", "[", "1", "]", "-", "cam_range", ",", "pos", "[", "1", "]", "+", "cam_range", ")", "\n", "# update geometry positions", "\n", "for", "e", ",", "entity", "in", "enumerate", "(", "self", ".", "world", ".", "entities", ")", ":", "\n", "                ", "self", ".", "render_geoms_xform", "[", "e", "]", ".", "set_translation", "(", "*", "entity", ".", "state", ".", "p_pos", ")", "\n", "if", "hasattr", "(", "entity", ".", "state", ",", "'angle'", ")", ":", "\n", "                    ", "self", ".", "render_geoms_xform", "[", "e", "]", ".", "set_rotation", "(", "entity", ".", "state", ".", "angle", ")", "\n", "# render to display or array", "\n", "", "", "results", ".", "append", "(", "self", ".", "viewers", "[", "i", "]", ".", "render", "(", "return_rgb_array", "=", "mode", "==", "'rgb_array'", ")", ")", "\n", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_positions": [[280, 282], ["None"], "methods", ["None"], ["", "def", "get_positions", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", ".", "state", ".", "p_pos", "for", "agent", "in", "self", ".", "world", ".", "agents", "if", "agent", ".", "movable", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_landmark_positions": [[283, 285], ["None"], "methods", ["None"], ["", "def", "get_landmark_positions", "(", "self", ")", ":", "\n", "        ", "return", "[", "landmark", ".", "state", ".", "p_pos", "for", "landmark", "in", "self", ".", "world", ".", "landmarks", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_communications": [[286, 288], ["None"], "methods", ["None"], ["", "def", "get_communications", "(", "self", ")", ":", "\n", "        ", "return", "[", "agent", ".", "state", ".", "c", "for", "agent", "in", "self", ".", "world", ".", "agents", "if", "not", "agent", ".", "silent", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv._make_receptor_locations": [[290, 308], ["numpy.linspace", "dx.append", "numpy.linspace", "numpy.linspace", "numpy.array", "numpy.linspace", "dx.append", "dx.append", "numpy.array", "numpy.array", "numpy.cos", "numpy.sin"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "_make_receptor_locations", "(", "self", ",", "agent", ")", ":", "\n", "        ", "receptor_type", "=", "'polar'", "\n", "range_min", "=", "0.05", "*", "2.0", "\n", "range_max", "=", "1.00", "\n", "dx", "=", "[", "]", "\n", "# circular receptive field", "\n", "if", "receptor_type", "==", "'polar'", ":", "\n", "            ", "for", "angle", "in", "np", ".", "linspace", "(", "-", "np", ".", "pi", ",", "+", "np", ".", "pi", ",", "8", ",", "endpoint", "=", "False", ")", ":", "\n", "                ", "for", "distance", "in", "np", ".", "linspace", "(", "range_min", ",", "range_max", ",", "3", ")", ":", "\n", "                    ", "dx", ".", "append", "(", "distance", "*", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "angle", ")", ",", "np", ".", "sin", "(", "angle", ")", "]", ")", ")", "\n", "# add origin", "\n", "", "", "dx", ".", "append", "(", "np", ".", "array", "(", "[", "0.0", ",", "0.0", "]", ")", ")", "\n", "# grid receptive field", "\n", "", "if", "receptor_type", "==", "'grid'", ":", "\n", "            ", "for", "x", "in", "np", ".", "linspace", "(", "-", "range_max", ",", "+", "range_max", ",", "5", ")", ":", "\n", "                ", "for", "y", "in", "np", ".", "linspace", "(", "-", "range_max", ",", "+", "range_max", ",", "5", ")", ":", "\n", "                    ", "dx", ".", "append", "(", "np", ".", "array", "(", "[", "x", ",", "y", "]", ")", ")", "\n", "", "", "", "return", "dx", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.BatchMultiAgentEnv.__init__": [[318, 320], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "env_batch", ")", ":", "\n", "        ", "self", ".", "env_batch", "=", "env_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.BatchMultiAgentEnv.n": [[321, 324], ["numpy.sum"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "@", "property", "\n", "def", "n", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "sum", "(", "[", "env", ".", "n", "for", "env", "in", "self", ".", "env_batch", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.BatchMultiAgentEnv.action_space": [[325, 328], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "action_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env_batch", "[", "0", "]", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.BatchMultiAgentEnv.observation_space": [[329, 332], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "observation_space", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "env_batch", "[", "0", "]", ".", "observation_space", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.BatchMultiAgentEnv.step": [[333, 347], ["env.step"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "action_n", ",", "time", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "reward_n", "=", "[", "]", "\n", "done_n", "=", "[", "]", "\n", "info_n", "=", "{", "'n'", ":", "[", "]", "}", "\n", "i", "=", "0", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "obs", ",", "reward", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action_n", "[", "i", ":", "(", "i", "+", "env", ".", "n", ")", "]", ",", "time", ")", "\n", "i", "+=", "env", ".", "n", "\n", "obs_n", "+=", "obs", "\n", "# reward = [r / len(self.env_batch) for r in reward]", "\n", "reward_n", "+=", "reward", "\n", "done_n", "+=", "done", "\n", "", "return", "obs_n", ",", "reward_n", ",", "done_n", ",", "info_n", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.BatchMultiAgentEnv.reset": [[348, 353], ["env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs_n", "=", "[", "]", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "obs_n", "+=", "env", ".", "reset", "(", ")", "\n", "", "return", "obs_n", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.BatchMultiAgentEnv.render": [[355, 360], ["env.render"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ",", "close", "=", "True", ")", ":", "\n", "        ", "results_n", "=", "[", "]", "\n", "for", "env", "in", "self", ".", "env_batch", ":", "\n", "            ", "results_n", "+=", "env", ".", "render", "(", "mode", ",", "close", ")", "\n", "", "return", "results_n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener.Scenario.make_world": [[6, 32], ["multiagent.core.World", "enumerate", "enumerate", "simple_speaker_listener.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "3", "\n", "num_landmarks", "=", "3", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "size", "=", "0.075", "\n", "# speaker", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "movable", "=", "False", "\n", "# listener", "\n", "world", ".", "agents", "[", "1", "]", ".", "silent", "=", "True", "\n", "# add landmarks", "\n", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener.Scenario.reset_world": [[33, 58], ["numpy.random.choice", "enumerate", "numpy.array", "numpy.array", "numpy.array", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# assign goals to agents", "\n", "        ", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "None", "\n", "agent", ".", "goal_b", "=", "None", "\n", "# want listener to go to the goal landmark", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "1", "]", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "# random properties for agents", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "world", ".", "landmarks", "[", "0", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.65", ",", "0.15", ",", "0.15", "]", ")", "\n", "world", ".", "landmarks", "[", "1", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "world", ".", "landmarks", "[", "2", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.65", "]", ")", "\n", "# special colors for goals", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "color", "+", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener.Scenario.benchmark_data": [[59, 62], ["simple_speaker_listener.Scenario.reward", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener.Scenario.reward": [[63, 68], ["numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# squared distance from listener to landmark", "\n", "        ", "a", "=", "world", ".", "agents", "[", "0", "]", "\n", "dist2", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "goal_a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", "\n", "return", "-", "dist2", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener.Scenario.observation": [[69, 92], ["numpy.zeros", "entity_pos.append", "comm.append", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_color", "=", "np", ".", "zeros", "(", "world", ".", "dim_color", ")", "\n", "if", "agent", ".", "goal_b", "is", "not", "None", ":", "\n", "            ", "goal_color", "=", "agent", ".", "goal_b", ".", "color", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "# communication of all other agents", "\n", "", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", "or", "(", "other", ".", "state", ".", "c", "is", "None", ")", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "\n", "# speaker", "\n", "", "if", "not", "agent", ".", "movable", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "goal_color", "]", ")", "\n", "# listener", "\n", "", "if", "agent", ".", "silent", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", "+", "comm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.make_world": [[17, 59], ["cars.road_world.RoadWorld", "cars.road_world.RoadWorld.set_agents", "enumerate", "enumerate", "simple_car_pixels.create_circular_mask", "cars.road_world.RoadWorld.reset", "simple_car_pixels.Scenario.reset_world", "cars.car_dynamics.Car", "multiagent.core.Surface", "multiagent.dynamic_agent.DynamicAgent", "range", "range", "numpy.min", "numpy.max", "numpy.min", "range", "simple_car_pixels.Scenario.rgb2gray", "len", "cars.road_world.RoadWorld.get_views"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.set_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.create_circular_mask", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.rgb2gray", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "RoadWorld", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_p", "=", "2", "# x, y, orientation, speed", "\n", "world", ".", "collaborative", "=", "True", "\n", "\n", "# add agents", "\n", "num_agents", "=", "2", "\n", "n_frames", "=", "4", "\n", "world", ".", "set_agents", "(", "[", "DynamicAgent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", ")", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'dynamic agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "color", "=", "colors", "[", "i", "]", "\n", "agent", ".", "body", "=", "Car", "(", "world", ".", "box2d", ")", "\n", "agent", ".", "scale", "=", "SCALE", "\n", "\n", "agent", ".", "shape", "=", "[", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY1", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY2", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY3", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY4", "]", "]", "\n", "agent", ".", "size", "=", "SIZE", "\n", "\n", "", "self", ".", "stacks", "=", "[", "[", "self", ".", "rgb2gray", "(", "world", ".", "get_views", "(", ")", "[", "i", "]", ")", "]", "*", "n_frames", "for", "i", "in", "range", "(", "len", "(", "world", ".", "agents", ")", ")", "]", "\n", "\n", "world", ".", "agents", "[", "0", "]", ".", "max_speed", "=", ".1", "\n", "world", ".", "agents", "[", "1", "]", ".", "max_speed", "=", ".15", "\n", "\n", "world", ".", "surfaces", "=", "[", "Surface", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "s", ".", "name", "=", "'surface %d'", "%", "i", "\n", "s", ".", "collide", "=", "False", "\n", "s", ".", "movable", "=", "False", "\n", "\n", "", "self", ".", "mask", "=", "create_circular_mask", "(", "STATE_H", ",", "STATE_W", ")", "\n", "self", ".", "mask", "=", "(", "self", ".", "mask", "-", "np", ".", "min", "(", "self", ".", "mask", ")", ")", "/", "(", "np", ".", "max", "(", "self", ".", "mask", ")", "-", "np", ".", "min", "(", "self", ".", "mask", ")", ")", "\n", "\n", "# make initial conditions", "\n", "world", ".", "reset", "(", ")", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.reset_world": [[60, 82], ["numpy.array", "numpy.random.choice", "numpy.random.choice", "enumerate", "enumerate", "numpy.array", "len", "numpy.zeros", "agent.body.make", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.array", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "coord", "=", "np", ".", "array", "(", "world", ".", "track", ")", "[", ":", ",", "2", ":", "4", "]", "\n", "norm_coord", "=", "np", ".", "array", "(", "[", "(", "c", "[", "0", "]", "/", "SCALE", ",", "c", "[", "1", "]", "/", "SCALE", ")", "for", "c", "in", "coord", "]", ")", "\n", "\n", "# all agents start somewhere", "\n", "start_i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "coord", ")", ")", "\n", "dist", "=", "5", "\n", "orient_clockwise", "=", "np", ".", "random", ".", "choice", "(", "2", ")", "\n", "delta_angle", "=", "orient_clockwise", "*", "np", ".", "pi", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "idx", "=", "(", "start_i", "-", "i", "*", "dist", ")", "%", "len", "(", "coord", ")", "if", "orient_clockwise", "==", "0.", "else", "(", "start_i", "+", "i", "*", "dist", ")", "%", "len", "(", "coord", ")", "\n", "agent", ".", "state", ".", "p_pos", "=", "norm_coord", "[", "idx", "]", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "angle", "=", "world", ".", "track", "[", "idx", "]", "[", "1", "]", "+", "delta_angle", "\n", "agent", ".", "body", ".", "make", "(", "*", "world", ".", "track", "[", "idx", "]", "[", "1", ":", "4", "]", ")", "# TODO: set x, y", "\n", "\n", "# pure for visualizing the track", "\n", "", "for", "i", ",", "surface", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "surface", ".", "color", "=", "np", ".", "array", "(", "[", "color", "for", "poly", ",", "color", ",", "id", ",", "lane", "in", "world", ".", "road_poly", "if", "lane", "==", "i", "]", ")", "\n", "surface", ".", "state", ".", "p_pos", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "poly", "=", "np", ".", "array", "(", "[", "[", "(", "c_i", "[", "0", "]", "/", "SCALE", ",", "c_i", "[", "1", "]", "/", "SCALE", ")", "for", "c_i", "in", "poly", "]", "for", "poly", ",", "color", ",", "id", ",", "lane", "in", "world", ".", "road_poly", "if", "lane", "==", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.is_off_road": [[83, 89], ["numpy.array", "numpy.any"], "methods", ["None"], ["", "", "def", "is_off_road", "(", "self", ",", "view", ")", ":", "\n", "        ", "center", "=", "STATE_H", "//", "2", ",", "STATE_W", "//", "2", "\n", "area_under_car", "=", "np", ".", "array", "(", "view", "[", "center", "[", "0", "]", "-", "1", ":", "center", "[", "0", "]", "+", "1", ",", "\n", "center", "[", "1", "]", "-", "1", ":", "center", "[", "1", "]", "+", "1", "]", ")", "\n", "\n", "return", "np", ".", "any", "(", "area_under_car", ">", "100", ")", "# outside road color is white", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.is_collision": [[90, 95], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.reward": [[96, 109], ["view.transpose", "numpy.sum", "abs", "numpy.array().reshape", "view.transpose.reshape", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "rew", "=", "0.", "\n", "\n", "for", "view", "in", "world", ".", "top_views", ":", "\n", "            ", "h", ",", "w", ",", "c", "=", "view", ".", "shape", "\n", "pixels", "=", "view", ".", "transpose", "(", "2", ",", "1", ",", "0", ")", "#* np.repeat(self.mask.reshape(1, h, w), 3, axis=0)", "\n", "rew", "-=", "np", ".", "sum", "(", "abs", "(", "np", ".", "array", "(", "ROAD_COLOR", ")", ".", "reshape", "(", "3", ",", "-", "1", ")", "-", "pixels", ".", "reshape", "(", "3", ",", "-", "1", ")", "/", "255.", ")", "/", "(", "c", "*", "h", "*", "w", ")", ")", "\n", "\n", "# if agent.collide:", "\n", "#     for a in world.agents:", "\n", "#         if self.is_collision(a, agent):", "\n", "#             rew -= 1", "\n", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.rgb2gray": [[110, 118], ["numpy.dot"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rgb2gray", "(", "rgb", ",", "norm", "=", "True", ")", ":", "\n", "# rgb image -> gray [0, 1]", "\n", "        ", "gray", "=", "np", ".", "dot", "(", "rgb", "[", "...", ",", ":", "]", ",", "[", "0.299", ",", "0.587", ",", "0.114", "]", ")", "\n", "if", "norm", ":", "\n", "# normalize", "\n", "            ", "gray", "=", "gray", "/", "128.", "-", "1.", "\n", "", "return", "gray", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.observation": [[119, 128], ["world.get_views", "enumerate", "simple_car_pixels.Scenario.rgb2gray", "simple_car_pixels.Scenario.stacks[].pop", "simple_car_pixels.Scenario.stacks[].append", "numpy.expand_dims", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.rgb2gray", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "views", "=", "world", ".", "get_views", "(", ")", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "==", "agent", ":", "\n", "                ", "view", "=", "views", "[", "i", "]", "\n", "view", "=", "self", ".", "rgb2gray", "(", "view", ")", "\n", "self", ".", "stacks", "[", "i", "]", ".", "pop", "(", "0", ")", "\n", "self", ".", "stacks", "[", "i", "]", ".", "append", "(", "view", ")", "\n", "return", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "self", ".", "stacks", "[", "i", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.done": [[129, 131], ["None"], "methods", ["None"], ["", "", "", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.Scenario.benchmark_data": [[132, 147], ["world.get_views", "enumerate", "simple_car_pixels.Scenario.reward", "simple_car_pixels.Scenario.is_collision", "simple_car_pixels.Scenario.is_off_road"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.is_off_road"], ["", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "collisions", "=", "0", "\n", "off_road", "=", "0", "\n", "\n", "views", "=", "world", ".", "get_views", "(", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "i", ",", "a", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "                ", "if", "a", "!=", "agent", ":", "\n", "                    ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                        ", "collisions", "+=", "1", "\n", "", "", "else", ":", "\n", "                    ", "if", "self", ".", "is_off_road", "(", "views", "[", "i", "]", ")", ":", "\n", "                        ", "off_road", "+=", "1", "\n", "\n", "", "", "", "", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "collisions", ",", "off_road", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels.create_circular_mask": [[149, 154], ["int", "int", "numpy.sqrt", "numpy.sqrt", "cars.road_world.STATE_H", "cars.road_world.STATE_W"], "function", ["None"], ["", "", "def", "create_circular_mask", "(", "h", ",", "w", ")", ":", "\n", "    ", "center", "=", "(", "int", "(", "w", "/", "2", ")", ",", "int", "(", "h", "/", "2", ")", ")", "\n", "\n", "Y", ",", "X", "=", "np", ".", "ogrid", "[", ":", "h", ",", ":", "w", "]", "\n", "return", "np", ".", "sqrt", "(", "center", "[", "0", "]", "**", "2", "+", "center", "[", "1", "]", "**", "2", ")", "-", "np", ".", "sqrt", "(", "(", "X", "-", "center", "[", "0", "]", ")", "**", "2", "+", "(", "Y", "-", "center", "[", "1", "]", ")", "**", "2", ")", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener6.Scenario.make_world": [[12, 48], ["multiagent.core.World", "enumerate", "enumerate", "enumerate", "simple_speaker_listener6.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "multiagent.core.Landmark", "numpy.array", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "5", "\n", "num_landmarks", "=", "6", "\n", "num_obstacles", "=", "6", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "size", "=", "0.075", "\n", "# speaker", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "movable", "=", "False", "\n", "# listener", "\n", "world", ".", "agents", "[", "1", "]", ".", "silent", "=", "True", "\n", "world", ".", "agents", "[", "1", "]", ".", "collide", "=", "True", "\n", "# add landmarks", "\n", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "# add obstacles", "\n", "", "world", ".", "obstacles", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_obstacles", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'obstacle %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "True", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.15", "]", ")", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener6.Scenario.reset_world": [[49, 77], ["numpy.random.choice", "enumerate", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# assign goals to agents", "\n", "        ", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "None", "\n", "agent", ".", "goal_b", "=", "None", "\n", "# want listener to go to the goal landmark", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "1", "]", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "# random properties for agents", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "colors", "[", "i", "]", "\n", "\n", "# special colors for goals", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "color", "+", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener6.Scenario.benchmark_data": [[78, 90], ["numpy.argmax", "numpy.sum", "simple_speaker_listener6.Scenario.is_collision", "simple_speaker_listener6.Scenario.reward", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "message", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "message", "=", "np", ".", "argmax", "(", "agent", ".", "state", ".", "c", ")", "\n", "", "collisions", "=", "0", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "", "return", "(", "-", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", ",", "message", ",", "collisions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener6.Scenario.is_collision": [[91, 96], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener6.Scenario.reward": [[97, 106], ["numpy.sum", "numpy.square", "simple_speaker_listener6.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# squared distance from listener to landmark", "\n", "        ", "a", "=", "world", ".", "agents", "[", "0", "]", "\n", "rew", "=", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "goal_a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener6.Scenario.observation": [[107, 136], ["random.shuffle", "numpy.zeros", "numpy.zeros", "entity_pos.append", "comm.append", "random.shuffle", "numpy.concatenate", "numpy.concatenate", "obs_pos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_pos", "=", "[", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", ",", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "]", "\n", "if", "agent", ".", "goal_b", "is", "not", "None", ":", "\n", "            ", "goal_pos", "[", "0", "]", "=", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "\n", "goal_pos", "[", "1", "]", "=", "agent", ".", "goal_b", ".", "state", ".", "p_pos", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "entity_pos", ")", "\n", "\n", "# communication of all other agents", "\n", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", "or", "(", "other", ".", "state", ".", "c", "is", "None", ")", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "\n", "# speaker", "\n", "", "if", "not", "agent", ".", "movable", ":", "\n", "            ", "obs_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "obstacles", ":", "\n", "                ", "obs_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "obs_pos", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "goal_pos", "[", "0", "]", "]", "+", "[", "goal_pos", "[", "1", "]", "]", "+", "obs_pos", ")", "\n", "# listener", "\n", "", "if", "agent", ".", "silent", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "comm", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener2.Scenario.make_world": [[11, 37], ["multiagent.core.World", "enumerate", "enumerate", "simple_speaker_listener2.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "5", "\n", "num_landmarks", "=", "6", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "size", "=", "0.075", "\n", "# speaker", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "movable", "=", "False", "\n", "# listener", "\n", "world", ".", "agents", "[", "1", "]", ".", "silent", "=", "True", "\n", "# add landmarks", "\n", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener2.Scenario.reset_world": [[38, 63], ["numpy.random.choice", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# assign goals to agents", "\n", "        ", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "None", "\n", "agent", ".", "goal_b", "=", "None", "\n", "# want listener to go to the goal landmark", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "1", "]", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "# random properties for agents", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "colors", "[", "i", "]", "\n", "\n", "# special colors for goals", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "color", "+", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener2.Scenario.benchmark_data": [[64, 71], ["numpy.argmax", "simple_speaker_listener2.Scenario.reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "message", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "message", "=", "np", ".", "argmax", "(", "agent", ".", "state", ".", "c", ")", "\n", "", "return", "(", "-", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener2.Scenario.reward": [[72, 77], ["numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# squared distance from listener to landmark", "\n", "        ", "a", "=", "world", ".", "agents", "[", "0", "]", "\n", "dist2", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "goal_a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", "\n", "return", "-", "dist2", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener2.Scenario.observation": [[78, 105], ["numpy.zeros", "numpy.zeros", "entity_pos.append", "comm.append", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_pos", "=", "[", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", ",", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "]", "\n", "if", "agent", ".", "goal_b", "is", "not", "None", ":", "\n", "            ", "goal_pos", "[", "0", "]", "=", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "\n", "goal_pos", "[", "1", "]", "=", "agent", ".", "goal_b", ".", "state", ".", "p_pos", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "# communication of all other agents", "\n", "", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", "or", "(", "other", ".", "state", ".", "c", "is", "None", ")", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "\n", "# position of other agent", "\n", "\n", "\n", "# speaker", "\n", "", "if", "not", "agent", ".", "movable", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "goal_pos", "[", "0", "]", "]", "+", "[", "goal_pos", "[", "1", "]", "]", ")", "\n", "# listener", "\n", "", "if", "agent", ".", "silent", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", "+", "comm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener4.Scenario.make_world": [[15, 51], ["multiagent.core.World", "enumerate", "enumerate", "enumerate", "simple_speaker_listener4.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "multiagent.core.Landmark", "numpy.array", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "5", "\n", "num_landmarks", "=", "12", "\n", "num_obstacles", "=", "12", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "size", "=", "0.075", "\n", "# speaker", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "movable", "=", "False", "\n", "# listener", "\n", "world", ".", "agents", "[", "1", "]", ".", "silent", "=", "True", "\n", "world", ".", "agents", "[", "1", "]", ".", "collide", "=", "True", "\n", "# add landmarks", "\n", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "# add obstacles", "\n", "", "world", ".", "obstacles", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_obstacles", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'obstacle %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "True", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.15", "]", ")", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener4.Scenario.reset_world": [[52, 80], ["numpy.random.choice", "enumerate", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# assign goals to agents", "\n", "        ", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "None", "\n", "agent", ".", "goal_b", "=", "None", "\n", "# want listener to go to the goal landmark", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "1", "]", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "# random properties for agents", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "colors", "[", "i", "]", "\n", "\n", "# special colors for goals", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "color", "+", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener4.Scenario.benchmark_data": [[81, 93], ["numpy.argmax", "numpy.sum", "simple_speaker_listener4.Scenario.is_collision", "simple_speaker_listener4.Scenario.reward", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "message", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "message", "=", "np", ".", "argmax", "(", "agent", ".", "state", ".", "c", ")", "\n", "", "collisions", "=", "0", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "", "return", "(", "-", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", ",", "message", ",", "collisions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener4.Scenario.is_collision": [[94, 99], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener4.Scenario.reward": [[100, 109], ["numpy.sum", "numpy.square", "simple_speaker_listener4.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# squared distance from listener to landmark", "\n", "        ", "a", "=", "world", ".", "agents", "[", "0", "]", "\n", "rew", "=", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "goal_a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener4.Scenario.observation": [[110, 139], ["random.shuffle", "numpy.zeros", "numpy.zeros", "entity_pos.append", "comm.append", "random.shuffle", "numpy.concatenate", "numpy.concatenate", "obs_pos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_pos", "=", "[", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", ",", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "]", "\n", "if", "agent", ".", "goal_b", "is", "not", "None", ":", "\n", "            ", "goal_pos", "[", "0", "]", "=", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "\n", "goal_pos", "[", "1", "]", "=", "agent", ".", "goal_b", ".", "state", ".", "p_pos", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "entity_pos", ")", "\n", "\n", "# communication of all other agents", "\n", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", "or", "(", "other", ".", "state", ".", "c", "is", "None", ")", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "\n", "# speaker", "\n", "", "if", "not", "agent", ".", "movable", ":", "\n", "            ", "obs_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "obstacles", ":", "\n", "                ", "obs_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "obs_pos", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "goal_pos", "[", "0", "]", "]", "+", "[", "goal_pos", "[", "1", "]", "]", "+", "obs_pos", ")", "\n", "# listener", "\n", "", "if", "agent", ".", "silent", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", "+", "comm", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.CryptoAgent.__init__": [[15, 18], ["multiagent.core.Agent.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CryptoAgent", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "key", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.make_world": [[21, 45], ["multiagent.core.World", "enumerate", "enumerate", "simple_crypto.Scenario.reset_world", "simple_crypto.CryptoAgent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "num_agents", "=", "3", "\n", "num_adversaries", "=", "1", "\n", "num_landmarks", "=", "2", "\n", "world", ".", "dim_c", "=", "4", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "CryptoAgent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "speaker", "=", "True", "if", "i", "==", "2", "else", "False", "\n", "agent", ".", "movable", "=", "False", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.reset_world": [[47, 76], ["enumerate", "enumerate", "zip", "numpy.random.choice", "enumerate", "numpy.array", "numpy.zeros", "numpy.random.choice", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.75", ",", "0.25", ",", "0.25", "]", ")", "\n", "", "agent", ".", "key", "=", "None", "\n", "# random properties for landmarks", "\n", "", "color_list", "=", "[", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "for", "i", "in", "world", ".", "landmarks", "]", "\n", "for", "i", ",", "color", "in", "enumerate", "(", "color_list", ")", ":", "\n", "            ", "color", "[", "i", "]", "+=", "1", "\n", "", "for", "color", ",", "landmark", "in", "zip", "(", "color_list", ",", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "color", "\n", "# set goal landmark", "\n", "", "goal", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "world", ".", "agents", "[", "1", "]", ".", "color", "=", "goal", ".", "color", "\n", "world", ".", "agents", "[", "2", "]", ".", "key", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", ".", "color", "\n", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "goal", "\n", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.benchmark_data": [[78, 81], ["None"], "methods", ["None"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "return", "(", "agent", ".", "state", ".", "c", ",", "agent", ".", "goal_a", ".", "color", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.good_listeners": [[83, 85], ["None"], "methods", ["None"], ["", "def", "good_listeners", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "and", "not", "agent", ".", "speaker", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.good_agents": [[87, 89], ["None"], "methods", ["None"], ["", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.adversaries": [[91, 93], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.reward": [[94, 96], ["simple_crypto.Scenario.adversary_reward", "simple_crypto.Scenario.agent_reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversary_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.agent_reward"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "self", ".", "adversary_reward", "(", "agent", ",", "world", ")", "if", "agent", ".", "adversary", "else", "self", ".", "agent_reward", "(", "agent", ",", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.agent_reward": [[97, 115], ["simple_crypto.Scenario.good_listeners", "simple_crypto.Scenario.adversaries", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.good_listeners", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversaries", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "agent_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents rewarded if Bob can reconstruct message, but adversary (Eve) cannot", "\n", "        ", "good_listeners", "=", "self", ".", "good_listeners", "(", "world", ")", "\n", "adversaries", "=", "self", ".", "adversaries", "(", "world", ")", "\n", "good_rew", "=", "0", "\n", "adv_rew", "=", "0", "\n", "for", "a", "in", "good_listeners", ":", "\n", "            ", "if", "(", "a", ".", "state", ".", "c", "==", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", ")", ".", "all", "(", ")", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "good_rew", "-=", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "c", "-", "agent", ".", "goal_a", ".", "color", ")", ")", "\n", "", "", "for", "a", "in", "adversaries", ":", "\n", "            ", "if", "(", "a", ".", "state", ".", "c", "==", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", ")", ".", "all", "(", ")", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "adv_l1", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "c", "-", "agent", ".", "goal_a", ".", "color", ")", ")", "\n", "adv_rew", "+=", "adv_l1", "\n", "", "", "return", "adv_rew", "+", "good_rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.adversary_reward": [[116, 122], ["numpy.sum", "numpy.square", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "adversary_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Adversary (Eve) is rewarded if it can reconstruct original goal", "\n", "        ", "rew", "=", "0", "\n", "if", "not", "(", "agent", ".", "state", ".", "c", "==", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", ")", ".", "all", "(", ")", ":", "\n", "            ", "rew", "-=", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "c", "-", "agent", ".", "goal_a", ".", "color", ")", ")", "\n", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_crypto.Scenario.observation": [[124, 170], ["numpy.zeros", "numpy.array", "entity_pos.append", "comm.append", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "print", "print", "print", "print", "print", "print", "print", "print", "print", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "numpy.random.randn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_color", "=", "np", ".", "zeros", "(", "world", ".", "dim_color", ")", "\n", "if", "agent", ".", "goal_a", "is", "not", "None", ":", "\n", "            ", "goal_color", "=", "agent", ".", "goal_a", ".", "color", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# communication of all other agents", "\n", "", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", "or", "(", "other", ".", "state", ".", "c", "is", "None", ")", "or", "not", "other", ".", "speaker", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "\n", "", "confer", "=", "np", ".", "array", "(", "[", "0", "]", ")", "\n", "\n", "if", "world", ".", "agents", "[", "2", "]", ".", "key", "is", "None", ":", "\n", "            ", "confer", "=", "np", ".", "array", "(", "[", "1", "]", ")", "\n", "key", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "goal_color", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "else", ":", "\n", "            ", "key", "=", "world", ".", "agents", "[", "2", "]", ".", "key", "\n", "\n", "", "prnt", "=", "False", "\n", "# speaker", "\n", "if", "agent", ".", "speaker", ":", "\n", "            ", "if", "prnt", ":", "\n", "                ", "print", "(", "'speaker'", ")", "\n", "print", "(", "agent", ".", "state", ".", "c", ")", "\n", "print", "(", "np", ".", "concatenate", "(", "[", "goal_color", "]", "+", "[", "key", "]", "+", "[", "confer", "]", "+", "[", "np", ".", "random", ".", "randn", "(", "1", ")", "]", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "[", "goal_color", "]", "+", "[", "key", "]", ")", "\n", "# listener", "\n", "", "if", "not", "agent", ".", "speaker", "and", "not", "agent", ".", "adversary", ":", "\n", "            ", "if", "prnt", ":", "\n", "                ", "print", "(", "'listener'", ")", "\n", "print", "(", "agent", ".", "state", ".", "c", ")", "\n", "print", "(", "np", ".", "concatenate", "(", "[", "key", "]", "+", "comm", "+", "[", "confer", "]", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "[", "key", "]", "+", "comm", ")", "\n", "", "if", "not", "agent", ".", "speaker", "and", "agent", ".", "adversary", ":", "\n", "            ", "if", "prnt", ":", "\n", "                ", "print", "(", "'adversary'", ")", "\n", "print", "(", "agent", ".", "state", ".", "c", ")", "\n", "print", "(", "np", ".", "concatenate", "(", "comm", "+", "[", "confer", "]", ")", ")", "\n", "", "return", "np", ".", "concatenate", "(", "comm", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener5.Scenario.make_world": [[12, 48], ["multiagent.core.World", "enumerate", "enumerate", "enumerate", "simple_speaker_listener5.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "multiagent.core.Landmark", "numpy.array", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "5", "\n", "num_landmarks", "=", "3", "\n", "num_obstacles", "=", "6", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "size", "=", "0.075", "\n", "# speaker", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "movable", "=", "False", "\n", "# listener", "\n", "world", ".", "agents", "[", "1", "]", ".", "silent", "=", "True", "\n", "world", ".", "agents", "[", "1", "]", ".", "collide", "=", "True", "\n", "# add landmarks", "\n", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "# add obstacles", "\n", "", "world", ".", "obstacles", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_obstacles", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'obstacle %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "True", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.15", "]", ")", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener5.Scenario.reset_world": [[49, 77], ["numpy.random.choice", "enumerate", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# assign goals to agents", "\n", "        ", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "None", "\n", "agent", ".", "goal_b", "=", "None", "\n", "# want listener to go to the goal landmark", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "1", "]", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "# random properties for agents", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "colors", "[", "i", "]", "\n", "\n", "# special colors for goals", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "color", "+", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener5.Scenario.benchmark_data": [[78, 90], ["numpy.argmax", "numpy.sum", "simple_speaker_listener5.Scenario.is_collision", "simple_speaker_listener5.Scenario.reward", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "message", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "message", "=", "np", ".", "argmax", "(", "agent", ".", "state", ".", "c", ")", "\n", "", "collisions", "=", "0", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "", "return", "(", "-", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", ",", "message", ",", "collisions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener5.Scenario.is_collision": [[91, 96], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener5.Scenario.reward": [[97, 106], ["numpy.sum", "numpy.square", "simple_speaker_listener5.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# squared distance from listener to landmark", "\n", "        ", "a", "=", "world", ".", "agents", "[", "0", "]", "\n", "rew", "=", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "goal_a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener5.Scenario.observation": [[107, 136], ["random.shuffle", "numpy.zeros", "numpy.zeros", "entity_pos.append", "comm.append", "random.shuffle", "numpy.concatenate", "numpy.concatenate", "obs_pos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_pos", "=", "[", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", ",", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "]", "\n", "if", "agent", ".", "goal_b", "is", "not", "None", ":", "\n", "            ", "goal_pos", "[", "0", "]", "=", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "\n", "goal_pos", "[", "1", "]", "=", "agent", ".", "goal_b", ".", "state", ".", "p_pos", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "entity_pos", ")", "\n", "\n", "# communication of all other agents", "\n", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", "or", "(", "other", ".", "state", ".", "c", "is", "None", ")", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "\n", "# speaker", "\n", "", "if", "not", "agent", ".", "movable", ":", "\n", "            ", "obs_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "obstacles", ":", "\n", "                ", "obs_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "obs_pos", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "goal_pos", "[", "0", "]", "]", "+", "[", "goal_pos", "[", "1", "]", "]", "+", "obs_pos", ")", "\n", "# listener", "\n", "", "if", "agent", ".", "silent", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", "+", "comm", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.transition_utils._index_to_cell": [[5, 8], ["numpy.array", "int"], "function", ["None"], ["def", "_index_to_cell", "(", "s", ",", "dims", ")", ":", "\n", "    ", "cell", "=", "[", "int", "(", "s", "/", "dims", "[", "1", "]", ")", ",", "s", "%", "dims", "[", "1", "]", "]", "\n", "return", "np", ".", "array", "(", "cell", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.transition_utils._cell_to_index": [[10, 12], ["None"], "function", ["None"], ["", "def", "_cell_to_index", "(", "cell", ",", "dims", ")", ":", "\n", "    ", "return", "cell", "[", "1", "]", "+", "dims", "[", "1", "]", "*", "cell", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.transition_utils._location_to_index": [[14, 16], ["numpy.where", "numpy.all"], "function", ["None"], ["", "def", "_location_to_index", "(", "locations", ",", "locs", ")", ":", "\n", "    ", "return", "np", ".", "where", "(", "np", ".", "all", "(", "locations", "==", "locs", ",", "axis", "=", "1", ")", ")", "[", "0", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.transition_utils._dist_locs": [[18, 24], ["transition_utils._dist_locs._dir_to_dist"], "function", ["None"], ["", "def", "_dist_locs", "(", "p1", ",", "p2", ",", "dims", ",", "round_off_func", "=", "lambda", "x", ":", "x", ")", ":", "\n", "    ", "def", "_dir_to_dist", "(", "p_pos1", ",", "p_pos2", ")", ":", "\n", "        ", "delta_pos", "=", "p_pos2", "-", "p_pos1", "\n", "return", "round_off_func", "(", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", ")", "\n", "\n", "", "return", "_dir_to_dist", "(", "_index_to_cell", "(", "p1", ",", "dims", ")", ",", "_index_to_cell", "(", "p2", ",", "dims", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.transition_utils.switch_places": [[29, 42], ["len", "len"], "function", ["None"], ["def", "switch_places", "(", "locs", ",", "locs_new", ")", ":", "\n", "    ", "\"\"\" return true if locations between agents are switched between successive time steps\n    locs: locations at t1 of all agents\n    locs_t2: locations at t2 of all agents\n    \"\"\"", "\n", "if", "len", "(", "locs", ")", "==", "2", ":", "\n", "        ", "return", "(", "locs", "[", "0", "]", "==", "locs_new", "[", "1", "]", ")", "and", "(", "locs", "[", "1", "]", "==", "locs_new", "[", "0", "]", ")", "\n", "", "elif", "len", "(", "locs", ")", "==", "3", ":", "\n", "        ", "return", "(", "(", "locs", "[", "0", "]", "==", "locs_new", "[", "1", "]", ")", "and", "(", "locs", "[", "1", "]", "==", "locs_new", "[", "0", "]", ")", ")", "or", "(", "(", "locs", "[", "0", "]", "==", "locs_new", "[", "2", "]", ")", "and", "(", "locs", "[", "2", "]", "==", "locs_new", "[", "0", "]", ")", ")", "or", "(", "(", "locs", "[", "1", "]", "==", "locs_new", "[", "2", "]", ")", "and", "(", "locs", "[", "2", "]", "==", "locs_new", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple.Scenario.make_world": [[6, 23], ["multiagent.core.World", "enumerate", "enumerate", "simple.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "1", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "silent", "=", "True", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "1", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple.Scenario.reset_world": [[24, 40], ["enumerate", "enumerate", "numpy.array", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.75", ",", "0.75", ",", "0.75", "]", ")", "\n", "", "world", ".", "landmarks", "[", "0", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.75", ",", "0.25", ",", "0.25", "]", ")", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple.Scenario.reward": [[41, 44], ["numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "dist2", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "world", ".", "landmarks", "[", "0", "]", ".", "state", ".", "p_pos", ")", ")", "\n", "return", "-", "dist2", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple.Scenario.observation": [[45, 51], ["numpy.concatenate", "entity_pos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_reference.Scenario.make_world": [[6, 25], ["multiagent.core.World", "enumerate", "enumerate", "simple_reference.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "10", "\n", "world", ".", "collaborative", "=", "True", "# whether agents share rewards", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "3", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_reference.Scenario.reset_world": [[26, 54], ["numpy.random.choice", "numpy.random.choice", "enumerate", "numpy.array", "numpy.array", "numpy.array", "enumerate", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# assign goals to agents", "\n", "        ", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "None", "\n", "agent", ".", "goal_b", "=", "None", "\n", "# want other agent to go to the goal landmark", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "1", "]", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "world", ".", "agents", "[", "1", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "0", "]", "\n", "world", ".", "agents", "[", "1", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "# random properties for agents", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "world", ".", "landmarks", "[", "0", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.75", ",", "0.25", ",", "0.25", "]", ")", "\n", "world", ".", "landmarks", "[", "1", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.75", ",", "0.25", "]", ")", "\n", "world", ".", "landmarks", "[", "2", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.75", "]", ")", "\n", "# special colors for goals", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "color", "\n", "world", ".", "agents", "[", "1", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "1", "]", ".", "goal_b", ".", "color", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_reference.Scenario.benchmark_data": [[55, 60], ["numpy.sqrt", "numpy.sum", "simple_reference.Scenario.reward", "numpy.argmax", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "dist_goal", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "-", "agent", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "occupied_landmarks", "=", "1", "if", "dist_goal", "<", ".1", "else", "0", "\n", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "np", ".", "argmax", "(", "agent", ".", "state", ".", "c", ")", ",", "dist_goal", ",", "occupied_landmarks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_reference.Scenario.reward": [[61, 66], ["numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "if", "agent", ".", "goal_a", "is", "None", "or", "agent", ".", "goal_b", "is", "None", ":", "\n", "            ", "return", "0.0", "\n", "", "dist2", "=", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "-", "agent", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", "\n", "return", "-", "dist2", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_reference.Scenario.observation": [[67, 87], ["numpy.concatenate", "numpy.zeros", "numpy.zeros", "entity_pos.append", "entity_color.append", "comm.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_color", "=", "[", "np", ".", "zeros", "(", "world", ".", "dim_color", ")", ",", "np", ".", "zeros", "(", "world", ".", "dim_color", ")", "]", "\n", "if", "agent", ".", "goal_b", "is", "not", "None", ":", "\n", "            ", "goal_color", "[", "1", "]", "=", "agent", ".", "goal_b", ".", "color", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# entity colors", "\n", "", "entity_color", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_color", ".", "append", "(", "entity", ".", "color", ")", "\n", "# communication of all other agents", "\n", "", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", "+", "[", "goal_color", "[", "1", "]", "]", "+", "comm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.make_world": [[17, 61], ["multiagent.road_world.RoadWorld", "multiagent.road_world.RoadWorld.set_agents", "enumerate", "enumerate", "simple_car_pixels_3agents.create_circular_mask", "multiagent.road_world.RoadWorld.reset", "simple_car_pixels_3agents.Scenario.reset_world", "multiagent.scenarios.car_dynamics.Car", "multiagent.core.Surface", "multiagent.dynamic_agent.DynamicAgent", "range", "range", "numpy.min", "numpy.max", "numpy.min", "range", "simple_car_pixels_3agents.Scenario.rgb2gray", "len", "multiagent.road_world.RoadWorld.get_views"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.set_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.create_circular_mask", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.rgb2gray", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "RoadWorld", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_p", "=", "2", "# x, y, orientation, speed", "\n", "world", ".", "collaborative", "=", "True", "\n", "\n", "# add agents", "\n", "num_agents", "=", "3", "\n", "n_frames", "=", "4", "\n", "world", ".", "set_agents", "(", "[", "DynamicAgent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", ")", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'dynamic agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "color", "=", "colors", "[", "i", "]", "\n", "agent", ".", "body", "=", "Car", "(", "world", ".", "box2d", ")", "\n", "agent", ".", "scale", "=", "SCALE", "\n", "\n", "agent", ".", "shape", "=", "[", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY1", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY2", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY3", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY4", "]", "]", "\n", "agent", ".", "size", "=", "SIZE", "\n", "\n", "", "self", ".", "stacks", "=", "[", "[", "self", ".", "rgb2gray", "(", "world", ".", "get_views", "(", ")", "[", "i", "]", ")", "]", "*", "n_frames", "for", "i", "in", "range", "(", "len", "(", "world", ".", "agents", ")", ")", "]", "\n", "\n", "world", ".", "agents", "[", "0", "]", ".", "max_speed", "=", ".05", "\n", "world", ".", "agents", "[", "1", "]", ".", "max_speed", "=", ".1", "\n", "world", ".", "agents", "[", "2", "]", ".", "max_speed", "=", ".15", "\n", "\n", "\n", "world", ".", "surfaces", "=", "[", "Surface", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "s", ".", "name", "=", "'surface %d'", "%", "i", "\n", "s", ".", "collide", "=", "False", "\n", "s", ".", "movable", "=", "False", "\n", "\n", "", "self", ".", "mask", "=", "create_circular_mask", "(", "STATE_H", ",", "STATE_W", ")", "\n", "self", ".", "mask", "=", "(", "self", ".", "mask", "-", "np", ".", "min", "(", "self", ".", "mask", ")", ")", "/", "(", "np", ".", "max", "(", "self", ".", "mask", ")", "-", "np", ".", "min", "(", "self", ".", "mask", ")", ")", "\n", "\n", "# make initial conditions", "\n", "world", ".", "reset", "(", ")", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.reset_world": [[62, 84], ["numpy.array", "numpy.random.choice", "numpy.random.choice", "enumerate", "enumerate", "numpy.array", "len", "numpy.zeros", "agent.body.make", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.array", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "coord", "=", "np", ".", "array", "(", "world", ".", "track", ")", "[", ":", ",", "2", ":", "4", "]", "\n", "norm_coord", "=", "np", ".", "array", "(", "[", "(", "c", "[", "0", "]", "/", "SCALE", ",", "c", "[", "1", "]", "/", "SCALE", ")", "for", "c", "in", "coord", "]", ")", "\n", "\n", "# all agents start somewhere", "\n", "start_i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "coord", ")", ")", "\n", "dist", "=", "5", "\n", "orient_clockwise", "=", "np", ".", "random", ".", "choice", "(", "2", ")", "\n", "delta_angle", "=", "orient_clockwise", "*", "np", ".", "pi", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "idx", "=", "(", "start_i", "-", "i", "*", "dist", ")", "%", "len", "(", "coord", ")", "if", "orient_clockwise", "==", "0.", "else", "(", "start_i", "+", "i", "*", "dist", ")", "%", "len", "(", "coord", ")", "\n", "agent", ".", "state", ".", "p_pos", "=", "norm_coord", "[", "idx", "]", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "angle", "=", "world", ".", "track", "[", "idx", "]", "[", "1", "]", "+", "delta_angle", "\n", "agent", ".", "body", ".", "make", "(", "*", "world", ".", "track", "[", "idx", "]", "[", "1", ":", "4", "]", ")", "# TODO: set x, y", "\n", "\n", "# pure for visualizing the track", "\n", "", "for", "i", ",", "surface", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "surface", ".", "color", "=", "np", ".", "array", "(", "[", "color", "for", "poly", ",", "color", ",", "id", ",", "lane", "in", "world", ".", "road_poly", "if", "lane", "==", "i", "]", ")", "\n", "surface", ".", "state", ".", "p_pos", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "poly", "=", "np", ".", "array", "(", "[", "[", "(", "c_i", "[", "0", "]", "/", "SCALE", ",", "c_i", "[", "1", "]", "/", "SCALE", ")", "for", "c_i", "in", "poly", "]", "for", "poly", ",", "color", ",", "id", ",", "lane", "in", "world", ".", "road_poly", "if", "lane", "==", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.is_off_road": [[85, 91], ["numpy.array", "numpy.any"], "methods", ["None"], ["", "", "def", "is_off_road", "(", "self", ",", "view", ")", ":", "\n", "        ", "center", "=", "STATE_H", "//", "2", ",", "STATE_W", "//", "2", "\n", "area_under_car", "=", "np", ".", "array", "(", "view", "[", "center", "[", "0", "]", "-", "1", ":", "center", "[", "0", "]", "+", "1", ",", "\n", "center", "[", "1", "]", "-", "1", ":", "center", "[", "1", "]", "+", "1", "]", ")", "\n", "\n", "return", "np", ".", "any", "(", "area_under_car", ">", "100", ")", "# outside road color is white", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.is_collision": [[92, 97], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.reward": [[98, 111], ["view.transpose", "numpy.sum", "abs", "numpy.array().reshape", "view.transpose.reshape", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "rew", "=", "0.", "\n", "\n", "for", "view", "in", "world", ".", "top_views", ":", "\n", "            ", "h", ",", "w", ",", "c", "=", "view", ".", "shape", "\n", "pixels", "=", "view", ".", "transpose", "(", "2", ",", "1", ",", "0", ")", "#* np.repeat(self.mask.reshape(1, h, w), 3, axis=0)", "\n", "rew", "-=", "np", ".", "sum", "(", "abs", "(", "np", ".", "array", "(", "ROAD_COLOR", ")", ".", "reshape", "(", "3", ",", "-", "1", ")", "-", "pixels", ".", "reshape", "(", "3", ",", "-", "1", ")", "/", "255.", ")", "/", "(", "c", "*", "h", "*", "w", ")", ")", "\n", "\n", "# if agent.collide:", "\n", "#     for a in world.agents:", "\n", "#         if self.is_collision(a, agent):", "\n", "#             rew -= 1", "\n", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.rgb2gray": [[112, 120], ["numpy.dot"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rgb2gray", "(", "rgb", ",", "norm", "=", "True", ")", ":", "\n", "# rgb image -> gray [0, 1]", "\n", "        ", "gray", "=", "np", ".", "dot", "(", "rgb", "[", "...", ",", ":", "]", ",", "[", "0.299", ",", "0.587", ",", "0.114", "]", ")", "\n", "if", "norm", ":", "\n", "# normalize", "\n", "            ", "gray", "=", "gray", "/", "128.", "-", "1.", "\n", "", "return", "gray", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.observation": [[121, 130], ["world.get_views", "enumerate", "simple_car_pixels_3agents.Scenario.rgb2gray", "simple_car_pixels_3agents.Scenario.stacks[].pop", "simple_car_pixels_3agents.Scenario.stacks[].append", "numpy.expand_dims", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.rgb2gray", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "views", "=", "world", ".", "get_views", "(", ")", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "==", "agent", ":", "\n", "                ", "view", "=", "views", "[", "i", "]", "\n", "view", "=", "self", ".", "rgb2gray", "(", "view", ")", "\n", "self", ".", "stacks", "[", "i", "]", ".", "pop", "(", "0", ")", "\n", "self", ".", "stacks", "[", "i", "]", ".", "append", "(", "view", ")", "\n", "return", "np", ".", "expand_dims", "(", "np", ".", "array", "(", "self", ".", "stacks", "[", "i", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.done": [[131, 133], ["None"], "methods", ["None"], ["", "", "", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.benchmark_data": [[134, 149], ["world.get_views", "enumerate", "simple_car_pixels_3agents.Scenario.reward", "simple_car_pixels_3agents.Scenario.is_collision", "simple_car_pixels_3agents.Scenario.is_off_road"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.Scenario.is_off_road"], ["", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "collisions", "=", "0", "\n", "off_road", "=", "0", "\n", "\n", "views", "=", "world", ".", "get_views", "(", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "i", ",", "a", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "                ", "if", "a", "!=", "agent", ":", "\n", "                    ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                        ", "collisions", "+=", "1", "\n", "", "", "else", ":", "\n", "                    ", "if", "self", ".", "is_off_road", "(", "views", "[", "i", "]", ")", ":", "\n", "                        ", "off_road", "+=", "1", "\n", "\n", "", "", "", "", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "collisions", ",", "off_road", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car_pixels_3agents.create_circular_mask": [[151, 156], ["int", "int", "numpy.sqrt", "numpy.sqrt", "multiagent.road_world.STATE_H", "multiagent.road_world.STATE_W"], "function", ["None"], ["", "", "def", "create_circular_mask", "(", "h", ",", "w", ")", ":", "\n", "    ", "center", "=", "(", "int", "(", "w", "/", "2", ")", ",", "int", "(", "h", "/", "2", ")", ")", "\n", "\n", "Y", ",", "X", "=", "np", ".", "ogrid", "[", ":", "h", ",", ":", "w", "]", "\n", "return", "np", ".", "sqrt", "(", "center", "[", "0", "]", "**", "2", "+", "center", "[", "1", "]", "**", "2", ")", "-", "np", ".", "sqrt", "(", "(", "X", "-", "center", "[", "0", "]", ")", "**", "2", "+", "(", "Y", "-", "center", "[", "1", "]", ")", "**", "2", ")", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener3.Scenario.make_world": [[12, 48], ["multiagent.core.World", "enumerate", "enumerate", "enumerate", "simple_speaker_listener3.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "multiagent.core.Landmark", "numpy.array", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "5", "\n", "num_landmarks", "=", "6", "\n", "num_obstacles", "=", "6", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "2", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "size", "=", "0.075", "\n", "# speaker", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "movable", "=", "False", "\n", "# listener", "\n", "world", ".", "agents", "[", "1", "]", ".", "silent", "=", "True", "\n", "world", ".", "agents", "[", "1", "]", ".", "collide", "=", "True", "\n", "# add landmarks", "\n", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "# add obstacles", "\n", "", "world", ".", "obstacles", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_obstacles", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'obstacle %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "True", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.04", "\n", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.15", "]", ")", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener3.Scenario.reset_world": [[49, 77], ["numpy.random.choice", "enumerate", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# assign goals to agents", "\n", "        ", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "None", "\n", "agent", ".", "goal_b", "=", "None", "\n", "# want listener to go to the goal landmark", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", "=", "world", ".", "agents", "[", "1", "]", "\n", "world", ".", "agents", "[", "0", "]", ".", "goal_b", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "# random properties for agents", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "colors", "[", "i", "]", "\n", "\n", "# special colors for goals", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "color", "=", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "color", "+", "np", ".", "array", "(", "[", "0.45", ",", "0.45", ",", "0.45", "]", ")", "\n", "# set random initial states", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener3.Scenario.benchmark_data": [[78, 90], ["numpy.argmax", "numpy.sum", "simple_speaker_listener3.Scenario.is_collision", "simple_speaker_listener3.Scenario.reward", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "if", "agent", ".", "silent", ":", "\n", "            ", "message", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "message", "=", "np", ".", "argmax", "(", "agent", ".", "state", ".", "c", ")", "\n", "", "collisions", "=", "0", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "", "return", "(", "-", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "np", ".", "sum", "(", "np", ".", "square", "(", "world", ".", "agents", "[", "0", "]", ".", "goal_a", ".", "state", ".", "p_pos", "-", "world", ".", "agents", "[", "0", "]", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", ",", "message", ",", "collisions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener3.Scenario.is_collision": [[91, 96], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener3.Scenario.reward": [[97, 106], ["numpy.sum", "numpy.square", "simple_speaker_listener3.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# squared distance from listener to landmark", "\n", "        ", "a", "=", "world", ".", "agents", "[", "0", "]", "\n", "rew", "=", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "goal_a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_b", ".", "state", ".", "p_pos", ")", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "obs", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obs", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_speaker_listener3.Scenario.observation": [[107, 136], ["random.shuffle", "numpy.zeros", "numpy.zeros", "entity_pos.append", "comm.append", "random.shuffle", "numpy.concatenate", "numpy.concatenate", "obs_pos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# goal color", "\n", "        ", "goal_pos", "=", "[", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", ",", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "]", "\n", "if", "agent", ".", "goal_b", "is", "not", "None", ":", "\n", "            ", "goal_pos", "[", "0", "]", "=", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "\n", "goal_pos", "[", "1", "]", "=", "agent", ".", "goal_b", ".", "state", ".", "p_pos", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "entity_pos", ")", "\n", "\n", "# communication of all other agents", "\n", "comm", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", "or", "(", "other", ".", "state", ".", "c", "is", "None", ")", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "\n", "# speaker", "\n", "", "if", "not", "agent", ".", "movable", ":", "\n", "            ", "obs_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "obstacles", ":", "\n", "                ", "obs_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "obs_pos", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "goal_pos", "[", "0", "]", "]", "+", "[", "goal_pos", "[", "1", "]", "]", "+", "obs_pos", ")", "\n", "# listener", "\n", "", "if", "agent", ".", "silent", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", "+", "comm", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.make_world": [[7, 58], ["multiagent.core.World", "enumerate", "enumerate", "enumerate", "enumerate", "simple_world_comm.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "multiagent.core.Landmark", "multiagent.core.Landmark", "range", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "4", "\n", "#world.damping = 1", "\n", "num_good_agents", "=", "2", "\n", "num_adversaries", "=", "4", "\n", "num_agents", "=", "num_adversaries", "+", "num_good_agents", "\n", "num_landmarks", "=", "1", "\n", "num_food", "=", "2", "\n", "num_forests", "=", "2", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "leader", "=", "True", "if", "i", "==", "0", "else", "False", "\n", "agent", ".", "silent", "=", "True", "if", "i", ">", "0", "else", "False", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "size", "=", "0.075", "if", "agent", ".", "adversary", "else", "0.045", "\n", "agent", ".", "accel", "=", "3.0", "if", "agent", ".", "adversary", "else", "4.0", "\n", "#agent.accel = 20.0 if agent.adversary else 25.0", "\n", "agent", ".", "max_speed", "=", "1.0", "if", "agent", ".", "adversary", "else", "1.3", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "True", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.2", "\n", "landmark", ".", "boundary", "=", "False", "\n", "", "world", ".", "food", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_food", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'food %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.03", "\n", "landmark", ".", "boundary", "=", "False", "\n", "", "world", ".", "forests", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_forests", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "forests", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'forest %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.3", "\n", "landmark", ".", "boundary", "=", "False", "\n", "", "world", ".", "landmarks", "+=", "world", ".", "food", "\n", "world", ".", "landmarks", "+=", "world", ".", "forests", "\n", "#world.landmarks += self.set_boundaries(world)  # world boundaries now penalized with negative reward", "\n", "# make initial conditions", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.set_boundaries": [[59, 86], ["int", "enumerate", "range", "range", "numpy.array", "numpy.zeros", "multiagent.core.Landmark", "numpy.array", "boundary_list.append", "multiagent.core.Landmark", "numpy.array", "boundary_list.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "set_boundaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "boundary_list", "=", "[", "]", "\n", "landmark_size", "=", "1", "\n", "edge", "=", "1", "+", "landmark_size", "\n", "num_landmarks", "=", "int", "(", "edge", "*", "2", "/", "landmark_size", ")", "\n", "for", "x_pos", "in", "[", "-", "edge", ",", "edge", "]", ":", "\n", "            ", "for", "i", "in", "range", "(", "num_landmarks", ")", ":", "\n", "                ", "l", "=", "Landmark", "(", ")", "\n", "l", ".", "state", ".", "p_pos", "=", "np", ".", "array", "(", "[", "x_pos", ",", "-", "1", "+", "i", "*", "landmark_size", "]", ")", "\n", "boundary_list", ".", "append", "(", "l", ")", "\n", "\n", "", "", "for", "y_pos", "in", "[", "-", "edge", ",", "edge", "]", ":", "\n", "            ", "for", "i", "in", "range", "(", "num_landmarks", ")", ":", "\n", "                ", "l", "=", "Landmark", "(", ")", "\n", "l", ".", "state", ".", "p_pos", "=", "np", ".", "array", "(", "[", "-", "1", "+", "i", "*", "landmark_size", ",", "y_pos", "]", ")", "\n", "boundary_list", ".", "append", "(", "l", ")", "\n", "\n", "", "", "for", "i", ",", "l", "in", "enumerate", "(", "boundary_list", ")", ":", "\n", "            ", "l", ".", "name", "=", "'boundary %d'", "%", "i", "\n", "l", ".", "collide", "=", "True", "\n", "l", ".", "movable", "=", "False", "\n", "l", ".", "boundary", "=", "True", "\n", "l", ".", "color", "=", "np", ".", "array", "(", "[", "0.75", ",", "0.75", ",", "0.75", "]", ")", "\n", "l", ".", "size", "=", "landmark_size", "\n", "l", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n", "", "return", "boundary_list", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.reset_world": [[88, 114], ["enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.45", ",", "0.95", ",", "0.45", "]", ")", "if", "not", "agent", ".", "adversary", "else", "np", ".", "array", "(", "[", "0.95", ",", "0.45", ",", "0.45", "]", ")", "\n", "agent", ".", "color", "-=", "np", ".", "array", "(", "[", "0.3", ",", "0.3", ",", "0.3", "]", ")", "if", "agent", ".", "leader", "else", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.65", "]", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "forests", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.6", ",", "0.9", ",", "0.6", "]", ")", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.9", ",", "+", "0.9", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "food", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.9", ",", "+", "0.9", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "forests", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.9", ",", "+", "0.9", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.benchmark_data": [[115, 124], ["simple_world_comm.Scenario.good_agents", "simple_world_comm.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.good_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "if", "agent", ".", "adversary", ":", "\n", "            ", "collisions", "=", "0", "\n", "for", "a", "in", "self", ".", "good_agents", "(", "world", ")", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "return", "collisions", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.is_collision": [[126, 131], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.good_agents": [[134, 136], ["None"], "methods", ["None"], ["", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.adversaries": [[138, 140], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.reward": [[142, 147], ["simple_world_comm.Scenario.adversary_reward", "simple_world_comm.Scenario.agent_reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversary_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.agent_reward"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "#boundary_reward = -10 if self.outside_boundary(agent) else 0", "\n", "        ", "main_reward", "=", "self", ".", "adversary_reward", "(", "agent", ",", "world", ")", "if", "agent", ".", "adversary", "else", "self", ".", "agent_reward", "(", "agent", ",", "world", ")", "\n", "return", "main_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.outside_boundary": [[148, 153], ["None"], "methods", ["None"], ["", "def", "outside_boundary", "(", "self", ",", "agent", ")", ":", "\n", "        ", "if", "agent", ".", "state", ".", "p_pos", "[", "0", "]", ">", "1", "or", "agent", ".", "state", ".", "p_pos", "[", "0", "]", "<", "-", "1", "or", "agent", ".", "state", ".", "p_pos", "[", "1", "]", ">", "1", "or", "agent", ".", "state", ".", "p_pos", "[", "1", "]", "<", "-", "1", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.agent_reward": [[155, 184], ["simple_world_comm.Scenario.adversaries", "range", "min", "abs", "simple_world_comm.Scenario.is_collision", "min", "simple_world_comm.Scenario.is_collision", "numpy.exp", "simple_world_comm.Scenario.agent_reward.bound"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversaries", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "", "def", "agent_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "        ", "rew", "=", "0", "\n", "shape", "=", "False", "\n", "adversaries", "=", "self", ".", "adversaries", "(", "world", ")", "\n", "if", "shape", ":", "\n", "            ", "for", "adv", "in", "adversaries", ":", "\n", "                ", "rew", "+=", "0.1", "*", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "adv", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "adversaries", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "5", "\n", "", "", "", "def", "bound", "(", "x", ")", ":", "\n", "            ", "if", "x", "<", "0.9", ":", "\n", "                ", "return", "0", "\n", "", "if", "x", "<", "1.0", ":", "\n", "                ", "return", "(", "x", "-", "0.9", ")", "*", "10", "\n", "", "return", "min", "(", "np", ".", "exp", "(", "2", "*", "x", "-", "2", ")", ",", "10", ")", "# 1 + (x - 1) * (x - 1)", "\n", "\n", "", "for", "p", "in", "range", "(", "world", ".", "dim_p", ")", ":", "\n", "            ", "x", "=", "abs", "(", "agent", ".", "state", ".", "p_pos", "[", "p", "]", ")", "\n", "rew", "-=", "2", "*", "bound", "(", "x", ")", "\n", "\n", "", "for", "food", "in", "world", ".", "food", ":", "\n", "            ", "if", "self", ".", "is_collision", "(", "agent", ",", "food", ")", ":", "\n", "                ", "rew", "+=", "2", "\n", "", "", "rew", "+=", "0.05", "*", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "food", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "food", "in", "world", ".", "food", "]", ")", "\n", "\n", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.adversary_reward": [[185, 199], ["simple_world_comm.Scenario.good_agents", "simple_world_comm.Scenario.adversaries", "min", "simple_world_comm.Scenario.is_collision", "numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.good_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversaries", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "adversary_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "        ", "rew", "=", "0", "\n", "shape", "=", "True", "\n", "agents", "=", "self", ".", "good_agents", "(", "world", ")", "\n", "adversaries", "=", "self", ".", "adversaries", "(", "world", ")", "\n", "if", "shape", ":", "\n", "            ", "rew", "-=", "0.1", "*", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "agents", "]", ")", "\n", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "ag", "in", "agents", ":", "\n", "                ", "for", "adv", "in", "adversaries", ":", "\n", "                    ", "if", "self", ".", "is_collision", "(", "ag", ",", "adv", ")", ":", "\n", "                        ", "rew", "+=", "5", "\n", "", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.observation2": [[201, 223], ["numpy.concatenate", "comm.append", "other_pos.append", "entity_pos.append", "food_pos.append", "other_vel.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation2", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "if", "not", "entity", ".", "boundary", ":", "\n", "                ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "", "", "food_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "food", ":", "\n", "            ", "if", "not", "entity", ".", "boundary", ":", "\n", "                ", "food_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# communication of all other agents", "\n", "", "", "comm", "=", "[", "]", "\n", "other_pos", "=", "[", "]", "\n", "other_vel", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "if", "not", "other", ".", "adversary", ":", "\n", "                ", "other_vel", ".", "append", "(", "other", ".", "state", ".", "p_vel", ")", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_world_comm.Scenario.observation": [[224, 288], ["simple_world_comm.Scenario.is_collision", "simple_world_comm.Scenario.is_collision", "simple_world_comm.Scenario.good_agents", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "comm.append", "simple_world_comm.Scenario.is_collision", "simple_world_comm.Scenario.is_collision", "any", "any", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "entity_pos.append", "food_pos.append", "other_pos.append", "other_pos.append", "prey_forest.append", "prey_forest.append", "prey_forest_lead.append", "prey_forest_lead.append", "other_vel.append", "other_vel.append", "simple_world_comm.Scenario.is_collision", "numpy.array", "numpy.array", "simple_world_comm.Scenario.is_collision", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.good_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "if", "not", "entity", ".", "boundary", ":", "\n", "                ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "", "", "in_forest", "=", "[", "np", ".", "array", "(", "[", "-", "1", "]", ")", ",", "np", ".", "array", "(", "[", "-", "1", "]", ")", "]", "\n", "inf1", "=", "False", "\n", "inf2", "=", "False", "\n", "if", "self", ".", "is_collision", "(", "agent", ",", "world", ".", "forests", "[", "0", "]", ")", ":", "\n", "            ", "in_forest", "[", "0", "]", "=", "np", ".", "array", "(", "[", "1", "]", ")", "\n", "inf1", "=", "True", "\n", "", "if", "self", ".", "is_collision", "(", "agent", ",", "world", ".", "forests", "[", "1", "]", ")", ":", "\n", "            ", "in_forest", "[", "1", "]", "=", "np", ".", "array", "(", "[", "1", "]", ")", "\n", "inf2", "=", "True", "\n", "\n", "", "food_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "food", ":", "\n", "            ", "if", "not", "entity", ".", "boundary", ":", "\n", "                ", "food_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# communication of all other agents", "\n", "", "", "comm", "=", "[", "]", "\n", "other_pos", "=", "[", "]", "\n", "other_vel", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "oth_f1", "=", "self", ".", "is_collision", "(", "other", ",", "world", ".", "forests", "[", "0", "]", ")", "\n", "oth_f2", "=", "self", ".", "is_collision", "(", "other", ",", "world", ".", "forests", "[", "1", "]", ")", "\n", "if", "(", "inf1", "and", "oth_f1", ")", "or", "(", "inf2", "and", "oth_f2", ")", "or", "(", "not", "inf1", "and", "not", "oth_f1", "and", "not", "inf2", "and", "not", "oth_f2", ")", "or", "agent", ".", "leader", ":", "#without forest vis", "\n", "                ", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "if", "not", "other", ".", "adversary", ":", "\n", "                    ", "other_vel", ".", "append", "(", "other", ".", "state", ".", "p_vel", ")", "\n", "", "", "else", ":", "\n", "                ", "other_pos", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "if", "not", "other", ".", "adversary", ":", "\n", "                    ", "other_vel", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "\n", "# to tell the pred when the prey are in the forest", "\n", "", "", "", "prey_forest", "=", "[", "]", "\n", "ga", "=", "self", ".", "good_agents", "(", "world", ")", "\n", "for", "a", "in", "ga", ":", "\n", "            ", "if", "any", "(", "[", "self", ".", "is_collision", "(", "a", ",", "f", ")", "for", "f", "in", "world", ".", "forests", "]", ")", ":", "\n", "                ", "prey_forest", ".", "append", "(", "np", ".", "array", "(", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "prey_forest", ".", "append", "(", "np", ".", "array", "(", "[", "-", "1", "]", ")", ")", "\n", "# to tell leader when pred are in forest", "\n", "", "", "prey_forest_lead", "=", "[", "]", "\n", "for", "f", "in", "world", ".", "forests", ":", "\n", "            ", "if", "any", "(", "[", "self", ".", "is_collision", "(", "a", ",", "f", ")", "for", "a", "in", "ga", "]", ")", ":", "\n", "                ", "prey_forest_lead", ".", "append", "(", "np", ".", "array", "(", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "prey_forest_lead", ".", "append", "(", "np", ".", "array", "(", "[", "-", "1", "]", ")", ")", "\n", "\n", "", "", "comm", "=", "[", "world", ".", "agents", "[", "0", "]", ".", "state", ".", "c", "]", "\n", "\n", "if", "agent", ".", "adversary", "and", "not", "agent", ".", "leader", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "in_forest", "+", "comm", ")", "\n", "", "if", "agent", ".", "leader", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "\n", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", "+", "in_forest", "+", "comm", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", "+", "in_forest", "+", "other_vel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.make_world": [[16, 53], ["cars.road_world.RoadWorld", "cars.road_world.RoadWorld.set_agents", "enumerate", "enumerate", "cars.road_world.RoadWorld.reset", "simple_car.Scenario.reset_world", "cars.car_dynamics.Car", "multiagent.core.Surface", "multiagent.dynamic_agent.DynamicAgent", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.set_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "RoadWorld", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_p", "=", "2", "# x, y, orientation, speed", "\n", "world", ".", "collaborative", "=", "True", "\n", "\n", "# add agents", "\n", "num_agents", "=", "2", "\n", "world", ".", "set_agents", "(", "[", "DynamicAgent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", ")", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'dynamic agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "color", "=", "colors", "[", "i", "]", "\n", "agent", ".", "body", "=", "Car", "(", "world", ".", "box2d", ")", "\n", "agent", ".", "scale", "=", "SCALE", "\n", "\n", "agent", ".", "shape", "=", "[", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY1", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY2", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY3", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY4", "]", "]", "\n", "agent", ".", "size", "=", "SIZE", "\n", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "max_speed", "=", ".1", "\n", "world", ".", "agents", "[", "1", "]", ".", "max_speed", "=", ".15", "\n", "\n", "world", ".", "surfaces", "=", "[", "Surface", "(", ")", "for", "i", "in", "range", "(", "1", ")", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "s", ".", "name", "=", "'surface %d'", "%", "i", "\n", "s", ".", "collide", "=", "False", "\n", "s", ".", "movable", "=", "False", "\n", "\n", "# make initial conditions", "\n", "", "world", ".", "num_lanes", "=", "1", "\n", "world", ".", "reset", "(", ")", "\n", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.reset_world": [[54, 74], ["numpy.array", "numpy.random.choice", "enumerate", "enumerate", "numpy.array", "len", "numpy.zeros", "agent.body.make", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.array", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "coord", "=", "np", ".", "array", "(", "world", ".", "track", ")", "[", ":", ",", "2", ":", "4", "]", "\n", "norm_coord", "=", "np", ".", "array", "(", "[", "(", "c", "[", "0", "]", "/", "SCALE", ",", "c", "[", "1", "]", "/", "SCALE", ")", "for", "c", "in", "coord", "]", ")", "\n", "\n", "# all agents start somewhere", "\n", "start_i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "coord", ")", ")", "\n", "dist", "=", "5", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "idx", "=", "(", "start_i", "-", "i", "*", "dist", ")", "%", "len", "(", "coord", ")", "\n", "agent", ".", "state", ".", "p_pos", "=", "norm_coord", "[", "idx", "]", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "angle", "=", "world", ".", "track", "[", "idx", "]", "[", "1", "]", "\n", "agent", ".", "body", ".", "make", "(", "*", "world", ".", "track", "[", "idx", "]", "[", "1", ":", "4", "]", ")", "# TODO: set x, y", "\n", "\n", "# pure for visualizing the track", "\n", "", "for", "i", ",", "surface", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "surface", ".", "color", "=", "np", ".", "array", "(", "[", "color", "for", "poly", ",", "color", ",", "id", ",", "lane", "in", "world", ".", "road_poly", "if", "lane", "==", "i", "]", ")", "\n", "surface", ".", "state", ".", "p_pos", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "poly", "=", "np", ".", "array", "(", "[", "[", "(", "c_i", "[", "0", "]", "/", "SCALE", ",", "c_i", "[", "1", "]", "/", "SCALE", ")", "for", "c_i", "in", "poly", "]", "for", "poly", ",", "color", ",", "id", ",", "lane", "in", "world", ".", "road_poly", "if", "lane", "==", "i", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.is_collision": [[75, 80], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.reward": [[81, 94], ["numpy.sum", "zip", "view.transpose", "abs", "simple_car.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "rew", "=", "0.", "\n", "for", "view", "in", "world", ".", "top_views", ":", "\n", "            ", "for", "road_color", ",", "road_patch", "in", "zip", "(", "ROAD_COLOR", ",", "view", ".", "transpose", "(", "2", ",", "1", ",", "0", ")", ")", ":", "\n", "                ", "rew", "-=", "abs", "(", "road_color", "-", "road_patch", "/", "255.", ")", "\n", "", "", "c", ",", "w", ",", "h", "=", "view", ".", "shape", "\n", "rew", "/=", "(", "c", "*", "w", "*", "h", ")", "\n", "rew", "=", "np", ".", "sum", "(", "rew", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "world", ".", "agents", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.rgb2gray": [[95, 103], ["numpy.dot"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rgb2gray", "(", "rgb", ",", "norm", "=", "True", ")", ":", "\n", "# rgb image -> gray [0, 1]", "\n", "        ", "gray", "=", "np", ".", "dot", "(", "rgb", "[", "...", ",", ":", "]", ",", "[", "0.299", ",", "0.587", ",", "0.114", "]", ")", "\n", "if", "norm", ":", "\n", "# normalize", "\n", "            ", "gray", "=", "gray", "/", "128.", "-", "1.", "\n", "", "return", "gray", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.observation": [[104, 118], ["enumerate", "numpy.array", "simple_car.Scenario.rgb2gray", "numpy.concatenate", "numpy.hstack", "other_pos.append", "numpy.cos", "numpy.sin", "simple_car.Scenario.reshape", "world.get_views"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.rgb2gray", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "other_pos", "=", "[", "]", "\n", "view", "=", "None", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "==", "agent", ":", "\n", "                ", "view", "=", "world", ".", "get_views", "(", ")", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "", "", "dir", "=", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "agent", ".", "state", ".", "angle", ")", ",", "np", ".", "sin", "(", "agent", ".", "state", ".", "angle", ")", "]", ")", "\n", "view", "=", "self", ".", "rgb2gray", "(", "view", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "dir", "]", "+", "other_pos", ")", "\n", "return", "np", ".", "hstack", "(", "(", "obs", ",", "view", ".", "reshape", "(", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.done": [[119, 121], ["None"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car.Scenario.benchmark_data": [[122, 124], ["simple_car.Scenario.reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_push.Scenario.make_world": [[6, 32], ["multiagent.core.World", "enumerate", "enumerate", "simple_push.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_agents", "=", "2", "\n", "num_adversaries", "=", "1", "\n", "num_landmarks", "=", "2", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "if", "i", "<", "num_adversaries", ":", "\n", "                ", "agent", ".", "adversary", "=", "True", "\n", "", "else", ":", "\n", "                ", "agent", ".", "adversary", "=", "False", "\n", "# add landmarks", "\n", "", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_push.Scenario.reset_world": [[33, 57], ["enumerate", "numpy.random.choice", "enumerate", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros", "numpy.array"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for landmarks", "\n", "        ", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.1", ",", "0.1", ",", "0.1", "]", ")", "\n", "landmark", ".", "color", "[", "i", "+", "1", "]", "+=", "0.8", "\n", "landmark", ".", "index", "=", "i", "\n", "# set goal landmark", "\n", "", "goal", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "goal_a", "=", "goal", "\n", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "if", "agent", ".", "adversary", ":", "\n", "                ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.75", ",", "0.25", ",", "0.25", "]", ")", "\n", "", "else", ":", "\n", "                ", "j", "=", "goal", ".", "index", "\n", "agent", ".", "color", "[", "j", "+", "1", "]", "+=", "0.5", "\n", "# set random initial states", "\n", "", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_push.Scenario.reward": [[58, 61], ["simple_push.Scenario.adversary_reward", "simple_push.Scenario.agent_reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversary_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.agent_reward"], ["", "", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "        ", "return", "self", ".", "adversary_reward", "(", "agent", ",", "world", ")", "if", "agent", ".", "adversary", "else", "self", ".", "agent_reward", "(", "agent", ",", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_push.Scenario.agent_reward": [[62, 65], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "agent_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# the distance to the goal", "\n", "        ", "return", "-", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "agent", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_push.Scenario.adversary_reward": [[66, 75], ["min", "numpy.sqrt", "numpy.sqrt", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "adversary_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# keep the nearest good agents away from the goal", "\n", "        ", "agent_dist", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "world", ".", "agents", "if", "not", "a", ".", "adversary", "]", "\n", "pos_rew", "=", "min", "(", "agent_dist", ")", "\n", "#nearest_agent = world.good_agents[np.argmin(agent_dist)]", "\n", "#neg_rew = np.sqrt(np.sum(np.square(nearest_agent.state.p_pos - agent.state.p_pos)))", "\n", "neg_rew", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "#neg_rew = sum([np.sqrt(np.sum(np.square(a.state.p_pos - agent.state.p_pos))) for a in world.good_agents])", "\n", "return", "pos_rew", "-", "neg_rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_push.Scenario.observation": [[76, 97], ["entity_pos.append", "entity_color.append", "comm.append", "other_pos.append", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "# world.entities:", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# entity colors", "\n", "", "entity_color", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "# world.entities:", "\n", "            ", "entity_color", ".", "append", "(", "entity", ".", "color", ")", "\n", "# communication of all other agents", "\n", "", "comm", "=", "[", "]", "\n", "other_pos", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "if", "not", "agent", ".", "adversary", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "agent", ".", "color", "]", "+", "entity_pos", "+", "entity_color", "+", "other_pos", ")", "\n", "", "else", ":", "\n", "#other_pos = list(reversed(other_pos)) if random.uniform(0,1) > 0.5 else other_pos  # randomize position of other agents in adversary network", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "entity_pos", "+", "other_pos", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.make_world": [[17, 62], ["cars.road_world.RoadWorld", "cars.road_world.RoadWorld.set_agents", "enumerate", "enumerate", "enumerate", "simple_car2.Scenario.reset_world", "cars.car_dynamics.Car", "multiagent.core.Surface", "multiagent.core.Landmark", "numpy.array", "multiagent.dynamic_agent.DynamicAgent", "range", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.set_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "RoadWorld", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_p", "=", "2", "# x, y, orientation, speed", "\n", "num_obstacles", "=", "3", "\n", "world", ".", "collaborative", "=", "True", "\n", "\n", "# add agents", "\n", "num_agents", "=", "2", "\n", "world", ".", "set_agents", "(", "[", "DynamicAgent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", ")", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'dynamic agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "color", "=", "colors", "[", "i", "]", "\n", "agent", ".", "body", "=", "Car", "(", "world", ".", "box2d", ")", "\n", "agent", ".", "scale", "=", "SCALE", "\n", "\n", "agent", ".", "shape", "=", "[", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY1", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY2", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY3", "]", ",", "\n", "[", "(", "x", "*", "SIZE", "/", "SCALE", ",", "y", "*", "SIZE", "/", "SCALE", ")", "for", "x", ",", "y", "in", "HULL_POLY4", "]", "]", "\n", "agent", ".", "size", "=", "SIZE", "\n", "\n", "", "world", ".", "agents", "[", "0", "]", ".", "max_speed", "=", ".1", "\n", "world", ".", "agents", "[", "1", "]", ".", "max_speed", "=", ".15", "\n", "\n", "world", ".", "surfaces", "=", "[", "Surface", "(", ")", "for", "i", "in", "range", "(", "1", ")", "]", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "s", ".", "name", "=", "'surface %d'", "%", "i", "\n", "s", ".", "collide", "=", "False", "\n", "s", ".", "movable", "=", "False", "\n", "\n", "# add obstacles", "\n", "", "world", ".", "obstacles", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_obstacles", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'obstacle %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "True", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.01", "\n", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.255", ",", "0.165", ",", "0.0", "]", ")", "\n", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.reset_world": [[63, 91], ["world.reset", "numpy.array", "numpy.random.choice", "enumerate", "enumerate", "enumerate", "numpy.array", "len", "numpy.zeros", "agent.body.make", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.array", "numpy.mean", "numpy.zeros", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "        ", "world", ".", "reset", "(", ")", "\n", "coord", "=", "np", ".", "array", "(", "world", ".", "track", ")", "[", ":", ",", "2", ":", "4", "]", "\n", "norm_coord", "=", "np", ".", "array", "(", "[", "(", "c", "[", "0", "]", "/", "SCALE", ",", "c", "[", "1", "]", "/", "SCALE", ")", "for", "c", "in", "coord", "]", ")", "\n", "\n", "# all agents start somewhere", "\n", "start_i", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "coord", ")", ")", "\n", "dist", "=", "5", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "idx", "=", "(", "start_i", "-", "i", "*", "dist", ")", "%", "len", "(", "coord", ")", "\n", "agent", ".", "state", ".", "p_pos", "=", "norm_coord", "[", "idx", "]", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "angle", "=", "world", ".", "track", "[", "idx", "]", "[", "1", "]", "\n", "agent", ".", "body", ".", "make", "(", "*", "world", ".", "track", "[", "idx", "]", "[", "1", ":", "4", "]", ")", "# TODO: set x, y", "\n", "\n", "# pure for visualizing the track", "\n", "", "for", "i", ",", "surface", "in", "enumerate", "(", "world", ".", "surfaces", ")", ":", "\n", "            ", "surface", ".", "color", "=", "np", ".", "array", "(", "[", "color", "for", "(", "_", ",", "color", ")", "in", "world", ".", "road_poly", "]", ")", "\n", "surface", ".", "state", ".", "p_pos", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "surface", ".", "poly", "=", "np", ".", "array", "(", "[", "[", "(", "c_i", "[", "0", "]", "/", "SCALE", ",", "c_i", "[", "1", "]", "/", "SCALE", ")", "for", "c_i", "in", "coordinates", "]", "for", "(", "coordinates", ",", "_", ")", "in", "world", ".", "road_poly", "]", ")", "\n", "surface", ".", "v", "=", "np", ".", "mean", "(", "surface", ".", "poly", "[", ":", ",", "0", ":", "2", "]", ",", "axis", "=", "1", ")", "\n", "\n", "# reset obstacle position", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "obstacles", ")", ":", "\n", "            ", "idx", "=", "(", "start_i", "+", "(", "i", "+", "1", ")", "*", "dist", ")", "%", "len", "(", "coord", ")", "\n", "landmark", ".", "state", ".", "p_pos", "=", "norm_coord", "[", "idx", "]", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.is_collision": [[92, 97], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.reward": [[98, 114], ["numpy.sum", "zip", "view.transpose", "abs", "simple_car2.Scenario.is_collision", "simple_car2.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "rew", "=", "0.", "\n", "for", "view", "in", "world", ".", "top_views", ":", "\n", "            ", "for", "road_color", ",", "road_patch", "in", "zip", "(", "ROAD_COLOR", ",", "view", ".", "transpose", "(", "2", ",", "1", ",", "0", ")", ")", ":", "\n", "                ", "rew", "-=", "abs", "(", "road_color", "-", "road_patch", "/", "255.", ")", "\n", "", "", "c", ",", "w", ",", "h", "=", "view", ".", "shape", "\n", "rew", "/=", "(", "c", "*", "w", "*", "h", ")", "\n", "rew", "=", "np", ".", "sum", "(", "rew", ")", "\n", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "world", ".", "agents", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "for", "obstacle", "in", "world", ".", "obstacles", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "obstacle", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.rgb2gray": [[115, 123], ["numpy.dot"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rgb2gray", "(", "rgb", ",", "norm", "=", "True", ")", ":", "\n", "# rgb image -> gray [0, 1]", "\n", "        ", "gray", "=", "np", ".", "dot", "(", "rgb", "[", "...", ",", ":", "]", ",", "[", "0.299", ",", "0.587", ",", "0.114", "]", ")", "\n", "if", "norm", ":", "\n", "# normalize", "\n", "            ", "gray", "=", "gray", "/", "128.", "-", "1.", "\n", "", "return", "gray", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.observation": [[124, 143], ["enumerate", "numpy.array", "simple_car2.Scenario.rgb2gray", "numpy.concatenate", "numpy.hstack", "entity_pos.append", "other_pos.append", "numpy.cos", "numpy.sin", "simple_car2.Scenario.reshape", "world.get_views"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.rgb2gray", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "other_pos", "=", "[", "]", "\n", "view", "=", "None", "\n", "for", "i", ",", "other", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "if", "other", "==", "agent", ":", "\n", "                ", "view", "=", "world", ".", "get_views", "(", ")", "[", "i", "]", "\n", "", "else", ":", "\n", "                ", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "# get positions of all entities in this agent's reference frame", "\n", "", "", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "obstacles", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "", "dir", "=", "np", ".", "array", "(", "[", "np", ".", "cos", "(", "agent", ".", "state", ".", "angle", ")", ",", "np", ".", "sin", "(", "agent", ".", "state", ".", "angle", ")", "]", ")", "\n", "view", "=", "self", ".", "rgb2gray", "(", "view", ")", "\n", "obs", "=", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "[", "dir", "]", "+", "other_pos", "+", "entity_pos", ")", "\n", "return", "np", ".", "hstack", "(", "(", "obs", ",", "view", ".", "reshape", "(", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.done": [[144, 146], ["None"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_car2.Scenario.benchmark_data": [[147, 149], ["simple_car2.Scenario.reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward"], ["", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_spread.Scenario.make_world": [[11, 34], ["multiagent.core.World", "enumerate", "enumerate", "simple_spread.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_agents", "=", "3", "\n", "num_landmarks", "=", "3", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "size", "=", "0.15", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_spread.Scenario.reset_world": [[35, 50], ["enumerate", "enumerate", "enumerate", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "colors", "[", "i", "]", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_spread.Scenario.benchmark_data": [[51, 65], ["min", "simple_spread.Scenario.reward", "numpy.sqrt", "min", "simple_spread.Scenario.is_collision", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "collisions", "=", "0", "\n", "occupied_landmarks", "=", "0", "\n", "min_dists", "=", "0", "\n", "for", "l", "in", "world", ".", "landmarks", ":", "\n", "            ", "dists", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "world", ".", "agents", "]", "\n", "min_dists", "+=", "min", "(", "dists", ")", "\n", "if", "min", "(", "dists", ")", "<", "0.1", ":", "\n", "                ", "occupied_landmarks", "+=", "1", "\n", "", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "world", ".", "agents", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "collisions", ",", "min_dists", ",", "occupied_landmarks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_spread.Scenario.is_collision": [[67, 72], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_spread.Scenario.reward": [[73, 84], ["min", "numpy.sqrt", "simple_spread.Scenario.is_collision", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark, penalized for collisions", "\n", "        ", "rew", "=", "0", "\n", "for", "l", "in", "world", ".", "landmarks", ":", "\n", "            ", "dists", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "world", ".", "agents", "]", "\n", "rew", "-=", "min", "(", "dists", ")", "\n", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "world", ".", "agents", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_spread.Scenario.observation": [[85, 102], ["numpy.concatenate", "entity_pos.append", "entity_color.append", "comm.append", "other_pos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "# world.entities:", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# entity colors", "\n", "", "entity_color", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "# world.entities:", "\n", "            ", "entity_color", ".", "append", "(", "entity", ".", "color", ")", "\n", "# communication of all other agents", "\n", "", "comm", "=", "[", "]", "\n", "other_pos", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", "+", "comm", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.make_world": [[7, 37], ["multiagent.core.World", "enumerate", "enumerate", "simple_tag.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_good_agents", "=", "1", "\n", "num_adversaries", "=", "3", "\n", "num_agents", "=", "num_adversaries", "+", "num_good_agents", "\n", "num_landmarks", "=", "2", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "size", "=", "0.075", "if", "agent", ".", "adversary", "else", "0.05", "\n", "agent", ".", "accel", "=", "3.0", "if", "agent", ".", "adversary", "else", "4.0", "\n", "#agent.accel = 20.0 if agent.adversary else 25.0", "\n", "agent", ".", "max_speed", "=", "1.0", "if", "agent", ".", "adversary", "else", "1.3", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "True", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.2", "\n", "landmark", ".", "boundary", "=", "False", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.reset_world": [[39, 55], ["enumerate", "enumerate", "enumerate", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.85", ",", "0.35", "]", ")", "if", "not", "agent", ".", "adversary", "else", "np", ".", "array", "(", "[", "0.85", ",", "0.35", ",", "0.35", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "if", "not", "landmark", ".", "boundary", ":", "\n", "                ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "0.9", ",", "+", "0.9", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.benchmark_data": [[57, 67], ["simple_tag.Scenario.good_agents", "simple_tag.Scenario.is_collision"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.good_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision"], ["", "", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "if", "agent", ".", "adversary", ":", "\n", "            ", "collisions", "=", "0", "\n", "for", "a", "in", "self", ".", "good_agents", "(", "world", ")", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "return", "collisions", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.is_collision": [[69, 74], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.good_agents": [[76, 78], ["None"], "methods", ["None"], ["", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.adversaries": [[80, 82], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.reward": [[84, 88], ["simple_tag.Scenario.adversary_reward", "simple_tag.Scenario.agent_reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversary_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.agent_reward"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "        ", "main_reward", "=", "self", ".", "adversary_reward", "(", "agent", ",", "world", ")", "if", "agent", ".", "adversary", "else", "self", ".", "agent_reward", "(", "agent", ",", "world", ")", "\n", "return", "main_reward", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.agent_reward": [[89, 114], ["simple_tag.Scenario.adversaries", "range", "min", "abs", "simple_tag.Scenario.agent_reward.bound"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversaries", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["", "def", "agent_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are negatively rewarded if caught by adversaries", "\n", "        ", "rew", "=", "0", "\n", "shape", "=", "False", "\n", "adversaries", "=", "self", ".", "adversaries", "(", "world", ")", "\n", "if", "shape", ":", "# reward can optionally be shaped (increased reward for increased distance from adversary)", "\n", "            ", "for", "adv", "in", "adversaries", ":", "\n", "                ", "rew", "+=", "0.1", "*", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "adv", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "adversaries", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "10", "\n", "\n", "# agents are penalized for exiting the screen, so that they can be caught by the adversaries", "\n", "", "", "", "def", "bound", "(", "x", ")", ":", "\n", "            ", "if", "x", "<", "0.9", ":", "\n", "                ", "return", "0", "\n", "", "if", "x", "<", "1.0", ":", "\n", "                ", "return", "(", "x", "-", "0.9", ")", "*", "10", "\n", "", "return", "min", "(", "np", ".", "exp", "(", "2", "*", "x", "-", "2", ")", ",", "10", ")", "\n", "", "for", "p", "in", "range", "(", "world", ".", "dim_p", ")", ":", "\n", "            ", "x", "=", "abs", "(", "agent", ".", "state", ".", "p_pos", "[", "p", "]", ")", "\n", "rew", "-=", "bound", "(", "x", ")", "\n", "\n", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.adversary_reward": [[115, 130], ["simple_tag.Scenario.good_agents", "simple_tag.Scenario.adversaries", "min", "simple_tag.Scenario.is_collision", "numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.good_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversaries", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "adversary_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Adversaries are rewarded for collisions with agents", "\n", "        ", "rew", "=", "0", "\n", "shape", "=", "False", "\n", "agents", "=", "self", ".", "good_agents", "(", "world", ")", "\n", "adversaries", "=", "self", ".", "adversaries", "(", "world", ")", "\n", "if", "shape", ":", "# reward can optionally be shaped (decreased reward for increased distance from agents)", "\n", "            ", "for", "adv", "in", "adversaries", ":", "\n", "                ", "rew", "-=", "0.1", "*", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "adv", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "agents", "]", ")", "\n", "", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "ag", "in", "agents", ":", "\n", "                ", "for", "adv", "in", "adversaries", ":", "\n", "                    ", "if", "self", ".", "is_collision", "(", "ag", ",", "adv", ")", ":", "\n", "                        ", "rew", "+=", "10", "\n", "", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_tag.Scenario.observation": [[131, 148], ["numpy.concatenate", "comm.append", "other_pos.append", "entity_pos.append", "other_vel.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "if", "not", "entity", ".", "boundary", ":", "\n", "                ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# communication of all other agents", "\n", "", "", "comm", "=", "[", "]", "\n", "other_pos", "=", "[", "]", "\n", "other_vel", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "if", "not", "other", ".", "adversary", ":", "\n", "                ", "other_vel", ".", "append", "(", "other", ".", "state", ".", "p_vel", ")", "\n", "", "", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", "+", "other_vel", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.__init__.load": [[5, 8], ["os.join", "imp.load_source", "os.dirname"], "function", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.make_world": [[8, 34], ["multiagent.core.World", "enumerate", "enumerate", "simple_adversary.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_agents", "=", "3", "\n", "world", ".", "num_agents", "=", "num_agents", "\n", "num_adversaries", "=", "1", "\n", "num_landmarks", "=", "num_agents", "-", "1", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "False", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "adversary", "=", "True", "if", "i", "<", "num_adversaries", "else", "False", "\n", "agent", ".", "size", "=", "0.15", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "landmark", ".", "size", "=", "0.08", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.reset_world": [[35, 56], ["numpy.array", "range", "enumerate", "numpy.random.choice", "numpy.array", "enumerate", "numpy.array", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "world", ".", "agents", "[", "0", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.85", ",", "0.35", ",", "0.35", "]", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "world", ".", "num_agents", ")", ":", "\n", "            ", "world", ".", "agents", "[", "i", "]", ".", "color", "=", "np", ".", "array", "(", "[", "0.35", ",", "0.35", ",", "0.85", "]", ")", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.15", ",", "0.15", "]", ")", "\n", "# set goal landmark", "\n", "", "goal", "=", "np", ".", "random", ".", "choice", "(", "world", ".", "landmarks", ")", "\n", "goal", ".", "color", "=", "np", ".", "array", "(", "[", "0.15", ",", "0.65", ",", "0.15", "]", ")", "\n", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "goal_a", "=", "goal", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.benchmark_data": [[57, 67], ["numpy.sum", "dists.append", "tuple", "numpy.square", "dists.append", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# returns data for benchmarking purposes", "\n", "        ", "if", "agent", ".", "adversary", ":", "\n", "            ", "return", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "agent", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", "\n", "", "else", ":", "\n", "            ", "dists", "=", "[", "]", "\n", "for", "l", "in", "world", ".", "landmarks", ":", "\n", "                ", "dists", ".", "append", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "", "dists", ".", "append", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "agent", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "\n", "return", "tuple", "(", "dists", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.good_agents": [[69, 71], ["None"], "methods", ["None"], ["", "", "def", "good_agents", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "not", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversaries": [[73, 75], ["None"], "methods", ["None"], ["", "def", "adversaries", "(", "self", ",", "world", ")", ":", "\n", "        ", "return", "[", "agent", "for", "agent", "in", "world", ".", "agents", "if", "agent", ".", "adversary", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.reward": [[76, 79], ["simple_adversary.Scenario.adversary_reward", "simple_adversary.Scenario.agent_reward"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversary_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.agent_reward"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark", "\n", "        ", "return", "self", ".", "adversary_reward", "(", "agent", ",", "world", ")", "if", "agent", ".", "adversary", "else", "self", ".", "agent_reward", "(", "agent", ",", "world", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.agent_reward": [[80, 108], ["simple_adversary.Scenario.adversaries", "simple_adversary.Scenario.good_agents", "sum", "min", "min", "min", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sum", "numpy.sum", "numpy.sqrt", "numpy.sqrt", "numpy.sum", "numpy.square", "numpy.square", "numpy.sum", "numpy.sum", "numpy.square", "numpy.square", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversaries", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.good_agents", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "agent_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Rewarded based on how close any good agent is to the goal landmark, and how far the adversary is from it", "\n", "        ", "shaped_reward", "=", "True", "\n", "shaped_adv_reward", "=", "True", "\n", "\n", "# Calculate negative reward for adversary", "\n", "adversary_agents", "=", "self", ".", "adversaries", "(", "world", ")", "\n", "if", "shaped_adv_reward", ":", "# distance-based adversary reward", "\n", "            ", "adv_rew", "=", "sum", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "adversary_agents", "]", ")", "\n", "", "else", ":", "# proximity-based adversary reward (binary)", "\n", "            ", "adv_rew", "=", "0", "\n", "for", "a", "in", "adversary_agents", ":", "\n", "                ", "if", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "<", "2", "*", "a", ".", "goal_a", ".", "size", ":", "\n", "                    ", "adv_rew", "-=", "5", "\n", "\n", "# Calculate positive reward for agents", "\n", "", "", "", "good_agents", "=", "self", ".", "good_agents", "(", "world", ")", "\n", "if", "shaped_reward", ":", "# distance-based agent reward", "\n", "            ", "pos_rew", "=", "-", "min", "(", "\n", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "good_agents", "]", ")", "\n", "", "else", ":", "# proximity-based agent reward (binary)", "\n", "            ", "pos_rew", "=", "0", "\n", "if", "min", "(", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "good_agents", "]", ")", "<", "2", "*", "agent", ".", "goal_a", ".", "size", ":", "\n", "                ", "pos_rew", "+=", "5", "\n", "", "pos_rew", "-=", "min", "(", "\n", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "a", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "good_agents", "]", ")", "\n", "", "return", "pos_rew", "+", "adv_rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.adversary_reward": [[109, 119], ["numpy.sum", "numpy.sqrt", "numpy.square", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "adversary_reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Rewarded based on proximity to the goal landmark", "\n", "        ", "shaped_reward", "=", "True", "\n", "if", "shaped_reward", ":", "# distance-based reward", "\n", "            ", "return", "-", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "agent", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", "\n", "", "else", ":", "# proximity-based reward (binary)", "\n", "            ", "adv_rew", "=", "0", "\n", "if", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "agent", ".", "state", ".", "p_pos", "-", "agent", ".", "goal_a", ".", "state", ".", "p_pos", ")", ")", ")", "<", "2", "*", "agent", ".", "goal_a", ".", "size", ":", "\n", "                ", "adv_rew", "+=", "5", "\n", "", "return", "adv_rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_adversary.Scenario.observation": [[121, 140], ["entity_pos.append", "entity_color.append", "other_pos.append", "numpy.concatenate", "numpy.concatenate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# entity colors", "\n", "", "entity_color", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "\n", "            ", "entity_color", ".", "append", "(", "entity", ".", "color", ")", "\n", "# communication of all other agents", "\n", "", "other_pos", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "\n", "", "if", "not", "agent", ".", "adversary", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "goal_a", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "concatenate", "(", "entity_pos", "+", "other_pos", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.make_world": [[12, 35], ["multiagent.core.World", "enumerate", "enumerate", "simple_order.Scenario.reset_world", "multiagent.core.Agent", "multiagent.core.Landmark", "range", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world"], ["    ", "def", "make_world", "(", "self", ")", ":", "\n", "        ", "world", "=", "World", "(", ")", "\n", "# set any world properties first", "\n", "world", ".", "dim_c", "=", "2", "\n", "num_agents", "=", "3", "\n", "num_landmarks", "=", "3", "\n", "world", ".", "collaborative", "=", "True", "\n", "# add agents", "\n", "world", ".", "agents", "=", "[", "Agent", "(", ")", "for", "i", "in", "range", "(", "num_agents", ")", "]", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "name", "=", "'agent %d'", "%", "i", "\n", "agent", ".", "collide", "=", "True", "\n", "agent", ".", "silent", "=", "True", "\n", "agent", ".", "size", "=", "0.15", "\n", "# add landmarks", "\n", "", "world", ".", "landmarks", "=", "[", "Landmark", "(", ")", "for", "i", "in", "range", "(", "num_landmarks", ")", "]", "\n", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "name", "=", "'landmark %d'", "%", "i", "\n", "landmark", ".", "collide", "=", "False", "\n", "landmark", ".", "movable", "=", "False", "\n", "# make initial conditions", "\n", "", "self", ".", "reset_world", "(", "world", ")", "\n", "return", "world", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reset_world": [[36, 51], ["enumerate", "enumerate", "enumerate", "numpy.array", "numpy.random.uniform", "numpy.zeros", "numpy.zeros", "numpy.random.uniform", "numpy.zeros"], "methods", ["None"], ["", "def", "reset_world", "(", "self", ",", "world", ")", ":", "\n", "# random properties for agents", "\n", "        ", "for", "i", ",", "agent", "in", "enumerate", "(", "world", ".", "agents", ")", ":", "\n", "            ", "agent", ".", "color", "=", "colors", "[", "i", "]", "\n", "# random properties for landmarks", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "color", "=", "np", ".", "array", "(", "[", "0.25", ",", "0.25", ",", "0.25", "]", ")", "\n", "# set random initial states", "\n", "", "for", "agent", "in", "world", ".", "agents", ":", "\n", "            ", "agent", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "agent", ".", "state", ".", "c", "=", "np", ".", "zeros", "(", "world", ".", "dim_c", ")", "\n", "", "for", "i", ",", "landmark", "in", "enumerate", "(", "world", ".", "landmarks", ")", ":", "\n", "            ", "landmark", ".", "state", ".", "p_pos", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "+", "1", ",", "world", ".", "dim_p", ")", "\n", "landmark", ".", "state", ".", "p_vel", "=", "np", ".", "zeros", "(", "world", ".", "dim_p", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.benchmark_data": [[52, 66], ["min", "simple_order.Scenario.reward", "numpy.sqrt", "min", "simple_order.Scenario.is_collision", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "", "def", "benchmark_data", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "collisions", "=", "0", "\n", "occupied_landmarks", "=", "0", "\n", "min_dists", "=", "0", "\n", "for", "l", "in", "world", ".", "landmarks", ":", "\n", "            ", "dists", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "world", ".", "agents", "]", "\n", "min_dists", "+=", "min", "(", "dists", ")", "\n", "if", "min", "(", "dists", ")", "<", "0.1", ":", "\n", "                ", "occupied_landmarks", "+=", "1", "\n", "", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "world", ".", "agents", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "collisions", "+=", "1", "\n", "", "", "", "return", "(", "self", ".", "reward", "(", "agent", ",", "world", ")", ",", "collisions", ",", "min_dists", ",", "occupied_landmarks", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision": [[68, 73], ["numpy.sqrt", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "is_collision", "(", "self", ",", "agent1", ",", "agent2", ")", ":", "\n", "        ", "delta_pos", "=", "agent1", ".", "state", ".", "p_pos", "-", "agent2", ".", "state", ".", "p_pos", "\n", "dist", "=", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "delta_pos", ")", ")", ")", "\n", "dist_min", "=", "agent1", ".", "size", "+", "agent2", ".", "size", "\n", "return", "True", "if", "dist", "<", "dist_min", "else", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.reward": [[74, 85], ["min", "numpy.sqrt", "simple_order.Scenario.is_collision", "numpy.sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.is_collision", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "reward", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# Agents are rewarded based on minimum agent distance to each landmark, penalized for collisions", "\n", "        ", "rew", "=", "0", "\n", "for", "l", "in", "world", ".", "landmarks", ":", "\n", "            ", "dists", "=", "[", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "np", ".", "square", "(", "a", ".", "state", ".", "p_pos", "-", "l", ".", "state", ".", "p_pos", ")", ")", ")", "for", "a", "in", "world", ".", "agents", "]", "\n", "rew", "-=", "min", "(", "dists", ")", "\n", "", "if", "agent", ".", "collide", ":", "\n", "            ", "for", "a", "in", "world", ".", "agents", ":", "\n", "                ", "if", "self", ".", "is_collision", "(", "a", ",", "agent", ")", ":", "\n", "                    ", "rew", "-=", "1", "\n", "", "", "", "return", "rew", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.observation": [[86, 105], ["random.shuffle", "random.shuffle", "numpy.concatenate", "entity_pos.append", "entity_color.append", "comm.append", "other_pos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "observation", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "# get positions of all entities in this agent's reference frame", "\n", "        ", "entity_pos", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "# world.entities:", "\n", "            ", "entity_pos", ".", "append", "(", "entity", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "# entity colors", "\n", "", "entity_color", "=", "[", "]", "\n", "for", "entity", "in", "world", ".", "landmarks", ":", "# world.entities:", "\n", "            ", "entity_color", ".", "append", "(", "entity", ".", "color", ")", "\n", "# communication of all other agents", "\n", "", "comm", "=", "[", "]", "\n", "other_pos", "=", "[", "]", "\n", "for", "other", "in", "world", ".", "agents", ":", "\n", "            ", "if", "other", "is", "agent", ":", "continue", "\n", "comm", ".", "append", "(", "other", ".", "state", ".", "c", ")", "\n", "other_pos", ".", "append", "(", "other", ".", "state", ".", "p_pos", "-", "agent", ".", "state", ".", "p_pos", ")", "\n", "", "random", ".", "shuffle", "(", "other_pos", ")", "\n", "random", ".", "shuffle", "(", "entity_pos", ")", "\n", "return", "np", ".", "concatenate", "(", "[", "agent", ".", "state", ".", "p_vel", "]", "+", "[", "agent", ".", "state", ".", "p_pos", "]", "+", "entity_pos", "+", "other_pos", "+", "comm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.scenarios.simple_order.Scenario.done": [[106, 108], ["None"], "methods", ["None"], ["", "def", "done", "(", "self", ",", "agent", ",", "world", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.info_theory._normalize": [[7, 13], ["sum", "ValueError"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["def", "_normalize", "(", "P", ")", ":", "\n", "    ", "\"\"\" normalize probability distribution \"\"\"", "\n", "s", "=", "sum", "(", "P", ")", "\n", "if", "s", "==", "0.", ":", "\n", "        ", "raise", "ValueError", "(", "\"input distribution has sum zero\"", ")", "\n", "", "return", "P", "/", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.info_theory.blahut_arimoto": [[15, 46], ["numpy.log2", "numpy.exp", "numpy.log2", "info_theory._normalize", "numpy.sum", "numpy.sum", "numpy.sum", "numpy.max", "q_x.reshape", "numpy.log2", "P_yx.sum", "numpy.log2"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.info_theory._normalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "blahut_arimoto", "(", "P_yx", ",", "q_x", ",", "epsilon", "=", "0.001", ",", "deterministic", "=", "False", ",", "iters", "=", "20", ")", ":", "\n", "    ", "\"\"\"\n    Compute the channel capacity C of a channel p(y|x) using the Blahut-Arimoto algorithm. To do\n    this, finds the input distribution p(x) that maximises the mutual information I(X;Y)\n    determined by p(y|x) and p(x).\n\n    P_yx : defines the channel p(y|x)\n    iters : number of iterations\n    \"\"\"", "\n", "P_yx", "=", "P_yx", "+", "eps", "\n", "if", "not", "deterministic", ":", "\n", "        ", "T", "=", "1", "\n", "i", "=", "0", "\n", "while", "T", ">", "epsilon", "and", "i", "<", "iters", ":", "\n", "# update PHI", "\n", "            ", "PHI_yx", "=", "(", "P_yx", "*", "q_x", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "/", "(", "P_yx", "@", "q_x", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "r_x", "=", "np", ".", "exp", "(", "np", ".", "sum", "(", "P_yx", "*", "log2", "(", "PHI_yx", ")", ",", "axis", "=", "0", ")", ")", "\n", "# channel capactiy", "\n", "C", "=", "log2", "(", "np", ".", "sum", "(", "r_x", ")", ")", "\n", "# check convergence", "\n", "T", "=", "np", ".", "max", "(", "log2", "(", "r_x", "/", "q_x", ")", ")", "-", "C", "\n", "# update q", "\n", "q_x", "[", ":", "]", "=", "_normalize", "(", "r_x", "+", "eps", ")", "\n", "i", "+=", "1", "\n", "", "if", "C", "<", "0", ":", "\n", "            ", "C", "=", "0", "\n", "", "return", "C", "\n", "", "else", ":", "\n", "# assume all columns in channel matrix are peaked on a single state", "\n", "# log of number of reachable states", "\n", "        ", "return", "log2", "(", "np", ".", "sum", "(", "P_yx", ".", "sum", "(", "axis", "=", "1", ")", ">", "0.999", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.__init__": [[14, 52], ["len", "utils.agents.DDPGAgent"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "agent_init_params", ",", "alg_types", ",", "\n", "gamma", "=", "0.95", ",", "tau", "=", "0.01", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "\n", "discrete_action", "=", "False", ",", "recurrent", "=", "False", ",", "\n", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            agent_init_params (list of dict): List of dicts with parameters to\n                                              initialize each agent\n                num_in_pol (int): Input dimensions to policy\n                num_out_pol (int): Output dimensions to policy\n                num_in_critic (int): Input dimensions to critic\n            alg_types (list of str): Learning algorithm for each agent (DDPG\n                                       or MADDPG)\n            gamma (float): Discount factor\n            tau (float): Target update rate\n            lr (float): Learning rate for policy and critic\n            hidden_dim (int): Number of hidden dimensions for networks\n            discrete_action (bool): Whether or not to use discrete action space\n            recurrent (bool): Whether or not to use LSTM instead of MLP\n        \"\"\"", "\n", "self", ".", "nagents", "=", "len", "(", "alg_types", ")", "\n", "self", ".", "alg_types", "=", "alg_types", "\n", "self", ".", "agents", "=", "[", "DDPGAgent", "(", "lr", "=", "lr", ",", "discrete_action", "=", "discrete_action", ",", "\n", "hidden_dim", "=", "hidden_dim", ",", "recurrent", "=", "recurrent", ",", "\n", "convolutional", "=", "convolutional", ",", "\n", "**", "params", ")", "\n", "for", "params", "in", "agent_init_params", "]", "\n", "self", ".", "agent_init_params", "=", "agent_init_params", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "tau", "=", "tau", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "discrete_action", "=", "discrete_action", "\n", "self", ".", "pol_dev", "=", "'cpu'", "# device for policies", "\n", "self", ".", "critic_dev", "=", "'cpu'", "# device for critics", "\n", "self", ".", "trgt_pol_dev", "=", "'cpu'", "# device for target policies", "\n", "self", ".", "trgt_critic_dev", "=", "'cpu'", "# device for target critics", "\n", "self", ".", "niter", "=", "0", "\n", "self", ".", "convolutional", "=", "convolutional", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.policies": [[54, 57], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "policies", "(", "self", ")", ":", "\n", "        ", "return", "[", "a", ".", "policy", "for", "a", "in", "self", ".", "agents", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.target_policies": [[58, 61], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "target_policies", "(", "self", ")", ":", "\n", "        ", "return", "[", "a", ".", "target_policy", "for", "a", "in", "self", ".", "agents", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.scale_noise": [[62, 70], ["a.scale_noise"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.scale_noise"], ["", "def", "scale_noise", "(", "self", ",", "scale", ")", ":", "\n", "        ", "\"\"\"\n        Scale noise for each agent\n        Inputs:\n            scale (float): scale of noise\n        \"\"\"", "\n", "for", "a", "in", "self", ".", "agents", ":", "\n", "            ", "a", ".", "scale_noise", "(", "scale", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.reset_noise": [[71, 74], ["a.reset_noise"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.reset_noise"], ["", "", "def", "reset_noise", "(", "self", ")", ":", "\n", "        ", "for", "a", "in", "self", ".", "agents", ":", "\n", "            ", "a", ".", "reset_noise", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.step": [[75, 86], ["a.step", "zip"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "", "def", "step", "(", "self", ",", "observations", ",", "explore", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Take a step forward in environment with all agents\n        Inputs:\n            observations: List of observations for each agent\n            explore (boolean): Whether or not to add exploration noise\n        Outputs:\n            actions: List of actions for each agent\n        \"\"\"", "\n", "return", "[", "a", ".", "step", "(", "obs", ",", "explore", "=", "explore", ")", "for", "a", ",", "obs", "in", "zip", "(", "self", ".", "agents", ",", "\n", "observations", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.update": [[87, 198], ["curr_agent.critic_optimizer.zero_grad", "curr_agent.critic", "MSELoss", "MSELoss.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "curr_agent.critic_optimizer.step", "curr_agent.policy_optimizer.zero_grad", "pol_loss.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "curr_agent.policy_optimizer.step", "target_value.detach", "utils.misc.average_gradients", "curr_agent.critic.parameters", "curr_agent.policy", "utils.misc.gumbel_softmax", "curr_agent.policy", "zip", "curr_agent.critic().mean", "utils.misc.average_gradients", "curr_agent.policy.parameters", "logger.add_scalars", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "rews[].view", "emps[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "utils.misc.onehot_from_logits", "pi", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "curr_agent.target_critic", "dones[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "all_pol_acs.append", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "curr_agent.critic", "pi", "zip", "zip", "utils.misc.onehot_from_logits", "curr_agent.target_policy", "all_pol_acs.append", "all_pol_acs.append", "curr_agent.target_policy", "utils.misc.onehot_from_logits", "utils.misc.onehot_from_logits", "pi", "curr_agent.target_policy", "pi"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.average_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.average_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits"], ["", "def", "update", "(", "self", ",", "sample", ",", "agent_i", ",", "parallel", "=", "False", ",", "logger", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Update parameters of agent model based on sample from replay buffer\n        Inputs:\n            sample: tuple of (observations, actions, rewards, next\n                    observations, and episode end masks) sampled randomly from\n                    the replay buffer. Each is a list with entries\n                    corresponding to each agent\n            agent_i (int): index of agent to update\n            parallel (bool): If true, will average gradients across threads\n            logger (SummaryWriter from Tensorboard-Pytorch):\n                If passed in, important quantities will be logged\n        \"\"\"", "\n", "obs", ",", "acs", ",", "rews", ",", "emps", ",", "next_obs", ",", "dones", "=", "sample", "\n", "curr_agent", "=", "self", ".", "agents", "[", "agent_i", "]", "\n", "\n", "curr_agent", ".", "critic_optimizer", ".", "zero_grad", "(", ")", "\n", "if", "self", ".", "alg_types", "[", "agent_i", "]", "==", "'MADDPG'", ":", "\n", "            ", "if", "self", ".", "discrete_action", ":", "# one-hot encode action", "\n", "                ", "all_trgt_acs", "=", "[", "onehot_from_logits", "(", "pi", "(", "nobs", ")", ")", "for", "pi", ",", "nobs", "in", "\n", "zip", "(", "self", ".", "target_policies", ",", "next_obs", ")", "]", "\n", "", "else", ":", "\n", "                ", "all_trgt_acs", "=", "[", "pi", "(", "nobs", ")", "for", "pi", ",", "nobs", "in", "zip", "(", "self", ".", "target_policies", ",", "\n", "next_obs", ")", "]", "\n", "\n", "", "if", "self", ".", "convolutional", ":", "\n", "                ", "S", "=", "torch", ".", "cat", "(", "(", "next_obs", ")", ",", "dim", "=", "1", ")", "\n", "A", "=", "torch", ".", "cat", "(", "(", "all_trgt_acs", ")", ",", "dim", "=", "1", ")", "\n", "trgt_vf_in", "=", "(", "S", ",", "A", ")", "\n", "", "else", ":", "\n", "                ", "trgt_vf_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "all_trgt_acs", ")", ",", "dim", "=", "1", ")", "\n", "", "", "else", ":", "# DDPG", "\n", "            ", "if", "self", ".", "discrete_action", ":", "\n", "                ", "if", "self", ".", "convolutional", ":", "\n", "                    ", "trgt_vf_in", "=", "(", "next_obs", "[", "agent_i", "]", ",", "onehot_from_logits", "(", "curr_agent", ".", "target_policy", "(", "next_obs", "[", "agent_i", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "trgt_vf_in", "=", "torch", ".", "cat", "(", "\n", "(", "next_obs", "[", "agent_i", "]", ",", "onehot_from_logits", "(", "curr_agent", ".", "target_policy", "(", "next_obs", "[", "agent_i", "]", ")", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "", "", "else", ":", "\n", "                ", "trgt_vf_in", "=", "torch", ".", "cat", "(", "(", "next_obs", "[", "agent_i", "]", ",", "\n", "curr_agent", ".", "target_policy", "(", "next_obs", "[", "agent_i", "]", ")", ")", ",", "\n", "dim", "=", "1", ")", "\n", "\n", "", "", "target_value", "=", "(", "rews", "[", "agent_i", "]", ".", "view", "(", "-", "1", ",", "1", ")", "+", "emps", "[", "agent_i", "]", ".", "view", "(", "-", "1", ",", "1", ")", "+", "self", ".", "gamma", "*", "\n", "curr_agent", ".", "target_critic", "(", "trgt_vf_in", ")", "*", "\n", "(", "1", "-", "dones", "[", "agent_i", "]", ".", "view", "(", "-", "1", ",", "1", ")", ")", ")", "\n", "\n", "if", "self", ".", "alg_types", "[", "agent_i", "]", "==", "'MADDPG'", ":", "\n", "            ", "if", "self", ".", "convolutional", ":", "\n", "                ", "vf_in", "=", "(", "torch", ".", "cat", "(", "(", "obs", ")", ",", "dim", "=", "1", ")", ",", "torch", ".", "cat", "(", "(", "acs", ")", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "vf_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "acs", ")", ",", "dim", "=", "1", ")", "\n", "", "", "else", ":", "# DDPG", "\n", "            ", "if", "self", ".", "convolutional", ":", "\n", "                ", "vf_in", "=", "(", "obs", "[", "agent_i", "]", ",", "acs", "[", "agent_i", "]", ")", "\n", "", "else", ":", "\n", "                ", "vf_in", "=", "torch", ".", "cat", "(", "(", "obs", "[", "agent_i", "]", ",", "acs", "[", "agent_i", "]", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "", "actual_value", "=", "curr_agent", ".", "critic", "(", "vf_in", ")", "\n", "vf_loss", "=", "MSELoss", "(", "actual_value", ",", "target_value", ".", "detach", "(", ")", ")", "\n", "vf_loss", ".", "backward", "(", ")", "\n", "if", "parallel", ":", "\n", "            ", "average_gradients", "(", "curr_agent", ".", "critic", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "curr_agent", ".", "critic", ".", "parameters", "(", ")", ",", "0.5", ")", "\n", "curr_agent", ".", "critic_optimizer", ".", "step", "(", ")", "\n", "\n", "curr_agent", ".", "policy_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "if", "self", ".", "discrete_action", ":", "\n", "# Forward pass as if onehot (hard=True) but backprop through a differentiable", "\n", "# Gumbel-Softmax sample. The MADDPG paper uses the Gumbel-Softmax trick to backprop", "\n", "# through discrete categorical samples, but I'm not sure if that is", "\n", "# correct since it removes the assumption of a deterministic policy for", "\n", "# DDPG. Regardless, discrete policies don't seem to learn properly without it.", "\n", "            ", "curr_pol_out", "=", "curr_agent", ".", "policy", "(", "obs", "[", "agent_i", "]", ")", "\n", "curr_pol_vf_in", "=", "gumbel_softmax", "(", "curr_pol_out", ",", "hard", "=", "True", ",", "device", "=", "self", ".", "critic_dev", ")", "\n", "", "else", ":", "\n", "            ", "curr_pol_out", "=", "curr_agent", ".", "policy", "(", "obs", "[", "agent_i", "]", ")", "\n", "curr_pol_vf_in", "=", "curr_pol_out", "\n", "", "if", "self", ".", "alg_types", "[", "agent_i", "]", "==", "'MADDPG'", ":", "\n", "            ", "all_pol_acs", "=", "[", "]", "\n", "for", "i", ",", "pi", ",", "ob", "in", "zip", "(", "range", "(", "self", ".", "nagents", ")", ",", "self", ".", "policies", ",", "obs", ")", ":", "\n", "                ", "if", "i", "==", "agent_i", ":", "\n", "                    ", "all_pol_acs", ".", "append", "(", "curr_pol_vf_in", ")", "\n", "", "elif", "self", ".", "discrete_action", ":", "\n", "                    ", "all_pol_acs", ".", "append", "(", "onehot_from_logits", "(", "pi", "(", "ob", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "all_pol_acs", ".", "append", "(", "pi", "(", "ob", ")", ")", "\n", "\n", "", "", "if", "self", ".", "convolutional", ":", "\n", "                ", "vf_in", "=", "(", "torch", ".", "cat", "(", "(", "obs", ")", ",", "dim", "=", "1", ")", ",", "torch", ".", "cat", "(", "(", "all_pol_acs", ")", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "vf_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "all_pol_acs", ")", ",", "dim", "=", "1", ")", "\n", "", "", "else", ":", "# DDPG", "\n", "            ", "if", "self", ".", "convolutional", ":", "\n", "                ", "vf_in", "=", "(", "obs", "[", "agent_i", "]", ",", "curr_pol_vf_in", ")", "\n", "", "else", ":", "\n", "                ", "vf_in", "=", "torch", ".", "cat", "(", "(", "obs", "[", "agent_i", "]", ",", "curr_pol_vf_in", ")", ",", "dim", "=", "1", ")", "\n", "", "", "pol_loss", "=", "-", "curr_agent", ".", "critic", "(", "vf_in", ")", ".", "mean", "(", ")", "\n", "pol_loss", "+=", "(", "curr_pol_out", "**", "2", ")", ".", "mean", "(", ")", "*", "1e-3", "\n", "pol_loss", ".", "backward", "(", ")", "\n", "if", "parallel", ":", "\n", "            ", "average_gradients", "(", "curr_agent", ".", "policy", ")", "\n", "", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "curr_agent", ".", "policy", ".", "parameters", "(", ")", ",", "0.5", ")", "\n", "curr_agent", ".", "policy_optimizer", ".", "step", "(", ")", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'agent%i/losses'", "%", "agent_i", ",", "\n", "{", "'vf_loss'", ":", "vf_loss", ",", "\n", "'pol_loss'", ":", "pol_loss", "}", ",", "\n", "self", ".", "niter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.update_all_targets": [[199, 208], ["utils.misc.soft_update", "utils.misc.soft_update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.soft_update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.soft_update"], ["", "", "def", "update_all_targets", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Update all target networks (called after normal updates have been\n        performed for each agent)\n        \"\"\"", "\n", "for", "a", "in", "self", ".", "agents", ":", "\n", "            ", "soft_update", "(", "a", ".", "target_critic", ",", "a", ".", "critic", ",", "self", ".", "tau", ")", "\n", "soft_update", "(", "a", ".", "target_policy", ",", "a", ".", "policy", ",", "self", ".", "tau", ")", "\n", "", "self", ".", "niter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.prep_training": [[209, 235], ["enumerate", "a.policy.train", "a.critic.train", "a.target_policy.train", "a.target_critic.train", "x.cuda", "x.cpu", "fn", "fn", "fn", "fn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "prep_training", "(", "self", ",", "device", "=", "'gpu'", ")", ":", "\n", "        ", "for", "i", ",", "a", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "a", ".", "policy", ".", "train", "(", ")", "\n", "a", ".", "critic", ".", "train", "(", ")", "\n", "a", ".", "target_policy", ".", "train", "(", ")", "\n", "a", ".", "target_critic", ".", "train", "(", ")", "\n", "", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "", "if", "not", "self", ".", "pol_dev", "==", "device", ":", "\n", "            ", "for", "a", "in", "self", ".", "agents", ":", "\n", "                ", "a", ".", "policy", "=", "fn", "(", "a", ".", "policy", ")", "\n", "", "self", ".", "pol_dev", "=", "device", "\n", "", "if", "not", "self", ".", "critic_dev", "==", "device", ":", "\n", "            ", "for", "a", "in", "self", ".", "agents", ":", "\n", "                ", "a", ".", "critic", "=", "fn", "(", "a", ".", "critic", ")", "\n", "", "self", ".", "critic_dev", "=", "device", "\n", "", "if", "not", "self", ".", "trgt_pol_dev", "==", "device", ":", "\n", "            ", "for", "a", "in", "self", ".", "agents", ":", "\n", "                ", "a", ".", "target_policy", "=", "fn", "(", "a", ".", "target_policy", ")", "\n", "", "self", ".", "trgt_pol_dev", "=", "device", "\n", "", "if", "not", "self", ".", "trgt_critic_dev", "==", "device", ":", "\n", "            ", "for", "a", "in", "self", ".", "agents", ":", "\n", "                ", "a", ".", "target_critic", "=", "fn", "(", "a", ".", "target_critic", ")", "\n", "", "self", ".", "trgt_critic_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.prep_rollouts": [[236, 248], ["enumerate", "a.policy.eval", "x.cuda", "x.cpu", "fn"], "methods", ["None"], ["", "", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "for", "i", ",", "a", "in", "enumerate", "(", "self", ".", "agents", ")", ":", "\n", "            ", "a", ".", "policy", ".", "eval", "(", ")", "\n", "", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "# only need main policy for rollouts", "\n", "", "if", "not", "self", ".", "pol_dev", "==", "device", ":", "\n", "            ", "for", "a", "in", "self", ".", "agents", ":", "\n", "                ", "a", ".", "policy", "=", "fn", "(", "a", ".", "policy", ")", "\n", "", "self", ".", "pol_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.save": [[249, 257], ["maddpg.MADDPG.prep_training", "torch.save", "torch.save", "torch.save", "torch.save", "a.get_params"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.get_params"], ["", "", "def", "save", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Save trained parameters of all agents into one file\n        \"\"\"", "\n", "self", ".", "prep_training", "(", "device", "=", "'cpu'", ")", "# move parameters to CPU before saving", "\n", "save_dict", "=", "{", "'init_dict'", ":", "self", ".", "init_dict", ",", "\n", "'agent_params'", ":", "[", "a", ".", "get_params", "(", ")", "for", "a", "in", "self", ".", "agents", "]", "}", "\n", "torch", ".", "save", "(", "save_dict", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_env": [[258, 301], ["zip", "cls", "isinstance", "get_shape", "agent_init_params.append", "isinstance", "get_shape", "get_shape", "sum"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "@", "classmethod", "\n", "def", "init_from_env", "(", "cls", ",", "env", ",", "agent_alg", "=", "\"MADDPG\"", ",", "adversary_alg", "=", "\"MADDPG\"", ",", "\n", "gamma", "=", "0.95", ",", "tau", "=", "0.01", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate instance of this class from multi-agent environment\n        \"\"\"", "\n", "agent_init_params", "=", "[", "]", "\n", "alg_types", "=", "[", "adversary_alg", "if", "atype", "==", "'adversary'", "else", "agent_alg", "for", "\n", "atype", "in", "env", ".", "agent_types", "]", "\n", "for", "acsp", ",", "obsp", ",", "algtype", "in", "zip", "(", "env", ".", "action_space", ",", "env", ".", "observation_space", ",", "\n", "alg_types", ")", ":", "\n", "            ", "num_in_pol", "=", "obsp", ".", "shape", "[", "0", "]", "\n", "if", "isinstance", "(", "acsp", ",", "Box", ")", ":", "\n", "                ", "discrete_action", "=", "False", "\n", "get_shape", "=", "lambda", "x", ":", "x", ".", "shape", "[", "0", "]", "\n", "", "elif", "isinstance", "(", "acsp", ",", "Discrete", ")", ":", "# Discrete", "\n", "                ", "discrete_action", "=", "True", "\n", "get_shape", "=", "lambda", "x", ":", "x", ".", "n", "\n", "", "else", ":", "\n", "                ", "discrete_action", "=", "True", "\n", "get_shape", "=", "lambda", "x", ":", "sum", "(", "x", ".", "high", "-", "x", ".", "low", "+", "1", ")", "\n", "", "num_out_pol", "=", "get_shape", "(", "acsp", ")", "\n", "if", "algtype", "==", "\"MADDPG\"", ":", "\n", "                ", "num_in_critic", "=", "0", "\n", "for", "oobsp", "in", "env", ".", "observation_space", ":", "\n", "                    ", "num_in_critic", "+=", "oobsp", ".", "shape", "[", "0", "]", "\n", "", "for", "oacsp", "in", "env", ".", "action_space", ":", "\n", "                    ", "num_in_critic", "+=", "get_shape", "(", "oacsp", ")", "\n", "", "", "else", ":", "\n", "                ", "num_in_critic", "=", "obsp", ".", "shape", "[", "0", "]", "+", "get_shape", "(", "acsp", ")", "\n", "", "agent_init_params", ".", "append", "(", "{", "'num_in_pol'", ":", "num_in_pol", ",", "\n", "'num_out_pol'", ":", "num_out_pol", ",", "\n", "'num_in_critic'", ":", "num_in_critic", "}", ")", "\n", "", "init_dict", "=", "{", "'gamma'", ":", "gamma", ",", "'tau'", ":", "tau", ",", "'lr'", ":", "lr", ",", "\n", "'hidden_dim'", ":", "hidden_dim", ",", "\n", "'alg_types'", ":", "alg_types", ",", "\n", "'agent_init_params'", ":", "agent_init_params", ",", "\n", "'discrete_action'", ":", "discrete_action", ",", "\n", "'recurrent'", ":", "recurrent", ",", "\n", "'convolutional'", ":", "convolutional", "}", "\n", "instance", "=", "cls", "(", "**", "init_dict", ")", "\n", "instance", ".", "init_dict", "=", "init_dict", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_save": [[302, 313], ["torch.load", "torch.load", "torch.load", "torch.load", "cls", "zip", "a.load_params"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.load_params"], ["", "@", "classmethod", "\n", "def", "init_from_save", "(", "cls", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate instance of this class from file created by 'save' method\n        \"\"\"", "\n", "save_dict", "=", "torch", ".", "load", "(", "filename", ")", "\n", "instance", "=", "cls", "(", "**", "save_dict", "[", "'init_dict'", "]", ")", "\n", "instance", ".", "init_dict", "=", "save_dict", "[", "'init_dict'", "]", "\n", "for", "a", ",", "params", "in", "zip", "(", "instance", ".", "agents", ",", "save_dict", "[", "'agent_params'", "]", ")", ":", "\n", "            ", "a", ".", "load_params", "(", "params", ")", "\n", "", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_directory": [[314, 348], ["os.walk", "random.choice", "copy.copy", "enumerate", "len", "list", "list", "file.endswith", "itertools.combinations", "itertools.combinations_with_replacement", "os.path.join", "print", "torch.load", "torch.load", "torch.load", "torch.load", "cls", "zip", "instances.append", "a.load_params"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.agents.DDPGAgent.load_params"], ["", "@", "classmethod", "\n", "def", "init_from_directory", "(", "cls", ",", "directory", ")", ":", "\n", "        ", "import", "os", "\n", "import", "numpy", "as", "np", "\n", "import", "copy", "\n", "import", "itertools", "\n", "import", "random", "\n", "\"\"\"\n        Instantiate instance of this class from file created by 'save' method\n        \"\"\"", "\n", "instances", "=", "[", "]", "\n", "for", "r", ",", "d", ",", "f", "in", "os", ".", "walk", "(", "directory", ")", ":", "\n", "            ", "for", "file", "in", "f", ":", "\n", "                ", "if", "file", ".", "endswith", "(", "\"model.pt\"", ")", ":", "\n", "                    ", "filename", "=", "os", ".", "path", ".", "join", "(", "r", ",", "file", ")", "\n", "print", "(", "f'loaded {filename}'", ")", "\n", "save_dict", "=", "torch", ".", "load", "(", "filename", ")", "\n", "instance", "=", "cls", "(", "**", "save_dict", "[", "'init_dict'", "]", ")", "\n", "instance", ".", "init_dict", "=", "save_dict", "[", "'init_dict'", "]", "\n", "for", "a", ",", "params", "in", "zip", "(", "instance", ".", "agents", ",", "save_dict", "[", "'agent_params'", "]", ")", ":", "\n", "                        ", "a", ".", "load_params", "(", "params", ")", "\n", "", "instances", ".", "append", "(", "instance", ")", "\n", "\n", "", "", "", "n_agents", "=", "instances", "[", "0", "]", ".", "nagents", "\n", "if", "n_agents", "==", "len", "(", "instances", ")", ":", "\n", "            ", "combinations", "=", "list", "(", "itertools", ".", "combinations", "(", "instances", ",", "n_agents", ")", ")", "\n", "", "else", ":", "\n", "            ", "combinations", "=", "list", "(", "itertools", ".", "combinations_with_replacement", "(", "instances", ",", "n_agents", ")", ")", "\n", "\n", "", "comb", "=", "random", ".", "choice", "(", "combinations", ")", "\n", "copy_instance", "=", "copy", ".", "copy", "(", "instances", "[", "0", "]", ")", "\n", "for", "i", ",", "agent", "in", "enumerate", "(", "copy_instance", ".", "agents", ")", ":", "\n", "            ", "copy_instance", ".", "agents", "[", "i", "]", "=", "comb", "[", "i", "]", ".", "agents", "[", "i", "]", "\n", "", "return", "copy_instance", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_empowerment.VariationalBaseEmpowerment.__init__": [[2, 4], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_empowerment.VariationalBaseEmpowerment.compute": [[5, 7], ["None"], "methods", ["None"], ["", "def", "compute", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_empowerment.VariationalBaseEmpowerment.update": [[8, 10], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_empowerment.VariationalBaseEmpowerment.prep_training": [[11, 13], ["None"], "methods", ["None"], ["", "def", "prep_training", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_empowerment.VariationalBaseEmpowerment.prep_rollouts": [[14, 16], ["None"], "methods", ["None"], ["", "def", "prep_rollouts", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.__init__": [[2, 4], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device": [[5, 7], ["None"], "methods", ["None"], ["", "def", "get_device", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.set_device": [[8, 10], ["None"], "methods", ["None"], ["", "def", "set_device", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "device", "=", "device", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.ComputerTransferAction.__init__": [[14, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "plan_dev", "=", "empowerment", ".", "plan_dev", "\n", "self", ".", "source_dev", "=", "empowerment", ".", "source_dev", "\n", "self", ".", "trans_dev", "=", "empowerment", ".", "trans_dev", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.ComputerTransferAction.compute": [[22, 54], ["torch.no_grad", "zip", "torch.cat", "variational_transfer_action_empowerment.ComputerTransferAction.transition", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.numpy", "torch.autograd.Variable", "torch.cat.append", "torch.cat.append", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat.append", "E.mean", "torch.ones", "torch.Tensor", "range", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "numpy.vstack", "source", "source", "torch.cat.append", "planning"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "next_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "vstack", "(", "next_obs", "[", ":", ",", "i", "]", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "for", "i", "in", "range", "(", "rewards", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "source", ")", ":", "\n", "                ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "False", ")", ")", "\n", "\n", "", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "prob_plan", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "                ", "length", "=", "no", ".", "shape", "[", "1", "]", "\n", "nno", "=", "trans_out", "[", ":", ",", "start", ":", "start", "+", "length", "]", "\n", "acs_", "=", "[", "]", "\n", "for", "j", ",", "ac", "in", "enumerate", "(", "acs_src", ")", ":", "\n", "                    ", "if", "j", "!=", "i", ":", "acs_", ".", "append", "(", "ac", ")", "\n", "", "acs_", "=", "torch", ".", "cat", "(", "acs_", ",", "dim", "=", "1", ")", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ",", "acs_", ")", ",", "dim", "=", "1", ")", "\n", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "False", ")", ")", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "E", ".", "mean", "(", ")", "*", "torch", ".", "ones", "(", "(", "1", ",", "rewards", ".", "shape", "[", "1", "]", ")", ")", "\n", "return", "i_rews", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.ComputerTransferAction.prep_rollouts": [[55, 78], ["variational_transfer_action_empowerment.ComputerTransferAction.transition.eval", "variational_transfer_action_empowerment.ComputerTransferAction.transition.eval", "fn", "fn.eval", "fn.eval", "x.cuda", "x.cpu", "fn", "fn"], "methods", ["None"], ["", "", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "eval", "(", ")", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "# only need main policy for rollouts", "\n", "", "if", "not", "self", ".", "trans_dev", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "trans_dev", "=", "device", "\n", "", "self", ".", "transition", ".", "eval", "(", ")", "\n", "if", "not", "self", ".", "source_dev", "==", "device", ":", "\n", "            ", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "", "self", ".", "source_dev", "=", "device", "\n", "", "for", "source", "in", "self", ".", "source", ":", "\n", "            ", "source", ".", "eval", "(", ")", "\n", "", "if", "not", "self", ".", "plan_dev", "==", "device", ":", "\n", "            ", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "", "self", ".", "plan_dev", "=", "device", "\n", "", "for", "planning", "in", "self", ".", "planning", ":", "\n", "            ", "planning", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.ComputerTransferAction.prepare_training": [[79, 83], ["None"], "methods", ["None"], ["", "", "def", "prepare_training", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "trans_dev", "=", "device", "\n", "self", ".", "source_dev", "=", "device", "\n", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.TrainerTransferAction.__init__": [[86, 102], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "variational_transfer_action_empowerment.TrainerTransferAction.transition.parameters", "list", "list", "mlp.parameters", "mlp.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "plan_dev", "=", "empowerment", ".", "plan_dev", "\n", "self", ".", "source_dev", "=", "empowerment", ".", "source_dev", "\n", "self", ".", "trans_dev", "=", "empowerment", ".", "trans_dev", "\n", "\n", "self", ".", "transition_optimizer", "=", "Adam", "(", "self", ".", "transition", ".", "parameters", "(", ")", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "params_planning", "=", "[", "]", "\n", "for", "mlp", "in", "self", ".", "planning", ":", "params_planning", "+=", "list", "(", "mlp", ".", "parameters", "(", ")", ")", "\n", "self", ".", "planning_optimizer", "=", "Adam", "(", "params_planning", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "params_source", "=", "[", "]", "\n", "for", "mlp", "in", "self", ".", "source", ":", "params_source", "+=", "list", "(", "mlp", ".", "parameters", "(", ")", ")", "\n", "self", ".", "source_optimizer", "=", "Adam", "(", "params_source", "+", "params_planning", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "self", ".", "niter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.TrainerTransferAction.update": [[103, 165], ["variational_transfer_action_empowerment.TrainerTransferAction.transition_optimizer.zero_grad", "torch.cat", "variational_transfer_action_empowerment.TrainerTransferAction.transition", "MSELoss", "MSELoss.backward", "variational_transfer_action_empowerment.TrainerTransferAction.transition_optimizer.step", "variational_transfer_action_empowerment.TrainerTransferAction.planning_optimizer.zero_grad", "enumerate", "torch.cat", "torch.cat", "MSELoss", "MSELoss.backward", "variational_transfer_action_empowerment.TrainerTransferAction.planning_optimizer.step", "variational_transfer_action_empowerment.TrainerTransferAction.source_optimizer.zero_grad", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.backward", "variational_transfer_action_empowerment.TrainerTransferAction.source_optimizer.step", "torch.cat", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.cat", "variational_transfer_action_empowerment.TrainerTransferAction.transition", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat.append", "E.mean", "logger.add_scalars", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "torch.cat.append", "planning", "source", "source", "torch.cat.append", "planning", "MSELoss.detach", "MSELoss.detach", "i_rews.detach"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", ")", ":", "\n", "        ", "obs", ",", "acs", ",", "rews", ",", "emps", ",", "next_obs", ",", "dones", "=", "sample", "\n", "\n", "self", ".", "transition_optimizer", ".", "zero_grad", "(", ")", "\n", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "acs", ")", ",", "dim", "=", "1", ")", "\n", "next_obs_pred", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "trans_loss", "=", "MSELoss", "(", "next_obs_pred", ",", "torch", ".", "cat", "(", "next_obs", ",", "dim", "=", "1", ")", ")", "\n", "trans_loss", ".", "backward", "(", ")", "\n", "self", ".", "transition_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "planning_optimizer", ".", "zero_grad", "(", ")", "\n", "acs_plan", "=", "[", "]", "\n", "for", "i", ",", "(", "o", ",", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "obs", ",", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "            ", "acs_", "=", "[", "]", "\n", "for", "j", ",", "ac", "in", "enumerate", "(", "acs", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "acs_", ".", "append", "(", "ac", ")", "\n", "", "acs_", "=", "torch", ".", "cat", "(", "acs_", ",", "dim", "=", "1", ")", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "o", ",", "no", ",", "acs_", ")", ",", "dim", "=", "1", ")", "\n", "acs_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "True", ")", ")", "\n", "", "acs_plan", "=", "torch", ".", "cat", "(", "acs_plan", ",", "dim", "=", "1", ")", "\n", "acs_torch", "=", "torch", ".", "cat", "(", "acs", ",", "dim", "=", "1", ")", "\n", "plan_loss", "=", "MSELoss", "(", "acs_plan", ",", "acs_torch", ")", "\n", "plan_loss", ".", "backward", "(", ")", "\n", "self", ".", "planning_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "source_optimizer", ".", "zero_grad", "(", ")", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "source", ")", ":", "\n", "            ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "False", ")", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "", "prob_plan", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "            ", "length", "=", "no", ".", "shape", "[", "1", "]", "\n", "nno", "=", "trans_out", "[", ":", ",", "start", ":", "start", "+", "length", "]", "\n", "acs_", "=", "[", "]", "\n", "for", "j", ",", "ac", "in", "enumerate", "(", "acs", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "acs_", ".", "append", "(", "ac", ")", "\n", "", "acs_", "=", "torch", ".", "cat", "(", "acs_", ",", "dim", "=", "1", ")", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ",", "acs_", ")", ",", "dim", "=", "1", ")", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "False", ")", ")", "\n", "start", "+=", "length", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "-", "E", ".", "mean", "(", ")", "\n", "i_rews", ".", "backward", "(", ")", "\n", "self", ".", "source_optimizer", ".", "step", "(", ")", "\n", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'empowerment/losses'", ",", "\n", "{", "'trans_loss'", ":", "trans_loss", ".", "detach", "(", ")", ",", "\n", "'plan_loss'", ":", "plan_loss", ".", "detach", "(", ")", ",", "\n", "'i_rews'", ":", "i_rews", ".", "detach", "(", ")", "}", ",", "\n", "self", ".", "niter", ")", "\n", "", "self", ".", "niter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.TrainerTransferAction.prepare_training": [[166, 185], ["variational_transfer_action_empowerment.TrainerTransferAction.transition.train", "fn", "x.cuda", "x.cpu", "fn", "fn.train", "fn", "fn.train"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "prepare_training", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "transition", ".", "train", "(", ")", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "", "if", "not", "self", ".", "trans_dev", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "trans_dev", "=", "device", "\n", "", "if", "not", "self", ".", "source_dev", "==", "device", ":", "\n", "            ", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "source", ".", "train", "(", ")", "\n", "", "self", ".", "source_dev", "=", "device", "\n", "", "if", "not", "self", ".", "plan_dev", "==", "device", ":", "\n", "            ", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "planning", ".", "train", "(", ")", "\n", "", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.TrainerTransferAction.prep_rollouts": [[186, 190], ["None"], "methods", ["None"], ["", "", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "trans_dev", "=", "device", "\n", "self", ".", "source_dev", "=", "device", "\n", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.__init__": [[193, 208], ["variational_empowerment.VariationalBaseEmpowerment.__init__", "utils.networks.MLPNetwork", "variational_transfer_action_empowerment.ComputerTransferAction", "variational_transfer_action_empowerment.TrainerTransferAction", "utils.networks.MLPNetwork", "utils.networks.MLPNetwork"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "init_params", ",", "num_in_trans", ",", "num_out_trans", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "\n", "convolutional", "=", "False", ")", ":", "\n", "        ", "super", "(", "VariationalTransferActionEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transition", "=", "MLPNetwork", "(", "num_in_trans", ",", "num_out_trans", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "source", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_src'", "]", ",", "p", "[", "'num_out_src'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "self", ".", "planning", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_plan'", "]", ",", "p", "[", "'num_out_plan'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "\n", "self", ".", "lr", "=", "lr", "\n", "\n", "self", ".", "trans_dev", "=", "'cpu'", "# device for transition", "\n", "self", ".", "source_dev", "=", "'cpu'", "\n", "self", ".", "plan_dev", "=", "'cpu'", "\n", "\n", "self", ".", "computer", "=", "ComputerTransferAction", "(", "self", ")", "\n", "self", ".", "trainer", "=", "TrainerTransferAction", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.compute": [[209, 211], ["variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.computer.compute"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "return", "self", ".", "computer", ".", "compute", "(", "rewards", ",", "next_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.update": [[212, 214], ["variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.trainer.update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "trainer", ".", "update", "(", "sample", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.prep_training": [[215, 219], ["variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.computer.prepare_training", "variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.trainer.prepare_training", "variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.transition.train"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prepare_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prepare_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "prep_training", "(", "self", ",", "device", "=", "'gpu'", ")", ":", "\n", "        ", "self", ".", "computer", ".", "prepare_training", "(", "device", ")", "\n", "self", ".", "trainer", ".", "prepare_training", "(", "device", ")", "\n", "self", ".", "transition", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.prep_rollouts": [[220, 223], ["variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.computer.prep_rollouts", "variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.trainer.prep_rollouts"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts"], ["", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "computer", ".", "prep_rollouts", "(", ")", "\n", "self", ".", "trainer", ".", "prep_rollouts", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_action_empowerment.VariationalTransferActionEmpowerment.init_from_env": [[224, 259], ["enumerate", "cls", "zip", "enumerate", "init_params.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "@", "classmethod", "\n", "def", "init_from_env", "(", "cls", ",", "env", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate instance of this class from multi-agent environment\n        \"\"\"", "\n", "init_params", "=", "[", "]", "\n", "\n", "num_in_transition", "=", "num_out_transition", "=", "0", "\n", "for", "i", ",", "(", "acsp", ",", "obsp", ")", "in", "enumerate", "(", "zip", "(", "env", ".", "action_space", ",", "env", ".", "observation_space", ")", ")", ":", "\n", "            ", "num_in_source", "=", "obsp", ".", "shape", "[", "0", "]", "\n", "num_out_source", "=", "acsp", ".", "n", "\n", "\n", "num_in_planning", "=", "2", "*", "obsp", ".", "shape", "[", "0", "]", "\n", "for", "j", ",", "acsp_j", "in", "enumerate", "(", "env", ".", "action_space", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "num_in_planning", "+=", "acsp_j", ".", "n", "\n", "", "num_out_planning", "=", "acsp", ".", "n", "\n", "\n", "num_in_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "+", "acsp", ".", "n", "\n", "num_out_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "\n", "\n", "init_params", ".", "append", "(", "{", "'num_in_src'", ":", "num_in_source", ",", "\n", "'num_in_plan'", ":", "num_in_planning", ",", "\n", "'num_out_src'", ":", "num_out_source", ",", "\n", "'num_out_plan'", ":", "num_out_planning", "}", ")", "\n", "\n", "", "init_dict", "=", "{", "'lr'", ":", "lr", ",", "\n", "'hidden_dim'", ":", "hidden_dim", ",", "\n", "'init_params'", ":", "init_params", ",", "\n", "'num_in_trans'", ":", "num_in_transition", ",", "\n", "'num_out_trans'", ":", "num_out_transition", ",", "\n", "'recurrent'", ":", "recurrent", ",", "\n", "'convolutional'", ":", "convolutional", "}", "\n", "instance", "=", "cls", "(", "**", "init_dict", ")", "\n", "instance", ".", "init_dict", "=", "init_dict", "\n", "return", "instance", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.Computer.__init__": [[16, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "si", ")", ":", "\n", "        ", "self", ".", "transition", "=", "si", ".", "transition", "\n", "self", ".", "planning", "=", "si", ".", "planning", "\n", "self", ".", "device", "=", "si", ".", "device", "\n", "self", ".", "agents", "=", "si", ".", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.Computer.compute": [[22, 95], ["zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "social_influence.Computer.transition", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.cat.append", "numpy.cumsum().tolist", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "numpy.cumsum().tolist", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "zip", "torch.cat.append", "torch.cat.append", "utils.misc.gumbel_softmax", "zip", "source.policy", "source.policy", "numpy.cumsum", "utils.misc.gumbel_softmax", "planning", "numpy.cumsum", "social_influence.Computer.device.get_device", "social_influence.Computer.device.get_device", "social_influence.Computer.agents[].policy", "social_influence.Computer.device.get_device", "social_influence.Computer.device.get_device"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "compute", "(", "self", ",", "next_obs", ")", ":", "\n", "# acs_pi_k = []", "\n", "# prob_pi_k = []", "\n", "# for no, pi in zip(next_obs, self.agents):", "\n", "#     acs_pi_k.append(gumbel_softmax(pi.policy(no), device=self.device.get_device(), hard=True))", "\n", "#     prob_pi_k.append(F.softmax(pi.policy(no), dim=1).unsqueeze(1))  # for stacking later, dim = [B, 1, A]", "\n", "#", "\n", "# final_obs = self.transition(torch.cat((*next_obs, *acs_pi_k), dim=1))", "\n", "#", "\n", "# end_idx = [0] + np.cumsum([ne_ob.shape[1] for ne_ob in next_obs]).tolist()", "\n", "# start_end = [(start, end) for start, end in zip(end_idx, end_idx[1:])]", "\n", "#", "\n", "# # P(action distribution of agent j | k takes action taken)", "\n", "# action_dist = []    # action_dist dim = [num agents, batch_size, num agents - 1, action_dim]", "\n", "# for k, no in enumerate(next_obs):", "\n", "#     prob_pi_j = []", "\n", "#     for j, pi_j in enumerate(self.agents):", "\n", "#         if j == k: continue     # computing effect on other agents", "\n", "#         final_obs_j = final_obs[:, start_end[j][0]:start_end[j][1]]", "\n", "#         prob_pi_j.append(F.softmax(pi_j.policy(final_obs_j), dim=1).unsqueeze(1))", "\n", "#     prob_pi_j = torch.cat(prob_pi_j, dim=1)", "\n", "#     action_dist.append(prob_pi_j)", "\n", "#", "\n", "# # [P(k takes action 0) * (action distribution of agent j | k takes action 0) + ...]", "\n", "# marginal_action_dists = []", "\n", "# for k, (no, pi) in enumerate(zip(next_obs, self.agents)):", "\n", "#     batch_size, action_dim = acs_pi_k[k].shape", "\n", "#     all_acs_pi_k = torch.nn.functional.one_hot(torch.arange(action_dim)).float()", "\n", "#     for one_hot_ac in all_acs_pi_k:", "\n", "#         # replace inside the original acs_pi_k, k's action", "\n", "#         acs_pi_k_modified = acs_pi_k", "\n", "#         acs_pi_k_modified[k] = one_hot_ac.unsqueeze(0).repeat(batch_size, 1)", "\n", "#         tilde_final_obs = self.transition(torch.cat((*next_obs, *acs_pi_k_modified), dim=1))", "\n", "#", "\n", "#         for j, pi_j in enumerate(self.agents):", "\n", "#             if j == k: continue  # computing effect on other agent", "\n", "#             tilde_final_obs_j = tilde_final_obs[:, start_end[j][0]:start_end[j][1]]", "\n", "#             mrgn_dist_acs_j = F.softmax(pi_j.policy(tilde_final_obs_j), dim=1).unsqueeze(1)", "\n", "#         marginal_action_dists.append()", "\n", "        ", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "agents", ")", ":", "\n", "            ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", ".", "policy", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", ".", "policy", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "\n", "", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "prob_plan", "=", "[", "]", "\n", "end_idx", "=", "[", "0", "]", "+", "np", ".", "cumsum", "(", "[", "ne_ob", ".", "shape", "[", "1", "]", "for", "ne_ob", "in", "next_obs", "]", ")", ".", "tolist", "(", ")", "\n", "start_end", "=", "[", "(", "start", ",", "end", ")", "for", "start", ",", "end", "in", "zip", "(", "end_idx", ",", "end_idx", "[", "1", ":", "]", ")", "]", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "            ", "nno", "=", "trans_out", "[", ":", ",", "start_end", "[", "i", "]", "[", "0", "]", ":", "start_end", "[", "i", "]", "[", "1", "]", "]", "\n", "acs_", "=", "[", "]", "\n", "for", "j", ",", "ac", "in", "enumerate", "(", "acs_src", ")", ":", "\n", "                ", "if", "j", "==", "i", ":", "continue", "\n", "nno_other", "=", "trans_out", "[", ":", ",", "start_end", "[", "j", "]", "[", "0", "]", ":", "start_end", "[", "j", "]", "[", "1", "]", "]", "\n", "acs_", ".", "append", "(", "\n", "gumbel_softmax", "(", "self", ".", "agents", "[", "j", "]", ".", "policy", "(", "nno_other", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "True", ")", ")", "\n", "", "acs_", "=", "torch", ".", "cat", "(", "acs_", ",", "dim", "=", "1", ")", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ",", "acs_", ")", ",", "dim", "=", "1", ")", "\n", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "\n", "# for returning the si for individual agents", "\n", "end_idx", "=", "[", "0", "]", "+", "np", ".", "cumsum", "(", "[", "ne_ac", ".", "shape", "[", "1", "]", "for", "ne_ac", "in", "acs_src", "]", ")", ".", "tolist", "(", ")", "\n", "start_end", "=", "[", "(", "start", ",", "end", ")", "for", "start", ",", "end", "in", "zip", "(", "end_idx", ",", "end_idx", "[", "1", ":", "]", ")", "]", "\n", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "si", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "result", "=", "torch", ".", "cat", "(", "[", "si", "[", ":", ",", "start", ":", "end", "]", "for", "(", "start", ",", "end", ")", "in", "start_end", "]", ",", "dim", "=", "0", ")", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.Trainer.__init__": [[98, 111], ["torch.optim.Adam", "torch.optim.Adam", "flatten", "flatten", "torch.optim.Adam", "torch.optim.Adam", "social_influence.Trainer.transition.parameters", "list", "list", "mlp.parameters", "a.policy.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "si", ")", ":", "\n", "        ", "self", ".", "transition", "=", "si", ".", "transition", "\n", "self", ".", "planning", "=", "si", ".", "planning", "\n", "self", ".", "device", "=", "si", ".", "device", "\n", "self", ".", "agents", "=", "si", ".", "agents", "\n", "self", ".", "computer", "=", "si", ".", "computer", "\n", "\n", "self", ".", "transition_optimizer", "=", "Adam", "(", "self", ".", "transition", ".", "parameters", "(", ")", ",", "lr", "=", "si", ".", "lr", ")", "\n", "flatten", "=", "lambda", "l", ":", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "params_planning", "=", "flatten", "(", "[", "list", "(", "(", "mlp", ".", "parameters", "(", ")", ")", ")", "for", "mlp", "in", "self", ".", "planning", "]", ")", "\n", "params_agents", "=", "flatten", "(", "[", "list", "(", "a", ".", "policy", ".", "parameters", "(", ")", ")", "for", "a", "in", "self", ".", "agents", "]", ")", "\n", "self", ".", "si_optimizer", "=", "Adam", "(", "params_agents", "+", "params_planning", ",", "lr", "=", "si", ".", "lr", ")", "\n", "self", ".", "niter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.Trainer.update": [[112, 135], ["social_influence.Trainer.transition_optimizer.zero_grad", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "social_influence.Trainer.transition", "MSELoss", "MSELoss.backward", "social_influence.Trainer.transition_optimizer.step", "social_influence.Trainer.si_optimizer.zero_grad", "social_influence.Trainer.computer.compute", "i_rews.backward", "social_influence.Trainer.si_optimizer.step", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "social_influence.Trainer.mean", "logger.add_scalars", "MSELoss.detach", "i_rews.detach"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", ")", ":", "\n", "\n", "        ", "obs", ",", "acs", ",", "rews", ",", "emps", ",", "next_obs", ",", "dones", "=", "sample", "\n", "\n", "self", ".", "transition_optimizer", ".", "zero_grad", "(", ")", "\n", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "acs", ")", ",", "dim", "=", "1", ")", "\n", "next_obs_pred", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "trans_loss", "=", "MSELoss", "(", "next_obs_pred", ",", "torch", ".", "cat", "(", "next_obs", ",", "dim", "=", "1", ")", ")", "\n", "trans_loss", ".", "backward", "(", ")", "\n", "self", ".", "transition_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "si_optimizer", ".", "zero_grad", "(", ")", "\n", "SI", "=", "self", ".", "computer", ".", "compute", "(", "next_obs", ")", "\n", "i_rews", "=", "-", "SI", ".", "mean", "(", ")", "\n", "i_rews", ".", "backward", "(", ")", "\n", "self", ".", "si_optimizer", ".", "step", "(", ")", "\n", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'si/losses'", ",", "\n", "{", "'trans_loss'", ":", "trans_loss", ".", "detach", "(", ")", ",", "\n", "'i_rews'", ":", "i_rews", ".", "detach", "(", ")", "}", ",", "\n", "self", ".", "niter", ")", "\n", "", "self", ".", "niter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.SocialInfluence.__init__": [[138, 152], ["empowerment.base_empowerment.BaseEmpowerment.__init__", "empowerment.device.Device", "utils.networks.MLPNetwork", "social_influence.Computer", "social_influence.Trainer", "utils.networks.MLPNetwork"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agents", ",", "init_params", ",", "num_in_trans", ",", "num_out_trans", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "\n", "convolutional", "=", "False", ")", ":", "\n", "        ", "super", "(", "SocialInfluence", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "agents", "=", "agents", "\n", "self", ".", "device", "=", "Device", "(", "'cpu'", ")", "\n", "self", ".", "transition", "=", "MLPNetwork", "(", "num_in_trans", ",", "num_out_trans", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "planning", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_plan'", "]", ",", "p", "[", "'num_out_plan'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "\n", "self", ".", "lr", "=", "lr", "\n", "\n", "self", ".", "niter", "=", "0", "\n", "\n", "self", ".", "computer", "=", "Computer", "(", "self", ")", "\n", "self", ".", "trainer", "=", "Trainer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.SocialInfluence.compute": [[153, 159], ["social_influence.SocialInfluence.computer.compute", "social_influence.SocialInfluence.mean", "social_influence.SocialInfluence.mean.detach().numpy().reshape", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "range", "social_influence.SocialInfluence.mean.detach().numpy", "numpy.vstack", "social_influence.SocialInfluence.mean.detach"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "next_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "vstack", "(", "next_obs", "[", ":", ",", "i", "]", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "for", "i", "in", "range", "(", "next_obs", ".", "shape", "[", "1", "]", ")", "]", "\n", "si", "=", "self", ".", "computer", ".", "compute", "(", "next_obs", ")", "\n", "i_rews", "=", "si", ".", "mean", "(", "-", "1", ")", "\n", "return", "i_rews", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.SocialInfluence.update": [[160, 162], ["social_influence.SocialInfluence.trainer.update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "trainer", ".", "update", "(", "sample", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.SocialInfluence.prep_training": [[163, 178], ["social_influence.SocialInfluence.transition.train", "social_influence.SocialInfluence.device.set_device", "fn.train", "fn", "x.cuda", "x.cpu", "social_influence.SocialInfluence.device.get_device", "fn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.set_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "prep_training", "(", "self", ",", "device", "=", "'gpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "train", "(", ")", "\n", "for", "planning", "in", "self", ".", "planning", ":", "\n", "            ", "planning", ".", "train", "(", ")", "\n", "\n", "", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "", "if", "not", "self", ".", "device", ".", "get_device", "(", ")", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "\n", "", "", "self", ".", "device", ".", "set_device", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.SocialInfluence.prep_rollouts": [[179, 195], ["social_influence.SocialInfluence.transition.eval", "social_influence.SocialInfluence.device.set_device", "fn.eval", "fn", "x.cuda", "x.cpu", "social_influence.SocialInfluence.device.get_device", "fn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.set_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "eval", "(", ")", "\n", "for", "planning", "in", "self", ".", "planning", ":", "\n", "            ", "planning", ".", "eval", "(", ")", "\n", "\n", "", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "# only need main policy for rollouts", "\n", "", "if", "not", "self", ".", "device", ".", "get_device", "(", ")", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "\n", "", "", "self", ".", "device", ".", "set_device", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.social_influence.SocialInfluence.init": [[196, 227], ["enumerate", "cls", "zip", "enumerate", "init_params.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "@", "classmethod", "\n", "def", "init", "(", "cls", ",", "agents", ",", "env", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate instance of this class from multi-agent environment\n        \"\"\"", "\n", "init_params", "=", "[", "]", "\n", "\n", "num_in_transition", "=", "num_out_transition", "=", "0", "\n", "for", "i", ",", "(", "acsp", ",", "obsp", ")", "in", "enumerate", "(", "zip", "(", "env", ".", "action_space", ",", "env", ".", "observation_space", ")", ")", ":", "\n", "\n", "            ", "num_in_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "+", "acsp", ".", "n", "\n", "num_out_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "\n", "\n", "num_in_planning", "=", "2", "*", "obsp", ".", "shape", "[", "0", "]", "\n", "for", "j", ",", "acsp_j", "in", "enumerate", "(", "env", ".", "action_space", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "num_in_planning", "+=", "acsp_j", ".", "n", "\n", "", "num_out_planning", "=", "acsp", ".", "n", "\n", "init_params", ".", "append", "(", "{", "'num_in_plan'", ":", "num_in_planning", ",", "\n", "'num_out_plan'", ":", "num_out_planning", "}", ")", "\n", "\n", "", "init_dict", "=", "{", "'agents'", ":", "agents", ",", "\n", "'lr'", ":", "lr", ",", "\n", "'hidden_dim'", ":", "hidden_dim", ",", "\n", "'init_params'", ":", "init_params", ",", "\n", "'num_in_trans'", ":", "num_in_transition", ",", "\n", "'num_out_trans'", ":", "num_out_transition", ",", "\n", "'recurrent'", ":", "recurrent", ",", "\n", "'convolutional'", ":", "convolutional", "}", "\n", "instance", "=", "cls", "(", "**", "init_dict", ")", "\n", "instance", ".", "init_dict", "=", "init_dict", "\n", "return", "instance", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.__init__": [[14, 22], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "plan_dev", "=", "empowerment", ".", "plan_dev", "\n", "self", ".", "source_dev", "=", "empowerment", ".", "source_dev", "\n", "self", ".", "trans_dev", "=", "empowerment", ".", "trans_dev", "\n", "self", ".", "agents", "=", "empowerment", ".", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.compute": [[23, 52], ["torch.no_grad", "zip", "torch.cat", "variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.transition", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.numpy", "torch.autograd.Variable", "torch.cat.append", "torch.cat.append", "zip", "utils.misc.gumbel_softmax", "torch.cat", "torch.cat.append", "E.mean", "torch.ones", "torch.Tensor", "range", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.agents[].policy", "utils.misc.gumbel_softmax", "numpy.vstack", "source", "source", "planning"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "next_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "vstack", "(", "next_obs", "[", ":", ",", "i", "]", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "for", "i", "in", "range", "(", "rewards", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "source", ")", ":", "\n", "                ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "False", ")", ")", "\n", "\n", "", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "prob_plan", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "                ", "length", "=", "no", ".", "shape", "[", "1", "]", "\n", "nno", "=", "trans_out", "[", ":", ",", "start", ":", "start", "+", "length", "]", "\n", "acs_pi", "=", "gumbel_softmax", "(", "self", ".", "agents", "[", "i", "]", ".", "policy", "(", "nno", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ",", "acs_pi", ")", ",", "dim", "=", "1", ")", "\n", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "False", ")", ")", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "E", ".", "mean", "(", ")", "*", "torch", ".", "ones", "(", "(", "1", ",", "rewards", ".", "shape", "[", "1", "]", ")", ")", "\n", "return", "i_rews", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.prep_rollouts": [[53, 76], ["variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.transition.eval", "variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.transition.eval", "fn", "fn.eval", "fn.eval", "x.cuda", "x.cpu", "fn", "fn"], "methods", ["None"], ["", "", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "eval", "(", ")", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "# only need main policy for rollouts", "\n", "", "if", "not", "self", ".", "trans_dev", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "trans_dev", "=", "device", "\n", "", "self", ".", "transition", ".", "eval", "(", ")", "\n", "if", "not", "self", ".", "source_dev", "==", "device", ":", "\n", "            ", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "", "self", ".", "source_dev", "=", "device", "\n", "", "for", "source", "in", "self", ".", "source", ":", "\n", "            ", "source", ".", "eval", "(", ")", "\n", "", "if", "not", "self", ".", "plan_dev", "==", "device", ":", "\n", "            ", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "", "self", ".", "plan_dev", "=", "device", "\n", "", "for", "planning", "in", "self", ".", "planning", ":", "\n", "            ", "planning", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi.prepare_training": [[77, 81], ["None"], "methods", ["None"], ["", "", "def", "prepare_training", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "trans_dev", "=", "device", "\n", "self", ".", "source_dev", "=", "device", "\n", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.__init__": [[84, 105], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.transition.parameters", "list", "list", "mlp.parameters", "mlp.parameters", "list", "list", "a.policy.parameters", "a.critic.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "plan_dev", "=", "empowerment", ".", "plan_dev", "\n", "self", ".", "source_dev", "=", "empowerment", ".", "source_dev", "\n", "self", ".", "trans_dev", "=", "empowerment", ".", "trans_dev", "\n", "self", ".", "agents", "=", "empowerment", ".", "agents", "\n", "\n", "self", ".", "transition_optimizer", "=", "Adam", "(", "self", ".", "transition", ".", "parameters", "(", ")", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "params_planning", "=", "[", "]", "\n", "for", "mlp", "in", "self", ".", "planning", ":", "params_planning", "+=", "list", "(", "mlp", ".", "parameters", "(", ")", ")", "\n", "self", ".", "planning_optimizer", "=", "Adam", "(", "params_planning", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "params_source", "=", "[", "]", "\n", "for", "mlp", "in", "self", ".", "source", ":", "params_source", "+=", "list", "(", "mlp", ".", "parameters", "(", ")", ")", "\n", "params_agents", "=", "[", "]", "\n", "for", "a", "in", "self", ".", "agents", ":", "\n", "            ", "params_agents", "+=", "list", "(", "a", ".", "policy", ".", "parameters", "(", ")", ")", "+", "list", "(", "a", ".", "critic", ".", "parameters", "(", ")", ")", "\n", "\n", "", "self", ".", "source_optimizer", "=", "Adam", "(", "params_source", "+", "params_planning", "+", "params_agents", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "self", ".", "niter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.update": [[106, 149], ["variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.transition_optimizer.zero_grad", "torch.cat", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.transition", "MSELoss", "MSELoss.backward", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.transition_optimizer.step", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.source_optimizer.zero_grad", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.backward", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.source_optimizer.step", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.cat", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.transition", "zip", "utils.misc.gumbel_softmax", "torch.cat", "torch.cat.append", "E.mean", "logger.add_scalars", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.agents[].policy", "utils.misc.gumbel_softmax", "source", "source", "planning", "MSELoss.detach", "i_rews.detach"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", ")", ":", "\n", "        ", "obs", ",", "acs", ",", "rews", ",", "emps", ",", "next_obs", ",", "dones", "=", "sample", "\n", "\n", "self", ".", "transition_optimizer", ".", "zero_grad", "(", ")", "\n", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "acs", ")", ",", "dim", "=", "1", ")", "\n", "next_obs_pred", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "trans_loss", "=", "MSELoss", "(", "next_obs_pred", ",", "torch", ".", "cat", "(", "next_obs", ",", "dim", "=", "1", ")", ")", "\n", "trans_loss", ".", "backward", "(", ")", "\n", "self", ".", "transition_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "source_optimizer", ".", "zero_grad", "(", ")", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "source", ")", ":", "\n", "            ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "False", ")", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "", "prob_plan", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "            ", "length", "=", "no", ".", "shape", "[", "1", "]", "\n", "nno", "=", "trans_out", "[", ":", ",", "start", ":", "start", "+", "length", "]", "\n", "acs_pi", "=", "gumbel_softmax", "(", "self", ".", "agents", "[", "i", "]", ".", "policy", "(", "nno", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ",", "acs_pi", ")", ",", "dim", "=", "1", ")", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "False", ")", ")", "\n", "start", "+=", "length", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "-", "E", ".", "mean", "(", ")", "\n", "i_rews", ".", "backward", "(", ")", "\n", "self", ".", "source_optimizer", ".", "step", "(", ")", "\n", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'empowerment/losses'", ",", "\n", "{", "'trans_loss'", ":", "trans_loss", ".", "detach", "(", ")", ",", "\n", "'i_rews'", ":", "i_rews", ".", "detach", "(", ")", "}", ",", "\n", "self", ".", "niter", ")", "\n", "", "self", ".", "niter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.prepare_training": [[150, 169], ["variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.transition.train", "fn", "x.cuda", "x.cpu", "fn", "fn.train", "fn", "fn.train"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "prepare_training", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "transition", ".", "train", "(", ")", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "", "if", "not", "self", ".", "trans_dev", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "trans_dev", "=", "device", "\n", "", "if", "not", "self", ".", "source_dev", "==", "device", ":", "\n", "            ", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "source", ".", "train", "(", ")", "\n", "", "self", ".", "source_dev", "=", "device", "\n", "", "if", "not", "self", ".", "plan_dev", "==", "device", ":", "\n", "            ", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "planning", ".", "train", "(", ")", "\n", "", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi.prep_rollouts": [[170, 174], ["None"], "methods", ["None"], ["", "", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "trans_dev", "=", "device", "\n", "self", ".", "source_dev", "=", "device", "\n", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.__init__": [[177, 193], ["variational_empowerment.VariationalBaseEmpowerment.__init__", "utils.networks.MLPNetwork", "variational_transfer_single_action_pi_empowerment.ComputerTransferSingleActionPi", "variational_transfer_single_action_pi_empowerment.TrainerTransferSingleActionPi", "utils.networks.MLPNetwork", "utils.networks.MLPNetwork"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agents", ",", "init_params", ",", "num_in_trans", ",", "num_out_trans", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "\n", "convolutional", "=", "False", ")", ":", "\n", "        ", "super", "(", "VariationalTransferSingleActionPiEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "agents", "=", "agents", "\n", "self", ".", "transition", "=", "MLPNetwork", "(", "num_in_trans", ",", "num_out_trans", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "source", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_src'", "]", ",", "p", "[", "'num_out_src'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "self", ".", "planning", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_plan'", "]", ",", "p", "[", "'num_out_plan'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "\n", "self", ".", "lr", "=", "lr", "\n", "\n", "self", ".", "trans_dev", "=", "'cpu'", "# device for transition", "\n", "self", ".", "source_dev", "=", "'cpu'", "\n", "self", ".", "plan_dev", "=", "'cpu'", "\n", "\n", "self", ".", "computer", "=", "ComputerTransferSingleActionPi", "(", "self", ")", "\n", "self", ".", "trainer", "=", "TrainerTransferSingleActionPi", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.compute": [[194, 196], ["variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.computer.compute"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "return", "self", ".", "computer", ".", "compute", "(", "rewards", ",", "next_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.update": [[197, 199], ["variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.trainer.update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "trainer", ".", "update", "(", "sample", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.prep_training": [[200, 204], ["variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.computer.prepare_training", "variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.trainer.prepare_training", "variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.transition.train"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prepare_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prepare_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "prep_training", "(", "self", ",", "device", "=", "'gpu'", ")", ":", "\n", "        ", "self", ".", "computer", ".", "prepare_training", "(", "device", ")", "\n", "self", ".", "trainer", ".", "prepare_training", "(", "device", ")", "\n", "self", ".", "transition", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.prep_rollouts": [[205, 208], ["variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.computer.prep_rollouts", "variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.trainer.prep_rollouts"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts"], ["", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "computer", ".", "prep_rollouts", "(", ")", "\n", "self", ".", "trainer", ".", "prep_rollouts", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_single_action_pi_empowerment.VariationalTransferSingleActionPiEmpowerment.init": [[209, 243], ["enumerate", "cls", "zip", "init_params.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "@", "classmethod", "\n", "def", "init", "(", "cls", ",", "agents", ",", "env", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate instance of this class from multi-agent environment\n        \"\"\"", "\n", "init_params", "=", "[", "]", "\n", "\n", "num_in_transition", "=", "num_out_transition", "=", "0", "\n", "for", "i", ",", "(", "acsp", ",", "obsp", ")", "in", "enumerate", "(", "zip", "(", "env", ".", "action_space", ",", "env", ".", "observation_space", ")", ")", ":", "\n", "            ", "num_in_source", "=", "obsp", ".", "shape", "[", "0", "]", "\n", "num_out_source", "=", "acsp", ".", "n", "\n", "\n", "num_in_planning", "=", "2", "*", "obsp", ".", "shape", "[", "0", "]", "+", "acsp", ".", "n", "\n", "num_out_planning", "=", "acsp", ".", "n", "\n", "\n", "num_in_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "+", "acsp", ".", "n", "\n", "num_out_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "\n", "\n", "init_params", ".", "append", "(", "{", "'num_in_src'", ":", "num_in_source", ",", "\n", "'num_in_plan'", ":", "num_in_planning", ",", "\n", "'num_out_src'", ":", "num_out_source", ",", "\n", "'num_out_plan'", ":", "num_out_planning", "}", ")", "\n", "\n", "", "init_dict", "=", "{", "'agents'", ":", "agents", ",", "\n", "'lr'", ":", "lr", ",", "\n", "'hidden_dim'", ":", "hidden_dim", ",", "\n", "'init_params'", ":", "init_params", ",", "\n", "'num_in_trans'", ":", "num_in_transition", ",", "\n", "'num_out_trans'", ":", "num_out_transition", ",", "\n", "'recurrent'", ":", "recurrent", ",", "\n", "'convolutional'", ":", "convolutional", "}", "\n", "instance", "=", "cls", "(", "**", "init_dict", ")", "\n", "instance", ".", "init_dict", "=", "init_dict", "\n", "return", "instance", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.base_empowerment.BaseEmpowerment.__init__": [[2, 4], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.base_empowerment.BaseEmpowerment.compute": [[5, 7], ["None"], "methods", ["None"], ["", "def", "compute", "(", "self", ",", "reward", ",", "next_obs", ")", ":", "\n", "        ", "return", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.base_empowerment.BaseEmpowerment.update": [[8, 10], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.base_empowerment.BaseEmpowerment.prep_training": [[11, 13], ["None"], "methods", ["None"], ["", "def", "prep_training", "(", "self", ",", "device", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.base_empowerment.BaseEmpowerment.prep_rollouts": [[14, 16], ["None"], "methods", ["None"], ["", "def", "prep_rollouts", "(", "self", ",", "device", ")", ":", "\n", "        ", "pass", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.JointEmpowerment.__init__": [[11, 22], ["empowerment.BaseEmpowerment.__init__", "numpy.array", "numpy.all", "numpy.all", "len", "len", "numpy.unique"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agents", ")", ":", "\n", "        ", "super", "(", "JointEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "agents", "=", "agents", "\n", "self", ".", "cell_num", "=", "8", "\n", "self", ".", "cell_size", "=", ".5", "\n", "self", ".", "n_land", "=", "3", "\n", "self", ".", "moves", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", ".1", "]", ",", "[", "0", ",", "-", ".1", "]", ",", "\n", "[", ".1", ",", "0", "]", ",", "[", "-", ".1", ",", "0", "]", ",", "[", "0", ",", ".05", "]", ",", "\n", "[", "0", ",", "-", ".05", "]", ",", "[", ".05", ",", "0", "]", ",", "[", "-", ".05", ",", "0", "]", "]", ")", "\n", "\n", "self", ".", "not_in_collision", "=", "lambda", "x", ":", "(", "len", "(", "x", ")", "==", "len", "(", "np", ".", "unique", "(", "x", ")", ")", ")", "&", "np", ".", "all", "(", "x", "!=", "'inf'", ")", "&", "np", ".", "all", "(", "x", "!=", "'-inf'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.JointEmpowerment.get_grid_indices": [[23, 34], ["obs.reshape", "numpy.floor", "numpy.floor", "float", "float", "float", "float"], "methods", ["None"], ["", "def", "get_grid_indices", "(", "self", ",", "obs", ")", ":", "\n", "        ", "p_land", "=", "obs", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "other_px", ",", "other_py", "=", "p_land", "[", ":", ",", "0", "]", ",", "p_land", "[", ":", ",", "1", "]", "\n", "other_x_index", "=", "np", ".", "floor", "(", "other_px", "/", "self", ".", "cell_size", "+", "self", ".", "cell_num", "/", "2", ")", "\n", "other_y_index", "=", "np", ".", "floor", "(", "other_py", "/", "self", ".", "cell_size", "+", "self", ".", "cell_num", "/", "2", ")", "\n", "other_x_index", "[", "other_x_index", "<", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "other_x_index", "[", "other_x_index", ">=", "self", ".", "cell_num", "]", "=", "float", "(", "'-inf'", ")", "\n", "other_y_index", "[", "other_y_index", "<", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "other_y_index", "[", "other_y_index", ">=", "self", ".", "cell_num", "]", "=", "float", "(", "'-inf'", ")", "\n", "grid_indices", "=", "self", ".", "cell_num", "*", "other_y_index", "+", "other_x_index", "\n", "return", "grid_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.JointEmpowerment.compute": [[35, 49], ["len", "empowerment.JointEmpowerment.get_grid_indices", "numpy.unique", "numpy.repeat", "numpy.repeat", "empowerment.JointEmpowerment.reshape", "len", "pos_obs_ag.reshape", "empowerment.JointEmpowerment.moves.reshape", "numpy.apply_along_axis"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.get_grid_indices"], ["", "def", "compute", "(", "self", ",", "reward", ",", "next_obs", ")", ":", "\n", "        ", "n_moves", "=", "len", "(", "self", ".", "moves", ")", "\n", "\n", "# get positions", "\n", "pos_obs_ag", "=", "next_obs", "[", "0", ",", ":", ",", "2", ":", "2", "+", "2", "]", "\n", "\n", "# new positions", "\n", "batch_obs_ag", "=", "np", ".", "repeat", "(", "pos_obs_ag", ".", "reshape", "(", "1", ",", "self", ".", "n_land", ",", "2", ")", ",", "n_moves", ",", "axis", "=", "0", ")", "+", "np", ".", "repeat", "(", "\n", "self", ".", "moves", ".", "reshape", "(", "n_moves", ",", "1", ",", "2", ")", ",", "self", ".", "n_land", ",", "axis", "=", "1", ")", "\n", "\n", "encoded", "=", "self", ".", "get_grid_indices", "(", "batch_obs_ag", ")", "\n", "unique_config", "=", "np", ".", "unique", "(", "encoded", ".", "reshape", "(", "n_moves", ",", "self", ".", "n_land", ")", ",", "axis", "=", "0", ")", "\n", "new_unique_config", "=", "unique_config", "[", "np", ".", "apply_along_axis", "(", "self", ".", "not_in_collision", ",", "1", ",", "unique_config", ")", "]", "\n", "return", "len", "(", "new_unique_config", ")", "*", "reward", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.__init__": [[52, 68], ["empowerment.BaseEmpowerment.__init__", "numpy.array", "numpy.zeros", "numpy.repeat", "numpy.repeat", "numpy.expand_dims", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agents", ")", ":", "\n", "        ", "super", "(", "TransferEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "agents", "=", "agents", "\n", "self", ".", "n_channels", "=", "3", "\n", "self", ".", "n_land", "=", "3", "\n", "self", ".", "moves", "=", "np", ".", "array", "(", "[", "[", "0", ",", "0", "]", ",", "[", "0", ",", ".1", "]", ",", "[", "0", ",", "-", ".1", "]", ",", "\n", "[", ".1", ",", "0", "]", ",", "[", "-", ".1", ",", "0", "]", ",", "[", "0", ",", ".05", "]", ",", "\n", "[", "0", ",", "-", ".05", "]", ",", "[", ".05", ",", "0", "]", ",", "[", "-", ".05", ",", "0", "]", "]", ")", "\n", "\n", "self", ".", "messages", "=", "np", ".", "zeros", "(", "(", "self", ".", "n_channels", "+", "1", ",", "self", ".", "n_channels", ")", ")", "\n", "\n", "self", ".", "rep_rows", "=", "lambda", "x", ",", "n", ":", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "x", ",", "0", ")", ",", "n", ",", "0", ")", "\n", "self", ".", "rep_cols", "=", "lambda", "x", ",", "n", ":", "np", ".", "repeat", "(", "np", ".", "expand_dims", "(", "x", ",", "1", ")", ",", "n", ",", "1", ")", "\n", "\n", "self", ".", "cell_num", "=", "20", "\n", "self", ".", "cell_size", "=", ".1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.compute": [[69, 71], ["empowerment.TransferEmpowerment.empowerment_over_moves", "empowerment.TransferEmpowerment.empowerment_over_messages"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.empowerment_over_moves", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.empowerment_over_messages"], ["", "def", "compute", "(", "self", ",", "reward", ",", "next_obs", ")", ":", "\n", "        ", "return", "reward", "*", "(", "self", ".", "empowerment_over_moves", "(", "next_obs", ")", "+", "self", ".", "empowerment_over_messages", "(", "next_obs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.empowerment_over_moves": [[72, 101], ["len", "numpy.repeat", "cast", "empowerment.TransferEmpowerment.agents[].policy", "algorithms.maddpg.onehot_from_logits", "empowerment.TransferEmpowerment.get_grid_indices().reshape", "numpy.unique", "len", "torch.autograd.Variable", "pos_obs.reshape", "numpy.concatenate", "empowerment.TransferEmpowerment.rep_rows", "empowerment.TransferEmpowerment.rep_cols", "torch.Tensor", "land_pos.reshape", "empowerment.TransferEmpowerment.get_grid_indices", "algorithms.maddpg.onehot_from_logits.max"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.get_grid_indices"], ["", "def", "empowerment_over_moves", "(", "self", ",", "next_obs", ")", ":", "\n", "\n", "        ", "cast", "=", "lambda", "x", ":", "Variable", "(", "torch", ".", "Tensor", "(", "x", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "n_messages", "=", "len", "(", "self", ".", "messages", ")", "\n", "\n", "# filter out landmarks", "\n", "land_pos", "=", "next_obs", "[", ":", ",", "1", "]", "[", "0", "]", "[", "2", ":", "2", "+", "self", ".", "n_land", "*", "2", "]", "\n", "\n", "# filter out messages", "\n", "pos_obs", "=", "next_obs", "[", ":", ",", "1", "]", "[", "0", "]", "[", ":", "-", "self", ".", "n_channels", "]", "\n", "\n", "# create future configuratins", "\n", "batch_obs", "=", "np", ".", "repeat", "(", "pos_obs", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "n_messages", ",", "axis", "=", "0", ")", "\n", "torch_obs", "=", "cast", "(", "np", ".", "concatenate", "(", "(", "batch_obs", ",", "self", ".", "messages", ")", ",", "axis", "=", "1", ")", ")", "\n", "logits", "=", "self", ".", "agents", "[", "1", "]", ".", "policy", "(", "torch_obs", ")", "\n", "actions", "=", "onehot_from_logits", "(", "logits", ")", "\n", "moves", "=", "self", ".", "moves", "[", "actions", ".", "max", "(", "1", ")", "[", "1", "]", "]", "\n", "\n", "next_land_pos", "=", "self", ".", "rep_rows", "(", "land_pos", ".", "reshape", "(", "-", "1", ",", "2", ")", ",", "n_messages", ")", "-", "self", ".", "rep_cols", "(", "moves", ",", "self", ".", "n_land", ")", "\n", "\n", "next_grid_indices", "=", "self", ".", "get_grid_indices", "(", "next_land_pos", ")", ".", "reshape", "(", "n_messages", ",", "self", ".", "n_channels", ")", "\n", "assert", "next_grid_indices", ".", "shape", "[", "0", "]", "==", "next_land_pos", ".", "shape", "[", "0", "]", "\n", "\n", "# return unique set", "\n", "unique_config", "=", "np", ".", "unique", "(", "next_grid_indices", ",", "axis", "=", "0", ")", "\n", "assert", "unique_config", ".", "shape", "[", "1", "]", "==", "self", ".", "n_land", "\n", "\n", "return", "len", "(", "unique_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.empowerment_over_messages": [[102, 124], ["len", "numpy.repeat", "numpy.concatenate", "cast", "empowerment.TransferEmpowerment.agents[].policy", "algorithms.maddpg.onehot_from_logits", "numpy.unique", "len", "torch.autograd.Variable", "numpy.repeat", "pos_obs_target.reshape", "algorithms.maddpg.onehot_from_logits.max", "torch.Tensor", "pos_obs_ag.reshape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.onehot_from_logits"], ["", "def", "empowerment_over_messages", "(", "self", ",", "next_obs", ")", ":", "\n", "        ", "cast", "=", "lambda", "x", ":", "Variable", "(", "torch", ".", "Tensor", "(", "x", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "n_moves", "=", "len", "(", "self", ".", "moves", ")", "\n", "\n", "# get positions", "\n", "pos_obs_ag", "=", "next_obs", "[", ":", ",", "0", "]", "[", "0", "]", "[", "0", ":", "2", "]", "\n", "pos_obs_target", "=", "next_obs", "[", ":", ",", "0", "]", "[", "0", "]", "[", "2", ":", "]", "\n", "\n", "# new positions", "\n", "batch_obs_ag", "=", "np", ".", "repeat", "(", "pos_obs_ag", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "n_moves", ",", "axis", "=", "0", ")", "+", "self", ".", "moves", "\n", "batch_obs_target", "=", "np", ".", "repeat", "(", "pos_obs_target", ".", "reshape", "(", "1", ",", "-", "1", ")", ",", "n_moves", ",", "axis", "=", "0", ")", "\n", "batch_obs", "=", "np", ".", "concatenate", "(", "(", "batch_obs_ag", ",", "batch_obs_target", ")", ",", "axis", "=", "1", ")", "\n", "torch_obs", "=", "cast", "(", "batch_obs", ")", "\n", "\n", "# messages", "\n", "logits", "=", "self", ".", "agents", "[", "0", "]", ".", "policy", "(", "torch_obs", ")", "\n", "messages", "=", "onehot_from_logits", "(", "logits", ")", "\n", "\n", "encoded", "=", "messages", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "unique_config", "=", "np", ".", "unique", "(", "encoded", ",", "axis", "=", "0", ")", "\n", "return", "len", "(", "unique_config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.empowerment.TransferEmpowerment.get_grid_indices": [[125, 136], ["obs.reshape", "numpy.floor", "numpy.floor", "float", "float", "float", "float"], "methods", ["None"], ["", "def", "get_grid_indices", "(", "self", ",", "obs", ")", ":", "\n", "        ", "p_land", "=", "obs", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "other_px", ",", "other_py", "=", "p_land", "[", ":", ",", "0", "]", ",", "p_land", "[", ":", ",", "1", "]", "\n", "other_x_index", "=", "np", ".", "floor", "(", "other_px", "/", "self", ".", "cell_size", "+", "self", ".", "cell_num", "/", "2", ")", "\n", "other_y_index", "=", "np", ".", "floor", "(", "other_py", "/", "self", ".", "cell_size", "+", "self", ".", "cell_num", "/", "2", ")", "\n", "other_x_index", "[", "other_x_index", "<", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "other_x_index", "[", "other_x_index", ">=", "self", ".", "cell_num", "]", "=", "float", "(", "'-inf'", ")", "\n", "other_y_index", "[", "other_y_index", "<", "0", "]", "=", "float", "(", "'-inf'", ")", "\n", "other_y_index", "[", "other_y_index", ">=", "self", ".", "cell_num", "]", "=", "float", "(", "'-inf'", ")", "\n", "grid_indices", "=", "self", ".", "cell_num", "*", "other_y_index", "+", "other_x_index", "\n", "return", "grid_indices", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.__init__": [[15, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "device", "=", "empowerment", ".", "device", "\n", "self", ".", "agents", "=", "empowerment", ".", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.compute": [[22, 50], ["zip", "torch.cat", "variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.transition", "enumerate", "torch.cat", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "numpy.cumsum().tolist", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat.append", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "zip", "torch.cat.append", "utils.misc.gumbel_softmax", "source", "source", "numpy.cumsum", "utils.misc.gumbel_softmax", "planning", "variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.device.get_device", "variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.device.get_device", "variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.agents[].policy", "variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.device.get_device", "variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi.device.get_device"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "compute", "(", "self", ",", "next_obs", ")", ":", "\n", "        ", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "source", ")", ":", "\n", "            ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "\n", "", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "prob_plan", "=", "[", "]", "\n", "end_idx", "=", "[", "0", "]", "+", "np", ".", "cumsum", "(", "[", "ne_ob", ".", "shape", "[", "1", "]", "for", "ne_ob", "in", "next_obs", "]", ")", ".", "tolist", "(", ")", "\n", "start_end", "=", "[", "(", "start", ",", "end", ")", "for", "start", ",", "end", "in", "zip", "(", "end_idx", ",", "end_idx", "[", "1", ":", "]", ")", "]", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "            ", "nno", "=", "trans_out", "[", ":", ",", "start_end", "[", "i", "]", "[", "0", "]", ":", "start_end", "[", "i", "]", "[", "1", "]", "]", "\n", "acs_", "=", "[", "]", "\n", "for", "j", ",", "ac", "in", "enumerate", "(", "acs_src", ")", ":", "\n", "                ", "if", "j", "==", "i", ":", "continue", "\n", "nno_other", "=", "trans_out", "[", ":", ",", "start_end", "[", "j", "]", "[", "0", "]", ":", "start_end", "[", "j", "]", "[", "1", "]", "]", "\n", "acs_", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "agents", "[", "j", "]", ".", "policy", "(", "nno_other", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "True", ")", ")", "\n", "", "acs_", "=", "torch", ".", "cat", "(", "acs_", ",", "dim", "=", "1", ")", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ",", "acs_", ")", ",", "dim", "=", "1", ")", "\n", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "return", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.__init__": [[53, 69], ["torch.optim.Adam", "flatten", "torch.optim.Adam", "flatten", "flatten", "torch.optim.Adam", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.transition.parameters", "list", "list", "mlp.parameters", "mlp.parameters", "list", "list", "a.policy.parameters", "a.critic.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "device", "=", "empowerment", ".", "device", "\n", "self", ".", "agents", "=", "empowerment", ".", "agents", "\n", "self", ".", "computer", "=", "empowerment", ".", "computer", "\n", "\n", "self", ".", "transition_optimizer", "=", "Adam", "(", "self", ".", "transition", ".", "parameters", "(", ")", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "flatten", "=", "lambda", "l", ":", "[", "item", "for", "sublist", "in", "l", "for", "item", "in", "sublist", "]", "\n", "params_planning", "=", "flatten", "(", "[", "list", "(", "(", "mlp", ".", "parameters", "(", ")", ")", ")", "for", "mlp", "in", "self", ".", "planning", "]", ")", "\n", "self", ".", "planning_optimizer", "=", "Adam", "(", "params_planning", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "params_source", "=", "flatten", "(", "[", "list", "(", "(", "mlp", ".", "parameters", "(", ")", ")", ")", "for", "mlp", "in", "self", ".", "source", "]", ")", "\n", "params_agents", "=", "flatten", "(", "[", "list", "(", "a", ".", "policy", ".", "parameters", "(", ")", ")", "+", "list", "(", "a", ".", "critic", ".", "parameters", "(", ")", ")", "for", "a", "in", "self", ".", "agents", "]", ")", "\n", "self", ".", "source_optimizer", "=", "Adam", "(", "params_source", "+", "params_planning", "+", "params_agents", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "self", ".", "niter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.update": [[70, 92], ["variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.transition_optimizer.zero_grad", "torch.cat", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.transition", "MSELoss", "MSELoss.backward", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.transition_optimizer.step", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.source_optimizer.zero_grad", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.computer.compute", "i_rews.backward", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.source_optimizer.step", "torch.cat", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi.mean", "logger.add_scalars", "MSELoss.detach", "i_rews.detach"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", ")", ":", "\n", "        ", "obs", ",", "acs", ",", "rews", ",", "emps", ",", "next_obs", ",", "dones", "=", "sample", "\n", "\n", "self", ".", "transition_optimizer", ".", "zero_grad", "(", ")", "\n", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "acs", ")", ",", "dim", "=", "1", ")", "\n", "next_obs_pred", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "trans_loss", "=", "MSELoss", "(", "next_obs_pred", ",", "torch", ".", "cat", "(", "next_obs", ",", "dim", "=", "1", ")", ")", "\n", "trans_loss", ".", "backward", "(", ")", "\n", "self", ".", "transition_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "source_optimizer", ".", "zero_grad", "(", ")", "\n", "E", "=", "self", ".", "computer", ".", "compute", "(", "next_obs", ")", "\n", "i_rews", "=", "-", "E", ".", "mean", "(", ")", "\n", "i_rews", ".", "backward", "(", ")", "\n", "self", ".", "source_optimizer", ".", "step", "(", ")", "\n", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'empowerment/losses'", ",", "\n", "{", "'trans_loss'", ":", "trans_loss", ".", "detach", "(", ")", ",", "\n", "'i_rews'", ":", "i_rews", ".", "detach", "(", ")", "}", ",", "\n", "self", ".", "niter", ")", "\n", "", "self", ".", "niter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.__init__": [[95, 108], ["empowerment.variational_empowerment.VariationalBaseEmpowerment.__init__", "utils.networks.MLPNetwork", "empowerment.device.Device", "variational_transfer_all_action_pi_empowerment.ComputerTransferAllActionPi", "variational_transfer_all_action_pi_empowerment.TrainerTransferAllActionPi", "utils.networks.MLPNetwork", "utils.networks.MLPNetwork"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agents", ",", "init_params", ",", "num_in_trans", ",", "num_out_trans", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "\n", "convolutional", "=", "False", ")", ":", "\n", "        ", "super", "(", "VariationalTransferAllActionPiEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "agents", "=", "agents", "\n", "self", ".", "transition", "=", "MLPNetwork", "(", "num_in_trans", ",", "num_out_trans", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "source", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_src'", "]", ",", "p", "[", "'num_out_src'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "self", ".", "planning", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_plan'", "]", ",", "p", "[", "'num_out_plan'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "\n", "self", ".", "lr", "=", "lr", "\n", "\n", "self", ".", "device", "=", "Device", "(", "'cpu'", ")", "\n", "self", ".", "computer", "=", "ComputerTransferAllActionPi", "(", "self", ")", "\n", "self", ".", "trainer", "=", "TrainerTransferAllActionPi", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.compute": [[109, 115], ["variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.computer.compute", "i_rews.detach().numpy", "torch.autograd.Variable", "variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.mean", "torch.ones", "torch.Tensor", "range", "i_rews.detach", "numpy.vstack"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "next_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "vstack", "(", "next_obs", "[", ":", ",", "i", "]", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "for", "i", "in", "range", "(", "next_obs", ".", "shape", "[", "1", "]", ")", "]", "\n", "E", "=", "self", ".", "computer", ".", "compute", "(", "next_obs", ")", "\n", "i_rews", "=", "E", ".", "mean", "(", ")", "*", "torch", ".", "ones", "(", "(", "1", ",", "rewards", ".", "shape", "[", "1", "]", ")", ")", "\n", "return", "i_rews", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.update": [[116, 118], ["variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.trainer.update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", "=", "None", ")", ":", "\n", "        ", "self", ".", "trainer", ".", "update", "(", "sample", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.prep_training": [[119, 138], ["variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.transition.train", "variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.device.set_device", "fn.train", "fn.train", "fn", "x.cuda", "x.cpu", "variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.device.get_device", "fn", "fn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.set_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "prep_training", "(", "self", ",", "device", "=", "'gpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "train", "(", ")", "\n", "for", "source", "in", "self", ".", "source", ":", "\n", "            ", "source", ".", "train", "(", ")", "\n", "", "for", "planning", "in", "self", ".", "planning", ":", "\n", "            ", "planning", ".", "train", "(", ")", "\n", "\n", "", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "", "if", "not", "self", ".", "device", ".", "get_device", "(", ")", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "\n", "", "", "self", ".", "device", ".", "set_device", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.prep_rollouts": [[139, 159], ["variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.transition.eval", "variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.device.set_device", "fn.eval", "fn.eval", "fn", "x.cuda", "x.cpu", "variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.device.get_device", "fn", "fn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.set_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "eval", "(", ")", "\n", "for", "planning", "in", "self", ".", "planning", ":", "\n", "            ", "planning", ".", "eval", "(", ")", "\n", "", "for", "source", "in", "self", ".", "source", ":", "\n", "            ", "source", ".", "eval", "(", ")", "\n", "\n", "", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "# only need main policy for rollouts", "\n", "", "if", "not", "self", ".", "device", ".", "get_device", "(", ")", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "\n", "", "", "self", ".", "device", ".", "set_device", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_all_action_pi_empowerment.VariationalTransferAllActionPiEmpowerment.init": [[160, 196], ["enumerate", "cls", "zip", "enumerate", "init_params.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "@", "classmethod", "\n", "def", "init", "(", "cls", ",", "agents", ",", "env", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate instance of this class from multi-agent environment\n        \"\"\"", "\n", "init_params", "=", "[", "]", "\n", "\n", "num_in_transition", "=", "num_out_transition", "=", "0", "\n", "for", "i", ",", "(", "acsp", ",", "obsp", ")", "in", "enumerate", "(", "zip", "(", "env", ".", "action_space", ",", "env", ".", "observation_space", ")", ")", ":", "\n", "            ", "num_in_source", "=", "obsp", ".", "shape", "[", "0", "]", "\n", "num_out_source", "=", "acsp", ".", "n", "\n", "\n", "num_in_planning", "=", "2", "*", "obsp", ".", "shape", "[", "0", "]", "\n", "for", "j", ",", "acsp_j", "in", "enumerate", "(", "env", ".", "action_space", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "num_in_planning", "+=", "acsp_j", ".", "n", "\n", "", "num_out_planning", "=", "acsp", ".", "n", "\n", "\n", "num_in_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "+", "acsp", ".", "n", "\n", "num_out_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "\n", "\n", "init_params", ".", "append", "(", "{", "'num_in_src'", ":", "num_in_source", ",", "\n", "'num_in_plan'", ":", "num_in_planning", ",", "\n", "'num_out_src'", ":", "num_out_source", ",", "\n", "'num_out_plan'", ":", "num_out_planning", "}", ")", "\n", "\n", "", "init_dict", "=", "{", "'agents'", ":", "agents", ",", "\n", "'lr'", ":", "lr", ",", "\n", "'hidden_dim'", ":", "hidden_dim", ",", "\n", "'init_params'", ":", "init_params", ",", "\n", "'num_in_trans'", ":", "num_in_transition", ",", "\n", "'num_out_trans'", ":", "num_out_transition", ",", "\n", "'recurrent'", ":", "recurrent", ",", "\n", "'convolutional'", ":", "convolutional", "}", "\n", "instance", "=", "cls", "(", "**", "init_dict", ")", "\n", "instance", ".", "init_dict", "=", "init_dict", "\n", "return", "instance", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.ComputerTransfer.__init__": [[14, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "plan_dev", "=", "empowerment", ".", "plan_dev", "\n", "self", ".", "source_dev", "=", "empowerment", ".", "source_dev", "\n", "self", ".", "trans_dev", "=", "empowerment", ".", "trans_dev", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.ComputerTransfer.compute": [[22, 49], ["torch.no_grad", "zip", "torch.cat", "variational_transfer_empowerment.ComputerTransfer.transition", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.numpy", "torch.autograd.Variable", "torch.cat.append", "torch.cat.append", "zip", "torch.cat", "torch.cat.append", "E.mean", "torch.ones", "torch.Tensor", "range", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "numpy.vstack", "source", "source", "planning"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "next_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "vstack", "(", "next_obs", "[", ":", ",", "i", "]", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "for", "i", "in", "range", "(", "rewards", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "source", ")", ":", "\n", "                ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "False", ")", ")", "\n", "\n", "", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "prob_plan", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "                ", "length", "=", "no", ".", "shape", "[", "1", "]", "\n", "nno", "=", "trans_out", "[", ":", ",", "start", ":", "start", "+", "length", "]", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ")", ",", "dim", "=", "1", ")", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "False", ")", ")", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "E", ".", "mean", "(", ")", "*", "torch", ".", "ones", "(", "(", "1", ",", "rewards", ".", "shape", "[", "1", "]", ")", ")", "\n", "return", "i_rews", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.ComputerTransfer.prep_rollouts": [[50, 73], ["variational_transfer_empowerment.ComputerTransfer.transition.eval", "variational_transfer_empowerment.ComputerTransfer.transition.eval", "fn", "fn.eval", "fn.eval", "x.cuda", "x.cpu", "fn", "fn"], "methods", ["None"], ["", "", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "eval", "(", ")", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "# only need main policy for rollouts", "\n", "", "if", "not", "self", ".", "trans_dev", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "trans_dev", "=", "device", "\n", "", "self", ".", "transition", ".", "eval", "(", ")", "\n", "if", "not", "self", ".", "source_dev", "==", "device", ":", "\n", "            ", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "", "self", ".", "source_dev", "=", "device", "\n", "", "for", "source", "in", "self", ".", "source", ":", "\n", "            ", "source", ".", "eval", "(", ")", "\n", "", "if", "not", "self", ".", "plan_dev", "==", "device", ":", "\n", "            ", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "", "self", ".", "plan_dev", "=", "device", "\n", "", "for", "planning", "in", "self", ".", "planning", ":", "\n", "            ", "planning", ".", "eval", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.ComputerTransfer.prepare_training": [[74, 78], ["None"], "methods", ["None"], ["", "", "def", "prepare_training", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "trans_dev", "=", "device", "\n", "self", ".", "source_dev", "=", "device", "\n", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.__init__": [[81, 97], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "variational_transfer_empowerment.TrainerTransfer.transition.parameters", "list", "list", "mlp.parameters", "mlp.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "empowerment", ".", "transition", "\n", "self", ".", "source", "=", "empowerment", ".", "source", "\n", "self", ".", "planning", "=", "empowerment", ".", "planning", "\n", "self", ".", "plan_dev", "=", "empowerment", ".", "plan_dev", "\n", "self", ".", "source_dev", "=", "empowerment", ".", "source_dev", "\n", "self", ".", "trans_dev", "=", "empowerment", ".", "trans_dev", "\n", "\n", "self", ".", "transition_optimizer", "=", "Adam", "(", "self", ".", "transition", ".", "parameters", "(", ")", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "params_planning", "=", "[", "]", "\n", "for", "mlp", "in", "self", ".", "planning", ":", "params_planning", "+=", "list", "(", "mlp", ".", "parameters", "(", ")", ")", "\n", "self", ".", "planning_optimizer", "=", "Adam", "(", "params_planning", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "params_source", "=", "[", "]", "\n", "for", "mlp", "in", "self", ".", "source", ":", "params_source", "+=", "list", "(", "mlp", ".", "parameters", "(", ")", ")", "\n", "self", ".", "source_optimizer", "=", "Adam", "(", "params_source", "+", "params_planning", ",", "lr", "=", "empowerment", ".", "lr", ")", "\n", "self", ".", "niter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.update": [[98, 152], ["variational_transfer_empowerment.TrainerTransfer.transition_optimizer.zero_grad", "torch.cat", "variational_transfer_empowerment.TrainerTransfer.transition", "MSELoss", "MSELoss.backward", "variational_transfer_empowerment.TrainerTransfer.transition_optimizer.step", "variational_transfer_empowerment.TrainerTransfer.planning_optimizer.zero_grad", "zip", "torch.cat", "torch.cat", "MSELoss", "MSELoss.backward", "variational_transfer_empowerment.TrainerTransfer.planning_optimizer.step", "variational_transfer_empowerment.TrainerTransfer.source_optimizer.zero_grad", "zip", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.backward", "variational_transfer_empowerment.TrainerTransfer.source_optimizer.step", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.cat", "variational_transfer_empowerment.TrainerTransfer.transition", "zip", "torch.cat", "torch.cat.append", "E.mean", "logger.add_scalars", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "planning", "source", "source", "planning", "MSELoss.detach", "MSELoss.detach", "i_rews.detach"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", ")", ":", "\n", "        ", "obs", ",", "acs", ",", "rews", ",", "emps", ",", "next_obs", ",", "dones", "=", "sample", "\n", "\n", "self", ".", "transition_optimizer", ".", "zero_grad", "(", ")", "\n", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "acs", ")", ",", "dim", "=", "1", ")", "\n", "next_obs_pred", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "trans_loss", "=", "MSELoss", "(", "next_obs_pred", ",", "torch", ".", "cat", "(", "next_obs", ",", "dim", "=", "1", ")", ")", "\n", "trans_loss", ".", "backward", "(", ")", "\n", "self", ".", "transition_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "planning_optimizer", ".", "zero_grad", "(", ")", "\n", "acs_plan", "=", "[", "]", "\n", "for", "o", ",", "no", ",", "planning", "in", "zip", "(", "obs", ",", "next_obs", ",", "self", ".", "planning", ")", ":", "\n", "            ", "plan_in", "=", "torch", ".", "cat", "(", "(", "o", ",", "no", ")", ",", "dim", "=", "1", ")", "\n", "acs_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "True", ")", ")", "\n", "", "acs_plan", "=", "torch", ".", "cat", "(", "acs_plan", ",", "dim", "=", "1", ")", "\n", "acs_torch", "=", "torch", ".", "cat", "(", "acs", ",", "dim", "=", "1", ")", "\n", "plan_loss", "=", "MSELoss", "(", "acs_plan", ",", "acs_torch", ")", "\n", "plan_loss", ".", "backward", "(", ")", "\n", "self", ".", "planning_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "source_optimizer", ".", "zero_grad", "(", ")", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", ",", "source", "in", "zip", "(", "next_obs", ",", "self", ".", "source", ")", ":", "\n", "            ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "source", "(", "no", ")", ",", "device", "=", "self", ".", "source_dev", ",", "hard", "=", "False", ")", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "", "prob_plan", "=", "[", "]", "\n", "start", "=", "0", "\n", "for", "i", ",", "(", "no", ",", "planning", ")", "in", "enumerate", "(", "zip", "(", "next_obs", ",", "self", ".", "planning", ")", ")", ":", "\n", "            ", "length", "=", "no", ".", "shape", "[", "1", "]", "\n", "nno", "=", "trans_out", "[", ":", ",", "start", ":", "start", "+", "length", "]", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ")", ",", "dim", "=", "1", ")", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "plan_dev", ",", "hard", "=", "False", ")", ")", "\n", "start", "+=", "length", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "-", "E", ".", "mean", "(", ")", "\n", "i_rews", ".", "backward", "(", ")", "\n", "self", ".", "source_optimizer", ".", "step", "(", ")", "\n", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'empowerment/losses'", ",", "\n", "{", "'trans_loss'", ":", "trans_loss", ".", "detach", "(", ")", ",", "\n", "'plan_loss'", ":", "plan_loss", ".", "detach", "(", ")", ",", "\n", "'i_rews'", ":", "i_rews", ".", "detach", "(", ")", "}", ",", "\n", "self", ".", "niter", ")", "\n", "", "self", ".", "niter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prepare_training": [[153, 172], ["variational_transfer_empowerment.TrainerTransfer.transition.train", "fn", "x.cuda", "x.cpu", "fn", "fn.train", "fn", "fn.train"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "prepare_training", "(", "self", ",", "device", ")", ":", "\n", "        ", "self", ".", "transition", ".", "train", "(", ")", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "", "if", "not", "self", ".", "trans_dev", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "trans_dev", "=", "device", "\n", "", "if", "not", "self", ".", "source_dev", "==", "device", ":", "\n", "            ", "for", "source", "in", "self", ".", "source", ":", "\n", "                ", "source", "=", "fn", "(", "source", ")", "\n", "source", ".", "train", "(", ")", "\n", "", "self", ".", "source_dev", "=", "device", "\n", "", "if", "not", "self", ".", "plan_dev", "==", "device", ":", "\n", "            ", "for", "planning", "in", "self", ".", "planning", ":", "\n", "                ", "planning", "=", "fn", "(", "planning", ")", "\n", "planning", ".", "train", "(", ")", "\n", "", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prep_rollouts": [[173, 177], ["None"], "methods", ["None"], ["", "", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "trans_dev", "=", "device", "\n", "self", ".", "source_dev", "=", "device", "\n", "self", ".", "plan_dev", "=", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.VariationalTransferEmpowerment.__init__": [[180, 195], ["variational_empowerment.VariationalBaseEmpowerment.__init__", "utils.networks.MLPNetwork", "variational_transfer_empowerment.ComputerTransfer", "variational_transfer_empowerment.TrainerTransfer", "utils.networks.MLPNetwork", "utils.networks.MLPNetwork"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "init_params", ",", "num_in_trans", ",", "num_out_trans", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "\n", "convolutional", "=", "False", ")", ":", "\n", "        ", "super", "(", "VariationalTransferEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transition", "=", "MLPNetwork", "(", "num_in_trans", ",", "num_out_trans", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "source", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_src'", "]", ",", "p", "[", "'num_out_src'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "self", ".", "planning", "=", "[", "MLPNetwork", "(", "p", "[", "'num_in_plan'", "]", ",", "p", "[", "'num_out_plan'", "]", ",", "recurrent", "=", "True", ")", "for", "p", "in", "init_params", "]", "\n", "\n", "self", ".", "lr", "=", "lr", "\n", "\n", "self", ".", "trans_dev", "=", "'cpu'", "# device for transition", "\n", "self", ".", "source_dev", "=", "'cpu'", "\n", "self", ".", "plan_dev", "=", "'cpu'", "\n", "\n", "self", ".", "computer", "=", "ComputerTransfer", "(", "self", ")", "\n", "self", ".", "trainer", "=", "TrainerTransfer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.VariationalTransferEmpowerment.compute": [[196, 198], ["variational_transfer_empowerment.VariationalTransferEmpowerment.computer.compute"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "return", "self", ".", "computer", ".", "compute", "(", "rewards", ",", "next_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.VariationalTransferEmpowerment.update": [[199, 201], ["variational_transfer_empowerment.VariationalTransferEmpowerment.trainer.update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "trainer", ".", "update", "(", "sample", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.VariationalTransferEmpowerment.prep_training": [[202, 206], ["variational_transfer_empowerment.VariationalTransferEmpowerment.computer.prepare_training", "variational_transfer_empowerment.VariationalTransferEmpowerment.trainer.prepare_training", "variational_transfer_empowerment.VariationalTransferEmpowerment.transition.train"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prepare_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.TrainerTransfer.prepare_training", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "prep_training", "(", "self", ",", "device", "=", "'gpu'", ")", ":", "\n", "        ", "self", ".", "computer", ".", "prepare_training", "(", "device", ")", "\n", "self", ".", "trainer", ".", "prepare_training", "(", "device", ")", "\n", "self", ".", "transition", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.VariationalTransferEmpowerment.prep_rollouts": [[207, 210], ["variational_transfer_empowerment.VariationalTransferEmpowerment.computer.prep_rollouts", "variational_transfer_empowerment.VariationalTransferEmpowerment.trainer.prep_rollouts"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts"], ["", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "computer", ".", "prep_rollouts", "(", ")", "\n", "self", ".", "trainer", ".", "prep_rollouts", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_transfer_empowerment.VariationalTransferEmpowerment.init_from_env": [[211, 244], ["zip", "cls", "init_params.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "@", "classmethod", "\n", "def", "init_from_env", "(", "cls", ",", "env", ",", "lr", "=", "0.01", ",", "hidden_dim", "=", "64", ",", "recurrent", "=", "False", ",", "convolutional", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate instance of this class from multi-agent environment\n        \"\"\"", "\n", "init_params", "=", "[", "]", "\n", "\n", "num_in_transition", "=", "num_out_transition", "=", "0", "\n", "for", "acsp", ",", "obsp", "in", "zip", "(", "env", ".", "action_space", ",", "env", ".", "observation_space", ")", ":", "\n", "            ", "num_in_source", "=", "obsp", ".", "shape", "[", "0", "]", "\n", "num_out_source", "=", "acsp", ".", "n", "\n", "\n", "num_in_planning", "=", "2", "*", "obsp", ".", "shape", "[", "0", "]", "\n", "num_out_planning", "=", "acsp", ".", "n", "\n", "\n", "num_in_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "+", "acsp", ".", "n", "\n", "num_out_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "\n", "\n", "init_params", ".", "append", "(", "{", "'num_in_src'", ":", "num_in_source", ",", "\n", "'num_in_plan'", ":", "num_in_planning", ",", "\n", "'num_out_src'", ":", "num_out_source", ",", "\n", "'num_out_plan'", ":", "num_out_planning", "}", ")", "\n", "\n", "", "init_dict", "=", "{", "'lr'", ":", "lr", ",", "\n", "'hidden_dim'", ":", "hidden_dim", ",", "\n", "'init_params'", ":", "init_params", ",", "\n", "'num_in_trans'", ":", "num_in_transition", ",", "\n", "'num_out_trans'", ":", "num_out_transition", ",", "\n", "'recurrent'", ":", "recurrent", ",", "\n", "'convolutional'", ":", "convolutional", "}", "\n", "instance", "=", "cls", "(", "**", "init_dict", ")", "\n", "instance", ".", "init_dict", "=", "init_dict", "\n", "return", "instance", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.ComputerJoint.__init__": [[15, 21], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "variational_joint_empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "variational_joint_empowerment", ".", "transition", "\n", "self", ".", "source", "=", "variational_joint_empowerment", ".", "source", "\n", "self", ".", "planning", "=", "variational_joint_empowerment", ".", "planning", "\n", "\n", "self", ".", "device", "=", "variational_joint_empowerment", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.ComputerJoint.compute": [[22, 48], ["torch.no_grad", "torch.cat", "variational_joint_empowerment.ComputerJoint.transition", "len", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.numpy", "torch.autograd.Variable", "torch.cat.append", "torch.cat.append", "torch.cat", "torch.cat.append", "E.mean", "torch.ones", "torch.Tensor", "range", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "numpy.vstack", "variational_joint_empowerment.ComputerJoint.source", "variational_joint_empowerment.ComputerJoint.source", "variational_joint_empowerment.ComputerJoint.planning", "variational_joint_empowerment.ComputerJoint.device.get_device", "variational_joint_empowerment.ComputerJoint.device.get_device", "variational_joint_empowerment.ComputerJoint.device.get_device"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "next_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "np", ".", "vstack", "(", "next_obs", "[", ":", ",", "i", "]", ")", ")", ",", "\n", "requires_grad", "=", "False", ")", "for", "i", "in", "range", "(", "rewards", ".", "shape", "[", "1", "]", ")", "]", "\n", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", "in", "next_obs", ":", "\n", "                ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "source", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "source", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "\n", "", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "prob_plan", "=", "[", "]", "\n", "n_obs", "=", "len", "(", "next_obs", "[", "0", "]", "[", "0", "]", ")", "\n", "for", "i", ",", "no", "in", "enumerate", "(", "next_obs", ")", ":", "\n", "                ", "nno", "=", "trans_out", "[", ":", ",", "i", "*", "n_obs", ":", "(", "i", "+", "1", ")", "*", "n_obs", "]", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ")", ",", "dim", "=", "1", ")", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "E", ".", "mean", "(", ")", "*", "torch", ".", "ones", "(", "(", "1", ",", "rewards", ".", "shape", "[", "1", "]", ")", ")", "\n", "return", "i_rews", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.TrainerJoint.__init__": [[51, 62], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "variational_joint_empowerment.TrainerJoint.transition.parameters", "variational_joint_empowerment.TrainerJoint.planning.parameters", "list", "list", "variational_joint_empowerment.TrainerJoint.source.parameters", "variational_joint_empowerment.TrainerJoint.planning.parameters"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "variational_joint_empowerment", ")", ":", "\n", "        ", "self", ".", "transition", "=", "variational_joint_empowerment", ".", "transition", "\n", "self", ".", "source", "=", "variational_joint_empowerment", ".", "source", "\n", "self", ".", "planning", "=", "variational_joint_empowerment", ".", "planning", "\n", "self", ".", "device", "=", "variational_joint_empowerment", ".", "device", "\n", "\n", "self", ".", "transition_optimizer", "=", "Adam", "(", "self", ".", "transition", ".", "parameters", "(", ")", ",", "lr", "=", "variational_joint_empowerment", ".", "lr", ")", "\n", "self", ".", "planning_optimizer", "=", "Adam", "(", "self", ".", "planning", ".", "parameters", "(", ")", ",", "lr", "=", "variational_joint_empowerment", ".", "lr", ")", "\n", "self", ".", "source_optimizer", "=", "Adam", "(", "list", "(", "self", ".", "source", ".", "parameters", "(", ")", ")", "+", "list", "(", "self", ".", "planning", ".", "parameters", "(", ")", ")", ",", "lr", "=", "variational_joint_empowerment", ".", "lr", ")", "\n", "\n", "self", ".", "niter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.TrainerJoint.update": [[63, 115], ["variational_joint_empowerment.TrainerJoint.transition_optimizer.zero_grad", "torch.cat", "variational_joint_empowerment.TrainerJoint.transition", "MSELoss", "MSELoss.backward", "variational_joint_empowerment.TrainerJoint.transition_optimizer.step", "variational_joint_empowerment.TrainerJoint.planning_optimizer.zero_grad", "zip", "torch.cat", "torch.cat", "MSELoss", "MSELoss.backward", "variational_joint_empowerment.TrainerJoint.planning_optimizer.step", "variational_joint_empowerment.TrainerJoint.source_optimizer.zero_grad", "len", "enumerate", "torch.cat", "torch.cat", "torch.cat", "i_rews.backward", "variational_joint_empowerment.TrainerJoint.source_optimizer.step", "torch.cat", "torch.cat", "torch.cat.append", "torch.cat.append", "torch.cat.append", "torch.no_grad", "torch.cat", "variational_joint_empowerment.TrainerJoint.transition", "torch.cat", "torch.cat.append", "E.mean", "logger.add_scalars", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "utils.misc.gumbel_softmax", "variational_joint_empowerment.TrainerJoint.planning", "variational_joint_empowerment.TrainerJoint.source", "variational_joint_empowerment.TrainerJoint.source", "variational_joint_empowerment.TrainerJoint.planning", "MSELoss.detach", "MSELoss.detach", "i_rews.detach", "variational_joint_empowerment.TrainerJoint.device.get_device", "variational_joint_empowerment.TrainerJoint.device.get_device", "variational_joint_empowerment.TrainerJoint.device.get_device", "variational_joint_empowerment.TrainerJoint.device.get_device"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.utils.misc.gumbel_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", ")", ":", "\n", "        ", "obs", ",", "acs", ",", "rews", ",", "emps", ",", "next_obs", ",", "dones", "=", "sample", "\n", "\n", "self", ".", "transition_optimizer", ".", "zero_grad", "(", ")", "\n", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "obs", ",", "*", "acs", ")", ",", "dim", "=", "1", ")", "\n", "next_obs_pred", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "trans_loss", "=", "MSELoss", "(", "next_obs_pred", ",", "torch", ".", "cat", "(", "next_obs", ",", "dim", "=", "1", ")", ")", "\n", "trans_loss", ".", "backward", "(", ")", "\n", "self", ".", "transition_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "planning_optimizer", ".", "zero_grad", "(", ")", "\n", "acs_plan", "=", "[", "]", "\n", "for", "o", ",", "no", "in", "zip", "(", "obs", ",", "next_obs", ")", ":", "\n", "            ", "plan_in", "=", "torch", ".", "cat", "(", "(", "o", ",", "no", ")", ",", "dim", "=", "1", ")", "\n", "acs_plan", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "True", ")", ")", "\n", "", "acs_plan", "=", "torch", ".", "cat", "(", "acs_plan", ",", "dim", "=", "1", ")", "\n", "acs_torch", "=", "torch", ".", "cat", "(", "acs", ",", "dim", "=", "1", ")", "\n", "plan_loss", "=", "MSELoss", "(", "acs_plan", ",", "acs_torch", ")", "\n", "plan_loss", ".", "backward", "(", ")", "\n", "self", ".", "planning_optimizer", ".", "step", "(", ")", "\n", "\n", "self", ".", "source_optimizer", ".", "zero_grad", "(", ")", "\n", "acs_src", "=", "[", "]", "\n", "prob_src", "=", "[", "]", "\n", "for", "no", "in", "next_obs", ":", "\n", "            ", "acs_src", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "source", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "True", ")", ")", "\n", "prob_src", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "source", "(", "no", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "trans_in", "=", "torch", ".", "cat", "(", "(", "*", "next_obs", ",", "*", "acs_src", ")", ",", "dim", "=", "1", ")", "\n", "trans_out", "=", "self", ".", "transition", "(", "trans_in", ")", "\n", "", "prob_plan", "=", "[", "]", "\n", "n_obs", "=", "len", "(", "next_obs", "[", "0", "]", "[", "0", "]", ")", "\n", "for", "i", ",", "no", "in", "enumerate", "(", "next_obs", ")", ":", "\n", "            ", "nno", "=", "trans_out", "[", ":", ",", "i", "*", "n_obs", ":", "(", "i", "+", "1", ")", "*", "n_obs", "]", "\n", "plan_in", "=", "torch", ".", "cat", "(", "(", "no", ",", "nno", ")", ",", "dim", "=", "1", ")", "\n", "prob_plan", ".", "append", "(", "gumbel_softmax", "(", "self", ".", "planning", "(", "plan_in", ")", ",", "device", "=", "self", ".", "device", ".", "get_device", "(", ")", ",", "hard", "=", "False", ")", ")", "\n", "", "prob_plan", "=", "torch", ".", "cat", "(", "prob_plan", ",", "dim", "=", "1", ")", "\n", "prob_src", "=", "torch", ".", "cat", "(", "prob_src", ",", "dim", "=", "1", ")", "\n", "acs_src", "=", "torch", ".", "cat", "(", "acs_src", ",", "dim", "=", "1", ")", "\n", "\n", "E", "=", "acs_src", "*", "prob_plan", "-", "acs_src", "*", "prob_src", "\n", "i_rews", "=", "-", "E", ".", "mean", "(", ")", "\n", "i_rews", ".", "backward", "(", ")", "\n", "self", ".", "source_optimizer", ".", "step", "(", ")", "\n", "\n", "if", "logger", "is", "not", "None", ":", "\n", "            ", "logger", ".", "add_scalars", "(", "'empowerment/losses'", ",", "\n", "{", "'trans_loss'", ":", "trans_loss", ".", "detach", "(", ")", ",", "\n", "'plan_loss'", ":", "plan_loss", ".", "detach", "(", ")", ",", "\n", "'i_rews'", ":", "i_rews", ".", "detach", "(", ")", "}", ",", "\n", "self", ".", "niter", ")", "\n", "", "self", ".", "niter", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.__init__": [[118, 129], ["empowerment.variational_empowerment.VariationalBaseEmpowerment.__init__", "utils.networks.MLPNetwork", "utils.networks.MLPNetwork", "utils.networks.MLPNetwork", "empowerment.device.Device", "variational_joint_empowerment.ComputerJoint", "variational_joint_empowerment.TrainerJoint"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "init_params", ",", "lr", "=", "0.01", ")", ":", "\n", "        ", "super", "(", "VariationalJointEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "transition", "=", "MLPNetwork", "(", "init_params", "[", "'num_in_trans'", "]", ",", "init_params", "[", "'num_out_trans'", "]", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "source", "=", "MLPNetwork", "(", "init_params", "[", "'num_in_src'", "]", ",", "init_params", "[", "'num_out_src'", "]", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "planning", "=", "MLPNetwork", "(", "init_params", "[", "'num_in_plan'", "]", ",", "init_params", "[", "'num_out_plan'", "]", ",", "recurrent", "=", "True", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "\n", "self", ".", "device", "=", "Device", "(", "'cpu'", ")", "\n", "\n", "self", ".", "computer", "=", "ComputerJoint", "(", "self", ")", "\n", "self", ".", "trainer", "=", "TrainerJoint", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.compute": [[130, 132], ["variational_joint_empowerment.VariationalJointEmpowerment.computer.compute"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute"], ["", "def", "compute", "(", "self", ",", "rewards", ",", "next_obs", ")", ":", "\n", "        ", "return", "self", ".", "computer", ".", "compute", "(", "rewards", ",", "next_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.update": [[133, 135], ["variational_joint_empowerment.VariationalJointEmpowerment.trainer.update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "update", "(", "self", ",", "sample", ",", "logger", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "trainer", ".", "update", "(", "sample", ",", "logger", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_training": [[136, 151], ["variational_joint_empowerment.VariationalJointEmpowerment.transition.train", "variational_joint_empowerment.VariationalJointEmpowerment.source.train", "variational_joint_empowerment.VariationalJointEmpowerment.planning.train", "variational_joint_empowerment.VariationalJointEmpowerment.device.set_device", "fn", "fn", "fn", "x.cuda", "x.cpu", "variational_joint_empowerment.VariationalJointEmpowerment.device.get_device"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.set_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "prep_training", "(", "self", ",", "device", "=", "'gpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "train", "(", ")", "\n", "self", ".", "source", ".", "train", "(", ")", "\n", "self", ".", "planning", ".", "train", "(", ")", "\n", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "", "if", "not", "self", ".", "device", ".", "get_device", "(", ")", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "source", "=", "fn", "(", "self", ".", "source", ")", "\n", "self", ".", "planning", "=", "fn", "(", "self", ".", "planning", ")", "\n", "\n", "", "self", ".", "device", ".", "set_device", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts": [[152, 168], ["variational_joint_empowerment.VariationalJointEmpowerment.transition.eval", "variational_joint_empowerment.VariationalJointEmpowerment.source.eval", "variational_joint_empowerment.VariationalJointEmpowerment.planning.eval", "variational_joint_empowerment.VariationalJointEmpowerment.device.set_device", "fn", "fn", "fn", "x.cuda", "x.cpu", "variational_joint_empowerment.VariationalJointEmpowerment.device.get_device"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.set_device", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.device.Device.get_device"], ["", "def", "prep_rollouts", "(", "self", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "transition", ".", "eval", "(", ")", "\n", "self", ".", "source", ".", "eval", "(", ")", "\n", "self", ".", "planning", ".", "eval", "(", ")", "\n", "\n", "if", "device", "==", "'gpu'", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "fn", "=", "lambda", "x", ":", "x", ".", "cpu", "(", ")", "\n", "# only need main policy for rollouts", "\n", "", "if", "not", "self", ".", "device", ".", "get_device", "(", ")", "==", "device", ":", "\n", "            ", "self", ".", "transition", "=", "fn", "(", "self", ".", "transition", ")", "\n", "self", ".", "source", "=", "fn", "(", "self", ".", "source", ")", "\n", "self", ".", "planning", "=", "fn", "(", "self", ".", "planning", ")", "\n", "\n", "", "self", ".", "device", ".", "set_device", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.init_from_env": [[169, 194], ["zip", "cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "init_from_env", "(", "cls", ",", "env", ")", ":", "\n", "        ", "num_in_source", "=", "num_out_source", "=", "num_in_planning", "=", "num_out_planning", "=", "num_in_transition", "=", "num_out_transition", "=", "0", "\n", "for", "acsp", ",", "obsp", "in", "zip", "(", "env", ".", "action_space", ",", "env", ".", "observation_space", ")", ":", "\n", "\n", "            ", "num_in_source", "=", "obsp", ".", "shape", "[", "0", "]", "\n", "num_out_source", "=", "acsp", ".", "n", "\n", "\n", "num_in_planning", "=", "2", "*", "obsp", ".", "shape", "[", "0", "]", "\n", "num_out_planning", "=", "acsp", ".", "n", "\n", "\n", "num_in_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "+", "acsp", ".", "n", "\n", "num_out_transition", "+=", "obsp", ".", "shape", "[", "0", "]", "\n", "\n", "", "init_params", "=", "{", "'num_in_src'", ":", "num_in_source", ",", "\n", "'num_in_plan'", ":", "num_in_planning", ",", "\n", "'num_in_trans'", ":", "num_in_transition", ",", "\n", "'num_out_src'", ":", "num_out_source", ",", "\n", "'num_out_plan'", ":", "num_out_planning", ",", "\n", "'num_out_trans'", ":", "num_out_transition", "}", "\n", "\n", "instance", "=", "cls", "(", "init_params", ")", "\n", "instance", ".", "init_dict", "=", "init_params", "\n", "return", "instance", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.__init__": [[5, 8], ["empowerment.base_empowerment.BaseEmpowerment.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "agents", ")", ":", "\n", "        ", "super", "(", "DummyEmpowerment", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "agents", "=", "agents", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.dummy_empowerment.DummyEmpowerment.compute": [[9, 11], ["None"], "methods", ["None"], ["", "def", "compute", "(", "self", ",", "reward", ",", "next_obs", ")", ":", "\n", "        ", "return", "reward", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.rolling_window": [[21, 25], ["numpy.lib.stride_tricks.as_strided"], "function", ["None"], ["def", "rolling_window", "(", "a", ",", "window", ")", ":", "\n", "    ", "shape", "=", "a", ".", "shape", "[", ":", "-", "1", "]", "+", "(", "a", ".", "shape", "[", "-", "1", "]", "-", "window", "+", "1", ",", "window", ")", "\n", "strides", "=", "a", ".", "strides", "+", "(", "a", ".", "strides", "[", "-", "1", "]", ",", ")", "\n", "return", "np", ".", "lib", ".", "stride_tricks", ".", "as_strided", "(", "a", ",", "shape", "=", "shape", ",", "strides", "=", "strides", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.window_func": [[26, 30], ["results_plotter.rolling_window", "numpy.np.mean"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.rolling_window", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "window_func", "(", "x", ",", "y", ",", "window", ",", "func", ")", ":", "\n", "    ", "yw", "=", "rolling_window", "(", "y", ",", "window", ")", "\n", "yw_func", "=", "func", "(", "yw", ",", "axis", "=", "-", "1", ")", "\n", "return", "x", "[", "window", "-", "1", ":", "]", ",", "yw_func", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.ts2xy": [[31, 47], ["numpy.cumsum", "numpy.arange", "len"], "function", ["None"], ["", "def", "ts2xy", "(", "ts", ",", "xaxis", ",", "yaxis", ")", ":", "\n", "    ", "if", "xaxis", "==", "X_TIMESTEPS", ":", "\n", "        ", "x", "=", "np", ".", "cumsum", "(", "ts", ".", "l", ".", "values", ")", "\n", "", "elif", "xaxis", "==", "X_EPISODES", ":", "\n", "        ", "x", "=", "np", ".", "arange", "(", "len", "(", "ts", ")", ")", "\n", "", "elif", "xaxis", "==", "X_WALLTIME", ":", "\n", "        ", "x", "=", "ts", ".", "t", ".", "values", "/", "3600.", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "if", "yaxis", "==", "Y_REWARD", ":", "\n", "        ", "y", "=", "ts", ".", "r", ".", "values", "\n", "", "elif", "yaxis", "==", "Y_TIMESTEPS", ":", "\n", "        ", "y", "=", "ts", ".", "l", ".", "values", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.plot_curves": [[48, 64], ["matplotlib.figure", "max", "enumerate", "matplotlib.xlim", "matplotlib.title", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.tight_layout", "plt.figure.canvas.mpl_connect", "matplotlib.grid", "matplotlib.scatter", "results_plotter.window_func", "matplotlib.plot", "matplotlib.tight_layout", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.window_func", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot"], ["", "def", "plot_curves", "(", "xy_list", ",", "xaxis", ",", "yaxis", ",", "title", ")", ":", "\n", "    ", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "8", ",", "2", ")", ")", "\n", "maxx", "=", "max", "(", "xy", "[", "0", "]", "[", "-", "1", "]", "for", "xy", "in", "xy_list", ")", "\n", "minx", "=", "0", "\n", "for", "(", "i", ",", "(", "x", ",", "y", ")", ")", "in", "enumerate", "(", "xy_list", ")", ":", "\n", "        ", "color", "=", "COLORS", "[", "i", "%", "len", "(", "COLORS", ")", "]", "\n", "plt", ".", "scatter", "(", "x", ",", "y", ",", "s", "=", "2", ")", "\n", "x", ",", "y_mean", "=", "window_func", "(", "x", ",", "y", ",", "EPISODES_WINDOW", ",", "np", ".", "mean", ")", "#So returns average of last EPISODE_WINDOW episodes", "\n", "plt", ".", "plot", "(", "x", ",", "y_mean", ",", "color", "=", "color", ")", "\n", "", "plt", ".", "xlim", "(", "minx", ",", "maxx", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "xlabel", "(", "xaxis", ")", "\n", "plt", ".", "ylabel", "(", "yaxis", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "fig", ".", "canvas", ".", "mpl_connect", "(", "'resize_event'", ",", "lambda", "event", ":", "plt", ".", "tight_layout", "(", ")", ")", "\n", "plt", ".", "grid", "(", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.split_by_task": [[66, 68], ["[].split", "taskpath[].split"], "function", ["None"], ["", "def", "split_by_task", "(", "taskpath", ")", ":", "\n", "    ", "return", "taskpath", "[", "'dirname'", "]", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "split", "(", "'-'", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.plot_results": [[69, 72], ["baselines.common.plot_util.load_results", "baselines.common.plot_util.plot_results", "int", "results_plotter.ts2xy"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.load_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.ts2xy"], ["", "def", "plot_results", "(", "dirs", ",", "num_timesteps", "=", "10e6", ",", "xaxis", "=", "X_TIMESTEPS", ",", "yaxis", "=", "Y_REWARD", ",", "title", "=", "''", ",", "split_fn", "=", "split_by_task", ")", ":", "\n", "    ", "results", "=", "plot_util", ".", "load_results", "(", "dirs", ")", "\n", "plot_util", ".", "plot_results", "(", "results", ",", "xy_fn", "=", "lambda", "r", ":", "ts2xy", "(", "r", "[", "'monitor'", "]", ",", "xaxis", ",", "yaxis", ")", ",", "split_fn", "=", "split_fn", ",", "average_group", "=", "True", ",", "resample", "=", "int", "(", "1e6", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.results_plotter.main": [[79, 92], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "results_plotter.plot_results", "matplotlib.show", "os.path.abspath", "int"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results"], ["", "def", "main", "(", ")", ":", "\n", "    ", "import", "argparse", "\n", "import", "os", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "'--dirs'", ",", "help", "=", "'List of log directories'", ",", "nargs", "=", "'*'", ",", "default", "=", "[", "'./log'", "]", ")", "\n", "parser", ".", "add_argument", "(", "'--num_timesteps'", ",", "type", "=", "int", ",", "default", "=", "int", "(", "10e6", ")", ")", "\n", "parser", ".", "add_argument", "(", "'--xaxis'", ",", "help", "=", "'Varible on X-axis'", ",", "default", "=", "X_TIMESTEPS", ")", "\n", "parser", ".", "add_argument", "(", "'--yaxis'", ",", "help", "=", "'Varible on Y-axis'", ",", "default", "=", "Y_REWARD", ")", "\n", "parser", ".", "add_argument", "(", "'--task_name'", ",", "help", "=", "'Title of plot'", ",", "default", "=", "'Breakout'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "dirs", "=", "[", "os", ".", "path", ".", "abspath", "(", "dir", ")", "for", "dir", "in", "args", ".", "dirs", "]", "\n", "plot_results", "(", "args", ".", "dirs", ",", "args", ".", "num_timesteps", ",", "args", ".", "xaxis", ",", "args", ".", "yaxis", ",", "args", ".", "task_name", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.KVWriter.writekvs": [[20, 22], ["None"], "methods", ["None"], ["    ", "def", "writekvs", "(", "self", ",", "kvs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.SeqWriter.writeseq": [[24, 26], ["None"], "methods", ["None"], ["    ", "def", "writeseq", "(", "self", ",", "seq", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat.__init__": [[28, 36], ["isinstance", "open", "hasattr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename_or_file", ")", ":", "\n", "        ", "if", "isinstance", "(", "filename_or_file", ",", "str", ")", ":", "\n", "            ", "self", ".", "file", "=", "open", "(", "filename_or_file", ",", "'wt'", ")", "\n", "self", ".", "own_file", "=", "True", "\n", "", "else", ":", "\n", "            ", "assert", "hasattr", "(", "filename_or_file", ",", "'read'", ")", ",", "'expected file or str, got %s'", "%", "filename_or_file", "\n", "self", ".", "file", "=", "filename_or_file", "\n", "self", ".", "own_file", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat.writekvs": [[37, 70], ["sorted", "sorted", "lines.append", "logger.HumanOutputFormat.file.write", "logger.HumanOutputFormat.file.flush", "kvs.items", "hasattr", "logger.HumanOutputFormat._truncate", "len", "print", "max", "max", "key2str.items", "lines.append", "str", "map", "map", "logger.HumanOutputFormat._truncate", "key2str.keys", "key2str.values", "kv[].lower", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat._truncate", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat._truncate"], ["", "", "def", "writekvs", "(", "self", ",", "kvs", ")", ":", "\n", "# Create strings for printing", "\n", "        ", "key2str", "=", "{", "}", "\n", "for", "(", "key", ",", "val", ")", "in", "sorted", "(", "kvs", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "hasattr", "(", "val", ",", "'__float__'", ")", ":", "\n", "                ", "valstr", "=", "'%-8.3g'", "%", "val", "\n", "", "else", ":", "\n", "                ", "valstr", "=", "str", "(", "val", ")", "\n", "", "key2str", "[", "self", ".", "_truncate", "(", "key", ")", "]", "=", "self", ".", "_truncate", "(", "valstr", ")", "\n", "\n", "# Find max widths", "\n", "", "if", "len", "(", "key2str", ")", "==", "0", ":", "\n", "            ", "print", "(", "'WARNING: tried to write empty key-value dict'", ")", "\n", "return", "\n", "", "else", ":", "\n", "            ", "keywidth", "=", "max", "(", "map", "(", "len", ",", "key2str", ".", "keys", "(", ")", ")", ")", "\n", "valwidth", "=", "max", "(", "map", "(", "len", ",", "key2str", ".", "values", "(", ")", ")", ")", "\n", "\n", "# Write out the data", "\n", "", "dashes", "=", "'-'", "*", "(", "keywidth", "+", "valwidth", "+", "7", ")", "\n", "lines", "=", "[", "dashes", "]", "\n", "for", "(", "key", ",", "val", ")", "in", "sorted", "(", "key2str", ".", "items", "(", ")", ",", "key", "=", "lambda", "kv", ":", "kv", "[", "0", "]", ".", "lower", "(", ")", ")", ":", "\n", "            ", "lines", ".", "append", "(", "'| %s%s | %s%s |'", "%", "(", "\n", "key", ",", "\n", "' '", "*", "(", "keywidth", "-", "len", "(", "key", ")", ")", ",", "\n", "val", ",", "\n", "' '", "*", "(", "valwidth", "-", "len", "(", "val", ")", ")", ",", "\n", ")", ")", "\n", "", "lines", ".", "append", "(", "dashes", ")", "\n", "self", ".", "file", ".", "write", "(", "'\\n'", ".", "join", "(", "lines", ")", "+", "'\\n'", ")", "\n", "\n", "# Flush the output to the file", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat._truncate": [[71, 74], ["len"], "methods", ["None"], ["", "def", "_truncate", "(", "self", ",", "s", ")", ":", "\n", "        ", "maxlen", "=", "30", "\n", "return", "s", "[", ":", "maxlen", "-", "3", "]", "+", "'...'", "if", "len", "(", "s", ")", ">", "maxlen", "else", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat.writeseq": [[75, 83], ["list", "enumerate", "logger.HumanOutputFormat.file.write", "logger.HumanOutputFormat.file.flush", "logger.HumanOutputFormat.file.write", "logger.HumanOutputFormat.file.write", "len"], "methods", ["None"], ["", "def", "writeseq", "(", "self", ",", "seq", ")", ":", "\n", "        ", "seq", "=", "list", "(", "seq", ")", "\n", "for", "(", "i", ",", "elem", ")", "in", "enumerate", "(", "seq", ")", ":", "\n", "            ", "self", ".", "file", ".", "write", "(", "elem", ")", "\n", "if", "i", "<", "len", "(", "seq", ")", "-", "1", ":", "# add space unless this is the last one", "\n", "                ", "self", ".", "file", ".", "write", "(", "' '", ")", "\n", "", "", "self", ".", "file", ".", "write", "(", "'\\n'", ")", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat.close": [[84, 87], ["logger.HumanOutputFormat.file.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "own_file", ":", "\n", "            ", "self", ".", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.JSONOutputFormat.__init__": [[89, 91], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ")", ":", "\n", "        ", "self", ".", "file", "=", "open", "(", "filename", ",", "'wt'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.JSONOutputFormat.writekvs": [[92, 98], ["sorted", "logger.JSONOutputFormat.file.write", "logger.JSONOutputFormat.file.flush", "kvs.items", "hasattr", "float", "json.dumps"], "methods", ["None"], ["", "def", "writekvs", "(", "self", ",", "kvs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "sorted", "(", "kvs", ".", "items", "(", ")", ")", ":", "\n", "            ", "if", "hasattr", "(", "v", ",", "'dtype'", ")", ":", "\n", "                ", "kvs", "[", "k", "]", "=", "float", "(", "v", ")", "\n", "", "", "self", ".", "file", ".", "write", "(", "json", ".", "dumps", "(", "kvs", ")", "+", "'\\n'", ")", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.JSONOutputFormat.close": [[99, 101], ["logger.JSONOutputFormat.file.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.CSVOutputFormat.__init__": [[103, 107], ["open"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ")", ":", "\n", "        ", "self", ".", "file", "=", "open", "(", "filename", ",", "'w+t'", ")", "\n", "self", ".", "keys", "=", "[", "]", "\n", "self", ".", "sep", "=", "','", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.CSVOutputFormat.writekvs": [[108, 134], ["list", "list.sort", "enumerate", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.flush", "logger.CSVOutputFormat.keys.extend", "logger.CSVOutputFormat.file.seek", "logger.CSVOutputFormat.file.readlines", "logger.CSVOutputFormat.file.seek", "enumerate", "logger.CSVOutputFormat.file.write", "kvs.get", "kvs.keys", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "logger.CSVOutputFormat.file.write", "str", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["", "def", "writekvs", "(", "self", ",", "kvs", ")", ":", "\n", "# Add our current row to the history", "\n", "        ", "extra_keys", "=", "list", "(", "kvs", ".", "keys", "(", ")", "-", "self", ".", "keys", ")", "\n", "extra_keys", ".", "sort", "(", ")", "\n", "if", "extra_keys", ":", "\n", "            ", "self", ".", "keys", ".", "extend", "(", "extra_keys", ")", "\n", "self", ".", "file", ".", "seek", "(", "0", ")", "\n", "lines", "=", "self", ".", "file", ".", "readlines", "(", ")", "\n", "self", ".", "file", ".", "seek", "(", "0", ")", "\n", "for", "(", "i", ",", "k", ")", "in", "enumerate", "(", "self", ".", "keys", ")", ":", "\n", "                ", "if", "i", ">", "0", ":", "\n", "                    ", "self", ".", "file", ".", "write", "(", "','", ")", "\n", "", "self", ".", "file", ".", "write", "(", "k", ")", "\n", "", "self", ".", "file", ".", "write", "(", "'\\n'", ")", "\n", "for", "line", "in", "lines", "[", "1", ":", "]", ":", "\n", "                ", "self", ".", "file", ".", "write", "(", "line", "[", ":", "-", "1", "]", ")", "\n", "self", ".", "file", ".", "write", "(", "self", ".", "sep", "*", "len", "(", "extra_keys", ")", ")", "\n", "self", ".", "file", ".", "write", "(", "'\\n'", ")", "\n", "", "", "for", "(", "i", ",", "k", ")", "in", "enumerate", "(", "self", ".", "keys", ")", ":", "\n", "            ", "if", "i", ">", "0", ":", "\n", "                ", "self", ".", "file", ".", "write", "(", "','", ")", "\n", "", "v", "=", "kvs", ".", "get", "(", "k", ")", "\n", "if", "v", "is", "not", "None", ":", "\n", "                ", "self", ".", "file", ".", "write", "(", "str", "(", "v", ")", ")", "\n", "", "", "self", ".", "file", ".", "write", "(", "'\\n'", ")", "\n", "self", ".", "file", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.CSVOutputFormat.close": [[135, 137], ["logger.CSVOutputFormat.file.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "self", ".", "file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.TensorBoardOutputFormat.__init__": [[143, 157], ["os.makedirs", "os.makedirs", "os.makedirs", "os.makedirs", "os.join", "os.join", "pywrap_tensorflow.EventsWriter", "os.abspath", "os.abspath", "compat.as_bytes"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dir", ",", "exist_ok", "=", "True", ")", "\n", "self", ".", "dir", "=", "dir", "\n", "self", ".", "step", "=", "1", "\n", "prefix", "=", "'events'", "\n", "path", "=", "osp", ".", "join", "(", "osp", ".", "abspath", "(", "dir", ")", ",", "prefix", ")", "\n", "import", "tensorflow", "as", "tf", "\n", "from", "tensorflow", ".", "python", "import", "pywrap_tensorflow", "\n", "from", "tensorflow", ".", "core", ".", "util", "import", "event_pb2", "\n", "from", "tensorflow", ".", "python", ".", "util", "import", "compat", "\n", "self", ".", "tf", "=", "tf", "\n", "self", ".", "event_pb2", "=", "event_pb2", "\n", "self", ".", "pywrap_tensorflow", "=", "pywrap_tensorflow", "\n", "self", ".", "writer", "=", "pywrap_tensorflow", ".", "EventsWriter", "(", "compat", ".", "as_bytes", "(", "path", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.TensorBoardOutputFormat.writekvs": [[158, 168], ["logger.TensorBoardOutputFormat.tf.Summary", "logger.TensorBoardOutputFormat.event_pb2.Event", "logger.TensorBoardOutputFormat.writer.WriteEvent", "logger.TensorBoardOutputFormat.writer.Flush", "logger.TensorBoardOutputFormat.tf.Summary.Value", "float", "time.time", "logger.TensorBoardOutputFormat.writekvs.summary_val"], "methods", ["None"], ["", "def", "writekvs", "(", "self", ",", "kvs", ")", ":", "\n", "        ", "def", "summary_val", "(", "k", ",", "v", ")", ":", "\n", "            ", "kwargs", "=", "{", "'tag'", ":", "k", ",", "'simple_value'", ":", "float", "(", "v", ")", "}", "\n", "return", "self", ".", "tf", ".", "Summary", ".", "Value", "(", "**", "kwargs", ")", "\n", "", "summary", "=", "self", ".", "tf", ".", "Summary", "(", "value", "=", "[", "summary_val", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "kvs", ".", "items", "(", ")", "]", ")", "\n", "event", "=", "self", ".", "event_pb2", ".", "Event", "(", "wall_time", "=", "time", ".", "time", "(", ")", ",", "summary", "=", "summary", ")", "\n", "event", ".", "step", "=", "self", ".", "step", "# is there any reason why you'd want to specify the step?", "\n", "self", ".", "writer", ".", "WriteEvent", "(", "event", ")", "\n", "self", ".", "writer", ".", "Flush", "(", ")", "\n", "self", ".", "step", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.TensorBoardOutputFormat.close": [[169, 173], ["logger.TensorBoardOutputFormat.writer.Close"], "methods", ["None"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "writer", ":", "\n", "            ", "self", ".", "writer", ".", "Close", "(", ")", "\n", "self", ".", "writer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.__init__": [[301, 308], ["collections.defaultdict", "collections.defaultdict"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "dir", ",", "output_formats", ",", "comm", "=", "None", ")", ":", "\n", "        ", "self", ".", "name2val", "=", "defaultdict", "(", "float", ")", "# values this iteration", "\n", "self", ".", "name2cnt", "=", "defaultdict", "(", "int", ")", "\n", "self", ".", "level", "=", "INFO", "\n", "self", ".", "dir", "=", "dir", "\n", "self", ".", "output_formats", "=", "output_formats", "\n", "self", ".", "comm", "=", "comm", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.logkv": [[311, 313], ["None"], "methods", ["None"], ["", "def", "logkv", "(", "self", ",", "key", ",", "val", ")", ":", "\n", "        ", "self", ".", "name2val", "[", "key", "]", "=", "val", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.logkv_mean": [[314, 318], ["None"], "methods", ["None"], ["", "def", "logkv_mean", "(", "self", ",", "key", ",", "val", ")", ":", "\n", "        ", "oldval", ",", "cnt", "=", "self", ".", "name2val", "[", "key", "]", ",", "self", ".", "name2cnt", "[", "key", "]", "\n", "self", ".", "name2val", "[", "key", "]", "=", "oldval", "*", "cnt", "/", "(", "cnt", "+", "1", ")", "+", "val", "/", "(", "cnt", "+", "1", ")", "\n", "self", ".", "name2cnt", "[", "key", "]", "=", "cnt", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.dumpkvs": [[319, 336], ["mpi_util.mpi_weighted_mean.copy", "logger.Logger.name2val.clear", "logger.Logger.name2cnt.clear", "mpi_util.mpi_weighted_mean", "isinstance", "fmt.writekvs", "logger.Logger.name2cnt.get", "logger.Logger.name2val.items"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.mpi_weighted_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.TensorBoardOutputFormat.writekvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["", "def", "dumpkvs", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "comm", "is", "None", ":", "\n", "            ", "d", "=", "self", ".", "name2val", "\n", "", "else", ":", "\n", "            ", "from", "baselines", ".", "common", "import", "mpi_util", "\n", "d", "=", "mpi_util", ".", "mpi_weighted_mean", "(", "self", ".", "comm", ",", "\n", "{", "name", ":", "(", "val", ",", "self", ".", "name2cnt", ".", "get", "(", "name", ",", "1", ")", ")", "\n", "for", "(", "name", ",", "val", ")", "in", "self", ".", "name2val", ".", "items", "(", ")", "}", ")", "\n", "if", "self", ".", "comm", ".", "rank", "!=", "0", ":", "\n", "                ", "d", "[", "'dummy'", "]", "=", "1", "# so we don't get a warning about empty dict", "\n", "", "", "out", "=", "d", ".", "copy", "(", ")", "# Return the dict for unit testing purposes", "\n", "for", "fmt", "in", "self", ".", "output_formats", ":", "\n", "            ", "if", "isinstance", "(", "fmt", ",", "KVWriter", ")", ":", "\n", "                ", "fmt", ".", "writekvs", "(", "d", ")", "\n", "", "", "self", ".", "name2val", ".", "clear", "(", ")", "\n", "self", ".", "name2cnt", ".", "clear", "(", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.log": [[337, 340], ["logger.Logger._do_log"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger._do_log"], ["", "def", "log", "(", "self", ",", "*", "args", ",", "level", "=", "INFO", ")", ":", "\n", "        ", "if", "self", ".", "level", "<=", "level", ":", "\n", "            ", "self", ".", "_do_log", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.set_level": [[343, 345], ["None"], "methods", ["None"], ["", "", "def", "set_level", "(", "self", ",", "level", ")", ":", "\n", "        ", "self", ".", "level", "=", "level", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.set_comm": [[346, 348], ["None"], "methods", ["None"], ["", "def", "set_comm", "(", "self", ",", "comm", ")", ":", "\n", "        ", "self", ".", "comm", "=", "comm", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.get_dir": [[349, 351], ["None"], "methods", ["None"], ["", "def", "get_dir", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "dir", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger.close": [[352, 355], ["fmt.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "for", "fmt", "in", "self", ".", "output_formats", ":", "\n", "            ", "fmt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.Logger._do_log": [[358, 362], ["isinstance", "fmt.writeseq", "map"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.HumanOutputFormat.writeseq"], ["", "", "def", "_do_log", "(", "self", ",", "args", ")", ":", "\n", "        ", "for", "fmt", "in", "self", ".", "output_formats", ":", "\n", "            ", "if", "isinstance", "(", "fmt", ",", "SeqWriter", ")", ":", "\n", "                ", "fmt", ".", "writeseq", "(", "map", "(", "str", ",", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.make_output_format": [[174, 188], ["os.makedirs", "os.makedirs", "logger.HumanOutputFormat", "logger.HumanOutputFormat", "os.join", "logger.JSONOutputFormat", "os.join", "logger.CSVOutputFormat", "os.join", "logger.TensorBoardOutputFormat", "ValueError", "os.join"], "function", ["None"], ["", "", "", "def", "make_output_format", "(", "format", ",", "ev_dir", ",", "log_suffix", "=", "''", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "ev_dir", ",", "exist_ok", "=", "True", ")", "\n", "if", "format", "==", "'stdout'", ":", "\n", "        ", "return", "HumanOutputFormat", "(", "sys", ".", "stdout", ")", "\n", "", "elif", "format", "==", "'log'", ":", "\n", "        ", "return", "HumanOutputFormat", "(", "osp", ".", "join", "(", "ev_dir", ",", "'log%s.txt'", "%", "log_suffix", ")", ")", "\n", "", "elif", "format", "==", "'json'", ":", "\n", "        ", "return", "JSONOutputFormat", "(", "osp", ".", "join", "(", "ev_dir", ",", "'progress%s.json'", "%", "log_suffix", ")", ")", "\n", "", "elif", "format", "==", "'csv'", ":", "\n", "        ", "return", "CSVOutputFormat", "(", "osp", ".", "join", "(", "ev_dir", ",", "'progress%s.csv'", "%", "log_suffix", ")", ")", "\n", "", "elif", "format", "==", "'tensorboard'", ":", "\n", "        ", "return", "TensorBoardOutputFormat", "(", "osp", ".", "join", "(", "ev_dir", ",", "'tb%s'", "%", "log_suffix", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Unknown format specified: %s'", "%", "(", "format", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv": [[193, 200], ["get_current().logkv", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "", "def", "logkv", "(", "key", ",", "val", ")", ":", "\n", "    ", "\"\"\"\n    Log a value of some diagnostic\n    Call this once for each diagnostic quantity, each iteration\n    If called many times, last value will be used.\n    \"\"\"", "\n", "get_current", "(", ")", ".", "logkv", "(", "key", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv_mean": [[201, 206], ["get_current().logkv_mean", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "def", "logkv_mean", "(", "key", ",", "val", ")", ":", "\n", "    ", "\"\"\"\n    The same as logkv(), but if called many times, values averaged.\n    \"\"\"", "\n", "get_current", "(", ")", ".", "logkv_mean", "(", "key", ",", "val", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkvs": [[207, 213], ["d.items", "logger.logkv"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv"], ["", "def", "logkvs", "(", "d", ")", ":", "\n", "    ", "\"\"\"\n    Log a dictionary of key-value pairs\n    \"\"\"", "\n", "for", "(", "k", ",", "v", ")", "in", "d", ".", "items", "(", ")", ":", "\n", "        ", "logkv", "(", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs": [[214, 219], ["get_current().dumpkvs", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "", "def", "dumpkvs", "(", ")", ":", "\n", "    ", "\"\"\"\n    Write all of the diagnostics from the current iteration\n    \"\"\"", "\n", "return", "get_current", "(", ")", ".", "dumpkvs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.getkvs": [[220, 222], ["logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "def", "getkvs", "(", ")", ":", "\n", "    ", "return", "get_current", "(", ")", ".", "name2val", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log": [[224, 229], ["get_current().log", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "def", "log", "(", "*", "args", ",", "level", "=", "INFO", ")", ":", "\n", "    ", "\"\"\"\n    Write the sequence of args, with no separators, to the console and output files (if you've configured an output file).\n    \"\"\"", "\n", "get_current", "(", ")", ".", "log", "(", "*", "args", ",", "level", "=", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.debug": [[230, 232], ["logger.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "debug", "(", "*", "args", ")", ":", "\n", "    ", "log", "(", "*", "args", ",", "level", "=", "DEBUG", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info": [[233, 235], ["logger.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "info", "(", "*", "args", ")", ":", "\n", "    ", "log", "(", "*", "args", ",", "level", "=", "INFO", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn": [[236, 238], ["logger.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "warn", "(", "*", "args", ")", ":", "\n", "    ", "log", "(", "*", "args", ",", "level", "=", "WARN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.error": [[239, 241], ["logger.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "error", "(", "*", "args", ")", ":", "\n", "    ", "log", "(", "*", "args", ",", "level", "=", "ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.set_level": [[243, 248], ["get_current().set_level", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.set_level", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "def", "set_level", "(", "level", ")", ":", "\n", "    ", "\"\"\"\n    Set logging threshold on current logger.\n    \"\"\"", "\n", "get_current", "(", ")", ".", "set_level", "(", "level", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.set_comm": [[249, 251], ["get_current().set_comm", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.set_comm", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "def", "set_comm", "(", "comm", ")", ":", "\n", "    ", "get_current", "(", ")", ".", "set_comm", "(", "comm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir": [[252, 258], ["get_current().get_dir", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["", "def", "get_dir", "(", ")", ":", "\n", "    ", "\"\"\"\n    Get directory that log files are being written to.\n    will be None if there is no output directory (i.e., if you didn't call start)\n    \"\"\"", "\n", "return", "get_current", "(", ")", ".", "get_dir", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.profile_kv": [[262, 270], ["time.time", "time.time", "logger.get_current"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current"], ["@", "contextmanager", "\n", "def", "profile_kv", "(", "scopename", ")", ":", "\n", "    ", "logkey", "=", "'wait_'", "+", "scopename", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "get_current", "(", ")", ".", "name2val", "[", "logkey", "]", "+=", "time", ".", "time", "(", ")", "-", "tstart", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.profile": [[271, 283], ["logger.profile_kv", "func"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.profile_kv"], ["", "", "def", "profile", "(", "n", ")", ":", "\n", "    ", "\"\"\"\n    Usage:\n    @profile(\"my_func\")\n    def my_func(): code\n    \"\"\"", "\n", "def", "decorator_with_name", "(", "func", ")", ":", "\n", "        ", "def", "func_wrapper", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "with", "profile_kv", "(", "n", ")", ":", "\n", "                ", "return", "func", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "return", "func_wrapper", "\n", "", "return", "decorator_with_name", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_current": [[289, 294], ["logger._configure_default_logger"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger._configure_default_logger"], ["", "def", "get_current", "(", ")", ":", "\n", "    ", "if", "Logger", ".", "CURRENT", "is", "None", ":", "\n", "        ", "_configure_default_logger", "(", ")", "\n", "\n", "", "return", "Logger", ".", "CURRENT", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_rank_without_mpi_import": [[363, 370], ["int"], "function", ["None"], ["", "", "", "", "def", "get_rank_without_mpi_import", "(", ")", ":", "\n", "# check environment variables here instead of importing mpi4py", "\n", "# to avoid calling MPI_Init() when this module is imported", "\n", "    ", "for", "varname", "in", "[", "'PMI_RANK'", ",", "'OMPI_COMM_WORLD_RANK'", "]", ":", "\n", "        ", "if", "varname", "in", "os", ".", "environ", ":", "\n", "            ", "return", "int", "(", "os", ".", "environ", "[", "varname", "]", ")", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure": [[372, 400], ["isinstance", "os.path.expanduser", "os.path.expanduser", "os.makedirs", "os.makedirs", "logger.get_rank_without_mpi_import", "filter", "logger.Logger", "os.getenv", "os.getenv", "os.join", "os.path.expanduser", "os.path.expanduser", "logger.make_output_format", "logger.log", "tempfile.gettempdir", "datetime.datetime.now().strftime", "os.getenv().split", "os.getenv().split", "os.getenv().split", "os.getenv().split", "datetime.datetime.now", "os.getenv", "os.getenv", "os.getenv", "os.getenv"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_rank_without_mpi_import", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.make_output_format", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "configure", "(", "dir", "=", "None", ",", "format_strs", "=", "None", ",", "comm", "=", "None", ",", "log_suffix", "=", "''", ")", ":", "\n", "    ", "\"\"\"\n    If comm is provided, average all numerical stats across that comm\n    \"\"\"", "\n", "if", "dir", "is", "None", ":", "\n", "        ", "dir", "=", "os", ".", "getenv", "(", "'OPENAI_LOGDIR'", ")", "\n", "", "if", "dir", "is", "None", ":", "\n", "        ", "dir", "=", "osp", ".", "join", "(", "tempfile", ".", "gettempdir", "(", ")", ",", "\n", "datetime", ".", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "\"openai-%Y-%m-%d-%H-%M-%S-%f\"", ")", ")", "\n", "", "assert", "isinstance", "(", "dir", ",", "str", ")", "\n", "dir", "=", "os", ".", "path", ".", "expanduser", "(", "dir", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "expanduser", "(", "dir", ")", ",", "exist_ok", "=", "True", ")", "\n", "\n", "rank", "=", "get_rank_without_mpi_import", "(", ")", "\n", "if", "rank", ">", "0", ":", "\n", "        ", "log_suffix", "=", "log_suffix", "+", "\"-rank%03i\"", "%", "rank", "\n", "\n", "", "if", "format_strs", "is", "None", ":", "\n", "        ", "if", "rank", "==", "0", ":", "\n", "            ", "format_strs", "=", "os", ".", "getenv", "(", "'OPENAI_LOG_FORMAT'", ",", "'stdout,log,csv'", ")", ".", "split", "(", "','", ")", "\n", "", "else", ":", "\n", "            ", "format_strs", "=", "os", ".", "getenv", "(", "'OPENAI_LOG_FORMAT_MPI'", ",", "'log'", ")", ".", "split", "(", "','", ")", "\n", "", "", "format_strs", "=", "filter", "(", "None", ",", "format_strs", ")", "\n", "output_formats", "=", "[", "make_output_format", "(", "f", ",", "dir", ",", "log_suffix", ")", "for", "f", "in", "format_strs", "]", "\n", "\n", "Logger", ".", "CURRENT", "=", "Logger", "(", "dir", "=", "dir", ",", "output_formats", "=", "output_formats", ",", "comm", "=", "comm", ")", "\n", "if", "output_formats", ":", "\n", "        ", "log", "(", "'Logging to %s'", "%", "dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger._configure_default_logger": [[401, 404], ["logger.configure"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure"], ["", "", "def", "_configure_default_logger", "(", ")", ":", "\n", "    ", "configure", "(", ")", "\n", "Logger", ".", "DEFAULT", "=", "Logger", ".", "CURRENT", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.reset": [[405, 410], ["Logger.CURRENT.close", "logger.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "reset", "(", ")", ":", "\n", "    ", "if", "Logger", ".", "CURRENT", "is", "not", "Logger", ".", "DEFAULT", ":", "\n", "        ", "Logger", ".", "CURRENT", ".", "close", "(", ")", "\n", "Logger", ".", "CURRENT", "=", "Logger", ".", "DEFAULT", "\n", "log", "(", "'Reset logger'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.scoped_configure": [[411, 420], ["logger.configure", "Logger.CURRENT.close"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "", "@", "contextmanager", "\n", "def", "scoped_configure", "(", "dir", "=", "None", ",", "format_strs", "=", "None", ",", "comm", "=", "None", ")", ":", "\n", "    ", "prevlogger", "=", "Logger", ".", "CURRENT", "\n", "configure", "(", "dir", "=", "dir", ",", "format_strs", "=", "format_strs", ",", "comm", "=", "comm", ")", "\n", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "Logger", ".", "CURRENT", ".", "close", "(", ")", "\n", "Logger", ".", "CURRENT", "=", "prevlogger", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger._demo": [[423, 450], ["logger.info", "logger.debug", "logger.set_level", "logger.debug", "os.path.exists", "os.path.exists", "logger.configure", "logger.logkv", "logger.logkv", "logger.dumpkvs", "logger.logkv", "logger.logkv", "logger.dumpkvs", "logger.info", "logger.logkv_mean", "logger.logkv_mean", "logger.logkv", "logger.dumpkvs", "logger.info", "logger.logkv", "logger.dumpkvs", "logger.logkv", "logger.dumpkvs", "shutil.rmtree"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.debug", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.set_level", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.debug", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs"], ["", "", "def", "_demo", "(", ")", ":", "\n", "    ", "info", "(", "\"hi\"", ")", "\n", "debug", "(", "\"shouldn't appear\"", ")", "\n", "set_level", "(", "DEBUG", ")", "\n", "debug", "(", "\"should appear\"", ")", "\n", "dir", "=", "\"/tmp/testlogging\"", "\n", "if", "os", ".", "path", ".", "exists", "(", "dir", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "dir", ")", "\n", "", "configure", "(", "dir", "=", "dir", ")", "\n", "logkv", "(", "\"a\"", ",", "3", ")", "\n", "logkv", "(", "\"b\"", ",", "2.5", ")", "\n", "dumpkvs", "(", ")", "\n", "logkv", "(", "\"b\"", ",", "-", "2.5", ")", "\n", "logkv", "(", "\"a\"", ",", "5.5", ")", "\n", "dumpkvs", "(", ")", "\n", "info", "(", "\"^^^ should see a = 5.5\"", ")", "\n", "logkv_mean", "(", "\"b\"", ",", "-", "22.5", ")", "\n", "logkv_mean", "(", "\"b\"", ",", "-", "44.4", ")", "\n", "logkv", "(", "\"a\"", ",", "5.5", ")", "\n", "dumpkvs", "(", ")", "\n", "info", "(", "\"^^^ should see b = -33.3\"", ")", "\n", "\n", "logkv", "(", "\"b\"", ",", "-", "2.5", ")", "\n", "dumpkvs", "(", ")", "\n", "\n", "logkv", "(", "\"a\"", ",", "\"longasslongasslongasslongasslongasslongassvalue\"", ")", "\n", "dumpkvs", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_json": [[456, 463], ["pandas.DataFrame", "open", "ds.append", "json.loads"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "read_json", "(", "fname", ")", ":", "\n", "    ", "import", "pandas", "\n", "ds", "=", "[", "]", "\n", "with", "open", "(", "fname", ",", "'rt'", ")", "as", "fh", ":", "\n", "        ", "for", "line", "in", "fh", ":", "\n", "            ", "ds", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "return", "pandas", ".", "DataFrame", "(", "ds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_csv": [[464, 467], ["pandas.read_csv"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_csv"], ["", "def", "read_csv", "(", "fname", ")", ":", "\n", "    ", "import", "pandas", "\n", "return", "pandas", ".", "read_csv", "(", "fname", ",", "index_col", "=", "None", ",", "comment", "=", "'#'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_tb": [[468, 500], ["os.isdir", "collections.defaultdict", "np.empty", "sorted", "enumerate", "pandas.DataFrame", "glob", "os.basename().startswith", "tf.train.summary_iterator", "collections.defaultdict.keys", "os.join", "NotImplementedError", "len", "os.basename", "max", "tag2pairs[].append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "read_tb", "(", "path", ")", ":", "\n", "    ", "\"\"\"\n    path : a tensorboard file OR a directory, where we will find all TB files\n           of the form events.*\n    \"\"\"", "\n", "import", "pandas", "\n", "import", "numpy", "as", "np", "\n", "from", "glob", "import", "glob", "\n", "import", "tensorflow", "as", "tf", "\n", "if", "osp", ".", "isdir", "(", "path", ")", ":", "\n", "        ", "fnames", "=", "glob", "(", "osp", ".", "join", "(", "path", ",", "\"events.*\"", ")", ")", "\n", "", "elif", "osp", ".", "basename", "(", "path", ")", ".", "startswith", "(", "\"events.\"", ")", ":", "\n", "        ", "fnames", "=", "[", "path", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "(", "\"Expected tensorboard file or directory containing them. Got %s\"", "%", "path", ")", "\n", "", "tag2pairs", "=", "defaultdict", "(", "list", ")", "\n", "maxstep", "=", "0", "\n", "for", "fname", "in", "fnames", ":", "\n", "        ", "for", "summary", "in", "tf", ".", "train", ".", "summary_iterator", "(", "fname", ")", ":", "\n", "            ", "if", "summary", ".", "step", ">", "0", ":", "\n", "                ", "for", "v", "in", "summary", ".", "summary", ".", "value", ":", "\n", "                    ", "pair", "=", "(", "summary", ".", "step", ",", "v", ".", "simple_value", ")", "\n", "tag2pairs", "[", "v", ".", "tag", "]", ".", "append", "(", "pair", ")", "\n", "", "maxstep", "=", "max", "(", "summary", ".", "step", ",", "maxstep", ")", "\n", "", "", "", "data", "=", "np", ".", "empty", "(", "(", "maxstep", ",", "len", "(", "tag2pairs", ")", ")", ")", "\n", "data", "[", ":", "]", "=", "np", ".", "nan", "\n", "tags", "=", "sorted", "(", "tag2pairs", ".", "keys", "(", ")", ")", "\n", "for", "(", "colidx", ",", "tag", ")", "in", "enumerate", "(", "tags", ")", ":", "\n", "        ", "pairs", "=", "tag2pairs", "[", "tag", "]", "\n", "for", "(", "step", ",", "value", ")", "in", "pairs", ":", "\n", "            ", "data", "[", "step", "-", "1", ",", "colidx", "]", "=", "value", "\n", "", "", "return", "pandas", ".", "DataFrame", "(", "data", ",", "columns", "=", "tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.train": [[53, 84], ["run.get_env_type", "print", "int", "run.get_learn_function", "run.get_learn_function_defaults", "get_learn_function_defaults.update", "run.build_env", "print", "get_learn_function.", "baselines.common.vec_env.vec_video_recorder.VecVideoRecorder", "os.join", "get_learn_function_defaults.get", "run.get_default_network", "baselines.logger.get_dir"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_env_type", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function_defaults", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.build_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_default_network", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["def", "train", "(", "args", ",", "extra_args", ")", ":", "\n", "    ", "env_type", ",", "env_id", "=", "get_env_type", "(", "args", ")", "\n", "print", "(", "'env_type: {}'", ".", "format", "(", "env_type", ")", ")", "\n", "\n", "total_timesteps", "=", "int", "(", "args", ".", "num_timesteps", ")", "\n", "seed", "=", "args", ".", "seed", "\n", "\n", "learn", "=", "get_learn_function", "(", "args", ".", "alg", ")", "\n", "alg_kwargs", "=", "get_learn_function_defaults", "(", "args", ".", "alg", ",", "env_type", ")", "\n", "alg_kwargs", ".", "update", "(", "extra_args", ")", "\n", "\n", "env", "=", "build_env", "(", "args", ")", "\n", "if", "args", ".", "save_video_interval", "!=", "0", ":", "\n", "        ", "env", "=", "VecVideoRecorder", "(", "env", ",", "osp", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "\"videos\"", ")", ",", "record_video_trigger", "=", "lambda", "x", ":", "x", "%", "args", ".", "save_video_interval", "==", "0", ",", "video_length", "=", "args", ".", "save_video_length", ")", "\n", "\n", "", "if", "args", ".", "network", ":", "\n", "        ", "alg_kwargs", "[", "'network'", "]", "=", "args", ".", "network", "\n", "", "else", ":", "\n", "        ", "if", "alg_kwargs", ".", "get", "(", "'network'", ")", "is", "None", ":", "\n", "            ", "alg_kwargs", "[", "'network'", "]", "=", "get_default_network", "(", "env_type", ")", "\n", "\n", "", "", "print", "(", "'Training {} on {}:{} with arguments \\n{}'", ".", "format", "(", "args", ".", "alg", ",", "env_type", ",", "env_id", ",", "alg_kwargs", ")", ")", "\n", "\n", "model", "=", "learn", "(", "\n", "env", "=", "env", ",", "\n", "seed", "=", "seed", ",", "\n", "total_timesteps", "=", "total_timesteps", ",", "\n", "**", "alg_kwargs", "\n", ")", "\n", "\n", "return", "model", ",", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.build_env": [[86, 119], ["multiprocessing.cpu_count", "run.get_env_type", "tensorflow.ConfigProto", "baselines.common.tf_util.get_session", "baselines.common.cmd_util.make_vec_env", "baselines.common.cmd_util.make_env", "baselines.common.vec_env.VecNormalize", "baselines.common.cmd_util.make_env", "baselines.common.cmd_util.make_vec_env", "baselines.common.vec_env.VecFrameStack"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_env_type", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_vec_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_vec_env"], ["", "def", "build_env", "(", "args", ")", ":", "\n", "    ", "ncpu", "=", "multiprocessing", ".", "cpu_count", "(", ")", "\n", "if", "sys", ".", "platform", "==", "'darwin'", ":", "ncpu", "//=", "2", "\n", "nenv", "=", "args", ".", "num_env", "or", "ncpu", "\n", "alg", "=", "args", ".", "alg", "\n", "seed", "=", "args", ".", "seed", "\n", "\n", "env_type", ",", "env_id", "=", "get_env_type", "(", "args", ")", "\n", "\n", "if", "env_type", "in", "{", "'atari'", ",", "'retro'", "}", ":", "\n", "        ", "if", "alg", "==", "'deepq'", ":", "\n", "            ", "env", "=", "make_env", "(", "env_id", ",", "env_type", ",", "seed", "=", "seed", ",", "wrapper_kwargs", "=", "{", "'frame_stack'", ":", "True", "}", ")", "\n", "", "elif", "alg", "==", "'trpo_mpi'", ":", "\n", "            ", "env", "=", "make_env", "(", "env_id", ",", "env_type", ",", "seed", "=", "seed", ")", "\n", "", "else", ":", "\n", "            ", "frame_stack_size", "=", "4", "\n", "env", "=", "make_vec_env", "(", "env_id", ",", "env_type", ",", "nenv", ",", "seed", ",", "gamestate", "=", "args", ".", "gamestate", ",", "reward_scale", "=", "args", ".", "reward_scale", ")", "\n", "env", "=", "VecFrameStack", "(", "env", ",", "frame_stack_size", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "config", "=", "tf", ".", "ConfigProto", "(", "allow_soft_placement", "=", "True", ",", "\n", "intra_op_parallelism_threads", "=", "1", ",", "\n", "inter_op_parallelism_threads", "=", "1", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "get_session", "(", "config", "=", "config", ")", "\n", "\n", "flatten_dict_observations", "=", "alg", "not", "in", "{", "'her'", "}", "\n", "env", "=", "make_vec_env", "(", "env_id", ",", "env_type", ",", "args", ".", "num_env", "or", "1", ",", "seed", ",", "reward_scale", "=", "args", ".", "reward_scale", ",", "flatten_dict_observations", "=", "flatten_dict_observations", ")", "\n", "\n", "if", "env_type", "==", "'mujoco'", ":", "\n", "            ", "env", "=", "VecNormalize", "(", "env", ",", "use_tf", "=", "True", ")", "\n", "\n", "", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_env_type": [[121, 146], ["gym.envs.registry.all", "_game_envs[].add", "_game_envs.keys", "_game_envs.items", "[].split", "re.sub", "_game_envs.keys", "env.entry_point.split"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add"], ["", "def", "get_env_type", "(", "args", ")", ":", "\n", "    ", "env_id", "=", "args", ".", "env", "\n", "\n", "if", "args", ".", "env_type", "is", "not", "None", ":", "\n", "        ", "return", "args", ".", "env_type", ",", "env_id", "\n", "\n", "# Re-parse the gym registry, since we could have new envs since last time.", "\n", "", "for", "env", "in", "gym", ".", "envs", ".", "registry", ".", "all", "(", ")", ":", "\n", "        ", "env_type", "=", "env", ".", "entry_point", ".", "split", "(", "':'", ")", "[", "0", "]", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", "\n", "_game_envs", "[", "env_type", "]", ".", "add", "(", "env", ".", "id", ")", "# This is a set so add is idempotent", "\n", "\n", "", "if", "env_id", "in", "_game_envs", ".", "keys", "(", ")", ":", "\n", "        ", "env_type", "=", "env_id", "\n", "env_id", "=", "[", "g", "for", "g", "in", "_game_envs", "[", "env_type", "]", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "env_type", "=", "None", "\n", "for", "g", ",", "e", "in", "_game_envs", ".", "items", "(", ")", ":", "\n", "            ", "if", "env_id", "in", "e", ":", "\n", "                ", "env_type", "=", "g", "\n", "break", "\n", "", "", "if", "':'", "in", "env_id", ":", "\n", "            ", "env_type", "=", "re", ".", "sub", "(", "r':.*'", ",", "''", ",", "env_id", ")", "\n", "", "assert", "env_type", "is", "not", "None", ",", "'env_id {} is not recognized in env types'", ".", "format", "(", "env_id", ",", "_game_envs", ".", "keys", "(", ")", ")", "\n", "\n", "", "return", "env_type", ",", "env_id", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_default_network": [[148, 153], ["None"], "function", ["None"], ["", "def", "get_default_network", "(", "env_type", ")", ":", "\n", "    ", "if", "env_type", "in", "{", "'atari'", ",", "'retro'", "}", ":", "\n", "        ", "return", "'cnn'", "\n", "", "else", ":", "\n", "        ", "return", "'mlp'", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_alg_module": [[154, 164], ["importlib.import_module", "importlib.import_module"], "function", ["None"], ["", "", "def", "get_alg_module", "(", "alg", ",", "submodule", "=", "None", ")", ":", "\n", "    ", "submodule", "=", "submodule", "or", "alg", "\n", "try", ":", "\n", "# first try to import the alg module from baselines", "\n", "        ", "alg_module", "=", "import_module", "(", "'.'", ".", "join", "(", "[", "'baselines'", ",", "alg", ",", "submodule", "]", ")", ")", "\n", "", "except", "ImportError", ":", "\n", "# then from rl_algs", "\n", "        ", "alg_module", "=", "import_module", "(", "'.'", ".", "join", "(", "[", "'rl_'", "+", "'algs'", ",", "alg", ",", "submodule", "]", ")", ")", "\n", "\n", "", "return", "alg_module", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function": [[166, 168], ["run.get_alg_module"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_alg_module"], ["", "def", "get_learn_function", "(", "alg", ")", ":", "\n", "    ", "return", "get_alg_module", "(", "alg", ")", ".", "learn", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function_defaults": [[170, 177], ["run.get_alg_module", "getattr"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_alg_module"], ["", "def", "get_learn_function_defaults", "(", "alg", ",", "env_type", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "alg_defaults", "=", "get_alg_module", "(", "alg", ",", "'defaults'", ")", "\n", "kwargs", "=", "getattr", "(", "alg_defaults", ",", "env_type", ")", "(", ")", "\n", "", "except", "(", "ImportError", ",", "AttributeError", ")", ":", "\n", "        ", "kwargs", "=", "{", "}", "\n", "", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.parse_cmdline_kwargs": [[180, 193], ["isinstance", "run.parse_cmdline_kwargs.parse"], "function", ["None"], ["", "def", "parse_cmdline_kwargs", "(", "args", ")", ":", "\n", "    ", "'''\n    convert a list of '='-spaced command-line arguments to a dictionary, evaluating python objects when possible\n    '''", "\n", "def", "parse", "(", "v", ")", ":", "\n", "\n", "        ", "assert", "isinstance", "(", "v", ",", "str", ")", "\n", "try", ":", "\n", "            ", "return", "eval", "(", "v", ")", "\n", "", "except", "(", "NameError", ",", "SyntaxError", ")", ":", "\n", "            ", "return", "v", "\n", "\n", "", "", "return", "{", "k", ":", "parse", "(", "v", ")", "for", "k", ",", "v", "in", "parse_unknown_args", "(", "args", ")", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.configure_logger": [[195, 200], ["baselines.logger.configure", "baselines.logger.configure"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure"], ["", "def", "configure_logger", "(", "log_path", ",", "**", "kwargs", ")", ":", "\n", "    ", "if", "log_path", "is", "not", "None", ":", "\n", "        ", "logger", ".", "configure", "(", "log_path", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "configure", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.main": [[202, 248], ["baselines.common.cmd_util.common_arg_parser", "baselines.common.cmd_util.common_arg_parser.parse_known_args", "run.parse_cmdline_kwargs", "run.train", "env.close", "run.configure_logger", "MPI.COMM_WORLD.Get_rank", "run.configure_logger", "os.expanduser", "model.save", "baselines.logger.log", "env.reset", "numpy.zeros", "MPI.COMM_WORLD.Get_rank", "hasattr", "isinstance", "numpy.zeros", "numpy.zeros", "env.step", "env.render", "model.step", "model.step", "isinstance", "done.any", "numpy.nonzero", "print"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.common_arg_parser", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.parse_cmdline_kwargs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.configure_logger", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.configure_logger", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "", "def", "main", "(", "args", ")", ":", "\n", "# configure logger, disable logging in child MPI processes (with rank > 0)", "\n", "\n", "    ", "arg_parser", "=", "common_arg_parser", "(", ")", "\n", "args", ",", "unknown_args", "=", "arg_parser", ".", "parse_known_args", "(", "args", ")", "\n", "extra_args", "=", "parse_cmdline_kwargs", "(", "unknown_args", ")", "\n", "\n", "if", "MPI", "is", "None", "or", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "==", "0", ":", "\n", "        ", "rank", "=", "0", "\n", "configure_logger", "(", "args", ".", "log_path", ")", "\n", "", "else", ":", "\n", "        ", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "configure_logger", "(", "args", ".", "log_path", ",", "format_strs", "=", "[", "]", ")", "\n", "\n", "", "model", ",", "env", "=", "train", "(", "args", ",", "extra_args", ")", "\n", "\n", "if", "args", ".", "save_path", "is", "not", "None", "and", "rank", "==", "0", ":", "\n", "        ", "save_path", "=", "osp", ".", "expanduser", "(", "args", ".", "save_path", ")", "\n", "model", ".", "save", "(", "save_path", ")", "\n", "\n", "", "if", "args", ".", "play", ":", "\n", "        ", "logger", ".", "log", "(", "\"Running trained model\"", ")", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "\n", "state", "=", "model", ".", "initial_state", "if", "hasattr", "(", "model", ",", "'initial_state'", ")", "else", "None", "\n", "dones", "=", "np", ".", "zeros", "(", "(", "1", ",", ")", ")", "\n", "\n", "episode_rew", "=", "np", ".", "zeros", "(", "env", ".", "num_envs", ")", "if", "isinstance", "(", "env", ",", "VecEnv", ")", "else", "np", ".", "zeros", "(", "1", ")", "\n", "while", "True", ":", "\n", "            ", "if", "state", "is", "not", "None", ":", "\n", "                ", "actions", ",", "_", ",", "state", ",", "_", "=", "model", ".", "step", "(", "obs", ",", "S", "=", "state", ",", "M", "=", "dones", ")", "\n", "", "else", ":", "\n", "                ", "actions", ",", "_", ",", "_", ",", "_", "=", "model", ".", "step", "(", "obs", ")", "\n", "\n", "", "obs", ",", "rew", ",", "done", ",", "_", "=", "env", ".", "step", "(", "actions", ")", "\n", "episode_rew", "+=", "rew", "\n", "env", ".", "render", "(", ")", "\n", "done_any", "=", "done", ".", "any", "(", ")", "if", "isinstance", "(", "done", ",", "np", ".", "ndarray", ")", "else", "done", "\n", "if", "done_any", ":", "\n", "                ", "for", "i", "in", "np", ".", "nonzero", "(", "done", ")", "[", "0", "]", ":", "\n", "                    ", "print", "(", "'episode_rew={}'", ".", "format", "(", "episode_rew", "[", "i", "]", ")", ")", "\n", "episode_rew", "[", "i", "]", "=", "0", "\n", "\n", "", "", "", "", "env", ".", "close", "(", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.a2c.Model.__init__": [[33, 117], ["int", "baselines.common.tf_util.get_session", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "policy.pd.neglogp", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.losses.mean_squared_error", "baselines.a2c.utils.find_trainable_variables", "tensorflow.gradients", "list", "tensorflow.train.RMSPropOptimizer", "tensorflow.train.RMSPropOptimizer.apply_gradients", "baselines.a2c.utils.Scheduler", "functools.partial", "functools.partial", "tensorflow.global_variables_initializer().run", "tensorflow.variable_scope", "policy", "policy", "policy.pd.entropy", "tensorflow.squeeze", "tensorflow.clip_by_global_norm", "zip", "range", "baselines.common.tf_util.get_session.run", "len", "baselines.a2c.utils.Scheduler.value", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.neglogp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.find_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value"], ["def", "__init__", "(", "self", ",", "policy", ",", "env", ",", "nsteps", ",", "\n", "ent_coef", "=", "0.01", ",", "vf_coef", "=", "0.5", ",", "max_grad_norm", "=", "0.5", ",", "lr", "=", "7e-4", ",", "\n", "alpha", "=", "0.99", ",", "epsilon", "=", "1e-5", ",", "total_timesteps", "=", "int", "(", "80e6", ")", ",", "lrschedule", "=", "'linear'", ")", ":", "\n", "\n", "        ", "sess", "=", "tf_util", ".", "get_session", "(", ")", "\n", "nenvs", "=", "env", ".", "num_envs", "\n", "nbatch", "=", "nenvs", "*", "nsteps", "\n", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'a2c_model'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# step_model is used for sampling", "\n", "            ", "step_model", "=", "policy", "(", "nenvs", ",", "1", ",", "sess", ")", "\n", "\n", "# train_model is used to train our network", "\n", "train_model", "=", "policy", "(", "nbatch", ",", "nsteps", ",", "sess", ")", "\n", "\n", "", "A", "=", "tf", ".", "placeholder", "(", "train_model", ".", "action", ".", "dtype", ",", "train_model", ".", "action", ".", "shape", ")", "\n", "ADV", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "\n", "R", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "\n", "LR", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ")", "\n", "\n", "# Calculate the loss", "\n", "# Total loss = Policy gradient loss - entropy * entropy coefficient + Value coefficient * value loss", "\n", "\n", "# Policy loss", "\n", "neglogpac", "=", "train_model", ".", "pd", ".", "neglogp", "(", "A", ")", "\n", "# L = A(s,a) * -logpi(a|s)", "\n", "pg_loss", "=", "tf", ".", "reduce_mean", "(", "ADV", "*", "neglogpac", ")", "\n", "\n", "# Entropy is used to improve exploration by limiting the premature convergence to suboptimal policy.", "\n", "entropy", "=", "tf", ".", "reduce_mean", "(", "train_model", ".", "pd", ".", "entropy", "(", ")", ")", "\n", "\n", "# Value loss", "\n", "vf_loss", "=", "losses", ".", "mean_squared_error", "(", "tf", ".", "squeeze", "(", "train_model", ".", "vf", ")", ",", "R", ")", "\n", "\n", "loss", "=", "pg_loss", "-", "entropy", "*", "ent_coef", "+", "vf_loss", "*", "vf_coef", "\n", "\n", "# Update parameters using loss", "\n", "# 1. Get the model parameters", "\n", "params", "=", "find_trainable_variables", "(", "\"a2c_model\"", ")", "\n", "\n", "# 2. Calculate the gradients", "\n", "grads", "=", "tf", ".", "gradients", "(", "loss", ",", "params", ")", "\n", "if", "max_grad_norm", "is", "not", "None", ":", "\n", "# Clip the gradients (normalize)", "\n", "            ", "grads", ",", "grad_norm", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "max_grad_norm", ")", "\n", "", "grads", "=", "list", "(", "zip", "(", "grads", ",", "params", ")", ")", "\n", "# zip aggregate each gradient with parameters associated", "\n", "# For instance zip(ABCD, xyza) => Ax, By, Cz, Da", "\n", "\n", "# 3. Make op for one policy and value update step of A2C", "\n", "trainer", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "LR", ",", "decay", "=", "alpha", ",", "epsilon", "=", "epsilon", ")", "\n", "\n", "_train", "=", "trainer", ".", "apply_gradients", "(", "grads", ")", "\n", "\n", "lr", "=", "Scheduler", "(", "v", "=", "lr", ",", "nvalues", "=", "total_timesteps", ",", "schedule", "=", "lrschedule", ")", "\n", "\n", "def", "train", "(", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ")", ":", "\n", "# Here we calculate advantage A(s,a) = R + yV(s') - V(s)", "\n", "# rewards = R + yV(s')", "\n", "            ", "advs", "=", "rewards", "-", "values", "\n", "for", "step", "in", "range", "(", "len", "(", "obs", ")", ")", ":", "\n", "                ", "cur_lr", "=", "lr", ".", "value", "(", ")", "\n", "\n", "", "td_map", "=", "{", "train_model", ".", "X", ":", "obs", ",", "A", ":", "actions", ",", "ADV", ":", "advs", ",", "R", ":", "rewards", ",", "LR", ":", "cur_lr", "}", "\n", "if", "states", "is", "not", "None", ":", "\n", "                ", "td_map", "[", "train_model", ".", "S", "]", "=", "states", "\n", "td_map", "[", "train_model", ".", "M", "]", "=", "masks", "\n", "", "policy_loss", ",", "value_loss", ",", "policy_entropy", ",", "_", "=", "sess", ".", "run", "(", "\n", "[", "pg_loss", ",", "vf_loss", ",", "entropy", ",", "_train", "]", ",", "\n", "td_map", "\n", ")", "\n", "return", "policy_loss", ",", "value_loss", ",", "policy_entropy", "\n", "\n", "\n", "", "self", ".", "train", "=", "train", "\n", "self", ".", "train_model", "=", "train_model", "\n", "self", ".", "step_model", "=", "step_model", "\n", "self", ".", "step", "=", "step_model", ".", "step", "\n", "self", ".", "value", "=", "step_model", ".", "value", "\n", "self", ".", "initial_state", "=", "step_model", ".", "initial_state", "\n", "self", ".", "save", "=", "functools", ".", "partial", "(", "tf_util", ".", "save_variables", ",", "sess", "=", "sess", ")", "\n", "self", ".", "load", "=", "functools", ".", "partial", "(", "tf_util", ".", "load_variables", ",", "sess", "=", "sess", ")", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", "session", "=", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.a2c.learn": [[119, 232], ["int", "baselines.common.set_global_seeds", "baselines.common.policies.build_policy", "a2c.Model", "baselines.a2c.runner.Runner", "collections.deque", "time.time", "range", "Model.load", "baselines.a2c.runner.Runner.run", "collections.deque.extend", "Model.train", "int", "time.time", "baselines.common.explained_variance", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.dump_tabular", "float", "float", "float", "baselines.ppo2.ppo2.safemean", "baselines.ppo2.ppo2.safemean"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.build_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.explained_variance", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean"], ["", "", "def", "learn", "(", "\n", "network", ",", "\n", "env", ",", "\n", "seed", "=", "None", ",", "\n", "nsteps", "=", "5", ",", "\n", "total_timesteps", "=", "int", "(", "80e6", ")", ",", "\n", "vf_coef", "=", "0.5", ",", "\n", "ent_coef", "=", "0.01", ",", "\n", "max_grad_norm", "=", "0.5", ",", "\n", "lr", "=", "7e-4", ",", "\n", "lrschedule", "=", "'linear'", ",", "\n", "epsilon", "=", "1e-5", ",", "\n", "alpha", "=", "0.99", ",", "\n", "gamma", "=", "0.99", ",", "\n", "log_interval", "=", "100", ",", "\n", "load_path", "=", "None", ",", "\n", "**", "network_kwargs", ")", ":", "\n", "\n", "    ", "'''\n    Main entrypoint for A2C algorithm. Train a policy with given network architecture on a given environment using a2c algorithm.\n\n    Parameters:\n    -----------\n\n    network:            policy network architecture. Either string (mlp, lstm, lnlstm, cnn_lstm, cnn, cnn_small, conv_only - see baselines.common/models.py for full list)\n                        specifying the standard network architecture, or a function that takes tensorflow tensor as input and returns\n                        tuple (output_tensor, extra_feed) where output tensor is the last network layer output, extra_feed is None for feed-forward\n                        neural nets, and extra_feed is a dictionary describing how to feed state into the network for recurrent neural nets.\n                        See baselines.common/policies.py/lstm for more details on using recurrent nets in policies\n\n\n    env:                RL environment. Should implement interface similar to VecEnv (baselines.common/vec_env) or be wrapped with DummyVecEnv (baselines.common/vec_env/dummy_vec_env.py)\n\n\n    seed:               seed to make random number sequence in the alorightm reproducible. By default is None which means seed from system noise generator (not reproducible)\n\n    nsteps:             int, number of steps of the vectorized environment per update (i.e. batch size is nsteps * nenv where\n                        nenv is number of environment copies simulated in parallel)\n\n    total_timesteps:    int, total number of timesteps to train on (default: 80M)\n\n    vf_coef:            float, coefficient in front of value function loss in the total loss function (default: 0.5)\n\n    ent_coef:           float, coeffictiant in front of the policy entropy in the total loss function (default: 0.01)\n\n    max_gradient_norm:  float, gradient is clipped to have global L2 norm no more than this value (default: 0.5)\n\n    lr:                 float, learning rate for RMSProp (current implementation has RMSProp hardcoded in) (default: 7e-4)\n\n    lrschedule:         schedule of learning rate. Can be 'linear', 'constant', or a function [0..1] -> [0..1] that takes fraction of the training progress as input and\n                        returns fraction of the learning rate (specified as lr) as output\n\n    epsilon:            float, RMSProp epsilon (stabilizes square root computation in denominator of RMSProp update) (default: 1e-5)\n\n    alpha:              float, RMSProp decay parameter (default: 0.99)\n\n    gamma:              float, reward discounting parameter (default: 0.99)\n\n    log_interval:       int, specifies how frequently the logs are printed out (default: 100)\n\n    **network_kwargs:   keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n                        For instance, 'mlp' network architecture has arguments num_hidden and num_layers.\n\n    '''", "\n", "\n", "\n", "\n", "set_global_seeds", "(", "seed", ")", "\n", "\n", "# Get the nb of env", "\n", "nenvs", "=", "env", ".", "num_envs", "\n", "policy", "=", "build_policy", "(", "env", ",", "network", ",", "**", "network_kwargs", ")", "\n", "\n", "# Instantiate the model object (that creates step_model and train_model)", "\n", "model", "=", "Model", "(", "policy", "=", "policy", ",", "env", "=", "env", ",", "nsteps", "=", "nsteps", ",", "ent_coef", "=", "ent_coef", ",", "vf_coef", "=", "vf_coef", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ",", "lr", "=", "lr", ",", "alpha", "=", "alpha", ",", "epsilon", "=", "epsilon", ",", "total_timesteps", "=", "total_timesteps", ",", "lrschedule", "=", "lrschedule", ")", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "model", ".", "load", "(", "load_path", ")", "\n", "\n", "# Instantiate the runner object", "\n", "", "runner", "=", "Runner", "(", "env", ",", "model", ",", "nsteps", "=", "nsteps", ",", "gamma", "=", "gamma", ")", "\n", "epinfobuf", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "\n", "# Calculate the batch_size", "\n", "nbatch", "=", "nenvs", "*", "nsteps", "\n", "\n", "# Start total timer", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "update", "in", "range", "(", "1", ",", "total_timesteps", "//", "nbatch", "+", "1", ")", ":", "\n", "# Get mini batch of experiences", "\n", "        ", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ",", "epinfos", "=", "runner", ".", "run", "(", ")", "\n", "epinfobuf", ".", "extend", "(", "epinfos", ")", "\n", "\n", "policy_loss", ",", "value_loss", ",", "policy_entropy", "=", "model", ".", "train", "(", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ")", "\n", "nseconds", "=", "time", ".", "time", "(", ")", "-", "tstart", "\n", "\n", "# Calculate the fps (frame per second)", "\n", "fps", "=", "int", "(", "(", "update", "*", "nbatch", ")", "/", "nseconds", ")", "\n", "if", "update", "%", "log_interval", "==", "0", "or", "update", "==", "1", ":", "\n", "# Calculates if value function is a good predicator of the returns (ev > 1)", "\n", "# or if it's just worse than predicting nothing (ev =< 0)", "\n", "            ", "ev", "=", "explained_variance", "(", "values", ",", "rewards", ")", "\n", "logger", ".", "record_tabular", "(", "\"nupdates\"", ",", "update", ")", "\n", "logger", ".", "record_tabular", "(", "\"total_timesteps\"", ",", "update", "*", "nbatch", ")", "\n", "logger", ".", "record_tabular", "(", "\"fps\"", ",", "fps", ")", "\n", "logger", ".", "record_tabular", "(", "\"policy_entropy\"", ",", "float", "(", "policy_entropy", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"value_loss\"", ",", "float", "(", "value_loss", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"explained_variance\"", ",", "float", "(", "ev", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"eprewmean\"", ",", "safemean", "(", "[", "epinfo", "[", "'r'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"eplenmean\"", ",", "safemean", "(", "[", "epinfo", "[", "'l'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "\n", "logger", ".", "dump_tabular", "(", ")", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.runner.Runner.__init__": [[15, 20], ["baselines.common.runners.AbstractEnvRunner.__init__", "model.train_model.action.shape.as_list"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "model", ",", "nsteps", "=", "5", ",", "gamma", "=", "0.99", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", "=", "env", ",", "model", "=", "model", ",", "nsteps", "=", "nsteps", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "batch_action_shape", "=", "[", "x", "if", "x", "is", "not", "None", "else", "-", "1", "for", "x", "in", "model", ".", "train_model", ".", "action", ".", "shape", ".", "as_list", "(", ")", "]", "\n", "self", ".", "ob_dtype", "=", "model", ".", "train_model", ".", "X", ".", "dtype", ".", "as_numpy_dtype", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.runner.Runner.run": [[21, 77], ["range", "numpy.asarray().swapaxes.append", "numpy.asarray().swapaxes().reshape", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "mb_actions.reshape.reshape.reshape", "mb_rewards.flatten.flatten.flatten", "mb_values.flatten.flatten.flatten", "mb_masks.flatten.flatten.flatten", "runner.Runner.model.step", "numpy.asarray().swapaxes().reshape.append", "mb_actions.reshape.reshape.append", "mb_values.flatten.flatten.append", "numpy.asarray().swapaxes.append", "runner.Runner.env.step", "mb_rewards.flatten.flatten.append", "runner.Runner.model.value().tolist", "enumerate", "numpy.copy", "info.get", "numpy.asarray().swapaxes", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "zip", "baselines.a2c.utils.discount_with_dones.tolist", "dones.tolist.tolist.tolist", "epinfos.append", "runner.Runner.model.value", "baselines.a2c.utils.discount_with_dones", "numpy.asarray", "baselines.a2c.utils.discount_with_dones"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.discount_with_dones", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.discount_with_dones"], ["", "def", "run", "(", "self", ")", ":", "\n", "# We initialize the lists that will contain the mb of experiences", "\n", "        ", "mb_obs", ",", "mb_rewards", ",", "mb_actions", ",", "mb_values", ",", "mb_dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "mb_states", "=", "self", ".", "states", "\n", "epinfos", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "self", ".", "nsteps", ")", ":", "\n", "# Given observations, take action and value (V(s))", "\n", "# We already have self.obs because Runner superclass run self.obs[:] = env.reset() on init", "\n", "            ", "actions", ",", "values", ",", "states", ",", "_", "=", "self", ".", "model", ".", "step", "(", "self", ".", "obs", ",", "S", "=", "self", ".", "states", ",", "M", "=", "self", ".", "dones", ")", "\n", "\n", "# Append the experiences", "\n", "mb_obs", ".", "append", "(", "np", ".", "copy", "(", "self", ".", "obs", ")", ")", "\n", "mb_actions", ".", "append", "(", "actions", ")", "\n", "mb_values", ".", "append", "(", "values", ")", "\n", "mb_dones", ".", "append", "(", "self", ".", "dones", ")", "\n", "\n", "# Take actions in env and look the results", "\n", "obs", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "env", ".", "step", "(", "actions", ")", "\n", "for", "info", "in", "infos", ":", "\n", "                ", "maybeepinfo", "=", "info", ".", "get", "(", "'episode'", ")", "\n", "if", "maybeepinfo", ":", "epinfos", ".", "append", "(", "maybeepinfo", ")", "\n", "", "self", ".", "states", "=", "states", "\n", "self", ".", "dones", "=", "dones", "\n", "self", ".", "obs", "=", "obs", "\n", "mb_rewards", ".", "append", "(", "rewards", ")", "\n", "", "mb_dones", ".", "append", "(", "self", ".", "dones", ")", "\n", "\n", "# Batch of steps to batch of rollouts", "\n", "mb_obs", "=", "np", ".", "asarray", "(", "mb_obs", ",", "dtype", "=", "self", ".", "ob_dtype", ")", ".", "swapaxes", "(", "1", ",", "0", ")", ".", "reshape", "(", "self", ".", "batch_ob_shape", ")", "\n", "mb_rewards", "=", "np", ".", "asarray", "(", "mb_rewards", ",", "dtype", "=", "np", ".", "float32", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_actions", "=", "np", ".", "asarray", "(", "mb_actions", ",", "dtype", "=", "self", ".", "model", ".", "train_model", ".", "action", ".", "dtype", ".", "name", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_values", "=", "np", ".", "asarray", "(", "mb_values", ",", "dtype", "=", "np", ".", "float32", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_dones", "=", "np", ".", "asarray", "(", "mb_dones", ",", "dtype", "=", "np", ".", "bool", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_masks", "=", "mb_dones", "[", ":", ",", ":", "-", "1", "]", "\n", "mb_dones", "=", "mb_dones", "[", ":", ",", "1", ":", "]", "\n", "\n", "\n", "if", "self", ".", "gamma", ">", "0.0", ":", "\n", "# Discount/bootstrap off value fn", "\n", "            ", "last_values", "=", "self", ".", "model", ".", "value", "(", "self", ".", "obs", ",", "S", "=", "self", ".", "states", ",", "M", "=", "self", ".", "dones", ")", ".", "tolist", "(", ")", "\n", "for", "n", ",", "(", "rewards", ",", "dones", ",", "value", ")", "in", "enumerate", "(", "zip", "(", "mb_rewards", ",", "mb_dones", ",", "last_values", ")", ")", ":", "\n", "                ", "rewards", "=", "rewards", ".", "tolist", "(", ")", "\n", "dones", "=", "dones", ".", "tolist", "(", ")", "\n", "if", "dones", "[", "-", "1", "]", "==", "0", ":", "\n", "                    ", "rewards", "=", "discount_with_dones", "(", "rewards", "+", "[", "value", "]", ",", "dones", "+", "[", "0", "]", ",", "self", ".", "gamma", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "rewards", "=", "discount_with_dones", "(", "rewards", ",", "dones", ",", "self", ".", "gamma", ")", "\n", "\n", "", "mb_rewards", "[", "n", "]", "=", "rewards", "\n", "\n", "", "", "mb_actions", "=", "mb_actions", ".", "reshape", "(", "self", ".", "batch_action_shape", ")", "\n", "\n", "mb_rewards", "=", "mb_rewards", ".", "flatten", "(", ")", "\n", "mb_values", "=", "mb_values", ".", "flatten", "(", ")", "\n", "mb_masks", "=", "mb_masks", ".", "flatten", "(", ")", "\n", "return", "mb_obs", ",", "mb_states", ",", "mb_rewards", ",", "mb_masks", ",", "mb_actions", ",", "mb_values", ",", "epinfos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.Scheduler.__init__": [[199, 204], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "v", ",", "nvalues", ",", "schedule", ")", ":", "\n", "        ", "self", ".", "n", "=", "0.", "\n", "self", ".", "v", "=", "v", "\n", "self", ".", "nvalues", "=", "nvalues", "\n", "self", ".", "schedule", "=", "schedules", "[", "schedule", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.Scheduler.value": [[205, 209], ["utils.Scheduler.schedule"], "methods", ["None"], ["", "def", "value", "(", "self", ")", ":", "\n", "        ", "current_value", "=", "self", ".", "v", "*", "self", ".", "schedule", "(", "self", ".", "n", "/", "self", ".", "nvalues", ")", "\n", "self", ".", "n", "+=", "1.", "\n", "return", "current_value", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.Scheduler.value_steps": [[210, 212], ["utils.Scheduler.schedule"], "methods", ["None"], ["", "def", "value_steps", "(", "self", ",", "steps", ")", ":", "\n", "        ", "return", "self", ".", "v", "*", "self", ".", "schedule", "(", "steps", "/", "self", ".", "nvalues", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.EpisodeStats.__init__": [[215, 223], ["range", "collections.deque", "collections.deque", "utils.EpisodeStats.episode_rewards.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["    ", "def", "__init__", "(", "self", ",", "nsteps", ",", "nenvs", ")", ":", "\n", "        ", "self", ".", "episode_rewards", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nenvs", ")", ":", "\n", "            ", "self", ".", "episode_rewards", ".", "append", "(", "[", "]", ")", "\n", "", "self", ".", "lenbuffer", "=", "deque", "(", "maxlen", "=", "40", ")", "# rolling buffer for episode lengths", "\n", "self", ".", "rewbuffer", "=", "deque", "(", "maxlen", "=", "40", ")", "# rolling buffer for episode rewards", "\n", "self", ".", "nsteps", "=", "nsteps", "\n", "self", ".", "nenvs", "=", "nenvs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.EpisodeStats.feed": [[224, 236], ["numpy.reshape", "numpy.reshape", "range", "range", "utils.EpisodeStats.episode_rewards[].append", "len", "sum", "utils.EpisodeStats.lenbuffer.append", "utils.EpisodeStats.rewbuffer.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "feed", "(", "self", ",", "rewards", ",", "masks", ")", ":", "\n", "        ", "rewards", "=", "np", ".", "reshape", "(", "rewards", ",", "[", "self", ".", "nenvs", ",", "self", ".", "nsteps", "]", ")", "\n", "masks", "=", "np", ".", "reshape", "(", "masks", ",", "[", "self", ".", "nenvs", ",", "self", ".", "nsteps", "]", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "self", ".", "nenvs", ")", ":", "\n", "            ", "for", "j", "in", "range", "(", "0", ",", "self", ".", "nsteps", ")", ":", "\n", "                ", "self", ".", "episode_rewards", "[", "i", "]", ".", "append", "(", "rewards", "[", "i", "]", "[", "j", "]", ")", "\n", "if", "masks", "[", "i", "]", "[", "j", "]", ":", "\n", "                    ", "l", "=", "len", "(", "self", ".", "episode_rewards", "[", "i", "]", ")", "\n", "s", "=", "sum", "(", "self", ".", "episode_rewards", "[", "i", "]", ")", "\n", "self", ".", "lenbuffer", ".", "append", "(", "l", ")", "\n", "self", ".", "rewbuffer", ".", "append", "(", "s", ")", "\n", "self", ".", "episode_rewards", "[", "i", "]", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.EpisodeStats.mean_length": [[237, 242], ["numpy.mean"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "", "", "def", "mean_length", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "lenbuffer", ":", "\n", "            ", "return", "np", ".", "mean", "(", "self", ".", "lenbuffer", ")", "\n", "", "else", ":", "\n", "            ", "return", "0", "# on the first params dump, no episodes are finished", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.EpisodeStats.mean_reward": [[243, 248], ["numpy.mean"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "def", "mean_reward", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "rewbuffer", ":", "\n", "            ", "return", "np", ".", "mean", "(", "self", ".", "rewbuffer", ")", "\n", "", "else", ":", "\n", "            ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.sample": [[6, 9], ["tensorflow.random_uniform", "tensorflow.argmax", "tensorflow.shape", "tensorflow.log", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["def", "sample", "(", "logits", ")", ":", "\n", "    ", "noise", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "logits", ")", ")", "\n", "return", "tf", ".", "argmax", "(", "logits", "-", "tf", ".", "log", "(", "-", "tf", ".", "log", "(", "noise", ")", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.cat_entropy": [[10, 16], ["tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "cat_entropy", "(", "logits", ")", ":", "\n", "    ", "a0", "=", "logits", "-", "tf", ".", "reduce_max", "(", "logits", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "z0", "=", "tf", ".", "reduce_sum", "(", "ea0", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "tf", ".", "reduce_sum", "(", "p0", "*", "(", "tf", ".", "log", "(", "z0", ")", "-", "a0", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.cat_entropy_softmax": [[17, 19], ["tensorflow.reduce_sum", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "cat_entropy_softmax", "(", "p0", ")", ":", "\n", "    ", "return", "-", "tf", ".", "reduce_sum", "(", "p0", "*", "tf", ".", "log", "(", "p0", "+", "1e-6", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.ortho_init": [[20, 36], ["tuple", "numpy.random.normal", "numpy.linalg.svd", "q.reshape.reshape", "len", "len", "numpy.prod"], "function", ["None"], ["", "def", "ortho_init", "(", "scale", "=", "1.0", ")", ":", "\n", "    ", "def", "_ortho_init", "(", "shape", ",", "dtype", ",", "partition_info", "=", "None", ")", ":", "\n", "#lasagne ortho init for tf", "\n", "        ", "shape", "=", "tuple", "(", "shape", ")", "\n", "if", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "flat_shape", "=", "shape", "\n", "", "elif", "len", "(", "shape", ")", "==", "4", ":", "# assumes NHWC", "\n", "            ", "flat_shape", "=", "(", "np", ".", "prod", "(", "shape", "[", ":", "-", "1", "]", ")", ",", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "a", "=", "np", ".", "random", ".", "normal", "(", "0.0", ",", "1.0", ",", "flat_shape", ")", "\n", "u", ",", "_", ",", "v", "=", "np", ".", "linalg", ".", "svd", "(", "a", ",", "full_matrices", "=", "False", ")", "\n", "q", "=", "u", "if", "u", ".", "shape", "==", "flat_shape", "else", "v", "# pick the one with the correct shape", "\n", "q", "=", "q", ".", "reshape", "(", "shape", ")", "\n", "return", "(", "scale", "*", "q", "[", ":", "shape", "[", "0", "]", ",", ":", "shape", "[", "1", "]", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "return", "_ortho_init", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv": [[37, 57], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "x.get_shape", "tensorflow.reshape", "tensorflow.nn.conv2d", "utils.ortho_init", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.ortho_init"], ["", "def", "conv", "(", "x", ",", "scope", ",", "*", ",", "nf", ",", "rf", ",", "stride", ",", "pad", "=", "'VALID'", ",", "init_scale", "=", "1.0", ",", "data_format", "=", "'NHWC'", ",", "one_dim_bias", "=", "False", ")", ":", "\n", "    ", "if", "data_format", "==", "'NHWC'", ":", "\n", "        ", "channel_ax", "=", "3", "\n", "strides", "=", "[", "1", ",", "stride", ",", "stride", ",", "1", "]", "\n", "bshape", "=", "[", "1", ",", "1", ",", "1", ",", "nf", "]", "\n", "", "elif", "data_format", "==", "'NCHW'", ":", "\n", "        ", "channel_ax", "=", "1", "\n", "strides", "=", "[", "1", ",", "1", ",", "stride", ",", "stride", "]", "\n", "bshape", "=", "[", "1", ",", "nf", ",", "1", ",", "1", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "bias_var_shape", "=", "[", "nf", "]", "if", "one_dim_bias", "else", "[", "1", ",", "nf", ",", "1", ",", "1", "]", "\n", "nin", "=", "x", ".", "get_shape", "(", ")", "[", "channel_ax", "]", ".", "value", "\n", "wshape", "=", "[", "rf", ",", "rf", ",", "nin", ",", "nf", "]", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "wshape", ",", "initializer", "=", "ortho_init", "(", "init_scale", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "bias_var_shape", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "if", "not", "one_dim_bias", "and", "data_format", "==", "'NHWC'", ":", "\n", "            ", "b", "=", "tf", ".", "reshape", "(", "b", ",", "bshape", ")", "\n", "", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "w", ",", "strides", "=", "strides", ",", "padding", "=", "pad", ",", "data_format", "=", "data_format", ")", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc": [[58, 64], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "x.get_shape", "utils.ortho_init", "tensorflow.constant_initializer"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.ortho_init"], ["", "", "def", "fc", "(", "x", ",", "scope", ",", "nh", ",", "*", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "nin", "=", "x", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "[", "nin", ",", "nh", "]", ",", "initializer", "=", "ortho_init", "(", "init_scale", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "[", "nh", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "init_bias", ")", ")", "\n", "return", "tf", ".", "matmul", "(", "x", ",", "w", ")", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq": [[65, 71], ["tensorflow.reshape", "tensorflow.reshape", "tensorflow.squeeze", "tensorflow.split"], "function", ["None"], ["", "", "def", "batch_to_seq", "(", "h", ",", "nbatch", ",", "nsteps", ",", "flat", "=", "False", ")", ":", "\n", "    ", "if", "flat", ":", "\n", "        ", "h", "=", "tf", ".", "reshape", "(", "h", ",", "[", "nbatch", ",", "nsteps", "]", ")", "\n", "", "else", ":", "\n", "        ", "h", "=", "tf", ".", "reshape", "(", "h", ",", "[", "nbatch", ",", "nsteps", ",", "-", "1", "]", ")", "\n", "", "return", "[", "tf", ".", "squeeze", "(", "v", ",", "[", "1", "]", ")", "for", "v", "in", "tf", ".", "split", "(", "axis", "=", "1", ",", "num_or_size_splits", "=", "nsteps", ",", "value", "=", "h", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.seq_to_batch": [[72, 80], ["h[].get_shape().as_list", "tensorflow.reshape", "tensorflow.reshape", "h[].get_shape", "len", "tensorflow.concat", "tensorflow.stack", "h[].get_shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "seq_to_batch", "(", "h", ",", "flat", "=", "False", ")", ":", "\n", "    ", "shape", "=", "h", "[", "0", "]", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "if", "not", "flat", ":", "\n", "        ", "assert", "(", "len", "(", "shape", ")", ">", "1", ")", "\n", "nh", "=", "h", "[", "0", "]", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "h", ")", ",", "[", "-", "1", ",", "nh", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "reshape", "(", "tf", ".", "stack", "(", "values", "=", "h", ",", "axis", "=", "1", ")", ",", "[", "-", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.lstm": [[81, 103], ["tensorflow.split", "enumerate", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "zip", "tensorflow.split", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.tanh", "xs[].get_shape", "tensorflow.tanh", "utils.ortho_init", "utils.ortho_init", "tensorflow.constant_initializer", "tensorflow.matmul", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.ortho_init", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.ortho_init"], ["", "", "def", "lstm", "(", "xs", ",", "ms", ",", "s", ",", "scope", ",", "nh", ",", "init_scale", "=", "1.0", ")", ":", "\n", "    ", "nbatch", ",", "nin", "=", "[", "v", ".", "value", "for", "v", "in", "xs", "[", "0", "]", ".", "get_shape", "(", ")", "]", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "wx", "=", "tf", ".", "get_variable", "(", "\"wx\"", ",", "[", "nin", ",", "nh", "*", "4", "]", ",", "initializer", "=", "ortho_init", "(", "init_scale", ")", ")", "\n", "wh", "=", "tf", ".", "get_variable", "(", "\"wh\"", ",", "[", "nh", ",", "nh", "*", "4", "]", ",", "initializer", "=", "ortho_init", "(", "init_scale", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "[", "nh", "*", "4", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "", "c", ",", "h", "=", "tf", ".", "split", "(", "axis", "=", "1", ",", "num_or_size_splits", "=", "2", ",", "value", "=", "s", ")", "\n", "for", "idx", ",", "(", "x", ",", "m", ")", "in", "enumerate", "(", "zip", "(", "xs", ",", "ms", ")", ")", ":", "\n", "        ", "c", "=", "c", "*", "(", "1", "-", "m", ")", "\n", "h", "=", "h", "*", "(", "1", "-", "m", ")", "\n", "z", "=", "tf", ".", "matmul", "(", "x", ",", "wx", ")", "+", "tf", ".", "matmul", "(", "h", ",", "wh", ")", "+", "b", "\n", "i", ",", "f", ",", "o", ",", "u", "=", "tf", ".", "split", "(", "axis", "=", "1", ",", "num_or_size_splits", "=", "4", ",", "value", "=", "z", ")", "\n", "i", "=", "tf", ".", "nn", ".", "sigmoid", "(", "i", ")", "\n", "f", "=", "tf", ".", "nn", ".", "sigmoid", "(", "f", ")", "\n", "o", "=", "tf", ".", "nn", ".", "sigmoid", "(", "o", ")", "\n", "u", "=", "tf", ".", "tanh", "(", "u", ")", "\n", "c", "=", "f", "*", "c", "+", "i", "*", "u", "\n", "h", "=", "o", "*", "tf", ".", "tanh", "(", "c", ")", "\n", "xs", "[", "idx", "]", "=", "h", "\n", "", "s", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "[", "c", ",", "h", "]", ")", "\n", "return", "xs", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils._ln": [[104, 109], ["tensorflow.nn.moments", "tensorflow.sqrt"], "function", ["None"], ["", "def", "_ln", "(", "x", ",", "g", ",", "b", ",", "e", "=", "1e-5", ",", "axes", "=", "[", "1", "]", ")", ":", "\n", "    ", "u", ",", "s", "=", "tf", ".", "nn", ".", "moments", "(", "x", ",", "axes", "=", "axes", ",", "keep_dims", "=", "True", ")", "\n", "x", "=", "(", "x", "-", "u", ")", "/", "tf", ".", "sqrt", "(", "s", "+", "e", ")", "\n", "x", "=", "x", "*", "g", "+", "b", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.lnlstm": [[110, 141], ["tensorflow.split", "enumerate", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "zip", "tensorflow.split", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.tanh", "xs[].get_shape", "tensorflow.tanh", "utils.ortho_init", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "utils.ortho_init", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "utils._ln", "utils._ln", "utils._ln", "tensorflow.matmul", "tensorflow.matmul"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.ortho_init", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.ortho_init", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils._ln", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils._ln", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils._ln"], ["", "def", "lnlstm", "(", "xs", ",", "ms", ",", "s", ",", "scope", ",", "nh", ",", "init_scale", "=", "1.0", ")", ":", "\n", "    ", "nbatch", ",", "nin", "=", "[", "v", ".", "value", "for", "v", "in", "xs", "[", "0", "]", ".", "get_shape", "(", ")", "]", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "wx", "=", "tf", ".", "get_variable", "(", "\"wx\"", ",", "[", "nin", ",", "nh", "*", "4", "]", ",", "initializer", "=", "ortho_init", "(", "init_scale", ")", ")", "\n", "gx", "=", "tf", ".", "get_variable", "(", "\"gx\"", ",", "[", "nh", "*", "4", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ")", "\n", "bx", "=", "tf", ".", "get_variable", "(", "\"bx\"", ",", "[", "nh", "*", "4", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "wh", "=", "tf", ".", "get_variable", "(", "\"wh\"", ",", "[", "nh", ",", "nh", "*", "4", "]", ",", "initializer", "=", "ortho_init", "(", "init_scale", ")", ")", "\n", "gh", "=", "tf", ".", "get_variable", "(", "\"gh\"", ",", "[", "nh", "*", "4", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ")", "\n", "bh", "=", "tf", ".", "get_variable", "(", "\"bh\"", ",", "[", "nh", "*", "4", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "[", "nh", "*", "4", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "gc", "=", "tf", ".", "get_variable", "(", "\"gc\"", ",", "[", "nh", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ")", "\n", "bc", "=", "tf", ".", "get_variable", "(", "\"bc\"", ",", "[", "nh", "]", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "\n", "", "c", ",", "h", "=", "tf", ".", "split", "(", "axis", "=", "1", ",", "num_or_size_splits", "=", "2", ",", "value", "=", "s", ")", "\n", "for", "idx", ",", "(", "x", ",", "m", ")", "in", "enumerate", "(", "zip", "(", "xs", ",", "ms", ")", ")", ":", "\n", "        ", "c", "=", "c", "*", "(", "1", "-", "m", ")", "\n", "h", "=", "h", "*", "(", "1", "-", "m", ")", "\n", "z", "=", "_ln", "(", "tf", ".", "matmul", "(", "x", ",", "wx", ")", ",", "gx", ",", "bx", ")", "+", "_ln", "(", "tf", ".", "matmul", "(", "h", ",", "wh", ")", ",", "gh", ",", "bh", ")", "+", "b", "\n", "i", ",", "f", ",", "o", ",", "u", "=", "tf", ".", "split", "(", "axis", "=", "1", ",", "num_or_size_splits", "=", "4", ",", "value", "=", "z", ")", "\n", "i", "=", "tf", ".", "nn", ".", "sigmoid", "(", "i", ")", "\n", "f", "=", "tf", ".", "nn", ".", "sigmoid", "(", "f", ")", "\n", "o", "=", "tf", ".", "nn", ".", "sigmoid", "(", "o", ")", "\n", "u", "=", "tf", ".", "tanh", "(", "u", ")", "\n", "c", "=", "f", "*", "c", "+", "i", "*", "u", "\n", "h", "=", "o", "*", "tf", ".", "tanh", "(", "_ln", "(", "c", ",", "gc", ",", "bc", ")", ")", "\n", "xs", "[", "idx", "]", "=", "h", "\n", "", "s", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "[", "c", ",", "h", "]", ")", "\n", "return", "xs", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv_to_fc": [[142, 146], ["numpy.prod", "tensorflow.reshape", "tf.reshape.get_shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "conv_to_fc", "(", "x", ")", ":", "\n", "    ", "nh", "=", "np", ".", "prod", "(", "[", "v", ".", "value", "for", "v", "in", "x", ".", "get_shape", "(", ")", "[", "1", ":", "]", "]", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "nh", "]", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.discount_with_dones": [[147, 154], ["zip", "discounted.append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "discount_with_dones", "(", "rewards", ",", "dones", ",", "gamma", ")", ":", "\n", "    ", "discounted", "=", "[", "]", "\n", "r", "=", "0", "\n", "for", "reward", ",", "done", "in", "zip", "(", "rewards", "[", ":", ":", "-", "1", "]", ",", "dones", "[", ":", ":", "-", "1", "]", ")", ":", "\n", "        ", "r", "=", "reward", "+", "gamma", "*", "r", "*", "(", "1.", "-", "done", ")", "# fixed off by one bug", "\n", "discounted", ".", "append", "(", "r", ")", "\n", "", "return", "discounted", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.find_trainable_variables": [[155, 157], ["tensorflow.trainable_variables"], "function", ["None"], ["", "def", "find_trainable_variables", "(", "key", ")", ":", "\n", "    ", "return", "tf", ".", "trainable_variables", "(", "key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.make_path": [[158, 160], ["os.makedirs"], "function", ["None"], ["", "def", "make_path", "(", "f", ")", ":", "\n", "    ", "return", "os", ".", "makedirs", "(", "f", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.constant": [[161, 163], ["None"], "function", ["None"], ["", "def", "constant", "(", "p", ")", ":", "\n", "    ", "return", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.linear": [[164, 166], ["None"], "function", ["None"], ["", "def", "linear", "(", "p", ")", ":", "\n", "    ", "return", "1", "-", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.middle_drop": [[167, 172], ["None"], "function", ["None"], ["", "def", "middle_drop", "(", "p", ")", ":", "\n", "    ", "eps", "=", "0.75", "\n", "if", "1", "-", "p", "<", "eps", ":", "\n", "        ", "return", "eps", "*", "0.1", "\n", "", "return", "1", "-", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.double_linear_con": [[173, 179], ["None"], "function", ["None"], ["", "def", "double_linear_con", "(", "p", ")", ":", "\n", "    ", "p", "*=", "2", "\n", "eps", "=", "0.125", "\n", "if", "1", "-", "p", "<", "eps", ":", "\n", "        ", "return", "eps", "\n", "", "return", "1", "-", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.double_middle_drop": [[180, 188], ["None"], "function", ["None"], ["", "def", "double_middle_drop", "(", "p", ")", ":", "\n", "    ", "eps1", "=", "0.75", "\n", "eps2", "=", "0.25", "\n", "if", "1", "-", "p", "<", "eps1", ":", "\n", "        ", "if", "1", "-", "p", "<", "eps2", ":", "\n", "            ", "return", "eps2", "*", "0.5", "\n", "", "return", "eps1", "*", "0.1", "\n", "", "return", "1", "-", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.get_by_index": [[251, 258], ["tensorflow.gather", "len", "len", "tensorflow.reshape", "x.get_shape", "idx.get_shape", "tensorflow.range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "", "", "def", "get_by_index", "(", "x", ",", "idx", ")", ":", "\n", "    ", "assert", "(", "len", "(", "x", ".", "get_shape", "(", ")", ")", "==", "2", ")", "\n", "assert", "(", "len", "(", "idx", ".", "get_shape", "(", ")", ")", "==", "1", ")", "\n", "idx_flattened", "=", "tf", ".", "range", "(", "0", ",", "x", ".", "shape", "[", "0", "]", ")", "*", "x", ".", "shape", "[", "1", "]", "+", "idx", "\n", "y", "=", "tf", ".", "gather", "(", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", "]", ")", ",", "# flatten input", "\n", "idx_flattened", ")", "# use flattened indices", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape": [[259, 264], ["zip", "t.get_shape().as_list", "str", "str", "t.get_shape", "t.get_shape", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "check_shape", "(", "ts", ",", "shapes", ")", ":", "\n", "    ", "i", "=", "0", "\n", "for", "(", "t", ",", "shape", ")", "in", "zip", "(", "ts", ",", "shapes", ")", ":", "\n", "        ", "assert", "t", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "==", "shape", ",", "\"id \"", "+", "str", "(", "i", ")", "+", "\" shape \"", "+", "str", "(", "t", ".", "get_shape", "(", ")", ")", "+", "str", "(", "shape", ")", "\n", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.avg_norm": [[265, 267], ["tensorflow.reduce_mean", "tensorflow.sqrt", "tensorflow.reduce_sum", "tensorflow.square"], "function", ["None"], ["", "", "def", "avg_norm", "(", "t", ")", ":", "\n", "    ", "return", "tf", ".", "reduce_mean", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "t", ")", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.gradient_add": [[268, 277], ["print"], "function", ["None"], ["", "def", "gradient_add", "(", "g1", ",", "g2", ",", "param", ")", ":", "\n", "    ", "print", "(", "[", "g1", ",", "g2", ",", "param", ".", "name", "]", ")", "\n", "assert", "(", "not", "(", "g1", "is", "None", "and", "g2", "is", "None", ")", ")", ",", "param", ".", "name", "\n", "if", "g1", "is", "None", ":", "\n", "        ", "return", "g2", "\n", "", "elif", "g2", "is", "None", ":", "\n", "        ", "return", "g1", "\n", "", "else", ":", "\n", "        ", "return", "g1", "+", "g2", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.q_explained_variance": [[278, 283], ["tensorflow.nn.moments", "tensorflow.nn.moments", "utils.check_shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape"], ["", "", "def", "q_explained_variance", "(", "qpred", ",", "q", ")", ":", "\n", "    ", "_", ",", "vary", "=", "tf", ".", "nn", ".", "moments", "(", "q", ",", "axes", "=", "[", "0", ",", "1", "]", ")", "\n", "_", ",", "varpred", "=", "tf", ".", "nn", ".", "moments", "(", "q", "-", "qpred", ",", "axes", "=", "[", "0", ",", "1", "]", ")", "\n", "check_shape", "(", "[", "vary", ",", "varpred", "]", ",", "[", "[", "]", "]", "*", "2", ")", "\n", "return", "1.0", "-", "(", "varpred", "/", "vary", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.defaults.atari": [[4, 16], ["dict", "baselines.common.models.cnn_small"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn_small"], ["def", "atari", "(", ")", ":", "\n", "    ", "return", "dict", "(", "\n", "network", "=", "cnn_small", "(", ")", ",", "\n", "timesteps_per_batch", "=", "512", ",", "\n", "max_kl", "=", "0.001", ",", "\n", "cg_iters", "=", "10", ",", "\n", "cg_damping", "=", "1e-3", ",", "\n", "gamma", "=", "0.98", ",", "\n", "lam", "=", "1.0", ",", "\n", "vf_iters", "=", "3", ",", "\n", "vf_stepsize", "=", "1e-4", ",", "\n", "entcoeff", "=", "0.00", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.defaults.mujoco": [[18, 30], ["dict", "baselines.common.models.mlp"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.mlp"], ["", "def", "mujoco", "(", ")", ":", "\n", "    ", "return", "dict", "(", "\n", "network", "=", "mlp", "(", "num_hidden", "=", "32", ",", "num_layers", "=", "2", ")", ",", "\n", "timesteps_per_batch", "=", "1024", ",", "\n", "max_kl", "=", "0.01", ",", "\n", "cg_iters", "=", "10", ",", "\n", "cg_damping", "=", "0.1", ",", "\n", "gamma", "=", "0.99", ",", "\n", "lam", "=", "0.98", ",", "\n", "vf_iters", "=", "5", ",", "\n", "vf_stepsize", "=", "1e-3", ",", "\n", "normalize_observations", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.traj_segment_generator": [[20, 75], ["env.action_space.sample", "env.reset", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.array", "np.array.copy", "pi.step", "env.step", "pi.step", "ep_rets.append", "ep_lens.append", "env.reset", "range", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "traj_segment_generator", "(", "pi", ",", "env", ",", "horizon", ",", "stochastic", ")", ":", "\n", "# Initialize state variables", "\n", "    ", "t", "=", "0", "\n", "ac", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "new", "=", "True", "\n", "rew", "=", "0.0", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "\n", "cur_ep_ret", "=", "0", "\n", "cur_ep_len", "=", "0", "\n", "ep_rets", "=", "[", "]", "\n", "ep_lens", "=", "[", "]", "\n", "\n", "# Initialize history arrays", "\n", "obs", "=", "np", ".", "array", "(", "[", "ob", "for", "_", "in", "range", "(", "horizon", ")", "]", ")", "\n", "rews", "=", "np", ".", "zeros", "(", "horizon", ",", "'float32'", ")", "\n", "vpreds", "=", "np", ".", "zeros", "(", "horizon", ",", "'float32'", ")", "\n", "news", "=", "np", ".", "zeros", "(", "horizon", ",", "'int32'", ")", "\n", "acs", "=", "np", ".", "array", "(", "[", "ac", "for", "_", "in", "range", "(", "horizon", ")", "]", ")", "\n", "prevacs", "=", "acs", ".", "copy", "(", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "prevac", "=", "ac", "\n", "ac", ",", "vpred", ",", "_", ",", "_", "=", "pi", ".", "step", "(", "ob", ",", "stochastic", "=", "stochastic", ")", "\n", "# Slight weirdness here because we need value function at time T", "\n", "# before returning segment [0, T-1] so we get the correct", "\n", "# terminal value", "\n", "if", "t", ">", "0", "and", "t", "%", "horizon", "==", "0", ":", "\n", "            ", "yield", "{", "\"ob\"", ":", "obs", ",", "\"rew\"", ":", "rews", ",", "\"vpred\"", ":", "vpreds", ",", "\"new\"", ":", "news", ",", "\n", "\"ac\"", ":", "acs", ",", "\"prevac\"", ":", "prevacs", ",", "\"nextvpred\"", ":", "vpred", "*", "(", "1", "-", "new", ")", ",", "\n", "\"ep_rets\"", ":", "ep_rets", ",", "\"ep_lens\"", ":", "ep_lens", "}", "\n", "_", ",", "vpred", ",", "_", ",", "_", "=", "pi", ".", "step", "(", "ob", ",", "stochastic", "=", "stochastic", ")", "\n", "# Be careful!!! if you change the downstream algorithm to aggregate", "\n", "# several of these batches, then be sure to do a deepcopy", "\n", "ep_rets", "=", "[", "]", "\n", "ep_lens", "=", "[", "]", "\n", "", "i", "=", "t", "%", "horizon", "\n", "obs", "[", "i", "]", "=", "ob", "\n", "vpreds", "[", "i", "]", "=", "vpred", "\n", "news", "[", "i", "]", "=", "new", "\n", "acs", "[", "i", "]", "=", "ac", "\n", "prevacs", "[", "i", "]", "=", "prevac", "\n", "\n", "ob", ",", "rew", ",", "new", ",", "_", "=", "env", ".", "step", "(", "ac", ")", "\n", "rews", "[", "i", "]", "=", "rew", "\n", "\n", "cur_ep_ret", "+=", "rew", "\n", "cur_ep_len", "+=", "1", "\n", "if", "new", ":", "\n", "            ", "ep_rets", ".", "append", "(", "cur_ep_ret", ")", "\n", "ep_lens", ".", "append", "(", "cur_ep_len", ")", "\n", "cur_ep_ret", "=", "0", "\n", "cur_ep_len", "=", "0", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "", "t", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.add_vtarg_and_adv": [[76, 88], ["numpy.append", "numpy.append", "len", "numpy.empty", "reversed", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "def", "add_vtarg_and_adv", "(", "seg", ",", "gamma", ",", "lam", ")", ":", "\n", "    ", "new", "=", "np", ".", "append", "(", "seg", "[", "\"new\"", "]", ",", "0", ")", "# last element is only used for last vtarg, but we already zeroed it if last new = 1", "\n", "vpred", "=", "np", ".", "append", "(", "seg", "[", "\"vpred\"", "]", ",", "seg", "[", "\"nextvpred\"", "]", ")", "\n", "T", "=", "len", "(", "seg", "[", "\"rew\"", "]", ")", "\n", "seg", "[", "\"adv\"", "]", "=", "gaelam", "=", "np", ".", "empty", "(", "T", ",", "'float32'", ")", "\n", "rew", "=", "seg", "[", "\"rew\"", "]", "\n", "lastgaelam", "=", "0", "\n", "for", "t", "in", "reversed", "(", "range", "(", "T", ")", ")", ":", "\n", "        ", "nonterminal", "=", "1", "-", "new", "[", "t", "+", "1", "]", "\n", "delta", "=", "rew", "[", "t", "]", "+", "gamma", "*", "vpred", "[", "t", "+", "1", "]", "*", "nonterminal", "-", "vpred", "[", "t", "]", "\n", "gaelam", "[", "t", "]", "=", "lastgaelam", "=", "delta", "+", "gamma", "*", "lam", "*", "nonterminal", "*", "lastgaelam", "\n", "", "seg", "[", "\"tdlamret\"", "]", "=", "seg", "[", "\"adv\"", "]", "+", "seg", "[", "\"vpred\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.learn": [[89, 393], ["baselines.get_session", "baselines.common.policies.build_policy", "baselines.common.set_global_seeds", "numpy.set_printoptions", "baselines.common.input.observation_placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "policy.pdtype.sample_placeholder", "policy.pd.kl", "policy.pd.entropy", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.exp", "tensorflow.reduce_mean", "trpo_mpi.get_trainable_variables", "trpo_mpi.get_pi_trainable_variables", "trpo_mpi.get_vf_trainable_variables", "baselines.common.mpi_adam.MpiAdam", "baselines.GetFlat", "baselines.SetFromFlat", "tensorflow.gradients", "tensorflow.placeholder", "tensorflow.add_n", "baselines.flatgrad", "baselines.function", "baselines.function", "baselines.function", "baselines.function", "baselines.function", "baselines.initialize", "U.GetFlat.", "U.SetFromFlat.", "baselines.common.mpi_adam.MpiAdam.sync", "print", "trpo_mpi.traj_segment_generator", "time.time", "collections.deque", "collections.deque", "MPI.COMM_WORLD.Get_size", "MPI.COMM_WORLD.Get_rank", "tensorflow.variable_scope", "baselines.common.policies.build_policy.", "tensorflow.variable_scope", "baselines.common.policies.build_policy.", "tensorflow.square", "var.get_shape().as_list", "baselines.intprod", "tangents.append", "baselines.flatgrad", "isinstance", "policy.load", "MPI.COMM_WORLD.Bcast", "get_flat.sum", "sum", "sum", "baselines.logger.log", "trpo_mpi.add_vtarg_and_adv", "hasattr", "hasattr", "U.function.", "trpo_mpi.learn.allmean"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.build_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.observation_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.kl", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.get_pi_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.get_vf_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.traj_segment_generator", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.add_vtarg_and_adv"], ["", "def", "learn", "(", "*", ",", "\n", "network", ",", "\n", "env", ",", "\n", "total_timesteps", ",", "\n", "timesteps_per_batch", "=", "1024", ",", "# what to train on", "\n", "max_kl", "=", "0.001", ",", "\n", "cg_iters", "=", "10", ",", "\n", "gamma", "=", "0.99", ",", "\n", "lam", "=", "1.0", ",", "# advantage estimation", "\n", "seed", "=", "None", ",", "\n", "ent_coef", "=", "0.0", ",", "\n", "cg_damping", "=", "1e-2", ",", "\n", "vf_stepsize", "=", "3e-4", ",", "\n", "vf_iters", "=", "3", ",", "\n", "max_episodes", "=", "0", ",", "max_iters", "=", "0", ",", "# time constraint", "\n", "callback", "=", "None", ",", "\n", "load_path", "=", "None", ",", "\n", "**", "network_kwargs", "\n", ")", ":", "\n", "    ", "'''\n    learn a policy function with TRPO algorithm\n\n    Parameters:\n    ----------\n\n    network                 neural network to learn. Can be either string ('mlp', 'cnn', 'lstm', 'lnlstm' for basic types)\n                            or function that takes input placeholder and returns tuple (output, None) for feedforward nets\n                            or (output, (state_placeholder, state_output, mask_placeholder)) for recurrent nets\n\n    env                     environment (one of the gym environments or wrapped via baselines.common.vec_env.VecEnv-type class\n\n    timesteps_per_batch     timesteps per gradient estimation batch\n\n    max_kl                  max KL divergence between old policy and new policy ( KL(pi_old || pi) )\n\n    ent_coef                coefficient of policy entropy term in the optimization objective\n\n    cg_iters                number of iterations of conjugate gradient algorithm\n\n    cg_damping              conjugate gradient damping\n\n    vf_stepsize             learning rate for adam optimizer used to optimie value function loss\n\n    vf_iters                number of iterations of value function optimization iterations per each policy optimization step\n\n    total_timesteps           max number of timesteps\n\n    max_episodes            max number of episodes\n\n    max_iters               maximum number of policy optimization iterations\n\n    callback                function to be called with (locals(), globals()) each policy optimization step\n\n    load_path               str, path to load the model from (default: None, i.e. no model is loaded)\n\n    **network_kwargs        keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n\n    Returns:\n    -------\n\n    learnt model\n\n    '''", "\n", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "        ", "nworkers", "=", "MPI", ".", "COMM_WORLD", ".", "Get_size", "(", ")", "\n", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "nworkers", "=", "1", "\n", "rank", "=", "0", "\n", "\n", "", "cpus_per_worker", "=", "1", "\n", "U", ".", "get_session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "\n", "inter_op_parallelism_threads", "=", "cpus_per_worker", ",", "\n", "intra_op_parallelism_threads", "=", "cpus_per_worker", "\n", ")", ")", "\n", "\n", "\n", "policy", "=", "build_policy", "(", "env", ",", "network", ",", "value_network", "=", "'copy'", ",", "**", "network_kwargs", ")", "\n", "set_global_seeds", "(", "seed", ")", "\n", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "3", ")", "\n", "# Setup losses and stuff", "\n", "# ----------------------------------------", "\n", "ob_space", "=", "env", ".", "observation_space", "\n", "ac_space", "=", "env", ".", "action_space", "\n", "\n", "ob", "=", "observation_placeholder", "(", "ob_space", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"pi\"", ")", ":", "\n", "        ", "pi", "=", "policy", "(", "observ_placeholder", "=", "ob", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"oldpi\"", ")", ":", "\n", "        ", "oldpi", "=", "policy", "(", "observ_placeholder", "=", "ob", ")", "\n", "\n", "", "atarg", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ")", "# Target advantage function (if applicable)", "\n", "ret", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ")", "# Empirical return", "\n", "\n", "ac", "=", "pi", ".", "pdtype", ".", "sample_placeholder", "(", "[", "None", "]", ")", "\n", "\n", "kloldnew", "=", "oldpi", ".", "pd", ".", "kl", "(", "pi", ".", "pd", ")", "\n", "ent", "=", "pi", ".", "pd", ".", "entropy", "(", ")", "\n", "meankl", "=", "tf", ".", "reduce_mean", "(", "kloldnew", ")", "\n", "meanent", "=", "tf", ".", "reduce_mean", "(", "ent", ")", "\n", "entbonus", "=", "ent_coef", "*", "meanent", "\n", "\n", "vferr", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "pi", ".", "vf", "-", "ret", ")", ")", "\n", "\n", "ratio", "=", "tf", ".", "exp", "(", "pi", ".", "pd", ".", "logp", "(", "ac", ")", "-", "oldpi", ".", "pd", ".", "logp", "(", "ac", ")", ")", "# advantage * pnew / pold", "\n", "surrgain", "=", "tf", ".", "reduce_mean", "(", "ratio", "*", "atarg", ")", "\n", "\n", "optimgain", "=", "surrgain", "+", "entbonus", "\n", "losses", "=", "[", "optimgain", ",", "meankl", ",", "entbonus", ",", "surrgain", ",", "meanent", "]", "\n", "loss_names", "=", "[", "\"optimgain\"", ",", "\"meankl\"", ",", "\"entloss\"", ",", "\"surrgain\"", ",", "\"entropy\"", "]", "\n", "\n", "dist", "=", "meankl", "\n", "\n", "all_var_list", "=", "get_trainable_variables", "(", "\"pi\"", ")", "\n", "# var_list = [v for v in all_var_list if v.name.split(\"/\")[1].startswith(\"pol\")]", "\n", "# vf_var_list = [v for v in all_var_list if v.name.split(\"/\")[1].startswith(\"vf\")]", "\n", "var_list", "=", "get_pi_trainable_variables", "(", "\"pi\"", ")", "\n", "vf_var_list", "=", "get_vf_trainable_variables", "(", "\"pi\"", ")", "\n", "\n", "vfadam", "=", "MpiAdam", "(", "vf_var_list", ")", "\n", "\n", "get_flat", "=", "U", ".", "GetFlat", "(", "var_list", ")", "\n", "set_from_flat", "=", "U", ".", "SetFromFlat", "(", "var_list", ")", "\n", "klgrads", "=", "tf", ".", "gradients", "(", "dist", ",", "var_list", ")", "\n", "flat_tangent", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"flat_tan\"", ")", "\n", "shapes", "=", "[", "var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "for", "var", "in", "var_list", "]", "\n", "start", "=", "0", "\n", "tangents", "=", "[", "]", "\n", "for", "shape", "in", "shapes", ":", "\n", "        ", "sz", "=", "U", ".", "intprod", "(", "shape", ")", "\n", "tangents", ".", "append", "(", "tf", ".", "reshape", "(", "flat_tangent", "[", "start", ":", "start", "+", "sz", "]", ",", "shape", ")", ")", "\n", "start", "+=", "sz", "\n", "", "gvp", "=", "tf", ".", "add_n", "(", "[", "tf", ".", "reduce_sum", "(", "g", "*", "tangent", ")", "for", "(", "g", ",", "tangent", ")", "in", "zipsame", "(", "klgrads", ",", "tangents", ")", "]", ")", "#pylint: disable=E1111", "\n", "fvp", "=", "U", ".", "flatgrad", "(", "gvp", ",", "var_list", ")", "\n", "\n", "assign_old_eq_new", "=", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "tf", ".", "assign", "(", "oldv", ",", "newv", ")", "\n", "for", "(", "oldv", ",", "newv", ")", "in", "zipsame", "(", "get_variables", "(", "\"oldpi\"", ")", ",", "get_variables", "(", "\"pi\"", ")", ")", "]", ")", "\n", "\n", "compute_losses", "=", "U", ".", "function", "(", "[", "ob", ",", "ac", ",", "atarg", "]", ",", "losses", ")", "\n", "compute_lossandgrad", "=", "U", ".", "function", "(", "[", "ob", ",", "ac", ",", "atarg", "]", ",", "losses", "+", "[", "U", ".", "flatgrad", "(", "optimgain", ",", "var_list", ")", "]", ")", "\n", "compute_fvp", "=", "U", ".", "function", "(", "[", "flat_tangent", ",", "ob", ",", "ac", ",", "atarg", "]", ",", "fvp", ")", "\n", "compute_vflossandgrad", "=", "U", ".", "function", "(", "[", "ob", ",", "ret", "]", ",", "U", ".", "flatgrad", "(", "vferr", ",", "vf_var_list", ")", ")", "\n", "\n", "@", "contextmanager", "\n", "def", "timed", "(", "msg", ")", ":", "\n", "        ", "if", "rank", "==", "0", ":", "\n", "            ", "print", "(", "colorize", "(", "msg", ",", "color", "=", "'magenta'", ")", ")", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "yield", "\n", "print", "(", "colorize", "(", "\"done in %.3f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "tstart", ")", ",", "color", "=", "'magenta'", ")", ")", "\n", "", "else", ":", "\n", "            ", "yield", "\n", "\n", "", "", "def", "allmean", "(", "x", ")", ":", "\n", "        ", "assert", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "            ", "out", "=", "np", ".", "empty_like", "(", "x", ")", "\n", "MPI", ".", "COMM_WORLD", ".", "Allreduce", "(", "x", ",", "out", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "out", "/=", "nworkers", "\n", "", "else", ":", "\n", "            ", "out", "=", "np", ".", "copy", "(", "x", ")", "\n", "\n", "", "return", "out", "\n", "\n", "", "U", ".", "initialize", "(", ")", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "pi", ".", "load", "(", "load_path", ")", "\n", "\n", "", "th_init", "=", "get_flat", "(", ")", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "        ", "MPI", ".", "COMM_WORLD", ".", "Bcast", "(", "th_init", ",", "root", "=", "0", ")", "\n", "\n", "", "set_from_flat", "(", "th_init", ")", "\n", "vfadam", ".", "sync", "(", ")", "\n", "print", "(", "\"Init param sum\"", ",", "th_init", ".", "sum", "(", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# Prepare for rollouts", "\n", "# ----------------------------------------", "\n", "seg_gen", "=", "traj_segment_generator", "(", "pi", ",", "env", ",", "timesteps_per_batch", ",", "stochastic", "=", "True", ")", "\n", "\n", "episodes_so_far", "=", "0", "\n", "timesteps_so_far", "=", "0", "\n", "iters_so_far", "=", "0", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "lenbuffer", "=", "deque", "(", "maxlen", "=", "40", ")", "# rolling buffer for episode lengths", "\n", "rewbuffer", "=", "deque", "(", "maxlen", "=", "40", ")", "# rolling buffer for episode rewards", "\n", "\n", "if", "sum", "(", "[", "max_iters", ">", "0", ",", "total_timesteps", ">", "0", ",", "max_episodes", ">", "0", "]", ")", "==", "0", ":", "\n", "# noththing to be done", "\n", "        ", "return", "pi", "\n", "\n", "", "assert", "sum", "(", "[", "max_iters", ">", "0", ",", "total_timesteps", ">", "0", ",", "max_episodes", ">", "0", "]", ")", "<", "2", ",", "'out of max_iters, total_timesteps, and max_episodes only one should be specified'", "\n", "\n", "while", "True", ":", "\n", "        ", "if", "callback", ":", "callback", "(", "locals", "(", ")", ",", "globals", "(", ")", ")", "\n", "if", "total_timesteps", "and", "timesteps_so_far", ">=", "total_timesteps", ":", "\n", "            ", "break", "\n", "", "elif", "max_episodes", "and", "episodes_so_far", ">=", "max_episodes", ":", "\n", "            ", "break", "\n", "", "elif", "max_iters", "and", "iters_so_far", ">=", "max_iters", ":", "\n", "            ", "break", "\n", "", "logger", ".", "log", "(", "\"********** Iteration %i ************\"", "%", "iters_so_far", ")", "\n", "\n", "with", "timed", "(", "\"sampling\"", ")", ":", "\n", "            ", "seg", "=", "seg_gen", ".", "__next__", "(", ")", "\n", "", "add_vtarg_and_adv", "(", "seg", ",", "gamma", ",", "lam", ")", "\n", "\n", "# ob, ac, atarg, ret, td1ret = map(np.concatenate, (obs, acs, atargs, rets, td1rets))", "\n", "ob", ",", "ac", ",", "atarg", ",", "tdlamret", "=", "seg", "[", "\"ob\"", "]", ",", "seg", "[", "\"ac\"", "]", ",", "seg", "[", "\"adv\"", "]", ",", "seg", "[", "\"tdlamret\"", "]", "\n", "vpredbefore", "=", "seg", "[", "\"vpred\"", "]", "# predicted value function before udpate", "\n", "atarg", "=", "(", "atarg", "-", "atarg", ".", "mean", "(", ")", ")", "/", "atarg", ".", "std", "(", ")", "# standardized advantage function estimate", "\n", "\n", "if", "hasattr", "(", "pi", ",", "\"ret_rms\"", ")", ":", "pi", ".", "ret_rms", ".", "update", "(", "tdlamret", ")", "\n", "if", "hasattr", "(", "pi", ",", "\"ob_rms\"", ")", ":", "pi", ".", "ob_rms", ".", "update", "(", "ob", ")", "# update running mean/std for policy", "\n", "\n", "args", "=", "seg", "[", "\"ob\"", "]", ",", "seg", "[", "\"ac\"", "]", ",", "atarg", "\n", "fvpargs", "=", "[", "arr", "[", ":", ":", "5", "]", "for", "arr", "in", "args", "]", "\n", "def", "fisher_vector_product", "(", "p", ")", ":", "\n", "            ", "return", "allmean", "(", "compute_fvp", "(", "p", ",", "*", "fvpargs", ")", ")", "+", "cg_damping", "*", "p", "\n", "\n", "", "assign_old_eq_new", "(", ")", "# set old parameter values to new parameter values", "\n", "with", "timed", "(", "\"computegrad\"", ")", ":", "\n", "            ", "*", "lossbefore", ",", "g", "=", "compute_lossandgrad", "(", "*", "args", ")", "\n", "", "lossbefore", "=", "allmean", "(", "np", ".", "array", "(", "lossbefore", ")", ")", "\n", "g", "=", "allmean", "(", "g", ")", "\n", "if", "np", ".", "allclose", "(", "g", ",", "0", ")", ":", "\n", "            ", "logger", ".", "log", "(", "\"Got zero gradient. not updating\"", ")", "\n", "", "else", ":", "\n", "            ", "with", "timed", "(", "\"cg\"", ")", ":", "\n", "                ", "stepdir", "=", "cg", "(", "fisher_vector_product", ",", "g", ",", "cg_iters", "=", "cg_iters", ",", "verbose", "=", "rank", "==", "0", ")", "\n", "", "assert", "np", ".", "isfinite", "(", "stepdir", ")", ".", "all", "(", ")", "\n", "shs", "=", ".5", "*", "stepdir", ".", "dot", "(", "fisher_vector_product", "(", "stepdir", ")", ")", "\n", "lm", "=", "np", ".", "sqrt", "(", "shs", "/", "max_kl", ")", "\n", "# logger.log(\"lagrange multiplier:\", lm, \"gnorm:\", np.linalg.norm(g))", "\n", "fullstep", "=", "stepdir", "/", "lm", "\n", "expectedimprove", "=", "g", ".", "dot", "(", "fullstep", ")", "\n", "surrbefore", "=", "lossbefore", "[", "0", "]", "\n", "stepsize", "=", "1.0", "\n", "thbefore", "=", "get_flat", "(", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "thnew", "=", "thbefore", "+", "fullstep", "*", "stepsize", "\n", "set_from_flat", "(", "thnew", ")", "\n", "meanlosses", "=", "surr", ",", "kl", ",", "*", "_", "=", "allmean", "(", "np", ".", "array", "(", "compute_losses", "(", "*", "args", ")", ")", ")", "\n", "improve", "=", "surr", "-", "surrbefore", "\n", "logger", ".", "log", "(", "\"Expected: %.3f Actual: %.3f\"", "%", "(", "expectedimprove", ",", "improve", ")", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "meanlosses", ")", ".", "all", "(", ")", ":", "\n", "                    ", "logger", ".", "log", "(", "\"Got non-finite value of losses -- bad!\"", ")", "\n", "", "elif", "kl", ">", "max_kl", "*", "1.5", ":", "\n", "                    ", "logger", ".", "log", "(", "\"violated KL constraint. shrinking step.\"", ")", "\n", "", "elif", "improve", "<", "0", ":", "\n", "                    ", "logger", ".", "log", "(", "\"surrogate didn't improve. shrinking step.\"", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "log", "(", "\"Stepsize OK!\"", ")", "\n", "break", "\n", "", "stepsize", "*=", ".5", "\n", "", "else", ":", "\n", "                ", "logger", ".", "log", "(", "\"couldn't compute a good step\"", ")", "\n", "set_from_flat", "(", "thbefore", ")", "\n", "", "if", "nworkers", ">", "1", "and", "iters_so_far", "%", "20", "==", "0", ":", "\n", "                ", "paramsums", "=", "MPI", ".", "COMM_WORLD", ".", "allgather", "(", "(", "thnew", ".", "sum", "(", ")", ",", "vfadam", ".", "getflat", "(", ")", ".", "sum", "(", ")", ")", ")", "# list of tuples", "\n", "assert", "all", "(", "np", ".", "allclose", "(", "ps", ",", "paramsums", "[", "0", "]", ")", "for", "ps", "in", "paramsums", "[", "1", ":", "]", ")", "\n", "\n", "", "", "for", "(", "lossname", ",", "lossval", ")", "in", "zip", "(", "loss_names", ",", "meanlosses", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "lossname", ",", "lossval", ")", "\n", "\n", "", "with", "timed", "(", "\"vf\"", ")", ":", "\n", "\n", "            ", "for", "_", "in", "range", "(", "vf_iters", ")", ":", "\n", "                ", "for", "(", "mbob", ",", "mbret", ")", "in", "dataset", ".", "iterbatches", "(", "(", "seg", "[", "\"ob\"", "]", ",", "seg", "[", "\"tdlamret\"", "]", ")", ",", "\n", "include_final_partial_batch", "=", "False", ",", "batch_size", "=", "64", ")", ":", "\n", "                    ", "g", "=", "allmean", "(", "compute_vflossandgrad", "(", "mbob", ",", "mbret", ")", ")", "\n", "vfadam", ".", "update", "(", "g", ",", "vf_stepsize", ")", "\n", "\n", "", "", "", "logger", ".", "record_tabular", "(", "\"ev_tdlam_before\"", ",", "explained_variance", "(", "vpredbefore", ",", "tdlamret", ")", ")", "\n", "\n", "lrlocal", "=", "(", "seg", "[", "\"ep_lens\"", "]", ",", "seg", "[", "\"ep_rets\"", "]", ")", "# local values", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "            ", "listoflrpairs", "=", "MPI", ".", "COMM_WORLD", ".", "allgather", "(", "lrlocal", ")", "# list of tuples", "\n", "", "else", ":", "\n", "            ", "listoflrpairs", "=", "[", "lrlocal", "]", "\n", "\n", "", "lens", ",", "rews", "=", "map", "(", "flatten_lists", ",", "zip", "(", "*", "listoflrpairs", ")", ")", "\n", "lenbuffer", ".", "extend", "(", "lens", ")", "\n", "rewbuffer", ".", "extend", "(", "rews", ")", "\n", "\n", "logger", ".", "record_tabular", "(", "\"EpLenMean\"", ",", "np", ".", "mean", "(", "lenbuffer", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"EpRewMean\"", ",", "np", ".", "mean", "(", "rewbuffer", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"EpThisIter\"", ",", "len", "(", "lens", ")", ")", "\n", "episodes_so_far", "+=", "len", "(", "lens", ")", "\n", "timesteps_so_far", "+=", "sum", "(", "lens", ")", "\n", "iters_so_far", "+=", "1", "\n", "\n", "logger", ".", "record_tabular", "(", "\"EpisodesSoFar\"", ",", "episodes_so_far", ")", "\n", "logger", ".", "record_tabular", "(", "\"TimestepsSoFar\"", ",", "timesteps_so_far", ")", "\n", "logger", ".", "record_tabular", "(", "\"TimeElapsed\"", ",", "time", ".", "time", "(", ")", "-", "tstart", ")", "\n", "\n", "if", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "dump_tabular", "(", ")", "\n", "\n", "", "", "return", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.flatten_lists": [[394, 396], ["None"], "function", ["None"], ["", "def", "flatten_lists", "(", "listoflists", ")", ":", "\n", "    ", "return", "[", "el", "for", "list_", "in", "listoflists", "for", "el", "in", "list_", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.get_variables": [[397, 399], ["tensorflow.get_collection"], "function", ["None"], ["", "def", "get_variables", "(", "scope", ")", ":", "\n", "    ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.get_trainable_variables": [[400, 402], ["tensorflow.get_collection"], "function", ["None"], ["", "def", "get_trainable_variables", "(", "scope", ")", ":", "\n", "    ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.get_vf_trainable_variables": [[403, 405], ["trpo_mpi.get_trainable_variables", "v.name[].split", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables"], ["", "def", "get_vf_trainable_variables", "(", "scope", ")", ":", "\n", "    ", "return", "[", "v", "for", "v", "in", "get_trainable_variables", "(", "scope", ")", "if", "'vf'", "in", "v", ".", "name", "[", "len", "(", "scope", ")", ":", "]", ".", "split", "(", "'/'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.trpo_mpi.trpo_mpi.get_pi_trainable_variables": [[406, 408], ["trpo_mpi.get_trainable_variables", "v.name[].split", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables"], ["", "def", "get_pi_trainable_variables", "(", "scope", ")", ":", "\n", "    ", "return", "[", "v", "for", "v", "in", "get_trainable_variables", "(", "scope", ")", "if", "'pi'", "in", "v", ".", "name", "[", "len", "(", "scope", ")", ":", "]", ".", "split", "(", "'/'", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her_sampler.make_sample_her_transitions": [[4, 64], ["numpy.random.randint", "numpy.random.randint", "numpy.where", "future_offset.astype.astype", "transitions.items", "reward_fun", "[].copy", "numpy.random.uniform", "key.startswith", "transitions[].reshape", "episode_batch.keys", "numpy.random.uniform", "transitions.keys", "key.replace"], "function", ["None"], ["def", "make_sample_her_transitions", "(", "replay_strategy", ",", "replay_k", ",", "reward_fun", ")", ":", "\n", "    ", "\"\"\"Creates a sample function that can be used for HER experience replay.\n\n    Args:\n        replay_strategy (in ['future', 'none']): the HER replay strategy; if set to 'none',\n            regular DDPG experience replay is used\n        replay_k (int): the ratio between HER replays and regular replays (e.g. k = 4 -> 4 times\n            as many HER replays as regular replays are used)\n        reward_fun (function): function to re-compute the reward with substituted goals\n    \"\"\"", "\n", "if", "replay_strategy", "==", "'future'", ":", "\n", "        ", "future_p", "=", "1", "-", "(", "1.", "/", "(", "1", "+", "replay_k", ")", ")", "\n", "", "else", ":", "# 'replay_strategy' == 'none'", "\n", "        ", "future_p", "=", "0", "\n", "\n", "", "def", "_sample_her_transitions", "(", "episode_batch", ",", "batch_size_in_transitions", ")", ":", "\n", "        ", "\"\"\"episode_batch is {key: array(buffer_size x T x dim_key)}\n        \"\"\"", "\n", "T", "=", "episode_batch", "[", "'u'", "]", ".", "shape", "[", "1", "]", "\n", "rollout_batch_size", "=", "episode_batch", "[", "'u'", "]", ".", "shape", "[", "0", "]", "\n", "batch_size", "=", "batch_size_in_transitions", "\n", "\n", "# Select which episodes and time steps to use.", "\n", "episode_idxs", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "rollout_batch_size", ",", "batch_size", ")", "\n", "t_samples", "=", "np", ".", "random", ".", "randint", "(", "T", ",", "size", "=", "batch_size", ")", "\n", "transitions", "=", "{", "key", ":", "episode_batch", "[", "key", "]", "[", "episode_idxs", ",", "t_samples", "]", ".", "copy", "(", ")", "\n", "for", "key", "in", "episode_batch", ".", "keys", "(", ")", "}", "\n", "\n", "# Select future time indexes proportional with probability future_p. These", "\n", "# will be used for HER replay by substituting in future goals.", "\n", "her_indexes", "=", "np", ".", "where", "(", "np", ".", "random", ".", "uniform", "(", "size", "=", "batch_size", ")", "<", "future_p", ")", "\n", "future_offset", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "batch_size", ")", "*", "(", "T", "-", "t_samples", ")", "\n", "future_offset", "=", "future_offset", ".", "astype", "(", "int", ")", "\n", "future_t", "=", "(", "t_samples", "+", "1", "+", "future_offset", ")", "[", "her_indexes", "]", "\n", "\n", "# Replace goal with achieved goal but only for the previously-selected", "\n", "# HER transitions (as defined by her_indexes). For the other transitions,", "\n", "# keep the original goal.", "\n", "future_ag", "=", "episode_batch", "[", "'ag'", "]", "[", "episode_idxs", "[", "her_indexes", "]", ",", "future_t", "]", "\n", "transitions", "[", "'g'", "]", "[", "her_indexes", "]", "=", "future_ag", "\n", "\n", "# Reconstruct info dictionary for reward  computation.", "\n", "info", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "transitions", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "'info_'", ")", ":", "\n", "                ", "info", "[", "key", ".", "replace", "(", "'info_'", ",", "''", ")", "]", "=", "value", "\n", "\n", "# Re-compute reward since we may have substituted the goal.", "\n", "", "", "reward_params", "=", "{", "k", ":", "transitions", "[", "k", "]", "for", "k", "in", "[", "'ag_2'", ",", "'g'", "]", "}", "\n", "reward_params", "[", "'info'", "]", "=", "info", "\n", "transitions", "[", "'r'", "]", "=", "reward_fun", "(", "**", "reward_params", ")", "\n", "\n", "transitions", "=", "{", "k", ":", "transitions", "[", "k", "]", ".", "reshape", "(", "batch_size", ",", "*", "transitions", "[", "k", "]", ".", "shape", "[", "1", ":", "]", ")", "\n", "for", "k", "in", "transitions", ".", "keys", "(", ")", "}", "\n", "\n", "assert", "(", "transitions", "[", "'u'", "]", ".", "shape", "[", "0", "]", "==", "batch_size_in_transitions", ")", "\n", "\n", "return", "transitions", "\n", "\n", "", "return", "_sample_her_transitions", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.__init__": [[11, 43], ["collections.deque", "collections.deque", "rollout.RolloutWorker.reset_all_rollouts", "rollout.RolloutWorker.clear_history", "key.replace", "dims.keys", "key.startswith"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.clear_history"], ["    ", "@", "store_args", "\n", "def", "__init__", "(", "self", ",", "venv", ",", "policy", ",", "dims", ",", "logger", ",", "T", ",", "rollout_batch_size", "=", "1", ",", "\n", "exploit", "=", "False", ",", "use_target_net", "=", "False", ",", "compute_Q", "=", "False", ",", "noise_eps", "=", "0", ",", "\n", "random_eps", "=", "0", ",", "history_len", "=", "100", ",", "render", "=", "False", ",", "monitor", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Rollout worker generates experience by interacting with one or many environments.\n\n        Args:\n            venv: vectorized gym environments.\n            policy (object): the policy that is used to act\n            dims (dict of ints): the dimensions for observations (o), goals (g), and actions (u)\n            logger (object): the logger that is used by the rollout worker\n            rollout_batch_size (int): the number of parallel rollouts that should be used\n            exploit (boolean): whether or not to exploit, i.e. to act optimally according to the\n                current policy without any exploration\n            use_target_net (boolean): whether or not to use the target net for rollouts\n            compute_Q (boolean): whether or not to compute the Q values alongside the actions\n            noise_eps (float): scale of the additive Gaussian noise\n            random_eps (float): probability of selecting a completely random action\n            history_len (int): length of history for statistics smoothing\n            render (boolean): whether or not to render the rollouts\n        \"\"\"", "\n", "\n", "assert", "self", ".", "T", ">", "0", "\n", "\n", "self", ".", "info_keys", "=", "[", "key", ".", "replace", "(", "'info_'", ",", "''", ")", "for", "key", "in", "dims", ".", "keys", "(", ")", "if", "key", ".", "startswith", "(", "'info_'", ")", "]", "\n", "\n", "self", ".", "success_history", "=", "deque", "(", "maxlen", "=", "history_len", ")", "\n", "self", ".", "Q_history", "=", "deque", "(", "maxlen", "=", "history_len", ")", "\n", "\n", "self", ".", "n_episodes", "=", "0", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "self", ".", "clear_history", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.reset_all_rollouts": [[44, 49], ["rollout.RolloutWorker.venv.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset_all_rollouts", "(", "self", ")", ":", "\n", "        ", "self", ".", "obs_dict", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "initial_o", "=", "self", ".", "obs_dict", "[", "'observation'", "]", "\n", "self", ".", "initial_ag", "=", "self", ".", "obs_dict", "[", "'achieved_goal'", "]", "\n", "self", ".", "g", "=", "self", ".", "obs_dict", "[", "'desired_goal'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.generate_rollouts": [[50, 137], ["rollout.RolloutWorker.reset_all_rollouts", "numpy.empty", "numpy.empty", "range", "obs.append", "achieved_goals.append", "dict", "zip", "numpy.mean", "rollout.RolloutWorker.success_history.append", "baselines.her.util.convert_episode_to_batch_major", "numpy.empty", "rollout.RolloutWorker.policy.get_actions", "numpy.empty", "numpy.empty", "numpy.zeros", "rollout.RolloutWorker.venv.step", "numpy.array", "any", "enumerate", "numpy.isnan().any", "dones.append", "obs.append", "achieved_goals.append", "successes.append", "acts.append", "goals.append", "numpy.empty.copy", "numpy.empty.copy", "numpy.array", "rollout.RolloutWorker.Q_history.append", "Qs.append", "u.reshape.reshape.reshape", "enumerate", "rollout.RolloutWorker.logger.warn", "rollout.RolloutWorker.reset_all_rollouts", "rollout.RolloutWorker.generate_rollouts", "numpy.empty.copy", "numpy.empty.copy", "numpy.array.copy", "u.reshape.reshape.copy", "rollout.RolloutWorker.g.copy", "numpy.mean", "i.get", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.convert_episode_to_batch_major", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.get_actions", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.reset_all_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.generate_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["", "def", "generate_rollouts", "(", "self", ")", ":", "\n", "        ", "\"\"\"Performs `rollout_batch_size` rollouts in parallel for time horizon `T` with the current\n        policy acting on it accordingly.\n        \"\"\"", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "\n", "# compute observations", "\n", "o", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'o'", "]", ")", ",", "np", ".", "float32", ")", "# observations", "\n", "ag", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'g'", "]", ")", ",", "np", ".", "float32", ")", "# achieved goals", "\n", "o", "[", ":", "]", "=", "self", ".", "initial_o", "\n", "ag", "[", ":", "]", "=", "self", ".", "initial_ag", "\n", "\n", "# generate episodes", "\n", "obs", ",", "achieved_goals", ",", "acts", ",", "goals", ",", "successes", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "dones", "=", "[", "]", "\n", "info_values", "=", "[", "np", ".", "empty", "(", "(", "self", ".", "T", "-", "1", ",", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'info_'", "+", "key", "]", ")", ",", "np", ".", "float32", ")", "for", "key", "in", "self", ".", "info_keys", "]", "\n", "Qs", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "T", ")", ":", "\n", "            ", "policy_output", "=", "self", ".", "policy", ".", "get_actions", "(", "\n", "o", ",", "ag", ",", "self", ".", "g", ",", "\n", "compute_Q", "=", "self", ".", "compute_Q", ",", "\n", "noise_eps", "=", "self", ".", "noise_eps", "if", "not", "self", ".", "exploit", "else", "0.", ",", "\n", "random_eps", "=", "self", ".", "random_eps", "if", "not", "self", ".", "exploit", "else", "0.", ",", "\n", "use_target_net", "=", "self", ".", "use_target_net", ")", "\n", "\n", "if", "self", ".", "compute_Q", ":", "\n", "                ", "u", ",", "Q", "=", "policy_output", "\n", "Qs", ".", "append", "(", "Q", ")", "\n", "", "else", ":", "\n", "                ", "u", "=", "policy_output", "\n", "\n", "", "if", "u", ".", "ndim", "==", "1", ":", "\n", "# The non-batched case should still have a reasonable shape.", "\n", "                ", "u", "=", "u", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "\n", "", "o_new", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'o'", "]", ")", ")", "\n", "ag_new", "=", "np", ".", "empty", "(", "(", "self", ".", "rollout_batch_size", ",", "self", ".", "dims", "[", "'g'", "]", ")", ")", "\n", "success", "=", "np", ".", "zeros", "(", "self", ".", "rollout_batch_size", ")", "\n", "# compute new states and observations", "\n", "obs_dict_new", ",", "_", ",", "done", ",", "info", "=", "self", ".", "venv", ".", "step", "(", "u", ")", "\n", "o_new", "=", "obs_dict_new", "[", "'observation'", "]", "\n", "ag_new", "=", "obs_dict_new", "[", "'achieved_goal'", "]", "\n", "success", "=", "np", ".", "array", "(", "[", "i", ".", "get", "(", "'is_success'", ",", "0.0", ")", "for", "i", "in", "info", "]", ")", "\n", "\n", "if", "any", "(", "done", ")", ":", "\n", "# here we assume all environments are done is ~same number of steps, so we terminate rollouts whenever any of the envs returns done", "\n", "# trick with using vecenvs is not to add the obs from the environments that are \"done\", because those are already observations", "\n", "# after a reset", "\n", "                ", "break", "\n", "\n", "", "for", "i", ",", "info_dict", "in", "enumerate", "(", "info", ")", ":", "\n", "                ", "for", "idx", ",", "key", "in", "enumerate", "(", "self", ".", "info_keys", ")", ":", "\n", "                    ", "info_values", "[", "idx", "]", "[", "t", ",", "i", "]", "=", "info", "[", "i", "]", "[", "key", "]", "\n", "\n", "", "", "if", "np", ".", "isnan", "(", "o_new", ")", ".", "any", "(", ")", ":", "\n", "                ", "self", ".", "logger", ".", "warn", "(", "'NaN caught during rollout generation. Trying again...'", ")", "\n", "self", ".", "reset_all_rollouts", "(", ")", "\n", "return", "self", ".", "generate_rollouts", "(", ")", "\n", "\n", "", "dones", ".", "append", "(", "done", ")", "\n", "obs", ".", "append", "(", "o", ".", "copy", "(", ")", ")", "\n", "achieved_goals", ".", "append", "(", "ag", ".", "copy", "(", ")", ")", "\n", "successes", ".", "append", "(", "success", ".", "copy", "(", ")", ")", "\n", "acts", ".", "append", "(", "u", ".", "copy", "(", ")", ")", "\n", "goals", ".", "append", "(", "self", ".", "g", ".", "copy", "(", ")", ")", "\n", "o", "[", "...", "]", "=", "o_new", "\n", "ag", "[", "...", "]", "=", "ag_new", "\n", "", "obs", ".", "append", "(", "o", ".", "copy", "(", ")", ")", "\n", "achieved_goals", ".", "append", "(", "ag", ".", "copy", "(", ")", ")", "\n", "\n", "episode", "=", "dict", "(", "o", "=", "obs", ",", "\n", "u", "=", "acts", ",", "\n", "g", "=", "goals", ",", "\n", "ag", "=", "achieved_goals", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "self", ".", "info_keys", ",", "info_values", ")", ":", "\n", "            ", "episode", "[", "'info_{}'", ".", "format", "(", "key", ")", "]", "=", "value", "\n", "\n", "# stats", "\n", "", "successful", "=", "np", ".", "array", "(", "successes", ")", "[", "-", "1", ",", ":", "]", "\n", "assert", "successful", ".", "shape", "==", "(", "self", ".", "rollout_batch_size", ",", ")", "\n", "success_rate", "=", "np", ".", "mean", "(", "successful", ")", "\n", "self", ".", "success_history", ".", "append", "(", "success_rate", ")", "\n", "if", "self", ".", "compute_Q", ":", "\n", "            ", "self", ".", "Q_history", ".", "append", "(", "np", ".", "mean", "(", "Qs", ")", ")", "\n", "", "self", ".", "n_episodes", "+=", "self", ".", "rollout_batch_size", "\n", "\n", "return", "convert_episode_to_batch_major", "(", "episode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.clear_history": [[138, 143], ["rollout.RolloutWorker.success_history.clear", "rollout.RolloutWorker.Q_history.clear"], "methods", ["None"], ["", "def", "clear_history", "(", "self", ")", ":", "\n", "        ", "\"\"\"Clears all histories that are used for statistics\n        \"\"\"", "\n", "self", ".", "success_history", ".", "clear", "(", ")", "\n", "self", ".", "Q_history", ".", "clear", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.current_success_rate": [[144, 146], ["numpy.mean"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "current_success_rate", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "success_history", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.current_mean_Q": [[147, 149], ["numpy.mean"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "current_mean_Q", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "mean", "(", "self", ".", "Q_history", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.save_policy": [[150, 155], ["open", "pickle.dump"], "methods", ["None"], ["", "def", "save_policy", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Pickles the current policy for later inspection.\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ".", "policy", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.logs": [[156, 169], ["numpy.mean", "prefix.endswith", "numpy.mean"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "def", "logs", "(", "self", ",", "prefix", "=", "'worker'", ")", ":", "\n", "        ", "\"\"\"Generates a dictionary that contains all collected statistics.\n        \"\"\"", "\n", "logs", "=", "[", "]", "\n", "logs", "+=", "[", "(", "'success_rate'", ",", "np", ".", "mean", "(", "self", ".", "success_history", ")", ")", "]", "\n", "if", "self", ".", "compute_Q", ":", "\n", "            ", "logs", "+=", "[", "(", "'mean_Q'", ",", "np", ".", "mean", "(", "self", ".", "Q_history", ")", ")", "]", "\n", "", "logs", "+=", "[", "(", "'episode'", ",", "self", ".", "n_episodes", ")", "]", "\n", "\n", "if", "prefix", "!=", "''", "and", "not", "prefix", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "return", "[", "(", "prefix", "+", "'/'", "+", "key", ",", "val", ")", "for", "key", ",", "val", "in", "logs", "]", "\n", "", "else", ":", "\n", "            ", "return", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.__init__": [[7, 31], ["threading.Lock", "numpy.empty", "buffer_shapes.items"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "buffer_shapes", ",", "size_in_transitions", ",", "T", ",", "sample_transitions", ")", ":", "\n", "        ", "\"\"\"Creates a replay buffer.\n\n        Args:\n            buffer_shapes (dict of ints): the shape for all buffers that are used in the replay\n                buffer\n            size_in_transitions (int): the size of the buffer, measured in transitions\n            T (int): the time horizon for episodes\n            sample_transitions (function): a function that samples from the replay buffer\n        \"\"\"", "\n", "self", ".", "buffer_shapes", "=", "buffer_shapes", "\n", "self", ".", "size", "=", "size_in_transitions", "//", "T", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "sample_transitions", "=", "sample_transitions", "\n", "\n", "# self.buffers is {key: array(size_in_episodes x T or T+1 x dim_key)}", "\n", "self", ".", "buffers", "=", "{", "key", ":", "np", ".", "empty", "(", "[", "self", ".", "size", ",", "*", "shape", "]", ")", "\n", "for", "key", ",", "shape", "in", "buffer_shapes", ".", "items", "(", ")", "}", "\n", "\n", "# memory management", "\n", "self", ".", "current_size", "=", "0", "\n", "self", ".", "n_transitions_stored", "=", "0", "\n", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.full": [[32, 36], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "full", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "==", "self", ".", "size", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.sample": [[37, 56], ["replay_buffer.ReplayBuffer.sample_transitions", "replay_buffer.ReplayBuffer.buffers.keys", "list", "replay_buffer.ReplayBuffer.buffers.keys"], "methods", ["None"], ["", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Returns a dict {key: array(batch_size x shapes[key])}\n        \"\"\"", "\n", "buffers", "=", "{", "}", "\n", "\n", "with", "self", ".", "lock", ":", "\n", "            ", "assert", "self", ".", "current_size", ">", "0", "\n", "for", "key", "in", "self", ".", "buffers", ".", "keys", "(", ")", ":", "\n", "                ", "buffers", "[", "key", "]", "=", "self", ".", "buffers", "[", "key", "]", "[", ":", "self", ".", "current_size", "]", "\n", "\n", "", "", "buffers", "[", "'o_2'", "]", "=", "buffers", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "buffers", "[", "'ag_2'", "]", "=", "buffers", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "buffers", ",", "batch_size", ")", "\n", "\n", "for", "key", "in", "(", "[", "'r'", ",", "'o_2'", ",", "'ag_2'", "]", "+", "list", "(", "self", ".", "buffers", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "assert", "key", "in", "transitions", ",", "\"key %s missing from transitions\"", "%", "key", "\n", "\n", "", "return", "transitions", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.store_episode": [[57, 72], ["numpy.all", "len", "replay_buffer.ReplayBuffer._get_storage_idx", "replay_buffer.ReplayBuffer.buffers.keys", "episode_batch.keys", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer._get_storage_idx"], ["", "def", "store_episode", "(", "self", ",", "episode_batch", ")", ":", "\n", "        ", "\"\"\"episode_batch: array(batch_size x (T or T+1) x dim_key)\n        \"\"\"", "\n", "batch_sizes", "=", "[", "len", "(", "episode_batch", "[", "key", "]", ")", "for", "key", "in", "episode_batch", ".", "keys", "(", ")", "]", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "batch_sizes", ")", "==", "batch_sizes", "[", "0", "]", ")", "\n", "batch_size", "=", "batch_sizes", "[", "0", "]", "\n", "\n", "with", "self", ".", "lock", ":", "\n", "            ", "idxs", "=", "self", ".", "_get_storage_idx", "(", "batch_size", ")", "\n", "\n", "# load inputs into buffers", "\n", "for", "key", "in", "self", ".", "buffers", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "buffers", "[", "key", "]", "[", "idxs", "]", "=", "episode_batch", "[", "key", "]", "\n", "\n", "", "self", ".", "n_transitions_stored", "+=", "batch_size", "*", "self", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.get_current_episode_size": [[73, 76], ["None"], "methods", ["None"], ["", "", "def", "get_current_episode_size", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.get_current_size": [[77, 80], ["None"], "methods", ["None"], ["", "", "def", "get_current_size", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "*", "self", ".", "T", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.get_transitions_stored": [[81, 84], ["None"], "methods", ["None"], ["", "", "def", "get_transitions_stored", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "n_transitions_stored", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.clear_buffer": [[85, 88], ["None"], "methods", ["None"], ["", "", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "self", ".", "current_size", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer._get_storage_idx": [[89, 109], ["min", "numpy.arange", "numpy.arange", "numpy.random.randint", "numpy.concatenate", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["", "", "def", "_get_storage_idx", "(", "self", ",", "inc", "=", "None", ")", ":", "\n", "        ", "inc", "=", "inc", "or", "1", "# size increment", "\n", "assert", "inc", "<=", "self", ".", "size", ",", "\"Batch committed to replay is too large!\"", "\n", "# go consecutively until you hit the end, and then go randomly.", "\n", "if", "self", ".", "current_size", "+", "inc", "<=", "self", ".", "size", ":", "\n", "            ", "idx", "=", "np", ".", "arange", "(", "self", ".", "current_size", ",", "self", ".", "current_size", "+", "inc", ")", "\n", "", "elif", "self", ".", "current_size", "<", "self", ".", "size", ":", "\n", "            ", "overflow", "=", "inc", "-", "(", "self", ".", "size", "-", "self", ".", "current_size", ")", "\n", "idx_a", "=", "np", ".", "arange", "(", "self", ".", "current_size", ",", "self", ".", "size", ")", "\n", "idx_b", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "current_size", ",", "overflow", ")", "\n", "idx", "=", "np", ".", "concatenate", "(", "[", "idx_a", ",", "idx_b", "]", ")", "\n", "", "else", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "size", ",", "inc", ")", "\n", "\n", "# update replay size", "\n", "", "self", ".", "current_size", "=", "min", "(", "self", ".", "size", ",", "self", ".", "current_size", "+", "inc", ")", "\n", "\n", "if", "inc", "==", "1", ":", "\n", "            ", "idx", "=", "idx", "[", "0", "]", "\n", "", "return", "idx", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.__init__": [[23, 108], ["baselines.her.util.import_function", "ddpg.dims_to_shapes", "collections.OrderedDict", "sorted", "baselines.her.replay_buffer.ReplayBuffer", "baselines.her.replay_buffer.ReplayBuffer", "ddpg.DDPG.input_dims.keys", "key.startswith", "tensorflow.variable_scope", "tensorflow.contrib.staging.StagingArea", "ddpg.DDPG.staging_tf.put", "ddpg.DDPG._create_network", "tensorflow.placeholder", "dims_to_shapes.items", "list", "ddpg.DDPG.stage_shapes.values", "ddpg.DDPG.stage_shapes.values", "ddpg.DDPG.stage_shapes.keys"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.import_function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.dims_to_shapes", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.put", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._create_network"], ["    ", "@", "store_args", "\n", "def", "__init__", "(", "self", ",", "input_dims", ",", "buffer_size", ",", "hidden", ",", "layers", ",", "network_class", ",", "polyak", ",", "batch_size", ",", "\n", "Q_lr", ",", "pi_lr", ",", "norm_eps", ",", "norm_clip", ",", "max_u", ",", "action_l2", ",", "clip_obs", ",", "scope", ",", "T", ",", "\n", "rollout_batch_size", ",", "subtract_goals", ",", "relative_goals", ",", "clip_pos_returns", ",", "clip_return", ",", "\n", "bc_loss", ",", "q_filter", ",", "num_demo", ",", "demo_batch_size", ",", "prm_loss_weight", ",", "aux_loss_weight", ",", "\n", "sample_transitions", ",", "gamma", ",", "reuse", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Implementation of DDPG that is used in combination with Hindsight Experience Replay (HER).\n            Added functionality to use demonstrations for training to Overcome exploration problem.\n\n        Args:\n            input_dims (dict of ints): dimensions for the observation (o), the goal (g), and the\n                actions (u)\n            buffer_size (int): number of transitions that are stored in the replay buffer\n            hidden (int): number of units in the hidden layers\n            layers (int): number of hidden layers\n            network_class (str): the network class that should be used (e.g. 'baselines.her.ActorCritic')\n            polyak (float): coefficient for Polyak-averaging of the target network\n            batch_size (int): batch size for training\n            Q_lr (float): learning rate for the Q (critic) network\n            pi_lr (float): learning rate for the pi (actor) network\n            norm_eps (float): a small value used in the normalizer to avoid numerical instabilities\n            norm_clip (float): normalized inputs are clipped to be in [-norm_clip, norm_clip]\n            max_u (float): maximum action magnitude, i.e. actions are in [-max_u, max_u]\n            action_l2 (float): coefficient for L2 penalty on the actions\n            clip_obs (float): clip observations before normalization to be in [-clip_obs, clip_obs]\n            scope (str): the scope used for the TensorFlow graph\n            T (int): the time horizon for rollouts\n            rollout_batch_size (int): number of parallel rollouts per DDPG agent\n            subtract_goals (function): function that subtracts goals from each other\n            relative_goals (boolean): whether or not relative goals should be fed into the network\n            clip_pos_returns (boolean): whether or not positive returns should be clipped\n            clip_return (float): clip returns to be in [-clip_return, clip_return]\n            sample_transitions (function) function that samples from the replay buffer\n            gamma (float): gamma used for Q learning updates\n            reuse (boolean): whether or not the networks should be reused\n            bc_loss: whether or not the behavior cloning loss should be used as an auxilliary loss\n            q_filter: whether or not a filter on the q value update should be used when training with demonstartions\n            num_demo: Number of episodes in to be used in the demonstration buffer\n            demo_batch_size: number of samples to be used from the demonstrations buffer, per mpi thread\n            prm_loss_weight: Weight corresponding to the primary loss\n            aux_loss_weight: Weight corresponding to the auxilliary loss also called the cloning loss\n        \"\"\"", "\n", "if", "self", ".", "clip_return", "is", "None", ":", "\n", "            ", "self", ".", "clip_return", "=", "np", ".", "inf", "\n", "\n", "", "self", ".", "create_actor_critic", "=", "import_function", "(", "self", ".", "network_class", ")", "\n", "\n", "input_shapes", "=", "dims_to_shapes", "(", "self", ".", "input_dims", ")", "\n", "self", ".", "dimo", "=", "self", ".", "input_dims", "[", "'o'", "]", "\n", "self", ".", "dimg", "=", "self", ".", "input_dims", "[", "'g'", "]", "\n", "self", ".", "dimu", "=", "self", ".", "input_dims", "[", "'u'", "]", "\n", "\n", "# Prepare staging area for feeding data to the model.", "\n", "stage_shapes", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "sorted", "(", "self", ".", "input_dims", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "'info_'", ")", ":", "\n", "                ", "continue", "\n", "", "stage_shapes", "[", "key", "]", "=", "(", "None", ",", "*", "input_shapes", "[", "key", "]", ")", "\n", "", "for", "key", "in", "[", "'o'", ",", "'g'", "]", ":", "\n", "            ", "stage_shapes", "[", "key", "+", "'_2'", "]", "=", "stage_shapes", "[", "key", "]", "\n", "", "stage_shapes", "[", "'r'", "]", "=", "(", "None", ",", ")", "\n", "self", ".", "stage_shapes", "=", "stage_shapes", "\n", "\n", "# Create network.", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "self", ".", "staging_tf", "=", "StagingArea", "(", "\n", "dtypes", "=", "[", "tf", ".", "float32", "for", "_", "in", "self", ".", "stage_shapes", ".", "keys", "(", ")", "]", ",", "\n", "shapes", "=", "list", "(", "self", ".", "stage_shapes", ".", "values", "(", ")", ")", ")", "\n", "self", ".", "buffer_ph_tf", "=", "[", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "shape", ")", "for", "shape", "in", "self", ".", "stage_shapes", ".", "values", "(", ")", "]", "\n", "self", ".", "stage_op", "=", "self", ".", "staging_tf", ".", "put", "(", "self", ".", "buffer_ph_tf", ")", "\n", "\n", "self", ".", "_create_network", "(", "reuse", "=", "reuse", ")", "\n", "\n", "# Configure the replay buffer.", "\n", "", "buffer_shapes", "=", "{", "key", ":", "(", "self", ".", "T", "-", "1", "if", "key", "!=", "'o'", "else", "self", ".", "T", ",", "*", "input_shapes", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "input_shapes", ".", "items", "(", ")", "}", "\n", "buffer_shapes", "[", "'g'", "]", "=", "(", "buffer_shapes", "[", "'g'", "]", "[", "0", "]", ",", "self", ".", "dimg", ")", "\n", "buffer_shapes", "[", "'ag'", "]", "=", "(", "self", ".", "T", ",", "self", ".", "dimg", ")", "\n", "\n", "buffer_size", "=", "(", "self", ".", "buffer_size", "//", "self", ".", "rollout_batch_size", ")", "*", "self", ".", "rollout_batch_size", "\n", "self", ".", "buffer", "=", "ReplayBuffer", "(", "buffer_shapes", ",", "buffer_size", ",", "self", ".", "T", ",", "self", ".", "sample_transitions", ")", "\n", "\n", "global", "DEMO_BUFFER", "\n", "DEMO_BUFFER", "=", "ReplayBuffer", "(", "buffer_shapes", ",", "buffer_size", ",", "self", ".", "T", ",", "self", ".", "sample_transitions", ")", "#initialize the demo buffer; in the same way as the primary data buffer", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._random_action": [[109, 111], ["numpy.random.uniform"], "methods", ["None"], ["", "def", "_random_action", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "self", ".", "max_u", ",", "high", "=", "self", ".", "max_u", ",", "size", "=", "(", "n", ",", "self", ".", "dimu", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._preprocess_og": [[112, 122], ["numpy.clip", "numpy.clip", "g.reshape.reshape.reshape", "ag.reshape.reshape.reshape", "ddpg.DDPG.subtract_goals", "g.reshape.reshape.reshape"], "methods", ["None"], ["", "def", "_preprocess_og", "(", "self", ",", "o", ",", "ag", ",", "g", ")", ":", "\n", "        ", "if", "self", ".", "relative_goals", ":", "\n", "            ", "g_shape", "=", "g", ".", "shape", "\n", "g", "=", "g", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", "\n", "ag", "=", "ag", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", "\n", "g", "=", "self", ".", "subtract_goals", "(", "g", ",", "ag", ")", "\n", "g", "=", "g", ".", "reshape", "(", "*", "g_shape", ")", "\n", "", "o", "=", "np", ".", "clip", "(", "o", ",", "-", "self", ".", "clip_obs", ",", "self", ".", "clip_obs", ")", "\n", "g", "=", "np", ".", "clip", "(", "g", ",", "-", "self", ".", "clip_obs", ",", "self", ".", "clip_obs", ")", "\n", "return", "o", ",", "g", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.step": [[123, 126], ["ddpg.DDPG.get_actions"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.get_actions"], ["", "def", "step", "(", "self", ",", "obs", ")", ":", "\n", "        ", "actions", "=", "self", ".", "get_actions", "(", "obs", "[", "'observation'", "]", ",", "obs", "[", "'achieved_goal'", "]", ",", "obs", "[", "'desired_goal'", "]", ")", "\n", "return", "actions", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.get_actions": [[128, 159], ["ddpg.DDPG._preprocess_og", "ddpg.DDPG.sess.run", "numpy.clip", "u.copy.copy.copy", "o.reshape", "g.reshape", "numpy.zeros", "numpy.random.randn", "numpy.random.binomial().reshape", "len", "ddpg.DDPG._random_action", "numpy.random.binomial"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._random_action"], ["", "def", "get_actions", "(", "self", ",", "o", ",", "ag", ",", "g", ",", "noise_eps", "=", "0.", ",", "random_eps", "=", "0.", ",", "use_target_net", "=", "False", ",", "\n", "compute_Q", "=", "False", ")", ":", "\n", "        ", "o", ",", "g", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "policy", "=", "self", ".", "target", "if", "use_target_net", "else", "self", ".", "main", "\n", "# values to compute", "\n", "vals", "=", "[", "policy", ".", "pi_tf", "]", "\n", "if", "compute_Q", ":", "\n", "            ", "vals", "+=", "[", "policy", ".", "Q_pi_tf", "]", "\n", "# feed", "\n", "", "feed", "=", "{", "\n", "policy", ".", "o_tf", ":", "o", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimo", ")", ",", "\n", "policy", ".", "g_tf", ":", "g", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", ",", "\n", "policy", ".", "u_tf", ":", "np", ".", "zeros", "(", "(", "o", ".", "size", "//", "self", ".", "dimo", ",", "self", ".", "dimu", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "}", "\n", "\n", "ret", "=", "self", ".", "sess", ".", "run", "(", "vals", ",", "feed_dict", "=", "feed", ")", "\n", "# action postprocessing", "\n", "u", "=", "ret", "[", "0", "]", "\n", "noise", "=", "noise_eps", "*", "self", ".", "max_u", "*", "np", ".", "random", ".", "randn", "(", "*", "u", ".", "shape", ")", "# gaussian noise", "\n", "u", "+=", "noise", "\n", "u", "=", "np", ".", "clip", "(", "u", ",", "-", "self", ".", "max_u", ",", "self", ".", "max_u", ")", "\n", "u", "+=", "np", ".", "random", ".", "binomial", "(", "1", ",", "random_eps", ",", "u", ".", "shape", "[", "0", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "*", "(", "self", ".", "_random_action", "(", "u", ".", "shape", "[", "0", "]", ")", "-", "u", ")", "# eps-greedy", "\n", "if", "u", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "u", "=", "u", "[", "0", "]", "\n", "", "u", "=", "u", ".", "copy", "(", ")", "\n", "ret", "[", "0", "]", "=", "u", "\n", "\n", "if", "len", "(", "ret", ")", "==", "1", ":", "\n", "            ", "return", "ret", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.init_demo_buffer": [[160, 216], ["numpy.load", "range", "baselines.logger.info", "key.replace", "numpy.empty", "range", "obs.append", "achieved_goals.append", "dict", "zip", "baselines.her.util.convert_episode_to_batch_major", "DEMO_BUFFER.store_episode", "baselines.logger.debug", "baselines.her.util.convert_episode_to_batch_major.clear", "DEMO_BUFFER.get_current_size", "ddpg.DDPG.input_dims.keys", "key.startswith", "obs.append", "acts.append", "goals.append", "achieved_goals.append", "enumerate", "DEMO_BUFFER.get_current_size", "baselines.her.util.transitions_in_episode_batch", "ddpg.DDPG.sample_transitions", "ddpg.DDPG._preprocess_og", "ddpg.DDPG.o_stats.update", "ddpg.DDPG.g_stats.update", "ddpg.DDPG.o_stats.recompute_stats", "ddpg.DDPG.g_stats.recompute_stats", "[].get", "[].get", "[].get", "[].get", "[].get"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.convert_episode_to_batch_major", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.store_episode", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.debug", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.get_current_size", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.get_current_size", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.transitions_in_episode_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.recompute_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.recompute_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["", "", "def", "init_demo_buffer", "(", "self", ",", "demoDataFile", ",", "update_stats", "=", "True", ")", ":", "#function that initializes the demo buffer", "\n", "\n", "        ", "demoData", "=", "np", ".", "load", "(", "demoDataFile", ")", "#load the demonstration data from data file", "\n", "info_keys", "=", "[", "key", ".", "replace", "(", "'info_'", ",", "''", ")", "for", "key", "in", "self", ".", "input_dims", ".", "keys", "(", ")", "if", "key", ".", "startswith", "(", "'info_'", ")", "]", "\n", "info_values", "=", "[", "np", ".", "empty", "(", "(", "self", ".", "T", "-", "1", ",", "1", ",", "self", ".", "input_dims", "[", "'info_'", "+", "key", "]", ")", ",", "np", ".", "float32", ")", "for", "key", "in", "info_keys", "]", "\n", "\n", "demo_data_obs", "=", "demoData", "[", "'obs'", "]", "\n", "demo_data_acs", "=", "demoData", "[", "'acs'", "]", "\n", "demo_data_info", "=", "demoData", "[", "'info'", "]", "\n", "\n", "for", "epsd", "in", "range", "(", "self", ".", "num_demo", ")", ":", "# we initialize the whole demo buffer at the start of the training", "\n", "            ", "obs", ",", "acts", ",", "goals", ",", "achieved_goals", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "i", "=", "0", "\n", "for", "transition", "in", "range", "(", "self", ".", "T", "-", "1", ")", ":", "\n", "                ", "obs", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'observation'", ")", "]", ")", "\n", "acts", ".", "append", "(", "[", "demo_data_acs", "[", "epsd", "]", "[", "transition", "]", "]", ")", "\n", "goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'desired_goal'", ")", "]", ")", "\n", "achieved_goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'achieved_goal'", ")", "]", ")", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "info_keys", ")", ":", "\n", "                    ", "info_values", "[", "idx", "]", "[", "transition", ",", "i", "]", "=", "demo_data_info", "[", "epsd", "]", "[", "transition", "]", "[", "key", "]", "\n", "\n", "\n", "", "", "obs", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "self", ".", "T", "-", "1", "]", ".", "get", "(", "'observation'", ")", "]", ")", "\n", "achieved_goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "self", ".", "T", "-", "1", "]", ".", "get", "(", "'achieved_goal'", ")", "]", ")", "\n", "\n", "episode", "=", "dict", "(", "o", "=", "obs", ",", "\n", "u", "=", "acts", ",", "\n", "g", "=", "goals", ",", "\n", "ag", "=", "achieved_goals", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "info_keys", ",", "info_values", ")", ":", "\n", "                ", "episode", "[", "'info_{}'", ".", "format", "(", "key", ")", "]", "=", "value", "\n", "\n", "", "episode", "=", "convert_episode_to_batch_major", "(", "episode", ")", "\n", "global", "DEMO_BUFFER", "\n", "DEMO_BUFFER", ".", "store_episode", "(", "episode", ")", "# create the observation dict and append them into the demonstration buffer", "\n", "logger", ".", "debug", "(", "\"Demo buffer size currently \"", ",", "DEMO_BUFFER", ".", "get_current_size", "(", ")", ")", "#print out the demonstration buffer size", "\n", "\n", "if", "update_stats", ":", "\n", "# add transitions to normalizer to normalize the demo data as well", "\n", "                ", "episode", "[", "'o_2'", "]", "=", "episode", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "episode", "[", "'ag_2'", "]", "=", "episode", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "num_normalizing_transitions", "=", "transitions_in_episode_batch", "(", "episode", ")", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "episode", ",", "num_normalizing_transitions", ")", "\n", "\n", "o", ",", "g", ",", "ag", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", ",", "transitions", "[", "'ag'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "# No need to preprocess the o_2 and g_2 since this is only used for stats", "\n", "\n", "self", ".", "o_stats", ".", "update", "(", "transitions", "[", "'o'", "]", ")", "\n", "self", ".", "g_stats", ".", "update", "(", "transitions", "[", "'g'", "]", ")", "\n", "\n", "self", ".", "o_stats", ".", "recompute_stats", "(", ")", "\n", "self", ".", "g_stats", ".", "recompute_stats", "(", ")", "\n", "", "episode", ".", "clear", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Demo buffer size: \"", ",", "DEMO_BUFFER", ".", "get_current_size", "(", ")", ")", "#print out the demonstration buffer size", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.store_episode": [[217, 241], ["ddpg.DDPG.buffer.store_episode", "baselines.her.util.transitions_in_episode_batch", "ddpg.DDPG.sample_transitions", "ddpg.DDPG._preprocess_og", "ddpg.DDPG.o_stats.update", "ddpg.DDPG.g_stats.update", "ddpg.DDPG.o_stats.recompute_stats", "ddpg.DDPG.g_stats.recompute_stats"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.store_episode", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.transitions_in_episode_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.recompute_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.recompute_stats"], ["", "def", "store_episode", "(", "self", ",", "episode_batch", ",", "update_stats", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        episode_batch: array of batch_size x (T or T+1) x dim_key\n                       'o' is of size T+1, others are of size T\n        \"\"\"", "\n", "\n", "self", ".", "buffer", ".", "store_episode", "(", "episode_batch", ")", "\n", "\n", "if", "update_stats", ":", "\n", "# add transitions to normalizer", "\n", "            ", "episode_batch", "[", "'o_2'", "]", "=", "episode_batch", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "episode_batch", "[", "'ag_2'", "]", "=", "episode_batch", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "num_normalizing_transitions", "=", "transitions_in_episode_batch", "(", "episode_batch", ")", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "episode_batch", ",", "num_normalizing_transitions", ")", "\n", "\n", "o", ",", "g", ",", "ag", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", ",", "transitions", "[", "'ag'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "# No need to preprocess the o_2 and g_2 since this is only used for stats", "\n", "\n", "self", ".", "o_stats", ".", "update", "(", "transitions", "[", "'o'", "]", ")", "\n", "self", ".", "g_stats", ".", "update", "(", "transitions", "[", "'g'", "]", ")", "\n", "\n", "self", ".", "o_stats", ".", "recompute_stats", "(", ")", "\n", "self", ".", "g_stats", ".", "recompute_stats", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.get_current_buffer_size": [[242, 244], ["ddpg.DDPG.buffer.get_current_size"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.get_current_size"], ["", "", "def", "get_current_buffer_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "buffer", ".", "get_current_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._sync_optimizers": [[245, 248], ["ddpg.DDPG.Q_adam.sync", "ddpg.DDPG.pi_adam.sync"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync"], ["", "def", "_sync_optimizers", "(", "self", ")", ":", "\n", "        ", "self", ".", "Q_adam", ".", "sync", "(", ")", "\n", "self", ".", "pi_adam", ".", "sync", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._grads": [[249, 258], ["ddpg.DDPG.sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "_grads", "(", "self", ")", ":", "\n", "# Avoid feed_dict here for performance!", "\n", "        ", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "=", "self", ".", "sess", ".", "run", "(", "[", "\n", "self", ".", "Q_loss_tf", ",", "\n", "self", ".", "main", ".", "Q_pi_tf", ",", "\n", "self", ".", "Q_grad_tf", ",", "\n", "self", ".", "pi_grad_tf", "\n", "]", ")", "\n", "return", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._update": [[259, 262], ["ddpg.DDPG.Q_adam.update", "ddpg.DDPG.pi_adam.update"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "_update", "(", "self", ",", "Q_grad", ",", "pi_grad", ")", ":", "\n", "        ", "self", ".", "Q_adam", ".", "update", "(", "Q_grad", ",", "self", ".", "Q_lr", ")", "\n", "self", ".", "pi_adam", ".", "update", "(", "pi_grad", ",", "self", ".", "pi_lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.sample_batch": [[263, 283], ["ddpg.DDPG._preprocess_og", "ddpg.DDPG._preprocess_og", "ddpg.DDPG.buffer.sample", "DEMO_BUFFER.sample", "DEMO_BUFFER.sample.items", "ddpg.DDPG.buffer.sample", "transitions[].tolist", "numpy.array", "ddpg.DDPG.stage_shapes.keys", "transitions[].tolist.append", "v.tolist"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._preprocess_og", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "sample_batch", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "bc_loss", ":", "#use demonstration buffer to sample as well if bc_loss flag is set TRUE", "\n", "            ", "transitions", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", "-", "self", ".", "demo_batch_size", ")", "\n", "global", "DEMO_BUFFER", "\n", "transitions_demo", "=", "DEMO_BUFFER", ".", "sample", "(", "self", ".", "demo_batch_size", ")", "#sample from the demo buffer", "\n", "for", "k", ",", "values", "in", "transitions_demo", ".", "items", "(", ")", ":", "\n", "                ", "rolloutV", "=", "transitions", "[", "k", "]", ".", "tolist", "(", ")", "\n", "for", "v", "in", "values", ":", "\n", "                    ", "rolloutV", ".", "append", "(", "v", ".", "tolist", "(", ")", ")", "\n", "", "transitions", "[", "k", "]", "=", "np", ".", "array", "(", "rolloutV", ")", "\n", "", "", "else", ":", "\n", "            ", "transitions", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", ")", "#otherwise only sample from primary buffer", "\n", "\n", "", "o", ",", "o_2", ",", "g", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'o_2'", "]", ",", "transitions", "[", "'g'", "]", "\n", "ag", ",", "ag_2", "=", "transitions", "[", "'ag'", "]", ",", "transitions", "[", "'ag_2'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "transitions", "[", "'o_2'", "]", ",", "transitions", "[", "'g_2'", "]", "=", "self", ".", "_preprocess_og", "(", "o_2", ",", "ag_2", ",", "g", ")", "\n", "\n", "transitions_batch", "=", "[", "transitions", "[", "key", "]", "for", "key", "in", "self", ".", "stage_shapes", ".", "keys", "(", ")", "]", "\n", "return", "transitions_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.stage_batch": [[284, 289], ["ddpg.DDPG.sess.run", "ddpg.DDPG.sample_batch", "len", "len", "dict", "zip"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.sample_batch"], ["", "def", "stage_batch", "(", "self", ",", "batch", "=", "None", ")", ":", "\n", "        ", "if", "batch", "is", "None", ":", "\n", "            ", "batch", "=", "self", ".", "sample_batch", "(", ")", "\n", "", "assert", "len", "(", "self", ".", "buffer_ph_tf", ")", "==", "len", "(", "batch", ")", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "stage_op", ",", "feed_dict", "=", "dict", "(", "zip", "(", "self", ".", "buffer_ph_tf", ",", "batch", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.train": [[290, 296], ["ddpg.DDPG._grads", "ddpg.DDPG._update", "ddpg.DDPG.stage_batch"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._grads", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.stage_batch"], ["", "def", "train", "(", "self", ",", "stage", "=", "True", ")", ":", "\n", "        ", "if", "stage", ":", "\n", "            ", "self", ".", "stage_batch", "(", ")", "\n", "", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "=", "self", ".", "_grads", "(", ")", "\n", "self", ".", "_update", "(", "Q_grad", ",", "pi_grad", ")", "\n", "return", "critic_loss", ",", "actor_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._init_target_net": [[297, 299], ["ddpg.DDPG.sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "_init_target_net", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "init_target_net_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.update_target_net": [[300, 302], ["ddpg.DDPG.sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "update_target_net", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "update_target_net_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.clear_buffer": [[303, 305], ["ddpg.DDPG.buffer.clear_buffer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.clear_buffer"], ["", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "self", ".", "buffer", ".", "clear_buffer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars": [[306, 310], ["tensorflow.get_collection", "len"], "methods", ["None"], ["", "def", "_vars", "(", "self", ",", "scope", ")", ":", "\n", "        ", "res", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "self", ".", "scope", "+", "'/'", "+", "scope", ")", "\n", "assert", "len", "(", "res", ")", ">", "0", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._global_vars": [[311, 314], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "_global_vars", "(", "self", ",", "scope", ")", ":", "\n", "        ", "res", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "scope", "+", "'/'", "+", "scope", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._create_network": [[315, 405], ["baselines.logger.info", "baselines.common.tf_util.get_session", "ddpg.DDPG.staging_tf.get", "collections.OrderedDict", "tensorflow.reshape", "numpy.concatenate", "tensorflow.clip_by_value", "tensorflow.reduce_mean", "tensorflow.gradients", "tensorflow.gradients", "zip", "zip", "baselines.her.util.flatten_grads", "baselines.her.util.flatten_grads", "baselines.common.mpi_adam.MpiAdam", "baselines.common.mpi_adam.MpiAdam", "list", "list", "tensorflow.variables_initializer().run", "ddpg.DDPG._sync_optimizers", "ddpg.DDPG._init_target_net", "tensorflow.variable_scope", "baselines.her.normalizer.Normalizer", "tensorflow.variable_scope", "baselines.her.normalizer.Normalizer", "tensorflow.variable_scope", "ddpg.DDPG.create_actor_critic", "vs.reuse_variables", "tensorflow.variable_scope", "collections.OrderedDict.copy", "ddpg.DDPG.create_actor_critic", "vs.reuse_variables", "len", "len", "tensorflow.square", "tensorflow.reshape", "tensorflow.reduce_sum", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "len", "len", "len", "len", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._global_vars", "ddpg.DDPG._global_vars", "map", "map", "vs.reuse_variables", "vs.reuse_variables", "numpy.zeros", "numpy.ones", "vs.reuse_variables", "vs.reuse_variables", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "tensorflow.boolean_mask", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "ddpg.DDPG._vars", "zip", "zip", "tensorflow.variables_initializer", "enumerate", "tensorflow.stop_gradient", "tensorflow.square", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "v[].assign", "v[].assign", "ddpg.DDPG._global_vars", "ddpg.DDPG.stage_shapes.keys", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.square", "tensorflow.square", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask", "tensorflow.boolean_mask"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.flatten_grads", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.flatten_grads", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._sync_optimizers", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._init_target_net", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._global_vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._global_vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._global_vars"], ["", "def", "_create_network", "(", "self", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating a DDPG agent with action space %d x %s...\"", "%", "(", "self", ".", "dimu", ",", "self", ".", "max_u", ")", ")", "\n", "self", ".", "sess", "=", "tf_util", ".", "get_session", "(", ")", "\n", "\n", "# running averages", "\n", "with", "tf", ".", "variable_scope", "(", "'o_stats'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "self", ".", "o_stats", "=", "Normalizer", "(", "self", ".", "dimo", ",", "self", ".", "norm_eps", ",", "self", ".", "norm_clip", ",", "sess", "=", "self", ".", "sess", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'g_stats'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "self", ".", "g_stats", "=", "Normalizer", "(", "self", ".", "dimg", ",", "self", ".", "norm_eps", ",", "self", ".", "norm_clip", ",", "sess", "=", "self", ".", "sess", ")", "\n", "\n", "# mini-batch sampling.", "\n", "", "batch", "=", "self", ".", "staging_tf", ".", "get", "(", ")", "\n", "batch_tf", "=", "OrderedDict", "(", "[", "(", "key", ",", "batch", "[", "i", "]", ")", "\n", "for", "i", ",", "key", "in", "enumerate", "(", "self", ".", "stage_shapes", ".", "keys", "(", ")", ")", "]", ")", "\n", "batch_tf", "[", "'r'", "]", "=", "tf", ".", "reshape", "(", "batch_tf", "[", "'r'", "]", ",", "[", "-", "1", ",", "1", "]", ")", "\n", "\n", "#choose only the demo buffer samples", "\n", "mask", "=", "np", ".", "concatenate", "(", "(", "np", ".", "zeros", "(", "self", ".", "batch_size", "-", "self", ".", "demo_batch_size", ")", ",", "np", ".", "ones", "(", "self", ".", "demo_batch_size", ")", ")", ",", "axis", "=", "0", ")", "\n", "\n", "# networks", "\n", "with", "tf", ".", "variable_scope", "(", "'main'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "self", ".", "main", "=", "self", ".", "create_actor_critic", "(", "batch_tf", ",", "net_type", "=", "'main'", ",", "**", "self", ".", "__dict__", ")", "\n", "vs", ".", "reuse_variables", "(", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'target'", ")", "as", "vs", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "vs", ".", "reuse_variables", "(", ")", "\n", "", "target_batch_tf", "=", "batch_tf", ".", "copy", "(", ")", "\n", "target_batch_tf", "[", "'o'", "]", "=", "batch_tf", "[", "'o_2'", "]", "\n", "target_batch_tf", "[", "'g'", "]", "=", "batch_tf", "[", "'g_2'", "]", "\n", "self", ".", "target", "=", "self", ".", "create_actor_critic", "(", "\n", "target_batch_tf", ",", "net_type", "=", "'target'", ",", "**", "self", ".", "__dict__", ")", "\n", "vs", ".", "reuse_variables", "(", ")", "\n", "", "assert", "len", "(", "self", ".", "_vars", "(", "\"main\"", ")", ")", "==", "len", "(", "self", ".", "_vars", "(", "\"target\"", ")", ")", "\n", "\n", "# loss functions", "\n", "target_Q_pi_tf", "=", "self", ".", "target", ".", "Q_pi_tf", "\n", "clip_range", "=", "(", "-", "self", ".", "clip_return", ",", "0.", "if", "self", ".", "clip_pos_returns", "else", "np", ".", "inf", ")", "\n", "target_tf", "=", "tf", ".", "clip_by_value", "(", "batch_tf", "[", "'r'", "]", "+", "self", ".", "gamma", "*", "target_Q_pi_tf", ",", "*", "clip_range", ")", "\n", "self", ".", "Q_loss_tf", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "stop_gradient", "(", "target_tf", ")", "-", "self", ".", "main", ".", "Q_tf", ")", ")", "\n", "\n", "if", "self", ".", "bc_loss", "==", "1", "and", "self", ".", "q_filter", "==", "1", ":", "# train with demonstrations and use bc_loss and q_filter both", "\n", "            ", "maskMain", "=", "tf", ".", "reshape", "(", "tf", ".", "boolean_mask", "(", "self", ".", "main", ".", "Q_tf", ">", "self", ".", "main", ".", "Q_pi_tf", ",", "mask", ")", ",", "[", "-", "1", "]", ")", "#where is the demonstrator action better than actor action according to the critic? choose those samples only", "\n", "#define the cloning loss on the actor's actions only on the samples which adhere to the above masks", "\n", "self", ".", "cloning_loss_tf", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "tf", ".", "boolean_mask", "(", "tf", ".", "boolean_mask", "(", "(", "self", ".", "main", ".", "pi_tf", ")", ",", "mask", ")", ",", "maskMain", ",", "axis", "=", "0", ")", "-", "tf", ".", "boolean_mask", "(", "tf", ".", "boolean_mask", "(", "(", "batch_tf", "[", "'u'", "]", ")", ",", "mask", ")", ",", "maskMain", ",", "axis", "=", "0", ")", ")", ")", "\n", "self", ".", "pi_loss_tf", "=", "-", "self", ".", "prm_loss_weight", "*", "tf", ".", "reduce_mean", "(", "self", ".", "main", ".", "Q_pi_tf", ")", "#primary loss scaled by it's respective weight prm_loss_weight", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "prm_loss_weight", "*", "self", ".", "action_l2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "main", ".", "pi_tf", "/", "self", ".", "max_u", ")", ")", "#L2 loss on action values scaled by the same weight prm_loss_weight", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "aux_loss_weight", "*", "self", ".", "cloning_loss_tf", "#adding the cloning loss to the actor loss as an auxilliary loss scaled by its weight aux_loss_weight", "\n", "\n", "", "elif", "self", ".", "bc_loss", "==", "1", "and", "self", ".", "q_filter", "==", "0", ":", "# train with demonstrations without q_filter", "\n", "            ", "self", ".", "cloning_loss_tf", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "tf", ".", "boolean_mask", "(", "(", "self", ".", "main", ".", "pi_tf", ")", ",", "mask", ")", "-", "tf", ".", "boolean_mask", "(", "(", "batch_tf", "[", "'u'", "]", ")", ",", "mask", ")", ")", ")", "\n", "self", ".", "pi_loss_tf", "=", "-", "self", ".", "prm_loss_weight", "*", "tf", ".", "reduce_mean", "(", "self", ".", "main", ".", "Q_pi_tf", ")", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "prm_loss_weight", "*", "self", ".", "action_l2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "main", ".", "pi_tf", "/", "self", ".", "max_u", ")", ")", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "aux_loss_weight", "*", "self", ".", "cloning_loss_tf", "\n", "\n", "", "else", ":", "#If  not training with demonstrations", "\n", "            ", "self", ".", "pi_loss_tf", "=", "-", "tf", ".", "reduce_mean", "(", "self", ".", "main", ".", "Q_pi_tf", ")", "\n", "self", ".", "pi_loss_tf", "+=", "self", ".", "action_l2", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "main", ".", "pi_tf", "/", "self", ".", "max_u", ")", ")", "\n", "\n", "", "Q_grads_tf", "=", "tf", ".", "gradients", "(", "self", ".", "Q_loss_tf", ",", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "\n", "pi_grads_tf", "=", "tf", ".", "gradients", "(", "self", ".", "pi_loss_tf", ",", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "\n", "assert", "len", "(", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "==", "len", "(", "Q_grads_tf", ")", "\n", "assert", "len", "(", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "==", "len", "(", "pi_grads_tf", ")", "\n", "self", ".", "Q_grads_vars_tf", "=", "zip", "(", "Q_grads_tf", ",", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "\n", "self", ".", "pi_grads_vars_tf", "=", "zip", "(", "pi_grads_tf", ",", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "\n", "self", ".", "Q_grad_tf", "=", "flatten_grads", "(", "grads", "=", "Q_grads_tf", ",", "var_list", "=", "self", ".", "_vars", "(", "'main/Q'", ")", ")", "\n", "self", ".", "pi_grad_tf", "=", "flatten_grads", "(", "grads", "=", "pi_grads_tf", ",", "var_list", "=", "self", ".", "_vars", "(", "'main/pi'", ")", ")", "\n", "\n", "# optimizers", "\n", "self", ".", "Q_adam", "=", "MpiAdam", "(", "self", ".", "_vars", "(", "'main/Q'", ")", ",", "scale_grad_by_procs", "=", "False", ")", "\n", "self", ".", "pi_adam", "=", "MpiAdam", "(", "self", ".", "_vars", "(", "'main/pi'", ")", ",", "scale_grad_by_procs", "=", "False", ")", "\n", "\n", "# polyak averaging", "\n", "self", ".", "main_vars", "=", "self", ".", "_vars", "(", "'main/Q'", ")", "+", "self", ".", "_vars", "(", "'main/pi'", ")", "\n", "self", ".", "target_vars", "=", "self", ".", "_vars", "(", "'target/Q'", ")", "+", "self", ".", "_vars", "(", "'target/pi'", ")", "\n", "self", ".", "stats_vars", "=", "self", ".", "_global_vars", "(", "'o_stats'", ")", "+", "self", ".", "_global_vars", "(", "'g_stats'", ")", "\n", "self", ".", "init_target_net_op", "=", "list", "(", "\n", "map", "(", "lambda", "v", ":", "v", "[", "0", "]", ".", "assign", "(", "v", "[", "1", "]", ")", ",", "zip", "(", "self", ".", "target_vars", ",", "self", ".", "main_vars", ")", ")", ")", "\n", "self", ".", "update_target_net_op", "=", "list", "(", "\n", "map", "(", "lambda", "v", ":", "v", "[", "0", "]", ".", "assign", "(", "self", ".", "polyak", "*", "v", "[", "0", "]", "+", "(", "1.", "-", "self", ".", "polyak", ")", "*", "v", "[", "1", "]", ")", ",", "zip", "(", "self", ".", "target_vars", ",", "self", ".", "main_vars", ")", ")", ")", "\n", "\n", "# initialize all variables", "\n", "tf", ".", "variables_initializer", "(", "self", ".", "_global_vars", "(", "''", ")", ")", ".", "run", "(", ")", "\n", "self", ".", "_sync_optimizers", "(", ")", "\n", "self", ".", "_init_target_net", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.logs": [[406, 417], ["numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "prefix.endswith", "ddpg.DDPG.sess.run", "ddpg.DDPG.sess.run", "ddpg.DDPG.sess.run", "ddpg.DDPG.sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "logs", "(", "self", ",", "prefix", "=", "''", ")", ":", "\n", "        ", "logs", "=", "[", "]", "\n", "logs", "+=", "[", "(", "'stats_o/mean'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "o_stats", ".", "mean", "]", ")", ")", ")", "]", "\n", "logs", "+=", "[", "(", "'stats_o/std'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "o_stats", ".", "std", "]", ")", ")", ")", "]", "\n", "logs", "+=", "[", "(", "'stats_g/mean'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "g_stats", ".", "mean", "]", ")", ")", ")", "]", "\n", "logs", "+=", "[", "(", "'stats_g/std'", ",", "np", ".", "mean", "(", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "g_stats", ".", "std", "]", ")", ")", ")", "]", "\n", "\n", "if", "prefix", "!=", "''", "and", "not", "prefix", ".", "endswith", "(", "'/'", ")", ":", "\n", "            ", "return", "[", "(", "prefix", "+", "'/'", "+", "key", ",", "val", ")", "for", "key", ",", "val", "in", "logs", "]", "\n", "", "else", ":", "\n", "            ", "return", "logs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.__getstate__": [[418, 429], ["ddpg.DDPG.sess.run", "ddpg.DDPG.__dict__.items", "all", "ddpg.DDPG._global_vars"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._global_vars"], ["", "", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Our policies can be loaded from pkl, but after unpickling you cannot continue training.\n        \"\"\"", "\n", "excluded_subnames", "=", "[", "'_tf'", ",", "'_op'", ",", "'_vars'", ",", "'_adam'", ",", "'buffer'", ",", "'sess'", ",", "'_stats'", ",", "\n", "'main'", ",", "'target'", ",", "'lock'", ",", "'env'", ",", "'sample_transitions'", ",", "\n", "'stage_shapes'", ",", "'create_actor_critic'", "]", "\n", "\n", "state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "self", ".", "__dict__", ".", "items", "(", ")", "if", "all", "(", "[", "not", "subname", "in", "k", "for", "subname", "in", "excluded_subnames", "]", ")", "}", "\n", "state", "[", "'buffer_size'", "]", "=", "self", ".", "buffer_size", "\n", "state", "[", "'tf'", "]", "=", "self", ".", "sess", ".", "run", "(", "[", "x", "for", "x", "in", "self", ".", "_global_vars", "(", "''", ")", "if", "'buffer'", "not", "in", "x", ".", "name", "]", ")", "\n", "return", "state", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.__setstate__": [[430, 445], ["ddpg.DDPG.__init__", "state.items", "ddpg.DDPG.sess.run", "len", "len", "tensorflow.assign", "ddpg.DDPG._global_vars", "zip"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG._global_vars"], ["", "def", "__setstate__", "(", "self", ",", "state", ")", ":", "\n", "        ", "if", "'sample_transitions'", "not", "in", "state", ":", "\n", "# We don't need this for playing the policy.", "\n", "            ", "state", "[", "'sample_transitions'", "]", "=", "None", "\n", "\n", "", "self", ".", "__init__", "(", "**", "state", ")", "\n", "# set up stats (they are overwritten in __init__)", "\n", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "[", "-", "6", ":", "]", "==", "'_stats'", ":", "\n", "                ", "self", ".", "__dict__", "[", "k", "]", "=", "v", "\n", "# load TF variables", "\n", "", "", "vars", "=", "[", "x", "for", "x", "in", "self", ".", "_global_vars", "(", "''", ")", "if", "'buffer'", "not", "in", "x", ".", "name", "]", "\n", "assert", "(", "len", "(", "vars", ")", "==", "len", "(", "state", "[", "\"tf\"", "]", ")", ")", "\n", "node", "=", "[", "tf", ".", "assign", "(", "var", ",", "val", ")", "for", "var", ",", "val", "in", "zip", "(", "vars", ",", "state", "[", "\"tf\"", "]", ")", "]", "\n", "self", ".", "sess", ".", "run", "(", "node", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.save": [[446, 448], ["baselines.common.tf_util.save_variables"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_variables"], ["", "def", "save", "(", "self", ",", "save_path", ")", ":", "\n", "        ", "tf_util", ".", "save_variables", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.dims_to_shapes": [[16, 18], ["tuple", "tuple", "input_dims.items"], "function", ["None"], ["def", "dims_to_shapes", "(", "input_dims", ")", ":", "\n", "    ", "return", "{", "key", ":", "tuple", "(", "[", "val", "]", ")", "if", "val", ">", "0", "else", "tuple", "(", ")", "for", "key", ",", "val", "in", "input_dims", ".", "items", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer.__init__": [[11, 63], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.group", "tensorflow.group", "threading.Lock", "tensorflow.get_default_session", "normalizer.Normalizer.count_tf.assign_add", "normalizer.Normalizer.sum_tf.assign_add", "normalizer.Normalizer.sumsq_tf.assign_add", "tensorflow.assign", "tensorflow.assign", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.ones_initializer", "tensorflow.zeros_initializer", "tensorflow.ones_initializer", "tensorflow.sqrt", "tensorflow.maximum", "tensorflow.square", "tensorflow.square"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "eps", "=", "1e-2", ",", "default_clip_range", "=", "np", ".", "inf", ",", "sess", "=", "None", ")", ":", "\n", "        ", "\"\"\"A normalizer that ensures that observations are approximately distributed according to\n        a standard Normal distribution (i.e. have mean zero and variance one).\n\n        Args:\n            size (int): the size of the observation to be normalized\n            eps (float): a small constant that avoids underflows\n            default_clip_range (float): normalized observations are clipped to be in\n                [-default_clip_range, default_clip_range]\n            sess (object): the TensorFlow session to be used\n        \"\"\"", "\n", "self", ".", "size", "=", "size", "\n", "self", ".", "eps", "=", "eps", "\n", "self", ".", "default_clip_range", "=", "default_clip_range", "\n", "self", ".", "sess", "=", "sess", "if", "sess", "is", "not", "None", "else", "tf", ".", "get_default_session", "(", ")", "\n", "\n", "self", ".", "local_sum", "=", "np", ".", "zeros", "(", "self", ".", "size", ",", "np", ".", "float32", ")", "\n", "self", ".", "local_sumsq", "=", "np", ".", "zeros", "(", "self", ".", "size", ",", "np", ".", "float32", ")", "\n", "self", ".", "local_count", "=", "np", ".", "zeros", "(", "1", ",", "np", ".", "float32", ")", "\n", "\n", "self", ".", "sum_tf", "=", "tf", ".", "get_variable", "(", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "shape", "=", "self", ".", "local_sum", ".", "shape", ",", "name", "=", "'sum'", ",", "\n", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "sumsq_tf", "=", "tf", ".", "get_variable", "(", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "shape", "=", "self", ".", "local_sumsq", ".", "shape", ",", "name", "=", "'sumsq'", ",", "\n", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "count_tf", "=", "tf", ".", "get_variable", "(", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ",", "shape", "=", "self", ".", "local_count", ".", "shape", ",", "name", "=", "'count'", ",", "\n", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "mean", "=", "tf", ".", "get_variable", "(", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "shape", "=", "(", "self", ".", "size", ",", ")", ",", "name", "=", "'mean'", ",", "\n", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "std", "=", "tf", ".", "get_variable", "(", "\n", "initializer", "=", "tf", ".", "ones_initializer", "(", ")", ",", "shape", "=", "(", "self", ".", "size", ",", ")", ",", "name", "=", "'std'", ",", "\n", "trainable", "=", "False", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "count_pl", "=", "tf", ".", "placeholder", "(", "name", "=", "'count_pl'", ",", "shape", "=", "(", "1", ",", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "sum_pl", "=", "tf", ".", "placeholder", "(", "name", "=", "'sum_pl'", ",", "shape", "=", "(", "self", ".", "size", ",", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "self", ".", "sumsq_pl", "=", "tf", ".", "placeholder", "(", "name", "=", "'sumsq_pl'", ",", "shape", "=", "(", "self", ".", "size", ",", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "\n", "self", ".", "update_op", "=", "tf", ".", "group", "(", "\n", "self", ".", "count_tf", ".", "assign_add", "(", "self", ".", "count_pl", ")", ",", "\n", "self", ".", "sum_tf", ".", "assign_add", "(", "self", ".", "sum_pl", ")", ",", "\n", "self", ".", "sumsq_tf", ".", "assign_add", "(", "self", ".", "sumsq_pl", ")", "\n", ")", "\n", "self", ".", "recompute_op", "=", "tf", ".", "group", "(", "\n", "tf", ".", "assign", "(", "self", ".", "mean", ",", "self", ".", "sum_tf", "/", "self", ".", "count_tf", ")", ",", "\n", "tf", ".", "assign", "(", "self", ".", "std", ",", "tf", ".", "sqrt", "(", "tf", ".", "maximum", "(", "\n", "tf", ".", "square", "(", "self", ".", "eps", ")", ",", "\n", "self", ".", "sumsq_tf", "/", "self", ".", "count_tf", "-", "tf", ".", "square", "(", "self", ".", "sum_tf", "/", "self", ".", "count_tf", ")", "\n", ")", ")", ")", ",", "\n", ")", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer.update": [[64, 71], ["v.reshape.reshape.reshape", "v.reshape.reshape.sum", "numpy.square().sum", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "update", "(", "self", ",", "v", ")", ":", "\n", "        ", "v", "=", "v", ".", "reshape", "(", "-", "1", ",", "self", ".", "size", ")", "\n", "\n", "with", "self", ".", "lock", ":", "\n", "            ", "self", ".", "local_sum", "+=", "v", ".", "sum", "(", "axis", "=", "0", ")", "\n", "self", ".", "local_sumsq", "+=", "(", "np", ".", "square", "(", "v", ")", ")", ".", "sum", "(", "axis", "=", "0", ")", "\n", "self", ".", "local_count", "[", "0", "]", "+=", "v", ".", "shape", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer.normalize": [[72, 78], ["baselines.her.util.reshape_for_broadcasting", "baselines.her.util.reshape_for_broadcasting", "tensorflow.clip_by_value"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.reshape_for_broadcasting", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.reshape_for_broadcasting"], ["", "", "def", "normalize", "(", "self", ",", "v", ",", "clip_range", "=", "None", ")", ":", "\n", "        ", "if", "clip_range", "is", "None", ":", "\n", "            ", "clip_range", "=", "self", ".", "default_clip_range", "\n", "", "mean", "=", "reshape_for_broadcasting", "(", "self", ".", "mean", ",", "v", ")", "\n", "std", "=", "reshape_for_broadcasting", "(", "self", ".", "std", ",", "v", ")", "\n", "return", "tf", ".", "clip_by_value", "(", "(", "v", "-", "mean", ")", "/", "std", ",", "-", "clip_range", ",", "clip_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer.denormalize": [[79, 83], ["baselines.her.util.reshape_for_broadcasting", "baselines.her.util.reshape_for_broadcasting"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.reshape_for_broadcasting", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.reshape_for_broadcasting"], ["", "def", "denormalize", "(", "self", ",", "v", ")", ":", "\n", "        ", "mean", "=", "reshape_for_broadcasting", "(", "self", ".", "mean", ",", "v", ")", "\n", "std", "=", "reshape_for_broadcasting", "(", "self", ".", "std", ",", "v", ")", "\n", "return", "mean", "+", "v", "*", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer._mpi_average": [[84, 89], ["numpy.zeros_like", "mpi4py.MPI.COMM_WORLD.Allreduce", "mpi4py.MPI.COMM_WORLD.Get_size"], "methods", ["None"], ["", "def", "_mpi_average", "(", "self", ",", "x", ")", ":", "\n", "        ", "buf", "=", "np", ".", "zeros_like", "(", "x", ")", "\n", "MPI", ".", "COMM_WORLD", ".", "Allreduce", "(", "x", ",", "buf", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "buf", "/=", "MPI", ".", "COMM_WORLD", ".", "Get_size", "(", ")", "\n", "return", "buf", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer.synchronize": [[90, 95], ["normalizer.Normalizer._mpi_average", "normalizer.Normalizer._mpi_average", "normalizer.Normalizer._mpi_average"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer._mpi_average", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer._mpi_average", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer._mpi_average"], ["", "def", "synchronize", "(", "self", ",", "local_sum", ",", "local_sumsq", ",", "local_count", ",", "root", "=", "None", ")", ":", "\n", "        ", "local_sum", "[", "...", "]", "=", "self", ".", "_mpi_average", "(", "local_sum", ")", "\n", "local_sumsq", "[", "...", "]", "=", "self", ".", "_mpi_average", "(", "local_sumsq", ")", "\n", "local_count", "[", "...", "]", "=", "self", ".", "_mpi_average", "(", "local_count", ")", "\n", "return", "local_sum", ",", "local_sumsq", ",", "local_count", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.Normalizer.recompute_stats": [[96, 119], ["normalizer.Normalizer.synchronize", "normalizer.Normalizer.sess.run", "normalizer.Normalizer.sess.run", "normalizer.Normalizer.local_count.copy", "normalizer.Normalizer.local_sum.copy", "normalizer.Normalizer.local_sumsq.copy"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.synchronize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "recompute_stats", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "# Copy over results.", "\n", "            ", "local_count", "=", "self", ".", "local_count", ".", "copy", "(", ")", "\n", "local_sum", "=", "self", ".", "local_sum", ".", "copy", "(", ")", "\n", "local_sumsq", "=", "self", ".", "local_sumsq", ".", "copy", "(", ")", "\n", "\n", "# Reset.", "\n", "self", ".", "local_count", "[", "...", "]", "=", "0", "\n", "self", ".", "local_sum", "[", "...", "]", "=", "0", "\n", "self", ".", "local_sumsq", "[", "...", "]", "=", "0", "\n", "\n", "# We perform the synchronization outside of the lock to keep the critical section as short", "\n", "# as possible.", "\n", "", "synced_sum", ",", "synced_sumsq", ",", "synced_count", "=", "self", ".", "synchronize", "(", "\n", "local_sum", "=", "local_sum", ",", "local_sumsq", "=", "local_sumsq", ",", "local_count", "=", "local_count", ")", "\n", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "update_op", ",", "feed_dict", "=", "{", "\n", "self", ".", "count_pl", ":", "synced_count", ",", "\n", "self", ".", "sum_pl", ":", "synced_sum", ",", "\n", "self", ".", "sumsq_pl", ":", "synced_sumsq", ",", "\n", "}", ")", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "recompute_op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.__init__": [[122, 126], ["tensorflow.zeros", "tensorflow.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ",", "std", "=", "1.", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "self", ".", "mean", "=", "tf", ".", "zeros", "(", "self", ".", "size", ",", "tf", ".", "float32", ")", "\n", "self", ".", "std", "=", "std", "*", "tf", ".", "ones", "(", "self", ".", "size", ",", "tf", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.update": [[127, 129], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "x", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.normalize": [[130, 132], ["None"], "methods", ["None"], ["", "def", "normalize", "(", "self", ",", "x", ",", "clip_range", "=", "None", ")", ":", "\n", "        ", "return", "x", "/", "self", ".", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.denormalize": [[133, 135], ["None"], "methods", ["None"], ["", "def", "denormalize", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "std", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.synchronize": [[136, 138], ["None"], "methods", ["None"], ["", "def", "synchronize", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.normalizer.IdentityNormalizer.recompute_stats": [[139, 141], ["None"], "methods", ["None"], ["", "def", "recompute_stats", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.mpi_average": [[14, 20], ["isinstance", "any", "baselines.common.mpi_moments.mpi_moments", "numpy.array"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.mpi_moments"], ["def", "mpi_average", "(", "value", ")", ":", "\n", "    ", "if", "not", "isinstance", "(", "value", ",", "list", ")", ":", "\n", "        ", "value", "=", "[", "value", "]", "\n", "", "if", "not", "any", "(", "value", ")", ":", "\n", "        ", "value", "=", "[", "0.", "]", "\n", "", "return", "mpi_moments", "(", "np", ".", "array", "(", "value", ")", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.train": [[22, 85], ["mpi4py.MPI.COMM_WORLD.Get_rank", "baselines.logger.info", "range", "os.path.join", "os.path.join", "os.path.join", "policy.init_demo_buffer", "rollout_worker.clear_history", "range", "evaluator.clear_history", "range", "baselines.logger.record_tabular", "evaluator.logs", "rollout_worker.logs", "policy.logs", "her.mpi_average", "numpy.random.uniform", "np.random.uniform.copy", "mpi4py.MPI.COMM_WORLD.Bcast", "rollout_worker.generate_rollouts", "policy.store_episode", "range", "policy.update_target_net", "evaluator.generate_rollouts", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.dump_tabular", "evaluator.current_success_rate", "baselines.logger.info", "evaluator.save_policy", "evaluator.save_policy", "os.path.join.format", "baselines.logger.info", "evaluator.save_policy", "policy.train", "her.mpi_average", "her.mpi_average", "her.mpi_average"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.init_demo_buffer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.clear_history", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.clear_history", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.logs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.logs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.logs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.mpi_average", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.generate_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.store_episode", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.update_target_net", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.generate_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.current_success_rate", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.save_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.save_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.save_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.mpi_average", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.mpi_average", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.mpi_average"], ["", "def", "train", "(", "*", ",", "policy", ",", "rollout_worker", ",", "evaluator", ",", "\n", "n_epochs", ",", "n_test_rollouts", ",", "n_cycles", ",", "n_batches", ",", "policy_save_interval", ",", "\n", "save_path", ",", "demo_file", ",", "**", "kwargs", ")", ":", "\n", "    ", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "\n", "if", "save_path", ":", "\n", "        ", "latest_policy_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'policy_latest.pkl'", ")", "\n", "best_policy_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'policy_best.pkl'", ")", "\n", "periodic_policy_path", "=", "os", ".", "path", ".", "join", "(", "save_path", ",", "'policy_{}.pkl'", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Training...\"", ")", "\n", "best_success_rate", "=", "-", "1", "\n", "\n", "if", "policy", ".", "bc_loss", "==", "1", ":", "policy", ".", "init_demo_buffer", "(", "demo_file", ")", "#initialize demo buffer if training with demonstrations", "\n", "\n", "# num_timesteps = n_epochs * n_cycles * rollout_length * number of rollout workers", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "# train", "\n", "        ", "rollout_worker", ".", "clear_history", "(", ")", "\n", "for", "_", "in", "range", "(", "n_cycles", ")", ":", "\n", "            ", "episode", "=", "rollout_worker", ".", "generate_rollouts", "(", ")", "\n", "policy", ".", "store_episode", "(", "episode", ")", "\n", "for", "_", "in", "range", "(", "n_batches", ")", ":", "\n", "                ", "policy", ".", "train", "(", ")", "\n", "", "policy", ".", "update_target_net", "(", ")", "\n", "\n", "# test", "\n", "", "evaluator", ".", "clear_history", "(", ")", "\n", "for", "_", "in", "range", "(", "n_test_rollouts", ")", ":", "\n", "            ", "evaluator", ".", "generate_rollouts", "(", ")", "\n", "\n", "# record logs", "\n", "", "logger", ".", "record_tabular", "(", "'epoch'", ",", "epoch", ")", "\n", "for", "key", ",", "val", "in", "evaluator", ".", "logs", "(", "'test'", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "key", ",", "mpi_average", "(", "val", ")", ")", "\n", "", "for", "key", ",", "val", "in", "rollout_worker", ".", "logs", "(", "'train'", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "key", ",", "mpi_average", "(", "val", ")", ")", "\n", "", "for", "key", ",", "val", "in", "policy", ".", "logs", "(", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "key", ",", "mpi_average", "(", "val", ")", ")", "\n", "\n", "", "if", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "dump_tabular", "(", ")", "\n", "\n", "# save the policy if it's better than the previous ones", "\n", "", "success_rate", "=", "mpi_average", "(", "evaluator", ".", "current_success_rate", "(", ")", ")", "\n", "if", "rank", "==", "0", "and", "success_rate", ">=", "best_success_rate", "and", "save_path", ":", "\n", "            ", "best_success_rate", "=", "success_rate", "\n", "logger", ".", "info", "(", "'New best success rate: {}. Saving policy to {} ...'", ".", "format", "(", "best_success_rate", ",", "best_policy_path", ")", ")", "\n", "evaluator", ".", "save_policy", "(", "best_policy_path", ")", "\n", "evaluator", ".", "save_policy", "(", "latest_policy_path", ")", "\n", "", "if", "rank", "==", "0", "and", "policy_save_interval", ">", "0", "and", "epoch", "%", "policy_save_interval", "==", "0", "and", "save_path", ":", "\n", "            ", "policy_path", "=", "periodic_policy_path", ".", "format", "(", "epoch", ")", "\n", "logger", ".", "info", "(", "'Saving periodic policy to {} ...'", ".", "format", "(", "policy_path", ")", ")", "\n", "evaluator", ".", "save_policy", "(", "policy_path", ")", "\n", "\n", "# make sure that different threads have different seeds", "\n", "", "local_uniform", "=", "np", ".", "random", ".", "uniform", "(", "size", "=", "(", "1", ",", ")", ")", "\n", "root_uniform", "=", "local_uniform", ".", "copy", "(", ")", "\n", "MPI", ".", "COMM_WORLD", ".", "Bcast", "(", "root_uniform", ",", "root", "=", "0", ")", "\n", "if", "rank", "!=", "0", ":", "\n", "            ", "assert", "local_uniform", "[", "0", "]", "!=", "root_uniform", "[", "0", "]", "\n", "\n", "", "", "return", "policy", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.learn": [[87, 178], ["baselines.common.set_global_seeds", "config.prepare_params.update", "baselines.prepare_params", "config.prepare_params.update", "baselines.log_params", "baselines.configure_dims", "baselines.configure_ddpg", "baselines.her.rollout.RolloutWorker", "baselines.her.rollout.RolloutWorker", "her.train", "mpi4py.MPI.COMM_WORLD.Get_rank", "mpi4py.MPI.COMM_WORLD.Get_size", "config.prepare_params.update", "open", "json.dump", "baselines.logger.warn", "baselines.logger.warn", "baselines.logger.warn", "baselines.logger.warn", "baselines.logger.warn", "baselines.common.tf_util.load_variables", "os.path.join", "baselines.logger.get_dir"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.prepare_params", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.log_params", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.configure_dims", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.configure_ddpg", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["", "def", "learn", "(", "*", ",", "network", ",", "env", ",", "total_timesteps", ",", "\n", "seed", "=", "None", ",", "\n", "eval_env", "=", "None", ",", "\n", "replay_strategy", "=", "'future'", ",", "\n", "policy_save_interval", "=", "5", ",", "\n", "clip_return", "=", "True", ",", "\n", "demo_file", "=", "None", ",", "\n", "override_params", "=", "None", ",", "\n", "load_path", "=", "None", ",", "\n", "save_path", "=", "None", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "\n", "    ", "override_params", "=", "override_params", "or", "{", "}", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "        ", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "num_cpu", "=", "MPI", ".", "COMM_WORLD", ".", "Get_size", "(", ")", "\n", "\n", "# Seed everything.", "\n", "", "rank_seed", "=", "seed", "+", "1000000", "*", "rank", "if", "seed", "is", "not", "None", "else", "None", "\n", "set_global_seeds", "(", "rank_seed", ")", "\n", "\n", "# Prepare params.", "\n", "params", "=", "config", ".", "DEFAULT_PARAMS", "\n", "env_name", "=", "env", ".", "spec", ".", "id", "\n", "params", "[", "'env_name'", "]", "=", "env_name", "\n", "params", "[", "'replay_strategy'", "]", "=", "replay_strategy", "\n", "if", "env_name", "in", "config", ".", "DEFAULT_ENV_PARAMS", ":", "\n", "        ", "params", ".", "update", "(", "config", ".", "DEFAULT_ENV_PARAMS", "[", "env_name", "]", ")", "# merge env-specific parameters in", "\n", "", "params", ".", "update", "(", "**", "override_params", ")", "# makes it possible to override any parameter", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "'params.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "         ", "json", ".", "dump", "(", "params", ",", "f", ")", "\n", "", "params", "=", "config", ".", "prepare_params", "(", "params", ")", "\n", "params", "[", "'rollout_batch_size'", "]", "=", "env", ".", "num_envs", "\n", "\n", "if", "demo_file", "is", "not", "None", ":", "\n", "        ", "params", "[", "'bc_loss'", "]", "=", "1", "\n", "", "params", ".", "update", "(", "kwargs", ")", "\n", "\n", "config", ".", "log_params", "(", "params", ",", "logger", "=", "logger", ")", "\n", "\n", "if", "num_cpu", "==", "1", ":", "\n", "        ", "logger", ".", "warn", "(", ")", "\n", "logger", ".", "warn", "(", "'*** Warning ***'", ")", "\n", "logger", ".", "warn", "(", "\n", "'You are running HER with just a single MPI worker. This will work, but the '", "+", "\n", "'experiments that we report in Plappert et al. (2018, https://arxiv.org/abs/1802.09464) '", "+", "\n", "'were obtained with --num_cpu 19. This makes a significant difference and if you '", "+", "\n", "'are looking to reproduce those results, be aware of this. Please also refer to '", "+", "\n", "'https://github.com/openai/baselines/issues/314 for further details.'", ")", "\n", "logger", ".", "warn", "(", "'****************'", ")", "\n", "logger", ".", "warn", "(", ")", "\n", "\n", "", "dims", "=", "config", ".", "configure_dims", "(", "params", ")", "\n", "policy", "=", "config", ".", "configure_ddpg", "(", "dims", "=", "dims", ",", "params", "=", "params", ",", "clip_return", "=", "clip_return", ")", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "tf_util", ".", "load_variables", "(", "load_path", ")", "\n", "\n", "", "rollout_params", "=", "{", "\n", "'exploit'", ":", "False", ",", "\n", "'use_target_net'", ":", "False", ",", "\n", "'use_demo_states'", ":", "True", ",", "\n", "'compute_Q'", ":", "False", ",", "\n", "'T'", ":", "params", "[", "'T'", "]", ",", "\n", "}", "\n", "\n", "eval_params", "=", "{", "\n", "'exploit'", ":", "True", ",", "\n", "'use_target_net'", ":", "params", "[", "'test_with_polyak'", "]", ",", "\n", "'use_demo_states'", ":", "False", ",", "\n", "'compute_Q'", ":", "True", ",", "\n", "'T'", ":", "params", "[", "'T'", "]", ",", "\n", "}", "\n", "\n", "for", "name", "in", "[", "'T'", ",", "'rollout_batch_size'", ",", "'gamma'", ",", "'noise_eps'", ",", "'random_eps'", "]", ":", "\n", "        ", "rollout_params", "[", "name", "]", "=", "params", "[", "name", "]", "\n", "eval_params", "[", "name", "]", "=", "params", "[", "name", "]", "\n", "\n", "", "eval_env", "=", "eval_env", "or", "env", "\n", "\n", "rollout_worker", "=", "RolloutWorker", "(", "env", ",", "policy", ",", "dims", ",", "logger", ",", "monitor", "=", "True", ",", "**", "rollout_params", ")", "\n", "evaluator", "=", "RolloutWorker", "(", "eval_env", ",", "policy", ",", "dims", ",", "logger", ",", "**", "eval_params", ")", "\n", "\n", "n_cycles", "=", "params", "[", "'n_cycles'", "]", "\n", "n_epochs", "=", "total_timesteps", "//", "n_cycles", "//", "rollout_worker", ".", "T", "//", "rollout_worker", ".", "rollout_batch_size", "\n", "\n", "return", "train", "(", "\n", "save_path", "=", "save_path", ",", "policy", "=", "policy", ",", "rollout_worker", "=", "rollout_worker", ",", "\n", "evaluator", "=", "evaluator", ",", "n_epochs", "=", "n_epochs", ",", "n_test_rollouts", "=", "params", "[", "'n_test_rollouts'", "]", ",", "\n", "n_cycles", "=", "params", "[", "'n_cycles'", "]", ",", "n_batches", "=", "params", "[", "'n_batches'", "]", ",", "\n", "policy_save_interval", "=", "policy_save_interval", ",", "demo_file", "=", "demo_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her.main": [[180, 190], ["click.command", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "click.option", "her.learn", "int", "click.Choice"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn"], ["", "@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "option", "(", "'--env'", ",", "type", "=", "str", ",", "default", "=", "'FetchReach-v1'", ",", "help", "=", "'the name of the OpenAI Gym environment that you want to train on'", ")", "\n", "@", "click", ".", "option", "(", "'--total_timesteps'", ",", "type", "=", "int", ",", "default", "=", "int", "(", "5e5", ")", ",", "help", "=", "'the number of timesteps to run'", ")", "\n", "@", "click", ".", "option", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'the random seed used to seed both the environment and the training code'", ")", "\n", "@", "click", ".", "option", "(", "'--policy_save_interval'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "help", "=", "'the interval with which policy pickles are saved. If set to 0, only the best and latest policy will be pickled.'", ")", "\n", "@", "click", ".", "option", "(", "'--replay_strategy'", ",", "type", "=", "click", ".", "Choice", "(", "[", "'future'", ",", "'none'", "]", ")", ",", "default", "=", "'future'", ",", "help", "=", "'the HER replay strategy to be used. \"future\" uses HER, \"none\" disables HER.'", ")", "\n", "@", "click", ".", "option", "(", "'--clip_return'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "help", "=", "'whether or not returns should be clipped'", ")", "\n", "@", "click", ".", "option", "(", "'--demo_file'", ",", "type", "=", "str", ",", "default", "=", "'PATH/TO/DEMO/DATA/FILE.npz'", ",", "help", "=", "'demo data file path'", ")", "\n", "def", "main", "(", "**", "kwargs", ")", ":", "\n", "    ", "learn", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.actor_critic.ActorCritic.__init__": [[6, 45], ["actor_critic.ActorCritic.o_stats.normalize", "actor_critic.ActorCritic.g_stats.normalize", "tensorflow.concat", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.concat", "baselines.her.util.nn", "tensorflow.concat", "baselines.her.util.nn", "tensorflow.tanh", "baselines.her.util.nn"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.normalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.normalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.nn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.nn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.nn"], ["    ", "@", "store_args", "\n", "def", "__init__", "(", "self", ",", "inputs_tf", ",", "dimo", ",", "dimg", ",", "dimu", ",", "max_u", ",", "o_stats", ",", "g_stats", ",", "hidden", ",", "layers", ",", "\n", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"The actor-critic network and related training code.\n\n        Args:\n            inputs_tf (dict of tensors): all necessary inputs for the network: the\n                observation (o), the goal (g), and the action (u)\n            dimo (int): the dimension of the observations\n            dimg (int): the dimension of the goals\n            dimu (int): the dimension of the actions\n            max_u (float): the maximum magnitude of actions; action outputs will be scaled\n                accordingly\n            o_stats (baselines.her.Normalizer): normalizer for observations\n            g_stats (baselines.her.Normalizer): normalizer for goals\n            hidden (int): number of hidden units that should be used in hidden layers\n            layers (int): number of hidden layers\n        \"\"\"", "\n", "self", ".", "o_tf", "=", "inputs_tf", "[", "'o'", "]", "\n", "self", ".", "g_tf", "=", "inputs_tf", "[", "'g'", "]", "\n", "self", ".", "u_tf", "=", "inputs_tf", "[", "'u'", "]", "\n", "\n", "# Prepare inputs for actor and critic.", "\n", "o", "=", "self", ".", "o_stats", ".", "normalize", "(", "self", ".", "o_tf", ")", "\n", "g", "=", "self", ".", "g_stats", ".", "normalize", "(", "self", ".", "g_tf", ")", "\n", "input_pi", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "[", "o", ",", "g", "]", ")", "# for actor", "\n", "\n", "# Networks.", "\n", "with", "tf", ".", "variable_scope", "(", "'pi'", ")", ":", "\n", "            ", "self", ".", "pi_tf", "=", "self", ".", "max_u", "*", "tf", ".", "tanh", "(", "nn", "(", "\n", "input_pi", ",", "[", "self", ".", "hidden", "]", "*", "self", ".", "layers", "+", "[", "self", ".", "dimu", "]", ")", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "'Q'", ")", ":", "\n", "# for policy training", "\n", "            ", "input_Q", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "[", "o", ",", "g", ",", "self", ".", "pi_tf", "/", "self", ".", "max_u", "]", ")", "\n", "self", ".", "Q_pi_tf", "=", "nn", "(", "input_Q", ",", "[", "self", ".", "hidden", "]", "*", "self", ".", "layers", "+", "[", "1", "]", ")", "\n", "# for critic training", "\n", "input_Q", "=", "tf", ".", "concat", "(", "axis", "=", "1", ",", "values", "=", "[", "o", ",", "g", ",", "self", ".", "u_tf", "/", "self", ".", "max_u", "]", ")", "\n", "self", ".", "_input_Q", "=", "input_Q", "# exposed for tests", "\n", "self", ".", "Q_tf", "=", "nn", "(", "input_Q", ",", "[", "self", ".", "hidden", "]", "*", "self", ".", "layers", "+", "[", "1", "]", ",", "reuse", "=", "True", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.store_args": [[14, 39], ["inspect.getfullargspec", "functools.wraps", "dict", "dict.update", "dict.copy", "zip", "defaults.copy.update", "util..__dict__.update", "method", "zip", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["def", "store_args", "(", "method", ")", ":", "\n", "    ", "\"\"\"Stores provided method args as instance attributes.\n    \"\"\"", "\n", "argspec", "=", "inspect", ".", "getfullargspec", "(", "method", ")", "\n", "defaults", "=", "{", "}", "\n", "if", "argspec", ".", "defaults", "is", "not", "None", ":", "\n", "        ", "defaults", "=", "dict", "(", "\n", "zip", "(", "argspec", ".", "args", "[", "-", "len", "(", "argspec", ".", "defaults", ")", ":", "]", ",", "argspec", ".", "defaults", ")", ")", "\n", "", "if", "argspec", ".", "kwonlydefaults", "is", "not", "None", ":", "\n", "        ", "defaults", ".", "update", "(", "argspec", ".", "kwonlydefaults", ")", "\n", "", "arg_names", "=", "argspec", ".", "args", "[", "1", ":", "]", "\n", "\n", "@", "functools", ".", "wraps", "(", "method", ")", "\n", "def", "wrapper", "(", "*", "positional_args", ",", "**", "keyword_args", ")", ":", "\n", "        ", "self", "=", "positional_args", "[", "0", "]", "\n", "# Get default arg values", "\n", "args", "=", "defaults", ".", "copy", "(", ")", "\n", "# Add provided arg values", "\n", "for", "name", ",", "value", "in", "zip", "(", "arg_names", ",", "positional_args", "[", "1", ":", "]", ")", ":", "\n", "            ", "args", "[", "name", "]", "=", "value", "\n", "", "args", ".", "update", "(", "keyword_args", ")", "\n", "self", ".", "__dict__", ".", "update", "(", "args", ")", "\n", "return", "method", "(", "*", "positional_args", ",", "**", "keyword_args", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.import_function": [[41, 48], ["spec.split", "importlib.import_module", "getattr"], "function", ["None"], ["", "def", "import_function", "(", "spec", ")", ":", "\n", "    ", "\"\"\"Import a function identified by a string like \"pkg.module:fn_name\".\n    \"\"\"", "\n", "mod_name", ",", "fn_name", "=", "spec", ".", "split", "(", "':'", ")", "\n", "module", "=", "importlib", ".", "import_module", "(", "mod_name", ")", "\n", "fn", "=", "getattr", "(", "module", ",", "fn_name", ")", "\n", "return", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.flatten_grads": [[50, 55], ["tensorflow.concat", "tensorflow.reshape", "zip", "baselines.common.tf_util.numel"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.numel"], ["", "def", "flatten_grads", "(", "var_list", ",", "grads", ")", ":", "\n", "    ", "\"\"\"Flattens a variables and their gradients.\n    \"\"\"", "\n", "return", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "grad", ",", "[", "U", ".", "numel", "(", "v", ")", "]", ")", "\n", "for", "(", "v", ",", "grad", ")", "in", "zip", "(", "var_list", ",", "grads", ")", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.nn": [[57, 73], ["enumerate", "tensorflow.layers.dense", "tensorflow.reshape", "activation", "tensorflow.contrib.layers.xavier_initializer", "len", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense"], ["", "def", "nn", "(", "input", ",", "layers_sizes", ",", "reuse", "=", "None", ",", "flatten", "=", "False", ",", "name", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Creates a simple neural network\n    \"\"\"", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "layers_sizes", ")", ":", "\n", "        ", "activation", "=", "tf", ".", "nn", ".", "relu", "if", "i", "<", "len", "(", "layers_sizes", ")", "-", "1", "else", "None", "\n", "input", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", "=", "input", ",", "\n", "units", "=", "size", ",", "\n", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ",", "\n", "reuse", "=", "reuse", ",", "\n", "name", "=", "name", "+", "'_'", "+", "str", "(", "i", ")", ")", "\n", "if", "activation", ":", "\n", "            ", "input", "=", "activation", "(", "input", ")", "\n", "", "", "if", "flatten", ":", "\n", "        ", "assert", "layers_sizes", "[", "-", "1", "]", "==", "1", "\n", "input", "=", "tf", ".", "reshape", "(", "input", ",", "[", "-", "1", "]", ")", "\n", "", "return", "input", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.install_mpi_excepthook": [[75, 86], ["old_hook", "sys.stdout.flush", "sys.stderr.flush", "MPI.COMM_WORLD.Abort"], "function", ["None"], ["", "def", "install_mpi_excepthook", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "from", "mpi4py", "import", "MPI", "\n", "old_hook", "=", "sys", ".", "excepthook", "\n", "\n", "def", "new_hook", "(", "a", ",", "b", ",", "c", ")", ":", "\n", "        ", "old_hook", "(", "a", ",", "b", ",", "c", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "MPI", ".", "COMM_WORLD", ".", "Abort", "(", ")", "\n", "", "sys", ".", "excepthook", "=", "new_hook", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.mpi_fork": [[88, 112], ["os.getenv", "os.environ.copy", "os.environ.copy.update", "subprocess.check_call", "util.install_mpi_excepthook", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.install_mpi_excepthook"], ["", "def", "mpi_fork", "(", "n", ",", "extra_mpi_args", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Re-launches the current script with workers\n    Returns \"parent\" for original parent, \"child\" for MPI children\n    \"\"\"", "\n", "if", "n", "<=", "1", ":", "\n", "        ", "return", "\"child\"", "\n", "", "if", "os", ".", "getenv", "(", "\"IN_MPI\"", ")", "is", "None", ":", "\n", "        ", "env", "=", "os", ".", "environ", ".", "copy", "(", ")", "\n", "env", ".", "update", "(", "\n", "MKL_NUM_THREADS", "=", "\"1\"", ",", "\n", "OMP_NUM_THREADS", "=", "\"1\"", ",", "\n", "IN_MPI", "=", "\"1\"", "\n", ")", "\n", "# \"-bind-to core\" is crucial for good performance", "\n", "args", "=", "[", "\"mpirun\"", ",", "\"-np\"", ",", "str", "(", "n", ")", "]", "+", "extra_mpi_args", "+", "[", "sys", ".", "executable", "]", "\n", "\n", "args", "+=", "sys", ".", "argv", "\n", "subprocess", ".", "check_call", "(", "args", ",", "env", "=", "env", ")", "\n", "return", "\"parent\"", "\n", "", "else", ":", "\n", "        ", "install_mpi_excepthook", "(", ")", "\n", "return", "\"child\"", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.convert_episode_to_batch_major": [[114, 125], ["episode.keys", "numpy.array().copy", "np.array().copy.swapaxes", "numpy.array"], "function", ["None"], ["", "", "def", "convert_episode_to_batch_major", "(", "episode", ")", ":", "\n", "    ", "\"\"\"Converts an episode to have the batch dimension in the major (first)\n    dimension.\n    \"\"\"", "\n", "episode_batch", "=", "{", "}", "\n", "for", "key", "in", "episode", ".", "keys", "(", ")", ":", "\n", "        ", "val", "=", "np", ".", "array", "(", "episode", "[", "key", "]", ")", ".", "copy", "(", ")", "\n", "# make inputs batch-major instead of time-major", "\n", "episode_batch", "[", "key", "]", "=", "val", ".", "swapaxes", "(", "0", ",", "1", ")", "\n", "\n", "", "return", "episode_batch", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.transitions_in_episode_batch": [[127, 132], ["None"], "function", ["None"], ["", "def", "transitions_in_episode_batch", "(", "episode_batch", ")", ":", "\n", "    ", "\"\"\"Number of transitions in a given episode batch.\n    \"\"\"", "\n", "shape", "=", "episode_batch", "[", "'u'", "]", ".", "shape", "\n", "return", "shape", "[", "0", "]", "*", "shape", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.util.reshape_for_broadcasting": [[134, 141], ["len", "tensorflow.reshape", "target.get_shape", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "reshape_for_broadcasting", "(", "source", ",", "target", ")", ":", "\n", "    ", "\"\"\"Reshapes a tensor (source) to have the correct shape and dtype of the target\n    before broadcasting it with MPI.\n    \"\"\"", "\n", "dim", "=", "len", "(", "target", ".", "get_shape", "(", ")", ")", "\n", "shape", "=", "(", "[", "1", "]", "*", "(", "dim", "-", "1", ")", ")", "+", "[", "-", "1", "]", "\n", "return", "tf", ".", "reshape", "(", "tf", ".", "cast", "(", "source", ",", "target", ".", "dtype", ")", ",", "shape", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.cached_make_env": [[61, 71], ["config.prepare_params.make_env"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env"], ["def", "cached_make_env", "(", "make_env", ")", ":", "\n", "    ", "\"\"\"\n    Only creates a new environment from the provided function if one has not yet already been\n    created. This is useful here because we need to infer certain properties of the env, e.g.\n    its observation and action spaces, without any intend of actually using it.\n    \"\"\"", "\n", "if", "make_env", "not", "in", "CACHED_ENVS", ":", "\n", "        ", "env", "=", "make_env", "(", ")", "\n", "CACHED_ENVS", "[", "make_env", "]", "=", "env", "\n", "", "return", "CACHED_ENVS", "[", "make_env", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.prepare_params": [[73, 120], ["dict", "config.cached_make_env", "hasattr", "gym.make", "isinstance", "numpy.array", "baselines.bench.monitor.Monitor", "gym.wrappers.TimeLimit", "baselines.logger.get_dir", "MPI.COMM_WORLD.Get_rank", "os.path.join", "baselines.logger.warn", "baselines.logger.get_dir", "str", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.cached_make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["", "def", "prepare_params", "(", "kwargs", ")", ":", "\n", "# DDPG params", "\n", "    ", "ddpg_params", "=", "dict", "(", ")", "\n", "env_name", "=", "kwargs", "[", "'env_name'", "]", "\n", "\n", "def", "make_env", "(", "subrank", "=", "None", ")", ":", "\n", "        ", "env", "=", "gym", ".", "make", "(", "env_name", ")", "\n", "if", "subrank", "is", "not", "None", "and", "logger", ".", "get_dir", "(", ")", "is", "not", "None", ":", "\n", "            ", "try", ":", "\n", "                ", "from", "mpi4py", "import", "MPI", "\n", "mpi_rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "                ", "MPI", "=", "None", "\n", "mpi_rank", "=", "0", "\n", "logger", ".", "warn", "(", "'Running with a single MPI process. This should work, but the results may differ from the ones publshed in Plappert et al.'", ")", "\n", "\n", "", "max_episode_steps", "=", "env", ".", "_max_episode_steps", "\n", "env", "=", "Monitor", "(", "env", ",", "\n", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "str", "(", "mpi_rank", ")", "+", "'.'", "+", "str", "(", "subrank", ")", ")", ",", "\n", "allow_early_resets", "=", "True", ")", "\n", "# hack to re-expose _max_episode_steps (ideally should replace reliance on it downstream)", "\n", "env", "=", "gym", ".", "wrappers", ".", "TimeLimit", "(", "env", ",", "max_episode_steps", "=", "max_episode_steps", ")", "\n", "", "return", "env", "\n", "\n", "", "kwargs", "[", "'make_env'", "]", "=", "make_env", "\n", "tmp_env", "=", "cached_make_env", "(", "kwargs", "[", "'make_env'", "]", ")", "\n", "assert", "hasattr", "(", "tmp_env", ",", "'_max_episode_steps'", ")", "\n", "kwargs", "[", "'T'", "]", "=", "tmp_env", ".", "_max_episode_steps", "\n", "\n", "kwargs", "[", "'max_u'", "]", "=", "np", ".", "array", "(", "kwargs", "[", "'max_u'", "]", ")", "if", "isinstance", "(", "kwargs", "[", "'max_u'", "]", ",", "list", ")", "else", "kwargs", "[", "'max_u'", "]", "\n", "kwargs", "[", "'gamma'", "]", "=", "1.", "-", "1.", "/", "kwargs", "[", "'T'", "]", "\n", "if", "'lr'", "in", "kwargs", ":", "\n", "        ", "kwargs", "[", "'pi_lr'", "]", "=", "kwargs", "[", "'lr'", "]", "\n", "kwargs", "[", "'Q_lr'", "]", "=", "kwargs", "[", "'lr'", "]", "\n", "del", "kwargs", "[", "'lr'", "]", "\n", "", "for", "name", "in", "[", "'buffer_size'", ",", "'hidden'", ",", "'layers'", ",", "\n", "'network_class'", ",", "\n", "'polyak'", ",", "\n", "'batch_size'", ",", "'Q_lr'", ",", "'pi_lr'", ",", "\n", "'norm_eps'", ",", "'norm_clip'", ",", "'max_u'", ",", "\n", "'action_l2'", ",", "'clip_obs'", ",", "'scope'", ",", "'relative_goals'", "]", ":", "\n", "        ", "ddpg_params", "[", "name", "]", "=", "kwargs", "[", "name", "]", "\n", "kwargs", "[", "'_'", "+", "name", "]", "=", "kwargs", "[", "name", "]", "\n", "del", "kwargs", "[", "name", "]", "\n", "", "kwargs", "[", "'ddpg_params'", "]", "=", "ddpg_params", "\n", "\n", "return", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.log_params": [[122, 125], ["sorted", "params.keys", "baselines.logger.info"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info"], ["", "def", "log_params", "(", "params", ",", "logger", "=", "logger", ")", ":", "\n", "    ", "for", "key", "in", "sorted", "(", "params", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'{}: {}'", ".", "format", "(", "key", ",", "params", "[", "key", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.configure_her": [[127, 145], ["config.cached_make_env", "cached_make_env.reset", "baselines.her.her_sampler.make_sample_her_transitions", "cached_make_env.compute_reward"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.cached_make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.her_sampler.make_sample_her_transitions"], ["", "", "def", "configure_her", "(", "params", ")", ":", "\n", "    ", "env", "=", "cached_make_env", "(", "params", "[", "'make_env'", "]", ")", "\n", "env", ".", "reset", "(", ")", "\n", "\n", "def", "reward_fun", "(", "ag_2", ",", "g", ",", "info", ")", ":", "# vectorized", "\n", "        ", "return", "env", ".", "compute_reward", "(", "achieved_goal", "=", "ag_2", ",", "desired_goal", "=", "g", ",", "info", "=", "info", ")", "\n", "\n", "# Prepare configuration for HER.", "\n", "", "her_params", "=", "{", "\n", "'reward_fun'", ":", "reward_fun", ",", "\n", "}", "\n", "for", "name", "in", "[", "'replay_strategy'", ",", "'replay_k'", "]", ":", "\n", "        ", "her_params", "[", "name", "]", "=", "params", "[", "name", "]", "\n", "params", "[", "'_'", "+", "name", "]", "=", "her_params", "[", "name", "]", "\n", "del", "params", "[", "name", "]", "\n", "", "sample_her_transitions", "=", "make_sample_her_transitions", "(", "**", "her_params", ")", "\n", "\n", "return", "sample_her_transitions", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.simple_goal_subtract": [[147, 150], ["None"], "function", ["None"], ["", "def", "simple_goal_subtract", "(", "a", ",", "b", ")", ":", "\n", "    ", "assert", "a", ".", "shape", "==", "b", ".", "shape", "\n", "return", "a", "-", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.configure_ddpg": [[152, 184], ["config.configure_her", "dims.copy", "config.cached_make_env", "cached_make_env.reset", "ddpg_params.update", "baselines.her.ddpg.DDPG"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.configure_her", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.cached_make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "configure_ddpg", "(", "dims", ",", "params", ",", "reuse", "=", "False", ",", "use_mpi", "=", "True", ",", "clip_return", "=", "True", ")", ":", "\n", "    ", "sample_her_transitions", "=", "configure_her", "(", "params", ")", "\n", "# Extract relevant parameters.", "\n", "gamma", "=", "params", "[", "'gamma'", "]", "\n", "rollout_batch_size", "=", "params", "[", "'rollout_batch_size'", "]", "\n", "ddpg_params", "=", "params", "[", "'ddpg_params'", "]", "\n", "\n", "input_dims", "=", "dims", ".", "copy", "(", ")", "\n", "\n", "# DDPG agent", "\n", "env", "=", "cached_make_env", "(", "params", "[", "'make_env'", "]", ")", "\n", "env", ".", "reset", "(", ")", "\n", "ddpg_params", ".", "update", "(", "{", "'input_dims'", ":", "input_dims", ",", "# agent takes an input observations", "\n", "'T'", ":", "params", "[", "'T'", "]", ",", "\n", "'clip_pos_returns'", ":", "True", ",", "# clip positive returns", "\n", "'clip_return'", ":", "(", "1.", "/", "(", "1.", "-", "gamma", ")", ")", "if", "clip_return", "else", "np", ".", "inf", ",", "# max abs of return", "\n", "'rollout_batch_size'", ":", "rollout_batch_size", ",", "\n", "'subtract_goals'", ":", "simple_goal_subtract", ",", "\n", "'sample_transitions'", ":", "sample_her_transitions", ",", "\n", "'gamma'", ":", "gamma", ",", "\n", "'bc_loss'", ":", "params", "[", "'bc_loss'", "]", ",", "\n", "'q_filter'", ":", "params", "[", "'q_filter'", "]", ",", "\n", "'num_demo'", ":", "params", "[", "'num_demo'", "]", ",", "\n", "'demo_batch_size'", ":", "params", "[", "'demo_batch_size'", "]", ",", "\n", "'prm_loss_weight'", ":", "params", "[", "'prm_loss_weight'", "]", ",", "\n", "'aux_loss_weight'", ":", "params", "[", "'aux_loss_weight'", "]", ",", "\n", "}", ")", "\n", "ddpg_params", "[", "'info'", "]", "=", "{", "\n", "'env_name'", ":", "params", "[", "'env_name'", "]", ",", "\n", "}", "\n", "policy", "=", "DDPG", "(", "reuse", "=", "reuse", ",", "**", "ddpg_params", ",", "use_mpi", "=", "use_mpi", ")", "\n", "return", "policy", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.configure_dims": [[186, 202], ["config.cached_make_env", "cached_make_env.reset", "cached_make_env.step", "info.items", "cached_make_env.action_space.sample", "numpy.array", "value.reshape.reshape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.cached_make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample"], ["", "def", "configure_dims", "(", "params", ")", ":", "\n", "    ", "env", "=", "cached_make_env", "(", "params", "[", "'make_env'", "]", ")", "\n", "env", ".", "reset", "(", ")", "\n", "obs", ",", "_", ",", "_", ",", "info", "=", "env", ".", "step", "(", "env", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "\n", "dims", "=", "{", "\n", "'o'", ":", "obs", "[", "'observation'", "]", ".", "shape", "[", "0", "]", ",", "\n", "'u'", ":", "env", ".", "action_space", ".", "shape", "[", "0", "]", ",", "\n", "'g'", ":", "obs", "[", "'desired_goal'", "]", ".", "shape", "[", "0", "]", ",", "\n", "}", "\n", "for", "key", ",", "value", "in", "info", ".", "items", "(", ")", ":", "\n", "        ", "value", "=", "np", ".", "array", "(", "value", ")", "\n", "if", "value", ".", "ndim", "==", "0", ":", "\n", "            ", "value", "=", "value", ".", "reshape", "(", "1", ")", "\n", "", "dims", "[", "'info_{}'", ".", "format", "(", "key", ")", "]", "=", "value", ".", "shape", "[", "0", "]", "\n", "", "return", "dims", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.plot.smooth_reward_curve": [[12, 19], ["int", "numpy.ceil", "numpy.convolve", "numpy.convolve", "numpy.ones", "numpy.ones_like", "numpy.ones", "len"], "function", ["None"], ["def", "smooth_reward_curve", "(", "x", ",", "y", ")", ":", "\n", "    ", "halfwidth", "=", "int", "(", "np", ".", "ceil", "(", "len", "(", "x", ")", "/", "60", ")", ")", "# Halfwidth of our smoothing convolution", "\n", "k", "=", "halfwidth", "\n", "xsmoo", "=", "x", "\n", "ysmoo", "=", "np", ".", "convolve", "(", "y", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "mode", "=", "'same'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "np", ".", "ones", "(", "2", "*", "k", "+", "1", ")", ",", "\n", "mode", "=", "'same'", ")", "\n", "return", "xsmoo", ",", "ysmoo", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.plot.load_results": [[21, 38], ["numpy.genfromtxt", "enumerate", "os.path.exists", "open", "len", "name.strip", "data.reshape.reshape", "len", "lines[].split"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.strip"], ["", "def", "load_results", "(", "file", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "file", ")", ":", "\n", "        ", "return", "None", "\n", "", "with", "open", "(", "file", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "[", "line", "for", "line", "in", "f", "]", "\n", "", "if", "len", "(", "lines", ")", "<", "2", ":", "\n", "        ", "return", "None", "\n", "", "keys", "=", "[", "name", ".", "strip", "(", ")", "for", "name", "in", "lines", "[", "0", "]", ".", "split", "(", "','", ")", "]", "\n", "data", "=", "np", ".", "genfromtxt", "(", "file", ",", "delimiter", "=", "','", ",", "skip_header", "=", "1", ",", "filling_values", "=", "0.", ")", "\n", "if", "data", ".", "ndim", "==", "1", ":", "\n", "        ", "data", "=", "data", ".", "reshape", "(", "1", ",", "-", "1", ")", "\n", "", "assert", "data", ".", "ndim", "==", "2", "\n", "assert", "data", ".", "shape", "[", "-", "1", "]", "==", "len", "(", "keys", ")", "\n", "result", "=", "{", "}", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "keys", ")", ":", "\n", "        ", "result", "[", "key", "]", "=", "data", "[", ":", ",", "idx", "]", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.plot.pad": [[40, 54], ["numpy.max", "numpy.array", "numpy.concatenate", "padded_xs.append", "len", "padded_xs.append", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "pad", "(", "xs", ",", "value", "=", "np", ".", "nan", ")", ":", "\n", "    ", "maxlen", "=", "np", ".", "max", "(", "[", "len", "(", "x", ")", "for", "x", "in", "xs", "]", ")", "\n", "\n", "padded_xs", "=", "[", "]", "\n", "for", "x", "in", "xs", ":", "\n", "        ", "if", "x", ".", "shape", "[", "0", "]", ">=", "maxlen", ":", "\n", "            ", "padded_xs", ".", "append", "(", "x", ")", "\n", "\n", "", "padding", "=", "np", ".", "ones", "(", "(", "maxlen", "-", "x", ".", "shape", "[", "0", "]", ",", ")", "+", "x", ".", "shape", "[", "1", ":", "]", ")", "*", "value", "\n", "x_padded", "=", "np", ".", "concatenate", "(", "[", "x", ",", "padding", "]", ",", "axis", "=", "0", ")", "\n", "assert", "x_padded", ".", "shape", "[", "1", ":", "]", "==", "x", ".", "shape", "[", "1", ":", "]", "\n", "assert", "x_padded", ".", "shape", "[", "0", "]", "==", "maxlen", "\n", "padded_xs", ".", "append", "(", "x_padded", ")", "\n", "", "return", "np", ".", "array", "(", "padded_xs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.play.main": [[12, 58], ["click.command", "click.argument", "click.option", "click.option", "click.option", "baselines.common.set_global_seeds", "baselines.prepare_params", "baselines.log_params", "baselines.configure_dims", "baselines.her.rollout.RolloutWorker", "baselines.her.rollout.RolloutWorker.seed", "baselines.her.rollout.RolloutWorker.clear_history", "range", "baselines.her.rollout.RolloutWorker.logs", "baselines.logger.dump_tabular", "open", "pickle.load", "config.prepare_params.update", "bool", "baselines.her.rollout.RolloutWorker.generate_rollouts", "baselines.logger.record_tabular", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.prepare_params", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.log_params", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiment.config.configure_dims", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.clear_history", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.ddpg.DDPG.logs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.rollout.RolloutWorker.generate_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["@", "click", ".", "command", "(", ")", "\n", "@", "click", ".", "argument", "(", "'policy_file'", ",", "type", "=", "str", ")", "\n", "@", "click", ".", "option", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "@", "click", ".", "option", "(", "'--n_test_rollouts'", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "@", "click", ".", "option", "(", "'--render'", ",", "type", "=", "int", ",", "default", "=", "1", ")", "\n", "def", "main", "(", "policy_file", ",", "seed", ",", "n_test_rollouts", ",", "render", ")", ":", "\n", "    ", "set_global_seeds", "(", "seed", ")", "\n", "\n", "# Load policy.", "\n", "with", "open", "(", "policy_file", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "policy", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "env_name", "=", "policy", ".", "info", "[", "'env_name'", "]", "\n", "\n", "# Prepare params.", "\n", "params", "=", "config", ".", "DEFAULT_PARAMS", "\n", "if", "env_name", "in", "config", ".", "DEFAULT_ENV_PARAMS", ":", "\n", "        ", "params", ".", "update", "(", "config", ".", "DEFAULT_ENV_PARAMS", "[", "env_name", "]", ")", "# merge env-specific parameters in", "\n", "", "params", "[", "'env_name'", "]", "=", "env_name", "\n", "params", "=", "config", ".", "prepare_params", "(", "params", ")", "\n", "config", ".", "log_params", "(", "params", ",", "logger", "=", "logger", ")", "\n", "\n", "dims", "=", "config", ".", "configure_dims", "(", "params", ")", "\n", "\n", "eval_params", "=", "{", "\n", "'exploit'", ":", "True", ",", "\n", "'use_target_net'", ":", "params", "[", "'test_with_polyak'", "]", ",", "\n", "'compute_Q'", ":", "True", ",", "\n", "'rollout_batch_size'", ":", "1", ",", "\n", "'render'", ":", "bool", "(", "render", ")", ",", "\n", "}", "\n", "\n", "for", "name", "in", "[", "'T'", ",", "'gamma'", ",", "'noise_eps'", ",", "'random_eps'", "]", ":", "\n", "        ", "eval_params", "[", "name", "]", "=", "params", "[", "name", "]", "\n", "\n", "", "evaluator", "=", "RolloutWorker", "(", "params", "[", "'make_env'", "]", ",", "policy", ",", "dims", ",", "logger", ",", "**", "eval_params", ")", "\n", "evaluator", ".", "seed", "(", "seed", ")", "\n", "\n", "# Run evaluation.", "\n", "evaluator", ".", "clear_history", "(", ")", "\n", "for", "_", "in", "range", "(", "n_test_rollouts", ")", ":", "\n", "        ", "evaluator", ".", "generate_rollouts", "(", ")", "\n", "\n", "# record logs", "\n", "", "for", "key", ",", "val", "in", "evaluator", ".", "logs", "(", "'test'", ")", ":", "\n", "        ", "logger", ".", "record_tabular", "(", "key", ",", "np", ".", "mean", "(", "val", ")", ")", "\n", "", "logger", ".", "dump_tabular", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.data_generation.fetch_data_generation.main": [[11, 29], ["gym.make", "gym.make.reset", "print", "numpy.savez_compressed", "len", "gym.make.reset", "print", "fetch_data_generation.goToGoal", "str", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.data_generation.fetch_data_generation.goToGoal"], ["def", "main", "(", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "'FetchPickAndPlace-v1'", ")", "\n", "numItr", "=", "100", "\n", "initStateSpace", "=", "\"random\"", "\n", "env", ".", "reset", "(", ")", "\n", "print", "(", "\"Reset!\"", ")", "\n", "while", "len", "(", "actions", ")", "<", "numItr", ":", "\n", "        ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "print", "(", "\"ITERATION NUMBER \"", ",", "len", "(", "actions", ")", ")", "\n", "goToGoal", "(", "env", ",", "obs", ")", "\n", "\n", "\n", "", "fileName", "=", "\"data_fetch\"", "\n", "fileName", "+=", "\"_\"", "+", "initStateSpace", "\n", "fileName", "+=", "\"_\"", "+", "str", "(", "numItr", ")", "\n", "fileName", "+=", "\".npz\"", "\n", "\n", "np", ".", "savez_compressed", "(", "fileName", ",", "acs", "=", "actions", ",", "obs", "=", "observations", ",", "info", "=", "infos", ")", "# save the file", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.data_generation.fetch_data_generation.goToGoal": [[30, 123], ["object_rel_pos.copy", "episodeObs.append", "actions.append", "observations.append", "infos.append", "env.render", "object_rel_pos.copy", "range", "env.step", "episodeAcs.append", "episodeInfo.append", "episodeObs.append", "env.render", "range", "env.step", "episodeAcs.append", "episodeInfo.append", "episodeObs.append", "env.render", "range", "env.step", "episodeAcs.append", "episodeInfo.append", "episodeObs.append", "env.render", "env.step", "episodeAcs.append", "episodeInfo.append", "episodeObs.append", "numpy.linalg.norm", "len", "numpy.linalg.norm", "len", "numpy.linalg.norm", "len", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "goToGoal", "(", "env", ",", "lastObs", ")", ":", "\n", "\n", "    ", "goal", "=", "lastObs", "[", "'desired_goal'", "]", "\n", "objectPos", "=", "lastObs", "[", "'observation'", "]", "[", "3", ":", "6", "]", "\n", "object_rel_pos", "=", "lastObs", "[", "'observation'", "]", "[", "6", ":", "9", "]", "\n", "episodeAcs", "=", "[", "]", "\n", "episodeObs", "=", "[", "]", "\n", "episodeInfo", "=", "[", "]", "\n", "\n", "object_oriented_goal", "=", "object_rel_pos", ".", "copy", "(", ")", "\n", "object_oriented_goal", "[", "2", "]", "+=", "0.03", "# first make the gripper go slightly above the object", "\n", "\n", "timeStep", "=", "0", "#count the total number of timesteps", "\n", "episodeObs", ".", "append", "(", "lastObs", ")", "\n", "\n", "while", "np", ".", "linalg", ".", "norm", "(", "object_oriented_goal", ")", ">=", "0.005", "and", "timeStep", "<=", "env", ".", "_max_episode_steps", ":", "\n", "        ", "env", ".", "render", "(", ")", "\n", "action", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "object_oriented_goal", "=", "object_rel_pos", ".", "copy", "(", ")", "\n", "object_oriented_goal", "[", "2", "]", "+=", "0.03", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "object_oriented_goal", ")", ")", ":", "\n", "            ", "action", "[", "i", "]", "=", "object_oriented_goal", "[", "i", "]", "*", "6", "\n", "\n", "", "action", "[", "len", "(", "action", ")", "-", "1", "]", "=", "0.05", "#open", "\n", "\n", "obsDataNew", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "timeStep", "+=", "1", "\n", "\n", "episodeAcs", ".", "append", "(", "action", ")", "\n", "episodeInfo", ".", "append", "(", "info", ")", "\n", "episodeObs", ".", "append", "(", "obsDataNew", ")", "\n", "\n", "objectPos", "=", "obsDataNew", "[", "'observation'", "]", "[", "3", ":", "6", "]", "\n", "object_rel_pos", "=", "obsDataNew", "[", "'observation'", "]", "[", "6", ":", "9", "]", "\n", "\n", "", "while", "np", ".", "linalg", ".", "norm", "(", "object_rel_pos", ")", ">=", "0.005", "and", "timeStep", "<=", "env", ".", "_max_episode_steps", ":", "\n", "        ", "env", ".", "render", "(", ")", "\n", "action", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "object_rel_pos", ")", ")", ":", "\n", "            ", "action", "[", "i", "]", "=", "object_rel_pos", "[", "i", "]", "*", "6", "\n", "\n", "", "action", "[", "len", "(", "action", ")", "-", "1", "]", "=", "-", "0.005", "\n", "\n", "obsDataNew", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "timeStep", "+=", "1", "\n", "\n", "episodeAcs", ".", "append", "(", "action", ")", "\n", "episodeInfo", ".", "append", "(", "info", ")", "\n", "episodeObs", ".", "append", "(", "obsDataNew", ")", "\n", "\n", "objectPos", "=", "obsDataNew", "[", "'observation'", "]", "[", "3", ":", "6", "]", "\n", "object_rel_pos", "=", "obsDataNew", "[", "'observation'", "]", "[", "6", ":", "9", "]", "\n", "\n", "\n", "", "while", "np", ".", "linalg", ".", "norm", "(", "goal", "-", "objectPos", ")", ">=", "0.01", "and", "timeStep", "<=", "env", ".", "_max_episode_steps", ":", "\n", "        ", "env", ".", "render", "(", ")", "\n", "action", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "goal", "-", "objectPos", ")", ")", ":", "\n", "            ", "action", "[", "i", "]", "=", "(", "goal", "-", "objectPos", ")", "[", "i", "]", "*", "6", "\n", "\n", "", "action", "[", "len", "(", "action", ")", "-", "1", "]", "=", "-", "0.005", "\n", "\n", "obsDataNew", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "timeStep", "+=", "1", "\n", "\n", "episodeAcs", ".", "append", "(", "action", ")", "\n", "episodeInfo", ".", "append", "(", "info", ")", "\n", "episodeObs", ".", "append", "(", "obsDataNew", ")", "\n", "\n", "objectPos", "=", "obsDataNew", "[", "'observation'", "]", "[", "3", ":", "6", "]", "\n", "object_rel_pos", "=", "obsDataNew", "[", "'observation'", "]", "[", "6", ":", "9", "]", "\n", "\n", "", "while", "True", ":", "#limit the number of timesteps in the episode to a fixed duration", "\n", "        ", "env", ".", "render", "(", ")", "\n", "action", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "action", "[", "len", "(", "action", ")", "-", "1", "]", "=", "-", "0.005", "# keep the gripper closed", "\n", "\n", "obsDataNew", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "timeStep", "+=", "1", "\n", "\n", "episodeAcs", ".", "append", "(", "action", ")", "\n", "episodeInfo", ".", "append", "(", "info", ")", "\n", "episodeObs", ".", "append", "(", "obsDataNew", ")", "\n", "\n", "objectPos", "=", "obsDataNew", "[", "'observation'", "]", "[", "3", ":", "6", "]", "\n", "object_rel_pos", "=", "obsDataNew", "[", "'observation'", "]", "[", "6", ":", "9", "]", "\n", "\n", "if", "timeStep", ">=", "env", ".", "_max_episode_steps", ":", "break", "\n", "\n", "", "actions", ".", "append", "(", "episodeAcs", ")", "\n", "observations", ".", "append", "(", "episodeObs", ")", "\n", "infos", ".", "append", "(", "episodeInfo", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke._run": [[2, 4], ["baselines.common.tests.util.smoketest"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.smoketest"], ["def", "_run", "(", "argstr", ")", ":", "\n", "    ", "smoketest", "(", "'--alg=ddpg --env=Pendulum-v0 --num_timesteps=0 '", "+", "argstr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke.test_popart": [[5, 7], ["test_smoke._run"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke._run"], ["", "def", "test_popart", "(", ")", ":", "\n", "    ", "_run", "(", "'--normalize_returns=True --popart=True'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke.test_noise_normal": [[8, 10], ["test_smoke._run"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke._run"], ["", "def", "test_noise_normal", "(", ")", ":", "\n", "    ", "_run", "(", "'--noise_type=normal_0.1'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke.test_noise_ou": [[11, 13], ["test_smoke._run"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke._run"], ["", "def", "test_noise_ou", "(", ")", ":", "\n", "    ", "_run", "(", "'--noise_type=ou_0.1'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke.test_noise_adaptive": [[14, 16], ["test_smoke._run"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.test_smoke._run"], ["", "def", "test_noise_adaptive", "(", ")", ":", "\n", "    ", "_run", "(", "'--noise_type=adaptive-param_0.2,normal_0.1'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.AdaptiveParamNoiseSpec.__init__": [[5, 11], ["None"], "methods", ["None"], ["class", "OUNoise", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "action_dimension", ",", "scale", "=", "0.1", ",", "mu", "=", "0", ",", "theta", "=", "0.15", ",", "sigma", "=", "0.2", ")", ":", "\n", "        ", "self", ".", "action_dimension", "=", "action_dimension", "\n", "self", ".", "scale", "=", "scale", "\n", "self", ".", "mu", "=", "mu", "\n", "self", ".", "theta", "=", "theta", "\n", "self", ".", "sigma", "=", "sigma", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.AdaptiveParamNoiseSpec.adapt": [[12, 19], ["None"], "methods", ["None"], ["self", ".", "state", "=", "np", ".", "ones", "(", "self", ".", "action_dimension", ")", "*", "self", ".", "mu", "\n", "self", ".", "reset", "(", ")", "\n", "\n", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "state", "=", "np", ".", "ones", "(", "self", ".", "action_dimension", ")", "*", "self", ".", "mu", "\n", "\n", "", "def", "noise", "(", "self", ")", ":", "\n", "        ", "x", "=", "self", ".", "state", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.AdaptiveParamNoiseSpec.get_stats": [[20, 25], ["None"], "methods", ["None"], ["dx", "=", "self", ".", "theta", "*", "(", "self", ".", "mu", "-", "x", ")", "+", "self", ".", "sigma", "*", "np", ".", "random", ".", "randn", "(", "len", "(", "x", ")", ")", "\n", "self", ".", "state", "=", "x", "+", "dx", "\n", "return", "self", ".", "state", "*", "self", ".", "scale", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.AdaptiveParamNoiseSpec.__repr__": [[26, 29], ["fmt.format"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.ActionNoise.reset": [[32, 34], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.NormalActionNoise.__init__": [[37, 40], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.NormalActionNoise.__call__": [[41, 43], ["numpy.random.normal"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.NormalActionNoise.__repr__": [[44, 46], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.OrnsteinUhlenbeckActionNoise.__init__": [[50, 57], ["noise.OrnsteinUhlenbeckActionNoise.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.OrnsteinUhlenbeckActionNoise.__call__": [[58, 62], ["numpy.random.normal", "numpy.sqrt"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.OrnsteinUhlenbeckActionNoise.reset": [[63, 65], ["numpy.zeros_like"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.OrnsteinUhlenbeckActionNoise.__repr__": [[66, 68], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Model.__init__": [[6, 9], ["baselines.common.models.get_network_builder"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.get_network_builder"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "network_builder", "=", "get_network_builder", "(", "network", ")", "(", "**", "network_kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Model.vars": [[10, 13], ["tensorflow.get_collection"], "methods", ["None"], ["", "@", "property", "\n", "def", "vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Model.trainable_vars": [[14, 17], ["tensorflow.get_collection"], "methods", ["None"], ["", "@", "property", "\n", "def", "trainable_vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "self", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Model.perturbable_vars": [[18, 21], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "perturbable_vars", "(", "self", ")", ":", "\n", "        ", "return", "[", "var", "for", "var", "in", "self", ".", "trainable_vars", "if", "'LayerNorm'", "not", "in", "var", ".", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Actor.__init__": [[24, 27], ["models.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nb_actions", ",", "name", "=", "'actor'", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "network", "=", "network", ",", "**", "network_kwargs", ")", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Actor.__call__": [[28, 34], ["tensorflow.variable_scope", "models.Actor.network_builder", "tensorflow.layers.dense", "tensorflow.nn.tanh", "tensorflow.random_uniform_initializer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense"], ["", "def", "__call__", "(", "self", ",", "obs", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "self", ".", "network_builder", "(", "obs", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "self", ".", "nb_actions", ",", "kernel_initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "3e-3", ",", "maxval", "=", "3e-3", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "tanh", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Critic.__init__": [[37, 40], ["models.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "name", "=", "'critic'", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "network", "=", "network", ",", "**", "network_kwargs", ")", "\n", "self", ".", "layer_norm", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Critic.__call__": [[41, 47], ["tensorflow.variable_scope", "tensorflow.concat", "models.Critic.network_builder", "tensorflow.layers.dense", "tensorflow.random_uniform_initializer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense"], ["", "def", "__call__", "(", "self", ",", "obs", ",", "action", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "tf", ".", "concat", "(", "[", "obs", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "# this assumes observation and action can be concatenated", "\n", "x", "=", "self", ".", "network_builder", "(", "x", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "3e-3", ",", "maxval", "=", "3e-3", ")", ",", "name", "=", "'output'", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.models.Critic.output_vars": [[48, 52], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "output_vars", "(", "self", ")", ":", "\n", "        ", "output_vars", "=", "[", "var", "for", "var", "in", "self", ".", "trainable_vars", "if", "'output'", "in", "var", ".", "name", "]", "\n", "return", "output_vars", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.__init__": [[67, 148], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "copy.copy.copy", "copy.copy.copy", "actor", "critic", "ddpg_learner.denormalize", "critic", "ddpg_learner.denormalize", "ddpg_learner.denormalize", "ddpg_learner.DDPG.setup_actor_optimizer", "ddpg_learner.DDPG.setup_critic_optimizer", "ddpg_learner.DDPG.setup_stats", "ddpg_learner.DDPG.setup_target_network_updates", "ddpg_learner.normalize", "ddpg_learner.normalize", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "copy.copy.copy.", "ddpg_learner.DDPG.setup_param_noise", "ddpg_learner.DDPG.setup_popart", "tensorflow.variable_scope", "tensorflow.variable_scope", "baselines.common.mpi_running_mean_std.RunningMeanStd", "tensorflow.variable_scope", "tensorflow.variable_scope", "baselines.common.mpi_running_mean_std.RunningMeanStd", "copy.copy.copy."], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.denormalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.denormalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.denormalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_actor_optimizer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_critic_optimizer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_target_network_updates", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.normalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.normalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_param_noise", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_popart"], ["    ", "def", "__init__", "(", "self", ",", "actor", ",", "critic", ",", "memory", ",", "observation_shape", ",", "action_shape", ",", "param_noise", "=", "None", ",", "action_noise", "=", "None", ",", "\n", "gamma", "=", "0.99", ",", "tau", "=", "0.001", ",", "normalize_returns", "=", "False", ",", "enable_popart", "=", "False", ",", "normalize_observations", "=", "True", ",", "\n", "batch_size", "=", "128", ",", "observation_range", "=", "(", "-", "5.", ",", "5.", ")", ",", "action_range", "=", "(", "-", "1.", ",", "1.", ")", ",", "return_range", "=", "(", "-", "np", ".", "inf", ",", "np", ".", "inf", ")", ",", "\n", "critic_l2_reg", "=", "0.", ",", "actor_lr", "=", "1e-4", ",", "critic_lr", "=", "1e-3", ",", "clip_norm", "=", "None", ",", "reward_scale", "=", "1.", ")", ":", "\n", "# Inputs.", "\n", "        ", "self", ".", "obs0", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", ")", "+", "observation_shape", ",", "name", "=", "'obs0'", ")", "\n", "self", ".", "obs1", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", ")", "+", "observation_shape", ",", "name", "=", "'obs1'", ")", "\n", "self", ".", "terminals1", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'terminals1'", ")", "\n", "self", ".", "rewards", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'rewards'", ")", "\n", "self", ".", "actions", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", ")", "+", "action_shape", ",", "name", "=", "'actions'", ")", "\n", "self", ".", "critic_target", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", "None", ",", "1", ")", ",", "name", "=", "'critic_target'", ")", "\n", "self", ".", "param_noise_stddev", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "(", ")", ",", "name", "=", "'param_noise_stddev'", ")", "\n", "\n", "# Parameters.", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "tau", "=", "tau", "\n", "self", ".", "memory", "=", "memory", "\n", "self", ".", "normalize_observations", "=", "normalize_observations", "\n", "self", ".", "normalize_returns", "=", "normalize_returns", "\n", "self", ".", "action_noise", "=", "action_noise", "\n", "self", ".", "param_noise", "=", "param_noise", "\n", "self", ".", "action_range", "=", "action_range", "\n", "self", ".", "return_range", "=", "return_range", "\n", "self", ".", "observation_range", "=", "observation_range", "\n", "self", ".", "critic", "=", "critic", "\n", "self", ".", "actor", "=", "actor", "\n", "self", ".", "actor_lr", "=", "actor_lr", "\n", "self", ".", "critic_lr", "=", "critic_lr", "\n", "self", ".", "clip_norm", "=", "clip_norm", "\n", "self", ".", "enable_popart", "=", "enable_popart", "\n", "self", ".", "reward_scale", "=", "reward_scale", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "stats_sample", "=", "None", "\n", "self", ".", "critic_l2_reg", "=", "critic_l2_reg", "\n", "\n", "# Observation normalization.", "\n", "if", "self", ".", "normalize_observations", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'obs_rms'", ")", ":", "\n", "                ", "self", ".", "obs_rms", "=", "RunningMeanStd", "(", "shape", "=", "observation_shape", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "obs_rms", "=", "None", "\n", "", "normalized_obs0", "=", "tf", ".", "clip_by_value", "(", "normalize", "(", "self", ".", "obs0", ",", "self", ".", "obs_rms", ")", ",", "\n", "self", ".", "observation_range", "[", "0", "]", ",", "self", ".", "observation_range", "[", "1", "]", ")", "\n", "normalized_obs1", "=", "tf", ".", "clip_by_value", "(", "normalize", "(", "self", ".", "obs1", ",", "self", ".", "obs_rms", ")", ",", "\n", "self", ".", "observation_range", "[", "0", "]", ",", "self", ".", "observation_range", "[", "1", "]", ")", "\n", "\n", "# Return normalization.", "\n", "if", "self", ".", "normalize_returns", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'ret_rms'", ")", ":", "\n", "                ", "self", ".", "ret_rms", "=", "RunningMeanStd", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "ret_rms", "=", "None", "\n", "\n", "# Create target networks.", "\n", "", "target_actor", "=", "copy", "(", "actor", ")", "\n", "target_actor", ".", "name", "=", "'target_actor'", "\n", "self", ".", "target_actor", "=", "target_actor", "\n", "target_critic", "=", "copy", "(", "critic", ")", "\n", "target_critic", ".", "name", "=", "'target_critic'", "\n", "self", ".", "target_critic", "=", "target_critic", "\n", "\n", "# Create networks and core TF parts that are shared across setup parts.", "\n", "self", ".", "actor_tf", "=", "actor", "(", "normalized_obs0", ")", "\n", "self", ".", "normalized_critic_tf", "=", "critic", "(", "normalized_obs0", ",", "self", ".", "actions", ")", "\n", "self", ".", "critic_tf", "=", "denormalize", "(", "tf", ".", "clip_by_value", "(", "self", ".", "normalized_critic_tf", ",", "self", ".", "return_range", "[", "0", "]", ",", "self", ".", "return_range", "[", "1", "]", ")", ",", "self", ".", "ret_rms", ")", "\n", "self", ".", "normalized_critic_with_actor_tf", "=", "critic", "(", "normalized_obs0", ",", "self", ".", "actor_tf", ",", "reuse", "=", "True", ")", "\n", "self", ".", "critic_with_actor_tf", "=", "denormalize", "(", "tf", ".", "clip_by_value", "(", "self", ".", "normalized_critic_with_actor_tf", ",", "self", ".", "return_range", "[", "0", "]", ",", "self", ".", "return_range", "[", "1", "]", ")", ",", "self", ".", "ret_rms", ")", "\n", "Q_obs1", "=", "denormalize", "(", "target_critic", "(", "normalized_obs1", ",", "target_actor", "(", "normalized_obs1", ")", ")", ",", "self", ".", "ret_rms", ")", "\n", "self", ".", "target_Q", "=", "self", ".", "rewards", "+", "(", "1.", "-", "self", ".", "terminals1", ")", "*", "gamma", "*", "Q_obs1", "\n", "\n", "# Set up parts.", "\n", "if", "self", ".", "param_noise", "is", "not", "None", ":", "\n", "            ", "self", ".", "setup_param_noise", "(", "normalized_obs0", ")", "\n", "", "self", ".", "setup_actor_optimizer", "(", ")", "\n", "self", ".", "setup_critic_optimizer", "(", ")", "\n", "if", "self", ".", "normalize_returns", "and", "self", ".", "enable_popart", ":", "\n", "            ", "self", ".", "setup_popart", "(", ")", "\n", "", "self", ".", "setup_stats", "(", ")", "\n", "self", ".", "setup_target_network_updates", "(", ")", "\n", "\n", "self", ".", "initial_state", "=", "None", "# recurrent architectures not supported yet", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_target_network_updates": [[149, 154], ["ddpg_learner.get_target_updates", "ddpg_learner.get_target_updates"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.get_target_updates", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.get_target_updates"], ["", "def", "setup_target_network_updates", "(", "self", ")", ":", "\n", "        ", "actor_init_updates", ",", "actor_soft_updates", "=", "get_target_updates", "(", "self", ".", "actor", ".", "vars", ",", "self", ".", "target_actor", ".", "vars", ",", "self", ".", "tau", ")", "\n", "critic_init_updates", ",", "critic_soft_updates", "=", "get_target_updates", "(", "self", ".", "critic", ".", "vars", ",", "self", ".", "target_critic", ".", "vars", ",", "self", ".", "tau", ")", "\n", "self", ".", "target_init_updates", "=", "[", "actor_init_updates", ",", "critic_init_updates", "]", "\n", "self", ".", "target_soft_updates", "=", "[", "actor_soft_updates", ",", "critic_soft_updates", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_param_noise": [[155, 171], ["copy.copy.copy", "copy.copy.copy.", "baselines.logger.info", "ddpg_learner.get_perturbed_actor_updates", "copy.copy.copy", "copy.copy.copy.", "ddpg_learner.get_perturbed_actor_updates", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.get_perturbed_actor_updates", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.get_perturbed_actor_updates"], ["", "def", "setup_param_noise", "(", "self", ",", "normalized_obs0", ")", ":", "\n", "        ", "assert", "self", ".", "param_noise", "is", "not", "None", "\n", "\n", "# Configure perturbed actor.", "\n", "param_noise_actor", "=", "copy", "(", "self", ".", "actor", ")", "\n", "param_noise_actor", ".", "name", "=", "'param_noise_actor'", "\n", "self", ".", "perturbed_actor_tf", "=", "param_noise_actor", "(", "normalized_obs0", ")", "\n", "logger", ".", "info", "(", "'setting up param noise'", ")", "\n", "self", ".", "perturb_policy_ops", "=", "get_perturbed_actor_updates", "(", "self", ".", "actor", ",", "param_noise_actor", ",", "self", ".", "param_noise_stddev", ")", "\n", "\n", "# Configure separate copy for stddev adoption.", "\n", "adaptive_param_noise_actor", "=", "copy", "(", "self", ".", "actor", ")", "\n", "adaptive_param_noise_actor", ".", "name", "=", "'adaptive_param_noise_actor'", "\n", "adaptive_actor_tf", "=", "adaptive_param_noise_actor", "(", "normalized_obs0", ")", "\n", "self", ".", "perturb_adaptive_policy_ops", "=", "get_perturbed_actor_updates", "(", "self", ".", "actor", ",", "adaptive_param_noise_actor", ",", "self", ".", "param_noise_stddev", ")", "\n", "self", ".", "adaptive_policy_distance", "=", "tf", ".", "sqrt", "(", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "actor_tf", "-", "adaptive_actor_tf", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_actor_optimizer": [[172, 182], ["baselines.logger.info", "sum", "baselines.logger.info", "baselines.logger.info", "baselines.flatgrad", "baselines.common.mpi_adam.MpiAdam", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "var.get_shape().as_list", "functools.reduce", "var.get_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "setup_actor_optimizer", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'setting up actor optimizer'", ")", "\n", "self", ".", "actor_loss", "=", "-", "tf", ".", "reduce_mean", "(", "self", ".", "critic_with_actor_tf", ")", "\n", "actor_shapes", "=", "[", "var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "for", "var", "in", "self", ".", "actor", ".", "trainable_vars", "]", "\n", "actor_nb_params", "=", "sum", "(", "[", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "*", "y", ",", "shape", ")", "for", "shape", "in", "actor_shapes", "]", ")", "\n", "logger", ".", "info", "(", "'  actor shapes: {}'", ".", "format", "(", "actor_shapes", ")", ")", "\n", "logger", ".", "info", "(", "'  actor params: {}'", ".", "format", "(", "actor_nb_params", ")", ")", "\n", "self", ".", "actor_grads", "=", "U", ".", "flatgrad", "(", "self", ".", "actor_loss", ",", "self", ".", "actor", ".", "trainable_vars", ",", "clip_norm", "=", "self", ".", "clip_norm", ")", "\n", "self", ".", "actor_optimizer", "=", "MpiAdam", "(", "var_list", "=", "self", ".", "actor", ".", "trainable_vars", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-08", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_critic_optimizer": [[183, 204], ["baselines.logger.info", "tensorflow.clip_by_value", "tensorflow.clip_by_value", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "sum", "baselines.logger.info", "baselines.logger.info", "baselines.flatgrad", "baselines.common.mpi_adam.MpiAdam", "ddpg_learner.normalize", "tensorflow.square", "tensorflow.square", "baselines.logger.info", "tensorflow.layers.apply_regularization", "tensorflow.layers.apply_regularization", "var.get_shape().as_list", "baselines.logger.info", "tensorflow.layers.l2_regularizer", "tensorflow.layers.l2_regularizer", "functools.reduce", "var.get_shape", "var.name.endswith"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.normalize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "setup_critic_optimizer", "(", "self", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'setting up critic optimizer'", ")", "\n", "normalized_critic_target_tf", "=", "tf", ".", "clip_by_value", "(", "normalize", "(", "self", ".", "critic_target", ",", "self", ".", "ret_rms", ")", ",", "self", ".", "return_range", "[", "0", "]", ",", "self", ".", "return_range", "[", "1", "]", ")", "\n", "self", ".", "critic_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "self", ".", "normalized_critic_tf", "-", "normalized_critic_target_tf", ")", ")", "\n", "if", "self", ".", "critic_l2_reg", ">", "0.", ":", "\n", "            ", "critic_reg_vars", "=", "[", "var", "for", "var", "in", "self", ".", "critic", ".", "trainable_vars", "if", "var", ".", "name", ".", "endswith", "(", "'/w:0'", ")", "and", "'output'", "not", "in", "var", ".", "name", "]", "\n", "for", "var", "in", "critic_reg_vars", ":", "\n", "                ", "logger", ".", "info", "(", "'  regularizing: {}'", ".", "format", "(", "var", ".", "name", ")", ")", "\n", "", "logger", ".", "info", "(", "'  applying l2 regularization with {}'", ".", "format", "(", "self", ".", "critic_l2_reg", ")", ")", "\n", "critic_reg", "=", "tc", ".", "layers", ".", "apply_regularization", "(", "\n", "tc", ".", "layers", ".", "l2_regularizer", "(", "self", ".", "critic_l2_reg", ")", ",", "\n", "weights_list", "=", "critic_reg_vars", "\n", ")", "\n", "self", ".", "critic_loss", "+=", "critic_reg", "\n", "", "critic_shapes", "=", "[", "var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "for", "var", "in", "self", ".", "critic", ".", "trainable_vars", "]", "\n", "critic_nb_params", "=", "sum", "(", "[", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "*", "y", ",", "shape", ")", "for", "shape", "in", "critic_shapes", "]", ")", "\n", "logger", ".", "info", "(", "'  critic shapes: {}'", ".", "format", "(", "critic_shapes", ")", ")", "\n", "logger", ".", "info", "(", "'  critic params: {}'", ".", "format", "(", "critic_nb_params", ")", ")", "\n", "self", ".", "critic_grads", "=", "U", ".", "flatgrad", "(", "self", ".", "critic_loss", ",", "self", ".", "critic", ".", "trainable_vars", ",", "clip_norm", "=", "self", ".", "clip_norm", ")", "\n", "self", ".", "critic_optimizer", "=", "MpiAdam", "(", "var_list", "=", "self", ".", "critic", ".", "trainable_vars", ",", "\n", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-08", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_popart": [[205, 222], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "len", "M.assign", "b.assign", "M.get_shape", "b.get_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "setup_popart", "(", "self", ")", ":", "\n", "# See https://arxiv.org/pdf/1602.07714.pdf for details.", "\n", "        ", "self", ".", "old_std", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "1", "]", ",", "name", "=", "'old_std'", ")", "\n", "new_std", "=", "self", ".", "ret_rms", ".", "std", "\n", "self", ".", "old_mean", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "[", "1", "]", ",", "name", "=", "'old_mean'", ")", "\n", "new_mean", "=", "self", ".", "ret_rms", ".", "mean", "\n", "\n", "self", ".", "renormalize_Q_outputs_op", "=", "[", "]", "\n", "for", "vs", "in", "[", "self", ".", "critic", ".", "output_vars", ",", "self", ".", "target_critic", ".", "output_vars", "]", ":", "\n", "            ", "assert", "len", "(", "vs", ")", "==", "2", "\n", "M", ",", "b", "=", "vs", "\n", "assert", "'kernel'", "in", "M", ".", "name", "\n", "assert", "'bias'", "in", "b", ".", "name", "\n", "assert", "M", ".", "get_shape", "(", ")", "[", "-", "1", "]", "==", "1", "\n", "assert", "b", ".", "get_shape", "(", ")", "[", "-", "1", "]", "==", "1", "\n", "self", ".", "renormalize_Q_outputs_op", "+=", "[", "M", ".", "assign", "(", "M", "*", "self", ".", "old_std", "/", "new_std", ")", "]", "\n", "self", ".", "renormalize_Q_outputs_op", "+=", "[", "b", ".", "assign", "(", "(", "b", "*", "self", ".", "old_std", "+", "self", ".", "old_mean", "-", "new_mean", ")", "/", "new_std", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.setup_stats": [[223, 258], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "ddpg_learner.reduce_std", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "ddpg_learner.reduce_std", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "ddpg_learner.reduce_std", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "ddpg_learner.reduce_std"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.reduce_std", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.reduce_std", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.reduce_std", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.reduce_std"], ["", "", "def", "setup_stats", "(", "self", ")", ":", "\n", "        ", "ops", "=", "[", "]", "\n", "names", "=", "[", "]", "\n", "\n", "if", "self", ".", "normalize_returns", ":", "\n", "            ", "ops", "+=", "[", "self", ".", "ret_rms", ".", "mean", ",", "self", ".", "ret_rms", ".", "std", "]", "\n", "names", "+=", "[", "'ret_rms_mean'", ",", "'ret_rms_std'", "]", "\n", "\n", "", "if", "self", ".", "normalize_observations", ":", "\n", "            ", "ops", "+=", "[", "tf", ".", "reduce_mean", "(", "self", ".", "obs_rms", ".", "mean", ")", ",", "tf", ".", "reduce_mean", "(", "self", ".", "obs_rms", ".", "std", ")", "]", "\n", "names", "+=", "[", "'obs_rms_mean'", ",", "'obs_rms_std'", "]", "\n", "\n", "", "ops", "+=", "[", "tf", ".", "reduce_mean", "(", "self", ".", "critic_tf", ")", "]", "\n", "names", "+=", "[", "'reference_Q_mean'", "]", "\n", "ops", "+=", "[", "reduce_std", "(", "self", ".", "critic_tf", ")", "]", "\n", "names", "+=", "[", "'reference_Q_std'", "]", "\n", "\n", "ops", "+=", "[", "tf", ".", "reduce_mean", "(", "self", ".", "critic_with_actor_tf", ")", "]", "\n", "names", "+=", "[", "'reference_actor_Q_mean'", "]", "\n", "ops", "+=", "[", "reduce_std", "(", "self", ".", "critic_with_actor_tf", ")", "]", "\n", "names", "+=", "[", "'reference_actor_Q_std'", "]", "\n", "\n", "ops", "+=", "[", "tf", ".", "reduce_mean", "(", "self", ".", "actor_tf", ")", "]", "\n", "names", "+=", "[", "'reference_action_mean'", "]", "\n", "ops", "+=", "[", "reduce_std", "(", "self", ".", "actor_tf", ")", "]", "\n", "names", "+=", "[", "'reference_action_std'", "]", "\n", "\n", "if", "self", ".", "param_noise", ":", "\n", "            ", "ops", "+=", "[", "tf", ".", "reduce_mean", "(", "self", ".", "perturbed_actor_tf", ")", "]", "\n", "names", "+=", "[", "'reference_perturbed_action_mean'", "]", "\n", "ops", "+=", "[", "reduce_std", "(", "self", ".", "perturbed_actor_tf", ")", "]", "\n", "names", "+=", "[", "'reference_perturbed_action_std'", "]", "\n", "\n", "", "self", ".", "stats_ops", "=", "ops", "\n", "self", ".", "stats_names", "=", "names", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.step": [[259, 279], ["numpy.clip", "baselines.adjust_shape", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.action_noise"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.adjust_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "step", "(", "self", ",", "obs", ",", "apply_noise", "=", "True", ",", "compute_Q", "=", "True", ")", ":", "\n", "        ", "if", "self", ".", "param_noise", "is", "not", "None", "and", "apply_noise", ":", "\n", "            ", "actor_tf", "=", "self", ".", "perturbed_actor_tf", "\n", "", "else", ":", "\n", "            ", "actor_tf", "=", "self", ".", "actor_tf", "\n", "", "feed_dict", "=", "{", "self", ".", "obs0", ":", "U", ".", "adjust_shape", "(", "self", ".", "obs0", ",", "[", "obs", "]", ")", "}", "\n", "if", "compute_Q", ":", "\n", "            ", "action", ",", "q", "=", "self", ".", "sess", ".", "run", "(", "[", "actor_tf", ",", "self", ".", "critic_with_actor_tf", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "", "else", ":", "\n", "            ", "action", "=", "self", ".", "sess", ".", "run", "(", "actor_tf", ",", "feed_dict", "=", "feed_dict", ")", "\n", "q", "=", "None", "\n", "\n", "", "if", "self", ".", "action_noise", "is", "not", "None", "and", "apply_noise", ":", "\n", "            ", "noise", "=", "self", ".", "action_noise", "(", ")", "\n", "assert", "noise", ".", "shape", "==", "action", "[", "0", "]", ".", "shape", "\n", "action", "+=", "noise", "\n", "", "action", "=", "np", ".", "clip", "(", "action", ",", "self", ".", "action_range", "[", "0", "]", ",", "self", ".", "action_range", "[", "1", "]", ")", "\n", "\n", "\n", "return", "action", ",", "q", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.store_transition": [[280, 288], ["range", "ddpg_learner.DDPG.memory.append", "ddpg_learner.DDPG.obs_rms.update", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "store_transition", "(", "self", ",", "obs0", ",", "action", ",", "reward", ",", "obs1", ",", "terminal1", ")", ":", "\n", "        ", "reward", "*=", "self", ".", "reward_scale", "\n", "\n", "B", "=", "obs0", ".", "shape", "[", "0", "]", "\n", "for", "b", "in", "range", "(", "B", ")", ":", "\n", "            ", "self", ".", "memory", ".", "append", "(", "obs0", "[", "b", "]", ",", "action", "[", "b", "]", ",", "reward", "[", "b", "]", ",", "obs1", "[", "b", "]", ",", "terminal1", "[", "b", "]", ")", "\n", "if", "self", ".", "normalize_observations", ":", "\n", "                ", "self", ".", "obs_rms", ".", "update", "(", "np", ".", "array", "(", "[", "obs0", "[", "b", "]", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.train": [[289, 332], ["ddpg_learner.DDPG.memory.sample", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.actor_optimizer.update", "ddpg_learner.DDPG.critic_optimizer.update", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.ret_rms.update", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.flatten", "batch[].astype", "numpy.array", "numpy.array", "batch[].astype"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "", "", "def", "train", "(", "self", ")", ":", "\n", "# Get a batch.", "\n", "        ", "batch", "=", "self", ".", "memory", ".", "sample", "(", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "\n", "if", "self", ".", "normalize_returns", "and", "self", ".", "enable_popart", ":", "\n", "            ", "old_mean", ",", "old_std", ",", "target_Q", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "ret_rms", ".", "mean", ",", "self", ".", "ret_rms", ".", "std", ",", "self", ".", "target_Q", "]", ",", "feed_dict", "=", "{", "\n", "self", ".", "obs1", ":", "batch", "[", "'obs1'", "]", ",", "\n", "self", ".", "rewards", ":", "batch", "[", "'rewards'", "]", ",", "\n", "self", ".", "terminals1", ":", "batch", "[", "'terminals1'", "]", ".", "astype", "(", "'float32'", ")", ",", "\n", "}", ")", "\n", "self", ".", "ret_rms", ".", "update", "(", "target_Q", ".", "flatten", "(", ")", ")", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "renormalize_Q_outputs_op", ",", "feed_dict", "=", "{", "\n", "self", ".", "old_std", ":", "np", ".", "array", "(", "[", "old_std", "]", ")", ",", "\n", "self", ".", "old_mean", ":", "np", ".", "array", "(", "[", "old_mean", "]", ")", ",", "\n", "}", ")", "\n", "\n", "# Run sanity check. Disabled by default since it slows down things considerably.", "\n", "# print('running sanity check')", "\n", "# target_Q_new, new_mean, new_std = self.sess.run([self.target_Q, self.ret_rms.mean, self.ret_rms.std], feed_dict={", "\n", "#     self.obs1: batch['obs1'],", "\n", "#     self.rewards: batch['rewards'],", "\n", "#     self.terminals1: batch['terminals1'].astype('float32'),", "\n", "# })", "\n", "# print(target_Q_new, target_Q, new_mean, new_std)", "\n", "# assert (np.abs(target_Q - target_Q_new) < 1e-3).all()", "\n", "", "else", ":", "\n", "            ", "target_Q", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "target_Q", ",", "feed_dict", "=", "{", "\n", "self", ".", "obs1", ":", "batch", "[", "'obs1'", "]", ",", "\n", "self", ".", "rewards", ":", "batch", "[", "'rewards'", "]", ",", "\n", "self", ".", "terminals1", ":", "batch", "[", "'terminals1'", "]", ".", "astype", "(", "'float32'", ")", ",", "\n", "}", ")", "\n", "\n", "# Get all gradients and perform a synced update.", "\n", "", "ops", "=", "[", "self", ".", "actor_grads", ",", "self", ".", "actor_loss", ",", "self", ".", "critic_grads", ",", "self", ".", "critic_loss", "]", "\n", "actor_grads", ",", "actor_loss", ",", "critic_grads", ",", "critic_loss", "=", "self", ".", "sess", ".", "run", "(", "ops", ",", "feed_dict", "=", "{", "\n", "self", ".", "obs0", ":", "batch", "[", "'obs0'", "]", ",", "\n", "self", ".", "actions", ":", "batch", "[", "'actions'", "]", ",", "\n", "self", ".", "critic_target", ":", "target_Q", ",", "\n", "}", ")", "\n", "self", ".", "actor_optimizer", ".", "update", "(", "actor_grads", ",", "stepsize", "=", "self", ".", "actor_lr", ")", "\n", "self", ".", "critic_optimizer", ".", "update", "(", "critic_grads", ",", "stepsize", "=", "self", ".", "critic_lr", ")", "\n", "\n", "return", "critic_loss", ",", "actor_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.initialize": [[333, 339], ["ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.actor_optimizer.sync", "ddpg_learner.DDPG.critic_optimizer.sync", "ddpg_learner.DDPG.sess.run", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "initialize", "(", "self", ",", "sess", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "\n", "self", ".", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "self", ".", "actor_optimizer", ".", "sync", "(", ")", "\n", "self", ".", "critic_optimizer", ".", "sync", "(", ")", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "target_init_updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.update_target_net": [[340, 342], ["ddpg_learner.DDPG.sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "update_target_net", "(", "self", ")", ":", "\n", "        ", "self", ".", "sess", ".", "run", "(", "self", ".", "target_soft_updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.get_stats": [[343, 361], ["ddpg_learner.DDPG.sess.run", "dict", "ddpg_learner.DDPG.memory.sample", "len", "len", "zip", "ddpg_learner.DDPG.param_noise.get_stats"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.get_stats"], ["", "def", "get_stats", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "stats_sample", "is", "None", ":", "\n", "# Get a sample and keep that fixed for all further computations.", "\n", "# This allows us to estimate the change in value for the same set of inputs.", "\n", "            ", "self", ".", "stats_sample", "=", "self", ".", "memory", ".", "sample", "(", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "", "values", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "stats_ops", ",", "feed_dict", "=", "{", "\n", "self", ".", "obs0", ":", "self", ".", "stats_sample", "[", "'obs0'", "]", ",", "\n", "self", ".", "actions", ":", "self", ".", "stats_sample", "[", "'actions'", "]", ",", "\n", "}", ")", "\n", "\n", "names", "=", "self", ".", "stats_names", "[", ":", "]", "\n", "assert", "len", "(", "names", ")", "==", "len", "(", "values", ")", "\n", "stats", "=", "dict", "(", "zip", "(", "names", ",", "values", ")", ")", "\n", "\n", "if", "self", ".", "param_noise", "is", "not", "None", ":", "\n", "            ", "stats", "=", "{", "**", "stats", ",", "**", "self", ".", "param_noise", ".", "get_stats", "(", ")", "}", "\n", "\n", "", "return", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.adapt_param_noise": [[362, 388], ["ddpg_learner.DDPG.memory.sample", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.sess.run", "ddpg_learner.DDPG.param_noise.adapt", "MPI.COMM_WORLD.allreduce", "MPI.COMM_WORLD.Get_size"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.noise.AdaptiveParamNoiseSpec.adapt"], ["", "def", "adapt_param_noise", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "mpi4py", "import", "MPI", "\n", "", "except", "ImportError", ":", "\n", "            ", "MPI", "=", "None", "\n", "\n", "", "if", "self", ".", "param_noise", "is", "None", ":", "\n", "            ", "return", "0.", "\n", "\n", "# Perturb a separate copy of the policy to adjust the scale for the next \"real\" perturbation.", "\n", "", "batch", "=", "self", ".", "memory", ".", "sample", "(", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "perturb_adaptive_policy_ops", ",", "feed_dict", "=", "{", "\n", "self", ".", "param_noise_stddev", ":", "self", ".", "param_noise", ".", "current_stddev", ",", "\n", "}", ")", "\n", "distance", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "adaptive_policy_distance", ",", "feed_dict", "=", "{", "\n", "self", ".", "obs0", ":", "batch", "[", "'obs0'", "]", ",", "\n", "self", ".", "param_noise_stddev", ":", "self", ".", "param_noise", ".", "current_stddev", ",", "\n", "}", ")", "\n", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "            ", "mean_distance", "=", "MPI", ".", "COMM_WORLD", ".", "allreduce", "(", "distance", ",", "op", "=", "MPI", ".", "SUM", ")", "/", "MPI", ".", "COMM_WORLD", ".", "Get_size", "(", ")", "\n", "", "else", ":", "\n", "            ", "mean_distance", "=", "distance", "\n", "\n", "", "self", ".", "param_noise", ".", "adapt", "(", "mean_distance", ")", "\n", "return", "mean_distance", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.reset": [[389, 396], ["ddpg_learner.DDPG.action_noise.reset", "ddpg_learner.DDPG.sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "reset", "(", "self", ")", ":", "\n", "# Reset internal state after an episode is complete.", "\n", "        ", "if", "self", ".", "action_noise", "is", "not", "None", ":", "\n", "            ", "self", ".", "action_noise", ".", "reset", "(", ")", "\n", "", "if", "self", ".", "param_noise", "is", "not", "None", ":", "\n", "            ", "self", ".", "sess", ".", "run", "(", "self", ".", "perturb_policy_ops", ",", "feed_dict", "=", "{", "\n", "self", ".", "param_noise_stddev", ":", "self", ".", "param_noise", ".", "current_stddev", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.normalize": [[17, 21], ["None"], "function", ["None"], ["", "def", "normalize", "(", "x", ",", "stats", ")", ":", "\n", "    ", "if", "stats", "is", "None", ":", "\n", "        ", "return", "x", "\n", "", "return", "(", "x", "-", "stats", ".", "mean", ")", "/", "(", "stats", ".", "std", "+", "1e-8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.denormalize": [[23, 27], ["None"], "function", ["None"], ["", "def", "denormalize", "(", "x", ",", "stats", ")", ":", "\n", "    ", "if", "stats", "is", "None", ":", "\n", "        ", "return", "x", "\n", "", "return", "x", "*", "stats", ".", "std", "+", "stats", ".", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.reduce_std": [[28, 30], ["tensorflow.sqrt", "ddpg_learner.reduce_var"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.reduce_var"], ["", "def", "reduce_std", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "return", "tf", ".", "sqrt", "(", "reduce_var", "(", "x", ",", "axis", "=", "axis", ",", "keepdims", "=", "keepdims", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.reduce_var": [[31, 35], ["tensorflow.reduce_mean", "tensorflow.square", "tensorflow.reduce_mean"], "function", ["None"], ["", "def", "reduce_var", "(", "x", ",", "axis", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "m", "=", "tf", ".", "reduce_mean", "(", "x", ",", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", "\n", "devs_squared", "=", "tf", ".", "square", "(", "x", "-", "m", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "devs_squared", ",", "axis", "=", "axis", ",", "keepdims", "=", "keepdims", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.get_target_updates": [[36, 48], ["baselines.logger.info", "zip", "len", "len", "baselines.logger.info", "init_updates.append", "soft_updates.append", "len", "len", "len", "len", "tensorflow.group", "tensorflow.group", "tensorflow.assign", "tensorflow.assign"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "get_target_updates", "(", "vars", ",", "target_vars", ",", "tau", ")", ":", "\n", "    ", "logger", ".", "info", "(", "'setting up target updates ...'", ")", "\n", "soft_updates", "=", "[", "]", "\n", "init_updates", "=", "[", "]", "\n", "assert", "len", "(", "vars", ")", "==", "len", "(", "target_vars", ")", "\n", "for", "var", ",", "target_var", "in", "zip", "(", "vars", ",", "target_vars", ")", ":", "\n", "        ", "logger", ".", "info", "(", "'  {} <- {}'", ".", "format", "(", "target_var", ".", "name", ",", "var", ".", "name", ")", ")", "\n", "init_updates", ".", "append", "(", "tf", ".", "assign", "(", "target_var", ",", "var", ")", ")", "\n", "soft_updates", ".", "append", "(", "tf", ".", "assign", "(", "target_var", ",", "(", "1.", "-", "tau", ")", "*", "target_var", "+", "tau", "*", "var", ")", ")", "\n", "", "assert", "len", "(", "init_updates", ")", "==", "len", "(", "vars", ")", "\n", "assert", "len", "(", "soft_updates", ")", "==", "len", "(", "vars", ")", "\n", "return", "tf", ".", "group", "(", "*", "init_updates", ")", ",", "tf", ".", "group", "(", "*", "soft_updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.get_perturbed_actor_updates": [[50, 64], ["zip", "tensorflow.group", "len", "len", "len", "len", "len", "len", "baselines.logger.info", "updates.append", "baselines.logger.info", "updates.append", "tensorflow.assign", "tensorflow.assign", "tensorflow.random_normal", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape"], ["", "def", "get_perturbed_actor_updates", "(", "actor", ",", "perturbed_actor", ",", "param_noise_stddev", ")", ":", "\n", "    ", "assert", "len", "(", "actor", ".", "vars", ")", "==", "len", "(", "perturbed_actor", ".", "vars", ")", "\n", "assert", "len", "(", "actor", ".", "perturbable_vars", ")", "==", "len", "(", "perturbed_actor", ".", "perturbable_vars", ")", "\n", "\n", "updates", "=", "[", "]", "\n", "for", "var", ",", "perturbed_var", "in", "zip", "(", "actor", ".", "vars", ",", "perturbed_actor", ".", "vars", ")", ":", "\n", "        ", "if", "var", "in", "actor", ".", "perturbable_vars", ":", "\n", "            ", "logger", ".", "info", "(", "'  {} <- {} + noise'", ".", "format", "(", "perturbed_var", ".", "name", ",", "var", ".", "name", ")", ")", "\n", "updates", ".", "append", "(", "tf", ".", "assign", "(", "perturbed_var", ",", "var", "+", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "var", ")", ",", "mean", "=", "0.", ",", "stddev", "=", "param_noise_stddev", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "'  {} <- {}'", ".", "format", "(", "perturbed_var", ".", "name", ",", "var", ".", "name", ")", ")", "\n", "updates", ".", "append", "(", "tf", ".", "assign", "(", "perturbed_var", ",", "var", ")", ")", "\n", "", "", "assert", "len", "(", "updates", ")", "==", "len", "(", "actor", ".", "vars", ")", "\n", "return", "tf", ".", "group", "(", "*", "updates", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg.learn": [[21, 276], ["baselines.common.set_global_seeds", "baselines.ddpg.memory.Memory", "baselines.ddpg.models.Critic", "baselines.ddpg.models.Actor", "baselines.logger.info", "baselines.ddpg.ddpg_learner.DDPG", "baselines.logger.info", "baselines.logger.info", "collections.deque", "collections.deque", "baselines.get_session", "baselines.ddpg.ddpg_learner.DDPG.initialize", "U.get_session.graph.finalize", "baselines.ddpg.ddpg_learner.DDPG.reset", "env.reset", "numpy.zeros", "numpy.zeros", "time.time", "range", "MPI.COMM_WORLD.Get_rank", "noise_type.split", "str", "eval_env.reset", "range", "baselines.ddpg.ddpg_learner.DDPG.get_stats", "agent.get_stats.copy", "numpy.mean", "numpy.std", "numpy.mean", "numpy.std", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "numpy.array", "sorted", "baselines.logger.info", "baselines.logger.get_dir", "int", "int", "current_noise_type.strip.strip", "baselines.ddpg.ddpg_learner.DDPG.__dict__.items", "range", "range", "MPI.COMM_WORLD.Get_size", "time.time", "float", "float", "numpy.mean", "len", "isinstance", "MPI.COMM_WORLD.allreduce", "stats.copy.keys", "baselines.logger.record_tabular", "baselines.logger.dump_tabular", "hasattr", "numpy.abs", "baselines.ddpg.ddpg_learner.DDPG.reset", "baselines.ddpg.ddpg_learner.DDPG.step", "env.step", "epoch_actions.append", "epoch_qs.append", "baselines.ddpg.ddpg_learner.DDPG.store_transition", "range", "baselines.ddpg.ddpg_learner.DDPG.train", "epoch_critic_losses.append", "epoch_actor_losses.append", "baselines.ddpg.ddpg_learner.DDPG.update_target_net", "numpy.zeros", "range", "numpy.isscalar", "zip", "hasattr", "current_noise_type.strip.split", "baselines.ddpg.noise.AdaptiveParamNoiseSpec", "env.render", "env.render", "len", "baselines.ddpg.ddpg_learner.DDPG.adapt_param_noise", "epoch_adaptive_distances.append", "baselines.ddpg.ddpg_learner.DDPG.step", "eval_env.step", "eval_qs.append", "range", "ValueError", "numpy.array().flatten", "stats.copy.values", "stats.copy.keys", "open", "pickle.dump", "open", "pickle.dump", "current_noise_type.strip.split", "baselines.ddpg.noise.NormalActionNoise", "epoch_episode_rewards.append", "collections.deque.append", "epoch_episode_steps.append", "eval_env.render", "len", "os.path.join", "env.get_state", "os.path.join", "eval_env.get_state", "float", "float", "current_noise_type.strip.split", "baselines.ddpg.noise.OrnsteinUhlenbeckActionNoise", "RuntimeError", "baselines.ddpg.ddpg_learner.DDPG.reset", "eval_episode_rewards.append", "collections.deque.append", "numpy.array", "numpy.zeros", "float", "numpy.ones", "numpy.zeros", "float", "numpy.ones"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.get_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.strip", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.store_transition", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.update_target_net", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.ddpg_learner.DDPG.adapt_param_noise", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["\n", "class", "DDPG", "(", "object", ")", ":", "\n", "    ", "@", "store_args", "\n", "def", "__init__", "(", "self", ",", "input_dims", ",", "buffer_size", ",", "hidden", ",", "layers", ",", "network_class", ",", "polyak", ",", "batch_size", ",", "\n", "Q_lr", ",", "pi_lr", ",", "norm_eps", ",", "norm_clip", ",", "max_u", ",", "action_l2", ",", "clip_obs", ",", "scope", ",", "T", ",", "\n", "rollout_batch_size", ",", "subtract_goals", ",", "relative_goals", ",", "clip_pos_returns", ",", "clip_return", ",", "\n", "bc_loss", ",", "q_filter", ",", "num_demo", ",", "demo_batch_size", ",", "prm_loss_weight", ",", "aux_loss_weight", ",", "\n", "sample_transitions", ",", "gamma", ",", "reuse", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Implementation of DDPG that is used in combination with Hindsight Experience Replay (HER).\n            Added functionality to use demonstrations for training to Overcome exploration problem.\n\n        Args:\n            input_dims (dict of ints): dimensions for the observation (o), the goal (g), and the\n                actions (u)\n            buffer_size (int): number of transitions that are stored in the replay buffer\n            hidden (int): number of units in the hidden layers\n            layers (int): number of hidden layers\n            network_class (str): the network class that should be used (e.g. 'baselines.her.ActorCritic')\n            polyak (float): coefficient for Polyak-averaging of the target network\n            batch_size (int): batch size for training\n            Q_lr (float): learning rate for the Q (critic) network\n            pi_lr (float): learning rate for the pi (actor) network\n            norm_eps (float): a small value used in the normalizer to avoid numerical instabilities\n            norm_clip (float): normalized inputs are clipped to be in [-norm_clip, norm_clip]\n            max_u (float): maximum action magnitude, i.e. actions are in [-max_u, max_u]\n            action_l2 (float): coefficient for L2 penalty on the actions\n            clip_obs (float): clip observations before normalization to be in [-clip_obs, clip_obs]\n            scope (str): the scope used for the TensorFlow graph\n            T (int): the time horizon for rollouts\n            rollout_batch_size (int): number of parallel rollouts per DDPG agent\n            subtract_goals (function): function that subtracts goals from each other\n            relative_goals (boolean): whether or not relative goals should be fed into the network\n            clip_pos_returns (boolean): whether or not positive returns should be clipped\n            clip_return (float): clip returns to be in [-clip_return, clip_return]\n            sample_transitions (function) function that samples from the replay buffer\n            gamma (float): gamma used for Q learning updates\n            reuse (boolean): whether or not the networks should be reused\n            bc_loss: whether or not the behavior cloning loss should be used as an auxilliary loss\n            q_filter: whether or not a filter on the q value update should be used when training with demonstartions\n            num_demo: Number of episodes in to be used in the demonstration buffer\n            demo_batch_size: number of samples to be used from the demonstrations buffer, per mpi thread\n            prm_loss_weight: Weight corresponding to the primary loss\n            aux_loss_weight: Weight corresponding to the auxilliary loss also called the cloning loss\n        \"\"\"", "\n", "if", "self", ".", "clip_return", "is", "None", ":", "\n", "            ", "self", ".", "clip_return", "=", "np", ".", "inf", "\n", "\n", "", "self", ".", "create_actor_critic", "=", "import_function", "(", "self", ".", "network_class", ")", "\n", "\n", "input_shapes", "=", "dims_to_shapes", "(", "self", ".", "input_dims", ")", "\n", "self", ".", "dimo", "=", "self", ".", "input_dims", "[", "'o'", "]", "\n", "self", ".", "dimg", "=", "self", ".", "input_dims", "[", "'g'", "]", "\n", "self", ".", "dimu", "=", "self", ".", "input_dims", "[", "'u'", "]", "\n", "\n", "# Prepare staging area for feeding data to the model.", "\n", "stage_shapes", "=", "OrderedDict", "(", ")", "\n", "for", "key", "in", "sorted", "(", "self", ".", "input_dims", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "key", ".", "startswith", "(", "'info_'", ")", ":", "\n", "                ", "continue", "\n", "", "stage_shapes", "[", "key", "]", "=", "(", "None", ",", "*", "input_shapes", "[", "key", "]", ")", "\n", "", "for", "key", "in", "[", "'o'", ",", "'g'", "]", ":", "\n", "            ", "stage_shapes", "[", "key", "+", "'_2'", "]", "=", "stage_shapes", "[", "key", "]", "\n", "", "stage_shapes", "[", "'r'", "]", "=", "(", "None", ",", ")", "\n", "self", ".", "stage_shapes", "=", "stage_shapes", "\n", "\n", "# Create network.", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "self", ".", "staging_tf", "=", "StagingArea", "(", "\n", "dtypes", "=", "[", "tf", ".", "float32", "for", "_", "in", "self", ".", "stage_shapes", ".", "keys", "(", ")", "]", ",", "\n", "shapes", "=", "list", "(", "self", ".", "stage_shapes", ".", "values", "(", ")", ")", ")", "\n", "self", ".", "buffer_ph_tf", "=", "[", "\n", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "shape", "=", "shape", ")", "for", "shape", "in", "self", ".", "stage_shapes", ".", "values", "(", ")", "]", "\n", "self", ".", "stage_op", "=", "self", ".", "staging_tf", ".", "put", "(", "self", ".", "buffer_ph_tf", ")", "\n", "\n", "self", ".", "_create_network", "(", "reuse", "=", "reuse", ")", "\n", "\n", "# Configure the replay buffer.", "\n", "", "buffer_shapes", "=", "{", "key", ":", "(", "self", ".", "T", "-", "1", "if", "key", "!=", "'o'", "else", "self", ".", "T", ",", "*", "input_shapes", "[", "key", "]", ")", "\n", "for", "key", ",", "val", "in", "input_shapes", ".", "items", "(", ")", "}", "\n", "buffer_shapes", "[", "'g'", "]", "=", "(", "buffer_shapes", "[", "'g'", "]", "[", "0", "]", ",", "self", ".", "dimg", ")", "\n", "buffer_shapes", "[", "'ag'", "]", "=", "(", "self", ".", "T", ",", "self", ".", "dimg", ")", "\n", "\n", "buffer_size", "=", "(", "self", ".", "buffer_size", "//", "self", ".", "rollout_batch_size", ")", "*", "self", ".", "rollout_batch_size", "\n", "self", ".", "buffer", "=", "ReplayBuffer", "(", "buffer_shapes", ",", "buffer_size", ",", "self", ".", "T", ",", "self", ".", "sample_transitions", ")", "\n", "\n", "global", "DEMO_BUFFER", "\n", "DEMO_BUFFER", "=", "ReplayBuffer", "(", "buffer_shapes", ",", "buffer_size", ",", "self", ".", "T", ",", "self", ".", "sample_transitions", ")", "#initialize the demo buffer; in the same way as the primary data buffer", "\n", "\n", "", "def", "_random_action", "(", "self", ",", "n", ")", ":", "\n", "        ", "return", "np", ".", "random", ".", "uniform", "(", "low", "=", "-", "self", ".", "max_u", ",", "high", "=", "self", ".", "max_u", ",", "size", "=", "(", "n", ",", "self", ".", "dimu", ")", ")", "\n", "\n", "", "def", "_preprocess_og", "(", "self", ",", "o", ",", "ag", ",", "g", ")", ":", "\n", "        ", "if", "self", ".", "relative_goals", ":", "\n", "            ", "g_shape", "=", "g", ".", "shape", "\n", "g", "=", "g", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", "\n", "ag", "=", "ag", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", "\n", "g", "=", "self", ".", "subtract_goals", "(", "g", ",", "ag", ")", "\n", "g", "=", "g", ".", "reshape", "(", "*", "g_shape", ")", "\n", "", "o", "=", "np", ".", "clip", "(", "o", ",", "-", "self", ".", "clip_obs", ",", "self", ".", "clip_obs", ")", "\n", "g", "=", "np", ".", "clip", "(", "g", ",", "-", "self", ".", "clip_obs", ",", "self", ".", "clip_obs", ")", "\n", "return", "o", ",", "g", "\n", "\n", "", "def", "step", "(", "self", ",", "obs", ")", ":", "\n", "        ", "actions", "=", "self", ".", "get_actions", "(", "obs", "[", "'observation'", "]", ",", "obs", "[", "'achieved_goal'", "]", ",", "obs", "[", "'desired_goal'", "]", ")", "\n", "return", "actions", ",", "None", ",", "None", ",", "None", "\n", "\n", "\n", "", "def", "get_actions", "(", "self", ",", "o", ",", "ag", ",", "g", ",", "noise_eps", "=", "0.", ",", "random_eps", "=", "0.", ",", "use_target_net", "=", "False", ",", "\n", "compute_Q", "=", "False", ")", ":", "\n", "        ", "o", ",", "g", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "policy", "=", "self", ".", "target", "if", "use_target_net", "else", "self", ".", "main", "\n", "# values to compute", "\n", "vals", "=", "[", "policy", ".", "pi_tf", "]", "\n", "if", "compute_Q", ":", "\n", "            ", "vals", "+=", "[", "policy", ".", "Q_pi_tf", "]", "\n", "# feed", "\n", "", "feed", "=", "{", "\n", "policy", ".", "o_tf", ":", "o", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimo", ")", ",", "\n", "policy", ".", "g_tf", ":", "g", ".", "reshape", "(", "-", "1", ",", "self", ".", "dimg", ")", ",", "\n", "policy", ".", "u_tf", ":", "np", ".", "zeros", "(", "(", "o", ".", "size", "//", "self", ".", "dimo", ",", "self", ".", "dimu", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "}", "\n", "\n", "ret", "=", "self", ".", "sess", ".", "run", "(", "vals", ",", "feed_dict", "=", "feed", ")", "\n", "# action postprocessing", "\n", "u", "=", "ret", "[", "0", "]", "\n", "noise", "=", "noise_eps", "*", "self", ".", "max_u", "*", "np", ".", "random", ".", "randn", "(", "*", "u", ".", "shape", ")", "# gaussian noise", "\n", "u", "+=", "noise", "\n", "u", "=", "np", ".", "clip", "(", "u", ",", "-", "self", ".", "max_u", ",", "self", ".", "max_u", ")", "\n", "u", "+=", "np", ".", "random", ".", "binomial", "(", "1", ",", "random_eps", ",", "u", ".", "shape", "[", "0", "]", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "*", "(", "self", ".", "_random_action", "(", "u", ".", "shape", "[", "0", "]", ")", "-", "u", ")", "# eps-greedy", "\n", "if", "u", ".", "shape", "[", "0", "]", "==", "1", ":", "\n", "            ", "u", "=", "u", "[", "0", "]", "\n", "", "u", "=", "u", ".", "copy", "(", ")", "\n", "ret", "[", "0", "]", "=", "u", "\n", "\n", "if", "len", "(", "ret", ")", "==", "1", ":", "\n", "            ", "return", "ret", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "ret", "\n", "\n", "", "", "def", "init_demo_buffer", "(", "self", ",", "demoDataFile", ",", "update_stats", "=", "True", ")", ":", "#function that initializes the demo buffer", "\n", "\n", "        ", "demoData", "=", "np", ".", "load", "(", "demoDataFile", ")", "#load the demonstration data from data file", "\n", "info_keys", "=", "[", "key", ".", "replace", "(", "'info_'", ",", "''", ")", "for", "key", "in", "self", ".", "input_dims", ".", "keys", "(", ")", "if", "key", ".", "startswith", "(", "'info_'", ")", "]", "\n", "info_values", "=", "[", "np", ".", "empty", "(", "(", "self", ".", "T", "-", "1", ",", "1", ",", "self", ".", "input_dims", "[", "'info_'", "+", "key", "]", ")", ",", "np", ".", "float32", ")", "for", "key", "in", "info_keys", "]", "\n", "\n", "demo_data_obs", "=", "demoData", "[", "'obs'", "]", "\n", "demo_data_acs", "=", "demoData", "[", "'acs'", "]", "\n", "demo_data_info", "=", "demoData", "[", "'info'", "]", "\n", "\n", "for", "epsd", "in", "range", "(", "self", ".", "num_demo", ")", ":", "# we initialize the whole demo buffer at the start of the training", "\n", "            ", "obs", ",", "acts", ",", "goals", ",", "achieved_goals", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "i", "=", "0", "\n", "for", "transition", "in", "range", "(", "self", ".", "T", "-", "1", ")", ":", "\n", "                ", "obs", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'observation'", ")", "]", ")", "\n", "acts", ".", "append", "(", "[", "demo_data_acs", "[", "epsd", "]", "[", "transition", "]", "]", ")", "\n", "goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'desired_goal'", ")", "]", ")", "\n", "achieved_goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "transition", "]", ".", "get", "(", "'achieved_goal'", ")", "]", ")", "\n", "for", "idx", ",", "key", "in", "enumerate", "(", "info_keys", ")", ":", "\n", "                    ", "info_values", "[", "idx", "]", "[", "transition", ",", "i", "]", "=", "demo_data_info", "[", "epsd", "]", "[", "transition", "]", "[", "key", "]", "\n", "\n", "\n", "", "", "obs", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "self", ".", "T", "-", "1", "]", ".", "get", "(", "'observation'", ")", "]", ")", "\n", "achieved_goals", ".", "append", "(", "[", "demo_data_obs", "[", "epsd", "]", "[", "self", ".", "T", "-", "1", "]", ".", "get", "(", "'achieved_goal'", ")", "]", ")", "\n", "\n", "episode", "=", "dict", "(", "o", "=", "obs", ",", "\n", "u", "=", "acts", ",", "\n", "g", "=", "goals", ",", "\n", "ag", "=", "achieved_goals", ")", "\n", "for", "key", ",", "value", "in", "zip", "(", "info_keys", ",", "info_values", ")", ":", "\n", "                ", "episode", "[", "'info_{}'", ".", "format", "(", "key", ")", "]", "=", "value", "\n", "\n", "", "episode", "=", "convert_episode_to_batch_major", "(", "episode", ")", "\n", "global", "DEMO_BUFFER", "\n", "DEMO_BUFFER", ".", "store_episode", "(", "episode", ")", "# create the observation dict and append them into the demonstration buffer", "\n", "logger", ".", "debug", "(", "\"Demo buffer size currently \"", ",", "DEMO_BUFFER", ".", "get_current_size", "(", ")", ")", "#print out the demonstration buffer size", "\n", "\n", "if", "update_stats", ":", "\n", "# add transitions to normalizer to normalize the demo data as well", "\n", "                ", "episode", "[", "'o_2'", "]", "=", "episode", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "episode", "[", "'ag_2'", "]", "=", "episode", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "num_normalizing_transitions", "=", "transitions_in_episode_batch", "(", "episode", ")", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "episode", ",", "num_normalizing_transitions", ")", "\n", "\n", "o", ",", "g", ",", "ag", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", ",", "transitions", "[", "'ag'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "# No need to preprocess the o_2 and g_2 since this is only used for stats", "\n", "\n", "self", ".", "o_stats", ".", "update", "(", "transitions", "[", "'o'", "]", ")", "\n", "self", ".", "g_stats", ".", "update", "(", "transitions", "[", "'g'", "]", ")", "\n", "\n", "self", ".", "o_stats", ".", "recompute_stats", "(", ")", "\n", "self", ".", "g_stats", ".", "recompute_stats", "(", ")", "\n", "", "episode", ".", "clear", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Demo buffer size: \"", ",", "DEMO_BUFFER", ".", "get_current_size", "(", ")", ")", "#print out the demonstration buffer size", "\n", "\n", "", "def", "store_episode", "(", "self", ",", "episode_batch", ",", "update_stats", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        episode_batch: array of batch_size x (T or T+1) x dim_key\n                       'o' is of size T+1, others are of size T\n        \"\"\"", "\n", "\n", "self", ".", "buffer", ".", "store_episode", "(", "episode_batch", ")", "\n", "\n", "if", "update_stats", ":", "\n", "# add transitions to normalizer", "\n", "            ", "episode_batch", "[", "'o_2'", "]", "=", "episode_batch", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "episode_batch", "[", "'ag_2'", "]", "=", "episode_batch", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "num_normalizing_transitions", "=", "transitions_in_episode_batch", "(", "episode_batch", ")", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "episode_batch", ",", "num_normalizing_transitions", ")", "\n", "\n", "o", ",", "g", ",", "ag", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", ",", "transitions", "[", "'ag'", "]", "\n", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'g'", "]", "=", "self", ".", "_preprocess_og", "(", "o", ",", "ag", ",", "g", ")", "\n", "# No need to preprocess the o_2 and g_2 since this is only used for stats", "\n", "\n", "self", ".", "o_stats", ".", "update", "(", "transitions", "[", "'o'", "]", ")", "\n", "self", ".", "g_stats", ".", "update", "(", "transitions", "[", "'g'", "]", ")", "\n", "\n", "self", ".", "o_stats", ".", "recompute_stats", "(", ")", "\n", "self", ".", "g_stats", ".", "recompute_stats", "(", ")", "\n", "\n", "", "", "def", "get_current_buffer_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "buffer", ".", "get_current_size", "(", ")", "\n", "\n", "", "def", "_sync_optimizers", "(", "self", ")", ":", "\n", "        ", "self", ".", "Q_adam", ".", "sync", "(", ")", "\n", "self", ".", "pi_adam", ".", "sync", "(", ")", "\n", "\n", "", "def", "_grads", "(", "self", ")", ":", "\n", "# Avoid feed_dict here for performance!", "\n", "        ", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "=", "self", ".", "sess", ".", "run", "(", "[", "\n", "self", ".", "Q_loss_tf", ",", "\n", "self", ".", "main", ".", "Q_pi_tf", ",", "\n", "self", ".", "Q_grad_tf", ",", "\n", "self", ".", "pi_grad_tf", "\n", "]", ")", "\n", "return", "critic_loss", ",", "actor_loss", ",", "Q_grad", ",", "pi_grad", "\n", "\n", "", "def", "_update", "(", "self", ",", "Q_grad", ",", "pi_grad", ")", ":", "\n", "        ", "self", ".", "Q_adam", ".", "update", "(", "Q_grad", ",", "self", ".", "Q_lr", ")", "\n", "self", ".", "pi_adam", ".", "update", "(", "pi_grad", ",", "self", ".", "pi_lr", ")", "\n", "\n", "", "def", "sample_batch", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "bc_loss", ":", "#use demonstration buffer to sample as well if bc_loss flag is set TRUE", "\n", "            ", "transitions", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", "-", "self", ".", "demo_batch_size", ")", "\n", "global", "DEMO_BUFFER", "\n", "transitions_demo", "=", "DEMO_BUFFER", ".", "sample", "(", "self", ".", "demo_batch_size", ")", "#sample from the demo buffer", "\n", "for", "k", ",", "values", "in", "transitions_demo", ".", "items", "(", ")", ":", "\n", "                ", "rolloutV", "=", "transitions", "[", "k", "]", ".", "tolist", "(", ")", "\n", "for", "v", "in", "values", ":", "\n", "                    ", "rolloutV", ".", "append", "(", "v", ".", "tolist", "(", ")", ")", "\n", "", "transitions", "[", "k", "]", "=", "np", ".", "array", "(", "rolloutV", ")", "\n", "", "", "else", ":", "\n", "            ", "transitions", "=", "self", ".", "buffer", ".", "sample", "(", "self", ".", "batch_size", ")", "#otherwise only sample from primary buffer", "\n", "\n", "", "o", ",", "o_2", ",", "g", "=", "transitions", "[", "'o'", "]", ",", "transitions", "[", "'o_2'", "]", ",", "transitions", "[", "'g'", "]", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.__init__": [[5, 10], ["numpy.zeros().astype", "numpy.zeros"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "maxlen", ",", "shape", ",", "dtype", "=", "'float32'", ")", ":", "\n", "        ", "self", ".", "maxlen", "=", "maxlen", "\n", "self", ".", "start", "=", "0", "\n", "self", ".", "length", "=", "0", "\n", "self", ".", "data", "=", "np", ".", "zeros", "(", "(", "maxlen", ",", ")", "+", "shape", ")", ".", "astype", "(", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.__len__": [[11, 13], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.__getitem__": [[14, 18], ["KeyError"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "idx", "<", "0", "or", "idx", ">=", "self", ".", "length", ":", "\n", "            ", "raise", "KeyError", "(", ")", "\n", "", "return", "self", ".", "data", "[", "(", "self", ".", "start", "+", "idx", ")", "%", "self", ".", "maxlen", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.get_batch": [[19, 21], ["None"], "methods", ["None"], ["", "def", "get_batch", "(", "self", ",", "idxs", ")", ":", "\n", "        ", "return", "self", ".", "data", "[", "(", "self", ".", "start", "+", "idxs", ")", "%", "self", ".", "maxlen", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.append": [[22, 33], ["RuntimeError"], "methods", ["None"], ["", "def", "append", "(", "self", ",", "v", ")", ":", "\n", "        ", "if", "self", ".", "length", "<", "self", ".", "maxlen", ":", "\n", "# We have space, simply increase the length.", "\n", "            ", "self", ".", "length", "+=", "1", "\n", "", "elif", "self", ".", "length", "==", "self", ".", "maxlen", ":", "\n", "# No space, \"remove\" the first item.", "\n", "            ", "self", ".", "start", "=", "(", "self", ".", "start", "+", "1", ")", "%", "self", ".", "maxlen", "\n", "", "else", ":", "\n", "# This should never happen.", "\n", "            ", "raise", "RuntimeError", "(", ")", "\n", "", "self", ".", "data", "[", "(", "self", ".", "start", "+", "self", ".", "length", "-", "1", ")", "%", "self", ".", "maxlen", "]", "=", "v", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.__init__": [[43, 51], ["memory.RingBuffer", "memory.RingBuffer", "memory.RingBuffer", "memory.RingBuffer", "memory.RingBuffer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "limit", ",", "action_shape", ",", "observation_shape", ")", ":", "\n", "        ", "self", ".", "limit", "=", "limit", "\n", "\n", "self", ".", "observations0", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "observation_shape", ")", "\n", "self", ".", "actions", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "action_shape", ")", "\n", "self", ".", "rewards", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "(", "1", ",", ")", ")", "\n", "self", ".", "terminals1", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "(", "1", ",", ")", ")", "\n", "self", ".", "observations1", "=", "RingBuffer", "(", "limit", ",", "shape", "=", "observation_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.sample": [[52, 70], ["numpy.random.randint", "memory.Memory.observations0.get_batch", "memory.Memory.observations1.get_batch", "memory.Memory.actions.get_batch", "memory.Memory.rewards.get_batch", "memory.Memory.terminals1.get_batch", "memory.array_min2d", "memory.array_min2d", "memory.array_min2d", "memory.array_min2d", "memory.array_min2d"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.get_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.get_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.get_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.get_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.RingBuffer.get_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.array_min2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.array_min2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.array_min2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.array_min2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.array_min2d"], ["", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "# Draw such that we always have a proceeding element.", "\n", "        ", "batch_idxs", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "nb_entries", "-", "2", ",", "size", "=", "batch_size", ")", "\n", "\n", "obs0_batch", "=", "self", ".", "observations0", ".", "get_batch", "(", "batch_idxs", ")", "\n", "obs1_batch", "=", "self", ".", "observations1", ".", "get_batch", "(", "batch_idxs", ")", "\n", "action_batch", "=", "self", ".", "actions", ".", "get_batch", "(", "batch_idxs", ")", "\n", "reward_batch", "=", "self", ".", "rewards", ".", "get_batch", "(", "batch_idxs", ")", "\n", "terminal1_batch", "=", "self", ".", "terminals1", ".", "get_batch", "(", "batch_idxs", ")", "\n", "\n", "result", "=", "{", "\n", "'obs0'", ":", "array_min2d", "(", "obs0_batch", ")", ",", "\n", "'obs1'", ":", "array_min2d", "(", "obs1_batch", ")", ",", "\n", "'rewards'", ":", "array_min2d", "(", "reward_batch", ")", ",", "\n", "'actions'", ":", "array_min2d", "(", "action_batch", ")", ",", "\n", "'terminals1'", ":", "array_min2d", "(", "terminal1_batch", ")", ",", "\n", "}", "\n", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append": [[71, 80], ["memory.Memory.observations0.append", "memory.Memory.actions.append", "memory.Memory.rewards.append", "memory.Memory.observations1.append", "memory.Memory.terminals1.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "append", "(", "self", ",", "obs0", ",", "action", ",", "reward", ",", "obs1", ",", "terminal1", ",", "training", "=", "True", ")", ":", "\n", "        ", "if", "not", "training", ":", "\n", "            ", "return", "\n", "\n", "", "self", ".", "observations0", ".", "append", "(", "obs0", ")", "\n", "self", ".", "actions", ".", "append", "(", "action", ")", "\n", "self", ".", "rewards", ".", "append", "(", "reward", ")", "\n", "self", ".", "observations1", ".", "append", "(", "obs1", ")", "\n", "self", ".", "terminals1", ".", "append", "(", "terminal1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.nb_entries": [[81, 84], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "nb_entries", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "observations0", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.array_min2d": [[35, 40], ["numpy.array", "np.array.reshape"], "function", ["None"], ["", "", "def", "array_min2d", "(", "x", ")", ":", "\n", "    ", "x", "=", "np", ".", "array", "(", "x", ")", "\n", "if", "x", ".", "ndim", ">=", "2", ":", "\n", "        ", "return", "x", "\n", "", "return", "x", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.models.build_q_func": [[5, 46], ["isinstance", "get_network_builder", "tensorflow.variable_scope", "network", "isinstance", "tensorflow.flatten", "tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.reduce_mean", "NotImplementedError", "tensorflow.fully_connected", "tensorflow.nn.relu", "tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.expand_dims", "tensorflow.layer_norm", "tensorflow.fully_connected", "tensorflow.nn.relu", "tensorflow.layer_norm"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.get_network_builder"], ["class", "Model", "(", "object", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "name", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "network_builder", "=", "get_network_builder", "(", "network", ")", "(", "**", "network_kwargs", ")", "\n", "\n", "", "@", "property", "\n", "def", "vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "name", ")", "\n", "\n", "", "@", "property", "\n", "def", "trainable_vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "self", ".", "name", ")", "\n", "\n", "", "@", "property", "\n", "def", "perturbable_vars", "(", "self", ")", ":", "\n", "        ", "return", "[", "var", "for", "var", "in", "self", ".", "trainable_vars", "if", "'LayerNorm'", "not", "in", "var", ".", "name", "]", "\n", "\n", "\n", "", "", "class", "Actor", "(", "Model", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "nb_actions", ",", "name", "=", "'actor'", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "network", "=", "network", ",", "**", "network_kwargs", ")", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "\n", "", "def", "__call__", "(", "self", ",", "obs", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "self", ".", "network_builder", "(", "obs", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "self", ".", "nb_actions", ",", "kernel_initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "3e-3", ",", "maxval", "=", "3e-3", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "tanh", "(", "x", ")", "\n", "", "return", "x", "\n", "\n", "\n", "", "", "class", "Critic", "(", "Model", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "name", "=", "'critic'", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "network", "=", "network", ",", "**", "network_kwargs", ")", "\n", "self", ".", "layer_norm", "=", "True", "\n", "\n", "", "def", "__call__", "(", "self", ",", "obs", ",", "action", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "tf", ".", "concat", "(", "[", "obs", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "# this assumes observation and action can be concatenated", "\n", "x", "=", "self", ".", "network_builder", "(", "x", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "3e-3", ",", "maxval", "=", "3e-3", ")", ",", "name", "=", "'output'", ")", "\n", "", "return", "x", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.defaults.atari": [[1, 17], ["dict"], "function", ["None"], ["from", "baselines", ".", "common", ".", "models", "import", "mlp", ",", "cnn_small", "\n", "\n", "\n", "def", "atari", "(", ")", ":", "\n", "    ", "return", "dict", "(", "\n", "network", "=", "cnn_small", "(", ")", ",", "\n", "timesteps_per_batch", "=", "512", ",", "\n", "max_kl", "=", "0.001", ",", "\n", "cg_iters", "=", "10", ",", "\n", "cg_damping", "=", "1e-3", ",", "\n", "gamma", "=", "0.98", ",", "\n", "lam", "=", "1.0", ",", "\n", "vf_iters", "=", "3", ",", "\n", "vf_stepsize", "=", "1e-4", ",", "\n", "entcoeff", "=", "0.00", ",", "\n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.defaults.retro": [[19, 21], ["defaults.atari"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.defaults.atari"], ["    ", "return", "dict", "(", "\n", "network", "=", "mlp", "(", "num_hidden", "=", "32", ",", "num_layers", "=", "2", ")", ",", "\n", "timesteps_per_batch", "=", "1024", ",", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.ActWrapper.__init__": [[24, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "act", ",", "act_params", ")", ":", "\n", "        ", "self", ".", "_act", "=", "act", "\n", "self", ".", "_act_params", "=", "act_params", "\n", "self", ".", "initial_state", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.ActWrapper.load_act": [[29, 45], ["baselines.deepq.build_act", "tensorflow.Session", "tensorflow.Session.__enter__", "baselines.deepq.ActWrapper", "open", "cloudpickle.load", "tempfile.TemporaryDirectory", "os.path.join", "zipfile.ZipFile().extractall", "baselines.common.tf_util.load_variables", "open", "f.write", "os.path.join", "zipfile.ZipFile"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.build_act", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_variables"], ["", "@", "staticmethod", "\n", "def", "load_act", "(", "path", ")", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "model_data", ",", "act_params", "=", "cloudpickle", ".", "load", "(", "f", ")", "\n", "", "act", "=", "deepq", ".", "build_act", "(", "**", "act_params", ")", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "__enter__", "(", ")", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "td", ":", "\n", "            ", "arc_path", "=", "os", ".", "path", ".", "join", "(", "td", ",", "\"packed.zip\"", ")", "\n", "with", "open", "(", "arc_path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "model_data", ")", "\n", "\n", "", "zipfile", ".", "ZipFile", "(", "arc_path", ",", "'r'", ",", "zipfile", ".", "ZIP_DEFLATED", ")", ".", "extractall", "(", "td", ")", "\n", "load_variables", "(", "os", ".", "path", ".", "join", "(", "td", ",", "\"model\"", ")", ")", "\n", "\n", "", "return", "ActWrapper", "(", "act", ",", "act_params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.ActWrapper.__call__": [[46, 48], ["baselines.deepq.ActWrapper._act"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "_act", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.ActWrapper.step": [[49, 54], ["kwargs.pop", "kwargs.pop", "baselines.deepq.ActWrapper._act"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "observation", ",", "**", "kwargs", ")", ":", "\n", "# DQN doesn't use RNNs so we ignore states and masks", "\n", "        ", "kwargs", ".", "pop", "(", "'S'", ",", "None", ")", "\n", "kwargs", ".", "pop", "(", "'M'", ",", "None", ")", "\n", "return", "self", ".", "_act", "(", "[", "observation", "]", ",", "**", "kwargs", ")", ",", "None", ",", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.ActWrapper.save_act": [[55, 73], ["os.path.join", "tempfile.TemporaryDirectory", "baselines.common.tf_util.save_variables", "os.path.join", "open", "cloudpickle.dump", "baselines.logger.get_dir", "os.path.join", "zipfile.ZipFile", "os.walk", "open", "f.read", "os.path.join", "zipf.write", "os.path.relpath"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["", "def", "save_act", "(", "self", ",", "path", "=", "None", ")", ":", "\n", "        ", "\"\"\"Save model to a pickle located at `path`\"\"\"", "\n", "if", "path", "is", "None", ":", "\n", "            ", "path", "=", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "\"model.pkl\"", ")", "\n", "\n", "", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "td", ":", "\n", "            ", "save_variables", "(", "os", ".", "path", ".", "join", "(", "td", ",", "\"model\"", ")", ")", "\n", "arc_name", "=", "os", ".", "path", ".", "join", "(", "td", ",", "\"packed.zip\"", ")", "\n", "with", "zipfile", ".", "ZipFile", "(", "arc_name", ",", "'w'", ")", "as", "zipf", ":", "\n", "                ", "for", "root", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "td", ")", ":", "\n", "                    ", "for", "fname", "in", "files", ":", "\n", "                        ", "file_path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "if", "file_path", "!=", "arc_name", ":", "\n", "                            ", "zipf", ".", "write", "(", "file_path", ",", "os", ".", "path", ".", "relpath", "(", "file_path", ",", "td", ")", ")", "\n", "", "", "", "", "with", "open", "(", "arc_name", ",", "\"rb\"", ")", "as", "f", ":", "\n", "                ", "model_data", "=", "f", ".", "read", "(", ")", "\n", "", "", "with", "open", "(", "path", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "cloudpickle", ".", "dump", "(", "(", "model_data", ",", "self", ".", "_act_params", ")", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.ActWrapper.save": [[74, 76], ["baselines.common.tf_util.save_variables"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_variables"], ["", "", "def", "save", "(", "self", ",", "path", ")", ":", "\n", "        ", "save_variables", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.load_act": [[78, 93], ["deepq.ActWrapper.load_act"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.load_act"], ["", "", "def", "load_act", "(", "path", ")", ":", "\n", "    ", "\"\"\"Load act function that was returned by learn function.\n\n    Parameters\n    ----------\n    path: str\n        path to the act function pickle\n\n    Returns\n    -------\n    act: ActWrapper\n        function that takes a batch of observations\n        and returns actions.\n    \"\"\"", "\n", "return", "ActWrapper", ".", "load_act", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.deepq.learn": [[95, 333], ["baselines.common.tf_util.get_session", "baselines.common.set_global_seeds", "baselines.deepq.models.build_q_func", "baselines.deepq.build_train", "deepq.ActWrapper", "baselines.common.schedules.LinearSchedule", "baselines.initialize", "update_target", "env.reset", "baselines.deepq.utils.ObservationInput", "baselines.deepq.replay_buffer.PrioritizedReplayBuffer", "baselines.common.schedules.LinearSchedule", "baselines.deepq.replay_buffer.ReplayBuffer", "tempfile.TemporaryDirectory", "os.path.join", "range", "tensorflow.train.AdamOptimizer", "int", "tensorflow.train.latest_checkpoint", "baselines.common.tf_util.load_variables", "baselines.logger.log", "env.step", "baselines.deepq.replay_buffer.ReplayBuffer.add", "round", "len", "baselines.common.tf_util.load_variables", "baselines.common.tf_util.load_variables", "baselines.logger.log", "callback", "baselines.common.schedules.LinearSchedule.value", "ActWrapper.", "float", "env.reset", "episode_rewards.append", "train", "update_target", "numpy.mean", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.dump_tabular", "baselines.logger.log", "locals", "globals", "numpy.log", "baselines.deepq.replay_buffer.ReplayBuffer.sample", "baselines.deepq.replay_buffer.ReplayBuffer.sample", "baselines.deepq.replay_buffer.ReplayBuffer.update_priorities", "int", "baselines.common.tf_util.save_variables", "numpy.array", "numpy.ones_like", "numpy.abs", "len", "baselines.logger.log", "baselines.common.schedules.LinearSchedule.value", "baselines.common.schedules.LinearSchedule.value", "baselines.common.schedules.LinearSchedule.value", "baselines.common.schedules.LinearSchedule.value", "float"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.models.build_q_func", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.build_train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_cartpole.callback", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.update_priorities", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value"], ["", "def", "learn", "(", "env", ",", "\n", "network", ",", "\n", "seed", "=", "None", ",", "\n", "lr", "=", "5e-4", ",", "\n", "total_timesteps", "=", "100000", ",", "\n", "buffer_size", "=", "50000", ",", "\n", "exploration_fraction", "=", "0.1", ",", "\n", "exploration_final_eps", "=", "0.02", ",", "\n", "train_freq", "=", "1", ",", "\n", "batch_size", "=", "32", ",", "\n", "print_freq", "=", "100", ",", "\n", "checkpoint_freq", "=", "10000", ",", "\n", "checkpoint_path", "=", "None", ",", "\n", "learning_starts", "=", "1000", ",", "\n", "gamma", "=", "1.0", ",", "\n", "target_network_update_freq", "=", "500", ",", "\n", "prioritized_replay", "=", "False", ",", "\n", "prioritized_replay_alpha", "=", "0.6", ",", "\n", "prioritized_replay_beta0", "=", "0.4", ",", "\n", "prioritized_replay_beta_iters", "=", "None", ",", "\n", "prioritized_replay_eps", "=", "1e-6", ",", "\n", "param_noise", "=", "False", ",", "\n", "callback", "=", "None", ",", "\n", "load_path", "=", "None", ",", "\n", "**", "network_kwargs", "\n", ")", ":", "\n", "    ", "\"\"\"Train a deepq model.\n\n    Parameters\n    -------\n    env: gym.Env\n        environment to train on\n    network: string or a function\n        neural network to use as a q function approximator. If string, has to be one of the names of registered models in baselines.common.models\n        (mlp, cnn, conv_only). If a function, should take an observation tensor and return a latent variable tensor, which\n        will be mapped to the Q function heads (see build_q_func in baselines.deepq.models for details on that)\n    seed: int or None\n        prng seed. The runs with the same seed \"should\" give the same results. If None, no seeding is used.\n    lr: float\n        learning rate for adam optimizer\n    total_timesteps: int\n        number of env steps to optimizer for\n    buffer_size: int\n        size of the replay buffer\n    exploration_fraction: float\n        fraction of entire training period over which the exploration rate is annealed\n    exploration_final_eps: float\n        final value of random action probability\n    train_freq: int\n        update the model every `train_freq` steps.\n    batch_size: int\n        size of a batch sampled from replay buffer for training\n    print_freq: int\n        how often to print out training progress\n        set to None to disable printing\n    checkpoint_freq: int\n        how often to save the model. This is so that the best version is restored\n        at the end of the training. If you do not wish to restore the best version at\n        the end of the training set this variable to None.\n    learning_starts: int\n        how many steps of the model to collect transitions for before learning starts\n    gamma: float\n        discount factor\n    target_network_update_freq: int\n        update the target network every `target_network_update_freq` steps.\n    prioritized_replay: True\n        if True prioritized replay buffer will be used.\n    prioritized_replay_alpha: float\n        alpha parameter for prioritized replay buffer\n    prioritized_replay_beta0: float\n        initial value of beta for prioritized replay buffer\n    prioritized_replay_beta_iters: int\n        number of iterations over which beta will be annealed from initial value\n        to 1.0. If set to None equals to total_timesteps.\n    prioritized_replay_eps: float\n        epsilon to add to the TD errors when updating priorities.\n    param_noise: bool\n        whether or not to use parameter space noise (https://arxiv.org/abs/1706.01905)\n    callback: (locals, globals) -> None\n        function called at every steps with state of the algorithm.\n        If callback returns true training stops.\n    load_path: str\n        path to load the model from. (default: None)\n    **network_kwargs\n        additional keyword arguments to pass to the network builder.\n\n    Returns\n    -------\n    act: ActWrapper\n        Wrapper over act function. Adds ability to save it and load it.\n        See header of baselines/deepq/categorical.py for details on the act function.\n    \"\"\"", "\n", "# Create all the functions necessary to train the model", "\n", "\n", "sess", "=", "get_session", "(", ")", "\n", "set_global_seeds", "(", "seed", ")", "\n", "\n", "q_func", "=", "build_q_func", "(", "network", ",", "**", "network_kwargs", ")", "\n", "\n", "# capture the shape outside the closure so that the env object is not serialized", "\n", "# by cloudpickle when serializing make_obs_ph", "\n", "\n", "observation_space", "=", "env", ".", "observation_space", "\n", "def", "make_obs_ph", "(", "name", ")", ":", "\n", "        ", "return", "ObservationInput", "(", "observation_space", ",", "name", "=", "name", ")", "\n", "\n", "", "act", ",", "train", ",", "update_target", ",", "debug", "=", "deepq", ".", "build_train", "(", "\n", "make_obs_ph", "=", "make_obs_ph", ",", "\n", "q_func", "=", "q_func", ",", "\n", "num_actions", "=", "env", ".", "action_space", ".", "n", ",", "\n", "optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "lr", ")", ",", "\n", "gamma", "=", "gamma", ",", "\n", "grad_norm_clipping", "=", "10", ",", "\n", "param_noise", "=", "param_noise", "\n", ")", "\n", "\n", "act_params", "=", "{", "\n", "'make_obs_ph'", ":", "make_obs_ph", ",", "\n", "'q_func'", ":", "q_func", ",", "\n", "'num_actions'", ":", "env", ".", "action_space", ".", "n", ",", "\n", "}", "\n", "\n", "act", "=", "ActWrapper", "(", "act", ",", "act_params", ")", "\n", "\n", "# Create the replay buffer", "\n", "if", "prioritized_replay", ":", "\n", "        ", "replay_buffer", "=", "PrioritizedReplayBuffer", "(", "buffer_size", ",", "alpha", "=", "prioritized_replay_alpha", ")", "\n", "if", "prioritized_replay_beta_iters", "is", "None", ":", "\n", "            ", "prioritized_replay_beta_iters", "=", "total_timesteps", "\n", "", "beta_schedule", "=", "LinearSchedule", "(", "prioritized_replay_beta_iters", ",", "\n", "initial_p", "=", "prioritized_replay_beta0", ",", "\n", "final_p", "=", "1.0", ")", "\n", "", "else", ":", "\n", "        ", "replay_buffer", "=", "ReplayBuffer", "(", "buffer_size", ")", "\n", "beta_schedule", "=", "None", "\n", "# Create the schedule for exploration starting from 1.", "\n", "", "exploration", "=", "LinearSchedule", "(", "schedule_timesteps", "=", "int", "(", "exploration_fraction", "*", "total_timesteps", ")", ",", "\n", "initial_p", "=", "1.0", ",", "\n", "final_p", "=", "exploration_final_eps", ")", "\n", "\n", "# Initialize the parameters and copy them to the target network.", "\n", "U", ".", "initialize", "(", ")", "\n", "update_target", "(", ")", "\n", "\n", "episode_rewards", "=", "[", "0.0", "]", "\n", "saved_mean_reward", "=", "None", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "reset", "=", "True", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "td", ":", "\n", "        ", "td", "=", "checkpoint_path", "or", "td", "\n", "\n", "model_file", "=", "os", ".", "path", ".", "join", "(", "td", ",", "\"model\"", ")", "\n", "model_saved", "=", "False", "\n", "\n", "if", "tf", ".", "train", ".", "latest_checkpoint", "(", "td", ")", "is", "not", "None", ":", "\n", "            ", "load_variables", "(", "model_file", ")", "\n", "logger", ".", "log", "(", "'Loaded model from {}'", ".", "format", "(", "model_file", ")", ")", "\n", "model_saved", "=", "True", "\n", "", "elif", "load_path", "is", "not", "None", ":", "\n", "            ", "load_variables", "(", "load_path", ")", "\n", "logger", ".", "log", "(", "'Loaded model from {}'", ".", "format", "(", "load_path", ")", ")", "\n", "\n", "\n", "", "for", "t", "in", "range", "(", "total_timesteps", ")", ":", "\n", "            ", "if", "callback", "is", "not", "None", ":", "\n", "                ", "if", "callback", "(", "locals", "(", ")", ",", "globals", "(", ")", ")", ":", "\n", "                    ", "break", "\n", "# Take action and update exploration to the newest value", "\n", "", "", "kwargs", "=", "{", "}", "\n", "if", "not", "param_noise", ":", "\n", "                ", "update_eps", "=", "exploration", ".", "value", "(", "t", ")", "\n", "update_param_noise_threshold", "=", "0.", "\n", "", "else", ":", "\n", "                ", "update_eps", "=", "0.", "\n", "# Compute the threshold such that the KL divergence between perturbed and non-perturbed", "\n", "# policy is comparable to eps-greedy exploration with eps = exploration.value(t).", "\n", "# See Appendix C.1 in Parameter Space Noise for Exploration, Plappert et al., 2017", "\n", "# for detailed explanation.", "\n", "update_param_noise_threshold", "=", "-", "np", ".", "log", "(", "1.", "-", "exploration", ".", "value", "(", "t", ")", "+", "exploration", ".", "value", "(", "t", ")", "/", "float", "(", "env", ".", "action_space", ".", "n", ")", ")", "\n", "kwargs", "[", "'reset'", "]", "=", "reset", "\n", "kwargs", "[", "'update_param_noise_threshold'", "]", "=", "update_param_noise_threshold", "\n", "kwargs", "[", "'update_param_noise_scale'", "]", "=", "True", "\n", "", "action", "=", "act", "(", "np", ".", "array", "(", "obs", ")", "[", "None", "]", ",", "update_eps", "=", "update_eps", ",", "**", "kwargs", ")", "[", "0", "]", "\n", "env_action", "=", "action", "\n", "reset", "=", "False", "\n", "new_obs", ",", "rew", ",", "done", ",", "_", "=", "env", ".", "step", "(", "env_action", ")", "\n", "# Store transition in the replay buffer.", "\n", "replay_buffer", ".", "add", "(", "obs", ",", "action", ",", "rew", ",", "new_obs", ",", "float", "(", "done", ")", ")", "\n", "obs", "=", "new_obs", "\n", "\n", "episode_rewards", "[", "-", "1", "]", "+=", "rew", "\n", "if", "done", ":", "\n", "                ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "episode_rewards", ".", "append", "(", "0.0", ")", "\n", "reset", "=", "True", "\n", "\n", "", "if", "t", ">", "learning_starts", "and", "t", "%", "train_freq", "==", "0", ":", "\n", "# Minimize the error in Bellman's equation on a batch sampled from replay buffer.", "\n", "                ", "if", "prioritized_replay", ":", "\n", "                    ", "experience", "=", "replay_buffer", ".", "sample", "(", "batch_size", ",", "beta", "=", "beta_schedule", ".", "value", "(", "t", ")", ")", "\n", "(", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", ",", "weights", ",", "batch_idxes", ")", "=", "experience", "\n", "", "else", ":", "\n", "                    ", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", "=", "replay_buffer", ".", "sample", "(", "batch_size", ")", "\n", "weights", ",", "batch_idxes", "=", "np", ".", "ones_like", "(", "rewards", ")", ",", "None", "\n", "", "td_errors", "=", "train", "(", "obses_t", ",", "actions", ",", "rewards", ",", "obses_tp1", ",", "dones", ",", "weights", ")", "\n", "if", "prioritized_replay", ":", "\n", "                    ", "new_priorities", "=", "np", ".", "abs", "(", "td_errors", ")", "+", "prioritized_replay_eps", "\n", "replay_buffer", ".", "update_priorities", "(", "batch_idxes", ",", "new_priorities", ")", "\n", "\n", "", "", "if", "t", ">", "learning_starts", "and", "t", "%", "target_network_update_freq", "==", "0", ":", "\n", "# Update target network periodically.", "\n", "                ", "update_target", "(", ")", "\n", "\n", "", "mean_100ep_reward", "=", "round", "(", "np", ".", "mean", "(", "episode_rewards", "[", "-", "101", ":", "-", "1", "]", ")", ",", "1", ")", "\n", "num_episodes", "=", "len", "(", "episode_rewards", ")", "\n", "if", "done", "and", "print_freq", "is", "not", "None", "and", "len", "(", "episode_rewards", ")", "%", "print_freq", "==", "0", ":", "\n", "                ", "logger", ".", "record_tabular", "(", "\"steps\"", ",", "t", ")", "\n", "logger", ".", "record_tabular", "(", "\"episodes\"", ",", "num_episodes", ")", "\n", "logger", ".", "record_tabular", "(", "\"mean 100 episode reward\"", ",", "mean_100ep_reward", ")", "\n", "logger", ".", "record_tabular", "(", "\"% time spent exploring\"", ",", "int", "(", "100", "*", "exploration", ".", "value", "(", "t", ")", ")", ")", "\n", "logger", ".", "dump_tabular", "(", ")", "\n", "\n", "", "if", "(", "checkpoint_freq", "is", "not", "None", "and", "t", ">", "learning_starts", "and", "\n", "num_episodes", ">", "100", "and", "t", "%", "checkpoint_freq", "==", "0", ")", ":", "\n", "                ", "if", "saved_mean_reward", "is", "None", "or", "mean_100ep_reward", ">", "saved_mean_reward", ":", "\n", "                    ", "if", "print_freq", "is", "not", "None", ":", "\n", "                        ", "logger", ".", "log", "(", "\"Saving model due to mean reward increase: {} -> {}\"", ".", "format", "(", "\n", "saved_mean_reward", ",", "mean_100ep_reward", ")", ")", "\n", "", "save_variables", "(", "model_file", ")", "\n", "model_saved", "=", "True", "\n", "saved_mean_reward", "=", "mean_100ep_reward", "\n", "", "", "", "if", "model_saved", ":", "\n", "            ", "if", "print_freq", "is", "not", "None", ":", "\n", "                ", "logger", ".", "log", "(", "\"Restored model with mean reward: {}\"", ".", "format", "(", "saved_mean_reward", ")", ")", "\n", "", "load_variables", "(", "model_file", ")", "\n", "\n", "", "", "return", "act", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.scope_vars": [[100, 118], ["tensorflow.get_collection", "isinstance"], "function", ["None"], ["def", "scope_vars", "(", "scope", ",", "trainable_only", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Get variables inside a scope\n    The scope can be specified as a string\n    Parameters\n    ----------\n    scope: str or VariableScope\n        scope in which the variables reside.\n    trainable_only: bool\n        whether or not to return only the variables that were marked as trainable.\n    Returns\n    -------\n    vars: [tf.Variable]\n        list of variables in `scope`.\n    \"\"\"", "\n", "return", "tf", ".", "get_collection", "(", "\n", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", "if", "trainable_only", "else", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "\n", "scope", "=", "scope", "if", "isinstance", "(", "scope", ",", "str", ")", "else", "scope", ".", "name", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.scope_name": [[121, 124], ["tensorflow.get_variable_scope"], "function", ["None"], ["", "def", "scope_name", "(", ")", ":", "\n", "    ", "\"\"\"Returns the name of current scope as a string, e.g. deepq/q_func\"\"\"", "\n", "return", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.absolute_scope_name": [[126, 129], ["build_graph.scope_name"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.scope_name"], ["", "def", "absolute_scope_name", "(", "relative_scope_name", ")", ":", "\n", "    ", "\"\"\"Appends parent scope name to `relative_scope_name`\"\"\"", "\n", "return", "scope_name", "(", ")", "+", "\"/\"", "+", "relative_scope_name", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.default_param_noise_filter": [[131, 144], ["tensorflow.trainable_variables"], "function", ["None"], ["", "def", "default_param_noise_filter", "(", "var", ")", ":", "\n", "    ", "if", "var", "not", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "# We never perturb non-trainable vars.", "\n", "        ", "return", "False", "\n", "", "if", "\"fully_connected\"", "in", "var", ".", "name", ":", "\n", "# We perturb fully-connected layers.", "\n", "        ", "return", "True", "\n", "\n", "# The remaining layers are likely conv or layer norm layers, which we do not wish to", "\n", "# perturb (in the former case because they only extract features, in the latter case because", "\n", "# we use them for normalization purposes). If you change your network, you will likely want", "\n", "# to re-consider which layers to perturb and which to keep untouched.", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.build_act": [[146, 200], ["tensorflow.variable_scope", "make_obs_ph", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.get_variable", "q_func", "tensorflow.argmax", "tensorflow.random_uniform", "tensorflow.where", "tensorflow.cond", "tf.get_variable.assign", "baselines.function", "make_obs_ph.get", "tensorflow.shape", "tensorflow.stack", "tensorflow.random_uniform", "tensorflow.cond", "U.function.", "tensorflow.constant_initializer", "make_obs_ph.get", "tensorflow.stack"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["", "def", "build_act", "(", "make_obs_ph", ",", "q_func", ",", "num_actions", ",", "scope", "=", "\"deepq\"", ",", "reuse", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates the act function:\n\n    Parameters\n    ----------\n    make_obs_ph: str -> tf.placeholder or TfInput\n        a function that take a name and creates a placeholder of input with that name\n    q_func: (tf.Variable, int, str, bool) -> tf.Variable\n        the model that takes the following inputs:\n            observation_in: object\n                the output of observation placeholder\n            num_actions: int\n                number of actions\n            scope: str\n            reuse: bool\n                should be passed to outer variable scope\n        and returns a tensor of shape (batch_size, num_actions) with values of every action.\n    num_actions: int\n        number of actions.\n    scope: str or VariableScope\n        optional scope for variable_scope.\n    reuse: bool or None\n        whether or not the variables should be reused. To be able to reuse the scope must be given.\n\n    Returns\n    -------\n    act: (tf.Variable, bool, float) -> tf.Variable\n        function to select and action given observation.\n`       See the top of the file for details.\n    \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "observations_ph", "=", "make_obs_ph", "(", "\"observation\"", ")", "\n", "stochastic_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "(", ")", ",", "name", "=", "\"stochastic\"", ")", "\n", "update_eps_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", ")", ",", "name", "=", "\"update_eps\"", ")", "\n", "\n", "eps", "=", "tf", ".", "get_variable", "(", "\"eps\"", ",", "(", ")", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ")", "\n", "\n", "q_values", "=", "q_func", "(", "observations_ph", ".", "get", "(", ")", ",", "num_actions", ",", "scope", "=", "\"q_func\"", ")", "\n", "deterministic_actions", "=", "tf", ".", "argmax", "(", "q_values", ",", "axis", "=", "1", ")", "\n", "\n", "batch_size", "=", "tf", ".", "shape", "(", "observations_ph", ".", "get", "(", ")", ")", "[", "0", "]", "\n", "random_actions", "=", "tf", ".", "random_uniform", "(", "tf", ".", "stack", "(", "[", "batch_size", "]", ")", ",", "minval", "=", "0", ",", "maxval", "=", "num_actions", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "chose_random", "=", "tf", ".", "random_uniform", "(", "tf", ".", "stack", "(", "[", "batch_size", "]", ")", ",", "minval", "=", "0", ",", "maxval", "=", "1", ",", "dtype", "=", "tf", ".", "float32", ")", "<", "eps", "\n", "stochastic_actions", "=", "tf", ".", "where", "(", "chose_random", ",", "random_actions", ",", "deterministic_actions", ")", "\n", "\n", "output_actions", "=", "tf", ".", "cond", "(", "stochastic_ph", ",", "lambda", ":", "stochastic_actions", ",", "lambda", ":", "deterministic_actions", ")", "\n", "update_eps_expr", "=", "eps", ".", "assign", "(", "tf", ".", "cond", "(", "update_eps_ph", ">=", "0", ",", "lambda", ":", "update_eps_ph", ",", "lambda", ":", "eps", ")", ")", "\n", "_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "observations_ph", ",", "stochastic_ph", ",", "update_eps_ph", "]", ",", "\n", "outputs", "=", "output_actions", ",", "\n", "givens", "=", "{", "update_eps_ph", ":", "-", "1.0", ",", "stochastic_ph", ":", "True", "}", ",", "\n", "updates", "=", "[", "update_eps_expr", "]", ")", "\n", "def", "act", "(", "ob", ",", "stochastic", "=", "True", ",", "update_eps", "=", "-", "1", ")", ":", "\n", "            ", "return", "_act", "(", "ob", ",", "stochastic", ",", "update_eps", ")", "\n", "", "return", "act", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.build_act_with_param_noise": [[202, 315], ["tensorflow.variable_scope", "make_obs_ph", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "q_func", "q_func", "q_func", "build_graph.build_act_with_param_noise.perturb_vars"], "function", ["None"], ["", "", "def", "build_act_with_param_noise", "(", "make_obs_ph", ",", "q_func", ",", "num_actions", ",", "scope", "=", "\"deepq\"", ",", "reuse", "=", "None", ",", "param_noise_filter_func", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates the act function with support for parameter space noise exploration (https://arxiv.org/abs/1706.01905):\n\n    Parameters\n    ----------\n    make_obs_ph: str -> tf.placeholder or TfInput\n        a function that take a name and creates a placeholder of input with that name\n    q_func: (tf.Variable, int, str, bool) -> tf.Variable\n        the model that takes the following inputs:\n            observation_in: object\n                the output of observation placeholder\n            num_actions: int\n                number of actions\n            scope: str\n            reuse: bool\n                should be passed to outer variable scope\n        and returns a tensor of shape (batch_size, num_actions) with values of every action.\n    num_actions: int\n        number of actions.\n    scope: str or VariableScope\n        optional scope for variable_scope.\n    reuse: bool or None\n        whether or not the variables should be reused. To be able to reuse the scope must be given.\n    param_noise_filter_func: tf.Variable -> bool\n        function that decides whether or not a variable should be perturbed. Only applicable\n        if param_noise is True. If set to None, default_param_noise_filter is used by default.\n\n    Returns\n    -------\n    act: (tf.Variable, bool, float, bool, float, bool) -> tf.Variable\n        function to select and action given observation.\n`       See the top of the file for details.\n    \"\"\"", "\n", "if", "param_noise_filter_func", "is", "None", ":", "\n", "        ", "param_noise_filter_func", "=", "default_param_noise_filter", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "observations_ph", "=", "make_obs_ph", "(", "\"observation\"", ")", "\n", "stochastic_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "(", ")", ",", "name", "=", "\"stochastic\"", ")", "\n", "update_eps_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", ")", ",", "name", "=", "\"update_eps\"", ")", "\n", "update_param_noise_threshold_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", ")", ",", "name", "=", "\"update_param_noise_threshold\"", ")", "\n", "update_param_noise_scale_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "(", ")", ",", "name", "=", "\"update_param_noise_scale\"", ")", "\n", "reset_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "bool", ",", "(", ")", ",", "name", "=", "\"reset\"", ")", "\n", "\n", "eps", "=", "tf", ".", "get_variable", "(", "\"eps\"", ",", "(", ")", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0", ")", ")", "\n", "param_noise_scale", "=", "tf", ".", "get_variable", "(", "\"param_noise_scale\"", ",", "(", ")", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.01", ")", ",", "trainable", "=", "False", ")", "\n", "param_noise_threshold", "=", "tf", ".", "get_variable", "(", "\"param_noise_threshold\"", ",", "(", ")", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.05", ")", ",", "trainable", "=", "False", ")", "\n", "\n", "# Unmodified Q.", "\n", "q_values", "=", "q_func", "(", "observations_ph", ".", "get", "(", ")", ",", "num_actions", ",", "scope", "=", "\"q_func\"", ")", "\n", "\n", "# Perturbable Q used for the actual rollout.", "\n", "q_values_perturbed", "=", "q_func", "(", "observations_ph", ".", "get", "(", ")", ",", "num_actions", ",", "scope", "=", "\"perturbed_q_func\"", ")", "\n", "# We have to wrap this code into a function due to the way tf.cond() works. See", "\n", "# https://stackoverflow.com/questions/37063952/confused-by-the-behavior-of-tf-cond for", "\n", "# a more detailed discussion.", "\n", "def", "perturb_vars", "(", "original_scope", ",", "perturbed_scope", ")", ":", "\n", "            ", "all_vars", "=", "scope_vars", "(", "absolute_scope_name", "(", "original_scope", ")", ")", "\n", "all_perturbed_vars", "=", "scope_vars", "(", "absolute_scope_name", "(", "perturbed_scope", ")", ")", "\n", "assert", "len", "(", "all_vars", ")", "==", "len", "(", "all_perturbed_vars", ")", "\n", "perturb_ops", "=", "[", "]", "\n", "for", "var", ",", "perturbed_var", "in", "zip", "(", "all_vars", ",", "all_perturbed_vars", ")", ":", "\n", "                ", "if", "param_noise_filter_func", "(", "perturbed_var", ")", ":", "\n", "# Perturb this variable.", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "perturbed_var", ",", "var", "+", "tf", ".", "random_normal", "(", "shape", "=", "tf", ".", "shape", "(", "var", ")", ",", "mean", "=", "0.", ",", "stddev", "=", "param_noise_scale", ")", ")", "\n", "", "else", ":", "\n", "# Do not perturb, just assign.", "\n", "                    ", "op", "=", "tf", ".", "assign", "(", "perturbed_var", ",", "var", ")", "\n", "", "perturb_ops", ".", "append", "(", "op", ")", "\n", "", "assert", "len", "(", "perturb_ops", ")", "==", "len", "(", "all_vars", ")", "\n", "return", "tf", ".", "group", "(", "*", "perturb_ops", ")", "\n", "\n", "# Set up functionality to re-compute `param_noise_scale`. This perturbs yet another copy", "\n", "# of the network and measures the effect of that perturbation in action space. If the perturbation", "\n", "# is too big, reduce scale of perturbation, otherwise increase.", "\n", "", "q_values_adaptive", "=", "q_func", "(", "observations_ph", ".", "get", "(", ")", ",", "num_actions", ",", "scope", "=", "\"adaptive_q_func\"", ")", "\n", "perturb_for_adaption", "=", "perturb_vars", "(", "original_scope", "=", "\"q_func\"", ",", "perturbed_scope", "=", "\"adaptive_q_func\"", ")", "\n", "kl", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "softmax", "(", "q_values", ")", "*", "(", "tf", ".", "log", "(", "tf", ".", "nn", ".", "softmax", "(", "q_values", ")", ")", "-", "tf", ".", "log", "(", "tf", ".", "nn", ".", "softmax", "(", "q_values_adaptive", ")", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "mean_kl", "=", "tf", ".", "reduce_mean", "(", "kl", ")", "\n", "def", "update_scale", "(", ")", ":", "\n", "            ", "with", "tf", ".", "control_dependencies", "(", "[", "perturb_for_adaption", "]", ")", ":", "\n", "                ", "update_scale_expr", "=", "tf", ".", "cond", "(", "mean_kl", "<", "param_noise_threshold", ",", "\n", "lambda", ":", "param_noise_scale", ".", "assign", "(", "param_noise_scale", "*", "1.01", ")", ",", "\n", "lambda", ":", "param_noise_scale", ".", "assign", "(", "param_noise_scale", "/", "1.01", ")", ",", "\n", ")", "\n", "", "return", "update_scale_expr", "\n", "\n", "# Functionality to update the threshold for parameter space noise.", "\n", "", "update_param_noise_threshold_expr", "=", "param_noise_threshold", ".", "assign", "(", "tf", ".", "cond", "(", "update_param_noise_threshold_ph", ">=", "0", ",", "\n", "lambda", ":", "update_param_noise_threshold_ph", ",", "lambda", ":", "param_noise_threshold", ")", ")", "\n", "\n", "# Put everything together.", "\n", "deterministic_actions", "=", "tf", ".", "argmax", "(", "q_values_perturbed", ",", "axis", "=", "1", ")", "\n", "batch_size", "=", "tf", ".", "shape", "(", "observations_ph", ".", "get", "(", ")", ")", "[", "0", "]", "\n", "random_actions", "=", "tf", ".", "random_uniform", "(", "tf", ".", "stack", "(", "[", "batch_size", "]", ")", ",", "minval", "=", "0", ",", "maxval", "=", "num_actions", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "chose_random", "=", "tf", ".", "random_uniform", "(", "tf", ".", "stack", "(", "[", "batch_size", "]", ")", ",", "minval", "=", "0", ",", "maxval", "=", "1", ",", "dtype", "=", "tf", ".", "float32", ")", "<", "eps", "\n", "stochastic_actions", "=", "tf", ".", "where", "(", "chose_random", ",", "random_actions", ",", "deterministic_actions", ")", "\n", "\n", "output_actions", "=", "tf", ".", "cond", "(", "stochastic_ph", ",", "lambda", ":", "stochastic_actions", ",", "lambda", ":", "deterministic_actions", ")", "\n", "update_eps_expr", "=", "eps", ".", "assign", "(", "tf", ".", "cond", "(", "update_eps_ph", ">=", "0", ",", "lambda", ":", "update_eps_ph", ",", "lambda", ":", "eps", ")", ")", "\n", "updates", "=", "[", "\n", "update_eps_expr", ",", "\n", "tf", ".", "cond", "(", "reset_ph", ",", "lambda", ":", "perturb_vars", "(", "original_scope", "=", "\"q_func\"", ",", "perturbed_scope", "=", "\"perturbed_q_func\"", ")", ",", "lambda", ":", "tf", ".", "group", "(", "*", "[", "]", ")", ")", ",", "\n", "tf", ".", "cond", "(", "update_param_noise_scale_ph", ",", "lambda", ":", "update_scale", "(", ")", ",", "lambda", ":", "tf", ".", "Variable", "(", "0.", ",", "trainable", "=", "False", ")", ")", ",", "\n", "update_param_noise_threshold_expr", ",", "\n", "]", "\n", "_act", "=", "U", ".", "function", "(", "inputs", "=", "[", "observations_ph", ",", "stochastic_ph", ",", "update_eps_ph", ",", "reset_ph", ",", "update_param_noise_threshold_ph", ",", "update_param_noise_scale_ph", "]", ",", "\n", "outputs", "=", "output_actions", ",", "\n", "givens", "=", "{", "update_eps_ph", ":", "-", "1.0", ",", "stochastic_ph", ":", "True", ",", "reset_ph", ":", "False", ",", "update_param_noise_threshold_ph", ":", "False", ",", "update_param_noise_scale_ph", ":", "False", "}", ",", "\n", "updates", "=", "updates", ")", "\n", "def", "act", "(", "ob", ",", "reset", "=", "False", ",", "update_param_noise_threshold", "=", "False", ",", "update_param_noise_scale", "=", "False", ",", "stochastic", "=", "True", ",", "update_eps", "=", "-", "1", ")", ":", "\n", "            ", "return", "_act", "(", "ob", ",", "stochastic", ",", "update_eps", ",", "reset", ",", "update_param_noise_threshold", ",", "update_param_noise_scale", ")", "\n", "", "return", "act", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.build_train": [[317, 450], ["build_graph.build_act_with_param_noise", "build_graph.build_act", "tensorflow.variable_scope", "make_obs_ph", "tensorflow.placeholder", "tensorflow.placeholder", "make_obs_ph", "tensorflow.placeholder", "tensorflow.placeholder", "q_func", "tensorflow.get_collection", "q_func", "tensorflow.get_collection", "tensorflow.reduce_sum", "baselines.huber_loss", "tensorflow.reduce_mean", "zip", "tensorflow.group", "baselines.function", "baselines.function", "baselines.function", "make_obs_ph.get", "make_obs_ph.get", "q_func", "tensorflow.argmax", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.stop_gradient", "optimizer.compute_gradients", "enumerate", "optimizer.apply_gradients", "optimizer.minimize", "sorted", "sorted", "tf.group.append", "tensorflow.one_hot", "make_obs_ph.get", "var_target.assign", "tensorflow.one_hot", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope", "tensorflow.clip_by_norm"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.build_act_with_param_noise", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.build_graph.build_act", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.huber_loss", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.MpiAdamOptimizer.compute_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.minimize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["", "", "def", "build_train", "(", "make_obs_ph", ",", "q_func", ",", "num_actions", ",", "optimizer", ",", "grad_norm_clipping", "=", "None", ",", "gamma", "=", "1.0", ",", "\n", "double_q", "=", "True", ",", "scope", "=", "\"deepq\"", ",", "reuse", "=", "None", ",", "param_noise", "=", "False", ",", "param_noise_filter_func", "=", "None", ")", ":", "\n", "    ", "\"\"\"Creates the train function:\n\n    Parameters\n    ----------\n    make_obs_ph: str -> tf.placeholder or TfInput\n        a function that takes a name and creates a placeholder of input with that name\n    q_func: (tf.Variable, int, str, bool) -> tf.Variable\n        the model that takes the following inputs:\n            observation_in: object\n                the output of observation placeholder\n            num_actions: int\n                number of actions\n            scope: str\n            reuse: bool\n                should be passed to outer variable scope\n        and returns a tensor of shape (batch_size, num_actions) with values of every action.\n    num_actions: int\n        number of actions\n    reuse: bool\n        whether or not to reuse the graph variables\n    optimizer: tf.train.Optimizer\n        optimizer to use for the Q-learning objective.\n    grad_norm_clipping: float or None\n        clip gradient norms to this value. If None no clipping is performed.\n    gamma: float\n        discount rate.\n    double_q: bool\n        if true will use Double Q Learning (https://arxiv.org/abs/1509.06461).\n        In general it is a good idea to keep it enabled.\n    scope: str or VariableScope\n        optional scope for variable_scope.\n    reuse: bool or None\n        whether or not the variables should be reused. To be able to reuse the scope must be given.\n    param_noise: bool\n        whether or not to use parameter space noise (https://arxiv.org/abs/1706.01905)\n    param_noise_filter_func: tf.Variable -> bool\n        function that decides whether or not a variable should be perturbed. Only applicable\n        if param_noise is True. If set to None, default_param_noise_filter is used by default.\n\n    Returns\n    -------\n    act: (tf.Variable, bool, float) -> tf.Variable\n        function to select and action given observation.\n`       See the top of the file for details.\n    train: (object, np.array, np.array, object, np.array, np.array) -> np.array\n        optimize the error in Bellman's equation.\n`       See the top of the file for details.\n    update_target: () -> ()\n        copy the parameters from optimized Q function to the target Q function.\n`       See the top of the file for details.\n    debug: {str: function}\n        a bunch of functions to print debug data like q_values.\n    \"\"\"", "\n", "if", "param_noise", ":", "\n", "        ", "act_f", "=", "build_act_with_param_noise", "(", "make_obs_ph", ",", "q_func", ",", "num_actions", ",", "scope", "=", "scope", ",", "reuse", "=", "reuse", ",", "\n", "param_noise_filter_func", "=", "param_noise_filter_func", ")", "\n", "", "else", ":", "\n", "        ", "act_f", "=", "build_act", "(", "make_obs_ph", ",", "q_func", ",", "num_actions", ",", "scope", "=", "scope", ",", "reuse", "=", "reuse", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "# set up placeholders", "\n", "        ", "obs_t_input", "=", "make_obs_ph", "(", "\"obs_t\"", ")", "\n", "act_t_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "name", "=", "\"action\"", ")", "\n", "rew_t_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"reward\"", ")", "\n", "obs_tp1_input", "=", "make_obs_ph", "(", "\"obs_tp1\"", ")", "\n", "done_mask_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"done\"", ")", "\n", "importance_weights_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ",", "name", "=", "\"weight\"", ")", "\n", "\n", "# q network evaluation", "\n", "q_t", "=", "q_func", "(", "obs_t_input", ".", "get", "(", ")", ",", "num_actions", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ")", "# reuse parameters from act", "\n", "q_func_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "+", "\"/q_func\"", ")", "\n", "\n", "# target q network evalution", "\n", "q_tp1", "=", "q_func", "(", "obs_tp1_input", ".", "get", "(", ")", ",", "num_actions", ",", "scope", "=", "\"target_q_func\"", ")", "\n", "target_q_func_vars", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "+", "\"/target_q_func\"", ")", "\n", "\n", "# q scores for actions which we know were selected in the given state.", "\n", "q_t_selected", "=", "tf", ".", "reduce_sum", "(", "q_t", "*", "tf", ".", "one_hot", "(", "act_t_ph", ",", "num_actions", ")", ",", "1", ")", "\n", "\n", "# compute estimate of best possible value starting from state at t + 1", "\n", "if", "double_q", ":", "\n", "            ", "q_tp1_using_online_net", "=", "q_func", "(", "obs_tp1_input", ".", "get", "(", ")", ",", "num_actions", ",", "scope", "=", "\"q_func\"", ",", "reuse", "=", "True", ")", "\n", "q_tp1_best_using_online_net", "=", "tf", ".", "argmax", "(", "q_tp1_using_online_net", ",", "1", ")", "\n", "q_tp1_best", "=", "tf", ".", "reduce_sum", "(", "q_tp1", "*", "tf", ".", "one_hot", "(", "q_tp1_best_using_online_net", ",", "num_actions", ")", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "q_tp1_best", "=", "tf", ".", "reduce_max", "(", "q_tp1", ",", "1", ")", "\n", "", "q_tp1_best_masked", "=", "(", "1.0", "-", "done_mask_ph", ")", "*", "q_tp1_best", "\n", "\n", "# compute RHS of bellman equation", "\n", "q_t_selected_target", "=", "rew_t_ph", "+", "gamma", "*", "q_tp1_best_masked", "\n", "\n", "# compute the error (potentially clipped)", "\n", "td_error", "=", "q_t_selected", "-", "tf", ".", "stop_gradient", "(", "q_t_selected_target", ")", "\n", "errors", "=", "U", ".", "huber_loss", "(", "td_error", ")", "\n", "weighted_error", "=", "tf", ".", "reduce_mean", "(", "importance_weights_ph", "*", "errors", ")", "\n", "\n", "# compute optimization op (potentially with gradient clipping)", "\n", "if", "grad_norm_clipping", "is", "not", "None", ":", "\n", "            ", "gradients", "=", "optimizer", ".", "compute_gradients", "(", "weighted_error", ",", "var_list", "=", "q_func_vars", ")", "\n", "for", "i", ",", "(", "grad", ",", "var", ")", "in", "enumerate", "(", "gradients", ")", ":", "\n", "                ", "if", "grad", "is", "not", "None", ":", "\n", "                    ", "gradients", "[", "i", "]", "=", "(", "tf", ".", "clip_by_norm", "(", "grad", ",", "grad_norm_clipping", ")", ",", "var", ")", "\n", "", "", "optimize_expr", "=", "optimizer", ".", "apply_gradients", "(", "gradients", ")", "\n", "", "else", ":", "\n", "            ", "optimize_expr", "=", "optimizer", ".", "minimize", "(", "weighted_error", ",", "var_list", "=", "q_func_vars", ")", "\n", "\n", "# update_target_fn will be called periodically to copy Q network to target Q network", "\n", "", "update_target_expr", "=", "[", "]", "\n", "for", "var", ",", "var_target", "in", "zip", "(", "sorted", "(", "q_func_vars", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ",", "\n", "sorted", "(", "target_q_func_vars", ",", "key", "=", "lambda", "v", ":", "v", ".", "name", ")", ")", ":", "\n", "            ", "update_target_expr", ".", "append", "(", "var_target", ".", "assign", "(", "var", ")", ")", "\n", "", "update_target_expr", "=", "tf", ".", "group", "(", "*", "update_target_expr", ")", "\n", "\n", "# Create callable functions", "\n", "train", "=", "U", ".", "function", "(", "\n", "inputs", "=", "[", "\n", "obs_t_input", ",", "\n", "act_t_ph", ",", "\n", "rew_t_ph", ",", "\n", "obs_tp1_input", ",", "\n", "done_mask_ph", ",", "\n", "importance_weights_ph", "\n", "]", ",", "\n", "outputs", "=", "td_error", ",", "\n", "updates", "=", "[", "optimize_expr", "]", "\n", ")", "\n", "update_target", "=", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "update_target_expr", "]", ")", "\n", "\n", "q_values", "=", "U", ".", "function", "(", "[", "obs_t_input", "]", ",", "q_t", ")", "\n", "\n", "return", "act_f", ",", "train", ",", "update_target", ",", "{", "'q_values'", ":", "q_values", "}", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.ReplayBuffer.__init__": [[8, 20], ["None"], "methods", ["None"], ["        ", "\"\"\"Creates a replay buffer.\n\n        Args:\n            buffer_shapes (dict of ints): the shape for all buffers that are used in the replay\n                buffer\n            size_in_transitions (int): the size of the buffer, measured in transitions\n            T (int): the time horizon for episodes\n            sample_transitions (function): a function that samples from the replay buffer\n        \"\"\"", "\n", "self", ".", "buffer_shapes", "=", "buffer_shapes", "\n", "self", ".", "size", "=", "size_in_transitions", "//", "T", "\n", "self", ".", "T", "=", "T", "\n", "self", ".", "sample_transitions", "=", "sample_transitions", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.ReplayBuffer.__len__": [[21, 23], ["len"], "methods", ["None"], ["\n", "# self.buffers is {key: array(size_in_episodes x T or T+1 x dim_key)}", "\n", "self", ".", "buffers", "=", "{", "key", ":", "np", ".", "empty", "(", "[", "self", ".", "size", ",", "*", "shape", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.ReplayBuffer.add": [[24, 32], ["len", "replay_buffer.ReplayBuffer._storage.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["for", "key", ",", "shape", "in", "buffer_shapes", ".", "items", "(", ")", "}", "\n", "\n", "# memory management", "\n", "self", ".", "current_size", "=", "0", "\n", "self", ".", "n_transitions_stored", "=", "0", "\n", "\n", "self", ".", "lock", "=", "threading", ".", "Lock", "(", ")", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.ReplayBuffer._encode_sample": [[33, 44], ["obses_t.append", "actions.append", "rewards.append", "obses_tp1.append", "dones.append", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["def", "full", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "==", "self", ".", "size", "\n", "\n", "", "", "def", "sample", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Returns a dict {key: array(batch_size x shapes[key])}\n        \"\"\"", "\n", "buffers", "=", "{", "}", "\n", "\n", "with", "self", ".", "lock", ":", "\n", "            ", "assert", "self", ".", "current_size", ">", "0", "\n", "for", "key", "in", "self", ".", "buffers", ".", "keys", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.ReplayBuffer.sample": [[45, 69], ["replay_buffer.ReplayBuffer._encode_sample", "random.randint", "range", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.ReplayBuffer._encode_sample"], ["                ", "buffers", "[", "key", "]", "=", "self", ".", "buffers", "[", "key", "]", "[", ":", "self", ".", "current_size", "]", "\n", "\n", "", "", "buffers", "[", "'o_2'", "]", "=", "buffers", "[", "'o'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "buffers", "[", "'ag_2'", "]", "=", "buffers", "[", "'ag'", "]", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n", "transitions", "=", "self", ".", "sample_transitions", "(", "buffers", ",", "batch_size", ")", "\n", "\n", "for", "key", "in", "(", "[", "'r'", ",", "'o_2'", ",", "'ag_2'", "]", "+", "list", "(", "self", ".", "buffers", ".", "keys", "(", ")", ")", ")", ":", "\n", "            ", "assert", "key", "in", "transitions", ",", "\"key %s missing from transitions\"", "%", "key", "\n", "\n", "", "return", "transitions", "\n", "\n", "", "def", "store_episode", "(", "self", ",", "episode_batch", ")", ":", "\n", "        ", "\"\"\"episode_batch: array(batch_size x (T or T+1) x dim_key)\n        \"\"\"", "\n", "batch_sizes", "=", "[", "len", "(", "episode_batch", "[", "key", "]", ")", "for", "key", "in", "episode_batch", ".", "keys", "(", ")", "]", "\n", "assert", "np", ".", "all", "(", "np", ".", "array", "(", "batch_sizes", ")", "==", "batch_sizes", "[", "0", "]", ")", "\n", "batch_size", "=", "batch_sizes", "[", "0", "]", "\n", "\n", "with", "self", ".", "lock", ":", "\n", "            ", "idxs", "=", "self", ".", "_get_storage_idx", "(", "batch_size", ")", "\n", "\n", "# load inputs into buffers", "\n", "for", "key", "in", "self", ".", "buffers", ".", "keys", "(", ")", ":", "\n", "                ", "self", ".", "buffers", "[", "key", "]", "[", "idxs", "]", "=", "episode_batch", "[", "key", "]", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.__init__": [[72, 99], ["replay_buffer.ReplayBuffer.__init__", "baselines.common.segment_tree.SumSegmentTree", "baselines.common.segment_tree.MinSegmentTree"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["\n", "", "", "def", "get_current_episode_size", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "\n", "\n", "", "", "def", "get_current_size", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "current_size", "*", "self", ".", "T", "\n", "\n", "", "", "def", "get_transitions_stored", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "return", "self", ".", "n_transitions_stored", "\n", "\n", "", "", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "with", "self", ".", "lock", ":", "\n", "            ", "self", ".", "current_size", "=", "0", "\n", "\n", "", "", "def", "_get_storage_idx", "(", "self", ",", "inc", "=", "None", ")", ":", "\n", "        ", "inc", "=", "inc", "or", "1", "# size increment", "\n", "assert", "inc", "<=", "self", ".", "size", ",", "\"Batch committed to replay is too large!\"", "\n", "# go consecutively until you hit the end, and then go randomly.", "\n", "if", "self", ".", "current_size", "+", "inc", "<=", "self", ".", "size", ":", "\n", "            ", "idx", "=", "np", ".", "arange", "(", "self", ".", "current_size", ",", "self", ".", "current_size", "+", "inc", ")", "\n", "", "elif", "self", ".", "current_size", "<", "self", ".", "size", ":", "\n", "            ", "overflow", "=", "inc", "-", "(", "self", ".", "size", "-", "self", ".", "current_size", ")", "\n", "idx_a", "=", "np", ".", "arange", "(", "self", ".", "current_size", ",", "self", ".", "size", ")", "\n", "idx_b", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "current_size", ",", "overflow", ")", "\n", "idx", "=", "np", ".", "concatenate", "(", "[", "idx_a", ",", "idx_b", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add": [[100, 106], ["replay_buffer.ReplayBuffer.add"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add"], ["", "else", ":", "\n", "            ", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "self", ".", "size", ",", "inc", ")", "\n", "\n", "# update replay size", "\n", "", "self", ".", "current_size", "=", "min", "(", "self", ".", "size", ",", "self", ".", "current_size", "+", "inc", ")", "\n", "\n", "if", "inc", "==", "1", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer._sample_proportional": [[107, 116], ["replay_buffer.PrioritizedReplayBuffer._it_sum.sum", "range", "replay_buffer.PrioritizedReplayBuffer._it_sum.find_prefixsum_idx", "res.append", "len", "random.random"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["            ", "idx", "=", "idx", "[", "0", "]", "\n", "", "return", "idx", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.sample": [[117, 168], ["replay_buffer.PrioritizedReplayBuffer._sample_proportional", "numpy.array", "replay_buffer.PrioritizedReplayBuffer._encode_sample", "tuple", "replay_buffer.PrioritizedReplayBuffer._it_min.min", "replay_buffer.PrioritizedReplayBuffer._it_sum.sum", "numpy.array.append", "len", "replay_buffer.PrioritizedReplayBuffer._it_sum.sum", "list", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer._sample_proportional", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.ReplayBuffer._encode_sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.update_priorities": [[169, 192], ["zip", "len", "len", "max", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.__init__.wrap_atari_dqn": [[6, 9], ["wrap_deepmind"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.wrap_deepmind"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.TfInput.__init__": [[10, 16], ["None"], "methods", ["None"], ["", "def", "cat_entropy", "(", "logits", ")", ":", "\n", "    ", "a0", "=", "logits", "-", "tf", ".", "reduce_max", "(", "logits", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "z0", "=", "tf", ".", "reduce_sum", "(", "ea0", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "tf", ".", "reduce_sum", "(", "p0", "*", "(", "tf", ".", "log", "(", "z0", ")", "-", "a0", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.TfInput.get": [[17, 22], ["None"], "methods", ["None"], ["", "def", "cat_entropy_softmax", "(", "p0", ")", ":", "\n", "    ", "return", "-", "tf", ".", "reduce_sum", "(", "p0", "*", "tf", ".", "log", "(", "p0", "+", "1e-6", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "def", "ortho_init", "(", "scale", "=", "1.0", ")", ":", "\n", "    ", "def", "_ortho_init", "(", "shape", ",", "dtype", ",", "partition_info", "=", "None", ")", ":", "\n", "#lasagne ortho init for tf", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.TfInput.make_feed_dict": [[23, 26], ["None"], "methods", ["None"], ["        ", "shape", "=", "tuple", "(", "shape", ")", "\n", "if", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "flat_shape", "=", "shape", "\n", "", "elif", "len", "(", "shape", ")", "==", "4", ":", "# assumes NHWC", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.PlaceholderTfInput.__init__": [[29, 33], ["utils.TfInput.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["            ", "raise", "NotImplementedError", "\n", "", "a", "=", "np", ".", "random", ".", "normal", "(", "0.0", ",", "1.0", ",", "flat_shape", ")", "\n", "u", ",", "_", ",", "v", "=", "np", ".", "linalg", ".", "svd", "(", "a", ",", "full_matrices", "=", "False", ")", "\n", "q", "=", "u", "if", "u", ".", "shape", "==", "flat_shape", "else", "v", "# pick the one with the correct shape", "\n", "q", "=", "q", ".", "reshape", "(", "shape", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.PlaceholderTfInput.get": [[34, 36], ["None"], "methods", ["None"], ["return", "(", "scale", "*", "q", "[", ":", "shape", "[", "0", "]", ",", ":", "shape", "[", "1", "]", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "return", "_ortho_init", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.PlaceholderTfInput.make_feed_dict": [[37, 39], ["baselines.common.tf_util.adjust_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.adjust_shape"], ["", "def", "conv", "(", "x", ",", "scope", ",", "*", ",", "nf", ",", "rf", ",", "stride", ",", "pad", "=", "'VALID'", ",", "init_scale", "=", "1.0", ",", "data_format", "=", "'NHWC'", ",", "one_dim_bias", "=", "False", ")", ":", "\n", "    ", "if", "data_format", "==", "'NHWC'", ":", "\n", "        ", "channel_ax", "=", "3", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.ObservationInput.__init__": [[42, 55], ["baselines.common.input.observation_input", "utils.PlaceholderTfInput.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.observation_input", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["", "elif", "data_format", "==", "'NCHW'", ":", "\n", "        ", "channel_ax", "=", "1", "\n", "strides", "=", "[", "1", ",", "1", ",", "stride", ",", "stride", "]", "\n", "bshape", "=", "[", "1", ",", "nf", ",", "1", ",", "1", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "bias_var_shape", "=", "[", "nf", "]", "if", "one_dim_bias", "else", "[", "1", ",", "nf", ",", "1", ",", "1", "]", "\n", "nin", "=", "x", ".", "get_shape", "(", ")", "[", "channel_ax", "]", ".", "value", "\n", "wshape", "=", "[", "rf", ",", "rf", ",", "nin", ",", "nf", "]", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ")", ":", "\n", "        ", "w", "=", "tf", ".", "get_variable", "(", "\"w\"", ",", "wshape", ",", "initializer", "=", "ortho_init", "(", "init_scale", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "bias_var_shape", ",", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ")", "\n", "if", "not", "one_dim_bias", "and", "data_format", "==", "'NHWC'", ":", "\n", "            ", "b", "=", "tf", ".", "reshape", "(", "b", ",", "bshape", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.ObservationInput.get": [[56, 58], ["None"], "methods", ["None"], ["", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "w", ",", "strides", "=", "strides", ",", "padding", "=", "pad", ",", "data_format", "=", "data_format", ")", "+", "b", "\n", "\n", "", "", "def", "fc", "(", "x", ",", "scope", ",", "nh", ",", "*", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.enjoy_cartpole.main": [[6, 18], ["gym.make", "baselines.deepq.learn", "print", "gym.make.reset", "gym.make.render", "gym.make.step", "deepq.learn."], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["def", "main", "(", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "\"CartPole-v0\"", ")", "\n", "act", "=", "deepq", ".", "learn", "(", "env", ",", "network", "=", "'mlp'", ",", "total_timesteps", "=", "0", ",", "load_path", "=", "\"cartpole_model.pkl\"", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "obs", ",", "done", "=", "env", ".", "reset", "(", ")", ",", "False", "\n", "episode_rew", "=", "0", "\n", "while", "not", "done", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "obs", ",", "rew", ",", "done", ",", "_", "=", "env", ".", "step", "(", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", ")", "\n", "episode_rew", "+=", "rew", "\n", "", "print", "(", "\"Episode reward\"", ",", "episode_rew", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.custom_cartpole.model": [[16, 23], ["tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.fully_connected"], "function", ["None"], ["def", "model", "(", "inpt", ",", "num_actions", ",", "scope", ",", "reuse", "=", "False", ")", ":", "\n", "    ", "\"\"\"This model takes as input an observation and returns values of all actions.\"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "        ", "out", "=", "inpt", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "64", ",", "activation_fn", "=", "tf", ".", "nn", ".", "tanh", ")", "\n", "out", "=", "layers", ".", "fully_connected", "(", "out", ",", "num_outputs", "=", "num_actions", ",", "activation_fn", "=", "None", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.enjoy_pong.main": [[5, 25], ["gym.make", "baselines.deepq.wrap_atari_dqn", "baselines.deepq.learn", "print", "deepq.wrap_atari_dqn.reset", "deepq.wrap_atari_dqn.render", "deepq.wrap_atari_dqn.step", "deepq.learn."], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.__init__.wrap_atari_dqn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["def", "main", "(", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "\"PongNoFrameskip-v4\"", ")", "\n", "env", "=", "deepq", ".", "wrap_atari_dqn", "(", "env", ")", "\n", "model", "=", "deepq", ".", "learn", "(", "\n", "env", ",", "\n", "\"conv_only\"", ",", "\n", "convs", "=", "[", "(", "32", ",", "8", ",", "4", ")", ",", "(", "64", ",", "4", ",", "2", ")", ",", "(", "64", ",", "3", ",", "1", ")", "]", ",", "\n", "hiddens", "=", "[", "256", "]", ",", "\n", "dueling", "=", "True", ",", "\n", "total_timesteps", "=", "0", "\n", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "obs", ",", "done", "=", "env", ".", "reset", "(", ")", ",", "False", "\n", "episode_rew", "=", "0", "\n", "while", "not", "done", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "obs", ",", "rew", ",", "done", ",", "_", "=", "env", ".", "step", "(", "model", "(", "obs", "[", "None", "]", ")", "[", "0", "]", ")", "\n", "episode_rew", "+=", "rew", "\n", "", "print", "(", "\"Episode reward\"", ",", "episode_rew", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.enjoy_mountaincar.main": [[7, 24], ["gym.make", "baselines.deepq.learn", "print", "baselines.common.models.mlp", "gym.make.reset", "gym.make.render", "gym.make.step", "deepq.learn."], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.mlp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["def", "main", "(", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "\"MountainCar-v0\"", ")", "\n", "act", "=", "deepq", ".", "learn", "(", "\n", "env", ",", "\n", "network", "=", "models", ".", "mlp", "(", "num_layers", "=", "1", ",", "num_hidden", "=", "64", ")", ",", "\n", "total_timesteps", "=", "0", ",", "\n", "load_path", "=", "'mountaincar_model.pkl'", "\n", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "obs", ",", "done", "=", "env", ".", "reset", "(", ")", ",", "False", "\n", "episode_rew", "=", "0", "\n", "while", "not", "done", ":", "\n", "            ", "env", ".", "render", "(", ")", "\n", "obs", ",", "rew", ",", "done", ",", "_", "=", "env", ".", "step", "(", "act", "(", "obs", "[", "None", "]", ")", "[", "0", "]", ")", "\n", "episode_rew", "+=", "rew", "\n", "", "print", "(", "\"Episode reward\"", ",", "episode_rew", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_mountaincar.main": [[7, 23], ["gym.make", "baselines.deepq.learn", "print", "deepq.learn.save", "baselines.common.models.mlp"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.mlp"], ["def", "main", "(", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "\"MountainCar-v0\"", ")", "\n", "# Enabling layer_norm here is import for parameter space noise!", "\n", "act", "=", "deepq", ".", "learn", "(", "\n", "env", ",", "\n", "network", "=", "models", ".", "mlp", "(", "num_hidden", "=", "64", ",", "num_layers", "=", "1", ")", ",", "\n", "lr", "=", "1e-3", ",", "\n", "total_timesteps", "=", "100000", ",", "\n", "buffer_size", "=", "50000", ",", "\n", "exploration_fraction", "=", "0.1", ",", "\n", "exploration_final_eps", "=", "0.1", ",", "\n", "print_freq", "=", "10", ",", "\n", "param_noise", "=", "True", "\n", ")", "\n", "print", "(", "\"Saving model to mountaincar_model.pkl\"", ")", "\n", "act", ".", "save", "(", "\"mountaincar_model.pkl\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_cartpole.callback": [[6, 10], ["sum"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["def", "callback", "(", "lcl", ",", "_glb", ")", ":", "\n", "# stop training if reward exceeds 199", "\n", "    ", "is_solved", "=", "lcl", "[", "'t'", "]", ">", "100", "and", "sum", "(", "lcl", "[", "'episode_rewards'", "]", "[", "-", "101", ":", "-", "1", "]", ")", "/", "100", ">=", "199", "\n", "return", "is_solved", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_cartpole.main": [[12, 27], ["gym.make", "baselines.deepq.learn", "print", "deepq.learn.save"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save"], ["", "def", "main", "(", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "\"CartPole-v0\"", ")", "\n", "act", "=", "deepq", ".", "learn", "(", "\n", "env", ",", "\n", "network", "=", "'mlp'", ",", "\n", "lr", "=", "1e-3", ",", "\n", "total_timesteps", "=", "100000", ",", "\n", "buffer_size", "=", "50000", ",", "\n", "exploration_fraction", "=", "0.1", ",", "\n", "exploration_final_eps", "=", "0.02", ",", "\n", "print_freq", "=", "10", ",", "\n", "callback", "=", "callback", "\n", ")", "\n", "print", "(", "\"Saving model to cartpole_model.pkl\"", ")", "\n", "act", ".", "save", "(", "\"cartpole_model.pkl\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_pong.main": [[7, 32], ["baselines.logger.configure", "baselines.common.atari_wrappers.make_atari", "baselines.bench.Monitor", "baselines.deepq.wrap_atari_dqn", "baselines.deepq.learn", "deepq.learn.save", "deepq.wrap_atari_dqn.close", "baselines.logger.get_dir", "int"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.make_atari", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.__init__.wrap_atari_dqn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["def", "main", "(", ")", ":", "\n", "    ", "logger", ".", "configure", "(", ")", "\n", "env", "=", "make_atari", "(", "'PongNoFrameskip-v4'", ")", "\n", "env", "=", "bench", ".", "Monitor", "(", "env", ",", "logger", ".", "get_dir", "(", ")", ")", "\n", "env", "=", "deepq", ".", "wrap_atari_dqn", "(", "env", ")", "\n", "\n", "model", "=", "deepq", ".", "learn", "(", "\n", "env", ",", "\n", "\"conv_only\"", ",", "\n", "convs", "=", "[", "(", "32", ",", "8", ",", "4", ")", ",", "(", "64", ",", "4", ",", "2", ")", ",", "(", "64", ",", "3", ",", "1", ")", "]", ",", "\n", "hiddens", "=", "[", "256", "]", ",", "\n", "dueling", "=", "True", ",", "\n", "lr", "=", "1e-4", ",", "\n", "total_timesteps", "=", "int", "(", "1e7", ")", ",", "\n", "buffer_size", "=", "10000", ",", "\n", "exploration_fraction", "=", "0.1", ",", "\n", "exploration_final_eps", "=", "0.01", ",", "\n", "train_freq", "=", "4", ",", "\n", "learning_starts", "=", "10000", ",", "\n", "target_network_update_freq", "=", "1000", ",", "\n", "gamma", "=", "0.99", ",", "\n", ")", "\n", "\n", "model", ".", "save", "(", "'pong_model.pkl'", ")", "\n", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.defaults.mujoco": [[1, 5], ["dict"], "function", ["None"], ["from", "baselines", ".", "common", ".", "models", "import", "mlp", ",", "cnn_small", "\n", "\n", "\n", "def", "atari", "(", ")", ":", "\n", "    ", "return", "dict", "(", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.gmatmul": [[3, 53], ["tf.transpose.get_shape", "tf.transpose.get_shape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "len", "len", "list", "list.remove", "list.insert", "tensorflow.transpose", "list", "list.remove", "list.insert", "tensorflow.transpose", "tf.transpose.get_shape", "tf.transpose.get_shape", "tensorflow.reshape", "tensorflow.matmul", "tensorflow.reshape", "tf.transpose.get_shape", "tf.transpose.get_shape", "range", "int", "range", "len", "len", "len", "list", "list.remove", "list.insert", "tensorflow.transpose", "list", "list.remove", "list.insert", "tensorflow.transpose", "tensorflow.matmul", "len", "len", "tf.transpose.get_shape", "tf.transpose.get_shape", "len", "range", "int", "range", "len", "len", "len", "len", "tf.transpose.get_shape", "tf.transpose.get_shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["def", "gmatmul", "(", "a", ",", "b", ",", "transpose_a", "=", "False", ",", "transpose_b", "=", "False", ",", "reduce_dim", "=", "None", ")", ":", "\n", "    ", "assert", "reduce_dim", "is", "not", "None", "\n", "\n", "# weird batch matmul", "\n", "if", "len", "(", "a", ".", "get_shape", "(", ")", ")", "==", "2", "and", "len", "(", "b", ".", "get_shape", "(", ")", ")", ">", "2", ":", "\n", "# reshape reduce_dim to the left most dim in b", "\n", "        ", "b_shape", "=", "b", ".", "get_shape", "(", ")", "\n", "if", "reduce_dim", "!=", "0", ":", "\n", "            ", "b_dims", "=", "list", "(", "range", "(", "len", "(", "b_shape", ")", ")", ")", "\n", "b_dims", ".", "remove", "(", "reduce_dim", ")", "\n", "b_dims", ".", "insert", "(", "0", ",", "reduce_dim", ")", "\n", "b", "=", "tf", ".", "transpose", "(", "b", ",", "b_dims", ")", "\n", "", "b_t_shape", "=", "b", ".", "get_shape", "(", ")", "\n", "b", "=", "tf", ".", "reshape", "(", "b", ",", "[", "int", "(", "b_shape", "[", "reduce_dim", "]", ")", ",", "-", "1", "]", ")", "\n", "result", "=", "tf", ".", "matmul", "(", "a", ",", "b", ",", "transpose_a", "=", "transpose_a", ",", "\n", "transpose_b", "=", "transpose_b", ")", "\n", "result", "=", "tf", ".", "reshape", "(", "result", ",", "b_t_shape", ")", "\n", "if", "reduce_dim", "!=", "0", ":", "\n", "            ", "b_dims", "=", "list", "(", "range", "(", "len", "(", "b_shape", ")", ")", ")", "\n", "b_dims", ".", "remove", "(", "0", ")", "\n", "b_dims", ".", "insert", "(", "reduce_dim", ",", "0", ")", "\n", "result", "=", "tf", ".", "transpose", "(", "result", ",", "b_dims", ")", "\n", "", "return", "result", "\n", "\n", "", "elif", "len", "(", "a", ".", "get_shape", "(", ")", ")", ">", "2", "and", "len", "(", "b", ".", "get_shape", "(", ")", ")", "==", "2", ":", "\n", "# reshape reduce_dim to the right most dim in a", "\n", "        ", "a_shape", "=", "a", ".", "get_shape", "(", ")", "\n", "outter_dim", "=", "len", "(", "a_shape", ")", "-", "1", "\n", "reduce_dim", "=", "len", "(", "a_shape", ")", "-", "reduce_dim", "-", "1", "\n", "if", "reduce_dim", "!=", "outter_dim", ":", "\n", "            ", "a_dims", "=", "list", "(", "range", "(", "len", "(", "a_shape", ")", ")", ")", "\n", "a_dims", ".", "remove", "(", "reduce_dim", ")", "\n", "a_dims", ".", "insert", "(", "outter_dim", ",", "reduce_dim", ")", "\n", "a", "=", "tf", ".", "transpose", "(", "a", ",", "a_dims", ")", "\n", "", "a_t_shape", "=", "a", ".", "get_shape", "(", ")", "\n", "a", "=", "tf", ".", "reshape", "(", "a", ",", "[", "-", "1", ",", "int", "(", "a_shape", "[", "reduce_dim", "]", ")", "]", ")", "\n", "result", "=", "tf", ".", "matmul", "(", "a", ",", "b", ",", "transpose_a", "=", "transpose_a", ",", "\n", "transpose_b", "=", "transpose_b", ")", "\n", "result", "=", "tf", ".", "reshape", "(", "result", ",", "a_t_shape", ")", "\n", "if", "reduce_dim", "!=", "outter_dim", ":", "\n", "            ", "a_dims", "=", "list", "(", "range", "(", "len", "(", "a_shape", ")", ")", ")", "\n", "a_dims", ".", "remove", "(", "outter_dim", ")", "\n", "a_dims", ".", "insert", "(", "reduce_dim", ",", "outter_dim", ")", "\n", "result", "=", "tf", ".", "transpose", "(", "result", ",", "a_dims", ")", "\n", "", "return", "result", "\n", "\n", "", "elif", "len", "(", "a", ".", "get_shape", "(", ")", ")", "==", "2", "and", "len", "(", "b", ".", "get_shape", "(", ")", ")", "==", "2", ":", "\n", "        ", "return", "tf", ".", "matmul", "(", "a", ",", "b", ",", "transpose_a", "=", "transpose_a", ",", "transpose_b", "=", "transpose_b", ")", "\n", "\n", "", "assert", "False", ",", "'something went wrong'", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.clipoutNeg": [[55, 58], ["tensorflow.cast"], "function", ["None"], ["", "def", "clipoutNeg", "(", "vec", ",", "threshold", "=", "1e-6", ")", ":", "\n", "    ", "mask", "=", "tf", ".", "cast", "(", "vec", ">", "threshold", ",", "tf", ".", "float32", ")", "\n", "return", "mask", "*", "vec", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.detectMinVal": [[60, 71], ["tensorflow.reduce_min", "tensorflow.reduce_max", "kfac_utils.clipoutNeg", "tensorflow.cond", "tensorflow.logical_or", "tensorflow.greater", "tensorflow.less", "tensorflow.Print", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.clipoutNeg"], ["", "def", "detectMinVal", "(", "input_mat", ",", "var", ",", "threshold", "=", "1e-6", ",", "name", "=", "''", ",", "debug", "=", "False", ")", ":", "\n", "    ", "eigen_min", "=", "tf", ".", "reduce_min", "(", "input_mat", ")", "\n", "eigen_max", "=", "tf", ".", "reduce_max", "(", "input_mat", ")", "\n", "eigen_ratio", "=", "eigen_max", "/", "eigen_min", "\n", "input_mat_clipped", "=", "clipoutNeg", "(", "input_mat", ",", "threshold", ")", "\n", "\n", "if", "debug", ":", "\n", "        ", "input_mat_clipped", "=", "tf", ".", "cond", "(", "tf", ".", "logical_or", "(", "tf", ".", "greater", "(", "eigen_ratio", ",", "0.", ")", ",", "tf", ".", "less", "(", "eigen_ratio", ",", "-", "500", ")", ")", ",", "lambda", ":", "input_mat_clipped", ",", "lambda", ":", "tf", ".", "Print", "(", "\n", "input_mat_clipped", ",", "[", "tf", ".", "convert_to_tensor", "(", "'screwed ratio '", "+", "name", "+", "' eigen values!!!'", ")", ",", "tf", ".", "convert_to_tensor", "(", "var", ".", "name", ")", ",", "eigen_min", ",", "eigen_max", ",", "eigen_ratio", "]", ")", ")", "\n", "\n", "", "return", "input_mat_clipped", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.factorReshape": [[73, 87], ["grad.get_shape", "tensorflow.reshape", "tensorflow.reshape", "len", "len", "tf.reshape.get_shape", "tf.reshape.get_shape", "len", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "factorReshape", "(", "Q", ",", "e", ",", "grad", ",", "facIndx", "=", "0", ",", "ftype", "=", "'act'", ")", ":", "\n", "    ", "grad_shape", "=", "grad", ".", "get_shape", "(", ")", "\n", "if", "ftype", "==", "'act'", ":", "\n", "        ", "assert", "e", ".", "get_shape", "(", ")", "[", "0", "]", "==", "grad_shape", "[", "facIndx", "]", "\n", "expanded_shape", "=", "[", "1", ",", "]", "*", "len", "(", "grad_shape", ")", "\n", "expanded_shape", "[", "facIndx", "]", "=", "-", "1", "\n", "e", "=", "tf", ".", "reshape", "(", "e", ",", "expanded_shape", ")", "\n", "", "if", "ftype", "==", "'grad'", ":", "\n", "        ", "assert", "e", ".", "get_shape", "(", ")", "[", "0", "]", "==", "grad_shape", "[", "len", "(", "grad_shape", ")", "-", "facIndx", "-", "1", "]", "\n", "expanded_shape", "=", "[", "1", ",", "]", "*", "len", "(", "grad_shape", ")", "\n", "expanded_shape", "[", "len", "(", "grad_shape", ")", "-", "facIndx", "-", "1", "]", "=", "-", "1", "\n", "e", "=", "tf", ".", "reshape", "(", "e", ",", "expanded_shape", ")", "\n", "\n", "", "return", "Q", ",", "e", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.__init__": [[15, 57], ["tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.Variable"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "learning_rate", "=", "0.01", ",", "momentum", "=", "0.9", ",", "clip_kl", "=", "0.01", ",", "kfac_update", "=", "2", ",", "stats_accum_iter", "=", "60", ",", "full_stats_init", "=", "False", ",", "cold_iter", "=", "100", ",", "cold_lr", "=", "None", ",", "is_async", "=", "False", ",", "async_stats", "=", "False", ",", "epsilon", "=", "1e-2", ",", "stats_decay", "=", "0.95", ",", "blockdiag_bias", "=", "False", ",", "channel_fac", "=", "False", ",", "factored_damping", "=", "False", ",", "approxT2", "=", "False", ",", "use_float64", "=", "False", ",", "weight_decay_dict", "=", "{", "}", ",", "max_grad_norm", "=", "0.5", ")", ":", "\n", "        ", "self", ".", "max_grad_norm", "=", "max_grad_norm", "\n", "self", ".", "_lr", "=", "learning_rate", "\n", "self", ".", "_momentum", "=", "momentum", "\n", "self", ".", "_clip_kl", "=", "clip_kl", "\n", "self", ".", "_channel_fac", "=", "channel_fac", "\n", "self", ".", "_kfac_update", "=", "kfac_update", "\n", "self", ".", "_async", "=", "is_async", "\n", "self", ".", "_async_stats", "=", "async_stats", "\n", "self", ".", "_epsilon", "=", "epsilon", "\n", "self", ".", "_stats_decay", "=", "stats_decay", "\n", "self", ".", "_blockdiag_bias", "=", "blockdiag_bias", "\n", "self", ".", "_approxT2", "=", "approxT2", "\n", "self", ".", "_use_float64", "=", "use_float64", "\n", "self", ".", "_factored_damping", "=", "factored_damping", "\n", "self", ".", "_cold_iter", "=", "cold_iter", "\n", "if", "cold_lr", "==", "None", ":", "\n", "# good heuristics", "\n", "            ", "self", ".", "_cold_lr", "=", "self", ".", "_lr", "# * 3.", "\n", "", "else", ":", "\n", "            ", "self", ".", "_cold_lr", "=", "cold_lr", "\n", "", "self", ".", "_stats_accum_iter", "=", "stats_accum_iter", "\n", "self", ".", "_weight_decay_dict", "=", "weight_decay_dict", "\n", "self", ".", "_diag_init_coeff", "=", "0.", "\n", "self", ".", "_full_stats_init", "=", "full_stats_init", "\n", "if", "not", "self", ".", "_full_stats_init", ":", "\n", "            ", "self", ".", "_stats_accum_iter", "=", "self", ".", "_cold_iter", "\n", "\n", "", "self", ".", "sgd_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "'KFAC/sgd_step'", ",", "trainable", "=", "False", ")", "\n", "self", ".", "global_step", "=", "tf", ".", "Variable", "(", "\n", "0", ",", "name", "=", "'KFAC/global_step'", ",", "trainable", "=", "False", ")", "\n", "self", ".", "cold_step", "=", "tf", ".", "Variable", "(", "0", ",", "name", "=", "'KFAC/cold_step'", ",", "trainable", "=", "False", ")", "\n", "self", ".", "factor_step", "=", "tf", ".", "Variable", "(", "\n", "0", ",", "name", "=", "'KFAC/factor_step'", ",", "trainable", "=", "False", ")", "\n", "self", ".", "stats_step", "=", "tf", ".", "Variable", "(", "\n", "0", ",", "name", "=", "'KFAC/stats_step'", ",", "trainable", "=", "False", ")", "\n", "self", ".", "vFv", "=", "tf", ".", "Variable", "(", "0.", ",", "name", "=", "'KFAC/vFv'", ",", "trainable", "=", "False", ")", "\n", "\n", "self", ".", "factors", "=", "{", "}", "\n", "self", ".", "param_vars", "=", "[", "]", "\n", "self", ".", "stats", "=", "{", "}", "\n", "self", ".", "stats_eigen", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getFactors": [[58, 182], ["tensorflow.get_default_graph", "zip", "kfac.KfacOptimizer.getFactors.searchFactors"], "methods", ["None"], ["", "def", "getFactors", "(", "self", ",", "g", ",", "varlist", ")", ":", "\n", "        ", "graph", "=", "tf", ".", "get_default_graph", "(", ")", "\n", "factorTensors", "=", "{", "}", "\n", "fpropTensors", "=", "[", "]", "\n", "bpropTensors", "=", "[", "]", "\n", "opTypes", "=", "[", "]", "\n", "fops", "=", "[", "]", "\n", "\n", "def", "searchFactors", "(", "gradient", ",", "graph", ")", ":", "\n", "# hard coded search stratergy", "\n", "            ", "bpropOp", "=", "gradient", ".", "op", "\n", "bpropOp_name", "=", "bpropOp", ".", "name", "\n", "\n", "bTensors", "=", "[", "]", "\n", "fTensors", "=", "[", "]", "\n", "\n", "# combining additive gradient, assume they are the same op type and", "\n", "# indepedent", "\n", "if", "'AddN'", "in", "bpropOp_name", ":", "\n", "                ", "factors", "=", "[", "]", "\n", "for", "g", "in", "gradient", ".", "op", ".", "inputs", ":", "\n", "                    ", "factors", ".", "append", "(", "searchFactors", "(", "g", ",", "graph", ")", ")", "\n", "", "op_names", "=", "[", "item", "[", "'opName'", "]", "for", "item", "in", "factors", "]", "\n", "# TO-DO: need to check all the attribute of the ops as well", "\n", "print", "(", "gradient", ".", "name", ")", "\n", "print", "(", "op_names", ")", "\n", "print", "(", "len", "(", "np", ".", "unique", "(", "op_names", ")", ")", ")", "\n", "assert", "len", "(", "np", ".", "unique", "(", "op_names", ")", ")", "==", "1", ",", "gradient", ".", "name", "+", "' is shared among different computation OPs'", "\n", "\n", "bTensors", "=", "reduce", "(", "lambda", "x", ",", "y", ":", "x", "+", "y", ",", "\n", "[", "item", "[", "'bpropFactors'", "]", "for", "item", "in", "factors", "]", ")", "\n", "if", "len", "(", "factors", "[", "0", "]", "[", "'fpropFactors'", "]", ")", ">", "0", ":", "\n", "                    ", "fTensors", "=", "reduce", "(", "\n", "lambda", "x", ",", "y", ":", "x", "+", "y", ",", "[", "item", "[", "'fpropFactors'", "]", "for", "item", "in", "factors", "]", ")", "\n", "", "fpropOp_name", "=", "op_names", "[", "0", "]", "\n", "fpropOp", "=", "factors", "[", "0", "]", "[", "'op'", "]", "\n", "", "else", ":", "\n", "                ", "fpropOp_name", "=", "re", ".", "search", "(", "\n", "'gradientsSampled(_[0-9]+|)/(.+?)_grad'", ",", "bpropOp_name", ")", ".", "group", "(", "2", ")", "\n", "fpropOp", "=", "graph", ".", "get_operation_by_name", "(", "fpropOp_name", ")", "\n", "if", "fpropOp", ".", "op_def", ".", "name", "in", "KFAC_OPS", ":", "\n", "# Known OPs", "\n", "###", "\n", "                    ", "bTensor", "=", "[", "\n", "i", "for", "i", "in", "bpropOp", ".", "inputs", "if", "'gradientsSampled'", "in", "i", ".", "name", "]", "[", "-", "1", "]", "\n", "bTensorShape", "=", "fpropOp", ".", "outputs", "[", "0", "]", ".", "get_shape", "(", ")", "\n", "if", "bTensor", ".", "get_shape", "(", ")", "[", "0", "]", ".", "value", "==", "None", ":", "\n", "                        ", "bTensor", ".", "set_shape", "(", "bTensorShape", ")", "\n", "", "bTensors", ".", "append", "(", "bTensor", ")", "\n", "###", "\n", "if", "fpropOp", ".", "op_def", ".", "name", "==", "'BiasAdd'", ":", "\n", "                        ", "fTensors", "=", "[", "]", "\n", "", "else", ":", "\n", "                        ", "fTensors", ".", "append", "(", "\n", "[", "i", "for", "i", "in", "fpropOp", ".", "inputs", "if", "param", ".", "op", ".", "name", "not", "in", "i", ".", "name", "]", "[", "0", "]", ")", "\n", "", "fpropOp_name", "=", "fpropOp", ".", "op_def", ".", "name", "\n", "", "else", ":", "\n", "# unknown OPs, block approximation used", "\n", "                    ", "bInputsList", "=", "[", "i", "for", "i", "in", "bpropOp", ".", "inputs", "[", "\n", "0", "]", ".", "op", ".", "inputs", "if", "'gradientsSampled'", "in", "i", ".", "name", "if", "'Shape'", "not", "in", "i", ".", "name", "]", "\n", "if", "len", "(", "bInputsList", ")", ">", "0", ":", "\n", "                        ", "bTensor", "=", "bInputsList", "[", "0", "]", "\n", "bTensorShape", "=", "fpropOp", ".", "outputs", "[", "0", "]", ".", "get_shape", "(", ")", "\n", "if", "len", "(", "bTensor", ".", "get_shape", "(", ")", ")", ">", "0", "and", "bTensor", ".", "get_shape", "(", ")", "[", "0", "]", ".", "value", "==", "None", ":", "\n", "                            ", "bTensor", ".", "set_shape", "(", "bTensorShape", ")", "\n", "", "bTensors", ".", "append", "(", "bTensor", ")", "\n", "", "fpropOp_name", "=", "opTypes", ".", "append", "(", "'UNK-'", "+", "fpropOp", ".", "op_def", ".", "name", ")", "\n", "\n", "", "", "return", "{", "'opName'", ":", "fpropOp_name", ",", "'op'", ":", "fpropOp", ",", "'fpropFactors'", ":", "fTensors", ",", "'bpropFactors'", ":", "bTensors", "}", "\n", "\n", "", "for", "t", ",", "param", "in", "zip", "(", "g", ",", "varlist", ")", ":", "\n", "            ", "if", "KFAC_DEBUG", ":", "\n", "                ", "print", "(", "(", "'get factor for '", "+", "param", ".", "name", ")", ")", "\n", "", "factors", "=", "searchFactors", "(", "t", ",", "graph", ")", "\n", "factorTensors", "[", "param", "]", "=", "factors", "\n", "\n", "########", "\n", "# check associated weights and bias for homogeneous coordinate representation", "\n", "# and check redundent factors", "\n", "# TO-DO: there may be a bug to detect associate bias and weights for", "\n", "# forking layer, e.g. in inception models.", "\n", "", "for", "param", "in", "varlist", ":", "\n", "            ", "factorTensors", "[", "param", "]", "[", "'assnWeights'", "]", "=", "None", "\n", "factorTensors", "[", "param", "]", "[", "'assnBias'", "]", "=", "None", "\n", "", "for", "param", "in", "varlist", ":", "\n", "            ", "if", "factorTensors", "[", "param", "]", "[", "'opName'", "]", "==", "'BiasAdd'", ":", "\n", "                ", "factorTensors", "[", "param", "]", "[", "'assnWeights'", "]", "=", "None", "\n", "for", "item", "in", "varlist", ":", "\n", "                    ", "if", "len", "(", "factorTensors", "[", "item", "]", "[", "'bpropFactors'", "]", ")", ">", "0", ":", "\n", "                        ", "if", "(", "set", "(", "factorTensors", "[", "item", "]", "[", "'bpropFactors'", "]", ")", "==", "set", "(", "factorTensors", "[", "param", "]", "[", "'bpropFactors'", "]", ")", ")", "and", "(", "len", "(", "factorTensors", "[", "item", "]", "[", "'fpropFactors'", "]", ")", ">", "0", ")", ":", "\n", "                            ", "factorTensors", "[", "param", "]", "[", "'assnWeights'", "]", "=", "item", "\n", "factorTensors", "[", "item", "]", "[", "'assnBias'", "]", "=", "param", "\n", "factorTensors", "[", "param", "]", "[", "'bpropFactors'", "]", "=", "factorTensors", "[", "\n", "item", "]", "[", "'bpropFactors'", "]", "\n", "\n", "########", "\n", "\n", "########", "\n", "# concatenate the additive gradients along the batch dimension, i.e.", "\n", "# assuming independence structure", "\n", "", "", "", "", "", "for", "key", "in", "[", "'fpropFactors'", ",", "'bpropFactors'", "]", ":", "\n", "            ", "for", "i", ",", "param", "in", "enumerate", "(", "varlist", ")", ":", "\n", "                ", "if", "len", "(", "factorTensors", "[", "param", "]", "[", "key", "]", ")", ">", "0", ":", "\n", "                    ", "if", "(", "key", "+", "'_concat'", ")", "not", "in", "factorTensors", "[", "param", "]", ":", "\n", "                        ", "name_scope", "=", "factorTensors", "[", "param", "]", "[", "key", "]", "[", "0", "]", ".", "name", ".", "split", "(", "':'", ")", "[", "\n", "0", "]", "\n", "with", "tf", ".", "name_scope", "(", "name_scope", ")", ":", "\n", "                            ", "factorTensors", "[", "param", "]", "[", "\n", "key", "+", "'_concat'", "]", "=", "tf", ".", "concat", "(", "factorTensors", "[", "param", "]", "[", "key", "]", ",", "0", ")", "\n", "", "", "", "else", ":", "\n", "                    ", "factorTensors", "[", "param", "]", "[", "key", "+", "'_concat'", "]", "=", "None", "\n", "", "for", "j", ",", "param2", "in", "enumerate", "(", "varlist", "[", "(", "i", "+", "1", ")", ":", "]", ")", ":", "\n", "                    ", "if", "(", "len", "(", "factorTensors", "[", "param", "]", "[", "key", "]", ")", ">", "0", ")", "and", "(", "set", "(", "factorTensors", "[", "param2", "]", "[", "key", "]", ")", "==", "set", "(", "factorTensors", "[", "param", "]", "[", "key", "]", ")", ")", ":", "\n", "                        ", "factorTensors", "[", "param2", "]", "[", "key", "]", "=", "factorTensors", "[", "param", "]", "[", "key", "]", "\n", "factorTensors", "[", "param2", "]", "[", "\n", "key", "+", "'_concat'", "]", "=", "factorTensors", "[", "param", "]", "[", "key", "+", "'_concat'", "]", "\n", "########", "\n", "\n", "", "", "", "", "if", "KFAC_DEBUG", ":", "\n", "            ", "for", "items", "in", "zip", "(", "varlist", ",", "fpropTensors", ",", "bpropTensors", ",", "opTypes", ")", ":", "\n", "                ", "print", "(", "(", "items", "[", "0", "]", ".", "name", ",", "factorTensors", "[", "item", "]", ")", ")", "\n", "", "", "self", ".", "factors", "=", "factorTensors", "\n", "return", "factorTensors", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getStats": [[183, 284], ["len", "tensorflow.device", "var.get_shape", "var.get_shape", "fpropFactor.get_shape", "bpropFactor.get_shape", "bpropFactor.get_shape", "tensorflow.Variable", "[].append", "tensorflow.Variable", "[].append", "var.get_shape", "var.get_shape", "fpropFactor.get_shape", "bpropFactor.get_shape", "bpropFactor.get_shape", "tensorflow.Variable", "[].append", "fpropFactor.get_shape", "tensorflow.diag", "tensorflow.ones", "tensorflow.diag", "tensorflow.diag", "tensorflow.ones", "tensorflow.ones", "bpropFactor.get_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "getStats", "(", "self", ",", "factors", ",", "varlist", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "stats", ")", "==", "0", ":", "\n", "# initialize stats variables on CPU because eigen decomp is", "\n", "# computed on CPU", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu'", ")", ":", "\n", "                ", "tmpStatsCache", "=", "{", "}", "\n", "\n", "# search for tensor factors and", "\n", "# use block diag approx for the bias units", "\n", "for", "var", "in", "varlist", ":", "\n", "                    ", "fpropFactor", "=", "factors", "[", "var", "]", "[", "'fpropFactors_concat'", "]", "\n", "bpropFactor", "=", "factors", "[", "var", "]", "[", "'bpropFactors_concat'", "]", "\n", "opType", "=", "factors", "[", "var", "]", "[", "'opName'", "]", "\n", "if", "opType", "==", "'Conv2D'", ":", "\n", "                        ", "Kh", "=", "var", ".", "get_shape", "(", ")", "[", "0", "]", "\n", "Kw", "=", "var", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "C", "=", "fpropFactor", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "\n", "Oh", "=", "bpropFactor", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "Ow", "=", "bpropFactor", ".", "get_shape", "(", ")", "[", "2", "]", "\n", "if", "Oh", "==", "1", "and", "Ow", "==", "1", "and", "self", ".", "_channel_fac", ":", "\n", "# factorization along the channels do not support", "\n", "# homogeneous coordinate", "\n", "                            ", "var_assnBias", "=", "factors", "[", "var", "]", "[", "'assnBias'", "]", "\n", "if", "var_assnBias", ":", "\n", "                                ", "factors", "[", "var", "]", "[", "'assnBias'", "]", "=", "None", "\n", "factors", "[", "var_assnBias", "]", "[", "'assnWeights'", "]", "=", "None", "\n", "##", "\n", "\n", "", "", "", "", "for", "var", "in", "varlist", ":", "\n", "                    ", "fpropFactor", "=", "factors", "[", "var", "]", "[", "'fpropFactors_concat'", "]", "\n", "bpropFactor", "=", "factors", "[", "var", "]", "[", "'bpropFactors_concat'", "]", "\n", "opType", "=", "factors", "[", "var", "]", "[", "'opName'", "]", "\n", "self", ".", "stats", "[", "var", "]", "=", "{", "'opName'", ":", "opType", ",", "\n", "'fprop_concat_stats'", ":", "[", "]", ",", "\n", "'bprop_concat_stats'", ":", "[", "]", ",", "\n", "'assnWeights'", ":", "factors", "[", "var", "]", "[", "'assnWeights'", "]", ",", "\n", "'assnBias'", ":", "factors", "[", "var", "]", "[", "'assnBias'", "]", ",", "\n", "}", "\n", "if", "fpropFactor", "is", "not", "None", ":", "\n", "                        ", "if", "fpropFactor", "not", "in", "tmpStatsCache", ":", "\n", "                            ", "if", "opType", "==", "'Conv2D'", ":", "\n", "                                ", "Kh", "=", "var", ".", "get_shape", "(", ")", "[", "0", "]", "\n", "Kw", "=", "var", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "C", "=", "fpropFactor", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "\n", "Oh", "=", "bpropFactor", ".", "get_shape", "(", ")", "[", "1", "]", "\n", "Ow", "=", "bpropFactor", ".", "get_shape", "(", ")", "[", "2", "]", "\n", "if", "Oh", "==", "1", "and", "Ow", "==", "1", "and", "self", ".", "_channel_fac", ":", "\n", "# factorization along the channels", "\n", "# assume independence between input channels and spatial", "\n", "# 2K-1 x 2K-1 covariance matrix and C x C covariance matrix", "\n", "# factorization along the channels do not", "\n", "# support homogeneous coordinate, assnBias", "\n", "# is always None", "\n", "                                    ", "fpropFactor2_size", "=", "Kh", "*", "Kw", "\n", "slot_fpropFactor_stats2", "=", "tf", ".", "Variable", "(", "tf", ".", "diag", "(", "tf", ".", "ones", "(", "\n", "[", "fpropFactor2_size", "]", ")", ")", "*", "self", ".", "_diag_init_coeff", ",", "name", "=", "'KFAC_STATS/'", "+", "fpropFactor", ".", "op", ".", "name", ",", "trainable", "=", "False", ")", "\n", "self", ".", "stats", "[", "var", "]", "[", "'fprop_concat_stats'", "]", ".", "append", "(", "\n", "slot_fpropFactor_stats2", ")", "\n", "\n", "fpropFactor_size", "=", "C", "\n", "", "else", ":", "\n", "# 2K-1 x 2K-1 x C x C covariance matrix", "\n", "# assume BHWC", "\n", "                                    ", "fpropFactor_size", "=", "Kh", "*", "Kw", "*", "C", "\n", "", "", "else", ":", "\n", "# D x D covariance matrix", "\n", "                                ", "fpropFactor_size", "=", "fpropFactor", ".", "get_shape", "(", ")", "[", "-", "1", "]", "\n", "\n", "# use homogeneous coordinate", "\n", "", "if", "not", "self", ".", "_blockdiag_bias", "and", "self", ".", "stats", "[", "var", "]", "[", "'assnBias'", "]", ":", "\n", "                                ", "fpropFactor_size", "+=", "1", "\n", "\n", "", "slot_fpropFactor_stats", "=", "tf", ".", "Variable", "(", "tf", ".", "diag", "(", "tf", ".", "ones", "(", "\n", "[", "fpropFactor_size", "]", ")", ")", "*", "self", ".", "_diag_init_coeff", ",", "name", "=", "'KFAC_STATS/'", "+", "fpropFactor", ".", "op", ".", "name", ",", "trainable", "=", "False", ")", "\n", "self", ".", "stats", "[", "var", "]", "[", "'fprop_concat_stats'", "]", ".", "append", "(", "\n", "slot_fpropFactor_stats", ")", "\n", "if", "opType", "!=", "'Conv2D'", ":", "\n", "                                ", "tmpStatsCache", "[", "fpropFactor", "]", "=", "self", ".", "stats", "[", "\n", "var", "]", "[", "'fprop_concat_stats'", "]", "\n", "", "", "else", ":", "\n", "                            ", "self", ".", "stats", "[", "var", "]", "[", "\n", "'fprop_concat_stats'", "]", "=", "tmpStatsCache", "[", "fpropFactor", "]", "\n", "\n", "", "", "if", "bpropFactor", "is", "not", "None", ":", "\n", "# no need to collect backward stats for bias vectors if", "\n", "# using homogeneous coordinates", "\n", "                        ", "if", "not", "(", "(", "not", "self", ".", "_blockdiag_bias", ")", "and", "self", ".", "stats", "[", "var", "]", "[", "'assnWeights'", "]", ")", ":", "\n", "                            ", "if", "bpropFactor", "not", "in", "tmpStatsCache", ":", "\n", "                                ", "slot_bpropFactor_stats", "=", "tf", ".", "Variable", "(", "tf", ".", "diag", "(", "tf", ".", "ones", "(", "[", "bpropFactor", ".", "get_shape", "(", "\n", ")", "[", "-", "1", "]", "]", ")", ")", "*", "self", ".", "_diag_init_coeff", ",", "name", "=", "'KFAC_STATS/'", "+", "bpropFactor", ".", "op", ".", "name", ",", "trainable", "=", "False", ")", "\n", "self", ".", "stats", "[", "var", "]", "[", "'bprop_concat_stats'", "]", ".", "append", "(", "\n", "slot_bpropFactor_stats", ")", "\n", "tmpStatsCache", "[", "bpropFactor", "]", "=", "self", ".", "stats", "[", "\n", "var", "]", "[", "'bprop_concat_stats'", "]", "\n", "", "else", ":", "\n", "                                ", "self", ".", "stats", "[", "var", "]", "[", "\n", "'bprop_concat_stats'", "]", "=", "tmpStatsCache", "[", "bpropFactor", "]", "\n", "\n", "", "", "", "", "", "", "return", "self", ".", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.compute_and_apply_stats": [[285, 292], ["kfac.KfacOptimizer.compute_stats", "kfac.KfacOptimizer.apply_stats", "tensorflow.trainable_variables"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.compute_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_stats"], ["", "def", "compute_and_apply_stats", "(", "self", ",", "loss_sampled", ",", "var_list", "=", "None", ")", ":", "\n", "        ", "varlist", "=", "var_list", "\n", "if", "varlist", "is", "None", ":", "\n", "            ", "varlist", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "", "stats", "=", "self", ".", "compute_stats", "(", "loss_sampled", ",", "var_list", "=", "varlist", ")", "\n", "return", "self", ".", "apply_stats", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.compute_stats": [[293, 439], ["tensorflow.gradients", "kfac.KfacOptimizer.getFactors", "kfac.KfacOptimizer.getStats", "tensorflow.trainable_variables", "tensorflow.Print", "int", "int", "list", "int", "updateOps.append", "tensorflow.reduce_sum.get_shape", "int", "tensorflow.to_float", "updateOps.append", "statsUpdates.keys", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "stats_var.get_shape", "tensorflow.shape", "fops.get_attr", "fops.get_attr", "int", "int", "int", "int", "int", "int", "tensorflow.matmul", "tensorflow.cast", "stats_var.get_shape", "tensorflow.shape", "tensorflow.matmul", "tensorflow.to_float", "var.get_shape", "tensorflow.extract_image_patches", "tensorflow.reduce_mean.get_shape", "tensorflow.concat", "tensorflow.concat", "len", "tensorflow.reduce_sum", "tensorflow.reduce_sum.get_shape", "tensorflow.reduce_sum.get_shape", "len", "tensorflow.batch_svd", "tensorflow.expand_dims", "tensorflow.reduce_mean.get_shape", "patches_k.set_shape", "patches_c.set_shape", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "print", "tensorflow.shape", "print", "tensorflow.reshape", "tensorflow.sqrt", "print", "tensorflow.ones", "print", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.ones", "tensorflow.shape", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getFactors", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getStats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape"], ["", "def", "compute_stats", "(", "self", ",", "loss_sampled", ",", "var_list", "=", "None", ")", ":", "\n", "        ", "varlist", "=", "var_list", "\n", "if", "varlist", "is", "None", ":", "\n", "            ", "varlist", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "\n", "", "gs", "=", "tf", ".", "gradients", "(", "loss_sampled", ",", "varlist", ",", "name", "=", "'gradientsSampled'", ")", "\n", "self", ".", "gs", "=", "gs", "\n", "factors", "=", "self", ".", "getFactors", "(", "gs", ",", "varlist", ")", "\n", "stats", "=", "self", ".", "getStats", "(", "factors", ",", "varlist", ")", "\n", "\n", "updateOps", "=", "[", "]", "\n", "statsUpdates", "=", "{", "}", "\n", "statsUpdates_cache", "=", "{", "}", "\n", "for", "var", "in", "varlist", ":", "\n", "            ", "opType", "=", "factors", "[", "var", "]", "[", "'opName'", "]", "\n", "fops", "=", "factors", "[", "var", "]", "[", "'op'", "]", "\n", "fpropFactor", "=", "factors", "[", "var", "]", "[", "'fpropFactors_concat'", "]", "\n", "fpropStats_vars", "=", "stats", "[", "var", "]", "[", "'fprop_concat_stats'", "]", "\n", "bpropFactor", "=", "factors", "[", "var", "]", "[", "'bpropFactors_concat'", "]", "\n", "bpropStats_vars", "=", "stats", "[", "var", "]", "[", "'bprop_concat_stats'", "]", "\n", "SVD_factors", "=", "{", "}", "\n", "for", "stats_var", "in", "fpropStats_vars", ":", "\n", "                ", "stats_var_dim", "=", "int", "(", "stats_var", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "if", "stats_var", "not", "in", "statsUpdates_cache", ":", "\n", "                    ", "old_fpropFactor", "=", "fpropFactor", "\n", "B", "=", "(", "tf", ".", "shape", "(", "fpropFactor", ")", "[", "0", "]", ")", "# batch size", "\n", "if", "opType", "==", "'Conv2D'", ":", "\n", "                        ", "strides", "=", "fops", ".", "get_attr", "(", "\"strides\"", ")", "\n", "padding", "=", "fops", ".", "get_attr", "(", "\"padding\"", ")", "\n", "convkernel_size", "=", "var", ".", "get_shape", "(", ")", "[", "0", ":", "3", "]", "\n", "\n", "KH", "=", "int", "(", "convkernel_size", "[", "0", "]", ")", "\n", "KW", "=", "int", "(", "convkernel_size", "[", "1", "]", ")", "\n", "C", "=", "int", "(", "convkernel_size", "[", "2", "]", ")", "\n", "flatten_size", "=", "int", "(", "KH", "*", "KW", "*", "C", ")", "\n", "\n", "Oh", "=", "int", "(", "bpropFactor", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "Ow", "=", "int", "(", "bpropFactor", ".", "get_shape", "(", ")", "[", "2", "]", ")", "\n", "\n", "if", "Oh", "==", "1", "and", "Ow", "==", "1", "and", "self", ".", "_channel_fac", ":", "\n", "# factorization along the channels", "\n", "# assume independence among input channels", "\n", "# factor = B x 1 x 1 x (KH xKW x C)", "\n", "# patches = B x Oh x Ow x (KH xKW x C)", "\n", "                            ", "if", "len", "(", "SVD_factors", ")", "==", "0", ":", "\n", "                                ", "if", "KFAC_DEBUG", ":", "\n", "                                    ", "print", "(", "(", "'approx %s act factor with rank-1 SVD factors'", "%", "(", "var", ".", "name", ")", ")", ")", "\n", "# find closest rank-1 approx to the feature map", "\n", "", "S", ",", "U", ",", "V", "=", "tf", ".", "batch_svd", "(", "tf", ".", "reshape", "(", "\n", "fpropFactor", ",", "[", "-", "1", ",", "KH", "*", "KW", ",", "C", "]", ")", ")", "\n", "# get rank-1 approx slides", "\n", "sqrtS1", "=", "tf", ".", "expand_dims", "(", "tf", ".", "sqrt", "(", "S", "[", ":", ",", "0", ",", "0", "]", ")", ",", "1", ")", "\n", "patches_k", "=", "U", "[", ":", ",", ":", ",", "0", "]", "*", "sqrtS1", "# B x KH*KW", "\n", "full_factor_shape", "=", "fpropFactor", ".", "get_shape", "(", ")", "\n", "patches_k", ".", "set_shape", "(", "\n", "[", "full_factor_shape", "[", "0", "]", ",", "KH", "*", "KW", "]", ")", "\n", "patches_c", "=", "V", "[", ":", ",", ":", ",", "0", "]", "*", "sqrtS1", "# B x C", "\n", "patches_c", ".", "set_shape", "(", "[", "full_factor_shape", "[", "0", "]", ",", "C", "]", ")", "\n", "SVD_factors", "[", "C", "]", "=", "patches_c", "\n", "SVD_factors", "[", "KH", "*", "KW", "]", "=", "patches_k", "\n", "", "fpropFactor", "=", "SVD_factors", "[", "stats_var_dim", "]", "\n", "\n", "", "else", ":", "\n", "# poor mem usage implementation", "\n", "                            ", "patches", "=", "tf", ".", "extract_image_patches", "(", "fpropFactor", ",", "ksizes", "=", "[", "1", ",", "convkernel_size", "[", "\n", "0", "]", ",", "convkernel_size", "[", "1", "]", ",", "1", "]", ",", "strides", "=", "strides", ",", "rates", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "padding", ")", "\n", "\n", "if", "self", ".", "_approxT2", ":", "\n", "                                ", "if", "KFAC_DEBUG", ":", "\n", "                                    ", "print", "(", "(", "'approxT2 act fisher for %s'", "%", "(", "var", ".", "name", ")", ")", ")", "\n", "# T^2 terms * 1/T^2, size: B x C", "\n", "", "fpropFactor", "=", "tf", ".", "reduce_mean", "(", "patches", ",", "[", "1", ",", "2", "]", ")", "\n", "", "else", ":", "\n", "# size: (B x Oh x Ow) x C", "\n", "                                ", "fpropFactor", "=", "tf", ".", "reshape", "(", "\n", "patches", ",", "[", "-", "1", ",", "flatten_size", "]", ")", "/", "Oh", "/", "Ow", "\n", "", "", "", "fpropFactor_size", "=", "int", "(", "fpropFactor", ".", "get_shape", "(", ")", "[", "-", "1", "]", ")", "\n", "if", "stats_var_dim", "==", "(", "fpropFactor_size", "+", "1", ")", "and", "not", "self", ".", "_blockdiag_bias", ":", "\n", "                        ", "if", "opType", "==", "'Conv2D'", "and", "not", "self", ".", "_approxT2", ":", "\n", "# correct padding for numerical stability (we", "\n", "# divided out OhxOw from activations for T1 approx)", "\n", "                            ", "fpropFactor", "=", "tf", ".", "concat", "(", "[", "fpropFactor", ",", "tf", ".", "ones", "(", "\n", "[", "tf", ".", "shape", "(", "fpropFactor", ")", "[", "0", "]", ",", "1", "]", ")", "/", "Oh", "/", "Ow", "]", ",", "1", ")", "\n", "", "else", ":", "\n", "# use homogeneous coordinates", "\n", "                            ", "fpropFactor", "=", "tf", ".", "concat", "(", "\n", "[", "fpropFactor", ",", "tf", ".", "ones", "(", "[", "tf", ".", "shape", "(", "fpropFactor", ")", "[", "0", "]", ",", "1", "]", ")", "]", ",", "1", ")", "\n", "\n", "# average over the number of data points in a batch", "\n", "# divided by B", "\n", "", "", "cov", "=", "tf", ".", "matmul", "(", "fpropFactor", ",", "fpropFactor", ",", "\n", "transpose_a", "=", "True", ")", "/", "tf", ".", "cast", "(", "B", ",", "tf", ".", "float32", ")", "\n", "updateOps", ".", "append", "(", "cov", ")", "\n", "statsUpdates", "[", "stats_var", "]", "=", "cov", "\n", "if", "opType", "!=", "'Conv2D'", ":", "\n", "# HACK: for convolution we recompute fprop stats for", "\n", "# every layer including forking layers", "\n", "                        ", "statsUpdates_cache", "[", "stats_var", "]", "=", "cov", "\n", "\n", "", "", "", "for", "stats_var", "in", "bpropStats_vars", ":", "\n", "                ", "stats_var_dim", "=", "int", "(", "stats_var", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "if", "stats_var", "not", "in", "statsUpdates_cache", ":", "\n", "                    ", "old_bpropFactor", "=", "bpropFactor", "\n", "bpropFactor_shape", "=", "bpropFactor", ".", "get_shape", "(", ")", "\n", "B", "=", "tf", ".", "shape", "(", "bpropFactor", ")", "[", "0", "]", "# batch size", "\n", "C", "=", "int", "(", "bpropFactor_shape", "[", "-", "1", "]", ")", "# num channels", "\n", "if", "opType", "==", "'Conv2D'", "or", "len", "(", "bpropFactor_shape", ")", "==", "4", ":", "\n", "                        ", "if", "fpropFactor", "is", "not", "None", ":", "\n", "                            ", "if", "self", ".", "_approxT2", ":", "\n", "                                ", "if", "KFAC_DEBUG", ":", "\n", "                                    ", "print", "(", "(", "'approxT2 grad fisher for %s'", "%", "(", "var", ".", "name", ")", ")", ")", "\n", "", "bpropFactor", "=", "tf", ".", "reduce_sum", "(", "\n", "bpropFactor", ",", "[", "1", ",", "2", "]", ")", "# T^2 terms * 1/T^2", "\n", "", "else", ":", "\n", "                                ", "bpropFactor", "=", "tf", ".", "reshape", "(", "\n", "bpropFactor", ",", "[", "-", "1", ",", "C", "]", ")", "*", "Oh", "*", "Ow", "# T * 1/T terms", "\n", "", "", "else", ":", "\n", "# just doing block diag approx. spatial independent", "\n", "# structure does not apply here. summing over", "\n", "# spatial locations", "\n", "                            ", "if", "KFAC_DEBUG", ":", "\n", "                                ", "print", "(", "(", "'block diag approx fisher for %s'", "%", "(", "var", ".", "name", ")", ")", ")", "\n", "", "bpropFactor", "=", "tf", ".", "reduce_sum", "(", "bpropFactor", ",", "[", "1", ",", "2", "]", ")", "\n", "\n", "# assume sampled loss is averaged. TO-DO:figure out better", "\n", "# way to handle this", "\n", "", "", "bpropFactor", "*=", "tf", ".", "to_float", "(", "B", ")", "\n", "##", "\n", "\n", "cov_b", "=", "tf", ".", "matmul", "(", "\n", "bpropFactor", ",", "bpropFactor", ",", "transpose_a", "=", "True", ")", "/", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "bpropFactor", ")", "[", "0", "]", ")", "\n", "\n", "updateOps", ".", "append", "(", "cov_b", ")", "\n", "statsUpdates", "[", "stats_var", "]", "=", "cov_b", "\n", "statsUpdates_cache", "[", "stats_var", "]", "=", "cov_b", "\n", "\n", "", "", "", "if", "KFAC_DEBUG", ":", "\n", "            ", "aKey", "=", "list", "(", "statsUpdates", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "statsUpdates", "[", "aKey", "]", "=", "tf", ".", "Print", "(", "statsUpdates", "[", "aKey", "]", ",", "\n", "[", "tf", ".", "convert_to_tensor", "(", "'step:'", ")", ",", "\n", "self", ".", "global_step", ",", "\n", "tf", ".", "convert_to_tensor", "(", "\n", "'computing stats'", ")", ",", "\n", "]", ")", "\n", "", "self", ".", "statsUpdates", "=", "statsUpdates", "\n", "return", "statsUpdates", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_stats": [[440, 475], ["tensorflow.group", "kfac.KfacOptimizer._apply_stats", "tensorflow.FIFOQueue", "tensorflow.FIFOQueue.enqueue", "tensorflow.train.QueueRunner", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.group", "tensorflow.FIFOQueue.dequeue", "tensorflow.equal", "tensorflow.greater_equal", "tensorflow.greater", "kfac.KfacOptimizer._apply_stats", "tensorflow.FIFOQueue.size", "tensorflow.convert_to_tensor", "tensorflow.group", "kfac.KfacOptimizer.apply_stats.updateRunningAvgStats"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer._apply_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer._apply_stats"], ["", "def", "apply_stats", "(", "self", ",", "statsUpdates", ")", ":", "\n", "        ", "\"\"\" compute stats and update/apply the new stats to the running average\n        \"\"\"", "\n", "\n", "def", "updateAccumStats", "(", ")", ":", "\n", "            ", "if", "self", ".", "_full_stats_init", ":", "\n", "                ", "return", "tf", ".", "cond", "(", "tf", ".", "greater", "(", "self", ".", "sgd_step", ",", "self", ".", "_cold_iter", ")", ",", "lambda", ":", "tf", ".", "group", "(", "*", "self", ".", "_apply_stats", "(", "statsUpdates", ",", "accumulate", "=", "True", ",", "accumulateCoeff", "=", "1.", "/", "self", ".", "_stats_accum_iter", ")", ")", ",", "tf", ".", "no_op", ")", "\n", "", "else", ":", "\n", "                ", "return", "tf", ".", "group", "(", "*", "self", ".", "_apply_stats", "(", "statsUpdates", ",", "accumulate", "=", "True", ",", "accumulateCoeff", "=", "1.", "/", "self", ".", "_stats_accum_iter", ")", ")", "\n", "\n", "", "", "def", "updateRunningAvgStats", "(", "statsUpdates", ",", "fac_iter", "=", "1", ")", ":", "\n", "# return tf.cond(tf.greater_equal(self.factor_step,", "\n", "# tf.convert_to_tensor(fac_iter)), lambda:", "\n", "# tf.group(*self._apply_stats(stats_list, varlist)), tf.no_op)", "\n", "            ", "return", "tf", ".", "group", "(", "*", "self", ".", "_apply_stats", "(", "statsUpdates", ")", ")", "\n", "\n", "", "if", "self", ".", "_async_stats", ":", "\n", "# asynchronous stats update", "\n", "            ", "update_stats", "=", "self", ".", "_apply_stats", "(", "statsUpdates", ")", "\n", "\n", "queue", "=", "tf", ".", "FIFOQueue", "(", "1", ",", "[", "item", ".", "dtype", "for", "item", "in", "update_stats", "]", ",", "shapes", "=", "[", "\n", "item", ".", "get_shape", "(", ")", "for", "item", "in", "update_stats", "]", ")", "\n", "enqueue_op", "=", "queue", ".", "enqueue", "(", "update_stats", ")", "\n", "\n", "def", "dequeue_stats_op", "(", ")", ":", "\n", "                ", "return", "queue", ".", "dequeue", "(", ")", "\n", "", "self", ".", "qr_stats", "=", "tf", ".", "train", ".", "QueueRunner", "(", "queue", ",", "[", "enqueue_op", "]", ")", "\n", "update_stats_op", "=", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "queue", ".", "size", "(", ")", ",", "tf", ".", "convert_to_tensor", "(", "\n", "0", ")", ")", ",", "tf", ".", "no_op", ",", "lambda", ":", "tf", ".", "group", "(", "*", "[", "dequeue_stats_op", "(", ")", ",", "]", ")", ")", "\n", "", "else", ":", "\n", "# synchronous stats update", "\n", "            ", "update_stats_op", "=", "tf", ".", "cond", "(", "tf", ".", "greater_equal", "(", "\n", "self", ".", "stats_step", ",", "self", ".", "_stats_accum_iter", ")", ",", "lambda", ":", "updateRunningAvgStats", "(", "statsUpdates", ")", ",", "updateAccumStats", ")", "\n", "", "self", ".", "_update_stats_op", "=", "update_stats_op", "\n", "return", "update_stats_op", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer._apply_stats": [[476, 511], ["updateOps.append", "tensorflow.control_dependencies", "tensorflow.assign_add", "tensorflow.Print", "tensorflow.assign_add", "tensorflow.assign", "tensorflow.assign_add", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "_apply_stats", "(", "self", ",", "statsUpdates", ",", "accumulate", "=", "False", ",", "accumulateCoeff", "=", "0.", ")", ":", "\n", "        ", "updateOps", "=", "[", "]", "\n", "# obtain the stats var list", "\n", "for", "stats_var", "in", "statsUpdates", ":", "\n", "            ", "stats_new", "=", "statsUpdates", "[", "stats_var", "]", "\n", "if", "accumulate", ":", "\n", "# simple superbatch averaging", "\n", "                ", "update_op", "=", "tf", ".", "assign_add", "(", "\n", "stats_var", ",", "accumulateCoeff", "*", "stats_new", ",", "use_locking", "=", "True", ")", "\n", "", "else", ":", "\n", "# exponential running averaging", "\n", "                ", "update_op", "=", "tf", ".", "assign", "(", "\n", "stats_var", ",", "stats_var", "*", "self", ".", "_stats_decay", ",", "use_locking", "=", "True", ")", "\n", "update_op", "=", "tf", ".", "assign_add", "(", "\n", "update_op", ",", "(", "1.", "-", "self", ".", "_stats_decay", ")", "*", "stats_new", ",", "use_locking", "=", "True", ")", "\n", "", "updateOps", ".", "append", "(", "update_op", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "updateOps", ")", ":", "\n", "            ", "stats_step_op", "=", "tf", ".", "assign_add", "(", "self", ".", "stats_step", ",", "1", ")", "\n", "\n", "", "if", "KFAC_DEBUG", ":", "\n", "            ", "stats_step_op", "=", "(", "tf", ".", "Print", "(", "stats_step_op", ",", "\n", "[", "tf", ".", "convert_to_tensor", "(", "'step:'", ")", ",", "\n", "self", ".", "global_step", ",", "\n", "tf", ".", "convert_to_tensor", "(", "'fac step:'", ")", ",", "\n", "self", ".", "factor_step", ",", "\n", "tf", ".", "convert_to_tensor", "(", "'sgd step:'", ")", ",", "\n", "self", ".", "sgd_step", ",", "\n", "tf", ".", "convert_to_tensor", "(", "'Accum:'", ")", ",", "\n", "tf", ".", "convert_to_tensor", "(", "accumulate", ")", ",", "\n", "tf", ".", "convert_to_tensor", "(", "'Accum coeff:'", ")", ",", "\n", "tf", ".", "convert_to_tensor", "(", "accumulateCoeff", ")", ",", "\n", "tf", ".", "convert_to_tensor", "(", "'stat step:'", ")", ",", "\n", "self", ".", "stats_step", ",", "updateOps", "[", "0", "]", ",", "updateOps", "[", "1", "]", "]", ")", ")", "\n", "", "return", "[", "stats_step_op", ",", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getStatsEigen": [[512, 537], ["len", "tensorflow.device", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.ones", "tensorflow.diag", "stats_var.get_shape", "tensorflow.ones", "stats_var.name.split", "stats_var.name.split"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "getStatsEigen", "(", "self", ",", "stats", "=", "None", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "stats_eigen", ")", "==", "0", ":", "\n", "            ", "stats_eigen", "=", "{", "}", "\n", "if", "stats", "is", "None", ":", "\n", "                ", "stats", "=", "self", ".", "stats", "\n", "\n", "", "tmpEigenCache", "=", "{", "}", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "for", "var", "in", "stats", ":", "\n", "                    ", "for", "key", "in", "[", "'fprop_concat_stats'", ",", "'bprop_concat_stats'", "]", ":", "\n", "                        ", "for", "stats_var", "in", "stats", "[", "var", "]", "[", "key", "]", ":", "\n", "                            ", "if", "stats_var", "not", "in", "tmpEigenCache", ":", "\n", "                                ", "stats_dim", "=", "stats_var", ".", "get_shape", "(", ")", "[", "1", "]", ".", "value", "\n", "e", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "\n", "[", "stats_dim", "]", ")", ",", "name", "=", "'KFAC_FAC/'", "+", "stats_var", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", "+", "'/e'", ",", "trainable", "=", "False", ")", "\n", "Q", "=", "tf", ".", "Variable", "(", "tf", ".", "diag", "(", "tf", ".", "ones", "(", "\n", "[", "stats_dim", "]", ")", ")", ",", "name", "=", "'KFAC_FAC/'", "+", "stats_var", ".", "name", ".", "split", "(", "':'", ")", "[", "0", "]", "+", "'/Q'", ",", "trainable", "=", "False", ")", "\n", "stats_eigen", "[", "stats_var", "]", "=", "{", "'e'", ":", "e", ",", "'Q'", ":", "Q", "}", "\n", "tmpEigenCache", "[", "\n", "stats_var", "]", "=", "stats_eigen", "[", "stats_var", "]", "\n", "", "else", ":", "\n", "                                ", "stats_eigen", "[", "stats_var", "]", "=", "tmpEigenCache", "[", "\n", "stats_var", "]", "\n", "", "", "", "", "", "self", ".", "stats_eigen", "=", "stats_eigen", "\n", "", "return", "self", ".", "stats_eigen", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.computeStatsEigen": [[538, 601], ["tensorflow.device", "print", "tensorflow.control_dependencies", "tensorflow.control_dependencies", "updateOps.append", "local_list.append", "copied_list.append", "copied_list.append", "tensorflow.self_adjoint_eig", "updateOps.append", "updateOps.append", "tensorflow.Print", "tensorflow.cast", "tensorflow.cast", "tensorflow.constant", "tensorflow.cast", "tensorflow.identity", "tensorflow.convert_to_tensor", "tensorflow.identity"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.constant"], ["", "def", "computeStatsEigen", "(", "self", ")", ":", "\n", "        ", "\"\"\" compute the eigen decomp using copied var stats to avoid concurrent read/write from other queue \"\"\"", "\n", "# TO-DO: figure out why this op has delays (possibly moving", "\n", "# eigenvectors around?)", "\n", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "            ", "def", "removeNone", "(", "tensor_list", ")", ":", "\n", "                ", "local_list", "=", "[", "]", "\n", "for", "item", "in", "tensor_list", ":", "\n", "                    ", "if", "item", "is", "not", "None", ":", "\n", "                        ", "local_list", ".", "append", "(", "item", ")", "\n", "", "", "return", "local_list", "\n", "\n", "", "def", "copyStats", "(", "var_list", ")", ":", "\n", "                ", "print", "(", "\"copying stats to buffer tensors before eigen decomp\"", ")", "\n", "redundant_stats", "=", "{", "}", "\n", "copied_list", "=", "[", "]", "\n", "for", "item", "in", "var_list", ":", "\n", "                    ", "if", "item", "is", "not", "None", ":", "\n", "                        ", "if", "item", "not", "in", "redundant_stats", ":", "\n", "                            ", "if", "self", ".", "_use_float64", ":", "\n", "                                ", "redundant_stats", "[", "item", "]", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "identity", "(", "item", ")", ",", "tf", ".", "float64", ")", "\n", "", "else", ":", "\n", "                                ", "redundant_stats", "[", "item", "]", "=", "tf", ".", "identity", "(", "item", ")", "\n", "", "", "copied_list", ".", "append", "(", "redundant_stats", "[", "item", "]", ")", "\n", "", "else", ":", "\n", "                        ", "copied_list", ".", "append", "(", "None", ")", "\n", "", "", "return", "copied_list", "\n", "#stats = [copyStats(self.fStats), copyStats(self.bStats)]", "\n", "#stats = [self.fStats, self.bStats]", "\n", "\n", "", "stats_eigen", "=", "self", ".", "stats_eigen", "\n", "computedEigen", "=", "{", "}", "\n", "eigen_reverse_lookup", "=", "{", "}", "\n", "updateOps", "=", "[", "]", "\n", "# sync copied stats", "\n", "# with tf.control_dependencies(removeNone(stats[0]) +", "\n", "# removeNone(stats[1])):", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "]", ")", ":", "\n", "                ", "for", "stats_var", "in", "stats_eigen", ":", "\n", "                    ", "if", "stats_var", "not", "in", "computedEigen", ":", "\n", "                        ", "eigens", "=", "tf", ".", "self_adjoint_eig", "(", "stats_var", ")", "\n", "e", "=", "eigens", "[", "0", "]", "\n", "Q", "=", "eigens", "[", "1", "]", "\n", "if", "self", ".", "_use_float64", ":", "\n", "                            ", "e", "=", "tf", ".", "cast", "(", "e", ",", "tf", ".", "float32", ")", "\n", "Q", "=", "tf", ".", "cast", "(", "Q", ",", "tf", ".", "float32", ")", "\n", "", "updateOps", ".", "append", "(", "e", ")", "\n", "updateOps", ".", "append", "(", "Q", ")", "\n", "computedEigen", "[", "stats_var", "]", "=", "{", "'e'", ":", "e", ",", "'Q'", ":", "Q", "}", "\n", "eigen_reverse_lookup", "[", "e", "]", "=", "stats_eigen", "[", "stats_var", "]", "[", "'e'", "]", "\n", "eigen_reverse_lookup", "[", "Q", "]", "=", "stats_eigen", "[", "stats_var", "]", "[", "'Q'", "]", "\n", "\n", "", "", "", "self", ".", "eigen_reverse_lookup", "=", "eigen_reverse_lookup", "\n", "self", ".", "eigen_update_list", "=", "updateOps", "\n", "\n", "if", "KFAC_DEBUG", ":", "\n", "                ", "self", ".", "eigen_update_list", "=", "[", "item", "for", "item", "in", "updateOps", "]", "\n", "with", "tf", ".", "control_dependencies", "(", "updateOps", ")", ":", "\n", "                    ", "updateOps", ".", "append", "(", "tf", ".", "Print", "(", "tf", ".", "constant", "(", "\n", "0.", ")", ",", "[", "tf", ".", "convert_to_tensor", "(", "'computed factor eigen'", ")", "]", ")", ")", "\n", "\n", "", "", "", "return", "updateOps", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.applyStatsEigen": [[602, 617], ["print", "enumerate", "zip", "updateOps.append", "tensorflow.control_dependencies", "tensorflow.assign_add", "updateOps.append", "len", "tensorflow.assign", "updateOps.append", "tensorflow.Print", "tensorflow.constant", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.constant"], ["", "def", "applyStatsEigen", "(", "self", ",", "eigen_list", ")", ":", "\n", "        ", "updateOps", "=", "[", "]", "\n", "print", "(", "(", "'updating %d eigenvalue/vectors'", "%", "len", "(", "eigen_list", ")", ")", ")", "\n", "for", "i", ",", "(", "tensor", ",", "mark", ")", "in", "enumerate", "(", "zip", "(", "eigen_list", ",", "self", ".", "eigen_update_list", ")", ")", ":", "\n", "            ", "stats_eigen_var", "=", "self", ".", "eigen_reverse_lookup", "[", "mark", "]", "\n", "updateOps", ".", "append", "(", "\n", "tf", ".", "assign", "(", "stats_eigen_var", ",", "tensor", ",", "use_locking", "=", "True", ")", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "updateOps", ")", ":", "\n", "            ", "factor_step_op", "=", "tf", ".", "assign_add", "(", "self", ".", "factor_step", ",", "1", ")", "\n", "updateOps", ".", "append", "(", "factor_step_op", ")", "\n", "if", "KFAC_DEBUG", ":", "\n", "                ", "updateOps", ".", "append", "(", "tf", ".", "Print", "(", "tf", ".", "constant", "(", "\n", "0.", ")", ",", "[", "tf", ".", "convert_to_tensor", "(", "'updated kfac factors'", ")", "]", ")", ")", "\n", "", "", "return", "updateOps", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getKfacPrecondUpdates": [[618, 802], ["zip", "print", "zip", "tensorflow.minimum", "len", "len", "len", "tensorflow.Print", "tensorflow.reduce_sum", "print", "tensorflow.sqrt", "tensorflow.Print", "tensorflow.control_dependencies", "enumerate", "zip", "tensorflow.expand_dims.get_shape", "enumerate", "enumerate", "enumerate", "enumerate", "print", "len", "len", "len", "int", "int", "int", "int", "tensorflow.concat", "detectMinVal", "factorReshape", "eigVals.append", "gmatmul", "detectMinVal", "factorReshape", "eigVals.append", "gmatmul", "len", "zip", "gmatmul", "gmatmul", "int", "tensorflow.reshape", "tensorflow.slice", "tensorflow.reshape", "tensorflow.sqrt", "tensorflow.convert_to_tensor", "tensorflow.convert_to_tensor", "tensorflow.assign", "tensorflow.expand_dims.get_shape", "tensorflow.reshape", "tensorflow.reshape", "len", "int", "tensorflow.expand_dims", "int", "int", "print", "print", "len", "tensorflow.pow", "tensorflow.reduce_mean", "tensorflow.slice", "var_assnBias.get_shape", "tensorflow.reduce_sum", "tensorflow.expand_dims.get_shape", "tensorflow.expand_dims.get_shape", "tensorflow.expand_dims.get_shape", "tensorflow.expand_dims.get_shape", "len", "tensorflow.expand_dims.get_shape", "tensorflow.expand_dims", "tensorflow.abs", "len", "tensorflow.expand_dims.get_shape", "tensorflow.pow", "tensorflow.expand_dims.get_shape", "tensorflow.expand_dims.get_shape", "tensorflow.expand_dims.get_shape", "len", "tensorflow.sqrt", "functools.reduce", "tensorflow.pow", "tensorflow.pow"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.detectMinVal", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.factorReshape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.gmatmul", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.detectMinVal", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.factorReshape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.gmatmul", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.gmatmul", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac_utils.gmatmul", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce"], ["", "def", "getKfacPrecondUpdates", "(", "self", ",", "gradlist", ",", "varlist", ")", ":", "\n", "        ", "updatelist", "=", "[", "]", "\n", "vg", "=", "0.", "\n", "\n", "assert", "len", "(", "self", ".", "stats", ")", ">", "0", "\n", "assert", "len", "(", "self", ".", "stats_eigen", ")", ">", "0", "\n", "assert", "len", "(", "self", ".", "factors", ")", ">", "0", "\n", "counter", "=", "0", "\n", "\n", "grad_dict", "=", "{", "var", ":", "grad", "for", "grad", ",", "var", "in", "zip", "(", "gradlist", ",", "varlist", ")", "}", "\n", "\n", "for", "grad", ",", "var", "in", "zip", "(", "gradlist", ",", "varlist", ")", ":", "\n", "            ", "GRAD_RESHAPE", "=", "False", "\n", "GRAD_TRANSPOSE", "=", "False", "\n", "\n", "fpropFactoredFishers", "=", "self", ".", "stats", "[", "var", "]", "[", "'fprop_concat_stats'", "]", "\n", "bpropFactoredFishers", "=", "self", ".", "stats", "[", "var", "]", "[", "'bprop_concat_stats'", "]", "\n", "\n", "if", "(", "len", "(", "fpropFactoredFishers", ")", "+", "len", "(", "bpropFactoredFishers", ")", ")", ">", "0", ":", "\n", "                ", "counter", "+=", "1", "\n", "GRAD_SHAPE", "=", "grad", ".", "get_shape", "(", ")", "\n", "if", "len", "(", "grad", ".", "get_shape", "(", ")", ")", ">", "2", ":", "\n", "# reshape conv kernel parameters", "\n", "                    ", "KW", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "KH", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "C", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "2", "]", ")", "\n", "D", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "3", "]", ")", "\n", "\n", "if", "len", "(", "fpropFactoredFishers", ")", ">", "1", "and", "self", ".", "_channel_fac", ":", "\n", "# reshape conv kernel parameters into tensor", "\n", "                        ", "grad", "=", "tf", ".", "reshape", "(", "grad", ",", "[", "KW", "*", "KH", ",", "C", ",", "D", "]", ")", "\n", "", "else", ":", "\n", "# reshape conv kernel parameters into 2D grad", "\n", "                        ", "grad", "=", "tf", ".", "reshape", "(", "grad", ",", "[", "-", "1", ",", "D", "]", ")", "\n", "", "GRAD_RESHAPE", "=", "True", "\n", "", "elif", "len", "(", "grad", ".", "get_shape", "(", ")", ")", "==", "1", ":", "\n", "# reshape bias or 1D parameters", "\n", "                    ", "D", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "\n", "grad", "=", "tf", ".", "expand_dims", "(", "grad", ",", "0", ")", "\n", "GRAD_RESHAPE", "=", "True", "\n", "", "else", ":", "\n", "# 2D parameters", "\n", "                    ", "C", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "D", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "1", "]", ")", "\n", "\n", "", "if", "(", "self", ".", "stats", "[", "var", "]", "[", "'assnBias'", "]", "is", "not", "None", ")", "and", "not", "self", ".", "_blockdiag_bias", ":", "\n", "# use homogeneous coordinates only works for 2D grad.", "\n", "# TO-DO: figure out how to factorize bias grad", "\n", "# stack bias grad", "\n", "                    ", "var_assnBias", "=", "self", ".", "stats", "[", "var", "]", "[", "'assnBias'", "]", "\n", "grad", "=", "tf", ".", "concat", "(", "\n", "[", "grad", ",", "tf", ".", "expand_dims", "(", "grad_dict", "[", "var_assnBias", "]", ",", "0", ")", "]", ",", "0", ")", "\n", "\n", "# project gradient to eigen space and reshape the eigenvalues", "\n", "# for broadcasting", "\n", "", "eigVals", "=", "[", "]", "\n", "\n", "for", "idx", ",", "stats", "in", "enumerate", "(", "self", ".", "stats", "[", "var", "]", "[", "'fprop_concat_stats'", "]", ")", ":", "\n", "                    ", "Q", "=", "self", ".", "stats_eigen", "[", "stats", "]", "[", "'Q'", "]", "\n", "e", "=", "detectMinVal", "(", "self", ".", "stats_eigen", "[", "stats", "]", "[", "\n", "'e'", "]", ",", "var", ",", "name", "=", "'act'", ",", "debug", "=", "KFAC_DEBUG", ")", "\n", "\n", "Q", ",", "e", "=", "factorReshape", "(", "Q", ",", "e", ",", "grad", ",", "facIndx", "=", "idx", ",", "ftype", "=", "'act'", ")", "\n", "eigVals", ".", "append", "(", "e", ")", "\n", "grad", "=", "gmatmul", "(", "Q", ",", "grad", ",", "transpose_a", "=", "True", ",", "reduce_dim", "=", "idx", ")", "\n", "\n", "", "for", "idx", ",", "stats", "in", "enumerate", "(", "self", ".", "stats", "[", "var", "]", "[", "'bprop_concat_stats'", "]", ")", ":", "\n", "                    ", "Q", "=", "self", ".", "stats_eigen", "[", "stats", "]", "[", "'Q'", "]", "\n", "e", "=", "detectMinVal", "(", "self", ".", "stats_eigen", "[", "stats", "]", "[", "\n", "'e'", "]", ",", "var", ",", "name", "=", "'grad'", ",", "debug", "=", "KFAC_DEBUG", ")", "\n", "\n", "Q", ",", "e", "=", "factorReshape", "(", "Q", ",", "e", ",", "grad", ",", "facIndx", "=", "idx", ",", "ftype", "=", "'grad'", ")", "\n", "eigVals", ".", "append", "(", "e", ")", "\n", "grad", "=", "gmatmul", "(", "grad", ",", "Q", ",", "transpose_b", "=", "False", ",", "reduce_dim", "=", "idx", ")", "\n", "##", "\n", "\n", "#####", "\n", "# whiten using eigenvalues", "\n", "", "weightDecayCoeff", "=", "0.", "\n", "if", "var", "in", "self", ".", "_weight_decay_dict", ":", "\n", "                    ", "weightDecayCoeff", "=", "self", ".", "_weight_decay_dict", "[", "var", "]", "\n", "if", "KFAC_DEBUG", ":", "\n", "                        ", "print", "(", "(", "'weight decay coeff for %s is %f'", "%", "(", "var", ".", "name", ",", "weightDecayCoeff", ")", ")", ")", "\n", "\n", "", "", "if", "self", ".", "_factored_damping", ":", "\n", "                    ", "if", "KFAC_DEBUG", ":", "\n", "                        ", "print", "(", "(", "'use factored damping for %s'", "%", "(", "var", ".", "name", ")", ")", ")", "\n", "", "coeffs", "=", "1.", "\n", "num_factors", "=", "len", "(", "eigVals", ")", "\n", "# compute the ratio of two trace norm of the left and right", "\n", "# KFac matrices, and their generalization", "\n", "if", "len", "(", "eigVals", ")", "==", "1", ":", "\n", "                        ", "damping", "=", "self", ".", "_epsilon", "+", "weightDecayCoeff", "\n", "", "else", ":", "\n", "                        ", "damping", "=", "tf", ".", "pow", "(", "\n", "self", ".", "_epsilon", "+", "weightDecayCoeff", ",", "1.", "/", "num_factors", ")", "\n", "", "eigVals_tnorm_avg", "=", "[", "tf", ".", "reduce_mean", "(", "\n", "tf", ".", "abs", "(", "e", ")", ")", "for", "e", "in", "eigVals", "]", "\n", "for", "e", ",", "e_tnorm", "in", "zip", "(", "eigVals", ",", "eigVals_tnorm_avg", ")", ":", "\n", "                        ", "eig_tnorm_negList", "=", "[", "\n", "item", "for", "item", "in", "eigVals_tnorm_avg", "if", "item", "!=", "e_tnorm", "]", "\n", "if", "len", "(", "eigVals", ")", "==", "1", ":", "\n", "                            ", "adjustment", "=", "1.", "\n", "", "elif", "len", "(", "eigVals", ")", "==", "2", ":", "\n", "                            ", "adjustment", "=", "tf", ".", "sqrt", "(", "\n", "e_tnorm", "/", "eig_tnorm_negList", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "                            ", "eig_tnorm_negList_prod", "=", "reduce", "(", "\n", "lambda", "x", ",", "y", ":", "x", "*", "y", ",", "eig_tnorm_negList", ")", "\n", "adjustment", "=", "tf", ".", "pow", "(", "\n", "tf", ".", "pow", "(", "e_tnorm", ",", "num_factors", "-", "1.", ")", "/", "eig_tnorm_negList_prod", ",", "1.", "/", "num_factors", ")", "\n", "", "coeffs", "*=", "(", "e", "+", "adjustment", "*", "damping", ")", "\n", "", "", "else", ":", "\n", "                    ", "coeffs", "=", "1.", "\n", "damping", "=", "(", "self", ".", "_epsilon", "+", "weightDecayCoeff", ")", "\n", "for", "e", "in", "eigVals", ":", "\n", "                        ", "coeffs", "*=", "e", "\n", "", "coeffs", "+=", "damping", "\n", "\n", "#grad = tf.Print(grad, [tf.convert_to_tensor('1'), tf.convert_to_tensor(var.name), grad.get_shape()])", "\n", "\n", "", "grad", "/=", "coeffs", "\n", "\n", "#grad = tf.Print(grad, [tf.convert_to_tensor('2'), tf.convert_to_tensor(var.name), grad.get_shape()])", "\n", "#####", "\n", "# project gradient back to euclidean space", "\n", "for", "idx", ",", "stats", "in", "enumerate", "(", "self", ".", "stats", "[", "var", "]", "[", "'fprop_concat_stats'", "]", ")", ":", "\n", "                    ", "Q", "=", "self", ".", "stats_eigen", "[", "stats", "]", "[", "'Q'", "]", "\n", "grad", "=", "gmatmul", "(", "Q", ",", "grad", ",", "transpose_a", "=", "False", ",", "reduce_dim", "=", "idx", ")", "\n", "\n", "", "for", "idx", ",", "stats", "in", "enumerate", "(", "self", ".", "stats", "[", "var", "]", "[", "'bprop_concat_stats'", "]", ")", ":", "\n", "                    ", "Q", "=", "self", ".", "stats_eigen", "[", "stats", "]", "[", "'Q'", "]", "\n", "grad", "=", "gmatmul", "(", "grad", ",", "Q", ",", "transpose_b", "=", "True", ",", "reduce_dim", "=", "idx", ")", "\n", "##", "\n", "\n", "#grad = tf.Print(grad, [tf.convert_to_tensor('3'), tf.convert_to_tensor(var.name), grad.get_shape()])", "\n", "", "if", "(", "self", ".", "stats", "[", "var", "]", "[", "'assnBias'", "]", "is", "not", "None", ")", "and", "not", "self", ".", "_blockdiag_bias", ":", "\n", "# use homogeneous coordinates only works for 2D grad.", "\n", "# TO-DO: figure out how to factorize bias grad", "\n", "# un-stack bias grad", "\n", "                    ", "var_assnBias", "=", "self", ".", "stats", "[", "var", "]", "[", "'assnBias'", "]", "\n", "C_plus_one", "=", "int", "(", "grad", ".", "get_shape", "(", ")", "[", "0", "]", ")", "\n", "grad_assnBias", "=", "tf", ".", "reshape", "(", "tf", ".", "slice", "(", "grad", ",", "\n", "begin", "=", "[", "\n", "C_plus_one", "-", "1", ",", "0", "]", ",", "\n", "size", "=", "[", "1", ",", "-", "1", "]", ")", ",", "var_assnBias", ".", "get_shape", "(", ")", ")", "\n", "grad_assnWeights", "=", "tf", ".", "slice", "(", "grad", ",", "\n", "begin", "=", "[", "0", ",", "0", "]", ",", "\n", "size", "=", "[", "C_plus_one", "-", "1", ",", "-", "1", "]", ")", "\n", "grad_dict", "[", "var_assnBias", "]", "=", "grad_assnBias", "\n", "grad", "=", "grad_assnWeights", "\n", "\n", "#grad = tf.Print(grad, [tf.convert_to_tensor('4'), tf.convert_to_tensor(var.name), grad.get_shape()])", "\n", "", "if", "GRAD_RESHAPE", ":", "\n", "                    ", "grad", "=", "tf", ".", "reshape", "(", "grad", ",", "GRAD_SHAPE", ")", "\n", "\n", "", "grad_dict", "[", "var", "]", "=", "grad", "\n", "\n", "", "", "print", "(", "(", "'projecting %d gradient matrices'", "%", "counter", ")", ")", "\n", "\n", "for", "g", ",", "var", "in", "zip", "(", "gradlist", ",", "varlist", ")", ":", "\n", "            ", "grad", "=", "grad_dict", "[", "var", "]", "\n", "### clipping ###", "\n", "if", "KFAC_DEBUG", ":", "\n", "                ", "print", "(", "(", "'apply clipping to %s'", "%", "(", "var", ".", "name", ")", ")", ")", "\n", "", "tf", ".", "Print", "(", "grad", ",", "[", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "grad", ",", "2", ")", ")", ")", "]", ",", "\"Euclidean norm of new grad\"", ")", "\n", "local_vg", "=", "tf", ".", "reduce_sum", "(", "grad", "*", "g", "*", "(", "self", ".", "_lr", "*", "self", ".", "_lr", ")", ")", "\n", "vg", "+=", "local_vg", "\n", "\n", "# recale everything", "\n", "", "if", "KFAC_DEBUG", ":", "\n", "            ", "print", "(", "'apply vFv clipping'", ")", "\n", "\n", "", "scaling", "=", "tf", ".", "minimum", "(", "1.", ",", "tf", ".", "sqrt", "(", "self", ".", "_clip_kl", "/", "vg", ")", ")", "\n", "if", "KFAC_DEBUG", ":", "\n", "            ", "scaling", "=", "tf", ".", "Print", "(", "scaling", ",", "[", "tf", ".", "convert_to_tensor", "(", "\n", "'clip: '", ")", ",", "scaling", ",", "tf", ".", "convert_to_tensor", "(", "' vFv: '", ")", ",", "vg", "]", ")", "\n", "", "with", "tf", ".", "control_dependencies", "(", "[", "tf", ".", "assign", "(", "self", ".", "vFv", ",", "vg", ")", "]", ")", ":", "\n", "            ", "updatelist", "=", "[", "grad_dict", "[", "var", "]", "for", "var", "in", "varlist", "]", "\n", "for", "i", ",", "item", "in", "enumerate", "(", "updatelist", ")", ":", "\n", "                ", "updatelist", "[", "i", "]", "=", "scaling", "*", "item", "\n", "\n", "", "", "return", "updatelist", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.compute_gradients": [[803, 810], ["tensorflow.gradients", "tensorflow.trainable_variables", "zip"], "methods", ["None"], ["", "def", "compute_gradients", "(", "self", ",", "loss", ",", "var_list", "=", "None", ")", ":", "\n", "        ", "varlist", "=", "var_list", "\n", "if", "varlist", "is", "None", ":", "\n", "            ", "varlist", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "", "g", "=", "tf", ".", "gradients", "(", "loss", ",", "varlist", ")", "\n", "\n", "return", "[", "(", "a", ",", "b", ")", "for", "a", ",", "b", "in", "zip", "(", "g", ",", "varlist", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients_kfac": [[811, 896], ["list", "tensorflow.assign_add", "updateOps.append", "zip", "len", "kfac.KfacOptimizer.getStatsEigen", "print", "kfac.KfacOptimizer.computeStatsEigen", "tensorflow.FIFOQueue", "tensorflow.cond", "tensorflow.train.QueueRunner", "tensorflow.control_dependencies", "updateOps.append", "tensorflow.group", "tensorflow.logical_and", "tensorflow.FIFOQueue.dequeue", "dependency_list.append", "tensorflow.control_dependencies", "updateOps.append", "tensorflow.equal", "tensorflow.greater_equal", "tensorflow.FIFOQueue.enqueue", "tensorflow.group", "tensorflow.cond", "tensorflow.cond", "tensorflow.control_dependencies", "tensorflow.cond", "tensorflow.train.MomentumOptimizer", "updateOps.append", "item.get_shape", "tensorflow.mod", "tensorflow.convert_to_tensor", "kfac.KfacOptimizer.computeStatsEigen", "tensorflow.logical_and", "tensorflow.greater_equal", "list", "kfac.KfacOptimizer.getKfacPrecondUpdates", "tensorflow.greater", "kfac.KfacOptimizer.apply_gradients_kfac.optimOp"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getStatsEigen", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.computeStatsEigen", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.computeStatsEigen", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.getKfacPrecondUpdates"], ["", "def", "apply_gradients_kfac", "(", "self", ",", "grads", ")", ":", "\n", "        ", "g", ",", "varlist", "=", "list", "(", "zip", "(", "*", "grads", ")", ")", "\n", "\n", "if", "len", "(", "self", ".", "stats_eigen", ")", "==", "0", ":", "\n", "            ", "self", ".", "getStatsEigen", "(", ")", "\n", "\n", "", "qr", "=", "None", "\n", "# launch eigen-decomp on a queue thread", "\n", "if", "self", ".", "_async", ":", "\n", "            ", "print", "(", "'Use async eigen decomp'", ")", "\n", "# get a list of factor loading tensors", "\n", "factorOps_dummy", "=", "self", ".", "computeStatsEigen", "(", ")", "\n", "\n", "# define a queue for the list of factor loading tensors", "\n", "queue", "=", "tf", ".", "FIFOQueue", "(", "1", ",", "[", "item", ".", "dtype", "for", "item", "in", "factorOps_dummy", "]", ",", "shapes", "=", "[", "\n", "item", ".", "get_shape", "(", ")", "for", "item", "in", "factorOps_dummy", "]", ")", "\n", "enqueue_op", "=", "tf", ".", "cond", "(", "tf", ".", "logical_and", "(", "tf", ".", "equal", "(", "tf", ".", "mod", "(", "self", ".", "stats_step", ",", "self", ".", "_kfac_update", ")", ",", "tf", ".", "convert_to_tensor", "(", "\n", "0", ")", ")", ",", "tf", ".", "greater_equal", "(", "self", ".", "stats_step", ",", "self", ".", "_stats_accum_iter", ")", ")", ",", "lambda", ":", "queue", ".", "enqueue", "(", "self", ".", "computeStatsEigen", "(", ")", ")", ",", "tf", ".", "no_op", ")", "\n", "\n", "def", "dequeue_op", "(", ")", ":", "\n", "                ", "return", "queue", ".", "dequeue", "(", ")", "\n", "\n", "", "qr", "=", "tf", ".", "train", ".", "QueueRunner", "(", "queue", ",", "[", "enqueue_op", "]", ")", "\n", "\n", "", "updateOps", "=", "[", "]", "\n", "global_step_op", "=", "tf", ".", "assign_add", "(", "self", ".", "global_step", ",", "1", ")", "\n", "updateOps", ".", "append", "(", "global_step_op", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "global_step_op", "]", ")", ":", "\n", "\n", "# compute updates", "\n", "            ", "assert", "self", ".", "_update_stats_op", "!=", "None", "\n", "updateOps", ".", "append", "(", "self", ".", "_update_stats_op", ")", "\n", "dependency_list", "=", "[", "]", "\n", "if", "not", "self", ".", "_async", ":", "\n", "                ", "dependency_list", ".", "append", "(", "self", ".", "_update_stats_op", ")", "\n", "\n", "", "with", "tf", ".", "control_dependencies", "(", "dependency_list", ")", ":", "\n", "                ", "def", "no_op_wrapper", "(", ")", ":", "\n", "                    ", "return", "tf", ".", "group", "(", "*", "[", "tf", ".", "assign_add", "(", "self", ".", "cold_step", ",", "1", ")", "]", ")", "\n", "\n", "", "if", "not", "self", ".", "_async", ":", "\n", "# synchronous eigen-decomp updates", "\n", "                    ", "updateFactorOps", "=", "tf", ".", "cond", "(", "tf", ".", "logical_and", "(", "tf", ".", "equal", "(", "tf", ".", "mod", "(", "self", ".", "stats_step", ",", "self", ".", "_kfac_update", ")", ",", "\n", "tf", ".", "convert_to_tensor", "(", "0", ")", ")", ",", "\n", "tf", ".", "greater_equal", "(", "self", ".", "stats_step", ",", "self", ".", "_stats_accum_iter", ")", ")", ",", "lambda", ":", "tf", ".", "group", "(", "*", "self", ".", "applyStatsEigen", "(", "self", ".", "computeStatsEigen", "(", ")", ")", ")", ",", "no_op_wrapper", ")", "\n", "", "else", ":", "\n", "# asynchronous eigen-decomp updates using queue", "\n", "                    ", "updateFactorOps", "=", "tf", ".", "cond", "(", "tf", ".", "greater_equal", "(", "self", ".", "stats_step", ",", "self", ".", "_stats_accum_iter", ")", ",", "\n", "lambda", ":", "tf", ".", "cond", "(", "tf", ".", "equal", "(", "queue", ".", "size", "(", ")", ",", "tf", ".", "convert_to_tensor", "(", "0", ")", ")", ",", "\n", "tf", ".", "no_op", ",", "\n", "\n", "lambda", ":", "tf", ".", "group", "(", "\n", "*", "self", ".", "applyStatsEigen", "(", "dequeue_op", "(", ")", ")", ")", ",", "\n", ")", ",", "\n", "no_op_wrapper", ")", "\n", "\n", "", "updateOps", ".", "append", "(", "updateFactorOps", ")", "\n", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "updateFactorOps", "]", ")", ":", "\n", "                    ", "def", "gradOp", "(", ")", ":", "\n", "                        ", "return", "list", "(", "g", ")", "\n", "\n", "", "def", "getKfacGradOp", "(", ")", ":", "\n", "                        ", "return", "self", ".", "getKfacPrecondUpdates", "(", "g", ",", "varlist", ")", "\n", "", "u", "=", "tf", ".", "cond", "(", "tf", ".", "greater", "(", "self", ".", "factor_step", ",", "\n", "tf", ".", "convert_to_tensor", "(", "0", ")", ")", ",", "getKfacGradOp", ",", "gradOp", ")", "\n", "\n", "optim", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "\n", "self", ".", "_lr", "*", "(", "1.", "-", "self", ".", "_momentum", ")", ",", "self", ".", "_momentum", ")", "\n", "#optim = tf.train.AdamOptimizer(self._lr, epsilon=0.01)", "\n", "\n", "def", "optimOp", "(", ")", ":", "\n", "                        ", "def", "updateOptimOp", "(", ")", ":", "\n", "                            ", "if", "self", ".", "_full_stats_init", ":", "\n", "                                ", "return", "tf", ".", "cond", "(", "tf", ".", "greater", "(", "self", ".", "factor_step", ",", "tf", ".", "convert_to_tensor", "(", "0", ")", ")", ",", "lambda", ":", "optim", ".", "apply_gradients", "(", "list", "(", "zip", "(", "u", ",", "varlist", ")", ")", ")", ",", "tf", ".", "no_op", ")", "\n", "", "else", ":", "\n", "                                ", "return", "optim", ".", "apply_gradients", "(", "list", "(", "zip", "(", "u", ",", "varlist", ")", ")", ")", "\n", "", "", "if", "self", ".", "_full_stats_init", ":", "\n", "                            ", "return", "tf", ".", "cond", "(", "tf", ".", "greater_equal", "(", "self", ".", "stats_step", ",", "self", ".", "_stats_accum_iter", ")", ",", "updateOptimOp", ",", "tf", ".", "no_op", ")", "\n", "", "else", ":", "\n", "                            ", "return", "tf", ".", "cond", "(", "tf", ".", "greater_equal", "(", "self", ".", "sgd_step", ",", "self", ".", "_cold_iter", ")", ",", "updateOptimOp", ",", "tf", ".", "no_op", ")", "\n", "", "", "updateOps", ".", "append", "(", "optimOp", "(", ")", ")", "\n", "\n", "", "", "", "return", "tf", ".", "group", "(", "*", "updateOps", ")", ",", "qr", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients": [[897, 923], ["tensorflow.train.MomentumOptimizer", "kfac.KfacOptimizer.apply_gradients_kfac", "zip", "list", "tensorflow.assign_add", "tensorflow.train.MomentumOptimizer.apply_gradients", "tensorflow.group", "tensorflow.cond", "tensorflow.clip_by_global_norm", "zip", "tensorflow.greater", "tensorflow.control_dependencies", "tensorflow.Print", "tensorflow.convert_to_tensor"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients_kfac", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients"], ["", "def", "apply_gradients", "(", "self", ",", "grads", ")", ":", "\n", "        ", "coldOptim", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "\n", "self", ".", "_cold_lr", ",", "self", ".", "_momentum", ")", "\n", "\n", "def", "coldSGDstart", "(", ")", ":", "\n", "            ", "sgd_grads", ",", "sgd_var", "=", "zip", "(", "*", "grads", ")", "\n", "\n", "if", "self", ".", "max_grad_norm", "!=", "None", ":", "\n", "                ", "sgd_grads", ",", "sgd_grad_norm", "=", "tf", ".", "clip_by_global_norm", "(", "sgd_grads", ",", "self", ".", "max_grad_norm", ")", "\n", "\n", "", "sgd_grads", "=", "list", "(", "zip", "(", "sgd_grads", ",", "sgd_var", ")", ")", "\n", "\n", "sgd_step_op", "=", "tf", ".", "assign_add", "(", "self", ".", "sgd_step", ",", "1", ")", "\n", "coldOptim_op", "=", "coldOptim", ".", "apply_gradients", "(", "sgd_grads", ")", "\n", "if", "KFAC_DEBUG", ":", "\n", "                ", "with", "tf", ".", "control_dependencies", "(", "[", "sgd_step_op", ",", "coldOptim_op", "]", ")", ":", "\n", "                    ", "sgd_step_op", "=", "tf", ".", "Print", "(", "\n", "sgd_step_op", ",", "[", "self", ".", "sgd_step", ",", "tf", ".", "convert_to_tensor", "(", "'doing cold sgd step'", ")", "]", ")", "\n", "", "", "return", "tf", ".", "group", "(", "*", "[", "sgd_step_op", ",", "coldOptim_op", "]", ")", "\n", "\n", "", "kfacOptim_op", ",", "qr", "=", "self", ".", "apply_gradients_kfac", "(", "grads", ")", "\n", "\n", "def", "warmKFACstart", "(", ")", ":", "\n", "            ", "return", "kfacOptim_op", "\n", "\n", "", "return", "tf", ".", "cond", "(", "tf", ".", "greater", "(", "self", ".", "sgd_step", ",", "self", ".", "_cold_iter", ")", ",", "warmKFACstart", ",", "coldSGDstart", ")", ",", "qr", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.minimize": [[924, 929], ["kfac.KfacOptimizer.compute_gradients", "kfac.KfacOptimizer.compute_and_apply_stats", "kfac.KfacOptimizer.apply_gradients"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.MpiAdamOptimizer.compute_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.compute_and_apply_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients"], ["", "def", "minimize", "(", "self", ",", "loss", ",", "loss_sampled", ",", "var_list", "=", "None", ")", ":", "\n", "        ", "grads", "=", "self", ".", "compute_gradients", "(", "loss", ",", "var_list", "=", "var_list", ")", "\n", "update_stats_op", "=", "self", ".", "compute_and_apply_stats", "(", "\n", "loss_sampled", ",", "var_list", "=", "var_list", ")", "\n", "return", "self", ".", "apply_gradients", "(", "grads", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.acktr.Model.__init__": [[20, 94], ["baselines.common.tf_util.get_session", "policy.pdtype.sample_placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "policy.pd.neglogp", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.losses.mean_squared_error", "baselines.a2c.utils.find_trainable_variables", "tensorflow.gradients", "baselines.a2c.utils.Scheduler", "functools.partial", "functools.partial", "tensorflow.global_variables_initializer().run", "tensorflow.variable_scope", "policy", "policy", "policy.pd.entropy", "tensorflow.squeeze", "tensorflow.reduce_mean", "tensorflow.random_normal", "tensorflow.reduce_mean", "tensorflow.device", "baselines.acktr.kfac.KfacOptimizer", "baselines.acktr.kfac.KfacOptimizer.compute_and_apply_stats", "baselines.acktr.kfac.KfacOptimizer.apply_gradients", "range", "baselines.common.tf_util.get_session.run", "tensorflow.shape", "tensorflow.pow", "list", "len", "acktr.Model.lr.value", "tensorflow.global_variables_initializer", "zip", "tensorflow.stop_gradient"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.neglogp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.find_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.compute_and_apply_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value"], ["    ", "def", "__init__", "(", "self", ",", "policy", ",", "ob_space", ",", "ac_space", ",", "nenvs", ",", "total_timesteps", ",", "nprocs", "=", "32", ",", "nsteps", "=", "20", ",", "\n", "ent_coef", "=", "0.01", ",", "vf_coef", "=", "0.5", ",", "vf_fisher_coef", "=", "1.0", ",", "lr", "=", "0.25", ",", "max_grad_norm", "=", "0.5", ",", "\n", "kfac_clip", "=", "0.001", ",", "lrschedule", "=", "'linear'", ",", "is_async", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "sess", "=", "sess", "=", "get_session", "(", ")", "\n", "nbatch", "=", "nenvs", "*", "nsteps", "\n", "with", "tf", ".", "variable_scope", "(", "'acktr_model'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "model", "=", "step_model", "=", "policy", "(", "nenvs", ",", "1", ",", "sess", "=", "sess", ")", "\n", "self", ".", "model2", "=", "train_model", "=", "policy", "(", "nenvs", "*", "nsteps", ",", "nsteps", ",", "sess", "=", "sess", ")", "\n", "\n", "", "A", "=", "train_model", ".", "pdtype", ".", "sample_placeholder", "(", "[", "None", "]", ")", "\n", "ADV", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "\n", "R", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "\n", "PG_LR", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ")", "\n", "VF_LR", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ")", "\n", "\n", "neglogpac", "=", "train_model", ".", "pd", ".", "neglogp", "(", "A", ")", "\n", "self", ".", "logits", "=", "train_model", ".", "pi", "\n", "\n", "##training loss", "\n", "pg_loss", "=", "tf", ".", "reduce_mean", "(", "ADV", "*", "neglogpac", ")", "\n", "entropy", "=", "tf", ".", "reduce_mean", "(", "train_model", ".", "pd", ".", "entropy", "(", ")", ")", "\n", "pg_loss", "=", "pg_loss", "-", "ent_coef", "*", "entropy", "\n", "vf_loss", "=", "tf", ".", "losses", ".", "mean_squared_error", "(", "tf", ".", "squeeze", "(", "train_model", ".", "vf", ")", ",", "R", ")", "\n", "train_loss", "=", "pg_loss", "+", "vf_coef", "*", "vf_loss", "\n", "\n", "\n", "##Fisher loss construction", "\n", "self", ".", "pg_fisher", "=", "pg_fisher_loss", "=", "-", "tf", ".", "reduce_mean", "(", "neglogpac", ")", "\n", "sample_net", "=", "train_model", ".", "vf", "+", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "train_model", ".", "vf", ")", ")", "\n", "self", ".", "vf_fisher", "=", "vf_fisher_loss", "=", "-", "vf_fisher_coef", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "pow", "(", "train_model", ".", "vf", "-", "tf", ".", "stop_gradient", "(", "sample_net", ")", ",", "2", ")", ")", "\n", "self", ".", "joint_fisher", "=", "joint_fisher_loss", "=", "pg_fisher_loss", "+", "vf_fisher_loss", "\n", "\n", "self", ".", "params", "=", "params", "=", "find_trainable_variables", "(", "\"acktr_model\"", ")", "\n", "\n", "self", ".", "grads_check", "=", "grads", "=", "tf", ".", "gradients", "(", "train_loss", ",", "params", ")", "\n", "\n", "with", "tf", ".", "device", "(", "'/gpu:0'", ")", ":", "\n", "            ", "self", ".", "optim", "=", "optim", "=", "kfac", ".", "KfacOptimizer", "(", "learning_rate", "=", "PG_LR", ",", "clip_kl", "=", "kfac_clip", ",", "momentum", "=", "0.9", ",", "kfac_update", "=", "1", ",", "epsilon", "=", "0.01", ",", "stats_decay", "=", "0.99", ",", "is_async", "=", "is_async", ",", "cold_iter", "=", "10", ",", "max_grad_norm", "=", "max_grad_norm", ")", "\n", "\n", "# update_stats_op = optim.compute_and_apply_stats(joint_fisher_loss, var_list=params)", "\n", "optim", ".", "compute_and_apply_stats", "(", "joint_fisher_loss", ",", "var_list", "=", "params", ")", "\n", "train_op", ",", "q_runner", "=", "optim", ".", "apply_gradients", "(", "list", "(", "zip", "(", "grads", ",", "params", ")", ")", ")", "\n", "", "self", ".", "q_runner", "=", "q_runner", "\n", "self", ".", "lr", "=", "Scheduler", "(", "v", "=", "lr", ",", "nvalues", "=", "total_timesteps", ",", "schedule", "=", "lrschedule", ")", "\n", "\n", "def", "train", "(", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ")", ":", "\n", "            ", "advs", "=", "rewards", "-", "values", "\n", "for", "step", "in", "range", "(", "len", "(", "obs", ")", ")", ":", "\n", "                ", "cur_lr", "=", "self", ".", "lr", ".", "value", "(", ")", "\n", "\n", "", "td_map", "=", "{", "train_model", ".", "X", ":", "obs", ",", "A", ":", "actions", ",", "ADV", ":", "advs", ",", "R", ":", "rewards", ",", "PG_LR", ":", "cur_lr", ",", "VF_LR", ":", "cur_lr", "}", "\n", "if", "states", "is", "not", "None", ":", "\n", "                ", "td_map", "[", "train_model", ".", "S", "]", "=", "states", "\n", "td_map", "[", "train_model", ".", "M", "]", "=", "masks", "\n", "\n", "", "policy_loss", ",", "value_loss", ",", "policy_entropy", ",", "_", "=", "sess", ".", "run", "(", "\n", "[", "pg_loss", ",", "vf_loss", ",", "entropy", ",", "train_op", "]", ",", "\n", "td_map", "\n", ")", "\n", "return", "policy_loss", ",", "value_loss", ",", "policy_entropy", "\n", "\n", "\n", "", "self", ".", "train", "=", "train", "\n", "self", ".", "save", "=", "functools", ".", "partial", "(", "save_variables", ",", "sess", "=", "sess", ")", "\n", "self", ".", "load", "=", "functools", ".", "partial", "(", "load_variables", ",", "sess", "=", "sess", ")", "\n", "self", ".", "train_model", "=", "train_model", "\n", "self", ".", "step_model", "=", "step_model", "\n", "self", ".", "step", "=", "step_model", ".", "step", "\n", "self", ".", "value", "=", "step_model", ".", "value", "\n", "self", ".", "initial_state", "=", "step_model", ".", "initial_state", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", "session", "=", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.acktr.learn": [[95, 159], ["int", "baselines.common.set_global_seeds", "baselines.common.policies.build_policy", "make_model", "baselines.a2c.runner.Runner", "collections.deque", "time.time", "tensorflow.train.Coordinator", "range", "tf.train.Coordinator.request_stop", "tf.train.Coordinator.join", "acktr.Model", "baselines.logger.get_dir", "make_model.load", "make_model.q_runner.create_threads", "baselines.a2c.runner.Runner.run", "collections.deque.extend", "make_model.train", "int", "open", "fh.write", "time.time", "baselines.common.explained_variance", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.dump_tabular", "baselines.logger.get_dir", "os.join", "print", "make_model.save", "os.join", "cloudpickle.dumps", "float", "float", "float", "float", "baselines.ppo2.ppo2.safemean", "baselines.ppo2.ppo2.safemean", "baselines.logger.get_dir", "baselines.logger.get_dir"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.build_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.explained_variance", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["", "", "def", "learn", "(", "network", ",", "env", ",", "seed", ",", "total_timesteps", "=", "int", "(", "40e6", ")", ",", "gamma", "=", "0.99", ",", "log_interval", "=", "100", ",", "nprocs", "=", "32", ",", "nsteps", "=", "20", ",", "\n", "ent_coef", "=", "0.01", ",", "vf_coef", "=", "0.5", ",", "vf_fisher_coef", "=", "1.0", ",", "lr", "=", "0.25", ",", "max_grad_norm", "=", "0.5", ",", "\n", "kfac_clip", "=", "0.001", ",", "save_interval", "=", "None", ",", "lrschedule", "=", "'linear'", ",", "load_path", "=", "None", ",", "is_async", "=", "True", ",", "**", "network_kwargs", ")", ":", "\n", "    ", "set_global_seeds", "(", "seed", ")", "\n", "\n", "\n", "if", "network", "==", "'cnn'", ":", "\n", "        ", "network_kwargs", "[", "'one_dim_bias'", "]", "=", "True", "\n", "\n", "", "policy", "=", "build_policy", "(", "env", ",", "network", ",", "**", "network_kwargs", ")", "\n", "\n", "nenvs", "=", "env", ".", "num_envs", "\n", "ob_space", "=", "env", ".", "observation_space", "\n", "ac_space", "=", "env", ".", "action_space", "\n", "make_model", "=", "lambda", ":", "Model", "(", "policy", ",", "ob_space", ",", "ac_space", ",", "nenvs", ",", "total_timesteps", ",", "nprocs", "=", "nprocs", ",", "nsteps", "\n", "=", "nsteps", ",", "ent_coef", "=", "ent_coef", ",", "vf_coef", "=", "vf_coef", ",", "vf_fisher_coef", "=", "\n", "vf_fisher_coef", ",", "lr", "=", "lr", ",", "max_grad_norm", "=", "max_grad_norm", ",", "kfac_clip", "=", "kfac_clip", ",", "\n", "lrschedule", "=", "lrschedule", ",", "is_async", "=", "is_async", ")", "\n", "if", "save_interval", "and", "logger", ".", "get_dir", "(", ")", ":", "\n", "        ", "import", "cloudpickle", "\n", "with", "open", "(", "osp", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "'make_model.pkl'", ")", ",", "'wb'", ")", "as", "fh", ":", "\n", "            ", "fh", ".", "write", "(", "cloudpickle", ".", "dumps", "(", "make_model", ")", ")", "\n", "", "", "model", "=", "make_model", "(", ")", "\n", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "model", ".", "load", "(", "load_path", ")", "\n", "\n", "", "runner", "=", "Runner", "(", "env", ",", "model", ",", "nsteps", "=", "nsteps", ",", "gamma", "=", "gamma", ")", "\n", "epinfobuf", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "nbatch", "=", "nenvs", "*", "nsteps", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "coord", "=", "tf", ".", "train", ".", "Coordinator", "(", ")", "\n", "if", "is_async", ":", "\n", "        ", "enqueue_threads", "=", "model", ".", "q_runner", ".", "create_threads", "(", "model", ".", "sess", ",", "coord", "=", "coord", ",", "start", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "enqueue_threads", "=", "[", "]", "\n", "\n", "", "for", "update", "in", "range", "(", "1", ",", "total_timesteps", "//", "nbatch", "+", "1", ")", ":", "\n", "        ", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ",", "epinfos", "=", "runner", ".", "run", "(", ")", "\n", "epinfobuf", ".", "extend", "(", "epinfos", ")", "\n", "policy_loss", ",", "value_loss", ",", "policy_entropy", "=", "model", ".", "train", "(", "obs", ",", "states", ",", "rewards", ",", "masks", ",", "actions", ",", "values", ")", "\n", "model", ".", "old_obs", "=", "obs", "\n", "nseconds", "=", "time", ".", "time", "(", ")", "-", "tstart", "\n", "fps", "=", "int", "(", "(", "update", "*", "nbatch", ")", "/", "nseconds", ")", "\n", "if", "update", "%", "log_interval", "==", "0", "or", "update", "==", "1", ":", "\n", "            ", "ev", "=", "explained_variance", "(", "values", ",", "rewards", ")", "\n", "logger", ".", "record_tabular", "(", "\"nupdates\"", ",", "update", ")", "\n", "logger", ".", "record_tabular", "(", "\"total_timesteps\"", ",", "update", "*", "nbatch", ")", "\n", "logger", ".", "record_tabular", "(", "\"fps\"", ",", "fps", ")", "\n", "logger", ".", "record_tabular", "(", "\"policy_entropy\"", ",", "float", "(", "policy_entropy", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"policy_loss\"", ",", "float", "(", "policy_loss", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"value_loss\"", ",", "float", "(", "value_loss", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"explained_variance\"", ",", "float", "(", "ev", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"eprewmean\"", ",", "safemean", "(", "[", "epinfo", "[", "'r'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"eplenmean\"", ",", "safemean", "(", "[", "epinfo", "[", "'l'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "\n", "logger", ".", "dump_tabular", "(", ")", "\n", "\n", "", "if", "save_interval", "and", "(", "update", "%", "save_interval", "==", "0", "or", "update", "==", "1", ")", "and", "logger", ".", "get_dir", "(", ")", ":", "\n", "            ", "savepath", "=", "osp", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "'checkpoint%.5i'", "%", "update", ")", "\n", "print", "(", "'Saving to'", ",", "savepath", ")", "\n", "model", ".", "save", "(", "savepath", ")", "\n", "", "", "coord", ".", "request_stop", "(", ")", "\n", "coord", ".", "join", "(", "enqueue_threads", ")", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense": [[3, 20], ["tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.bias_add", "len", "tensorflow.multiply", "tensorflow.add_to_collection", "tensorflow.matmul", "tensorflow.get_variable_scope().name.split", "tensorflow.constant_initializer", "tensorflow.nn.l2_loss", "x.get_shape", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope().name.split", "tensorflow.get_variable_scope"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["import", "tensorflow", "as", "tf", "\n", "from", "collections", "import", "deque", "\n", "\n", "def", "sample", "(", "logits", ")", ":", "\n", "    ", "noise", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "logits", ")", ")", "\n", "return", "tf", ".", "argmax", "(", "logits", "-", "tf", ".", "log", "(", "-", "tf", ".", "log", "(", "noise", ")", ")", ",", "1", ")", "\n", "\n", "", "def", "cat_entropy", "(", "logits", ")", ":", "\n", "    ", "a0", "=", "logits", "-", "tf", ".", "reduce_max", "(", "logits", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "z0", "=", "tf", ".", "reduce_sum", "(", "ea0", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "tf", ".", "reduce_sum", "(", "p0", "*", "(", "tf", ".", "log", "(", "z0", ")", "-", "a0", ")", ",", "1", ")", "\n", "\n", "", "def", "cat_entropy_softmax", "(", "p0", ")", ":", "\n", "    ", "return", "-", "tf", ".", "reduce_sum", "(", "p0", "*", "tf", ".", "log", "(", "p0", "+", "1e-6", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "def", "ortho_init", "(", "scale", "=", "1.0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.kl_div": [[21, 29], ["tensorflow.reduce_sum", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.square", "tensorflow.log", "tensorflow.log"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["    ", "def", "_ortho_init", "(", "shape", ",", "dtype", ",", "partition_info", "=", "None", ")", ":", "\n", "#lasagne ortho init for tf", "\n", "        ", "shape", "=", "tuple", "(", "shape", ")", "\n", "if", "len", "(", "shape", ")", "==", "2", ":", "\n", "            ", "flat_shape", "=", "shape", "\n", "", "elif", "len", "(", "shape", ")", "==", "4", ":", "# assumes NHWC", "\n", "            ", "flat_shape", "=", "(", "np", ".", "prod", "(", "shape", "[", ":", "-", "1", "]", ")", ",", "shape", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.__init__": [[5, 29], ["None"], "methods", ["None"], ["class", "ReplayBuffer", "(", "object", ")", ":", "\n", "    ", "\"\"\"\n    Replay Buffer for multi-agent RL with parallel rollouts\n    \"\"\"", "\n", "def", "__init__", "(", "self", ",", "max_steps", ",", "num_agents", ",", "obs_dims", ",", "ac_dims", ")", ":", "\n", "        ", "\"\"\"\n        Inputs:\n            max_steps (int): Maximum number of timepoints to store in buffer\n            num_agents (int): Number of agents in environment\n            obs_dims (list of ints): number of obervation dimensions for each\n                                     agent\n            ac_dims (list of ints): number of action dimensions for each agent\n        \"\"\"", "\n", "self", ".", "max_steps", "=", "max_steps", "\n", "self", ".", "num_agents", "=", "num_agents", "\n", "self", ".", "obs_buffs", "=", "[", "]", "\n", "self", ".", "ac_buffs", "=", "[", "]", "\n", "self", ".", "rew_buffs", "=", "[", "]", "\n", "self", ".", "emp_buffs", "=", "[", "]", "\n", "self", ".", "next_obs_buffs", "=", "[", "]", "\n", "self", ".", "done_buffs", "=", "[", "]", "\n", "for", "odim", ",", "adim", "in", "zip", "(", "obs_dims", ",", "ac_dims", ")", ":", "\n", "            ", "self", ".", "ac_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "max_steps", ",", "adim", ")", ")", ")", "\n", "self", ".", "rew_buffs", ".", "append", "(", "np", ".", "zeros", "(", "max_steps", ")", ")", "\n", "self", ".", "emp_buffs", ".", "append", "(", "np", ".", "zeros", "(", "max_steps", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.has_atleast": [[30, 34], ["None"], "methods", ["None"], ["self", ".", "done_buffs", ".", "append", "(", "np", ".", "zeros", "(", "max_steps", ")", ")", "\n", "if", "type", "(", "odim", ")", "==", "int", ":", "\n", "                ", "self", ".", "next_obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "max_steps", ",", "odim", ")", ")", ")", "\n", "self", ".", "obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "max_steps", ",", "odim", ")", ")", ")", "\n", "", "else", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.can_sample": [[35, 37], ["None"], "methods", ["None"], ["                ", "self", ".", "next_obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "(", "max_steps", ",", ")", "+", "odim", ")", ")", ")", "\n", "self", ".", "obs_buffs", ".", "append", "(", "np", ".", "zeros", "(", "(", "(", "max_steps", ",", ")", "+", "odim", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.decode": [[39, 46], ["buffer._stack_obs"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer._stack_obs"], ["self", ".", "curr_i", "=", "0", "# current index to write to (ovewrite oldest data)", "\n", "\n", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "filled_i", "\n", "\n", "", "def", "push", "(", "self", ",", "observations", ",", "actions", ",", "rewards", ",", "emps", ",", "next_observations", ",", "dones", ")", ":", "\n", "        ", "nentries", "=", "observations", ".", "shape", "[", "0", "]", "# handle multiple parallel environments", "\n", "if", "self", ".", "curr_i", "+", "nentries", ">", "self", ".", "max_steps", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.put": [[47, 69], ["min", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "numpy.empty", "list", "list", "list", "list", "list", "list"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["            ", "rollover", "=", "self", ".", "max_steps", "-", "self", ".", "curr_i", "# num of indices to roll over", "\n", "for", "agent_i", "in", "range", "(", "self", ".", "num_agents", ")", ":", "\n", "                ", "self", ".", "obs_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "obs_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ",", "axis", "=", "0", ")", "\n", "self", ".", "ac_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "ac_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ",", "axis", "=", "0", ")", "\n", "self", ".", "rew_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "rew_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ")", "\n", "self", ".", "emp_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "emp_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ")", "\n", "self", ".", "next_obs_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "\n", "self", ".", "next_obs_buffs", "[", "agent_i", "]", ",", "rollover", ",", "axis", "=", "0", ")", "\n", "self", ".", "done_buffs", "[", "agent_i", "]", "=", "np", ".", "roll", "(", "self", ".", "done_buffs", "[", "agent_i", "]", ",", "\n", "rollover", ")", "\n", "", "self", ".", "curr_i", "=", "0", "\n", "self", ".", "filled_i", "=", "self", ".", "max_steps", "\n", "", "for", "agent_i", "in", "range", "(", "self", ".", "num_agents", ")", ":", "\n", "            ", "self", ".", "obs_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "np", ".", "vstack", "(", "\n", "observations", "[", ":", ",", "agent_i", "]", ")", "\n", "# actions are already batched by agent, so they are indexed differently", "\n", "self", ".", "ac_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "actions", "[", "agent_i", "]", "\n", "self", ".", "rew_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "rewards", "[", ":", ",", "agent_i", "]", "\n", "self", ".", "emp_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "emps", "[", ":", ",", "agent_i", "]", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.take": [[70, 76], ["numpy.empty", "range", "list"], "methods", ["None"], ["self", ".", "next_obs_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "np", ".", "vstack", "(", "\n", "next_observations", "[", ":", ",", "agent_i", "]", ")", "\n", "self", ".", "done_buffs", "[", "agent_i", "]", "[", "self", ".", "curr_i", ":", "self", ".", "curr_i", "+", "nentries", "]", "=", "dones", "[", ":", ",", "agent_i", "]", "\n", "", "self", ".", "curr_i", "+=", "nentries", "\n", "if", "self", ".", "filled_i", "<", "self", ".", "max_steps", ":", "\n", "            ", "self", ".", "filled_i", "+=", "nentries", "\n", "", "if", "self", ".", "curr_i", "==", "self", ".", "max_steps", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get": [[77, 98], ["buffer.Buffer.can_sample", "numpy.random.randint", "numpy.arange", "buffer.Buffer.take"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.can_sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.take"], ["            ", "self", ".", "curr_i", "=", "0", "\n", "\n", "", "", "def", "sample", "(", "self", ",", "N", ",", "to_gpu", "=", "False", ",", "norm_rews", "=", "True", ")", ":", "\n", "        ", "inds", "=", "np", ".", "random", ".", "choice", "(", "np", ".", "arange", "(", "self", ".", "filled_i", ")", ",", "size", "=", "N", ",", "\n", "replace", "=", "False", ")", "\n", "if", "to_gpu", ":", "\n", "            ", "cast", "=", "lambda", "x", ":", "Variable", "(", "Tensor", "(", "x", ")", ",", "requires_grad", "=", "False", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "            ", "cast", "=", "lambda", "x", ":", "Variable", "(", "Tensor", "(", "x", ")", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "if", "norm_rews", ":", "\n", "            ", "ret_rews", "=", "[", "cast", "(", "(", "self", ".", "rew_buffs", "[", "i", "]", "[", "inds", "]", "-", "\n", "self", ".", "rew_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "mean", "(", ")", ")", "/", "\n", "self", ".", "rew_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "std", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "ret_emps", "=", "[", "cast", "(", "(", "self", ".", "emp_buffs", "[", "i", "]", "[", "inds", "]", "-", "\n", "self", ".", "emp_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "mean", "(", ")", ")", "/", "\n", "self", ".", "emp_buffs", "[", "i", "]", "[", ":", "self", ".", "filled_i", "]", ".", "std", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "", "else", ":", "\n", "            ", "ret_rews", "=", "[", "cast", "(", "self", ".", "rew_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "ret_emps", "=", "[", "cast", "(", "self", ".", "emp_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer._stack_obs_ref": [[101, 123], ["numpy.empty", "numpy.zeros", "numpy.reshape().swapaxes", "numpy.reshape().swapaxes", "range", "numpy.reshape", "obs[].transpose", "numpy.reshape", "numpy.reshape"], "function", ["None"], ["[", "cast", "(", "self", ".", "ac_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", ",", "\n", "ret_rews", ",", "\n", "ret_emps", ",", "\n", "[", "cast", "(", "self", ".", "next_obs_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", ",", "\n", "[", "cast", "(", "self", ".", "done_buffs", "[", "i", "]", "[", "inds", "]", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", ")", "\n", "\n", "", "def", "get_average_rewards", "(", "self", ",", "N", ")", ":", "\n", "        ", "if", "self", ".", "filled_i", "==", "self", ".", "max_steps", ":", "\n", "            ", "inds", "=", "np", ".", "arange", "(", "self", ".", "curr_i", "-", "N", ",", "self", ".", "curr_i", ")", "# allow for negative indexing", "\n", "", "else", ":", "\n", "            ", "inds", "=", "np", ".", "arange", "(", "max", "(", "0", ",", "self", ".", "curr_i", "-", "N", ")", ",", "self", ".", "curr_i", ")", "\n", "", "return", "[", "self", ".", "rew_buffs", "[", "i", "]", "[", "inds", "]", ".", "mean", "(", ")", "for", "i", "in", "range", "(", "self", ".", "num_agents", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer._stack_obs": [[124, 141], ["numpy.zeros", "numpy.ones", "mask.reshape.reshape", "range", "tuple", "numpy.ones", "len"], "function", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.test_stack_obs": [[142, 157], ["numpy.random.random", "numpy.random.randint", "buffer._stack_obs_ref", "buffer._stack_obs", "numpy.testing.assert_allclose"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer._stack_obs_ref", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer._stack_obs"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.defaults.atari": [[1, 4], ["dict"], "function", ["None"], ["from", "baselines", ".", "common", ".", "models", "import", "mlp", ",", "cnn_small", "\n", "\n", "\n", "def", "atari", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.policies.AcerCnnPolicy.__init__": [[9, 44], ["tensorflow.placeholder", "baselines.a2c.utils.sample", "tensorflow.variable_scope", "baselines.common.policies.nature_cnn", "baselines.a2c.utils.fc", "tensorflow.nn.softmax", "baselines.a2c.utils.fc", "tensorflow.nn.softmax", "sess.run", "sess.run", "sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.nature_cnn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "ob_space", ",", "ac_space", ",", "nenv", ",", "nsteps", ",", "nstack", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "nbatch", "=", "nenv", "*", "nsteps", "\n", "nh", ",", "nw", ",", "nc", "=", "ob_space", ".", "shape", "\n", "ob_shape", "=", "(", "nbatch", ",", "nh", ",", "nw", ",", "nc", "*", "nstack", ")", "\n", "nact", "=", "ac_space", ".", "n", "\n", "X", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "ob_shape", ")", "# obs", "\n", "with", "tf", ".", "variable_scope", "(", "\"model\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "h", "=", "nature_cnn", "(", "X", ")", "\n", "pi_logits", "=", "fc", "(", "h", ",", "'pi'", ",", "nact", ",", "init_scale", "=", "0.01", ")", "\n", "pi", "=", "tf", ".", "nn", ".", "softmax", "(", "pi_logits", ")", "\n", "q", "=", "fc", "(", "h", ",", "'q'", ",", "nact", ")", "\n", "\n", "", "a", "=", "sample", "(", "tf", ".", "nn", ".", "softmax", "(", "pi_logits", ")", ")", "# could change this to use self.pi instead", "\n", "self", ".", "initial_state", "=", "[", "]", "# not stateful", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "pi", "=", "pi", "# actual policy params now", "\n", "self", ".", "pi_logits", "=", "pi_logits", "\n", "self", ".", "q", "=", "q", "\n", "self", ".", "vf", "=", "q", "\n", "\n", "def", "step", "(", "ob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# returns actions, mus, states", "\n", "            ", "a0", ",", "pi0", "=", "sess", ".", "run", "(", "[", "a", ",", "pi", "]", ",", "{", "X", ":", "ob", "}", ")", "\n", "return", "a0", ",", "pi0", ",", "[", "]", "# dummy state", "\n", "\n", "", "def", "out", "(", "ob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "pi0", ",", "q0", "=", "sess", ".", "run", "(", "[", "pi", ",", "q", "]", ",", "{", "X", ":", "ob", "}", ")", "\n", "return", "pi0", ",", "q0", "\n", "\n", "", "def", "act", "(", "ob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "sess", ".", "run", "(", "a", ",", "{", "X", ":", "ob", "}", ")", "\n", "\n", "", "self", ".", "step", "=", "step", "\n", "self", ".", "out", "=", "out", "\n", "self", ".", "act", "=", "act", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.policies.AcerLstmPolicy.__init__": [[47, 82], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.a2c.utils.sample", "numpy.zeros", "tensorflow.variable_scope", "baselines.common.policies.nature_cnn", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.lstm", "baselines.a2c.utils.seq_to_batch", "baselines.a2c.utils.fc", "tensorflow.nn.softmax", "baselines.a2c.utils.fc", "sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.nature_cnn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.lstm", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.seq_to_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["    ", "def", "__init__", "(", "self", ",", "sess", ",", "ob_space", ",", "ac_space", ",", "nenv", ",", "nsteps", ",", "nstack", ",", "reuse", "=", "False", ",", "nlstm", "=", "256", ")", ":", "\n", "        ", "nbatch", "=", "nenv", "*", "nsteps", "\n", "nh", ",", "nw", ",", "nc", "=", "ob_space", ".", "shape", "\n", "ob_shape", "=", "(", "nbatch", ",", "nh", ",", "nw", ",", "nc", "*", "nstack", ")", "\n", "nact", "=", "ac_space", ".", "n", "\n", "X", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "ob_shape", ")", "# obs", "\n", "M", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "#mask (done t-1)", "\n", "S", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nenv", ",", "nlstm", "*", "2", "]", ")", "#states", "\n", "with", "tf", ".", "variable_scope", "(", "\"model\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "h", "=", "nature_cnn", "(", "X", ")", "\n", "\n", "# lstm", "\n", "xs", "=", "batch_to_seq", "(", "h", ",", "nenv", ",", "nsteps", ")", "\n", "ms", "=", "batch_to_seq", "(", "M", ",", "nenv", ",", "nsteps", ")", "\n", "h5", ",", "snew", "=", "lstm", "(", "xs", ",", "ms", ",", "S", ",", "'lstm1'", ",", "nh", "=", "nlstm", ")", "\n", "h5", "=", "seq_to_batch", "(", "h5", ")", "\n", "\n", "pi_logits", "=", "fc", "(", "h5", ",", "'pi'", ",", "nact", ",", "init_scale", "=", "0.01", ")", "\n", "pi", "=", "tf", ".", "nn", ".", "softmax", "(", "pi_logits", ")", "\n", "q", "=", "fc", "(", "h5", ",", "'q'", ",", "nact", ")", "\n", "\n", "", "a", "=", "sample", "(", "pi_logits", ")", "# could change this to use self.pi instead", "\n", "self", ".", "initial_state", "=", "np", ".", "zeros", "(", "(", "nenv", ",", "nlstm", "*", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "M", "=", "M", "\n", "self", ".", "S", "=", "S", "\n", "self", ".", "pi", "=", "pi", "# actual policy params now", "\n", "self", ".", "q", "=", "q", "\n", "\n", "def", "step", "(", "ob", ",", "state", ",", "mask", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# returns actions, mus, states", "\n", "            ", "a0", ",", "pi0", ",", "s", "=", "sess", ".", "run", "(", "[", "a", ",", "pi", ",", "snew", "]", ",", "{", "X", ":", "ob", ",", "S", ":", "state", ",", "M", ":", "mask", "}", ")", "\n", "return", "a0", ",", "pi0", ",", "s", "\n", "\n", "", "self", ".", "step", "=", "step", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.runner.Runner.__init__": [[9, 24], ["baselines.common.runners.AbstractEnvRunner.__init__", "isinstance", "isinstance", "env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["\n", "def", "__init__", "(", "self", ",", "env", ",", "model", ",", "nsteps", "=", "5", ",", "gamma", "=", "0.99", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", "=", "env", ",", "model", "=", "model", ",", "nsteps", "=", "nsteps", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "batch_action_shape", "=", "[", "x", "if", "x", "is", "not", "None", "else", "-", "1", "for", "x", "in", "model", ".", "train_model", ".", "action", ".", "shape", ".", "as_list", "(", ")", "]", "\n", "self", ".", "ob_dtype", "=", "model", ".", "train_model", ".", "X", ".", "dtype", ".", "as_numpy_dtype", "\n", "\n", "", "def", "run", "(", "self", ")", ":", "\n", "# We initialize the lists that will contain the mb of experiences", "\n", "        ", "mb_obs", ",", "mb_rewards", ",", "mb_actions", ",", "mb_values", ",", "mb_dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "mb_states", "=", "self", ".", "states", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.runner.Runner.run": [[26, 61], ["numpy.split", "range", "numpy.asarray().swapaxes.append", "numpy.asarray().swapaxes.append", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "numpy.asarray().swapaxes", "runner.Runner.model._step", "numpy.asarray().swapaxes.append", "numpy.asarray().swapaxes.append", "numpy.asarray().swapaxes.append", "numpy.asarray().swapaxes.append", "runner.Runner.env.step", "numpy.asarray().swapaxes.append", "numpy.asarray().swapaxes.append", "numpy.copy", "numpy.copy", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["for", "n", "in", "range", "(", "self", ".", "nsteps", ")", ":", "\n", "# Given observations, take action and value (V(s))", "\n", "# We already have self.obs because Runner superclass run self.obs[:] = env.reset() on init", "\n", "            ", "actions", ",", "values", ",", "states", ",", "_", "=", "self", ".", "model", ".", "step", "(", "self", ".", "obs", ",", "S", "=", "self", ".", "states", ",", "M", "=", "self", ".", "dones", ")", "\n", "\n", "# Append the experiences", "\n", "mb_obs", ".", "append", "(", "np", ".", "copy", "(", "self", ".", "obs", ")", ")", "\n", "mb_actions", ".", "append", "(", "actions", ")", "\n", "mb_values", ".", "append", "(", "values", ")", "\n", "mb_dones", ".", "append", "(", "self", ".", "dones", ")", "\n", "\n", "# Take actions in env and look the results", "\n", "obs", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "env", ".", "step", "(", "actions", ")", "\n", "for", "info", "in", "infos", ":", "\n", "                ", "maybeepinfo", "=", "info", ".", "get", "(", "'episode'", ")", "\n", "if", "maybeepinfo", ":", "epinfos", ".", "append", "(", "maybeepinfo", ")", "\n", "", "self", ".", "states", "=", "states", "\n", "self", ".", "dones", "=", "dones", "\n", "self", ".", "obs", "=", "obs", "\n", "mb_rewards", ".", "append", "(", "rewards", ")", "\n", "", "mb_dones", ".", "append", "(", "self", ".", "dones", ")", "\n", "\n", "# Batch of steps to batch of rollouts", "\n", "mb_obs", "=", "np", ".", "asarray", "(", "mb_obs", ",", "dtype", "=", "self", ".", "ob_dtype", ")", ".", "swapaxes", "(", "1", ",", "0", ")", ".", "reshape", "(", "self", ".", "batch_ob_shape", ")", "\n", "mb_rewards", "=", "np", ".", "asarray", "(", "mb_rewards", ",", "dtype", "=", "np", ".", "float32", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_actions", "=", "np", ".", "asarray", "(", "mb_actions", ",", "dtype", "=", "self", ".", "model", ".", "train_model", ".", "action", ".", "dtype", ".", "name", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_values", "=", "np", ".", "asarray", "(", "mb_values", ",", "dtype", "=", "np", ".", "float32", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_dones", "=", "np", ".", "asarray", "(", "mb_dones", ",", "dtype", "=", "np", ".", "bool", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_masks", "=", "mb_dones", "[", ":", ",", ":", "-", "1", "]", "\n", "mb_dones", "=", "mb_dones", "[", ":", ",", "1", ":", "]", "\n", "\n", "\n", "if", "self", ".", "gamma", ">", "0.0", ":", "\n", "# Discount/bootstrap off value fn", "\n", "            ", "last_values", "=", "self", ".", "model", ".", "value", "(", "self", ".", "obs", ",", "S", "=", "self", ".", "states", ",", "M", "=", "self", ".", "dones", ")", ".", "tolist", "(", ")", "\n", "for", "n", ",", "(", "rewards", ",", "dones", ",", "value", ")", "in", "enumerate", "(", "zip", "(", "mb_rewards", ",", "mb_dones", ",", "last_values", ")", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.Model.__init__": [[59, 228], ["baselines.common.tf_util.get_session", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.a2c.utils.find_trainable_variables", "print", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reduce_sum", "map", "baselines.a2c.utils.get_by_index", "baselines.a2c.utils.get_by_index", "baselines.a2c.utils.get_by_index", "acer.q_retrace", "tensorflow.reduce_mean", "acer.strip", "baselines.a2c.utils.check_shape", "baselines.a2c.utils.check_shape", "tensorflow.log", "tensorflow.log", "baselines.a2c.utils.check_shape", "tensorflow.reduce_sum", "baselines.a2c.utils.check_shape", "baselines.a2c.utils.q_explained_variance", "tensorflow.reduce_mean", "baselines.a2c.utils.check_shape", "list", "tensorflow.train.RMSPropOptimizer", "tensorflow.train.RMSPropOptimizer.apply_gradients", "baselines.a2c.utils.Scheduler", "functools.partial", "functools.partial", "tensorflow.global_variables_initializer().run", "tensorflow.variable_scope", "policy", "policy", "print", "tensorflow.train.ExponentialMovingAverage.average", "print", "tensorflow.variable_scope", "policy", "baselines.a2c.utils.cat_entropy_softmax", "tensorflow.stop_gradient", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.gradients", "tensorflow.reduce_sum", "tensorflow.maximum", "baselines.a2c.utils.avg_norm", "baselines.a2c.utils.avg_norm", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.gradients", "tensorflow.gradients", "tensorflow.global_norm", "tensorflow.global_norm", "tensorflow.gradients", "tensorflow.clip_by_global_norm", "zip", "tensorflow.control_dependencies", "tensorflow.group", "baselines.a2c.utils.Scheduler.value_steps", "policy._evaluate", "len", "getter", "acer.strip", "tensorflow.stop_gradient", "tensorflow.square", "tensorflow.abs", "tensorflow.abs", "baselines.a2c.utils.gradient_add", "baselines.a2c.utils.avg_norm", "tensorflow.global_variables_initializer", "tensorflow.minimum", "tensorflow.reshape", "zip", "baselines.common.tf_util.get_session.run", "tensorflow.stop_gradient", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.nn.relu", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.find_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.get_by_index", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.get_by_index", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.get_by_index", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.q_retrace", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.strip", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.q_explained_variance", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.cat_entropy_softmax", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.avg_norm", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.avg_norm", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.Scheduler.value_steps", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue._evaluate", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.strip", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.gradient_add", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.avg_norm", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["    ", "def", "__init__", "(", "self", ",", "policy", ",", "ob_space", ",", "ac_space", ",", "nenvs", ",", "nsteps", ",", "ent_coef", ",", "q_coef", ",", "gamma", ",", "max_grad_norm", ",", "lr", ",", "\n", "rprop_alpha", ",", "rprop_epsilon", ",", "total_timesteps", ",", "lrschedule", ",", "\n", "c", ",", "trust_region", ",", "alpha", ",", "delta", ")", ":", "\n", "\n", "        ", "sess", "=", "get_session", "(", ")", "\n", "nact", "=", "ac_space", ".", "n", "\n", "nbatch", "=", "nenvs", "*", "nsteps", "\n", "\n", "A", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "nbatch", "]", ")", "# actions", "\n", "D", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "# dones", "\n", "R", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "# rewards, not returns", "\n", "MU", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", ",", "nact", "]", ")", "# mu's", "\n", "LR", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ")", "\n", "eps", "=", "1e-6", "\n", "\n", "step_ob_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "ob_space", ".", "dtype", ",", "shape", "=", "(", "nenvs", ",", ")", "+", "ob_space", ".", "shape", ")", "\n", "train_ob_placeholder", "=", "tf", ".", "placeholder", "(", "dtype", "=", "ob_space", ".", "dtype", ",", "shape", "=", "(", "nenvs", "*", "(", "nsteps", "+", "1", ")", ",", ")", "+", "ob_space", ".", "shape", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'acer_model'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "\n", "            ", "step_model", "=", "policy", "(", "nbatch", "=", "nenvs", ",", "nsteps", "=", "1", ",", "observ_placeholder", "=", "step_ob_placeholder", ",", "sess", "=", "sess", ")", "\n", "train_model", "=", "policy", "(", "nbatch", "=", "nbatch", ",", "nsteps", "=", "nsteps", ",", "observ_placeholder", "=", "train_ob_placeholder", ",", "sess", "=", "sess", ")", "\n", "\n", "\n", "", "params", "=", "find_trainable_variables", "(", "\"acer_model\"", ")", "\n", "print", "(", "\"Params {}\"", ".", "format", "(", "len", "(", "params", ")", ")", ")", "\n", "for", "var", "in", "params", ":", "\n", "            ", "print", "(", "var", ")", "\n", "\n", "# create polyak averaged model", "\n", "", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "alpha", ")", "\n", "ema_apply_op", "=", "ema", ".", "apply", "(", "params", ")", "\n", "\n", "def", "custom_getter", "(", "getter", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "v", "=", "ema", ".", "average", "(", "getter", "(", "*", "args", ",", "**", "kwargs", ")", ")", "\n", "print", "(", "v", ".", "name", ")", "\n", "return", "v", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"acer_model\"", ",", "custom_getter", "=", "custom_getter", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "polyak_model", "=", "policy", "(", "nbatch", "=", "nbatch", ",", "nsteps", "=", "nsteps", ",", "observ_placeholder", "=", "train_ob_placeholder", ",", "sess", "=", "sess", ")", "\n", "\n", "# Notation: (var) = batch variable, (var)s = seqeuence variable, (var)_i = variable index by action at step i", "\n", "\n", "# action probability distributions according to train_model, polyak_model and step_model", "\n", "# poilcy.pi is probability distribution parameters; to obtain distribution that sums to 1 need to take softmax", "\n", "", "train_model_p", "=", "tf", ".", "nn", ".", "softmax", "(", "train_model", ".", "pi", ")", "\n", "polyak_model_p", "=", "tf", ".", "nn", ".", "softmax", "(", "polyak_model", ".", "pi", ")", "\n", "step_model_p", "=", "tf", ".", "nn", ".", "softmax", "(", "step_model", ".", "pi", ")", "\n", "v", "=", "tf", ".", "reduce_sum", "(", "train_model_p", "*", "train_model", ".", "q", ",", "axis", "=", "-", "1", ")", "# shape is [nenvs * (nsteps + 1)]", "\n", "\n", "# strip off last step", "\n", "f", ",", "f_pol", ",", "q", "=", "map", "(", "lambda", "var", ":", "strip", "(", "var", ",", "nenvs", ",", "nsteps", ")", ",", "[", "train_model_p", ",", "polyak_model_p", ",", "train_model", ".", "q", "]", ")", "\n", "# Get pi and q values for actions taken", "\n", "f_i", "=", "get_by_index", "(", "f", ",", "A", ")", "\n", "q_i", "=", "get_by_index", "(", "q", ",", "A", ")", "\n", "\n", "# Compute ratios for importance truncation", "\n", "rho", "=", "f", "/", "(", "MU", "+", "eps", ")", "\n", "rho_i", "=", "get_by_index", "(", "rho", ",", "A", ")", "\n", "\n", "# Calculate Q_retrace targets", "\n", "qret", "=", "q_retrace", "(", "R", ",", "D", ",", "q_i", ",", "v", ",", "rho_i", ",", "nenvs", ",", "nsteps", ",", "gamma", ")", "\n", "\n", "# Calculate losses", "\n", "# Entropy", "\n", "# entropy = tf.reduce_mean(strip(train_model.pd.entropy(), nenvs, nsteps))", "\n", "entropy", "=", "tf", ".", "reduce_mean", "(", "cat_entropy_softmax", "(", "f", ")", ")", "\n", "\n", "# Policy Graident loss, with truncated importance sampling & bias correction", "\n", "v", "=", "strip", "(", "v", ",", "nenvs", ",", "nsteps", ",", "True", ")", "\n", "check_shape", "(", "[", "qret", ",", "v", ",", "rho_i", ",", "f_i", "]", ",", "[", "[", "nenvs", "*", "nsteps", "]", "]", "*", "4", ")", "\n", "check_shape", "(", "[", "rho", ",", "f", ",", "q", "]", ",", "[", "[", "nenvs", "*", "nsteps", ",", "nact", "]", "]", "*", "2", ")", "\n", "\n", "# Truncated importance sampling", "\n", "adv", "=", "qret", "-", "v", "\n", "logf", "=", "tf", ".", "log", "(", "f_i", "+", "eps", ")", "\n", "gain_f", "=", "logf", "*", "tf", ".", "stop_gradient", "(", "adv", "*", "tf", ".", "minimum", "(", "c", ",", "rho_i", ")", ")", "# [nenvs * nsteps]", "\n", "loss_f", "=", "-", "tf", ".", "reduce_mean", "(", "gain_f", ")", "\n", "\n", "# Bias correction for the truncation", "\n", "adv_bc", "=", "(", "q", "-", "tf", ".", "reshape", "(", "v", ",", "[", "nenvs", "*", "nsteps", ",", "1", "]", ")", ")", "# [nenvs * nsteps, nact]", "\n", "logf_bc", "=", "tf", ".", "log", "(", "f", "+", "eps", ")", "# / (f_old + eps)", "\n", "check_shape", "(", "[", "adv_bc", ",", "logf_bc", "]", ",", "[", "[", "nenvs", "*", "nsteps", ",", "nact", "]", "]", "*", "2", ")", "\n", "gain_bc", "=", "tf", ".", "reduce_sum", "(", "logf_bc", "*", "tf", ".", "stop_gradient", "(", "adv_bc", "*", "tf", ".", "nn", ".", "relu", "(", "1.0", "-", "(", "c", "/", "(", "rho", "+", "eps", ")", ")", ")", "*", "f", ")", ",", "axis", "=", "1", ")", "#IMP: This is sum, as expectation wrt f", "\n", "loss_bc", "=", "-", "tf", ".", "reduce_mean", "(", "gain_bc", ")", "\n", "\n", "loss_policy", "=", "loss_f", "+", "loss_bc", "\n", "\n", "# Value/Q function loss, and explained variance", "\n", "check_shape", "(", "[", "qret", ",", "q_i", "]", ",", "[", "[", "nenvs", "*", "nsteps", "]", "]", "*", "2", ")", "\n", "ev", "=", "q_explained_variance", "(", "tf", ".", "reshape", "(", "q_i", ",", "[", "nenvs", ",", "nsteps", "]", ")", ",", "tf", ".", "reshape", "(", "qret", ",", "[", "nenvs", ",", "nsteps", "]", ")", ")", "\n", "loss_q", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "tf", ".", "stop_gradient", "(", "qret", ")", "-", "q_i", ")", "*", "0.5", ")", "\n", "\n", "# Net loss", "\n", "check_shape", "(", "[", "loss_policy", ",", "loss_q", ",", "entropy", "]", ",", "[", "[", "]", "]", "*", "3", ")", "\n", "loss", "=", "loss_policy", "+", "q_coef", "*", "loss_q", "-", "ent_coef", "*", "entropy", "\n", "\n", "if", "trust_region", ":", "\n", "            ", "g", "=", "tf", ".", "gradients", "(", "-", "(", "loss_policy", "-", "ent_coef", "*", "entropy", ")", "*", "nsteps", "*", "nenvs", ",", "f", ")", "#[nenvs * nsteps, nact]", "\n", "# k = tf.gradients(KL(f_pol || f), f)", "\n", "k", "=", "-", "f_pol", "/", "(", "f", "+", "eps", ")", "#[nenvs * nsteps, nact] # Directly computed gradient of KL divergence wrt f", "\n", "k_dot_g", "=", "tf", ".", "reduce_sum", "(", "k", "*", "g", ",", "axis", "=", "-", "1", ")", "\n", "adj", "=", "tf", ".", "maximum", "(", "0.0", ",", "(", "tf", ".", "reduce_sum", "(", "k", "*", "g", ",", "axis", "=", "-", "1", ")", "-", "delta", ")", "/", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "k", ")", ",", "axis", "=", "-", "1", ")", "+", "eps", ")", ")", "#[nenvs * nsteps]", "\n", "\n", "# Calculate stats (before doing adjustment) for logging.", "\n", "avg_norm_k", "=", "avg_norm", "(", "k", ")", "\n", "avg_norm_g", "=", "avg_norm", "(", "g", ")", "\n", "avg_norm_k_dot_g", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "k_dot_g", ")", ")", "\n", "avg_norm_adj", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "abs", "(", "adj", ")", ")", "\n", "\n", "g", "=", "g", "-", "tf", ".", "reshape", "(", "adj", ",", "[", "nenvs", "*", "nsteps", ",", "1", "]", ")", "*", "k", "\n", "grads_f", "=", "-", "g", "/", "(", "nenvs", "*", "nsteps", ")", "# These are turst region adjusted gradients wrt f ie statistics of policy pi", "\n", "grads_policy", "=", "tf", ".", "gradients", "(", "f", ",", "params", ",", "grads_f", ")", "\n", "grads_q", "=", "tf", ".", "gradients", "(", "loss_q", "*", "q_coef", ",", "params", ")", "\n", "grads", "=", "[", "gradient_add", "(", "g1", ",", "g2", ",", "param", ")", "for", "(", "g1", ",", "g2", ",", "param", ")", "in", "zip", "(", "grads_policy", ",", "grads_q", ",", "params", ")", "]", "\n", "\n", "avg_norm_grads_f", "=", "avg_norm", "(", "grads_f", ")", "*", "(", "nsteps", "*", "nenvs", ")", "\n", "norm_grads_q", "=", "tf", ".", "global_norm", "(", "grads_q", ")", "\n", "norm_grads_policy", "=", "tf", ".", "global_norm", "(", "grads_policy", ")", "\n", "", "else", ":", "\n", "            ", "grads", "=", "tf", ".", "gradients", "(", "loss", ",", "params", ")", "\n", "\n", "", "if", "max_grad_norm", "is", "not", "None", ":", "\n", "            ", "grads", ",", "norm_grads", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "max_grad_norm", ")", "\n", "", "grads", "=", "list", "(", "zip", "(", "grads", ",", "params", ")", ")", "\n", "trainer", "=", "tf", ".", "train", ".", "RMSPropOptimizer", "(", "learning_rate", "=", "LR", ",", "decay", "=", "rprop_alpha", ",", "epsilon", "=", "rprop_epsilon", ")", "\n", "_opt_op", "=", "trainer", ".", "apply_gradients", "(", "grads", ")", "\n", "\n", "# so when you call _train, you first do the gradient step, then you apply ema", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "_opt_op", "]", ")", ":", "\n", "            ", "_train", "=", "tf", ".", "group", "(", "ema_apply_op", ")", "\n", "\n", "", "lr", "=", "Scheduler", "(", "v", "=", "lr", ",", "nvalues", "=", "total_timesteps", ",", "schedule", "=", "lrschedule", ")", "\n", "\n", "# Ops/Summaries to run, and their names for logging", "\n", "run_ops", "=", "[", "_train", ",", "loss", ",", "loss_q", ",", "entropy", ",", "loss_policy", ",", "loss_f", ",", "loss_bc", ",", "ev", ",", "norm_grads", "]", "\n", "names_ops", "=", "[", "'loss'", ",", "'loss_q'", ",", "'entropy'", ",", "'loss_policy'", ",", "'loss_f'", ",", "'loss_bc'", ",", "'explained_variance'", ",", "\n", "'norm_grads'", "]", "\n", "if", "trust_region", ":", "\n", "            ", "run_ops", "=", "run_ops", "+", "[", "norm_grads_q", ",", "norm_grads_policy", ",", "avg_norm_grads_f", ",", "avg_norm_k", ",", "avg_norm_g", ",", "avg_norm_k_dot_g", ",", "\n", "avg_norm_adj", "]", "\n", "names_ops", "=", "names_ops", "+", "[", "'norm_grads_q'", ",", "'norm_grads_policy'", ",", "'avg_norm_grads_f'", ",", "'avg_norm_k'", ",", "'avg_norm_g'", ",", "\n", "'avg_norm_k_dot_g'", ",", "'avg_norm_adj'", "]", "\n", "\n", "", "def", "train", "(", "obs", ",", "actions", ",", "rewards", ",", "dones", ",", "mus", ",", "states", ",", "masks", ",", "steps", ")", ":", "\n", "            ", "cur_lr", "=", "lr", ".", "value_steps", "(", "steps", ")", "\n", "td_map", "=", "{", "train_model", ".", "X", ":", "obs", ",", "polyak_model", ".", "X", ":", "obs", ",", "A", ":", "actions", ",", "R", ":", "rewards", ",", "D", ":", "dones", ",", "MU", ":", "mus", ",", "LR", ":", "cur_lr", "}", "\n", "if", "states", "is", "not", "None", ":", "\n", "                ", "td_map", "[", "train_model", ".", "S", "]", "=", "states", "\n", "td_map", "[", "train_model", ".", "M", "]", "=", "masks", "\n", "td_map", "[", "polyak_model", ".", "S", "]", "=", "states", "\n", "td_map", "[", "polyak_model", ".", "M", "]", "=", "masks", "\n", "\n", "", "return", "names_ops", ",", "sess", ".", "run", "(", "run_ops", ",", "td_map", ")", "[", "1", ":", "]", "# strip off _train", "\n", "\n", "", "def", "_step", "(", "observation", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "step_model", ".", "_evaluate", "(", "[", "step_model", ".", "action", ",", "step_model_p", ",", "step_model", ".", "state", "]", ",", "observation", ",", "**", "kwargs", ")", "\n", "\n", "\n", "\n", "", "self", ".", "train", "=", "train", "\n", "self", ".", "save", "=", "functools", ".", "partial", "(", "save_variables", ",", "sess", "=", "sess", ")", "\n", "self", ".", "load", "=", "functools", ".", "partial", "(", "load_variables", ",", "sess", "=", "sess", ")", "\n", "self", ".", "train_model", "=", "train_model", "\n", "self", ".", "step_model", "=", "step_model", "\n", "self", ".", "_step", "=", "_step", "\n", "self", ".", "step", "=", "self", ".", "step_model", ".", "step", "\n", "\n", "self", ".", "initial_state", "=", "step_model", ".", "initial_state", "\n", "tf", ".", "global_variables_initializer", "(", ")", ".", "run", "(", "session", "=", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.Acer.__init__": [[231, 239], ["baselines.a2c.utils.EpisodeStats"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "runner", ",", "model", ",", "buffer", ",", "log_interval", ")", ":", "\n", "        ", "self", ".", "runner", "=", "runner", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "buffer", "=", "buffer", "\n", "self", ".", "log_interval", "=", "log_interval", "\n", "self", ".", "tstart", "=", "None", "\n", "self", ".", "episode_stats", "=", "EpisodeStats", "(", "runner", ".", "nsteps", ",", "runner", ".", "nenv", ")", "\n", "self", ".", "steps", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.Acer.call": [[240, 273], ["obs.reshape.reshape.reshape", "actions.reshape.reshape.reshape", "rewards.reshape.reshape.reshape", "mus.reshape.reshape.reshape", "dones.reshape.reshape.reshape", "masks.reshape.reshape.reshape", "model.train", "runner.run", "acer.Acer.episode_stats.feed", "buffer.get", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "zip", "baselines.logger.dump_tabular", "buffer.put", "int", "acer.Acer.episode_stats.mean_length", "acer.Acer.episode_stats.mean_reward", "baselines.logger.record_tabular", "int", "float", "time.time"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.EpisodeStats.feed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.put", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.EpisodeStats.mean_length", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.EpisodeStats.mean_reward"], ["", "def", "call", "(", "self", ",", "on_policy", ")", ":", "\n", "        ", "runner", ",", "model", ",", "buffer", ",", "steps", "=", "self", ".", "runner", ",", "self", ".", "model", ",", "self", ".", "buffer", ",", "self", ".", "steps", "\n", "if", "on_policy", ":", "\n", "            ", "enc_obs", ",", "obs", ",", "actions", ",", "rewards", ",", "mus", ",", "dones", ",", "masks", "=", "runner", ".", "run", "(", ")", "\n", "self", ".", "episode_stats", ".", "feed", "(", "rewards", ",", "dones", ")", "\n", "if", "buffer", "is", "not", "None", ":", "\n", "                ", "buffer", ".", "put", "(", "enc_obs", ",", "actions", ",", "rewards", ",", "mus", ",", "dones", ",", "masks", ")", "\n", "", "", "else", ":", "\n", "# get obs, actions, rewards, mus, dones from buffer.", "\n", "            ", "obs", ",", "actions", ",", "rewards", ",", "mus", ",", "dones", ",", "masks", "=", "buffer", ".", "get", "(", ")", "\n", "\n", "\n", "# reshape stuff correctly", "\n", "", "obs", "=", "obs", ".", "reshape", "(", "runner", ".", "batch_ob_shape", ")", "\n", "actions", "=", "actions", ".", "reshape", "(", "[", "runner", ".", "nbatch", "]", ")", "\n", "rewards", "=", "rewards", ".", "reshape", "(", "[", "runner", ".", "nbatch", "]", ")", "\n", "mus", "=", "mus", ".", "reshape", "(", "[", "runner", ".", "nbatch", ",", "runner", ".", "nact", "]", ")", "\n", "dones", "=", "dones", ".", "reshape", "(", "[", "runner", ".", "nbatch", "]", ")", "\n", "masks", "=", "masks", ".", "reshape", "(", "[", "runner", ".", "batch_ob_shape", "[", "0", "]", "]", ")", "\n", "\n", "names_ops", ",", "values_ops", "=", "model", ".", "train", "(", "obs", ",", "actions", ",", "rewards", ",", "dones", ",", "mus", ",", "model", ".", "initial_state", ",", "masks", ",", "steps", ")", "\n", "\n", "if", "on_policy", "and", "(", "int", "(", "steps", "/", "runner", ".", "nbatch", ")", "%", "self", ".", "log_interval", "==", "0", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "\"total_timesteps\"", ",", "steps", ")", "\n", "logger", ".", "record_tabular", "(", "\"fps\"", ",", "int", "(", "steps", "/", "(", "time", ".", "time", "(", ")", "-", "self", ".", "tstart", ")", ")", ")", "\n", "# IMP: In EpisodicLife env, during training, we get done=True at each loss of life, not just at the terminal state.", "\n", "# Thus, this is mean until end of life, not end of episode.", "\n", "# For true episode rewards, see the monitor files in the log folder.", "\n", "logger", ".", "record_tabular", "(", "\"mean_episode_length\"", ",", "self", ".", "episode_stats", ".", "mean_length", "(", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"mean_episode_reward\"", ",", "self", ".", "episode_stats", ".", "mean_reward", "(", ")", ")", "\n", "for", "name", ",", "val", "in", "zip", "(", "names_ops", ",", "values_ops", ")", ":", "\n", "                ", "logger", ".", "record_tabular", "(", "name", ",", "float", "(", "val", ")", ")", "\n", "", "logger", ".", "dump_tabular", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.strip": [[21, 24], ["baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.seq_to_batch"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.seq_to_batch"], ["def", "strip", "(", "var", ",", "nenvs", ",", "nsteps", ",", "flat", "=", "False", ")", ":", "\n", "    ", "vars", "=", "batch_to_seq", "(", "var", ",", "nenvs", ",", "nsteps", "+", "1", ",", "flat", ")", "\n", "return", "seq_to_batch", "(", "vars", "[", ":", "-", "1", "]", ",", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.q_retrace": [[25, 52], ["baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.batch_to_seq", "range", "baselines.a2c.utils.seq_to_batch", "tensorflow.minimum", "baselines.a2c.utils.check_shape", "qrets.append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.seq_to_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.check_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "q_retrace", "(", "R", ",", "D", ",", "q_i", ",", "v", ",", "rho_i", ",", "nenvs", ",", "nsteps", ",", "gamma", ")", ":", "\n", "    ", "\"\"\"\n    Calculates q_retrace targets\n\n    :param R: Rewards\n    :param D: Dones\n    :param q_i: Q values for actions taken\n    :param v: V values\n    :param rho_i: Importance weight for each action\n    :return: Q_retrace values\n    \"\"\"", "\n", "rho_bar", "=", "batch_to_seq", "(", "tf", ".", "minimum", "(", "1.0", ",", "rho_i", ")", ",", "nenvs", ",", "nsteps", ",", "True", ")", "# list of len steps, shape [nenvs]", "\n", "rs", "=", "batch_to_seq", "(", "R", ",", "nenvs", ",", "nsteps", ",", "True", ")", "# list of len steps, shape [nenvs]", "\n", "ds", "=", "batch_to_seq", "(", "D", ",", "nenvs", ",", "nsteps", ",", "True", ")", "# list of len steps, shape [nenvs]", "\n", "q_is", "=", "batch_to_seq", "(", "q_i", ",", "nenvs", ",", "nsteps", ",", "True", ")", "\n", "vs", "=", "batch_to_seq", "(", "v", ",", "nenvs", ",", "nsteps", "+", "1", ",", "True", ")", "\n", "v_final", "=", "vs", "[", "-", "1", "]", "\n", "qret", "=", "v_final", "\n", "qrets", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "nsteps", "-", "1", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "        ", "check_shape", "(", "[", "qret", ",", "ds", "[", "i", "]", ",", "rs", "[", "i", "]", ",", "rho_bar", "[", "i", "]", ",", "q_is", "[", "i", "]", ",", "vs", "[", "i", "]", "]", ",", "[", "[", "nenvs", "]", "]", "*", "6", ")", "\n", "qret", "=", "rs", "[", "i", "]", "+", "gamma", "*", "qret", "*", "(", "1.0", "-", "ds", "[", "i", "]", ")", "\n", "qrets", ".", "append", "(", "qret", ")", "\n", "qret", "=", "(", "rho_bar", "[", "i", "]", "*", "(", "qret", "-", "q_is", "[", "i", "]", ")", ")", "+", "vs", "[", "i", "]", "\n", "", "qrets", "=", "qrets", "[", ":", ":", "-", "1", "]", "\n", "qret", "=", "seq_to_batch", "(", "qrets", ",", "flat", "=", "True", ")", "\n", "return", "qret", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.learn": [[275, 382], ["int", "print", "print", "baselines.common.set_global_seeds", "baselines.common.policies.build_policy", "acer.Model", "baselines.acer.runner.Runner", "acer.Acer", "time.time", "range", "locals", "isinstance", "baselines.common.vec_env.vec_frame_stack.VecFrameStack", "Model.load", "baselines.acer.buffer.Buffer", "acer.Acer.call", "baselines.acer.buffer.Buffer.has_atleast", "numpy.random.poisson", "range", "acer.Acer.call"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.build_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.Acer.call", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.has_atleast", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.acer.Acer.call"], ["", "", "", "def", "learn", "(", "network", ",", "env", ",", "seed", "=", "None", ",", "nsteps", "=", "20", ",", "total_timesteps", "=", "int", "(", "80e6", ")", ",", "q_coef", "=", "0.5", ",", "ent_coef", "=", "0.01", ",", "\n", "max_grad_norm", "=", "10", ",", "lr", "=", "7e-4", ",", "lrschedule", "=", "'linear'", ",", "rprop_epsilon", "=", "1e-5", ",", "rprop_alpha", "=", "0.99", ",", "gamma", "=", "0.99", ",", "\n", "log_interval", "=", "100", ",", "buffer_size", "=", "50000", ",", "replay_ratio", "=", "4", ",", "replay_start", "=", "10000", ",", "c", "=", "10.0", ",", "\n", "trust_region", "=", "True", ",", "alpha", "=", "0.99", ",", "delta", "=", "1", ",", "load_path", "=", "None", ",", "**", "network_kwargs", ")", ":", "\n", "\n", "    ", "'''\n    Main entrypoint for ACER (Actor-Critic with Experience Replay) algorithm (https://arxiv.org/pdf/1611.01224.pdf)\n    Train an agent with given network architecture on a given environment using ACER.\n\n    Parameters:\n    ----------\n\n    network:            policy network architecture. Either string (mlp, lstm, lnlstm, cnn_lstm, cnn, cnn_small, conv_only - see baselines.common/models.py for full list)\n                        specifying the standard network architecture, or a function that takes tensorflow tensor as input and returns\n                        tuple (output_tensor, extra_feed) where output tensor is the last network layer output, extra_feed is None for feed-forward\n                        neural nets, and extra_feed is a dictionary describing how to feed state into the network for recurrent neural nets.\n                        See baselines.common/policies.py/lstm for more details on using recurrent nets in policies\n\n    env:                environment. Needs to be vectorized for parallel environment simulation.\n                        The environments produced by gym.make can be wrapped using baselines.common.vec_env.DummyVecEnv class.\n\n    nsteps:             int, number of steps of the vectorized environment per update (i.e. batch size is nsteps * nenv where\n                        nenv is number of environment copies simulated in parallel) (default: 20)\n\n    nstack:             int, size of the frame stack, i.e. number of the frames passed to the step model. Frames are stacked along channel dimension\n                        (last image dimension) (default: 4)\n\n    total_timesteps:    int, number of timesteps (i.e. number of actions taken in the environment) (default: 80M)\n\n    q_coef:             float, value function loss coefficient in the optimization objective (analog of vf_coef for other actor-critic methods)\n\n    ent_coef:           float, policy entropy coefficient in the optimization objective (default: 0.01)\n\n    max_grad_norm:      float, gradient norm clipping coefficient. If set to None, no clipping. (default: 10),\n\n    lr:                 float, learning rate for RMSProp (current implementation has RMSProp hardcoded in) (default: 7e-4)\n\n    lrschedule:         schedule of learning rate. Can be 'linear', 'constant', or a function [0..1] -> [0..1] that takes fraction of the training progress as input and\n                        returns fraction of the learning rate (specified as lr) as output\n\n    rprop_epsilon:      float, RMSProp epsilon (stabilizes square root computation in denominator of RMSProp update) (default: 1e-5)\n\n    rprop_alpha:        float, RMSProp decay parameter (default: 0.99)\n\n    gamma:              float, reward discounting factor (default: 0.99)\n\n    log_interval:       int, number of updates between logging events (default: 100)\n\n    buffer_size:        int, size of the replay buffer (default: 50k)\n\n    replay_ratio:       int, now many (on average) batches of data to sample from the replay buffer take after batch from the environment (default: 4)\n\n    replay_start:       int, the sampling from the replay buffer does not start until replay buffer has at least that many samples (default: 10k)\n\n    c:                  float, importance weight clipping factor (default: 10)\n\n    trust_region        bool, whether or not algorithms estimates the gradient KL divergence between the old and updated policy and uses it to determine step size  (default: True)\n\n    delta:              float, max KL divergence between the old policy and updated policy (default: 1)\n\n    alpha:              float, momentum factor in the Polyak (exponential moving average) averaging of the model parameters (default: 0.99)\n\n    load_path:          str, path to load the model from (default: None)\n\n    **network_kwargs:               keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n                                    For instance, 'mlp' network architecture has arguments num_hidden and num_layers.\n\n    '''", "\n", "\n", "print", "(", "\"Running Acer Simple\"", ")", "\n", "print", "(", "locals", "(", ")", ")", "\n", "set_global_seeds", "(", "seed", ")", "\n", "if", "not", "isinstance", "(", "env", ",", "VecFrameStack", ")", ":", "\n", "        ", "env", "=", "VecFrameStack", "(", "env", ",", "1", ")", "\n", "\n", "", "policy", "=", "build_policy", "(", "env", ",", "network", ",", "estimate_q", "=", "True", ",", "**", "network_kwargs", ")", "\n", "nenvs", "=", "env", ".", "num_envs", "\n", "ob_space", "=", "env", ".", "observation_space", "\n", "ac_space", "=", "env", ".", "action_space", "\n", "\n", "nstack", "=", "env", ".", "nstack", "\n", "model", "=", "Model", "(", "policy", "=", "policy", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ",", "nenvs", "=", "nenvs", ",", "nsteps", "=", "nsteps", ",", "\n", "ent_coef", "=", "ent_coef", ",", "q_coef", "=", "q_coef", ",", "gamma", "=", "gamma", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ",", "lr", "=", "lr", ",", "rprop_alpha", "=", "rprop_alpha", ",", "rprop_epsilon", "=", "rprop_epsilon", ",", "\n", "total_timesteps", "=", "total_timesteps", ",", "lrschedule", "=", "lrschedule", ",", "c", "=", "c", ",", "\n", "trust_region", "=", "trust_region", ",", "alpha", "=", "alpha", ",", "delta", "=", "delta", ")", "\n", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "model", ".", "load", "(", "load_path", ")", "\n", "\n", "", "runner", "=", "Runner", "(", "env", "=", "env", ",", "model", "=", "model", ",", "nsteps", "=", "nsteps", ")", "\n", "if", "replay_ratio", ">", "0", ":", "\n", "        ", "buffer", "=", "Buffer", "(", "env", "=", "env", ",", "nsteps", "=", "nsteps", ",", "size", "=", "buffer_size", ")", "\n", "", "else", ":", "\n", "        ", "buffer", "=", "None", "\n", "", "nbatch", "=", "nenvs", "*", "nsteps", "\n", "acer", "=", "Acer", "(", "runner", ",", "model", ",", "buffer", ",", "log_interval", ")", "\n", "acer", ".", "tstart", "=", "time", ".", "time", "(", ")", "\n", "\n", "for", "acer", ".", "steps", "in", "range", "(", "0", ",", "total_timesteps", ",", "nbatch", ")", ":", "#nbatch samples, 1 on_policy call and multiple off-policy calls", "\n", "        ", "acer", ".", "call", "(", "on_policy", "=", "True", ")", "\n", "if", "replay_ratio", ">", "0", "and", "buffer", ".", "has_atleast", "(", "replay_start", ")", ":", "\n", "            ", "n", "=", "np", ".", "random", ".", "poisson", "(", "replay_ratio", ")", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "                ", "acer", ".", "call", "(", "on_policy", "=", "False", ")", "# no simulation steps in this", "\n", "\n", "", "", "", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.constfn": [[16, 20], ["None"], "function", ["None"], ["def", "constfn", "(", "val", ")", ":", "\n", "    ", "def", "f", "(", "_", ")", ":", "\n", "        ", "return", "val", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.learn": [[21, 219], ["baselines.common.set_global_seeds", "isinstance", "isinstance", "int", "baselines.common.policies.build_policy", "model_fn", "baselines.ppo2.runner.Runner", "collections.deque", "time.perf_counter", "range", "ppo2.constfn", "callable", "ppo2.constfn", "callable", "model_fn.load", "baselines.ppo2.runner.Runner", "collections.deque", "init_fn", "time.perf_counter", "constfn.", "constfn.", "baselines.ppo2.runner.Runner.run", "collections.deque.extend", "numpy.mean", "time.perf_counter", "int", "MPI.COMM_WORLD.Get_rank", "baselines.logger.info", "baselines.ppo2.runner.Runner.run", "baselines.logger.info", "collections.deque.extend", "numpy.arange", "range", "numpy.arange", "numpy.arange().reshape", "range", "update_fn", "baselines.common.explained_variance", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.logkv", "zip", "baselines.logger.dumpkvs", "baselines.logger.get_dir", "os.join", "os.makedirs", "os.makedirs", "os.join", "print", "model_fn.save", "numpy.random.shuffle", "range", "numpy.random.shuffle", "range", "float", "ppo2.safemean", "ppo2.safemean", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.logkv", "baselines.logger.get_dir", "mblossvals.append", "numpy.arange", "flatinds[].ravel", "mblossvals.append", "ppo2.safemean", "ppo2.safemean", "model_fn.train", "model_fn.train"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.build_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.constfn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.constfn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.explained_variance", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train"], ["", "def", "learn", "(", "*", ",", "network", ",", "env", ",", "total_timesteps", ",", "eval_env", "=", "None", ",", "seed", "=", "None", ",", "nsteps", "=", "2048", ",", "ent_coef", "=", "0.0", ",", "lr", "=", "3e-4", ",", "\n", "vf_coef", "=", "0.5", ",", "max_grad_norm", "=", "0.5", ",", "gamma", "=", "0.99", ",", "lam", "=", "0.95", ",", "\n", "log_interval", "=", "10", ",", "nminibatches", "=", "4", ",", "noptepochs", "=", "4", ",", "cliprange", "=", "0.2", ",", "\n", "save_interval", "=", "0", ",", "load_path", "=", "None", ",", "model_fn", "=", "None", ",", "update_fn", "=", "None", ",", "init_fn", "=", "None", ",", "mpi_rank_weight", "=", "1", ",", "comm", "=", "None", ",", "**", "network_kwargs", ")", ":", "\n", "    ", "'''\n    Learn policy using PPO algorithm (https://arxiv.org/abs/1707.06347)\n\n    Parameters:\n    ----------\n\n    network:                          policy network architecture. Either string (mlp, lstm, lnlstm, cnn_lstm, cnn, cnn_small, conv_only - see baselines.common/models.py for full list)\n                                      specifying the standard network architecture, or a function that takes tensorflow tensor as input and returns\n                                      tuple (output_tensor, extra_feed) where output tensor is the last network layer output, extra_feed is None for feed-forward\n                                      neural nets, and extra_feed is a dictionary describing how to feed state into the network for recurrent neural nets.\n                                      See common/models.py/lstm for more details on using recurrent nets in policies\n\n    env: baselines.common.vec_env.VecEnv     environment. Needs to be vectorized for parallel environment simulation.\n                                      The environments produced by gym.make can be wrapped using baselines.common.vec_env.DummyVecEnv class.\n\n\n    nsteps: int                       number of steps of the vectorized environment per update (i.e. batch size is nsteps * nenv where\n                                      nenv is number of environment copies simulated in parallel)\n\n    total_timesteps: int              number of timesteps (i.e. number of actions taken in the environment)\n\n    ent_coef: float                   policy entropy coefficient in the optimization objective\n\n    lr: float or function             learning rate, constant or a schedule function [0,1] -> R+ where 1 is beginning of the\n                                      training and 0 is the end of the training.\n\n    vf_coef: float                    value function loss coefficient in the optimization objective\n\n    max_grad_norm: float or None      gradient norm clipping coefficient\n\n    gamma: float                      discounting factor\n\n    lam: float                        advantage estimation discounting factor (lambda in the paper)\n\n    log_interval: int                 number of timesteps between logging events\n\n    nminibatches: int                 number of training minibatches per update. For recurrent policies,\n                                      should be smaller or equal than number of environments run in parallel.\n\n    noptepochs: int                   number of training epochs per update\n\n    cliprange: float or function      clipping range, constant or schedule function [0,1] -> R+ where 1 is beginning of the training\n                                      and 0 is the end of the training\n\n    save_interval: int                number of timesteps between saving events\n\n    load_path: str                    path to load the model from\n\n    **network_kwargs:                 keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n                                      For instance, 'mlp' network architecture has arguments num_hidden and num_layers.\n\n\n\n    '''", "\n", "\n", "set_global_seeds", "(", "seed", ")", "\n", "\n", "if", "isinstance", "(", "lr", ",", "float", ")", ":", "lr", "=", "constfn", "(", "lr", ")", "\n", "else", ":", "assert", "callable", "(", "lr", ")", "\n", "if", "isinstance", "(", "cliprange", ",", "float", ")", ":", "cliprange", "=", "constfn", "(", "cliprange", ")", "\n", "else", ":", "assert", "callable", "(", "cliprange", ")", "\n", "total_timesteps", "=", "int", "(", "total_timesteps", ")", "\n", "\n", "policy", "=", "build_policy", "(", "env", ",", "network", ",", "**", "network_kwargs", ")", "\n", "\n", "# Get the nb of env", "\n", "nenvs", "=", "env", ".", "num_envs", "\n", "\n", "# Get state_space and action_space", "\n", "ob_space", "=", "env", ".", "observation_space", "\n", "ac_space", "=", "env", ".", "action_space", "\n", "\n", "# Calculate the batch_size", "\n", "nbatch", "=", "nenvs", "*", "nsteps", "\n", "nbatch_train", "=", "nbatch", "//", "nminibatches", "\n", "is_mpi_root", "=", "(", "MPI", "is", "None", "or", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "==", "0", ")", "\n", "\n", "# Instantiate the model object (that creates act_model and train_model)", "\n", "if", "model_fn", "is", "None", ":", "\n", "        ", "from", "baselines", ".", "ppo2", ".", "model", "import", "Model", "\n", "model_fn", "=", "Model", "\n", "\n", "", "model", "=", "model_fn", "(", "policy", "=", "policy", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ",", "nbatch_act", "=", "nenvs", ",", "nbatch_train", "=", "nbatch_train", ",", "\n", "nsteps", "=", "nsteps", ",", "ent_coef", "=", "ent_coef", ",", "vf_coef", "=", "vf_coef", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ",", "comm", "=", "comm", ",", "mpi_rank_weight", "=", "mpi_rank_weight", ")", "\n", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "model", ".", "load", "(", "load_path", ")", "\n", "# Instantiate the runner object", "\n", "", "runner", "=", "Runner", "(", "env", "=", "env", ",", "model", "=", "model", ",", "nsteps", "=", "nsteps", ",", "gamma", "=", "gamma", ",", "lam", "=", "lam", ")", "\n", "if", "eval_env", "is", "not", "None", ":", "\n", "        ", "eval_runner", "=", "Runner", "(", "env", "=", "eval_env", ",", "model", "=", "model", ",", "nsteps", "=", "nsteps", ",", "gamma", "=", "gamma", ",", "lam", "=", "lam", ")", "\n", "\n", "", "epinfobuf", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "if", "eval_env", "is", "not", "None", ":", "\n", "        ", "eval_epinfobuf", "=", "deque", "(", "maxlen", "=", "100", ")", "\n", "\n", "", "if", "init_fn", "is", "not", "None", ":", "\n", "        ", "init_fn", "(", ")", "\n", "\n", "# Start total timer", "\n", "", "tfirststart", "=", "time", ".", "perf_counter", "(", ")", "\n", "\n", "nupdates", "=", "total_timesteps", "//", "nbatch", "\n", "for", "update", "in", "range", "(", "1", ",", "nupdates", "+", "1", ")", ":", "\n", "        ", "assert", "nbatch", "%", "nminibatches", "==", "0", "\n", "# Start timer", "\n", "tstart", "=", "time", ".", "perf_counter", "(", ")", "\n", "frac", "=", "1.0", "-", "(", "update", "-", "1.0", ")", "/", "nupdates", "\n", "# Calculate the learning rate", "\n", "lrnow", "=", "lr", "(", "frac", ")", "\n", "# Calculate the cliprange", "\n", "cliprangenow", "=", "cliprange", "(", "frac", ")", "\n", "\n", "if", "update", "%", "log_interval", "==", "0", "and", "is_mpi_root", ":", "logger", ".", "info", "(", "'Stepping environment...'", ")", "\n", "\n", "# Get minibatch", "\n", "obs", ",", "returns", ",", "masks", ",", "actions", ",", "values", ",", "neglogpacs", ",", "states", ",", "epinfos", "=", "runner", ".", "run", "(", ")", "#pylint: disable=E0632", "\n", "if", "eval_env", "is", "not", "None", ":", "\n", "            ", "eval_obs", ",", "eval_returns", ",", "eval_masks", ",", "eval_actions", ",", "eval_values", ",", "eval_neglogpacs", ",", "eval_states", ",", "eval_epinfos", "=", "eval_runner", ".", "run", "(", ")", "#pylint: disable=E0632", "\n", "\n", "", "if", "update", "%", "log_interval", "==", "0", "and", "is_mpi_root", ":", "logger", ".", "info", "(", "'Done.'", ")", "\n", "\n", "epinfobuf", ".", "extend", "(", "epinfos", ")", "\n", "if", "eval_env", "is", "not", "None", ":", "\n", "            ", "eval_epinfobuf", ".", "extend", "(", "eval_epinfos", ")", "\n", "\n", "# Here what we're going to do is for each minibatch calculate the loss and append it.", "\n", "", "mblossvals", "=", "[", "]", "\n", "if", "states", "is", "None", ":", "# nonrecurrent version", "\n", "# Index of each element of batch_size", "\n", "# Create the indices array", "\n", "            ", "inds", "=", "np", ".", "arange", "(", "nbatch", ")", "\n", "for", "_", "in", "range", "(", "noptepochs", ")", ":", "\n", "# Randomize the indexes", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "inds", ")", "\n", "# 0 to batch_size with batch_train_size step", "\n", "for", "start", "in", "range", "(", "0", ",", "nbatch", ",", "nbatch_train", ")", ":", "\n", "                    ", "end", "=", "start", "+", "nbatch_train", "\n", "mbinds", "=", "inds", "[", "start", ":", "end", "]", "\n", "slices", "=", "(", "arr", "[", "mbinds", "]", "for", "arr", "in", "(", "obs", ",", "returns", ",", "masks", ",", "actions", ",", "values", ",", "neglogpacs", ")", ")", "\n", "mblossvals", ".", "append", "(", "model", ".", "train", "(", "lrnow", ",", "cliprangenow", ",", "*", "slices", ")", ")", "\n", "", "", "", "else", ":", "# recurrent version", "\n", "            ", "assert", "nenvs", "%", "nminibatches", "==", "0", "\n", "envsperbatch", "=", "nenvs", "//", "nminibatches", "\n", "envinds", "=", "np", ".", "arange", "(", "nenvs", ")", "\n", "flatinds", "=", "np", ".", "arange", "(", "nenvs", "*", "nsteps", ")", ".", "reshape", "(", "nenvs", ",", "nsteps", ")", "\n", "for", "_", "in", "range", "(", "noptepochs", ")", ":", "\n", "                ", "np", ".", "random", ".", "shuffle", "(", "envinds", ")", "\n", "for", "start", "in", "range", "(", "0", ",", "nenvs", ",", "envsperbatch", ")", ":", "\n", "                    ", "end", "=", "start", "+", "envsperbatch", "\n", "mbenvinds", "=", "envinds", "[", "start", ":", "end", "]", "\n", "mbflatinds", "=", "flatinds", "[", "mbenvinds", "]", ".", "ravel", "(", ")", "\n", "slices", "=", "(", "arr", "[", "mbflatinds", "]", "for", "arr", "in", "(", "obs", ",", "returns", ",", "masks", ",", "actions", ",", "values", ",", "neglogpacs", ")", ")", "\n", "mbstates", "=", "states", "[", "mbenvinds", "]", "\n", "mblossvals", ".", "append", "(", "model", ".", "train", "(", "lrnow", ",", "cliprangenow", ",", "*", "slices", ",", "mbstates", ")", ")", "\n", "\n", "# Feedforward --> get losses --> update", "\n", "", "", "", "lossvals", "=", "np", ".", "mean", "(", "mblossvals", ",", "axis", "=", "0", ")", "\n", "# End timer", "\n", "tnow", "=", "time", ".", "perf_counter", "(", ")", "\n", "# Calculate the fps (frame per second)", "\n", "fps", "=", "int", "(", "nbatch", "/", "(", "tnow", "-", "tstart", ")", ")", "\n", "\n", "if", "update_fn", "is", "not", "None", ":", "\n", "            ", "update_fn", "(", "update", ")", "\n", "\n", "", "if", "update", "%", "log_interval", "==", "0", "or", "update", "==", "1", ":", "\n", "# Calculates if value function is a good predicator of the returns (ev > 1)", "\n", "# or if it's just worse than predicting nothing (ev =< 0)", "\n", "            ", "ev", "=", "explained_variance", "(", "values", ",", "returns", ")", "\n", "logger", ".", "logkv", "(", "\"misc/serial_timesteps\"", ",", "update", "*", "nsteps", ")", "\n", "logger", ".", "logkv", "(", "\"misc/nupdates\"", ",", "update", ")", "\n", "logger", ".", "logkv", "(", "\"misc/total_timesteps\"", ",", "update", "*", "nbatch", ")", "\n", "logger", ".", "logkv", "(", "\"fps\"", ",", "fps", ")", "\n", "logger", ".", "logkv", "(", "\"misc/explained_variance\"", ",", "float", "(", "ev", ")", ")", "\n", "logger", ".", "logkv", "(", "'eprewmean'", ",", "safemean", "(", "[", "epinfo", "[", "'r'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "\n", "logger", ".", "logkv", "(", "'eplenmean'", ",", "safemean", "(", "[", "epinfo", "[", "'l'", "]", "for", "epinfo", "in", "epinfobuf", "]", ")", ")", "\n", "if", "eval_env", "is", "not", "None", ":", "\n", "                ", "logger", ".", "logkv", "(", "'eval_eprewmean'", ",", "safemean", "(", "[", "epinfo", "[", "'r'", "]", "for", "epinfo", "in", "eval_epinfobuf", "]", ")", ")", "\n", "logger", ".", "logkv", "(", "'eval_eplenmean'", ",", "safemean", "(", "[", "epinfo", "[", "'l'", "]", "for", "epinfo", "in", "eval_epinfobuf", "]", ")", ")", "\n", "", "logger", ".", "logkv", "(", "'misc/time_elapsed'", ",", "tnow", "-", "tfirststart", ")", "\n", "for", "(", "lossval", ",", "lossname", ")", "in", "zip", "(", "lossvals", ",", "model", ".", "loss_names", ")", ":", "\n", "                ", "logger", ".", "logkv", "(", "'loss/'", "+", "lossname", ",", "lossval", ")", "\n", "\n", "", "logger", ".", "dumpkvs", "(", ")", "\n", "", "if", "save_interval", "and", "(", "update", "%", "save_interval", "==", "0", "or", "update", "==", "1", ")", "and", "logger", ".", "get_dir", "(", ")", "and", "is_mpi_root", ":", "\n", "            ", "checkdir", "=", "osp", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "'checkpoints'", ")", "\n", "os", ".", "makedirs", "(", "checkdir", ",", "exist_ok", "=", "True", ")", "\n", "savepath", "=", "osp", ".", "join", "(", "checkdir", ",", "'%.5i'", "%", "update", ")", "\n", "print", "(", "'Saving to'", ",", "savepath", ")", "\n", "model", ".", "save", "(", "savepath", ")", "\n", "\n", "", "", "return", "model", "\n", "# Avoid division error when calculate the mean (in our case if epinfo is empty returns np.nan, not return an error)", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.ppo2.safemean": [[220, 222], ["numpy.mean", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "safemean", "(", "xs", ")", ":", "\n", "    ", "return", "np", ".", "nan", "if", "len", "(", "xs", ")", "==", "0", "else", "np", ".", "mean", "(", "xs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.defaults.mujoco": [[1, 13], ["dict"], "function", ["None"], ["from", "baselines", ".", "common", ".", "models", "import", "mlp", ",", "cnn_small", "\n", "\n", "\n", "def", "atari", "(", ")", ":", "\n", "    ", "return", "dict", "(", "\n", "network", "=", "cnn_small", "(", ")", ",", "\n", "timesteps_per_batch", "=", "512", ",", "\n", "max_kl", "=", "0.001", ",", "\n", "cg_iters", "=", "10", ",", "\n", "cg_damping", "=", "1e-3", ",", "\n", "gamma", "=", "0.98", ",", "\n", "lam", "=", "1.0", ",", "\n", "vf_iters", "=", "3", ",", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.defaults.atari": [[15, 22], ["dict"], "function", ["None"], ["entcoeff", "=", "0.00", ",", "\n", ")", "\n", "\n", "", "def", "mujoco", "(", ")", ":", "\n", "    ", "return", "dict", "(", "\n", "network", "=", "mlp", "(", "num_hidden", "=", "32", ",", "num_layers", "=", "2", ")", ",", "\n", "timesteps_per_batch", "=", "1024", ",", "\n", "max_kl", "=", "0.01", ",", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.defaults.retro": [[24, 26], ["defaults.atari"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.defaults.atari"], ["cg_damping", "=", "0.1", ",", "\n", "gamma", "=", "0.99", ",", "\n", "lam", "=", "0.98", ",", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.runner.Runner.__init__": [[13, 19], ["baselines.common.runners.AbstractEnvRunner.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["\n", "def", "__init__", "(", "self", ",", "env", ",", "model", ",", "nsteps", "=", "5", ",", "gamma", "=", "0.99", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "env", "=", "env", ",", "model", "=", "model", ",", "nsteps", "=", "nsteps", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "batch_action_shape", "=", "[", "x", "if", "x", "is", "not", "None", "else", "-", "1", "for", "x", "in", "model", ".", "train_model", ".", "action", ".", "shape", ".", "as_list", "(", ")", "]", "\n", "self", ".", "ob_dtype", "=", "model", ".", "train_model", ".", "X", ".", "dtype", ".", "as_numpy_dtype", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.runner.Runner.run": [[20, 68], ["range", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "runner.Runner.model.value", "numpy.zeros_like", "numpy.zeros_like", "reversed", "runner.Runner.model.step", "numpy.asarray.append", "numpy.asarray.append", "numpy.asarray.append", "numpy.asarray.append", "numpy.asarray.append", "runner.Runner.env.step", "numpy.asarray.append", "range", "runner.Runner.obs.copy", "info.get", "map", "epinfos.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["\n", "", "def", "run", "(", "self", ")", ":", "\n", "# We initialize the lists that will contain the mb of experiences", "\n", "        ", "mb_obs", ",", "mb_rewards", ",", "mb_actions", ",", "mb_values", ",", "mb_dones", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "mb_states", "=", "self", ".", "states", "\n", "epinfos", "=", "[", "]", "\n", "for", "n", "in", "range", "(", "self", ".", "nsteps", ")", ":", "\n", "# Given observations, take action and value (V(s))", "\n", "# We already have self.obs because Runner superclass run self.obs[:] = env.reset() on init", "\n", "            ", "actions", ",", "values", ",", "states", ",", "_", "=", "self", ".", "model", ".", "step", "(", "self", ".", "obs", ",", "S", "=", "self", ".", "states", ",", "M", "=", "self", ".", "dones", ")", "\n", "\n", "# Append the experiences", "\n", "mb_obs", ".", "append", "(", "np", ".", "copy", "(", "self", ".", "obs", ")", ")", "\n", "mb_actions", ".", "append", "(", "actions", ")", "\n", "mb_values", ".", "append", "(", "values", ")", "\n", "mb_dones", ".", "append", "(", "self", ".", "dones", ")", "\n", "\n", "# Take actions in env and look the results", "\n", "obs", ",", "rewards", ",", "dones", ",", "infos", "=", "self", ".", "env", ".", "step", "(", "actions", ")", "\n", "for", "info", "in", "infos", ":", "\n", "                ", "maybeepinfo", "=", "info", ".", "get", "(", "'episode'", ")", "\n", "if", "maybeepinfo", ":", "epinfos", ".", "append", "(", "maybeepinfo", ")", "\n", "", "self", ".", "states", "=", "states", "\n", "self", ".", "dones", "=", "dones", "\n", "self", ".", "obs", "=", "obs", "\n", "mb_rewards", ".", "append", "(", "rewards", ")", "\n", "", "mb_dones", ".", "append", "(", "self", ".", "dones", ")", "\n", "\n", "# Batch of steps to batch of rollouts", "\n", "mb_obs", "=", "np", ".", "asarray", "(", "mb_obs", ",", "dtype", "=", "self", ".", "ob_dtype", ")", ".", "swapaxes", "(", "1", ",", "0", ")", ".", "reshape", "(", "self", ".", "batch_ob_shape", ")", "\n", "mb_rewards", "=", "np", ".", "asarray", "(", "mb_rewards", ",", "dtype", "=", "np", ".", "float32", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_actions", "=", "np", ".", "asarray", "(", "mb_actions", ",", "dtype", "=", "self", ".", "model", ".", "train_model", ".", "action", ".", "dtype", ".", "name", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_values", "=", "np", ".", "asarray", "(", "mb_values", ",", "dtype", "=", "np", ".", "float32", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_dones", "=", "np", ".", "asarray", "(", "mb_dones", ",", "dtype", "=", "np", ".", "bool", ")", ".", "swapaxes", "(", "1", ",", "0", ")", "\n", "mb_masks", "=", "mb_dones", "[", ":", ",", ":", "-", "1", "]", "\n", "mb_dones", "=", "mb_dones", "[", ":", ",", "1", ":", "]", "\n", "\n", "\n", "if", "self", ".", "gamma", ">", "0.0", ":", "\n", "# Discount/bootstrap off value fn", "\n", "            ", "last_values", "=", "self", ".", "model", ".", "value", "(", "self", ".", "obs", ",", "S", "=", "self", ".", "states", ",", "M", "=", "self", ".", "dones", ")", ".", "tolist", "(", ")", "\n", "for", "n", ",", "(", "rewards", ",", "dones", ",", "value", ")", "in", "enumerate", "(", "zip", "(", "mb_rewards", ",", "mb_dones", ",", "last_values", ")", ")", ":", "\n", "                ", "rewards", "=", "rewards", ".", "tolist", "(", ")", "\n", "dones", "=", "dones", ".", "tolist", "(", ")", "\n", "if", "dones", "[", "-", "1", "]", "==", "0", ":", "\n", "                    ", "rewards", "=", "discount_with_dones", "(", "rewards", "+", "[", "value", "]", ",", "dones", "+", "[", "0", "]", ",", "self", ".", "gamma", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "rewards", "=", "discount_with_dones", "(", "rewards", ",", "dones", ",", "self", ".", "gamma", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.runner.sf01": [[69, 75], ["arr.swapaxes().reshape", "arr.swapaxes"], "function", ["None"], ["", "mb_rewards", "[", "n", "]", "=", "rewards", "\n", "\n", "", "", "mb_actions", "=", "mb_actions", ".", "reshape", "(", "self", ".", "batch_action_shape", ")", "\n", "\n", "mb_rewards", "=", "mb_rewards", ".", "flatten", "(", ")", "\n", "mb_values", "=", "mb_values", ".", "flatten", "(", ")", "\n", "mb_masks", "=", "mb_masks", ".", "flatten", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.test_microbatches.test_microbatches": [[12, 33], ["functools.partial", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "baselines.common.tf_util.make_session", "functools.partial.", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "baselines.common.tf_util.make_session", "functools.partial.", "gym.make", "gym.make.seed", "baselines.common.tf_util.make_session.run", "baselines.common.tf_util.make_session.run", "numpy.testing.assert_allclose", "tensorflow.Graph", "tensorflow.trainable_variables", "tensorflow.Graph", "functools.partial", "tensorflow.trainable_variables"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["def", "test_microbatches", "(", ")", ":", "\n", "    ", "def", "env_fn", "(", ")", ":", "\n", "        ", "env", "=", "gym", ".", "make", "(", "'CartPole-v0'", ")", "\n", "env", ".", "seed", "(", "0", ")", "\n", "return", "env", "\n", "\n", "", "learn_fn", "=", "partial", "(", "learn", ",", "network", "=", "'mlp'", ",", "nsteps", "=", "32", ",", "total_timesteps", "=", "32", ",", "seed", "=", "0", ")", "\n", "\n", "env_ref", "=", "DummyVecEnv", "(", "[", "env_fn", "]", ")", "\n", "sess_ref", "=", "make_session", "(", "make_default", "=", "True", ",", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "\n", "learn_fn", "(", "env", "=", "env_ref", ")", "\n", "vars_ref", "=", "{", "v", ".", "name", ":", "sess_ref", ".", "run", "(", "v", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "}", "\n", "\n", "env_test", "=", "DummyVecEnv", "(", "[", "env_fn", "]", ")", "\n", "sess_test", "=", "make_session", "(", "make_default", "=", "True", ",", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "\n", "learn_fn", "(", "env", "=", "env_test", ",", "model_fn", "=", "partial", "(", "MicrobatchedModel", ",", "microbatch_size", "=", "2", ")", ")", "\n", "# learn_fn(env=env_test)", "\n", "vars_test", "=", "{", "v", ".", "name", ":", "sess_test", ".", "run", "(", "v", ")", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "}", "\n", "\n", "for", "v", "in", "vars_ref", ":", "\n", "        ", "np", ".", "testing", ".", "assert_allclose", "(", "vars_ref", "[", "v", "]", ",", "vars_test", "[", "v", "]", ",", "atol", "=", "3e-3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.model.Model.__init__": [[27, 132], ["baselines.common.tf_util.get_session", "policy.pdtype.sample_placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "policy.pd.neglogp", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.square", "tensorflow.exp", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.trainable_variables", "model.Model.trainer.compute_gradients", "zip", "list", "model.Model.trainer.apply_gradients", "functools.partial", "functools.partial", "baselines.common.tf_util.initialize", "tensorflow.get_collection", "tensorflow.variable_scope", "policy", "policy.pd.entropy", "tensorflow.clip_by_value", "tensorflow.reduce_mean", "tensorflow.clip_by_value", "tensorflow.maximum", "tensorflow.reduce_mean", "tensorflow.to_float", "MpiAdamOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.clip_by_global_norm", "zip", "sync_from_root", "policy", "policy", "tensorflow.maximum", "tensorflow.square", "tensorflow.greater", "comm.Get_size", "tensorflow.abs"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.neglogp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.MpiAdamOptimizer.compute_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.sync_from_root"], ["def", "__init__", "(", "self", ",", "*", ",", "policy", ",", "ob_space", ",", "ac_space", ",", "nbatch_act", ",", "nbatch_train", ",", "\n", "nsteps", ",", "ent_coef", ",", "vf_coef", ",", "max_grad_norm", ",", "mpi_rank_weight", "=", "1", ",", "comm", "=", "None", ",", "microbatch_size", "=", "None", ")", ":", "\n", "        ", "self", ".", "sess", "=", "sess", "=", "get_session", "(", ")", "\n", "\n", "if", "MPI", "is", "not", "None", "and", "comm", "is", "None", ":", "\n", "            ", "comm", "=", "MPI", ".", "COMM_WORLD", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'ppo2_model'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "# CREATE OUR TWO MODELS", "\n", "# act_model that is used for sampling", "\n", "            ", "act_model", "=", "policy", "(", "nbatch_act", ",", "1", ",", "sess", ")", "\n", "\n", "# Train model for training", "\n", "if", "microbatch_size", "is", "None", ":", "\n", "                ", "train_model", "=", "policy", "(", "nbatch_train", ",", "nsteps", ",", "sess", ")", "\n", "", "else", ":", "\n", "                ", "train_model", "=", "policy", "(", "microbatch_size", ",", "nsteps", ",", "sess", ")", "\n", "\n", "# CREATE THE PLACEHOLDERS", "\n", "", "", "self", ".", "A", "=", "A", "=", "train_model", ".", "pdtype", ".", "sample_placeholder", "(", "[", "None", "]", ")", "\n", "self", ".", "ADV", "=", "ADV", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "self", ".", "R", "=", "R", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "# Keep track of old actor", "\n", "self", ".", "OLDNEGLOGPAC", "=", "OLDNEGLOGPAC", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "# Keep track of old critic", "\n", "self", ".", "OLDVPRED", "=", "OLDVPRED", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", ")", "\n", "self", ".", "LR", "=", "LR", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ")", "\n", "# Cliprange", "\n", "self", ".", "CLIPRANGE", "=", "CLIPRANGE", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "]", ")", "\n", "\n", "neglogpac", "=", "train_model", ".", "pd", ".", "neglogp", "(", "A", ")", "\n", "\n", "# Calculate the entropy", "\n", "# Entropy is used to improve exploration by limiting the premature convergence to suboptimal policy.", "\n", "entropy", "=", "tf", ".", "reduce_mean", "(", "train_model", ".", "pd", ".", "entropy", "(", ")", ")", "\n", "\n", "# CALCULATE THE LOSS", "\n", "# Total loss = Policy gradient loss - entropy * entropy coefficient + Value coefficient * value loss", "\n", "\n", "# Clip the value to reduce variability during Critic training", "\n", "# Get the predicted value", "\n", "vpred", "=", "train_model", ".", "vf", "\n", "vpredclipped", "=", "OLDVPRED", "+", "tf", ".", "clip_by_value", "(", "train_model", ".", "vf", "-", "OLDVPRED", ",", "-", "CLIPRANGE", ",", "CLIPRANGE", ")", "\n", "# Unclipped value", "\n", "vf_losses1", "=", "tf", ".", "square", "(", "vpred", "-", "R", ")", "\n", "# Clipped value", "\n", "vf_losses2", "=", "tf", ".", "square", "(", "vpredclipped", "-", "R", ")", "\n", "\n", "vf_loss", "=", ".5", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "maximum", "(", "vf_losses1", ",", "vf_losses2", ")", ")", "\n", "\n", "# Calculate ratio (pi current policy / pi old policy)", "\n", "ratio", "=", "tf", ".", "exp", "(", "OLDNEGLOGPAC", "-", "neglogpac", ")", "\n", "\n", "# Defining Loss = - J is equivalent to max J", "\n", "pg_losses", "=", "-", "ADV", "*", "ratio", "\n", "\n", "pg_losses2", "=", "-", "ADV", "*", "tf", ".", "clip_by_value", "(", "ratio", ",", "1.0", "-", "CLIPRANGE", ",", "1.0", "+", "CLIPRANGE", ")", "\n", "\n", "# Final PG loss", "\n", "pg_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "maximum", "(", "pg_losses", ",", "pg_losses2", ")", ")", "\n", "approxkl", "=", ".5", "*", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "neglogpac", "-", "OLDNEGLOGPAC", ")", ")", "\n", "clipfrac", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "to_float", "(", "tf", ".", "greater", "(", "tf", ".", "abs", "(", "ratio", "-", "1.0", ")", ",", "CLIPRANGE", ")", ")", ")", "\n", "\n", "# Total loss", "\n", "loss", "=", "pg_loss", "-", "entropy", "*", "ent_coef", "+", "vf_loss", "*", "vf_coef", "\n", "\n", "# UPDATE THE PARAMETERS USING LOSS", "\n", "# 1. Get the model parameters", "\n", "params", "=", "tf", ".", "trainable_variables", "(", "'ppo2_model'", ")", "\n", "# 2. Build our trainer", "\n", "if", "comm", "is", "not", "None", "and", "comm", ".", "Get_size", "(", ")", ">", "1", ":", "\n", "            ", "self", ".", "trainer", "=", "MpiAdamOptimizer", "(", "comm", ",", "learning_rate", "=", "LR", ",", "mpi_rank_weight", "=", "mpi_rank_weight", ",", "epsilon", "=", "1e-5", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "trainer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "learning_rate", "=", "LR", ",", "epsilon", "=", "1e-5", ")", "\n", "# 3. Calculate the gradients", "\n", "", "grads_and_var", "=", "self", ".", "trainer", ".", "compute_gradients", "(", "loss", ",", "params", ")", "\n", "grads", ",", "var", "=", "zip", "(", "*", "grads_and_var", ")", "\n", "\n", "if", "max_grad_norm", "is", "not", "None", ":", "\n", "# Clip the gradients (normalize)", "\n", "            ", "grads", ",", "_grad_norm", "=", "tf", ".", "clip_by_global_norm", "(", "grads", ",", "max_grad_norm", ")", "\n", "", "grads_and_var", "=", "list", "(", "zip", "(", "grads", ",", "var", ")", ")", "\n", "# zip aggregate each gradient with parameters associated", "\n", "# For instance zip(ABCD, xyza) => Ax, By, Cz, Da", "\n", "\n", "self", ".", "grads", "=", "grads", "\n", "self", ".", "var", "=", "var", "\n", "self", ".", "_train_op", "=", "self", ".", "trainer", ".", "apply_gradients", "(", "grads_and_var", ")", "\n", "self", ".", "loss_names", "=", "[", "'policy_loss'", ",", "'value_loss'", ",", "'policy_entropy'", ",", "'approxkl'", ",", "'clipfrac'", "]", "\n", "self", ".", "stats_list", "=", "[", "pg_loss", ",", "vf_loss", ",", "entropy", ",", "approxkl", ",", "clipfrac", "]", "\n", "\n", "\n", "self", ".", "train_model", "=", "train_model", "\n", "self", ".", "act_model", "=", "act_model", "\n", "self", ".", "step", "=", "act_model", ".", "step", "\n", "self", ".", "value", "=", "act_model", ".", "value", "\n", "self", ".", "initial_state", "=", "act_model", ".", "initial_state", "\n", "\n", "self", ".", "save", "=", "functools", ".", "partial", "(", "save_variables", ",", "sess", "=", "sess", ")", "\n", "self", ".", "load", "=", "functools", ".", "partial", "(", "load_variables", ",", "sess", "=", "sess", ")", "\n", "\n", "initialize", "(", ")", "\n", "global_variables", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "\"\"", ")", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "            ", "sync_from_root", "(", "sess", ",", "global_variables", ",", "comm", "=", "comm", ")", "#pylint: disable=E1101", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.model.Model.train": [[133, 159], ["model.Model.sess.run", "advs.mean", "advs.std"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "def", "train", "(", "self", ",", "lr", ",", "cliprange", ",", "obs", ",", "returns", ",", "masks", ",", "actions", ",", "values", ",", "neglogpacs", ",", "states", "=", "None", ")", ":", "\n", "# Here we calculate advantage A(s,a) = R + yV(s') - V(s)", "\n", "# Returns = R + yV(s')", "\n", "        ", "advs", "=", "returns", "-", "values", "\n", "\n", "# Normalize the advantages", "\n", "advs", "=", "(", "advs", "-", "advs", ".", "mean", "(", ")", ")", "/", "(", "advs", ".", "std", "(", ")", "+", "1e-8", ")", "\n", "\n", "td_map", "=", "{", "\n", "self", ".", "train_model", ".", "X", ":", "obs", ",", "\n", "self", ".", "A", ":", "actions", ",", "\n", "self", ".", "ADV", ":", "advs", ",", "\n", "self", ".", "R", ":", "returns", ",", "\n", "self", ".", "LR", ":", "lr", ",", "\n", "self", ".", "CLIPRANGE", ":", "cliprange", ",", "\n", "self", ".", "OLDNEGLOGPAC", ":", "neglogpacs", ",", "\n", "self", ".", "OLDVPRED", ":", "values", "\n", "}", "\n", "if", "states", "is", "not", "None", ":", "\n", "            ", "td_map", "[", "self", ".", "train_model", ".", "S", "]", "=", "states", "\n", "td_map", "[", "self", ".", "train_model", ".", "M", "]", "=", "masks", "\n", "\n", "", "return", "self", ".", "sess", ".", "run", "(", "\n", "self", ".", "stats_list", "+", "[", "self", ".", "_train_op", "]", ",", "\n", "td_map", "\n", ")", "[", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.microbatched_model.MicrobatchedModel.__init__": [[10, 33], ["baselines.ppo2.model.Model.__init__", "list", "microbatched_model.MicrobatchedModel.trainer.apply_gradients", "tensorflow.placeholder", "zip"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.apply_gradients"], ["def", "__init__", "(", "self", ",", "*", ",", "policy", ",", "ob_space", ",", "ac_space", ",", "nbatch_act", ",", "nbatch_train", ",", "\n", "nsteps", ",", "ent_coef", ",", "vf_coef", ",", "max_grad_norm", ",", "mpi_rank_weight", ",", "comm", ",", "microbatch_size", ")", ":", "\n", "\n", "        ", "self", ".", "nmicrobatches", "=", "nbatch_train", "//", "microbatch_size", "\n", "self", ".", "microbatch_size", "=", "microbatch_size", "\n", "assert", "nbatch_train", "%", "microbatch_size", "==", "0", ",", "'microbatch_size ({}) should divide nbatch_train ({}) evenly'", ".", "format", "(", "microbatch_size", ",", "nbatch_train", ")", "\n", "\n", "super", "(", ")", ".", "__init__", "(", "\n", "policy", "=", "policy", ",", "\n", "ob_space", "=", "ob_space", ",", "\n", "ac_space", "=", "ac_space", ",", "\n", "nbatch_act", "=", "nbatch_act", ",", "\n", "nbatch_train", "=", "microbatch_size", ",", "\n", "nsteps", "=", "nsteps", ",", "\n", "ent_coef", "=", "ent_coef", ",", "\n", "vf_coef", "=", "vf_coef", ",", "\n", "max_grad_norm", "=", "max_grad_norm", ",", "\n", "mpi_rank_weight", "=", "mpi_rank_weight", ",", "\n", "comm", "=", "comm", ")", "\n", "\n", "self", ".", "grads_ph", "=", "[", "tf", ".", "placeholder", "(", "dtype", "=", "g", ".", "dtype", ",", "shape", "=", "g", ".", "shape", ")", "for", "g", "in", "self", ".", "grads", "]", "\n", "grads_ph_and_vars", "=", "list", "(", "zip", "(", "self", ".", "grads_ph", ",", "self", ".", "var", ")", ")", "\n", "self", ".", "_apply_gradients_op", "=", "self", ".", "trainer", ".", "apply_gradients", "(", "grads_ph_and_vars", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo2.microbatched_model.MicrobatchedModel.train": [[35, 76], ["range", "microbatched_model.MicrobatchedModel.sess.run", "numpy.mean().tolist", "range", "microbatched_model.MicrobatchedModel.sess.run", "stats_vs.append", "advs.mean", "advs.std", "enumerate", "zip", "numpy.mean", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "train", "(", "self", ",", "lr", ",", "cliprange", ",", "obs", ",", "returns", ",", "masks", ",", "actions", ",", "values", ",", "neglogpacs", ",", "states", "=", "None", ")", ":", "\n", "        ", "assert", "states", "is", "None", ",", "\"microbatches with recurrent models are not supported yet\"", "\n", "\n", "# Here we calculate advantage A(s,a) = R + yV(s') - V(s)", "\n", "# Returns = R + yV(s')", "\n", "advs", "=", "returns", "-", "values", "\n", "\n", "# Normalize the advantages", "\n", "advs", "=", "(", "advs", "-", "advs", ".", "mean", "(", ")", ")", "/", "(", "advs", ".", "std", "(", ")", "+", "1e-8", ")", "\n", "\n", "# Initialize empty list for per-microbatch stats like pg_loss, vf_loss, entropy, approxkl (whatever is in self.stats_list)", "\n", "stats_vs", "=", "[", "]", "\n", "\n", "for", "microbatch_idx", "in", "range", "(", "self", ".", "nmicrobatches", ")", ":", "\n", "            ", "_sli", "=", "range", "(", "microbatch_idx", "*", "self", ".", "microbatch_size", ",", "(", "microbatch_idx", "+", "1", ")", "*", "self", ".", "microbatch_size", ")", "\n", "td_map", "=", "{", "\n", "self", ".", "train_model", ".", "X", ":", "obs", "[", "_sli", "]", ",", "\n", "self", ".", "A", ":", "actions", "[", "_sli", "]", ",", "\n", "self", ".", "ADV", ":", "advs", "[", "_sli", "]", ",", "\n", "self", ".", "R", ":", "returns", "[", "_sli", "]", ",", "\n", "self", ".", "CLIPRANGE", ":", "cliprange", ",", "\n", "self", ".", "OLDNEGLOGPAC", ":", "neglogpacs", "[", "_sli", "]", ",", "\n", "self", ".", "OLDVPRED", ":", "values", "[", "_sli", "]", "\n", "}", "\n", "\n", "# Compute gradient on a microbatch (note that variables do not change here) ...", "\n", "grad_v", ",", "stats_v", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "grads", ",", "self", ".", "stats_list", "]", ",", "td_map", ")", "\n", "if", "microbatch_idx", "==", "0", ":", "\n", "                ", "sum_grad_v", "=", "grad_v", "\n", "", "else", ":", "\n", "# .. and add to the total of the gradients", "\n", "                ", "for", "i", ",", "g", "in", "enumerate", "(", "grad_v", ")", ":", "\n", "                    ", "sum_grad_v", "[", "i", "]", "+=", "g", "\n", "", "", "stats_vs", ".", "append", "(", "stats_v", ")", "\n", "\n", "", "feed_dict", "=", "{", "ph", ":", "sum_g", "/", "self", ".", "nmicrobatches", "for", "ph", ",", "sum_g", "in", "zip", "(", "self", ".", "grads_ph", ",", "sum_grad_v", ")", "}", "\n", "feed_dict", "[", "self", ".", "LR", "]", "=", "lr", "\n", "# Update variables using average of the gradients", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "_apply_gradients_op", ",", "feed_dict", ")", "\n", "# Return average of the stats", "\n", "return", "np", ".", "mean", "(", "np", ".", "array", "(", "stats_vs", ")", ",", "axis", "=", "0", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.test_monitor.test_monitor": [[5, 32], ["gym.make", "gym.make.seed", "monitor.Monitor", "monitor.Monitor.reset", "range", "open", "open.readline", "f.readline.startswith", "json.loads", "pandas.read_csv", "open.close", "os.remove", "uuid.uuid4", "monitor.Monitor.step", "set", "set", "monitor.Monitor.reset", "json.loads.keys", "pandas.read_csv.keys"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_csv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["def", "test_monitor", "(", ")", ":", "\n", "    ", "import", "pandas", "\n", "import", "os", "\n", "import", "uuid", "\n", "\n", "env", "=", "gym", ".", "make", "(", "\"CartPole-v1\"", ")", "\n", "env", ".", "seed", "(", "0", ")", "\n", "mon_file", "=", "\"/tmp/baselines-test-%s.monitor.csv\"", "%", "uuid", ".", "uuid4", "(", ")", "\n", "menv", "=", "Monitor", "(", "env", ",", "mon_file", ")", "\n", "menv", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "1000", ")", ":", "\n", "        ", "_", ",", "_", ",", "done", ",", "_", "=", "menv", ".", "step", "(", "0", ")", "\n", "if", "done", ":", "\n", "            ", "menv", ".", "reset", "(", ")", "\n", "\n", "", "", "f", "=", "open", "(", "mon_file", ",", "'rt'", ")", "\n", "\n", "firstline", "=", "f", ".", "readline", "(", ")", "\n", "assert", "firstline", ".", "startswith", "(", "'#'", ")", "\n", "metadata", "=", "json", ".", "loads", "(", "firstline", "[", "1", ":", "]", ")", "\n", "assert", "metadata", "[", "'env_id'", "]", "==", "\"CartPole-v1\"", "\n", "assert", "set", "(", "metadata", ".", "keys", "(", ")", ")", "==", "{", "'env_id'", ",", "'t_start'", "}", ",", "\"Incorrect keys in monitor metadata\"", "\n", "\n", "last_logline", "=", "pandas", ".", "read_csv", "(", "f", ",", "index_col", "=", "None", ")", "\n", "assert", "set", "(", "last_logline", ".", "keys", "(", ")", ")", "==", "{", "'l'", ",", "'t'", ",", "'r'", "}", ",", "\"Incorrect keys in monitor logline\"", "\n", "f", ".", "close", "(", ")", "\n", "os", ".", "remove", "(", "mon_file", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.__init__": [[14, 34], ["gym.core.Wrapper.__init__", "time.time", "monitor.ResultsWriter", "time.time"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "filename", ",", "allow_early_resets", "=", "False", ",", "reset_keywords", "=", "(", ")", ",", "info_keywords", "=", "(", ")", ")", ":", "\n", "        ", "Wrapper", ".", "__init__", "(", "self", ",", "env", "=", "env", ")", "\n", "self", ".", "tstart", "=", "time", ".", "time", "(", ")", "\n", "if", "filename", ":", "\n", "            ", "self", ".", "results_writer", "=", "ResultsWriter", "(", "filename", ",", "\n", "header", "=", "{", "\"t_start\"", ":", "time", ".", "time", "(", ")", ",", "'env_id'", ":", "env", ".", "spec", "and", "env", ".", "spec", ".", "id", "}", ",", "\n", "extra_keys", "=", "reset_keywords", "+", "info_keywords", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "results_writer", "=", "None", "\n", "", "self", ".", "reset_keywords", "=", "reset_keywords", "\n", "self", ".", "info_keywords", "=", "info_keywords", "\n", "self", ".", "allow_early_resets", "=", "allow_early_resets", "\n", "self", ".", "rewards", "=", "None", "\n", "self", ".", "needs_reset", "=", "True", "\n", "self", ".", "episode_rewards", "=", "[", "]", "\n", "self", ".", "episode_lengths", "=", "[", "]", "\n", "self", ".", "episode_times", "=", "[", "]", "\n", "self", ".", "total_steps", "=", "0", "\n", "self", ".", "current_reset_info", "=", "{", "}", "# extra info about the current episode, that was passed in during reset()", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.reset": [[35, 43], ["monitor.Monitor.reset_state", "monitor.Monitor.env.reset", "kwargs.get", "ValueError"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.reset_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "reset_state", "(", ")", "\n", "for", "k", "in", "self", ".", "reset_keywords", ":", "\n", "            ", "v", "=", "kwargs", ".", "get", "(", "k", ")", "\n", "if", "v", "is", "None", ":", "\n", "                ", "raise", "ValueError", "(", "'Expected you to pass kwarg %s into reset'", "%", "k", ")", "\n", "", "self", ".", "current_reset_info", "[", "k", "]", "=", "v", "\n", "", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.reset_state": [[44, 49], ["RuntimeError"], "methods", ["None"], ["", "def", "reset_state", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "allow_early_resets", "and", "not", "self", ".", "needs_reset", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Tried to reset an environment before done. If you want to allow early resets, wrap your env with Monitor(env, path, allow_early_resets=True)\"", ")", "\n", "", "self", ".", "rewards", "=", "[", "]", "\n", "self", ".", "needs_reset", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.step": [[51, 57], ["monitor.Monitor.env.step", "monitor.Monitor.update", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "needs_reset", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Tried to step environment that needs reset\"", ")", "\n", "", "ob", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "update", "(", "ob", ",", "rew", ",", "done", ",", "info", ")", "\n", "return", "(", "ob", ",", "rew", ",", "done", ",", "info", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.update": [[58, 78], ["monitor.Monitor.rewards.append", "sum", "len", "monitor.Monitor.episode_rewards.append", "monitor.Monitor.episode_lengths.append", "monitor.Monitor.episode_times.append", "epinfo.update", "isinstance", "isinstance", "round", "round", "monitor.Monitor.results_writer.write_row", "time.time", "time.time"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.ResultsWriter.write_row"], ["", "def", "update", "(", "self", ",", "ob", ",", "rew", ",", "done", ",", "info", ")", ":", "\n", "        ", "self", ".", "rewards", ".", "append", "(", "rew", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "needs_reset", "=", "True", "\n", "eprew", "=", "sum", "(", "self", ".", "rewards", ")", "\n", "eplen", "=", "len", "(", "self", ".", "rewards", ")", "\n", "epinfo", "=", "{", "\"r\"", ":", "round", "(", "eprew", ",", "6", ")", ",", "\"l\"", ":", "eplen", ",", "\"t\"", ":", "round", "(", "time", ".", "time", "(", ")", "-", "self", ".", "tstart", ",", "6", ")", "}", "\n", "for", "k", "in", "self", ".", "info_keywords", ":", "\n", "                ", "epinfo", "[", "k", "]", "=", "info", "[", "k", "]", "\n", "", "self", ".", "episode_rewards", ".", "append", "(", "eprew", ")", "\n", "self", ".", "episode_lengths", ".", "append", "(", "eplen", ")", "\n", "self", ".", "episode_times", ".", "append", "(", "time", ".", "time", "(", ")", "-", "self", ".", "tstart", ")", "\n", "epinfo", ".", "update", "(", "self", ".", "current_reset_info", ")", "\n", "if", "self", ".", "results_writer", ":", "\n", "                ", "self", ".", "results_writer", ".", "write_row", "(", "epinfo", ")", "\n", "", "assert", "isinstance", "(", "info", ",", "dict", ")", "\n", "if", "isinstance", "(", "info", ",", "dict", ")", ":", "\n", "                ", "info", "[", "'episode'", "]", "=", "epinfo", "\n", "\n", "", "", "self", ".", "total_steps", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.close": [[79, 83], ["super().close", "monitor.Monitor.f.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "super", "(", "Monitor", ",", "self", ")", ".", "close", "(", ")", "\n", "if", "self", ".", "f", "is", "not", "None", ":", "\n", "            ", "self", ".", "f", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.get_total_steps": [[84, 86], ["None"], "methods", ["None"], ["", "", "def", "get_total_steps", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "total_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.get_episode_rewards": [[87, 89], ["None"], "methods", ["None"], ["", "def", "get_episode_rewards", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "episode_rewards", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.get_episode_lengths": [[90, 92], ["None"], "methods", ["None"], ["", "def", "get_episode_lengths", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "episode_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.Monitor.get_episode_times": [[93, 95], ["None"], "methods", ["None"], ["", "def", "get_episode_times", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "episode_times", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.ResultsWriter.__init__": [[101, 116], ["open", "isinstance", "monitor.ResultsWriter.f.write", "csv.DictWriter", "monitor.ResultsWriter.logger.writeheader", "monitor.ResultsWriter.f.flush", "os.join.endswith", "os.isdir", "os.join", "json.dumps", "tuple"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "header", "=", "''", ",", "extra_keys", "=", "(", ")", ")", ":", "\n", "        ", "self", ".", "extra_keys", "=", "extra_keys", "\n", "assert", "filename", "is", "not", "None", "\n", "if", "not", "filename", ".", "endswith", "(", "Monitor", ".", "EXT", ")", ":", "\n", "            ", "if", "osp", ".", "isdir", "(", "filename", ")", ":", "\n", "                ", "filename", "=", "osp", ".", "join", "(", "filename", ",", "Monitor", ".", "EXT", ")", "\n", "", "else", ":", "\n", "                ", "filename", "=", "filename", "+", "\".\"", "+", "Monitor", ".", "EXT", "\n", "", "", "self", ".", "f", "=", "open", "(", "filename", ",", "\"wt\"", ")", "\n", "if", "isinstance", "(", "header", ",", "dict", ")", ":", "\n", "            ", "header", "=", "'# {} \\n'", ".", "format", "(", "json", ".", "dumps", "(", "header", ")", ")", "\n", "", "self", ".", "f", ".", "write", "(", "header", ")", "\n", "self", ".", "logger", "=", "csv", ".", "DictWriter", "(", "self", ".", "f", ",", "fieldnames", "=", "(", "'r'", ",", "'l'", ",", "'t'", ")", "+", "tuple", "(", "extra_keys", ")", ")", "\n", "self", ".", "logger", ".", "writeheader", "(", ")", "\n", "self", ".", "f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.ResultsWriter.write_row": [[117, 121], ["monitor.ResultsWriter.logger.writerow", "monitor.ResultsWriter.f.flush"], "methods", ["None"], ["", "def", "write_row", "(", "self", ",", "epinfo", ")", ":", "\n", "        ", "if", "self", ".", "logger", ":", "\n", "            ", "self", ".", "logger", ".", "writerow", "(", "epinfo", ")", "\n", "self", ".", "f", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.get_monitor_files": [[123, 125], ["glob.glob", "os.join"], "function", ["None"], ["", "", "", "def", "get_monitor_files", "(", "dir", ")", ":", "\n", "    ", "return", "glob", "(", "osp", ".", "join", "(", "dir", ",", "\"*\"", "+", "Monitor", ".", "EXT", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.load_results": [[126, 164], ["pandas.concat", "pandas.DataFrame.sort_values", "pandas.DataFrame.reset_index", "min", "glob.glob", "glob.glob", "monitor.LoadMonitorResultsError", "dfs.append", "os.join", "os.join", "open", "fname.endswith", "fh.readline", "json.loads", "pandas.read_csv", "headers.append", "fname.endswith", "fh.readlines", "json.loads", "headers.append", "pandas.DataFrame", "json.loads", "episodes.append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_csv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "load_results", "(", "dir", ")", ":", "\n", "    ", "import", "pandas", "\n", "monitor_files", "=", "(", "\n", "glob", "(", "osp", ".", "join", "(", "dir", ",", "\"*monitor.json\"", ")", ")", "+", "\n", "glob", "(", "osp", ".", "join", "(", "dir", ",", "\"*monitor.csv\"", ")", ")", ")", "# get both csv and (old) json files", "\n", "if", "not", "monitor_files", ":", "\n", "        ", "raise", "LoadMonitorResultsError", "(", "\"no monitor files of the form *%s found in %s\"", "%", "(", "Monitor", ".", "EXT", ",", "dir", ")", ")", "\n", "", "dfs", "=", "[", "]", "\n", "headers", "=", "[", "]", "\n", "for", "fname", "in", "monitor_files", ":", "\n", "        ", "with", "open", "(", "fname", ",", "'rt'", ")", "as", "fh", ":", "\n", "            ", "if", "fname", ".", "endswith", "(", "'csv'", ")", ":", "\n", "                ", "firstline", "=", "fh", ".", "readline", "(", ")", "\n", "if", "not", "firstline", ":", "\n", "                    ", "continue", "\n", "", "assert", "firstline", "[", "0", "]", "==", "'#'", "\n", "header", "=", "json", ".", "loads", "(", "firstline", "[", "1", ":", "]", ")", "\n", "df", "=", "pandas", ".", "read_csv", "(", "fh", ",", "index_col", "=", "None", ")", "\n", "headers", ".", "append", "(", "header", ")", "\n", "", "elif", "fname", ".", "endswith", "(", "'json'", ")", ":", "# Deprecated json format", "\n", "                ", "episodes", "=", "[", "]", "\n", "lines", "=", "fh", ".", "readlines", "(", ")", "\n", "header", "=", "json", ".", "loads", "(", "lines", "[", "0", "]", ")", "\n", "headers", ".", "append", "(", "header", ")", "\n", "for", "line", "in", "lines", "[", "1", ":", "]", ":", "\n", "                    ", "episode", "=", "json", ".", "loads", "(", "line", ")", "\n", "episodes", ".", "append", "(", "episode", ")", "\n", "", "df", "=", "pandas", ".", "DataFrame", "(", "episodes", ")", "\n", "", "else", ":", "\n", "                ", "assert", "0", ",", "'unreachable'", "\n", "", "df", "[", "'t'", "]", "+=", "header", "[", "'t_start'", "]", "\n", "", "dfs", ".", "append", "(", "df", ")", "\n", "", "df", "=", "pandas", ".", "concat", "(", "dfs", ")", "\n", "df", ".", "sort_values", "(", "'t'", ",", "inplace", "=", "True", ")", "\n", "df", ".", "reset_index", "(", "inplace", "=", "True", ")", "\n", "df", "[", "'t'", "]", "-=", "min", "(", "header", "[", "'t_start'", "]", "for", "header", "in", "headers", ")", "\n", "df", ".", "headers", "=", "headers", "# HACK to preserve backwards compatibility", "\n", "return", "df", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.benchmarks.register_benchmark": [[13, 24], ["_BENCHMARKS.append", "ValueError", "remove_version_re.sub", "t.get", "t.get"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get"], ["def", "register_benchmark", "(", "benchmark", ")", ":", "\n", "    ", "for", "b", "in", "_BENCHMARKS", ":", "\n", "        ", "if", "b", "[", "'name'", "]", "==", "benchmark", "[", "'name'", "]", ":", "\n", "            ", "raise", "ValueError", "(", "'Benchmark with name %s already registered!'", "%", "b", "[", "'name'", "]", ")", "\n", "\n", "# automatically add a description if it is not present", "\n", "", "", "if", "'tasks'", "in", "benchmark", ":", "\n", "        ", "for", "t", "in", "benchmark", "[", "'tasks'", "]", ":", "\n", "            ", "if", "'desc'", "not", "in", "t", ":", "\n", "                ", "t", "[", "'desc'", "]", "=", "remove_version_re", ".", "sub", "(", "''", ",", "t", ".", "get", "(", "'env_id'", ",", "t", ".", "get", "(", "'id'", ")", ")", ")", "\n", "", "", "", "_BENCHMARKS", ".", "append", "(", "benchmark", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.benchmarks.list_benchmarks": [[26, 28], ["None"], "function", ["None"], ["", "def", "list_benchmarks", "(", ")", ":", "\n", "    ", "return", "[", "b", "[", "'name'", "]", "for", "b", "in", "_BENCHMARKS", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.benchmarks.get_benchmark": [[30, 35], ["ValueError", "benchmarks.list_benchmarks"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.benchmarks.list_benchmarks"], ["", "def", "get_benchmark", "(", "benchmark_name", ")", ":", "\n", "    ", "for", "b", "in", "_BENCHMARKS", ":", "\n", "        ", "if", "b", "[", "'name'", "]", "==", "benchmark_name", ":", "\n", "            ", "return", "b", "\n", "", "", "raise", "ValueError", "(", "'%s not found! Known benchmarks: %s'", "%", "(", "benchmark_name", ",", "list_benchmarks", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.benchmarks.get_task": [[37, 40], ["next", "filter"], "function", ["None"], ["", "def", "get_task", "(", "benchmark", ",", "env_id", ")", ":", "\n", "    ", "\"\"\"Get a task by env_id. Return None if the benchmark doesn't have the env\"\"\"", "\n", "return", "next", "(", "filter", "(", "lambda", "task", ":", "task", "[", "'env_id'", "]", "==", "env_id", ",", "benchmark", "[", "'tasks'", "]", ")", ",", "None", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.benchmarks.find_task_for_env_id_in_any_benchmark": [[42, 48], ["None"], "function", ["None"], ["", "def", "find_task_for_env_id_in_any_benchmark", "(", "env_id", ")", ":", "\n", "    ", "for", "bm", "in", "_BENCHMARKS", ":", "\n", "        ", "for", "task", "in", "bm", "[", "\"tasks\"", "]", ":", "\n", "            ", "if", "task", "[", "\"env_id\"", "]", "==", "env_id", ":", "\n", "                ", "return", "bm", ",", "task", "\n", "", "", "", "return", "None", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.mlp_policy.MlpPolicy.__init__": [[9, 13], ["tensorflow.variable_scope", "mlp_policy.MlpPolicy._init", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy._init"], ["def", "__init__", "(", "self", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "self", ".", "_init", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.mlp_policy.MlpPolicy._init": [[14, 51], ["isinstance", "baselines.common.distributions.make_pdtype", "baselines.get_placeholder", "baselines.common.distributions.make_pdtype.pdfromflat", "tensorflow.placeholder", "baselines.switch", "baselines.function", "tensorflow.variable_scope", "baselines.common.mpi_running_mean_std.RunningMeanStd", "tensorflow.variable_scope", "tensorflow.clip_by_value", "range", "tensorflow.variable_scope", "range", "mlp_policy.MlpPolicy.pd.sample", "mlp_policy.MlpPolicy.pd.mode", "tensorflow.nn.tanh", "tensorflow.layers.dense", "tensorflow.nn.tanh", "isinstance", "tensorflow.layers.dense", "tensorflow.get_variable", "tensorflow.concat", "tensorflow.layers.dense", "list", "tensorflow.layers.dense", "tensorflow.layers.dense", "baselines.normc_initializer", "baselines.normc_initializer", "tensorflow.zeros_initializer", "baselines.common.distributions.make_pdtype.param_shape", "baselines.normc_initializer", "baselines.normc_initializer", "baselines.normc_initializer", "baselines.common.distributions.make_pdtype.param_shape", "baselines.common.distributions.make_pdtype.param_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.switch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mode", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape"], ["", "", "def", "_init", "(", "self", ",", "ob_space", ",", "ac_space", ",", "hid_size", ",", "num_hid_layers", ",", "gaussian_fixed_var", "=", "True", ")", ":", "\n", "        ", "assert", "isinstance", "(", "ob_space", ",", "gym", ".", "spaces", ".", "Box", ")", "\n", "\n", "self", ".", "pdtype", "=", "pdtype", "=", "make_pdtype", "(", "ac_space", ")", "\n", "sequence_length", "=", "None", "\n", "\n", "ob", "=", "U", ".", "get_placeholder", "(", "name", "=", "\"ob\"", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "sequence_length", "]", "+", "list", "(", "ob_space", ".", "shape", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"obfilter\"", ")", ":", "\n", "            ", "self", ".", "ob_rms", "=", "RunningMeanStd", "(", "shape", "=", "ob_space", ".", "shape", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'vf'", ")", ":", "\n", "            ", "obz", "=", "tf", ".", "clip_by_value", "(", "(", "ob", "-", "self", ".", "ob_rms", ".", "mean", ")", "/", "self", ".", "ob_rms", ".", "std", ",", "-", "5.0", ",", "5.0", ")", "\n", "last_out", "=", "obz", "\n", "for", "i", "in", "range", "(", "num_hid_layers", ")", ":", "\n", "                ", "last_out", "=", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "hid_size", ",", "name", "=", "\"fc%i\"", "%", "(", "i", "+", "1", ")", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", ")", "\n", "", "self", ".", "vpred", "=", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "1", ",", "name", "=", "'final'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", "[", ":", ",", "0", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'pol'", ")", ":", "\n", "            ", "last_out", "=", "obz", "\n", "for", "i", "in", "range", "(", "num_hid_layers", ")", ":", "\n", "                ", "last_out", "=", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "hid_size", ",", "name", "=", "'fc%i'", "%", "(", "i", "+", "1", ")", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", ")", "\n", "", "if", "gaussian_fixed_var", "and", "isinstance", "(", "ac_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "                ", "mean", "=", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "pdtype", ".", "param_shape", "(", ")", "[", "0", "]", "//", "2", ",", "name", "=", "'final'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "0.01", ")", ")", "\n", "logstd", "=", "tf", ".", "get_variable", "(", "name", "=", "\"logstd\"", ",", "shape", "=", "[", "1", ",", "pdtype", ".", "param_shape", "(", ")", "[", "0", "]", "//", "2", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "pdparam", "=", "tf", ".", "concat", "(", "[", "mean", ",", "mean", "*", "0.0", "+", "logstd", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "pdparam", "=", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "pdtype", ".", "param_shape", "(", ")", "[", "0", "]", ",", "name", "=", "'final'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "0.01", ")", ")", "\n", "\n", "", "", "self", ".", "pd", "=", "pdtype", ".", "pdfromflat", "(", "pdparam", ")", "\n", "\n", "self", ".", "state_in", "=", "[", "]", "\n", "self", ".", "state_out", "=", "[", "]", "\n", "\n", "stochastic", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "shape", "=", "(", ")", ")", "\n", "ac", "=", "U", ".", "switch", "(", "stochastic", ",", "self", ".", "pd", ".", "sample", "(", ")", ",", "self", ".", "pd", ".", "mode", "(", ")", ")", "\n", "self", ".", "_act", "=", "U", ".", "function", "(", "[", "stochastic", ",", "ob", "]", ",", "[", "ac", ",", "self", ".", "vpred", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.mlp_policy.MlpPolicy.act": [[52, 55], ["mlp_policy.MlpPolicy._act"], "methods", ["None"], ["", "def", "act", "(", "self", ",", "stochastic", ",", "ob", ")", ":", "\n", "        ", "ac1", ",", "vpred1", "=", "self", ".", "_act", "(", "stochastic", ",", "ob", "[", "None", "]", ")", "\n", "return", "ac1", "[", "0", "]", ",", "vpred1", "[", "0", "]", "\n", "", "def", "get_variables", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.mlp_policy.MlpPolicy.get_variables": [[55, 57], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "get_variables", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "scope", ")", "\n", "", "def", "get_trainable_variables", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.mlp_policy.MlpPolicy.get_trainable_variables": [[57, 59], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "get_trainable_variables", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "self", ".", "scope", ")", "\n", "", "def", "get_initial_state", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.mlp_policy.MlpPolicy.get_initial_state": [[59, 61], ["None"], "methods", ["None"], ["", "def", "get_initial_state", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_humanoid.RewScale.__init__": [[41, 44], ["gym.RewardWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "scale", ")", ":", "\n", "        ", "gym", ".", "RewardWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "", "def", "reward", "(", "self", ",", "r", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_humanoid.RewScale.reward": [[44, 46], ["None"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "r", ")", ":", "\n", "        ", "return", "r", "*", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_humanoid.train": [[9, 39], ["baselines.common.tf_util.make_session().__enter__", "baselines.common.cmd_util.make_mujoco_env", "run_humanoid.RewScale", "baselines.logger.log", "pposgd_simple.learn", "RewScale.close", "mlp_policy.MlpPolicy", "baselines.common.tf_util.save_state", "baselines.common.tf_util.make_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_mujoco_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session"], ["def", "train", "(", "num_timesteps", ",", "seed", ",", "model_path", "=", "None", ")", ":", "\n", "    ", "env_id", "=", "'Humanoid-v2'", "\n", "from", "baselines", ".", "ppo1", "import", "mlp_policy", ",", "pposgd_simple", "\n", "U", ".", "make_session", "(", "num_cpu", "=", "1", ")", ".", "__enter__", "(", ")", "\n", "def", "policy_fn", "(", "name", ",", "ob_space", ",", "ac_space", ")", ":", "\n", "        ", "return", "mlp_policy", ".", "MlpPolicy", "(", "name", "=", "name", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ",", "\n", "hid_size", "=", "64", ",", "num_hid_layers", "=", "2", ")", "\n", "", "env", "=", "make_mujoco_env", "(", "env_id", ",", "seed", ")", "\n", "\n", "# parameters below were the best found in a simple random search", "\n", "# these are good enough to make humanoid walk, but whether those are", "\n", "# an absolute best or not is not certain", "\n", "env", "=", "RewScale", "(", "env", ",", "0.1", ")", "\n", "logger", ".", "log", "(", "\"NOTE: reward will be scaled by a factor of 10  in logged stats. Check the monitor for unscaled reward.\"", ")", "\n", "pi", "=", "pposgd_simple", ".", "learn", "(", "env", ",", "policy_fn", ",", "\n", "max_timesteps", "=", "num_timesteps", ",", "\n", "timesteps_per_actorbatch", "=", "2048", ",", "\n", "clip_param", "=", "0.1", ",", "entcoeff", "=", "0.0", ",", "\n", "optim_epochs", "=", "10", ",", "\n", "optim_stepsize", "=", "1e-4", ",", "\n", "optim_batchsize", "=", "64", ",", "\n", "gamma", "=", "0.99", ",", "\n", "lam", "=", "0.95", ",", "\n", "schedule", "=", "'constant'", ",", "\n", ")", "\n", "env", ".", "close", "(", ")", "\n", "if", "model_path", ":", "\n", "        ", "U", ".", "save_state", "(", "model_path", ")", "\n", "\n", "", "return", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_humanoid.main": [[47, 71], ["baselines.logger.configure", "baselines.common.cmd_util.mujoco_arg_parser", "baselines.common.cmd_util.mujoco_arg_parser.add_argument", "baselines.common.cmd_util.mujoco_arg_parser.set_defaults", "baselines.common.cmd_util.mujoco_arg_parser.parse_args", "run_humanoid.train", "run_humanoid.train", "baselines.common.tf_util.load_state", "baselines.common.cmd_util.make_mujoco_env", "baselines.common.cmd_util.make_mujoco_env.reset", "os.path.join", "int", "baselines.common.cmd_util.make_mujoco_env.step", "baselines.common.cmd_util.make_mujoco_env.render", "baselines.logger.get_dir", "train.act", "baselines.common.cmd_util.make_mujoco_env.reset"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.mujoco_arg_parser", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_mujoco_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.act", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "logger", ".", "configure", "(", ")", "\n", "parser", "=", "mujoco_arg_parser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--model-path'", ",", "default", "=", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "'humanoid_policy'", ")", ")", "\n", "parser", ".", "set_defaults", "(", "num_timesteps", "=", "int", "(", "5e7", ")", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "if", "not", "args", ".", "play", ":", "\n", "# train the model", "\n", "        ", "train", "(", "num_timesteps", "=", "args", ".", "num_timesteps", ",", "seed", "=", "args", ".", "seed", ",", "model_path", "=", "args", ".", "model_path", ")", "\n", "", "else", ":", "\n", "# construct the model object, load pre-trained model and render", "\n", "        ", "pi", "=", "train", "(", "num_timesteps", "=", "1", ",", "seed", "=", "args", ".", "seed", ")", "\n", "U", ".", "load_state", "(", "args", ".", "model_path", ")", "\n", "env", "=", "make_mujoco_env", "(", "'Humanoid-v2'", ",", "seed", "=", "0", ")", "\n", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "while", "True", ":", "\n", "            ", "action", "=", "pi", ".", "act", "(", "stochastic", "=", "False", ",", "ob", "=", "ob", ")", "[", "0", "]", "\n", "ob", ",", "_", ",", "done", ",", "_", "=", "env", ".", "step", "(", "action", ")", "\n", "env", ".", "render", "(", ")", "\n", "if", "done", ":", "\n", "                ", "ob", "=", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_robotics.train": [[10, 32], ["mpi4py.MPI.COMM_WORLD.Get_rank", "U.single_threaded_session", "U.single_threaded_session.__enter__", "mujoco_py.ignore_mujoco_warnings().__enter__", "baselines.common.set_global_seeds", "baselines.common.cmd_util.make_robotics_env", "pposgd_simple.learn", "baselines.common.cmd_util.make_robotics_env.close", "mlp_policy.MlpPolicy", "mujoco_py.ignore_mujoco_warnings"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.single_threaded_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_robotics_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["def", "train", "(", "env_id", ",", "num_timesteps", ",", "seed", ")", ":", "\n", "    ", "from", "baselines", ".", "ppo1", "import", "mlp_policy", ",", "pposgd_simple", "\n", "import", "baselines", ".", "common", ".", "tf_util", "as", "U", "\n", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "sess", "=", "U", ".", "single_threaded_session", "(", ")", "\n", "sess", ".", "__enter__", "(", ")", "\n", "mujoco_py", ".", "ignore_mujoco_warnings", "(", ")", ".", "__enter__", "(", ")", "\n", "workerseed", "=", "seed", "+", "10000", "*", "rank", "\n", "set_global_seeds", "(", "workerseed", ")", "\n", "env", "=", "make_robotics_env", "(", "env_id", ",", "workerseed", ",", "rank", "=", "rank", ")", "\n", "def", "policy_fn", "(", "name", ",", "ob_space", ",", "ac_space", ")", ":", "\n", "        ", "return", "mlp_policy", ".", "MlpPolicy", "(", "name", "=", "name", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ",", "\n", "hid_size", "=", "256", ",", "num_hid_layers", "=", "3", ")", "\n", "\n", "", "pposgd_simple", ".", "learn", "(", "env", ",", "policy_fn", ",", "\n", "max_timesteps", "=", "num_timesteps", ",", "\n", "timesteps_per_actorbatch", "=", "2048", ",", "\n", "clip_param", "=", "0.2", ",", "entcoeff", "=", "0.0", ",", "\n", "optim_epochs", "=", "5", ",", "optim_stepsize", "=", "3e-4", ",", "optim_batchsize", "=", "256", ",", "\n", "gamma", "=", "0.99", ",", "lam", "=", "0.95", ",", "schedule", "=", "'linear'", ",", "\n", ")", "\n", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_robotics.main": [[34, 37], ["baselines.common.cmd_util.robotics_arg_parser().parse_args", "run_robotics.train", "baselines.common.cmd_util.robotics_arg_parser"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.robotics_arg_parser"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "robotics_arg_parser", "(", ")", ".", "parse_args", "(", ")", "\n", "train", "(", "args", ".", "env", ",", "num_timesteps", "=", "args", ".", "num_timesteps", ",", "seed", "=", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.pposgd_simple.traj_segment_generator": [[11, 63], ["env.action_space.sample", "env.reset", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.array", "np.array.copy", "pi.act", "env.step", "ep_rets.append", "ep_lens.append", "env.reset", "range", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.act", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["def", "traj_segment_generator", "(", "pi", ",", "env", ",", "horizon", ",", "stochastic", ")", ":", "\n", "    ", "t", "=", "0", "\n", "ac", "=", "env", ".", "action_space", ".", "sample", "(", ")", "# not used, just so we have the datatype", "\n", "new", "=", "True", "# marks if we're on first timestep of an episode", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "\n", "cur_ep_ret", "=", "0", "# return in current episode", "\n", "cur_ep_len", "=", "0", "# len of current episode", "\n", "ep_rets", "=", "[", "]", "# returns of completed episodes in this segment", "\n", "ep_lens", "=", "[", "]", "# lengths of ...", "\n", "\n", "# Initialize history arrays", "\n", "obs", "=", "np", ".", "array", "(", "[", "ob", "for", "_", "in", "range", "(", "horizon", ")", "]", ")", "\n", "rews", "=", "np", ".", "zeros", "(", "horizon", ",", "'float32'", ")", "\n", "vpreds", "=", "np", ".", "zeros", "(", "horizon", ",", "'float32'", ")", "\n", "news", "=", "np", ".", "zeros", "(", "horizon", ",", "'int32'", ")", "\n", "acs", "=", "np", ".", "array", "(", "[", "ac", "for", "_", "in", "range", "(", "horizon", ")", "]", ")", "\n", "prevacs", "=", "acs", ".", "copy", "(", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "prevac", "=", "ac", "\n", "ac", ",", "vpred", "=", "pi", ".", "act", "(", "stochastic", ",", "ob", ")", "\n", "# Slight weirdness here because we need value function at time T", "\n", "# before returning segment [0, T-1] so we get the correct", "\n", "# terminal value", "\n", "if", "t", ">", "0", "and", "t", "%", "horizon", "==", "0", ":", "\n", "            ", "yield", "{", "\"ob\"", ":", "obs", ",", "\"rew\"", ":", "rews", ",", "\"vpred\"", ":", "vpreds", ",", "\"new\"", ":", "news", ",", "\n", "\"ac\"", ":", "acs", ",", "\"prevac\"", ":", "prevacs", ",", "\"nextvpred\"", ":", "vpred", "*", "(", "1", "-", "new", ")", ",", "\n", "\"ep_rets\"", ":", "ep_rets", ",", "\"ep_lens\"", ":", "ep_lens", "}", "\n", "# Be careful!!! if you change the downstream algorithm to aggregate", "\n", "# several of these batches, then be sure to do a deepcopy", "\n", "ep_rets", "=", "[", "]", "\n", "ep_lens", "=", "[", "]", "\n", "", "i", "=", "t", "%", "horizon", "\n", "obs", "[", "i", "]", "=", "ob", "\n", "vpreds", "[", "i", "]", "=", "vpred", "\n", "news", "[", "i", "]", "=", "new", "\n", "acs", "[", "i", "]", "=", "ac", "\n", "prevacs", "[", "i", "]", "=", "prevac", "\n", "\n", "ob", ",", "rew", ",", "new", ",", "_", "=", "env", ".", "step", "(", "ac", ")", "\n", "rews", "[", "i", "]", "=", "rew", "\n", "\n", "cur_ep_ret", "+=", "rew", "\n", "cur_ep_len", "+=", "1", "\n", "if", "new", ":", "\n", "            ", "ep_rets", ".", "append", "(", "cur_ep_ret", ")", "\n", "ep_lens", ".", "append", "(", "cur_ep_len", ")", "\n", "cur_ep_ret", "=", "0", "\n", "cur_ep_len", "=", "0", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "", "t", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.pposgd_simple.add_vtarg_and_adv": [[64, 79], ["numpy.append", "numpy.append", "len", "numpy.empty", "reversed", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "def", "add_vtarg_and_adv", "(", "seg", ",", "gamma", ",", "lam", ")", ":", "\n", "    ", "\"\"\"\n    Compute target value using TD(lambda) estimator, and advantage with GAE(lambda)\n    \"\"\"", "\n", "new", "=", "np", ".", "append", "(", "seg", "[", "\"new\"", "]", ",", "0", ")", "# last element is only used for last vtarg, but we already zeroed it if last new = 1", "\n", "vpred", "=", "np", ".", "append", "(", "seg", "[", "\"vpred\"", "]", ",", "seg", "[", "\"nextvpred\"", "]", ")", "\n", "T", "=", "len", "(", "seg", "[", "\"rew\"", "]", ")", "\n", "seg", "[", "\"adv\"", "]", "=", "gaelam", "=", "np", ".", "empty", "(", "T", ",", "'float32'", ")", "\n", "rew", "=", "seg", "[", "\"rew\"", "]", "\n", "lastgaelam", "=", "0", "\n", "for", "t", "in", "reversed", "(", "range", "(", "T", ")", ")", ":", "\n", "        ", "nonterminal", "=", "1", "-", "new", "[", "t", "+", "1", "]", "\n", "delta", "=", "rew", "[", "t", "]", "+", "gamma", "*", "vpred", "[", "t", "+", "1", "]", "*", "nonterminal", "-", "vpred", "[", "t", "]", "\n", "gaelam", "[", "t", "]", "=", "lastgaelam", "=", "delta", "+", "gamma", "*", "lam", "*", "nonterminal", "*", "lastgaelam", "\n", "", "seg", "[", "\"tdlamret\"", "]", "=", "seg", "[", "\"adv\"", "]", "+", "seg", "[", "\"vpred\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.pposgd_simple.learn": [[80, 215], ["policy_fn", "policy_fn", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.get_placeholder_cached", "policy_fn.pdtype.sample_placeholder", "policy_fn.pd.kl", "policy_fn.pd.entropy", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.exp", "tensorflow.reduce_mean", "policy_fn.get_trainable_variables", "baselines.function", "baselines.common.mpi_adam.MpiAdam", "baselines.function", "baselines.function", "baselines.initialize", "baselines.common.mpi_adam.MpiAdam.sync", "pposgd_simple.traj_segment_generator", "time.time", "collections.deque", "collections.deque", "tensorflow.clip_by_value", "tensorflow.reduce_mean", "tensorflow.square", "sum", "baselines.logger.log", "traj_segment_generator.__next__", "pposgd_simple.add_vtarg_and_adv", "baselines.common.Dataset", "hasattr", "U.function.", "baselines.logger.log", "baselines.logger.log", "range", "baselines.logger.log", "baselines.common.Dataset.iterate_once", "baselines.common.mpi_moments.mpi_moments", "baselines.logger.log", "baselines.common.zipsame", "baselines.logger.record_tabular", "mpi4py.MPI.COMM_WORLD.allgather", "map", "collections.deque.extend", "collections.deque.extend", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "len", "sum", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "policy_fn.pd.logp", "policy_fn.pd.logp", "tensorflow.minimum", "callback", "tf.placeholder.std", "dict", "policy_fn.ob_rms.update", "baselines.common.fmt_row", "baselines.common.Dataset.iterate_once", "baselines.logger.log", "U.function.", "losses.append", "baselines.common.fmt_row", "baselines.logger.record_tabular", "baselines.common.explained_variance", "zip", "numpy.mean", "numpy.mean", "len", "mpi4py.MPI.COMM_WORLD.Get_rank", "baselines.logger.dump_tabular", "baselines.flatgrad", "tensorflow.assign", "locals", "globals", "max", "tf.placeholder.mean", "U.function.", "baselines.common.mpi_adam.MpiAdam.update", "losses.append", "baselines.common.fmt_row", "time.time", "baselines.common.zipsame", "numpy.mean", "policy_fn.get_variables", "policy_fn.get_variables", "float", "time.time"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder_cached", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.kl", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.traj_segment_generator", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.add_vtarg_and_adv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.iterate_once", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.mpi_moments", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.zipsame", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.logp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.logp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_cartpole.callback", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.fmt_row", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.iterate_once", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.fmt_row", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.explained_variance", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.fmt_row", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.zipsame", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.get_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.get_variables"], ["", "def", "learn", "(", "env", ",", "policy_fn", ",", "*", ",", "\n", "timesteps_per_actorbatch", ",", "# timesteps per actor per update", "\n", "clip_param", ",", "entcoeff", ",", "# clipping parameter epsilon, entropy coeff", "\n", "optim_epochs", ",", "optim_stepsize", ",", "optim_batchsize", ",", "# optimization hypers", "\n", "gamma", ",", "lam", ",", "# advantage estimation", "\n", "max_timesteps", "=", "0", ",", "max_episodes", "=", "0", ",", "max_iters", "=", "0", ",", "max_seconds", "=", "0", ",", "# time constraint", "\n", "callback", "=", "None", ",", "# you can do anything in the callback, since it takes locals(), globals()", "\n", "adam_epsilon", "=", "1e-5", ",", "\n", "schedule", "=", "'constant'", "# annealing for stepsize parameters (epsilon and adam)", "\n", ")", ":", "\n", "# Setup losses and stuff", "\n", "# ----------------------------------------", "\n", "    ", "ob_space", "=", "env", ".", "observation_space", "\n", "ac_space", "=", "env", ".", "action_space", "\n", "pi", "=", "policy_fn", "(", "\"pi\"", ",", "ob_space", ",", "ac_space", ")", "# Construct network for new policy", "\n", "oldpi", "=", "policy_fn", "(", "\"oldpi\"", ",", "ob_space", ",", "ac_space", ")", "# Network for old policy", "\n", "atarg", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ")", "# Target advantage function (if applicable)", "\n", "ret", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ")", "# Empirical return", "\n", "\n", "lrmult", "=", "tf", ".", "placeholder", "(", "name", "=", "'lrmult'", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "]", ")", "# learning rate multiplier, updated with schedule", "\n", "\n", "ob", "=", "U", ".", "get_placeholder_cached", "(", "name", "=", "\"ob\"", ")", "\n", "ac", "=", "pi", ".", "pdtype", ".", "sample_placeholder", "(", "[", "None", "]", ")", "\n", "\n", "kloldnew", "=", "oldpi", ".", "pd", ".", "kl", "(", "pi", ".", "pd", ")", "\n", "ent", "=", "pi", ".", "pd", ".", "entropy", "(", ")", "\n", "meankl", "=", "tf", ".", "reduce_mean", "(", "kloldnew", ")", "\n", "meanent", "=", "tf", ".", "reduce_mean", "(", "ent", ")", "\n", "pol_entpen", "=", "(", "-", "entcoeff", ")", "*", "meanent", "\n", "\n", "ratio", "=", "tf", ".", "exp", "(", "pi", ".", "pd", ".", "logp", "(", "ac", ")", "-", "oldpi", ".", "pd", ".", "logp", "(", "ac", ")", ")", "# pnew / pold", "\n", "surr1", "=", "ratio", "*", "atarg", "# surrogate from conservative policy iteration", "\n", "surr2", "=", "tf", ".", "clip_by_value", "(", "ratio", ",", "1.0", "-", "clip_param", ",", "1.0", "+", "clip_param", ")", "*", "atarg", "#", "\n", "pol_surr", "=", "-", "tf", ".", "reduce_mean", "(", "tf", ".", "minimum", "(", "surr1", ",", "surr2", ")", ")", "# PPO's pessimistic surrogate (L^CLIP)", "\n", "vf_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "pi", ".", "vpred", "-", "ret", ")", ")", "\n", "total_loss", "=", "pol_surr", "+", "pol_entpen", "+", "vf_loss", "\n", "losses", "=", "[", "pol_surr", ",", "pol_entpen", ",", "vf_loss", ",", "meankl", ",", "meanent", "]", "\n", "loss_names", "=", "[", "\"pol_surr\"", ",", "\"pol_entpen\"", ",", "\"vf_loss\"", ",", "\"kl\"", ",", "\"ent\"", "]", "\n", "\n", "var_list", "=", "pi", ".", "get_trainable_variables", "(", ")", "\n", "lossandgrad", "=", "U", ".", "function", "(", "[", "ob", ",", "ac", ",", "atarg", ",", "ret", ",", "lrmult", "]", ",", "losses", "+", "[", "U", ".", "flatgrad", "(", "total_loss", ",", "var_list", ")", "]", ")", "\n", "adam", "=", "MpiAdam", "(", "var_list", ",", "epsilon", "=", "adam_epsilon", ")", "\n", "\n", "assign_old_eq_new", "=", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "tf", ".", "assign", "(", "oldv", ",", "newv", ")", "\n", "for", "(", "oldv", ",", "newv", ")", "in", "zipsame", "(", "oldpi", ".", "get_variables", "(", ")", ",", "pi", ".", "get_variables", "(", ")", ")", "]", ")", "\n", "compute_losses", "=", "U", ".", "function", "(", "[", "ob", ",", "ac", ",", "atarg", ",", "ret", ",", "lrmult", "]", ",", "losses", ")", "\n", "\n", "U", ".", "initialize", "(", ")", "\n", "adam", ".", "sync", "(", ")", "\n", "\n", "# Prepare for rollouts", "\n", "# ----------------------------------------", "\n", "seg_gen", "=", "traj_segment_generator", "(", "pi", ",", "env", ",", "timesteps_per_actorbatch", ",", "stochastic", "=", "True", ")", "\n", "\n", "episodes_so_far", "=", "0", "\n", "timesteps_so_far", "=", "0", "\n", "iters_so_far", "=", "0", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "lenbuffer", "=", "deque", "(", "maxlen", "=", "100", ")", "# rolling buffer for episode lengths", "\n", "rewbuffer", "=", "deque", "(", "maxlen", "=", "100", ")", "# rolling buffer for episode rewards", "\n", "\n", "assert", "sum", "(", "[", "max_iters", ">", "0", ",", "max_timesteps", ">", "0", ",", "max_episodes", ">", "0", ",", "max_seconds", ">", "0", "]", ")", "==", "1", ",", "\"Only one time constraint permitted\"", "\n", "\n", "while", "True", ":", "\n", "        ", "if", "callback", ":", "callback", "(", "locals", "(", ")", ",", "globals", "(", ")", ")", "\n", "if", "max_timesteps", "and", "timesteps_so_far", ">=", "max_timesteps", ":", "\n", "            ", "break", "\n", "", "elif", "max_episodes", "and", "episodes_so_far", ">=", "max_episodes", ":", "\n", "            ", "break", "\n", "", "elif", "max_iters", "and", "iters_so_far", ">=", "max_iters", ":", "\n", "            ", "break", "\n", "", "elif", "max_seconds", "and", "time", ".", "time", "(", ")", "-", "tstart", ">=", "max_seconds", ":", "\n", "            ", "break", "\n", "\n", "", "if", "schedule", "==", "'constant'", ":", "\n", "            ", "cur_lrmult", "=", "1.0", "\n", "", "elif", "schedule", "==", "'linear'", ":", "\n", "            ", "cur_lrmult", "=", "max", "(", "1.0", "-", "float", "(", "timesteps_so_far", ")", "/", "max_timesteps", ",", "0", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "logger", ".", "log", "(", "\"********** Iteration %i ************\"", "%", "iters_so_far", ")", "\n", "\n", "seg", "=", "seg_gen", ".", "__next__", "(", ")", "\n", "add_vtarg_and_adv", "(", "seg", ",", "gamma", ",", "lam", ")", "\n", "\n", "# ob, ac, atarg, ret, td1ret = map(np.concatenate, (obs, acs, atargs, rets, td1rets))", "\n", "ob", ",", "ac", ",", "atarg", ",", "tdlamret", "=", "seg", "[", "\"ob\"", "]", ",", "seg", "[", "\"ac\"", "]", ",", "seg", "[", "\"adv\"", "]", ",", "seg", "[", "\"tdlamret\"", "]", "\n", "vpredbefore", "=", "seg", "[", "\"vpred\"", "]", "# predicted value function before udpate", "\n", "atarg", "=", "(", "atarg", "-", "atarg", ".", "mean", "(", ")", ")", "/", "atarg", ".", "std", "(", ")", "# standardized advantage function estimate", "\n", "d", "=", "Dataset", "(", "dict", "(", "ob", "=", "ob", ",", "ac", "=", "ac", ",", "atarg", "=", "atarg", ",", "vtarg", "=", "tdlamret", ")", ",", "deterministic", "=", "pi", ".", "recurrent", ")", "\n", "optim_batchsize", "=", "optim_batchsize", "or", "ob", ".", "shape", "[", "0", "]", "\n", "\n", "if", "hasattr", "(", "pi", ",", "\"ob_rms\"", ")", ":", "pi", ".", "ob_rms", ".", "update", "(", "ob", ")", "# update running mean/std for policy", "\n", "\n", "assign_old_eq_new", "(", ")", "# set old parameter values to new parameter values", "\n", "logger", ".", "log", "(", "\"Optimizing...\"", ")", "\n", "logger", ".", "log", "(", "fmt_row", "(", "13", ",", "loss_names", ")", ")", "\n", "# Here we do a bunch of optimization epochs over the data", "\n", "for", "_", "in", "range", "(", "optim_epochs", ")", ":", "\n", "            ", "losses", "=", "[", "]", "# list of tuples, each of which gives the loss for a minibatch", "\n", "for", "batch", "in", "d", ".", "iterate_once", "(", "optim_batchsize", ")", ":", "\n", "                ", "*", "newlosses", ",", "g", "=", "lossandgrad", "(", "batch", "[", "\"ob\"", "]", ",", "batch", "[", "\"ac\"", "]", ",", "batch", "[", "\"atarg\"", "]", ",", "batch", "[", "\"vtarg\"", "]", ",", "cur_lrmult", ")", "\n", "adam", ".", "update", "(", "g", ",", "optim_stepsize", "*", "cur_lrmult", ")", "\n", "losses", ".", "append", "(", "newlosses", ")", "\n", "", "logger", ".", "log", "(", "fmt_row", "(", "13", ",", "np", ".", "mean", "(", "losses", ",", "axis", "=", "0", ")", ")", ")", "\n", "\n", "", "logger", ".", "log", "(", "\"Evaluating losses...\"", ")", "\n", "losses", "=", "[", "]", "\n", "for", "batch", "in", "d", ".", "iterate_once", "(", "optim_batchsize", ")", ":", "\n", "            ", "newlosses", "=", "compute_losses", "(", "batch", "[", "\"ob\"", "]", ",", "batch", "[", "\"ac\"", "]", ",", "batch", "[", "\"atarg\"", "]", ",", "batch", "[", "\"vtarg\"", "]", ",", "cur_lrmult", ")", "\n", "losses", ".", "append", "(", "newlosses", ")", "\n", "", "meanlosses", ",", "_", ",", "_", "=", "mpi_moments", "(", "losses", ",", "axis", "=", "0", ")", "\n", "logger", ".", "log", "(", "fmt_row", "(", "13", ",", "meanlosses", ")", ")", "\n", "for", "(", "lossval", ",", "name", ")", "in", "zipsame", "(", "meanlosses", ",", "loss_names", ")", ":", "\n", "            ", "logger", ".", "record_tabular", "(", "\"loss_\"", "+", "name", ",", "lossval", ")", "\n", "", "logger", ".", "record_tabular", "(", "\"ev_tdlam_before\"", ",", "explained_variance", "(", "vpredbefore", ",", "tdlamret", ")", ")", "\n", "lrlocal", "=", "(", "seg", "[", "\"ep_lens\"", "]", ",", "seg", "[", "\"ep_rets\"", "]", ")", "# local values", "\n", "listoflrpairs", "=", "MPI", ".", "COMM_WORLD", ".", "allgather", "(", "lrlocal", ")", "# list of tuples", "\n", "lens", ",", "rews", "=", "map", "(", "flatten_lists", ",", "zip", "(", "*", "listoflrpairs", ")", ")", "\n", "lenbuffer", ".", "extend", "(", "lens", ")", "\n", "rewbuffer", ".", "extend", "(", "rews", ")", "\n", "logger", ".", "record_tabular", "(", "\"EpLenMean\"", ",", "np", ".", "mean", "(", "lenbuffer", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"EpRewMean\"", ",", "np", ".", "mean", "(", "rewbuffer", ")", ")", "\n", "logger", ".", "record_tabular", "(", "\"EpThisIter\"", ",", "len", "(", "lens", ")", ")", "\n", "episodes_so_far", "+=", "len", "(", "lens", ")", "\n", "timesteps_so_far", "+=", "sum", "(", "lens", ")", "\n", "iters_so_far", "+=", "1", "\n", "logger", ".", "record_tabular", "(", "\"EpisodesSoFar\"", ",", "episodes_so_far", ")", "\n", "logger", ".", "record_tabular", "(", "\"TimestepsSoFar\"", ",", "timesteps_so_far", ")", "\n", "logger", ".", "record_tabular", "(", "\"TimeElapsed\"", ",", "time", ".", "time", "(", ")", "-", "tstart", ")", "\n", "if", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "==", "0", ":", "\n", "            ", "logger", ".", "dump_tabular", "(", ")", "\n", "\n", "", "", "return", "pi", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.pposgd_simple.flatten_lists": [[216, 218], ["None"], "function", ["None"], ["", "def", "flatten_lists", "(", "listoflists", ")", ":", "\n", "    ", "return", "[", "el", "for", "list_", "in", "listoflists", "for", "el", "in", "list_", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.cnn_policy.CnnPolicy.__init__": [[8, 12], ["tensorflow.variable_scope", "cnn_policy.CnnPolicy._init", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy._init"], ["def", "__init__", "(", "self", ",", "name", ",", "ob_space", ",", "ac_space", ",", "kind", "=", "'large'", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "self", ".", "_init", "(", "ob_space", ",", "ac_space", ",", "kind", ")", "\n", "self", ".", "scope", "=", "tf", ".", "get_variable_scope", "(", ")", ".", "name", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.cnn_policy.CnnPolicy._init": [[13, 46], ["isinstance", "baselines.common.distributions.make_pdtype", "baselines.get_placeholder", "tensorflow.layers.dense", "baselines.common.distributions.make_pdtype.pdfromflat", "tensorflow.placeholder", "cnn_policy.CnnPolicy.pd.sample", "baselines.function", "tensorflow.nn.relu", "tensorflow.nn.relu", "baselines.flattenallbut0", "tensorflow.nn.relu", "tensorflow.layers.dense", "baselines.conv2d", "baselines.conv2d", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "baselines.flattenallbut0", "tensorflow.nn.relu", "baselines.common.distributions.make_pdtype.param_shape", "baselines.normc_initializer", "list", "baselines.conv2d", "baselines.conv2d", "baselines.conv2d", "tensorflow.layers.dense", "baselines.normc_initializer", "baselines.normc_initializer", "baselines.normc_initializer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flattenallbut0", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flattenallbut0", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer"], ["", "", "def", "_init", "(", "self", ",", "ob_space", ",", "ac_space", ",", "kind", ")", ":", "\n", "        ", "assert", "isinstance", "(", "ob_space", ",", "gym", ".", "spaces", ".", "Box", ")", "\n", "\n", "self", ".", "pdtype", "=", "pdtype", "=", "make_pdtype", "(", "ac_space", ")", "\n", "sequence_length", "=", "None", "\n", "\n", "ob", "=", "U", ".", "get_placeholder", "(", "name", "=", "\"ob\"", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "sequence_length", "]", "+", "list", "(", "ob_space", ".", "shape", ")", ")", "\n", "\n", "x", "=", "ob", "/", "255.0", "\n", "if", "kind", "==", "'small'", ":", "# from A3C paper", "\n", "            ", "x", "=", "tf", ".", "nn", ".", "relu", "(", "U", ".", "conv2d", "(", "x", ",", "16", ",", "\"l1\"", ",", "[", "8", ",", "8", "]", ",", "[", "4", ",", "4", "]", ",", "pad", "=", "\"VALID\"", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "U", ".", "conv2d", "(", "x", ",", "32", ",", "\"l2\"", ",", "[", "4", ",", "4", "]", ",", "[", "2", ",", "2", "]", ",", "pad", "=", "\"VALID\"", ")", ")", "\n", "x", "=", "U", ".", "flattenallbut0", "(", "x", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "layers", ".", "dense", "(", "x", ",", "256", ",", "name", "=", "'lin'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", ")", "\n", "", "elif", "kind", "==", "'large'", ":", "# Nature DQN", "\n", "            ", "x", "=", "tf", ".", "nn", ".", "relu", "(", "U", ".", "conv2d", "(", "x", ",", "32", ",", "\"l1\"", ",", "[", "8", ",", "8", "]", ",", "[", "4", ",", "4", "]", ",", "pad", "=", "\"VALID\"", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "U", ".", "conv2d", "(", "x", ",", "64", ",", "\"l2\"", ",", "[", "4", ",", "4", "]", ",", "[", "2", ",", "2", "]", ",", "pad", "=", "\"VALID\"", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "U", ".", "conv2d", "(", "x", ",", "64", ",", "\"l3\"", ",", "[", "3", ",", "3", "]", ",", "[", "1", ",", "1", "]", ",", "pad", "=", "\"VALID\"", ")", ")", "\n", "x", "=", "U", ".", "flattenallbut0", "(", "x", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "layers", ".", "dense", "(", "x", ",", "512", ",", "name", "=", "'lin'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "pdtype", ".", "param_shape", "(", ")", "[", "0", "]", ",", "name", "=", "'logits'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "0.01", ")", ")", "\n", "self", ".", "pd", "=", "pdtype", ".", "pdfromflat", "(", "logits", ")", "\n", "self", ".", "vpred", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "1", ",", "name", "=", "'value'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", "[", ":", ",", "0", "]", "\n", "\n", "self", ".", "state_in", "=", "[", "]", "\n", "self", ".", "state_out", "=", "[", "]", "\n", "\n", "stochastic", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "shape", "=", "(", ")", ")", "\n", "ac", "=", "self", ".", "pd", ".", "sample", "(", ")", "# XXX", "\n", "self", ".", "_act", "=", "U", ".", "function", "(", "[", "stochastic", ",", "ob", "]", ",", "[", "ac", ",", "self", ".", "vpred", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.cnn_policy.CnnPolicy.act": [[47, 50], ["cnn_policy.CnnPolicy._act"], "methods", ["None"], ["", "def", "act", "(", "self", ",", "stochastic", ",", "ob", ")", ":", "\n", "        ", "ac1", ",", "vpred1", "=", "self", ".", "_act", "(", "stochastic", ",", "ob", "[", "None", "]", ")", "\n", "return", "ac1", "[", "0", "]", ",", "vpred1", "[", "0", "]", "\n", "", "def", "get_variables", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.cnn_policy.CnnPolicy.get_variables": [[50, 52], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "get_variables", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "scope", ")", "\n", "", "def", "get_trainable_variables", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.cnn_policy.CnnPolicy.get_trainable_variables": [[52, 54], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "get_trainable_variables", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "self", ".", "scope", ")", "\n", "", "def", "get_initial_state", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.cnn_policy.CnnPolicy.get_initial_state": [[54, 56], ["None"], "methods", ["None"], ["", "def", "get_initial_state", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_mujoco.train": [[7, 22], ["baselines.common.tf_util.make_session().__enter__", "baselines.common.cmd_util.make_mujoco_env", "pposgd_simple.learn", "baselines.common.cmd_util.make_mujoco_env.close", "mlp_policy.MlpPolicy", "baselines.common.tf_util.make_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_mujoco_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session"], ["def", "train", "(", "env_id", ",", "num_timesteps", ",", "seed", ")", ":", "\n", "    ", "from", "baselines", ".", "ppo1", "import", "mlp_policy", ",", "pposgd_simple", "\n", "U", ".", "make_session", "(", "num_cpu", "=", "1", ")", ".", "__enter__", "(", ")", "\n", "def", "policy_fn", "(", "name", ",", "ob_space", ",", "ac_space", ")", ":", "\n", "        ", "return", "mlp_policy", ".", "MlpPolicy", "(", "name", "=", "name", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ",", "\n", "hid_size", "=", "64", ",", "num_hid_layers", "=", "2", ")", "\n", "", "env", "=", "make_mujoco_env", "(", "env_id", ",", "seed", ")", "\n", "pposgd_simple", ".", "learn", "(", "env", ",", "policy_fn", ",", "\n", "max_timesteps", "=", "num_timesteps", ",", "\n", "timesteps_per_actorbatch", "=", "2048", ",", "\n", "clip_param", "=", "0.2", ",", "entcoeff", "=", "0.0", ",", "\n", "optim_epochs", "=", "10", ",", "optim_stepsize", "=", "3e-4", ",", "optim_batchsize", "=", "64", ",", "\n", "gamma", "=", "0.99", ",", "lam", "=", "0.95", ",", "schedule", "=", "'linear'", ",", "\n", ")", "\n", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_mujoco.main": [[23, 27], ["baselines.common.cmd_util.mujoco_arg_parser().parse_args", "baselines.logger.configure", "run_mujoco.train", "baselines.common.cmd_util.mujoco_arg_parser"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.mujoco_arg_parser"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "mujoco_arg_parser", "(", ")", ".", "parse_args", "(", ")", "\n", "logger", ".", "configure", "(", ")", "\n", "train", "(", "args", ".", "env", ",", "num_timesteps", "=", "args", ".", "num_timesteps", ",", "seed", "=", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_atari.train": [[11, 42], ["mpi4py.MPI.COMM_WORLD.Get_rank", "U.single_threaded_session", "U.single_threaded_session.__enter__", "baselines.common.set_global_seeds", "baselines.common.atari_wrappers.make_atari", "baselines.bench.Monitor", "baselines.common.atari_wrappers.wrap_deepmind.seed", "baselines.common.atari_wrappers.wrap_deepmind", "baselines.common.atari_wrappers.wrap_deepmind.seed", "pposgd_simple.learn", "baselines.common.atari_wrappers.wrap_deepmind.close", "baselines.logger.configure", "baselines.logger.configure", "cnn_policy.CnnPolicy", "baselines.logger.get_dir", "os.join", "int", "mpi4py.MPI.COMM_WORLD.Get_rank", "baselines.logger.get_dir", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.single_threaded_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.make_atari", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["def", "train", "(", "env_id", ",", "num_timesteps", ",", "seed", ")", ":", "\n", "    ", "from", "baselines", ".", "ppo1", "import", "pposgd_simple", ",", "cnn_policy", "\n", "import", "baselines", ".", "common", ".", "tf_util", "as", "U", "\n", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "sess", "=", "U", ".", "single_threaded_session", "(", ")", "\n", "sess", ".", "__enter__", "(", ")", "\n", "if", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "configure", "(", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "configure", "(", "format_strs", "=", "[", "]", ")", "\n", "", "workerseed", "=", "seed", "+", "10000", "*", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "if", "seed", "is", "not", "None", "else", "None", "\n", "set_global_seeds", "(", "workerseed", ")", "\n", "env", "=", "make_atari", "(", "env_id", ")", "\n", "def", "policy_fn", "(", "name", ",", "ob_space", ",", "ac_space", ")", ":", "#pylint: disable=W0613", "\n", "        ", "return", "cnn_policy", ".", "CnnPolicy", "(", "name", "=", "name", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ")", "\n", "", "env", "=", "bench", ".", "Monitor", "(", "env", ",", "logger", ".", "get_dir", "(", ")", "and", "\n", "osp", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "str", "(", "rank", ")", ")", ")", "\n", "env", ".", "seed", "(", "workerseed", ")", "\n", "\n", "env", "=", "wrap_deepmind", "(", "env", ")", "\n", "env", ".", "seed", "(", "workerseed", ")", "\n", "\n", "pposgd_simple", ".", "learn", "(", "env", ",", "policy_fn", ",", "\n", "max_timesteps", "=", "int", "(", "num_timesteps", "*", "1.1", ")", ",", "\n", "timesteps_per_actorbatch", "=", "256", ",", "\n", "clip_param", "=", "0.2", ",", "entcoeff", "=", "0.01", ",", "\n", "optim_epochs", "=", "4", ",", "optim_stepsize", "=", "1e-3", ",", "optim_batchsize", "=", "64", ",", "\n", "gamma", "=", "0.99", ",", "lam", "=", "0.95", ",", "\n", "schedule", "=", "'linear'", "\n", ")", "\n", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ppo1.run_atari.main": [[43, 46], ["baselines.common.cmd_util.atari_arg_parser().parse_args", "run_atari.train", "baselines.common.cmd_util.atari_arg_parser"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.atari_arg_parser"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "atari_arg_parser", "(", ")", ".", "parse_args", "(", ")", "\n", "train", "(", "args", ".", "env", ",", "num_timesteps", "=", "args", ".", "num_timesteps", ",", "seed", "=", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.statistics.stats.__init__": [[13, 33], ["tensorflow.summary.merge", "tensorflow.variable_scope", "tensorflow.placeholder", "tensorflow.summary.scalar", "statistics.stats.scalar_summaries_ph.append", "statistics.stats.scalar_summaries.append", "tensorflow.placeholder", "tensorflow.summary.scalar", "statistics.stats.histogram_summaries_ph.append", "statistics.stats.histogram_summaries.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["    ", "def", "__init__", "(", "self", ",", "scalar_keys", "=", "[", "]", ",", "histogram_keys", "=", "[", "]", ")", ":", "\n", "        ", "self", ".", "scalar_keys", "=", "scalar_keys", "\n", "self", ".", "histogram_keys", "=", "histogram_keys", "\n", "self", ".", "scalar_summaries", "=", "[", "]", "\n", "self", ".", "scalar_summaries_ph", "=", "[", "]", "\n", "self", ".", "histogram_summaries_ph", "=", "[", "]", "\n", "self", ".", "histogram_summaries", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "'summary'", ")", ":", "\n", "            ", "for", "k", "in", "scalar_keys", ":", "\n", "                ", "ph", "=", "tf", ".", "placeholder", "(", "'float32'", ",", "None", ",", "name", "=", "k", "+", "'.scalar.summary'", ")", "\n", "sm", "=", "tf", ".", "summary", ".", "scalar", "(", "k", "+", "'.scalar.summary'", ",", "ph", ")", "\n", "self", ".", "scalar_summaries_ph", ".", "append", "(", "ph", ")", "\n", "self", ".", "scalar_summaries", ".", "append", "(", "sm", ")", "\n", "", "for", "k", "in", "histogram_keys", ":", "\n", "                ", "ph", "=", "tf", ".", "placeholder", "(", "'float32'", ",", "None", ",", "name", "=", "k", "+", "'.histogram.summary'", ")", "\n", "sm", "=", "tf", ".", "summary", ".", "scalar", "(", "k", "+", "'.histogram.summary'", ",", "ph", ")", "\n", "self", ".", "histogram_summaries_ph", ".", "append", "(", "ph", ")", "\n", "self", ".", "histogram_summaries", ".", "append", "(", "sm", ")", "\n", "\n", "", "", "self", ".", "summaries", "=", "tf", ".", "summary", ".", "merge", "(", "self", ".", "scalar_summaries", "+", "self", ".", "histogram_summaries", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.statistics.stats.add_all_summary": [[34, 46], ["baselines.get_session", "zip", "baselines.get_session.run", "writer.add_summary", "numpy.sum", "feed_dict.update", "numpy.isnan"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "add_all_summary", "(", "self", ",", "writer", ",", "values", ",", "iter", ")", ":", "\n", "# Note that the order of the incoming ```values``` should be the same as the that of the", "\n", "#            ```scalar_keys``` given in ```__init__```", "\n", "        ", "if", "np", ".", "sum", "(", "np", ".", "isnan", "(", "values", ")", "+", "0", ")", "!=", "0", ":", "\n", "            ", "return", "\n", "", "sess", "=", "U", ".", "get_session", "(", ")", "\n", "keys", "=", "self", ".", "scalar_summaries_ph", "+", "self", ".", "histogram_summaries_ph", "\n", "feed_dict", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "zip", "(", "keys", ",", "values", ")", ":", "\n", "            ", "feed_dict", ".", "update", "(", "{", "k", ":", "v", "}", ")", "\n", "", "summaries_str", "=", "sess", ".", "run", "(", "self", ".", "summaries", ",", "feed_dict", ")", "\n", "writer", ".", "add_summary", "(", "summaries_str", ",", "iter", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.__init__": [[18, 24], ["tensorflow.variable_scope", "mlp_policy.MlpPolicy._init", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.get_variable_scope", "tensorflow.get_variable_scope"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy._init"], ["sequence_length", "=", "None", "\n", "\n", "ob", "=", "U", ".", "get_placeholder", "(", "name", "=", "\"ob\"", ",", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "sequence_length", "]", "+", "list", "(", "ob_space", ".", "shape", ")", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"obfilter\"", ")", ":", "\n", "            ", "self", ".", "ob_rms", "=", "RunningMeanStd", "(", "shape", "=", "ob_space", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy._init": [[25, 63], ["isinstance", "baselines.common.distributions.make_pdtype", "baselines.get_placeholder", "tensorflow.clip_by_value", "range", "range", "baselines.common.distributions.make_pdtype.pdfromflat", "baselines.get_placeholder", "baselines.switch", "baselines.function", "tensorflow.variable_scope", "baselines.common.mpi_running_mean_std.RunningMeanStd", "tensorflow.nn.tanh", "baselines.acktr.utils.dense", "tensorflow.nn.tanh", "isinstance", "baselines.acktr.utils.dense", "tensorflow.get_variable", "tensorflow.concat", "baselines.acktr.utils.dense", "mlp_policy.MlpPolicy.pd.sample", "mlp_policy.MlpPolicy.pd.mode", "baselines.acktr.utils.dense", "baselines.acktr.utils.dense", "baselines.normc_initializer", "baselines.normc_initializer", "list", "baselines.normc_initializer", "tensorflow.zeros_initializer", "baselines.common.distributions.make_pdtype.param_shape", "baselines.normc_initializer", "baselines.normc_initializer", "baselines.common.distributions.make_pdtype.param_shape", "baselines.common.distributions.make_pdtype.param_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.switch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mode", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape"], ["", "with", "tf", ".", "variable_scope", "(", "'vf'", ")", ":", "\n", "            ", "obz", "=", "tf", ".", "clip_by_value", "(", "(", "ob", "-", "self", ".", "ob_rms", ".", "mean", ")", "/", "self", ".", "ob_rms", ".", "std", ",", "-", "5.0", ",", "5.0", ")", "\n", "last_out", "=", "obz", "\n", "for", "i", "in", "range", "(", "num_hid_layers", ")", ":", "\n", "                ", "last_out", "=", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "hid_size", ",", "name", "=", "\"fc%i\"", "%", "(", "i", "+", "1", ")", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", ")", "\n", "", "self", ".", "vpred", "=", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "1", ",", "name", "=", "'final'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", "[", ":", ",", "0", "]", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'pol'", ")", ":", "\n", "            ", "last_out", "=", "obz", "\n", "for", "i", "in", "range", "(", "num_hid_layers", ")", ":", "\n", "                ", "last_out", "=", "tf", ".", "nn", ".", "tanh", "(", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "hid_size", ",", "name", "=", "'fc%i'", "%", "(", "i", "+", "1", ")", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "1.0", ")", ")", ")", "\n", "", "if", "gaussian_fixed_var", "and", "isinstance", "(", "ac_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "                ", "mean", "=", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "pdtype", ".", "param_shape", "(", ")", "[", "0", "]", "//", "2", ",", "name", "=", "'final'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "0.01", ")", ")", "\n", "logstd", "=", "tf", ".", "get_variable", "(", "name", "=", "\"logstd\"", ",", "shape", "=", "[", "1", ",", "pdtype", ".", "param_shape", "(", ")", "[", "0", "]", "//", "2", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "pdparam", "=", "tf", ".", "concat", "(", "[", "mean", ",", "mean", "*", "0.0", "+", "logstd", "]", ",", "axis", "=", "1", ")", "\n", "", "else", ":", "\n", "                ", "pdparam", "=", "tf", ".", "layers", ".", "dense", "(", "last_out", ",", "pdtype", ".", "param_shape", "(", ")", "[", "0", "]", ",", "name", "=", "'final'", ",", "kernel_initializer", "=", "U", ".", "normc_initializer", "(", "0.01", ")", ")", "\n", "\n", "", "", "self", ".", "pd", "=", "pdtype", ".", "pdfromflat", "(", "pdparam", ")", "\n", "\n", "self", ".", "state_in", "=", "[", "]", "\n", "self", ".", "state_out", "=", "[", "]", "\n", "\n", "stochastic", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "shape", "=", "(", ")", ")", "\n", "ac", "=", "U", ".", "switch", "(", "stochastic", ",", "self", ".", "pd", ".", "sample", "(", ")", ",", "self", ".", "pd", ".", "mode", "(", ")", ")", "\n", "self", ".", "_act", "=", "U", ".", "function", "(", "[", "stochastic", ",", "ob", "]", ",", "[", "ac", ",", "self", ".", "vpred", "]", ")", "\n", "\n", "", "def", "act", "(", "self", ",", "stochastic", ",", "ob", ")", ":", "\n", "        ", "ac1", ",", "vpred1", "=", "self", ".", "_act", "(", "stochastic", ",", "ob", "[", "None", "]", ")", "\n", "return", "ac1", "[", "0", "]", ",", "vpred1", "[", "0", "]", "\n", "", "def", "get_variables", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "self", ".", "scope", ")", "\n", "", "def", "get_trainable_variables", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "self", ".", "scope", ")", "\n", "", "def", "get_initial_state", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.act": [[64, 67], ["mlp_policy.MlpPolicy._act"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.get_variables": [[68, 70], ["tensorflow.get_collection"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.get_trainable_variables": [[71, 73], ["tensorflow.get_collection"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.get_initial_state": [[74, 76], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.behavior_clone.argsparser": [[24, 40], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "baselines.common.misc_util.boolean_flag", "baselines.common.misc_util.boolean_flag", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.boolean_flag", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.boolean_flag"], ["def", "argsparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Tensorflow Implementation of Behavior Cloning\"", ")", "\n", "parser", ".", "add_argument", "(", "'--env_id'", ",", "help", "=", "'environment ID'", ",", "default", "=", "'Hopper-v2'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'RNG seed'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--expert_path'", ",", "type", "=", "str", ",", "default", "=", "'data/deterministic.trpo.Hopper.0.00.npz'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint_dir'", ",", "help", "=", "'the directory to save model'", ",", "default", "=", "'checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "help", "=", "'the directory to save log file'", ",", "default", "=", "'log'", ")", "\n", "#  Mujoco Dataset Configuration", "\n", "parser", ".", "add_argument", "(", "'--traj_limitation'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "# Network Configuration (Using MLP Policy)", "\n", "parser", ".", "add_argument", "(", "'--policy_hidden_size'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "# for evaluatation", "\n", "boolean_flag", "(", "parser", ",", "'stochastic_policy'", ",", "default", "=", "False", ",", "help", "=", "'use stochastic/deterministic policy to evaluate'", ")", "\n", "boolean_flag", "(", "parser", ",", "'save_sample'", ",", "default", "=", "False", ",", "help", "=", "'save the trajectories or not'", ")", "\n", "parser", ".", "add_argument", "(", "'--BC_max_iter'", ",", "help", "=", "'Max iteration for training BC'", ",", "type", "=", "int", ",", "default", "=", "1e5", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.behavior_clone.learn": [[42, 78], ["int", "policy_func", "baselines.common.tf_util.get_placeholder_cached", "policy_func.pdtype.sample_placeholder", "baselines.common.tf_util.get_placeholder_cached", "tensorflow.reduce_mean", "policy_func.get_trainable_variables", "baselines.common.mpi_adam.MpiAdam", "baselines.common.tf_util.function", "baselines.common.tf_util.initialize", "baselines.common.mpi_adam.MpiAdam.sync", "baselines.logger.log", "tqdm.tqdm", "baselines.common.tf_util.save_variables", "tensorflow.square", "range", "dataset.get_next_batch", "U.function.", "baselines.common.mpi_adam.MpiAdam.update", "os.join", "int", "dataset.get_next_batch", "U.function.", "baselines.logger.log", "tempfile.TemporaryDirectory", "policy_func.get_variables", "baselines.common.tf_util.flatgrad"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder_cached", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder_cached", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.get_next_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.get_next_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.get_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad"], ["", "def", "learn", "(", "env", ",", "policy_func", ",", "dataset", ",", "optim_batch_size", "=", "128", ",", "max_iters", "=", "1e4", ",", "\n", "adam_epsilon", "=", "1e-5", ",", "optim_stepsize", "=", "3e-4", ",", "\n", "ckpt_dir", "=", "None", ",", "log_dir", "=", "None", ",", "task_name", "=", "None", ",", "\n", "verbose", "=", "False", ")", ":", "\n", "\n", "    ", "val_per_iter", "=", "int", "(", "max_iters", "/", "10", ")", "\n", "ob_space", "=", "env", ".", "observation_space", "\n", "ac_space", "=", "env", ".", "action_space", "\n", "pi", "=", "policy_func", "(", "\"pi\"", ",", "ob_space", ",", "ac_space", ")", "# Construct network for new policy", "\n", "# placeholder", "\n", "ob", "=", "U", ".", "get_placeholder_cached", "(", "name", "=", "\"ob\"", ")", "\n", "ac", "=", "pi", ".", "pdtype", ".", "sample_placeholder", "(", "[", "None", "]", ")", "\n", "stochastic", "=", "U", ".", "get_placeholder_cached", "(", "name", "=", "\"stochastic\"", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "ac", "-", "pi", ".", "ac", ")", ")", "\n", "var_list", "=", "pi", ".", "get_trainable_variables", "(", ")", "\n", "adam", "=", "MpiAdam", "(", "var_list", ",", "epsilon", "=", "adam_epsilon", ")", "\n", "lossandgrad", "=", "U", ".", "function", "(", "[", "ob", ",", "ac", ",", "stochastic", "]", ",", "[", "loss", "]", "+", "[", "U", ".", "flatgrad", "(", "loss", ",", "var_list", ")", "]", ")", "\n", "\n", "U", ".", "initialize", "(", ")", "\n", "adam", ".", "sync", "(", ")", "\n", "logger", ".", "log", "(", "\"Pretraining with Behavior Cloning...\"", ")", "\n", "for", "iter_so_far", "in", "tqdm", "(", "range", "(", "int", "(", "max_iters", ")", ")", ")", ":", "\n", "        ", "ob_expert", ",", "ac_expert", "=", "dataset", ".", "get_next_batch", "(", "optim_batch_size", ",", "'train'", ")", "\n", "train_loss", ",", "g", "=", "lossandgrad", "(", "ob_expert", ",", "ac_expert", ",", "True", ")", "\n", "adam", ".", "update", "(", "g", ",", "optim_stepsize", ")", "\n", "if", "verbose", "and", "iter_so_far", "%", "val_per_iter", "==", "0", ":", "\n", "            ", "ob_expert", ",", "ac_expert", "=", "dataset", ".", "get_next_batch", "(", "-", "1", ",", "'val'", ")", "\n", "val_loss", ",", "_", "=", "lossandgrad", "(", "ob_expert", ",", "ac_expert", ",", "True", ")", "\n", "logger", ".", "log", "(", "\"Training loss: {}, Validation loss: {}\"", ".", "format", "(", "train_loss", ",", "val_loss", ")", ")", "\n", "\n", "", "", "if", "ckpt_dir", "is", "None", ":", "\n", "        ", "savedir_fname", "=", "tempfile", ".", "TemporaryDirectory", "(", ")", ".", "name", "\n", "", "else", ":", "\n", "        ", "savedir_fname", "=", "osp", ".", "join", "(", "ckpt_dir", ",", "task_name", ")", "\n", "", "U", ".", "save_variables", "(", "savedir_fname", ",", "variables", "=", "pi", ".", "get_variables", "(", ")", ")", "\n", "return", "savedir_fname", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.behavior_clone.get_task_name": [[80, 86], ["args.env_id.split"], "function", ["None"], ["", "def", "get_task_name", "(", "args", ")", ":", "\n", "    ", "task_name", "=", "'BC'", "\n", "task_name", "+=", "'.{}'", ".", "format", "(", "args", ".", "env_id", ".", "split", "(", "\"-\"", ")", "[", "0", "]", ")", "\n", "task_name", "+=", "'.traj_limitation_{}'", ".", "format", "(", "args", ".", "traj_limitation", ")", "\n", "task_name", "+=", "\".seed_{}\"", ".", "format", "(", "args", ".", "seed", ")", "\n", "return", "task_name", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.behavior_clone.main": [[88, 120], ["baselines.common.tf_util.make_session().__enter__", "baselines.common.set_global_seeds", "gym.make", "baselines.bench.Monitor", "bench.Monitor.seed", "gym.logger.setLevel", "behavior_clone.get_task_name", "os.join", "os.join", "baselines.gail.dataset.mujoco_dset.Mujoco_Dset", "behavior_clone.learn", "baselines.gail.run_mujoco.runner", "baselines.gail.mlp_policy.MlpPolicy", "baselines.common.tf_util.make_session", "baselines.logger.get_dir", "os.join", "baselines.logger.get_dir"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.get_task_name", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.runner", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "U", ".", "make_session", "(", "num_cpu", "=", "1", ")", ".", "__enter__", "(", ")", "\n", "set_global_seeds", "(", "args", ".", "seed", ")", "\n", "env", "=", "gym", ".", "make", "(", "args", ".", "env_id", ")", "\n", "\n", "def", "policy_fn", "(", "name", ",", "ob_space", ",", "ac_space", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "return", "mlp_policy", ".", "MlpPolicy", "(", "name", "=", "name", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ",", "\n", "reuse", "=", "reuse", ",", "hid_size", "=", "args", ".", "policy_hidden_size", ",", "num_hid_layers", "=", "2", ")", "\n", "", "env", "=", "bench", ".", "Monitor", "(", "env", ",", "logger", ".", "get_dir", "(", ")", "and", "\n", "osp", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "\"monitor.json\"", ")", ")", "\n", "env", ".", "seed", "(", "args", ".", "seed", ")", "\n", "gym", ".", "logger", ".", "setLevel", "(", "logging", ".", "WARN", ")", "\n", "task_name", "=", "get_task_name", "(", "args", ")", "\n", "args", ".", "checkpoint_dir", "=", "osp", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "task_name", ")", "\n", "args", ".", "log_dir", "=", "osp", ".", "join", "(", "args", ".", "log_dir", ",", "task_name", ")", "\n", "dataset", "=", "Mujoco_Dset", "(", "expert_path", "=", "args", ".", "expert_path", ",", "traj_limitation", "=", "args", ".", "traj_limitation", ")", "\n", "savedir_fname", "=", "learn", "(", "env", ",", "\n", "policy_fn", ",", "\n", "dataset", ",", "\n", "max_iters", "=", "args", ".", "BC_max_iter", ",", "\n", "ckpt_dir", "=", "args", ".", "checkpoint_dir", ",", "\n", "log_dir", "=", "args", ".", "log_dir", ",", "\n", "task_name", "=", "task_name", ",", "\n", "verbose", "=", "True", ")", "\n", "avg_len", ",", "avg_ret", "=", "runner", "(", "env", ",", "\n", "policy_fn", ",", "\n", "savedir_fname", ",", "\n", "timesteps_per_batch", "=", "1024", ",", "\n", "number_trajs", "=", "10", ",", "\n", "stochastic_policy", "=", "args", ".", "stochastic_policy", ",", "\n", "save", "=", "args", ".", "save_sample", ",", "\n", "reuse", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.__init__": [[21, 55], ["tuple", "adversary.TransitionClassifier.build_ph", "adversary.TransitionClassifier.build_graph", "adversary.TransitionClassifier.build_graph", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.reduce_mean", "tensorflow.concat", "tensorflow.reduce_mean", "adversary.TransitionClassifier.get_trainable_variables", "baselines.common.tf_util.function", "tensorflow.to_float", "tensorflow.to_float", "adversary.logit_bernoulli_entropy", "tensorflow.log", "tensorflow.zeros_like", "tensorflow.ones_like", "zip", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "baselines.common.tf_util.flatgrad", "tensorflow.nn.sigmoid"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.build_ph", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.build_graph", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.build_graph", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.logit_bernoulli_entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "hidden_size", ",", "entcoeff", "=", "0.001", ",", "lr_rate", "=", "1e-3", ",", "scope", "=", "\"adversary\"", ")", ":", "\n", "        ", "self", ".", "scope", "=", "scope", "\n", "self", ".", "observation_shape", "=", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "actions_shape", "=", "env", ".", "action_space", ".", "shape", "\n", "self", ".", "input_shape", "=", "tuple", "(", "[", "o", "+", "a", "for", "o", ",", "a", "in", "zip", "(", "self", ".", "observation_shape", ",", "self", ".", "actions_shape", ")", "]", ")", "\n", "self", ".", "num_actions", "=", "env", ".", "action_space", ".", "shape", "[", "0", "]", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "build_ph", "(", ")", "\n", "# Build grpah", "\n", "generator_logits", "=", "self", ".", "build_graph", "(", "self", ".", "generator_obs_ph", ",", "self", ".", "generator_acs_ph", ",", "reuse", "=", "False", ")", "\n", "expert_logits", "=", "self", ".", "build_graph", "(", "self", ".", "expert_obs_ph", ",", "self", ".", "expert_acs_ph", ",", "reuse", "=", "True", ")", "\n", "# Build accuracy", "\n", "generator_acc", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "to_float", "(", "tf", ".", "nn", ".", "sigmoid", "(", "generator_logits", ")", "<", "0.5", ")", ")", "\n", "expert_acc", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "to_float", "(", "tf", ".", "nn", ".", "sigmoid", "(", "expert_logits", ")", ">", "0.5", ")", ")", "\n", "# Build regression loss", "\n", "# let x = logits, z = targets.", "\n", "# z * -log(sigmoid(x)) + (1 - z) * -log(1 - sigmoid(x))", "\n", "generator_loss", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "generator_logits", ",", "labels", "=", "tf", ".", "zeros_like", "(", "generator_logits", ")", ")", "\n", "generator_loss", "=", "tf", ".", "reduce_mean", "(", "generator_loss", ")", "\n", "expert_loss", "=", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "expert_logits", ",", "labels", "=", "tf", ".", "ones_like", "(", "expert_logits", ")", ")", "\n", "expert_loss", "=", "tf", ".", "reduce_mean", "(", "expert_loss", ")", "\n", "# Build entropy loss", "\n", "logits", "=", "tf", ".", "concat", "(", "[", "generator_logits", ",", "expert_logits", "]", ",", "0", ")", "\n", "entropy", "=", "tf", ".", "reduce_mean", "(", "logit_bernoulli_entropy", "(", "logits", ")", ")", "\n", "entropy_loss", "=", "-", "entcoeff", "*", "entropy", "\n", "# Loss + Accuracy terms", "\n", "self", ".", "losses", "=", "[", "generator_loss", ",", "expert_loss", ",", "entropy", ",", "entropy_loss", ",", "generator_acc", ",", "expert_acc", "]", "\n", "self", ".", "loss_name", "=", "[", "\"generator_loss\"", ",", "\"expert_loss\"", ",", "\"entropy\"", ",", "\"entropy_loss\"", ",", "\"generator_acc\"", ",", "\"expert_acc\"", "]", "\n", "self", ".", "total_loss", "=", "generator_loss", "+", "expert_loss", "+", "entropy_loss", "\n", "# Build Reward for policy", "\n", "self", ".", "reward_op", "=", "-", "tf", ".", "log", "(", "1", "-", "tf", ".", "nn", ".", "sigmoid", "(", "generator_logits", ")", "+", "1e-8", ")", "\n", "var_list", "=", "self", ".", "get_trainable_variables", "(", ")", "\n", "self", ".", "lossandgrad", "=", "U", ".", "function", "(", "[", "self", ".", "generator_obs_ph", ",", "self", ".", "generator_acs_ph", ",", "self", ".", "expert_obs_ph", ",", "self", ".", "expert_acs_ph", "]", ",", "\n", "self", ".", "losses", "+", "[", "U", ".", "flatgrad", "(", "self", ".", "total_loss", ",", "var_list", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.build_ph": [[56, 61], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "build_ph", "(", "self", ")", ":", "\n", "        ", "self", ".", "generator_obs_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "observation_shape", ",", "name", "=", "\"observations_ph\"", ")", "\n", "self", ".", "generator_acs_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "actions_shape", ",", "name", "=", "\"actions_ph\"", ")", "\n", "self", ".", "expert_obs_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "observation_shape", ",", "name", "=", "\"expert_observations_ph\"", ")", "\n", "self", ".", "expert_acs_ph", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "(", "None", ",", ")", "+", "self", ".", "actions_shape", ",", "name", "=", "\"expert_actions_ph\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.build_graph": [[62, 75], ["tensorflow.variable_scope", "tensorflow.concat", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected", "tensorflow.contrib.layers.fully_connected", "tensorflow.get_variable_scope().reuse_variables", "tensorflow.variable_scope", "baselines.common.mpi_running_mean_std.RunningMeanStd", "tensorflow.get_variable_scope"], "methods", ["None"], ["", "def", "build_graph", "(", "self", ",", "obs_ph", ",", "acs_ph", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "if", "reuse", ":", "\n", "                ", "tf", ".", "get_variable_scope", "(", ")", ".", "reuse_variables", "(", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"obfilter\"", ")", ":", "\n", "                ", "self", ".", "obs_rms", "=", "RunningMeanStd", "(", "shape", "=", "self", ".", "observation_shape", ")", "\n", "", "obs", "=", "(", "obs_ph", "-", "self", ".", "obs_rms", ".", "mean", ")", "/", "self", ".", "obs_rms", ".", "std", "\n", "_input", "=", "tf", ".", "concat", "(", "[", "obs", ",", "acs_ph", "]", ",", "axis", "=", "1", ")", "# concatenate the two input -> form a transition", "\n", "p_h1", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "_input", ",", "self", ".", "hidden_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "tanh", ")", "\n", "p_h2", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "p_h1", ",", "self", ".", "hidden_size", ",", "activation_fn", "=", "tf", ".", "nn", ".", "tanh", ")", "\n", "logits", "=", "tf", ".", "contrib", ".", "layers", ".", "fully_connected", "(", "p_h2", ",", "1", ",", "activation_fn", "=", "tf", ".", "identity", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables": [[76, 78], ["tensorflow.get_collection"], "methods", ["None"], ["", "def", "get_trainable_variables", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "self", ".", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_reward": [[79, 88], ["tensorflow.get_default_session", "tensorflow.get_default_session.run", "len", "numpy.expand_dims", "len", "numpy.expand_dims"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "get_reward", "(", "self", ",", "obs", ",", "acs", ")", ":", "\n", "        ", "sess", "=", "tf", ".", "get_default_session", "(", ")", "\n", "if", "len", "(", "obs", ".", "shape", ")", "==", "1", ":", "\n", "            ", "obs", "=", "np", ".", "expand_dims", "(", "obs", ",", "0", ")", "\n", "", "if", "len", "(", "acs", ".", "shape", ")", "==", "1", ":", "\n", "            ", "acs", "=", "np", ".", "expand_dims", "(", "acs", ",", "0", ")", "\n", "", "feed_dict", "=", "{", "self", ".", "generator_obs_ph", ":", "obs", ",", "self", ".", "generator_acs_ph", ":", "acs", "}", "\n", "reward", "=", "sess", ".", "run", "(", "self", ".", "reward_op", ",", "feed_dict", ")", "\n", "return", "reward", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.logsigmoid": [[11, 14], ["tensorflow.nn.softplus"], "function", ["None"], ["def", "logsigmoid", "(", "a", ")", ":", "\n", "    ", "'''Equivalent to tf.log(tf.sigmoid(a))'''", "\n", "return", "-", "tf", ".", "nn", ".", "softplus", "(", "-", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.logit_bernoulli_entropy": [[16, 19], ["adversary.logsigmoid", "tensorflow.nn.sigmoid"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.logsigmoid"], ["def", "logit_bernoulli_entropy", "(", "logits", ")", ":", "\n", "    ", "ent", "=", "(", "1.", "-", "tf", ".", "nn", ".", "sigmoid", "(", "logits", ")", ")", "*", "logits", "-", "logsigmoid", "(", "logits", ")", "\n", "return", "ent", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.load_dataset": [[28, 31], ["baselines.gail.dataset.mujoco_dset.Mujoco_Dset"], "function", ["None"], ["def", "load_dataset", "(", "expert_path", ")", ":", "\n", "    ", "dataset", "=", "Mujoco_Dset", "(", "expert_path", "=", "expert_path", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.argsparser": [[33, 41], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "baselines.common.misc_util.boolean_flag", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.boolean_flag"], ["", "def", "argsparser", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "'Do evaluation'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--policy_hidden_size'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'--env'", ",", "type", "=", "str", ",", "choices", "=", "[", "'Hopper'", ",", "'Walker2d'", ",", "'HalfCheetah'", ",", "\n", "'Humanoid'", ",", "'HumanoidStandup'", "]", ")", "\n", "boolean_flag", "(", "parser", ",", "'stochastic_policy'", ",", "default", "=", "False", ",", "help", "=", "'use stochastic/deterministic policy to evaluate'", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.evaluate_env": [[43, 90], ["os.path.join", "gail-eval.load_dataset", "glob.glob", "enumerate", "baselines.gail.mlp_policy.MlpPolicy", "os.path.join", "gail-eval.evaluate_env.get_checkpoint_dir"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.load_dataset"], ["", "def", "evaluate_env", "(", "env_name", ",", "seed", ",", "policy_hidden_size", ",", "stochastic", ",", "reuse", ",", "prefix", ")", ":", "\n", "\n", "    ", "def", "get_checkpoint_dir", "(", "checkpoint_list", ",", "limit", ",", "prefix", ")", ":", "\n", "        ", "for", "checkpoint", "in", "checkpoint_list", ":", "\n", "            ", "if", "(", "'limitation_'", "+", "str", "(", "limit", ")", "in", "checkpoint", ")", "and", "(", "prefix", "in", "checkpoint", ")", ":", "\n", "                ", "return", "checkpoint", "\n", "", "", "return", "None", "\n", "\n", "", "def", "policy_fn", "(", "name", ",", "ob_space", ",", "ac_space", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "return", "mlp_policy", ".", "MlpPolicy", "(", "name", "=", "name", ",", "ob_space", "=", "ob_space", ",", "ac_space", "=", "ac_space", ",", "\n", "reuse", "=", "reuse", ",", "hid_size", "=", "policy_hidden_size", ",", "num_hid_layers", "=", "2", ")", "\n", "\n", "", "data_path", "=", "os", ".", "path", ".", "join", "(", "'data'", ",", "'deterministic.trpo.'", "+", "env_name", "+", "'.0.00.npz'", ")", "\n", "dataset", "=", "load_dataset", "(", "data_path", ")", "\n", "checkpoint_list", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "'checkpoint'", ",", "'*'", "+", "env_name", "+", "\".*\"", ")", ")", "\n", "log", "=", "{", "\n", "'traj_limitation'", ":", "[", "]", ",", "\n", "'upper_bound'", ":", "[", "]", ",", "\n", "'avg_ret'", ":", "[", "]", ",", "\n", "'avg_len'", ":", "[", "]", ",", "\n", "'normalized_ret'", ":", "[", "]", "\n", "}", "\n", "for", "i", ",", "limit", "in", "enumerate", "(", "CONFIG", "[", "'traj_limitation'", "]", ")", ":", "\n", "# Do one evaluation", "\n", "        ", "upper_bound", "=", "sum", "(", "dataset", ".", "rets", "[", ":", "limit", "]", ")", "/", "limit", "\n", "checkpoint_dir", "=", "get_checkpoint_dir", "(", "checkpoint_list", ",", "limit", ",", "prefix", "=", "prefix", ")", "\n", "checkpoint_path", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "checkpoint_dir", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_name", "+", "'-v1'", ")", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "print", "(", "'Trajectory limitation: {}, Load checkpoint: {}, '", ".", "format", "(", "limit", ",", "checkpoint_path", ")", ")", "\n", "avg_len", ",", "avg_ret", "=", "run_mujoco", ".", "runner", "(", "env", ",", "\n", "policy_fn", ",", "\n", "checkpoint_path", ",", "\n", "timesteps_per_batch", "=", "1024", ",", "\n", "number_trajs", "=", "10", ",", "\n", "stochastic_policy", "=", "stochastic", ",", "\n", "reuse", "=", "(", "(", "i", "!=", "0", ")", "or", "reuse", ")", ")", "\n", "normalized_ret", "=", "avg_ret", "/", "upper_bound", "\n", "print", "(", "'Upper bound: {}, evaluation returns: {}, normalized scores: {}'", ".", "format", "(", "\n", "upper_bound", ",", "avg_ret", ",", "normalized_ret", ")", ")", "\n", "log", "[", "'traj_limitation'", "]", ".", "append", "(", "limit", ")", "\n", "log", "[", "'upper_bound'", "]", ".", "append", "(", "upper_bound", ")", "\n", "log", "[", "'avg_ret'", "]", ".", "append", "(", "avg_ret", ")", "\n", "log", "[", "'avg_len'", "]", ".", "append", "(", "avg_len", ")", "\n", "log", "[", "'normalized_ret'", "]", ".", "append", "(", "normalized_ret", ")", "\n", "env", ".", "close", "(", ")", "\n", "", "return", "log", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.plot": [[92, 128], ["matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.title", "matplotlib.legend", "matplotlib.grid", "matplotlib.savefig", "matplotlib.close", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.title", "matplotlib.legend", "matplotlib.grid", "matplotlib.ylim", "matplotlib.savefig", "matplotlib.close", "numpy.ones", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "plot", "(", "env_name", ",", "bc_log", ",", "gail_log", ",", "stochastic", ")", ":", "\n", "    ", "upper_bound", "=", "bc_log", "[", "'upper_bound'", "]", "\n", "bc_avg_ret", "=", "bc_log", "[", "'avg_ret'", "]", "\n", "gail_avg_ret", "=", "gail_log", "[", "'avg_ret'", "]", "\n", "plt", ".", "plot", "(", "CONFIG", "[", "'traj_limitation'", "]", ",", "upper_bound", ")", "\n", "plt", ".", "plot", "(", "CONFIG", "[", "'traj_limitation'", "]", ",", "bc_avg_ret", ")", "\n", "plt", ".", "plot", "(", "CONFIG", "[", "'traj_limitation'", "]", ",", "gail_avg_ret", ")", "\n", "plt", ".", "xlabel", "(", "'Number of expert trajectories'", ")", "\n", "plt", ".", "ylabel", "(", "'Accumulated reward'", ")", "\n", "plt", ".", "title", "(", "'{} unnormalized scores'", ".", "format", "(", "env_name", ")", ")", "\n", "plt", ".", "legend", "(", "[", "'expert'", ",", "'bc-imitator'", ",", "'gail-imitator'", "]", ",", "loc", "=", "'lower right'", ")", "\n", "plt", ".", "grid", "(", "b", "=", "True", ",", "which", "=", "'major'", ",", "color", "=", "'gray'", ",", "linestyle", "=", "'--'", ")", "\n", "if", "stochastic", ":", "\n", "        ", "title_name", "=", "'result/{}-unnormalized-stochastic-scores.png'", ".", "format", "(", "env_name", ")", "\n", "", "else", ":", "\n", "        ", "title_name", "=", "'result/{}-unnormalized-deterministic-scores.png'", ".", "format", "(", "env_name", ")", "\n", "", "plt", ".", "savefig", "(", "title_name", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "bc_normalized_ret", "=", "bc_log", "[", "'normalized_ret'", "]", "\n", "gail_normalized_ret", "=", "gail_log", "[", "'normalized_ret'", "]", "\n", "plt", ".", "plot", "(", "CONFIG", "[", "'traj_limitation'", "]", ",", "np", ".", "ones", "(", "len", "(", "CONFIG", "[", "'traj_limitation'", "]", ")", ")", ")", "\n", "plt", ".", "plot", "(", "CONFIG", "[", "'traj_limitation'", "]", ",", "bc_normalized_ret", ")", "\n", "plt", ".", "plot", "(", "CONFIG", "[", "'traj_limitation'", "]", ",", "gail_normalized_ret", ")", "\n", "plt", ".", "xlabel", "(", "'Number of expert trajectories'", ")", "\n", "plt", ".", "ylabel", "(", "'Normalized performance'", ")", "\n", "plt", ".", "title", "(", "'{} normalized scores'", ".", "format", "(", "env_name", ")", ")", "\n", "plt", ".", "legend", "(", "[", "'expert'", ",", "'bc-imitator'", ",", "'gail-imitator'", "]", ",", "loc", "=", "'lower right'", ")", "\n", "plt", ".", "grid", "(", "b", "=", "True", ",", "which", "=", "'major'", ",", "color", "=", "'gray'", ",", "linestyle", "=", "'--'", ")", "\n", "if", "stochastic", ":", "\n", "        ", "title_name", "=", "'result/{}-normalized-stochastic-scores.png'", ".", "format", "(", "env_name", ")", "\n", "", "else", ":", "\n", "        ", "title_name", "=", "'result/{}-normalized-deterministic-scores.png'", ".", "format", "(", "env_name", ")", "\n", "", "plt", ".", "ylim", "(", "0", ",", "1.6", ")", "\n", "plt", ".", "savefig", "(", "title_name", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.main": [[130, 143], ["baselines.common.tf_util.make_session().__enter__", "baselines.common.set_global_seeds", "print", "gail-eval.evaluate_env", "print", "print", "gail-eval.evaluate_env", "print", "print", "gail-eval.plot", "baselines.common.tf_util.make_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.evaluate_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.gail-eval.evaluate_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session"], ["", "def", "main", "(", "args", ")", ":", "\n", "    ", "U", ".", "make_session", "(", "num_cpu", "=", "1", ")", ".", "__enter__", "(", ")", "\n", "set_global_seeds", "(", "args", ".", "seed", ")", "\n", "print", "(", "'Evaluating {}'", ".", "format", "(", "args", ".", "env", ")", ")", "\n", "bc_log", "=", "evaluate_env", "(", "args", ".", "env", ",", "args", ".", "seed", ",", "args", ".", "policy_hidden_size", ",", "\n", "args", ".", "stochastic_policy", ",", "False", ",", "'BC'", ")", "\n", "print", "(", "'Evaluation for {}'", ".", "format", "(", "args", ".", "env", ")", ")", "\n", "print", "(", "bc_log", ")", "\n", "gail_log", "=", "evaluate_env", "(", "args", ".", "env", ",", "args", ".", "seed", ",", "args", ".", "policy_hidden_size", ",", "\n", "args", ".", "stochastic_policy", ",", "True", ",", "'gail'", ")", "\n", "print", "(", "'Evaluation for {}'", ".", "format", "(", "args", ".", "env", ")", ")", "\n", "print", "(", "gail_log", ")", "\n", "plot", "(", "args", ".", "env", ",", "bc_log", ",", "gail_log", ",", "args", ".", "stochastic_policy", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.argsparser": [[23, 56], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "baselines.common.misc_util.boolean_flag", "baselines.common.misc_util.boolean_flag", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "baselines.common.misc_util.boolean_flag", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.boolean_flag", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.boolean_flag", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.boolean_flag"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "mujoco_arg_parser", "(", ")", ".", "parse_args", "(", ")", "\n", "logger", ".", "configure", "(", ")", "\n", "train", "(", "args", ".", "env", ",", "num_timesteps", "=", "args", ".", "num_timesteps", ",", "seed", "=", "args", ".", "seed", ")", "\n", "\n", "", "if", "__name__", "==", "'__main__'", ":", "\n", "    ", "main", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.get_task_name": [[58, 69], ["args.env_id.split", "str", "str", "str", "str", "str"], "function", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.main": [[71, 119], ["baselines.common.tf_util.make_session().__enter__", "baselines.common.set_global_seeds", "gym.make", "baselines.bench.Monitor", "bench.Monitor.seed", "gym.logger.setLevel", "run_mujoco.get_task_name", "os.join", "os.join", "bench.Monitor.close", "baselines.gail.mlp_policy.MlpPolicy", "baselines.gail.dataset.mujoco_dset.Mujoco_Dset", "baselines.gail.adversary.TransitionClassifier", "run_mujoco.train", "baselines.common.tf_util.make_session", "baselines.logger.get_dir", "os.join", "run_mujoco.runner", "baselines.logger.get_dir"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.get_task_name", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.runner", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.train": [[121, 155], ["behavior_clone.learn", "mpi4py.MPI.COMM_WORLD.Get_rank", "baselines.common.set_global_seeds", "env.seed", "trpo_mpi.learn", "baselines.logger.set_level", "mpi4py.MPI.COMM_WORLD.Get_rank"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.set_level"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.runner": [[157, 194], ["policy_func", "baselines.common.tf_util.initialize", "baselines.common.tf_util.load_variables", "tqdm.tqdm", "print", "print", "range", "run_mujoco.traj_1_generator", "obs_list.append", "acs_list.append", "len_list.append", "ret_list.append", "print", "print", "numpy.savez", "sum", "len", "sum", "len", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "load_model_path.split"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.traj_1_generator", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.run_mujoco.traj_1_generator": [[197, 235], ["env.action_space.sample", "env.reset", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "pi.act", "np.array.append", "np.array.append", "np.array.append", "env.step", "np.array.append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.act", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.traj_segment_generator": [[23, 89], ["env.action_space.sample", "env.reset", "numpy.array", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.zeros", "numpy.array", "np.array.copy", "pi.act", "reward_giver.get_reward", "env.step", "pi.act", "ep_rets.append", "ep_true_rets.append", "ep_lens.append", "env.reset", "range", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.act", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.mlp_policy.MlpPolicy.act", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["ac", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "new", "=", "True", "\n", "rew", "=", "0.0", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "\n", "cur_ep_ret", "=", "0", "\n", "cur_ep_len", "=", "0", "\n", "ep_rets", "=", "[", "]", "\n", "ep_lens", "=", "[", "]", "\n", "\n", "# Initialize history arrays", "\n", "obs", "=", "np", ".", "array", "(", "[", "ob", "for", "_", "in", "range", "(", "horizon", ")", "]", ")", "\n", "rews", "=", "np", ".", "zeros", "(", "horizon", ",", "'float32'", ")", "\n", "vpreds", "=", "np", ".", "zeros", "(", "horizon", ",", "'float32'", ")", "\n", "news", "=", "np", ".", "zeros", "(", "horizon", ",", "'int32'", ")", "\n", "acs", "=", "np", ".", "array", "(", "[", "ac", "for", "_", "in", "range", "(", "horizon", ")", "]", ")", "\n", "prevacs", "=", "acs", ".", "copy", "(", ")", "\n", "\n", "while", "True", ":", "\n", "        ", "prevac", "=", "ac", "\n", "ac", ",", "vpred", ",", "_", ",", "_", "=", "pi", ".", "step", "(", "ob", ",", "stochastic", "=", "stochastic", ")", "\n", "# Slight weirdness here because we need value function at time T", "\n", "# before returning segment [0, T-1] so we get the correct", "\n", "# terminal value", "\n", "if", "t", ">", "0", "and", "t", "%", "horizon", "==", "0", ":", "\n", "            ", "yield", "{", "\"ob\"", ":", "obs", ",", "\"rew\"", ":", "rews", ",", "\"vpred\"", ":", "vpreds", ",", "\"new\"", ":", "news", ",", "\n", "\"ac\"", ":", "acs", ",", "\"prevac\"", ":", "prevacs", ",", "\"nextvpred\"", ":", "vpred", "*", "(", "1", "-", "new", ")", ",", "\n", "\"ep_rets\"", ":", "ep_rets", ",", "\"ep_lens\"", ":", "ep_lens", "}", "\n", "_", ",", "vpred", ",", "_", ",", "_", "=", "pi", ".", "step", "(", "ob", ",", "stochastic", "=", "stochastic", ")", "\n", "# Be careful!!! if you change the downstream algorithm to aggregate", "\n", "# several of these batches, then be sure to do a deepcopy", "\n", "ep_rets", "=", "[", "]", "\n", "ep_lens", "=", "[", "]", "\n", "", "i", "=", "t", "%", "horizon", "\n", "obs", "[", "i", "]", "=", "ob", "\n", "vpreds", "[", "i", "]", "=", "vpred", "\n", "news", "[", "i", "]", "=", "new", "\n", "acs", "[", "i", "]", "=", "ac", "\n", "prevacs", "[", "i", "]", "=", "prevac", "\n", "\n", "ob", ",", "rew", ",", "new", ",", "_", "=", "env", ".", "step", "(", "ac", ")", "\n", "rews", "[", "i", "]", "=", "rew", "\n", "\n", "cur_ep_ret", "+=", "rew", "\n", "cur_ep_len", "+=", "1", "\n", "if", "new", ":", "\n", "            ", "ep_rets", ".", "append", "(", "cur_ep_ret", ")", "\n", "ep_lens", ".", "append", "(", "cur_ep_len", ")", "\n", "cur_ep_ret", "=", "0", "\n", "cur_ep_len", "=", "0", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "", "t", "+=", "1", "\n", "\n", "", "", "def", "add_vtarg_and_adv", "(", "seg", ",", "gamma", ",", "lam", ")", ":", "\n", "    ", "new", "=", "np", ".", "append", "(", "seg", "[", "\"new\"", "]", ",", "0", ")", "# last element is only used for last vtarg, but we already zeroed it if last new = 1", "\n", "vpred", "=", "np", ".", "append", "(", "seg", "[", "\"vpred\"", "]", ",", "seg", "[", "\"nextvpred\"", "]", ")", "\n", "T", "=", "len", "(", "seg", "[", "\"rew\"", "]", ")", "\n", "seg", "[", "\"adv\"", "]", "=", "gaelam", "=", "np", ".", "empty", "(", "T", ",", "'float32'", ")", "\n", "rew", "=", "seg", "[", "\"rew\"", "]", "\n", "lastgaelam", "=", "0", "\n", "for", "t", "in", "reversed", "(", "range", "(", "T", ")", ")", ":", "\n", "        ", "nonterminal", "=", "1", "-", "new", "[", "t", "+", "1", "]", "\n", "delta", "=", "rew", "[", "t", "]", "+", "gamma", "*", "vpred", "[", "t", "+", "1", "]", "*", "nonterminal", "-", "vpred", "[", "t", "]", "\n", "gaelam", "[", "t", "]", "=", "lastgaelam", "=", "delta", "+", "gamma", "*", "lam", "*", "nonterminal", "*", "lastgaelam", "\n", "", "seg", "[", "\"tdlamret\"", "]", "=", "seg", "[", "\"adv\"", "]", "+", "seg", "[", "\"vpred\"", "]", "\n", "\n", "", "def", "learn", "(", "*", ",", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.add_vtarg_and_adv": [[91, 103], ["numpy.append", "numpy.append", "len", "numpy.empty", "reversed", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["env", ",", "\n", "total_timesteps", ",", "\n", "timesteps_per_batch", "=", "1024", ",", "# what to train on", "\n", "max_kl", "=", "0.001", ",", "\n", "cg_iters", "=", "10", ",", "\n", "gamma", "=", "0.99", ",", "\n", "lam", "=", "1.0", ",", "# advantage estimation", "\n", "seed", "=", "None", ",", "\n", "ent_coef", "=", "0.0", ",", "\n", "cg_damping", "=", "1e-2", ",", "\n", "vf_stepsize", "=", "3e-4", ",", "\n", "vf_iters", "=", "3", ",", "\n", "max_episodes", "=", "0", ",", "max_iters", "=", "0", ",", "# time constraint", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.learn": [[105, 351], ["mpi4py.MPI.COMM_WORLD.Get_size", "mpi4py.MPI.COMM_WORLD.Get_rank", "numpy.set_printoptions", "policy_func", "policy_func", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.get_placeholder_cached", "policy_func.pdtype.sample_placeholder", "policy_func.pd.kl", "policy_func.pd.entropy", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.exp", "tensorflow.reduce_mean", "policy_func.get_trainable_variables", "baselines.common.mpi_adam.MpiAdam", "baselines.common.mpi_adam.MpiAdam", "baselines.GetFlat", "baselines.SetFromFlat", "tensorflow.gradients", "tensorflow.placeholder", "tensorflow.add_n", "baselines.flatgrad", "baselines.function", "baselines.function", "baselines.function", "baselines.function", "baselines.function", "baselines.initialize", "U.GetFlat.", "mpi4py.MPI.COMM_WORLD.Bcast", "U.SetFromFlat.", "baselines.common.mpi_adam.MpiAdam.sync", "baselines.common.mpi_adam.MpiAdam.sync", "trpo_mpi.traj_segment_generator", "time.time", "collections.deque", "collections.deque", "collections.deque", "baselines.gail.statistics.stats", "baselines.gail.statistics.stats", "baselines.gail.statistics.stats", "tensorflow.square", "len", "reward_giver.get_trainable_variables", "var.get_shape().as_list", "baselines.intprod", "tangents.append", "baselines.flatgrad", "isinstance", "numpy.empty_like", "mpi4py.MPI.COMM_WORLD.Allreduce", "print", "sum", "baselines.load_state", "baselines.logger.log", "baselines.logger.log", "range", "zip", "baselines.logger.record_tabular", "baselines.logger.log", "baselines.logger.log", "expert_dataset.get_next_batch", "baselines.common.dataset.iterbatches", "baselines.logger.log", "mpi4py.MPI.COMM_WORLD.allgather", "map", "collections.deque.extend", "collections.deque.extend", "collections.deque.extend", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "len", "sum", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "baselines.logger.record_tabular", "policy_func.pd.logp", "policy_func.pd.logp", "v.name.startswith", "len", "tensorflow.reshape", "tensorflow.reduce_sum", "print", "time.time", "print", "get_flat.sum", "callback", "os.path.join", "os.makedirs", "tensorflow.train.Saver", "tf.train.Saver.save", "trpo_mpi.add_vtarg_and_adv", "hasattr", "U.function.", "trpo_mpi.learn.allmean"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder_cached", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.kl", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.traj_segment_generator", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.adversary.TransitionClassifier.get_trainable_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.get_next_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.iterbatches", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.logp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.logp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_cartpole.callback", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.add_vtarg_and_adv"], ["load_path", "=", "None", ",", "\n", "**", "network_kwargs", "\n", ")", ":", "\n", "    ", "'''\n    learn a policy function with TRPO algorithm\n\n    Parameters:\n    ----------\n\n    network                 neural network to learn. Can be either string ('mlp', 'cnn', 'lstm', 'lnlstm' for basic types)\n                            or function that takes input placeholder and returns tuple (output, None) for feedforward nets\n                            or (output, (state_placeholder, state_output, mask_placeholder)) for recurrent nets\n\n    env                     environment (one of the gym environments or wrapped via baselines.common.vec_env.VecEnv-type class\n\n    timesteps_per_batch     timesteps per gradient estimation batch\n\n    max_kl                  max KL divergence between old policy and new policy ( KL(pi_old || pi) )\n\n    ent_coef                coefficient of policy entropy term in the optimization objective\n\n    cg_iters                number of iterations of conjugate gradient algorithm\n\n    cg_damping              conjugate gradient damping\n\n    vf_stepsize             learning rate for adam optimizer used to optimie value function loss\n\n    vf_iters                number of iterations of value function optimization iterations per each policy optimization step\n\n    total_timesteps           max number of timesteps\n\n    max_episodes            max number of episodes\n\n    max_iters               maximum number of policy optimization iterations\n\n    callback                function to be called with (locals(), globals()) each policy optimization step\n\n    load_path               str, path to load the model from (default: None, i.e. no model is loaded)\n\n    **network_kwargs        keyword arguments to the policy / network builder. See baselines.common/policies.py/build_policy and arguments to a particular type of network\n\n    Returns:\n    -------\n\n    learnt model\n\n    '''", "\n", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "        ", "nworkers", "=", "MPI", ".", "COMM_WORLD", ".", "Get_size", "(", ")", "\n", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "", "else", ":", "\n", "        ", "nworkers", "=", "1", "\n", "rank", "=", "0", "\n", "\n", "", "cpus_per_worker", "=", "1", "\n", "U", ".", "get_session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "\n", "inter_op_parallelism_threads", "=", "cpus_per_worker", ",", "\n", "intra_op_parallelism_threads", "=", "cpus_per_worker", "\n", ")", ")", "\n", "\n", "\n", "policy", "=", "build_policy", "(", "env", ",", "network", ",", "value_network", "=", "'copy'", ",", "**", "network_kwargs", ")", "\n", "set_global_seeds", "(", "seed", ")", "\n", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "3", ")", "\n", "# Setup losses and stuff", "\n", "# ----------------------------------------", "\n", "ob_space", "=", "env", ".", "observation_space", "\n", "ac_space", "=", "env", ".", "action_space", "\n", "\n", "ob", "=", "observation_placeholder", "(", "ob_space", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"pi\"", ")", ":", "\n", "        ", "pi", "=", "policy", "(", "observ_placeholder", "=", "ob", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"oldpi\"", ")", ":", "\n", "        ", "oldpi", "=", "policy", "(", "observ_placeholder", "=", "ob", ")", "\n", "\n", "", "atarg", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ")", "# Target advantage function (if applicable)", "\n", "ret", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ")", "# Empirical return", "\n", "\n", "ac", "=", "pi", ".", "pdtype", ".", "sample_placeholder", "(", "[", "None", "]", ")", "\n", "\n", "kloldnew", "=", "oldpi", ".", "pd", ".", "kl", "(", "pi", ".", "pd", ")", "\n", "ent", "=", "pi", ".", "pd", ".", "entropy", "(", ")", "\n", "meankl", "=", "tf", ".", "reduce_mean", "(", "kloldnew", ")", "\n", "meanent", "=", "tf", ".", "reduce_mean", "(", "ent", ")", "\n", "entbonus", "=", "ent_coef", "*", "meanent", "\n", "\n", "vferr", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "square", "(", "pi", ".", "vf", "-", "ret", ")", ")", "\n", "\n", "ratio", "=", "tf", ".", "exp", "(", "pi", ".", "pd", ".", "logp", "(", "ac", ")", "-", "oldpi", ".", "pd", ".", "logp", "(", "ac", ")", ")", "# advantage * pnew / pold", "\n", "surrgain", "=", "tf", ".", "reduce_mean", "(", "ratio", "*", "atarg", ")", "\n", "\n", "optimgain", "=", "surrgain", "+", "entbonus", "\n", "losses", "=", "[", "optimgain", ",", "meankl", ",", "entbonus", ",", "surrgain", ",", "meanent", "]", "\n", "loss_names", "=", "[", "\"optimgain\"", ",", "\"meankl\"", ",", "\"entloss\"", ",", "\"surrgain\"", ",", "\"entropy\"", "]", "\n", "\n", "dist", "=", "meankl", "\n", "\n", "all_var_list", "=", "get_trainable_variables", "(", "\"pi\"", ")", "\n", "# var_list = [v for v in all_var_list if v.name.split(\"/\")[1].startswith(\"pol\")]", "\n", "# vf_var_list = [v for v in all_var_list if v.name.split(\"/\")[1].startswith(\"vf\")]", "\n", "var_list", "=", "get_pi_trainable_variables", "(", "\"pi\"", ")", "\n", "vf_var_list", "=", "get_vf_trainable_variables", "(", "\"pi\"", ")", "\n", "\n", "vfadam", "=", "MpiAdam", "(", "vf_var_list", ")", "\n", "\n", "get_flat", "=", "U", ".", "GetFlat", "(", "var_list", ")", "\n", "set_from_flat", "=", "U", ".", "SetFromFlat", "(", "var_list", ")", "\n", "klgrads", "=", "tf", ".", "gradients", "(", "dist", ",", "var_list", ")", "\n", "flat_tangent", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "\"flat_tan\"", ")", "\n", "shapes", "=", "[", "var", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "for", "var", "in", "var_list", "]", "\n", "start", "=", "0", "\n", "tangents", "=", "[", "]", "\n", "for", "shape", "in", "shapes", ":", "\n", "        ", "sz", "=", "U", ".", "intprod", "(", "shape", ")", "\n", "tangents", ".", "append", "(", "tf", ".", "reshape", "(", "flat_tangent", "[", "start", ":", "start", "+", "sz", "]", ",", "shape", ")", ")", "\n", "start", "+=", "sz", "\n", "", "gvp", "=", "tf", ".", "add_n", "(", "[", "tf", ".", "reduce_sum", "(", "g", "*", "tangent", ")", "for", "(", "g", ",", "tangent", ")", "in", "zipsame", "(", "klgrads", ",", "tangents", ")", "]", ")", "#pylint: disable=E1111", "\n", "fvp", "=", "U", ".", "flatgrad", "(", "gvp", ",", "var_list", ")", "\n", "\n", "assign_old_eq_new", "=", "U", ".", "function", "(", "[", "]", ",", "[", "]", ",", "updates", "=", "[", "tf", ".", "assign", "(", "oldv", ",", "newv", ")", "\n", "for", "(", "oldv", ",", "newv", ")", "in", "zipsame", "(", "get_variables", "(", "\"oldpi\"", ")", ",", "get_variables", "(", "\"pi\"", ")", ")", "]", ")", "\n", "\n", "compute_losses", "=", "U", ".", "function", "(", "[", "ob", ",", "ac", ",", "atarg", "]", ",", "losses", ")", "\n", "compute_lossandgrad", "=", "U", ".", "function", "(", "[", "ob", ",", "ac", ",", "atarg", "]", ",", "losses", "+", "[", "U", ".", "flatgrad", "(", "optimgain", ",", "var_list", ")", "]", ")", "\n", "compute_fvp", "=", "U", ".", "function", "(", "[", "flat_tangent", ",", "ob", ",", "ac", ",", "atarg", "]", ",", "fvp", ")", "\n", "compute_vflossandgrad", "=", "U", ".", "function", "(", "[", "ob", ",", "ret", "]", ",", "U", ".", "flatgrad", "(", "vferr", ",", "vf_var_list", ")", ")", "\n", "\n", "@", "contextmanager", "\n", "def", "timed", "(", "msg", ")", ":", "\n", "        ", "if", "rank", "==", "0", ":", "\n", "            ", "print", "(", "colorize", "(", "msg", ",", "color", "=", "'magenta'", ")", ")", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "yield", "\n", "print", "(", "colorize", "(", "\"done in %.3f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "tstart", ")", ",", "color", "=", "'magenta'", ")", ")", "\n", "", "else", ":", "\n", "            ", "yield", "\n", "\n", "", "", "def", "allmean", "(", "x", ")", ":", "\n", "        ", "assert", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "            ", "out", "=", "np", ".", "empty_like", "(", "x", ")", "\n", "MPI", ".", "COMM_WORLD", ".", "Allreduce", "(", "x", ",", "out", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "out", "/=", "nworkers", "\n", "", "else", ":", "\n", "            ", "out", "=", "np", ".", "copy", "(", "x", ")", "\n", "\n", "", "return", "out", "\n", "\n", "", "U", ".", "initialize", "(", ")", "\n", "if", "load_path", "is", "not", "None", ":", "\n", "        ", "pi", ".", "load", "(", "load_path", ")", "\n", "\n", "", "th_init", "=", "get_flat", "(", ")", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "        ", "MPI", ".", "COMM_WORLD", ".", "Bcast", "(", "th_init", ",", "root", "=", "0", ")", "\n", "\n", "", "set_from_flat", "(", "th_init", ")", "\n", "vfadam", ".", "sync", "(", ")", "\n", "print", "(", "\"Init param sum\"", ",", "th_init", ".", "sum", "(", ")", ",", "flush", "=", "True", ")", "\n", "\n", "# Prepare for rollouts", "\n", "# ----------------------------------------", "\n", "seg_gen", "=", "traj_segment_generator", "(", "pi", ",", "env", ",", "timesteps_per_batch", ",", "stochastic", "=", "True", ")", "\n", "\n", "episodes_so_far", "=", "0", "\n", "timesteps_so_far", "=", "0", "\n", "iters_so_far", "=", "0", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "lenbuffer", "=", "deque", "(", "maxlen", "=", "40", ")", "# rolling buffer for episode lengths", "\n", "rewbuffer", "=", "deque", "(", "maxlen", "=", "40", ")", "# rolling buffer for episode rewards", "\n", "\n", "if", "sum", "(", "[", "max_iters", ">", "0", ",", "total_timesteps", ">", "0", ",", "max_episodes", ">", "0", "]", ")", "==", "0", ":", "\n", "# noththing to be done", "\n", "        ", "return", "pi", "\n", "\n", "", "assert", "sum", "(", "[", "max_iters", ">", "0", ",", "total_timesteps", ">", "0", ",", "max_episodes", ">", "0", "]", ")", "<", "2", ",", "'out of max_iters, total_timesteps, and max_episodes only one should be specified'", "\n", "\n", "while", "True", ":", "\n", "        ", "if", "callback", ":", "callback", "(", "locals", "(", ")", ",", "globals", "(", ")", ")", "\n", "if", "total_timesteps", "and", "timesteps_so_far", ">=", "total_timesteps", ":", "\n", "            ", "break", "\n", "", "elif", "max_episodes", "and", "episodes_so_far", ">=", "max_episodes", ":", "\n", "            ", "break", "\n", "", "elif", "max_iters", "and", "iters_so_far", ">=", "max_iters", ":", "\n", "            ", "break", "\n", "", "logger", ".", "log", "(", "\"********** Iteration %i ************\"", "%", "iters_so_far", ")", "\n", "\n", "with", "timed", "(", "\"sampling\"", ")", ":", "\n", "            ", "seg", "=", "seg_gen", ".", "__next__", "(", ")", "\n", "", "add_vtarg_and_adv", "(", "seg", ",", "gamma", ",", "lam", ")", "\n", "\n", "# ob, ac, atarg, ret, td1ret = map(np.concatenate, (obs, acs, atargs, rets, td1rets))", "\n", "ob", ",", "ac", ",", "atarg", ",", "tdlamret", "=", "seg", "[", "\"ob\"", "]", ",", "seg", "[", "\"ac\"", "]", ",", "seg", "[", "\"adv\"", "]", ",", "seg", "[", "\"tdlamret\"", "]", "\n", "vpredbefore", "=", "seg", "[", "\"vpred\"", "]", "# predicted value function before udpate", "\n", "atarg", "=", "(", "atarg", "-", "atarg", ".", "mean", "(", ")", ")", "/", "atarg", ".", "std", "(", ")", "# standardized advantage function estimate", "\n", "\n", "if", "hasattr", "(", "pi", ",", "\"ret_rms\"", ")", ":", "pi", ".", "ret_rms", ".", "update", "(", "tdlamret", ")", "\n", "if", "hasattr", "(", "pi", ",", "\"ob_rms\"", ")", ":", "pi", ".", "ob_rms", ".", "update", "(", "ob", ")", "# update running mean/std for policy", "\n", "\n", "args", "=", "seg", "[", "\"ob\"", "]", ",", "seg", "[", "\"ac\"", "]", ",", "atarg", "\n", "fvpargs", "=", "[", "arr", "[", ":", ":", "5", "]", "for", "arr", "in", "args", "]", "\n", "def", "fisher_vector_product", "(", "p", ")", ":", "\n", "            ", "return", "allmean", "(", "compute_fvp", "(", "p", ",", "*", "fvpargs", ")", ")", "+", "cg_damping", "*", "p", "\n", "\n", "", "assign_old_eq_new", "(", ")", "# set old parameter values to new parameter values", "\n", "with", "timed", "(", "\"computegrad\"", ")", ":", "\n", "            ", "*", "lossbefore", ",", "g", "=", "compute_lossandgrad", "(", "*", "args", ")", "\n", "", "lossbefore", "=", "allmean", "(", "np", ".", "array", "(", "lossbefore", ")", ")", "\n", "g", "=", "allmean", "(", "g", ")", "\n", "if", "np", ".", "allclose", "(", "g", ",", "0", ")", ":", "\n", "            ", "logger", ".", "log", "(", "\"Got zero gradient. not updating\"", ")", "\n", "", "else", ":", "\n", "            ", "with", "timed", "(", "\"cg\"", ")", ":", "\n", "                ", "stepdir", "=", "cg", "(", "fisher_vector_product", ",", "g", ",", "cg_iters", "=", "cg_iters", ",", "verbose", "=", "rank", "==", "0", ")", "\n", "", "assert", "np", ".", "isfinite", "(", "stepdir", ")", ".", "all", "(", ")", "\n", "shs", "=", ".5", "*", "stepdir", ".", "dot", "(", "fisher_vector_product", "(", "stepdir", ")", ")", "\n", "lm", "=", "np", ".", "sqrt", "(", "shs", "/", "max_kl", ")", "\n", "# logger.log(\"lagrange multiplier:\", lm, \"gnorm:\", np.linalg.norm(g))", "\n", "fullstep", "=", "stepdir", "/", "lm", "\n", "expectedimprove", "=", "g", ".", "dot", "(", "fullstep", ")", "\n", "surrbefore", "=", "lossbefore", "[", "0", "]", "\n", "stepsize", "=", "1.0", "\n", "thbefore", "=", "get_flat", "(", ")", "\n", "for", "_", "in", "range", "(", "10", ")", ":", "\n", "                ", "thnew", "=", "thbefore", "+", "fullstep", "*", "stepsize", "\n", "set_from_flat", "(", "thnew", ")", "\n", "meanlosses", "=", "surr", ",", "kl", ",", "*", "_", "=", "allmean", "(", "np", ".", "array", "(", "compute_losses", "(", "*", "args", ")", ")", ")", "\n", "improve", "=", "surr", "-", "surrbefore", "\n", "logger", ".", "log", "(", "\"Expected: %.3f Actual: %.3f\"", "%", "(", "expectedimprove", ",", "improve", ")", ")", "\n", "if", "not", "np", ".", "isfinite", "(", "meanlosses", ")", ".", "all", "(", ")", ":", "\n", "                    ", "logger", ".", "log", "(", "\"Got non-finite value of losses -- bad!\"", ")", "\n", "", "elif", "kl", ">", "max_kl", "*", "1.5", ":", "\n", "                    ", "logger", ".", "log", "(", "\"violated KL constraint. shrinking step.\"", ")", "\n", "", "elif", "improve", "<", "0", ":", "\n", "                    ", "logger", ".", "log", "(", "\"surrogate didn't improve. shrinking step.\"", ")", "\n", "", "else", ":", "\n", "                    ", "logger", ".", "log", "(", "\"Stepsize OK!\"", ")", "\n", "break", "\n", "", "stepsize", "*=", ".5", "\n", "", "else", ":", "\n", "                ", "logger", ".", "log", "(", "\"couldn't compute a good step\"", ")", "\n", "set_from_flat", "(", "thbefore", ")", "\n", "", "if", "nworkers", ">", "1", "and", "iters_so_far", "%", "20", "==", "0", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.gail.trpo_mpi.flatten_lists": [[353, 355], ["None"], "function", ["None"], ["assert", "all", "(", "np", ".", "allclose", "(", "ps", ",", "paramsums", "[", "0", "]", ")", "for", "ps", "in", "paramsums", "[", "1", ":", "]", ")", "\n", "\n", "", "", "for", "(", "lossname", ",", "lossval", ")", "in", "zip", "(", "loss_names", ",", "meanlosses", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Dset.__init__": [[13, 20], ["len", "mujoco_dset.Dset.init_pointer", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Dset.init_pointer"], ["    ", "def", "__init__", "(", "self", ",", "inputs", ",", "labels", ",", "randomize", ")", ":", "\n", "        ", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "labels", "=", "labels", "\n", "assert", "len", "(", "self", ".", "inputs", ")", "==", "len", "(", "self", ".", "labels", ")", "\n", "self", ".", "randomize", "=", "randomize", "\n", "self", ".", "num_pairs", "=", "len", "(", "inputs", ")", "\n", "self", ".", "init_pointer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Dset.init_pointer": [[21, 28], ["numpy.arange", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle"], ["", "def", "init_pointer", "(", "self", ")", ":", "\n", "        ", "self", ".", "pointer", "=", "0", "\n", "if", "self", ".", "randomize", ":", "\n", "            ", "idx", "=", "np", ".", "arange", "(", "self", ".", "num_pairs", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "idx", ")", "\n", "self", ".", "inputs", "=", "self", ".", "inputs", "[", "idx", ",", ":", "]", "\n", "self", ".", "labels", "=", "self", ".", "labels", "[", "idx", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Dset.get_next_batch": [[29, 40], ["mujoco_dset.Dset.init_pointer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Dset.init_pointer"], ["", "", "def", "get_next_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "# if batch_size is negative -> return all", "\n", "        ", "if", "batch_size", "<", "0", ":", "\n", "            ", "return", "self", ".", "inputs", ",", "self", ".", "labels", "\n", "", "if", "self", ".", "pointer", "+", "batch_size", ">=", "self", ".", "num_pairs", ":", "\n", "            ", "self", ".", "init_pointer", "(", ")", "\n", "", "end", "=", "self", ".", "pointer", "+", "batch_size", "\n", "inputs", "=", "self", ".", "inputs", "[", "self", ".", "pointer", ":", "end", ",", ":", "]", "\n", "labels", "=", "self", ".", "labels", "[", "self", ".", "pointer", ":", "end", ",", ":", "]", "\n", "self", ".", "pointer", "=", "end", "\n", "return", "inputs", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.__init__": [[43, 78], ["numpy.load", "numpy.std", "min", "len", "mujoco_dset.Dset", "mujoco_dset.Dset", "mujoco_dset.Dset", "mujoco_dset.Mujoco_Dset.log_info", "len", "len", "numpy.reshape", "numpy.reshape", "numpy.vstack", "numpy.vstack", "sum", "len", "numpy.array", "len", "numpy.squeeze", "len", "len", "len", "numpy.prod", "numpy.prod", "int", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.log_info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["    ", "def", "__init__", "(", "self", ",", "expert_path", ",", "train_fraction", "=", "0.7", ",", "traj_limitation", "=", "-", "1", ",", "randomize", "=", "True", ")", ":", "\n", "        ", "traj_data", "=", "np", ".", "load", "(", "expert_path", ")", "\n", "if", "traj_limitation", "<", "0", ":", "\n", "            ", "traj_limitation", "=", "len", "(", "traj_data", "[", "'obs'", "]", ")", "\n", "", "obs", "=", "traj_data", "[", "'obs'", "]", "[", ":", "traj_limitation", "]", "\n", "acs", "=", "traj_data", "[", "'acs'", "]", "[", ":", "traj_limitation", "]", "\n", "\n", "# obs, acs: shape (N, L, ) + S where N = # episodes, L = episode length", "\n", "# and S is the environment observation/action space.", "\n", "# Flatten to (N * L, prod(S))", "\n", "if", "len", "(", "obs", ".", "shape", ")", ">", "2", ":", "\n", "            ", "self", ".", "obs", "=", "np", ".", "reshape", "(", "obs", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "obs", ".", "shape", "[", "2", ":", "]", ")", "]", ")", "\n", "self", ".", "acs", "=", "np", ".", "reshape", "(", "acs", ",", "[", "-", "1", ",", "np", ".", "prod", "(", "acs", ".", "shape", "[", "2", ":", "]", ")", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "obs", "=", "np", ".", "vstack", "(", "obs", ")", "\n", "self", ".", "acs", "=", "np", ".", "vstack", "(", "acs", ")", "\n", "\n", "", "self", ".", "rets", "=", "traj_data", "[", "'ep_rets'", "]", "[", ":", "traj_limitation", "]", "\n", "self", ".", "avg_ret", "=", "sum", "(", "self", ".", "rets", ")", "/", "len", "(", "self", ".", "rets", ")", "\n", "self", ".", "std_ret", "=", "np", ".", "std", "(", "np", ".", "array", "(", "self", ".", "rets", ")", ")", "\n", "if", "len", "(", "self", ".", "acs", ")", ">", "2", ":", "\n", "            ", "self", ".", "acs", "=", "np", ".", "squeeze", "(", "self", ".", "acs", ")", "\n", "", "assert", "len", "(", "self", ".", "obs", ")", "==", "len", "(", "self", ".", "acs", ")", "\n", "self", ".", "num_traj", "=", "min", "(", "traj_limitation", ",", "len", "(", "traj_data", "[", "'obs'", "]", ")", ")", "\n", "self", ".", "num_transition", "=", "len", "(", "self", ".", "obs", ")", "\n", "self", ".", "randomize", "=", "randomize", "\n", "self", ".", "dset", "=", "Dset", "(", "self", ".", "obs", ",", "self", ".", "acs", ",", "self", ".", "randomize", ")", "\n", "# for behavior cloning", "\n", "self", ".", "train_set", "=", "Dset", "(", "self", ".", "obs", "[", ":", "int", "(", "self", ".", "num_transition", "*", "train_fraction", ")", ",", ":", "]", ",", "\n", "self", ".", "acs", "[", ":", "int", "(", "self", ".", "num_transition", "*", "train_fraction", ")", ",", ":", "]", ",", "\n", "self", ".", "randomize", ")", "\n", "self", ".", "val_set", "=", "Dset", "(", "self", ".", "obs", "[", "int", "(", "self", ".", "num_transition", "*", "train_fraction", ")", ":", ",", ":", "]", ",", "\n", "self", ".", "acs", "[", "int", "(", "self", ".", "num_transition", "*", "train_fraction", ")", ":", ",", ":", "]", ",", "\n", "self", ".", "randomize", ")", "\n", "self", ".", "log_info", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.log_info": [[79, 84], ["baselines.logger.log", "baselines.logger.log", "baselines.logger.log", "baselines.logger.log"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "log_info", "(", "self", ")", ":", "\n", "        ", "logger", ".", "log", "(", "\"Total trajectories: %d\"", "%", "self", ".", "num_traj", ")", "\n", "logger", ".", "log", "(", "\"Total transitions: %d\"", "%", "self", ".", "num_transition", ")", "\n", "logger", ".", "log", "(", "\"Average returns: %f\"", "%", "self", ".", "avg_ret", ")", "\n", "logger", ".", "log", "(", "\"Std for returns: %f\"", "%", "self", ".", "std_ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.get_next_batch": [[85, 94], ["mujoco_dset.Mujoco_Dset.dset.get_next_batch", "mujoco_dset.Mujoco_Dset.train_set.get_next_batch", "mujoco_dset.Mujoco_Dset.val_set.get_next_batch"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.get_next_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.get_next_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.get_next_batch"], ["", "def", "get_next_batch", "(", "self", ",", "batch_size", ",", "split", "=", "None", ")", ":", "\n", "        ", "if", "split", "is", "None", ":", "\n", "            ", "return", "self", ".", "dset", ".", "get_next_batch", "(", "batch_size", ")", "\n", "", "elif", "split", "==", "'train'", ":", "\n", "            ", "return", "self", ".", "train_set", ".", "get_next_batch", "(", "batch_size", ")", "\n", "", "elif", "split", "==", "'val'", ":", "\n", "            ", "return", "self", ".", "val_set", ".", "get_next_batch", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.Mujoco_Dset.plot": [[95, 100], ["plt.hist", "plt.savefig", "plt.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "", "def", "plot", "(", "self", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "plt", ".", "hist", "(", "self", ".", "rets", ")", "\n", "plt", ".", "savefig", "(", "\"histogram_rets.png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.dataset.mujoco_dset.test": [[102, 106], ["mujoco_dset.Mujoco_Dset", "mujoco_dset.Mujoco_Dset.plot"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot"], ["", "", "def", "test", "(", "expert_path", ",", "traj_limitation", ",", "plot", ")", ":", "\n", "    ", "dset", "=", "Mujoco_Dset", "(", "expert_path", ",", "traj_limitation", "=", "traj_limitation", ")", "\n", "if", "plot", ":", "\n", "        ", "dset", ".", "plot", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.wrappers.TimeLimit.__init__": [[4, 8], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "max_episode_steps", "=", "None", ")", ":", "\n", "        ", "super", "(", "TimeLimit", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "_max_episode_steps", "=", "max_episode_steps", "\n", "self", ".", "_elapsed_steps", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.wrappers.TimeLimit.step": [[9, 16], ["wrappers.TimeLimit.env.step"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "observation", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "ac", ")", "\n", "self", ".", "_elapsed_steps", "+=", "1", "\n", "if", "self", ".", "_elapsed_steps", ">=", "self", ".", "_max_episode_steps", ":", "\n", "            ", "done", "=", "True", "\n", "info", "[", "'TimeLimit.truncated'", "]", "=", "True", "\n", "", "return", "observation", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.wrappers.TimeLimit.reset": [[17, 20], ["wrappers.TimeLimit.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_elapsed_steps", "=", "0", "\n", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.wrappers.ClipActionsWrapper.step": [[22, 27], ["np.nan_to_num", "np.clip", "wrappers.ClipActionsWrapper.env.step"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["    ", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "action", "=", "np", ".", "nan_to_num", "(", "action", ")", "\n", "action", "=", "np", ".", "clip", "(", "action", ",", "self", ".", "action_space", ".", "low", ",", "self", ".", "action_space", ".", "high", ")", "\n", "return", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.wrappers.ClipActionsWrapper.reset": [[28, 30], ["wrappers.ClipActionsWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.discount": [[5, 24], ["scipy.signal.lfilter"], "function", ["None"], ["def", "discount", "(", "x", ",", "gamma", ")", ":", "\n", "    ", "\"\"\"\n    computes discounted sums along 0th dimension of x.\n\n    inputs\n    ------\n    x: ndarray\n    gamma: float\n\n    outputs\n    -------\n    y: ndarray with same shape as x, satisfying\n\n        y[t] = x[t] + gamma*x[t+1] + gamma^2*x[t+2] + ... + gamma^k x[t+k],\n                where k = len(x) - t - 1\n\n    \"\"\"", "\n", "assert", "x", ".", "ndim", ">=", "1", "\n", "return", "scipy", ".", "signal", ".", "lfilter", "(", "[", "1", "]", ",", "[", "1", ",", "-", "gamma", "]", ",", "x", "[", ":", ":", "-", "1", "]", ",", "axis", "=", "0", ")", "[", ":", ":", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.explained_variance": [[25, 39], ["numpy.var", "numpy.var"], "function", ["None"], ["", "def", "explained_variance", "(", "ypred", ",", "y", ")", ":", "\n", "    ", "\"\"\"\n    Computes fraction of variance that ypred explains about y.\n    Returns 1 - Var[y-ypred] / Var[y]\n\n    interpretation:\n        ev=0  =>  might as well have predicted zero\n        ev=1  =>  perfect prediction\n        ev<0  =>  worse than just predicting zero\n\n    \"\"\"", "\n", "assert", "y", ".", "ndim", "==", "1", "and", "ypred", ".", "ndim", "==", "1", "\n", "vary", "=", "np", ".", "var", "(", "y", ")", "\n", "return", "np", ".", "nan", "if", "vary", "==", "0", "else", "1", "-", "np", ".", "var", "(", "y", "-", "ypred", ")", "/", "vary", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.explained_variance_2d": [[40, 46], ["numpy.var", "numpy.var"], "function", ["None"], ["", "def", "explained_variance_2d", "(", "ypred", ",", "y", ")", ":", "\n", "    ", "assert", "y", ".", "ndim", "==", "2", "and", "ypred", ".", "ndim", "==", "2", "\n", "vary", "=", "np", ".", "var", "(", "y", ",", "axis", "=", "0", ")", "\n", "out", "=", "1", "-", "np", ".", "var", "(", "y", "-", "ypred", ")", "/", "vary", "\n", "out", "[", "vary", "<", "1e-10", "]", "=", "0", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.ncc": [[47, 49], ["numpy.corrcoef"], "function", ["None"], ["", "def", "ncc", "(", "ypred", ",", "y", ")", ":", "\n", "    ", "return", "np", ".", "corrcoef", "(", "ypred", ",", "y", ")", "[", "1", ",", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.flatten_arrays": [[50, 52], ["numpy.concatenate"], "function", ["None"], ["", "def", "flatten_arrays", "(", "arrs", ")", ":", "\n", "    ", "return", "np", ".", "concatenate", "(", "[", "arr", ".", "flat", "for", "arr", "in", "arrs", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.unflatten_vector": [[53, 62], ["numpy.prod", "vec[].reshape", "arrs.append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "unflatten_vector", "(", "vec", ",", "shapes", ")", ":", "\n", "    ", "i", "=", "0", "\n", "arrs", "=", "[", "]", "\n", "for", "shape", "in", "shapes", ":", "\n", "        ", "size", "=", "np", ".", "prod", "(", "shape", ")", "\n", "arr", "=", "vec", "[", "i", ":", "i", "+", "size", "]", ".", "reshape", "(", "shape", ")", "\n", "arrs", ".", "append", "(", "arr", ")", "\n", "i", "+=", "size", "\n", "", "return", "arrs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.discount_with_boundaries": [[63, 74], ["numpy.zeros_like", "range"], "function", ["None"], ["", "def", "discount_with_boundaries", "(", "X", ",", "New", ",", "gamma", ")", ":", "\n", "    ", "\"\"\"\n    X: 2d array of floats, time x features\n    New: 2d array of bools, indicating when a new episode has started\n    \"\"\"", "\n", "Y", "=", "np", ".", "zeros_like", "(", "X", ")", "\n", "T", "=", "X", ".", "shape", "[", "0", "]", "\n", "Y", "[", "T", "-", "1", "]", "=", "X", "[", "T", "-", "1", "]", "\n", "for", "t", "in", "range", "(", "T", "-", "2", ",", "-", "1", ",", "-", "1", ")", ":", "\n", "        ", "Y", "[", "t", "]", "=", "X", "[", "t", "]", "+", "gamma", "*", "Y", "[", "t", "+", "1", "]", "*", "(", "1", "-", "New", "[", "t", "+", "1", "]", ")", "\n", "", "return", "Y", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.test_discount_with_boundaries": [[75, 85], ["numpy.array", "math_util.discount_with_boundaries", "numpy.allclose"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.math_util.discount_with_boundaries"], ["", "def", "test_discount_with_boundaries", "(", ")", ":", "\n", "    ", "gamma", "=", "0.9", "\n", "x", "=", "np", ".", "array", "(", "[", "1.0", ",", "2.0", ",", "3.0", ",", "4.0", "]", ",", "'float32'", ")", "\n", "starts", "=", "[", "1.0", ",", "0.0", ",", "0.0", ",", "1.0", "]", "\n", "y", "=", "discount_with_boundaries", "(", "x", ",", "starts", ",", "gamma", ")", "\n", "assert", "np", ".", "allclose", "(", "y", ",", "[", "\n", "1", "+", "gamma", "*", "2", "+", "gamma", "**", "2", "*", "3", ",", "\n", "2", "+", "gamma", "*", "3", ",", "\n", "3", ",", "\n", "4", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register": [[9, 14], ["None"], "function", ["None"], ["\n", "", "@", "property", "\n", "def", "vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ",", "scope", "=", "self", ".", "name", ")", "\n", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.nature_cnn": [[15, 27], ["activ", "activ", "activ", "baselines.a2c.utils.conv_to_fc", "activ", "tensorflow.cast", "baselines.a2c.utils.conv", "baselines.a2c.utils.conv", "baselines.a2c.utils.conv", "baselines.a2c.utils.fc", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv_to_fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc"], ["def", "trainable_vars", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", "=", "self", ".", "name", ")", "\n", "\n", "", "@", "property", "\n", "def", "perturbable_vars", "(", "self", ")", ":", "\n", "        ", "return", "[", "var", "for", "var", "in", "self", ".", "trainable_vars", "if", "'LayerNorm'", "not", "in", "var", ".", "name", "]", "\n", "\n", "\n", "", "", "class", "Actor", "(", "Model", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "nb_actions", ",", "name", "=", "'actor'", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "network", "=", "network", ",", "**", "network_kwargs", ")", "\n", "self", ".", "nb_actions", "=", "nb_actions", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.build_impala_cnn": [[28, 72], ["tensorflow.layers.flatten", "tensorflow.nn.relu", "tensorflow.layers.dense", "str", "tensorflow.layers.conv2d", "tensorflow.nn.relu", "models.build_impala_cnn.conv_layer"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.utils.dense", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d"], ["", "def", "__call__", "(", "self", ",", "obs", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "self", ".", "network_builder", "(", "obs", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "self", ".", "nb_actions", ",", "kernel_initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "3e-3", ",", "maxval", "=", "3e-3", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "tanh", "(", "x", ")", "\n", "", "return", "x", "\n", "\n", "\n", "", "", "class", "Critic", "(", "Model", ")", ":", "\n", "    ", "def", "__init__", "(", "self", ",", "name", "=", "'critic'", ",", "network", "=", "'mlp'", ",", "**", "network_kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "name", "=", "name", ",", "network", "=", "network", ",", "**", "network_kwargs", ")", "\n", "self", ".", "layer_norm", "=", "True", "\n", "\n", "", "def", "__call__", "(", "self", ",", "obs", ",", "action", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "name", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "x", "=", "tf", ".", "concat", "(", "[", "obs", ",", "action", "]", ",", "axis", "=", "-", "1", ")", "# this assumes observation and action can be concatenated", "\n", "x", "=", "self", ".", "network_builder", "(", "x", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "1", ",", "kernel_initializer", "=", "tf", ".", "random_uniform_initializer", "(", "minval", "=", "-", "3e-3", ",", "maxval", "=", "3e-3", ")", ",", "name", "=", "'output'", ")", "\n", "", "return", "x", "\n", "\n", "", "@", "property", "\n", "def", "output_vars", "(", "self", ")", ":", "\n", "        ", "output_vars", "=", "[", "var", "for", "var", "in", "self", ".", "trainable_vars", "if", "'output'", "in", "var", ".", "name", "]", "\n", "return", "output_vars", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.mlp": [[74, 104], ["models.register", "tensorflow.layers.flatten", "range", "baselines.a2c.utils.fc", "activation", "tensorflow.contrib.layers.layer_norm", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn": [[106, 111], ["models.register", "models.nature_cnn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.nature_cnn"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.impala_cnn": [[112, 117], ["models.register", "models.build_impala_cnn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.build_impala_cnn"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn_small": [[118, 130], ["models.register", "activ", "activ", "baselines.a2c.utils.conv_to_fc", "activ", "tensorflow.cast", "baselines.a2c.utils.conv", "baselines.a2c.utils.conv", "baselines.a2c.utils.fc", "numpy.sqrt", "numpy.sqrt", "numpy.sqrt"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv_to_fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.conv", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.lstm": [[131, 184], ["models.register", "tensorflow.layers.flatten", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.seq_to_batch", "numpy.zeros", "baselines.a2c.utils.lnlstm", "baselines.a2c.utils.lstm", "tf.placeholder.shape.as_list"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.seq_to_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.lnlstm", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.lstm"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn_lstm": [[186, 211], ["models.register", "conv_fn", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.batch_to_seq", "baselines.a2c.utils.seq_to_batch", "numpy.zeros", "baselines.a2c.utils.lnlstm", "baselines.a2c.utils.lstm", "tf.placeholder.shape.as_list"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.batch_to_seq", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.seq_to_batch", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.lnlstm", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.lstm"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.impala_cnn_lstm": [[212, 215], ["models.register", "models.cnn_lstm"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn_lstm"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn_lnlstm": [[216, 219], ["models.register", "models.cnn_lstm"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.cnn_lstm"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.conv_only": [[221, 250], ["models.register", "tensorflow.cast", "tensorflow.variable_scope", "tensorflow.contrib.layers.convolution2d"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.register"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models._normalize_clip_observation": [[251, 255], ["baselines.common.mpi_running_mean_std.RunningMeanStd", "tensorflow.clip_by_value", "min", "max"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.get_network_builder": [[257, 276], ["callable", "ValueError"], "function", ["None"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.mpi_mean": [[6, 19], ["numpy.asarray", "np.asarray.sum", "numpy.zeros", "x.sum.ravel", "comm.allreduce", "globalsum[].reshape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["def", "mpi_mean", "(", "x", ",", "axis", "=", "0", ",", "comm", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "x", "=", "np", ".", "asarray", "(", "x", ")", "\n", "assert", "x", ".", "ndim", ">", "0", "\n", "if", "comm", "is", "None", ":", "comm", "=", "MPI", ".", "COMM_WORLD", "\n", "xsum", "=", "x", ".", "sum", "(", "axis", "=", "axis", ",", "keepdims", "=", "keepdims", ")", "\n", "n", "=", "xsum", ".", "size", "\n", "localsum", "=", "np", ".", "zeros", "(", "n", "+", "1", ",", "x", ".", "dtype", ")", "\n", "localsum", "[", ":", "n", "]", "=", "xsum", ".", "ravel", "(", ")", "\n", "localsum", "[", "n", "]", "=", "x", ".", "shape", "[", "axis", "]", "\n", "# globalsum = np.zeros_like(localsum)", "\n", "# comm.Allreduce(localsum, globalsum, op=MPI.SUM)", "\n", "globalsum", "=", "comm", ".", "allreduce", "(", "localsum", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "return", "globalsum", "[", ":", "n", "]", ".", "reshape", "(", "xsum", ".", "shape", ")", "/", "globalsum", "[", "n", "]", ",", "globalsum", "[", "n", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.mpi_moments": [[20, 33], ["numpy.asarray", "mpi_moments.mpi_mean", "numpy.square", "mpi_moments.mpi_mean", "numpy.sqrt", "mean.reshape.reshape", "std.reshape.reshape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.mpi_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.mpi_mean"], ["", "def", "mpi_moments", "(", "x", ",", "axis", "=", "0", ",", "comm", "=", "None", ",", "keepdims", "=", "False", ")", ":", "\n", "    ", "x", "=", "np", ".", "asarray", "(", "x", ")", "\n", "assert", "x", ".", "ndim", ">", "0", "\n", "mean", ",", "count", "=", "mpi_mean", "(", "x", ",", "axis", "=", "axis", ",", "comm", "=", "comm", ",", "keepdims", "=", "True", ")", "\n", "sqdiffs", "=", "np", ".", "square", "(", "x", "-", "mean", ")", "\n", "meansqdiff", ",", "count1", "=", "mpi_mean", "(", "sqdiffs", ",", "axis", "=", "axis", ",", "comm", "=", "comm", ",", "keepdims", "=", "True", ")", "\n", "assert", "count1", "==", "count", "\n", "std", "=", "np", ".", "sqrt", "(", "meansqdiff", ")", "\n", "if", "not", "keepdims", ":", "\n", "        ", "newshape", "=", "mean", ".", "shape", "[", ":", "axis", "]", "+", "mean", ".", "shape", "[", "axis", "+", "1", ":", "]", "\n", "mean", "=", "mean", ".", "reshape", "(", "newshape", ")", "\n", "std", "=", "std", ".", "reshape", "(", "newshape", ")", "\n", "", "return", "mean", ",", "std", ",", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.test_runningmeanstd": [[35, 40], ["subprocess.check_call"], "function", ["None"], ["", "def", "test_runningmeanstd", "(", ")", ":", "\n", "    ", "import", "subprocess", "\n", "subprocess", ".", "check_call", "(", "[", "'mpirun'", ",", "'-np'", ",", "'3'", ",", "\n", "'python'", ",", "'-c'", ",", "\n", "'from baselines.common.mpi_moments import _helper_runningmeanstd; _helper_runningmeanstd()'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments._helper_runningmeanstd": [[41, 61], ["numpy.random.seed", "numpy.concatenate", "mpi_moments.mpi_moments", "baselines.common.zipsame", "np.concatenate.mean", "np.concatenate.std", "print", "numpy.allclose", "print", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "comm.Get_rank"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_moments.mpi_moments", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.zipsame", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "_helper_runningmeanstd", "(", ")", ":", "\n", "    ", "comm", "=", "MPI", ".", "COMM_WORLD", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "for", "(", "triple", ",", "axis", ")", "in", "[", "\n", "(", "(", "np", ".", "random", ".", "randn", "(", "3", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ")", ")", ",", "0", ")", ",", "\n", "(", "(", "np", ".", "random", ".", "randn", "(", "3", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ",", "2", ")", ")", ",", "0", ")", ",", "\n", "(", "(", "np", ".", "random", ".", "randn", "(", "2", ",", "3", ")", ",", "np", ".", "random", ".", "randn", "(", "2", ",", "4", ")", ",", "np", ".", "random", ".", "randn", "(", "2", ",", "4", ")", ")", ",", "1", ")", ",", "\n", "]", ":", "\n", "\n", "\n", "        ", "x", "=", "np", ".", "concatenate", "(", "triple", ",", "axis", "=", "axis", ")", "\n", "ms1", "=", "[", "x", ".", "mean", "(", "axis", "=", "axis", ")", ",", "x", ".", "std", "(", "axis", "=", "axis", ")", ",", "x", ".", "shape", "[", "axis", "]", "]", "\n", "\n", "\n", "ms2", "=", "mpi_moments", "(", "triple", "[", "comm", ".", "Get_rank", "(", ")", "]", ",", "axis", "=", "axis", ")", "\n", "\n", "for", "(", "a1", ",", "a2", ")", "in", "zipsame", "(", "ms1", ",", "ms2", ")", ":", "\n", "            ", "print", "(", "a1", ",", "a2", ")", "\n", "assert", "np", ".", "allclose", "(", "a1", ",", "a2", ")", "\n", "print", "(", "\"ok!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.observation_placeholder": [[5, 32], ["tensorflow.placeholder", "isinstance", "isinstance", "isinstance"], "function", ["None"], ["def", "observation_placeholder", "(", "ob_space", ",", "batch_size", "=", "None", ",", "name", "=", "'Ob'", ")", ":", "\n", "    ", "'''\n    Create placeholder to feed observations into of the size appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space     observation space\n\n    batch_size: int         size of the batch to be fed into input. Can be left None in most cases.\n\n    name: str               name of the placeholder\n\n    Returns:\n    -------\n\n    tensorflow placeholder tensor\n    '''", "\n", "\n", "assert", "isinstance", "(", "ob_space", ",", "Discrete", ")", "or", "isinstance", "(", "ob_space", ",", "Box", ")", "or", "isinstance", "(", "ob_space", ",", "MultiDiscrete", ")", ",", "'Can only deal with Discrete and Box observation spaces for now'", "\n", "\n", "dtype", "=", "ob_space", ".", "dtype", "\n", "if", "dtype", "==", "np", ".", "int8", ":", "\n", "        ", "dtype", "=", "np", ".", "uint8", "\n", "\n", "", "return", "tf", ".", "placeholder", "(", "shape", "=", "(", "batch_size", ",", ")", "+", "ob_space", ".", "shape", ",", "dtype", "=", "dtype", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.observation_input": [[34, 42], ["input.observation_placeholder", "input.encode_observation"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.observation_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.encode_observation"], ["", "def", "observation_input", "(", "ob_space", ",", "batch_size", "=", "None", ",", "name", "=", "'Ob'", ")", ":", "\n", "    ", "'''\n    Create placeholder to feed observations into of the size appropriate to the observation space, and add input\n    encoder of the appropriate type.\n    '''", "\n", "\n", "placeholder", "=", "observation_placeholder", "(", "ob_space", ",", "batch_size", ",", "name", ")", "\n", "return", "placeholder", ",", "encode_observation", "(", "ob_space", ",", "placeholder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.encode_observation": [[43, 64], ["isinstance", "tensorflow.to_float", "isinstance", "tensorflow.one_hot", "tensorflow.to_float", "isinstance", "tensorflow.cast", "tensorflow.concat", "tensorflow.to_float", "tensorflow.one_hot", "range"], "function", ["None"], ["", "def", "encode_observation", "(", "ob_space", ",", "placeholder", ")", ":", "\n", "    ", "'''\n    Encode input in the way that is appropriate to the observation space\n\n    Parameters:\n    ----------\n\n    ob_space: gym.Space             observation space\n\n    placeholder: tf.placeholder     observation input placeholder\n    '''", "\n", "if", "isinstance", "(", "ob_space", ",", "Discrete", ")", ":", "\n", "        ", "return", "tf", ".", "to_float", "(", "tf", ".", "one_hot", "(", "placeholder", ",", "ob_space", ".", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "ob_space", ",", "Box", ")", ":", "\n", "        ", "return", "tf", ".", "to_float", "(", "placeholder", ")", "\n", "", "elif", "isinstance", "(", "ob_space", ",", "MultiDiscrete", ")", ":", "\n", "        ", "placeholder", "=", "tf", ".", "cast", "(", "placeholder", ",", "tf", ".", "int32", ")", "\n", "one_hots", "=", "[", "tf", ".", "to_float", "(", "tf", ".", "one_hot", "(", "placeholder", "[", "...", ",", "i", "]", ",", "ob_space", ".", "nvec", "[", "i", "]", ")", ")", "for", "i", "in", "range", "(", "placeholder", ".", "shape", "[", "-", "1", "]", ")", "]", "\n", "return", "tf", ".", "concat", "(", "one_hots", ",", "axis", "=", "-", "1", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.smooth": [[11, 38], ["len", "numpy.ones_like", "y.mean", "numpy.ones", "numpy.convolve", "numpy.convolve", "numpy.ones", "numpy.ones_like", "numpy.convolve", "numpy.convolve", "numpy.ones_like"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["def", "smooth", "(", "y", ",", "radius", ",", "mode", "=", "'two_sided'", ",", "valid_only", "=", "False", ")", ":", "\n", "    ", "'''\n    Smooth signal y, where radius is determines the size of the window\n\n    mode='twosided':\n        average over the window [max(index - radius, 0), min(index + radius, len(y)-1)]\n    mode='causal':\n        average over the window [max(index - radius, 0), index]\n\n    valid_only: put nan in entries where the full-sized window is not available\n\n    '''", "\n", "assert", "mode", "in", "(", "'two_sided'", ",", "'causal'", ")", "\n", "if", "len", "(", "y", ")", "<", "2", "*", "radius", "+", "1", ":", "\n", "        ", "return", "np", ".", "ones_like", "(", "y", ")", "*", "y", ".", "mean", "(", ")", "\n", "", "elif", "mode", "==", "'two_sided'", ":", "\n", "        ", "convkernel", "=", "np", ".", "ones", "(", "2", "*", "radius", "+", "1", ")", "\n", "out", "=", "np", ".", "convolve", "(", "y", ",", "convkernel", ",", "mode", "=", "'same'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "convkernel", ",", "mode", "=", "'same'", ")", "\n", "if", "valid_only", ":", "\n", "            ", "out", "[", ":", "radius", "]", "=", "out", "[", "-", "radius", ":", "]", "=", "np", ".", "nan", "\n", "", "", "elif", "mode", "==", "'causal'", ":", "\n", "        ", "convkernel", "=", "np", ".", "ones", "(", "radius", ")", "\n", "out", "=", "np", ".", "convolve", "(", "y", ",", "convkernel", ",", "mode", "=", "'full'", ")", "/", "np", ".", "convolve", "(", "np", ".", "ones_like", "(", "y", ")", ",", "convkernel", ",", "mode", "=", "'full'", ")", "\n", "out", "=", "out", "[", ":", "-", "radius", "+", "1", "]", "\n", "if", "valid_only", ":", "\n", "            ", "out", "[", ":", "radius", "]", "=", "np", ".", "nan", "\n", "", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.one_sided_ema": [[39, 110], ["xolds.astype.astype", "yolds.astype.astype", "numpy.linspace", "numpy.exp", "numpy.zeros_like", "numpy.zeros_like", "range", "len", "len", "len", "len", "len", "numpy.exp"], "function", ["None"], ["", "def", "one_sided_ema", "(", "xolds", ",", "yolds", ",", "low", "=", "None", ",", "high", "=", "None", ",", "n", "=", "512", ",", "decay_steps", "=", "1.", ",", "low_counts_threshold", "=", "1e-8", ")", ":", "\n", "    ", "'''\n    perform one-sided (causal) EMA (exponential moving average)\n    smoothing and resampling to an even grid with n points.\n    Does not do extrapolation, so we assume\n    xolds[0] <= low && high <= xolds[-1]\n\n    Arguments:\n\n    xolds: array or list  - x values of data. Needs to be sorted in ascending order\n    yolds: array of list  - y values of data. Has to have the same length as xolds\n\n    low: float            - min value of the new x grid. By default equals to xolds[0]\n    high: float           - max value of the new x grid. By default equals to xolds[-1]\n\n    n: int                - number of points in new x grid\n\n    decay_steps: float    - EMA decay factor, expressed in new x grid steps.\n\n    low_counts_threshold: float or int\n                          - y values with counts less than this value will be set to NaN\n\n    Returns:\n        tuple sum_ys, count_ys where\n            xs        - array with new x grid\n            ys        - array of EMA of y at each point of the new x grid\n            count_ys  - array of EMA of y counts at each point of the new x grid\n\n    '''", "\n", "\n", "low", "=", "xolds", "[", "0", "]", "if", "low", "is", "None", "else", "low", "\n", "high", "=", "xolds", "[", "-", "1", "]", "if", "high", "is", "None", "else", "high", "\n", "\n", "assert", "xolds", "[", "0", "]", "<=", "low", ",", "'low = {} < xolds[0] = {} - extrapolation not permitted!'", ".", "format", "(", "low", ",", "xolds", "[", "0", "]", ")", "\n", "assert", "xolds", "[", "-", "1", "]", ">=", "high", ",", "'high = {} > xolds[-1] = {}  - extrapolation not permitted!'", ".", "format", "(", "high", ",", "xolds", "[", "-", "1", "]", ")", "\n", "assert", "len", "(", "xolds", ")", "==", "len", "(", "yolds", ")", ",", "'length of xolds ({}) and yolds ({}) do not match!'", ".", "format", "(", "len", "(", "xolds", ")", ",", "len", "(", "yolds", ")", ")", "\n", "\n", "\n", "xolds", "=", "xolds", ".", "astype", "(", "'float64'", ")", "\n", "yolds", "=", "yolds", ".", "astype", "(", "'float64'", ")", "\n", "\n", "luoi", "=", "0", "# last unused old index", "\n", "sum_y", "=", "0.", "\n", "count_y", "=", "0.", "\n", "xnews", "=", "np", ".", "linspace", "(", "low", ",", "high", ",", "n", ")", "\n", "decay_period", "=", "(", "high", "-", "low", ")", "/", "(", "n", "-", "1", ")", "*", "decay_steps", "\n", "interstep_decay", "=", "np", ".", "exp", "(", "-", "1.", "/", "decay_steps", ")", "\n", "sum_ys", "=", "np", ".", "zeros_like", "(", "xnews", ")", "\n", "count_ys", "=", "np", ".", "zeros_like", "(", "xnews", ")", "\n", "for", "i", "in", "range", "(", "n", ")", ":", "\n", "        ", "xnew", "=", "xnews", "[", "i", "]", "\n", "sum_y", "*=", "interstep_decay", "\n", "count_y", "*=", "interstep_decay", "\n", "while", "True", ":", "\n", "            ", "if", "luoi", ">=", "len", "(", "xolds", ")", ":", "\n", "                ", "break", "\n", "", "xold", "=", "xolds", "[", "luoi", "]", "\n", "if", "xold", "<=", "xnew", ":", "\n", "                ", "decay", "=", "np", ".", "exp", "(", "-", "(", "xnew", "-", "xold", ")", "/", "decay_period", ")", "\n", "sum_y", "+=", "decay", "*", "yolds", "[", "luoi", "]", "\n", "count_y", "+=", "decay", "\n", "luoi", "+=", "1", "\n", "", "else", ":", "\n", "                ", "break", "\n", "", "", "sum_ys", "[", "i", "]", "=", "sum_y", "\n", "count_ys", "[", "i", "]", "=", "count_y", "\n", "\n", "", "ys", "=", "sum_ys", "/", "count_ys", "\n", "ys", "[", "count_ys", "<", "low_counts_threshold", "]", "=", "np", ".", "nan", "\n", "\n", "return", "xnews", ",", "ys", ",", "count_ys", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.symmetric_ema": [[111, 148], ["plot_util.one_sided_ema", "plot_util.one_sided_ema"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.one_sided_ema", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.one_sided_ema"], ["", "def", "symmetric_ema", "(", "xolds", ",", "yolds", ",", "low", "=", "None", ",", "high", "=", "None", ",", "n", "=", "512", ",", "decay_steps", "=", "1.", ",", "low_counts_threshold", "=", "1e-8", ")", ":", "\n", "    ", "'''\n    perform symmetric EMA (exponential moving average)\n    smoothing and resampling to an even grid with n points.\n    Does not do extrapolation, so we assume\n    xolds[0] <= low && high <= xolds[-1]\n\n    Arguments:\n\n    xolds: array or list  - x values of data. Needs to be sorted in ascending order\n    yolds: array of list  - y values of data. Has to have the same length as xolds\n\n    low: float            - min value of the new x grid. By default equals to xolds[0]\n    high: float           - max value of the new x grid. By default equals to xolds[-1]\n\n    n: int                - number of points in new x grid\n\n    decay_steps: float    - EMA decay factor, expressed in new x grid steps.\n\n    low_counts_threshold: float or int\n                          - y values with counts less than this value will be set to NaN\n\n    Returns:\n        tuple sum_ys, count_ys where\n            xs        - array with new x grid\n            ys        - array of EMA of y at each point of the new x grid\n            count_ys  - array of EMA of y counts at each point of the new x grid\n\n    '''", "\n", "xs", ",", "ys1", ",", "count_ys1", "=", "one_sided_ema", "(", "xolds", ",", "yolds", ",", "low", ",", "high", ",", "n", ",", "decay_steps", ",", "low_counts_threshold", "=", "0", ")", "\n", "_", ",", "ys2", ",", "count_ys2", "=", "one_sided_ema", "(", "-", "xolds", "[", ":", ":", "-", "1", "]", ",", "yolds", "[", ":", ":", "-", "1", "]", ",", "-", "high", ",", "-", "low", ",", "n", ",", "decay_steps", ",", "low_counts_threshold", "=", "0", ")", "\n", "ys2", "=", "ys2", "[", ":", ":", "-", "1", "]", "\n", "count_ys2", "=", "count_ys2", "[", ":", ":", "-", "1", "]", "\n", "count_ys", "=", "count_ys1", "+", "count_ys2", "\n", "ys", "=", "(", "ys1", "*", "count_ys1", "+", "ys2", "*", "count_ys2", ")", "/", "count_ys", "\n", "ys", "[", "count_ys", "<", "low_counts_threshold", "]", "=", "np", ".", "nan", "\n", "return", "xs", ",", "ys", ",", "count_ys", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.load_results": [[152, 221], ["isinstance", "os.exists", "os.walk", "os.walk", "print", "os.expanduser", "os.expanduser", "re.compile", "set().intersection", "any", "os.join", "os.join", "len", "os.exists", "allresults.append", "set", "open", "json.load", "pandas.DataFrame", "os.exists", "pandas.DataFrame", "result.get", "result.get", "Result", "print", "re.compile.match", "os.join", "baselines.logger.read_json", "baselines.bench.monitor.load_results", "print", "print", "baselines.logger.read_csv", "print", "print"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_json", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.load_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.read_csv"], ["def", "load_results", "(", "root_dir_or_dirs", ",", "enable_progress", "=", "True", ",", "enable_monitor", "=", "True", ",", "verbose", "=", "False", ")", ":", "\n", "    ", "'''\n    load summaries of runs from a list of directories (including subdirectories)\n    Arguments:\n\n    enable_progress: bool - if True, will attempt to load data from progress.csv files (data saved by logger). Default: True\n\n    enable_monitor: bool - if True, will attempt to load data from monitor.csv files (data saved by Monitor environment wrapper). Default: True\n\n    verbose: bool - if True, will print out list of directories from which the data is loaded. Default: False\n\n\n    Returns:\n    List of Result objects with the following fields:\n         - dirname - path to the directory data was loaded from\n         - metadata - run metadata (such as command-line arguments and anything else in metadata.json file\n         - monitor - if enable_monitor is True, this field contains pandas dataframe with loaded monitor.csv file (or aggregate of all *.monitor.csv files in the directory)\n         - progress - if enable_progress is True, this field contains pandas dataframe with loaded progress.csv file\n    '''", "\n", "import", "re", "\n", "if", "isinstance", "(", "root_dir_or_dirs", ",", "str", ")", ":", "\n", "        ", "rootdirs", "=", "[", "osp", ".", "expanduser", "(", "root_dir_or_dirs", ")", "]", "\n", "", "else", ":", "\n", "        ", "rootdirs", "=", "[", "osp", ".", "expanduser", "(", "d", ")", "for", "d", "in", "root_dir_or_dirs", "]", "\n", "", "allresults", "=", "[", "]", "\n", "for", "rootdir", "in", "rootdirs", ":", "\n", "        ", "assert", "osp", ".", "exists", "(", "rootdir", ")", ",", "\"%s doesn't exist\"", "%", "rootdir", "\n", "for", "dirname", ",", "dirs", ",", "files", "in", "os", ".", "walk", "(", "rootdir", ")", ":", "\n", "            ", "if", "'-proc'", "in", "dirname", ":", "\n", "                ", "files", "[", ":", "]", "=", "[", "]", "\n", "continue", "\n", "", "monitor_re", "=", "re", ".", "compile", "(", "r'(\\d+\\.)?(\\d+\\.)?monitor\\.csv'", ")", "\n", "if", "set", "(", "[", "'metadata.json'", ",", "'monitor.json'", ",", "'progress.json'", ",", "'progress.csv'", "]", ")", ".", "intersection", "(", "files", ")", "or", "any", "(", "[", "f", "for", "f", "in", "files", "if", "monitor_re", ".", "match", "(", "f", ")", "]", ")", ":", "# also match monitor files like 0.1.monitor.csv", "\n", "# used to be uncommented, which means do not go deeper than current directory if any of the data files", "\n", "# are found", "\n", "# dirs[:] = []", "\n", "                ", "result", "=", "{", "'dirname'", ":", "dirname", "}", "\n", "if", "\"metadata.json\"", "in", "files", ":", "\n", "                    ", "with", "open", "(", "osp", ".", "join", "(", "dirname", ",", "\"metadata.json\"", ")", ",", "\"r\"", ")", "as", "fh", ":", "\n", "                        ", "result", "[", "'metadata'", "]", "=", "json", ".", "load", "(", "fh", ")", "\n", "", "", "progjson", "=", "osp", ".", "join", "(", "dirname", ",", "\"progress.json\"", ")", "\n", "progcsv", "=", "osp", ".", "join", "(", "dirname", ",", "\"progress.csv\"", ")", "\n", "if", "enable_progress", ":", "\n", "                    ", "if", "osp", ".", "exists", "(", "progjson", ")", ":", "\n", "                        ", "result", "[", "'progress'", "]", "=", "pandas", ".", "DataFrame", "(", "read_json", "(", "progjson", ")", ")", "\n", "", "elif", "osp", ".", "exists", "(", "progcsv", ")", ":", "\n", "                        ", "try", ":", "\n", "                            ", "result", "[", "'progress'", "]", "=", "read_csv", "(", "progcsv", ")", "\n", "", "except", "pandas", ".", "errors", ".", "EmptyDataError", ":", "\n", "                            ", "print", "(", "'skipping progress file in '", ",", "dirname", ",", "'empty data'", ")", "\n", "", "", "else", ":", "\n", "                        ", "if", "verbose", ":", "print", "(", "'skipping %s: no progress file'", "%", "dirname", ")", "\n", "\n", "", "", "if", "enable_monitor", ":", "\n", "                    ", "try", ":", "\n", "                        ", "result", "[", "'monitor'", "]", "=", "pandas", ".", "DataFrame", "(", "monitor", ".", "load_results", "(", "dirname", ")", ")", "\n", "", "except", "monitor", ".", "LoadMonitorResultsError", ":", "\n", "                        ", "print", "(", "'skipping %s: no monitor files'", "%", "dirname", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                        ", "print", "(", "'exception loading monitor file in %s: %s'", "%", "(", "dirname", ",", "e", ")", ")", "\n", "\n", "", "", "if", "result", ".", "get", "(", "'monitor'", ")", "is", "not", "None", "or", "result", ".", "get", "(", "'progress'", ")", "is", "not", "None", ":", "\n", "                    ", "allresults", ".", "append", "(", "Result", "(", "**", "result", ")", ")", "\n", "if", "verbose", ":", "\n", "                        ", "print", "(", "'successfully loaded %s'", "%", "dirname", ")", "\n", "\n", "", "", "", "", "", "if", "verbose", ":", "print", "(", "'loaded %i results'", "%", "len", "(", "allresults", ")", ")", "\n", "return", "allresults", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.default_xy_fn": [[227, 231], ["numpy.cumsum", "plot_util.smooth"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.smooth"], ["def", "default_xy_fn", "(", "r", ")", ":", "\n", "    ", "x", "=", "np", ".", "cumsum", "(", "r", ".", "monitor", ".", "l", ")", "\n", "y", "=", "smooth", "(", "r", ".", "monitor", ".", "r", ",", "radius", "=", "10", ")", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.default_split_fn": [[232, 239], ["re.search", "re.search.group"], "function", ["None"], ["", "def", "default_split_fn", "(", "r", ")", ":", "\n", "    ", "import", "re", "\n", "# match name between slash and -<digits> at the end of the string", "\n", "# (slash in the beginning or -<digits> in the end or either may be missing)", "\n", "match", "=", "re", ".", "search", "(", "r'[^/-]+(?=(-\\d+)?\\Z)'", ",", "r", ".", "dirname", ")", "\n", "if", "match", ":", "\n", "        ", "return", "match", ".", "group", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results": [[240, 406], ["collections.defaultdict", "isinstance", "matplotlib.subplots", "list", "enumerate", "split_fn", "sk2r[].append", "len", "len", "set", "sorted", "collections.defaultdict", "collections.defaultdict", "matplotlib.tight_layout", "any", "ax.set_title", "len", "collections.defaultdict.keys", "group_fn", "xy_fn", "map", "sorted", "g2l.keys", "ax.legend", "len", "range", "group_fn", "numpy.arange", "gresults[].append", "ax.plot", "min", "numpy.mean", "numpy.std", "[].plot", "g2l.values", "matplotlib.sca", "matplotlib.xlabel", "matplotlib.sca", "matplotlib.ylabel", "len", "plot_util.symmetric_ema", "any", "map", "all", "max", "min", "numpy.linspace", "plot_util.plot_results.allequal"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.symmetric_ema", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["", "", "def", "plot_results", "(", "\n", "allresults", ",", "*", ",", "\n", "xy_fn", "=", "default_xy_fn", ",", "\n", "split_fn", "=", "default_split_fn", ",", "\n", "group_fn", "=", "default_split_fn", ",", "\n", "average_group", "=", "False", ",", "\n", "shaded_std", "=", "True", ",", "\n", "shaded_err", "=", "True", ",", "\n", "figsize", "=", "None", ",", "\n", "legend_outside", "=", "False", ",", "\n", "resample", "=", "0", ",", "\n", "smooth_step", "=", "1.0", ",", "\n", "tiling", "=", "'vertical'", ",", "\n", "xlabel", "=", "None", ",", "\n", "ylabel", "=", "None", "\n", ")", ":", "\n", "    ", "'''\n    Plot multiple Results objects\n\n    xy_fn: function Result -> x,y           - function that converts results objects into tuple of x and y values.\n                                              By default, x is cumsum of episode lengths, and y is episode rewards\n\n    split_fn: function Result -> hashable   - function that converts results objects into keys to split curves into sub-panels by.\n                                              That is, the results r for which split_fn(r) is different will be put on different sub-panels.\n                                              By default, the portion of r.dirname between last / and -<digits> is returned. The sub-panels are\n                                              stacked vertically in the figure.\n\n    group_fn: function Result -> hashable   - function that converts results objects into keys to group curves by.\n                                              That is, the results r for which group_fn(r) is the same will be put into the same group.\n                                              Curves in the same group have the same color (if average_group is False), or averaged over\n                                              (if average_group is True). The default value is the same as default value for split_fn\n\n    average_group: bool                     - if True, will average the curves in the same group and plot the mean. Enables resampling\n                                              (if resample = 0, will use 512 steps)\n\n    shaded_std: bool                        - if True (default), the shaded region corresponding to standard deviation of the group of curves will be\n                                              shown (only applicable if average_group = True)\n\n    shaded_err: bool                        - if True (default), the shaded region corresponding to error in mean estimate of the group of curves\n                                              (that is, standard deviation divided by square root of number of curves) will be\n                                              shown (only applicable if average_group = True)\n\n    figsize: tuple or None                  - size of the resulting figure (including sub-panels). By default, width is 6 and height is 6 times number of\n                                              sub-panels.\n\n\n    legend_outside: bool                    - if True, will place the legend outside of the sub-panels.\n\n    resample: int                           - if not zero, size of the uniform grid in x direction to resample onto. Resampling is performed via symmetric\n                                              EMA smoothing (see the docstring for symmetric_ema).\n                                              Default is zero (no resampling). Note that if average_group is True, resampling is necessary; in that case, default\n                                              value is 512.\n\n    smooth_step: float                      - when resampling (i.e. when resample > 0 or average_group is True), use this EMA decay parameter (in units of the new grid step).\n                                              See docstrings for decay_steps in symmetric_ema or one_sided_ema functions.\n\n    '''", "\n", "\n", "if", "split_fn", "is", "None", ":", "split_fn", "=", "lambda", "_", ":", "''", "\n", "if", "group_fn", "is", "None", ":", "group_fn", "=", "lambda", "_", ":", "''", "\n", "sk2r", "=", "defaultdict", "(", "list", ")", "# splitkey2results", "\n", "for", "result", "in", "allresults", ":", "\n", "        ", "splitkey", "=", "split_fn", "(", "result", ")", "\n", "sk2r", "[", "splitkey", "]", ".", "append", "(", "result", ")", "\n", "", "assert", "len", "(", "sk2r", ")", ">", "0", "\n", "assert", "isinstance", "(", "resample", ",", "int", ")", ",", "\"0: don't resample. <integer>: that many samples\"", "\n", "if", "tiling", "==", "'vertical'", "or", "tiling", "is", "None", ":", "\n", "        ", "nrows", "=", "len", "(", "sk2r", ")", "\n", "ncols", "=", "1", "\n", "", "elif", "tiling", "==", "'horizontal'", ":", "\n", "        ", "ncols", "=", "len", "(", "sk2r", ")", "\n", "nrows", "=", "1", "\n", "", "elif", "tiling", "==", "'symmetric'", ":", "\n", "        ", "import", "math", "\n", "N", "=", "len", "(", "sk2r", ")", "\n", "largest_divisor", "=", "1", "\n", "for", "i", "in", "range", "(", "1", ",", "int", "(", "math", ".", "sqrt", "(", "N", ")", ")", "+", "1", ")", ":", "\n", "            ", "if", "N", "%", "i", "==", "0", ":", "\n", "                ", "largest_divisor", "=", "i", "\n", "", "", "ncols", "=", "largest_divisor", "\n", "nrows", "=", "N", "//", "ncols", "\n", "", "figsize", "=", "figsize", "or", "(", "6", "*", "ncols", ",", "6", "*", "nrows", ")", "\n", "\n", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "nrows", ",", "ncols", ",", "sharex", "=", "False", ",", "squeeze", "=", "False", ",", "figsize", "=", "figsize", ")", "\n", "\n", "groups", "=", "list", "(", "set", "(", "group_fn", "(", "result", ")", "for", "result", "in", "allresults", ")", ")", "\n", "\n", "default_samples", "=", "512", "\n", "if", "average_group", ":", "\n", "        ", "resample", "=", "resample", "or", "default_samples", "\n", "\n", "", "for", "(", "isplit", ",", "sk", ")", "in", "enumerate", "(", "sorted", "(", "sk2r", ".", "keys", "(", ")", ")", ")", ":", "\n", "        ", "g2l", "=", "{", "}", "\n", "g2c", "=", "defaultdict", "(", "int", ")", "\n", "sresults", "=", "sk2r", "[", "sk", "]", "\n", "gresults", "=", "defaultdict", "(", "list", ")", "\n", "idx_row", "=", "isplit", "//", "ncols", "\n", "idx_col", "=", "isplit", "%", "ncols", "\n", "ax", "=", "axarr", "[", "idx_row", "]", "[", "idx_col", "]", "\n", "for", "result", "in", "sresults", ":", "\n", "            ", "group", "=", "group_fn", "(", "result", ")", "\n", "g2c", "[", "group", "]", "+=", "1", "\n", "x", ",", "y", "=", "xy_fn", "(", "result", ")", "\n", "if", "x", "is", "None", ":", "x", "=", "np", ".", "arange", "(", "len", "(", "y", ")", ")", "\n", "x", ",", "y", "=", "map", "(", "np", ".", "asarray", ",", "(", "x", ",", "y", ")", ")", "\n", "if", "average_group", ":", "\n", "                ", "gresults", "[", "group", "]", ".", "append", "(", "(", "x", ",", "y", ")", ")", "\n", "", "else", ":", "\n", "                ", "if", "resample", ":", "\n", "                    ", "x", ",", "y", ",", "counts", "=", "symmetric_ema", "(", "x", ",", "y", ",", "x", "[", "0", "]", ",", "x", "[", "-", "1", "]", ",", "resample", ",", "decay_steps", "=", "smooth_step", ")", "\n", "", "l", ",", "=", "ax", ".", "plot", "(", "x", ",", "y", ",", "color", "=", "COLORS", "[", "groups", ".", "index", "(", "group", ")", "%", "len", "(", "COLORS", ")", "]", ")", "\n", "g2l", "[", "group", "]", "=", "l", "\n", "", "", "if", "average_group", ":", "\n", "            ", "for", "group", "in", "sorted", "(", "groups", ")", ":", "\n", "                ", "xys", "=", "gresults", "[", "group", "]", "\n", "if", "not", "any", "(", "xys", ")", ":", "\n", "                    ", "continue", "\n", "", "color", "=", "COLORS", "[", "groups", ".", "index", "(", "group", ")", "%", "len", "(", "COLORS", ")", "]", "\n", "origxs", "=", "[", "xy", "[", "0", "]", "for", "xy", "in", "xys", "]", "\n", "minxlen", "=", "min", "(", "map", "(", "len", ",", "origxs", ")", ")", "\n", "def", "allequal", "(", "qs", ")", ":", "\n", "                    ", "return", "all", "(", "(", "q", "==", "qs", "[", "0", "]", ")", ".", "all", "(", ")", "for", "q", "in", "qs", "[", "1", ":", "]", ")", "\n", "", "if", "resample", ":", "\n", "                    ", "low", "=", "max", "(", "x", "[", "0", "]", "for", "x", "in", "origxs", ")", "\n", "high", "=", "min", "(", "x", "[", "-", "1", "]", "for", "x", "in", "origxs", ")", "\n", "usex", "=", "np", ".", "linspace", "(", "low", ",", "high", ",", "resample", ")", "\n", "ys", "=", "[", "]", "\n", "for", "(", "x", ",", "y", ")", "in", "xys", ":", "\n", "                        ", "ys", ".", "append", "(", "symmetric_ema", "(", "x", ",", "y", ",", "low", ",", "high", ",", "resample", ",", "decay_steps", "=", "smooth_step", ")", "[", "1", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "assert", "allequal", "(", "[", "x", "[", ":", "minxlen", "]", "for", "x", "in", "origxs", "]", ")", ",", "'If you want to average unevenly sampled data, set resample=<number of samples you want>'", "\n", "usex", "=", "origxs", "[", "0", "]", "\n", "ys", "=", "[", "xy", "[", "1", "]", "[", ":", "minxlen", "]", "for", "xy", "in", "xys", "]", "\n", "", "ymean", "=", "np", ".", "mean", "(", "ys", ",", "axis", "=", "0", ")", "\n", "ystd", "=", "np", ".", "std", "(", "ys", ",", "axis", "=", "0", ")", "\n", "ystderr", "=", "ystd", "/", "np", ".", "sqrt", "(", "len", "(", "ys", ")", ")", "\n", "l", ",", "=", "axarr", "[", "idx_row", "]", "[", "idx_col", "]", ".", "plot", "(", "usex", ",", "ymean", ",", "color", "=", "color", ")", "\n", "g2l", "[", "group", "]", "=", "l", "\n", "if", "shaded_err", ":", "\n", "                    ", "ax", ".", "fill_between", "(", "usex", ",", "ymean", "-", "ystderr", ",", "ymean", "+", "ystderr", ",", "color", "=", "color", ",", "alpha", "=", ".4", ")", "\n", "", "if", "shaded_std", ":", "\n", "                    ", "ax", ".", "fill_between", "(", "usex", ",", "ymean", "-", "ystd", ",", "ymean", "+", "ystd", ",", "color", "=", "color", ",", "alpha", "=", ".2", ")", "\n", "\n", "\n", "# https://matplotlib.org/users/legend_guide.html", "\n", "", "", "", "plt", ".", "tight_layout", "(", ")", "\n", "if", "any", "(", "g2l", ".", "keys", "(", ")", ")", ":", "\n", "            ", "ax", ".", "legend", "(", "\n", "g2l", ".", "values", "(", ")", ",", "\n", "[", "'%s (%i)'", "%", "(", "g", ",", "g2c", "[", "g", "]", ")", "for", "g", "in", "g2l", "]", "if", "average_group", "else", "g2l", ".", "keys", "(", ")", ",", "\n", "loc", "=", "2", "if", "legend_outside", "else", "None", ",", "\n", "bbox_to_anchor", "=", "(", "1", ",", "1", ")", "if", "legend_outside", "else", "None", ")", "\n", "", "ax", ".", "set_title", "(", "sk", ")", "\n", "# add xlabels, but only to the bottom row", "\n", "if", "xlabel", "is", "not", "None", ":", "\n", "            ", "for", "ax", "in", "axarr", "[", "-", "1", "]", ":", "\n", "                ", "plt", ".", "sca", "(", "ax", ")", "\n", "plt", ".", "xlabel", "(", "xlabel", ")", "\n", "# add ylabels, but only to left column", "\n", "", "", "if", "ylabel", "is", "not", "None", ":", "\n", "            ", "for", "ax", "in", "axarr", "[", ":", ",", "0", "]", ":", "\n", "                ", "plt", ".", "sca", "(", "ax", ")", "\n", "plt", ".", "ylabel", "(", "ylabel", ")", "\n", "\n", "", "", "", "return", "f", ",", "axarr", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.regression_analysis": [[407, 415], ["list", "list.remove", "sm.OLS", "sm.OLS.fit", "print", "df.columns.copy", "sm.add_constant", "mod.fit.summary"], "function", ["None"], ["", "def", "regression_analysis", "(", "df", ")", ":", "\n", "    ", "xcols", "=", "list", "(", "df", ".", "columns", ".", "copy", "(", ")", ")", "\n", "xcols", ".", "remove", "(", "'score'", ")", "\n", "ycols", "=", "[", "'score'", "]", "\n", "import", "statsmodels", ".", "api", "as", "sm", "\n", "mod", "=", "sm", ".", "OLS", "(", "df", "[", "ycols", "]", ",", "sm", ".", "add_constant", "(", "df", "[", "xcols", "]", ")", ",", "hasconst", "=", "False", ")", "\n", "res", "=", "mod", ".", "fit", "(", ")", "\n", "print", "(", "res", ".", "summary", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.test_smooth": [[416, 433], ["numpy.cumsum", "numpy.sin", "plot_util.symmetric_ema", "plot_util.symmetric_ema", "plot_util.symmetric_ema", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.legend", "matplotlib.show", "np.cumsum.min", "np.cumsum.max", "np.cumsum.min", "np.cumsum.max", "np.cumsum.min", "np.cumsum.max", "numpy.random.randn", "numpy.random.rand"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.symmetric_ema", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.symmetric_ema", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.symmetric_ema", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["", "def", "test_smooth", "(", ")", ":", "\n", "    ", "norig", "=", "100", "\n", "nup", "=", "300", "\n", "ndown", "=", "30", "\n", "xs", "=", "np", ".", "cumsum", "(", "np", ".", "random", ".", "rand", "(", "norig", ")", "*", "10", "/", "norig", ")", "\n", "yclean", "=", "np", ".", "sin", "(", "xs", ")", "\n", "ys", "=", "yclean", "+", ".1", "*", "np", ".", "random", ".", "randn", "(", "yclean", ".", "size", ")", "\n", "xup", ",", "yup", ",", "_", "=", "symmetric_ema", "(", "xs", ",", "ys", ",", "xs", ".", "min", "(", ")", ",", "xs", ".", "max", "(", ")", ",", "nup", ",", "decay_steps", "=", "nup", "/", "ndown", ")", "\n", "xdown", ",", "ydown", ",", "_", "=", "symmetric_ema", "(", "xs", ",", "ys", ",", "xs", ".", "min", "(", ")", ",", "xs", ".", "max", "(", ")", ",", "ndown", ",", "decay_steps", "=", "ndown", "/", "ndown", ")", "\n", "xsame", ",", "ysame", ",", "_", "=", "symmetric_ema", "(", "xs", ",", "ys", ",", "xs", ".", "min", "(", ")", ",", "xs", ".", "max", "(", ")", ",", "norig", ",", "decay_steps", "=", "norig", "/", "ndown", ")", "\n", "plt", ".", "plot", "(", "xs", ",", "ys", ",", "label", "=", "'orig'", ",", "marker", "=", "'x'", ")", "\n", "plt", ".", "plot", "(", "xup", ",", "yup", ",", "label", "=", "'up'", ",", "marker", "=", "'x'", ")", "\n", "plt", ".", "plot", "(", "xdown", ",", "ydown", ",", "label", "=", "'down'", ",", "marker", "=", "'x'", ")", "\n", "plt", ".", "plot", "(", "xsame", ",", "ysame", ",", "label", "=", "'same'", ",", "marker", "=", "'x'", ")", "\n", "plt", ".", "plot", "(", "xs", ",", "yclean", ",", "label", "=", "'clean'", ",", "marker", "=", "'x'", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.__init__": [[18, 65], ["tensorflow.constant", "policies.PolicyWithValue.__dict__.update", "tensorflow.layers.flatten", "tensorflow.layers.flatten", "baselines.common.distributions.make_pdtype", "policies.PolicyWithValue.pdtype.pdfromlatent", "policies.PolicyWithValue.pd.sample", "policies.PolicyWithValue.pd.neglogp", "tensorflow.get_default_session", "isinstance", "baselines.a2c.utils.fc", "baselines.a2c.utils.fc"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.constant", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.make_pdtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.pdfromlatent", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.neglogp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc"], ["pi", "=", "tf", ".", "nn", ".", "softmax", "(", "pi_logits", ")", "\n", "q", "=", "fc", "(", "h", ",", "'q'", ",", "nact", ")", "\n", "\n", "", "a", "=", "sample", "(", "tf", ".", "nn", ".", "softmax", "(", "pi_logits", ")", ")", "# could change this to use self.pi instead", "\n", "self", ".", "initial_state", "=", "[", "]", "# not stateful", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "pi", "=", "pi", "# actual policy params now", "\n", "self", ".", "pi_logits", "=", "pi_logits", "\n", "self", ".", "q", "=", "q", "\n", "self", ".", "vf", "=", "q", "\n", "\n", "def", "step", "(", "ob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "# returns actions, mus, states", "\n", "            ", "a0", ",", "pi0", "=", "sess", ".", "run", "(", "[", "a", ",", "pi", "]", ",", "{", "X", ":", "ob", "}", ")", "\n", "return", "a0", ",", "pi0", ",", "[", "]", "# dummy state", "\n", "\n", "", "def", "out", "(", "ob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "pi0", ",", "q0", "=", "sess", ".", "run", "(", "[", "pi", ",", "q", "]", ",", "{", "X", ":", "ob", "}", ")", "\n", "return", "pi0", ",", "q0", "\n", "\n", "", "def", "act", "(", "ob", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "return", "sess", ".", "run", "(", "a", ",", "{", "X", ":", "ob", "}", ")", "\n", "\n", "", "self", ".", "step", "=", "step", "\n", "self", ".", "out", "=", "out", "\n", "self", ".", "act", "=", "act", "\n", "\n", "", "", "class", "AcerLstmPolicy", "(", "object", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "sess", ",", "ob_space", ",", "ac_space", ",", "nenv", ",", "nsteps", ",", "nstack", ",", "reuse", "=", "False", ",", "nlstm", "=", "256", ")", ":", "\n", "        ", "nbatch", "=", "nenv", "*", "nsteps", "\n", "nh", ",", "nw", ",", "nc", "=", "ob_space", ".", "shape", "\n", "ob_shape", "=", "(", "nbatch", ",", "nh", ",", "nw", ",", "nc", "*", "nstack", ")", "\n", "nact", "=", "ac_space", ".", "n", "\n", "X", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "ob_shape", ")", "# obs", "\n", "M", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nbatch", "]", ")", "#mask (done t-1)", "\n", "S", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "nenv", ",", "nlstm", "*", "2", "]", ")", "#states", "\n", "with", "tf", ".", "variable_scope", "(", "\"model\"", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "h", "=", "nature_cnn", "(", "X", ")", "\n", "\n", "# lstm", "\n", "xs", "=", "batch_to_seq", "(", "h", ",", "nenv", ",", "nsteps", ")", "\n", "ms", "=", "batch_to_seq", "(", "M", ",", "nenv", ",", "nsteps", ")", "\n", "h5", ",", "snew", "=", "lstm", "(", "xs", ",", "ms", ",", "S", ",", "'lstm1'", ",", "nh", "=", "nlstm", ")", "\n", "h5", "=", "seq_to_batch", "(", "h5", ")", "\n", "\n", "pi_logits", "=", "fc", "(", "h5", ",", "'pi'", ",", "nact", ",", "init_scale", "=", "0.01", ")", "\n", "pi", "=", "tf", ".", "nn", ".", "softmax", "(", "pi_logits", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue._evaluate": [[66, 76], ["extra_feed.items", "sess.run", "baselines.common.tf_util.adjust_shape", "policies.PolicyWithValue.__dict__.keys", "isinstance", "baselines.common.tf_util.adjust_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.adjust_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.adjust_shape"], ["q", "=", "fc", "(", "h5", ",", "'q'", ",", "nact", ")", "\n", "\n", "", "a", "=", "sample", "(", "pi_logits", ")", "# could change this to use self.pi instead", "\n", "self", ".", "initial_state", "=", "np", ".", "zeros", "(", "(", "nenv", ",", "nlstm", "*", "2", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "X", "=", "X", "\n", "self", ".", "M", "=", "M", "\n", "self", ".", "S", "=", "S", "\n", "self", ".", "pi", "=", "pi", "# actual policy params now", "\n", "self", ".", "q", "=", "q", "\n", "\n", "def", "step", "(", "ob", ",", "state", ",", "mask", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.step": [[77, 97], ["policies.PolicyWithValue._evaluate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue._evaluate"], ["# returns actions, mus, states", "\n", "            ", "a0", ",", "pi0", ",", "s", "=", "sess", ".", "run", "(", "[", "a", ",", "pi", ",", "snew", "]", ",", "{", "X", ":", "ob", ",", "S", ":", "state", ",", "M", ":", "mask", "}", ")", "\n", "return", "a0", ",", "pi0", ",", "s", "\n", "\n", "", "self", ".", "step", "=", "step", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.value": [[98, 114], ["policies.PolicyWithValue._evaluate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue._evaluate"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save": [[115, 117], ["baselines.common.tf_util.save_state"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_state"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load": [[118, 120], ["baselines.common.tf_util.load_state"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_state"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.build_policy": [[121, 180], ["isinstance", "baselines.common.input.encode_observation", "policies.PolicyWithValue", "baselines.common.models.get_network_builder", "baselines.common.input.observation_placeholder", "policies._normalize_clip_observation", "tensorflow.variable_scope", "policy_network", "isinstance", "callable", "tensorflow.variable_scope", "_v_net", "policy_network", "extra_tensors.update"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.encode_observation", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.get_network_builder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.input.observation_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies._normalize_clip_observation", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies._normalize_clip_observation": [[182, 186], ["baselines.common.mpi_running_mean_std.RunningMeanStd", "tensorflow.clip_by_value", "min", "max"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], []], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_fork.mpi_fork": [[3, 24], ["os.getenv", "os.environ.copy", "os.environ.copy.update", "subprocess.check_call", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["def", "mpi_fork", "(", "n", ",", "bind_to_core", "=", "False", ")", ":", "\n", "    ", "\"\"\"Re-launches the current script with workers\n    Returns \"parent\" for original parent, \"child\" for MPI children\n    \"\"\"", "\n", "if", "n", "<=", "1", ":", "\n", "        ", "return", "\"child\"", "\n", "", "if", "os", ".", "getenv", "(", "\"IN_MPI\"", ")", "is", "None", ":", "\n", "        ", "env", "=", "os", ".", "environ", ".", "copy", "(", ")", "\n", "env", ".", "update", "(", "\n", "MKL_NUM_THREADS", "=", "\"1\"", ",", "\n", "OMP_NUM_THREADS", "=", "\"1\"", ",", "\n", "IN_MPI", "=", "\"1\"", "\n", ")", "\n", "args", "=", "[", "\"mpirun\"", ",", "\"-np\"", ",", "str", "(", "n", ")", "]", "\n", "if", "bind_to_core", ":", "\n", "            ", "args", "+=", "[", "\"-bind-to\"", ",", "\"core\"", "]", "\n", "", "args", "+=", "[", "sys", ".", "executable", "]", "+", "sys", ".", "argv", "\n", "subprocess", ".", "check_call", "(", "args", ",", "env", "=", "env", ")", "\n", "return", "\"parent\"", "\n", "", "else", ":", "\n", "        ", "return", "\"child\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.runners.AbstractEnvRunner.__init__": [[5, 15], ["numpy.zeros", "env.reset", "hasattr", "range"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["    ", "def", "__init__", "(", "self", ",", "*", ",", "env", ",", "model", ",", "nsteps", ")", ":", "\n", "        ", "self", ".", "env", "=", "env", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "nenv", "=", "nenv", "=", "env", ".", "num_envs", "if", "hasattr", "(", "env", ",", "'num_envs'", ")", "else", "1", "\n", "self", ".", "batch_ob_shape", "=", "(", "nenv", "*", "nsteps", ",", ")", "+", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "obs", "=", "np", ".", "zeros", "(", "(", "nenv", ",", ")", "+", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "env", ".", "observation_space", ".", "dtype", ".", "name", ")", "\n", "self", ".", "obs", "[", ":", "]", "=", "env", ".", "reset", "(", ")", "\n", "self", ".", "nsteps", "=", "nsteps", "\n", "self", ".", "states", "=", "model", ".", "initial_state", "\n", "self", ".", "dones", "=", "[", "False", "for", "_", "in", "range", "(", "nenv", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.runners.AbstractEnvRunner.run": [[16, 19], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "run", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.fmt_row": [[12, 16], ["console_util.fmt_item", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.fmt_item"], ["def", "fmt_row", "(", "width", ",", "row", ",", "header", "=", "False", ")", ":", "\n", "    ", "out", "=", "\" | \"", ".", "join", "(", "fmt_item", "(", "x", ",", "width", ")", "for", "x", "in", "row", ")", "\n", "if", "header", ":", "out", "=", "out", "+", "\"\\n\"", "+", "\"-\"", "*", "len", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.fmt_item": [[17, 29], ["isinstance", "isinstance", "x.item.item", "abs", "str", "len"], "function", ["None"], ["", "def", "fmt_item", "(", "x", ",", "l", ")", ":", "\n", "    ", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "assert", "x", ".", "ndim", "==", "0", "\n", "x", "=", "x", ".", "item", "(", ")", "\n", "", "if", "isinstance", "(", "x", ",", "(", "float", ",", "np", ".", "float32", ",", "np", ".", "float64", ")", ")", ":", "\n", "        ", "v", "=", "abs", "(", "x", ")", "\n", "if", "(", "v", "<", "1e-4", "or", "v", ">", "1e+4", ")", "and", "v", ">", "0", ":", "\n", "            ", "rep", "=", "\"%7.2e\"", "%", "x", "\n", "", "else", ":", "\n", "            ", "rep", "=", "\"%7.5f\"", "%", "x", "\n", "", "", "else", ":", "rep", "=", "str", "(", "x", ")", "\n", "return", "\" \"", "*", "(", "l", "-", "len", "(", "rep", ")", ")", "+", "rep", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.colorize": [[42, 49], ["attr.append", "str", "attr.append"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["def", "colorize", "(", "string", ",", "color", "=", "'green'", ",", "bold", "=", "False", ",", "highlight", "=", "False", ")", ":", "\n", "    ", "attr", "=", "[", "]", "\n", "num", "=", "color2num", "[", "color", "]", "\n", "if", "highlight", ":", "num", "+=", "10", "\n", "attr", ".", "append", "(", "str", "(", "num", ")", ")", "\n", "if", "bold", ":", "attr", ".", "append", "(", "'1'", ")", "\n", "return", "'\\x1b[%sm%s\\x1b[0m'", "%", "(", "';'", ".", "join", "(", "attr", ")", ",", "string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.print_cmd": [[50, 56], ["isinstance", "print", "console_util.colorize", "shlex.quote"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.colorize"], ["", "def", "print_cmd", "(", "cmd", ",", "dry", "=", "False", ")", ":", "\n", "    ", "if", "isinstance", "(", "cmd", ",", "str", ")", ":", "# for shell=True", "\n", "        ", "pass", "\n", "", "else", ":", "\n", "        ", "cmd", "=", "' '", ".", "join", "(", "shlex", ".", "quote", "(", "arg", ")", "for", "arg", "in", "cmd", ")", "\n", "", "print", "(", "colorize", "(", "(", "'CMD: '", "if", "not", "dry", "else", "'DRY: '", ")", "+", "cmd", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.get_git_commit": [[58, 60], ["subprocess.check_output().decode", "subprocess.check_output"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.decode"], ["", "def", "get_git_commit", "(", "cwd", "=", "None", ")", ":", "\n", "    ", "return", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'rev-parse'", ",", "'--short'", ",", "'HEAD'", "]", ",", "cwd", "=", "cwd", ")", ".", "decode", "(", "'utf8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.get_git_commit_message": [[61, 63], ["subprocess.check_output().decode", "subprocess.check_output"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.decode"], ["", "def", "get_git_commit_message", "(", "cwd", "=", "None", ")", ":", "\n", "    ", "return", "subprocess", ".", "check_output", "(", "[", "'git'", ",", "'show'", ",", "'-s'", ",", "'--format=%B'", ",", "'HEAD'", "]", ",", "cwd", "=", "cwd", ")", ".", "decode", "(", "'utf8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.ccap": [[64, 68], ["console_util.print_cmd", "subprocess.check_call"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.print_cmd"], ["", "def", "ccap", "(", "cmd", ",", "dry", "=", "False", ",", "env", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "print_cmd", "(", "cmd", ",", "dry", ")", "\n", "if", "not", "dry", ":", "\n", "        ", "subprocess", ".", "check_call", "(", "cmd", ",", "env", "=", "env", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.timed": [[72, 81], ["print", "time.time", "print", "console_util.colorize", "console_util.colorize", "time.time"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.colorize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.console_util.colorize"], ["@", "contextmanager", "\n", "def", "timed", "(", "msg", ")", ":", "\n", "    ", "global", "MESSAGE_DEPTH", "#pylint: disable=W0603", "\n", "print", "(", "colorize", "(", "'\\t'", "*", "MESSAGE_DEPTH", "+", "'=: '", "+", "msg", ",", "color", "=", "'magenta'", ")", ")", "\n", "tstart", "=", "time", ".", "time", "(", ")", "\n", "MESSAGE_DEPTH", "+=", "1", "\n", "yield", "\n", "MESSAGE_DEPTH", "-=", "1", "\n", "print", "(", "colorize", "(", "'\\t'", "*", "MESSAGE_DEPTH", "+", "\"done in %.3f seconds\"", "%", "(", "time", ".", "time", "(", ")", "-", "tstart", ")", ",", "color", "=", "'magenta'", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_vec_env": [[22, 60], ["baselines.logger.get_dir", "baselines.common.set_global_seeds", "MPI.COMM_WORLD.Get_rank", "baselines.common.vec_env.subproc_vec_env.SubprocVecEnv", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "cmd_util.make_env", "cmd_util.make_vec_env.make_thunk"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env"], ["def", "make_vec_env", "(", "env_id", ",", "env_type", ",", "num_env", ",", "seed", ",", "\n", "wrapper_kwargs", "=", "None", ",", "\n", "env_kwargs", "=", "None", ",", "\n", "start_index", "=", "0", ",", "\n", "reward_scale", "=", "1.0", ",", "\n", "flatten_dict_observations", "=", "True", ",", "\n", "gamestate", "=", "None", ",", "\n", "initializer", "=", "None", ",", "\n", "force_dummy", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored SubprocVecEnv for Atari and MuJoCo.\n    \"\"\"", "\n", "wrapper_kwargs", "=", "wrapper_kwargs", "or", "{", "}", "\n", "env_kwargs", "=", "env_kwargs", "or", "{", "}", "\n", "mpi_rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "if", "MPI", "else", "0", "\n", "seed", "=", "seed", "+", "10000", "*", "mpi_rank", "if", "seed", "is", "not", "None", "else", "None", "\n", "logger_dir", "=", "logger", ".", "get_dir", "(", ")", "\n", "def", "make_thunk", "(", "rank", ",", "initializer", "=", "None", ")", ":", "\n", "        ", "return", "lambda", ":", "make_env", "(", "\n", "env_id", "=", "env_id", ",", "\n", "env_type", "=", "env_type", ",", "\n", "mpi_rank", "=", "mpi_rank", ",", "\n", "subrank", "=", "rank", ",", "\n", "seed", "=", "seed", ",", "\n", "reward_scale", "=", "reward_scale", ",", "\n", "gamestate", "=", "gamestate", ",", "\n", "flatten_dict_observations", "=", "flatten_dict_observations", ",", "\n", "wrapper_kwargs", "=", "wrapper_kwargs", ",", "\n", "env_kwargs", "=", "env_kwargs", ",", "\n", "logger_dir", "=", "logger_dir", ",", "\n", "initializer", "=", "initializer", "\n", ")", "\n", "\n", "", "set_global_seeds", "(", "seed", ")", "\n", "if", "not", "force_dummy", "and", "num_env", ">", "1", ":", "\n", "        ", "return", "SubprocVecEnv", "(", "[", "make_thunk", "(", "i", "+", "start_index", ",", "initializer", "=", "initializer", ")", "for", "i", "in", "range", "(", "num_env", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "return", "DummyVecEnv", "(", "[", "make_thunk", "(", "i", "+", "start_index", ",", "initializer", "=", "None", ")", "for", "i", "in", "range", "(", "num_env", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env": [[62, 106], ["retro_wrappers.wrap_deepmind_retro.seed", "baselines.bench.Monitor", "isinstance", "initializer", "re.sub", "re.sub", "importlib.import_module", "baselines.common.atari_wrappers.make_atari", "isinstance", "gym.wrappers.FlattenObservation", "baselines.common.atari_wrappers.wrap_deepmind", "baselines.common.wrappers.ClipActionsWrapper", "baselines.common.retro_wrappers.RewardScaler", "baselines.common.retro_wrappers.make_retro", "gym.make", "os.path.join", "baselines.common.retro_wrappers.wrap_deepmind_retro", "str", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.make_atari", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.wrap_deepmind", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.make_retro", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.wrap_deepmind_retro"], ["", "", "def", "make_env", "(", "env_id", ",", "env_type", ",", "mpi_rank", "=", "0", ",", "subrank", "=", "0", ",", "seed", "=", "None", ",", "reward_scale", "=", "1.0", ",", "gamestate", "=", "None", ",", "flatten_dict_observations", "=", "True", ",", "wrapper_kwargs", "=", "None", ",", "env_kwargs", "=", "None", ",", "logger_dir", "=", "None", ",", "initializer", "=", "None", ")", ":", "\n", "    ", "if", "initializer", "is", "not", "None", ":", "\n", "        ", "initializer", "(", "mpi_rank", "=", "mpi_rank", ",", "subrank", "=", "subrank", ")", "\n", "\n", "", "wrapper_kwargs", "=", "wrapper_kwargs", "or", "{", "}", "\n", "env_kwargs", "=", "env_kwargs", "or", "{", "}", "\n", "if", "':'", "in", "env_id", ":", "\n", "        ", "import", "re", "\n", "import", "importlib", "\n", "module_name", "=", "re", ".", "sub", "(", "':.*'", ",", "''", ",", "env_id", ")", "\n", "env_id", "=", "re", ".", "sub", "(", "'.*:'", ",", "''", ",", "env_id", ")", "\n", "importlib", ".", "import_module", "(", "module_name", ")", "\n", "", "if", "env_type", "==", "'atari'", ":", "\n", "        ", "env", "=", "make_atari", "(", "env_id", ")", "\n", "", "elif", "env_type", "==", "'retro'", ":", "\n", "        ", "import", "retro", "\n", "gamestate", "=", "gamestate", "or", "retro", ".", "State", ".", "DEFAULT", "\n", "env", "=", "retro_wrappers", ".", "make_retro", "(", "game", "=", "env_id", ",", "max_episode_steps", "=", "10000", ",", "use_restricted_actions", "=", "retro", ".", "Actions", ".", "DISCRETE", ",", "state", "=", "gamestate", ")", "\n", "", "else", ":", "\n", "        ", "env", "=", "gym", ".", "make", "(", "env_id", ",", "**", "env_kwargs", ")", "\n", "\n", "", "if", "flatten_dict_observations", "and", "isinstance", "(", "env", ".", "observation_space", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "        ", "env", "=", "FlattenObservation", "(", "env", ")", "\n", "\n", "", "env", ".", "seed", "(", "seed", "+", "subrank", "if", "seed", "is", "not", "None", "else", "None", ")", "\n", "env", "=", "Monitor", "(", "env", ",", "\n", "logger_dir", "and", "os", ".", "path", ".", "join", "(", "logger_dir", ",", "str", "(", "mpi_rank", ")", "+", "'.'", "+", "str", "(", "subrank", ")", ")", ",", "\n", "allow_early_resets", "=", "True", ")", "\n", "\n", "\n", "if", "env_type", "==", "'atari'", ":", "\n", "        ", "env", "=", "wrap_deepmind", "(", "env", ",", "**", "wrapper_kwargs", ")", "\n", "", "elif", "env_type", "==", "'retro'", ":", "\n", "        ", "if", "'frame_stack'", "not", "in", "wrapper_kwargs", ":", "\n", "            ", "wrapper_kwargs", "[", "'frame_stack'", "]", "=", "1", "\n", "", "env", "=", "retro_wrappers", ".", "wrap_deepmind_retro", "(", "env", ",", "**", "wrapper_kwargs", ")", "\n", "\n", "", "if", "isinstance", "(", "env", ".", "action_space", ",", "gym", ".", "spaces", ".", "Box", ")", ":", "\n", "        ", "env", "=", "ClipActionsWrapper", "(", "env", ")", "\n", "\n", "", "if", "reward_scale", "!=", "1", ":", "\n", "        ", "env", "=", "retro_wrappers", ".", "RewardScaler", "(", "env", ",", "reward_scale", ")", "\n", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_mujoco_env": [[108, 123], ["MPI.COMM_WORLD.Get_rank", "baselines.common.set_global_seeds", "gym.make", "baselines.bench.Monitor", "RewardScaler.seed", "os.path.join", "RewardScaler", "baselines.logger.get_dir", "baselines.logger.get_dir", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["", "def", "make_mujoco_env", "(", "env_id", ",", "seed", ",", "reward_scale", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored gym.Env for MuJoCo.\n    \"\"\"", "\n", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "myseed", "=", "seed", "+", "1000", "*", "rank", "if", "seed", "is", "not", "None", "else", "None", "\n", "set_global_seeds", "(", "myseed", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "logger_path", "=", "None", "if", "logger", ".", "get_dir", "(", ")", "is", "None", "else", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "str", "(", "rank", ")", ")", "\n", "env", "=", "Monitor", "(", "env", ",", "logger_path", ",", "allow_early_resets", "=", "True", ")", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "if", "reward_scale", "!=", "1.0", ":", "\n", "        ", "from", "baselines", ".", "common", ".", "retro_wrappers", "import", "RewardScaler", "\n", "env", "=", "RewardScaler", "(", "env", ",", "reward_scale", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_robotics_env": [[124, 136], ["baselines.common.set_global_seeds", "gym.make", "gym.wrappers.FlattenObservation", "baselines.bench.Monitor", "baselines.bench.Monitor.seed", "gym.wrappers.FilterObservation", "baselines.logger.get_dir", "os.path.join", "baselines.logger.get_dir", "str"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.get_dir"], ["", "def", "make_robotics_env", "(", "env_id", ",", "seed", ",", "rank", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Create a wrapped, monitored gym.Env for MuJoCo.\n    \"\"\"", "\n", "set_global_seeds", "(", "seed", ")", "\n", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "env", "=", "FlattenObservation", "(", "FilterObservation", "(", "env", ",", "[", "'observation'", ",", "'desired_goal'", "]", ")", ")", "\n", "env", "=", "Monitor", "(", "\n", "env", ",", "logger", ".", "get_dir", "(", ")", "and", "os", ".", "path", ".", "join", "(", "logger", ".", "get_dir", "(", ")", ",", "str", "(", "rank", ")", ")", ",", "\n", "info_keywords", "=", "(", "'is_success'", ",", ")", ")", "\n", "env", ".", "seed", "(", "seed", ")", "\n", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.arg_parser": [[137, 143], ["argparse.ArgumentParser"], "function", ["None"], ["", "def", "arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an empty argparse.ArgumentParser.\n    \"\"\"", "\n", "import", "argparse", "\n", "return", "argparse", ".", "ArgumentParser", "(", "formatter_class", "=", "argparse", ".", "ArgumentDefaultsHelpFormatter", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.atari_arg_parser": [[144, 150], ["print", "cmd_util.common_arg_parser"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.common_arg_parser"], ["", "def", "atari_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an argparse.ArgumentParser for run_atari.py.\n    \"\"\"", "\n", "print", "(", "'Obsolete - use common_arg_parser instead'", ")", "\n", "return", "common_arg_parser", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.mujoco_arg_parser": [[151, 154], ["print", "cmd_util.common_arg_parser"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.common_arg_parser"], ["", "def", "mujoco_arg_parser", "(", ")", ":", "\n", "    ", "print", "(", "'Obsolete - use common_arg_parser instead'", ")", "\n", "return", "common_arg_parser", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.common_arg_parser": [[155, 175], ["cmd_util.arg_parser", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.arg_parser"], ["", "def", "common_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an argparse.ArgumentParser for run_mujoco.py.\n    \"\"\"", "\n", "parser", "=", "arg_parser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--env'", ",", "help", "=", "'environment ID'", ",", "type", "=", "str", ",", "default", "=", "'Reacher-v2'", ")", "\n", "parser", ".", "add_argument", "(", "'--env_type'", ",", "help", "=", "'type of environment, used when the environment type cannot be automatically determined'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'RNG seed'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--alg'", ",", "help", "=", "'Algorithm'", ",", "type", "=", "str", ",", "default", "=", "'ppo2'", ")", "\n", "parser", ".", "add_argument", "(", "'--num_timesteps'", ",", "type", "=", "float", ",", "default", "=", "1e6", ")", ",", "\n", "parser", ".", "add_argument", "(", "'--network'", ",", "help", "=", "'network type (mlp, cnn, lstm, cnn_lstm, conv_only)'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--gamestate'", ",", "help", "=", "'game state to load (so far only used in retro games)'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--num_env'", ",", "help", "=", "'Number of environment copies being run in parallel. When not specified, set to number of cpus for Atari, and to 1 for Mujoco'", ",", "default", "=", "None", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--reward_scale'", ",", "help", "=", "'Reward scale factor. Default: 1.0'", ",", "default", "=", "1.0", ",", "type", "=", "float", ")", "\n", "parser", ".", "add_argument", "(", "'--save_path'", ",", "help", "=", "'Path to save trained model to'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--save_video_interval'", ",", "help", "=", "'Save video every x steps (0 = disabled)'", ",", "default", "=", "0", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--save_video_length'", ",", "help", "=", "'Length of recorded video. Default: 200'", ",", "default", "=", "200", ",", "type", "=", "int", ")", "\n", "parser", ".", "add_argument", "(", "'--log_path'", ",", "help", "=", "'Directory to save learning curve data.'", ",", "default", "=", "None", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--play'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.robotics_arg_parser": [[176, 185], ["cmd_util.arg_parser", "arg_parser.add_argument", "arg_parser.add_argument", "arg_parser.add_argument", "int"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.arg_parser"], ["", "def", "robotics_arg_parser", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create an argparse.ArgumentParser for run_mujoco.py.\n    \"\"\"", "\n", "parser", "=", "arg_parser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--env'", ",", "help", "=", "'environment ID'", ",", "type", "=", "str", ",", "default", "=", "'FetchReach-v0'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "help", "=", "'RNG seed'", ",", "type", "=", "int", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'--num-timesteps'", ",", "type", "=", "int", ",", "default", "=", "int", "(", "1e6", ")", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.parse_unknown_args": [[187, 207], ["arg.startswith", "arg.split", "arg.split"], "function", ["None"], ["", "def", "parse_unknown_args", "(", "args", ")", ":", "\n", "    ", "\"\"\"\n    Parse arguments not consumed by arg parser into a dictionary\n    \"\"\"", "\n", "retval", "=", "{", "}", "\n", "preceded_by_key", "=", "False", "\n", "for", "arg", "in", "args", ":", "\n", "        ", "if", "arg", ".", "startswith", "(", "'--'", ")", ":", "\n", "            ", "if", "'='", "in", "arg", ":", "\n", "                ", "key", "=", "arg", ".", "split", "(", "'='", ")", "[", "0", "]", "[", "2", ":", "]", "\n", "value", "=", "arg", ".", "split", "(", "'='", ")", "[", "1", "]", "\n", "retval", "[", "key", "]", "=", "value", "\n", "", "else", ":", "\n", "                ", "key", "=", "arg", "[", "2", ":", "]", "\n", "preceded_by_key", "=", "True", "\n", "", "", "elif", "preceded_by_key", ":", "\n", "            ", "retval", "[", "key", "]", "=", "arg", "\n", "preceded_by_key", "=", "False", "\n", "\n", "", "", "return", "retval", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.Schedule.value": [[13, 16], ["NotImplementedError"], "methods", ["None"], ["    ", "def", "value", "(", "self", ",", "t", ")", ":", "\n", "        ", "\"\"\"Value of the schedule at time t\"\"\"", "\n", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.ConstantSchedule.__init__": [[19, 28], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"Value remains constant over time.\n\n        Parameters\n        ----------\n        value: float\n            Constant value of the schedule\n        \"\"\"", "\n", "self", ".", "_v", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.ConstantSchedule.value": [[29, 32], ["None"], "methods", ["None"], ["", "def", "value", "(", "self", ",", "t", ")", ":", "\n", "        ", "\"\"\"See Schedule.value\"\"\"", "\n", "return", "self", ".", "_v", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.PiecewiseSchedule.__init__": [[39, 63], ["sorted"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "endpoints", ",", "interpolation", "=", "linear_interpolation", ",", "outside_value", "=", "None", ")", ":", "\n", "        ", "\"\"\"Piecewise schedule.\n\n        endpoints: [(int, int)]\n            list of pairs `(time, value)` meanining that schedule should output\n            `value` when `t==time`. All the values for time must be sorted in\n            an increasing order. When t is between two times, e.g. `(time_a, value_a)`\n            and `(time_b, value_b)`, such that `time_a <= t < time_b` then value outputs\n            `interpolation(value_a, value_b, alpha)` where alpha is a fraction of\n            time passed between `time_a` and `time_b` for time `t`.\n        interpolation: lambda float, float, float: float\n            a function that takes value to the left and to the right of t according\n            to the `endpoints`. Alpha is the fraction of distance from left endpoint to\n            right endpoint that t has covered. See linear_interpolation for example.\n        outside_value: float\n            if the value is requested outside of all the intervals sepecified in\n            `endpoints` this value is returned. If None then AssertionError is\n            raised when outside value is requested.\n        \"\"\"", "\n", "idxes", "=", "[", "e", "[", "0", "]", "for", "e", "in", "endpoints", "]", "\n", "assert", "idxes", "==", "sorted", "(", "idxes", ")", "\n", "self", ".", "_interpolation", "=", "interpolation", "\n", "self", ".", "_outside_value", "=", "outside_value", "\n", "self", ".", "_endpoints", "=", "endpoints", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.PiecewiseSchedule.value": [[64, 74], ["zip", "schedules.PiecewiseSchedule._interpolation", "float"], "methods", ["None"], ["", "def", "value", "(", "self", ",", "t", ")", ":", "\n", "        ", "\"\"\"See Schedule.value\"\"\"", "\n", "for", "(", "l_t", ",", "l", ")", ",", "(", "r_t", ",", "r", ")", "in", "zip", "(", "self", ".", "_endpoints", "[", ":", "-", "1", "]", ",", "self", ".", "_endpoints", "[", "1", ":", "]", ")", ":", "\n", "            ", "if", "l_t", "<=", "t", "and", "t", "<", "r_t", ":", "\n", "                ", "alpha", "=", "float", "(", "t", "-", "l_t", ")", "/", "(", "r_t", "-", "l_t", ")", "\n", "return", "self", ".", "_interpolation", "(", "l", ",", "r", ",", "alpha", ")", "\n", "\n", "# t does not belong to any of the pieces, so doom.", "\n", "", "", "assert", "self", ".", "_outside_value", "is", "not", "None", "\n", "return", "self", ".", "_outside_value", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.__init__": [[77, 95], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "schedule_timesteps", ",", "final_p", ",", "initial_p", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Linear interpolation between initial_p and final_p over\n        schedule_timesteps. After this many timesteps pass final_p is\n        returned.\n\n        Parameters\n        ----------\n        schedule_timesteps: int\n            Number of timesteps for which to linearly anneal initial_p\n            to final_p\n        initial_p: float\n            initial output value\n        final_p: float\n            final output value\n        \"\"\"", "\n", "self", ".", "schedule_timesteps", "=", "schedule_timesteps", "\n", "self", ".", "final_p", "=", "final_p", "\n", "self", ".", "initial_p", "=", "initial_p", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value": [[96, 100], ["min", "float"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["", "def", "value", "(", "self", ",", "t", ")", ":", "\n", "        ", "\"\"\"See Schedule.value\"\"\"", "\n", "fraction", "=", "min", "(", "float", "(", "t", ")", "/", "self", ".", "schedule_timesteps", ",", "1.0", ")", "\n", "return", "self", ".", "initial_p", "+", "fraction", "*", "(", "self", ".", "final_p", "-", "self", ".", "initial_p", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.linear_interpolation": [[34, 36], ["None"], "function", ["None"], ["", "", "def", "linear_interpolation", "(", "l", ",", "r", ",", "alpha", ")", ":", "\n", "    ", "return", "l", "+", "alpha", "*", "(", "r", "-", "l", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.EzPickle.__init__": [[36, 39], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "_ezpickle_args", "=", "args", "\n", "self", ".", "_ezpickle_kwargs", "=", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.EzPickle.__getstate__": [[40, 42], ["None"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "return", "{", "\"_ezpickle_args\"", ":", "self", ".", "_ezpickle_args", ",", "\"_ezpickle_kwargs\"", ":", "self", ".", "_ezpickle_kwargs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.EzPickle.__setstate__": [[43, 46], ["misc_util.EzPickle.__dict__.update", "type"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "__setstate__", "(", "self", ",", "d", ")", ":", "\n", "        ", "out", "=", "type", "(", "self", ")", "(", "*", "d", "[", "\"_ezpickle_args\"", "]", ",", "**", "d", "[", "\"_ezpickle_kwargs\"", "]", ")", "\n", "self", ".", "__dict__", ".", "update", "(", "out", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.RunningAvg.__init__": [[108, 122], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "gamma", ",", "init_value", "=", "None", ")", ":", "\n", "        ", "\"\"\"Keep a running estimate of a quantity. This is a bit like mean\n        but more sensitive to recent changes.\n\n        Parameters\n        ----------\n        gamma: float\n            Must be between 0 and 1, where 0 is the most sensitive to recent\n            changes.\n        init_value: float or None\n            Initial value of the estimate. If None, it will be set on the first update.\n        \"\"\"", "\n", "self", ".", "_value", "=", "init_value", "\n", "self", ".", "_gamma", "=", "gamma", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.RunningAvg.update": [[123, 135], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "new_val", ")", ":", "\n", "        ", "\"\"\"Update the estimate.\n\n        Parameters\n        ----------\n        new_val: float\n            new observated value of estimated quantity.\n        \"\"\"", "\n", "if", "self", ".", "_value", "is", "None", ":", "\n", "            ", "self", ".", "_value", "=", "new_val", "\n", "", "else", ":", "\n", "            ", "self", ".", "_value", "=", "self", ".", "_gamma", "*", "self", ".", "_value", "+", "(", "1.0", "-", "self", ".", "_gamma", ")", "*", "new_val", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.RunningAvg.__float__": [[136, 139], ["None"], "methods", ["None"], ["", "", "def", "__float__", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get the current estimate\"\"\"", "\n", "return", "self", ".", "_value", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.zipsame": [[10, 14], ["len", "all", "zip", "len"], "function", ["None"], ["def", "zipsame", "(", "*", "seqs", ")", ":", "\n", "    ", "L", "=", "len", "(", "seqs", "[", "0", "]", ")", "\n", "assert", "all", "(", "len", "(", "seq", ")", "==", "L", "for", "seq", "in", "seqs", "[", "1", ":", "]", ")", "\n", "return", "zip", "(", "*", "seqs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.set_global_seeds": [[48, 63], ["numpy.random.seed", "random.seed", "MPI.COMM_WORLD.Get_rank", "tf.set_random_seed"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed"], ["", "", "def", "set_global_seeds", "(", "i", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "import", "MPI", "\n", "rank", "=", "MPI", ".", "COMM_WORLD", ".", "Get_rank", "(", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "rank", "=", "0", "\n", "\n", "", "myseed", "=", "i", "+", "1000", "*", "rank", "if", "i", "is", "not", "None", "else", "None", "\n", "try", ":", "\n", "        ", "import", "tensorflow", "as", "tf", "\n", "tf", ".", "set_random_seed", "(", "myseed", ")", "\n", "", "except", "ImportError", ":", "\n", "        ", "pass", "\n", "", "np", ".", "random", ".", "seed", "(", "myseed", ")", "\n", "random", ".", "seed", "(", "myseed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.pretty_eta": [[65, 105], ["misc_util.pretty_eta.helper"], "function", ["None"], ["", "def", "pretty_eta", "(", "seconds_left", ")", ":", "\n", "    ", "\"\"\"Print the number of seconds in human readable format.\n\n    Examples:\n    2 days\n    2 hours and 37 minutes\n    less than a minute\n\n    Paramters\n    ---------\n    seconds_left: int\n        Number of seconds to be converted to the ETA\n    Returns\n    -------\n    eta: str\n        String representing the pretty ETA.\n    \"\"\"", "\n", "minutes_left", "=", "seconds_left", "//", "60", "\n", "seconds_left", "%=", "60", "\n", "hours_left", "=", "minutes_left", "//", "60", "\n", "minutes_left", "%=", "60", "\n", "days_left", "=", "hours_left", "//", "24", "\n", "hours_left", "%=", "24", "\n", "\n", "def", "helper", "(", "cnt", ",", "name", ")", ":", "\n", "        ", "return", "\"{} {}{}\"", ".", "format", "(", "str", "(", "cnt", ")", ",", "name", ",", "(", "'s'", "if", "cnt", ">", "1", "else", "''", ")", ")", "\n", "\n", "", "if", "days_left", ">", "0", ":", "\n", "        ", "msg", "=", "helper", "(", "days_left", ",", "'day'", ")", "\n", "if", "hours_left", ">", "0", ":", "\n", "            ", "msg", "+=", "' and '", "+", "helper", "(", "hours_left", ",", "'hour'", ")", "\n", "", "return", "msg", "\n", "", "if", "hours_left", ">", "0", ":", "\n", "        ", "msg", "=", "helper", "(", "hours_left", ",", "'hour'", ")", "\n", "if", "minutes_left", ">", "0", ":", "\n", "            ", "msg", "+=", "' and '", "+", "helper", "(", "minutes_left", ",", "'minute'", ")", "\n", "", "return", "msg", "\n", "", "if", "minutes_left", ">", "0", ":", "\n", "        ", "return", "helper", "(", "minutes_left", ",", "'minute'", ")", "\n", "", "return", "'less than a minute'", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.boolean_flag": [[140, 157], ["name.replace", "parser.add_argument", "parser.add_argument"], "function", ["None"], ["", "", "def", "boolean_flag", "(", "parser", ",", "name", ",", "default", "=", "False", ",", "help", "=", "None", ")", ":", "\n", "    ", "\"\"\"Add a boolean flag to argparse parser.\n\n    Parameters\n    ----------\n    parser: argparse.Parser\n        parser to add the flag to\n    name: str\n        --<name> will enable the flag, while --no-<name> will disable it\n    default: bool or None\n        default value of the flag\n    help: str\n        help string for the flag\n    \"\"\"", "\n", "dest", "=", "name", ".", "replace", "(", "'-'", ",", "'_'", ")", "\n", "parser", ".", "add_argument", "(", "\"--\"", "+", "name", ",", "action", "=", "\"store_true\"", ",", "default", "=", "default", ",", "dest", "=", "dest", ",", "help", "=", "help", ")", "\n", "parser", ".", "add_argument", "(", "\"--no-\"", "+", "name", ",", "action", "=", "\"store_false\"", ",", "dest", "=", "dest", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.get_wrapper_by_name": [[159, 183], ["currentenv.class_name", "isinstance", "ValueError"], "function", ["None"], ["", "def", "get_wrapper_by_name", "(", "env", ",", "classname", ")", ":", "\n", "    ", "\"\"\"Given an a gym environment possibly wrapped multiple times, returns a wrapper\n    of class named classname or raises ValueError if no such wrapper was applied\n\n    Parameters\n    ----------\n    env: gym.Env of gym.Wrapper\n        gym environment\n    classname: str\n        name of the wrapper\n\n    Returns\n    -------\n    wrapper: gym.Wrapper\n        wrapper named classname\n    \"\"\"", "\n", "currentenv", "=", "env", "\n", "while", "True", ":", "\n", "        ", "if", "classname", "==", "currentenv", ".", "class_name", "(", ")", ":", "\n", "            ", "return", "currentenv", "\n", "", "elif", "isinstance", "(", "currentenv", ",", "gym", ".", "Wrapper", ")", ":", "\n", "            ", "currentenv", "=", "currentenv", ".", "env", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"Couldn't find wrapper named %s\"", "%", "classname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.relatively_safe_pickle_dump": [[185, 219], ["os.rename", "tempfile.NamedTemporaryFile", "pickle.dump", "uncompressed_file.file.flush", "open", "pickle.dump", "zipfile.ZipFile", "myzip.write"], "function", ["None"], ["", "", "", "def", "relatively_safe_pickle_dump", "(", "obj", ",", "path", ",", "compression", "=", "False", ")", ":", "\n", "    ", "\"\"\"This is just like regular pickle dump, except from the fact that failure cases are\n    different:\n\n        - It's never possible that we end up with a pickle in corrupted state.\n        - If a there was a different file at the path, that file will remain unchanged in the\n          even of failure (provided that filesystem rename is atomic).\n        - it is sometimes possible that we end up with useless temp file which needs to be\n          deleted manually (it will be removed automatically on the next function call)\n\n    The indended use case is periodic checkpoints of experiment state, such that we never\n    corrupt previous checkpoints if the current one fails.\n\n    Parameters\n    ----------\n    obj: object\n        object to pickle\n    path: str\n        path to the output file\n    compression: bool\n        if true pickle will be compressed\n    \"\"\"", "\n", "temp_storage", "=", "path", "+", "\".relatively_safe\"", "\n", "if", "compression", ":", "\n", "# Using gzip here would be simpler, but the size is limited to 2GB", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "uncompressed_file", ":", "\n", "            ", "pickle", ".", "dump", "(", "obj", ",", "uncompressed_file", ")", "\n", "uncompressed_file", ".", "file", ".", "flush", "(", ")", "\n", "with", "zipfile", ".", "ZipFile", "(", "temp_storage", ",", "\"w\"", ",", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ")", "as", "myzip", ":", "\n", "                ", "myzip", ".", "write", "(", "uncompressed_file", ".", "name", ",", "\"data\"", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "temp_storage", ",", "\"wb\"", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "obj", ",", "f", ")", "\n", "", "", "os", ".", "rename", "(", "temp_storage", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.misc_util.pickle_load": [[221, 244], ["zipfile.ZipFile", "open", "pickle.load", "myzip.open", "pickle.load"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load"], ["", "def", "pickle_load", "(", "path", ",", "compression", "=", "False", ")", ":", "\n", "    ", "\"\"\"Unpickle a possible compressed pickle.\n\n    Parameters\n    ----------\n    path: str\n        path to the output file\n    compression: bool\n        if true assumes that pickle was compressed when created and attempts decompression.\n\n    Returns\n    -------\n    obj: object\n        the unpickled object\n    \"\"\"", "\n", "\n", "if", "compression", ":", "\n", "        ", "with", "zipfile", ".", "ZipFile", "(", "path", ",", "\"r\"", ",", "compression", "=", "zipfile", ".", "ZIP_DEFLATED", ")", "as", "myzip", ":", "\n", "            ", "with", "myzip", ".", "open", "(", "\"data\"", ")", "as", "f", ":", "\n", "                ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.RunningMeanStd.__init__": [[7, 11], ["numpy.zeros", "numpy.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "epsilon", "=", "1e-4", ",", "shape", "=", "(", ")", ")", ":", "\n", "        ", "self", ".", "mean", "=", "np", ".", "zeros", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "var", "=", "np", ".", "ones", "(", "shape", ",", "'float64'", ")", "\n", "self", ".", "count", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.RunningMeanStd.update": [[12, 17], ["numpy.mean", "numpy.var", "running_mean_std.RunningMeanStd.update_from_moments"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.RunningMeanStd.update_from_moments"], ["", "def", "update", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_mean", "=", "np", ".", "mean", "(", "x", ",", "axis", "=", "0", ")", "\n", "batch_var", "=", "np", ".", "var", "(", "x", ",", "axis", "=", "0", ")", "\n", "batch_count", "=", "x", ".", "shape", "[", "0", "]", "\n", "self", ".", "update_from_moments", "(", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.RunningMeanStd.update_from_moments": [[18, 21], ["running_mean_std.update_mean_var_count_from_moments"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.update_mean_var_count_from_moments"], ["", "def", "update_from_moments", "(", "self", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", ":", "\n", "        ", "self", ".", "mean", ",", "self", ".", "var", ",", "self", ".", "count", "=", "update_mean_var_count_from_moments", "(", "\n", "self", ".", "mean", ",", "self", ".", "var", ",", "self", ".", "count", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.TfRunningMeanStd.__init__": [[42, 64], ["baselines.common.tf_util.get_session", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.group", "baselines.common.tf_util.get_session.run", "running_mean_std.TfRunningMeanStd._set_mean_var_count", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.variables_initializer", "running_mean_std.TfRunningMeanStd._var.assign", "running_mean_std.TfRunningMeanStd._mean.assign", "running_mean_std.TfRunningMeanStd._count.assign", "numpy.zeros", "numpy.ones", "numpy.full"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.TfRunningMeanStd._set_mean_var_count", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.her.replay_buffer.ReplayBuffer.full"], ["def", "__init__", "(", "self", ",", "epsilon", "=", "1e-4", ",", "shape", "=", "(", ")", ",", "scope", "=", "''", ")", ":", "\n", "        ", "sess", "=", "get_session", "(", ")", "\n", "\n", "self", ".", "_new_mean", "=", "tf", ".", "placeholder", "(", "shape", "=", "shape", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "self", ".", "_new_var", "=", "tf", ".", "placeholder", "(", "shape", "=", "shape", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "self", ".", "_new_count", "=", "tf", ".", "placeholder", "(", "shape", "=", "(", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "scope", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ")", ":", "\n", "            ", "self", ".", "_mean", "=", "tf", ".", "get_variable", "(", "'mean'", ",", "initializer", "=", "np", ".", "zeros", "(", "shape", ",", "'float64'", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "self", ".", "_var", "=", "tf", ".", "get_variable", "(", "'std'", ",", "initializer", "=", "np", ".", "ones", "(", "shape", ",", "'float64'", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "self", ".", "_count", "=", "tf", ".", "get_variable", "(", "'count'", ",", "initializer", "=", "np", ".", "full", "(", "(", ")", ",", "epsilon", ",", "'float64'", ")", ",", "dtype", "=", "tf", ".", "float64", ")", "\n", "\n", "", "self", ".", "update_ops", "=", "tf", ".", "group", "(", "[", "\n", "self", ".", "_var", ".", "assign", "(", "self", ".", "_new_var", ")", ",", "\n", "self", ".", "_mean", ".", "assign", "(", "self", ".", "_new_mean", ")", ",", "\n", "self", ".", "_count", ".", "assign", "(", "self", ".", "_new_count", ")", "\n", "]", ")", "\n", "\n", "sess", ".", "run", "(", "tf", ".", "variables_initializer", "(", "[", "self", ".", "_mean", ",", "self", ".", "_var", ",", "self", ".", "_count", "]", ")", ")", "\n", "self", ".", "sess", "=", "sess", "\n", "self", ".", "_set_mean_var_count", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.TfRunningMeanStd._set_mean_var_count": [[65, 67], ["running_mean_std.TfRunningMeanStd.sess.run"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "_set_mean_var_count", "(", "self", ")", ":", "\n", "        ", "self", ".", "mean", ",", "self", ".", "var", ",", "self", ".", "count", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "_mean", ",", "self", ".", "_var", ",", "self", ".", "_count", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.TfRunningMeanStd.update": [[68, 82], ["numpy.mean", "numpy.var", "running_mean_std.update_mean_var_count_from_moments", "running_mean_std.TfRunningMeanStd.sess.run", "running_mean_std.TfRunningMeanStd._set_mean_var_count"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.update_mean_var_count_from_moments", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.TfRunningMeanStd._set_mean_var_count"], ["", "def", "update", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_mean", "=", "np", ".", "mean", "(", "x", ",", "axis", "=", "0", ")", "\n", "batch_var", "=", "np", ".", "var", "(", "x", ",", "axis", "=", "0", ")", "\n", "batch_count", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "new_mean", ",", "new_var", ",", "new_count", "=", "update_mean_var_count_from_moments", "(", "self", ".", "mean", ",", "self", ".", "var", ",", "self", ".", "count", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", "\n", "\n", "self", ".", "sess", ".", "run", "(", "self", ".", "update_ops", ",", "feed_dict", "=", "{", "\n", "self", ".", "_new_mean", ":", "new_mean", ",", "\n", "self", ".", "_new_var", ":", "new_var", ",", "\n", "self", ".", "_new_count", ":", "new_count", "\n", "}", ")", "\n", "\n", "self", ".", "_set_mean_var_count", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.update_mean_var_count_from_moments": [[22, 34], ["numpy.square"], "function", ["None"], ["", "", "def", "update_mean_var_count_from_moments", "(", "mean", ",", "var", ",", "count", ",", "batch_mean", ",", "batch_var", ",", "batch_count", ")", ":", "\n", "    ", "delta", "=", "batch_mean", "-", "mean", "\n", "tot_count", "=", "count", "+", "batch_count", "\n", "\n", "new_mean", "=", "mean", "+", "delta", "*", "batch_count", "/", "tot_count", "\n", "m_a", "=", "var", "*", "count", "\n", "m_b", "=", "batch_var", "*", "batch_count", "\n", "M2", "=", "m_a", "+", "m_b", "+", "np", ".", "square", "(", "delta", ")", "*", "count", "*", "batch_count", "/", "tot_count", "\n", "new_var", "=", "M2", "/", "tot_count", "\n", "new_count", "=", "tot_count", "\n", "\n", "return", "new_mean", ",", "new_var", ",", "new_count", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.test_runningmeanstd": [[85, 101], ["running_mean_std.RunningMeanStd", "numpy.concatenate", "running_mean_std.RunningMeanStd.update", "running_mean_std.RunningMeanStd.update", "running_mean_std.RunningMeanStd.update", "numpy.testing.assert_allclose", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "np.concatenate.mean", "np.concatenate.var"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "def", "test_runningmeanstd", "(", ")", ":", "\n", "    ", "for", "(", "x1", ",", "x2", ",", "x3", ")", "in", "[", "\n", "(", "np", ".", "random", ".", "randn", "(", "3", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ")", ")", ",", "\n", "(", "np", ".", "random", ".", "randn", "(", "3", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ",", "2", ")", ")", ",", "\n", "]", ":", "\n", "\n", "        ", "rms", "=", "RunningMeanStd", "(", "epsilon", "=", "0.0", ",", "shape", "=", "x1", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n", "x", "=", "np", ".", "concatenate", "(", "[", "x1", ",", "x2", ",", "x3", "]", ",", "axis", "=", "0", ")", "\n", "ms1", "=", "[", "x", ".", "mean", "(", "axis", "=", "0", ")", ",", "x", ".", "var", "(", "axis", "=", "0", ")", "]", "\n", "rms", ".", "update", "(", "x1", ")", "\n", "rms", ".", "update", "(", "x2", ")", "\n", "rms", ".", "update", "(", "x3", ")", "\n", "ms2", "=", "[", "rms", ".", "mean", ",", "rms", ".", "var", "]", "\n", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "ms1", ",", "ms2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.test_tf_runningmeanstd": [[102, 118], ["running_mean_std.TfRunningMeanStd", "numpy.concatenate", "running_mean_std.TfRunningMeanStd.update", "running_mean_std.TfRunningMeanStd.update", "running_mean_std.TfRunningMeanStd.update", "numpy.testing.assert_allclose", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "np.concatenate.mean", "np.concatenate.var", "str", "numpy.random.randint"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "def", "test_tf_runningmeanstd", "(", ")", ":", "\n", "    ", "for", "(", "x1", ",", "x2", ",", "x3", ")", "in", "[", "\n", "(", "np", ".", "random", ".", "randn", "(", "3", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ")", ")", ",", "\n", "(", "np", ".", "random", ".", "randn", "(", "3", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ",", "2", ")", ")", ",", "\n", "]", ":", "\n", "\n", "        ", "rms", "=", "TfRunningMeanStd", "(", "epsilon", "=", "0.0", ",", "shape", "=", "x1", ".", "shape", "[", "1", ":", "]", ",", "scope", "=", "'running_mean_std'", "+", "str", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "128", ")", ")", ")", "\n", "\n", "x", "=", "np", ".", "concatenate", "(", "[", "x1", ",", "x2", ",", "x3", "]", ",", "axis", "=", "0", ")", "\n", "ms1", "=", "[", "x", ".", "mean", "(", "axis", "=", "0", ")", ",", "x", ".", "var", "(", "axis", "=", "0", ")", "]", "\n", "rms", ".", "update", "(", "x1", ")", "\n", "rms", ".", "update", "(", "x2", ")", "\n", "rms", ".", "update", "(", "x3", ")", "\n", "ms2", "=", "[", "rms", ".", "mean", ",", "rms", ".", "var", "]", "\n", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "ms1", ",", "ms2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.running_mean_std.profile_tf_runningmeanstd": [[120, 183], ["tf_util.get_session", "numpy.random.random", "running_mean_std.RunningMeanStd", "running_mean_std.TfRunningMeanStd", "time.time", "range", "time.time", "range", "time.time", "print", "print", "time.time", "range", "time.time", "range", "time.time", "print", "print", "running_mean_std.RunningMeanStd.update", "running_mean_std.TfRunningMeanStd.update", "tensorflow.ConfigProto"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "", "def", "profile_tf_runningmeanstd", "(", ")", ":", "\n", "    ", "import", "time", "\n", "from", "baselines", ".", "common", "import", "tf_util", "\n", "\n", "tf_util", ".", "get_session", "(", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "inter_op_parallelism_threads", "=", "1", ",", "\n", "intra_op_parallelism_threads", "=", "1", ",", "\n", "allow_soft_placement", "=", "True", "\n", ")", ")", "\n", "\n", "x", "=", "np", ".", "random", ".", "random", "(", "(", "376", ",", ")", ")", "\n", "\n", "n_trials", "=", "10000", "\n", "rms", "=", "RunningMeanStd", "(", ")", "\n", "tfrms", "=", "TfRunningMeanStd", "(", ")", "\n", "\n", "tic1", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "n_trials", ")", ":", "\n", "        ", "rms", ".", "update", "(", "x", ")", "\n", "\n", "", "tic2", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "n_trials", ")", ":", "\n", "        ", "tfrms", ".", "update", "(", "x", ")", "\n", "\n", "", "tic3", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'rms update time ({} trials): {} s'", ".", "format", "(", "n_trials", ",", "tic2", "-", "tic1", ")", ")", "\n", "print", "(", "'tfrms update time ({} trials): {} s'", ".", "format", "(", "n_trials", ",", "tic3", "-", "tic2", ")", ")", "\n", "\n", "\n", "tic1", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "n_trials", ")", ":", "\n", "        ", "z1", "=", "rms", ".", "mean", "\n", "\n", "", "tic2", "=", "time", ".", "time", "(", ")", "\n", "for", "_", "in", "range", "(", "n_trials", ")", ":", "\n", "        ", "z2", "=", "tfrms", ".", "mean", "\n", "\n", "", "assert", "z1", "==", "z2", "\n", "\n", "tic3", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'rms get mean time ({} trials): {} s'", ".", "format", "(", "n_trials", ",", "tic2", "-", "tic1", ")", ")", "\n", "print", "(", "'tfrms get mean time ({} trials): {} s'", ".", "format", "(", "n_trials", ",", "tic3", "-", "tic2", ")", ")", "\n", "\n", "\n", "\n", "'''\n    options = tf.RunOptions(trace_level=tf.RunOptions.FULL_TRACE) #pylint: disable=E1101\n    run_metadata = tf.RunMetadata()\n    profile_opts = dict(options=options, run_metadata=run_metadata)\n\n\n\n    from tensorflow.python.client import timeline\n    fetched_timeline = timeline.Timeline(run_metadata.step_stats) #pylint: disable=E1101\n    chrome_trace = fetched_timeline.generate_chrome_trace_format()\n    outfile = '/tmp/timeline.json'\n    with open(outfile, 'wt') as f:\n        f.write(chrome_trace)\n    print('Successfully saved profile to {}. Exiting.'.format(outfile))\n    exit(0)\n    '''", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.__init__": [[5, 35], ["range"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ",", "operation", ",", "neutral_element", ")", ":", "\n", "        ", "\"\"\"Build a Segment Tree data structure.\n\n        https://en.wikipedia.org/wiki/Segment_tree\n\n        Can be used as regular array, but with two\n        important differences:\n\n            a) setting item's value is slightly slower.\n               It is O(lg capacity) instead of O(1).\n            b) user has access to an efficient ( O(log segment size) )\n               `reduce` operation which reduces `operation` over\n               a contiguous subsequence of items in the array.\n\n        Paramters\n        ---------\n        capacity: int\n            Total size of the array - must be a power of two.\n        operation: lambda obj, obj -> obj\n            and operation for combining elements (eg. sum, max)\n            must form a mathematical group together with the set of\n            possible values for array elements (i.e. be associative)\n        neutral_element: obj\n            neutral element for the operation above. eg. float('-inf')\n            for max and 0 for sum.\n        \"\"\"", "\n", "assert", "capacity", ">", "0", "and", "capacity", "&", "(", "capacity", "-", "1", ")", "==", "0", ",", "\"capacity must be positive and a power of 2.\"", "\n", "self", ".", "_capacity", "=", "capacity", "\n", "self", ".", "_value", "=", "[", "neutral_element", "for", "_", "in", "range", "(", "2", "*", "capacity", ")", "]", "\n", "self", ".", "_operation", "=", "operation", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree._reduce_helper": [[36, 49], ["segment_tree.SegmentTree._reduce_helper", "segment_tree.SegmentTree._reduce_helper", "segment_tree.SegmentTree._operation", "segment_tree.SegmentTree._reduce_helper", "segment_tree.SegmentTree._reduce_helper"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree._reduce_helper", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree._reduce_helper", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree._reduce_helper", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree._reduce_helper"], ["", "def", "_reduce_helper", "(", "self", ",", "start", ",", "end", ",", "node", ",", "node_start", ",", "node_end", ")", ":", "\n", "        ", "if", "start", "==", "node_start", "and", "end", "==", "node_end", ":", "\n", "            ", "return", "self", ".", "_value", "[", "node", "]", "\n", "", "mid", "=", "(", "node_start", "+", "node_end", ")", "//", "2", "\n", "if", "end", "<=", "mid", ":", "\n", "            ", "return", "self", ".", "_reduce_helper", "(", "start", ",", "end", ",", "2", "*", "node", ",", "node_start", ",", "mid", ")", "\n", "", "else", ":", "\n", "            ", "if", "mid", "+", "1", "<=", "start", ":", "\n", "                ", "return", "self", ".", "_reduce_helper", "(", "start", ",", "end", ",", "2", "*", "node", "+", "1", ",", "mid", "+", "1", ",", "node_end", ")", "\n", "", "else", ":", "\n", "                ", "return", "self", ".", "_operation", "(", "\n", "self", ".", "_reduce_helper", "(", "start", ",", "mid", ",", "2", "*", "node", ",", "node_start", ",", "mid", ")", ",", "\n", "self", ".", "_reduce_helper", "(", "mid", "+", "1", ",", "end", ",", "2", "*", "node", "+", "1", ",", "mid", "+", "1", ",", "node_end", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce": [[51, 75], ["segment_tree.SegmentTree._reduce_helper"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree._reduce_helper"], ["", "", "", "def", "reduce", "(", "self", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns result of applying `self.operation`\n        to a contiguous subsequence of the array.\n\n            self.operation(arr[start], operation(arr[start+1], operation(... arr[end])))\n\n        Parameters\n        ----------\n        start: int\n            beginning of the subsequence\n        end: int\n            end of the subsequences\n\n        Returns\n        -------\n        reduced: obj\n            result of reducing self.operation over the specified range of array elements.\n        \"\"\"", "\n", "if", "end", "is", "None", ":", "\n", "            ", "end", "=", "self", ".", "_capacity", "\n", "", "if", "end", "<", "0", ":", "\n", "            ", "end", "+=", "self", ".", "_capacity", "\n", "", "end", "-=", "1", "\n", "return", "self", ".", "_reduce_helper", "(", "start", ",", "end", ",", "1", ",", "0", ",", "self", ".", "_capacity", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.__setitem__": [[76, 87], ["segment_tree.SegmentTree._operation"], "methods", ["None"], ["", "def", "__setitem__", "(", "self", ",", "idx", ",", "val", ")", ":", "\n", "# index of the leaf", "\n", "        ", "idx", "+=", "self", ".", "_capacity", "\n", "self", ".", "_value", "[", "idx", "]", "=", "val", "\n", "idx", "//=", "2", "\n", "while", "idx", ">=", "1", ":", "\n", "            ", "self", ".", "_value", "[", "idx", "]", "=", "self", ".", "_operation", "(", "\n", "self", ".", "_value", "[", "2", "*", "idx", "]", ",", "\n", "self", ".", "_value", "[", "2", "*", "idx", "+", "1", "]", "\n", ")", "\n", "idx", "//=", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.__getitem__": [[88, 91], ["None"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "assert", "0", "<=", "idx", "<", "self", ".", "_capacity", "\n", "return", "self", ".", "_value", "[", "self", ".", "_capacity", "+", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.__init__": [[94, 99], ["segment_tree.SegmentTree.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "        ", "super", "(", "SumSegmentTree", ",", "self", ")", ".", "__init__", "(", "\n", "capacity", "=", "capacity", ",", "\n", "operation", "=", "operator", ".", "add", ",", "\n", "neutral_element", "=", "0.0", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum": [[101, 104], ["segment_tree.SegmentTree.reduce"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce"], ["", "def", "sum", "(", "self", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns arr[start] + ... + arr[end]\"\"\"", "\n", "return", "super", "(", "SumSegmentTree", ",", "self", ")", ".", "reduce", "(", "start", ",", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx": [[105, 132], ["segment_tree.SumSegmentTree.sum"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "find_prefixsum_idx", "(", "self", ",", "prefixsum", ")", ":", "\n", "        ", "\"\"\"Find the highest index `i` in the array such that\n            sum(arr[0] + arr[1] + ... + arr[i - i]) <= prefixsum\n\n        if array values are probabilities, this function\n        allows to sample indexes according to the discrete\n        probability efficiently.\n\n        Parameters\n        ----------\n        perfixsum: float\n            upperbound on the sum of array prefix\n\n        Returns\n        -------\n        idx: int\n            highest index satisfying the prefixsum constraint\n        \"\"\"", "\n", "assert", "0", "<=", "prefixsum", "<=", "self", ".", "sum", "(", ")", "+", "1e-5", "\n", "idx", "=", "1", "\n", "while", "idx", "<", "self", ".", "_capacity", ":", "# while non-leaf", "\n", "            ", "if", "self", ".", "_value", "[", "2", "*", "idx", "]", ">", "prefixsum", ":", "\n", "                ", "idx", "=", "2", "*", "idx", "\n", "", "else", ":", "\n", "                ", "prefixsum", "-=", "self", ".", "_value", "[", "2", "*", "idx", "]", "\n", "idx", "=", "2", "*", "idx", "+", "1", "\n", "", "", "return", "idx", "-", "self", ".", "_capacity", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.__init__": [[135, 140], ["segment_tree.SegmentTree.__init__", "float"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "capacity", ")", ":", "\n", "        ", "super", "(", "MinSegmentTree", ",", "self", ")", ".", "__init__", "(", "\n", "capacity", "=", "capacity", ",", "\n", "operation", "=", "min", ",", "\n", "neutral_element", "=", "float", "(", "'inf'", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min": [[142, 146], ["segment_tree.SegmentTree.reduce"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SegmentTree.reduce"], ["", "def", "min", "(", "self", ",", "start", "=", "0", ",", "end", "=", "None", ")", ":", "\n", "        ", "\"\"\"Returns min(arr[start], ...,  arr[end])\"\"\"", "\n", "\n", "return", "super", "(", "MinSegmentTree", ",", "self", ")", ".", "reduce", "(", "start", ",", "end", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.sync_from_root": [[15, 27], ["comm.bcast", "sess.run", "sess.run", "tf.assign", "zip"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "sync_from_root", "(", "sess", ",", "variables", ",", "comm", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Send the root node's parameters to every worker.\n    Arguments:\n      sess: the TensorFlow session.\n      variables: all parameter variables including optimizer's\n    \"\"\"", "\n", "if", "comm", "is", "None", ":", "comm", "=", "MPI", ".", "COMM_WORLD", "\n", "import", "tensorflow", "as", "tf", "\n", "values", "=", "comm", ".", "bcast", "(", "sess", ".", "run", "(", "variables", ")", ")", "\n", "sess", ".", "run", "(", "[", "tf", ".", "assign", "(", "var", ",", "val", ")", "\n", "for", "(", "var", ",", "val", ")", "in", "zip", "(", "variables", ",", "values", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.gpu_count": [[28, 36], ["subprocess.check_output", "max", "shutil.which", "len", "subprocess.check_output.split"], "function", ["None"], ["", "def", "gpu_count", "(", ")", ":", "\n", "    ", "\"\"\"\n    Count the GPUs on this machine.\n    \"\"\"", "\n", "if", "shutil", ".", "which", "(", "'nvidia-smi'", ")", "is", "None", ":", "\n", "        ", "return", "0", "\n", "", "output", "=", "subprocess", ".", "check_output", "(", "[", "'nvidia-smi'", ",", "'--query-gpu=gpu_name'", ",", "'--format=csv'", "]", ")", "\n", "return", "max", "(", "0", ",", "len", "(", "output", ".", "split", "(", "b'\\n'", ")", ")", "-", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.setup_mpi_gpus": [[37, 48], ["mpi_util.get_local_rank_size", "map"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.get_local_rank_size"], ["", "def", "setup_mpi_gpus", "(", ")", ":", "\n", "    ", "\"\"\"\n    Set CUDA_VISIBLE_DEVICES to MPI rank if not already set\n    \"\"\"", "\n", "if", "'CUDA_VISIBLE_DEVICES'", "not", "in", "os", ".", "environ", ":", "\n", "        ", "if", "sys", ".", "platform", "==", "'darwin'", ":", "# This Assumes if you're on OSX you're just", "\n", "            ", "ids", "=", "[", "]", "# doing a smoke test and don't want GPUs", "\n", "", "else", ":", "\n", "            ", "lrank", ",", "_lsize", "=", "get_local_rank_size", "(", "MPI", ".", "COMM_WORLD", ")", "\n", "ids", "=", "[", "lrank", "]", "\n", "", "os", ".", "environ", "[", "\"CUDA_VISIBLE_DEVICES\"", "]", "=", "\",\"", ".", "join", "(", "map", "(", "str", ",", "ids", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.get_local_rank_size": [[49, 68], ["platform.node", "comm.allgather", "collections.defaultdict", "comm.Get_rank", "comm.Get_rank"], "function", ["None"], ["", "", "def", "get_local_rank_size", "(", "comm", ")", ":", "\n", "    ", "\"\"\"\n    Returns the rank of each process on its machine\n    The processes on a given machine will be assigned ranks\n        0, 1, 2, ..., N-1,\n    where N is the number of processes on this machine.\n\n    Useful if you want to assign one gpu per machine\n    \"\"\"", "\n", "this_node", "=", "platform", ".", "node", "(", ")", "\n", "ranks_nodes", "=", "comm", ".", "allgather", "(", "(", "comm", ".", "Get_rank", "(", ")", ",", "this_node", ")", ")", "\n", "node2rankssofar", "=", "defaultdict", "(", "int", ")", "\n", "local_rank", "=", "None", "\n", "for", "(", "rank", ",", "node", ")", "in", "ranks_nodes", ":", "\n", "        ", "if", "rank", "==", "comm", ".", "Get_rank", "(", ")", ":", "\n", "            ", "local_rank", "=", "node2rankssofar", "[", "node", "]", "\n", "", "node2rankssofar", "[", "node", "]", "+=", "1", "\n", "", "assert", "local_rank", "is", "not", "None", "\n", "return", "local_rank", ",", "node2rankssofar", "[", "this_node", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.share_file": [[69, 86], ["mpi_util.get_local_rank_size", "comm.Barrier", "comm.Get_rank", "comm.bcast", "comm.bcast", "open", "fh.read", "os.makedirs", "os.path.dirname", "open", "fh.write"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.get_local_rank_size"], ["", "def", "share_file", "(", "comm", ",", "path", ")", ":", "\n", "    ", "\"\"\"\n    Copies the file from rank 0 to all other ranks\n    Puts it in the same place on all machines\n    \"\"\"", "\n", "localrank", ",", "_", "=", "get_local_rank_size", "(", "comm", ")", "\n", "if", "comm", ".", "Get_rank", "(", ")", "==", "0", ":", "\n", "        ", "with", "open", "(", "path", ",", "'rb'", ")", "as", "fh", ":", "\n", "            ", "data", "=", "fh", ".", "read", "(", ")", "\n", "", "comm", ".", "bcast", "(", "data", ")", "\n", "", "else", ":", "\n", "        ", "data", "=", "comm", ".", "bcast", "(", "None", ")", "\n", "if", "localrank", "==", "0", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "path", ")", ",", "exist_ok", "=", "True", ")", "\n", "with", "open", "(", "path", ",", "'wb'", ")", "as", "fh", ":", "\n", "                ", "fh", ".", "write", "(", "data", ")", "\n", "", "", "", "comm", ".", "Barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.dict_gather": [[87, 109], ["comm.allgather", "collections.defaultdict", "collections.defaultdict.items", "d.items", "k2li[].append", "numpy.mean", "len", "numpy.sum", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "dict_gather", "(", "comm", ",", "d", ",", "op", "=", "'mean'", ",", "assert_all_have_data", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Perform a reduction operation over dicts\n    \"\"\"", "\n", "if", "comm", "is", "None", ":", "return", "d", "\n", "alldicts", "=", "comm", ".", "allgather", "(", "d", ")", "\n", "size", "=", "comm", ".", "size", "\n", "k2li", "=", "defaultdict", "(", "list", ")", "\n", "for", "d", "in", "alldicts", ":", "\n", "        ", "for", "(", "k", ",", "v", ")", "in", "d", ".", "items", "(", ")", ":", "\n", "            ", "k2li", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "", "", "result", "=", "{", "}", "\n", "for", "(", "k", ",", "li", ")", "in", "k2li", ".", "items", "(", ")", ":", "\n", "        ", "if", "assert_all_have_data", ":", "\n", "            ", "assert", "len", "(", "li", ")", "==", "size", ",", "\"only %i out of %i MPI workers have sent '%s'\"", "%", "(", "len", "(", "li", ")", ",", "size", ",", "k", ")", "\n", "", "if", "op", "==", "'mean'", ":", "\n", "            ", "result", "[", "k", "]", "=", "np", ".", "mean", "(", "li", ",", "axis", "=", "0", ")", "\n", "", "elif", "op", "==", "'sum'", ":", "\n", "            ", "result", "[", "k", "]", "=", "np", ".", "sum", "(", "li", ",", "axis", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "assert", "0", ",", "op", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.mpi_weighted_mean": [[110, 133], ["comm.gather", "collections.defaultdict", "collections.defaultdict", "n2vc.items", "float", "warnings.warn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn"], ["", "def", "mpi_weighted_mean", "(", "comm", ",", "local_name2valcount", ")", ":", "\n", "    ", "\"\"\"\n    Perform a weighted average over dicts that are each on a different node\n    Input: local_name2valcount: dict mapping key -> (value, count)\n    Returns: key -> mean\n    \"\"\"", "\n", "all_name2valcount", "=", "comm", ".", "gather", "(", "local_name2valcount", ")", "\n", "if", "comm", ".", "rank", "==", "0", ":", "\n", "        ", "name2sum", "=", "defaultdict", "(", "float", ")", "\n", "name2count", "=", "defaultdict", "(", "float", ")", "\n", "for", "n2vc", "in", "all_name2valcount", ":", "\n", "            ", "for", "(", "name", ",", "(", "val", ",", "count", ")", ")", "in", "n2vc", ".", "items", "(", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "val", "=", "float", "(", "val", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "if", "comm", ".", "rank", "==", "0", ":", "\n", "                        ", "warnings", ".", "warn", "(", "'WARNING: tried to compute mean on non-float {}={}'", ".", "format", "(", "name", ",", "val", ")", ")", "\n", "", "", "else", ":", "\n", "                    ", "name2sum", "[", "name", "]", "+=", "val", "*", "count", "\n", "name2count", "[", "name", "]", "+=", "count", "\n", "", "", "", "return", "{", "name", ":", "name2sum", "[", "name", "]", "/", "name2count", "[", "name", "]", "for", "name", "in", "name2sum", "}", "\n", "", "else", ":", "\n", "        ", "return", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.__init__": [[4, 11], ["dataset.Dataset.shuffle", "next", "iter", "data_map.values"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle"], ["    ", "def", "__init__", "(", "self", ",", "data_map", ",", "deterministic", "=", "False", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "data_map", "=", "data_map", "\n", "self", ".", "deterministic", "=", "deterministic", "\n", "self", ".", "enable_shuffle", "=", "shuffle", "\n", "self", ".", "n", "=", "next", "(", "iter", "(", "data_map", ".", "values", "(", ")", ")", ")", ".", "shape", "[", "0", "]", "\n", "self", ".", "_next_id", "=", "0", "\n", "self", ".", "shuffle", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle": [[12, 22], ["numpy.arange", "numpy.random.shuffle"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle"], ["", "def", "shuffle", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "deterministic", ":", "\n", "            ", "return", "\n", "", "perm", "=", "np", ".", "arange", "(", "self", ".", "n", ")", "\n", "np", ".", "random", ".", "shuffle", "(", "perm", ")", "\n", "\n", "for", "key", "in", "self", ".", "data_map", ":", "\n", "            ", "self", ".", "data_map", "[", "key", "]", "=", "self", ".", "data_map", "[", "key", "]", "[", "perm", "]", "\n", "\n", "", "self", ".", "_next_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.next_batch": [[23, 35], ["min", "dict", "dataset.Dataset.shuffle"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle"], ["", "def", "next_batch", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "_next_id", ">=", "self", ".", "n", "and", "self", ".", "enable_shuffle", ":", "\n", "            ", "self", ".", "shuffle", "(", ")", "\n", "\n", "", "cur_id", "=", "self", ".", "_next_id", "\n", "cur_batch_size", "=", "min", "(", "batch_size", ",", "self", ".", "n", "-", "self", ".", "_next_id", ")", "\n", "self", ".", "_next_id", "+=", "cur_batch_size", "\n", "\n", "data_map", "=", "dict", "(", ")", "\n", "for", "key", "in", "self", ".", "data_map", ":", "\n", "            ", "data_map", "[", "key", "]", "=", "self", ".", "data_map", "[", "key", "]", "[", "cur_id", ":", "cur_id", "+", "cur_batch_size", "]", "\n", "", "return", "data_map", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.iterate_once": [[36, 42], ["dataset.Dataset.shuffle", "dataset.Dataset.next_batch"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.next_batch"], ["", "def", "iterate_once", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "if", "self", ".", "enable_shuffle", ":", "self", ".", "shuffle", "(", ")", "\n", "\n", "while", "self", ".", "_next_id", "<=", "self", ".", "n", "-", "batch_size", ":", "\n", "            ", "yield", "self", ".", "next_batch", "(", "batch_size", ")", "\n", "", "self", ".", "_next_id", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.subset": [[43, 48], ["dict", "dataset.Dataset"], "methods", ["None"], ["", "def", "subset", "(", "self", ",", "num_elements", ",", "deterministic", "=", "True", ")", ":", "\n", "        ", "data_map", "=", "dict", "(", ")", "\n", "for", "key", "in", "self", ".", "data_map", ":", "\n", "            ", "data_map", "[", "key", "]", "=", "self", ".", "data_map", "[", "key", "]", "[", ":", "num_elements", "]", "\n", "", "return", "Dataset", "(", "data_map", ",", "deterministic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.iterbatches": [[50, 61], ["tuple", "all", "numpy.arange", "numpy.array_split", "map", "numpy.random.shuffle", "numpy.arange", "len", "tuple"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.dataset.Dataset.shuffle"], ["", "", "def", "iterbatches", "(", "arrays", ",", "*", ",", "num_batches", "=", "None", ",", "batch_size", "=", "None", ",", "shuffle", "=", "True", ",", "include_final_partial_batch", "=", "True", ")", ":", "\n", "    ", "assert", "(", "num_batches", "is", "None", ")", "!=", "(", "batch_size", "is", "None", ")", ",", "'Provide num_batches or batch_size, but not both'", "\n", "arrays", "=", "tuple", "(", "map", "(", "np", ".", "asarray", ",", "arrays", ")", ")", "\n", "n", "=", "arrays", "[", "0", "]", ".", "shape", "[", "0", "]", "\n", "assert", "all", "(", "a", ".", "shape", "[", "0", "]", "==", "n", "for", "a", "in", "arrays", "[", "1", ":", "]", ")", "\n", "inds", "=", "np", ".", "arange", "(", "n", ")", "\n", "if", "shuffle", ":", "np", ".", "random", ".", "shuffle", "(", "inds", ")", "\n", "sections", "=", "np", ".", "arange", "(", "0", ",", "n", ",", "batch_size", ")", "[", "1", ":", "]", "if", "num_batches", "is", "None", "else", "num_batches", "\n", "for", "batch_inds", "in", "np", ".", "array_split", "(", "inds", ",", "sections", ")", ":", "\n", "        ", "if", "include_final_partial_batch", "or", "len", "(", "batch_inds", ")", "==", "batch_size", ":", "\n", "            ", "yield", "tuple", "(", "a", "[", "batch_inds", "]", "for", "a", "in", "arrays", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.__init__": [[11, 24], ["sum", "numpy.zeros", "numpy.zeros", "baselines.SetFromFlat", "baselines.GetFlat", "baselines.numel"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.numel"], ["    ", "def", "__init__", "(", "self", ",", "var_list", ",", "*", ",", "beta1", "=", "0.9", ",", "beta2", "=", "0.999", ",", "epsilon", "=", "1e-08", ",", "scale_grad_by_procs", "=", "True", ",", "comm", "=", "None", ")", ":", "\n", "        ", "self", ".", "var_list", "=", "var_list", "\n", "self", ".", "beta1", "=", "beta1", "\n", "self", ".", "beta2", "=", "beta2", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "scale_grad_by_procs", "=", "scale_grad_by_procs", "\n", "size", "=", "sum", "(", "U", ".", "numel", "(", "v", ")", "for", "v", "in", "var_list", ")", "\n", "self", ".", "m", "=", "np", ".", "zeros", "(", "size", ",", "'float32'", ")", "\n", "self", ".", "v", "=", "np", ".", "zeros", "(", "size", ",", "'float32'", ")", "\n", "self", ".", "t", "=", "0", "\n", "self", ".", "setfromflat", "=", "U", ".", "SetFromFlat", "(", "var_list", ")", "\n", "self", ".", "getflat", "=", "U", ".", "GetFlat", "(", "var_list", ")", "\n", "self", ".", "comm", "=", "MPI", ".", "COMM_WORLD", "if", "comm", "is", "None", "and", "MPI", "is", "not", "None", "else", "comm", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.update": [[25, 43], ["localg.astype.astype.astype", "mpi_adam.MpiAdam.setfromflat", "mpi_adam.MpiAdam.check_synced", "numpy.zeros_like", "mpi_adam.MpiAdam.comm.Allreduce", "numpy.copy", "mpi_adam.MpiAdam.comm.Get_size", "numpy.sqrt", "numpy.sqrt", "mpi_adam.MpiAdam.getflat"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.check_synced"], ["", "def", "update", "(", "self", ",", "localg", ",", "stepsize", ")", ":", "\n", "        ", "if", "self", ".", "t", "%", "100", "==", "0", ":", "\n", "            ", "self", ".", "check_synced", "(", ")", "\n", "", "localg", "=", "localg", ".", "astype", "(", "'float32'", ")", "\n", "if", "self", ".", "comm", "is", "not", "None", ":", "\n", "            ", "globalg", "=", "np", ".", "zeros_like", "(", "localg", ")", "\n", "self", ".", "comm", ".", "Allreduce", "(", "localg", ",", "globalg", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "if", "self", ".", "scale_grad_by_procs", ":", "\n", "                ", "globalg", "/=", "self", ".", "comm", ".", "Get_size", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "globalg", "=", "np", ".", "copy", "(", "localg", ")", "\n", "\n", "", "self", ".", "t", "+=", "1", "\n", "a", "=", "stepsize", "*", "np", ".", "sqrt", "(", "1", "-", "self", ".", "beta2", "**", "self", ".", "t", ")", "/", "(", "1", "-", "self", ".", "beta1", "**", "self", ".", "t", ")", "\n", "self", ".", "m", "=", "self", ".", "beta1", "*", "self", ".", "m", "+", "(", "1", "-", "self", ".", "beta1", ")", "*", "globalg", "\n", "self", ".", "v", "=", "self", ".", "beta2", "*", "self", ".", "v", "+", "(", "1", "-", "self", ".", "beta2", ")", "*", "(", "globalg", "*", "globalg", ")", "\n", "step", "=", "(", "-", "a", ")", "*", "self", ".", "m", "/", "(", "np", ".", "sqrt", "(", "self", ".", "v", ")", "+", "self", ".", "epsilon", ")", "\n", "self", ".", "setfromflat", "(", "self", ".", "getflat", "(", ")", "+", "step", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.sync": [[44, 50], ["mpi_adam.MpiAdam.getflat", "mpi_adam.MpiAdam.comm.Bcast", "mpi_adam.MpiAdam.setfromflat"], "methods", ["None"], ["", "def", "sync", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "comm", "is", "None", ":", "\n", "            ", "return", "\n", "", "theta", "=", "self", ".", "getflat", "(", ")", "\n", "self", ".", "comm", ".", "Bcast", "(", "theta", ",", "root", "=", "0", ")", "\n", "self", ".", "setfromflat", "(", "theta", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.MpiAdam.check_synced": [[51, 62], ["mpi_adam.MpiAdam.comm.Get_rank", "mpi_adam.MpiAdam.getflat", "mpi_adam.MpiAdam.comm.Bcast", "mpi_adam.MpiAdam.getflat", "numpy.empty_like", "mpi_adam.MpiAdam.comm.Bcast"], "methods", ["None"], ["", "def", "check_synced", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "comm", "is", "None", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "comm", ".", "Get_rank", "(", ")", "==", "0", ":", "# this is root", "\n", "            ", "theta", "=", "self", ".", "getflat", "(", ")", "\n", "self", ".", "comm", ".", "Bcast", "(", "theta", ",", "root", "=", "0", ")", "\n", "", "else", ":", "\n", "            ", "thetalocal", "=", "self", ".", "getflat", "(", ")", "\n", "thetaroot", "=", "np", ".", "empty_like", "(", "thetalocal", ")", "\n", "self", ".", "comm", ".", "Bcast", "(", "thetaroot", ",", "root", "=", "0", ")", "\n", "assert", "(", "thetaroot", "==", "thetalocal", ")", ".", "all", "(", ")", ",", "(", "thetaroot", ",", "thetalocal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam.test_MpiAdam": [[63, 100], ["numpy.random.seed", "tensorflow.set_random_seed", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.train.AdamOptimizer().minimize", "baselines.function", "tensorflow.get_default_session().run", "range", "tensorflow.set_random_seed", "tensorflow.get_default_session().run", "baselines.function", "mpi_adam.MpiAdam", "range", "numpy.testing.assert_allclose", "numpy.random.randn().astype", "numpy.random.randn().astype", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.global_variables_initializer", "U.function.", "print", "losslist_ref.append", "tensorflow.global_variables_initializer", "U.function.", "mpi_adam.MpiAdam.update", "print", "losslist_test.append", "numpy.array", "numpy.array", "tensorflow.square", "tensorflow.sin", "tensorflow.train.AdamOptimizer", "tensorflow.get_default_session", "tensorflow.get_default_session", "baselines.flatgrad", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.minimize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad"], ["", "", "", "@", "U", ".", "in_session", "\n", "def", "test_MpiAdam", "(", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "\n", "a", "=", "tf", ".", "Variable", "(", "np", ".", "random", ".", "randn", "(", "3", ")", ".", "astype", "(", "'float32'", ")", ")", "\n", "b", "=", "tf", ".", "Variable", "(", "np", ".", "random", ".", "randn", "(", "2", ",", "5", ")", ".", "astype", "(", "'float32'", ")", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "a", ")", ")", "+", "tf", ".", "reduce_sum", "(", "tf", ".", "sin", "(", "b", ")", ")", "\n", "\n", "stepsize", "=", "1e-2", "\n", "update_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "stepsize", ")", ".", "minimize", "(", "loss", ")", "\n", "do_update", "=", "U", ".", "function", "(", "[", "]", ",", "loss", ",", "updates", "=", "[", "update_op", "]", ")", "\n", "\n", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "losslist_ref", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "l", "=", "do_update", "(", ")", "\n", "print", "(", "i", ",", "l", ")", "\n", "losslist_ref", ".", "append", "(", "l", ")", "\n", "\n", "\n", "\n", "", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "var_list", "=", "[", "a", ",", "b", "]", "\n", "lossandgrad", "=", "U", ".", "function", "(", "[", "]", ",", "[", "loss", ",", "U", ".", "flatgrad", "(", "loss", ",", "var_list", ")", "]", ")", "\n", "adam", "=", "MpiAdam", "(", "var_list", ")", "\n", "\n", "losslist_test", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "        ", "l", ",", "g", "=", "lossandgrad", "(", ")", "\n", "adam", ".", "update", "(", "g", ",", "stepsize", ")", "\n", "print", "(", "i", ",", "l", ")", "\n", "losslist_test", ".", "append", "(", "l", ")", "\n", "\n", "", "np", ".", "testing", ".", "assert_allclose", "(", "np", ".", "array", "(", "losslist_ref", ")", ",", "np", ".", "array", "(", "losslist_test", ")", ",", "atol", "=", "1e-4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StochasticFrameSkip.__init__": [[11, 18], ["gym.Wrapper.__init__", "numpy.random.RandomState", "hasattr"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "n", ",", "stickprob", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "n", "=", "n", "\n", "self", ".", "stickprob", "=", "stickprob", "\n", "self", ".", "curac", "=", "None", "\n", "self", ".", "rng", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "self", ".", "supports_want_render", "=", "hasattr", "(", "env", ",", "\"supports_want_render\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StochasticFrameSkip.reset": [[19, 22], ["retro_wrappers.StochasticFrameSkip.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "curac", "=", "None", "\n", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StochasticFrameSkip.step": [[23, 44], ["range", "retro_wrappers.StochasticFrameSkip.env.step", "retro_wrappers.StochasticFrameSkip.env.step", "retro_wrappers.StochasticFrameSkip.rng.rand"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "done", "=", "False", "\n", "totrew", "=", "0", "\n", "for", "i", "in", "range", "(", "self", ".", "n", ")", ":", "\n", "# First step after reset, use action", "\n", "            ", "if", "self", ".", "curac", "is", "None", ":", "\n", "                ", "self", ".", "curac", "=", "ac", "\n", "# First substep, delay with probability=stickprob", "\n", "", "elif", "i", "==", "0", ":", "\n", "                ", "if", "self", ".", "rng", ".", "rand", "(", ")", ">", "self", ".", "stickprob", ":", "\n", "                    ", "self", ".", "curac", "=", "ac", "\n", "# Second substep, new action definitely kicks in", "\n", "", "", "elif", "i", "==", "1", ":", "\n", "                ", "self", ".", "curac", "=", "ac", "\n", "", "if", "self", ".", "supports_want_render", "and", "i", "<", "self", ".", "n", "-", "1", ":", "\n", "                ", "ob", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "self", ".", "curac", ",", "want_render", "=", "False", ")", "\n", "", "else", ":", "\n", "                ", "ob", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "self", ".", "curac", ")", "\n", "", "totrew", "+=", "rew", "\n", "if", "done", ":", "break", "\n", "", "return", "ob", ",", "totrew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StochasticFrameSkip.seed": [[45, 47], ["retro_wrappers.StochasticFrameSkip.rng.seed"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed"], ["", "def", "seed", "(", "self", ",", "s", ")", ":", "\n", "        ", "self", ".", "rng", ".", "seed", "(", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.PartialFrameStack.__init__": [[49, 62], ["gym.Wrapper.__init__", "gym.spaces.Box", "collections.deque"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "k", ",", "channel", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Stack one channel (channel keyword) from previous frames\n        \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "shp", "=", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "\n", "shape", "=", "(", "shp", "[", "0", "]", ",", "shp", "[", "1", "]", ",", "shp", "[", "2", "]", "+", "k", "-", "1", ")", ",", "\n", "dtype", "=", "env", ".", "observation_space", ".", "dtype", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "frames", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "k", ")", "\n", "shp", "=", "env", ".", "observation_space", ".", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.PartialFrameStack.reset": [[63, 69], ["retro_wrappers.PartialFrameStack.env.reset", "range", "retro_wrappers.PartialFrameStack._get_ob", "retro_wrappers.PartialFrameStack.frames.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack._get_ob", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "ob", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "assert", "ob", ".", "shape", "[", "2", "]", ">", "self", ".", "channel", "\n", "for", "_", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "            ", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "", "return", "self", ".", "_get_ob", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.PartialFrameStack.step": [[70, 74], ["retro_wrappers.PartialFrameStack.env.step", "retro_wrappers.PartialFrameStack.frames.append", "retro_wrappers.PartialFrameStack._get_ob"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack._get_ob"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "ob", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "ac", ")", "\n", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "return", "self", ".", "_get_ob", "(", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.PartialFrameStack._get_ob": [[75, 79], ["numpy.concatenate", "len", "enumerate"], "methods", ["None"], ["", "def", "_get_ob", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "frames", ")", "==", "self", ".", "k", "\n", "return", "np", ".", "concatenate", "(", "[", "frame", "if", "i", "==", "self", ".", "k", "-", "1", "else", "frame", "[", ":", ",", ":", ",", "self", ".", "channel", ":", "self", ".", "channel", "+", "1", "]", "\n", "for", "(", "i", ",", "frame", ")", "in", "enumerate", "(", "self", ".", "frames", ")", "]", ",", "axis", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.Downsample.__init__": [[81, 90], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "ratio", ")", ":", "\n", "        ", "\"\"\"\n        Downsample images by a factor of ratio\n        \"\"\"", "\n", "gym", ".", "ObservationWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "(", "oldh", ",", "oldw", ",", "oldc", ")", "=", "env", ".", "observation_space", ".", "shape", "\n", "newshape", "=", "(", "oldh", "//", "ratio", ",", "oldw", "//", "ratio", ",", "oldc", ")", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "\n", "shape", "=", "newshape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.Downsample.observation": [[91, 97], ["cv2.resize"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "frame", ")", ":", "\n", "        ", "height", ",", "width", ",", "_", "=", "self", ".", "observation_space", ".", "shape", "\n", "frame", "=", "cv2", ".", "resize", "(", "frame", ",", "(", "width", ",", "height", ")", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", ")", "\n", "if", "frame", ".", "ndim", "==", "2", ":", "\n", "            ", "frame", "=", "frame", "[", ":", ",", ":", ",", "None", "]", "\n", "", "return", "frame", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.Rgb2gray.__init__": [[99, 107], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "\"\"\"\n        Downsample images by a factor of ratio\n        \"\"\"", "\n", "gym", ".", "ObservationWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "(", "oldh", ",", "oldw", ",", "_oldc", ")", "=", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "\n", "shape", "=", "(", "oldh", ",", "oldw", ",", "1", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.Rgb2gray.observation": [[108, 111], ["cv2.cvtColor"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "frame", ")", ":", "\n", "        ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "return", "frame", "[", ":", ",", ":", ",", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.MovieRecord.__init__": [[114, 119], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "savedir", ",", "k", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "savedir", "=", "savedir", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "epcount", "=", "0", "\n", "", "def", "reset", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.MovieRecord.reset": [[119, 127], ["retro_wrappers.MovieRecord.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "epcount", "%", "self", ".", "k", "==", "0", ":", "\n", "            ", "self", ".", "env", ".", "unwrapped", ".", "movie_path", "=", "self", ".", "savedir", "\n", "", "else", ":", "\n", "            ", "self", ".", "env", ".", "unwrapped", ".", "movie_path", "=", "None", "\n", "self", ".", "env", ".", "unwrapped", ".", "movie", "=", "None", "\n", "", "self", ".", "epcount", "+=", "1", "\n", "return", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AppendTimeout.__init__": [[129, 153], ["gym.Wrapper.__init__", "gym.spaces.Box", "isinstance", "copy.deepcopy", "gym.spaces.Dict", "gym.spaces.Dict", "numpy.array", "numpy.array", "hasattr"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "action_space", "=", "env", ".", "action_space", "\n", "self", ".", "timeout_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "np", ".", "array", "(", "[", "0.0", "]", ")", ",", "high", "=", "np", ".", "array", "(", "[", "1.0", "]", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "original_os", "=", "env", ".", "observation_space", "\n", "if", "isinstance", "(", "self", ".", "original_os", ",", "gym", ".", "spaces", ".", "Dict", ")", ":", "\n", "            ", "import", "copy", "\n", "ordered_dict", "=", "copy", ".", "deepcopy", "(", "self", ".", "original_os", ".", "spaces", ")", "\n", "ordered_dict", "[", "'value_estimation_timeout'", "]", "=", "self", ".", "timeout_space", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Dict", "(", "ordered_dict", ")", "\n", "self", ".", "dict_mode", "=", "True", "\n", "", "else", ":", "\n", "            ", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Dict", "(", "{", "\n", "'original'", ":", "self", ".", "original_os", ",", "\n", "'value_estimation_timeout'", ":", "self", ".", "timeout_space", "\n", "}", ")", "\n", "self", ".", "dict_mode", "=", "False", "\n", "", "self", ".", "ac_count", "=", "None", "\n", "while", "1", ":", "\n", "            ", "if", "not", "hasattr", "(", "env", ",", "\"_max_episode_steps\"", ")", ":", "# Looking for TimeLimit wrapper that has this field", "\n", "                ", "env", "=", "env", ".", "env", "\n", "continue", "\n", "", "break", "\n", "", "self", ".", "timeout", "=", "env", ".", "_max_episode_steps", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AppendTimeout.step": [[154, 158], ["retro_wrappers.AppendTimeout.env.step", "retro_wrappers.AppendTimeout._process"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AppendTimeout._process"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "self", ".", "ac_count", "+=", "1", "\n", "ob", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "ac", ")", "\n", "return", "self", ".", "_process", "(", "ob", ")", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AppendTimeout.reset": [[159, 162], ["retro_wrappers.AppendTimeout._process", "retro_wrappers.AppendTimeout.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AppendTimeout._process", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "ac_count", "=", "0", "\n", "return", "self", ".", "_process", "(", "self", ".", "env", ".", "reset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AppendTimeout._process": [[163, 169], ["None"], "methods", ["None"], ["", "def", "_process", "(", "self", ",", "ob", ")", ":", "\n", "        ", "fracmissing", "=", "1", "-", "self", ".", "ac_count", "/", "self", ".", "timeout", "\n", "if", "self", ".", "dict_mode", ":", "\n", "            ", "ob", "[", "'value_estimation_timeout'", "]", "=", "fracmissing", "\n", "", "else", ":", "\n", "            ", "return", "{", "'original'", ":", "ob", ",", "'value_estimation_timeout'", ":", "fracmissing", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StartDoingRandomActionsWrapper.__init__": [[174, 182], ["gym.Wrapper.__init__", "retro_wrappers.StartDoingRandomActionsWrapper.some_random_steps"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StartDoingRandomActionsWrapper.some_random_steps"], ["def", "__init__", "(", "self", ",", "env", ",", "max_random_steps", ",", "on_startup", "=", "True", ",", "every_episode", "=", "False", ")", ":", "\n", "        ", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "on_startup", "=", "on_startup", "\n", "self", ".", "every_episode", "=", "every_episode", "\n", "self", ".", "random_steps", "=", "max_random_steps", "\n", "self", ".", "last_obs", "=", "None", "\n", "if", "on_startup", ":", "\n", "            ", "self", ".", "some_random_steps", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StartDoingRandomActionsWrapper.some_random_steps": [[183, 190], ["retro_wrappers.StartDoingRandomActionsWrapper.env.reset", "numpy.random.randint", "range", "retro_wrappers.StartDoingRandomActionsWrapper.env.step", "retro_wrappers.StartDoingRandomActionsWrapper.env.action_space.sample", "retro_wrappers.StartDoingRandomActionsWrapper.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "", "def", "some_random_steps", "(", "self", ")", ":", "\n", "        ", "self", ".", "last_obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "n", "=", "np", ".", "random", ".", "randint", "(", "self", ".", "random_steps", ")", "\n", "#print(\"running for random %i frames\" % n)", "\n", "for", "_", "in", "range", "(", "n", ")", ":", "\n", "            ", "self", ".", "last_obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "self", ".", "env", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "if", "done", ":", "self", ".", "last_obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StartDoingRandomActionsWrapper.reset": [[191, 193], ["None"], "methods", ["None"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "last_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StartDoingRandomActionsWrapper.step": [[194, 201], ["retro_wrappers.StartDoingRandomActionsWrapper.env.step", "retro_wrappers.StartDoingRandomActionsWrapper.env.reset", "retro_wrappers.StartDoingRandomActionsWrapper.some_random_steps"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.StartDoingRandomActionsWrapper.some_random_steps"], ["", "def", "step", "(", "self", ",", "a", ")", ":", "\n", "        ", "self", ".", "last_obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "a", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "last_obs", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "if", "self", ".", "every_episode", ":", "\n", "                ", "self", ".", "some_random_steps", "(", ")", "\n", "", "", "return", "self", ".", "last_obs", ",", "rew", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.SonicDiscretizer.__init__": [[229, 241], ["gym.ActionWrapper.__init__", "gym.spaces.Discrete", "numpy.array", "retro_wrappers.SonicDiscretizer._actions.append", "len", "buttons.index"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", "SonicDiscretizer", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "buttons", "=", "[", "\"B\"", ",", "\"A\"", ",", "\"MODE\"", ",", "\"START\"", ",", "\"UP\"", ",", "\"DOWN\"", ",", "\"LEFT\"", ",", "\"RIGHT\"", ",", "\"C\"", ",", "\"Y\"", ",", "\"X\"", ",", "\"Z\"", "]", "\n", "actions", "=", "[", "[", "'LEFT'", "]", ",", "[", "'RIGHT'", "]", ",", "[", "'LEFT'", ",", "'DOWN'", "]", ",", "[", "'RIGHT'", ",", "'DOWN'", "]", ",", "[", "'DOWN'", "]", ",", "\n", "[", "'DOWN'", ",", "'B'", "]", ",", "[", "'B'", "]", "]", "\n", "self", ".", "_actions", "=", "[", "]", "\n", "for", "action", "in", "actions", ":", "\n", "            ", "arr", "=", "np", ".", "array", "(", "[", "False", "]", "*", "12", ")", "\n", "for", "button", "in", "action", ":", "\n", "                ", "arr", "[", "buttons", ".", "index", "(", "button", ")", "]", "=", "True", "\n", "", "self", ".", "_actions", ".", "append", "(", "arr", ")", "\n", "", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Discrete", "(", "len", "(", "self", ".", "_actions", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.SonicDiscretizer.action": [[242, 244], ["retro_wrappers.SonicDiscretizer._actions[].copy"], "methods", ["None"], ["", "def", "action", "(", "self", ",", "a", ")", ":", "# pylint: disable=W0221", "\n", "        ", "return", "self", ".", "_actions", "[", "a", "]", ".", "copy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.RewardScaler.__init__": [[251, 254], ["gym.RewardWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "env", ",", "scale", "=", "0.01", ")", ":", "\n", "        ", "super", "(", "RewardScaler", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "scale", "=", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.RewardScaler.reward": [[255, 257], ["None"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "return", "reward", "*", "self", ".", "scale", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AllowBacktracking.__init__": [[265, 269], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "super", "(", "AllowBacktracking", ",", "self", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "_cur_x", "=", "0", "\n", "self", ".", "_max_x", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AllowBacktracking.reset": [[270, 274], ["retro_wrappers.AllowBacktracking.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "# pylint: disable=E0202", "\n", "        ", "self", ".", "_cur_x", "=", "0", "\n", "self", ".", "_max_x", "=", "0", "\n", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.AllowBacktracking.step": [[275, 281], ["retro_wrappers.AllowBacktracking.env.step", "max", "max"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "# pylint: disable=E0202", "\n", "        ", "obs", ",", "rew", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "_cur_x", "+=", "rew", "\n", "rew", "=", "max", "(", "0", ",", "self", ".", "_cur_x", "-", "self", ".", "_max_x", ")", "\n", "self", ".", "_max_x", "=", "max", "(", "self", ".", "_max_x", ",", "self", ".", "_cur_x", ")", "\n", "return", "obs", ",", "rew", ",", "done", ",", "info", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.make_retro": [[202, 211], ["retro.make", "retro_wrappers.StochasticFrameSkip", "wrappers.TimeLimit"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make"], ["", "", "def", "make_retro", "(", "*", ",", "game", ",", "state", "=", "None", ",", "max_episode_steps", "=", "4500", ",", "**", "kwargs", ")", ":", "\n", "    ", "import", "retro", "\n", "if", "state", "is", "None", ":", "\n", "        ", "state", "=", "retro", ".", "State", ".", "DEFAULT", "\n", "", "env", "=", "retro", ".", "make", "(", "game", ",", "state", ",", "**", "kwargs", ")", "\n", "env", "=", "StochasticFrameSkip", "(", "env", ",", "n", "=", "4", ",", "stickprob", "=", "0.25", ")", "\n", "if", "max_episode_steps", "is", "not", "None", ":", "\n", "        ", "env", "=", "TimeLimit", "(", "env", ",", "max_episode_steps", "=", "max_episode_steps", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.retro_wrappers.wrap_deepmind_retro": [[212, 223], ["atari_wrappers.WarpFrame", "atari_wrappers.ClipRewardEnv", "atari_wrappers.FrameStack", "atari_wrappers.ScaledFloatFrame"], "function", ["None"], ["", "def", "wrap_deepmind_retro", "(", "env", ",", "scale", "=", "True", ",", "frame_stack", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Configure environment for retro games, using config similar to DeepMind-style Atari in wrap_deepmind\n    \"\"\"", "\n", "env", "=", "WarpFrame", "(", "env", ")", "\n", "env", "=", "ClipRewardEnv", "(", "env", ")", "\n", "if", "frame_stack", ">", "1", ":", "\n", "        ", "env", "=", "FrameStack", "(", "env", ",", "frame_stack", ")", "\n", "", "if", "scale", ":", "\n", "        ", "env", "=", "ScaledFloatFrame", "(", "env", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.MpiAdamOptimizer.__init__": [[13, 18], ["tensorflow.train.AdamOptimizer.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "comm", ",", "grad_clip", "=", "None", ",", "mpi_rank_weight", "=", "1", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "comm", "=", "comm", "\n", "self", ".", "grad_clip", "=", "grad_clip", "\n", "self", ".", "mpi_rank_weight", "=", "mpi_rank_weight", "\n", "tf", ".", "train", ".", "AdamOptimizer", ".", "__init__", "(", "self", ",", "**", "kwargs", ")", "\n", "", "def", "compute_gradients", "(", "self", ",", "loss", ",", "var_list", ",", "**", "kwargs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.MpiAdamOptimizer.compute_gradients": [[18, 52], ["tensorflow.train.AdamOptimizer.compute_gradients", "numpy.zeros", "mpi_adam_optimizer.MpiAdamOptimizer.comm.Allreduce", "numpy.zeros", "tensorflow.reduce_sum", "tensorflow.py_func", "tensorflow.py_func.set_shape", "tensorflow.split", "tensorflow.concat", "v.shape.as_list", "int", "numpy.array", "sum", "mpi_adam_optimizer.MpiAdamOptimizer.comm.Allreduce", "numpy.divide", "numpy.prod", "numpy.linalg.norm", "baselines.logger.logkv_mean", "baselines.logger.logkv_mean", "float", "mpi_adam_optimizer.check_synced", "tensorflow.reshape", "zip", "tensorflow.reshape", "float"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.MpiAdamOptimizer.compute_gradients", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.check_synced"], ["", "def", "compute_gradients", "(", "self", ",", "loss", ",", "var_list", ",", "**", "kwargs", ")", ":", "\n", "        ", "grads_and_vars", "=", "tf", ".", "train", ".", "AdamOptimizer", ".", "compute_gradients", "(", "self", ",", "loss", ",", "var_list", ",", "**", "kwargs", ")", "\n", "grads_and_vars", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "flat_grad", "=", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "g", ",", "(", "-", "1", ",", ")", ")", "for", "g", ",", "v", "in", "grads_and_vars", "]", ",", "axis", "=", "0", ")", "*", "self", ".", "mpi_rank_weight", "\n", "shapes", "=", "[", "v", ".", "shape", ".", "as_list", "(", ")", "for", "g", ",", "v", "in", "grads_and_vars", "]", "\n", "sizes", "=", "[", "int", "(", "np", ".", "prod", "(", "s", ")", ")", "for", "s", "in", "shapes", "]", "\n", "\n", "total_weight", "=", "np", ".", "zeros", "(", "1", ",", "np", ".", "float32", ")", "\n", "self", ".", "comm", ".", "Allreduce", "(", "np", ".", "array", "(", "[", "self", ".", "mpi_rank_weight", "]", ",", "dtype", "=", "np", ".", "float32", ")", ",", "total_weight", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "total_weight", "=", "total_weight", "[", "0", "]", "\n", "\n", "buf", "=", "np", ".", "zeros", "(", "sum", "(", "sizes", ")", ",", "np", ".", "float32", ")", "\n", "countholder", "=", "[", "0", "]", "# Counts how many times _collect_grads has been called", "\n", "stat", "=", "tf", ".", "reduce_sum", "(", "grads_and_vars", "[", "0", "]", "[", "1", "]", ")", "# sum of first variable", "\n", "def", "_collect_grads", "(", "flat_grad", ",", "np_stat", ")", ":", "\n", "            ", "if", "self", ".", "grad_clip", "is", "not", "None", ":", "\n", "                ", "gradnorm", "=", "np", ".", "linalg", ".", "norm", "(", "flat_grad", ")", "\n", "if", "gradnorm", ">", "1", ":", "\n", "                    ", "flat_grad", "/=", "gradnorm", "\n", "", "logger", ".", "logkv_mean", "(", "'gradnorm'", ",", "gradnorm", ")", "\n", "logger", ".", "logkv_mean", "(", "'gradclipfrac'", ",", "float", "(", "gradnorm", ">", "1", ")", ")", "\n", "", "self", ".", "comm", ".", "Allreduce", "(", "flat_grad", ",", "buf", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "np", ".", "divide", "(", "buf", ",", "float", "(", "total_weight", ")", ",", "out", "=", "buf", ")", "\n", "if", "countholder", "[", "0", "]", "%", "100", "==", "0", ":", "\n", "                ", "check_synced", "(", "np_stat", ",", "self", ".", "comm", ")", "\n", "", "countholder", "[", "0", "]", "+=", "1", "\n", "return", "buf", "\n", "\n", "", "avg_flat_grad", "=", "tf", ".", "py_func", "(", "_collect_grads", ",", "[", "flat_grad", ",", "stat", "]", ",", "tf", ".", "float32", ")", "\n", "avg_flat_grad", ".", "set_shape", "(", "flat_grad", ".", "shape", ")", "\n", "avg_grads", "=", "tf", ".", "split", "(", "avg_flat_grad", ",", "sizes", ",", "axis", "=", "0", ")", "\n", "avg_grads_and_vars", "=", "[", "(", "tf", ".", "reshape", "(", "g", ",", "v", ".", "shape", ")", ",", "v", ")", "\n", "for", "g", ",", "(", "_", ",", "v", ")", "in", "zip", "(", "avg_grads", ",", "grads_and_vars", ")", "]", "\n", "return", "avg_grads_and_vars", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.check_synced": [[53, 69], ["comm.gather", "all"], "function", ["None"], ["", "", "def", "check_synced", "(", "localval", ",", "comm", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    It's common to forget to initialize your variables to the same values, or\n    (less commonly) if you update them in some other way than adam, to get them out of sync.\n    This function checks that variables on all MPI workers are the same, and raises\n    an AssertionError otherwise\n\n    Arguments:\n        comm: MPI communicator\n        localval: list of local variables (list of variables on current worker to be compared with the other workers)\n    \"\"\"", "\n", "comm", "=", "comm", "or", "MPI", ".", "COMM_WORLD", "\n", "vals", "=", "comm", ".", "gather", "(", "localval", ")", "\n", "if", "comm", ".", "rank", "==", "0", ":", "\n", "        ", "assert", "all", "(", "val", "==", "vals", "[", "0", "]", "for", "val", "in", "vals", "[", "1", ":", "]", ")", ",", "'MpiAdamOptimizer detected that different workers have different weights: {}'", ".", "format", "(", "vals", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_adam_optimizer.test_nonfreeze": [[70, 91], ["baselines.common.tests.test_with_mpi.with_mpi", "numpy.random.seed", "tensorflow.set_random_seed", "tensorflow.Variable", "tensorflow.Variable", "tensorflow.ConfigProto", "baselines.common.tf_util.get_session", "MpiAdamOptimizer().minimize", "U.get_session.run", "range", "numpy.random.randn().astype", "numpy.random.randn().astype", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.global_variables_initializer", "U.get_session.run", "print", "losslist_ref.append", "tensorflow.square", "tensorflow.sin", "mpi_adam_optimizer.MpiAdamOptimizer", "numpy.random.randn", "numpy.random.randn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_with_mpi.with_mpi", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acktr.kfac.KfacOptimizer.minimize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "@", "with_mpi", "(", "timeout", "=", "5", ")", "\n", "def", "test_nonfreeze", "(", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "tf", ".", "set_random_seed", "(", "0", ")", "\n", "\n", "a", "=", "tf", ".", "Variable", "(", "np", ".", "random", ".", "randn", "(", "3", ")", ".", "astype", "(", "'float32'", ")", ")", "\n", "b", "=", "tf", ".", "Variable", "(", "np", ".", "random", ".", "randn", "(", "2", ",", "5", ")", ".", "astype", "(", "'float32'", ")", ")", "\n", "loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "a", ")", ")", "+", "tf", ".", "reduce_sum", "(", "tf", ".", "sin", "(", "b", ")", ")", "\n", "\n", "stepsize", "=", "1e-2", "\n", "# for some reason the session config with inter_op_parallelism_threads was causing", "\n", "# nested sess.run calls to freeze", "\n", "config", "=", "tf", ".", "ConfigProto", "(", "inter_op_parallelism_threads", "=", "1", ")", "\n", "sess", "=", "U", ".", "get_session", "(", "config", "=", "config", ")", "\n", "update_op", "=", "MpiAdamOptimizer", "(", "comm", "=", "MPI", ".", "COMM_WORLD", ",", "learning_rate", "=", "stepsize", ")", ".", "minimize", "(", "loss", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "losslist_ref", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "100", ")", ":", "\n", "        ", "l", ",", "_", "=", "sess", ".", "run", "(", "[", "loss", ",", "update_op", "]", ")", "\n", "print", "(", "i", ",", "l", ")", "\n", "losslist_ref", ".", "append", "(", "l", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.flatparam": [[11, 13], ["None"], "methods", ["None"], ["def", "flatparam", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.mode": [[13, 15], ["None"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.neglogp": [[15, 18], ["None"], "methods", ["None"], ["", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n", "# Usually it's easier to define the negative logprob", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.kl": [[18, 20], ["None"], "methods", ["None"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.entropy": [[20, 22], ["None"], "methods", ["None"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.sample": [[22, 24], ["None"], "methods", ["None"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "logp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.logp": [[24, 26], ["distributions.Pd.neglogp"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.neglogp"], ["", "def", "logp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "-", "self", ".", "neglogp", "(", "x", ")", "\n", "", "def", "get_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape": [[26, 28], ["distributions.Pd.flatparam"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.flatparam"], ["", "def", "get_shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "flatparam", "(", ")", ".", "shape", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape": [[28, 31], ["distributions.Pd.get_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "@", "property", "\n", "def", "shape", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "get_shape", "(", ")", "\n", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.__getitem__": [[31, 33], ["distributions.Pd.__class__", "distributions.Pd.flatparam"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.flatparam"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "__class__", "(", "self", ".", "flatparam", "(", ")", "[", "idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.pdclass": [[38, 40], ["None"], "methods", ["None"], ["def", "pdclass", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.pdfromflat": [[40, 42], ["distributions.PdType.pdclass"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.pdclass"], ["", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n", "        ", "return", "self", ".", "pdclass", "(", ")", "(", "flat", ")", "\n", "", "def", "pdfromlatent", "(", "self", ",", "latent_vector", ",", "init_scale", ",", "init_bias", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.pdfromlatent": [[42, 44], ["None"], "methods", ["None"], ["", "def", "pdfromlatent", "(", "self", ",", "latent_vector", ",", "init_scale", ",", "init_bias", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.param_shape": [[44, 46], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_shape": [[46, 48], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_dtype": [[48, 50], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.param_placeholder": [[51, 53], ["tensorflow.placeholder", "distributions.PdType.param_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape"], ["", "def", "param_placeholder", "(", "self", ",", "prepend_shape", ",", "name", "=", "None", ")", ":", "\n", "        ", "return", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "prepend_shape", "+", "self", ".", "param_shape", "(", ")", ",", "name", "=", "name", ")", "\n", "", "def", "sample_placeholder", "(", "self", ",", "prepend_shape", ",", "name", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder": [[53, 55], ["tensorflow.placeholder", "distributions.PdType.sample_dtype", "distributions.PdType.sample_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.sample_dtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.sample_shape"], ["", "def", "sample_placeholder", "(", "self", ",", "prepend_shape", ",", "name", "=", "None", ")", ":", "\n", "        ", "return", "tf", ".", "placeholder", "(", "dtype", "=", "self", ".", "sample_dtype", "(", ")", ",", "shape", "=", "prepend_shape", "+", "self", ".", "sample_shape", "(", ")", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.__eq__": [[56, 58], ["type", "type"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "type", "(", "self", ")", "==", "type", "(", "other", ")", ")", "and", "(", "self", ".", "__dict__", "==", "other", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPdType.__init__": [[60, 62], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ncat", ")", ":", "\n", "        ", "self", ".", "ncat", "=", "ncat", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPdType.pdclass": [[62, 64], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "CategoricalPd", "\n", "", "def", "pdfromlatent", "(", "self", ",", "latent_vector", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPdType.pdfromlatent": [[64, 67], ["distributions._matching_fc", "distributions.CategoricalPdType.pdfromflat"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions._matching_fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat"], ["", "def", "pdfromlatent", "(", "self", ",", "latent_vector", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n", "        ", "pdparam", "=", "_matching_fc", "(", "latent_vector", ",", "'pi'", ",", "self", ".", "ncat", ",", "init_scale", "=", "init_scale", ",", "init_bias", "=", "init_bias", ")", "\n", "return", "self", ".", "pdfromflat", "(", "pdparam", ")", ",", "pdparam", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPdType.param_shape": [[68, 70], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "ncat", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPdType.sample_shape": [[70, 72], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPdType.sample_dtype": [[72, 74], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.__init__": [[77, 80], ["nvec.astype"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "nvec", ")", ":", "\n", "        ", "self", ".", "ncats", "=", "nvec", ".", "astype", "(", "'int32'", ")", "\n", "assert", "(", "self", ".", "ncats", ">", "0", ")", ".", "all", "(", ")", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdclass": [[80, 82], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "MultiCategoricalPd", "\n", "", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat": [[82, 84], ["distributions.MultiCategoricalPd"], "methods", ["None"], ["", "def", "pdfromflat", "(", "self", ",", "flat", ")", ":", "\n", "        ", "return", "MultiCategoricalPd", "(", "self", ".", "ncats", ",", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromlatent": [[85, 88], ["distributions._matching_fc", "distributions.MultiCategoricalPdType.ncats.sum", "distributions.MultiCategoricalPdType.pdfromflat"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions._matching_fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat"], ["", "def", "pdfromlatent", "(", "self", ",", "latent", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n", "        ", "pdparam", "=", "_matching_fc", "(", "latent", ",", "'pi'", ",", "self", ".", "ncats", ".", "sum", "(", ")", ",", "init_scale", "=", "init_scale", ",", "init_bias", "=", "init_bias", ")", "\n", "return", "self", ".", "pdfromflat", "(", "pdparam", ")", ",", "pdparam", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.param_shape": [[89, 91], ["sum"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "sum", "(", "self", ".", "ncats", ")", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.sample_shape": [[91, 93], ["len"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "len", "(", "self", ".", "ncats", ")", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.sample_dtype": [[93, 95], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "int32", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPdType.__init__": [[97, 99], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPdType.pdclass": [[99, 101], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "DiagGaussianPd", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPdType.pdfromlatent": [[102, 107], ["distributions._matching_fc", "tensorflow.get_variable", "tensorflow.concat", "distributions.DiagGaussianPdType.pdfromflat", "tensorflow.zeros_initializer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions._matching_fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat"], ["", "def", "pdfromlatent", "(", "self", ",", "latent_vector", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n", "        ", "mean", "=", "_matching_fc", "(", "latent_vector", ",", "'pi'", ",", "self", ".", "size", ",", "init_scale", "=", "init_scale", ",", "init_bias", "=", "init_bias", ")", "\n", "logstd", "=", "tf", ".", "get_variable", "(", "name", "=", "'pi/logstd'", ",", "shape", "=", "[", "1", ",", "self", ".", "size", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ")", "\n", "pdparam", "=", "tf", ".", "concat", "(", "[", "mean", ",", "mean", "*", "0.0", "+", "logstd", "]", ",", "axis", "=", "1", ")", "\n", "return", "self", ".", "pdfromflat", "(", "pdparam", ")", ",", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPdType.param_shape": [[108, 110], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "2", "*", "self", ".", "size", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPdType.sample_shape": [[110, 112], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "size", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPdType.sample_dtype": [[112, 114], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "float32", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.__init__": [[116, 118], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "size", ")", ":", "\n", "        ", "self", ".", "size", "=", "size", "\n", "", "def", "pdclass", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.pdclass": [[118, 120], ["None"], "methods", ["None"], ["", "def", "pdclass", "(", "self", ")", ":", "\n", "        ", "return", "BernoulliPd", "\n", "", "def", "param_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.param_shape": [[120, 122], ["None"], "methods", ["None"], ["", "def", "param_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "size", "]", "\n", "", "def", "sample_shape", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.sample_shape": [[122, 124], ["None"], "methods", ["None"], ["", "def", "sample_shape", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "size", "]", "\n", "", "def", "sample_dtype", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.sample_dtype": [[124, 126], ["None"], "methods", ["None"], ["", "def", "sample_dtype", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "int32", "\n", "", "def", "pdfromlatent", "(", "self", ",", "latent_vector", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPdType.pdfromlatent": [[126, 129], ["distributions._matching_fc", "distributions.BernoulliPdType.pdfromflat"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions._matching_fc", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat"], ["", "def", "pdfromlatent", "(", "self", ",", "latent_vector", ",", "init_scale", "=", "1.0", ",", "init_bias", "=", "0.0", ")", ":", "\n", "        ", "pdparam", "=", "_matching_fc", "(", "latent_vector", ",", "'pi'", ",", "self", ".", "size", ",", "init_scale", "=", "init_scale", ",", "init_bias", "=", "init_bias", ")", "\n", "return", "self", ".", "pdfromflat", "(", "pdparam", ")", ",", "pdparam", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.__init__": [[154, 156], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logits", ")", ":", "\n", "        ", "self", ".", "logits", "=", "logits", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.flatparam": [[156, 158], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "logits", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.mode": [[158, 160], ["tensorflow.argmax"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "argmax", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.mean": [[161, 164], ["tensorflow.nn.softmax"], "methods", ["None"], ["", "@", "property", "\n", "def", "mean", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "nn", ".", "softmax", "(", "self", ".", "logits", ")", "\n", "", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.neglogp": [[164, 184], ["tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.one_hot.shape.as_list", "zip", "tensorflow.one_hot", "distributions.CategoricalPd.logits.get_shape().as_list", "tensorflow.one_hot.shape.as_list", "distributions.CategoricalPd.logits.shape.as_list", "distributions.CategoricalPd.logits.get_shape().as_list", "distributions.CategoricalPd.logits.get_shape", "distributions.CategoricalPd.logits.get_shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n", "# return tf.nn.sparse_softmax_cross_entropy_with_logits(logits=self.logits, labels=x)", "\n", "# Note: we can't use sparse_softmax_cross_entropy_with_logits because", "\n", "#       the implementation does not allow second-order derivatives...", "\n", "        ", "if", "x", ".", "dtype", "in", "{", "tf", ".", "uint8", ",", "tf", ".", "int32", ",", "tf", ".", "int64", "}", ":", "\n", "# one-hot encoding", "\n", "            ", "x_shape_list", "=", "x", ".", "shape", ".", "as_list", "(", ")", "\n", "logits_shape_list", "=", "self", ".", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", ":", "-", "1", "]", "\n", "for", "xs", ",", "ls", "in", "zip", "(", "x_shape_list", ",", "logits_shape_list", ")", ":", "\n", "                ", "if", "xs", "is", "not", "None", "and", "ls", "is", "not", "None", ":", "\n", "                    ", "assert", "xs", "==", "ls", ",", "'shape mismatch: {} in x vs {} in logits'", ".", "format", "(", "xs", ",", "ls", ")", "\n", "\n", "", "", "x", "=", "tf", ".", "one_hot", "(", "x", ",", "self", ".", "logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "# already encoded", "\n", "            ", "assert", "x", ".", "shape", ".", "as_list", "(", ")", "==", "self", ".", "logits", ".", "shape", ".", "as_list", "(", ")", "\n", "\n", "", "return", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "logits", "=", "self", ".", "logits", ",", "\n", "labels", "=", "x", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.kl": [[184, 193], ["tensorflow.exp", "tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "a0", "=", "self", ".", "logits", "-", "tf", ".", "reduce_max", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "a1", "=", "other", ".", "logits", "-", "tf", ".", "reduce_max", "(", "other", ".", "logits", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "ea1", "=", "tf", ".", "exp", "(", "a1", ")", "\n", "z0", "=", "tf", ".", "reduce_sum", "(", "ea0", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "z1", "=", "tf", ".", "reduce_sum", "(", "ea1", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "tf", ".", "reduce_sum", "(", "p0", "*", "(", "a0", "-", "tf", ".", "log", "(", "z0", ")", "-", "a1", "+", "tf", ".", "log", "(", "z1", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.entropy": [[193, 199], ["tensorflow.exp", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_max", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "a0", "=", "self", ".", "logits", "-", "tf", ".", "reduce_max", "(", "self", ".", "logits", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "ea0", "=", "tf", ".", "exp", "(", "a0", ")", "\n", "z0", "=", "tf", ".", "reduce_sum", "(", "ea0", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "p0", "=", "ea0", "/", "z0", "\n", "return", "tf", ".", "reduce_sum", "(", "p0", "*", "(", "tf", ".", "log", "(", "z0", ")", "-", "a0", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.sample": [[199, 202], ["tensorflow.random_uniform", "tensorflow.argmax", "tensorflow.shape", "tensorflow.log", "tensorflow.log"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "u", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "self", ".", "logits", ")", ",", "dtype", "=", "self", ".", "logits", ".", "dtype", ")", "\n", "return", "tf", ".", "argmax", "(", "self", ".", "logits", "-", "tf", ".", "log", "(", "-", "tf", ".", "log", "(", "u", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.CategoricalPd.fromflat": [[202, 205], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.__init__": [[207, 211], ["list", "map", "tensorflow.split", "numpy.array"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "nvec", ",", "flat", ")", ":", "\n", "        ", "self", ".", "flat", "=", "flat", "\n", "self", ".", "categoricals", "=", "list", "(", "map", "(", "CategoricalPd", ",", "\n", "tf", ".", "split", "(", "flat", ",", "np", ".", "array", "(", "nvec", ",", "dtype", "=", "np", ".", "int32", ")", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.flatparam": [[211, 213], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "flat", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.mode": [[213, 215], ["tensorflow.cast", "tensorflow.stack", "p.mode"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mode"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "cast", "(", "tf", ".", "stack", "(", "[", "p", ".", "mode", "(", ")", "for", "p", "in", "self", ".", "categoricals", "]", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "int32", ")", "\n", "", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.neglogp": [[215, 217], ["tensorflow.add_n", "p.neglogp", "zip", "tensorflow.unstack"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.neglogp"], ["", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "p", ".", "neglogp", "(", "px", ")", "for", "p", ",", "px", "in", "zip", "(", "self", ".", "categoricals", ",", "tf", ".", "unstack", "(", "x", ",", "axis", "=", "-", "1", ")", ")", "]", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.kl": [[217, 219], ["tensorflow.add_n", "p.kl", "zip"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.kl"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "p", ".", "kl", "(", "q", ")", "for", "p", ",", "q", "in", "zip", "(", "self", ".", "categoricals", ",", "other", ".", "categoricals", ")", "]", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.entropy": [[219, 221], ["tensorflow.add_n", "p.entropy"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "add_n", "(", "[", "p", ".", "entropy", "(", ")", "for", "p", "in", "self", ".", "categoricals", "]", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.sample": [[221, 223], ["tensorflow.cast", "tensorflow.stack", "p.sample"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "cast", "(", "tf", ".", "stack", "(", "[", "p", ".", "sample", "(", ")", "for", "p", "in", "self", ".", "categoricals", "]", ",", "axis", "=", "-", "1", ")", ",", "tf", ".", "int32", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPd.fromflat": [[223, 226], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.__init__": [[228, 234], ["tensorflow.split", "tensorflow.exp", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "flat", ")", ":", "\n", "        ", "self", ".", "flat", "=", "flat", "\n", "mean", ",", "logstd", "=", "tf", ".", "split", "(", "axis", "=", "len", "(", "flat", ".", "shape", ")", "-", "1", ",", "num_or_size_splits", "=", "2", ",", "value", "=", "flat", ")", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "logstd", "=", "logstd", "\n", "self", ".", "std", "=", "tf", ".", "exp", "(", "logstd", ")", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.flatparam": [[234, 236], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "flat", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.mode": [[236, 238], ["None"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean", "\n", "", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.neglogp": [[238, 242], ["tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.to_float", "tensorflow.square", "numpy.log", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape"], ["", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "0.5", "*", "tf", ".", "reduce_sum", "(", "tf", ".", "square", "(", "(", "x", "-", "self", ".", "mean", ")", "/", "self", ".", "std", ")", ",", "axis", "=", "-", "1", ")", "+", "0.5", "*", "np", ".", "log", "(", "2.0", "*", "np", ".", "pi", ")", "*", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "x", ")", "[", "-", "1", "]", ")", "+", "tf", ".", "reduce_sum", "(", "self", ".", "logstd", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.kl": [[242, 245], ["isinstance", "tensorflow.reduce_sum", "tensorflow.square", "tensorflow.square", "tensorflow.square"], "methods", ["None"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "assert", "isinstance", "(", "other", ",", "DiagGaussianPd", ")", "\n", "return", "tf", ".", "reduce_sum", "(", "other", ".", "logstd", "-", "self", ".", "logstd", "+", "(", "tf", ".", "square", "(", "self", ".", "std", ")", "+", "tf", ".", "square", "(", "self", ".", "mean", "-", "other", ".", "mean", ")", ")", "/", "(", "2.0", "*", "tf", ".", "square", "(", "other", ".", "std", ")", ")", "-", "0.5", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.entropy": [[245, 247], ["tensorflow.reduce_sum", "numpy.log"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "self", ".", "logstd", "+", ".5", "*", "np", ".", "log", "(", "2.0", "*", "np", ".", "pi", "*", "np", ".", "e", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.sample": [[247, 249], ["tensorflow.random_normal", "tensorflow.shape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "mean", "+", "self", ".", "std", "*", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "self", ".", "mean", ")", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.DiagGaussianPd.fromflat": [[249, 252], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.__init__": [[255, 258], ["tensorflow.sigmoid"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "logits", ")", ":", "\n", "        ", "self", ".", "logits", "=", "logits", "\n", "self", ".", "ps", "=", "tf", ".", "sigmoid", "(", "logits", ")", "\n", "", "def", "flatparam", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.flatparam": [[258, 260], ["None"], "methods", ["None"], ["", "def", "flatparam", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "logits", "\n", "", "@", "property", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean": [[260, 263], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "mean", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ps", "\n", "", "def", "mode", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mode": [[263, 265], ["tensorflow.round"], "methods", ["None"], ["", "def", "mode", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "round", "(", "self", ".", "ps", ")", "\n", "", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.neglogp": [[265, 267], ["tensorflow.reduce_sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.to_float"], "methods", ["None"], ["", "def", "neglogp", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "tf", ".", "to_float", "(", "x", ")", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "kl", "(", "self", ",", "other", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.kl": [[267, 269], ["tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "kl", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "other", ".", "logits", ",", "labels", "=", "self", ".", "ps", ")", ",", "axis", "=", "-", "1", ")", "-", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "self", ".", "ps", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "entropy", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy": [[269, 271], ["tensorflow.reduce_sum", "tensorflow.nn.sigmoid_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "entropy", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "reduce_sum", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "self", ".", "logits", ",", "labels", "=", "self", ".", "ps", ")", ",", "axis", "=", "-", "1", ")", "\n", "", "def", "sample", "(", "self", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample": [[271, 274], ["tensorflow.random_uniform", "tensorflow.to_float", "tensorflow.shape", "tensorflow.python.ops.math_ops.less"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape"], ["", "def", "sample", "(", "self", ")", ":", "\n", "        ", "u", "=", "tf", ".", "random_uniform", "(", "tf", ".", "shape", "(", "self", ".", "ps", ")", ")", "\n", "return", "tf", ".", "to_float", "(", "math_ops", ".", "less", "(", "u", ",", "self", ".", "ps", ")", ")", "\n", "", "@", "classmethod", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.fromflat": [[274, 277], ["cls"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "fromflat", "(", "cls", ",", "flat", ")", ":", "\n", "        ", "return", "cls", "(", "flat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.make_pdtype": [[278, 291], ["isinstance", "distributions.DiagGaussianPdType", "isinstance", "len", "distributions.CategoricalPdType", "isinstance", "distributions.MultiCategoricalPdType", "isinstance", "distributions.BernoulliPdType"], "function", ["None"], ["", "", "def", "make_pdtype", "(", "ac_space", ")", ":", "\n", "    ", "from", "gym", "import", "spaces", "\n", "if", "isinstance", "(", "ac_space", ",", "spaces", ".", "Box", ")", ":", "\n", "        ", "assert", "len", "(", "ac_space", ".", "shape", ")", "==", "1", "\n", "return", "DiagGaussianPdType", "(", "ac_space", ".", "shape", "[", "0", "]", ")", "\n", "", "elif", "isinstance", "(", "ac_space", ",", "spaces", ".", "Discrete", ")", ":", "\n", "        ", "return", "CategoricalPdType", "(", "ac_space", ".", "n", ")", "\n", "", "elif", "isinstance", "(", "ac_space", ",", "spaces", ".", "MultiDiscrete", ")", ":", "\n", "        ", "return", "MultiCategoricalPdType", "(", "ac_space", ".", "nvec", ")", "\n", "", "elif", "isinstance", "(", "ac_space", ",", "spaces", ".", "MultiBinary", ")", ":", "\n", "        ", "return", "BernoulliPdType", "(", "ac_space", ".", "n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.shape_el": [[292, 298], ["v.get_shape", "tensorflow.shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.shape"], ["", "", "def", "shape_el", "(", "v", ",", "i", ")", ":", "\n", "    ", "maybe", "=", "v", ".", "get_shape", "(", ")", "[", "i", "]", "\n", "if", "maybe", "is", "not", "None", ":", "\n", "        ", "return", "maybe", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "shape", "(", "v", ")", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.test_probtypes": [[299, 319], ["numpy.random.seed", "numpy.array", "distributions.DiagGaussianPdType", "distributions.validate_probtype", "numpy.array", "distributions.CategoricalPdType", "distributions.validate_probtype", "numpy.array", "distributions.MultiCategoricalPdType", "distributions.validate_probtype", "numpy.array", "distributions.BernoulliPdType", "distributions.validate_probtype"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.validate_probtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.validate_probtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.validate_probtype", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.validate_probtype"], ["", "", "@", "U", ".", "in_session", "\n", "def", "test_probtypes", "(", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "\n", "pdparam_diag_gauss", "=", "np", ".", "array", "(", "[", "-", ".2", ",", ".3", ",", ".4", ",", "-", ".5", ",", ".1", ",", "-", ".5", ",", ".1", ",", "0.8", "]", ")", "\n", "diag_gauss", "=", "DiagGaussianPdType", "(", "pdparam_diag_gauss", ".", "size", "//", "2", ")", "#pylint: disable=E1101", "\n", "validate_probtype", "(", "diag_gauss", ",", "pdparam_diag_gauss", ")", "\n", "\n", "pdparam_categorical", "=", "np", ".", "array", "(", "[", "-", ".2", ",", ".3", ",", ".5", "]", ")", "\n", "categorical", "=", "CategoricalPdType", "(", "pdparam_categorical", ".", "size", ")", "#pylint: disable=E1101", "\n", "validate_probtype", "(", "categorical", ",", "pdparam_categorical", ")", "\n", "\n", "nvec", "=", "[", "1", ",", "2", ",", "3", "]", "\n", "pdparam_multicategorical", "=", "np", ".", "array", "(", "[", "-", ".2", ",", ".3", ",", ".5", ",", ".1", ",", "1", ",", "-", ".1", "]", ")", "\n", "multicategorical", "=", "MultiCategoricalPdType", "(", "nvec", ")", "#pylint: disable=E1101", "\n", "validate_probtype", "(", "multicategorical", ",", "pdparam_multicategorical", ")", "\n", "\n", "pdparam_bernoulli", "=", "np", ".", "array", "(", "[", "-", ".2", ",", ".3", ",", ".5", "]", ")", "\n", "bernoulli", "=", "BernoulliPdType", "(", "pdparam_bernoulli", ".", "size", ")", "#pylint: disable=E1101", "\n", "validate_probtype", "(", "bernoulli", ",", "pdparam_bernoulli", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.validate_probtype": [[321, 349], ["numpy.repeat", "probtype.param_placeholder", "probtype.sample_placeholder", "probtype.pdfromflat", "baselines.function", "baselines.function", "tensorflow.get_default_session().run", "U.function.", "U.function.mean", "probtype.param_placeholder", "probtype.pdfromflat", "numpy.repeat", "baselines.function", "U.function.mean", "U.function.", "print", "probtype.pdfromflat.logp", "probtype.pdfromflat.entropy", "probtype.pdfromflat.sample", "calcloglik.mean", "calcloglik.std", "numpy.sqrt", "numpy.abs", "probtype.pdfromflat.kl", "calcloglik.mean", "calcloglik.std", "numpy.sqrt", "numpy.abs", "tensorflow.get_default_session", "U.function.", "numpy.random.randn", "U.function."], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.param_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.sample_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.PdType.param_placeholder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.MultiCategoricalPdType.pdfromflat", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.logp", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.entropy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.kl", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "def", "validate_probtype", "(", "probtype", ",", "pdparam", ")", ":", "\n", "    ", "N", "=", "100000", "\n", "# Check to see if mean negative log likelihood == differential entropy", "\n", "Mval", "=", "np", ".", "repeat", "(", "pdparam", "[", "None", ",", ":", "]", ",", "N", ",", "axis", "=", "0", ")", "\n", "M", "=", "probtype", ".", "param_placeholder", "(", "[", "N", "]", ")", "\n", "X", "=", "probtype", ".", "sample_placeholder", "(", "[", "N", "]", ")", "\n", "pd", "=", "probtype", ".", "pdfromflat", "(", "M", ")", "\n", "calcloglik", "=", "U", ".", "function", "(", "[", "X", ",", "M", "]", ",", "pd", ".", "logp", "(", "X", ")", ")", "\n", "calcent", "=", "U", ".", "function", "(", "[", "M", "]", ",", "pd", ".", "entropy", "(", ")", ")", "\n", "Xval", "=", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "pd", ".", "sample", "(", ")", ",", "feed_dict", "=", "{", "M", ":", "Mval", "}", ")", "\n", "logliks", "=", "calcloglik", "(", "Xval", ",", "Mval", ")", "\n", "entval_ll", "=", "-", "logliks", ".", "mean", "(", ")", "#pylint: disable=E1101", "\n", "entval_ll_stderr", "=", "logliks", ".", "std", "(", ")", "/", "np", ".", "sqrt", "(", "N", ")", "#pylint: disable=E1101", "\n", "entval", "=", "calcent", "(", "Mval", ")", ".", "mean", "(", ")", "#pylint: disable=E1101", "\n", "assert", "np", ".", "abs", "(", "entval", "-", "entval_ll", ")", "<", "3", "*", "entval_ll_stderr", "# within 3 sigmas", "\n", "\n", "# Check to see if kldiv[p,q] = - ent[p] - E_p[log q]", "\n", "M2", "=", "probtype", ".", "param_placeholder", "(", "[", "N", "]", ")", "\n", "pd2", "=", "probtype", ".", "pdfromflat", "(", "M2", ")", "\n", "q", "=", "pdparam", "+", "np", ".", "random", ".", "randn", "(", "pdparam", ".", "size", ")", "*", "0.1", "\n", "Mval2", "=", "np", ".", "repeat", "(", "q", "[", "None", ",", ":", "]", ",", "N", ",", "axis", "=", "0", ")", "\n", "calckl", "=", "U", ".", "function", "(", "[", "M", ",", "M2", "]", ",", "pd", ".", "kl", "(", "pd2", ")", ")", "\n", "klval", "=", "calckl", "(", "Mval", ",", "Mval2", ")", ".", "mean", "(", ")", "#pylint: disable=E1101", "\n", "logliks", "=", "calcloglik", "(", "Xval", ",", "Mval2", ")", "\n", "klval_ll", "=", "-", "entval", "-", "logliks", ".", "mean", "(", ")", "#pylint: disable=E1101", "\n", "klval_ll_stderr", "=", "logliks", ".", "std", "(", ")", "/", "np", ".", "sqrt", "(", "N", ")", "#pylint: disable=E1101", "\n", "assert", "np", ".", "abs", "(", "klval", "-", "klval_ll", ")", "<", "3", "*", "klval_ll_stderr", "# within 3 sigmas", "\n", "print", "(", "'ok on'", ",", "probtype", ",", "pdparam", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions._matching_fc": [[351, 356], ["baselines.a2c.utils.fc"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.fc"], ["", "def", "_matching_fc", "(", "tensor", ",", "name", ",", "size", ",", "init_scale", ",", "init_bias", ")", ":", "\n", "    ", "if", "tensor", ".", "shape", "[", "-", "1", "]", "==", "size", ":", "\n", "        ", "return", "tensor", "\n", "", "else", ":", "\n", "        ", "return", "fc", "(", "tensor", ",", "name", ",", "size", ",", "init_scale", "=", "init_scale", ",", "init_bias", "=", "init_bias", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._Function.__init__": [[183, 193], ["tensorflow.group", "list", "[].split", "hasattr", "type", "len", "inp.name.split"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "inputs", ",", "outputs", ",", "updates", ",", "givens", ")", ":", "\n", "        ", "for", "inpt", "in", "inputs", ":", "\n", "            ", "if", "not", "hasattr", "(", "inpt", ",", "'make_feed_dict'", ")", "and", "not", "(", "type", "(", "inpt", ")", "is", "tf", ".", "Tensor", "and", "len", "(", "inpt", ".", "op", ".", "inputs", ")", "==", "0", ")", ":", "\n", "                ", "assert", "False", ",", "\"inputs should all be placeholders, constants, or have a make_feed_dict method\"", "\n", "", "", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "input_names", "=", "{", "inp", ".", "name", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", ".", "split", "(", "\":\"", ")", "[", "0", "]", ":", "inp", "for", "inp", "in", "inputs", "}", "\n", "updates", "=", "updates", "or", "[", "]", "\n", "self", ".", "update_group", "=", "tf", ".", "group", "(", "*", "updates", ")", "\n", "self", ".", "outputs_update", "=", "list", "(", "outputs", ")", "+", "[", "self", ".", "update_group", "]", "\n", "self", ".", "givens", "=", "{", "}", "if", "givens", "is", "None", "else", "givens", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._Function._feed_input": [[194, 199], ["hasattr", "feed_dict.update", "tf_util.adjust_shape", "inpt.make_feed_dict"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.adjust_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.utils.PlaceholderTfInput.make_feed_dict"], ["", "def", "_feed_input", "(", "self", ",", "feed_dict", ",", "inpt", ",", "value", ")", ":", "\n", "        ", "if", "hasattr", "(", "inpt", ",", "'make_feed_dict'", ")", ":", "\n", "            ", "feed_dict", ".", "update", "(", "inpt", ".", "make_feed_dict", "(", "value", ")", ")", "\n", "", "else", ":", "\n", "            ", "feed_dict", "[", "inpt", "]", "=", "adjust_shape", "(", "inpt", ",", "value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._Function.__call__": [[200, 213], ["zip", "kwargs.items", "len", "tf_util.adjust_shape", "tf_util._Function._feed_input", "tf_util._Function._feed_input", "get_session().run", "len", "len", "feed_dict.get", "tf_util.get_session"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.adjust_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._Function._feed_input", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._Function._feed_input", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.acer.buffer.Buffer.get", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session"], ["", "", "def", "__call__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "len", "(", "args", ")", "+", "len", "(", "kwargs", ")", "<=", "len", "(", "self", ".", "inputs", ")", ",", "\"Too many arguments provided\"", "\n", "feed_dict", "=", "{", "}", "\n", "# Update feed dict with givens.", "\n", "for", "inpt", "in", "self", ".", "givens", ":", "\n", "            ", "feed_dict", "[", "inpt", "]", "=", "adjust_shape", "(", "inpt", ",", "feed_dict", ".", "get", "(", "inpt", ",", "self", ".", "givens", "[", "inpt", "]", ")", ")", "\n", "# Update the args", "\n", "", "for", "inpt", ",", "value", "in", "zip", "(", "self", ".", "inputs", ",", "args", ")", ":", "\n", "            ", "self", ".", "_feed_input", "(", "feed_dict", ",", "inpt", ",", "value", ")", "\n", "", "for", "inpt_name", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "_feed_input", "(", "feed_dict", ",", "self", ".", "input_names", "[", "inpt_name", "]", ",", "value", ")", "\n", "", "results", "=", "get_session", "(", ")", ".", "run", "(", "self", ".", "outputs_update", ",", "feed_dict", "=", "feed_dict", ")", "[", ":", "-", "1", "]", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.SetFromFlat.__init__": [[240, 253], ["list", "numpy.sum", "tensorflow.placeholder", "zip", "tensorflow.group", "map", "tf_util.intprod", "assigns.append", "tf_util.intprod", "tensorflow.assign", "tensorflow.reshape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod"], ["    ", "def", "__init__", "(", "self", ",", "var_list", ",", "dtype", "=", "tf", ".", "float32", ")", ":", "\n", "        ", "assigns", "=", "[", "]", "\n", "shapes", "=", "list", "(", "map", "(", "var_shape", ",", "var_list", ")", ")", "\n", "total_size", "=", "np", ".", "sum", "(", "[", "intprod", "(", "shape", ")", "for", "shape", "in", "shapes", "]", ")", "\n", "\n", "self", ".", "theta", "=", "theta", "=", "tf", ".", "placeholder", "(", "dtype", ",", "[", "total_size", "]", ")", "\n", "start", "=", "0", "\n", "assigns", "=", "[", "]", "\n", "for", "(", "shape", ",", "v", ")", "in", "zip", "(", "shapes", ",", "var_list", ")", ":", "\n", "            ", "size", "=", "intprod", "(", "shape", ")", "\n", "assigns", ".", "append", "(", "tf", ".", "assign", "(", "v", ",", "tf", ".", "reshape", "(", "theta", "[", "start", ":", "start", "+", "size", "]", ",", "shape", ")", ")", ")", "\n", "start", "+=", "size", "\n", "", "self", ".", "op", "=", "tf", ".", "group", "(", "*", "assigns", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.SetFromFlat.__call__": [[254, 256], ["tensorflow.get_default_session().run", "tensorflow.get_default_session"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "__call__", "(", "self", ",", "theta", ")", ":", "\n", "        ", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "self", ".", "op", ",", "feed_dict", "=", "{", "self", ".", "theta", ":", "theta", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.GetFlat.__init__": [[258, 260], ["tensorflow.concat", "tensorflow.reshape", "tf_util.numel"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.numel"], ["    ", "def", "__init__", "(", "self", ",", "var_list", ")", ":", "\n", "        ", "self", ".", "op", "=", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "[", "tf", ".", "reshape", "(", "v", ",", "[", "numel", "(", "v", ")", "]", ")", "for", "v", "in", "var_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.GetFlat.__call__": [[261, 263], ["tensorflow.get_default_session().run", "tensorflow.get_default_session"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "return", "tf", ".", "get_default_session", "(", ")", ".", "run", "(", "self", ".", "op", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.switch": [[9, 25], ["copy.copy", "tensorflow.cond", "tf.cond.set_shape", "then_expression.get_shape", "tensorflow.cast"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["def", "switch", "(", "condition", ",", "then_expression", ",", "else_expression", ")", ":", "\n", "    ", "\"\"\"Switches between two operations depending on a scalar value (int or bool).\n    Note that both `then_expression` and `else_expression`\n    should be symbolic tensors of the *same shape*.\n\n    # Arguments\n        condition: scalar tensor.\n        then_expression: TensorFlow operation.\n        else_expression: TensorFlow operation.\n    \"\"\"", "\n", "x_shape", "=", "copy", ".", "copy", "(", "then_expression", ".", "get_shape", "(", ")", ")", "\n", "x", "=", "tf", ".", "cond", "(", "tf", ".", "cast", "(", "condition", ",", "'bool'", ")", ",", "\n", "lambda", ":", "then_expression", ",", "\n", "lambda", ":", "else_expression", ")", "\n", "x", ".", "set_shape", "(", "x_shape", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.lrelu": [[30, 34], ["abs"], "function", ["None"], ["", "def", "lrelu", "(", "x", ",", "leak", "=", "0.2", ")", ":", "\n", "    ", "f1", "=", "0.5", "*", "(", "1", "+", "leak", ")", "\n", "f2", "=", "0.5", "*", "(", "1", "-", "leak", ")", "\n", "return", "f1", "*", "x", "+", "f2", "*", "abs", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.huber_loss": [[39, 45], ["tensorflow.where", "tensorflow.abs", "tensorflow.square", "tensorflow.abs"], "function", ["None"], ["", "def", "huber_loss", "(", "x", ",", "delta", "=", "1.0", ")", ":", "\n", "    ", "\"\"\"Reference: https://en.wikipedia.org/wiki/Huber_loss\"\"\"", "\n", "return", "tf", ".", "where", "(", "\n", "tf", ".", "abs", "(", "x", ")", "<", "delta", ",", "\n", "tf", ".", "square", "(", "x", ")", "*", "0.5", ",", "\n", "delta", "*", "(", "tf", ".", "abs", "(", "x", ")", "-", "0.5", "*", "delta", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session": [[51, 57], ["tensorflow.get_default_session", "tf_util.make_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session"], ["", "def", "get_session", "(", "config", "=", "None", ")", ":", "\n", "    ", "\"\"\"Get default session or create one with a given config\"\"\"", "\n", "sess", "=", "tf", ".", "get_default_session", "(", ")", "\n", "if", "sess", "is", "None", ":", "\n", "        ", "sess", "=", "make_session", "(", "config", "=", "config", ",", "make_default", "=", "True", ")", "\n", "", "return", "sess", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session": [[58, 73], ["int", "tensorflow.ConfigProto", "tensorflow.InteractiveSession", "tensorflow.Session", "os.getenv", "multiprocessing.cpu_count"], "function", ["None"], ["", "def", "make_session", "(", "config", "=", "None", ",", "num_cpu", "=", "None", ",", "make_default", "=", "False", ",", "graph", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns a session that will use <num_cpu> CPU's only\"\"\"", "\n", "if", "num_cpu", "is", "None", ":", "\n", "        ", "num_cpu", "=", "int", "(", "os", ".", "getenv", "(", "'RCALL_NUM_CPU'", ",", "multiprocessing", ".", "cpu_count", "(", ")", ")", ")", "\n", "", "if", "config", "is", "None", ":", "\n", "        ", "config", "=", "tf", ".", "ConfigProto", "(", "\n", "allow_soft_placement", "=", "True", ",", "\n", "inter_op_parallelism_threads", "=", "num_cpu", ",", "\n", "intra_op_parallelism_threads", "=", "num_cpu", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "\n", "", "if", "make_default", ":", "\n", "        ", "return", "tf", ".", "InteractiveSession", "(", "config", "=", "config", ",", "graph", "=", "graph", ")", "\n", "", "else", ":", "\n", "        ", "return", "tf", ".", "Session", "(", "config", "=", "config", ",", "graph", "=", "graph", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.single_threaded_session": [[74, 77], ["tf_util.make_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session"], ["", "", "def", "single_threaded_session", "(", ")", ":", "\n", "    ", "\"\"\"Returns a session which will only use a single CPU\"\"\"", "\n", "return", "make_session", "(", "num_cpu", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.in_session": [[78, 84], ["functools.wraps", "tensorflow.Session", "f"], "function", ["None"], ["", "def", "in_session", "(", "f", ")", ":", "\n", "    ", "@", "functools", ".", "wraps", "(", "f", ")", "\n", "def", "newfunc", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "with", "tf", ".", "Session", "(", ")", ":", "\n", "            ", "f", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "", "", "return", "newfunc", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize": [[87, 92], ["get_session().run", "ALREADY_INITIALIZED.update", "set", "tensorflow.variables_initializer", "tensorflow.global_variables", "tf_util.get_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session"], ["def", "initialize", "(", ")", ":", "\n", "    ", "\"\"\"Initialize all the uninitialized variables in the global scope.\"\"\"", "\n", "new_variables", "=", "set", "(", "tf", ".", "global_variables", "(", ")", ")", "-", "ALREADY_INITIALIZED", "\n", "get_session", "(", ")", ".", "run", "(", "tf", ".", "variables_initializer", "(", "new_variables", ")", ")", "\n", "ALREADY_INITIALIZED", ".", "update", "(", "new_variables", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.normc_initializer": [[97, 103], ["numpy.random.randn().astype", "tensorflow.constant", "numpy.sqrt", "numpy.random.randn", "numpy.square().sum", "numpy.square"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.a2c.utils.constant", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "normc_initializer", "(", "std", "=", "1.0", ",", "axis", "=", "0", ")", ":", "\n", "    ", "def", "_initializer", "(", "shape", ",", "dtype", "=", "None", ",", "partition_info", "=", "None", ")", ":", "# pylint: disable=W0613", "\n", "        ", "out", "=", "np", ".", "random", ".", "randn", "(", "*", "shape", ")", ".", "astype", "(", "dtype", ".", "as_numpy_dtype", ")", "\n", "out", "*=", "std", "/", "np", ".", "sqrt", "(", "np", ".", "square", "(", "out", ")", ".", "sum", "(", "axis", "=", "axis", ",", "keepdims", "=", "True", ")", ")", "\n", "return", "tf", ".", "constant", "(", "out", ")", "\n", "", "return", "_initializer", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d": [[104, 132], ["tensorflow.variable_scope", "tf_util.intprod", "numpy.sqrt", "tensorflow.get_variable", "tensorflow.get_variable", "int", "tf_util.intprod", "tensorflow.random_uniform_initializer", "tensorflow.summary.image", "tensorflow.nn.conv2d", "tensorflow.zeros_initializer", "tensorflow.transpose", "x.get_shape", "tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.conv2d", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "def", "conv2d", "(", "x", ",", "num_filters", ",", "name", ",", "filter_size", "=", "(", "3", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ")", ",", "pad", "=", "\"SAME\"", ",", "dtype", "=", "tf", ".", "float32", ",", "collections", "=", "None", ",", "\n", "summary_tag", "=", "None", ")", ":", "\n", "    ", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "        ", "stride_shape", "=", "[", "1", ",", "stride", "[", "0", "]", ",", "stride", "[", "1", "]", ",", "1", "]", "\n", "filter_shape", "=", "[", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "int", "(", "x", ".", "get_shape", "(", ")", "[", "3", "]", ")", ",", "num_filters", "]", "\n", "\n", "# there are \"num input feature maps * filter height * filter width\"", "\n", "# inputs to each hidden unit", "\n", "fan_in", "=", "intprod", "(", "filter_shape", "[", ":", "3", "]", ")", "\n", "# each unit in the lower layer receives a gradient from:", "\n", "# \"num output feature maps * filter height * filter width\" /", "\n", "#   pooling size", "\n", "fan_out", "=", "intprod", "(", "filter_shape", "[", ":", "2", "]", ")", "*", "num_filters", "\n", "# initialize weights with random weights", "\n", "w_bound", "=", "np", ".", "sqrt", "(", "6.", "/", "(", "fan_in", "+", "fan_out", ")", ")", "\n", "\n", "w", "=", "tf", ".", "get_variable", "(", "\"W\"", ",", "filter_shape", ",", "dtype", ",", "tf", ".", "random_uniform_initializer", "(", "-", "w_bound", ",", "w_bound", ")", ",", "\n", "collections", "=", "collections", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b\"", ",", "[", "1", ",", "1", ",", "1", ",", "num_filters", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "collections", "=", "collections", ")", "\n", "\n", "if", "summary_tag", "is", "not", "None", ":", "\n", "            ", "tf", ".", "summary", ".", "image", "(", "summary_tag", ",", "\n", "tf", ".", "transpose", "(", "tf", ".", "reshape", "(", "w", ",", "[", "filter_size", "[", "0", "]", ",", "filter_size", "[", "1", "]", ",", "-", "1", ",", "1", "]", ")", ",", "\n", "[", "2", ",", "0", ",", "1", ",", "3", "]", ")", ",", "\n", "max_images", "=", "10", ")", "\n", "\n", "", "return", "tf", ".", "nn", ".", "conv2d", "(", "x", ",", "w", ",", "stride_shape", ",", "pad", ")", "+", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function": [[137, 180], ["isinstance", "tf_util._Function", "isinstance", "tf_util._Function", "tf_util._Function", "outputs.values", "type", "zip", "_Function.", "outputs.keys", "_Function."], "function", ["None"], ["", "", "def", "function", "(", "inputs", ",", "outputs", ",", "updates", "=", "None", ",", "givens", "=", "None", ")", ":", "\n", "    ", "\"\"\"Just like Theano function. Take a bunch of tensorflow placeholders and expressions\n    computed based on those placeholders and produces f(inputs) -> outputs. Function f takes\n    values to be fed to the input's placeholders and produces the values of the expressions\n    in outputs.\n\n    Input values can be passed in the same order as inputs or can be provided as kwargs based\n    on placeholder name (passed to constructor or accessible via placeholder.op.name).\n\n    Example:\n        x = tf.placeholder(tf.int32, (), name=\"x\")\n        y = tf.placeholder(tf.int32, (), name=\"y\")\n        z = 3 * x + 2 * y\n        lin = function([x, y], z, givens={y: 0})\n\n        with single_threaded_session():\n            initialize()\n\n            assert lin(2) == 6\n            assert lin(x=3) == 9\n            assert lin(2, 2) == 10\n            assert lin(x=2, y=3) == 12\n\n    Parameters\n    ----------\n    inputs: [tf.placeholder, tf.constant, or object with make_feed_dict method]\n        list of input arguments\n    outputs: [tf.Variable] or tf.Variable\n        list of outputs or a single output to be returned from function. Returned\n        value will also have the same shape.\n    updates: [tf.Operation] or tf.Operation\n        list of update functions or single update function that will be run whenever\n        the function is called. The return is ignored.\n\n    \"\"\"", "\n", "if", "isinstance", "(", "outputs", ",", "list", ")", ":", "\n", "        ", "return", "_Function", "(", "inputs", ",", "outputs", ",", "updates", ",", "givens", "=", "givens", ")", "\n", "", "elif", "isinstance", "(", "outputs", ",", "(", "dict", ",", "collections", ".", "OrderedDict", ")", ")", ":", "\n", "        ", "f", "=", "_Function", "(", "inputs", ",", "outputs", ".", "values", "(", ")", ",", "updates", ",", "givens", "=", "givens", ")", "\n", "return", "lambda", "*", "args", ",", "**", "kwargs", ":", "type", "(", "outputs", ")", "(", "zip", "(", "outputs", ".", "keys", "(", ")", ",", "f", "(", "*", "args", ",", "**", "kwargs", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "f", "=", "_Function", "(", "inputs", ",", "[", "outputs", "]", ",", "updates", ",", "givens", "=", "givens", ")", "\n", "return", "lambda", "*", "args", ",", "**", "kwargs", ":", "f", "(", "*", "args", ",", "**", "kwargs", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.var_shape": [[218, 223], ["x.get_shape().as_list", "all", "x.get_shape", "isinstance"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "", "def", "var_shape", "(", "x", ")", ":", "\n", "    ", "out", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "assert", "all", "(", "isinstance", "(", "a", ",", "int", ")", "for", "a", "in", "out", ")", ",", "\"shape function assumes that shape is fully known\"", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.numel": [[224, 226], ["tf_util.intprod", "tf_util.var_shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.var_shape"], ["", "def", "numel", "(", "x", ")", ":", "\n", "    ", "return", "intprod", "(", "var_shape", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod": [[227, 229], ["int", "numpy.prod"], "function", ["None"], ["", "def", "intprod", "(", "x", ")", ":", "\n", "    ", "return", "int", "(", "np", ".", "prod", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flatgrad": [[230, 237], ["tensorflow.gradients", "tensorflow.concat", "tensorflow.clip_by_norm", "tensorflow.reshape", "zip", "tensorflow.zeros_like", "tf_util.numel"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.numel"], ["", "def", "flatgrad", "(", "loss", ",", "var_list", ",", "clip_norm", "=", "None", ")", ":", "\n", "    ", "grads", "=", "tf", ".", "gradients", "(", "loss", ",", "var_list", ")", "\n", "if", "clip_norm", "is", "not", "None", ":", "\n", "        ", "grads", "=", "[", "tf", ".", "clip_by_norm", "(", "grad", ",", "clip_norm", "=", "clip_norm", ")", "for", "grad", "in", "grads", "]", "\n", "", "return", "tf", ".", "concat", "(", "axis", "=", "0", ",", "values", "=", "[", "\n", "tf", ".", "reshape", "(", "grad", "if", "grad", "is", "not", "None", "else", "tf", ".", "zeros_like", "(", "v", ")", ",", "[", "numel", "(", "v", ")", "]", ")", "\n", "for", "(", "v", ",", "grad", ")", "in", "zip", "(", "var_list", ",", "grads", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.flattenallbut0": [[264, 266], ["tensorflow.reshape", "tf_util.intprod", "x.get_shape().as_list", "x.get_shape"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.intprod", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.Pd.get_shape"], ["", "", "def", "flattenallbut0", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "intprod", "(", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "[", "1", ":", "]", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder": [[273, 284], ["tensorflow.placeholder", "tensorflow.get_default_graph"], "function", ["None"], ["def", "get_placeholder", "(", "name", ",", "dtype", ",", "shape", ")", ":", "\n", "    ", "if", "name", "in", "_PLACEHOLDER_CACHE", ":", "\n", "        ", "out", ",", "dtype1", ",", "shape1", "=", "_PLACEHOLDER_CACHE", "[", "name", "]", "\n", "if", "out", ".", "graph", "==", "tf", ".", "get_default_graph", "(", ")", ":", "\n", "            ", "assert", "dtype1", "==", "dtype", "and", "shape1", "==", "shape", ",", "'Placeholder with name {} has already been registered and has shape {}, different from requested {}'", ".", "format", "(", "name", ",", "shape1", ",", "shape", ")", "\n", "return", "out", "\n", "\n", "", "", "out", "=", "tf", ".", "placeholder", "(", "dtype", "=", "dtype", ",", "shape", "=", "shape", ",", "name", "=", "name", ")", "\n", "_PLACEHOLDER_CACHE", "[", "name", "]", "=", "(", "out", ",", "dtype", ",", "shape", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_placeholder_cached": [[285, 287], ["None"], "function", ["None"], ["", "def", "get_placeholder_cached", "(", "name", ")", ":", "\n", "    ", "return", "_PLACEHOLDER_CACHE", "[", "name", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.display_var_info": [[294, 306], ["logger.info", "numpy.prod", "logger.info", "v.shape.as_list", "str", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info"], ["", "def", "display_var_info", "(", "vars", ")", ":", "\n", "    ", "from", "baselines", "import", "logger", "\n", "count_params", "=", "0", "\n", "for", "v", "in", "vars", ":", "\n", "        ", "name", "=", "v", ".", "name", "\n", "if", "\"/Adam\"", "in", "name", "or", "\"beta1_power\"", "in", "name", "or", "\"beta2_power\"", "in", "name", ":", "continue", "\n", "v_params", "=", "np", ".", "prod", "(", "v", ".", "shape", ".", "as_list", "(", ")", ")", "\n", "count_params", "+=", "v_params", "\n", "if", "\"/b:\"", "in", "name", "or", "\"/bias\"", "in", "name", ":", "continue", "# Wx+b, bias is not interesting to look at => count params, but not print", "\n", "logger", ".", "info", "(", "\"   %s%s %i params %s\"", "%", "(", "name", ",", "\" \"", "*", "(", "55", "-", "len", "(", "name", ")", ")", ",", "v_params", ",", "str", "(", "v", ".", "shape", ")", ")", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Total model parameters: %0.2f million\"", "%", "(", "count_params", "*", "1e-6", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_available_gpus": [[308, 320], ["device_lib.list_local_devices", "tf_util.get_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session"], ["", "def", "get_available_gpus", "(", "session_config", "=", "None", ")", ":", "\n", "# based on recipe from https://stackoverflow.com/a/38580201", "\n", "\n", "# Unless we allocate a session here, subsequent attempts to create one", "\n", "# will ignore our custom config (in particular, allow_growth=True will have", "\n", "# no effect).", "\n", "    ", "if", "session_config", "is", "None", ":", "\n", "        ", "session_config", "=", "get_session", "(", ")", ".", "_config", "\n", "\n", "", "from", "tensorflow", ".", "python", ".", "client", "import", "device_lib", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", "session_config", ")", "\n", "return", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_state": [[325, 331], ["logger.warn", "tensorflow.train.Saver", "tf.train.Saver.restore", "tf_util.get_session", "tensorflow.get_default_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session"], ["", "def", "load_state", "(", "fname", ",", "sess", "=", "None", ")", ":", "\n", "    ", "from", "baselines", "import", "logger", "\n", "logger", ".", "warn", "(", "'load_state method is deprecated, please use load_variables instead'", ")", "\n", "sess", "=", "sess", "or", "get_session", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "restore", "(", "tf", ".", "get_default_session", "(", ")", ",", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_state": [[332, 341], ["logger.warn", "os.path.dirname", "any", "tensorflow.train.Saver", "tf.train.Saver.save", "tf_util.get_session", "os.makedirs", "tensorflow.get_default_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session"], ["", "def", "save_state", "(", "fname", ",", "sess", "=", "None", ")", ":", "\n", "    ", "from", "baselines", "import", "logger", "\n", "logger", ".", "warn", "(", "'save_state method is deprecated, please use save_variables instead'", ")", "\n", "sess", "=", "sess", "or", "get_session", "(", ")", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "fname", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "saver", ".", "save", "(", "tf", ".", "get_default_session", "(", ")", ",", "fname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.save_variables": [[345, 356], ["sess.run", "os.path.dirname", "any", "joblib.dump", "tf_util.get_session", "tensorflow.get_collection", "os.makedirs", "zip"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session"], ["", "def", "save_variables", "(", "save_path", ",", "variables", "=", "None", ",", "sess", "=", "None", ")", ":", "\n", "    ", "import", "joblib", "\n", "sess", "=", "sess", "or", "get_session", "(", ")", "\n", "variables", "=", "variables", "or", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "\n", "ps", "=", "sess", ".", "run", "(", "variables", ")", "\n", "save_dict", "=", "{", "v", ".", "name", ":", "value", "for", "v", ",", "value", "in", "zip", "(", "variables", ",", "ps", ")", "}", "\n", "dirname", "=", "os", ".", "path", ".", "dirname", "(", "save_path", ")", "\n", "if", "any", "(", "dirname", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "dirname", ",", "exist_ok", "=", "True", ")", "\n", "", "joblib", ".", "dump", "(", "save_dict", ",", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.load_variables": [[357, 373], ["joblib.load", "isinstance", "sess.run", "tf_util.get_session", "tensorflow.get_collection", "os.path.expanduser", "zip", "len", "len", "restores.append", "restores.append", "v.assign", "v.assign"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "load_variables", "(", "load_path", ",", "variables", "=", "None", ",", "sess", "=", "None", ")", ":", "\n", "    ", "import", "joblib", "\n", "sess", "=", "sess", "or", "get_session", "(", ")", "\n", "variables", "=", "variables", "or", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_VARIABLES", ")", "\n", "\n", "loaded_params", "=", "joblib", ".", "load", "(", "os", ".", "path", ".", "expanduser", "(", "load_path", ")", ")", "\n", "restores", "=", "[", "]", "\n", "if", "isinstance", "(", "loaded_params", ",", "list", ")", ":", "\n", "        ", "assert", "len", "(", "loaded_params", ")", "==", "len", "(", "variables", ")", ",", "'number of variables loaded mismatches len(variables)'", "\n", "for", "d", ",", "v", "in", "zip", "(", "loaded_params", ",", "variables", ")", ":", "\n", "            ", "restores", ".", "append", "(", "v", ".", "assign", "(", "d", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "for", "v", "in", "variables", ":", "\n", "            ", "restores", ".", "append", "(", "v", ".", "assign", "(", "loaded_params", "[", "v", ".", "name", "]", ")", ")", "\n", "\n", "", "", "sess", ".", "run", "(", "restores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.adjust_shape": [[377, 402], ["isinstance", "tf_util._check_shape", "numpy.reshape", "numpy.array", "isinstance", "isinstance", "placeholder.shape.as_list"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._check_shape"], ["", "def", "adjust_shape", "(", "placeholder", ",", "data", ")", ":", "\n", "    ", "'''\n    adjust shape of the data to the shape of the placeholder if possible.\n    If shape is incompatible, AssertionError is thrown\n\n    Parameters:\n        placeholder     tensorflow input placeholder\n\n        data            input data to be (potentially) reshaped to be fed into placeholder\n\n    Returns:\n        reshaped data\n    '''", "\n", "\n", "if", "not", "isinstance", "(", "data", ",", "np", ".", "ndarray", ")", "and", "not", "isinstance", "(", "data", ",", "list", ")", ":", "\n", "        ", "return", "data", "\n", "", "if", "isinstance", "(", "data", ",", "list", ")", ":", "\n", "        ", "data", "=", "np", ".", "array", "(", "data", ")", "\n", "\n", "", "placeholder_shape", "=", "[", "x", "or", "-", "1", "for", "x", "in", "placeholder", ".", "shape", ".", "as_list", "(", ")", "]", "\n", "\n", "assert", "_check_shape", "(", "placeholder_shape", ",", "data", ".", "shape", ")", ",", "'Shape of data {} is not compatible with shape of the placeholder {}'", ".", "format", "(", "data", ".", "shape", ",", "placeholder_shape", ")", "\n", "\n", "return", "np", ".", "reshape", "(", "data", ",", "placeholder_shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._check_shape": [[404, 417], ["tf_util._squeeze_shape", "tf_util._squeeze_shape", "enumerate"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._squeeze_shape", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._squeeze_shape"], ["", "def", "_check_shape", "(", "placeholder_shape", ",", "data_shape", ")", ":", "\n", "    ", "''' check if two shapes are compatible (i.e. differ only by dimensions of size 1, or by the batch dimension)'''", "\n", "\n", "return", "True", "\n", "squeezed_placeholder_shape", "=", "_squeeze_shape", "(", "placeholder_shape", ")", "\n", "squeezed_data_shape", "=", "_squeeze_shape", "(", "data_shape", ")", "\n", "\n", "for", "i", ",", "s_data", "in", "enumerate", "(", "squeezed_data_shape", ")", ":", "\n", "        ", "s_placeholder", "=", "squeezed_placeholder_shape", "[", "i", "]", "\n", "if", "s_placeholder", "!=", "-", "1", "and", "s_data", "!=", "s_placeholder", ":", "\n", "            ", "return", "False", "\n", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util._squeeze_shape": [[419, 421], ["None"], "function", ["None"], ["", "def", "_squeeze_shape", "(", "shape", ")", ":", "\n", "    ", "return", "[", "x", "for", "x", "in", "shape", "if", "x", "!=", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.launch_tensorboard_in_background": [[426, 444], ["subprocess.Popen"], "function", ["None"], ["", "def", "launch_tensorboard_in_background", "(", "log_dir", ")", ":", "\n", "    ", "'''\n    To log the Tensorflow graph when using rl-algs\n    algorithms, you can run the following code\n    in your main script:\n        import threading, time\n        def start_tensorboard(session):\n            time.sleep(10) # Wait until graph is setup\n            tb_path = osp.join(logger.get_dir(), 'tb')\n            summary_writer = tf.summary.FileWriter(tb_path, graph=session.graph)\n            summary_op = tf.summary.merge_all()\n            launch_tensorboard_in_background(tb_path)\n        session = tf.get_default_session()\n        t = threading.Thread(target=start_tensorboard, args=([session]))\n        t.start()\n    '''", "\n", "import", "subprocess", "\n", "subprocess", ".", "Popen", "(", "[", "'tensorboard'", ",", "'--logdir'", ",", "log_dir", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.test_mpi_util.test_mpi_weighted_mean": [[9, 30], ["baselines.common.tests.test_with_mpi.with_mpi", "baselines.logger.scoped_configure", "baselines.common.mpi_util.mpi_weighted_mean", "name2valcount.items", "baselines.logger.dumpkvs", "range", "baselines.logger.logkv_mean"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_with_mpi.with_mpi", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.scoped_configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_util.mpi_weighted_mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.dumpkvs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.logkv_mean"], ["", "@", "with_mpi", "(", ")", "\n", "def", "test_mpi_weighted_mean", "(", ")", ":", "\n", "    ", "comm", "=", "MPI", ".", "COMM_WORLD", "\n", "with", "logger", ".", "scoped_configure", "(", "comm", "=", "comm", ")", ":", "\n", "        ", "if", "comm", ".", "rank", "==", "0", ":", "\n", "            ", "name2valcount", "=", "{", "'a'", ":", "(", "10", ",", "2", ")", ",", "'b'", ":", "(", "20", ",", "3", ")", "}", "\n", "", "elif", "comm", ".", "rank", "==", "1", ":", "\n", "            ", "name2valcount", "=", "{", "'a'", ":", "(", "19", ",", "1", ")", ",", "'c'", ":", "(", "42", ",", "3", ")", "}", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "d", "=", "mpi_util", ".", "mpi_weighted_mean", "(", "comm", ",", "name2valcount", ")", "\n", "correctval", "=", "{", "'a'", ":", "(", "10", "*", "2", "+", "19", ")", "/", "3.0", ",", "'b'", ":", "20", ",", "'c'", ":", "42", "}", "\n", "if", "comm", ".", "rank", "==", "0", ":", "\n", "            ", "assert", "d", "==", "correctval", ",", "'{} != {}'", ".", "format", "(", "d", ",", "correctval", ")", "\n", "\n", "", "for", "name", ",", "(", "val", ",", "count", ")", "in", "name2valcount", ".", "items", "(", ")", ":", "\n", "            ", "for", "_", "in", "range", "(", "count", ")", ":", "\n", "                ", "logger", ".", "logkv_mean", "(", "name", ",", "val", ")", "\n", "", "", "d2", "=", "logger", ".", "dumpkvs", "(", ")", "\n", "if", "comm", ".", "rank", "==", "0", ":", "\n", "            ", "assert", "d2", "==", "correctval", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cg.cg": [[2, 35], ["b.copy", "b.copy", "numpy.zeros_like", "b.copy.dot", "range", "print", "f_Ax", "b.copy.dot", "callback", "print", "callback", "print", "b.copy.dot", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_cartpole.callback", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.experiments.train_cartpole.callback"], ["def", "cg", "(", "f_Ax", ",", "b", ",", "cg_iters", "=", "10", ",", "callback", "=", "None", ",", "verbose", "=", "False", ",", "residual_tol", "=", "1e-10", ")", ":", "\n", "    ", "\"\"\"\n    Demmel p 312\n    \"\"\"", "\n", "p", "=", "b", ".", "copy", "(", ")", "\n", "r", "=", "b", ".", "copy", "(", ")", "\n", "x", "=", "np", ".", "zeros_like", "(", "b", ")", "\n", "rdotr", "=", "r", ".", "dot", "(", "r", ")", "\n", "\n", "fmtstr", "=", "\"%10i %10.3g %10.3g\"", "\n", "titlestr", "=", "\"%10s %10s %10s\"", "\n", "if", "verbose", ":", "print", "(", "titlestr", "%", "(", "\"iter\"", ",", "\"residual norm\"", ",", "\"soln norm\"", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "cg_iters", ")", ":", "\n", "        ", "if", "callback", "is", "not", "None", ":", "\n", "            ", "callback", "(", "x", ")", "\n", "", "if", "verbose", ":", "print", "(", "fmtstr", "%", "(", "i", ",", "rdotr", ",", "np", ".", "linalg", ".", "norm", "(", "x", ")", ")", ")", "\n", "z", "=", "f_Ax", "(", "p", ")", "\n", "v", "=", "rdotr", "/", "p", ".", "dot", "(", "z", ")", "\n", "x", "+=", "v", "*", "p", "\n", "r", "-=", "v", "*", "z", "\n", "newrdotr", "=", "r", ".", "dot", "(", "r", ")", "\n", "mu", "=", "newrdotr", "/", "rdotr", "\n", "p", "=", "r", "+", "mu", "*", "p", "\n", "\n", "rdotr", "=", "newrdotr", "\n", "if", "rdotr", "<", "residual_tol", ":", "\n", "            ", "break", "\n", "\n", "", "", "if", "callback", "is", "not", "None", ":", "\n", "        ", "callback", "(", "x", ")", "\n", "", "if", "verbose", ":", "print", "(", "fmtstr", "%", "(", "i", "+", "1", ",", "rdotr", ",", "np", ".", "linalg", ".", "norm", "(", "x", ")", ")", ")", "# pylint: disable=W0631", "\n", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.NoopResetEnv.__init__": [[13, 22], ["gym.Wrapper.__init__", "env.unwrapped.get_action_meanings"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "noop_max", "=", "30", ")", ":", "\n", "        ", "\"\"\"Sample initial states by taking random number of no-ops on reset.\n        No-op is assumed to be action 0.\n        \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "noop_max", "=", "noop_max", "\n", "self", ".", "override_num_noops", "=", "None", "\n", "self", ".", "noop_action", "=", "0", "\n", "assert", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", "[", "0", "]", "==", "'NOOP'", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.NoopResetEnv.reset": [[23, 37], ["atari_wrappers.NoopResetEnv.env.reset", "range", "atari_wrappers.NoopResetEnv.unwrapped.np_random.randint", "atari_wrappers.NoopResetEnv.env.step", "atari_wrappers.NoopResetEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\" Do no-op action for a number of steps in [1, noop_max].\"\"\"", "\n", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "if", "self", ".", "override_num_noops", "is", "not", "None", ":", "\n", "            ", "noops", "=", "self", ".", "override_num_noops", "\n", "", "else", ":", "\n", "            ", "noops", "=", "self", ".", "unwrapped", ".", "np_random", ".", "randint", "(", "1", ",", "self", ".", "noop_max", "+", "1", ")", "#pylint: disable=E1101", "\n", "", "assert", "noops", ">", "0", "\n", "obs", "=", "None", "\n", "for", "_", "in", "range", "(", "noops", ")", ":", "\n", "            ", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "self", ".", "noop_action", ")", "\n", "if", "done", ":", "\n", "                ", "obs", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.NoopResetEnv.step": [[38, 40], ["atari_wrappers.NoopResetEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "step", "(", "ac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FireResetEnv.__init__": [[42, 47], ["gym.Wrapper.__init__", "len", "env.unwrapped.get_action_meanings", "env.unwrapped.get_action_meanings"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "\"\"\"Take action on reset for environments that are fixed until firing.\"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "assert", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", "[", "1", "]", "==", "'FIRE'", "\n", "assert", "len", "(", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", ")", ">=", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FireResetEnv.reset": [[48, 57], ["atari_wrappers.FireResetEnv.env.reset", "atari_wrappers.FireResetEnv.env.step", "atari_wrappers.FireResetEnv.env.step", "atari_wrappers.FireResetEnv.env.reset", "atari_wrappers.FireResetEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "1", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "obs", ",", "_", ",", "done", ",", "_", "=", "self", ".", "env", ".", "step", "(", "2", ")", "\n", "if", "done", ":", "\n", "            ", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FireResetEnv.step": [[58, 60], ["atari_wrappers.FireResetEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "ac", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "step", "(", "ac", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.EpisodicLifeEnv.__init__": [[62, 69], ["gym.Wrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "\"\"\"Make end-of-life == end-of-episode, but only reset on true game over.\n        Done by DeepMind for the DQN and co. since it helps value estimation.\n        \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "lives", "=", "0", "\n", "self", ".", "was_real_done", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.EpisodicLifeEnv.step": [[70, 83], ["atari_wrappers.EpisodicLifeEnv.env.step", "atari_wrappers.EpisodicLifeEnv.env.unwrapped.ale.lives"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "was_real_done", "=", "done", "\n", "# check current lives, make loss of life terminal,", "\n", "# then update lives to handle bonus lives", "\n", "lives", "=", "self", ".", "env", ".", "unwrapped", ".", "ale", ".", "lives", "(", ")", "\n", "if", "lives", "<", "self", ".", "lives", "and", "lives", ">", "0", ":", "\n", "# for Qbert sometimes we stay in lives == 0 condition for a few frames", "\n", "# so it's important to keep lives > 0, so that we only reset once", "\n", "# the environment advertises done.", "\n", "            ", "done", "=", "True", "\n", "", "self", ".", "lives", "=", "lives", "\n", "return", "obs", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.EpisodicLifeEnv.reset": [[84, 96], ["atari_wrappers.EpisodicLifeEnv.env.unwrapped.ale.lives", "atari_wrappers.EpisodicLifeEnv.env.reset", "atari_wrappers.EpisodicLifeEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "\"\"\"Reset only when lives are exhausted.\n        This way all states are still reachable even though lives are episodic,\n        and the learner need not know about any of this behind-the-scenes.\n        \"\"\"", "\n", "if", "self", ".", "was_real_done", ":", "\n", "            ", "obs", "=", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "# no-op step to advance from terminal/lost life state", "\n", "            ", "obs", ",", "_", ",", "_", ",", "_", "=", "self", ".", "env", ".", "step", "(", "0", ")", "\n", "", "self", ".", "lives", "=", "self", ".", "env", ".", "unwrapped", ".", "ale", ".", "lives", "(", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.MaxAndSkipEnv.__init__": [[98, 104], ["gym.Wrapper.__init__", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "skip", "=", "4", ")", ":", "\n", "        ", "\"\"\"Return only every `skip`-th frame\"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "# most recent raw observations (for max pooling across time steps)", "\n", "self", ".", "_obs_buffer", "=", "np", ".", "zeros", "(", "(", "2", ",", ")", "+", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "self", ".", "_skip", "=", "skip", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.MaxAndSkipEnv.step": [[105, 121], ["range", "atari_wrappers.MaxAndSkipEnv._obs_buffer.max", "atari_wrappers.MaxAndSkipEnv.env.step"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "\"\"\"Repeat action, sum reward, and max over last observations.\"\"\"", "\n", "total_reward", "=", "0.0", "\n", "done", "=", "None", "\n", "for", "i", "in", "range", "(", "self", ".", "_skip", ")", ":", "\n", "            ", "obs", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "if", "i", "==", "self", ".", "_skip", "-", "2", ":", "self", ".", "_obs_buffer", "[", "0", "]", "=", "obs", "\n", "if", "i", "==", "self", ".", "_skip", "-", "1", ":", "self", ".", "_obs_buffer", "[", "1", "]", "=", "obs", "\n", "total_reward", "+=", "reward", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "# Note that the observation on the done=True frame", "\n", "# doesn't matter", "\n", "", "", "max_frame", "=", "self", ".", "_obs_buffer", ".", "max", "(", "axis", "=", "0", ")", "\n", "\n", "return", "max_frame", ",", "total_reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.MaxAndSkipEnv.reset": [[122, 124], ["atari_wrappers.MaxAndSkipEnv.env.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "self", ".", "env", ".", "reset", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.__init__": [[126, 128], ["gym.RewardWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "gym", ".", "RewardWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ClipRewardEnv.reward": [[129, 132], ["numpy.sign"], "methods", ["None"], ["", "def", "reward", "(", "self", ",", "reward", ")", ":", "\n", "        ", "\"\"\"Bin reward to {+1, 0, -1} by its sign.\"\"\"", "\n", "return", "np", ".", "sign", "(", "reward", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.WarpFrame.__init__": [[135, 165], ["gym.ObservationWrapper.__init__", "gym.spaces.Box", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "width", "=", "84", ",", "height", "=", "84", ",", "grayscale", "=", "True", ",", "dict_space_key", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Warp frames to 84x84 as done in the Nature paper and later work.\n\n        If the environment uses dictionary observations, `dict_space_key` can be specified which indicates which\n        observation should be warped.\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "env", ")", "\n", "self", ".", "_width", "=", "width", "\n", "self", ".", "_height", "=", "height", "\n", "self", ".", "_grayscale", "=", "grayscale", "\n", "self", ".", "_key", "=", "dict_space_key", "\n", "if", "self", ".", "_grayscale", ":", "\n", "            ", "num_colors", "=", "1", "\n", "", "else", ":", "\n", "            ", "num_colors", "=", "3", "\n", "\n", "", "new_space", "=", "gym", ".", "spaces", ".", "Box", "(", "\n", "low", "=", "0", ",", "\n", "high", "=", "255", ",", "\n", "shape", "=", "(", "self", ".", "_height", ",", "self", ".", "_width", ",", "num_colors", ")", ",", "\n", "dtype", "=", "np", ".", "uint8", ",", "\n", ")", "\n", "if", "self", ".", "_key", "is", "None", ":", "\n", "            ", "original_space", "=", "self", ".", "observation_space", "\n", "self", ".", "observation_space", "=", "new_space", "\n", "", "else", ":", "\n", "            ", "original_space", "=", "self", ".", "observation_space", ".", "spaces", "[", "self", ".", "_key", "]", "\n", "self", ".", "observation_space", ".", "spaces", "[", "self", ".", "_key", "]", "=", "new_space", "\n", "", "assert", "original_space", ".", "dtype", "==", "np", ".", "uint8", "and", "len", "(", "original_space", ".", "shape", ")", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.WarpFrame.observation": [[166, 186], ["cv2.resize", "cv2.cvtColor", "numpy.expand_dims", "obs.copy.copy.copy"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "self", ".", "_key", "is", "None", ":", "\n", "            ", "frame", "=", "obs", "\n", "", "else", ":", "\n", "            ", "frame", "=", "obs", "[", "self", ".", "_key", "]", "\n", "\n", "", "if", "self", ".", "_grayscale", ":", "\n", "            ", "frame", "=", "cv2", ".", "cvtColor", "(", "frame", ",", "cv2", ".", "COLOR_RGB2GRAY", ")", "\n", "", "frame", "=", "cv2", ".", "resize", "(", "\n", "frame", ",", "(", "self", ".", "_width", ",", "self", ".", "_height", ")", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", "\n", ")", "\n", "if", "self", ".", "_grayscale", ":", "\n", "            ", "frame", "=", "np", ".", "expand_dims", "(", "frame", ",", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "_key", "is", "None", ":", "\n", "            ", "obs", "=", "frame", "\n", "", "else", ":", "\n", "            ", "obs", "=", "obs", ".", "copy", "(", ")", "\n", "obs", "[", "self", ".", "_key", "]", "=", "frame", "\n", "", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack.__init__": [[189, 203], ["gym.Wrapper.__init__", "collections.deque", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ",", "k", ")", ":", "\n", "        ", "\"\"\"Stack k last frames.\n\n        Returns lazy array, which is much more memory efficient.\n\n        See Also\n        --------\n        baselines.common.atari_wrappers.LazyFrames\n        \"\"\"", "\n", "gym", ".", "Wrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "k", "=", "k", "\n", "self", ".", "frames", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "k", ")", "\n", "shp", "=", "env", ".", "observation_space", ".", "shape", "\n", "self", ".", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "255", ",", "shape", "=", "(", "shp", "[", ":", "-", "1", "]", "+", "(", "shp", "[", "-", "1", "]", "*", "k", ",", ")", ")", ",", "dtype", "=", "env", ".", "observation_space", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack.reset": [[204, 209], ["atari_wrappers.FrameStack.env.reset", "range", "atari_wrappers.FrameStack._get_ob", "atari_wrappers.FrameStack.frames.append"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack._get_ob", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "ob", "=", "self", ".", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "            ", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "", "return", "self", ".", "_get_ob", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack.step": [[210, 214], ["atari_wrappers.FrameStack.env.step", "atari_wrappers.FrameStack.frames.append", "atari_wrappers.FrameStack._get_ob"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack._get_ob"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "ob", ",", "reward", ",", "done", ",", "info", "=", "self", ".", "env", ".", "step", "(", "action", ")", "\n", "self", ".", "frames", ".", "append", "(", "ob", ")", "\n", "return", "self", ".", "_get_ob", "(", ")", ",", "reward", ",", "done", ",", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.FrameStack._get_ob": [[215, 218], ["atari_wrappers.LazyFrames", "len", "list"], "methods", ["None"], ["", "def", "_get_ob", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "frames", ")", "==", "self", ".", "k", "\n", "return", "LazyFrames", "(", "list", "(", "self", ".", "frames", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ScaledFloatFrame.__init__": [[220, 223], ["gym.ObservationWrapper.__init__", "gym.spaces.Box"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "gym", ".", "ObservationWrapper", ".", "__init__", "(", "self", ",", "env", ")", "\n", "self", ".", "observation_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "1", ",", "shape", "=", "env", ".", "observation_space", ".", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.ScaledFloatFrame.observation": [[224, 228], ["numpy.array().astype", "numpy.array"], "methods", ["None"], ["", "def", "observation", "(", "self", ",", "observation", ")", ":", "\n", "# careful! This undoes the memory optimization, use", "\n", "# with smaller replay buffers only.", "\n", "        ", "return", "np", ".", "array", "(", "observation", ")", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames.__init__": [[230, 240], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "frames", ")", ":", "\n", "        ", "\"\"\"This object ensures that common frames between the observations are only stored once.\n        It exists purely to optimize memory usage which can be huge for DQN's 1M frames replay\n        buffers.\n\n        This object should only be converted to numpy array before being passed to the model.\n\n        You'd not believe how complex the previous solution was.\"\"\"", "\n", "self", ".", "_frames", "=", "frames", "\n", "self", ".", "_out", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames._force": [[241, 246], ["numpy.concatenate"], "methods", ["None"], ["", "def", "_force", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_out", "is", "None", ":", "\n", "            ", "self", ".", "_out", "=", "np", ".", "concatenate", "(", "self", ".", "_frames", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "_frames", "=", "None", "\n", "", "return", "self", ".", "_out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames.__array__": [[247, 252], ["atari_wrappers.LazyFrames._force", "out.astype.astype.astype"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames._force"], ["", "def", "__array__", "(", "self", ",", "dtype", "=", "None", ")", ":", "\n", "        ", "out", "=", "self", ".", "_force", "(", ")", "\n", "if", "dtype", "is", "not", "None", ":", "\n", "            ", "out", "=", "out", ".", "astype", "(", "dtype", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames.__len__": [[253, 255], ["len", "atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames._force"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "_force", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames.__getitem__": [[256, 258], ["atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames._force"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "_force", "(", ")", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames.count": [[259, 262], ["atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames._force"], ["", "def", "count", "(", "self", ")", ":", "\n", "        ", "frames", "=", "self", ".", "_force", "(", ")", "\n", "return", "frames", ".", "shape", "[", "frames", ".", "ndim", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames.frame": [[263, 265], ["atari_wrappers.LazyFrames._force"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.LazyFrames._force"], ["", "def", "frame", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "_force", "(", ")", "[", "...", ",", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.make_atari": [[266, 274], ["gym.make", "atari_wrappers.NoopResetEnv", "atari_wrappers.MaxAndSkipEnv", "wrappers.TimeLimit"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make"], ["", "", "def", "make_atari", "(", "env_id", ",", "max_episode_steps", "=", "None", ")", ":", "\n", "    ", "env", "=", "gym", ".", "make", "(", "env_id", ")", "\n", "assert", "'NoFrameskip'", "in", "env", ".", "spec", ".", "id", "\n", "env", "=", "NoopResetEnv", "(", "env", ",", "noop_max", "=", "30", ")", "\n", "env", "=", "MaxAndSkipEnv", "(", "env", ",", "skip", "=", "4", ")", "\n", "if", "max_episode_steps", "is", "not", "None", ":", "\n", "        ", "env", "=", "TimeLimit", "(", "env", ",", "max_episode_steps", "=", "max_episode_steps", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.atari_wrappers.wrap_deepmind": [[275, 290], ["atari_wrappers.WarpFrame", "atari_wrappers.EpisodicLifeEnv", "FrameStack.unwrapped.get_action_meanings", "atari_wrappers.FireResetEnv", "atari_wrappers.ScaledFloatFrame", "atari_wrappers.ClipRewardEnv", "atari_wrappers.FrameStack"], "function", ["None"], ["", "def", "wrap_deepmind", "(", "env", ",", "episode_life", "=", "True", ",", "clip_rewards", "=", "True", ",", "frame_stack", "=", "False", ",", "scale", "=", "False", ")", ":", "\n", "    ", "\"\"\"Configure environment for DeepMind-style Atari.\n    \"\"\"", "\n", "if", "episode_life", ":", "\n", "        ", "env", "=", "EpisodicLifeEnv", "(", "env", ")", "\n", "", "if", "'FIRE'", "in", "env", ".", "unwrapped", ".", "get_action_meanings", "(", ")", ":", "\n", "        ", "env", "=", "FireResetEnv", "(", "env", ")", "\n", "", "env", "=", "WarpFrame", "(", "env", ")", "\n", "if", "scale", ":", "\n", "        ", "env", "=", "ScaledFloatFrame", "(", "env", ")", "\n", "", "if", "clip_rewards", ":", "\n", "        ", "env", "=", "ClipRewardEnv", "(", "env", ")", "\n", "", "if", "frame_stack", ":", "\n", "        ", "env", "=", "FrameStack", "(", "env", ",", "4", ")", "\n", "", "return", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tile_images.tile_images": [[3, 23], ["numpy.asarray", "int", "int", "numpy.array", "np.array.reshape", "img_nhwc.reshape.transpose", "img_HWhwc.transpose.reshape", "numpy.ceil", "numpy.ceil", "numpy.sqrt", "list", "float", "range"], "function", ["None"], ["def", "tile_images", "(", "img_nhwc", ")", ":", "\n", "    ", "\"\"\"\n    Tile N images into one big PxQ image\n    (P,Q) are chosen to be as close as possible, and if N\n    is square, then P=Q.\n\n    input: img_nhwc, list or array of images, ndim=4 once turned into array\n        n = batch index, h = height, w = width, c = channel\n    returns:\n        bigim_HWc, ndarray with ndim=3\n    \"\"\"", "\n", "img_nhwc", "=", "np", ".", "asarray", "(", "img_nhwc", ")", "\n", "N", ",", "h", ",", "w", ",", "c", "=", "img_nhwc", ".", "shape", "\n", "H", "=", "int", "(", "np", ".", "ceil", "(", "np", ".", "sqrt", "(", "N", ")", ")", ")", "\n", "W", "=", "int", "(", "np", ".", "ceil", "(", "float", "(", "N", ")", "/", "H", ")", ")", "\n", "img_nhwc", "=", "np", ".", "array", "(", "list", "(", "img_nhwc", ")", "+", "[", "img_nhwc", "[", "0", "]", "*", "0", "for", "_", "in", "range", "(", "N", ",", "H", "*", "W", ")", "]", ")", "\n", "img_HWhwc", "=", "img_nhwc", ".", "reshape", "(", "H", ",", "W", ",", "h", ",", "w", ",", "c", ")", "\n", "img_HhWwc", "=", "img_HWhwc", ".", "transpose", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", "\n", "img_Hh_Ww_c", "=", "img_HhWwc", ".", "reshape", "(", "H", "*", "h", ",", "W", "*", "w", ",", "c", ")", "\n", "return", "img_Hh_Ww_c", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.__init__": [[10, 39], ["tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.to_float", "tensorflow.sqrt", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.function", "tensorflow.maximum", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.to_float", "tensorflow.square", "tensorflow.assign_add", "tensorflow.assign_add", "tensorflow.assign_add"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function"], ["    ", "def", "__init__", "(", "self", ",", "epsilon", "=", "1e-2", ",", "shape", "=", "(", ")", ")", ":", "\n", "\n", "        ", "self", ".", "_sum", "=", "tf", ".", "get_variable", "(", "\n", "dtype", "=", "tf", ".", "float64", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "0.0", ")", ",", "\n", "name", "=", "\"runningsum\"", ",", "trainable", "=", "False", ")", "\n", "self", ".", "_sumsq", "=", "tf", ".", "get_variable", "(", "\n", "dtype", "=", "tf", ".", "float64", ",", "\n", "shape", "=", "shape", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "epsilon", ")", ",", "\n", "name", "=", "\"runningsumsq\"", ",", "trainable", "=", "False", ")", "\n", "self", ".", "_count", "=", "tf", ".", "get_variable", "(", "\n", "dtype", "=", "tf", ".", "float64", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "epsilon", ")", ",", "\n", "name", "=", "\"count\"", ",", "trainable", "=", "False", ")", "\n", "self", ".", "shape", "=", "shape", "\n", "\n", "self", ".", "mean", "=", "tf", ".", "to_float", "(", "self", ".", "_sum", "/", "self", ".", "_count", ")", "\n", "self", ".", "std", "=", "tf", ".", "sqrt", "(", "tf", ".", "maximum", "(", "tf", ".", "to_float", "(", "self", ".", "_sumsq", "/", "self", ".", "_count", ")", "-", "tf", ".", "square", "(", "self", ".", "mean", ")", ",", "1e-2", ")", ")", "\n", "\n", "newsum", "=", "tf", ".", "placeholder", "(", "shape", "=", "self", ".", "shape", ",", "dtype", "=", "tf", ".", "float64", ",", "name", "=", "'sum'", ")", "\n", "newsumsq", "=", "tf", ".", "placeholder", "(", "shape", "=", "self", ".", "shape", ",", "dtype", "=", "tf", ".", "float64", ",", "name", "=", "'var'", ")", "\n", "newcount", "=", "tf", ".", "placeholder", "(", "shape", "=", "[", "]", ",", "dtype", "=", "tf", ".", "float64", ",", "name", "=", "'count'", ")", "\n", "self", ".", "incfiltparams", "=", "U", ".", "function", "(", "[", "newsum", ",", "newsumsq", ",", "newcount", "]", ",", "[", "]", ",", "\n", "updates", "=", "[", "tf", ".", "assign_add", "(", "self", ".", "_sum", ",", "newsum", ")", ",", "\n", "tf", ".", "assign_add", "(", "self", ".", "_sumsq", ",", "newsumsq", ")", ",", "\n", "tf", ".", "assign_add", "(", "self", ".", "_count", ",", "newcount", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update": [[41, 49], ["x.astype.astype.astype", "int", "numpy.zeros", "numpy.concatenate", "mpi_running_mean_std.RunningMeanStd.incfiltparams", "numpy.prod", "MPI.COMM_WORLD.Allreduce", "totalvec[].reshape", "totalvec[].reshape", "x.astype.astype.sum().ravel", "numpy.square().sum().ravel", "numpy.array", "x.astype.astype.sum", "numpy.square().sum", "len", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "update", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "astype", "(", "'float64'", ")", "\n", "n", "=", "int", "(", "np", ".", "prod", "(", "self", ".", "shape", ")", ")", "\n", "totalvec", "=", "np", ".", "zeros", "(", "n", "*", "2", "+", "1", ",", "'float64'", ")", "\n", "addvec", "=", "np", ".", "concatenate", "(", "[", "x", ".", "sum", "(", "axis", "=", "0", ")", ".", "ravel", "(", ")", ",", "np", ".", "square", "(", "x", ")", ".", "sum", "(", "axis", "=", "0", ")", ".", "ravel", "(", ")", ",", "np", ".", "array", "(", "[", "len", "(", "x", ")", "]", ",", "dtype", "=", "'float64'", ")", "]", ")", "\n", "if", "MPI", "is", "not", "None", ":", "\n", "            ", "MPI", ".", "COMM_WORLD", ".", "Allreduce", "(", "addvec", ",", "totalvec", ",", "op", "=", "MPI", ".", "SUM", ")", "\n", "", "self", ".", "incfiltparams", "(", "totalvec", "[", "0", ":", "n", "]", ".", "reshape", "(", "self", ".", "shape", ")", ",", "totalvec", "[", "n", ":", "2", "*", "n", "]", ".", "reshape", "(", "self", ".", "shape", ")", ",", "totalvec", "[", "2", "*", "n", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.test_runningmeanstd": [[50, 68], ["mpi_running_mean_std.RunningMeanStd", "baselines.initialize", "numpy.concatenate", "mpi_running_mean_std.RunningMeanStd.update", "mpi_running_mean_std.RunningMeanStd.update", "mpi_running_mean_std.RunningMeanStd.update", "numpy.allclose", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "numpy.random.randn", "np.concatenate.mean", "np.concatenate.std", "RunningMeanStd.mean.eval", "RunningMeanStd.std.eval"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["", "", "@", "U", ".", "in_session", "\n", "def", "test_runningmeanstd", "(", ")", ":", "\n", "    ", "for", "(", "x1", ",", "x2", ",", "x3", ")", "in", "[", "\n", "(", "np", ".", "random", ".", "randn", "(", "3", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ")", ")", ",", "\n", "(", "np", ".", "random", ".", "randn", "(", "3", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ",", "2", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ",", "2", ")", ")", ",", "\n", "]", ":", "\n", "\n", "        ", "rms", "=", "RunningMeanStd", "(", "epsilon", "=", "0.0", ",", "shape", "=", "x1", ".", "shape", "[", "1", ":", "]", ")", "\n", "U", ".", "initialize", "(", ")", "\n", "\n", "x", "=", "np", ".", "concatenate", "(", "[", "x1", ",", "x2", ",", "x3", "]", ",", "axis", "=", "0", ")", "\n", "ms1", "=", "[", "x", ".", "mean", "(", "axis", "=", "0", ")", ",", "x", ".", "std", "(", "axis", "=", "0", ")", "]", "\n", "rms", ".", "update", "(", "x1", ")", "\n", "rms", ".", "update", "(", "x2", ")", "\n", "rms", ".", "update", "(", "x3", ")", "\n", "ms2", "=", "[", "rms", ".", "mean", ".", "eval", "(", ")", ",", "rms", ".", "std", ".", "eval", "(", ")", "]", "\n", "\n", "assert", "np", ".", "allclose", "(", "ms1", ",", "ms2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.test_dist": [[69, 107], ["numpy.random.seed", "mpi_running_mean_std.RunningMeanStd", "baselines.initialize", "mpi_running_mean_std.RunningMeanStd.update", "mpi_running_mean_std.RunningMeanStd.update", "mpi_running_mean_std.RunningMeanStd.update", "numpy.concatenate", "mpi_running_mean_std.test_dist.checkallclose"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "", "@", "U", ".", "in_session", "\n", "def", "test_dist", "(", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "p1", ",", "p2", ",", "p3", "=", "(", "np", ".", "random", ".", "randn", "(", "3", ",", "1", ")", ",", "np", ".", "random", ".", "randn", "(", "4", ",", "1", ")", ",", "np", ".", "random", ".", "randn", "(", "5", ",", "1", ")", ")", "\n", "q1", ",", "q2", ",", "q3", "=", "(", "np", ".", "random", ".", "randn", "(", "6", ",", "1", ")", ",", "np", ".", "random", ".", "randn", "(", "7", ",", "1", ")", ",", "np", ".", "random", ".", "randn", "(", "8", ",", "1", ")", ")", "\n", "\n", "# p1,p2,p3=(np.random.randn(3), np.random.randn(4), np.random.randn(5))", "\n", "# q1,q2,q3=(np.random.randn(6), np.random.randn(7), np.random.randn(8))", "\n", "\n", "comm", "=", "MPI", ".", "COMM_WORLD", "\n", "assert", "comm", ".", "Get_size", "(", ")", "==", "2", "\n", "if", "comm", ".", "Get_rank", "(", ")", "==", "0", ":", "\n", "        ", "x1", ",", "x2", ",", "x3", "=", "p1", ",", "p2", ",", "p3", "\n", "", "elif", "comm", ".", "Get_rank", "(", ")", "==", "1", ":", "\n", "        ", "x1", ",", "x2", ",", "x3", "=", "q1", ",", "q2", ",", "q3", "\n", "", "else", ":", "\n", "        ", "assert", "False", "\n", "\n", "", "rms", "=", "RunningMeanStd", "(", "epsilon", "=", "0.0", ",", "shape", "=", "(", "1", ",", ")", ")", "\n", "U", ".", "initialize", "(", ")", "\n", "\n", "rms", ".", "update", "(", "x1", ")", "\n", "rms", ".", "update", "(", "x2", ")", "\n", "rms", ".", "update", "(", "x3", ")", "\n", "\n", "bigvec", "=", "np", ".", "concatenate", "(", "[", "p1", ",", "p2", ",", "p3", ",", "q1", ",", "q2", ",", "q3", "]", ")", "\n", "\n", "def", "checkallclose", "(", "x", ",", "y", ")", ":", "\n", "        ", "print", "(", "x", ",", "y", ")", "\n", "return", "np", ".", "allclose", "(", "x", ",", "y", ")", "\n", "\n", "", "assert", "checkallclose", "(", "\n", "bigvec", ".", "mean", "(", "axis", "=", "0", ")", ",", "\n", "rms", ".", "mean", ".", "eval", "(", ")", ",", "\n", ")", "\n", "assert", "checkallclose", "(", "\n", "bigvec", ".", "std", "(", "axis", "=", "0", ")", ",", "\n", "rms", ".", "std", ".", "eval", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_with_mpi.with_mpi": [[14, 32], ["functools.wraps", "base64.b64encode", "subprocess.check_call", "cloudpickle.dumps", "pytest.mark.skipif", "str", "fn"], "function", ["None"], ["", "def", "with_mpi", "(", "nproc", "=", "2", ",", "timeout", "=", "30", ",", "skip_if_no_mpi", "=", "True", ")", ":", "\n", "    ", "def", "outer_thunk", "(", "fn", ")", ":", "\n", "        ", "@", "wraps", "(", "fn", ")", "\n", "def", "thunk", "(", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "            ", "serialized_fn", "=", "base64", ".", "b64encode", "(", "cloudpickle", ".", "dumps", "(", "lambda", ":", "fn", "(", "*", "args", ",", "**", "kwargs", ")", ")", ")", "\n", "subprocess", ".", "check_call", "(", "[", "\n", "'mpiexec'", ",", "'-n'", ",", "str", "(", "nproc", ")", ",", "\n", "sys", ".", "executable", ",", "\n", "'-m'", ",", "'baselines.common.tests.test_with_mpi'", ",", "\n", "serialized_fn", "\n", "]", ",", "env", "=", "os", ".", "environ", ",", "timeout", "=", "timeout", ")", "\n", "\n", "", "if", "skip_if_no_mpi", ":", "\n", "            ", "return", "pytest", ".", "mark", ".", "skipif", "(", "MPI", "is", "None", ",", "reason", "=", "\"MPI not present\"", ")", "(", "thunk", ")", "\n", "", "else", ":", "\n", "            ", "return", "thunk", "\n", "\n", "", "", "return", "outer_thunk", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_identity.test_discrete_identity": [[28, 42], ["pytest.mark.parametrize", "kwargs.update", "baselines.common.tests.util.simple_test", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv", "baselines.run.get_learn_function"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.simple_test", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function"], ["@", "mark_slow", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"alg\"", ",", "algos_disc", ")", "\n", "def", "test_discrete_identity", "(", "alg", ")", ":", "\n", "    ", "'''\n    Test if the algorithm (with an mlp policy)\n    can learn an identity transformation (i.e. return observation as an action)\n    '''", "\n", "\n", "kwargs", "=", "learn_kwargs", "[", "alg", "]", "\n", "kwargs", ".", "update", "(", "common_kwargs", ")", "\n", "\n", "learn_fn", "=", "lambda", "e", ":", "get_learn_function", "(", "alg", ")", "(", "env", "=", "e", ",", "**", "kwargs", ")", "\n", "env_fn", "=", "lambda", ":", "DiscreteIdentityEnv", "(", "10", ",", "episode_len", "=", "100", ")", "\n", "simple_test", "(", "env_fn", ",", "learn_fn", ",", "0.9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_identity.test_multidiscrete_identity": [[43, 57], ["pytest.mark.parametrize", "kwargs.update", "baselines.common.tests.util.simple_test", "baselines.common.tests.envs.identity_env.MultiDiscreteIdentityEnv", "baselines.run.get_learn_function"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.simple_test", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function"], ["", "@", "mark_slow", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"alg\"", ",", "algos_multidisc", ")", "\n", "def", "test_multidiscrete_identity", "(", "alg", ")", ":", "\n", "    ", "'''\n    Test if the algorithm (with an mlp policy)\n    can learn an identity transformation (i.e. return observation as an action)\n    '''", "\n", "\n", "kwargs", "=", "learn_kwargs", "[", "alg", "]", "\n", "kwargs", ".", "update", "(", "common_kwargs", ")", "\n", "\n", "learn_fn", "=", "lambda", "e", ":", "get_learn_function", "(", "alg", ")", "(", "env", "=", "e", ",", "**", "kwargs", ")", "\n", "env_fn", "=", "lambda", ":", "MultiDiscreteIdentityEnv", "(", "(", "3", ",", "3", ")", ",", "episode_len", "=", "100", ")", "\n", "simple_test", "(", "env_fn", ",", "learn_fn", ",", "0.9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_identity.test_continuous_identity": [[58, 73], ["pytest.mark.parametrize", "kwargs.update", "baselines.common.tests.util.simple_test", "baselines.common.tests.envs.identity_env.BoxIdentityEnv", "baselines.run.get_learn_function"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.simple_test", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function"], ["", "@", "mark_slow", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"alg\"", ",", "algos_cont", ")", "\n", "def", "test_continuous_identity", "(", "alg", ")", ":", "\n", "    ", "'''\n    Test if the algorithm (with an mlp policy)\n    can learn an identity transformation (i.e. return observation as an action)\n    to a required precision\n    '''", "\n", "\n", "kwargs", "=", "learn_kwargs", "[", "alg", "]", "\n", "kwargs", ".", "update", "(", "common_kwargs", ")", "\n", "learn_fn", "=", "lambda", "e", ":", "get_learn_function", "(", "alg", ")", "(", "env", "=", "e", ",", "**", "kwargs", ")", "\n", "\n", "env_fn", "=", "lambda", ":", "BoxIdentityEnv", "(", "(", "1", ",", ")", ",", "episode_len", "=", "100", ")", "\n", "simple_test", "(", "env_fn", ",", "learn_fn", ",", "-", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_doc_examples.test_lstm_example": [[10, 45], ["pytest.mark.skipif", "DummyVecEnv", "tf.Session", "sess.run", "DummyVecEnv.reset", "policies.build_policy", "tf.global_variables_initializer", "policy.step", "DummyVecEnv.step", "cmd_util.make_mujoco_env", "models.lstm"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.build_policy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_mujoco_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.models.lstm"], ["", "@", "pytest", ".", "mark", ".", "skipif", "(", "\n", "not", "_mujoco_present", ",", "\n", "reason", "=", "'error loading mujoco - either mujoco / mujoco key not present, or LD_LIBRARY_PATH is not pointing to mujoco library'", "\n", ")", "\n", "def", "test_lstm_example", "(", ")", ":", "\n", "    ", "import", "tensorflow", "as", "tf", "\n", "from", "baselines", ".", "common", "import", "policies", ",", "models", ",", "cmd_util", "\n", "from", "baselines", ".", "common", ".", "vec_env", ".", "dummy_vec_env", "import", "DummyVecEnv", "\n", "\n", "# create vectorized environment", "\n", "venv", "=", "DummyVecEnv", "(", "[", "lambda", ":", "cmd_util", ".", "make_mujoco_env", "(", "'Reacher-v2'", ",", "seed", "=", "0", ")", "]", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "# build policy based on lstm network with 128 units", "\n", "        ", "policy", "=", "policies", ".", "build_policy", "(", "venv", ",", "models", ".", "lstm", "(", "128", ")", ")", "(", "nbatch", "=", "1", ",", "nsteps", "=", "1", ")", "\n", "\n", "# initialize tensorflow variables", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# prepare environment variables", "\n", "ob", "=", "venv", ".", "reset", "(", ")", "\n", "state", "=", "policy", ".", "initial_state", "\n", "done", "=", "[", "False", "]", "\n", "step_counter", "=", "0", "\n", "\n", "# run a single episode until the end (i.e. until done)", "\n", "while", "True", ":", "\n", "            ", "action", ",", "_", ",", "state", ",", "_", "=", "policy", ".", "step", "(", "ob", ",", "S", "=", "state", ",", "M", "=", "done", ")", "\n", "ob", ",", "reward", ",", "done", ",", "_", "=", "venv", ".", "step", "(", "action", ")", "\n", "step_counter", "+=", "1", "\n", "if", "done", ":", "\n", "                ", "break", "\n", "\n", "\n", "", "", "assert", "step_counter", ">", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_schedules.test_piecewise_schedule": [[6, 21], ["baselines.common.schedules.PiecewiseSchedule", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value", "baselines.common.schedules.PiecewiseSchedule.value"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value"], ["def", "test_piecewise_schedule", "(", ")", ":", "\n", "    ", "ps", "=", "PiecewiseSchedule", "(", "[", "(", "-", "5", ",", "100", ")", ",", "(", "5", ",", "200", ")", ",", "(", "10", ",", "50", ")", ",", "(", "100", ",", "50", ")", ",", "(", "200", ",", "-", "50", ")", "]", ",", "outside_value", "=", "500", ")", "\n", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "-", "10", ")", ",", "500", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "0", ")", ",", "150", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "5", ")", ",", "200", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "9", ")", ",", "80", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "50", ")", ",", "50", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "80", ")", ",", "50", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "150", ")", ",", "0", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "175", ")", ",", "-", "25", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "201", ")", ",", "500", ")", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "500", ")", ",", "500", ")", "\n", "\n", "assert", "np", ".", "isclose", "(", "ps", ".", "value", "(", "200", "-", "1e-10", ")", ",", "-", "50", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_schedules.test_constant_schedule": [[23, 27], ["baselines.common.schedules.ConstantSchedule", "range", "numpy.isclose", "baselines.common.schedules.ConstantSchedule.value"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.schedules.LinearSchedule.value"], ["", "def", "test_constant_schedule", "(", ")", ":", "\n", "    ", "cs", "=", "ConstantSchedule", "(", "5", ")", "\n", "for", "i", "in", "range", "(", "-", "100", ",", "100", ")", ":", "\n", "        ", "assert", "np", ".", "isclose", "(", "cs", ".", "value", "(", "i", ")", ",", "5", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_tf_util.test_function": [[10, 24], ["tensorflow.Graph().as_default", "tensorflow.placeholder", "tensorflow.placeholder", "baselines.common.tf_util.function", "baselines.common.tf_util.single_threaded_session", "baselines.common.tf_util.initialize", "tensorflow.Graph", "baselines.common.tf_util.function.", "baselines.common.tf_util.function.", "baselines.common.tf_util.function.", "baselines.common.tf_util.function."], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.single_threaded_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize"], ["def", "test_function", "(", ")", ":", "\n", "    ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", ")", ",", "name", "=", "\"x\"", ")", "\n", "y", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", ")", ",", "name", "=", "\"y\"", ")", "\n", "z", "=", "3", "*", "x", "+", "2", "*", "y", "\n", "lin", "=", "function", "(", "[", "x", ",", "y", "]", ",", "z", ",", "givens", "=", "{", "y", ":", "0", "}", ")", "\n", "\n", "with", "single_threaded_session", "(", ")", ":", "\n", "            ", "initialize", "(", ")", "\n", "\n", "assert", "lin", "(", "2", ")", "==", "6", "\n", "assert", "lin", "(", "x", "=", "3", ")", "==", "9", "\n", "assert", "lin", "(", "2", ",", "2", ")", "==", "10", "\n", "assert", "lin", "(", "x", "=", "2", ",", "y", "=", "3", ")", "==", "12", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_tf_util.test_multikwargs": [[26, 38], ["tensorflow.Graph().as_default", "tensorflow.placeholder", "baselines.common.tf_util.function", "tensorflow.variable_scope", "tensorflow.placeholder", "baselines.common.tf_util.single_threaded_session", "baselines.common.tf_util.initialize", "tensorflow.Graph", "baselines.common.tf_util.function.", "baselines.common.tf_util.function."], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.single_threaded_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.initialize"], ["", "", "", "def", "test_multikwargs", "(", ")", ":", "\n", "    ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ":", "\n", "        ", "x", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", ")", ",", "name", "=", "\"x\"", ")", "\n", "with", "tf", ".", "variable_scope", "(", "\"other\"", ")", ":", "\n", "            ", "x2", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "(", ")", ",", "name", "=", "\"x\"", ")", "\n", "", "z", "=", "3", "*", "x", "+", "2", "*", "x2", "\n", "\n", "lin", "=", "function", "(", "[", "x", ",", "x2", "]", ",", "z", ",", "givens", "=", "{", "x2", ":", "0", "}", ")", "\n", "with", "single_threaded_session", "(", ")", ":", "\n", "            ", "initialize", "(", ")", "\n", "assert", "lin", "(", "2", ")", "==", "6", "\n", "assert", "lin", "(", "2", ",", "2", ")", "==", "10", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_segment_tree.test_tree_set": [[6, 18], ["baselines.common.segment_tree.SumSegmentTree", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["def", "test_tree_set", "(", ")", ":", "\n", "    ", "tree", "=", "SumSegmentTree", "(", "4", ")", "\n", "\n", "tree", "[", "2", "]", "=", "1.0", "\n", "tree", "[", "3", "]", "=", "3.0", "\n", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", ")", ",", "4.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "0", ",", "2", ")", ",", "0.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "0", ",", "3", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "2", ",", "3", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "2", ",", "-", "1", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "2", ",", "4", ")", ",", "4.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_segment_tree.test_tree_set_overlap": [[20, 31], ["baselines.common.segment_tree.SumSegmentTree", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum", "baselines.common.segment_tree.SumSegmentTree.sum"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "test_tree_set_overlap", "(", ")", ":", "\n", "    ", "tree", "=", "SumSegmentTree", "(", "4", ")", "\n", "\n", "tree", "[", "2", "]", "=", "1.0", "\n", "tree", "[", "2", "]", "=", "3.0", "\n", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", ")", ",", "3.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "2", ",", "3", ")", ",", "3.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "2", ",", "-", "1", ")", ",", "3.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "2", ",", "4", ")", ",", "3.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "sum", "(", "1", ",", "2", ")", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_segment_tree.test_prefixsum_idx": [[33, 45], ["baselines.common.segment_tree.SumSegmentTree", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx"], ["", "def", "test_prefixsum_idx", "(", ")", ":", "\n", "    ", "tree", "=", "SumSegmentTree", "(", "4", ")", "\n", "\n", "tree", "[", "2", "]", "=", "1.0", "\n", "tree", "[", "3", "]", "=", "3.0", "\n", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "0.0", ")", "==", "2", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "0.5", ")", "==", "2", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "0.99", ")", "==", "2", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "1.01", ")", "==", "3", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "3.00", ")", "==", "3", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "4.00", ")", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_segment_tree.test_prefixsum_idx2": [[47, 61], ["baselines.common.segment_tree.SumSegmentTree", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "baselines.common.segment_tree.SumSegmentTree.find_prefixsum_idx"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.find_prefixsum_idx"], ["", "def", "test_prefixsum_idx2", "(", ")", ":", "\n", "    ", "tree", "=", "SumSegmentTree", "(", "4", ")", "\n", "\n", "tree", "[", "0", "]", "=", "0.5", "\n", "tree", "[", "1", "]", "=", "1.0", "\n", "tree", "[", "2", "]", "=", "1.0", "\n", "tree", "[", "3", "]", "=", "3.0", "\n", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "0.00", ")", "==", "0", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "0.55", ")", "==", "1", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "0.99", ")", "==", "1", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "1.51", ")", "==", "2", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "3.00", ")", "==", "3", "\n", "assert", "tree", ".", "find_prefixsum_idx", "(", "5.50", ")", "==", "3", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_segment_tree.test_max_interval_tree": [[63, 96], ["baselines.common.segment_tree.MinSegmentTree", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "numpy.isclose", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min", "baselines.common.segment_tree.MinSegmentTree.min"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["", "def", "test_max_interval_tree", "(", ")", ":", "\n", "    ", "tree", "=", "MinSegmentTree", "(", "4", ")", "\n", "\n", "tree", "[", "0", "]", "=", "1.0", "\n", "tree", "[", "2", "]", "=", "0.5", "\n", "tree", "[", "3", "]", "=", "3.0", "\n", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", ")", ",", "0.5", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "2", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "3", ")", ",", "0.5", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "-", "1", ")", ",", "0.5", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "2", ",", "4", ")", ",", "0.5", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "3", ",", "4", ")", ",", "3.0", ")", "\n", "\n", "tree", "[", "2", "]", "=", "0.7", "\n", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", ")", ",", "0.7", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "2", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "3", ")", ",", "0.7", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "-", "1", ")", ",", "0.7", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "2", ",", "4", ")", ",", "0.7", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "3", ",", "4", ")", ",", "3.0", ")", "\n", "\n", "tree", "[", "2", "]", "=", "4.0", "\n", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "2", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "3", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "0", ",", "-", "1", ")", ",", "1.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "2", ",", "4", ")", ",", "3.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "2", ",", "3", ")", ",", "4.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "2", ",", "-", "1", ")", ",", "4.0", ")", "\n", "assert", "np", ".", "isclose", "(", "tree", ".", "min", "(", "3", ",", "4", ")", ",", "3.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_plot_util.test_plot_util": [[6, 17], ["baselines.common.plot_util.load_results", "baselines.common.plot_util.plot_results", "baselines.common.plot_util.plot_results", "baselines.common.plot_util.plot_results", "baselines.common.plot_util.plot_results", "baselines.common.plot_util.plot_results", "baselines.common.tests.util.smoketest", "len", "len", "len", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.load_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.plot_util.plot_results", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.smoketest"], ["def", "test_plot_util", "(", ")", ":", "\n", "    ", "nruns", "=", "4", "\n", "logdirs", "=", "[", "smoketest", "(", "'--alg=ppo2 --env=CartPole-v0 --num_timesteps=10000'", ")", "for", "_", "in", "range", "(", "nruns", ")", "]", "\n", "data", "=", "pu", ".", "load_results", "(", "logdirs", ")", "\n", "assert", "len", "(", "data", ")", "==", "4", "\n", "\n", "_", ",", "axes", "=", "pu", ".", "plot_results", "(", "data", "[", ":", "1", "]", ")", ";", "assert", "len", "(", "axes", ")", "==", "1", "\n", "_", ",", "axes", "=", "pu", ".", "plot_results", "(", "data", ",", "tiling", "=", "'vertical'", ")", ";", "assert", "axes", ".", "shape", "==", "(", "4", ",", "1", ")", "\n", "_", ",", "axes", "=", "pu", ".", "plot_results", "(", "data", ",", "tiling", "=", "'horizontal'", ")", ";", "assert", "axes", ".", "shape", "==", "(", "1", ",", "4", ")", "\n", "_", ",", "axes", "=", "pu", ".", "plot_results", "(", "data", ",", "tiling", "=", "'symmetric'", ")", ";", "assert", "axes", ".", "shape", "==", "(", "2", ",", "2", ")", "\n", "_", ",", "axes", "=", "pu", ".", "plot_results", "(", "data", ",", "split_fn", "=", "lambda", "_", ":", "''", ")", ";", "assert", "len", "(", "axes", ")", "==", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_fetchreach.test_fetchreach": [[19, 38], ["pytest.mark.parametrize", "common_kwargs.copy", "common_kwargs.copy.update", "baselines.common.tests.util.reward_per_episode_test", "learn_kwargs.keys", "gym.make", "gym.make.seed", "baselines.run.get_learn_function"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.reward_per_episode_test", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function"], ["@", "mark_slow", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"alg\"", ",", "learn_kwargs", ".", "keys", "(", ")", ")", "\n", "def", "test_fetchreach", "(", "alg", ")", ":", "\n", "    ", "'''\n    Test if the algorithm (with an mlp policy)\n    can learn the FetchReach task\n    '''", "\n", "\n", "kwargs", "=", "common_kwargs", ".", "copy", "(", ")", "\n", "kwargs", ".", "update", "(", "learn_kwargs", "[", "alg", "]", ")", "\n", "\n", "learn_fn", "=", "lambda", "e", ":", "get_learn_function", "(", "alg", ")", "(", "env", "=", "e", ",", "**", "kwargs", ")", "\n", "def", "env_fn", "(", ")", ":", "\n", "\n", "        ", "env", "=", "gym", ".", "make", "(", "'FetchReach-v1'", ")", "\n", "env", ".", "seed", "(", "0", ")", "\n", "return", "env", "\n", "\n", "", "reward_per_episode_test", "(", "env_fn", ",", "learn_fn", ",", "-", "15", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_cartpole.test_cartpole": [[24, 43], ["pytest.mark.parametrize", "common_kwargs.copy", "common_kwargs.copy.update", "baselines.common.tests.util.reward_per_episode_test", "learn_kwargs.keys", "gym.make", "gym.make.seed", "baselines.run.get_learn_function"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.reward_per_episode_test", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function"], ["@", "mark_slow", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"alg\"", ",", "learn_kwargs", ".", "keys", "(", ")", ")", "\n", "def", "test_cartpole", "(", "alg", ")", ":", "\n", "    ", "'''\n    Test if the algorithm (with an mlp policy)\n    can learn to balance the cartpole\n    '''", "\n", "\n", "kwargs", "=", "common_kwargs", ".", "copy", "(", ")", "\n", "kwargs", ".", "update", "(", "learn_kwargs", "[", "alg", "]", ")", "\n", "\n", "learn_fn", "=", "lambda", "e", ":", "get_learn_function", "(", "alg", ")", "(", "env", "=", "e", ",", "**", "kwargs", ")", "\n", "def", "env_fn", "(", ")", ":", "\n", "\n", "        ", "env", "=", "gym", ".", "make", "(", "'CartPole-v0'", ")", "\n", "env", ".", "seed", "(", "0", ")", "\n", "return", "env", "\n", "\n", "", "reward_per_episode_test", "(", "env_fn", ",", "learn_fn", ",", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_mnist.test_mnist": [[30, 47], ["pytest.mark.parametrize", "learn_kwargs.update", "baselines.run.get_learn_function", "baselines.common.tests.util.simple_test", "learn_args.keys", "baselines.run.get_learn_function.", "baselines.common.tests.envs.mnist_env.MnistEnv"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.simple_test"], ["@", "pytest", ".", "mark", ".", "skip", "\n", "@", "mark_slow", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"alg\"", ",", "learn_args", ".", "keys", "(", ")", ")", "\n", "def", "test_mnist", "(", "alg", ")", ":", "\n", "    ", "'''\n    Test if the algorithm can learn to classify MNIST digits.\n    Uses CNN policy.\n    '''", "\n", "\n", "learn_kwargs", "=", "learn_args", "[", "alg", "]", "\n", "learn_kwargs", ".", "update", "(", "common_kwargs", ")", "\n", "\n", "learn", "=", "get_learn_function", "(", "alg", ")", "\n", "learn_fn", "=", "lambda", "e", ":", "learn", "(", "env", "=", "e", ",", "**", "learn_kwargs", ")", "\n", "env_fn", "=", "lambda", ":", "MnistEnv", "(", "episode_len", "=", "100", ")", "\n", "\n", "simple_test", "(", "env_fn", ",", "learn_fn", ",", "0.6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_env_after_learn.test_env_after_learn": [[11, 28], ["pytest.mark.parametrize", "baselines.common.tf_util.make_session", "baselines.common.vec_env.subproc_vec_env.SubprocVecEnv", "baselines.run.get_learn_function", "baselines.run.get_learn_function.", "gym.make.reset", "gym.make.close", "gym.make", "tensorflow.Graph"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "'algo'", ",", "algos", ")", "\n", "def", "test_env_after_learn", "(", "algo", ")", ":", "\n", "    ", "def", "make_env", "(", ")", ":", "\n", "# acktr requires too much RAM, fails on travis", "\n", "        ", "env", "=", "gym", ".", "make", "(", "'CartPole-v1'", "if", "algo", "==", "'acktr'", "else", "'PongNoFrameskip-v4'", ")", "\n", "return", "env", "\n", "\n", "", "make_session", "(", "make_default", "=", "True", ",", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "\n", "env", "=", "SubprocVecEnv", "(", "[", "make_env", "]", ")", "\n", "\n", "learn", "=", "get_learn_function", "(", "algo", ")", "\n", "\n", "# Commenting out the following line resolves the issue, though crash happens at env.reset().", "\n", "learn", "(", "network", "=", "'mlp'", ",", "env", "=", "env", ",", "total_timesteps", "=", "0", ",", "load_path", "=", "None", ",", "seed", "=", "None", ")", "\n", "\n", "env", ".", "reset", "(", ")", "\n", "env", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_fixed_sequence.test_fixed_sequence": [[26, 46], ["pytest.mark.parametrize", "pytest.mark.parametrize", "kwargs.update", "baselines.common.tests.util.simple_test", "baselines.common.tests.envs.fixed_sequence_env.FixedSequenceEnv", "baselines.run.get_learn_function"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.simple_test", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function"], ["@", "mark_slow", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"alg\"", ",", "alg_list", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"rnn\"", ",", "rnn_list", ")", "\n", "def", "test_fixed_sequence", "(", "alg", ",", "rnn", ")", ":", "\n", "    ", "'''\n    Test if the algorithm (with a given policy)\n    can learn an identity transformation (i.e. return observation as an action)\n    '''", "\n", "\n", "kwargs", "=", "learn_kwargs", "[", "alg", "]", "\n", "kwargs", ".", "update", "(", "common_kwargs", ")", "\n", "\n", "env_fn", "=", "lambda", ":", "FixedSequenceEnv", "(", "n_actions", "=", "10", ",", "episode_len", "=", "5", ")", "\n", "learn", "=", "lambda", "e", ":", "get_learn_function", "(", "alg", ")", "(", "\n", "env", "=", "e", ",", "\n", "network", "=", "rnn", ",", "\n", "**", "kwargs", "\n", ")", "\n", "\n", "simple_test", "(", "env_fn", ",", "learn", ",", "0.7", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.simple_test": [[14, 40], ["numpy.random.seed", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "env_fn", "env_fn.seed", "tensorflow.Graph().as_default", "tensorflow.Session().as_default", "tensorflow.set_random_seed", "learn_fn", "range", "print", "env_fn.step", "float", "tensorflow.Graph", "tensorflow.Session", "env_fn.reset", "learn_fn.step", "learn_fn.step"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["def", "store_args", "(", "method", ")", ":", "\n", "    ", "\"\"\"Stores provided method args as instance attributes.\n    \"\"\"", "\n", "argspec", "=", "inspect", ".", "getfullargspec", "(", "method", ")", "\n", "defaults", "=", "{", "}", "\n", "if", "argspec", ".", "defaults", "is", "not", "None", ":", "\n", "        ", "defaults", "=", "dict", "(", "\n", "zip", "(", "argspec", ".", "args", "[", "-", "len", "(", "argspec", ".", "defaults", ")", ":", "]", ",", "argspec", ".", "defaults", ")", ")", "\n", "", "if", "argspec", ".", "kwonlydefaults", "is", "not", "None", ":", "\n", "        ", "defaults", ".", "update", "(", "argspec", ".", "kwonlydefaults", ")", "\n", "", "arg_names", "=", "argspec", ".", "args", "[", "1", ":", "]", "\n", "\n", "@", "functools", ".", "wraps", "(", "method", ")", "\n", "def", "wrapper", "(", "*", "positional_args", ",", "**", "keyword_args", ")", ":", "\n", "        ", "self", "=", "positional_args", "[", "0", "]", "\n", "# Get default arg values", "\n", "args", "=", "defaults", ".", "copy", "(", ")", "\n", "# Add provided arg values", "\n", "for", "name", ",", "value", "in", "zip", "(", "arg_names", ",", "positional_args", "[", "1", ":", "]", ")", ":", "\n", "            ", "args", "[", "name", "]", "=", "value", "\n", "", "args", ".", "update", "(", "keyword_args", ")", "\n", "self", ".", "__dict__", ".", "update", "(", "args", ")", "\n", "return", "method", "(", "*", "positional_args", ",", "**", "keyword_args", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.reward_per_episode_test": [[41, 52], ["baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "tensorflow.Graph().as_default", "tensorflow.Session().as_default", "learn_fn", "util.rollout", "print", "sum", "sum", "tensorflow.Graph", "tensorflow.Session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.rollout", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "import_function", "(", "spec", ")", ":", "\n", "    ", "\"\"\"Import a function identified by a string like \"pkg.module:fn_name\".\n    \"\"\"", "\n", "mod_name", ",", "fn_name", "=", "spec", ".", "split", "(", "':'", ")", "\n", "module", "=", "importlib", ".", "import_module", "(", "mod_name", ")", "\n", "fn", "=", "getattr", "(", "module", ",", "fn_name", ")", "\n", "return", "fn", "\n", "\n", "\n", "", "def", "flatten_grads", "(", "var_list", ",", "grads", ")", ":", "\n", "    ", "\"\"\"Flattens a variables and their gradients.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.rollout": [[53, 79], ["range", "env.reset", "rewards.append", "actions.append", "observations.append", "hasattr", "env.step", "episode_rew.append", "episode_actions.append", "episode_obs.append", "model.step", "model.step"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["return", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "grad", ",", "[", "U", ".", "numel", "(", "v", ")", "]", ")", "\n", "for", "(", "v", ",", "grad", ")", "in", "zip", "(", "var_list", ",", "grads", ")", "]", ",", "0", ")", "\n", "\n", "\n", "", "def", "nn", "(", "input", ",", "layers_sizes", ",", "reuse", "=", "None", ",", "flatten", "=", "False", ",", "name", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Creates a simple neural network\n    \"\"\"", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "layers_sizes", ")", ":", "\n", "        ", "activation", "=", "tf", ".", "nn", ".", "relu", "if", "i", "<", "len", "(", "layers_sizes", ")", "-", "1", "else", "None", "\n", "input", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", "=", "input", ",", "\n", "units", "=", "size", ",", "\n", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ",", "\n", "reuse", "=", "reuse", ",", "\n", "name", "=", "name", "+", "'_'", "+", "str", "(", "i", ")", ")", "\n", "if", "activation", ":", "\n", "            ", "input", "=", "activation", "(", "input", ")", "\n", "", "", "if", "flatten", ":", "\n", "        ", "assert", "layers_sizes", "[", "-", "1", "]", "==", "1", "\n", "input", "=", "tf", ".", "reshape", "(", "input", ",", "[", "-", "1", "]", ")", "\n", "", "return", "input", "\n", "\n", "\n", "", "def", "install_mpi_excepthook", "(", ")", ":", "\n", "    ", "import", "sys", "\n", "from", "mpi4py", "import", "MPI", "\n", "old_hook", "=", "sys", ".", "excepthook", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.util.smoketest": [[81, 93], ["tempfile.mkdtemp", "os.environ.copy", "subprocess.run", "argstr.split"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["        ", "old_hook", "(", "a", ",", "b", ",", "c", ")", "\n", "sys", ".", "stdout", ".", "flush", "(", ")", "\n", "sys", ".", "stderr", ".", "flush", "(", ")", "\n", "MPI", ".", "COMM_WORLD", ".", "Abort", "(", ")", "\n", "", "sys", ".", "excepthook", "=", "new_hook", "\n", "\n", "\n", "", "def", "mpi_fork", "(", "n", ",", "extra_mpi_args", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"Re-launches the current script with workers\n    Returns \"parent\" for original parent, \"child\" for MPI children\n    \"\"\"", "\n", "if", "n", "<=", "1", ":", "\n", "        ", "return", "\"child\"", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization.test_serialization": [[33, 83], ["pytest.mark.parametrize", "pytest.mark.parametrize", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "baselines.common.tests.envs.mnist_env.MnistEnv.reset().copy", "baselines.run.get_learn_function", "kwargs.update", "kwargs.update", "functools.partial", "learn_kwargs.keys", "network_kwargs.keys", "network_fn.endswith", "baselines.common.tests.envs.mnist_env.MnistEnv", "baselines.common.tests.envs.mnist_env.MnistEnv.seed", "tempfile.TemporaryDirectory", "os.path.join", "_serialize_variables.items", "numpy.testing.assert_allclose", "numpy.testing.assert_allclose", "baselines.common.tests.envs.mnist_env.MnistEnv.reset", "tensorflow.Graph().as_default", "baselines.common.tf_util.make_session().as_default", "functools.partial.", "learn.save", "test_serialization._get_action_stats", "test_serialization._serialize_variables", "tensorflow.Graph().as_default", "baselines.common.tf_util.make_session().as_default", "functools.partial.", "test_serialization._get_action_stats", "test_serialization._serialize_variables", "numpy.testing.assert_allclose", "tensorflow.Graph", "baselines.common.tf_util.make_session", "tensorflow.Graph", "baselines.common.tf_util.make_session"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization._get_action_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization._serialize_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization._get_action_stats", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization._serialize_variables", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "\"learn_fn\"", ",", "learn_kwargs", ".", "keys", "(", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"network_fn\"", ",", "network_kwargs", ".", "keys", "(", ")", ")", "\n", "def", "test_serialization", "(", "learn_fn", ",", "network_fn", ")", ":", "\n", "    ", "'''\n    Test if the trained model can be serialized\n    '''", "\n", "\n", "\n", "if", "network_fn", ".", "endswith", "(", "'lstm'", ")", "and", "learn_fn", "in", "[", "'acer'", ",", "'acktr'", ",", "'trpo_mpi'", ",", "'deepq'", "]", ":", "\n", "# TODO make acktr work with recurrent policies", "\n", "# and test", "\n", "# github issue: https://github.com/openai/baselines/issues/660", "\n", "            ", "return", "\n", "\n", "", "def", "make_env", "(", ")", ":", "\n", "        ", "env", "=", "MnistEnv", "(", "episode_len", "=", "100", ")", "\n", "env", ".", "seed", "(", "10", ")", "\n", "return", "env", "\n", "\n", "", "env", "=", "DummyVecEnv", "(", "[", "make_env", "]", ")", "\n", "ob", "=", "env", ".", "reset", "(", ")", ".", "copy", "(", ")", "\n", "learn", "=", "get_learn_function", "(", "learn_fn", ")", "\n", "\n", "kwargs", "=", "{", "}", "\n", "kwargs", ".", "update", "(", "network_kwargs", "[", "network_fn", "]", ")", "\n", "kwargs", ".", "update", "(", "learn_kwargs", "[", "learn_fn", "]", ")", "\n", "\n", "\n", "learn", "=", "partial", "(", "learn", ",", "env", "=", "env", ",", "network", "=", "network_fn", ",", "seed", "=", "0", ",", "**", "kwargs", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "td", ":", "\n", "        ", "model_path", "=", "os", ".", "path", ".", "join", "(", "td", ",", "'serialization_test_model'", ")", "\n", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "make_session", "(", ")", ".", "as_default", "(", ")", ":", "\n", "            ", "model", "=", "learn", "(", "total_timesteps", "=", "100", ")", "\n", "model", ".", "save", "(", "model_path", ")", "\n", "mean1", ",", "std1", "=", "_get_action_stats", "(", "model", ",", "ob", ")", "\n", "variables_dict1", "=", "_serialize_variables", "(", ")", "\n", "\n", "", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "make_session", "(", ")", ".", "as_default", "(", ")", ":", "\n", "            ", "model", "=", "learn", "(", "total_timesteps", "=", "0", ",", "load_path", "=", "model_path", ")", "\n", "mean2", ",", "std2", "=", "_get_action_stats", "(", "model", ",", "ob", ")", "\n", "variables_dict2", "=", "_serialize_variables", "(", ")", "\n", "\n", "", "for", "k", ",", "v", "in", "variables_dict1", ".", "items", "(", ")", ":", "\n", "            ", "np", ".", "testing", ".", "assert_allclose", "(", "v", ",", "variables_dict2", "[", "k", "]", ",", "atol", "=", "0.01", ",", "\n", "err_msg", "=", "'saved and loaded variable {} value mismatch'", ".", "format", "(", "k", ")", ")", "\n", "\n", "", "np", ".", "testing", ".", "assert_allclose", "(", "mean1", ",", "mean2", ",", "atol", "=", "0.5", ")", "\n", "np", ".", "testing", ".", "assert_allclose", "(", "std1", ",", "std2", ",", "atol", "=", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization.test_coexistence": [[85, 118], ["pytest.mark.parametrize", "pytest.mark.parametrize", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv", "baselines.run.get_learn_function", "kwargs.update", "kwargs.update", "functools.partial", "baselines.common.tf_util.make_session", "functools.partial.", "baselines.common.tf_util.make_session", "functools.partial.", "learn.step", "learn.step", "learn_kwargs.keys", "network_fn.endswith", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv.observation_space.sample", "baselines.common.vec_env.dummy_vec_env.DummyVecEnv.observation_space.sample", "tensorflow.Graph", "tensorflow.Graph", "gym.make"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.run.get_learn_function", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.make_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"learn_fn\"", ",", "learn_kwargs", ".", "keys", "(", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "\"network_fn\"", ",", "[", "'mlp'", "]", ")", "\n", "def", "test_coexistence", "(", "learn_fn", ",", "network_fn", ")", ":", "\n", "    ", "'''\n    Test if more than one model can exist at a time\n    '''", "\n", "\n", "if", "learn_fn", "==", "'deepq'", ":", "\n", "# TODO enable multiple DQN models to be useable at the same time", "\n", "# github issue https://github.com/openai/baselines/issues/656", "\n", "            ", "return", "\n", "\n", "", "if", "network_fn", ".", "endswith", "(", "'lstm'", ")", "and", "learn_fn", "in", "[", "'acktr'", ",", "'trpo_mpi'", ",", "'deepq'", "]", ":", "\n", "# TODO make acktr work with recurrent policies", "\n", "# and test", "\n", "# github issue: https://github.com/openai/baselines/issues/660", "\n", "            ", "return", "\n", "\n", "", "env", "=", "DummyVecEnv", "(", "[", "lambda", ":", "gym", ".", "make", "(", "'CartPole-v0'", ")", "]", ")", "\n", "learn", "=", "get_learn_function", "(", "learn_fn", ")", "\n", "\n", "kwargs", "=", "{", "}", "\n", "kwargs", ".", "update", "(", "network_kwargs", "[", "network_fn", "]", ")", "\n", "kwargs", ".", "update", "(", "learn_kwargs", "[", "learn_fn", "]", ")", "\n", "\n", "learn", "=", "partial", "(", "learn", ",", "env", "=", "env", ",", "network", "=", "network_fn", ",", "total_timesteps", "=", "0", ",", "**", "kwargs", ")", "\n", "make_session", "(", "make_default", "=", "True", ",", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "\n", "model1", "=", "learn", "(", "seed", "=", "1", ")", "\n", "make_session", "(", "make_default", "=", "True", ",", "graph", "=", "tf", ".", "Graph", "(", ")", ")", "\n", "model2", "=", "learn", "(", "seed", "=", "2", ")", "\n", "\n", "model1", ".", "step", "(", "env", ".", "observation_space", ".", "sample", "(", ")", ")", "\n", "model2", ".", "step", "(", "env", ".", "observation_space", ".", "sample", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization._serialize_variables": [[121, 126], ["baselines.common.tf_util.get_session", "tensorflow.trainable_variables", "baselines.common.tf_util.get_session.run", "zip"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tf_util.get_session", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run"], ["", "def", "_serialize_variables", "(", ")", ":", "\n", "    ", "sess", "=", "get_session", "(", ")", "\n", "variables", "=", "tf", ".", "trainable_variables", "(", ")", "\n", "values", "=", "sess", ".", "run", "(", "variables", ")", "\n", "return", "{", "var", ".", "name", ":", "value", "for", "var", ",", "value", "in", "zip", "(", "variables", ",", "values", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_serialization._get_action_stats": [[128, 139], ["numpy.mean", "numpy.std", "numpy.array", "numpy.array", "model.step", "range", "model.step", "range"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "def", "_get_action_stats", "(", "model", ",", "ob", ")", ":", "\n", "    ", "ntrials", "=", "1000", "\n", "if", "model", ".", "initial_state", "is", "None", "or", "model", ".", "initial_state", "==", "[", "]", ":", "\n", "        ", "actions", "=", "np", ".", "array", "(", "[", "model", ".", "step", "(", "ob", ")", "[", "0", "]", "for", "_", "in", "range", "(", "ntrials", ")", "]", ")", "\n", "", "else", ":", "\n", "        ", "actions", "=", "np", ".", "array", "(", "[", "model", ".", "step", "(", "ob", ",", "S", "=", "model", ".", "initial_state", ",", "M", "=", "[", "False", "]", ")", "[", "0", "]", "for", "_", "in", "range", "(", "ntrials", ")", "]", ")", "\n", "\n", "", "mean", "=", "np", ".", "mean", "(", "actions", ",", "axis", "=", "0", ")", "\n", "std", "=", "np", ".", "std", "(", "actions", ",", "axis", "=", "0", ")", "\n", "\n", "return", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env_test.test_discrete_nodelay": [[4, 19], ["baselines.common.tests.envs.identity_env.DiscreteIdentityEnv", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv.reset", "range", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv.action_space.sample", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv.step", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv.reset"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["def", "test_discrete_nodelay", "(", ")", ":", "\n", "    ", "nsteps", "=", "100", "\n", "eplen", "=", "50", "\n", "env", "=", "DiscreteIdentityEnv", "(", "10", ",", "episode_len", "=", "eplen", ")", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "for", "t", "in", "range", "(", "nsteps", ")", ":", "\n", "        ", "action", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "next_ob", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "assert", "rew", "==", "(", "1", "if", "action", "==", "ob", "else", "0", ")", "\n", "if", "(", "t", "+", "1", ")", "%", "eplen", "==", "0", ":", "\n", "            ", "assert", "done", "\n", "next_ob", "=", "env", ".", "reset", "(", ")", "\n", "", "else", ":", "\n", "            ", "assert", "not", "done", "\n", "", "ob", "=", "next_ob", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env_test.test_discrete_delay1": [[20, 37], ["baselines.common.tests.envs.identity_env.DiscreteIdentityEnv", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv.reset", "range", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv.action_space.sample", "baselines.common.tests.envs.identity_env.DiscreteIdentityEnv.step"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["", "", "def", "test_discrete_delay1", "(", ")", ":", "\n", "    ", "eplen", "=", "50", "\n", "env", "=", "DiscreteIdentityEnv", "(", "10", ",", "episode_len", "=", "eplen", ",", "delay", "=", "1", ")", "\n", "ob", "=", "env", ".", "reset", "(", ")", "\n", "prev_ob", "=", "None", "\n", "for", "t", "in", "range", "(", "eplen", ")", ":", "\n", "        ", "action", "=", "env", ".", "action_space", ".", "sample", "(", ")", "\n", "next_ob", ",", "rew", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "t", ">", "0", ":", "\n", "            ", "assert", "rew", "==", "(", "1", "if", "action", "==", "prev_ob", "else", "0", ")", "\n", "", "else", ":", "\n", "            ", "assert", "rew", "==", "0", "\n", "", "prev_ob", "=", "ob", "\n", "ob", "=", "next_ob", "\n", "if", "t", "<", "eplen", "-", "1", ":", "\n", "            ", "assert", "not", "done", "\n", "", "", "assert", "done", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv.__init__": [[10, 34], ["os.join", "numpy.random.RandomState", "gym.spaces.Box", "gym.spaces.Discrete", "mnist_env.MnistEnv.train_mode", "mnist_env.MnistEnv.reset", "tempfile.gettempdir", "filelock.FileLock", "input_data.read_data_sets"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv.train_mode", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "episode_len", "=", "None", ",", "\n", "no_images", "=", "None", "\n", ")", ":", "\n", "        ", "import", "filelock", "\n", "from", "tensorflow", ".", "examples", ".", "tutorials", ".", "mnist", "import", "input_data", "\n", "# we could use temporary directory for this with a context manager and", "\n", "# TemporaryDirecotry, but then each test that uses mnist would re-download the data", "\n", "# this way the data is not cleaned up, but we only download it once per machine", "\n", "mnist_path", "=", "osp", ".", "join", "(", "tempfile", ".", "gettempdir", "(", ")", ",", "'MNIST_data'", ")", "\n", "with", "filelock", ".", "FileLock", "(", "mnist_path", "+", "'.lock'", ")", ":", "\n", "           ", "self", ".", "mnist", "=", "input_data", ".", "read_data_sets", "(", "mnist_path", ")", "\n", "\n", "", "self", ".", "np_random", "=", "np", ".", "random", ".", "RandomState", "(", ")", "\n", "\n", "self", ".", "observation_space", "=", "Box", "(", "low", "=", "0.0", ",", "high", "=", "1.0", ",", "shape", "=", "(", "28", ",", "28", ",", "1", ")", ")", "\n", "self", ".", "action_space", "=", "Discrete", "(", "10", ")", "\n", "self", ".", "episode_len", "=", "episode_len", "\n", "self", ".", "time", "=", "0", "\n", "self", ".", "no_images", "=", "no_images", "\n", "\n", "self", ".", "train_mode", "(", ")", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv.reset": [[35, 40], ["mnist_env.MnistEnv._choose_next_state"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._choose_next_state"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_choose_next_state", "(", ")", "\n", "self", ".", "time", "=", "0", "\n", "\n", "return", "self", ".", "state", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv.step": [[41, 50], ["mnist_env.MnistEnv._get_reward", "mnist_env.MnistEnv._choose_next_state"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._get_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._choose_next_state"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "rew", "=", "self", ".", "_get_reward", "(", "actions", ")", "\n", "self", ".", "_choose_next_state", "(", ")", "\n", "done", "=", "False", "\n", "if", "self", ".", "episode_len", "and", "self", ".", "time", ">=", "self", ".", "episode_len", ":", "\n", "            ", "rew", "=", "0", "\n", "done", "=", "True", "\n", "\n", "", "return", "self", ".", "state", "[", "0", "]", ",", "rew", ",", "done", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv.seed": [[51, 53], ["mnist_env.MnistEnv.np_random.seed"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "np_random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv.train_mode": [[54, 56], ["None"], "methods", ["None"], ["", "def", "train_mode", "(", "self", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "self", ".", "mnist", ".", "train", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv.test_mode": [[57, 59], ["None"], "methods", ["None"], ["", "def", "test_mode", "(", "self", ")", ":", "\n", "        ", "self", ".", "dataset", "=", "self", ".", "mnist", ".", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv._choose_next_state": [[60, 67], ["mnist_env.MnistEnv.np_random.randint", "mnist_env.MnistEnv.dataset.images[].reshape"], "methods", ["None"], ["", "def", "_choose_next_state", "(", "self", ")", ":", "\n", "        ", "max_index", "=", "(", "self", ".", "no_images", "if", "self", ".", "no_images", "is", "not", "None", "else", "self", ".", "dataset", ".", "num_examples", ")", "-", "1", "\n", "index", "=", "self", ".", "np_random", ".", "randint", "(", "0", ",", "max_index", ")", "\n", "image", "=", "self", ".", "dataset", ".", "images", "[", "index", "]", ".", "reshape", "(", "28", ",", "28", ",", "1", ")", "*", "255", "\n", "label", "=", "self", ".", "dataset", ".", "labels", "[", "index", "]", "\n", "self", ".", "state", "=", "(", "image", ",", "label", ")", "\n", "self", ".", "time", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.mnist_env.MnistEnv._get_reward": [[68, 70], ["None"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "actions", ")", ":", "\n", "        ", "return", "1", "if", "self", ".", "state", "[", "1", "]", "==", "actions", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.IdentityEnv.__init__": [[8, 21], ["collections.deque"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "episode_len", "=", "None", ",", "\n", "delay", "=", "0", ",", "\n", "zero_first_rewards", "=", "True", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "observation_space", "=", "self", ".", "action_space", "\n", "self", ".", "episode_len", "=", "episode_len", "\n", "self", ".", "time", "=", "0", "\n", "self", ".", "delay", "=", "delay", "\n", "self", ".", "zero_first_rewards", "=", "zero_first_rewards", "\n", "self", ".", "q", "=", "deque", "(", "maxlen", "=", "delay", "+", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.IdentityEnv.reset": [[22, 29], ["identity_env.IdentityEnv.q.clear", "range", "identity_env.IdentityEnv.q.append", "identity_env.IdentityEnv.action_space.sample"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "q", ".", "clear", "(", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "delay", "+", "1", ")", ":", "\n", "            ", "self", ".", "q", ".", "append", "(", "self", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "", "self", ".", "time", "=", "0", "\n", "\n", "return", "self", ".", "q", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.IdentityEnv.step": [[30, 38], ["identity_env.IdentityEnv._get_reward", "identity_env.IdentityEnv.q.append", "identity_env.IdentityEnv.q.popleft", "identity_env.IdentityEnv.action_space.sample"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._get_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "rew", "=", "self", ".", "_get_reward", "(", "self", ".", "q", ".", "popleft", "(", ")", ",", "actions", ")", "\n", "if", "self", ".", "zero_first_rewards", "and", "self", ".", "time", "<", "self", ".", "delay", ":", "\n", "            ", "rew", "=", "0", "\n", "", "self", ".", "q", ".", "append", "(", "self", ".", "action_space", ".", "sample", "(", ")", ")", "\n", "self", ".", "time", "+=", "1", "\n", "done", "=", "self", ".", "episode_len", "is", "not", "None", "and", "self", ".", "time", ">=", "self", ".", "episode_len", "\n", "return", "self", ".", "q", "[", "-", "1", "]", ",", "rew", ",", "done", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.IdentityEnv.seed": [[39, 41], ["identity_env.IdentityEnv.action_space.seed"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "action_space", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.IdentityEnv._get_reward": [[42, 45], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "_get_reward", "(", "self", ",", "state", ",", "actions", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.DiscreteIdentityEnv.__init__": [[48, 58], ["gym.spaces.Discrete", "identity_env.IdentityEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dim", ",", "\n", "episode_len", "=", "None", ",", "\n", "delay", "=", "0", ",", "\n", "zero_first_rewards", "=", "True", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "action_space", "=", "Discrete", "(", "dim", ")", "\n", "super", "(", ")", ".", "__init__", "(", "episode_len", "=", "episode_len", ",", "delay", "=", "delay", ",", "zero_first_rewards", "=", "zero_first_rewards", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.DiscreteIdentityEnv._get_reward": [[59, 61], ["None"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "state", ",", "actions", ")", ":", "\n", "        ", "return", "1", "if", "state", "==", "actions", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.MultiDiscreteIdentityEnv.__init__": [[63, 72], ["gym.spaces.MultiDiscrete", "identity_env.IdentityEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "dims", ",", "\n", "episode_len", "=", "None", ",", "\n", "delay", "=", "0", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "action_space", "=", "MultiDiscrete", "(", "dims", ")", "\n", "super", "(", ")", ".", "__init__", "(", "episode_len", "=", "episode_len", ",", "delay", "=", "delay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.MultiDiscreteIdentityEnv._get_reward": [[73, 75], ["all"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "state", ",", "actions", ")", ":", "\n", "        ", "return", "1", "if", "all", "(", "state", "==", "actions", ")", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.BoxIdentityEnv.__init__": [[78, 86], ["gym.spaces.Box", "identity_env.IdentityEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "shape", ",", "\n", "episode_len", "=", "None", ",", "\n", ")", ":", "\n", "\n", "        ", "self", ".", "action_space", "=", "Box", "(", "low", "=", "-", "1.0", ",", "high", "=", "1.0", ",", "shape", "=", "shape", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "super", "(", ")", ".", "__init__", "(", "episode_len", "=", "episode_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.identity_env.BoxIdentityEnv._get_reward": [[87, 91], ["numpy.dot"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "state", ",", "actions", ")", ":", "\n", "        ", "diff", "=", "actions", "-", "state", "\n", "diff", "=", "diff", "[", ":", "]", "\n", "return", "-", "0.5", "*", "np", ".", "dot", "(", "diff", ",", "diff", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.__init__": [[7, 19], ["gym.spaces.Discrete", "gym.spaces.Discrete", "numpy.random.RandomState", "fixed_sequence_env.FixedSequenceEnv.np_random.randint", "range"], "methods", ["None"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "n_actions", "=", "10", ",", "\n", "episode_len", "=", "100", "\n", ")", ":", "\n", "        ", "self", ".", "action_space", "=", "Discrete", "(", "n_actions", ")", "\n", "self", ".", "observation_space", "=", "Discrete", "(", "1", ")", "\n", "self", ".", "np_random", "=", "np", ".", "random", ".", "RandomState", "(", "0", ")", "\n", "self", ".", "episode_len", "=", "episode_len", "\n", "self", ".", "sequence", "=", "[", "self", ".", "np_random", ".", "randint", "(", "0", ",", "self", ".", "action_space", ".", "n", ")", "\n", "for", "_", "in", "range", "(", "self", ".", "episode_len", ")", "]", "\n", "self", ".", "time", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.reset": [[21, 24], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "time", "=", "0", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.step": [[25, 33], ["fixed_sequence_env.FixedSequenceEnv._get_reward", "fixed_sequence_env.FixedSequenceEnv._choose_next_state"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._get_reward", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._choose_next_state"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "rew", "=", "self", ".", "_get_reward", "(", "actions", ")", "\n", "self", ".", "_choose_next_state", "(", ")", "\n", "done", "=", "False", "\n", "if", "self", ".", "episode_len", "and", "self", ".", "time", ">=", "self", ".", "episode_len", ":", "\n", "            ", "done", "=", "True", "\n", "\n", "", "return", "0", ",", "rew", ",", "done", ",", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed": [[34, 36], ["fixed_sequence_env.FixedSequenceEnv.np_random.seed"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed"], ["", "def", "seed", "(", "self", ",", "seed", "=", "None", ")", ":", "\n", "        ", "self", ".", "np_random", ".", "seed", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._choose_next_state": [[37, 39], ["None"], "methods", ["None"], ["", "def", "_choose_next_state", "(", "self", ")", ":", "\n", "        ", "self", ".", "time", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv._get_reward": [[40, 42], ["None"], "methods", ["None"], ["", "def", "_get_reward", "(", "self", ",", "actions", ")", ":", "\n", "        ", "return", "1", "if", "actions", "==", "self", ".", "sequence", "[", "self", ".", "time", "]", "else", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.SimpleEnv.__init__": [[120, 132], ["numpy.random.seed", "numpy.array", "gym.spaces.Box", "numpy.random.randint"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed"], ["def", "__init__", "(", "self", ",", "seed", ",", "shape", ",", "dtype", ")", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "self", ".", "_dtype", "=", "dtype", "\n", "self", ".", "_start_obs", "=", "np", ".", "array", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "0x100", ",", "size", "=", "shape", ")", ",", "\n", "dtype", "=", "dtype", ")", "\n", "self", ".", "_max_steps", "=", "seed", "+", "1", "\n", "self", ".", "_cur_obs", "=", "None", "\n", "self", ".", "_cur_step", "=", "0", "\n", "# this is 0xFF instead of 0x100 because the Box space includes", "\n", "# the high end, while randint does not", "\n", "self", ".", "action_space", "=", "gym", ".", "spaces", ".", "Box", "(", "low", "=", "0", ",", "high", "=", "0xFF", ",", "shape", "=", "shape", ",", "dtype", "=", "dtype", ")", "\n", "self", ".", "observation_space", "=", "self", ".", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.SimpleEnv.step": [[133, 139], ["numpy.array", "str"], "methods", ["None"], ["", "def", "step", "(", "self", ",", "action", ")", ":", "\n", "        ", "self", ".", "_cur_obs", "+=", "np", ".", "array", "(", "action", ",", "dtype", "=", "self", ".", "_dtype", ")", "\n", "self", ".", "_cur_step", "+=", "1", "\n", "done", "=", "self", ".", "_cur_step", ">=", "self", ".", "_max_steps", "\n", "reward", "=", "self", ".", "_cur_step", "/", "self", ".", "_max_steps", "\n", "return", "self", ".", "_cur_obs", ",", "reward", ",", "done", ",", "{", "'foo'", ":", "'bar'", "+", "str", "(", "reward", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.SimpleEnv.reset": [[140, 144], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_cur_obs", "=", "self", ".", "_start_obs", "\n", "self", ".", "_cur_step", "=", "0", "\n", "return", "self", ".", "_cur_obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.SimpleEnv.render": [[145, 147], ["None"], "methods", ["None"], ["", "def", "render", "(", "self", ",", "mode", "=", "None", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.assert_venvs_equal": [[14, 45], ["numpy.allclose", "venv1.action_space.seed", "range", "venv1.close", "venv2.close", "venv1.reset", "venv2.reset", "numpy.array", "venv1.step_wait", "venv2.step_wait", "zip", "numpy.array", "numpy.array", "numpy.array", "venv.step_async", "numpy.allclose", "list", "list", "venv1.action_space.sample", "range", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_async", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.sample"], ["def", "assert_venvs_equal", "(", "venv1", ",", "venv2", ",", "num_steps", ")", ":", "\n", "    ", "\"\"\"\n    Compare two environments over num_steps steps and make sure\n    that the observations produced by each are the same when given\n    the same actions.\n    \"\"\"", "\n", "assert", "venv1", ".", "num_envs", "==", "venv2", ".", "num_envs", "\n", "assert", "venv1", ".", "observation_space", ".", "shape", "==", "venv2", ".", "observation_space", ".", "shape", "\n", "assert", "venv1", ".", "observation_space", ".", "dtype", "==", "venv2", ".", "observation_space", ".", "dtype", "\n", "assert", "venv1", ".", "action_space", ".", "shape", "==", "venv2", ".", "action_space", ".", "shape", "\n", "assert", "venv1", ".", "action_space", ".", "dtype", "==", "venv2", ".", "action_space", ".", "dtype", "\n", "\n", "try", ":", "\n", "        ", "obs1", ",", "obs2", "=", "venv1", ".", "reset", "(", ")", ",", "venv2", ".", "reset", "(", ")", "\n", "assert", "np", ".", "array", "(", "obs1", ")", ".", "shape", "==", "np", ".", "array", "(", "obs2", ")", ".", "shape", "\n", "assert", "np", ".", "array", "(", "obs1", ")", ".", "shape", "==", "(", "venv1", ".", "num_envs", ",", ")", "+", "venv1", ".", "observation_space", ".", "shape", "\n", "assert", "np", ".", "allclose", "(", "obs1", ",", "obs2", ")", "\n", "venv1", ".", "action_space", ".", "seed", "(", "1337", ")", "\n", "for", "_", "in", "range", "(", "num_steps", ")", ":", "\n", "            ", "actions", "=", "np", ".", "array", "(", "[", "venv1", ".", "action_space", ".", "sample", "(", ")", "for", "_", "in", "range", "(", "venv1", ".", "num_envs", ")", "]", ")", "\n", "for", "venv", "in", "[", "venv1", ",", "venv2", "]", ":", "\n", "                ", "venv", ".", "step_async", "(", "actions", ")", "\n", "", "outs1", "=", "venv1", ".", "step_wait", "(", ")", "\n", "outs2", "=", "venv2", ".", "step_wait", "(", ")", "\n", "for", "out1", ",", "out2", "in", "zip", "(", "outs1", "[", ":", "3", "]", ",", "outs2", "[", ":", "3", "]", ")", ":", "\n", "                ", "assert", "np", ".", "array", "(", "out1", ")", ".", "shape", "==", "np", ".", "array", "(", "out2", ")", ".", "shape", "\n", "assert", "np", ".", "allclose", "(", "out1", ",", "out2", ")", "\n", "", "assert", "list", "(", "outs1", "[", "3", "]", ")", "==", "list", "(", "outs2", "[", "3", "]", ")", "\n", "", "", "finally", ":", "\n", "        ", "venv1", ".", "close", "(", ")", "\n", "venv2", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.test_vec_env": [[47, 68], ["pytest.mark.parametrize", "pytest.mark.parametrize", "dummy_vec_env.DummyVecEnv", "klass", "test_vec_env.assert_venvs_equal", "test_vec_env.test_vec_env.make_fn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.assert_venvs_equal"], ["", "", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'klass'", ",", "(", "ShmemVecEnv", ",", "SubprocVecEnv", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dtype'", ",", "(", "'uint8'", ",", "'float32'", ")", ")", "\n", "def", "test_vec_env", "(", "klass", ",", "dtype", ")", ":", "# pylint: disable=R0914", "\n", "    ", "\"\"\"\n    Test that a vectorized environment is equivalent to\n    DummyVecEnv, since DummyVecEnv is less likely to be\n    error prone.\n    \"\"\"", "\n", "num_envs", "=", "3", "\n", "num_steps", "=", "100", "\n", "shape", "=", "(", "3", ",", "8", ")", "\n", "\n", "def", "make_fn", "(", "seed", ")", ":", "\n", "        ", "\"\"\"\n        Get an environment constructor with a seed.\n        \"\"\"", "\n", "return", "lambda", ":", "SimpleEnv", "(", "seed", ",", "shape", ",", "dtype", ")", "\n", "", "fns", "=", "[", "make_fn", "(", "i", ")", "for", "i", "in", "range", "(", "num_envs", ")", "]", "\n", "env1", "=", "DummyVecEnv", "(", "fns", ")", "\n", "env2", "=", "klass", "(", "fns", ")", "\n", "assert_venvs_equal", "(", "env1", ",", "env2", ",", "num_steps", "=", "num_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.test_sync_sampling": [[70, 90], ["pytest.mark.parametrize", "pytest.mark.parametrize", "dummy_vec_env.DummyVecEnv", "subproc_vec_env.SubprocVecEnv", "test_vec_env.assert_venvs_equal", "test_vec_env.test_vec_env.make_fn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.assert_venvs_equal"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dtype'", ",", "(", "'uint8'", ",", "'float32'", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'num_envs_in_series'", ",", "(", "3", ",", "4", ",", "6", ")", ")", "\n", "def", "test_sync_sampling", "(", "dtype", ",", "num_envs_in_series", ")", ":", "\n", "    ", "\"\"\"\n    Test that a SubprocVecEnv running with envs in series\n    outputs the same as DummyVecEnv.\n    \"\"\"", "\n", "num_envs", "=", "12", "\n", "num_steps", "=", "100", "\n", "shape", "=", "(", "3", ",", "8", ")", "\n", "\n", "def", "make_fn", "(", "seed", ")", ":", "\n", "        ", "\"\"\"\n        Get an environment constructor with a seed.\n        \"\"\"", "\n", "return", "lambda", ":", "SimpleEnv", "(", "seed", ",", "shape", ",", "dtype", ")", "\n", "", "fns", "=", "[", "make_fn", "(", "i", ")", "for", "i", "in", "range", "(", "num_envs", ")", "]", "\n", "env1", "=", "DummyVecEnv", "(", "fns", ")", "\n", "env2", "=", "SubprocVecEnv", "(", "fns", ",", "in_series", "=", "num_envs_in_series", ")", "\n", "assert_venvs_equal", "(", "env1", ",", "env2", ",", "num_steps", "=", "num_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.test_sync_sampling_sanity": [[92, 112], ["pytest.mark.parametrize", "pytest.mark.parametrize", "subproc_vec_env.SubprocVecEnv", "subproc_vec_env.SubprocVecEnv", "test_vec_env.assert_venvs_equal", "test_vec_env.test_vec_env.make_fn"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.assert_venvs_equal"], ["", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'dtype'", ",", "(", "'uint8'", ",", "'float32'", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'num_envs_in_series'", ",", "(", "3", ",", "4", ",", "6", ")", ")", "\n", "def", "test_sync_sampling_sanity", "(", "dtype", ",", "num_envs_in_series", ")", ":", "\n", "    ", "\"\"\"\n    Test that a SubprocVecEnv running with envs in series\n    outputs the same as SubprocVecEnv without running in series.\n    \"\"\"", "\n", "num_envs", "=", "12", "\n", "num_steps", "=", "100", "\n", "shape", "=", "(", "3", ",", "8", ")", "\n", "\n", "def", "make_fn", "(", "seed", ")", ":", "\n", "        ", "\"\"\"\n        Get an environment constructor with a seed.\n        \"\"\"", "\n", "return", "lambda", ":", "SimpleEnv", "(", "seed", ",", "shape", ",", "dtype", ")", "\n", "", "fns", "=", "[", "make_fn", "(", "i", ")", "for", "i", "in", "range", "(", "num_envs", ")", "]", "\n", "env1", "=", "SubprocVecEnv", "(", "fns", ")", "\n", "env2", "=", "SubprocVecEnv", "(", "fns", ",", "in_series", "=", "num_envs_in_series", ")", "\n", "assert_venvs_equal", "(", "env1", ",", "env2", ",", "num_steps", "=", "num_steps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_vec_env.test_mpi_with_subprocvecenv": [[150, 158], ["baselines.common.tests.test_with_mpi.with_mpi", "subproc_vec_env.SubprocVecEnv", "subproc_vec_env.SubprocVecEnv.reset", "subproc_vec_env.SubprocVecEnv.close", "test_vec_env.SimpleEnv"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.tests.test_with_mpi.with_mpi", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "", "@", "with_mpi", "(", ")", "\n", "def", "test_mpi_with_subprocvecenv", "(", ")", ":", "\n", "    ", "shape", "=", "(", "2", ",", "3", ",", "4", ")", "\n", "nenv", "=", "1", "\n", "venv", "=", "SubprocVecEnv", "(", "[", "lambda", ":", "SimpleEnv", "(", "0", ",", "shape", ",", "'float32'", ")", "]", "*", "nenv", ")", "\n", "ob", "=", "venv", ".", "reset", "(", ")", "\n", "venv", ".", "close", "(", ")", "\n", "assert", "ob", ".", "shape", "==", "(", "nenv", ",", ")", "+", "shape", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_frame_stack.VecFrameStack.__init__": [[7, 16], ["numpy.repeat", "numpy.repeat", "numpy.zeros", "gym.spaces.Box", "vec_env.VecEnvWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "venv", ",", "nstack", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "self", ".", "nstack", "=", "nstack", "\n", "wos", "=", "venv", ".", "observation_space", "# wrapped ob space", "\n", "low", "=", "np", ".", "repeat", "(", "wos", ".", "low", ",", "self", ".", "nstack", ",", "axis", "=", "-", "1", ")", "\n", "high", "=", "np", ".", "repeat", "(", "wos", ".", "high", ",", "self", ".", "nstack", ",", "axis", "=", "-", "1", ")", "\n", "self", ".", "stackedobs", "=", "np", ".", "zeros", "(", "(", "venv", ".", "num_envs", ",", ")", "+", "low", ".", "shape", ",", "low", ".", "dtype", ")", "\n", "observation_space", "=", "spaces", ".", "Box", "(", "low", "=", "low", ",", "high", "=", "high", ",", "dtype", "=", "venv", ".", "observation_space", ".", "dtype", ")", "\n", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ",", "observation_space", "=", "observation_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_frame_stack.VecFrameStack.step_wait": [[17, 25], ["vec_frame_stack.VecFrameStack.venv.step_wait", "numpy.roll", "enumerate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "obs", ",", "rews", ",", "news", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "stackedobs", "=", "np", ".", "roll", "(", "self", ".", "stackedobs", ",", "shift", "=", "-", "1", ",", "axis", "=", "-", "1", ")", "\n", "for", "(", "i", ",", "new", ")", "in", "enumerate", "(", "news", ")", ":", "\n", "            ", "if", "new", ":", "\n", "                ", "self", ".", "stackedobs", "[", "i", "]", "=", "0", "\n", "", "", "self", ".", "stackedobs", "[", "...", ",", "-", "obs", ".", "shape", "[", "-", "1", "]", ":", "]", "=", "obs", "\n", "return", "self", ".", "stackedobs", ",", "rews", ",", "news", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_frame_stack.VecFrameStack.reset": [[26, 31], ["vec_frame_stack.VecFrameStack.venv.reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "stackedobs", "[", "...", "]", "=", "0", "\n", "self", ".", "stackedobs", "[", "...", ",", "-", "obs", ".", "shape", "[", "-", "1", "]", ":", "]", "=", "obs", "\n", "return", "self", ".", "stackedobs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_remove_dict_obs.VecExtractDictObs.__init__": [[4, 8], ["vec_env.VecEnvObservationWrapper.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "venv", ",", "key", ")", ":", "\n", "        ", "self", ".", "key", "=", "key", "\n", "super", "(", ")", ".", "__init__", "(", "venv", "=", "venv", ",", "\n", "observation_space", "=", "venv", ".", "observation_space", ".", "spaces", "[", "self", ".", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_remove_dict_obs.VecExtractDictObs.process": [[9, 11], ["None"], "methods", ["None"], ["", "def", "process", "(", "self", ",", "obs", ")", ":", "\n", "        ", "return", "obs", "[", "self", ".", "key", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.AlreadySteppingError.__init__": [[13, 16], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "'already running an async step'", "\n", "Exception", ".", "__init__", "(", "self", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.NotSteppingError.__init__": [[24, 27], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "msg", "=", "'not running an async step'", "\n", "Exception", ".", "__init__", "(", "self", ",", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.__init__": [[43, 47], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "num_envs", ",", "observation_space", ",", "action_space", ")", ":", "\n", "        ", "self", ".", "num_envs", "=", "num_envs", "\n", "self", ".", "observation_space", "=", "observation_space", "\n", "self", ".", "action_space", "=", "action_space", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.reset": [[48, 59], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Reset all the environments and return an array of\n        observations, or a dict of observation arrays.\n\n        If step_async is still doing work, that work will\n        be cancelled and step_wait() should not be called\n        until step_async() is invoked again.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.step_async": [[60, 71], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "\"\"\"\n        Tell all the environments to start taking a step\n        with the given actions.\n        Call step_wait() to get the results of the step.\n\n        You should not call this if a step_async run is\n        already pending.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.step_wait": [[72, 85], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Wait for the step taken with step_async().\n\n        Returns (obs, rews, dones, infos):\n         - obs: an array of observations, or a dict of\n                arrays of observations.\n         - rews: an array of rewards\n         - dones: an array of \"episode done\" booleans\n         - infos: a sequence of info objects\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.close_extras": [[86, 92], ["None"], "methods", ["None"], ["", "def", "close_extras", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Clean up the  extra resources, beyond what's in this base class.\n        Only runs when not self.closed.\n        \"\"\"", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.close": [[93, 100], ["vec_env.VecEnv.close_extras", "vec_env.VecEnv.viewer.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.close_extras", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "closed", ":", "\n", "            ", "return", "\n", "", "if", "self", ".", "viewer", "is", "not", "None", ":", "\n", "            ", "self", ".", "viewer", ".", "close", "(", ")", "\n", "", "self", ".", "close_extras", "(", ")", "\n", "self", ".", "closed", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.step": [[101, 109], ["vec_env.VecEnv.step_async", "vec_env.VecEnv.step_wait"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_async", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait"], ["", "def", "step", "(", "self", ",", "actions", ")", ":", "\n", "        ", "\"\"\"\n        Step the environments synchronously.\n\n        This is available for backwards compatibility.\n        \"\"\"", "\n", "self", ".", "step_async", "(", "actions", ")", "\n", "return", "self", ".", "step_wait", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.render": [[110, 120], ["vec_env.VecEnv.get_images", "baselines.common.tile_images.tile_images", "vec_env.VecEnv.get_viewer().imshow", "vec_env.VecEnv.get_viewer", "vec_env.VecEnv.get_viewer"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.get_images", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.tile_images.tile_images", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.SimpleImageViewer.imshow", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.get_viewer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.get_viewer"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "imgs", "=", "self", ".", "get_images", "(", ")", "\n", "bigimg", "=", "tile_images", "(", "imgs", ")", "\n", "if", "mode", "==", "'human'", ":", "\n", "            ", "self", ".", "get_viewer", "(", ")", ".", "imshow", "(", "bigimg", ")", "\n", "return", "self", ".", "get_viewer", "(", ")", ".", "isopen", "\n", "", "elif", "mode", "==", "'rgb_array'", ":", "\n", "            ", "return", "bigimg", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.get_images": [[121, 126], ["None"], "methods", ["None"], ["", "", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Return RGB images from each environment\n        \"\"\"", "\n", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.unwrapped": [[127, 133], ["isinstance"], "methods", ["None"], ["", "@", "property", "\n", "def", "unwrapped", "(", "self", ")", ":", "\n", "        ", "if", "isinstance", "(", "self", ",", "VecEnvWrapper", ")", ":", "\n", "            ", "return", "self", ".", "venv", ".", "unwrapped", "\n", "", "else", ":", "\n", "            ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnv.get_viewer": [[134, 139], ["rendering.SimpleImageViewer"], "methods", ["None"], ["", "", "def", "get_viewer", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "viewer", "is", "None", ":", "\n", "            ", "from", "gym", ".", "envs", ".", "classic_control", "import", "rendering", "\n", "self", ".", "viewer", "=", "rendering", ".", "SimpleImageViewer", "(", ")", "\n", "", "return", "self", ".", "viewer", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.__init__": [[146, 151], ["vec_env.VecEnv.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "observation_space", "=", "None", ",", "action_space", "=", "None", ")", ":", "\n", "        ", "self", ".", "venv", "=", "venv", "\n", "super", "(", ")", ".", "__init__", "(", "num_envs", "=", "venv", ".", "num_envs", ",", "\n", "observation_space", "=", "observation_space", "or", "venv", ".", "observation_space", ",", "\n", "action_space", "=", "action_space", "or", "venv", ".", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.step_async": [[152, 154], ["vec_env.VecEnvWrapper.venv.step_async"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_async"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "venv", ".", "step_async", "(", "actions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.reset": [[155, 158], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.step_wait": [[159, 162], ["None"], "methods", ["None"], ["", "@", "abstractmethod", "\n", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.close": [[163, 165], ["vec_env.VecEnvWrapper.venv.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.render": [[166, 168], ["vec_env.VecEnvWrapper.venv.render"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "render", "(", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.get_images": [[169, 171], ["vec_env.VecEnvWrapper.venv.get_images"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.get_images"], ["", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "venv", ".", "get_images", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvWrapper.__getattr__": [[172, 176], ["name.startswith", "getattr", "AttributeError"], "methods", ["None"], ["", "def", "__getattr__", "(", "self", ",", "name", ")", ":", "\n", "        ", "if", "name", ".", "startswith", "(", "'_'", ")", ":", "\n", "            ", "raise", "AttributeError", "(", "\"attempted to get missing private attribute '{}'\"", ".", "format", "(", "name", ")", ")", "\n", "", "return", "getattr", "(", "self", ".", "venv", ",", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvObservationWrapper.process": [[178, 181], ["None"], "methods", ["None"], ["    ", "@", "abstractmethod", "\n", "def", "process", "(", "self", ",", "obs", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvObservationWrapper.reset": [[182, 185], ["vec_env.VecEnvObservationWrapper.venv.reset", "vec_env.VecEnvObservationWrapper.process"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvObservationWrapper.process"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "return", "self", ".", "process", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvObservationWrapper.step_wait": [[186, 189], ["vec_env.VecEnvObservationWrapper.venv.step_wait", "vec_env.VecEnvObservationWrapper.process"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.VecEnvObservationWrapper.process"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "return", "self", ".", "process", "(", "obs", ")", ",", "rews", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.CloudpickleWrapper.__init__": [[195, 197], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "x", ")", ":", "\n", "        ", "self", ".", "x", "=", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.CloudpickleWrapper.__getstate__": [[198, 201], ["cloudpickle.dumps"], "methods", ["None"], ["", "def", "__getstate__", "(", "self", ")", ":", "\n", "        ", "import", "cloudpickle", "\n", "return", "cloudpickle", ".", "dumps", "(", "self", ".", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.CloudpickleWrapper.__setstate__": [[202, 205], ["pickle.loads"], "methods", ["None"], ["", "def", "__setstate__", "(", "self", ",", "ob", ")", ":", "\n", "        ", "import", "pickle", "\n", "self", ".", "x", "=", "pickle", ".", "loads", "(", "ob", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.clear_mpi_env_vars": [[207, 224], ["list", "os.environ.items", "os.environ.update", "k.startswith"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "", "@", "contextlib", ".", "contextmanager", "\n", "def", "clear_mpi_env_vars", "(", ")", ":", "\n", "    ", "\"\"\"\n    from mpi4py import MPI will call MPI_Init by default.  If the child process has MPI environment variables, MPI will think that the child process is an MPI process just like the parent and do bad things such as hang.\n    This context manager is a hacky way to clear those environment variables temporarily such as when we are starting multiprocessing\n    Processes.\n    \"\"\"", "\n", "removed_environment", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "list", "(", "os", ".", "environ", ".", "items", "(", ")", ")", ":", "\n", "        ", "for", "prefix", "in", "[", "'OMPI_'", ",", "'PMI_'", "]", ":", "\n", "            ", "if", "k", ".", "startswith", "(", "prefix", ")", ":", "\n", "                ", "removed_environment", "[", "k", "]", "=", "v", "\n", "del", "os", ".", "environ", "[", "k", "]", "\n", "", "", "", "try", ":", "\n", "        ", "yield", "\n", "", "finally", ":", "\n", "        ", "os", ".", "environ", ".", "update", "(", "removed_environment", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv.__init__": [[44, 74], ["len", "numpy.array_split", "multiprocessing.get_context", "zip", "subproc_vec_env.SubprocVecEnv.remotes[].send", "vec_env.VecEnv.__init__", "multiprocessing.get_context.Process", "remote.close", "subproc_vec_env.SubprocVecEnv.remotes[].recv", "zip", "vec_env.clear_mpi_env_vars", "p.start", "multiprocessing.get_context.Pipe", "range", "vec_env.CloudpickleWrapper"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.clear_mpi_env_vars"], ["def", "__init__", "(", "self", ",", "env_fns", ",", "spaces", "=", "None", ",", "context", "=", "'spawn'", ",", "in_series", "=", "1", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n\n        env_fns: iterable of callables -  functions that create environments to run in subprocesses. Need to be cloud-pickleable\n        in_series: number of environments to run in series in a single process\n        (e.g. when len(env_fns) == 12 and in_series == 3, it will run 4 processes, each running 3 envs in series)\n        \"\"\"", "\n", "self", ".", "waiting", "=", "False", "\n", "self", ".", "closed", "=", "False", "\n", "self", ".", "in_series", "=", "in_series", "\n", "nenvs", "=", "len", "(", "env_fns", ")", "\n", "assert", "nenvs", "%", "in_series", "==", "0", ",", "\"Number of envs must be divisible by number of envs to run in series\"", "\n", "self", ".", "nremotes", "=", "nenvs", "//", "in_series", "\n", "env_fns", "=", "np", ".", "array_split", "(", "env_fns", ",", "self", ".", "nremotes", ")", "\n", "ctx", "=", "mp", ".", "get_context", "(", "context", ")", "\n", "self", ".", "remotes", ",", "self", ".", "work_remotes", "=", "zip", "(", "*", "[", "ctx", ".", "Pipe", "(", ")", "for", "_", "in", "range", "(", "self", ".", "nremotes", ")", "]", ")", "\n", "self", ".", "ps", "=", "[", "ctx", ".", "Process", "(", "target", "=", "worker", ",", "args", "=", "(", "work_remote", ",", "remote", ",", "CloudpickleWrapper", "(", "env_fn", ")", ")", ")", "\n", "for", "(", "work_remote", ",", "remote", ",", "env_fn", ")", "in", "zip", "(", "self", ".", "work_remotes", ",", "self", ".", "remotes", ",", "env_fns", ")", "]", "\n", "for", "p", "in", "self", ".", "ps", ":", "\n", "            ", "p", ".", "daemon", "=", "True", "# if the main process crashes, we should not cause things to hang", "\n", "with", "clear_mpi_env_vars", "(", ")", ":", "\n", "                ", "p", ".", "start", "(", ")", "\n", "", "", "for", "remote", "in", "self", ".", "work_remotes", ":", "\n", "            ", "remote", ".", "close", "(", ")", "\n", "\n", "", "self", ".", "remotes", "[", "0", "]", ".", "send", "(", "(", "'get_spaces_spec'", ",", "None", ")", ")", "\n", "observation_space", ",", "action_space", ",", "self", ".", "spec", "=", "self", ".", "remotes", "[", "0", "]", ".", "recv", "(", ")", ".", "x", "\n", "self", ".", "viewer", "=", "None", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "nenvs", ",", "observation_space", ",", "action_space", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv.step_async": [[75, 81], ["subproc_vec_env.SubprocVecEnv._assert_not_closed", "numpy.array_split", "zip", "remote.send"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv._assert_not_closed"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "actions", "=", "np", ".", "array_split", "(", "actions", ",", "self", ".", "nremotes", ")", "\n", "for", "remote", ",", "action", "in", "zip", "(", "self", ".", "remotes", ",", "actions", ")", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'step'", ",", "action", ")", ")", "\n", "", "self", ".", "waiting", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv.step_wait": [[82, 89], ["subproc_vec_env.SubprocVecEnv._assert_not_closed", "subproc_vec_env._flatten_list", "zip", "remote.recv", "subproc_vec_env._flatten_obs", "numpy.stack", "numpy.stack"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv._assert_not_closed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env._flatten_list", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env._flatten_obs"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "results", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "results", "=", "_flatten_list", "(", "results", ")", "\n", "self", ".", "waiting", "=", "False", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "zip", "(", "*", "results", ")", "\n", "return", "_flatten_obs", "(", "obs", ")", ",", "np", ".", "stack", "(", "rews", ")", ",", "np", ".", "stack", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv.reset": [[90, 97], ["subproc_vec_env.SubprocVecEnv._assert_not_closed", "subproc_vec_env._flatten_list", "subproc_vec_env._flatten_obs", "remote.send", "remote.recv"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv._assert_not_closed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env._flatten_list", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env._flatten_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'reset'", ",", "None", ")", ")", "\n", "", "obs", "=", "[", "remote", ".", "recv", "(", ")", "for", "remote", "in", "self", ".", "remotes", "]", "\n", "obs", "=", "_flatten_list", "(", "obs", ")", "\n", "return", "_flatten_obs", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv.close_extras": [[98, 107], ["remote.send", "p.join", "remote.recv"], "methods", ["None"], ["", "def", "close_extras", "(", "self", ")", ":", "\n", "        ", "self", ".", "closed", "=", "True", "\n", "if", "self", ".", "waiting", ":", "\n", "            ", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "                ", "remote", ".", "recv", "(", ")", "\n", "", "", "for", "remote", "in", "self", ".", "remotes", ":", "\n", "            ", "remote", ".", "send", "(", "(", "'close'", ",", "None", ")", ")", "\n", "", "for", "p", "in", "self", ".", "ps", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv.get_images": [[108, 115], ["subproc_vec_env.SubprocVecEnv._assert_not_closed", "subproc_vec_env._flatten_list", "pipe.send", "pipe.recv"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv._assert_not_closed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env._flatten_list"], ["", "", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "self", ".", "_assert_not_closed", "(", ")", "\n", "for", "pipe", "in", "self", ".", "remotes", ":", "\n", "            ", "pipe", ".", "send", "(", "(", "'render'", ",", "None", ")", ")", "\n", "", "imgs", "=", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "remotes", "]", "\n", "imgs", "=", "_flatten_list", "(", "imgs", ")", "\n", "return", "imgs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv._assert_not_closed": [[116, 118], ["None"], "methods", ["None"], ["", "def", "_assert_not_closed", "(", "self", ")", ":", "\n", "        ", "assert", "not", "self", ".", "closed", ",", "\"Trying to operate on a SubprocVecEnv after calling close()\"", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.SubprocVecEnv.__del__": [[119, 122], ["subproc_vec_env.SubprocVecEnv.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "closed", ":", "\n", "            ", "self", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env.worker": [[7, 37], ["parent_remote.close", "env.step", "env_fn_wrapper", "env.reset", "remote.recv", "print", "env.close", "remote.send", "remote.send", "subproc_vec_env.worker.step_env"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["def", "worker", "(", "remote", ",", "parent_remote", ",", "env_fn_wrappers", ")", ":", "\n", "    ", "def", "step_env", "(", "env", ",", "action", ")", ":", "\n", "        ", "ob", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "action", ")", "\n", "if", "done", ":", "\n", "            ", "ob", "=", "env", ".", "reset", "(", ")", "\n", "", "return", "ob", ",", "reward", ",", "done", ",", "info", "\n", "\n", "", "parent_remote", ".", "close", "(", ")", "\n", "envs", "=", "[", "env_fn_wrapper", "(", ")", "for", "env_fn_wrapper", "in", "env_fn_wrappers", ".", "x", "]", "\n", "try", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "cmd", ",", "data", "=", "remote", ".", "recv", "(", ")", "\n", "if", "cmd", "==", "'step'", ":", "\n", "                ", "remote", ".", "send", "(", "[", "step_env", "(", "env", ",", "action", ")", "for", "env", ",", "action", "in", "zip", "(", "envs", ",", "data", ")", "]", ")", "\n", "", "elif", "cmd", "==", "'reset'", ":", "\n", "                ", "remote", ".", "send", "(", "[", "env", ".", "reset", "(", ")", "for", "env", "in", "envs", "]", ")", "\n", "", "elif", "cmd", "==", "'render'", ":", "\n", "                ", "remote", ".", "send", "(", "[", "env", ".", "render", "(", "mode", "=", "'rgb_array'", ")", "for", "env", "in", "envs", "]", ")", "\n", "", "elif", "cmd", "==", "'close'", ":", "\n", "                ", "remote", ".", "close", "(", ")", "\n", "break", "\n", "", "elif", "cmd", "==", "'get_spaces_spec'", ":", "\n", "                ", "remote", ".", "send", "(", "CloudpickleWrapper", "(", "(", "envs", "[", "0", "]", ".", "observation_space", ",", "envs", "[", "0", "]", ".", "action_space", ",", "envs", "[", "0", "]", ".", "spec", ")", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "NotImplementedError", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "print", "(", "'SubprocVecEnv worker: got KeyboardInterrupt'", ")", "\n", "", "finally", ":", "\n", "        ", "for", "env", "in", "envs", ":", "\n", "            ", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env._flatten_obs": [[123, 132], ["isinstance", "isinstance", "len", "obs[].keys", "numpy.stack", "numpy.stack"], "function", ["None"], ["", "", "", "def", "_flatten_obs", "(", "obs", ")", ":", "\n", "    ", "assert", "isinstance", "(", "obs", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "obs", ")", ">", "0", "\n", "\n", "if", "isinstance", "(", "obs", "[", "0", "]", ",", "dict", ")", ":", "\n", "        ", "keys", "=", "obs", "[", "0", "]", ".", "keys", "(", ")", "\n", "return", "{", "k", ":", "np", ".", "stack", "(", "[", "o", "[", "k", "]", "for", "o", "in", "obs", "]", ")", "for", "k", "in", "keys", "}", "\n", "", "else", ":", "\n", "        ", "return", "np", ".", "stack", "(", "obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.subproc_vec_env._flatten_list": [[133, 139], ["isinstance", "all", "len", "len"], "function", ["None"], ["", "", "def", "_flatten_list", "(", "l", ")", ":", "\n", "    ", "assert", "isinstance", "(", "l", ",", "(", "list", ",", "tuple", ")", ")", "\n", "assert", "len", "(", "l", ")", ">", "0", "\n", "assert", "all", "(", "[", "len", "(", "l_", ")", ">", "0", "for", "l_", "in", "l", "]", ")", "\n", "\n", "return", "[", "l__", "for", "l_", "in", "l", "for", "l__", "in", "l_", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.test_video_recorder.test_video_recorder": [[16, 48], ["pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "pytest.mark.parametrize", "klass", "gym.make", "tempfile.TemporaryDirectory", "vec_video_recorder.VecVideoRecorder", "vec_video_recorder.VecVideoRecorder.reset", "range", "vec_video_recorder.VecVideoRecorder.close", "glob.glob", "all", "range", "vec_video_recorder.VecVideoRecorder.step", "os.path.join", "len", "os.stat"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["@", "pytest", ".", "mark", ".", "parametrize", "(", "'klass'", ",", "(", "DummyVecEnv", ",", "ShmemVecEnv", ",", "SubprocVecEnv", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'num_envs'", ",", "(", "1", ",", "4", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'video_length'", ",", "(", "10", ",", "100", ")", ")", "\n", "@", "pytest", ".", "mark", ".", "parametrize", "(", "'video_interval'", ",", "(", "1", ",", "50", ")", ")", "\n", "def", "test_video_recorder", "(", "klass", ",", "num_envs", ",", "video_length", ",", "video_interval", ")", ":", "\n", "    ", "\"\"\"\n    Wrap an existing VecEnv with VevVideoRecorder,\n    Make (video_interval + video_length + 1) steps,\n    then check that the file is present\n    \"\"\"", "\n", "\n", "def", "make_fn", "(", ")", ":", "\n", "        ", "env", "=", "gym", ".", "make", "(", "'PongNoFrameskip-v4'", ")", "\n", "return", "env", "\n", "", "fns", "=", "[", "make_fn", "for", "_", "in", "range", "(", "num_envs", ")", "]", "\n", "env", "=", "klass", "(", "fns", ")", "\n", "\n", "with", "tempfile", ".", "TemporaryDirectory", "(", ")", "as", "video_path", ":", "\n", "        ", "env", "=", "VecVideoRecorder", "(", "env", ",", "video_path", ",", "record_video_trigger", "=", "lambda", "x", ":", "x", "%", "video_interval", "==", "0", ",", "video_length", "=", "video_length", ")", "\n", "\n", "env", ".", "reset", "(", ")", "\n", "for", "_", "in", "range", "(", "video_interval", "+", "video_length", "+", "1", ")", ":", "\n", "            ", "env", ".", "step", "(", "[", "0", "]", "*", "num_envs", ")", "\n", "", "env", ".", "close", "(", ")", "\n", "\n", "\n", "recorded_video", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "video_path", ",", "\"*.mp4\"", ")", ")", "\n", "\n", "# first and second step", "\n", "assert", "len", "(", "recorded_video", ")", "==", "2", "\n", "# Files are not empty", "\n", "assert", "all", "(", "os", ".", "stat", "(", "p", ")", ".", "st_size", "!=", "0", "for", "p", "in", "recorded_video", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.__init__": [[12, 30], ["vec_env.VecEnv.__init__", "util.obs_space_info", "numpy.zeros", "numpy.zeros", "fn", "len", "numpy.zeros", "range", "tuple"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.obs_space_info"], ["def", "__init__", "(", "self", ",", "env_fns", ")", ":", "\n", "        ", "\"\"\"\n        Arguments:\n\n        env_fns: iterable of callables      functions that build environments\n        \"\"\"", "\n", "self", ".", "envs", "=", "[", "fn", "(", ")", "for", "fn", "in", "env_fns", "]", "\n", "env", "=", "self", ".", "envs", "[", "0", "]", "\n", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "env", ".", "observation_space", ",", "env", ".", "action_space", ")", "\n", "obs_space", "=", "env", ".", "observation_space", "\n", "self", ".", "keys", ",", "shapes", ",", "dtypes", "=", "obs_space_info", "(", "obs_space", ")", "\n", "\n", "self", ".", "buf_obs", "=", "{", "k", ":", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", "+", "tuple", "(", "shapes", "[", "k", "]", ")", ",", "dtype", "=", "dtypes", "[", "k", "]", ")", "for", "k", "in", "self", ".", "keys", "}", "\n", "self", ".", "buf_dones", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "bool", ")", "\n", "self", ".", "buf_rews", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_envs", ",", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "self", ".", "buf_infos", "=", "[", "{", "}", "for", "_", "in", "range", "(", "self", ".", "num_envs", ")", "]", "\n", "self", ".", "actions", "=", "None", "\n", "self", ".", "spec", "=", "self", ".", "envs", "[", "0", "]", ".", "spec", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.step_async": [[31, 44], ["len"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "listify", "=", "True", "\n", "try", ":", "\n", "            ", "if", "len", "(", "actions", ")", "==", "self", ".", "num_envs", ":", "\n", "                ", "listify", "=", "False", "\n", "", "", "except", "TypeError", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "not", "listify", ":", "\n", "            ", "self", ".", "actions", "=", "actions", "\n", "", "else", ":", "\n", "            ", "assert", "self", ".", "num_envs", "==", "1", ",", "\"actions {} is either not a list or has a wrong size - cannot match to {} environments\"", ".", "format", "(", "actions", ",", "self", ".", "num_envs", ")", "\n", "self", ".", "actions", "=", "[", "actions", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.step_wait": [[45, 57], ["range", "dummy_vec_env.DummyVecEnv.envs[].step", "dummy_vec_env.DummyVecEnv._save_obs", "dummy_vec_env.DummyVecEnv._obs_from_buf", "numpy.copy", "numpy.copy", "dummy_vec_env.DummyVecEnv.buf_infos.copy", "dummy_vec_env.DummyVecEnv.envs[].reset"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv._save_obs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "for", "e", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "            ", "action", "=", "self", ".", "actions", "[", "e", "]", "\n", "# if isinstance(self.envs[e].action_space, spaces.Discrete):", "\n", "#    action = int(action)", "\n", "\n", "obs", ",", "self", ".", "buf_rews", "[", "e", "]", ",", "self", ".", "buf_dones", "[", "e", "]", ",", "self", ".", "buf_infos", "[", "e", "]", "=", "self", ".", "envs", "[", "e", "]", ".", "step", "(", "action", ")", "\n", "if", "self", ".", "buf_dones", "[", "e", "]", ":", "\n", "                ", "obs", "=", "self", ".", "envs", "[", "e", "]", ".", "reset", "(", ")", "\n", "", "self", ".", "_save_obs", "(", "e", ",", "obs", ")", "\n", "", "return", "(", "self", ".", "_obs_from_buf", "(", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_rews", ")", ",", "np", ".", "copy", "(", "self", ".", "buf_dones", ")", ",", "\n", "self", ".", "buf_infos", ".", "copy", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.reset": [[58, 63], ["range", "dummy_vec_env.DummyVecEnv._obs_from_buf", "dummy_vec_env.DummyVecEnv.envs[].reset", "dummy_vec_env.DummyVecEnv._save_obs"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv._save_obs"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "for", "e", "in", "range", "(", "self", ".", "num_envs", ")", ":", "\n", "            ", "obs", "=", "self", ".", "envs", "[", "e", "]", ".", "reset", "(", ")", "\n", "self", ".", "_save_obs", "(", "e", ",", "obs", ")", "\n", "", "return", "self", ".", "_obs_from_buf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv._save_obs": [[64, 70], ["None"], "methods", ["None"], ["", "def", "_save_obs", "(", "self", ",", "e", ",", "obs", ")", ":", "\n", "        ", "for", "k", "in", "self", ".", "keys", ":", "\n", "            ", "if", "k", "is", "None", ":", "\n", "                ", "self", ".", "buf_obs", "[", "k", "]", "[", "e", "]", "=", "obs", "\n", "", "else", ":", "\n", "                ", "self", ".", "buf_obs", "[", "k", "]", "[", "e", "]", "=", "obs", "[", "k", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv._obs_from_buf": [[71, 73], ["util.dict_to_obs", "util.copy_obs_dict"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.dict_to_obs", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.copy_obs_dict"], ["", "", "", "def", "_obs_from_buf", "(", "self", ")", ":", "\n", "        ", "return", "dict_to_obs", "(", "copy_obs_dict", "(", "self", ".", "buf_obs", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.get_images": [[74, 76], ["env.render"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["", "def", "get_images", "(", "self", ")", ":", "\n", "        ", "return", "[", "env", ".", "render", "(", "mode", "=", "'rgb_array'", ")", "for", "env", "in", "self", ".", "envs", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render": [[77, 82], ["dummy_vec_env.DummyVecEnv.envs[].render", "super().render"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["", "def", "render", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "if", "self", ".", "num_envs", "==", "1", ":", "\n", "            ", "return", "self", ".", "envs", "[", "0", "]", ".", "render", "(", "mode", "=", "mode", ")", "\n", "", "else", ":", "\n", "            ", "return", "super", "(", ")", ".", "render", "(", "mode", "=", "mode", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.__init__": [[12, 38], ["baselines.common.vec_env.VecEnvWrapper.__init__", "os.path.abspath", "os.path.exists", "os.mkdir", "os.getpid"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "directory", ",", "record_video_trigger", ",", "video_length", "=", "200", ")", ":", "\n", "        ", "\"\"\"\n        # Arguments\n            venv: VecEnv to wrap\n            directory: Where to save videos\n            record_video_trigger:\n                Function that defines when to start recording.\n                The function takes the current number of step,\n                and returns whether we should start recording or not.\n            video_length: Length of recorded video\n        \"\"\"", "\n", "\n", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "record_video_trigger", "=", "record_video_trigger", "\n", "self", ".", "video_recorder", "=", "None", "\n", "\n", "self", ".", "directory", "=", "os", ".", "path", ".", "abspath", "(", "directory", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "self", ".", "directory", ")", ":", "os", ".", "mkdir", "(", "self", ".", "directory", ")", "\n", "\n", "self", ".", "file_prefix", "=", "\"vecenv\"", "\n", "self", ".", "file_infix", "=", "'{}'", ".", "format", "(", "os", ".", "getpid", "(", ")", ")", "\n", "self", ".", "step_id", "=", "0", "\n", "self", ".", "video_length", "=", "video_length", "\n", "\n", "self", ".", "recording", "=", "False", "\n", "self", ".", "recorded_frames", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.reset": [[39, 45], ["vec_video_recorder.VecVideoRecorder.venv.reset", "vec_video_recorder.VecVideoRecorder.start_video_recorder"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "\n", "self", ".", "start_video_recorder", "(", ")", "\n", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder": [[46, 59], ["vec_video_recorder.VecVideoRecorder.close_video_recorder", "os.path.join", "gym.wrappers.monitoring.video_recorder.VideoRecorder", "vec_video_recorder.VecVideoRecorder.video_recorder.capture_frame"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder"], ["", "def", "start_video_recorder", "(", "self", ")", ":", "\n", "        ", "self", ".", "close_video_recorder", "(", ")", "\n", "\n", "base_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "directory", ",", "'{}.video.{}.video{:06}'", ".", "format", "(", "self", ".", "file_prefix", ",", "self", ".", "file_infix", ",", "self", ".", "step_id", ")", ")", "\n", "self", ".", "video_recorder", "=", "video_recorder", ".", "VideoRecorder", "(", "\n", "env", "=", "self", ".", "venv", ",", "\n", "base_path", "=", "base_path", ",", "\n", "metadata", "=", "{", "'step_id'", ":", "self", ".", "step_id", "}", "\n", ")", "\n", "\n", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "self", ".", "recorded_frames", "=", "1", "\n", "self", ".", "recording", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder._video_enabled": [[60, 62], ["vec_video_recorder.VecVideoRecorder.record_video_trigger"], "methods", ["None"], ["", "def", "_video_enabled", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "record_video_trigger", "(", "self", ".", "step_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.step_wait": [[63, 77], ["vec_video_recorder.VecVideoRecorder.venv.step_wait", "vec_video_recorder.VecVideoRecorder.video_recorder.capture_frame", "vec_video_recorder.VecVideoRecorder._video_enabled", "baselines.logger.info", "vec_video_recorder.VecVideoRecorder.close_video_recorder", "vec_video_recorder.VecVideoRecorder.start_video_recorder"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder._video_enabled", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.start_video_recorder"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "\n", "self", ".", "step_id", "+=", "1", "\n", "if", "self", ".", "recording", ":", "\n", "            ", "self", ".", "video_recorder", ".", "capture_frame", "(", ")", "\n", "self", ".", "recorded_frames", "+=", "1", "\n", "if", "self", ".", "recorded_frames", ">", "self", ".", "video_length", ":", "\n", "                ", "logger", ".", "info", "(", "\"Saving video to \"", ",", "self", ".", "video_recorder", ".", "path", ")", "\n", "self", ".", "close_video_recorder", "(", ")", "\n", "", "", "elif", "self", ".", "_video_enabled", "(", ")", ":", "\n", "                ", "self", ".", "start_video_recorder", "(", ")", "\n", "\n", "", "return", "obs", ",", "rews", ",", "dones", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder": [[78, 83], ["vec_video_recorder.VecVideoRecorder.video_recorder.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close_video_recorder", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "recording", ":", "\n", "            ", "self", ".", "video_recorder", ".", "close", "(", ")", "\n", "", "self", ".", "recording", "=", "False", "\n", "self", ".", "recorded_frames", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close": [[84, 87], ["baselines.common.vec_env.VecEnvWrapper.close", "vec_video_recorder.VecVideoRecorder.close_video_recorder"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close_video_recorder"], ["", "def", "close", "(", "self", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "close", "(", "self", ")", "\n", "self", ".", "close_video_recorder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.__del__": [[88, 90], ["vec_video_recorder.VecVideoRecorder.close"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "__del__", "(", "self", ")", ":", "\n", "        ", "self", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_normalize.VecNormalize.__init__": [[10, 25], ["VecEnvWrapper.__init__", "numpy.zeros", "TfRunningMeanStd", "TfRunningMeanStd", "RunningMeanStd", "RunningMeanStd"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["def", "__init__", "(", "self", ",", "venv", ",", "ob", "=", "True", ",", "ret", "=", "True", ",", "clipob", "=", "10.", ",", "cliprew", "=", "10.", ",", "gamma", "=", "0.99", ",", "epsilon", "=", "1e-8", ",", "use_tf", "=", "False", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "if", "use_tf", ":", "\n", "            ", "from", "baselines", ".", "common", ".", "running_mean_std", "import", "TfRunningMeanStd", "\n", "self", ".", "ob_rms", "=", "TfRunningMeanStd", "(", "shape", "=", "self", ".", "observation_space", ".", "shape", ",", "scope", "=", "'ob_rms'", ")", "if", "ob", "else", "None", "\n", "self", ".", "ret_rms", "=", "TfRunningMeanStd", "(", "shape", "=", "(", ")", ",", "scope", "=", "'ret_rms'", ")", "if", "ret", "else", "None", "\n", "", "else", ":", "\n", "            ", "from", "baselines", ".", "common", ".", "running_mean_std", "import", "RunningMeanStd", "\n", "self", ".", "ob_rms", "=", "RunningMeanStd", "(", "shape", "=", "self", ".", "observation_space", ".", "shape", ")", "if", "ob", "else", "None", "\n", "self", ".", "ret_rms", "=", "RunningMeanStd", "(", "shape", "=", "(", ")", ")", "if", "ret", "else", "None", "\n", "", "self", ".", "clipob", "=", "clipob", "\n", "self", ".", "cliprew", "=", "cliprew", "\n", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_normalize.VecNormalize.step_wait": [[26, 35], ["vec_normalize.VecNormalize.venv.step_wait", "vec_normalize.VecNormalize._obfilt", "vec_normalize.VecNormalize.ret_rms.update", "numpy.clip", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_normalize.VecNormalize._obfilt", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "obs", ",", "rews", ",", "news", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "ret", "=", "self", ".", "ret", "*", "self", ".", "gamma", "+", "rews", "\n", "obs", "=", "self", ".", "_obfilt", "(", "obs", ")", "\n", "if", "self", ".", "ret_rms", ":", "\n", "            ", "self", ".", "ret_rms", ".", "update", "(", "self", ".", "ret", ")", "\n", "rews", "=", "np", ".", "clip", "(", "rews", "/", "np", ".", "sqrt", "(", "self", ".", "ret_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "cliprew", ",", "self", ".", "cliprew", ")", "\n", "", "self", ".", "ret", "[", "news", "]", "=", "0.", "\n", "return", "obs", ",", "rews", ",", "news", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_normalize.VecNormalize._obfilt": [[36, 43], ["vec_normalize.VecNormalize.ob_rms.update", "numpy.clip", "numpy.sqrt"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "def", "_obfilt", "(", "self", ",", "obs", ")", ":", "\n", "        ", "if", "self", ".", "ob_rms", ":", "\n", "            ", "self", ".", "ob_rms", ".", "update", "(", "obs", ")", "\n", "obs", "=", "np", ".", "clip", "(", "(", "obs", "-", "self", ".", "ob_rms", ".", "mean", ")", "/", "np", ".", "sqrt", "(", "self", ".", "ob_rms", ".", "var", "+", "self", ".", "epsilon", ")", ",", "-", "self", ".", "clipob", ",", "self", ".", "clipob", ")", "\n", "return", "obs", "\n", "", "else", ":", "\n", "            ", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_normalize.VecNormalize.reset": [[44, 48], ["numpy.zeros", "vec_normalize.VecNormalize.venv.reset", "vec_normalize.VecNormalize._obfilt"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_normalize.VecNormalize._obfilt"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "ret", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ")", "\n", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "return", "self", ".", "_obfilt", "(", "obs", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_monitor.VecMonitor.__init__": [[8, 24], ["VecEnvWrapper.__init__", "time.time", "baselines.bench.monitor.ResultsWriter", "collections.deque", "collections.deque"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "venv", ",", "filename", "=", "None", ",", "keep_buf", "=", "0", ",", "info_keywords", "=", "(", ")", ")", ":", "\n", "        ", "VecEnvWrapper", ".", "__init__", "(", "self", ",", "venv", ")", "\n", "self", ".", "eprets", "=", "None", "\n", "self", ".", "eplens", "=", "None", "\n", "self", ".", "epcount", "=", "0", "\n", "self", ".", "tstart", "=", "time", ".", "time", "(", ")", "\n", "if", "filename", ":", "\n", "            ", "self", ".", "results_writer", "=", "ResultsWriter", "(", "filename", ",", "header", "=", "{", "'t_start'", ":", "self", ".", "tstart", "}", ",", "\n", "extra_keys", "=", "info_keywords", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "results_writer", "=", "None", "\n", "", "self", ".", "info_keywords", "=", "info_keywords", "\n", "self", ".", "keep_buf", "=", "keep_buf", "\n", "if", "self", ".", "keep_buf", ":", "\n", "            ", "self", ".", "epret_buf", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "keep_buf", ")", "\n", "self", ".", "eplen_buf", "=", "deque", "(", "[", "]", ",", "maxlen", "=", "keep_buf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_monitor.VecMonitor.reset": [[25, 30], ["vec_monitor.VecMonitor.venv.reset", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset"], ["", "", "def", "reset", "(", "self", ")", ":", "\n", "        ", "obs", "=", "self", ".", "venv", ".", "reset", "(", ")", "\n", "self", ".", "eprets", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ",", "'f'", ")", "\n", "self", ".", "eplens", "=", "np", ".", "zeros", "(", "self", ".", "num_envs", ",", "'i'", ")", "\n", "return", "obs", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_monitor.VecMonitor.step_wait": [[31, 56], ["vec_monitor.VecMonitor.venv.step_wait", "list", "range", "len", "infos[].copy", "round", "vec_monitor.VecMonitor.epret_buf.append", "vec_monitor.VecMonitor.eplen_buf.append", "vec_monitor.VecMonitor.results_writer.write_row", "time.time"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.bench.monitor.ResultsWriter.write_row"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "self", ".", "venv", ".", "step_wait", "(", ")", "\n", "self", ".", "eprets", "+=", "rews", "\n", "self", ".", "eplens", "+=", "1", "\n", "\n", "newinfos", "=", "list", "(", "infos", "[", ":", "]", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "dones", ")", ")", ":", "\n", "            ", "if", "dones", "[", "i", "]", ":", "\n", "                ", "info", "=", "infos", "[", "i", "]", ".", "copy", "(", ")", "\n", "ret", "=", "self", ".", "eprets", "[", "i", "]", "\n", "eplen", "=", "self", ".", "eplens", "[", "i", "]", "\n", "epinfo", "=", "{", "'r'", ":", "ret", ",", "'l'", ":", "eplen", ",", "'t'", ":", "round", "(", "time", ".", "time", "(", ")", "-", "self", ".", "tstart", ",", "6", ")", "}", "\n", "for", "k", "in", "self", ".", "info_keywords", ":", "\n", "                    ", "epinfo", "[", "k", "]", "=", "info", "[", "k", "]", "\n", "", "info", "[", "'episode'", "]", "=", "epinfo", "\n", "if", "self", ".", "keep_buf", ":", "\n", "                    ", "self", ".", "epret_buf", ".", "append", "(", "ret", ")", "\n", "self", ".", "eplen_buf", ".", "append", "(", "eplen", ")", "\n", "", "self", ".", "epcount", "+=", "1", "\n", "self", ".", "eprets", "[", "i", "]", "=", "0", "\n", "self", ".", "eplens", "[", "i", "]", "=", "0", "\n", "if", "self", ".", "results_writer", ":", "\n", "                    ", "self", ".", "results_writer", ".", "write_row", "(", "epinfo", ")", "\n", "", "newinfos", "[", "i", "]", "=", "info", "\n", "", "", "return", "obs", ",", "rews", ",", "dones", ",", "newinfos", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.copy_obs_dict": [[11, 16], ["numpy.copy", "obs.items"], "function", ["None"], ["from", "baselines", ".", "common", "import", "tf_util", "as", "U", "\n", "\n", "\n", "def", "store_args", "(", "method", ")", ":", "\n", "    ", "\"\"\"Stores provided method args as instance attributes.\n    \"\"\"", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.dict_to_obs": [[18, 26], ["set", "obs_dict.keys"], "function", ["None"], ["defaults", "=", "{", "}", "\n", "if", "argspec", ".", "defaults", "is", "not", "None", ":", "\n", "        ", "defaults", "=", "dict", "(", "\n", "zip", "(", "argspec", ".", "args", "[", "-", "len", "(", "argspec", ".", "defaults", ")", ":", "]", ",", "argspec", ".", "defaults", ")", ")", "\n", "", "if", "argspec", ".", "kwonlydefaults", "is", "not", "None", ":", "\n", "        ", "defaults", ".", "update", "(", "argspec", ".", "kwonlydefaults", ")", "\n", "", "arg_names", "=", "argspec", ".", "args", "[", "1", ":", "]", "\n", "\n", "@", "functools", ".", "wraps", "(", "method", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.obs_space_info": [[28, 54], ["isinstance", "subspaces.items", "isinstance", "isinstance", "keys.append", "isinstance", "range", "len"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["        ", "self", "=", "positional_args", "[", "0", "]", "\n", "# Get default arg values", "\n", "args", "=", "defaults", ".", "copy", "(", ")", "\n", "# Add provided arg values", "\n", "for", "name", ",", "value", "in", "zip", "(", "arg_names", ",", "positional_args", "[", "1", ":", "]", ")", ":", "\n", "            ", "args", "[", "name", "]", "=", "value", "\n", "", "args", ".", "update", "(", "keyword_args", ")", "\n", "self", ".", "__dict__", ".", "update", "(", "args", ")", "\n", "return", "method", "(", "*", "positional_args", ",", "**", "keyword_args", ")", "\n", "\n", "", "return", "wrapper", "\n", "\n", "\n", "", "def", "import_function", "(", "spec", ")", ":", "\n", "    ", "\"\"\"Import a function identified by a string like \"pkg.module:fn_name\".\n    \"\"\"", "\n", "mod_name", ",", "fn_name", "=", "spec", ".", "split", "(", "':'", ")", "\n", "module", "=", "importlib", ".", "import_module", "(", "mod_name", ")", "\n", "fn", "=", "getattr", "(", "module", ",", "fn_name", ")", "\n", "return", "fn", "\n", "\n", "\n", "", "def", "flatten_grads", "(", "var_list", ",", "grads", ")", ":", "\n", "    ", "\"\"\"Flattens a variables and their gradients.\n    \"\"\"", "\n", "return", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "grad", ",", "[", "U", ".", "numel", "(", "v", ")", "]", ")", "\n", "for", "(", "v", ",", "grad", ")", "in", "zip", "(", "var_list", ",", "grads", ")", "]", ",", "0", ")", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.obs_to_dict": [[56, 63], ["isinstance"], "function", ["None"], ["\n", "", "def", "nn", "(", "input", ",", "layers_sizes", ",", "reuse", "=", "None", ",", "flatten", "=", "False", ",", "name", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Creates a simple neural network\n    \"\"\"", "\n", "for", "i", ",", "size", "in", "enumerate", "(", "layers_sizes", ")", ":", "\n", "        ", "activation", "=", "tf", ".", "nn", ".", "relu", "if", "i", "<", "len", "(", "layers_sizes", ")", "-", "1", "else", "None", "\n", "input", "=", "tf", ".", "layers", ".", "dense", "(", "inputs", "=", "input", ",", "\n", "units", "=", "size", ",", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.__init__": [[25, 60], ["multiprocessing.get_context", "vec_env.VecEnv.__init__", "util.obs_space_info", "baselines.logger.log", "len", "vec_env.clear_mpi_env_vars", "zip", "baselines.logger.scoped_configure", "dummy.close", "multiprocessing.get_context.Array", "vec_env.CloudpickleWrapper", "multiprocessing.get_context.Pipe", "multiprocessing.get_context.Process", "shmem_vec_env.ShmemVecEnv.procs.append", "shmem_vec_env.ShmemVecEnv.parent_pipes.append", "mp.get_context.Process.start", "child_pipe.close", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.obs_space_info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.log", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_env.clear_mpi_env_vars", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.scoped_configure", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["def", "__init__", "(", "self", ",", "env_fns", ",", "spaces", "=", "None", ",", "context", "=", "'spawn'", ")", ":", "\n", "        ", "\"\"\"\n        If you don't specify observation_space, we'll have to create a dummy\n        environment to get it.\n        \"\"\"", "\n", "ctx", "=", "mp", ".", "get_context", "(", "context", ")", "\n", "if", "spaces", ":", "\n", "            ", "observation_space", ",", "action_space", "=", "spaces", "\n", "", "else", ":", "\n", "            ", "logger", ".", "log", "(", "'Creating dummy env object to get spaces'", ")", "\n", "with", "logger", ".", "scoped_configure", "(", "format_strs", "=", "[", "]", ")", ":", "\n", "                ", "dummy", "=", "env_fns", "[", "0", "]", "(", ")", "\n", "observation_space", ",", "action_space", "=", "dummy", ".", "observation_space", ",", "dummy", ".", "action_space", "\n", "dummy", ".", "close", "(", ")", "\n", "del", "dummy", "\n", "", "", "VecEnv", ".", "__init__", "(", "self", ",", "len", "(", "env_fns", ")", ",", "observation_space", ",", "action_space", ")", "\n", "self", ".", "obs_keys", ",", "self", ".", "obs_shapes", ",", "self", ".", "obs_dtypes", "=", "obs_space_info", "(", "observation_space", ")", "\n", "self", ".", "obs_bufs", "=", "[", "\n", "{", "k", ":", "ctx", ".", "Array", "(", "_NP_TO_CT", "[", "self", ".", "obs_dtypes", "[", "k", "]", ".", "type", "]", ",", "int", "(", "np", ".", "prod", "(", "self", ".", "obs_shapes", "[", "k", "]", ")", ")", ")", "for", "k", "in", "self", ".", "obs_keys", "}", "\n", "for", "_", "in", "env_fns", "]", "\n", "self", ".", "parent_pipes", "=", "[", "]", "\n", "self", ".", "procs", "=", "[", "]", "\n", "with", "clear_mpi_env_vars", "(", ")", ":", "\n", "            ", "for", "env_fn", ",", "obs_buf", "in", "zip", "(", "env_fns", ",", "self", ".", "obs_bufs", ")", ":", "\n", "                ", "wrapped_fn", "=", "CloudpickleWrapper", "(", "env_fn", ")", "\n", "parent_pipe", ",", "child_pipe", "=", "ctx", ".", "Pipe", "(", ")", "\n", "proc", "=", "ctx", ".", "Process", "(", "target", "=", "_subproc_worker", ",", "\n", "args", "=", "(", "child_pipe", ",", "parent_pipe", ",", "wrapped_fn", ",", "obs_buf", ",", "self", ".", "obs_shapes", ",", "self", ".", "obs_dtypes", ",", "self", ".", "obs_keys", ")", ")", "\n", "proc", ".", "daemon", "=", "True", "\n", "self", ".", "procs", ".", "append", "(", "proc", ")", "\n", "self", ".", "parent_pipes", ".", "append", "(", "parent_pipe", ")", "\n", "proc", ".", "start", "(", ")", "\n", "child_pipe", ".", "close", "(", ")", "\n", "", "", "self", ".", "waiting_step", "=", "False", "\n", "self", ".", "viewer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.reset": [[61, 68], ["shmem_vec_env.ShmemVecEnv._decode_obses", "baselines.logger.warn", "shmem_vec_env.ShmemVecEnv.step_wait", "pipe.send", "pipe.recv"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv._decode_obses", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.baselines.logger.warn", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "waiting_step", ":", "\n", "            ", "logger", ".", "warn", "(", "'Called reset() while waiting for the step to complete'", ")", "\n", "self", ".", "step_wait", "(", ")", "\n", "", "for", "pipe", "in", "self", ".", "parent_pipes", ":", "\n", "            ", "pipe", ".", "send", "(", "(", "'reset'", ",", "None", ")", ")", "\n", "", "return", "self", ".", "_decode_obses", "(", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "parent_pipes", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_async": [[69, 74], ["zip", "len", "len", "pipe.send"], "methods", ["None"], ["", "def", "step_async", "(", "self", ",", "actions", ")", ":", "\n", "        ", "assert", "len", "(", "actions", ")", "==", "len", "(", "self", ".", "parent_pipes", ")", "\n", "for", "pipe", ",", "act", "in", "zip", "(", "self", ".", "parent_pipes", ",", "actions", ")", ":", "\n", "            ", "pipe", ".", "send", "(", "(", "'step'", ",", "act", ")", ")", "\n", "", "self", ".", "waiting_step", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait": [[75, 80], ["zip", "pipe.recv", "shmem_vec_env.ShmemVecEnv._decode_obses", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv._decode_obses"], ["", "def", "step_wait", "(", "self", ")", ":", "\n", "        ", "outs", "=", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "parent_pipes", "]", "\n", "self", ".", "waiting_step", "=", "False", "\n", "obs", ",", "rews", ",", "dones", ",", "infos", "=", "zip", "(", "*", "outs", ")", "\n", "return", "self", ".", "_decode_obses", "(", "obs", ")", ",", "np", ".", "array", "(", "rews", ")", ",", "np", ".", "array", "(", "dones", ")", ",", "infos", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.close_extras": [[81, 91], ["shmem_vec_env.ShmemVecEnv.step_wait", "pipe.send", "pipe.recv", "pipe.close", "proc.join"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.step_wait", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "def", "close_extras", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "waiting_step", ":", "\n", "            ", "self", ".", "step_wait", "(", ")", "\n", "", "for", "pipe", "in", "self", ".", "parent_pipes", ":", "\n", "            ", "pipe", ".", "send", "(", "(", "'close'", ",", "None", ")", ")", "\n", "", "for", "pipe", "in", "self", ".", "parent_pipes", ":", "\n", "            ", "pipe", ".", "recv", "(", ")", "\n", "pipe", ".", "close", "(", ")", "\n", "", "for", "proc", "in", "self", ".", "procs", ":", "\n", "            ", "proc", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv.get_images": [[92, 96], ["pipe.send", "pipe.recv"], "methods", ["None"], ["", "", "def", "get_images", "(", "self", ",", "mode", "=", "'human'", ")", ":", "\n", "        ", "for", "pipe", "in", "self", ".", "parent_pipes", ":", "\n", "            ", "pipe", ".", "send", "(", "(", "'render'", ",", "None", ")", ")", "\n", "", "return", "[", "pipe", ".", "recv", "(", ")", "for", "pipe", "in", "self", ".", "parent_pipes", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env.ShmemVecEnv._decode_obses": [[97, 105], ["util.dict_to_obs", "numpy.array", "numpy.frombuffer().reshape", "numpy.frombuffer", "b.get_obj"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.dict_to_obs"], ["", "def", "_decode_obses", "(", "self", ",", "obs", ")", ":", "\n", "        ", "result", "=", "{", "}", "\n", "for", "k", "in", "self", ".", "obs_keys", ":", "\n", "\n", "            ", "bufs", "=", "[", "b", "[", "k", "]", "for", "b", "in", "self", ".", "obs_bufs", "]", "\n", "o", "=", "[", "np", ".", "frombuffer", "(", "b", ".", "get_obj", "(", ")", ",", "dtype", "=", "self", ".", "obs_dtypes", "[", "k", "]", ")", ".", "reshape", "(", "self", ".", "obs_shapes", "[", "k", "]", ")", "for", "b", "in", "bufs", "]", "\n", "result", "[", "k", "]", "=", "np", ".", "array", "(", "o", ")", "\n", "", "return", "dict_to_obs", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.shmem_vec_env._subproc_worker": [[107, 142], ["env_fn_wrapper.x", "parent_pipe.close", "util.obs_to_dict", "env_fn_wrapper.x.close", "obs_bufs[].get_obj", "numpy.frombuffer().reshape", "numpy.copyto", "pipe.recv", "print", "pipe.send", "numpy.frombuffer", "shmem_vec_env._subproc_worker._write_obs"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.util.obs_to_dict", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close"], ["", "", "def", "_subproc_worker", "(", "pipe", ",", "parent_pipe", ",", "env_fn_wrapper", ",", "obs_bufs", ",", "obs_shapes", ",", "obs_dtypes", ",", "keys", ")", ":", "\n", "    ", "\"\"\"\n    Control a single environment instance using IPC and\n    shared memory.\n    \"\"\"", "\n", "def", "_write_obs", "(", "maybe_dict_obs", ")", ":", "\n", "        ", "flatdict", "=", "obs_to_dict", "(", "maybe_dict_obs", ")", "\n", "for", "k", "in", "keys", ":", "\n", "            ", "dst", "=", "obs_bufs", "[", "k", "]", ".", "get_obj", "(", ")", "\n", "dst_np", "=", "np", ".", "frombuffer", "(", "dst", ",", "dtype", "=", "obs_dtypes", "[", "k", "]", ")", ".", "reshape", "(", "obs_shapes", "[", "k", "]", ")", "# pylint: disable=W0212", "\n", "np", ".", "copyto", "(", "dst_np", ",", "flatdict", "[", "k", "]", ")", "\n", "\n", "", "", "env", "=", "env_fn_wrapper", ".", "x", "(", ")", "\n", "parent_pipe", ".", "close", "(", ")", "\n", "try", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "cmd", ",", "data", "=", "pipe", ".", "recv", "(", ")", "\n", "if", "cmd", "==", "'reset'", ":", "\n", "                ", "pipe", ".", "send", "(", "_write_obs", "(", "env", ".", "reset", "(", ")", ")", ")", "\n", "", "elif", "cmd", "==", "'step'", ":", "\n", "                ", "obs", ",", "reward", ",", "done", ",", "info", "=", "env", ".", "step", "(", "data", ")", "\n", "if", "done", ":", "\n", "                    ", "obs", "=", "env", ".", "reset", "(", ")", "\n", "", "pipe", ".", "send", "(", "(", "_write_obs", "(", "obs", ")", ",", "reward", ",", "done", ",", "info", ")", ")", "\n", "", "elif", "cmd", "==", "'render'", ":", "\n", "                ", "pipe", ".", "send", "(", "env", ".", "render", "(", "mode", "=", "'rgb_array'", ")", ")", "\n", "", "elif", "cmd", "==", "'close'", ":", "\n", "                ", "pipe", ".", "send", "(", "None", ")", "\n", "break", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Got unrecognized cmd %s'", "%", "cmd", ")", "\n", "", "", "", "except", "KeyboardInterrupt", ":", "\n", "        ", "print", "(", "'ShmemVecEnv worker: got KeyboardInterrupt'", ")", "\n", "", "finally", ":", "\n", "        ", "env", ".", "close", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.__init__": [[50, 60], ["print", "car_dynamics.Car.make_hull", "car_dynamics.Car.make_wheels"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make_hull", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make_wheels"], ["    ", "def", "__init__", "(", "self", ",", "world", ")", ":", "\n", "        ", "print", "(", "\"Car constructor\"", ")", "\n", "self", ".", "hull", "=", "None", "\n", "self", ".", "wheels", "=", "[", "]", "\n", "self", ".", "fuel_spent", "=", "0.0", "\n", "self", ".", "world", "=", "world", "\n", "self", ".", "hull", "=", "self", ".", "make_hull", "(", "self", ".", "world", ",", "color", "=", "(", "0.8", ",", "0.0", ",", "0.0", ")", ")", "\n", "self", ".", "wheels", "=", "self", ".", "make_wheels", "(", "self", ".", "hull", ",", "self", ".", "world", ")", "\n", "self", ".", "drawlist", "=", "self", ".", "wheels", "+", "[", "self", ".", "hull", "]", "\n", "self", ".", "particles", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make_hull": [[61, 73], ["world.CreateDynamicBody", "Box2D.b2.fixtureDef", "Box2D.b2.fixtureDef", "Box2D.b2.fixtureDef", "Box2D.b2.fixtureDef", "Box2D.b2.polygonShape", "Box2D.b2.polygonShape", "Box2D.b2.polygonShape", "Box2D.b2.polygonShape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "make_hull", "(", "world", ",", "color", ")", ":", "\n", "        ", "hull", "=", "world", ".", "CreateDynamicBody", "(", "\n", "fixtures", "=", "[", "\n", "fixtureDef", "(", "shape", "=", "polygonShape", "(", "vertices", "=", "[", "(", "x", "*", "SIZE", ",", "y", "*", "SIZE", ")", "for", "x", ",", "y", "in", "HULL_POLY1", "]", ")", ",", "density", "=", "1.0", ")", ",", "\n", "fixtureDef", "(", "shape", "=", "polygonShape", "(", "vertices", "=", "[", "(", "x", "*", "SIZE", ",", "y", "*", "SIZE", ")", "for", "x", ",", "y", "in", "HULL_POLY2", "]", ")", ",", "density", "=", "1.0", ")", ",", "\n", "fixtureDef", "(", "shape", "=", "polygonShape", "(", "vertices", "=", "[", "(", "x", "*", "SIZE", ",", "y", "*", "SIZE", ")", "for", "x", ",", "y", "in", "HULL_POLY3", "]", ")", ",", "density", "=", "1.0", ")", ",", "\n", "fixtureDef", "(", "shape", "=", "polygonShape", "(", "vertices", "=", "[", "(", "x", "*", "SIZE", ",", "y", "*", "SIZE", ")", "for", "x", ",", "y", "in", "HULL_POLY4", "]", ")", ",", "density", "=", "1.0", ")", "\n", "]", "\n", ")", "\n", "hull", ".", "color", "=", "color", "\n", "return", "hull", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make_wheels": [[74, 117], ["world.CreateDynamicBody", "Box2D.b2.revoluteJointDef", "world.CreateJoint", "set", "wheels.append", "Box2D.b2.fixtureDef", "Box2D.b2.polygonShape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "@", "staticmethod", "\n", "def", "make_wheels", "(", "hull", ",", "world", ")", ":", "\n", "        ", "wheels", "=", "[", "]", "\n", "WHEEL_POLY", "=", "[", "\n", "(", "-", "WHEEL_W", ",", "+", "WHEEL_R", ")", ",", "(", "+", "WHEEL_W", ",", "+", "WHEEL_R", ")", ",", "\n", "(", "+", "WHEEL_W", ",", "-", "WHEEL_R", ")", ",", "(", "-", "WHEEL_W", ",", "-", "WHEEL_R", ")", "\n", "]", "\n", "for", "wx", ",", "wy", "in", "WHEELPOS", ":", "\n", "            ", "front_k", "=", "1.0", "if", "wy", ">", "0", "else", "1.0", "\n", "w", "=", "world", ".", "CreateDynamicBody", "(", "\n", "fixtures", "=", "fixtureDef", "(", "\n", "shape", "=", "polygonShape", "(", "vertices", "=", "[", "(", "x", "*", "front_k", "*", "SIZE", ",", "y", "*", "front_k", "*", "SIZE", ")", "for", "x", ",", "y", "in", "WHEEL_POLY", "]", ")", ",", "\n", "density", "=", "0.1", ",", "\n", "categoryBits", "=", "0x0020", ",", "\n", "maskBits", "=", "0x001", ",", "\n", "restitution", "=", "0.0", ")", "\n", ")", "\n", "w", ".", "wheel_rad", "=", "front_k", "*", "WHEEL_R", "*", "SIZE", "\n", "w", ".", "color", "=", "WHEEL_COLOR", "\n", "w", ".", "gas", "=", "0.0", "\n", "w", ".", "brake", "=", "0.0", "\n", "w", ".", "steer", "=", "0.0", "\n", "w", ".", "phase", "=", "0.0", "# wheel angle", "\n", "w", ".", "omega", "=", "0.0", "# angular velocity", "\n", "w", ".", "skid_start", "=", "None", "\n", "w", ".", "skid_particle", "=", "None", "\n", "rjd", "=", "revoluteJointDef", "(", "\n", "bodyA", "=", "hull", ",", "\n", "bodyB", "=", "w", ",", "\n", "localAnchorA", "=", "(", "wx", "*", "SIZE", ",", "wy", "*", "SIZE", ")", ",", "\n", "localAnchorB", "=", "(", "0", ",", "0", ")", ",", "\n", "enableMotor", "=", "True", ",", "\n", "enableLimit", "=", "True", ",", "\n", "maxMotorTorque", "=", "180", "*", "900", "*", "SIZE", "*", "SIZE", ",", "\n", "motorSpeed", "=", "0", ",", "\n", "lowerAngle", "=", "-", "0.4", ",", "\n", "upperAngle", "=", "+", "0.4", ",", "\n", ")", "\n", "w", ".", "joint", "=", "world", ".", "CreateJoint", "(", "rjd", ")", "\n", "w", ".", "tiles", "=", "set", "(", ")", "\n", "w", ".", "userData", "=", "w", "\n", "wheels", ".", "append", "(", "w", ")", "\n", "", "return", "wheels", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.make": [[118, 124], ["zip"], "methods", ["None"], ["", "def", "make", "(", "self", ",", "init_angle", ",", "init_x", ",", "init_y", ")", ":", "\n", "        ", "self", ".", "hull", ".", "position", "=", "(", "init_x", ",", "init_y", ")", "\n", "self", ".", "hull", ".", "angle", "=", "init_angle", "\n", "for", "w", ",", "w_pos", "in", "zip", "(", "self", ".", "wheels", ",", "WHEELPOS", ")", ":", "\n", "            ", "w", ".", "position", "=", "(", "init_x", "+", "w_pos", "[", "0", "]", "*", "SIZE", ",", "init_y", "+", "w_pos", "[", "1", "]", "*", "SIZE", ")", "\n", "w", ".", "angle", "=", "init_angle", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.apply_action": [[125, 129], ["car_dynamics.Car.steer", "car_dynamics.Car.gas", "car_dynamics.Car.brake"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.steer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.gas", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.brake"], ["", "", "def", "apply_action", "(", "self", ",", "u", ")", ":", "\n", "        ", "self", ".", "steer", "(", "-", "u", "[", "0", "]", ")", "\n", "self", ".", "gas", "(", "u", "[", "1", "]", ")", "\n", "self", ".", "brake", "(", "u", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.gas": [[130, 137], ["numpy.clip"], "methods", ["None"], ["", "def", "gas", "(", "self", ",", "gas", ")", ":", "\n", "        ", "'control: rear wheel drive'", "\n", "gas", "=", "np", ".", "clip", "(", "gas", ",", "0", ",", "1", ")", "\n", "for", "w", "in", "self", ".", "wheels", "[", "2", ":", "4", "]", ":", "\n", "            ", "diff", "=", "gas", "-", "w", ".", "gas", "\n", "if", "diff", ">", "0.1", ":", "diff", "=", "0.1", "# gradually increase, but stop immediately", "\n", "w", ".", "gas", "+=", "diff", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.brake": [[138, 142], ["None"], "methods", ["None"], ["", "", "def", "brake", "(", "self", ",", "b", ")", ":", "\n", "        ", "'control: brake b=0..1, more than 0.9 blocks wheels to zero rotation'", "\n", "for", "w", "in", "self", ".", "wheels", ":", "\n", "            ", "w", ".", "brake", "=", "b", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.steer": [[143, 147], ["None"], "methods", ["None"], ["", "", "def", "steer", "(", "self", ",", "s", ")", ":", "\n", "        ", "'control: steer s=-1..1, it takes time to rotate steering wheel from side to side, s is target position'", "\n", "self", ".", "wheels", "[", "0", "]", ".", "steer", "=", "s", "\n", "self", ".", "wheels", "[", "1", "]", ".", "steer", "=", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.step": [[148, 220], ["numpy.sign", "abs", "w.GetWorldVector", "w.GetWorldVector", "numpy.sqrt", "w.ApplyForceToCenter", "min", "max", "abs", "abs", "abs", "numpy.square", "numpy.square", "w.skid_particle.poly.append", "numpy.sign", "abs", "abs", "abs", "len", "car_dynamics.Car._create_particle"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car._create_particle"], ["", "def", "step", "(", "self", ",", "dt", ")", ":", "\n", "        ", "for", "w", "in", "self", ".", "wheels", ":", "\n", "# Steer each wheel", "\n", "            ", "dir", "=", "np", ".", "sign", "(", "w", ".", "steer", "-", "w", ".", "joint", ".", "angle", ")", "\n", "val", "=", "abs", "(", "w", ".", "steer", "-", "w", ".", "joint", ".", "angle", ")", "\n", "w", ".", "joint", ".", "motorSpeed", "=", "dir", "*", "min", "(", "50.0", "*", "val", ",", "3.0", ")", "\n", "\n", "# Position => friction_limit", "\n", "grass", "=", "True", "\n", "friction_limit", "=", "FRICTION_LIMIT", "*", "0.6", "# Grass friction if no tile", "\n", "for", "tile", "in", "w", ".", "tiles", ":", "\n", "                ", "friction_limit", "=", "max", "(", "friction_limit", ",", "FRICTION_LIMIT", "*", "tile", ".", "road_friction", ")", "\n", "grass", "=", "False", "\n", "\n", "# Force", "\n", "", "forw", "=", "w", ".", "GetWorldVector", "(", "(", "0", ",", "1", ")", ")", "\n", "side", "=", "w", ".", "GetWorldVector", "(", "(", "1", ",", "0", ")", ")", "\n", "v", "=", "w", ".", "linearVelocity", "\n", "vf", "=", "forw", "[", "0", "]", "*", "v", "[", "0", "]", "+", "forw", "[", "1", "]", "*", "v", "[", "1", "]", "# forward speed", "\n", "vs", "=", "side", "[", "0", "]", "*", "v", "[", "0", "]", "+", "side", "[", "1", "]", "*", "v", "[", "1", "]", "# side speed", "\n", "\n", "# WHEEL_MOMENT_OF_INERTIA*np.square(w.omega)/2 = E -- energy", "\n", "# WHEEL_MOMENT_OF_INERTIA*w.omega * domega/dt = dE/dt = W -- power", "\n", "# domega = dt*W/WHEEL_MOMENT_OF_INERTIA/w.omega", "\n", "w", ".", "omega", "+=", "dt", "*", "ENGINE_POWER", "*", "w", ".", "gas", "/", "WHEEL_MOMENT_OF_INERTIA", "/", "(", "abs", "(", "w", ".", "omega", ")", "+", "5.0", ")", "# small coef not to divide by zero", "\n", "self", ".", "fuel_spent", "+=", "dt", "*", "ENGINE_POWER", "*", "w", ".", "gas", "\n", "\n", "if", "w", ".", "brake", ">=", "0.9", ":", "\n", "                ", "w", ".", "omega", "=", "0", "\n", "", "elif", "w", ".", "brake", ">", "0", ":", "\n", "                ", "BRAKE_FORCE", "=", "15", "# radians per second", "\n", "dir", "=", "-", "np", ".", "sign", "(", "w", ".", "omega", ")", "\n", "val", "=", "BRAKE_FORCE", "*", "w", ".", "brake", "\n", "if", "abs", "(", "val", ")", ">", "abs", "(", "w", ".", "omega", ")", ":", "val", "=", "abs", "(", "w", ".", "omega", ")", "# low speed => same as = 0", "\n", "w", ".", "omega", "+=", "dir", "*", "val", "\n", "", "w", ".", "phase", "+=", "w", ".", "omega", "*", "dt", "\n", "\n", "vr", "=", "w", ".", "omega", "*", "w", ".", "wheel_rad", "# rotating wheel speed", "\n", "f_force", "=", "-", "vf", "+", "vr", "# force direction is direction of speed difference", "\n", "p_force", "=", "-", "vs", "\n", "\n", "# Physically correct is to always apply friction_limit until speed is equal.", "\n", "# But dt is finite, that will lead to oscillations if difference is already near zero.", "\n", "f_force", "*=", "205000", "*", "SIZE", "*", "SIZE", "# Random coefficient to cut oscillations in few steps (have no effect on friction_limit)", "\n", "p_force", "*=", "205000", "*", "SIZE", "*", "SIZE", "\n", "force", "=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "f_force", ")", "+", "np", ".", "square", "(", "p_force", ")", ")", "\n", "\n", "# Skid trace", "\n", "if", "abs", "(", "force", ")", ">", "2.0", "*", "friction_limit", ":", "\n", "                ", "if", "w", ".", "skid_particle", "and", "w", ".", "skid_particle", ".", "grass", "==", "grass", "and", "len", "(", "w", ".", "skid_particle", ".", "poly", ")", "<", "30", ":", "\n", "                    ", "w", ".", "skid_particle", ".", "poly", ".", "append", "(", "(", "w", ".", "position", "[", "0", "]", ",", "w", ".", "position", "[", "1", "]", ")", ")", "\n", "", "elif", "w", ".", "skid_start", "is", "None", ":", "\n", "                    ", "w", ".", "skid_start", "=", "w", ".", "position", "\n", "", "else", ":", "\n", "                    ", "w", ".", "skid_particle", "=", "self", ".", "_create_particle", "(", "w", ".", "skid_start", ",", "w", ".", "position", ",", "grass", ")", "\n", "w", ".", "skid_start", "=", "None", "\n", "", "", "else", ":", "\n", "                ", "w", ".", "skid_start", "=", "None", "\n", "w", ".", "skid_particle", "=", "None", "\n", "\n", "", "if", "abs", "(", "force", ")", ">", "friction_limit", ":", "\n", "                ", "f_force", "/=", "force", "\n", "p_force", "/=", "force", "\n", "force", "=", "friction_limit", "# Correct physics here", "\n", "f_force", "*=", "force", "\n", "p_force", "*=", "force", "\n", "\n", "", "w", ".", "omega", "-=", "dt", "*", "f_force", "*", "w", ".", "wheel_rad", "/", "WHEEL_MOMENT_OF_INERTIA", "\n", "\n", "w", ".", "ApplyForceToCenter", "(", "(", "\n", "p_force", "*", "side", "[", "0", "]", "+", "f_force", "*", "forw", "[", "0", "]", ",", "\n", "p_force", "*", "side", "[", "1", "]", "+", "f_force", "*", "forw", "[", "1", "]", ")", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.draw": [[221, 245], ["viewer.draw_polyline", "viewer.draw_polygon", "math.sin", "math.sin", "math.cos", "math.cos", "viewer.draw_polygon", "numpy.sign", "numpy.sign"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.draw_polyline", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.draw_polygon", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.draw_polygon"], ["", "", "def", "draw", "(", "self", ",", "viewer", ",", "draw_particles", "=", "True", ")", ":", "\n", "        ", "if", "draw_particles", ":", "\n", "            ", "for", "p", "in", "self", ".", "particles", ":", "\n", "                ", "viewer", ".", "draw_polyline", "(", "p", ".", "poly", ",", "color", "=", "p", ".", "color", ",", "linewidth", "=", "5", ")", "\n", "", "", "for", "obj", "in", "self", ".", "drawlist", ":", "\n", "            ", "for", "f", "in", "obj", ".", "fixtures", ":", "\n", "                ", "trans", "=", "f", ".", "body", ".", "transform", "\n", "path", "=", "[", "trans", "*", "v", "for", "v", "in", "f", ".", "shape", ".", "vertices", "]", "\n", "viewer", ".", "draw_polygon", "(", "path", ",", "color", "=", "obj", ".", "color", ")", "\n", "if", "\"phase\"", "not", "in", "obj", ".", "__dict__", ":", "continue", "\n", "a1", "=", "obj", ".", "phase", "\n", "a2", "=", "obj", ".", "phase", "+", "1.2", "# radians", "\n", "s1", "=", "math", ".", "sin", "(", "a1", ")", "\n", "s2", "=", "math", ".", "sin", "(", "a2", ")", "\n", "c1", "=", "math", ".", "cos", "(", "a1", ")", "\n", "c2", "=", "math", ".", "cos", "(", "a2", ")", "\n", "if", "s1", ">", "0", "and", "s2", ">", "0", ":", "continue", "\n", "if", "s1", ">", "0", ":", "c1", "=", "np", ".", "sign", "(", "c1", ")", "\n", "if", "s2", ">", "0", ":", "c2", "=", "np", ".", "sign", "(", "c2", ")", "\n", "white_poly", "=", "[", "\n", "(", "-", "WHEEL_W", "*", "SIZE", ",", "+", "WHEEL_R", "*", "c1", "*", "SIZE", ")", ",", "(", "+", "WHEEL_W", "*", "SIZE", ",", "+", "WHEEL_R", "*", "c1", "*", "SIZE", ")", ",", "\n", "(", "+", "WHEEL_W", "*", "SIZE", ",", "+", "WHEEL_R", "*", "c2", "*", "SIZE", ")", ",", "(", "-", "WHEEL_W", "*", "SIZE", ",", "+", "WHEEL_R", "*", "c2", "*", "SIZE", ")", "\n", "]", "\n", "viewer", ".", "draw_polygon", "(", "[", "trans", "*", "v", "for", "v", "in", "white_poly", "]", ",", "color", "=", "WHEEL_WHITE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car._create_particle": [[246, 258], ["Particle", "car_dynamics.Car.particles.append", "len", "car_dynamics.Car.particles.pop"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "", "def", "_create_particle", "(", "self", ",", "point1", ",", "point2", ",", "grass", ")", ":", "\n", "        ", "class", "Particle", ":", "\n", "            ", "pass", "\n", "", "p", "=", "Particle", "(", ")", "\n", "p", ".", "color", "=", "WHEEL_COLOR", "if", "not", "grass", "else", "MUD_COLOR", "\n", "p", ".", "ttl", "=", "1", "\n", "p", ".", "poly", "=", "[", "(", "point1", "[", "0", "]", ",", "point1", "[", "1", "]", ")", ",", "(", "point2", "[", "0", "]", ",", "point2", "[", "1", "]", ")", "]", "\n", "p", ".", "grass", "=", "grass", "\n", "self", ".", "particles", ".", "append", "(", "p", ")", "\n", "while", "len", "(", "self", ".", "particles", ")", ">", "30", ":", "\n", "            ", "self", ".", "particles", ".", "pop", "(", "0", ")", "\n", "", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.car_dynamics.Car.destroy": [[259, 265], ["car_dynamics.Car.world.DestroyBody", "car_dynamics.Car.world.DestroyBody"], "methods", ["None"], ["", "def", "destroy", "(", "self", ")", ":", "\n", "        ", "self", ".", "world", ".", "DestroyBody", "(", "self", ".", "hull", ")", "\n", "self", ".", "hull", "=", "None", "\n", "for", "w", "in", "self", ".", "wheels", ":", "\n", "            ", "self", ".", "world", ".", "DestroyBody", "(", "w", ")", "\n", "", "self", ".", "wheels", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator.__init__": [[38, 40], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._destroy": [[41, 46], ["road_creator.RoadCreator.world.DestroyBody"], "methods", ["None"], ["", "def", "_destroy", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "road", ":", "return", "\n", "for", "t", "in", "self", ".", "road", ":", "\n", "            ", "self", ".", "world", ".", "DestroyBody", "(", "t", ")", "\n", "", "self", ".", "road", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._to_relative": [[47, 49], ["None"], "methods", ["None"], ["", "def", "_to_relative", "(", "self", ",", "id", ")", ":", "\n", "        ", "return", "id", "-", "(", "self", ".", "info", "[", "'track'", "]", "<", "self", ".", "info", "[", "id", "]", "[", "'track'", "]", ")", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._get_track": [[50, 153], ["range", "len", "math.cos", "math.sin", "numpy.sqrt", "numpy.random.uniform", "checkpoints.append", "math.atan2", "math.cos", "math.sin", "track.append", "print", "numpy.random.uniform", "min", "min", "numpy.square", "numpy.square", "range", "abs", "abs", "len", "math.cos", "math.sin", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min"], ["", "def", "_get_track", "(", "self", ",", "num_checkpoints", ",", "track_rad", "=", "900", "/", "SCALE", ",", "x_bias", "=", "0", ",", "y_bias", "=", "0", ")", ":", "\n", "\n", "# num_checkpoints = 12", "\n", "\n", "# Create checkpoints", "\n", "        ", "checkpoints", "=", "[", "]", "\n", "for", "c", "in", "range", "(", "num_checkpoints", ")", ":", "\n", "            ", "alpha", "=", "2", "*", "math", ".", "pi", "*", "c", "/", "num_checkpoints", "+", "np", ".", "random", ".", "uniform", "(", "0", ",", "2", "*", "math", ".", "pi", "*", "1", "/", "num_checkpoints", ")", "\n", "rad", "=", "np", ".", "random", ".", "uniform", "(", "track_rad", "/", "3", ",", "track_rad", ")", "\n", "if", "c", "==", "0", ":", "\n", "                ", "alpha", "=", "0", "\n", "rad", "=", "1.5", "*", "track_rad", "\n", "", "if", "c", "==", "num_checkpoints", "-", "1", ":", "\n", "                ", "alpha", "=", "2", "*", "math", ".", "pi", "*", "c", "/", "num_checkpoints", "\n", "self", ".", "start_alpha", "=", "2", "*", "math", ".", "pi", "*", "(", "-", "0.5", ")", "/", "num_checkpoints", "\n", "rad", "=", "1.5", "*", "track_rad", "\n", "", "checkpoints", ".", "append", "(", "(", "alpha", ",", "rad", "*", "math", ".", "cos", "(", "alpha", ")", ",", "rad", "*", "math", ".", "sin", "(", "alpha", ")", ")", ")", "\n", "\n", "# print \"\\n\".join(str(h) for h in checkpoints)", "\n", "# self.road_poly = [ (    # uncomment this to see checkpoints", "\n", "#    [ (tx,ty) for a,tx,ty in checkpoints ],", "\n", "#    (0.7,0.7,0.9) ) ]", "\n", "\n", "# Go from one checkpoint to another to create track", "\n", "", "x", ",", "y", ",", "beta", "=", "1.5", "*", "track_rad", ",", "0", ",", "0", "\n", "dest_i", "=", "0", "\n", "laps", "=", "0", "\n", "track", "=", "[", "]", "\n", "no_freeze", "=", "2500", "\n", "visited_other_side", "=", "False", "\n", "while", "1", ":", "\n", "            ", "alpha", "=", "math", ".", "atan2", "(", "y", ",", "x", ")", "\n", "if", "visited_other_side", "and", "alpha", ">", "0", ":", "\n", "                ", "laps", "+=", "1", "\n", "visited_other_side", "=", "False", "\n", "", "if", "alpha", "<", "0", ":", "\n", "                ", "visited_other_side", "=", "True", "\n", "alpha", "+=", "2", "*", "math", ".", "pi", "\n", "", "while", "True", ":", "# Find destination from checkpoints", "\n", "                ", "failed", "=", "True", "\n", "while", "True", ":", "\n", "                    ", "dest_alpha", ",", "dest_x", ",", "dest_y", "=", "checkpoints", "[", "dest_i", "%", "len", "(", "checkpoints", ")", "]", "\n", "if", "alpha", "<=", "dest_alpha", ":", "\n", "                        ", "failed", "=", "False", "\n", "break", "\n", "", "dest_i", "+=", "1", "\n", "if", "dest_i", "%", "len", "(", "checkpoints", ")", "==", "0", ":", "break", "\n", "", "if", "not", "failed", ":", "break", "\n", "alpha", "-=", "2", "*", "math", ".", "pi", "\n", "continue", "\n", "", "r1x", "=", "math", ".", "cos", "(", "beta", ")", "\n", "r1y", "=", "math", ".", "sin", "(", "beta", ")", "\n", "p1x", "=", "-", "r1y", "\n", "p1y", "=", "r1x", "\n", "dest_dx", "=", "dest_x", "-", "x", "# vector towards destination", "\n", "dest_dy", "=", "dest_y", "-", "y", "\n", "proj", "=", "r1x", "*", "dest_dx", "+", "r1y", "*", "dest_dy", "# destination vector projected on rad", "\n", "while", "beta", "-", "alpha", ">", "1.5", "*", "math", ".", "pi", ":", "beta", "-=", "2", "*", "math", ".", "pi", "\n", "while", "beta", "-", "alpha", "<", "-", "1.5", "*", "math", ".", "pi", ":", "beta", "+=", "2", "*", "math", ".", "pi", "\n", "prev_beta", "=", "beta", "\n", "proj", "*=", "SCALE", "\n", "if", "proj", ">", "0.3", ":", "beta", "-=", "min", "(", "TRACK_TURN_RATE", ",", "abs", "(", "0.001", "*", "proj", ")", ")", "\n", "if", "proj", "<", "-", "0.3", ":", "beta", "+=", "min", "(", "TRACK_TURN_RATE", ",", "abs", "(", "0.001", "*", "proj", ")", ")", "\n", "x", "+=", "p1x", "*", "TRACK_DETAIL_STEP", "\n", "y", "+=", "p1y", "*", "TRACK_DETAIL_STEP", "\n", "track", ".", "append", "(", "(", "alpha", ",", "prev_beta", "*", "0.5", "+", "beta", "*", "0.5", ",", "x", ",", "y", ")", ")", "\n", "if", "laps", ">", "4", ":", "break", "\n", "no_freeze", "-=", "1", "\n", "if", "no_freeze", "==", "0", ":", "break", "\n", "# print \"\\n\".join([str(t) for t in enumerate(track)])", "\n", "\n", "# Find closed loop range i1..i2, first loop should be ignored, second is OK", "\n", "", "i1", ",", "i2", "=", "-", "1", ",", "-", "1", "\n", "i", "=", "len", "(", "track", ")", "\n", "while", "True", ":", "\n", "            ", "i", "-=", "1", "\n", "if", "i", "==", "0", ":", "return", "False", "# Failed", "\n", "pass_through_start", "=", "track", "[", "i", "]", "[", "0", "]", ">", "self", ".", "start_alpha", "and", "track", "[", "i", "-", "1", "]", "[", "0", "]", "<=", "self", ".", "start_alpha", "\n", "if", "pass_through_start", "and", "i2", "==", "-", "1", ":", "\n", "                ", "i2", "=", "i", "\n", "", "elif", "pass_through_start", "and", "i1", "==", "-", "1", ":", "\n", "                ", "i1", "=", "i", "\n", "break", "\n", "", "", "if", "self", ".", "verbose", ">", "0", ":", "\n", "            ", "print", "(", "\"Track generation: %i..%i -> %i-tiles track\"", "%", "(", "i1", ",", "i2", ",", "i2", "-", "i1", ")", ")", "\n", "", "assert", "i1", "!=", "-", "1", "\n", "assert", "i2", "!=", "-", "1", "\n", "\n", "track", "=", "track", "[", "i1", ":", "i2", "-", "1", "]", "\n", "\n", "first_beta", "=", "track", "[", "0", "]", "[", "1", "]", "\n", "first_perp_x", "=", "math", ".", "cos", "(", "first_beta", ")", "\n", "first_perp_y", "=", "math", ".", "sin", "(", "first_beta", ")", "\n", "# Length of perpendicular jump to put together head and tail", "\n", "well_glued_together", "=", "np", ".", "sqrt", "(", "\n", "np", ".", "square", "(", "first_perp_x", "*", "(", "track", "[", "0", "]", "[", "2", "]", "-", "track", "[", "-", "1", "]", "[", "2", "]", ")", ")", "+", "\n", "np", ".", "square", "(", "first_perp_y", "*", "(", "track", "[", "0", "]", "[", "3", "]", "-", "track", "[", "-", "1", "]", "[", "3", "]", ")", ")", ")", "\n", "if", "well_glued_together", ">", "TRACK_DETAIL_STEP", ":", "\n", "            ", "return", "False", "\n", "\n", "", "track", "=", "[", "[", "a", ",", "b", ",", "x", "+", "x_bias", "*", "2", ",", "y", "+", "y_bias", "*", "2", "]", "for", "a", ",", "b", ",", "x", ",", "y", "in", "track", "]", "\n", "track", "=", "[", "[", "track", "[", "i", "-", "1", "]", ",", "track", "[", "i", "]", "]", "for", "i", "in", "range", "(", "len", "(", "track", ")", ")", "]", "\n", "return", "track", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._get_possible_candidates_for_obstacles": [[154, 156], ["list", "range", "len"], "methods", ["None"], ["", "def", "_get_possible_candidates_for_obstacles", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "range", "(", "len", "(", "self", ".", "track", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._create_info": [[157, 344], ["numpy.zeros", "range", "range", "set", "numpy.mod", "numpy.mod", "range", "road_creator.RoadCreator.intersection_dict.items", "sum", "len", "len", "range", "enumerate", "list", "list.sort", "len", "numpy.logical_or", "len", "numpy.where", "numpy.where", "numpy.linalg.norm", "len", "numpy.linalg.norm", "len", "groups.append", "numpy.linalg.norm", "d[].argmin", "numpy.where", "numpy.abs().max", "numpy.abs().argmax", "numpy.linalg.norm.min", "intersection_dict[].append", "len", "len", "numpy.array_equal", "numpy.linalg.norm.min", "list.add", "len", "len", "road_creator.RoadCreator._create_info.backwards"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add"], ["", "def", "_create_info", "(", "self", ")", ":", "\n", "        ", "'''\n        Creates the matrix with the information about the track points,\n        whether they are at the end of the track, if they are intersections\n        '''", "\n", "# Get if point is at the end", "\n", "info", "=", "np", ".", "zeros", "(", "(", "sum", "(", "len", "(", "t", ")", "for", "t", "in", "self", ".", "tracks", ")", ")", ",", "dtype", "=", "[", "\n", "(", "'track'", ",", "'int'", ")", ",", "\n", "(", "'end'", ",", "'bool'", ")", ",", "\n", "(", "'begining'", ",", "'bool'", ")", ",", "\n", "(", "'intersection'", ",", "'bool'", ")", ",", "\n", "(", "'intersection_id'", ",", "'int'", ")", ",", "\n", "(", "'t'", ",", "'bool'", ")", ",", "\n", "(", "'x'", ",", "'bool'", ")", ",", "\n", "(", "'start'", ",", "'bool'", ")", ",", "\n", "(", "'used'", ",", "'bool'", ")", ",", "\n", "(", "'angle'", ",", "'float16'", ")", ",", "\n", "(", "'ang_class'", ",", "'float16'", ")", ",", "\n", "(", "'lanes'", ",", "np", ".", "ndarray", ")", ",", "\n", "(", "'count_left'", ",", "'int'", ")", ",", "\n", "(", "'count_right'", ",", "'int'", ")", ",", "\n", "(", "'count_left_delay'", ",", "'int'", ")", ",", "\n", "(", "'count_right_delay'", ",", "'int'", ")", ",", "\n", "(", "'visited'", ",", "bool", ")", ",", "\n", "# ('obstacles',np.ndarray)])", "\n", "(", "'obstacles'", ",", "bool", ")", "]", ")", "\n", "\n", "info", "[", "'ang_class'", "]", "=", "np", ".", "nan", "\n", "info", "[", "'intersection_id'", "]", "=", "-", "1", "\n", "info", "[", "'obstacles'", "]", "=", "False", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "info", ")", ")", ":", "\n", "            ", "info", "[", "i", "]", "[", "'lanes'", "]", "=", "[", "True", ",", "True", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "1", ",", "len", "(", "self", ".", "tracks", ")", ")", ":", "\n", "            ", "track", "=", "self", ".", "tracks", "[", "i", "]", "\n", "info", "[", "len", "(", "self", ".", "tracks", "[", "i", "-", "1", "]", ")", ":", "len", "(", "self", ".", "tracks", "[", "i", "-", "1", "]", ")", "+", "len", "(", "track", ")", "]", "[", "\n", "'track'", "]", "=", "i", "# This wont work for num_tracks > 2", "\n", "for", "j", "in", "range", "(", "len", "(", "track", ")", ")", ":", "\n", "                ", "pos", "=", "j", "+", "len", "(", "self", ".", "tracks", "[", "i", "-", "1", "]", ")", "\n", "p", "=", "track", "[", "j", "]", "\n", "next_p", "=", "track", "[", "(", "j", "+", "1", ")", "%", "len", "(", "track", ")", "]", "\n", "last_p", "=", "track", "[", "j", "-", "1", "]", "\n", "if", "np", ".", "array_equal", "(", "p", "[", "1", "]", ",", "next_p", "[", "0", "]", ")", "==", "False", ":", "\n", "# it is at the end", "\n", "                    ", "info", "[", "pos", "]", "[", "'end'", "]", "=", "True", "\n", "", "elif", "np", ".", "array_equal", "(", "p", "[", "0", "]", ",", "last_p", "[", "1", "]", ")", "==", "False", ":", "\n", "# it is at the start", "\n", "                    ", "info", "[", "pos", "]", "[", "'start'", "]", "=", "True", "\n", "\n", "# Trying to get all intersections", "\n", "", "", "", "intersections", "=", "set", "(", ")", "\n", "if", "self", ".", "num_tracks", ">", "1", ":", "\n", "            ", "for", "pos", ",", "point1", "in", "enumerate", "(", "self", ".", "tracks", "[", "0", "]", "[", ":", ",", "1", ",", "2", ":", "]", ")", ":", "\n", "                ", "d", "=", "np", ".", "linalg", ".", "norm", "(", "self", ".", "track", "[", "len", "(", "self", ".", "tracks", "[", "0", "]", ")", ":", ",", "1", ",", "2", ":", "]", "-", "point1", ",", "axis", "=", "1", ")", "\n", "if", "d", ".", "min", "(", ")", "<=", "2.05", "*", "TRACK_WIDTH", ":", "\n", "                    ", "intersections", ".", "add", "(", "pos", ")", "\n", "\n", "", "", "intersections", "=", "list", "(", "intersections", ")", "\n", "intersections", ".", "sort", "(", ")", "\n", "track_len", "=", "len", "(", "self", ".", "tracks", "[", "0", "]", ")", "\n", "\n", "def", "backwards", "(", ")", ":", "\n", "                ", "me", "=", "intersections", "[", "-", "1", "]", "\n", "del", "intersections", "[", "-", "1", "]", "\n", "if", "len", "(", "intersections", ")", "==", "0", ":", "\n", "                    ", "return", "[", "me", "]", "\n", "", "else", ":", "\n", "                    ", "if", "(", "me", "-", "1", ")", "%", "track_len", "==", "intersections", "[", "-", "1", "]", ":", "\n", "                        ", "return", "[", "me", "]", "+", "backwards", "(", ")", "\n", "", "else", ":", "\n", "                        ", "return", "[", "me", "]", "\n", "\n", "", "", "", "def", "forward", "(", ")", ":", "\n", "                ", "me", "=", "intersections", "[", "0", "]", "\n", "del", "intersections", "[", "0", "]", "\n", "if", "len", "(", "intersections", ")", "==", "0", ":", "\n", "                    ", "return", "[", "me", "]", "\n", "", "else", ":", "\n", "                    ", "if", "(", "me", "+", "1", ")", "%", "track_len", "==", "intersections", "[", "0", "]", ":", "\n", "                        ", "return", "[", "me", "]", "+", "forward", "(", ")", "\n", "", "else", ":", "\n", "                        ", "return", "[", "me", "]", "\n", "\n", "", "", "", "groups", "=", "[", "]", "\n", "tmp_lst", "=", "[", "]", "\n", "while", "len", "(", "intersections", ")", "!=", "0", ":", "\n", "                ", "me", "=", "intersections", "[", "0", "]", "\n", "tmp_lst", "=", "tmp_lst", "+", "backwards", "(", ")", "\n", "if", "len", "(", "intersections", ")", "!=", "0", ":", "\n", "                    ", "if", "(", "me", "-", "1", ")", "%", "track_len", "==", "intersections", "[", "-", "1", "]", ":", "\n", "                        ", "tmp_lst", "=", "tmp_lst", "+", "forward", "(", ")", "\n", "\n", "", "", "groups", ".", "append", "(", "tmp_lst", ")", "\n", "tmp_lst", "=", "[", "]", "\n", "\n", "", "for", "group", "in", "groups", ":", "\n", "                ", "min_dist_idx", "=", "None", "\n", "min_dist", "=", "1e10", "\n", "for", "idx", "in", "group", ":", "\n", "                    ", "d", "=", "np", ".", "linalg", ".", "norm", "(", "self", ".", "track", "[", "track_len", ":", ",", "1", ",", "2", ":", "]", "-", "self", ".", "track", "[", "idx", ",", "1", ",", "2", ":", "]", ",", "axis", "=", "1", ")", "\n", "if", "d", ".", "min", "(", ")", "<", "min_dist", ":", "\n", "                        ", "min_dist", "=", "d", ".", "min", "(", ")", "\n", "min_dist_idx", "=", "idx", "\n", "\n", "", "", "if", "min_dist", "<=", "TRACK_WIDTH", ":", "\n", "                    ", "intersections", ".", "append", "(", "min_dist_idx", ")", "\n", "\n", "", "", "info", "[", "'intersection'", "]", "[", "list", "(", "intersections", ")", "]", "=", "True", "\n", "\n", "# Classifying intersections", "\n", "for", "idx", "in", "intersections", ":", "\n", "                ", "point", "=", "self", ".", "track", "[", "idx", ",", "1", ",", "2", ":", "]", "\n", "d", "=", "np", ".", "linalg", ".", "norm", "(", "self", ".", "track", "[", ":", ",", "1", ",", "2", ":", "]", "-", "point", ",", "axis", "=", "1", ")", "\n", "argmin", "=", "d", "[", "info", "[", "'track'", "]", "!=", "0", "]", ".", "argmin", "(", ")", "\n", "filt", "=", "np", ".", "where", "(", "d", "<", "TRACK_WIDTH", "*", "2.5", ")", "\n", "\n", "# TODO ignore intersections with angles of pi/2", "\n", "\n", "if", "info", "[", "filt", "]", "[", "'start'", "]", ".", "sum", "(", ")", "-", "info", "[", "filt", "]", "[", "'end'", "]", ".", "sum", "(", ")", "!=", "0", ":", "\n", "                    ", "info", "[", "idx", "]", "[", "'t'", "]", "=", "True", "\n", "info", "[", "argmin", "+", "track_len", "]", "[", "'t'", "]", "=", "True", "\n", "", "else", ":", "\n", "# the sum can be zero because second tracks are not cutted in case of x", "\n", "                    ", "info", "[", "idx", "]", "[", "'x'", "]", "=", "True", "\n", "info", "[", "argmin", "+", "track_len", "]", "[", "'x'", "]", "=", "True", "\n", "\n", "# Getting angles of curves", "\n", "", "", "", "max_idxs", "=", "[", "]", "\n", "self", ".", "track", "[", ":", ",", "0", ",", "1", "]", "=", "np", ".", "mod", "(", "self", ".", "track", "[", ":", ",", "0", ",", "1", "]", ",", "2", "*", "math", ".", "pi", ")", "\n", "self", ".", "track", "[", ":", ",", "1", ",", "1", "]", "=", "np", ".", "mod", "(", "self", ".", "track", "[", ":", ",", "1", ",", "1", "]", ",", "2", "*", "math", ".", "pi", ")", "\n", "for", "num_track", "in", "range", "(", "self", ".", "num_tracks", ")", ":", "\n", "\n", "            ", "track", "=", "self", ".", "tracks", "[", "num_track", "]", "\n", "angles", "=", "track", "[", ":", ",", "0", ",", "1", "]", "-", "track", "[", ":", ",", "1", ",", "1", "]", "\n", "inters", "=", "np", ".", "logical_or", "(", "info", "[", "info", "[", "'track'", "]", "==", "num_track", "]", "[", "'t'", "]", ",", "info", "[", "info", "[", "'track'", "]", "==", "num_track", "]", "[", "'x'", "]", ")", "\n", "\n", "track_len_compl", "=", "(", "info", "[", "'track'", "]", "<", "num_track", ")", ".", "sum", "(", ")", "\n", "track_len", "=", "len", "(", "track", ")", "\n", "\n", "while", "np", ".", "abs", "(", "angles", ")", ".", "max", "(", ")", "!=", "0.0", ":", "\n", "                ", "max_rel_idx", "=", "np", ".", "abs", "(", "angles", ")", ".", "argmax", "(", ")", "\n", "\n", "rel_idxs", "=", "[", "(", "max_rel_idx", "+", "j", ")", "%", "track_len", "for", "j", "in", "range", "(", "-", "NUM_TILES_FOR_AVG", ",", "NUM_TILES_FOR_AVG", ")", "]", "\n", "idxs_safety", "=", "[", "(", "max_rel_idx", "+", "j", ")", "%", "track_len", "for", "j", "in", "\n", "range", "(", "-", "NUM_TILES_FOR_AVG", "*", "2", ",", "NUM_TILES_FOR_AVG", "*", "2", ")", "]", "\n", "\n", "if", "(", "inters", "[", "idxs_safety", "]", "==", "True", ")", ".", "sum", "(", ")", "==", "0", ":", "\n", "                    ", "max_idxs", ".", "append", "(", "max_rel_idx", "+", "track_len_compl", ")", "\n", "angles", "[", "rel_idxs", "]", "=", "0.0", "\n", "", "else", ":", "\n", "                    ", "angles", "[", "max_rel_idx", "]", "=", "0.0", "\n", "\n", "", "", "", "info", "[", "'angle'", "]", "[", "max_idxs", "]", "=", "self", ".", "track", "[", "max_idxs", ",", "0", ",", "1", "]", "-", "self", ".", "track", "[", "max_idxs", ",", "1", ",", "1", "]", "\n", "\n", "######### populating intersection_id", "\n", "intersection_dict", "=", "{", "}", "\n", "\n", "# Remove keys which are to close", "\n", "intersection_keys", "=", "np", ".", "where", "(", "info", "[", "'intersection'", "]", ")", "[", "0", "]", "\n", "intersection_vals", "=", "np", ".", "where", "(", "(", "info", "[", "'x'", "]", ")", "|", "(", "info", "[", "'t'", "]", ")", ")", "[", "0", "]", "\n", "\n", "for", "val", "in", "intersection_vals", ":", "\n", "            ", "tmp", "=", "self", ".", "track", "[", "intersection_keys", "]", "[", ":", ",", "1", ",", "2", ":", "]", "\n", "elm", "=", "self", ".", "track", "[", "val", ",", "1", ",", "2", ":", "]", "\n", "d", "=", "np", ".", "linalg", ".", "norm", "(", "tmp", "-", "elm", ",", "axis", "=", "1", ")", "\n", "if", "d", ".", "min", "(", ")", ">", "TRACK_WIDTH", "*", "2", ":", "\n", "                ", "if", "self", ".", "verbose", ">", "0", ":", "\n", "                    ", "print", "(", "\"the closest intersection is too far away\"", ")", "\n", "", "", "else", ":", "\n", "                ", "k", "=", "intersection_keys", "[", "d", ".", "argmin", "(", ")", "]", "\n", "\n", "if", "k", "in", "intersection_dict", ".", "keys", "(", ")", ":", "\n", "                    ", "pass", "\n", "", "else", ":", "\n", "                    ", "intersection_dict", "[", "k", "]", "=", "[", "]", "\n", "\n", "", "intersection_dict", "[", "k", "]", ".", "append", "(", "val", ")", "\n", "\n", "", "", "self", ".", "intersection_dict", "=", "intersection_dict", "\n", "\n", "for", "k", ",", "v", "in", "self", ".", "intersection_dict", ".", "items", "(", ")", ":", "\n", "            ", "info", "[", "'intersection_id'", "]", "[", "[", "k", "]", "+", "v", "]", "=", "k", "\n", "", "del", "self", ".", "intersection_dict", "\n", "##############################################", "\n", "\n", "self", ".", "info", "=", "info", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._set_lanes": [[345, 400], ["numpy.sort", "enumerate", "enumerate", "range", "road_creator.RoadCreator.np_random.randint", "sum", "sum", "numpy.subtract", "range", "len", "numpy.setdiff1d", "range", "len", "sum", "changes_bad.append", "range", "changes_bad.append", "numpy.random.randint", "len", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "def", "_set_lanes", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "num_lanes_changes", ">", "0", "and", "self", ".", "num_lanes", ">", "1", ":", "\n", "            ", "rm_lane", "=", "0", "# 1 remove lane, 0 keep lane", "\n", "lane", "=", "0", "# Which lane will be removed", "\n", "changes", "=", "np", ".", "sort", "(", "self", ".", "np_random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "track", ")", ",", "self", ".", "num_lanes_changes", ")", ")", "\n", "\n", "# check in changes work", "\n", "# There must be no change at least 50 pos before and end and after a start", "\n", "changes_bad", "=", "[", "]", "\n", "for", "pos", ",", "idx", "in", "enumerate", "(", "changes", ")", ":", "\n", "                ", "start_from", "=", "sum", "(", "self", ".", "info", "[", "'track'", "]", "<", "self", ".", "info", "[", "idx", "]", "[", "'track'", "]", ")", "\n", "until", "=", "sum", "(", "self", ".", "info", "[", "'track'", "]", "==", "self", ".", "info", "[", "idx", "]", "[", "'track'", "]", ")", "\n", "changes_in_track", "=", "np", ".", "subtract", "(", "changes", ",", "start_from", ")", "\n", "changes_in_track", "=", "changes_in_track", "[", "(", "changes_in_track", "<", "until", ")", "*", "(", "changes_in_track", ">", "0", ")", "]", "\n", "idx_relative", "=", "idx", "-", "start_from", "\n", "\n", "if", "sum", "(", "(", "(", "changes_in_track", "-", "idx", ")", ">", "0", ")", "*", "(", "\n", "(", "changes_in_track", "-", "idx", ")", "<", "10", ")", ")", ">", "0", ":", "# TODO wont work when at end of track", "\n", "                    ", "changes_bad", ".", "append", "(", "idx", ")", "\n", "next", "\n", "\n", "", "track_info", "=", "self", ".", "info", "[", "self", ".", "info", "[", "'track'", "]", "==", "self", ".", "info", "[", "idx", "]", "[", "'track'", "]", "]", "\n", "for", "i", "in", "range", "(", "50", "+", "1", ")", ":", "\n", "                    ", "if", "track_info", "[", "(", "idx_relative", "+", "i", ")", "%", "len", "(", "track_info", ")", "]", "[", "'end'", "]", "or", "track_info", "[", "idx_relative", "-", "i", "]", "[", "'start'", "]", ":", "\n", "                        ", "changes_bad", ".", "append", "(", "idx", ")", "\n", "break", "\n", "\n", "", "", "", "if", "len", "(", "changes_bad", ")", ">", "0", ":", "\n", "                ", "changes", "=", "np", ".", "setdiff1d", "(", "changes", ",", "changes_bad", ")", "\n", "\n", "", "counter", "=", "0", "# in order to avoid more than max number of single lanes tiles", "\n", "for", "i", ",", "point", "in", "enumerate", "(", "self", ".", "track", ")", ":", "\n", "                ", "change", "=", "True", "if", "i", "in", "changes", "else", "False", "\n", "rm_lane", "=", "(", "rm_lane", "+", "change", ")", "%", "2", "\n", "\n", "if", "change", "and", "rm_lane", "==", "1", ":", "# if it is time to change and the turn is to remove lane", "\n", "                    ", "lane", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "2", ",", "1", ")", "[", "0", "]", "\n", "\n", "", "if", "rm_lane", ":", "\n", "                    ", "self", ".", "info", "[", "i", "]", "[", "'lanes'", "]", "[", "lane", "]", "=", "False", "\n", "counter", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "counter", "=", "0", "\n", "\n", "# Change if end/inter of or if change prob", "\n", "", "if", "self", ".", "info", "[", "i", "]", "[", "'end'", "]", "or", "self", ".", "info", "[", "i", "]", "[", "'start'", "]", "or", "counter", ">", "self", ".", "max_single_lane", ":", "\n", "                    ", "rm_lane", "=", "0", "\n", "\n", "# Avoiding any change of lanes in last and beginning part of a track", "\n", "", "", "for", "num_track", "in", "range", "(", "self", ".", "num_tracks", ")", ":", "\n", "                ", "for", "lane", "in", "range", "(", "self", ".", "num_lanes", ")", ":", "\n", "                    ", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "                        ", "i", "%=", "len", "(", "self", ".", "tracks", "[", "num_track", "]", ")", "\n", "self", ".", "info", "[", "self", ".", "info", "[", "'track'", "]", "==", "num_track", "]", "[", "+", "i", "]", "[", "'lanes'", "]", "[", "lane", "]", "=", "True", "\n", "self", ".", "info", "[", "self", ".", "info", "[", "'track'", "]", "==", "num_track", "]", "[", "-", "i", "]", "[", "'lanes'", "]", "[", "lane", "]", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._remove_unfinished_roads": [[401, 419], ["set", "numpy.delete", "len", "list", "len", "numpy.delete", "any", "any", "set.update", "range", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.mpi_running_mean_std.RunningMeanStd.update"], ["", "", "", "", "", "def", "_remove_unfinished_roads", "(", "self", ")", ":", "\n", "        ", "n", "=", "0", "\n", "to_remove", "=", "set", "(", ")", "\n", "# The problem only appears in track1", "\n", "while", "n", "<", "len", "(", "self", ".", "tracks", "[", "0", "]", ")", ":", "\n", "            ", "prev_tile", "=", "self", ".", "tracks", "[", "0", "]", "[", "n", "-", "2", "]", "\n", "tile", "=", "self", ".", "tracks", "[", "0", "]", "[", "n", "-", "1", "]", "\n", "next_tile", "=", "self", ".", "tracks", "[", "0", "]", "[", "n", "]", "\n", "\n", "if", "any", "(", "tile", "[", "0", "]", "!=", "prev_tile", "[", "1", "]", ")", "or", "any", "(", "tile", "[", "1", "]", "!=", "next_tile", "[", "0", "]", ")", ":", "\n", "                ", "to_remove", ".", "update", "(", "n", ")", "\n", "n", "-=", "1", "\n", "", "else", ":", "\n", "                ", "n", "+=", "1", "\n", "", "", "self", ".", "tracks", "[", "0", "]", "=", "np", ".", "delete", "(", "self", ".", "tracks", "[", "0", "]", ",", "list", "(", "to_remove", ")", ",", "axis", "=", "0", ")", "\n", "\n", "if", "len", "(", "self", ".", "tracks", "[", "1", "]", ")", "<", "5", ":", "\n", "            ", "self", ".", "tracks", "[", "1", "]", "=", "np", ".", "delete", "(", "self", ".", "tracks", "[", "1", "]", ",", "range", "(", "len", "(", "self", ".", "tracks", "[", "1", "]", ")", ")", ",", "axis", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._choice_random_track_from_file": [[420, 423], ["numpy.random.choice"], "methods", ["None"], ["", "", "def", "_choice_random_track_from_file", "(", "self", ")", ":", "\n", "        ", "idx", "=", "np", ".", "random", ".", "choice", "(", "self", ".", "tracks_df", ".", "index", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._generate_track": [[424, 489], ["road_creator.RoadCreator._choice_random_track_from_file", "range", "road_creator.RoadCreator._create_info", "road_creator.RoadCreator._set_lanes", "pickle.load", "numpy.zeros", "road_creator.RoadCreator._get_track", "numpy.array", "tracks.append", "road_creator.RoadCreator._remove_unfinished_roads", "numpy.concatenate", "numpy.array", "open", "print", "print", "print", "len", "int", "numpy.array", "road_creator.RoadCreator._remove_roads", "str", "len", "numpy.random.uniform", "str", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._choice_random_track_from_file", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._create_info", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._set_lanes", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._get_track", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._remove_unfinished_roads", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._remove_roads"], ["", "def", "_generate_track", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "load_tracks_from", "is", "not", "None", ":", "\n", "            ", "idx", "=", "self", ".", "_choice_random_track_from_file", "(", ")", "\n", "try", ":", "\n", "                ", "dic", "=", "pickle", ".", "load", "(", "open", "(", "self", ".", "load_tracks_from", "+", "'/'", "+", "str", "(", "idx", ")", "+", "\".pkl\"", ",", "'rb'", ")", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "\"######## Error ########\"", ")", "\n", "print", "(", "\"error loading the track\"", ",", "str", "(", "idx", ")", ")", "\n", "print", "(", "e", ")", "\n", "return", "False", "\n", "", "else", ":", "\n", "                ", "self", ".", "track", "=", "dic", "[", "'track'", "]", "\n", "self", ".", "tracks", "=", "dic", "[", "'tracks'", "]", "\n", "self", ".", "info", "=", "dic", "[", "'info'", "]", "\n", "self", ".", "obstacle_contacts", "=", "np", ".", "zeros", "(", "(", "len", "(", "self", ".", "obstacles_poly", ")", ")", ",", "dtype", "=", "\n", "[", "(", "'count'", ",", "int", ")", ",", "(", "'count_delay'", ",", "int", ")", ",", "(", "'visited'", ",", "bool", ")", "]", ")", "\n", "\n", "self", ".", "info", "[", "[", "\n", "'count_left'", ",", "\n", "'count_right'", ",", "\n", "'count_right_delay'", ",", "\n", "'count_left_delay'", "]", "]", "=", "0", "\n", "self", ".", "info", "[", "'visited'", "]", "=", "False", "\n", "\n", "return", "True", "\n", "", "", "else", ":", "\n", "            ", "tracks", "=", "[", "]", "\n", "cp", "=", "12", "\n", "for", "_", "in", "range", "(", "self", ".", "num_tracks", ")", ":", "\n", "# The following variables allow for more complex tracks but, it is also", "\n", "# harder to controll their properties and correct behaviour", "\n", "                ", "track", "=", "self", ".", "_get_track", "(", "int", "(", "cp", "*", "(", "1", "**", "_", ")", ")", ")", "# ,x_bias=-40*_,y_bias=40*_)", "\n", "if", "not", "track", "or", "len", "(", "track", ")", "==", "0", ":", "return", "track", "\n", "track", "=", "np", ".", "array", "(", "track", ")", "\n", "if", "_", ">", "0", "and", "False", ":", "\n", "# adding rotation to decrease number of overlaps", "\n", "                    ", "theta", "=", "np", ".", "random", ".", "uniform", "(", ")", "*", "2", "*", "np", ".", "pi", "\n", "R", "=", "np", ".", "array", "(", "[", "[", "np", ".", "cos", "(", "theta", ")", ",", "-", "np", ".", "sin", "(", "theta", ")", "]", ",", "[", "np", ".", "sin", "(", "theta", ")", ",", "np", ".", "cos", "(", "theta", ")", "]", "]", ")", "\n", "track", "[", ":", ",", "0", ",", "2", ":", "]", "=", "(", "R", "@", "track", "[", ":", ",", "0", ",", "2", ":", "]", ".", "T", ")", ".", "T", "\n", "track", "[", ":", ",", "1", ",", "2", ":", "]", "=", "(", "R", "@", "track", "[", ":", ",", "1", ",", "2", ":", "]", ".", "T", ")", ".", "T", "\n", "track", "[", ":", ",", ":", "2", "]", "+=", "theta", "\n", "", "tracks", ".", "append", "(", "track", ")", "\n", "\n", "", "self", ".", "tracks", "=", "tracks", "\n", "if", "self", ".", "num_tracks", ">", "1", ":", "\n", "                ", "if", "self", ".", "_remove_roads", "(", ")", "==", "False", ":", "return", "False", "\n", "self", ".", "_remove_unfinished_roads", "(", ")", "\n", "\n", "", "if", "self", ".", "tracks", "[", "0", "]", ".", "size", "<=", "5", ":", "\n", "                ", "return", "False", "\n", "", "if", "self", ".", "num_tracks", ">", "1", ":", "\n", "                ", "if", "self", ".", "tracks", "[", "1", "]", ".", "size", "<=", "5", ":", "\n", "                    ", "return", "False", "\n", "", "if", "self", ".", "tracks", "[", "0", "]", ".", "shape", "[", "1", ":", "]", "!=", "self", ".", "tracks", "[", "1", "]", ".", "shape", "[", "1", ":", "]", ":", "\n", "                    ", "return", "False", "\n", "\n", "", "self", ".", "track", "=", "np", ".", "concatenate", "(", "self", ".", "tracks", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "track", "=", "np", ".", "array", "(", "self", ".", "tracks", "[", "0", "]", ")", "\n", "\n", "", "self", ".", "_create_info", "(", ")", "\n", "# Avoid lonely tiles at the begining of track", "\n", "if", "self", ".", "info", "[", "0", "]", "[", "'intersection_id'", "]", "!=", "-", "1", ":", "return", "False", "\n", "\n", "self", ".", "_set_lanes", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._create_single_track": [[490, 638], ["range", "len", "math.cos", "math.sin", "numpy.sqrt", "range", "range", "range", "numpy.random.uniform", "checkpoints.append", "math.atan2", "math.cos", "math.sin", "track.append", "len", "len", "range", "len", "range", "len", "road_creator.RoadCreator.box2d.CreateStaticBody", "road_creator.RoadCreator.road_poly.append", "road_creator.RoadCreator.road.append", "numpy.random.uniform", "min", "min", "numpy.square", "numpy.square", "numpy.sign", "abs", "numpy.sign", "road_creator.RoadCreator.road_poly.append", "abs", "abs", "abs", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "len", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "len"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.MinSegmentTree.min", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "def", "_create_single_track", "(", "self", ")", ":", "\n", "        ", "CHECKPOINTS", "=", "12", "\n", "\n", "# Create checkpoints", "\n", "checkpoints", "=", "[", "]", "\n", "for", "c", "in", "range", "(", "CHECKPOINTS", ")", ":", "\n", "            ", "alpha", "=", "2", "*", "math", ".", "pi", "*", "c", "/", "CHECKPOINTS", "+", "np", ".", "random", ".", "uniform", "(", "0", ",", "2", "*", "math", ".", "pi", "*", "1", "/", "CHECKPOINTS", ")", "\n", "rad", "=", "np", ".", "random", ".", "uniform", "(", "TRACK_RAD", "/", "3", ",", "TRACK_RAD", ")", "\n", "if", "c", "==", "0", ":", "\n", "                ", "alpha", "=", "0", "\n", "rad", "=", "1.5", "*", "TRACK_RAD", "\n", "", "if", "c", "==", "CHECKPOINTS", "-", "1", ":", "\n", "                ", "alpha", "=", "2", "*", "math", ".", "pi", "*", "c", "/", "CHECKPOINTS", "\n", "self", ".", "start_alpha", "=", "2", "*", "math", ".", "pi", "*", "(", "-", "0.5", ")", "/", "CHECKPOINTS", "\n", "rad", "=", "1.5", "*", "TRACK_RAD", "\n", "", "checkpoints", ".", "append", "(", "(", "alpha", ",", "rad", "*", "math", ".", "cos", "(", "alpha", ")", ",", "rad", "*", "math", ".", "sin", "(", "alpha", ")", ")", ")", "\n", "", "self", ".", "road", "=", "[", "]", "\n", "\n", "# Go from one checkpoint to another to create track", "\n", "x", ",", "y", ",", "beta", "=", "1.5", "*", "TRACK_RAD", ",", "0", ",", "0", "\n", "dest_i", "=", "0", "\n", "laps", "=", "0", "\n", "track", "=", "[", "]", "\n", "no_freeze", "=", "2500", "\n", "visited_other_side", "=", "False", "\n", "while", "True", ":", "\n", "            ", "alpha", "=", "math", ".", "atan2", "(", "y", ",", "x", ")", "\n", "if", "visited_other_side", "and", "alpha", ">", "0", ":", "\n", "                ", "laps", "+=", "1", "\n", "visited_other_side", "=", "False", "\n", "", "if", "alpha", "<", "0", ":", "\n", "                ", "visited_other_side", "=", "True", "\n", "alpha", "+=", "2", "*", "math", ".", "pi", "\n", "", "while", "True", ":", "# Find destination from checkpoints", "\n", "                ", "failed", "=", "True", "\n", "while", "True", ":", "\n", "                    ", "dest_alpha", ",", "dest_x", ",", "dest_y", "=", "checkpoints", "[", "dest_i", "%", "len", "(", "checkpoints", ")", "]", "\n", "if", "alpha", "<=", "dest_alpha", ":", "\n", "                        ", "failed", "=", "False", "\n", "break", "\n", "", "dest_i", "+=", "1", "\n", "if", "dest_i", "%", "len", "(", "checkpoints", ")", "==", "0", ":", "\n", "                        ", "break", "\n", "", "", "if", "not", "failed", ":", "\n", "                    ", "break", "\n", "", "alpha", "-=", "2", "*", "math", ".", "pi", "\n", "continue", "\n", "", "r1x", "=", "math", ".", "cos", "(", "beta", ")", "\n", "r1y", "=", "math", ".", "sin", "(", "beta", ")", "\n", "p1x", "=", "-", "r1y", "\n", "p1y", "=", "r1x", "\n", "dest_dx", "=", "dest_x", "-", "x", "# vector towards destination", "\n", "dest_dy", "=", "dest_y", "-", "y", "\n", "proj", "=", "r1x", "*", "dest_dx", "+", "r1y", "*", "dest_dy", "# destination vector projected on rad", "\n", "while", "beta", "-", "alpha", ">", "1.5", "*", "math", ".", "pi", ":", "\n", "                ", "beta", "-=", "2", "*", "math", ".", "pi", "\n", "", "while", "beta", "-", "alpha", "<", "-", "1.5", "*", "math", ".", "pi", ":", "\n", "                ", "beta", "+=", "2", "*", "math", ".", "pi", "\n", "", "prev_beta", "=", "beta", "\n", "proj", "*=", "SCALE", "\n", "if", "proj", ">", "0.3", ":", "\n", "                ", "beta", "-=", "min", "(", "TRACK_TURN_RATE", ",", "abs", "(", "0.001", "*", "proj", ")", ")", "\n", "", "if", "proj", "<", "-", "0.3", ":", "\n", "                ", "beta", "+=", "min", "(", "TRACK_TURN_RATE", ",", "abs", "(", "0.001", "*", "proj", ")", ")", "\n", "", "x", "+=", "p1x", "*", "TRACK_DETAIL_STEP", "\n", "y", "+=", "p1y", "*", "TRACK_DETAIL_STEP", "\n", "track", ".", "append", "(", "(", "alpha", ",", "prev_beta", "*", "0.5", "+", "beta", "*", "0.5", ",", "x", ",", "y", ")", ")", "\n", "if", "laps", ">", "4", ":", "\n", "                ", "break", "\n", "", "no_freeze", "-=", "1", "\n", "if", "no_freeze", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "# Find closed loop range i1..i2, first loop should be ignored, second is OK", "\n", "", "", "i1", ",", "i2", "=", "-", "1", ",", "-", "1", "\n", "i", "=", "len", "(", "track", ")", "\n", "while", "True", ":", "\n", "            ", "i", "-=", "1", "\n", "if", "i", "==", "0", ":", "\n", "                ", "return", "False", "# Failed", "\n", "", "pass_through_start", "=", "track", "[", "i", "]", "[", "0", "]", ">", "self", ".", "start_alpha", "and", "track", "[", "i", "-", "1", "]", "[", "0", "]", "<=", "self", ".", "start_alpha", "\n", "if", "pass_through_start", "and", "i2", "==", "-", "1", ":", "\n", "                ", "i2", "=", "i", "\n", "", "elif", "pass_through_start", "and", "i1", "==", "-", "1", ":", "\n", "                ", "i1", "=", "i", "\n", "break", "\n", "\n", "", "", "assert", "i1", "!=", "-", "1", "\n", "assert", "i2", "!=", "-", "1", "\n", "\n", "track", "=", "track", "[", "i1", ":", "i2", "-", "1", "]", "\n", "\n", "first_beta", "=", "track", "[", "0", "]", "[", "1", "]", "\n", "first_perp_x", "=", "math", ".", "cos", "(", "first_beta", ")", "\n", "first_perp_y", "=", "math", ".", "sin", "(", "first_beta", ")", "\n", "# Length of perpendicular jump to put together head and tail", "\n", "well_glued_together", "=", "np", ".", "sqrt", "(", "\n", "np", ".", "square", "(", "first_perp_x", "*", "(", "track", "[", "0", "]", "[", "2", "]", "-", "track", "[", "-", "1", "]", "[", "2", "]", ")", ")", "+", "\n", "np", ".", "square", "(", "first_perp_y", "*", "(", "track", "[", "0", "]", "[", "3", "]", "-", "track", "[", "-", "1", "]", "[", "3", "]", ")", ")", ")", "\n", "if", "well_glued_together", ">", "TRACK_DETAIL_STEP", ":", "\n", "            ", "return", "False", "\n", "\n", "# Red-white border on hard turns", "\n", "", "border", "=", "[", "False", "]", "*", "len", "(", "track", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "track", ")", ")", ":", "\n", "            ", "good", "=", "True", "\n", "oneside", "=", "0", "\n", "for", "neg", "in", "range", "(", "BORDER_MIN_COUNT", ")", ":", "\n", "                ", "beta1", "=", "track", "[", "i", "-", "neg", "-", "0", "]", "[", "1", "]", "\n", "beta2", "=", "track", "[", "i", "-", "neg", "-", "1", "]", "[", "1", "]", "\n", "good", "&=", "abs", "(", "beta1", "-", "beta2", ")", ">", "TRACK_TURN_RATE", "*", "0.2", "\n", "oneside", "+=", "np", ".", "sign", "(", "beta1", "-", "beta2", ")", "\n", "", "good", "&=", "abs", "(", "oneside", ")", "==", "BORDER_MIN_COUNT", "\n", "border", "[", "i", "]", "=", "good", "\n", "", "for", "i", "in", "range", "(", "len", "(", "track", ")", ")", ":", "\n", "            ", "for", "neg", "in", "range", "(", "BORDER_MIN_COUNT", ")", ":", "\n", "                ", "border", "[", "i", "-", "neg", "]", "|=", "border", "[", "i", "]", "\n", "\n", "# Create tiles", "\n", "", "", "for", "i", "in", "range", "(", "len", "(", "track", ")", ")", ":", "\n", "            ", "alpha1", ",", "beta1", ",", "x1", ",", "y1", "=", "track", "[", "i", "]", "\n", "alpha2", ",", "beta2", ",", "x2", ",", "y2", "=", "track", "[", "i", "-", "1", "]", "\n", "road1_l", "=", "(", "x1", "-", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta1", ")", ",", "y1", "-", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "road1_r", "=", "(", "x1", "+", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta1", ")", ",", "y1", "+", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "road2_l", "=", "(", "x2", "-", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta2", ")", ",", "y2", "-", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "road2_r", "=", "(", "x2", "+", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta2", ")", ",", "y2", "+", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "vertices", "=", "[", "road1_l", ",", "road1_r", ",", "road2_r", ",", "road2_l", "]", "\n", "self", ".", "fd_tile", ".", "shape", ".", "vertices", "=", "vertices", "\n", "t", "=", "self", ".", "box2d", ".", "CreateStaticBody", "(", "fixtures", "=", "self", ".", "fd_tile", ")", "\n", "t", ".", "userData", "=", "t", "\n", "c", "=", "0.01", "*", "(", "i", "%", "3", ")", "\n", "t", ".", "color", "=", "[", "ROAD_COLOR", "[", "0", "]", "+", "c", ",", "ROAD_COLOR", "[", "1", "]", "+", "c", ",", "ROAD_COLOR", "[", "2", "]", "+", "c", "]", "\n", "t", ".", "road_visited", "=", "False", "\n", "t", ".", "road_friction", "=", "1.0", "\n", "t", ".", "fixtures", "[", "0", "]", ".", "sensor", "=", "True", "\n", "self", ".", "road_poly", ".", "append", "(", "(", "[", "road1_l", ",", "road1_r", ",", "road2_r", ",", "road2_l", "]", ",", "t", ".", "color", ")", ")", "\n", "self", ".", "road", ".", "append", "(", "t", ")", "\n", "if", "border", "[", "i", "]", ":", "\n", "                ", "side", "=", "np", ".", "sign", "(", "beta2", "-", "beta1", ")", "\n", "b1_l", "=", "(", "x1", "+", "side", "*", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta1", ")", ",", "y1", "+", "side", "*", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "b1_r", "=", "(", "x1", "+", "side", "*", "(", "TRACK_WIDTH", "+", "BORDER", ")", "*", "math", ".", "cos", "(", "beta1", ")", ",", "\n", "y1", "+", "side", "*", "(", "TRACK_WIDTH", "+", "BORDER", ")", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "b2_l", "=", "(", "x2", "+", "side", "*", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta2", ")", ",", "y2", "+", "side", "*", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "b2_r", "=", "(", "x2", "+", "side", "*", "(", "TRACK_WIDTH", "+", "BORDER", ")", "*", "math", ".", "cos", "(", "beta2", ")", ",", "\n", "y2", "+", "side", "*", "(", "TRACK_WIDTH", "+", "BORDER", ")", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "self", ".", "road_poly", ".", "append", "(", "(", "[", "b1_l", ",", "b1_r", ",", "b2_r", ",", "b2_l", "]", ",", "(", "1", ",", "1", ",", "1", ")", "if", "i", "%", "2", "==", "0", "else", "(", "1", ",", "0", ",", "0", ")", ")", ")", "\n", "", "", "self", ".", "track", "=", "track", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._create_track": [[639, 832], ["road_creator.RoadCreator._generate_track", "range", "range", "len", "numpy.random.binomial", "range", "range", "range", "borders.append", "range", "road_creator.RoadCreator.track_lanes.append", "len", "len", "range", "len", "range", "len", "set", "numpy.sign", "abs", "numpy.sign", "road_creator.RoadCreator.road_poly.append", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin", "len", "road_creator.RoadCreator.box2d.CreateStaticBody", "road_creator.RoadCreator.road_poly.append", "road_creator.RoadCreator.road.append", "print", "abs", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sin", "sum", "points.append", "tuple", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "len", "sum", "sum", "len", "RuntimeError", "numpy.linalg.norm", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "math.cos", "math.sin", "sum", "numpy.where", "numpy.cross", "numpy.subtract", "len", "numpy.where", "numpy.subtract", "numpy.subtract", "d.argmin", "len", "numpy.linalg.norm", "numpy.intersect1d", "numpy.subtract", "numpy.linalg.norm", "len", "numpy.subtract"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._generate_track", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["", "def", "_create_track", "(", "self", ")", ":", "\n", "\n", "        ", "Ok", "=", "self", ".", "_generate_track", "(", ")", "\n", "if", "Ok", "is", "False", ":", "\n", "            ", "return", "False", "\n", "\n", "# Red-white border on hard turns", "\n", "", "borders", "=", "[", "]", "\n", "if", "True", ":", "\n", "            ", "for", "track", "in", "self", ".", "tracks", ":", "\n", "                ", "border", "=", "[", "False", "]", "*", "len", "(", "track", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "track", ")", ")", ":", "\n", "                    ", "good", "=", "True", "\n", "oneside", "=", "0", "\n", "for", "neg", "in", "range", "(", "BORDER_MIN_COUNT", ")", ":", "\n", "                        ", "beta1", "=", "track", "[", "i", "-", "neg", "]", "[", "1", "]", "[", "1", "]", "\n", "beta2", "=", "track", "[", "i", "-", "neg", "]", "[", "0", "]", "[", "1", "]", "\n", "good", "&=", "abs", "(", "beta1", "-", "beta2", ")", ">", "TRACK_TURN_RATE", "*", "0.2", "\n", "oneside", "+=", "np", ".", "sign", "(", "beta1", "-", "beta2", ")", "\n", "", "good", "&=", "abs", "(", "oneside", ")", "==", "BORDER_MIN_COUNT", "\n", "border", "[", "i", "]", "=", "good", "\n", "", "for", "i", "in", "range", "(", "len", "(", "track", ")", ")", ":", "\n", "                    ", "for", "neg", "in", "range", "(", "BORDER_MIN_COUNT", ")", ":", "\n", "# TODO ERROR, sometimes list index out of range", "\n", "                        ", "border", "[", "i", "-", "neg", "]", "|=", "border", "[", "i", "]", "\n", "", "", "borders", ".", "append", "(", "border", ")", "\n", "\n", "# Creating borders for printing", "\n", "", "pos", "=", "0", "\n", "for", "j", "in", "range", "(", "self", ".", "num_tracks", ")", ":", "\n", "                ", "track", "=", "self", ".", "tracks", "[", "j", "]", "\n", "border", "=", "borders", "[", "j", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "track", ")", ")", ":", "\n", "                    ", "alpha1", ",", "beta1", ",", "x1", ",", "y1", "=", "track", "[", "i", "]", "[", "1", "]", "\n", "alpha2", ",", "beta2", ",", "x2", ",", "y2", "=", "track", "[", "i", "]", "[", "0", "]", "\n", "if", "border", "[", "i", "]", ":", "\n", "                        ", "side", "=", "np", ".", "sign", "(", "beta2", "-", "beta1", ")", "\n", "\n", "c", "=", "1", "\n", "\n", "# Addapting border to appear at the right widht when there are different number of lanes", "\n", "if", "self", ".", "num_lanes", ">", "1", ":", "\n", "                            ", "if", "side", "==", "-", "1", "and", "self", ".", "info", "[", "pos", "]", "[", "'lanes'", "]", "[", "0", "]", "==", "False", ":", "c", "=", "0", "\n", "if", "side", "==", "+", "1", "and", "self", ".", "info", "[", "pos", "]", "[", "'lanes'", "]", "[", "1", "]", "==", "False", ":", "c", "=", "0", "\n", "\n", "", "b1_l", "=", "(", "\n", "x1", "+", "side", "*", "TRACK_WIDTH", "*", "c", "*", "math", ".", "cos", "(", "beta1", ")", ",", "y1", "+", "side", "*", "TRACK_WIDTH", "*", "c", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "b1_r", "=", "(", "x1", "+", "side", "*", "(", "TRACK_WIDTH", "*", "c", "+", "BORDER", ")", "*", "math", ".", "cos", "(", "beta1", ")", ",", "\n", "y1", "+", "side", "*", "(", "TRACK_WIDTH", "*", "c", "+", "BORDER", ")", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "b2_l", "=", "(", "\n", "x2", "+", "side", "*", "TRACK_WIDTH", "*", "c", "*", "math", ".", "cos", "(", "beta2", ")", ",", "y2", "+", "side", "*", "TRACK_WIDTH", "*", "c", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "b2_r", "=", "(", "x2", "+", "side", "*", "(", "TRACK_WIDTH", "*", "c", "+", "BORDER", ")", "*", "math", ".", "cos", "(", "beta2", ")", ",", "\n", "y2", "+", "side", "*", "(", "TRACK_WIDTH", "*", "c", "+", "BORDER", ")", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "self", ".", "road_poly", ".", "append", "(", "(", "[", "b1_l", ",", "b1_r", ",", "b2_r", ",", "b2_l", "]", ",", "(", "1", ",", "1", ",", "1", ")", "if", "i", "%", "2", "==", "0", "else", "(", "1", ",", "0", ",", "0", ")", ",", "0", ",", "0", ")", ")", "\n", "", "pos", "+=", "1", "\n", "\n", "# Create tiles", "\n", "", "", "", "for", "j", "in", "range", "(", "len", "(", "self", ".", "track", ")", ")", ":", "\n", "            ", "obstacle", "=", "np", ".", "random", ".", "binomial", "(", "1", ",", "0", ")", "\n", "alpha1", ",", "beta1", ",", "x1", ",", "y1", "=", "self", ".", "track", "[", "j", "]", "[", "1", "]", "\n", "alpha2", ",", "beta2", ",", "x2", ",", "y2", "=", "self", ".", "track", "[", "j", "]", "[", "0", "]", "\n", "\n", "# drawing angles of old config, the", "\n", "# black line is the angle (NOT WORKING)", "\n", "if", "SHOW_BETA_PI_ANGLE", ":", "\n", "                ", "if", "self", ".", "track_lanes", "==", "None", ":", "self", ".", "track_lanes", "=", "[", "]", "\n", "p1x", "=", "x1", "+", "np", ".", "cos", "(", "beta1", ")", "*", "0.2", "\n", "p1y", "=", "y1", "+", "np", ".", "sin", "(", "beta1", ")", "*", "0.2", "\n", "p2x", "=", "x1", "+", "np", ".", "cos", "(", "beta1", ")", "*", "0.2", "+", "np", ".", "cos", "(", "beta1", "+", "np", ".", "pi", "/", "2", ")", "*", "2", "\n", "p2y", "=", "y1", "+", "np", ".", "sin", "(", "beta1", ")", "*", "0.2", "+", "np", ".", "sin", "(", "beta1", "+", "np", ".", "pi", "/", "2", ")", "*", "2", "\n", "p3x", "=", "x1", "-", "np", ".", "cos", "(", "beta1", ")", "*", "0.2", "+", "np", ".", "cos", "(", "beta1", "+", "np", ".", "pi", "/", "2", ")", "*", "2", "\n", "p3y", "=", "y1", "-", "np", ".", "sin", "(", "beta1", ")", "*", "0.2", "+", "np", ".", "sin", "(", "beta1", "+", "np", ".", "pi", "/", "2", ")", "*", "2", "\n", "p4x", "=", "x1", "-", "np", ".", "cos", "(", "beta1", ")", "*", "0.2", "\n", "p4y", "=", "y1", "-", "np", ".", "sin", "(", "beta1", ")", "*", "0.2", "\n", "self", ".", "track_lanes", ".", "append", "(", "[", "\n", "[", "p1x", ",", "p1y", "]", ",", "\n", "[", "p2x", ",", "p2y", "]", ",", "\n", "[", "p3x", ",", "p3y", "]", ",", "\n", "[", "p4x", ",", "p4y", "]", "]", ")", "\n", "\n", "", "for", "lane", "in", "range", "(", "self", ".", "num_lanes", ")", ":", "\n", "                ", "if", "self", ".", "info", "[", "j", "]", "[", "'lanes'", "]", "[", "lane", "]", ":", "\n", "\n", "                    ", "joint", "=", "False", "# to differentiate joints from normal tiles", "\n", "\n", "r", "=", "1", "-", "(", "(", "lane", "+", "1", ")", "%", "self", ".", "num_lanes", ")", "\n", "l", "=", "1", "-", "(", "(", "lane", "+", "2", ")", "%", "self", ".", "num_lanes", ")", "\n", "\n", "# Get if it is the first or last", "\n", "first", "=", "False", "# first of lane", "\n", "last", "=", "False", "# last tile of line", "\n", "\n", "if", "self", ".", "info", "[", "j", "]", "[", "'end'", "]", "==", "False", "and", "self", ".", "info", "[", "j", "]", "[", "'start'", "]", "==", "False", ":", "\n", "\n", "# Getting if first tile of lane", "\n", "# if last tile was from the same lane", "\n", "                        ", "info_track", "=", "self", ".", "info", "[", "self", ".", "info", "[", "'track'", "]", "==", "self", ".", "info", "[", "j", "]", "[", "'track'", "]", "]", "\n", "j_relative", "=", "j", "-", "sum", "(", "self", ".", "info", "[", "'track'", "]", "<", "self", ".", "info", "[", "j", "]", "[", "'track'", "]", ")", "\n", "\n", "if", "info_track", "[", "j_relative", "-", "1", "]", "[", "'track'", "]", "==", "info_track", "[", "j_relative", "]", "[", "'track'", "]", ":", "\n", "# If last tile didnt exist", "\n", "                            ", "if", "info_track", "[", "j_relative", "-", "1", "]", "[", "'lanes'", "]", "[", "lane", "]", "==", "False", ":", "\n", "                                ", "first", "=", "True", "\n", "", "", "if", "info_track", "[", "(", "j_relative", "+", "1", ")", "%", "len", "(", "info_track", ")", "]", "[", "'track'", "]", "==", "info_track", "[", "j_relative", "]", "[", "'track'", "]", ":", "\n", "# If last tile didnt exist", "\n", "                            ", "if", "info_track", "[", "(", "j_relative", "+", "1", ")", "%", "len", "(", "info_track", ")", "]", "[", "'lanes'", "]", "[", "lane", "]", "==", "False", ":", "\n", "                                ", "last", "=", "True", "\n", "\n", "", "", "", "road1_l", "=", "(", "x1", "-", "(", "1", "-", "last", ")", "*", "l", "*", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta1", ")", ",", "\n", "y1", "-", "(", "1", "-", "last", ")", "*", "l", "*", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "road1_r", "=", "(", "x1", "+", "(", "1", "-", "last", ")", "*", "r", "*", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta1", ")", ",", "\n", "y1", "+", "(", "1", "-", "last", ")", "*", "r", "*", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta1", ")", ")", "\n", "road2_l", "=", "(", "x2", "-", "(", "1", "-", "first", ")", "*", "l", "*", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta2", ")", ",", "\n", "y2", "-", "(", "1", "-", "first", ")", "*", "l", "*", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "road2_r", "=", "(", "x2", "+", "(", "1", "-", "first", ")", "*", "r", "*", "TRACK_WIDTH", "*", "math", ".", "cos", "(", "beta2", ")", ",", "\n", "y2", "+", "(", "1", "-", "first", ")", "*", "r", "*", "TRACK_WIDTH", "*", "math", ".", "sin", "(", "beta2", ")", ")", "\n", "\n", "vertices", "=", "[", "road1_l", ",", "road1_r", ",", "road2_r", ",", "road2_l", "]", "\n", "\n", "if", "self", ".", "info", "[", "j", "]", "[", "'end'", "]", "==", "True", "or", "self", ".", "info", "[", "j", "]", "[", "'start'", "]", "==", "True", ":", "\n", "\n", "                        ", "points", "=", "[", "]", "# to store the new points", "\n", "p3", "=", "[", "]", "# in order to save all points 3 to create joints", "\n", "for", "i", "in", "[", "0", ",", "1", "]", ":", "# because there are two point to do", "\n", "# Get the closest point to a line make by the continuing trend of the original road points, the points will be the points", "\n", "# under a radius r from line to avoid taking points far away in the other extreme of the track", "\n", "# Remember the distance from a point p3 to a line p1,p2 is d = norm(np.cross(p2-p1, p1-p3))/norm(p2-p1)", "\n", "# p1=(x1,y1)+sin/cos, p2=(x2,y2)+sin/cos, p3=points in poly", "\n", "                            ", "if", "self", ".", "info", "[", "j", "]", "[", "'end'", "]", ":", "\n", "                                ", "p1", "=", "road1_l", "if", "i", "==", "0", "else", "road1_r", "\n", "p2", "=", "road2_l", "if", "i", "==", "0", "else", "road2_r", "\n", "", "else", ":", "\n", "                                ", "p1", "=", "road1_l", "if", "i", "==", "0", "else", "road1_r", "\n", "p2", "=", "road2_l", "if", "i", "==", "0", "else", "road2_r", "\n", "\n", "", "if", "len", "(", "p3", ")", "==", "0", ":", "\n", "                                ", "max_idx", "=", "sum", "(", "sum", "(", "self", ".", "info", "[", "self", ".", "info", "[", "'track'", "]", "==", "0", "]", "[", "'lanes'", "]", ",", "\n", "[", "]", ")", ")", "# this will work because only seconday tracks have ends", "\n", "p3_org", "=", "sum", "(", "[", "x", "[", "0", "]", "for", "x", "in", "self", ".", "road_poly", "[", ":", "max_idx", "]", "]", ",", "[", "]", ")", "\n", "# filter p3 by distance to p1 < TRACK_WIDTH*2", "\n", "distance", "=", "TRACK_WIDTH", "*", "2", "\n", "not_too_close", "=", "np", ".", "where", "(", "np", ".", "linalg", ".", "norm", "(", "np", ".", "subtract", "(", "p3_org", ",", "p1", ")", ",", "axis", "=", "1", ")", ">=", "TRACK_WIDTH", "/", "3", ")", "[", "0", "]", "\n", "while", "len", "(", "p3", ")", "==", "0", "and", "distance", "<", "PLAYFIELD", ":", "\n", "                                    ", "close", "=", "np", ".", "where", "(", "np", ".", "linalg", ".", "norm", "(", "np", ".", "subtract", "(", "p3_org", ",", "p1", ")", ",", "axis", "=", "1", ")", "<=", "distance", ")", "[", "0", "]", "\n", "p3", "=", "[", "p3_org", "[", "i", "]", "for", "i", "in", "np", ".", "intersect1d", "(", "close", ",", "not_too_close", ")", "]", "\n", "distance", "+=", "TRACK_WIDTH", "\n", "\n", "", "", "if", "len", "(", "p3", ")", "==", "0", ":", "\n", "                                ", "raise", "RuntimeError", "(", "'p3 lenght is zero'", ")", "\n", "\n", "", "d", "=", "(", "np", ".", "cross", "(", "np", ".", "subtract", "(", "p2", ",", "p1", ")", ",", "np", ".", "subtract", "(", "p1", ",", "p3", ")", ")", ")", "**", "2", "/", "np", ".", "linalg", ".", "norm", "(", "\n", "np", ".", "subtract", "(", "p2", ",", "p1", ")", ")", "\n", "points", ".", "append", "(", "p3", "[", "d", ".", "argmin", "(", ")", "]", ")", "\n", "\n", "", "if", "self", ".", "info", "[", "j", "]", "[", "'start'", "]", ":", "\n", "                            ", "vertices", "=", "[", "points", "[", "0", "]", ",", "points", "[", "1", "]", ",", "road1_r", ",", "road1_l", "]", "\n", "", "else", ":", "\n", "                            ", "vertices", "=", "[", "road2_r", ",", "road2_l", ",", "points", "[", "0", "]", ",", "points", "[", "1", "]", "]", "\n", "", "joint", "=", "True", "\n", "\n", "", "test_set", "=", "set", "(", "[", "tuple", "(", "p", ")", "for", "p", "in", "vertices", "]", ")", "\n", "if", "len", "(", "test_set", ")", ">=", "3", ":", "\n", "# TODO CHECK IF THIS AVOID THE ERROR OF ASSERTION COUNT >= 3", "\n", "# TODO remove this try and find a way of really catching the errer", "\n", "# try:", "\n", "                        ", "self", ".", "fd_tile", ".", "shape", ".", "vertices", "=", "vertices", "\n", "t", "=", "self", ".", "box2d", ".", "CreateStaticBody", "(", "fixtures", "=", "self", ".", "fd_tile", ")", "\n", "# except AssertionError as e:", "\n", "# print(str(e))", "\n", "# print(vertices)", "\n", "# return False", "\n", "t", ".", "userData", "=", "t", "\n", "i", "=", "0", "\n", "# changing the following i for j achives different colors when visited tiles", "\n", "c", "=", "0.01", "*", "(", "i", "%", "3", ")", "\n", "if", "joint", "and", "SHOW_JOINTS", ":", "\n", "                            ", "t", ".", "color", "=", "[", "1", ",", "1", ",", "1", "]", "\n", "", "else", ":", "\n", "# t.color = [ROAD_COLOR[0], ROAD_COLOR[1], ROAD_COLOR[2]]", "\n", "                            ", "t", ".", "color", "=", "[", "ROAD_COLOR", "[", "0", "]", "+", "c", ",", "ROAD_COLOR", "[", "1", "]", "+", "c", ",", "ROAD_COLOR", "[", "2", "]", "+", "c", "]", "\n", "", "t", ".", "road_visited", "=", "False", "\n", "t", ".", "typename", "=", "TILE_NAME", "\n", "t", ".", "road_friction", "=", "1.0", "\n", "t", ".", "id", "=", "j", "\n", "t", ".", "lane", "=", "lane", "\n", "t", ".", "fixtures", "[", "0", "]", ".", "sensor", "=", "True", "\n", "self", ".", "road_poly", ".", "append", "(", "(", "vertices", ",", "t", ".", "color", ",", "t", ".", "id", ",", "t", ".", "lane", ")", ")", "\n", "self", ".", "road", ".", "append", "(", "t", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "\"saved from error\"", ")", "\n", "\n", "", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._position_car_on_reset": [[833, 841], ["road_creator.RoadCreator.place_agent", "road_creator.RoadCreator.get_rnd_point_in_track"], "methods", ["None"], ["", "def", "_position_car_on_reset", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        This function takes care of placing the car in a position\n        at every reset call. This function should be modify to have\n        the desired behaviour of where the car appears, do not\n        re-spawn the car after the reset function has been called\n        \"\"\"", "\n", "self", ".", "place_agent", "(", "self", ".", "get_rnd_point_in_track", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._update_state": [[842, 848], ["None"], "methods", ["None"], ["", "def", "_update_state", "(", "self", ",", "new_frame", ")", ":", "\n", "        ", "if", "self", ".", "frames_per_state", ">", "1", ":", "\n", "            ", "self", ".", "state", "[", ":", ",", ":", ",", "-", "1", "]", "=", "new_frame", "\n", "self", ".", "state", "=", "self", ".", "state", "[", ":", ",", ":", ",", "self", ".", "_update_index", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "state", "=", "new_frame", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._transform_action": [[849, 862], ["None"], "methods", ["None"], ["", "", "def", "_transform_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "if", "self", ".", "discretize_actions", "==", "\"soft\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "", "elif", "self", ".", "discretize_actions", "==", "\"hard\"", ":", "\n", "# (\"NOTHING\", \"LEFT\", \"RIGHT\", \"ACCELERATE\", \"BREAK\")", "\n", "# angle, gas, break", "\n", "            ", "if", "action", "==", "0", ":", "action", "=", "[", "0", ",", "0", ",", "0.0", "]", "# Nothing", "\n", "if", "action", "==", "1", ":", "action", "=", "[", "-", "1", ",", "0", ",", "0.0", "]", "# Left", "\n", "if", "action", "==", "2", ":", "action", "=", "[", "+", "1", ",", "0", ",", "0.0", "]", "# Right", "\n", "if", "action", "==", "3", ":", "action", "=", "[", "0", ",", "+", "1", ",", "0.0", "]", "# Accelerate", "\n", "if", "action", "==", "4", ":", "action", "=", "[", "0", ",", "0", ",", "0.8", "]", "# break", "\n", "\n", "", "return", "action", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._remove_roads": [[863, 997], ["numpy.array", "numpy.array", "numpy.array", "range", "numpy.array", "set", "range", "numpy.delete", "numpy.array", "road_creator.RoadCreator._remove_roads._get_section"], "methods", ["None"], ["", "def", "_remove_roads", "(", "self", ")", ":", "\n", "\n", "        ", "if", "self", ".", "num_tracks", ">", "1", ":", "\n", "            ", "def", "_get_section", "(", "first", ",", "last", ",", "track", ")", ":", "\n", "                ", "sec", "=", "[", "]", "\n", "pos", "=", "0", "\n", "found", "=", "False", "\n", "while", "1", ":", "\n", "                    ", "point", "=", "track", "[", "pos", "%", "track", ".", "shape", "[", "0", "]", ",", ":", ",", "2", ":", "]", "\n", "if", "np", ".", "linalg", ".", "norm", "(", "point", "[", "1", "]", "-", "first", ")", "<=", "TRACK_WIDTH", "/", "2", ":", "\n", "                        ", "found", "=", "True", "\n", "", "if", "found", ":", "\n", "                        ", "sec", ".", "append", "(", "point", ")", "\n", "if", "np", ".", "linalg", ".", "norm", "(", "point", "[", "1", "]", "-", "last", ")", "<=", "TRACK_WIDTH", "/", "2", ":", "\n", "                            ", "break", "\n", "", "", "pos", "=", "pos", "+", "1", "\n", "if", "pos", "/", "track", ".", "shape", "[", "0", "]", ">=", "2", ":", "break", "\n", "", "if", "sec", "==", "[", "]", ":", "return", "False", "\n", "return", "np", ".", "array", "(", "sec", ")", "\n", "\n", "", "THRESHOLD", "=", "TRACK_WIDTH", "*", "2", "\n", "\n", "track1", "=", "np", ".", "array", "(", "self", ".", "tracks", "[", "0", "]", ")", "\n", "track2", "=", "np", ".", "array", "(", "self", ".", "tracks", "[", "1", "]", ")", "\n", "\n", "points1", "=", "track1", "[", ":", ",", ":", ",", "[", "2", ",", "3", "]", "]", "\n", "points2", "=", "track2", "[", ":", ",", ":", ",", "[", "2", ",", "3", "]", "]", "\n", "\n", "inter2", "=", "np", ".", "array", "(", "[", "x", "for", "x", "in", "points2", "if", "\n", "(", "np", ".", "linalg", ".", "norm", "(", "points1", "[", ":", ",", "1", ",", ":", "]", "-", "x", "[", "1", ":", "]", ",", "axis", "=", "1", ")", "<=", "TRACK_WIDTH", "/", "3.5", ")", ".", "sum", "(", ")", ">=", "1", "]", ")", "\n", "\n", "intersections", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "inter2", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "if", "np", ".", "array_equal", "(", "inter2", "[", "i", "-", "1", ",", "1", ",", ":", "]", ",", "inter2", "[", "i", ",", "0", ",", ":", "]", ")", "==", "False", "or", "np", ".", "array_equal", "(", "inter2", "[", "i", ",", "1", ",", ":", "]", ",", "\n", "inter2", "[", "(", "(", "\n", "i", "+", "1", ")", "%", "len", "(", "\n", "inter2", ")", ")", ",", "0", ",", "\n", ":", "]", ")", "==", "False", ":", "\n", "                    ", "intersections", ".", "append", "(", "inter2", "[", "i", "]", ")", "\n", "", "", "intersections", "=", "np", ".", "array", "(", "intersections", ")", "\n", "\n", "# For each point in intersection", "\n", "# > get section of both roads", "\n", "# > For each point in section in second road", "\n", "# > > get min distance", "\n", "# > get max of distances", "\n", "# if max dist < threshold remove", "\n", "removed_idx", "=", "set", "(", ")", "\n", "intersection_keys", "=", "[", "]", "\n", "intersection_vals", "=", "[", "]", "\n", "sec1_closer_to_center", "=", "None", "\n", "for", "i", "in", "range", "(", "intersections", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "_", ",", "first", "=", "intersections", "[", "i", "-", "1", "]", "\n", "last", ",", "_", "=", "intersections", "[", "i", "]", "\n", "\n", "sec1", "=", "_get_section", "(", "first", ",", "last", ",", "track1", ")", "\n", "sec2", "=", "_get_section", "(", "first", ",", "last", ",", "track2", ")", "\n", "\n", "sec1_distance_to_center", "=", "np", ".", "mean", "(", "np", ".", "linalg", ".", "norm", "(", "sec1", "[", "2", ":", "]", ",", "axis", "=", "1", ")", ")", "\n", "sec2_distance_to_center", "=", "np", ".", "mean", "(", "np", ".", "linalg", ".", "norm", "(", "sec2", "[", "2", ":", "]", ",", "axis", "=", "1", ")", ")", "\n", "\n", "if", "sec1", "is", "not", "False", "and", "sec2", "is", "not", "False", ":", "\n", "\n", "                    ", "remove", "=", "False", "\n", "if", "sec1_distance_to_center", ">", "sec2_distance_to_center", ":", "\n", "# sec1 is outside", "\n", "                        ", "if", "sec1_closer_to_center", "is", "False", ":", "\n", "                            ", "remove", "=", "True", "\n", "", "else", ":", "\n", "                            ", "sec1_closer_to_center", "=", "False", "\n", "", "", "else", ":", "\n", "# sec1 is inside", "\n", "                        ", "if", "sec1_closer_to_center", "is", "True", ":", "\n", "                            ", "remove", "=", "True", "\n", "", "else", ":", "\n", "                            ", "sec1_closer_to_center", "=", "True", "\n", "\n", "", "", "if", "remove", "is", "False", ":", "\n", "                        ", "max_min_d", "=", "0", "\n", "remove", "=", "False", "\n", "min_distances", "=", "[", "]", "\n", "for", "point", "in", "sec1", "[", ":", ",", "1", "]", ":", "\n", "                            ", "dist", "=", "np", ".", "linalg", ".", "norm", "(", "sec2", "[", ":", ",", "1", "]", "-", "point", ",", "axis", "=", "1", ")", ".", "min", "(", ")", "\n", "min_distances", ".", "append", "(", "dist", ")", "\n", "# min_d = dist if max_min_d < dist else max_min_d", "\n", "\n", "", "min_distances", "=", "np", ".", "array", "(", "min_distances", ")", "\n", "\n", "# if the max minimal distance is too small", "\n", "if", "min_distances", ".", "max", "(", ")", "<", "THRESHOLD", "*", "2", ":", "\n", "                            ", "remove", "=", "True", "\n", "# if the middle tiles of segment are too close to main track", "\n", "", "elif", "len", "(", "min_distances", ")", ">", "25", "and", "(", "min_distances", "[", "10", ":", "-", "10", "]", ".", "min", "(", ")", "<", "TRACK_WIDTH", "*", "3", ")", ":", "\n", "                            ", "remove", "=", "True", "\n", "# if the segment is smaller than MIN_SEGMENT_LENGHT", "\n", "", "elif", "len", "(", "min_distances", ")", "<", "MIN_SEGMENT_LENGHT", ":", "\n", "                            ", "remove", "=", "True", "\n", "# if there are more than 50 tiles very close to main track", "\n", "", "elif", "len", "(", "min_distances", ")", ">", "50", "and", "(", "min_distances", "<", "TRACK_WIDTH", "*", "2", ")", ".", "sum", "(", ")", ">", "50", ":", "\n", "                            ", "remove", "=", "True", "\n", "\n", "# Removing tiles", "\n", "", "", "if", "remove", ":", "\n", "                        ", "for", "point", "in", "sec2", ":", "\n", "                            ", "idx", "=", "np", ".", "all", "(", "track2", "[", ":", ",", ":", ",", "[", "2", ",", "3", "]", "]", "==", "point", ",", "axis", "=", "(", "1", ",", "2", ")", ")", "\n", "removed_idx", ".", "update", "(", "np", ".", "where", "(", "idx", ")", "[", "0", "]", ")", "\n", "", "", "else", ":", "\n", "                        ", "key", "=", "np", ".", "where", "(", "\n", "np", ".", "all", "(", "track1", "[", ":", ",", ":", ",", "[", "2", ",", "3", "]", "]", "==", "sec1", "[", "0", "]", ",", "axis", "=", "(", "1", ",", "2", ")", ")", ")", "[", "0", "]", "\n", "val", "=", "np", ".", "where", "(", "\n", "np", ".", "all", "(", "track2", "[", ":", ",", ":", ",", "[", "2", ",", "3", "]", "]", "==", "sec2", "[", "0", "]", ",", "axis", "=", "(", "1", ",", "2", ")", ")", ")", "[", "0", "]", "+", "len", "(", "track1", ")", "\n", "intersection_keys", ".", "append", "(", "key", "[", "0", "]", ")", "\n", "intersection_vals", ".", "append", "(", "val", "[", "0", "]", ")", "\n", "\n", "key", "=", "np", ".", "where", "(", "\n", "np", ".", "all", "(", "track1", "[", ":", ",", ":", ",", "[", "2", ",", "3", "]", "]", "==", "sec1", "[", "-", "1", "]", ",", "axis", "=", "(", "1", ",", "2", ")", ")", ")", "[", "0", "]", "\n", "val", "=", "np", ".", "where", "(", "\n", "np", ".", "all", "(", "track2", "[", ":", ",", ":", ",", "[", "2", ",", "3", "]", "]", "==", "sec2", "[", "-", "1", "]", ",", "axis", "=", "(", "1", ",", "2", ")", ")", ")", "[", "0", "]", "+", "len", "(", "track1", ")", "\n", "intersection_keys", ".", "append", "(", "key", "[", "0", "]", ")", "\n", "intersection_vals", ".", "append", "(", "val", "[", "0", "]", ")", "\n", "\n", "", "", "", "track2", "=", "np", ".", "delete", "(", "track2", ",", "list", "(", "removed_idx", ")", ",", "axis", "=", "0", ")", "# efficient way to delete them from np.array", "\n", "\n", "self", ".", "intersections", "=", "intersections", "\n", "\n", "if", "len", "(", "track1", ")", "==", "0", "or", "len", "(", "track2", ")", "==", "0", ":", "\n", "                ", "return", "False", "\n", "\n", "", "self", ".", "tracks", "[", "0", "]", "=", "track1", "\n", "self", ".", "tracks", "[", "1", "]", "=", "track2", "\n", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadViewer.__init__": [[17, 20], ["multiagent.rendering.Viewer.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "width", ",", "height", ")", ":", "\n", "        ", "super", "(", "RoadViewer", ",", "self", ")", ".", "__init__", "(", "width", ",", "height", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadViewer.set_bounds_at_angle": [[21, 35], ["numpy.array", "numpy.array", "numpy.dot", "multiagent.rendering.Transform", "numpy.cos", "numpy.sin"], "methods", ["None"], ["", "def", "set_bounds_at_angle", "(", "self", ",", "left", ",", "right", ",", "bottom", ",", "top", ",", "angle", ")", ":", "\n", "        ", "assert", "right", ">", "left", "and", "top", ">", "bottom", "\n", "# assert angle > 0 and angle < 2*np.pi", "\n", "scalex", "=", "self", ".", "width", "/", "(", "right", "-", "left", ")", "\n", "scaley", "=", "self", ".", "height", "/", "(", "top", "-", "bottom", ")", "\n", "p", "=", "np", ".", "array", "(", "[", "(", "right", "+", "left", ")", "/", "2", "*", "scalex", ",", "(", "top", "+", "bottom", ")", "/", "2", "*", "scaley", "]", ")", "\n", "c", ",", "s", "=", "np", ".", "cos", "(", "angle", ")", ",", "np", ".", "sin", "(", "angle", ")", "\n", "R", "=", "np", ".", "array", "(", "(", "(", "c", ",", "-", "s", ")", ",", "(", "s", ",", "c", ")", ")", ")", "\n", "p", "=", "np", ".", "dot", "(", "R", ",", "p", ")", "\n", "x_new", ",", "y_new", "=", "p", "[", "0", "]", ",", "p", "[", "1", "]", "\n", "self", ".", "transform", "=", "Transform", "(", "\n", "translation", "=", "(", "self", ".", "width", "/", "2", "-", "x_new", ",", "self", ".", "height", "/", "2", "-", "y_new", ")", ",", "\n", "scale", "=", "(", "scalex", ",", "scaley", ")", ",", "\n", "rotation", "=", "angle", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.__init__": [[39, 62], ["multiagent.core.World.__init__", "road_world.FrictionDetector", "Box2D.b2World", "Box2D.b2.fixtureDef", "Box2D.b2.polygonShape"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "RoadWorld", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "track", "=", "None", "\n", "self", ".", "road", "=", "None", "\n", "self", ".", "road_poly", "=", "[", "]", "\n", "self", ".", "contactListener_keepref", "=", "FrictionDetector", "(", "self", ")", "\n", "self", ".", "box2d", "=", "Box2D", ".", "b2World", "(", "(", "0", ",", "0", ")", ",", "contactListener", "=", "self", ".", "contactListener_keepref", ")", "\n", "\n", "self", ".", "fd_tile", "=", "fixtureDef", "(", "\n", "shape", "=", "polygonShape", "(", "vertices", "=", "[", "(", "0", ",", "0", ")", ",", "(", "1", ",", "0", ")", ",", "(", "1", ",", "-", "1", ")", ",", "(", "0", ",", "-", "1", ")", "]", ")", ")", "\n", "\n", "self", ".", "shared_viewer", "=", "False", "\n", "self", ".", "top_views", "=", "[", "]", "\n", "self", ".", "car_physics", "=", "False", "\n", "\n", "self", ".", "load_tracks_from", "=", "None", "\n", "self", ".", "num_tracks", "=", "2", "\n", "self", ".", "num_lanes_changes", "=", "0", "\n", "self", ".", "num_lanes", "=", "2", "\n", "self", ".", "max_single_lane", "=", "0", "\n", "self", ".", "verbose", "=", "0", "\n", "self", ".", "border_poly", "=", "[", "]", "\n", "self", ".", "road", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.set_agents": [[63, 71], ["len", "len"], "methods", ["None"], ["", "def", "set_agents", "(", "self", ",", "agents", ")", ":", "\n", "        ", "self", ".", "agents", "=", "agents", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "\n", "self", ".", "transforms", "=", "[", "None", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "viewers", "=", "[", "None", "]", "*", "len", "(", "self", ".", "agents", ")", "\n", "self", ".", "transforms", "=", "[", "None", "]", "*", "len", "(", "self", ".", "agents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._reset_viewers": [[72, 81], ["range", "len", "road_world.RoadViewer", "rendering.Transform"], "methods", ["None"], ["", "", "def", "_reset_viewers", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "# create viewers (if necessary)", "\n", "            ", "if", "self", ".", "viewers", "[", "i", "]", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "#from gym.envs.classic_control import rendering", "\n", "                ", "from", "multiagent", "import", "rendering", "\n", "self", ".", "viewers", "[", "i", "]", "=", "RoadViewer", "(", "STATE_W", ",", "STATE_H", ")", "\n", "self", ".", "transforms", "[", "i", "]", "=", "rendering", ".", "Transform", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._reset_render": [[82, 85], ["None"], "methods", ["None"], ["", "", "", "def", "_reset_render", "(", "self", ")", ":", "\n", "        ", "self", ".", "render_geoms", "=", "None", "\n", "self", ".", "render_geoms_xform", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._add_geoms_to_viewer": [[86, 116], ["enumerate", "rendering.Transform", "geom.add_attr", "road_world.RoadWorld.render_geoms.append", "road_world.RoadWorld.render_geoms_xform.append", "rendering.make_circle", "rendering.make_polygon_with_hole", "geom.set_color", "black_list.append", "viewer.add_geom", "geom.set_color", "geom.set_color"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Geom.add_attr", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_circle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.make_polygon_with_hole", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Viewer.add_geom", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.FilledPolygonWithHole.set_color"], ["", "def", "_add_geoms_to_viewer", "(", "self", ")", ":", "\n", "        ", "black_list", "=", "[", "]", "# not render agent in its own viewer", "\n", "# create rendering geometry", "\n", "if", "self", ".", "render_geoms", "is", "None", ":", "\n", "# import rendering only if we need it (and don't import for headless machines)", "\n", "# from gym.envs.classic_control import rendering", "\n", "            ", "from", "multiagent", "import", "rendering", "\n", "self", ".", "render_geoms", "=", "[", "]", "\n", "self", ".", "render_geoms_xform", "=", "[", "]", "\n", "for", "entity", "in", "self", ".", "entities", ":", "\n", "                ", "geom", "=", "rendering", ".", "make_circle", "(", "\n", "entity", ".", "size", ")", "if", "'surface'", "not", "in", "entity", ".", "name", "else", "rendering", ".", "make_polygon_with_hole", "(", "entity", ".", "poly", ")", "\n", "xform", "=", "rendering", ".", "Transform", "(", ")", "\n", "if", "'agent'", "in", "entity", ".", "name", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ",", "alpha", "=", "0.5", ")", "\n", "black_list", ".", "append", "(", "geom", ")", "\n", "", "elif", "'surface'", "in", "entity", ".", "name", ":", "\n", "                    ", "geom", ".", "set_color", "(", "entity", ".", "color", ")", "\n", "", "else", ":", "\n", "                    ", "geom", ".", "set_color", "(", "*", "entity", ".", "color", ")", "\n", "", "geom", ".", "add_attr", "(", "xform", ")", "\n", "self", ".", "render_geoms", ".", "append", "(", "geom", ")", "\n", "self", ".", "render_geoms_xform", ".", "append", "(", "xform", ")", "\n", "\n", "# add geoms to viewer", "\n", "", "for", "i", ",", "viewer", "in", "enumerate", "(", "self", ".", "viewers", ")", ":", "\n", "                ", "viewer", ".", "geoms", "=", "[", "]", "\n", "for", "geom", "in", "self", ".", "render_geoms", ":", "\n", "                    ", "if", "geom", "==", "black_list", "[", "i", "]", ":", "continue", "\n", "viewer", ".", "add_geom", "(", "geom", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._create_top_view": [[117, 134], ["range", "len", "road_world.RoadWorld.viewers[].set_bounds_at_angle", "enumerate", "road_world.RoadWorld.top_views.append", "numpy.zeros", "road_world.RoadWorld.render_geoms_xform[].set_translation", "road_world.RoadWorld.viewers[].render"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadViewer.set_bounds_at_angle", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.Transform.set_translation", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["", "", "", "", "def", "_create_top_view", "(", "self", ")", ":", "\n", "        ", "self", ".", "top_views", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "viewers", ")", ")", ":", "\n", "            ", "from", "multiagent", "import", "rendering", "\n", "# update bounds to center around agent", "\n", "cam_range", "=", "1", "if", "self", ".", "shared_viewer", "else", ".1", "\n", "if", "self", ".", "shared_viewer", ":", "\n", "                ", "pos", "=", "np", ".", "zeros", "(", "self", ".", "dim_p", ")", "\n", "", "else", ":", "\n", "                ", "pos", "=", "self", ".", "agents", "[", "i", "]", ".", "state", ".", "p_pos", "\n", "", "angle", "=", "-", "self", ".", "agents", "[", "i", "]", ".", "state", ".", "angle", "\n", "self", ".", "viewers", "[", "i", "]", ".", "set_bounds_at_angle", "(", "pos", "[", "0", "]", "-", "cam_range", ",", "pos", "[", "0", "]", "+", "cam_range", ",", "pos", "[", "1", "]", "-", "cam_range", ",", "pos", "[", "1", "]", "+", "cam_range", ",", "angle", ")", "\n", "# update geometry positions", "\n", "for", "e", ",", "entity", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "                ", "self", ".", "render_geoms_xform", "[", "e", "]", ".", "set_translation", "(", "*", "entity", ".", "state", ".", "p_pos", ")", "\n", "# render to display or array", "\n", "", "self", ".", "top_views", ".", "append", "(", "self", ".", "viewers", "[", "i", "]", ".", "render", "(", "return_rgb_array", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.get_views": [[135, 140], ["len", "numpy.random.rand", "len"], "methods", ["None"], ["", "", "def", "get_views", "(", "self", ")", ":", "\n", "        ", "if", "len", "(", "self", ".", "top_views", ")", "==", "0", ":", "\n", "            ", "self", ".", "top_views", "=", "np", ".", "random", ".", "rand", "(", "len", "(", "self", ".", "agents", ")", ",", "STATE_W", ",", "STATE_H", ",", "3", ")", "\n", "\n", "", "return", "self", ".", "top_views", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.propagate": [[141, 145], ["numpy.cos", "numpy.sin"], "methods", ["None"], ["", "def", "propagate", "(", "self", ",", "agent", ")", ":", "\n", "        ", "agent", ".", "state", ".", "angle", "=", "agent", ".", "state", ".", "angle", "+", "agent", ".", "action", ".", "r", "\n", "agent", ".", "state", ".", "p_vel", "[", "0", "]", "=", "agent", ".", "action", ".", "v", "*", "np", ".", "cos", "(", "agent", ".", "state", ".", "angle", "+", "np", ".", "pi", "/", "2", ")", "\n", "agent", ".", "state", ".", "p_vel", "[", "1", "]", "=", "agent", ".", "action", ".", "v", "*", "np", ".", "sin", "(", "agent", ".", "state", ".", "angle", "+", "np", ".", "pi", "/", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.integrate_state": [[147, 160], ["enumerate", "road_world.RoadWorld.propagate", "numpy.sqrt", "numpy.square", "numpy.square", "numpy.sqrt", "numpy.square", "numpy.square"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.propagate"], ["", "def", "integrate_state", "(", "self", ",", "p_force", ")", ":", "\n", "        ", "for", "i", ",", "entity", "in", "enumerate", "(", "self", ".", "entities", ")", ":", "\n", "            ", "if", "not", "entity", ".", "movable", ":", "continue", "\n", "self", ".", "propagate", "(", "entity", ")", "\n", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "*", "(", "1", "-", "self", ".", "damping", ")", "\n", "if", "(", "p_force", "[", "i", "]", "is", "not", "None", ")", ":", "\n", "                ", "entity", ".", "state", ".", "p_vel", "+=", "(", "p_force", "[", "i", "]", "/", "entity", ".", "mass", ")", "*", "self", ".", "dt", "\n", "", "if", "entity", ".", "max_speed", "is", "not", "None", ":", "\n", "                ", "speed", "=", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "\n", "if", "speed", ">", "entity", ".", "max_speed", ":", "\n", "                    ", "entity", ".", "state", ".", "p_vel", "=", "entity", ".", "state", ".", "p_vel", "/", "np", ".", "sqrt", "(", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "0", "]", ")", "+", "\n", "np", ".", "square", "(", "entity", ".", "state", ".", "p_vel", "[", "1", "]", ")", ")", "*", "entity", ".", "max_speed", "\n", "", "", "entity", ".", "state", ".", "p_pos", "+=", "entity", ".", "state", ".", "p_vel", "*", "self", ".", "dt", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step": [[162, 188], ["road_world.RoadWorld._reset_render", "road_world.RoadWorld._reset_viewers", "road_world.RoadWorld._add_geoms_to_viewer", "road_world.RoadWorld._create_top_view", "agent.action_callback", "len", "road_world.RoadWorld.box2d.Step", "road_world.RoadWorld.integrate_state", "road_world.RoadWorld.update_agent_state", "agent.transform_action_car_input", "agent.body.step", "agent.update_state", "agent.transform_action"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._reset_render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._reset_viewers", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._add_geoms_to_viewer", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._create_top_view", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.integrate_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.core.World.update_agent_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAgent.transform_action_car_input", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAgent.update_state", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.dynamic_agent.DynamicAgent.transform_action"], ["", "", "def", "step", "(", "self", ")", ":", "\n", "        ", "self", ".", "_reset_render", "(", ")", "\n", "self", ".", "_reset_viewers", "(", ")", "\n", "self", ".", "_add_geoms_to_viewer", "(", ")", "\n", "self", ".", "_create_top_view", "(", ")", "\n", "# set actions for scripted agents", "\n", "for", "agent", "in", "self", ".", "scripted_agents", ":", "\n", "            ", "agent", ".", "action", "=", "agent", ".", "action_callback", "(", "agent", ",", "self", ")", "\n", "# gather forces applied to entities", "\n", "", "p_force", "=", "[", "None", "]", "*", "len", "(", "self", ".", "entities", ")", "\n", "# apply agent physical controls", "\n", "if", "self", ".", "car_physics", ":", "\n", "            ", "for", "agent", "in", "self", ".", "agents", ":", "\n", "                ", "agent", ".", "transform_action_car_input", "(", ")", "\n", "agent", ".", "body", ".", "step", "(", "1.0", "/", "FPS", ")", "\n", "", "self", ".", "box2d", ".", "Step", "(", "1.0", "/", "FPS", ",", "6", "*", "30", ",", "2", "*", "30", ")", "\n", "for", "agent", "in", "self", ".", "agents", ":", "\n", "                ", "agent", ".", "update_state", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "for", "agent", "in", "self", ".", "agents", ":", "\n", "                ", "agent", ".", "transform_action", "(", ")", "\n", "", "self", ".", "integrate_state", "(", "p_force", ")", "\n", "\n", "# update agent state", "\n", "", "for", "agent", "in", "self", ".", "agents", ":", "\n", "            ", "self", ".", "update_agent_state", "(", "agent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._destroy": [[189, 195], ["road_world.RoadWorld.box2d.DestroyBody"], "methods", ["None"], ["", "", "def", "_destroy", "(", "self", ")", ":", "\n", "        ", "if", "not", "self", ".", "road", ":", "\n", "            ", "return", "\n", "", "for", "t", "in", "self", ".", "road", ":", "\n", "            ", "self", ".", "box2d", ".", "DestroyBody", "(", "t", ")", "\n", "", "self", ".", "road", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset": [[196, 215], ["road_world.RoadWorld._destroy", "numpy.array", "numpy.vstack", "road_world.RoadWorld._create_single_track", "road_world.RoadWorld._create_track", "enumerate"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld._destroy", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._create_single_track", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_creator.RoadCreator._create_track"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_destroy", "(", ")", "\n", "self", ".", "road_poly", "=", "[", "]", "\n", "\n", "if", "self", ".", "num_lanes", "==", "1", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "success", "=", "self", ".", "_create_single_track", "(", ")", "\n", "if", "success", ":", "break", "\n", "\n", "", "self", ".", "road_poly", "=", "[", "[", "poly", ",", "color", ",", "i", ",", "0", "]", "for", "i", ",", "(", "poly", ",", "color", ")", "in", "enumerate", "(", "self", ".", "road_poly", ")", "]", "\n", "\n", "", "else", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "success", "=", "self", ".", "_create_track", "(", ")", "\n", "if", "success", ":", "break", "\n", "\n", "", "self", ".", "track", "=", "np", ".", "vstack", "(", "(", "self", ".", "track", "[", ":", ",", "1", "]", ",", "self", ".", "track", "[", ":", ",", "0", "]", ")", ")", "\n", "\n", "", "self", ".", "road_poly", "=", "np", ".", "array", "(", "self", ".", "road_poly", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__": [[218, 221], ["Box2D.b2.contactListener.__init__"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.__init__"], ["    ", "def", "__init__", "(", "self", ",", "env", ")", ":", "\n", "        ", "contactListener", ".", "__init__", "(", "self", ")", "\n", "self", ".", "env", "=", "env", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.BeginContact": [[222, 224], ["road_world.FrictionDetector._contact"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector._contact"], ["", "def", "BeginContact", "(", "self", ",", "contact", ")", ":", "\n", "        ", "self", ".", "_contact", "(", "contact", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector.EndContact": [[225, 227], ["road_world.FrictionDetector._contact"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector._contact"], ["", "def", "EndContact", "(", "self", ",", "contact", ")", ":", "\n", "        ", "self", ".", "_contact", "(", "contact", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.FrictionDetector._contact": [[228, 253], ["obj.tiles.add", "obj.tiles.remove"], "methods", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.deepq.replay_buffer.PrioritizedReplayBuffer.add"], ["", "def", "_contact", "(", "self", ",", "contact", ",", "begin", ")", ":", "\n", "        ", "tile", "=", "None", "\n", "obj", "=", "None", "\n", "u1", "=", "contact", ".", "fixtureA", ".", "body", ".", "userData", "\n", "u2", "=", "contact", ".", "fixtureB", ".", "body", ".", "userData", "\n", "if", "u1", "and", "\"road_friction\"", "in", "u1", ".", "__dict__", ":", "\n", "            ", "tile", "=", "u1", "\n", "obj", "=", "u2", "\n", "", "if", "u2", "and", "\"road_friction\"", "in", "u2", ".", "__dict__", ":", "\n", "            ", "tile", "=", "u2", "\n", "obj", "=", "u1", "\n", "", "if", "not", "tile", ":", "\n", "            ", "return", "\n", "\n", "", "tile", ".", "color", "[", "0", "]", "=", "ROAD_COLOR", "[", "0", "]", "\n", "tile", ".", "color", "[", "1", "]", "=", "ROAD_COLOR", "[", "1", "]", "\n", "tile", ".", "color", "[", "2", "]", "=", "ROAD_COLOR", "[", "2", "]", "\n", "if", "not", "obj", "or", "\"tiles\"", "not", "in", "obj", ".", "__dict__", ":", "\n", "            ", "return", "\n", "", "if", "begin", ":", "\n", "            ", "obj", ".", "tiles", ".", "add", "(", "tile", ")", "\n", "if", "not", "tile", ".", "road_visited", ":", "\n", "                ", "tile", ".", "road_visited", "=", "True", "\n", "", "", "else", ":", "\n", "            ", "obj", ".", "tiles", ".", "remove", "(", "tile", ")", "", "", "", "", ""]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_action_data.print_table": [[10, 47], ["numpy.load", "numpy.load", "matplotlib.rc", "range", "plot_path.mkdir", "matplotlib.subplots", "ax.bar", "range", "ax.set_ylabel", "matplotlib.tight_layout", "f.savefig", "matplotlib.close", "pathlib.Path", "all_actions[].sum", "numpy.arange", "ax.bar", "ax.set_xlabel", "ax.set_xlabel", "all_actions[].sum", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["def", "print_table", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "(", "Path", "(", "'../models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "/", "(", "'run%i'", "%", "config", ".", "run_num", ")", ")", "\n", "if", "config", ".", "incremental", "is", "not", "None", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "config", ".", "incremental", ")", "\n", "", "else", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'model.pt'", "\n", "\n", "", "if", "config", ".", "save_plots", ":", "\n", "        ", "plot_path", "=", "model_path", ".", "parent", "/", "'plots'", "\n", "plot_path", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "", "stats_path", "=", "model_path", ".", "parent", "/", "'stats'", "\n", "all_infos", "=", "load", "(", "f'{stats_path}/all_infos.npy'", ")", "\n", "all_actions", "=", "load", "(", "f'{stats_path}/all_actions.npy'", ")", "\n", "\n", "plt", ".", "rc", "(", "'font'", ",", "family", "=", "'serif'", ")", "\n", "n_episodes", ",", "episode_length", ",", "n_agents", ",", "dim_a", "=", "all_actions", ".", "shape", "\n", "for", "a", "in", "range", "(", "n_agents", ")", ":", "\n", "        ", "if", "config", ".", "save_plots", ":", "\n", "            ", "width", "=", "0.1", "\n", "f", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "3", ",", "3", ")", ")", "\n", "bottom_data", "=", "all_actions", "[", "0", ",", ":", ",", "a", "]", ".", "sum", "(", "0", ")", "/", "episode_length", "\n", "ax", ".", "bar", "(", "np", ".", "arange", "(", "dim_a", ")", ",", "bottom_data", ")", "\n", "for", "ep_i", "in", "range", "(", "1", ",", "n_episodes", ")", ":", "\n", "                ", "data", "=", "all_actions", "[", "ep_i", ",", ":", ",", "a", "]", ".", "sum", "(", "0", ")", "/", "episode_length", "\n", "ax", ".", "bar", "(", "np", ".", "arange", "(", "dim_a", ")", ",", "data", ",", "bottom", "=", "bottom_data", ")", "\n", "bottom_data", "+=", "data", "\n", "# ax.set_ylim([0,1])", "\n", "", "if", "a", "==", "0", ":", "\n", "                ", "ax", ".", "set_xlabel", "(", "'Symbol'", ",", "fontsize", "=", "11", ")", "\n", "", "else", ":", "\n", "                ", "ax", ".", "set_xlabel", "(", "'Action'", ",", "fontsize", "=", "11", ")", "\n", "", "ax", ".", "set_ylabel", "(", "'Frequency'", ",", "fontsize", "=", "11", ")", "\n", "# ax.set_title(config.model_name)", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "f", ".", "savefig", "(", "f'{plot_path}/{config.model_name}_agent_{a}_actions.png'", ")", "\n", "plt", ".", "close", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.make_video.run": [[12, 74], ["torch.manual_seed", "numpy.random.seed", "utils.make_env.make_env", "utils.make_env.make_env.seed", "MADDPG.init_from_save.prep_rollouts", "range", "utils.make_env.make_env.close", "gif_path.mkdir", "algorithms.maddpg.MADDPG.init_from_directory", "algorithms.maddpg.MADDPG.init_from_save", "print", "utils.make_env.make_env.reset", "utils.make_env.make_env.render", "range", "frames.append", "time.time", "MADDPG.init_from_save.step", "utils.make_env.make_env.step", "time.time", "utils.make_env.make_env.render", "imageio.mimsave", "pathlib.Path", "ac.data.numpy().flatten", "frames.append", "time.sleep", "str", "pathlib.Path", "utils.make_env.make_env.render", "torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.Tensor().view", "torch.Tensor", "ac.data.numpy", "utils.make_env.make_env.render", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_directory", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.dummy_vec_env.DummyVecEnv.render"], ["def", "run", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "(", "Path", "(", "'models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "/", "\n", "(", "'run%i'", "%", "config", ".", "run_num", ")", ")", "\n", "if", "config", ".", "incremental", "is", "not", "None", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "\n", "config", ".", "incremental", ")", "\n", "", "else", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'model.pt'", "\n", "\n", "", "if", "config", ".", "save_gifs", ":", "\n", "        ", "gif_path", "=", "model_path", ".", "parent", "/", "'gifs'", "if", "not", "config", ".", "mixed_policies", "else", "model_path", ".", "parent", "/", "'gifs_mixed'", "\n", "gif_path", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "", "torch", ".", "manual_seed", "(", "config", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "config", ".", "seed", ")", "\n", "if", "config", ".", "mixed_policies", ":", "\n", "        ", "maddpg", "=", "MADDPG", ".", "init_from_directory", "(", "Path", "(", "'../models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", ")", "\n", "", "else", ":", "\n", "        ", "maddpg", "=", "MADDPG", ".", "init_from_save", "(", "model_path", ")", "\n", "", "env", "=", "make_env", "(", "config", ".", "env_id", ",", "benchmark", "=", "True", ",", "discrete_action", "=", "maddpg", ".", "discrete_action", ")", "\n", "env", ".", "seed", "(", "config", ".", "seed", ")", "\n", "maddpg", ".", "prep_rollouts", "(", "device", "=", "'cpu'", ")", "\n", "ifi", "=", "1", "/", "config", ".", "fps", "# inter-frame interval", "\n", "\n", "for", "ep_i", "in", "range", "(", "config", ".", "n_episodes", ")", ":", "\n", "        ", "print", "(", "\"Episode %i of %i\"", "%", "(", "ep_i", "+", "1", ",", "config", ".", "n_episodes", ")", ")", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "if", "config", ".", "save_gifs", ":", "\n", "            ", "frames", "=", "[", "]", "\n", "frames", ".", "append", "(", "env", ".", "render", "(", "'rgb_array'", ")", "[", "0", "]", ")", "\n", "", "env", ".", "render", "(", "'human'", ")", "\n", "# env.agents[1].state.p_pos = np.array([0., 0.])", "\n", "for", "t_i", "in", "range", "(", "config", ".", "episode_length", ")", ":", "\n", "            ", "calc_start", "=", "time", ".", "time", "(", ")", "\n", "# rearrange observations to be per agent, and convert to torch Variable", "\n", "torch_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "obs", "[", "i", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", ",", "\n", "requires_grad", "=", "False", ")", "if", "not", "obs", "[", "i", "]", ".", "ndim", "==", "4", "else", "Variable", "(", "torch", ".", "Tensor", "(", "obs", "[", "i", "]", ")", ",", "requires_grad", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "maddpg", ".", "nagents", ")", "]", "\n", "\n", "# get actions as torch Variables", "\n", "torch_actions", "=", "maddpg", ".", "step", "(", "torch_obs", ",", "explore", "=", "False", ")", "\n", "# convert actions to numpy arrays", "\n", "actions", "=", "[", "ac", ".", "data", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "for", "ac", "in", "torch_actions", "]", "\n", "# actions[0] = np.array([0., 0., 0., 0., 0.], dtype=np.float32)", "\n", "obs", ",", "rewards", ",", "dones", ",", "infos", "=", "env", ".", "step", "(", "actions", ")", "\n", "\n", "if", "config", ".", "save_gifs", ":", "\n", "                ", "frames", ".", "append", "(", "env", ".", "render", "(", "'rgb_array'", ")", "[", "0", "]", ")", "\n", "# frames.append(env.world.viewers[0].render(return_rgb_array = True)) uncomment if local views visible", "\n", "", "calc_end", "=", "time", ".", "time", "(", ")", "\n", "elapsed", "=", "calc_end", "-", "calc_start", "\n", "if", "elapsed", "<", "ifi", ":", "\n", "                ", "time", ".", "sleep", "(", "ifi", "-", "elapsed", ")", "\n", "", "env", ".", "render", "(", "'human'", ")", "\n", "\n", "", "if", "config", ".", "save_gifs", ":", "\n", "            ", "gif_num", "=", "0", "\n", "while", "(", "gif_path", "/", "(", "'%i_%i.gif'", "%", "(", "gif_num", ",", "ep_i", ")", ")", ")", ".", "exists", "(", ")", ":", "\n", "                ", "gif_num", "+=", "1", "\n", "", "imageio", ".", "mimsave", "(", "str", "(", "gif_path", "/", "(", "'%i_%i.gif'", "%", "(", "gif_num", ",", "ep_i", ")", ")", ")", ",", "\n", "frames", ",", "duration", "=", "ifi", ")", "\n", "", "", "env", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_time_series.load_data": [[16, 27], ["numpy.load", "PIL.Image.open", "numpy.load", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load"], ["def", "load_data", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "(", "Path", "(", "'../models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "/", "(", "'run%i'", "%", "config", ".", "run_num", ")", ")", "\n", "model_path", "=", "model_path", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "config", ".", "incremental", ")", "if", "config", ".", "incremental", "is", "not", "None", "else", "model_path", "/", "'model.pt'", "\n", "stats_path", "=", "model_path", ".", "parent", "/", "'stats'", "\n", "gif_path", "=", "model_path", ".", "parent", "/", "'gifs'", "\n", "\n", "# Load data to be plotted", "\n", "all_infos", "=", "load", "(", "f'{stats_path}/all_infos.npy'", ")", "\n", "all_images", "=", "Image", ".", "open", "(", "f'{gif_path}/0_{config.ep_num}.gif'", ")", "\n", "all_positions", "=", "load", "(", "f'{stats_path}/all_positions.npy'", ")", "\n", "return", "all_infos", ",", "all_images", ",", "all_positions", ",", "stats_path", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_time_series.plot_snapshots_grid": [[29, 52], ["numpy.arange", "scipy.ndimage.filters.gaussian_filter1d", "matplotlib.figure", "matplotlib.GridSpec", "enumerate", "matplotlib.subplot", "plt.subplot.plot", "plt.subplot.set_xticks", "plt.subplot.xaxis.grid", "matplotlib.savefig", "len", "PIL.ImageSequence.Iterator", "matplotlib.subplot", "plt.subplot.set_xlabel", "plt.subplot.set_xlabel", "plt.subplot.set_ylabel", "numpy.arange", "plt.subplot.imshow", "plt.subplot.set_xticks", "plt.subplot.set_yticks"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.rendering.SimpleImageViewer.imshow"], ["", "def", "plot_snapshots_grid", "(", "config", ",", "all_infos", ",", "all_images", ",", "all_positions", ",", "stats_path", ")", ":", "\n", "    ", "t", "=", "np", ".", "arange", "(", "len", "(", "all_infos", "[", "config", ".", "ep_num", "]", ")", ")", "\n", "r", "=", "all_infos", "[", "config", ".", "ep_num", ",", ":", ",", "0", ",", "0", "]", "\n", "r_smooth", "=", "gaussian_filter1d", "(", "r", ",", "sigma", "=", "2", ")", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "65", ",", "20", ")", ")", "\n", "n_cols", "=", "all_images", ".", "n_frames", "\n", "grid", "=", "plt", ".", "GridSpec", "(", "nrows", "=", "3", ",", "ncols", "=", "n_cols", ",", "wspace", "=", "0.1", ",", "hspace", "=", "0.3", ",", "figure", "=", "fig", ")", "\n", "\n", "# Snapshots", "\n", "for", "i", ",", "frame", "in", "enumerate", "(", "ImageSequence", ".", "Iterator", "(", "all_images", ")", ")", ":", "\n", "        ", "grid_ax", "=", "plt", ".", "subplot", "(", "grid", "[", "0", ",", "i", "]", ")", "\n", "grid_ax", ".", "imshow", "(", "frame", ")", ",", "grid_ax", ".", "set_xticks", "(", "[", "]", ")", ",", "grid_ax", ".", "set_yticks", "(", "[", "]", ")", "\n", "grid_ax", ".", "set_xlabel", "(", "f\"t={i}\"", ")", "\n", "\n", "# Rewards", "\n", "", "grid_ax", "=", "plt", ".", "subplot", "(", "grid", "[", "1", ",", ":", "]", ")", "\n", "grid_ax", ".", "plot", "(", "t", ",", "r_smooth", ",", "linestyle", "=", "'solid'", ",", "linewidth", "=", "5", ",", "color", "=", "colors", "[", "0", "]", ")", "\n", "grid_ax", ".", "set_xlabel", "(", "'time (s)'", ")", ",", "grid_ax", ".", "set_ylabel", "(", "'Reward'", ",", "color", "=", "colors", "[", "0", "]", ")", "\n", "grid_ax", ".", "set_xticks", "(", "np", ".", "arange", "(", "n_cols", ")", ")", "\n", "grid_ax", ".", "xaxis", ".", "grid", "(", ")", "\n", "\n", "plt", ".", "savefig", "(", "f'{stats_path}/rewards_snapshots_episode_{config.ep_num}.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_time_series.plot_all_in_one": [[54, 69], ["len", "numpy.around", "range", "PIL.Image.blend", "range", "PIL.Image.blend", "Image.blend.save", "list", "numpy.linspace", "math.floor", "[].convert", "PIL.Image.blend", "PIL.ImageSequence.Iterator", "PIL.ImageSequence.Iterator"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save"], ["", "def", "plot_all_in_one", "(", "config", ",", "all_infos", ",", "all_images", ",", "all_positions", ",", "stats_path", ",", "alpha", "=", "0.01", ")", ":", "\n", "    ", "n_tot", "=", "len", "(", "list", "(", "ImageSequence", ".", "Iterator", "(", "all_images", ")", ")", ")", "\n", "n_img", "=", "20", "\n", "imgs", "=", "[", "None", "]", "*", "n_img", "\n", "indeces", "=", "np", ".", "around", "(", "np", ".", "linspace", "(", "0", ",", "n_tot", "-", "n_img", ",", "n_img", ")", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "n_img", ")", ":", "\n", "        ", "idx", "=", "math", ".", "floor", "(", "indeces", "[", "i", "]", ")", "\n", "imgs", "[", "i", "]", "=", "ImageSequence", ".", "Iterator", "(", "all_images", ")", "[", "idx", "]", ".", "convert", "(", "\"RGBA\"", ")", "\n", "\n", "", "blended", "=", "Image", ".", "blend", "(", "imgs", "[", "0", "]", ",", "imgs", "[", "1", "]", ",", "alpha", "=", "alpha", ")", "\n", "for", "i", "in", "range", "(", "2", ",", "n_img", ")", ":", "\n", "        ", "blended", "=", "Image", ".", "blend", "(", "blended", ",", "imgs", "[", "i", "]", ",", "alpha", "=", "alpha", ")", "\n", "\n", "", "blended", "=", "Image", ".", "blend", "(", "blended", ",", "imgs", "[", "-", "1", "]", ",", "alpha", "=", "alpha", ")", "\n", "blended", ".", "save", "(", "f'{stats_path}/all_in_one_{config.ep_num}.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_communication_data.print_table": [[10, 49], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "matplotlib.rc", "range", "plot_path.mkdir", "matplotlib.subplots", "ax.bar", "range", "ax.set_xlabel", "ax.set_ylabel", "ax.set_title", "matplotlib.tight_layout", "f.savefig", "matplotlib.close", "pathlib.Path", "all_communications[].sum", "numpy.arange", "ax.bar", "all_communications[].sum", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum"], ["def", "print_table", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "(", "Path", "(", "'../models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "/", "(", "'run%i'", "%", "config", ".", "run_num", ")", ")", "\n", "if", "config", ".", "incremental", "is", "not", "None", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "config", ".", "incremental", ")", "\n", "", "else", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'model.pt'", "\n", "\n", "", "if", "config", ".", "save_plots", ":", "\n", "        ", "plot_path", "=", "model_path", ".", "parent", "/", "'plots'", "\n", "plot_path", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "", "stats_path", "=", "model_path", ".", "parent", "/", "'stats'", "\n", "all_infos", "=", "load", "(", "f'{stats_path}/all_infos.npy'", ")", "\n", "all_positions", "=", "load", "(", "f'{stats_path}/all_positions.npy'", ")", "\n", "all_communications", "=", "load", "(", "f'{stats_path}/all_communications.npy'", ")", "\n", "all_obs", "=", "load", "(", "f'{stats_path}/all_observations.npy'", ")", "\n", "\n", "plt", ".", "rc", "(", "'font'", ",", "family", "=", "'serif'", ")", "\n", "n_episodes", ",", "episode_length", ",", "n_speaking_agents", ",", "dim_c", "=", "all_communications", ".", "shape", "\n", "for", "a", "in", "range", "(", "n_speaking_agents", ")", ":", "\n", "        ", "if", "config", ".", "save_plots", ":", "\n", "            ", "f", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "3", ",", "3", ")", ")", "\n", "\n", "bottom_data", "=", "all_communications", "[", "0", ",", ":", ",", "a", "]", ".", "sum", "(", "0", ")", "/", "episode_length", "\n", "# ax.bar(np.arange(dim_c), bottom_data, color=all_obs[0,0,0:3])", "\n", "ax", ".", "bar", "(", "np", ".", "arange", "(", "dim_c", ")", ",", "bottom_data", ")", "\n", "for", "ep_i", "in", "range", "(", "1", ",", "n_episodes", ")", ":", "\n", "                ", "goal_color", "=", "all_obs", "[", "ep_i", ",", "0", ",", "0", ":", "3", "]", "\n", "data", "=", "all_communications", "[", "ep_i", ",", ":", ",", "a", "]", ".", "sum", "(", "0", ")", "/", "episode_length", "\n", "# ax.bar(np.arange(dim_c), data, bottom=bottom_data,color=goal_color)", "\n", "ax", ".", "bar", "(", "np", ".", "arange", "(", "dim_c", ")", ",", "data", ",", "bottom", "=", "bottom_data", ")", "\n", "bottom_data", "+=", "data", "\n", "# ax.set_ylim([0,1])", "\n", "", "ax", ".", "set_xlabel", "(", "'Symbol'", ",", "fontsize", "=", "11", ")", "\n", "ax", ".", "set_ylabel", "(", "'Frequency'", ",", "fontsize", "=", "11", ")", "\n", "ax", ".", "set_title", "(", "config", ".", "model_name", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "f", ".", "savefig", "(", "f'{plot_path}/communications_{config.model_name}.png'", ")", "\n", "plt", ".", "close", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.make_table.print_table": [[7, 47], ["numpy.load", "numpy.any().mean", "all_infos[].mean", "all_infos[].mean", "all_infos[].mean", "all_infos[].mean", "print", "print", "all_infos[].mean", "all_infos[].mean", "numpy.all().mean", "all_infos[].mean", "numpy.any().mean", "numpy.array().mean", "numpy.array().mean", "print", "print", "pathlib.Path", "numpy.any", "all_infos[].mean", "numpy.any().mean", "numpy.any().mean", "print", "print", "numpy.all", "numpy.any", "numpy.array", "numpy.array", "numpy.clip", "list", "numpy.any", "numpy.any", "numpy.abs", "map", "numpy.diff", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean"], ["def", "print_table", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "(", "Path", "(", "'models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "/", "(", "'run%i'", "%", "config", ".", "run_num", ")", ")", "\n", "if", "config", ".", "incremental", "is", "not", "None", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "config", ".", "incremental", ")", "\n", "", "else", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'model.pt'", "\n", "\n", "", "stats_path", "=", "model_path", ".", "parent", "/", "'stats'", "\n", "all_infos", "=", "load", "(", "f'{stats_path}/all_infos.npy'", ")", "\n", "if", "config", ".", "env_id", "==", "'simple_order'", ":", "\n", "        ", "collisions", "=", "np", ".", "any", "(", "all_infos", "[", ":", ",", ":", ",", ":", ",", "1", "]", ">", "1", ",", "axis", "=", "1", ")", ".", "mean", "(", ")", "\n", "avg_dist", "=", "all_infos", "[", ":", ",", ":", ",", ":", ",", "2", "]", ".", "mean", "(", ")", "\n", "reward", "=", "all_infos", "[", ":", ",", ":", ",", ":", ",", "0", "]", ".", "mean", "(", ")", "\n", "fin_dist", "=", "all_infos", "[", ":", ",", "-", "5", ":", ",", "1", ",", "1", "]", ".", "mean", "(", ")", "\n", "target_reach", "=", "all_infos", "[", ":", ",", ":", ",", ":", ",", "3", "]", ".", "mean", "(", ")", "\n", "\n", "print", "(", "f'reward: \\t obs_hit: \\t avg_dist:  \\t fin_dis:  \\t target_reach: '", ")", "\n", "print", "(", "f'\\t {reward:.3f}\\t {collisions:.3f} \\t {avg_dist:.3f} \\t {fin_dist:.3f} \\t {target_reach:.3f}'", ")", "\n", "\n", "", "elif", "'simple_speaker_listener'", "in", "config", ".", "env_id", ":", "\n", "        ", "ep", ",", "t", ",", "n_agents", ",", "metrics", "=", "all_infos", ".", "shape", "\n", "avg_dist", "=", "all_infos", "[", ":", ",", ":", ",", "1", ",", "1", "]", ".", "mean", "(", ")", "\n", "fin_dist", "=", "all_infos", "[", ":", ",", "-", "5", ":", ",", "1", ",", "1", "]", ".", "mean", "(", ")", "\n", "target_reach", "=", "np", ".", "all", "(", "all_infos", "[", ":", ",", "-", "5", ":", ",", "1", ",", "1", "]", "<", ".1", ",", "axis", "=", "1", ")", ".", "mean", "(", ")", "\n", "reward", "=", "all_infos", "[", ":", ",", ":", ",", "1", ",", "0", "]", ".", "mean", "(", ")", "\n", "\n", "collisions", "=", "np", ".", "any", "(", "all_infos", "[", ":", ",", ":", ",", "1", ",", "3", "]", ",", "axis", "=", "1", ")", ".", "mean", "(", ")", "\n", "alternating_frequency", "=", "np", ".", "array", "(", "np", ".", "clip", "(", "np", ".", "abs", "(", "np", ".", "diff", "(", "all_infos", "[", ":", ",", ":", ",", "0", ",", "2", "]", ",", "axis", "=", "1", ")", ")", ",", "0", ",", "1", ")", ")", ".", "mean", "(", ")", "\n", "distinct_token", "=", "np", ".", "array", "(", "list", "(", "map", "(", "len", ",", "np", ".", "unique", "(", "all_infos", "[", ":", ",", "-", "5", ":", ",", "0", ",", "2", "]", ",", "axis", "=", "1", ")", ")", ")", ")", ".", "mean", "(", ")", "\n", "\n", "print", "(", "f'reward: \\t obs_hit: \\t avg_dist:  \\t fin_dis:  \\t target_reach: \\t distinct_token: \\t alternating_frequency:'", ")", "\n", "print", "(", "f'\\t {reward:.3f}\\t {collisions:.3f} \\t {avg_dist:.3f} \\t {fin_dist:.3f} \\t {target_reach:.3f} \\t {distinct_token:.3f} \\t {alternating_frequency:.3f}'", ")", "\n", "\n", "", "elif", "config", ".", "env_id", "==", "'simple_car_pixels'", ":", "\n", "        ", "reward", "=", "all_infos", "[", ":", ",", ":", ",", "1", ",", "0", "]", ".", "mean", "(", ")", "\n", "collisions", "=", "np", ".", "any", "(", "all_infos", "[", ":", ",", ":", ",", "0", ",", "1", "]", ",", "axis", "=", "1", ")", ".", "mean", "(", ")", "\n", "off_road", "=", "np", ".", "any", "(", "all_infos", "[", ":", ",", ":", ",", "0", ",", "2", "]", ",", "axis", "=", "1", ")", ".", "mean", "(", ")", "\n", "\n", "print", "(", "f'reward: \\t collisions: \\t off_road: '", ")", "\n", "print", "(", "f'\\t {reward:.3f}\\t {collisions:.3f} \\t {off_road:.3f}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot": [[7, 60], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "matplotlib.rc", "matplotlib.subplots", "plot_path.mkdir", "range", "matplotlib.tight_layout", "f.savefig", "matplotlib.close", "obs_speaker.reshape", "numpy.zeros", "ax.plot", "ax.axis", "ax.set_xlabel", "ax.set_ylabel", "ax.set_xticks", "ax.set_yticks", "numpy.argmax", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot"], ["def", "plot", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "(", "Path", "(", "'models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "/", "(", "'run%i'", "%", "config", ".", "run_num", ")", ")", "\n", "if", "config", ".", "incremental", "is", "not", "None", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "config", ".", "incremental", ")", "\n", "", "else", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'model.pt'", "\n", "\n", "", "if", "config", ".", "save_plots", ":", "\n", "        ", "plot_path", "=", "model_path", ".", "parent", "/", "'plots'", "\n", "plot_path", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "", "stats_path", "=", "model_path", ".", "parent", "/", "'stats'", "\n", "all_infos", "=", "load", "(", "f'{stats_path}/all_infos.npy'", ")", "\n", "all_actions", "=", "load", "(", "f'{stats_path}/all_actions.npy'", ")", "\n", "all_positions", "=", "load", "(", "f'{stats_path}/all_positions.npy'", ")", "\n", "all_obs", "=", "load", "(", "f'{stats_path}/all_observations.npy'", ")", "\n", "\n", "plt", ".", "rc", "(", "'font'", ",", "family", "=", "'serif'", ")", "\n", "n_episodes", ",", "episode_length", ",", "n_agents", ",", "dim_a", "=", "all_actions", ".", "shape", "\n", "f", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "3", ",", "3", ")", ")", "\n", "if", "config", ".", "save_plots", ":", "\n", "        ", "for", "ep_i", "in", "range", "(", "n_episodes", ")", ":", "\n", "            ", "obs_speaker", "=", "all_obs", "[", "ep_i", ",", "0", ",", "4", ":", "16", "]", "\n", "obstacles", "=", "obs_speaker", ".", "reshape", "(", "-", "1", ",", "2", ")", "\n", "goal", "=", "all_obs", "[", "ep_i", ",", "0", ",", "2", ":", "4", "]", "\n", "\n", "a", "=", "0", "\n", "m", "=", "np", ".", "zeros", "(", "5", ")", "\n", "m", "[", "ep_i", "]", "=", "1", "\n", "ax", ".", "plot", "(", "all_positions", "[", "ep_i", ",", ":", ",", "a", ",", "0", "]", ",", "all_positions", "[", "ep_i", ",", ":", ",", "a", ",", "1", "]", ",", "label", "=", "f'$m_{ep_i}^0=${1}'", ")", "\n", "# ax.scatter(goal[0],goal[1], marker='*', label='goal', c='r')", "\n", "# ax.scatter(obstacles[:,0], obstacles[:, 1], marker='X', c='k', label='obstacles')", "\n", "ax", ".", "axis", "(", "[", "-", "1", ",", "1", ",", "-", "1", ",", "1", "]", ")", "\n", "ax", ".", "set_xlabel", "(", "'x-coordinate'", ",", "fontsize", "=", "16", ")", "\n", "ax", ".", "set_ylabel", "(", "'y-coordinate'", ",", "fontsize", "=", "16", ")", "\n", "# ax.set_title(config.model_name)", "\n", "# ax.legend(loc='lower right')", "\n", "ax", ".", "set_xticks", "(", "[", "]", ")", "\n", "ax", ".", "set_yticks", "(", "[", "]", ")", "\n", "# f.savefig(f'{plot_path}/stem_{config.model_name}_ep_{ep_i}_agent_listener.png')", "\n", "\n", "# f, ax = plt.subplots(nrows=1, ncols=1, figsize=(3, 3))", "\n", "a", "=", "0", "\n", "data", "=", "all_actions", "[", "ep_i", ",", ":", ",", "a", "]", "\n", "y", "=", "np", ".", "argmax", "(", "data", ",", "axis", "=", "1", ")", "\n", "# ax.stem(np.arange(episode_length), y)", "\n", "# ax.set_ylim([0, dim_a])", "\n", "# ax.set_xlabel('Time', fontsize=11)", "\n", "# ax.set_ylabel('Symbol', fontsize=11)", "\n", "# ax.set_title(config.model_name)", "\n", "", "plt", ".", "tight_layout", "(", ")", "\n", "f", ".", "savefig", "(", "f'{plot_path}/stem_{config.model_name}_ep_{ep_i}_agent_speaker.png'", ")", "\n", "plt", ".", "close", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.collect_table_data.run": [[12, 84], ["gif_path.mkdir", "torch.manual_seed", "numpy.random.seed", "utils.make_env.make_env", "utils.make_env.make_env.seed", "MADDPG.init_from_save.prep_rollouts", "numpy.empty", "sum", "sum", "numpy.zeros", "numpy.zeros", "numpy.zeros", "sum", "numpy.zeros", "range", "utils.make_env.make_env.close", "algorithms.maddpg.MADDPG.init_from_directory", "algorithms.maddpg.MADDPG.init_from_save", "print", "utils.make_env.make_env.reset", "range", "stats_path.mkdir", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "len", "time.time", "utils.make_env.make_env.get_positions", "utils.make_env.make_env.get_communications", "MADDPG.init_from_save.step", "utils.make_env.make_env.step", "numpy.concatenate", "time.time", "pathlib.Path", "ac.data.numpy().flatten", "numpy.asarray", "time.sleep", "len", "numpy.array", "pathlib.Path", "torch.autograd.Variable", "torch.autograd.Variable", "range", "torch.Tensor().view", "torch.Tensor", "ac.data.numpy", "numpy.array", "len", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.cmd_util.make_env", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.envs.fixed_sequence_env.FixedSequenceEnv.seed", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.empowerment.variational_joint_empowerment.VariationalJointEmpowerment.prep_rollouts", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.segment_tree.SumSegmentTree.sum", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.vec_env.vec_video_recorder.VecVideoRecorder.close", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_directory", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.algorithms.maddpg.MADDPG.init_from_save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.reset", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.save", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_positions", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.multiagent.environment.MultiAgentEnv.get_communications", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.cars.road_world.RoadWorld.step"], ["def", "run", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "(", "Path", "(", "'../models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", "/", "\n", "(", "'run%i'", "%", "config", ".", "run_num", ")", ")", "\n", "if", "config", ".", "incremental", "is", "not", "None", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'incremental'", "/", "(", "'model_ep%i.pt'", "%", "\n", "config", ".", "incremental", ")", "\n", "", "else", ":", "\n", "        ", "model_path", "=", "model_path", "/", "'model.pt'", "\n", "\n", "", "gif_path", "=", "model_path", ".", "parent", "/", "'stats'", "if", "not", "config", ".", "mixed_policies", "else", "model_path", ".", "parent", "/", "'stats_mixed'", "\n", "gif_path", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "config", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "config", ".", "seed", ")", "\n", "if", "config", ".", "mixed_policies", ":", "\n", "        ", "maddpg", "=", "MADDPG", ".", "init_from_directory", "(", "Path", "(", "'../models'", ")", "/", "config", ".", "env_id", "/", "config", ".", "model_name", ")", "\n", "", "else", ":", "\n", "        ", "maddpg", "=", "MADDPG", ".", "init_from_save", "(", "model_path", ")", "\n", "", "env", "=", "make_env", "(", "config", ".", "env_id", ",", "benchmark", "=", "True", ",", "discrete_action", "=", "maddpg", ".", "discrete_action", ")", "\n", "env", ".", "seed", "(", "config", ".", "seed", ")", "\n", "maddpg", ".", "prep_rollouts", "(", "device", "=", "'cpu'", ")", "\n", "ifi", "=", "1", "/", "config", ".", "fps", "# inter-frame interval", "\n", "all_infos", "=", "np", ".", "empty", "(", "(", "config", ".", "n_episodes", ",", "config", ".", "episode_length", ",", "maddpg", ".", "nagents", ",", "10", ")", ")", "\n", "n_movable_agents", "=", "sum", "(", "[", "1", "if", "a", ".", "movable", "else", "0", "for", "a", "in", "env", ".", "agents", "]", ")", "\n", "n_speaking_agents", "=", "sum", "(", "[", "0", "if", "a", ".", "silent", "else", "1", "for", "a", "in", "env", ".", "agents", "]", ")", "\n", "all_positions", "=", "np", ".", "zeros", "(", "(", "config", ".", "n_episodes", ",", "config", ".", "episode_length", ",", "n_movable_agents", ",", "env", ".", "world", ".", "dim_p", ")", ")", "\n", "all_communications", "=", "np", ".", "zeros", "(", "(", "config", ".", "n_episodes", ",", "config", ".", "episode_length", ",", "n_speaking_agents", ",", "env", ".", "world", ".", "dim_c", ")", ")", "\n", "all_actions", "=", "np", ".", "zeros", "(", "(", "config", ".", "n_episodes", ",", "config", ".", "episode_length", ",", "len", "(", "env", ".", "agents", ")", ",", "env", ".", "world", ".", "dim_c", ")", ")", "\n", "obs_space", "=", "sum", "(", "[", "obsp", ".", "shape", "[", "0", "]", "for", "obsp", "in", "env", ".", "observation_space", "]", ")", "\n", "all_obs", "=", "np", ".", "zeros", "(", "(", "config", ".", "n_episodes", ",", "config", ".", "episode_length", ",", "obs_space", ")", ")", "\n", "\n", "for", "ep_i", "in", "range", "(", "config", ".", "n_episodes", ")", ":", "\n", "        ", "print", "(", "\"Episode %i of %i\"", "%", "(", "ep_i", "+", "1", ",", "config", ".", "n_episodes", ")", ")", "\n", "obs", "=", "env", ".", "reset", "(", ")", "\n", "# env.agents[1].state.p_pos = np.array([0., 0.])", "\n", "for", "t_i", "in", "range", "(", "config", ".", "episode_length", ")", ":", "\n", "            ", "calc_start", "=", "time", ".", "time", "(", ")", "\n", "# rearrange observations to be per agent, and convert to torch Variable", "\n", "torch_obs", "=", "[", "Variable", "(", "torch", ".", "Tensor", "(", "obs", "[", "i", "]", ")", ".", "view", "(", "1", ",", "-", "1", ")", ",", "\n", "requires_grad", "=", "False", ")", "if", "not", "obs", "[", "i", "]", ".", "ndim", "==", "4", "else", "Variable", "(", "torch", ".", "Tensor", "(", "obs", "[", "i", "]", ")", ",", "requires_grad", "=", "False", ")", "\n", "for", "i", "in", "range", "(", "maddpg", ".", "nagents", ")", "]", "\n", "\n", "all_positions", "[", "ep_i", ",", "t_i", "]", "=", "env", ".", "get_positions", "(", ")", "\n", "all_communications", "[", "ep_i", ",", "t_i", "]", "=", "env", ".", "get_communications", "(", ")", "\n", "# get actions as torch Variables", "\n", "torch_actions", "=", "maddpg", ".", "step", "(", "torch_obs", ",", "explore", "=", "False", ")", "\n", "# convert actions to numpy arrays", "\n", "actions", "=", "[", "ac", ".", "data", ".", "numpy", "(", ")", ".", "flatten", "(", ")", "for", "ac", "in", "torch_actions", "]", "\n", "# actions[0] = np.array([0., 0., 0., 0., 0.], dtype=np.float32)", "\n", "# actions[0][ep_i] = 1.", "\n", "obs", ",", "rewards", ",", "dones", ",", "infos", "=", "env", ".", "step", "(", "actions", ")", "\n", "\n", "all_actions", "[", "ep_i", ",", "t_i", ",", ":", ",", ":", "]", "=", "actions", "\n", "all_obs", "[", "ep_i", ",", "t_i", ",", ":", "]", "=", "np", ".", "concatenate", "(", "np", ".", "asarray", "(", "obs", ")", ")", "\n", "\n", "calc_end", "=", "time", ".", "time", "(", ")", "\n", "elapsed", "=", "calc_end", "-", "calc_start", "\n", "if", "elapsed", "<", "ifi", ":", "\n", "                ", "time", ".", "sleep", "(", "ifi", "-", "elapsed", ")", "\n", "", "if", "len", "(", "np", ".", "array", "(", "infos", "[", "'n'", "]", ")", ".", "shape", ")", "<", "4", ":", "\n", "                ", "all_infos", "[", "ep_i", ",", "t_i", ",", ":", ",", ":", "len", "(", "infos", "[", "'n'", "]", "[", "-", "1", "]", ")", "]", "=", "np", ".", "array", "(", "infos", "[", "'n'", "]", ")", "\n", "\n", "", "", "", "env", ".", "close", "(", ")", "\n", "\n", "if", "config", ".", "save_stats", ":", "\n", "        ", "stats_path", "=", "model_path", ".", "parent", "/", "'stats'", "if", "not", "config", ".", "mixed_policies", "else", "model_path", ".", "parent", "/", "'stats_mixed'", "\n", "stats_path", ".", "mkdir", "(", "exist_ok", "=", "True", ")", "\n", "save", "(", "f'{stats_path}/all_infos.npy'", ",", "all_infos", ")", "\n", "save", "(", "f'{stats_path}/all_positions.npy'", ",", "all_positions", ")", "\n", "save", "(", "f'{stats_path}/all_communications.npy'", ",", "all_communications", ")", "\n", "save", "(", "f'{stats_path}/all_actions.npy'", ",", "all_actions", ")", "\n", "save", "(", "f'{stats_path}/all_observations.npy'", ",", "all_obs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_training_curve.load_data": [[16, 24], ["numpy.array", "open", "json.load", "json.load.items", "cast", "int", "key.split", "key.split"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.policies.PolicyWithValue.load"], ["def", "load_data", "(", "file_path", ",", "name", ",", "agent_num", "=", "0", ")", ":", "\n", "    ", "cast", "=", "lambda", "x", ":", "np", ".", "array", "(", "x", ")", "\n", "with", "open", "(", "file_path", ")", "as", "json_file", ":", "\n", "        ", "data", "=", "json", ".", "load", "(", "json_file", ")", "\n", "for", "key", ",", "value", "in", "data", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "==", "name", "and", "int", "(", "key", ".", "split", "(", "'/'", ")", "[", "-", "3", "]", "[", "-", "1", "]", ")", "==", "agent_num", ":", "\n", "                ", "d", "=", "cast", "(", "value", ")", "\n", "return", "d", "[", ":", ",", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_training_curve.plot_training_curve": [[26, 78], ["collections.defaultdict", "os.walk", "collections.defaultdict", "collections.defaultdict.items", "matplotlib.rc", "matplotlib.subplots", "enumerate", "ax.set_ylabel", "ax.set_ylim", "matplotlib.tight_layout", "matplotlib.savefig", "pathlib.Path", "numpy.asarray", "np.asarray.mean", "collections.defaultdict.items", "numpy.asarray", "load_data.mean", "numpy.arange", "len", "print", "scipy.ndimage.filters.gaussian_filter1d", "ax.plot", "ax.set_xlabel", "ax.legend", "f.endswith", "len", "load_data.std", "plot_training_curve.load_data", "data[].append", "r.split", "os.path.join"], "function", ["home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.common.distributions.BernoulliPd.mean", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_position_data.plot", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.evalutation.plot_training_curve.load_data", "home.repos.pwc.inspect_result.tessavdheiden_social_empowerment.ddpg.memory.Memory.append"], ["", "", "", "", "def", "plot_training_curve", "(", "config", ")", ":", "\n", "    ", "model_path", "=", "Path", "(", "'models'", ")", "/", "config", ".", "env_id", "\n", "\n", "names", "=", "[", "'baseline'", ",", "'empowerment'", ",", "'social'", ",", "'maddpg'", ",", "'social_influence'", "]", "\n", "data", "=", "defaultdict", "(", "list", ")", "\n", "\n", "curve_name", "=", "'rew_loss'", "# 'pol_loss'  'vf_loss'", "\n", "agent_num", "=", "0", "\n", "axis", "=", "1", "\n", "n_points", "=", "100", "\n", "\n", "# find files", "\n", "for", "r", ",", "_", ",", "files", "in", "os", ".", "walk", "(", "model_path", ")", ":", "\n", "        ", "for", "f", "in", "files", ":", "\n", "            ", "if", "f", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "                ", "name", "=", "r", ".", "split", "(", "'/'", ")", "[", "2", "]", "\n", "if", "name", "not", "in", "names", ":", "continue", "\n", "y", "=", "load_data", "(", "os", ".", "path", ".", "join", "(", "r", ",", "f", ")", ",", "name", "=", "curve_name", ",", "agent_num", "=", "agent_num", ")", "\n", "data", "[", "name", "]", ".", "append", "(", "y", ")", "\n", "", "", "", "avg_data", "=", "defaultdict", "(", "np", ".", "array", ")", "\n", "for", "k", ",", "v", "in", "data", ".", "items", "(", ")", ":", "\n", "        ", "tmp", "=", "np", ".", "asarray", "(", "v", ")", "\n", "avg_data", "[", "k", "]", "=", "tmp", ".", "mean", "(", "0", ")", "\n", "\n", "", "plt", ".", "rc", "(", "'font'", ",", "family", "=", "'serif'", ")", "\n", "# plt.rc('axes', labelsize=16)", "\n", "# plt.rcParams.update({'font.size': 16})", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "nrows", "=", "1", ",", "ncols", "=", "1", ",", "figsize", "=", "(", "3", ",", "3", ")", ")", "\n", "\n", "# data = dict(sorted(avg_data.items()))", "\n", "\n", "colors", "=", "[", "'r'", ",", "'g'", ",", "'b'", ",", "'gray'", "]", "\n", "for", "i", ",", "(", "name", ",", "values", ")", "in", "enumerate", "(", "data", ".", "items", "(", ")", ")", ":", "\n", "        ", "y", "=", "np", ".", "asarray", "(", "values", ")", "\n", "y_mean", "=", "y", ".", "mean", "(", "0", ")", "\n", "x_vals", "=", "np", ".", "arange", "(", "len", "(", "y_mean", ")", ")", "\n", "n_runs", "=", "len", "(", "values", ")", "\n", "print", "(", "n_runs", ")", "\n", "y_std", "=", "y", ".", "std", "(", "0", ")", "/", "(", "n_runs", "**", "0.5", ")", "\n", "y_smoothed", "=", "gaussian_filter1d", "(", "y_mean", ",", "sigma", "=", "100", ")", "\n", "ax", ".", "plot", "(", "y_smoothed", ",", "colors", "[", "i", "]", ",", "label", "=", "name", ")", "\n", "# ax.fill_between(x_vals, y_mean + y_std ,y_mean - y_std,alpha = 0.3)", "\n", "# ax[axis].plot(y, color, alpha=0.1)", "\n", "ax", ".", "set_xlabel", "(", "'Training steps'", ")", "\n", "ax", ".", "legend", "(", ")", "\n", "\n", "", "ax", ".", "set_ylabel", "(", "'Avarage return'", ",", "fontsize", "=", "11", ")", "\n", "ax", ".", "set_ylim", "(", "[", "-", "4", ",", "1", "]", ")", "\n", "# ax[0].set_ylabel('PolicyLoss', fontsize=11)", "\n", "# ax[2].set_ylabel('CriticLoss', fontsize=11)", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "model_path", "/", "f'learning_curve_scenario_{model_path.name}.png'", ")", "\n", "\n"]]}