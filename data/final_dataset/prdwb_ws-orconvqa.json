{"home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.set_seed": [[77, 83], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.to_list": [[84, 86], ["tensor.detach().cpu().tolist", "tensor.detach().cpu", "tensor.detach"], "function", ["None"], ["", "", "def", "to_list", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.str2bool": [[87, 96], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "        ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.train": [[101, 486], ["torch.utils.data.DataLoader", "transformers.AdamW", "int", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "os.path.join", "train_pipeline_weak_supervision.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "os.path.join", "recall_evaluator.evaluate", "numpy.average", "SummaryWriter.add_scalar", "p1_evaluator.evaluate", "numpy.average", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.close", "os.path.join", "torch.nn.parallel.DistributedDataParallel.eval", "numpy.asarray().reshape().tolist", "numpy.asarray().reshape().tolist", "numpy.asarray().reshape().tolist", "numpy.asarray().reshape().tolist", "train_pipeline_weak_supervision.gen_query_reps", "utils.get_train_retriever_run", "all_train_retriever_run.update", "all_train_gold_passage_hit_run.update", "torch.nn.parallel.DistributedDataParallel.train", "utils.gen_reader_features", "torch.nn.parallel.DistributedDataParallel.reader", "loss.mean.item", "reader_loss.mean.item", "qa_loss.mean.item", "rerank_loss.mean.item", "len", "len", "len", "len", "len", "len", "len", "len", "open", "json.dump", "all_train_gold_passage_hit_run.values", "int", "len", "open", "fout.write", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "train_pipeline_weak_supervision.retrieve", "train_pipeline_weak_supervision.retrieve_weak_supervision", "torch.nn.parallel.DistributedDataParallel.retriever", "torch.nn.parallel.DistributedDataParallel.retriever", "v.to", "loss.mean.mean", "reader_loss.mean.mean", "qa_loss.mean.mean", "rerank_loss.mean.mean", "loss.mean.backward", "retriever_loss.mean.item", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "recall_evaluator.evaluate.values", "p1_evaluator.evaluate.values", "v.values", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "numpy.asarray().reshape", "numpy.asarray().reshape", "numpy.asarray().reshape", "numpy.asarray().reshape", "numpy.where", "retrieve_weak_supervision.items", "batch.items", "batch[].to", "batch[].to", "batch[].to", "torch.from_numpy().to", "torch.from_numpy().to", "batch[].to", "batch[].to", "batch[].to", "torch.from_numpy().to", "utils.gen_reader_features.items", "retriever_loss.mean.mean", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "os.path.join", "os.path.join", "retriever_model_to_save.save_pretrained", "reader_model_to_save.save_pretrained", "torch.save", "logger.info", "json.dumps", "any", "isinstance", "numpy.asarray", "numpy.asarray", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "train_pipeline_weak_supervision.evaluate", "evaluate.items", "SummaryWriter.add_scalar", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.array", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr", "isinstance", "len", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.set_seed", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.evaluate", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.evaluate", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.gen_query_reps", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.get_train_retriever_run", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.train", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.gen_reader_features", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.retrieve", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.retrieve_weak_supervision", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "retriever_tokenizer", ",", "reader_tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "global", "em_answer_found_num", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'logs'", ")", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "\n", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "\n", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "# to compensate skipped steps:", "\n", "# args.num_train_epochs = args.num_train_epochs * 3", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "\n", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "\n", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "\n", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "args", ".", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_portion", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "\n", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "# model.to(f'cuda:{model.device_ids[0]}')", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "\n", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "\n", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "1", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "retriever_tr_loss", ",", "retriever_logging_loss", "=", "0.0", ",", "0.0", "\n", "reader_tr_loss", ",", "reader_logging_loss", "=", "0.0", ",", "0.0", "\n", "qa_tr_loss", ",", "qa_logging_loss", "=", "0.0", ",", "0.0", "\n", "rerank_tr_loss", ",", "rerank_logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "\n", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "num_has_positive_per_train_epoch", "=", "0", "\n", "train_info_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"train_info.txt\"", ")", "\n", "# Added here for reproductibility (even between python 2 and 3)", "\n", "set_seed", "(", "args", ")", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "\n", "all_train_retriever_run", "=", "{", "}", "# retriever results per epoch during training", "\n", "# measure how many positive passages identified by weak supervision are gold passages", "\n", "all_train_gold_passage_hit_run", "=", "{", "}", "\n", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "# we first get query representations in eval mode", "\n", "qids", "=", "np", ".", "asarray", "(", "batch", "[", "'qid'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "# print('qids', qids)", "\n", "question_texts", "=", "np", ".", "asarray", "(", "\n", "batch", "[", "'question_text'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "# print('question_texts', question_texts)", "\n", "answer_texts", "=", "np", ".", "asarray", "(", "\n", "batch", "[", "'answer_text'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "# print('answer_texts', answer_texts)", "\n", "answer_starts", "=", "np", ".", "asarray", "(", "\n", "batch", "[", "'answer_start'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "# print('answer_starts', answer_starts)", "\n", "query_reps", "=", "gen_query_reps", "(", "args", ",", "model", ",", "batch", ")", "\n", "\n", "if", "args", ".", "weak_supervision", "==", "'none'", ":", "\n", "                ", "retrieval_results", "=", "retrieve", "(", "args", ",", "qids", ",", "qid_to_idx", ",", "query_reps", ",", "\n", "passage_ids", ",", "passage_id_to_idx", ",", "passage_reps", ",", "\n", "qrels", ",", "qrels_sparse_matrix", ",", "\n", "gpu_index", ",", "include_positive_passage", "=", "True", ")", "\n", "", "else", ":", "\n", "                ", "retrieval_results", "=", "retrieve_weak_supervision", "(", "args", ",", "qids", ",", "qid_to_idx", ",", "query_reps", ",", "\n", "passage_ids", ",", "passage_id_to_idx", ",", "passage_reps", ",", "\n", "gpu_index", ",", "answer_texts", ",", "answer_starts", ")", "\n", "# obtain these values before dropping cannotanswer instances", "\n", "# for monitoring the training process", "\n", "", "pids_for_reader", "=", "retrieval_results", "[", "'pids_for_reader'", "]", "\n", "# print('pids_for_reader', pids_for_reader)", "\n", "passages_for_reader", "=", "retrieval_results", "[", "'passages_for_reader'", "]", "\n", "labels_for_reader", "=", "retrieval_results", "[", "'labels_for_reader'", "]", "\n", "\n", "# convert retriever results to qrel evaluation format:", "\n", "train_retriever_run", ",", "train_gold_passage_hit_run", "=", "get_train_retriever_run", "(", "\n", "qids", ",", "pids_for_reader", ",", "labels_for_reader", ")", "\n", "all_train_retriever_run", ".", "update", "(", "train_retriever_run", ")", "\n", "all_train_gold_passage_hit_run", ".", "update", "(", "train_gold_passage_hit_run", ")", "\n", "\n", "if", "args", ".", "weak_supervision", "!=", "'none'", ":", "\n", "\n", "                ", "if", "args", ".", "drop_cannotanswer", ":", "\n", "                    ", "weak_answer_texts", "=", "retrieval_results", "[", "'weak_answer_texts'", "]", "\n", "# print(weak_answer_texts)", "\n", "kept_idx", "=", "np", ".", "where", "(", "\n", "np", ".", "array", "(", "weak_answer_texts", ")", "!=", "'CANNOTANSWER'", ")", "\n", "for", "k", ",", "v", "in", "retrieval_results", ".", "items", "(", ")", ":", "\n", "                        ", "if", "not", "isinstance", "(", "v", ",", "int", ")", "and", "len", "(", "v", ")", ">", "0", ":", "\n", "                            ", "retrieval_results", "[", "k", "]", "=", "np", ".", "asarray", "(", "v", ")", "[", "kept_idx", "]", "\n", "\n", "", "", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", ":", "\n", "# print(k, type(v), v)", "\n", "                        ", "if", "isinstance", "(", "v", ",", "torch", ".", "Tensor", ")", ":", "\n", "                            ", "batch", "[", "k", "]", "=", "v", "[", "kept_idx", "]", "\n", "\n", "", "", "qids", "=", "np", ".", "asarray", "(", "qids", ")", "[", "kept_idx", "]", "\n", "question_texts", "=", "np", ".", "asarray", "(", "question_texts", ")", "[", "kept_idx", "]", "\n", "\n", "", "answer_texts", "=", "retrieval_results", "[", "'weak_answer_texts'", "]", "\n", "answer_starts", "=", "retrieval_results", "[", "'weak_answer_starts'", "]", "\n", "num_has_positive_per_train_epoch", "+=", "retrieval_results", "[", "'num_has_positive'", "]", "\n", "\n", "", "if", "(", "args", ".", "weak_supervision", "!=", "'none'", "and", "\n", "args", ".", "drop_cannotanswer", "and", "\n", "retrieval_results", "[", "'num_has_positive'", "]", "==", "0", ")", ":", "\n", "                ", "continue", "\n", "\n", "# obtain these values again after dropping cannotanswer instances", "\n", "", "pids_for_reader", "=", "retrieval_results", "[", "'pids_for_reader'", "]", "\n", "# print('pids_for_reader', pids_for_reader)", "\n", "passages_for_reader", "=", "retrieval_results", "[", "'passages_for_reader'", "]", "\n", "labels_for_reader", "=", "retrieval_results", "[", "'labels_for_reader'", "]", "\n", "\n", "if", "args", ".", "early_loss", ":", "\n", "                ", "passage_reps_for_retriever", "=", "retrieval_results", "[", "'passage_reps_for_retriever'", "]", "\n", "labels_for_retriever", "=", "retrieval_results", "[", "'labels_for_retriever'", "]", "\n", "\n", "# skip this step if there are instances are discarded", "\n", "# if len(pids_for_reader) == 0:", "\n", "#     print('all instances are skipped in this batch')", "\n", "#     continue", "\n", "\n", "", "if", "args", ".", "real_joint_learn", ":", "\n", "                ", "passage_reps_for_reader", "=", "retrieval_results", "[", "'passage_reps_for_reader'", "]", "\n", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "if", "args", ".", "early_loss", ":", "\n", "                ", "inputs", "=", "{", "'query_input_ids'", ":", "batch", "[", "'query_input_ids'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'query_attention_mask'", ":", "batch", "[", "'query_attention_mask'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'query_token_type_ids'", ":", "batch", "[", "'query_token_type_ids'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'passage_rep'", ":", "torch", ".", "from_numpy", "(", "passage_reps_for_retriever", ")", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'retrieval_label'", ":", "torch", ".", "from_numpy", "(", "labels_for_retriever", ")", ".", "to", "(", "args", ".", "device", ")", "}", "\n", "retriever_outputs", "=", "model", ".", "retriever", "(", "**", "inputs", ")", "\n", "# model outputs are always tuple in transformers (see doc)", "\n", "retriever_loss", "=", "retriever_outputs", "[", "0", "]", "\n", "\n", "", "if", "args", ".", "real_joint_learn", ":", "\n", "                ", "inputs", "=", "{", "'query_input_ids'", ":", "batch", "[", "'query_input_ids'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'query_attention_mask'", ":", "batch", "[", "'query_attention_mask'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'query_token_type_ids'", ":", "batch", "[", "'query_token_type_ids'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'passage_rep'", ":", "torch", ".", "from_numpy", "(", "passage_reps_for_reader", ")", ".", "to", "(", "args", ".", "device", ")", "}", "\n", "retriever_outputs_for_reader", "=", "model", ".", "retriever", "(", "**", "inputs", ")", "\n", "retriever_logits_for_reader", "=", "retriever_outputs_for_reader", "[", "0", "]", "\n", "# print('retriever_logits_for_reader',", "\n", "#       retriever_logits_for_reader.size())", "\n", "\n", "", "reader_batch", "=", "gen_reader_features", "(", "qids", ",", "question_texts", ",", "answer_texts", ",", "answer_starts", ",", "\n", "pids_for_reader", ",", "passages_for_reader", ",", "labels_for_reader", ",", "\n", "reader_tokenizer", ",", "args", ".", "reader_max_seq_length", ",", "is_training", "=", "True", ")", "\n", "\n", "reader_batch", "=", "{", "k", ":", "v", ".", "to", "(", "args", ".", "device", ")", "\n", "for", "k", ",", "v", "in", "reader_batch", ".", "items", "(", ")", "}", "\n", "inputs", "=", "{", "'input_ids'", ":", "reader_batch", "[", "'input_ids'", "]", ",", "\n", "'attention_mask'", ":", "reader_batch", "[", "'input_mask'", "]", ",", "\n", "'token_type_ids'", ":", "reader_batch", "[", "'segment_ids'", "]", ",", "\n", "'start_positions'", ":", "reader_batch", "[", "'start_position'", "]", ",", "\n", "'end_positions'", ":", "reader_batch", "[", "'end_position'", "]", ",", "\n", "'retrieval_label'", ":", "reader_batch", "[", "'retrieval_label'", "]", "}", "\n", "if", "args", ".", "real_joint_learn", ":", "\n", "                ", "inputs", "[", "'retriever_logits'", "]", "=", "retriever_logits_for_reader", "\n", "# print(reader_batch['start_position'])", "\n", "# print(answer_texts)", "\n", "", "reader_outputs", "=", "model", ".", "reader", "(", "**", "inputs", ")", "\n", "reader_loss", ",", "qa_loss", ",", "rerank_loss", "=", "reader_outputs", "[", "0", ":", "3", "]", "\n", "\n", "if", "args", ".", "early_loss", ":", "\n", "                ", "loss", "=", "retriever_loss", "+", "reader_loss", "\n", "", "else", ":", "\n", "                ", "loss", "=", "reader_loss", "\n", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel (not distributed) training", "\n", "if", "args", ".", "early_loss", ":", "\n", "                    ", "retriever_loss", "=", "retriever_loss", ".", "mean", "(", ")", "\n", "", "reader_loss", "=", "reader_loss", ".", "mean", "(", ")", "\n", "qa_loss", "=", "qa_loss", ".", "mean", "(", ")", "\n", "rerank_loss", "=", "rerank_loss", ".", "mean", "(", ")", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "if", "args", ".", "early_loss", ":", "\n", "                    ", "retriever_loss", "=", "retriever_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "", "reader_loss", "=", "reader_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "qa_loss", "=", "qa_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "rerank_loss", "=", "rerank_loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "args", ".", "early_loss", ":", "\n", "                ", "retriever_tr_loss", "+=", "retriever_loss", ".", "item", "(", ")", "\n", "", "reader_tr_loss", "+=", "reader_loss", ".", "item", "(", ")", "\n", "qa_tr_loss", "+=", "qa_loss", ".", "item", "(", ")", "\n", "rerank_tr_loss", "+=", "rerank_loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\n", "'eval_{}'", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\n", "'lr'", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\n", "'loss'", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "if", "args", ".", "early_loss", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "\n", "'retriever_loss'", ",", "(", "retriever_tr_loss", "-", "retriever_logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "", "tb_writer", ".", "add_scalar", "(", "\n", "'reader_loss'", ",", "(", "reader_tr_loss", "-", "reader_logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\n", "'qa_loss'", ",", "(", "qa_tr_loss", "-", "qa_logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\n", "'rerank_loss'", ",", "(", "rerank_tr_loss", "-", "rerank_logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "if", "args", ".", "early_loss", ":", "\n", "                        ", "retriever_logging_loss", "=", "retriever_tr_loss", "\n", "", "reader_logging_loss", "=", "reader_tr_loss", "\n", "qa_logging_loss", "=", "qa_tr_loss", "\n", "rerank_logging_loss", "=", "rerank_tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "global_step", ")", ")", "\n", "retriever_model_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'retriever'", ")", "\n", "reader_model_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'reader'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "retriever_model_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "retriever_model_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "reader_model_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "reader_model_dir", ")", "\n", "\n", "# Take care of distributed/parallel training", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "\n", "model", ",", "'module'", ")", "else", "model", "\n", "retriever_model_to_save", "=", "model_to_save", ".", "retriever", "\n", "retriever_model_to_save", ".", "save_pretrained", "(", "\n", "retriever_model_dir", ")", "\n", "reader_model_to_save", "=", "model_to_save", ".", "reader", "\n", "reader_model_to_save", ".", "save_pretrained", "(", "reader_model_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "# print(all_train_retriever_run)", "\n", "", "", "assert", "len", "(", "all_train_retriever_run", ")", "==", "len", "(", "train_dataset", ")", ",", "(", "\n", "len", "(", "all_train_retriever_run", ")", ",", "len", "(", "train_dataset", ")", ")", "\n", "assert", "len", "(", "all_train_gold_passage_hit_run", ")", "==", "len", "(", "train_dataset", ")", ",", "(", "\n", "len", "(", "all_train_gold_passage_hit_run", ")", ",", "len", "(", "train_dataset", ")", ")", "\n", "# print('all_train_retriever_run', all_train_retriever_run)", "\n", "# print('all_train_gold_passage_hit_run', all_train_gold_passage_hit_run)", "\n", "\n", "train_retriever_run_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"train_retriever_run_{}.json\"", ".", "format", "(", "global_step", ")", ")", "\n", "with", "open", "(", "train_retriever_run_file", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "json", ".", "dump", "(", "all_train_retriever_run", ",", "fout", ")", "\n", "\n", "", "train_retriever_metrics", "=", "recall_evaluator", ".", "evaluate", "(", "\n", "all_train_retriever_run", ")", "\n", "train_retriever_recall_list", "=", "[", "v", "[", "'recall_5'", "]", "\n", "for", "v", "in", "train_retriever_metrics", ".", "values", "(", ")", "]", "\n", "train_retriever_recall", "=", "np", ".", "average", "(", "train_retriever_recall_list", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'train_retriever_recall'", ",", "\n", "train_retriever_recall", ",", "global_step", ")", "\n", "# print('train_retriever_recall_list', train_retriever_recall_list)", "\n", "\n", "# measure how many positive passages identified by weak supervision are gold passages", "\n", "gold_hit_metrics", "=", "p1_evaluator", ".", "evaluate", "(", "\n", "all_train_gold_passage_hit_run", ")", "\n", "gold_hit_list", "=", "[", "v", "[", "'P_1'", "]", "for", "v", "in", "gold_hit_metrics", ".", "values", "(", ")", "]", "\n", "gold_hit_p1", "=", "np", ".", "average", "(", "gold_hit_list", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'gold hit percent'", ",", "gold_hit_p1", ",", "global_step", ")", "\n", "# print('gold_hit_list', gold_hit_list)", "\n", "\n", "# print('num_has_positive_per_train_epoch', num_has_positive_per_train_epoch)", "\n", "if", "args", ".", "weak_supervision", "!=", "'none'", ":", "\n", "# sanitiy check", "\n", "            ", "num_has_positive_per_train_epoch_2nd_approach", "=", "0", "\n", "for", "v", "in", "all_train_gold_passage_hit_run", ".", "values", "(", ")", ":", "\n", "                ", "for", "vv", "in", "v", ".", "values", "(", ")", ":", "\n", "                    ", "num_has_positive_per_train_epoch_2nd_approach", "+=", "vv", "\n", "", "", "num_has_positive_per_train_epoch_2nd_approach", "=", "int", "(", "\n", "num_has_positive_per_train_epoch_2nd_approach", ")", "\n", "assert", "num_has_positive_per_train_epoch_2nd_approach", "==", "num_has_positive_per_train_epoch", ",", "(", "\n", "num_has_positive_per_train_epoch_2nd_approach", ",", "num_has_positive_per_train_epoch", ")", "\n", "\n", "", "tb_writer", ".", "add_scalar", "(", "'num_has_positive_per_train_epoch (weak supervision only)'", ",", "\n", "num_has_positive_per_train_epoch", ",", "global_step", ")", "\n", "num_has_positive_per_train_epoch_percent", "=", "num_has_positive_per_train_epoch", "/", "len", "(", "train_dataset", ")", "\n", "tb_writer", ".", "add_scalar", "(", "'num_has_positive_per_train_epoch_percent(weak supervision only)'", ",", "\n", "num_has_positive_per_train_epoch_percent", ",", "global_step", ")", "\n", "\n", "epoch_train_info", "=", "{", "'step'", ":", "global_step", ",", "\n", "'num_has_positive_per_train_epoch (weak supervision only)'", ":", "num_has_positive_per_train_epoch", ",", "\n", "'num_has_positive_per_train_epoch_percent (weak supervision only)'", ":", "num_has_positive_per_train_epoch_percent", ",", "\n", "'gold hit percent'", ":", "gold_hit_p1", ",", "\n", "'train_retriever_recall'", ":", "train_retriever_recall", ",", "\n", "'em_answer_found_num (em+learned only)'", ":", "em_answer_found_num", "}", "\n", "with", "open", "(", "train_info_file", ",", "'a'", ")", "as", "fout", ":", "\n", "            ", "fout", ".", "write", "(", "json", ".", "dumps", "(", "epoch_train_info", ",", "indent", "=", "1", ")", "+", "'\\n'", ")", "\n", "\n", "", "num_has_positive_per_train_epoch", "=", "0", "\n", "em_answer_found_num", "=", "0", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.evaluate": [[491, 682], ["DatasetClass", "os.path.join", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "timeit.default_timer", "tqdm.tqdm", "logger.info", "os.path.join", "os.path.join", "os.path.join", "utils.write_predictions", "utils.write_final_predictions", "scorer.quac_eval", "utils.get_retrieval_metrics", "scorer.quac_eval.update", "train_pipeline_weak_supervision.evaluate.get_eval_answer_from_gold_num"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_predictions", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_final_predictions", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.quac_eval", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.get_retrieval_metrics"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "retriever_tokenizer", ",", "reader_tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "if", "prefix", "==", "'test'", ":", "\n", "        ", "eval_file", "=", "args", ".", "test_file", "\n", "orig_eval_file", "=", "args", ".", "orig_test_file", "\n", "", "else", ":", "\n", "        ", "eval_file", "=", "args", ".", "dev_file", "\n", "orig_eval_file", "=", "args", ".", "orig_dev_file", "\n", "", "pytrec_eval_evaluator", "=", "evaluator", "\n", "\n", "# dataset, examples, features = load_and_cache_examples(args, tokenizer, evaluate=True, output_examples=True)", "\n", "DatasetClass", "=", "RetrieverDataset", "\n", "dataset", "=", "DatasetClass", "(", "eval_file", ",", "retriever_tokenizer", ",", "\n", "args", ".", "load_small", ",", "args", ".", "history_num", ",", "\n", "query_max_seq_length", "=", "args", ".", "retriever_query_max_seq_length", ",", "\n", "is_pretraining", "=", "args", ".", "is_pretraining", ",", "\n", "given_query", "=", "True", ",", "\n", "given_passage", "=", "False", ",", "\n", "include_first_for_retriever", "=", "args", ".", "include_first_for_retriever", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "predict_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'predictions'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "predict_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "predict_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "# eval_sampler = SequentialSampler(", "\n", "#     dataset) if args.local_rank == -1 else DistributedSampler(dataset)", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "# model.to(f'cuda:{model.device_ids[0]}')", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "retriever_run_dict", ",", "rarank_run_dict", "=", "{", "}", ",", "{", "}", "\n", "examples", ",", "features", "=", "{", "}", ",", "{", "}", "\n", "all_results", "=", "[", "]", "\n", "start_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "qids", "=", "np", ".", "asarray", "(", "batch", "[", "'qid'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "# print(qids)", "\n", "question_texts", "=", "np", ".", "asarray", "(", "\n", "batch", "[", "'question_text'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "answer_texts", "=", "np", ".", "asarray", "(", "\n", "batch", "[", "'answer_text'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "answer_starts", "=", "np", ".", "asarray", "(", "\n", "batch", "[", "'answer_start'", "]", ")", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "query_reps", "=", "gen_query_reps", "(", "args", ",", "model", ",", "batch", ")", "\n", "\n", "# if args.weak_supervision == 'none':", "\n", "# during evaluation, no weak answers need to be matched", "\n", "# so we use retrieve instead of retrieve_weak_supervision", "\n", "retrieval_results", "=", "retrieve", "(", "args", ",", "qids", ",", "qid_to_idx", ",", "query_reps", ",", "\n", "passage_ids", ",", "passage_id_to_idx", ",", "passage_reps", ",", "\n", "qrels", ",", "qrels_sparse_matrix", ",", "\n", "gpu_index", ",", "include_positive_passage", "=", "False", ")", "\n", "#         else:", "\n", "#             retrieval_results = retrieve_weak_supervision(args, qids, qid_to_idx, query_reps,", "\n", "#                                                           passage_ids, passage_id_to_idx, passage_reps,", "\n", "#                                                           gpu_index, answer_texts, answer_starts)", "\n", "\n", "#         if args.weak_supervision != 'none':", "\n", "\n", "#             weak_answer_texts = retrieval_results['weak_answer_texts']", "\n", "#             weak_answer_starts = retrieval_results['weak_answer_starts']", "\n", "#             # if len(weak_answer_texts) > 0 and len(weak_answer_starts) > 0 and \\", "\n", "#             # (weak_answer_texts[0] != answer_texts[0] or weak_answer_starts[0] != answer_starts[0]):", "\n", "#             #     print('answer_texts', answer_texts, 'weak_answer_texts', weak_answer_texts)", "\n", "#             #     print('answer_starts', answer_starts, 'weak_answer_starts', weak_answer_starts)", "\n", "#             answer_texts = weak_answer_texts", "\n", "#             answer_starts = weak_answer_starts", "\n", "\n", "retriever_probs", "=", "retrieval_results", "[", "'retriever_probs'", "]", "\n", "# print('retriever_probs before', retriever_probs)", "\n", "pids_for_reader", "=", "retrieval_results", "[", "'pids_for_reader'", "]", "\n", "passages_for_reader", "=", "retrieval_results", "[", "'passages_for_reader'", "]", "\n", "labels_for_reader", "=", "retrieval_results", "[", "'labels_for_reader'", "]", "\n", "\n", "if", "args", ".", "real_joint_learn", ":", "\n", "            ", "passage_reps_for_reader", "=", "retrieval_results", "[", "'passage_reps_for_reader'", "]", "\n", "\n", "", "if", "args", ".", "real_joint_learn", ":", "\n", "            ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'query_input_ids'", ":", "batch", "[", "'query_input_ids'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'query_attention_mask'", ":", "batch", "[", "'query_attention_mask'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'query_token_type_ids'", ":", "batch", "[", "'query_token_type_ids'", "]", ".", "to", "(", "args", ".", "device", ")", ",", "\n", "'passage_rep'", ":", "torch", ".", "from_numpy", "(", "passage_reps_for_reader", ")", ".", "to", "(", "args", ".", "device", ")", "}", "\n", "retriever_outputs_for_reader", "=", "model", ".", "retriever", "(", "**", "inputs", ")", "\n", "retriever_logits_for_reader", "=", "retriever_outputs_for_reader", "[", "0", "]", "\n", "\n", "", "", "reader_batch", ",", "batch_examples", ",", "batch_features", "=", "gen_reader_features", "(", "qids", ",", "question_texts", ",", "answer_texts", ",", "\n", "answer_starts", ",", "pids_for_reader", ",", "\n", "passages_for_reader", ",", "labels_for_reader", ",", "\n", "reader_tokenizer", ",", "\n", "args", ".", "reader_max_seq_length", ",", "\n", "is_training", "=", "False", ")", "\n", "example_ids", "=", "reader_batch", "[", "'example_id'", "]", "\n", "# print('example_ids', example_ids)", "\n", "examples", ".", "update", "(", "batch_examples", ")", "\n", "features", ".", "update", "(", "batch_features", ")", "\n", "reader_batch", "=", "{", "k", ":", "v", ".", "to", "(", "args", ".", "device", ")", "\n", "for", "k", ",", "v", "in", "reader_batch", ".", "items", "(", ")", "if", "k", "!=", "'example_id'", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "'input_ids'", ":", "reader_batch", "[", "'input_ids'", "]", ",", "\n", "'attention_mask'", ":", "reader_batch", "[", "'input_mask'", "]", ",", "\n", "'token_type_ids'", ":", "reader_batch", "[", "'segment_ids'", "]", "}", "\n", "if", "args", ".", "real_joint_learn", ":", "\n", "                ", "inputs", "[", "'retriever_logits'", "]", "=", "retriever_logits_for_reader", "\n", "", "outputs", "=", "model", ".", "reader", "(", "**", "inputs", ")", "\n", "\n", "", "retriever_probs", "=", "retriever_probs", ".", "reshape", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "# print('retriever_probs after', retriever_probs)", "\n", "if", "args", ".", "real_joint_learn", ":", "\n", "            ", "for", "i", ",", "example_id", "in", "enumerate", "(", "example_ids", ")", ":", "\n", "                ", "result", "=", "RawResult", "(", "unique_id", "=", "example_id", ",", "\n", "start_logits", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "\n", "end_logits", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "retrieval_logits", "=", "to_list", "(", "outputs", "[", "2", "]", "[", "i", "]", ")", ",", "\n", "retriever_prob", "=", "to_list", "(", "outputs", "[", "3", "]", "[", "i", "]", "[", "0", "]", ")", ")", "# [i][0] is equivalent to squeeze", "\n", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "for", "i", ",", "example_id", "in", "enumerate", "(", "example_ids", ")", ":", "\n", "                ", "result", "=", "RawResult", "(", "unique_id", "=", "example_id", ",", "\n", "start_logits", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "\n", "end_logits", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "retrieval_logits", "=", "to_list", "(", "outputs", "[", "2", "]", "[", "i", "]", ")", ",", "\n", "retriever_prob", "=", "retriever_probs", "[", "i", "]", ")", "\n", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "", "evalTime", "=", "timeit", ".", "default_timer", "(", ")", "-", "start_time", "\n", "logger", ".", "info", "(", "\"  Evaluation done in total %f secs (%f sec per example)\"", ",", "\n", "evalTime", ",", "evalTime", "/", "len", "(", "dataset", ")", ")", "\n", "\n", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"instance_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_nbest_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"instance_nbest_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_final_prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"final_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "        ", "output_null_log_odds_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"instance_null_odds_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "", "else", ":", "\n", "        ", "output_null_log_odds_file", "=", "None", "\n", "\n", "", "all_predictions", "=", "write_predictions", "(", "examples", ",", "features", ",", "all_results", ",", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "args", ".", "do_lower_case", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "output_null_log_odds_file", ",", "args", ".", "verbose_logging", ",", "\n", "args", ".", "version_2_with_negative", ",", "args", ".", "null_score_diff_threshold", ")", "\n", "dialog_level_preds", "=", "write_final_predictions", "(", "all_predictions", ",", "output_final_prediction_file", ",", "\n", "use_rerank_prob", "=", "args", ".", "use_rerank_prob", ",", "\n", "use_retriever_prob", "=", "args", ".", "use_retriever_prob", ",", "\n", "real_joint_learn", "=", "args", ".", "real_joint_learn", ",", "\n", "involve_rerank_in_real_joint_learn", "=", "args", ".", "involve_rerank_in_real_joint_learn", ")", "\n", "eval_metrics", "=", "quac_eval", "(", "\n", "orig_eval_file", ",", "output_final_prediction_file", ")", "\n", "rerank_metrics", "=", "get_retrieval_metrics", "(", "\n", "pytrec_eval_evaluator", ",", "all_predictions", ",", "eval_retriever_probs", "=", "True", ")", "\n", "eval_metrics", ".", "update", "(", "rerank_metrics", ")", "\n", "\n", "# how many answers in dev/test prediction results come from the gold passage", "\n", "def", "get_eval_answer_from_gold_num", "(", "dialog_level_preds", ",", "qrels", ")", ":", "\n", "        ", "eval_answer_from_gold_num", "=", "0", "\n", "for", "v", "in", "dialog_level_preds", ":", "\n", "            ", "for", "each_qid", ",", "each_pid", "in", "zip", "(", "v", "[", "'qid'", "]", ",", "v", "[", "'pid'", "]", ")", ":", "\n", "# if each_pid in qrels[each_qid]:", "\n", "                ", "if", "each_pid", "in", "qrels", ".", "get", "(", "each_qid", ",", "{", "}", ")", ":", "# compatible with coqa, coqa has no qrels", "\n", "                    ", "eval_answer_from_gold_num", "+=", "1", "\n", "\n", "", "", "", "return", "eval_answer_from_gold_num", "\n", "\n", "", "eval_answer_from_gold_num", "=", "get_eval_answer_from_gold_num", "(", "dialog_level_preds", ",", "qrels", ")", "\n", "eval_answer_from_gold_persent", "=", "eval_answer_from_gold_num", "/", "len", "(", "dataset", ")", "\n", "eval_metrics", "[", "'eval_answer_from_gold_persent'", "]", "=", "eval_answer_from_gold_persent", "\n", "\n", "metrics_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"metrics_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "with", "open", "(", "metrics_file", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "json", ".", "dump", "(", "eval_metrics", ",", "fout", ")", "\n", "\n", "", "return", "eval_metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.gen_query_reps": [[687, 700], ["model.eval", "v.to", "torch.no_grad", "model.retriever", "batch.items"], "function", ["None"], ["", "def", "gen_query_reps", "(", "args", ",", "model", ",", "batch", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "args", ".", "device", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "\n", "if", "k", "not", "in", "[", "'example_id'", ",", "'qid'", ",", "'question_text'", ",", "'answer_text'", ",", "'answer_start'", "]", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "inputs", "=", "{", "}", "\n", "inputs", "[", "'query_input_ids'", "]", "=", "batch", "[", "'query_input_ids'", "]", "\n", "inputs", "[", "'query_attention_mask'", "]", "=", "batch", "[", "'query_attention_mask'", "]", "\n", "inputs", "[", "'query_token_type_ids'", "]", "=", "batch", "[", "'query_token_type_ids'", "]", "\n", "outputs", "=", "model", ".", "retriever", "(", "**", "inputs", ")", "\n", "query_reps", "=", "outputs", "[", "0", "]", "\n", "\n", "", "return", "query_reps", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.retrieve": [[705, 782], ["query_reps.detach().cpu().numpy.detach().cpu().numpy", "gpu_index.search", "numpy.copy", "numpy.expand_dims", "numpy.repeat", "qrels_sparse_matrix[].toarray", "scipy.special.softmax", "numpy.expand_dims", "numpy.repeat", "qrels_sparse_matrix[].toarray", "get_passages", "enumerate", "qrels_sparse_matrix[].toarray", "enumerate", "qrels_sparse_matrix[].toarray", "query_reps.detach().cpu().numpy.detach().cpu", "zip", "numpy.sum", "numpy.sum", "len", "zip", "numpy.sum", "numpy.sum", "len", "query_reps.detach().cpu().numpy.detach", "list", "list", "qrels[].keys", "qrels[].keys"], "function", ["None"], ["", "def", "retrieve", "(", "args", ",", "qids", ",", "qid_to_idx", ",", "query_reps", ",", "\n", "passage_ids", ",", "passage_id_to_idx", ",", "passage_reps", ",", "\n", "qrels", ",", "qrels_sparse_matrix", ",", "\n", "gpu_index", ",", "include_positive_passage", "=", "False", ")", ":", "\n", "    ", "query_reps", "=", "query_reps", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "D", ",", "I", "=", "gpu_index", ".", "search", "(", "query_reps", ",", "args", ".", "top_k_for_retriever", ")", "\n", "\n", "pidx_for_retriever", "=", "np", ".", "copy", "(", "I", ")", "\n", "qidx", "=", "[", "qid_to_idx", "[", "qid", "]", "for", "qid", "in", "qids", "]", "\n", "qidx_expanded", "=", "np", ".", "expand_dims", "(", "qidx", ",", "axis", "=", "1", ")", "\n", "qidx_expanded", "=", "np", ".", "repeat", "(", "qidx_expanded", ",", "args", ".", "top_k_for_retriever", ",", "axis", "=", "1", ")", "\n", "labels_for_retriever", "=", "qrels_sparse_matrix", "[", "qidx_expanded", ",", "pidx_for_retriever", "]", ".", "toarray", "(", "\n", ")", "\n", "# print('labels_for_retriever before', labels_for_retriever)", "\n", "if", "include_positive_passage", ":", "\n", "        ", "for", "i", ",", "(", "qid", ",", "labels_per_query", ")", "in", "enumerate", "(", "zip", "(", "qids", ",", "labels_for_retriever", ")", ")", ":", "\n", "            ", "has_positive", "=", "np", ".", "sum", "(", "labels_per_query", ")", "\n", "if", "not", "has_positive", ":", "\n", "                ", "positive_pid", "=", "list", "(", "qrels", "[", "qid", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "positive_pidx", "=", "passage_id_to_idx", "[", "positive_pid", "]", "\n", "pidx_for_retriever", "[", "i", "]", "[", "-", "1", "]", "=", "positive_pidx", "\n", "", "", "labels_for_retriever", "=", "qrels_sparse_matrix", "[", "qidx_expanded", ",", "pidx_for_retriever", "]", ".", "toarray", "(", "\n", ")", "\n", "# print('labels_for_retriever after', labels_for_retriever)", "\n", "assert", "np", ".", "sum", "(", "labels_for_retriever", ")", ">=", "len", "(", "labels_for_retriever", ")", "\n", "", "pids_for_retriever", "=", "passage_ids", "[", "pidx_for_retriever", "]", "\n", "passage_reps_for_retriever", "=", "passage_reps", "[", "pidx_for_retriever", "]", "\n", "\n", "scores", "=", "D", "[", ":", ",", ":", "args", ".", "top_k_for_reader", "]", "\n", "retriever_probs", "=", "sp", ".", "special", ".", "softmax", "(", "scores", ",", "axis", "=", "1", ")", "\n", "pidx_for_reader", "=", "I", "[", ":", ",", ":", "args", ".", "top_k_for_reader", "]", "\n", "# print('pidx_for_reader', pidx_for_reader)", "\n", "# print('qids', qids)", "\n", "# print('qidx', qidx)", "\n", "qidx_expanded", "=", "np", ".", "expand_dims", "(", "qidx", ",", "axis", "=", "1", ")", "\n", "qidx_expanded", "=", "np", ".", "repeat", "(", "qidx_expanded", ",", "args", ".", "top_k_for_reader", ",", "axis", "=", "1", ")", "\n", "# print('qidx_expanded', qidx_expanded)", "\n", "\n", "labels_for_reader", "=", "qrels_sparse_matrix", "[", "qidx_expanded", ",", "pidx_for_reader", "]", ".", "toarray", "(", "\n", ")", "\n", "# print('labels_for_reader before', labels_for_reader)", "\n", "# print('labels_for_reader before', labels_for_reader)", "\n", "if", "include_positive_passage", ":", "\n", "        ", "for", "i", ",", "(", "qid", ",", "labels_per_query", ")", "in", "enumerate", "(", "zip", "(", "qids", ",", "labels_for_reader", ")", ")", ":", "\n", "            ", "has_positive", "=", "np", ".", "sum", "(", "labels_per_query", ")", "\n", "if", "not", "has_positive", ":", "\n", "                ", "positive_pid", "=", "list", "(", "qrels", "[", "qid", "]", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "positive_pidx", "=", "passage_id_to_idx", "[", "positive_pid", "]", "\n", "pidx_for_reader", "[", "i", "]", "[", "-", "1", "]", "=", "positive_pidx", "\n", "", "", "labels_for_reader", "=", "qrels_sparse_matrix", "[", "qidx_expanded", ",", "pidx_for_reader", "]", ".", "toarray", "(", "\n", ")", "\n", "# print('labels_for_reader after', labels_for_reader)", "\n", "assert", "np", ".", "sum", "(", "labels_for_reader", ")", ">=", "len", "(", "labels_for_reader", ")", "\n", "# print('labels_for_reader after', labels_for_reader)", "\n", "", "pids_for_reader", "=", "passage_ids", "[", "pidx_for_reader", "]", "\n", "# print('pids_for_reader', pids_for_reader)", "\n", "passages_for_reader", "=", "get_passages", "(", "pidx_for_reader", ",", "args", ")", "\n", "# we do not need to modify scores and probs matrices because they will only be", "\n", "# needed at evaluation, where include_positive_passage will be false", "\n", "if", "args", ".", "real_joint_learn", ":", "\n", "        ", "passage_reps_for_reader", "=", "passage_reps", "[", "pidx_for_reader", "]", "\n", "\n", "", "return_dict", "=", "{", "'qidx'", ":", "qidx", ",", "\n", "'pidx_for_retriever'", ":", "pidx_for_retriever", ",", "\n", "'pids_for_retriever'", ":", "pids_for_retriever", ",", "\n", "'passage_reps_for_retriever'", ":", "passage_reps_for_retriever", ",", "\n", "'labels_for_retriever'", ":", "labels_for_retriever", ",", "\n", "'retriever_probs'", ":", "retriever_probs", ",", "\n", "'pidx_for_reader'", ":", "pidx_for_reader", ",", "\n", "'pids_for_reader'", ":", "pids_for_reader", ",", "\n", "'passages_for_reader'", ":", "passages_for_reader", ",", "\n", "'labels_for_reader'", ":", "labels_for_reader", "}", "\n", "\n", "if", "args", ".", "real_joint_learn", ":", "\n", "        ", "return_dict", "[", "'passage_reps_for_reader'", "]", "=", "passage_reps_for_reader", "\n", "\n", "", "return", "return_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.retrieve_weak_supervision": [[787, 925], ["query_reps.detach().cpu().numpy.detach().cpu().numpy", "gpu_index.search", "get_passages", "enumerate", "numpy.vstack", "scipy.special.softmax", "numpy.array", "numpy.array", "zip", "find_weak_answer_func", "new_passages_for_reader_list.append", "np.array.append", "np.array.append", "weak_answer_texts.append", "len", "len", "numpy.hstack", "numpy.array", "query_reps.detach().cpu().numpy.detach().cpu", "copy.copy", "numpy.zeros", "query_reps.detach().cpu().numpy.detach"], "function", ["None"], ["", "def", "retrieve_weak_supervision", "(", "args", ",", "qids", ",", "qid_to_idx", ",", "query_reps", ",", "\n", "passage_ids", ",", "passage_id_to_idx", ",", "passage_reps", ",", "\n", "gpu_index", ",", "answer_texts", ",", "answer_starts", ")", ":", "\n", "    ", "find_weak_answer_funcs", "=", "{", "\n", "'em'", ":", "find_weak_answer_em", ",", "\n", "'f1'", ":", "find_weak_answer_f1", ",", "\n", "'learned'", ":", "find_weak_answer_learned", ",", "\n", "'em+learned'", ":", "find_weak_answer_em_learned", "}", "\n", "find_weak_answer_func", "=", "find_weak_answer_funcs", "[", "args", ".", "weak_supervision", "]", "\n", "\n", "query_reps", "=", "query_reps", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "D", ",", "I", "=", "gpu_index", ".", "search", "(", "query_reps", ",", "args", ".", "top_k_for_retriever", ")", "\n", "\n", "pidx_for_retriever", "=", "I", "[", ":", ",", ":", "args", ".", "top_k_for_retriever", "]", "\n", "# qidx = [qid_to_idx[qid] for qid in qids]", "\n", "\n", "pidx_for_reader", "=", "I", "[", ":", ",", ":", "args", ".", "top_k_for_reader", "]", "\n", "pids_for_reader", "=", "passage_ids", "[", "pidx_for_reader", "]", "\n", "passages_for_reader", "=", "get_passages", "(", "pidx_for_reader", ",", "args", ")", "\n", "# print('passages_for_reader', type(passages_for_reader), passages_for_reader)", "\n", "\n", "# qidx_expanded = np.expand_dims(qidx, axis=1)", "\n", "# qidx_expanded = np.repeat(qidx_expanded, args.top_k_for_reader, axis=1)", "\n", "# true_labels_for_reader = qrels_sparse_matrix[qidx_expanded, pidx_for_reader].toarray()", "\n", "\n", "# print('pidx_for_reader', pidx_for_reader)", "\n", "# print('qids', qids)", "\n", "# print('qidx', qidx)", "\n", "\n", "num_has_positive", "=", "0", "\n", "\n", "labels_for_reader", "=", "[", "]", "\n", "weak_answer_starts", "=", "[", "]", "\n", "weak_answer_texts", "=", "[", "]", "\n", "# valid_idx = []  # queries with at least one gold passage identifed by weak supervision is valid", "\n", "# queries (training instances) w/o any gold passage will be discarded", "\n", "new_passages_for_reader_list", "=", "[", "]", "\n", "for", "i", ",", "(", "qid", ",", "answer_text", ",", "answer_start", ",", "passages_per_query", ")", "in", "enumerate", "(", "zip", "(", "qids", ",", "answer_texts", ",", "answer_starts", ",", "passages_for_reader", ")", ")", ":", "\n", "        ", "(", "labels_per_query", ",", "final_weak_answer_start", ",", "weak_answer_text", ",", "\n", "int_has_positive", ",", "new_passages_per_query", ")", "=", "find_weak_answer_func", "(", "\n", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", "\n", "new_passages_for_reader_list", ".", "append", "(", "new_passages_per_query", ")", "\n", "\n", "# print('int_has_positive:', int_has_positive)", "\n", "# print('answer_start:', answer_start)", "\n", "# print('answer_text:', answer_text)", "\n", "# print('final_weak_answer_start:', final_weak_answer_start)", "\n", "# print('weak_answer_text:', weak_answer_text)", "\n", "# print('labels_per_query:', labels_per_query)", "\n", "# print('passages_per_query', passages_per_query)", "\n", "\n", "num_has_positive", "+=", "int_has_positive", "\n", "labels_for_reader", ".", "append", "(", "copy", "(", "labels_per_query", ")", ")", "\n", "weak_answer_starts", ".", "append", "(", "final_weak_answer_start", ")", "\n", "weak_answer_texts", ".", "append", "(", "weak_answer_text", ")", "\n", "# if weak_answer_starts[i] != -1 and weak_answer_starts[i] != answer_start:", "\n", "#     print('answer_start', answer_start, 'weak_answer_start', weak_answer_starts[i])", "\n", "#     print('true_labels_per_query', true_labels_for_reader[i], 'labels_per_query', labels_per_query)", "\n", "#     print('passages_for_reader', passages_for_reader)", "\n", "", "new_passages_for_reader", "=", "np", ".", "vstack", "(", "new_passages_for_reader_list", ")", "\n", "\n", "# print('new_passages_for_reader', type(new_passages_for_reader), new_passages_for_reader)", "\n", "\n", "scores", "=", "D", "[", ":", ",", ":", "args", ".", "top_k_for_reader", "]", "\n", "retriever_probs", "=", "sp", ".", "special", ".", "softmax", "(", "scores", ",", "axis", "=", "1", ")", "\n", "labels_for_reader", "=", "np", ".", "array", "(", "labels_for_reader", ")", "\n", "weak_answer_starts", "=", "np", ".", "array", "(", "weak_answer_starts", ")", "\n", "\n", "assert", "len", "(", "weak_answer_texts", ")", "==", "len", "(", "\n", "answer_texts", ")", ",", "(", "'len (weak)_answer_texts'", ",", "weak_answer_texts", ",", "answer_texts", ")", "\n", "# assert np.sum(labels_for_reader) >= len(labels_for_reader)", "\n", "\n", "if", "args", ".", "early_loss", ":", "\n", "        ", "pids_for_retriever", "=", "passage_ids", "[", "pidx_for_retriever", "]", "\n", "passage_reps_for_retriever", "=", "passage_reps", "[", "pidx_for_retriever", "]", "\n", "\n", "\n", "top_k_diff", "=", "args", ".", "top_k_for_retriever", "-", "args", ".", "top_k_for_reader", "\n", "assert", "top_k_diff", ">=", "0", ",", "'top_k_for_retriever should >= top_k_for_reader'", "\n", "batch_size", ",", "block_num", "=", "labels_for_reader", ".", "shape", "\n", "# since we have already identified a positive passage in top_k_for_reader,", "\n", "# the rest of top_k_for_retriever will be considered as negative passages", "\n", "labels_for_retriever", "=", "np", ".", "hstack", "(", "(", "labels_for_reader", ",", "\n", "np", ".", "zeros", "(", "(", "batch_size", ",", "top_k_diff", ")", ",", "dtype", "=", "int", ")", ")", ")", "\n", "# print('labels_for_reader', labels_for_reader)", "\n", "# print('labels_for_retriever', labels_for_retriever)", "\n", "#         if args.top_k_for_retriever == args.top_k_for_reader:", "\n", "#             # print('top_k_for_retriever == top_k_for_reader')", "\n", "#             pids_for_retriever = np.copy(pids_for_reader)", "\n", "#             passage_reps_for_retriever = passage_reps[pidx_for_retriever]", "\n", "#             labels_for_retriever = np.copy(labels_for_reader)", "\n", "#         else:", "\n", "#             passages_for_retriever = get_passages(pidx_for_retriever, args)", "\n", "#             labels_for_retriever = []", "\n", "#             for i, (qid, answer_text, passages_per_query) in enumerate(zip(qids, answer_texts, passages_for_retriever)):", "\n", "#                 labels_per_query, _, _, _, _ = find_weak_answer_func(", "\n", "#                     args, qid, answer_text, passages_per_query)", "\n", "\n", "#                 labels_for_retriever.append(copy(labels_per_query))", "\n", "\n", "#             # print('labels_for_retriever', labels_for_retriever)", "\n", "#             assert np.sum(labels_for_retriever) >= len(labels_for_retriever)", "\n", "\n", "#             pids_for_retriever = passage_ids[pidx_for_retriever]", "\n", "#             passage_reps_for_retriever = passage_reps[pidx_for_retriever]", "\n", "\n", "", "else", ":", "\n", "        ", "pidx_for_retriever", "=", "[", "]", "\n", "pids_for_retriever", "=", "[", "]", "\n", "passage_reps_for_retriever", "=", "[", "]", "\n", "labels_for_retriever", "=", "[", "]", "\n", "\n", "# print('pids_for_reader', pids_for_reader)", "\n", "\n", "# we do not need to modify scores and probs matrices because they will only be", "\n", "# needed at evaluation, where include_positive_passage will be false", "\n", "", "if", "args", ".", "real_joint_learn", ":", "\n", "        ", "passage_reps_for_reader", "=", "passage_reps", "[", "pidx_for_reader", "]", "\n", "\n", "", "return_dict", "=", "{", "# 'qidx': qidx,", "\n", "'pidx_for_retriever'", ":", "pidx_for_retriever", ",", "\n", "'pids_for_retriever'", ":", "pids_for_retriever", ",", "\n", "'passage_reps_for_retriever'", ":", "passage_reps_for_retriever", ",", "\n", "'labels_for_retriever'", ":", "np", ".", "array", "(", "labels_for_retriever", ")", ",", "\n", "'retriever_probs'", ":", "retriever_probs", ",", "\n", "'pidx_for_reader'", ":", "pidx_for_reader", ",", "\n", "'pids_for_reader'", ":", "pids_for_reader", ",", "\n", "'passages_for_reader'", ":", "new_passages_for_reader", ",", "\n", "'labels_for_reader'", ":", "labels_for_reader", ",", "\n", "'weak_answer_starts'", ":", "weak_answer_starts", ",", "\n", "'weak_answer_texts'", ":", "weak_answer_texts", ",", "\n", "'num_has_positive'", ":", "num_has_positive", "}", "\n", "\n", "if", "args", ".", "real_joint_learn", ":", "\n", "# passages_for_reader = passages_for_reader[valid_idx]", "\n", "        ", "return_dict", "[", "'passage_reps_for_reader'", "]", "=", "passage_reps_for_reader", "\n", "\n", "", "return", "return_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.find_weak_answer_em": [[930, 958], ["enumerate", "int", "len", "passage.lower().find", "answer_text.lower", "passage.lower", "len"], "function", ["None"], ["", "def", "find_weak_answer_em", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", ":", "\n", "    ", "labels_per_query", "=", "[", "0", "]", "*", "len", "(", "passages_per_query", ")", "\n", "has_positive", "=", "False", "\n", "final_weak_answer_text", "=", "None", "\n", "final_weak_answer_start", "=", "None", "\n", "for", "i", ",", "passage", "in", "enumerate", "(", "passages_per_query", ")", ":", "\n", "        ", "weak_answer_start", "=", "passage", ".", "lower", "(", ")", ".", "find", "(", "answer_text", ".", "lower", "(", ")", ")", "\n", "if", "weak_answer_start", "!=", "-", "1", ":", "\n", "            ", "has_positive", "=", "True", "\n", "labels_per_query", "[", "i", "]", "=", "1", "\n", "final_weak_answer_text", "=", "passage", "[", "weak_answer_start", ":", "weak_answer_start", "+", "len", "(", "answer_text", ")", "]", "\n", "final_weak_answer_start", "=", "weak_answer_start", "\n", "break", "\n", "\n", "", "", "if", "not", "has_positive", ":", "\n", "# if no gold passage is identified, we assume the first retrieved passage is true for retriever", "\n", "# and cannotanswer is the weak answer for reader", "\n", "# labels_per_query[0] = 1", "\n", "        ", "final_weak_answer_start", "=", "0", "\n", "final_weak_answer_text", "=", "'CANNOTANSWER'", "\n", "\n", "", "int_has_positive", "=", "int", "(", "has_positive", ")", "\n", "# print('qid', qid)", "\n", "# print('answer_text', answer_text)", "\n", "# print('final_weak_answer_text', final_weak_answer_text)", "\n", "# print('int_has_positive', int_has_positive)", "\n", "return", "(", "labels_per_query", ",", "final_weak_answer_start", ",", "final_weak_answer_text", ",", "\n", "int_has_positive", ",", "passages_per_query", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.find_weak_answer_f1": [[963, 999], ["enumerate", "int", "len", "nlp", "str", "scorer.f1_score", "passage.index"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.f1_score"], ["", "def", "find_weak_answer_f1", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", ":", "\n", "    ", "labels_per_query", "=", "[", "0", "]", "*", "len", "(", "passages_per_query", ")", "\n", "\n", "has_positive", "=", "False", "\n", "max_f1", "=", "-", "1.0", "\n", "best_passage_idx", "=", "-", "1", "\n", "best_weak_answer_text", "=", "None", "\n", "best_weak_answer_start", "=", "None", "\n", "\n", "for", "i", ",", "passage", "in", "enumerate", "(", "passages_per_query", ")", ":", "\n", "        ", "doc", "=", "nlp", "(", "str", "(", "passage", ")", ")", "\n", "sents", "=", "doc", ".", "sents", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "sent", "=", "sent", ".", "text", "\n", "weak_answer_f1", "=", "f1_score", "(", "sent", ",", "answer_text", ")", "\n", "sent_idx", "=", "passage", ".", "index", "(", "sent", ")", "\n", "if", "weak_answer_f1", ">", "max_f1", ":", "\n", "                ", "max_f1", "=", "weak_answer_f1", "\n", "best_passage_idx", "=", "i", "\n", "best_weak_answer_text", "=", "sent", "\n", "best_weak_answer_start", "=", "sent_idx", "\n", "# print('max_f1', max_f1)", "\n", "", "", "", "if", "max_f1", ">", "0", ":", "\n", "        ", "has_positive", "=", "True", "\n", "labels_per_query", "[", "best_passage_idx", "]", "=", "1", "\n", "", "else", ":", "\n", "# if no gold passage is identified, we assume the first retrieved passage is true for retriever", "\n", "# and cannotanswer is the weak answer for reader", "\n", "# labels_per_query[0] = 1", "\n", "        ", "best_weak_answer_start", "=", "0", "\n", "best_weak_answer_text", "=", "'CANNOTANSWER'", "\n", "\n", "", "int_has_positive", "=", "int", "(", "has_positive", ")", "\n", "\n", "return", "(", "labels_per_query", ",", "best_weak_answer_start", ",", "best_weak_answer_text", ",", "\n", "int_has_positive", ",", "passages_per_query", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.find_weak_answer_learned": [[1004, 1043], ["train_pipeline_weak_supervision.supervisor_inference", "float", "enumerate", "int", "len", "zip", "numpy.array", "examples.values", "passage.find"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.supervisor_inference"], ["", "def", "find_weak_answer_learned", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", ":", "\n", "    ", "supervisor_outputs", ",", "examples", "=", "supervisor_inference", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", "\n", "# to deal with the inconsistent space in passage and answer:", "\n", "new_passages_per_qery", "=", "[", "' '", ".", "join", "(", "example", ".", "doc_tokens", ")", "for", "example", "in", "examples", ".", "values", "(", ")", "]", "\n", "# print([example.example_id for example in examples.values()])", "\n", "# print(new_passages_per_qery)", "\n", "labels_per_query", "=", "[", "0", "]", "*", "len", "(", "passages_per_query", ")", "\n", "\n", "has_positive", "=", "False", "\n", "max_score", "=", "float", "(", "'-inf'", ")", "\n", "best_passage_idx", "=", "-", "1", "\n", "best_weak_answer_text", "=", "None", "\n", "best_weak_answer_start", "=", "None", "\n", "\n", "for", "i", ",", "(", "passage", ",", "supervisor_output", ")", "in", "enumerate", "(", "zip", "(", "new_passages_per_qery", ",", "supervisor_outputs", ")", ")", ":", "\n", "        ", "weak_answer", "=", "supervisor_output", "[", "'weak_answer'", "]", "\n", "score", "=", "supervisor_output", "[", "'score'", "]", "\n", "if", "weak_answer", "!=", "'CANNOTANSWER'", "and", "weak_answer", "!=", "'empty'", ":", "\n", "            ", "has_positive", "=", "True", "\n", "if", "score", ">", "max_score", ":", "\n", "                ", "max_score", "=", "score", "\n", "best_passage_idx", "=", "i", "\n", "best_weak_answer_text", "=", "weak_answer", "\n", "best_weak_answer_start", "=", "passage", ".", "find", "(", "weak_answer", ")", "\n", "assert", "best_weak_answer_start", "!=", "-", "1", ",", "(", "weak_answer", ",", "answer_text", ",", "score", ",", "passage", ")", "\n", "# print('max_f1', max_f1)", "\n", "", "", "", "if", "has_positive", ":", "\n", "        ", "labels_per_query", "[", "best_passage_idx", "]", "=", "1", "\n", "", "else", ":", "\n", "# if no gold passage is identified, we assume the first retrieved passage is true for retriever", "\n", "# and cannotanswer is the weak answer for reader", "\n", "# labels_per_query[0] = 1", "\n", "        ", "best_weak_answer_start", "=", "0", "\n", "best_weak_answer_text", "=", "'CANNOTANSWER'", "\n", "\n", "", "int_has_positive", "=", "int", "(", "has_positive", ")", "\n", "# print('max_score', max_score, 'best_weak_answer_text', best_weak_answer_text)", "\n", "return", "(", "labels_per_query", ",", "best_weak_answer_start", ",", "best_weak_answer_text", ",", "\n", "int_has_positive", ",", "np", ".", "array", "(", "new_passages_per_qery", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.find_weak_answer_em_learned": [[1048, 1084], ["train_pipeline_weak_supervision.find_weak_answer_em", "train_pipeline_weak_supervision.find_weak_answer_learned", "new_passages_per_query.tolist", "open", "fout.write", "json.dumps"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.find_weak_answer_em", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.find_weak_answer_learned"], ["", "def", "find_weak_answer_em_learned", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", ":", "\n", "    ", "global", "em_answer_found_num", "\n", "\n", "method", "=", "None", "\n", "em_result", "=", "find_weak_answer_em", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", "\n", "em_weak_answer", "=", "em_result", "[", "2", "]", "\n", "if", "em_weak_answer", "!=", "'CANNOTANSWER'", ":", "\n", "# print('using em', em_weak_answer)", "\n", "        ", "em_answer_found_num", "+=", "1", "\n", "return_result", "=", "em_result", "\n", "method", "=", "'em'", "\n", "", "else", ":", "\n", "        ", "learned_result", "=", "find_weak_answer_learned", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", "\n", "# learned_weak_answer = learned_result[2]", "\n", "# print('using learned', 'em:', em_weak_answer, 'learned:', learned_weak_answer)", "\n", "return_result", "=", "learned_result", "\n", "method", "=", "'learned'", "\n", "\n", "", "if", "args", ".", "case_study", ":", "\n", "        ", "(", "labels_per_query", ",", "final_weak_answer_start", ",", "weak_answer_text", ",", "\n", "int_has_positive", ",", "new_passages_per_query", ")", "=", "return_result", "\n", "\n", "if", "weak_answer_text", "!=", "'CANNOTANSWER'", ":", "\n", "            ", "log_dict", "=", "{", "'method'", ":", "method", ",", "\n", "'qid'", ":", "qid", ",", "\n", "'answer'", ":", "answer_text", ",", "\n", "'weak_answer'", ":", "weak_answer_text", ",", "\n", "'weak_answer_start'", ":", "final_weak_answer_start", ",", "\n", "'int_has_positive'", ":", "int_has_positive", ",", "\n", "'labels_per_query'", ":", "labels_per_query", ",", "\n", "'new_passages_per_query'", ":", "new_passages_per_query", ".", "tolist", "(", ")", "}", "\n", "\n", "with", "open", "(", "args", ".", "case_study_file", ",", "'a'", ")", "as", "fout", ":", "\n", "                ", "fout", ".", "write", "(", "json", ".", "dumps", "(", "log_dict", ",", "indent", "=", "1", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "", "return", "return_result", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.supervisor_inference": [[1089, 1195], ["enumerate", "train_pipeline_weak_supervision.supervisor_inference.supervisor_collate"], "function", ["None"], ["", "def", "supervisor_inference", "(", "args", ",", "qid", ",", "answer_text", ",", "passages_per_query", ")", ":", "\n", "\n", "    ", "def", "gen_supervisor_feature", "(", "tokenizer", ",", "example_id", ",", "answer_text", ",", "paragraph_text", ")", ":", "\n", "        ", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "            ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "prev_is_whitespace", ":", "\n", "                    ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                    ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "is_impossible", "=", "False", "\n", "\n", "example", "=", "QuacExample", "(", "\n", "example_id", "=", "example_id", ",", "\n", "qas_id", "=", "example_id", ",", "# qas_id is the same with example id to keep it unique", "\n", "question_text", "=", "answer_text", ",", "\n", "doc_tokens", "=", "doc_tokens", ",", "\n", "orig_answer_text", "=", "orig_answer_text", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "is_impossible", ")", "\n", "\n", "feature", "=", "convert_example_to_feature", "(", "\n", "example", ",", "tokenizer", ",", "is_training", "=", "False", ")", "\n", "feature_dict", "=", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "'example_id'", ":", "feature", ".", "example_id", "}", "\n", "return", "feature_dict", ",", "example", ",", "feature", "\n", "\n", "", "def", "supervisor_collate", "(", "feature_dicts", ")", ":", "\n", "        ", "collated", "=", "{", "}", "\n", "keys", "=", "feature_dicts", "[", "0", "]", ".", "keys", "(", ")", "\n", "for", "key", "in", "keys", ":", "\n", "            ", "if", "key", "!=", "'example_id'", ":", "\n", "                ", "collated", "[", "key", "]", "=", "np", ".", "vstack", "(", "[", "dic", "[", "key", "]", "for", "dic", "in", "feature_dicts", "]", ")", "\n", "collated", "[", "key", "]", "=", "torch", ".", "from_numpy", "(", "collated", "[", "key", "]", ")", "\n", "", "", "if", "'example_id'", "in", "keys", ":", "\n", "            ", "collated", "[", "'example_id'", "]", "=", "[", "dic", "[", "'example_id'", "]", "\n", "for", "dic", "in", "feature_dicts", "]", "\n", "\n", "", "return", "collated", "\n", "\n", "", "examples", "=", "{", "}", "\n", "features", "=", "{", "}", "\n", "supervisor_feature_dicts", "=", "[", "]", "\n", "for", "i", ",", "passage", "in", "enumerate", "(", "passages_per_query", ")", ":", "\n", "        ", "example_id", "=", "'{}*{}'", ".", "format", "(", "qid", ",", "i", ")", "\n", "supervisor_feature_dict", ",", "supervisor_example", ",", "supervisor_feature", "=", "gen_supervisor_feature", "(", "\n", "supervisor_tokenizer", ",", "example_id", ",", "answer_text", ",", "passage", ")", "\n", "supervisor_feature_dicts", ".", "append", "(", "supervisor_feature_dict", ")", "\n", "examples", "[", "example_id", "]", "=", "supervisor_example", "\n", "features", "[", "example_id", "]", "=", "supervisor_feature", "\n", "\n", "", "batch", "=", "supervisor_collate", "(", "supervisor_feature_dicts", ")", "\n", "\n", "all_results", "=", "[", "]", "\n", "\n", "supervisor_model", ".", "eval", "(", ")", "\n", "example_ids", "=", "batch", "[", "'example_id'", "]", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "args", ".", "supervisor_device", ")", "\n", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "if", "k", "!=", "'example_id'", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "'input_ids'", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "'input_mask'", "]", ",", "\n", "'token_type_ids'", ":", "batch", "[", "'segment_ids'", "]", "}", "\n", "outputs", "=", "supervisor_model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "example_id", "in", "enumerate", "(", "example_ids", ")", ":", "\n", "        ", "result", "=", "RawResult", "(", "unique_id", "=", "example_id", ",", "\n", "start_logits", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "\n", "end_logits", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "retrieval_logits", "=", "[", "1", "]", ")", "# retrieval_logits is not used", "\n", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "# Compute predictions", "\n", "", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"instance_predictions_{}.json\"", ".", "format", "(", "'supervisor_temp'", ")", ")", "\n", "output_nbest_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"instance_nbest_predictions_{}.json\"", ".", "format", "(", "'supervisor_temp'", ")", ")", "\n", "output_final_prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"final_predictions_{}.json\"", ".", "format", "(", "'supervisor_temp'", ")", ")", "\n", "output_null_log_odds_file", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "\"instance_null_odds_{}.json\"", ".", "format", "(", "'supervisor_temp'", ")", ")", "\n", "\n", "\n", "all_predictions", "=", "write_predictions", "(", "examples", ",", "features", ",", "all_results", ",", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "args", ".", "do_lower_case", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "output_null_log_odds_file", ",", "args", ".", "verbose_logging", ",", "\n", "True", ",", "args", ".", "null_score_diff_threshold", ")", "\n", "supervisor_output", "=", "write_weak_supervisor_predictions", "(", "\n", "all_predictions", ",", "output_final_prediction_file", ")", "\n", "\n", "# print(supervisor_output)", "\n", "\n", "return", "supervisor_output", ",", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_pipeline_weak_supervision.get_passage": [[1200, 1204], ["linecache.getline", "json.loads", "json.loads.strip"], "function", ["None"], ["", "def", "get_passage", "(", "i", ",", "args", ")", ":", "\n", "    ", "line", "=", "linecache", ".", "getline", "(", "args", ".", "blocks_path", ",", "i", "+", "1", ")", "\n", "line", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "return", "line", "[", "'text'", "]", "\n", "", "get_passages", "=", "np", ".", "vectorize", "(", "get_passage", ")", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForOrconvqa.__init__": [[52, 66], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "modeling.BertForOrconvqa.init_weights"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForOrconvqa", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_qa_labels", "=", "config", ".", "num_qa_labels", "\n", "self", ".", "num_retrieval_labels", "=", "config", ".", "num_retrieval_labels", "\n", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_qa_labels", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_retrieval_labels", ")", "\n", "\n", "self", ".", "qa_loss_factor", "=", "config", ".", "qa_loss_factor", "\n", "self", ".", "retrieval_loss_factor", "=", "config", ".", "retrieval_loss_factor", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForOrconvqa.forward": [[67, 114], ["modeling.BertForOrconvqa.bert", "modeling.BertForOrconvqa.qa_outputs", "modeling.BertForOrconvqa.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "modeling.BertForOrconvqa.dropout", "modeling.BertForOrconvqa.classifier", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "modeling.BertForOrconvqa.view", "retrieval_label.view", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "retrieval_label", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "qa_logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "qa_logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "retrieval_logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", "retrieval_logits", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", "and", "retrieval_label", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "qa_loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "qa_loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "qa_loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "qa_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "retrieval_loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "retrieval_loss", "=", "retrieval_loss_fct", "(", "retrieval_logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_retrieval_labels", ")", ",", "retrieval_label", ".", "view", "(", "-", "1", ")", ")", "\n", "\n", "total_loss", "=", "self", ".", "qa_loss_factor", "*", "qa_loss", "+", "self", ".", "retrieval_loss_factor", "*", "retrieval_loss", "\n", "\n", "outputs", "=", "(", "total_loss", ",", "qa_loss", ",", "retrieval_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForOrconvqaGlobal.__init__": [[146, 171], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "modeling.BertForOrconvqaGlobal.init_weights", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForOrconvqaGlobal", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_qa_labels", "=", "config", ".", "num_qa_labels", "\n", "self", ".", "bert", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "# reranker", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "qa_loss_factor", "=", "config", ".", "qa_loss_factor", "\n", "self", ".", "retrieval_loss_factor", "=", "config", ".", "retrieval_loss_factor", "\n", "\n", "try", ":", "\n", "            ", "self", ".", "real_joint_learn", "=", "config", ".", "real_joint_learn", "\n", "self", ".", "involve_rerank_in_real_joint_learn", "=", "config", ".", "involve_rerank_in_real_joint_learn", "\n", "", "except", ":", "\n", "# for re-eval of bertserini", "\n", "# self.real_joint_learn = True", "\n", "            ", "self", ".", "real_joint_learn", "=", "False", "\n", "self", ".", "involve_rerank_in_real_joint_learn", "=", "False", "\n", "\n", "", "if", "self", ".", "real_joint_learn", ":", "\n", "            ", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "+", "1", ",", "config", ".", "num_qa_labels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_qa_labels", ")", "\n", "\n", "", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForOrconvqaGlobal.forward": [[172, 356], ["input_ids.view.view.size", "input_ids.view.view.view", "attention_mask.view.view.view", "token_type_ids.view.view.view", "modeling.BertForOrconvqaGlobal.bert", "modeling.BertForOrconvqaGlobal.qa_outputs", "modeling.BertForOrconvqaGlobal.split", "start_logits.view.view.squeeze", "end_logits.view.view.squeeze", "modeling.BertForOrconvqaGlobal.dropout", "modeling.BertForOrconvqaGlobal.classifier", "retriever_logits.view.view.view", "retriever_logits.view.view.unsqueeze", "retrieval_logits_to_concat.expand.expand.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "start_logits.view.view.view", "end_logits.view.view.view", "retrieval_logits.view.view.view", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze().argmax", "start_logits.view.view.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "start_positions.squeeze.squeeze.squeeze().max", "end_positions.squeeze.squeeze.squeeze().max", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size", "start_positions.squeeze.squeeze.squeeze", "end_positions.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "retrieval_label", "=", "None", ",", "\n", "retriever_logits", "=", "None", ")", ":", "\n", "\n", "        ", "batch_size", ",", "num_blocks", ",", "seq_len", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "\n", "outputs", "=", "self", ".", "bert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "# (batch_size * num_blocks, seq_len, hidden_size)", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "if", "retriever_logits", "is", "not", "None", ":", "\n", "# retriever_logits before view: (batch_size, num_blocks)", "\n", "            ", "retriever_logits", "=", "retriever_logits", ".", "view", "(", "batch_size", "*", "num_blocks", ",", "1", ")", "# (batch_size * num_blocks, 1)", "\n", "", "if", "self", ".", "real_joint_learn", ":", "\n", "# (batch_size * num_blocks, 1, 1)", "\n", "            ", "retrieval_logits_to_concat", "=", "retriever_logits", ".", "unsqueeze", "(", "dim", "=", "-", "1", ")", "\n", "# (batch_size * num_blocks, seq_len, 1)", "\n", "retrieval_logits_to_concat", "=", "retrieval_logits_to_concat", ".", "expand", "(", "-", "1", ",", "seq_len", ",", "-", "1", ")", "\n", "sequence_output", "=", "torch", ".", "cat", "(", "(", "sequence_output", ",", "retrieval_logits_to_concat", ")", ",", "dim", "=", "-", "1", ")", "\n", "# print('sequence_output', sequence_output.size())", "\n", "\n", "", "qa_logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "qa_logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "# (batch_size * num_blocks, seq_len)", "\n", "# print('start_logits', start_logits.size())", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "retrieval_logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "# (batch_size * num_blocks, 1) # this is for reranking", "\n", "# print('retrieval_logits', retrieval_logits.size())", "\n", "\n", "if", "retriever_logits", "is", "not", "None", ":", "\n", "            ", "outputs", "=", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", "retrieval_logits", ",", "retriever_logits", ")", "+", "outputs", "[", "2", ":", "]", "\n", "", "else", ":", "\n", "            ", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", "retrieval_logits", ")", "+", "outputs", "[", "2", ":", "]", "\n", "\n", "#         if (start_positions is not None and end_positions is not None and ", "\n", "#             retrieval_label is not None and retriever_logits is None and self.real_joint_learn is False):", "\n", "\n", "", "if", "(", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", "and", "\n", "retrieval_label", "is", "not", "None", ")", ":", "\n", "\n", "            ", "start_logits", "=", "start_logits", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "# retrival_logits = retrieval_logits.squeeze(-1)", "\n", "retrieval_logits", "=", "retrieval_logits", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", ".", "max", "(", "dim", "=", "1", ")", ".", "values", "\n", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", ".", "max", "(", "dim", "=", "1", ")", ".", "values", "\n", "retrieval_label", "=", "retrieval_label", ".", "squeeze", "(", "-", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "qa_loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "# qa_loss_fct = CrossEntropyLoss(ignore_index=0)", "\n", "start_loss", "=", "qa_loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "qa_loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "qa_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "retrieval_loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "retrieval_loss", "=", "retrieval_loss_fct", "(", "retrieval_logits", ",", "retrieval_label", ")", "\n", "\n", "total_loss", "=", "self", ".", "qa_loss_factor", "*", "qa_loss", "+", "self", ".", "retrieval_loss_factor", "*", "retrieval_loss", "\n", "\n", "outputs", "=", "(", "total_loss", ",", "qa_loss", ",", "retrieval_loss", ",", ")", "+", "outputs", "\n", "\n", "#         if (start_positions is not None and end_positions is not None and ", "\n", "#             retrieval_label is not None and retriever_logits is not None and ", "\n", "#             self.real_joint_learn):", "\n", "\n", "#             start_logits = start_logits.view(batch_size, num_blocks, seq_len)", "\n", "#             end_logits = end_logits.view(batch_size, num_blocks, seq_len)", "\n", "\n", "#             # retrival_logits = retrieval_logits.squeeze(-1)", "\n", "#             retrieval_logits = retrieval_logits.view(batch_size, num_blocks)", "\n", "#             retriever_logits = retriever_logits.view(batch_size, num_blocks)", "\n", "\n", "\n", "#             if self.involve_rerank_in_real_joint_learn:", "\n", "#                 joint_learn_logits = retrieval_logits + retriever_logits", "\n", "#             else:", "\n", "#                 joint_learn_logits = retriever_logits", "\n", "\n", "#             joint_learn_logits = joint_learn_logits.unsqueeze(dim=-1)", "\n", "\n", "#             add the joint learn logits ", "\n", "#             start_logits = start_logits + joint_learn_logits", "\n", "#             end_logits = end_logits + joint_learn_logits", "\n", "\n", "#             start_logits = start_logits.view(batch_size, -1)", "\n", "#             end_logits = end_logits.view(batch_size, -1)", "\n", "\n", "#             start_positions = start_positions.squeeze(-1).max(dim=1).values", "\n", "#             end_positions = end_positions.squeeze(-1).max(dim=1).values", "\n", "#             retrieval_label = retrieval_label.squeeze(-1).argmax(dim=1)", "\n", "\n", "#             # If we are on multi-GPU, split add a dimension", "\n", "#             if len(start_positions.size()) > 1:", "\n", "#                 start_positions = start_positions.squeeze(-1)", "\n", "#             if len(end_positions.size()) > 1:", "\n", "#                 end_positions = end_positions.squeeze(-1)", "\n", "#             # sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "#             ignored_index = start_logits.size(1)", "\n", "#             start_positions.clamp_(0, ignored_index)", "\n", "#             end_positions.clamp_(0, ignored_index)", "\n", "\n", "#             qa_loss_fct = CrossEntropyLoss(ignore_index=ignored_index)", "\n", "#             start_loss = qa_loss_fct(start_logits, start_positions)", "\n", "#             end_loss = qa_loss_fct(end_logits, end_positions)", "\n", "#             qa_loss = (start_loss + end_loss) / 2", "\n", "\n", "#             retrieval_loss_fct = CrossEntropyLoss()", "\n", "#             retrieval_loss = retrieval_loss_fct(retrieval_logits, retrieval_label)", "\n", "\n", "#             total_loss = self.qa_loss_factor * qa_loss + self.retrieval_loss_factor * retrieval_loss", "\n", "\n", "#             outputs = (total_loss, qa_loss, retrieval_loss,) + outputs", "\n", "\n", "# real joint learning with the reranker", "\n", "#         if (start_positions is not None and end_positions is not None and ", "\n", "#             retrieval_label is not None and retriever_logits is None and ", "\n", "#             self.real_joint_learn):", "\n", "\n", "#             start_logits = start_logits.view(batch_size, num_blocks, seq_len)", "\n", "#             end_logits = end_logits.view(batch_size, num_blocks, seq_len)", "\n", "\n", "#             # retrival_logits = retrieval_logits.squeeze(-1)", "\n", "#             retrieval_logits = retrieval_logits.view(batch_size, num_blocks)", "\n", "\n", "#             if self.involve_rerank_in_real_joint_learn:", "\n", "#                 joint_learn_logits = retrieval_logits                ", "\n", "#                 joint_learn_logits = joint_learn_logits.unsqueeze(dim=-1)", "\n", "#                 start_logits = start_logits + joint_learn_logits", "\n", "#                 end_logits = end_logits + joint_learn_logits", "\n", "\n", "#             start_logits = start_logits.view(batch_size, -1)", "\n", "#             end_logits = end_logits.view(batch_size, -1)", "\n", "\n", "#             start_positions = start_positions.squeeze(-1).max(dim=1).values", "\n", "#             end_positions = end_positions.squeeze(-1).max(dim=1).values", "\n", "#             retrieval_label = retrieval_label.squeeze(-1).argmax(dim=1)", "\n", "\n", "#             # If we are on multi-GPU, split add a dimension", "\n", "#             if len(start_positions.size()) > 1:", "\n", "#                 start_positions = start_positions.squeeze(-1)", "\n", "#             if len(end_positions.size()) > 1:", "\n", "#                 end_positions = end_positions.squeeze(-1)", "\n", "#             # sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "#             ignored_index = start_logits.size(1)", "\n", "#             start_positions.clamp_(0, ignored_index)", "\n", "#             end_positions.clamp_(0, ignored_index)", "\n", "\n", "#             qa_loss_fct = CrossEntropyLoss(ignore_index=ignored_index)", "\n", "#             start_loss = qa_loss_fct(start_logits, start_positions)", "\n", "#             end_loss = qa_loss_fct(end_logits, end_positions)", "\n", "#             qa_loss = (start_loss + end_loss) / 2", "\n", "\n", "#             retrieval_loss_fct = CrossEntropyLoss()", "\n", "#             retrieval_loss = retrieval_loss_fct(retrieval_logits, retrieval_label)", "\n", "\n", "#             total_loss = self.qa_loss_factor * qa_loss + self.retrieval_loss_factor * retrieval_loss", "\n", "\n", "#             outputs = (total_loss, qa_loss, retrieval_loss,) + outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.AlbertForOrconvqaGlobal.__init__": [[389, 402], ["transformers.modeling_albert.AlbertPreTrainedModel.__init__", "transformers.AlbertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "modeling.AlbertForOrconvqaGlobal.init_weights"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertForOrconvqaGlobal", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_qa_labels", "=", "config", ".", "num_qa_labels", "\n", "\n", "self", ".", "albert", "=", "AlbertModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_qa_labels", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "qa_loss_factor", "=", "config", ".", "qa_loss_factor", "\n", "self", ".", "retrieval_loss_factor", "=", "config", ".", "retrieval_loss_factor", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.AlbertForOrconvqaGlobal.forward": [[403, 467], ["input_ids.view.view.size", "input_ids.view.view.view", "attention_mask.view.view.view", "token_type_ids.view.view.view", "modeling.AlbertForOrconvqaGlobal.albert", "modeling.AlbertForOrconvqaGlobal.qa_outputs", "modeling.AlbertForOrconvqaGlobal.split", "start_logits.view.view.squeeze", "end_logits.view.view.squeeze", "modeling.AlbertForOrconvqaGlobal.dropout", "modeling.AlbertForOrconvqaGlobal.classifier", "start_logits.view.view.view", "end_logits.view.view.view", "retrieval_logits.view.view.squeeze", "retrieval_logits.view.view.view", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze().argmax", "start_logits.view.view.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "start_positions.squeeze.squeeze.squeeze().max", "end_positions.squeeze.squeeze.squeeze().max", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size", "start_positions.squeeze.squeeze.squeeze", "end_positions.squeeze.squeeze.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "retrieval_label", "=", "None", ")", ":", "\n", "\n", "        ", "batch_size", ",", "num_blocks", ",", "seq_len", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "\n", "outputs", "=", "self", ".", "albert", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "qa_logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "qa_logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "# (batch_size * num_blocks, seq_len)", "\n", "# print('start_logits', start_logits.size())", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "retrieval_logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "# (batch_size * num_blocks, 1)", "\n", "# print('retrieval_logits', retrieval_logits.size())", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", "retrieval_logits", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", "and", "retrieval_label", "is", "not", "None", ":", "\n", "            ", "start_logits", "=", "start_logits", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "retrival_logits", "=", "retrieval_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "retrieval_logits", "=", "retrieval_logits", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", ".", "max", "(", "dim", "=", "1", ")", ".", "values", "\n", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", ".", "max", "(", "dim", "=", "1", ")", ".", "values", "\n", "retrieval_label", "=", "retrieval_label", ".", "squeeze", "(", "-", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "qa_loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "qa_loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "qa_loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "qa_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "retrieval_loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "retrieval_loss", "=", "retrieval_loss_fct", "(", "retrieval_logits", ",", "retrieval_label", ")", "\n", "\n", "total_loss", "=", "self", ".", "qa_loss_factor", "*", "qa_loss", "+", "self", ".", "retrieval_loss_factor", "*", "retrieval_loss", "\n", "\n", "outputs", "=", "(", "total_loss", ",", "qa_loss", ",", "retrieval_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForRetriever.__init__": [[473, 486], ["transformers.BertPreTrainedModel.__init__", "transformers.BertModel", "torch.nn.Linear", "torch.nn.Linear", "transformers.BertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "modeling.BertForRetriever.init_weights"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForRetriever", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "query_encoder", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "query_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "proj_size", ")", "\n", "\n", "self", ".", "passage_encoder", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "passage_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "proj_size", ")", "\n", "self", ".", "proj_size", "=", "config", ".", "proj_size", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForRetriever.forward": [[487, 541], ["modeling.BertForRetriever.query_encoder", "modeling.BertForRetriever.dropout", "modeling.BertForRetriever.query_proj", "modeling.BertForRetriever.passage_encoder", "modeling.BertForRetriever.dropout", "modeling.BertForRetriever.passage_proj", "passage_rep.view.view.view", "query_rep.transpose.transpose.unsqueeze", "query_rep.transpose.transpose.expand", "query_rep.transpose.transpose.transpose", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.softmax", "torch.softmax", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze().argmax", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "retrieval_logits.view.view.view", "len", "passage_input_ids.view.view.size", "passage_input_ids.view.view.view", "passage_attention_mask.view.view.view", "passage_token_type_ids.view.view.view", "passage_input_ids.view.view.size", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query_input_ids", "=", "None", ",", "query_attention_mask", "=", "None", ",", "query_token_type_ids", "=", "None", ",", "\n", "passage_input_ids", "=", "None", ",", "passage_attention_mask", "=", "None", ",", "passage_token_type_ids", "=", "None", ",", "\n", "retrieval_label", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "if", "query_input_ids", "is", "not", "None", ":", "\n", "            ", "query_outputs", "=", "self", ".", "query_encoder", "(", "query_input_ids", ",", "\n", "attention_mask", "=", "query_attention_mask", ",", "\n", "token_type_ids", "=", "query_token_type_ids", ")", "\n", "\n", "query_pooled_output", "=", "query_outputs", "[", "1", "]", "\n", "query_pooled_output", "=", "self", ".", "dropout", "(", "query_pooled_output", ")", "\n", "query_rep", "=", "self", ".", "query_proj", "(", "query_pooled_output", ")", "# batch_size, proj_size    ", "\n", "# print(query_rep[:, 0])", "\n", "outputs", "=", "(", "query_rep", ",", ")", "+", "outputs", "\n", "\n", "", "if", "passage_input_ids", "is", "not", "None", ":", "\n", "            ", "if", "len", "(", "passage_input_ids", ".", "size", "(", ")", ")", "==", "3", ":", "\n", "# this means we are pretraining", "\n", "                ", "batch_size", ",", "num_blocks", ",", "seq_len", "=", "passage_input_ids", ".", "size", "(", ")", "\n", "passage_input_ids", "=", "passage_input_ids", ".", "view", "(", "-", "1", ",", "seq_len", ")", "# batch_size * num_blocks, seq_len", "\n", "passage_attention_mask", "=", "passage_attention_mask", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "passage_token_type_ids", "=", "passage_token_type_ids", ".", "view", "(", "-", "1", ",", "seq_len", ")", "\n", "\n", "", "passage_outputs", "=", "self", ".", "passage_encoder", "(", "passage_input_ids", ",", "\n", "attention_mask", "=", "passage_attention_mask", ",", "\n", "token_type_ids", "=", "passage_token_type_ids", ")", "\n", "\n", "passage_pooled_output", "=", "passage_outputs", "[", "1", "]", "\n", "passage_pooled_output", "=", "self", ".", "dropout", "(", "passage_pooled_output", ")", "\n", "passage_rep", "=", "self", ".", "passage_proj", "(", "passage_pooled_output", ")", "# batch_size * num_blocks, proj_size", "\n", "# print(passage_rep[:, 0])", "\n", "outputs", "=", "(", "passage_rep", ",", ")", "+", "outputs", "\n", "\n", "", "if", "query_input_ids", "is", "not", "None", "and", "passage_input_ids", "is", "not", "None", "and", "retrieval_label", "is", "not", "None", ":", "\n", "            ", "passage_rep", "=", "passage_rep", ".", "view", "(", "batch_size", ",", "num_blocks", ",", "-", "1", ")", "# batch_size, num_blocks, proj_size      ", "\n", "query_rep", "=", "query_rep", ".", "unsqueeze", "(", "-", "1", ")", "# query_rep (batch_size, proj_size, 1)", "\n", "query_rep", "=", "query_rep", ".", "expand", "(", "batch_size", ",", "self", ".", "proj_size", ",", "num_blocks", ")", "# batch_size, proj_size, num_blocks)", "\n", "query_rep", "=", "query_rep", ".", "transpose", "(", "1", ",", "2", ")", "# query_rep (batch_size, num_blocks, proj_size)", "\n", "retrieval_logits", "=", "query_rep", "*", "passage_rep", "# batch_size, num_blocks, proj_size", "\n", "retrieval_logits", "=", "torch", ".", "sum", "(", "retrieval_logits", ",", "dim", "=", "-", "1", ")", "# batch_size, num_blocks", "\n", "retrieval_probs", "=", "F", ".", "softmax", "(", "retrieval_logits", ",", "dim", "=", "1", ")", "\n", "# print('retrieval_label before', retrieval_label.size(), retrieval_label)", "\n", "retrieval_label", "=", "retrieval_label", ".", "squeeze", "(", "-", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "# print('retrieval_label after', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# print('retrieval_logits', retrieval_logits.size(), retrieval_logits)", "\n", "# print('retrieval_label', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss", "=", "retrieval_loss_fct", "(", "retrieval_logits", ",", "retrieval_label", ")", "\n", "\n", "retrieval_logits", "=", "retrieval_logits", ".", "view", "(", "-", "1", ")", "\n", "outputs", "=", "(", "retrieval_loss", ",", "retrieval_logits", ",", "retrieval_probs", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForRetriever.from_pretrained": [[542, 729], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "load_tf2_checkpoint_in_pytorch_model.tie_weights", "load_tf2_checkpoint_in_pytorch_model.eval", "logger.warning", "cls.config_class.from_pretrained", "torch.load", "torch.load", "torch.load", "torch.load", "transformers.file_utils.cached_path.endswith", "collections.OrderedDict.copy.keys", "zip", "getattr", "collections.OrderedDict", "collections.OrderedDict.copy.items", "modeling.BertForRetriever.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.AlbertForRetrieverOnlyPositivePassage.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "is", "not", "None", "and", "(", "\n", "\"albert\"", "in", "pretrained_model_name_or_path", "and", "\"v2\"", "in", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\"There is currently an upstream reproducibility issue with ALBERT v2 models. Please see \"", "+", "\n", "\"https://github.com/google-research/google-research/issues/119 for more information.\"", ")", "\n", "\n", "", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "'state_dict'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "'from_tf'", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "'resume_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "'output_loading_info'", ",", "False", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", ")", ":", "\n", "# Load from a TF 1.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "elif", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\"Error no file named {} found in directory {} or `from_tf` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", "]", ",", "\n", "pretrained_model_name_or_path", ")", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", "+", "\".index\"", ")", ":", "\n", "                ", "assert", "from_tf", ",", "\"We found a TensorFlow checkpoint at {}, please set from_tf to True to load from this checkpoint\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "+", "\".index\"", ")", "\n", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "\n", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", "\n", "", "else", ":", "\n", "                    ", "msg", "=", "\"Model name '{}' was not found in model name list ({}). \"", "\"We assumed '{}' was a path or url to model weight files named one of {} but \"", "\"couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ",", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "]", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "if", "from_tf", ":", "\n", "            ", "if", "resolved_archive_file", ".", "endswith", "(", "'.index'", ")", ":", "\n", "# Load from a TensorFlow 1.X checkpoint - provided by original authors", "\n", "                ", "model", "=", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "", "else", ":", "\n", "# Load from our TensorFlow 2.0 checkpoints", "\n", "                ", "try", ":", "\n", "                    ", "from", "transformers", "import", "load_tf2_checkpoint_in_pytorch_model", "\n", "model", "=", "load_tf2_checkpoint_in_pytorch_model", "(", "model", ",", "resolved_archive_file", ",", "allow_missing_keys", "=", "True", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "                    ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "e", "\n", "", "", "", "else", ":", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "            ", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "key", "==", "'lm_head.decoder.weight'", ":", "\n", "                    ", "new_key", "=", "'lm_head.weight'", "\n", "", "if", "new_key", ":", "\n", "                    ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "                ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "# print('orig state dict', state_dict.keys(), len(state_dict))", "\n", "customized_state_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "k_split", "=", "k", ".", "split", "(", "'.'", ")", "\n", "if", "k_split", "[", "0", "]", "==", "'bert'", ":", "\n", "                    ", "k_split", "[", "0", "]", "=", "'query_encoder'", "\n", "customized_state_dict", "[", "'.'", ".", "join", "(", "k_split", ")", "]", "=", "v", "\n", "k_split", "[", "0", "]", "=", "'passage_encoder'", "\n", "customized_state_dict", "[", "'.'", ".", "join", "(", "k_split", ")", "]", "=", "v", "\n", "\n", "", "", "if", "len", "(", "customized_state_dict", ")", "==", "0", ":", "\n", "# loading from our trained model", "\n", "                ", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "# print('using orig state dict', state_dict.keys())", "\n", "", "else", ":", "\n", "# loading from original bert model", "\n", "                ", "state_dict", "=", "customized_state_dict", ".", "copy", "(", ")", "\n", "# print('using custome state dict', state_dict.keys())", "\n", "\n", "# print('modified state dict', state_dict.keys(), len(state_dict))", "\n", "", "if", "metadata", "is", "not", "None", ":", "\n", "                ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "# PyTorch's `_load_from_state_dict` does not copy parameters in a module's descendants", "\n", "# so we need to apply the function recursively.", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "                ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                    ", "if", "child", "is", "not", "None", ":", "\n", "                        ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "''", "\n", "model_to_load", "=", "model", "\n", "#             if not hasattr(model, cls.base_model_prefix) and any(s.startswith(cls.base_model_prefix) for s in state_dict.keys()):", "\n", "#                 start_prefix = cls.base_model_prefix + '.'", "\n", "#             if hasattr(model, cls.base_model_prefix) and not any(s.startswith(cls.base_model_prefix) for s in state_dict.keys()):", "\n", "#                 model_to_load = getattr(model, cls.base_model_prefix)", "\n", "\n", "#             load(model_to_load, prefix=start_prefix)", "\n", "load", "(", "model_to_load", ",", "prefix", "=", "''", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "\n", "", "", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied if needed", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForRetrieverOnlyPositivePassage.__init__": [[735, 748], ["modeling.BertForRetriever.__init__", "transformers.BertModel", "torch.nn.Linear", "torch.nn.Linear", "transformers.BertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "modeling.BertForRetrieverOnlyPositivePassage.init_weights"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "BertForRetriever", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "query_encoder", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "query_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "proj_size", ")", "\n", "\n", "self", ".", "passage_encoder", "=", "BertModel", "(", "config", ")", "\n", "self", ".", "passage_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "proj_size", ")", "\n", "self", ".", "proj_size", "=", "config", ".", "proj_size", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.BertForRetrieverOnlyPositivePassage.forward": [[749, 789], ["modeling.BertForRetrieverOnlyPositivePassage.query_encoder", "modeling.BertForRetrieverOnlyPositivePassage.dropout", "modeling.BertForRetrieverOnlyPositivePassage.query_proj", "modeling.BertForRetrieverOnlyPositivePassage.passage_encoder", "modeling.BertForRetrieverOnlyPositivePassage.dropout", "modeling.BertForRetrieverOnlyPositivePassage.passage_proj", "modeling.BertForRetrieverOnlyPositivePassage.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling.BertForRetrieverOnlyPositivePassage.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query_input_ids", "=", "None", ",", "query_attention_mask", "=", "None", ",", "query_token_type_ids", "=", "None", ",", "\n", "passage_input_ids", "=", "None", ",", "passage_attention_mask", "=", "None", ",", "passage_token_type_ids", "=", "None", ",", "\n", "retrieval_label", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "if", "query_input_ids", "is", "not", "None", ":", "\n", "            ", "query_outputs", "=", "self", ".", "query_encoder", "(", "query_input_ids", ",", "\n", "attention_mask", "=", "query_attention_mask", ",", "\n", "token_type_ids", "=", "query_token_type_ids", ")", "\n", "\n", "query_pooled_output", "=", "query_outputs", "[", "1", "]", "\n", "query_pooled_output", "=", "self", ".", "dropout", "(", "query_pooled_output", ")", "\n", "query_rep", "=", "self", ".", "query_proj", "(", "query_pooled_output", ")", "# batch_size, proj_size    ", "\n", "# print(query_rep[:, 0])", "\n", "outputs", "=", "(", "query_rep", ",", ")", "+", "outputs", "\n", "\n", "", "if", "passage_input_ids", "is", "not", "None", ":", "\n", "            ", "passage_outputs", "=", "self", ".", "passage_encoder", "(", "passage_input_ids", ",", "\n", "attention_mask", "=", "passage_attention_mask", ",", "\n", "token_type_ids", "=", "passage_token_type_ids", ")", "\n", "\n", "passage_pooled_output", "=", "passage_outputs", "[", "1", "]", "\n", "passage_pooled_output", "=", "self", ".", "dropout", "(", "passage_pooled_output", ")", "\n", "passage_rep", "=", "self", ".", "passage_proj", "(", "passage_pooled_output", ")", "# batch_size, proj_size", "\n", "# print(passage_rep[:, 0])", "\n", "outputs", "=", "(", "passage_rep", ",", ")", "+", "outputs", "\n", "\n", "", "if", "query_input_ids", "is", "not", "None", "and", "passage_input_ids", "is", "not", "None", ":", "\n", "            ", "passage_rep_t", "=", "passage_rep", ".", "transpose", "(", "0", ",", "1", ")", "# proj_size, batch_size", "\n", "retrieval_logits", "=", "torch", ".", "matmul", "(", "query_rep", ",", "passage_rep_t", ")", "# batch_size, batch_size", "\n", "retrieval_label", "=", "torch", ".", "arange", "(", "query_rep", ".", "size", "(", "0", ")", ",", "device", "=", "query_rep", ".", "device", ",", "dtype", "=", "retrieval_label", ".", "dtype", ")", "\n", "# print('retrieval_label after', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# print('retrieval_logits', retrieval_logits.size(), retrieval_logits)", "\n", "# print('retrieval_label', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss", "=", "retrieval_loss_fct", "(", "retrieval_logits", ",", "retrieval_label", ")", "\n", "\n", "outputs", "=", "(", "retrieval_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.AlbertForRetrieverOnlyPositivePassage.__init__": [[794, 807], ["transformers.modeling_albert.AlbertPreTrainedModel.__init__", "transformers.AlbertModel", "torch.nn.Linear", "torch.nn.Linear", "transformers.AlbertModel", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "modeling.AlbertForRetrieverOnlyPositivePassage.init_weights"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "AlbertForRetrieverOnlyPositivePassage", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "query_encoder", "=", "AlbertModel", "(", "config", ")", "\n", "self", ".", "query_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "proj_size", ")", "\n", "\n", "self", ".", "passage_encoder", "=", "AlbertModel", "(", "config", ")", "\n", "self", ".", "passage_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "proj_size", ")", "\n", "self", ".", "proj_size", "=", "config", ".", "proj_size", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.AlbertForRetrieverOnlyPositivePassage.forward": [[808, 896], ["modeling.AlbertForRetrieverOnlyPositivePassage.query_encoder", "modeling.AlbertForRetrieverOnlyPositivePassage.dropout", "modeling.AlbertForRetrieverOnlyPositivePassage.query_proj", "modeling.AlbertForRetrieverOnlyPositivePassage.passage_encoder", "modeling.AlbertForRetrieverOnlyPositivePassage.dropout", "modeling.AlbertForRetrieverOnlyPositivePassage.passage_proj", "modeling.AlbertForRetrieverOnlyPositivePassage.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling.AlbertForRetrieverOnlyPositivePassage.size", "query_rep.transpose.transpose.unsqueeze", "query_rep.transpose.transpose.expand", "query_rep.transpose.transpose.transpose", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.softmax", "torch.softmax", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze().argmax", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling.AlbertForRetrieverOnlyPositivePassage.size", "query_rep.transpose.transpose.unsqueeze", "query_rep.transpose.transpose.expand", "query_rep.transpose.transpose.transpose", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "query_rep.transpose.transpose.size", "len", "modeling.AlbertForRetrieverOnlyPositivePassage.size", "retrieval_label.squeeze().argmax.squeeze().argmax.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "query_input_ids", "=", "None", ",", "query_attention_mask", "=", "None", ",", "query_token_type_ids", "=", "None", ",", "\n", "passage_input_ids", "=", "None", ",", "passage_attention_mask", "=", "None", ",", "passage_token_type_ids", "=", "None", ",", "\n", "retrieval_label", "=", "None", ",", "query_rep", "=", "None", ",", "passage_rep", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "if", "query_input_ids", "is", "not", "None", ":", "\n", "            ", "query_outputs", "=", "self", ".", "query_encoder", "(", "query_input_ids", ",", "\n", "attention_mask", "=", "query_attention_mask", ",", "\n", "token_type_ids", "=", "query_token_type_ids", ")", "\n", "\n", "query_pooled_output", "=", "query_outputs", "[", "1", "]", "\n", "query_pooled_output", "=", "self", ".", "dropout", "(", "query_pooled_output", ")", "\n", "query_rep", "=", "self", ".", "query_proj", "(", "query_pooled_output", ")", "# batch_size, proj_size    ", "\n", "# print(query_rep[:, 0])", "\n", "outputs", "=", "(", "query_rep", ",", ")", "+", "outputs", "\n", "\n", "", "if", "passage_input_ids", "is", "not", "None", ":", "\n", "            ", "passage_outputs", "=", "self", ".", "passage_encoder", "(", "passage_input_ids", ",", "\n", "attention_mask", "=", "passage_attention_mask", ",", "\n", "token_type_ids", "=", "passage_token_type_ids", ")", "\n", "\n", "passage_pooled_output", "=", "passage_outputs", "[", "1", "]", "\n", "passage_pooled_output", "=", "self", ".", "dropout", "(", "passage_pooled_output", ")", "\n", "passage_rep", "=", "self", ".", "passage_proj", "(", "passage_pooled_output", ")", "# batch_size, proj_size", "\n", "# print(passage_rep[:, 0])", "\n", "outputs", "=", "(", "passage_rep", ",", ")", "+", "outputs", "\n", "\n", "", "if", "query_input_ids", "is", "not", "None", "and", "passage_input_ids", "is", "not", "None", ":", "\n", "            ", "passage_rep_t", "=", "passage_rep", ".", "transpose", "(", "0", ",", "1", ")", "# proj_size, batch_size", "\n", "retrieval_logits", "=", "torch", ".", "matmul", "(", "query_rep", ",", "passage_rep_t", ")", "# batch_size, batch_size", "\n", "retrieval_label", "=", "torch", ".", "arange", "(", "query_rep", ".", "size", "(", "0", ")", ",", "device", "=", "query_rep", ".", "device", ",", "dtype", "=", "retrieval_label", ".", "dtype", ")", "\n", "# print('retrieval_label after', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# print('retrieval_logits', retrieval_logits.size(), retrieval_logits)", "\n", "# print('retrieval_label', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss", "=", "retrieval_loss_fct", "(", "retrieval_logits", ",", "retrieval_label", ")", "\n", "\n", "outputs", "=", "(", "retrieval_loss", ",", ")", "+", "outputs", "\n", "\n", "", "if", "query_input_ids", "is", "not", "None", "and", "passage_rep", "is", "not", "None", "and", "retrieval_label", "is", "not", "None", "and", "len", "(", "passage_rep", ".", "size", "(", ")", ")", "==", "3", ":", "\n", "# this is during fine tuning", "\n", "# passage_rep: batch_size, num_blocks, proj_size      ", "\n", "# query_outputs = self.query_encoder(query_input_ids,", "\n", "#                     attention_mask=query_attention_mask,", "\n", "#                     token_type_ids=query_token_type_ids)", "\n", "\n", "# query_pooled_output = query_outputs[1]", "\n", "# query_pooled_output = self.dropout(query_pooled_output)", "\n", "# query_rep = self.query_proj(query_pooled_output) # batch_size, proj_size  ", "\n", "\n", "            ", "batch_size", ",", "num_blocks", ",", "proj_size", "=", "passage_rep", ".", "size", "(", ")", "\n", "query_rep", "=", "query_rep", ".", "unsqueeze", "(", "-", "1", ")", "# query_rep (batch_size, proj_size, 1)", "\n", "query_rep", "=", "query_rep", ".", "expand", "(", "batch_size", ",", "self", ".", "proj_size", ",", "num_blocks", ")", "# batch_size, proj_size, num_blocks)", "\n", "query_rep", "=", "query_rep", ".", "transpose", "(", "1", ",", "2", ")", "# query_rep (batch_size, num_blocks, proj_size)", "\n", "retrieval_logits", "=", "query_rep", "*", "passage_rep", "# batch_size, num_blocks, proj_size", "\n", "retrieval_logits", "=", "torch", ".", "sum", "(", "retrieval_logits", ",", "dim", "=", "-", "1", ")", "# batch_size, num_blocks", "\n", "retrieval_probs", "=", "F", ".", "softmax", "(", "retrieval_logits", ",", "dim", "=", "1", ")", "\n", "# print('retrieval_label before', retrieval_label.size(), retrieval_label)", "\n", "retrieval_label", "=", "retrieval_label", ".", "squeeze", "(", "-", "1", ")", ".", "argmax", "(", "dim", "=", "1", ")", "\n", "# print('retrieval_label after', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# print('retrieval_logits', retrieval_logits.size(), retrieval_logits)", "\n", "# print('retrieval_label', retrieval_label.size(), retrieval_label)", "\n", "retrieval_loss", "=", "retrieval_loss_fct", "(", "retrieval_logits", ",", "retrieval_label", ")", "\n", "\n", "outputs", "=", "(", "retrieval_loss", ",", ")", "+", "outputs", "\n", "\n", "", "if", "query_input_ids", "is", "not", "None", "and", "passage_rep", "is", "not", "None", "and", "retrieval_label", "is", "None", ":", "\n", "# this is during fine tuning", "\n", "# passage_rep: batch_size, num_blocks, proj_size      ", "\n", "# query_outputs = self.query_encoder(query_input_ids,", "\n", "#                     attention_mask=query_attention_mask,", "\n", "#                     token_type_ids=query_token_type_ids)", "\n", "\n", "# query_pooled_output = query_outputs[1]", "\n", "# query_pooled_output = self.dropout(query_pooled_output)", "\n", "# query_rep = self.query_proj(query_pooled_output) # batch_size, proj_size  ", "\n", "\n", "            ", "batch_size", ",", "num_blocks", ",", "proj_size", "=", "passage_rep", ".", "size", "(", ")", "\n", "query_rep", "=", "query_rep", ".", "unsqueeze", "(", "-", "1", ")", "# query_rep (batch_size, proj_size, 1)", "\n", "query_rep", "=", "query_rep", ".", "expand", "(", "batch_size", ",", "self", ".", "proj_size", ",", "num_blocks", ")", "# batch_size, proj_size, num_blocks)", "\n", "query_rep", "=", "query_rep", ".", "transpose", "(", "1", ",", "2", ")", "# query_rep (batch_size, num_blocks, proj_size)", "\n", "retrieval_logits", "=", "query_rep", "*", "passage_rep", "# batch_size, num_blocks, proj_size", "\n", "retrieval_logits", "=", "torch", ".", "sum", "(", "retrieval_logits", ",", "dim", "=", "-", "1", ")", "# batch_size, num_blocks", "\n", "\n", "outputs", "=", "(", "retrieval_logits", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.AlbertForRetrieverOnlyPositivePassage.from_pretrained": [[897, 1084], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "load_tf2_checkpoint_in_pytorch_model.tie_weights", "load_tf2_checkpoint_in_pytorch_model.eval", "logger.warning", "cls.config_class.from_pretrained", "torch.load", "torch.load", "torch.load", "torch.load", "transformers.file_utils.cached_path.endswith", "collections.OrderedDict.copy.keys", "zip", "getattr", "collections.OrderedDict", "collections.OrderedDict.copy.items", "modeling.AlbertForRetrieverOnlyPositivePassage.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.AlbertForRetrieverOnlyPositivePassage.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"\n        \"\"\"", "\n", "if", "pretrained_model_name_or_path", "is", "not", "None", "and", "(", "\n", "\"albert\"", "in", "pretrained_model_name_or_path", "and", "\"v2\"", "in", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "logger", ".", "warning", "(", "\"There is currently an upstream reproducibility issue with ALBERT v2 models. Please see \"", "+", "\n", "\"https://github.com/google-research/google-research/issues/119 for more information.\"", ")", "\n", "\n", "", "config", "=", "kwargs", ".", "pop", "(", "'config'", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "'state_dict'", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "'cache_dir'", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "'from_tf'", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "'force_download'", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "'resume_download'", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "'proxies'", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "'output_loading_info'", ",", "False", ")", "\n", "\n", "# Load config", "\n", "if", "config", "is", "None", ":", "\n", "            ", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "**", "kwargs", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", ")", ":", "\n", "# Load from a TF 1.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "elif", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\"Error no file named {} found in directory {} or `from_tf` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", "]", ",", "\n", "pretrained_model_name_or_path", ")", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", "+", "\".index\"", ")", ":", "\n", "                ", "assert", "from_tf", ",", "\"We found a TensorFlow checkpoint at {}, please set from_tf to True to load from this checkpoint\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "+", "\".index\"", ")", "\n", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "\n", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "archive_file", ",", "cache_dir", "=", "cache_dir", ",", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "\n", "archive_file", ")", "\n", "", "else", ":", "\n", "                    ", "msg", "=", "\"Model name '{}' was not found in model name list ({}). \"", "\"We assumed '{}' was a path or url to model weight files named one of {} but \"", "\"couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "', '", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ",", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "]", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "\n", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "'cpu'", ")", "\n", "\n", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "if", "from_tf", ":", "\n", "            ", "if", "resolved_archive_file", ".", "endswith", "(", "'.index'", ")", ":", "\n", "# Load from a TensorFlow 1.X checkpoint - provided by original authors", "\n", "                ", "model", "=", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "", "else", ":", "\n", "# Load from our TensorFlow 2.0 checkpoints", "\n", "                ", "try", ":", "\n", "                    ", "from", "transformers", "import", "load_tf2_checkpoint_in_pytorch_model", "\n", "model", "=", "load_tf2_checkpoint_in_pytorch_model", "(", "model", ",", "resolved_archive_file", ",", "allow_missing_keys", "=", "True", ")", "\n", "", "except", "ImportError", "as", "e", ":", "\n", "                    ", "logger", ".", "error", "(", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "e", "\n", "", "", "", "else", ":", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "            ", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_key", "=", "None", "\n", "if", "'gamma'", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "'gamma'", ",", "'weight'", ")", "\n", "", "if", "'beta'", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "'beta'", ",", "'bias'", ")", "\n", "", "if", "key", "==", "'lm_head.decoder.weight'", ":", "\n", "                    ", "new_key", "=", "'lm_head.weight'", "\n", "", "if", "new_key", ":", "\n", "                    ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "                ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "", "metadata", "=", "getattr", "(", "state_dict", ",", "'_metadata'", ",", "None", ")", "\n", "# print('orig state dict', state_dict.keys(), len(state_dict))", "\n", "customized_state_dict", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "k", ",", "v", "in", "state_dict", ".", "items", "(", ")", ":", "\n", "                ", "k_split", "=", "k", ".", "split", "(", "'.'", ")", "\n", "if", "k_split", "[", "0", "]", "==", "'albert'", ":", "\n", "                    ", "k_split", "[", "0", "]", "=", "'query_encoder'", "\n", "customized_state_dict", "[", "'.'", ".", "join", "(", "k_split", ")", "]", "=", "v", "\n", "k_split", "[", "0", "]", "=", "'passage_encoder'", "\n", "customized_state_dict", "[", "'.'", ".", "join", "(", "k_split", ")", "]", "=", "v", "\n", "\n", "", "", "if", "len", "(", "customized_state_dict", ")", "==", "0", ":", "\n", "# loading from our trained model", "\n", "                ", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "# print('using orig state dict', state_dict.keys())", "\n", "", "else", ":", "\n", "# loading from original bert model", "\n", "                ", "state_dict", "=", "customized_state_dict", ".", "copy", "(", ")", "\n", "# print('using custome state dict', state_dict.keys())", "\n", "\n", "# print('modified state dict', state_dict.keys(), len(state_dict))", "\n", "", "if", "metadata", "is", "not", "None", ":", "\n", "                ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "# PyTorch's `_load_from_state_dict` does not copy parameters in a module's descendants", "\n", "# so we need to apply the function recursively.", "\n", "", "def", "load", "(", "module", ",", "prefix", "=", "''", ")", ":", "\n", "                ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                    ", "if", "child", "is", "not", "None", ":", "\n", "                        ", "load", "(", "child", ",", "prefix", "+", "name", "+", "'.'", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "''", "\n", "model_to_load", "=", "model", "\n", "#             if not hasattr(model, cls.base_model_prefix) and any(s.startswith(cls.base_model_prefix) for s in state_dict.keys()):", "\n", "#                 start_prefix = cls.base_model_prefix + '.'", "\n", "#             if hasattr(model, cls.base_model_prefix) and not any(s.startswith(cls.base_model_prefix) for s in state_dict.keys()):", "\n", "#                 model_to_load = getattr(model, cls.base_model_prefix)", "\n", "\n", "#             load(model_to_load, prefix=start_prefix)", "\n", "load", "(", "model_to_load", ",", "prefix", "=", "''", ")", "\n", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", ")", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", ")", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "'Error(s) in loading state_dict for {}:\\n\\t{}'", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", ")", ")", "\n", "\n", "", "", "model", ".", "tie_weights", "(", ")", "# make sure word embedding weights are still tied if needed", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\"missing_keys\"", ":", "missing_keys", ",", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\"error_msgs\"", ":", "error_msgs", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.modeling.Pipeline.__init__": [[1086, 1091], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Pipeline", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "reader", "=", "None", "\n", "self", ".", "retriever", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputExample.__init__": [[33, 38], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "text_a", ",", "text_b", "=", "None", ",", "label", "=", "None", ")", ":", "\n", "        ", "self", ".", "guid", "=", "guid", "\n", "self", ".", "text_a", "=", "text_a", "\n", "self", ".", "text_b", "=", "text_b", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputExample.__repr__": [[39, 41], ["str", "retriever_utils.RetrieverInputExample.to_json_string"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputExample.to_dict": [[42, 46], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputExample.to_json_string": [[47, 50], ["json.dumps", "retriever_utils.RetrieverInputExample.to_dict"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.__init__": [[64, 69], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "attention_mask", ",", "token_type_ids", ",", "label", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "attention_mask", "=", "attention_mask", "\n", "self", ".", "token_type_ids", "=", "token_type_ids", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.__repr__": [[70, 72], ["str", "retriever_utils.RetrieverInputFeatures.to_json_string"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.to_dict": [[73, 77], ["copy.deepcopy"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a Python dictionary.\"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.to_json_string": [[78, 81], ["json.dumps", "retriever_utils.RetrieverInputFeatures.to_dict"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverInputFeatures.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"Serializes this instance to a JSON string.\"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverDataset.__init__": [[84, 120], ["io.open", "len", "f.readlines"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "tokenizer", ",", "\n", "load_small", ",", "history_num", ",", "prepend_history_questions", "=", "True", ",", "\n", "prepend_history_answers", "=", "False", ",", "\n", "query_max_seq_length", "=", "128", ",", "passage_max_seq_length", "=", "384", ",", "\n", "is_pretraining", "=", "False", ",", "given_query", "=", "False", ",", "\n", "given_passage", "=", "False", ",", "only_positive_passage", "=", "True", ",", "\n", "include_first_for_retriever", "=", "False", ")", ":", "\n", "\n", "        ", "self", ".", "_filename", "=", "filename", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_load_small", "=", "load_small", "\n", "self", ".", "_history_num", "=", "history_num", "\n", "self", ".", "_query_max_seq_length", "=", "query_max_seq_length", "\n", "self", ".", "_passage_max_seq_length", "=", "passage_max_seq_length", "\n", "self", ".", "_prepend_history_questions", "=", "prepend_history_questions", "\n", "self", ".", "_prepend_history_answers", "=", "prepend_history_answers", "\n", "\n", "# if given query:", "\n", "# if pretraining: using rewrite as question", "\n", "# else: using concat of question", "\n", "self", ".", "_is_pretraining", "=", "is_pretraining", "\n", "self", ".", "_given_query", "=", "given_query", "\n", "self", ".", "_given_passage", "=", "given_passage", "\n", "\n", "# if we only pass the positive passages to the model", "\n", "# the rest of the passges in the batch are considered as negatives", "\n", "self", ".", "_only_positive_passage", "=", "only_positive_passage", "\n", "\n", "self", ".", "_include_first_for_retriever", "=", "include_first_for_retriever", "\n", "\n", "self", ".", "_total_data", "=", "0", "\n", "if", "self", ".", "_load_small", ":", "\n", "            ", "self", ".", "_total_data", "=", "50", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "self", ".", "_total_data", "=", "len", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverDataset.__len__": [[121, 123], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_total_data", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.RetrieverDataset.__getitem__": [[124, 229], ["linecache.getline", "json.loads", "linecache.getline.strip", "retriever_utils.RetrieverInputExample", "retriever_utils.retriever_convert_example_to_feature", "return_feature_dict.update", "question_text_list.append", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.argmax", "retriever_utils.RetrieverInputExample", "retriever_utils.retriever_convert_example_to_feature", "return_feature_dict.update", "enumerate", "batch[].keys", "return_feature_dict.update", "numpy.asarray", "numpy.asarray", "numpy.asarray", "zip", "retriever_utils.RetrieverInputExample", "retriever_utils.retriever_convert_example_to_feature", "batch.append", "len", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.vstack", "question_text_list.append", "question_text_list.append"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.retriever_convert_example_to_feature", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.retriever_convert_example_to_feature", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.retriever_convert_example_to_feature"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"read a line of preprocessed open-retrieval quac file into a quac example\"\"\"", "\n", "line", "=", "linecache", ".", "getline", "(", "self", ".", "_filename", ",", "idx", "+", "1", ")", "\n", "entry", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "qas_id", "=", "entry", "[", "\"qid\"", "]", "\n", "retrieval_labels", "=", "entry", "[", "'retrieval_labels'", "]", "\n", "\n", "return_feature_dict", "=", "{", "}", "\n", "\n", "if", "self", ".", "_given_query", ":", "\n", "            ", "if", "self", ".", "_is_pretraining", "or", "self", ".", "_history_num", "==", "-", "1", ":", "\n", "                ", "question_text_for_retriever", "=", "entry", "[", "\"rewrite\"", "]", "\n", "question_text", "=", "entry", "[", "\"rewrite\"", "]", "\n", "", "else", ":", "\n", "                ", "orig_question_text", "=", "entry", "[", "\"question\"", "]", "\n", "history", "=", "entry", "[", "'history'", "]", "\n", "question_text_list", "=", "[", "]", "\n", "if", "self", ".", "_history_num", ">", "0", ":", "\n", "                    ", "for", "turn", "in", "history", "[", "-", "self", ".", "_history_num", ":", "]", ":", "\n", "                        ", "if", "self", ".", "_prepend_history_questions", ":", "\n", "                            ", "question_text_list", ".", "append", "(", "turn", "[", "'question'", "]", ")", "\n", "", "if", "self", ".", "_prepend_history_answers", ":", "\n", "                            ", "question_text_list", ".", "append", "(", "turn", "[", "'answer'", "]", "[", "'text'", "]", ")", "\n", "", "", "", "question_text_list", ".", "append", "(", "orig_question_text", ")", "\n", "question_text", "=", "' [SEP] '", ".", "join", "(", "question_text_list", ")", "\n", "question_text_for_retriever", "=", "question_text", "\n", "\n", "# include the first question in addition to history_num for retriever (not reader)", "\n", "if", "self", ".", "_include_first_for_retriever", "and", "len", "(", "history", ")", ">", "0", ":", "\n", "                    ", "first_question", "=", "history", "[", "0", "]", "[", "'question'", "]", "\n", "if", "first_question", "!=", "question_text_list", "[", "0", "]", ":", "\n", "                        ", "question_text_for_retriever", "=", "first_question", "+", "' [SEP] '", "+", "question_text", "\n", "\n", "# print('question_text_for_retriever', question_text_for_retriever)", "\n", "# print('question_text', question_text)", "\n", "\n", "# print('question_text_for_retriever', question_text_for_retriever)", "\n", "", "", "", "query_example", "=", "RetrieverInputExample", "(", "guid", "=", "qas_id", ",", "text_a", "=", "question_text_for_retriever", ")", "\n", "query_feature", "=", "retriever_convert_example_to_feature", "(", "query_example", ",", "self", ".", "_tokenizer", ",", "\n", "max_length", "=", "self", ".", "_query_max_seq_length", ")", "\n", "query_feature_dict", "=", "{", "'query_input_ids'", ":", "np", ".", "asarray", "(", "query_feature", ".", "input_ids", ")", ",", "\n", "'query_token_type_ids'", ":", "np", ".", "asarray", "(", "query_feature", ".", "token_type_ids", ")", ",", "\n", "'query_attention_mask'", ":", "np", ".", "asarray", "(", "query_feature", ".", "attention_mask", ")", ",", "\n", "'qid'", ":", "qas_id", "}", "\n", "# during fine-tuning, we also return the query text for training reader", "\n", "if", "not", "self", ".", "_is_pretraining", ":", "\n", "                ", "query_feature_dict", "[", "'question_text'", "]", "=", "question_text", "\n", "query_feature_dict", "[", "'answer_text'", "]", "=", "entry", "[", "'answer'", "]", "[", "'text'", "]", "\n", "query_feature_dict", "[", "'answer_start'", "]", "=", "entry", "[", "'answer'", "]", "[", "'answer_start'", "]", "\n", "\n", "", "return_feature_dict", ".", "update", "(", "query_feature_dict", ")", "\n", "\n", "", "if", "self", ".", "_given_passage", ":", "\n", "            ", "passages", "=", "entry", "[", "'evidences'", "]", "\n", "\n", "if", "self", ".", "_only_positive_passage", ":", "\n", "                ", "postive_idx", "=", "np", ".", "argmax", "(", "retrieval_labels", ")", "\n", "passage", "=", "passages", "[", "postive_idx", "]", "\n", "\n", "example_id", "=", "'{}_{}'", ".", "format", "(", "qas_id", ",", "postive_idx", ")", "\n", "passage_example", "=", "RetrieverInputExample", "(", "\n", "guid", "=", "example_id", ",", "\n", "text_a", "=", "passage", ",", "\n", "label", "=", "1", ")", "\n", "\n", "passage_feature", "=", "retriever_convert_example_to_feature", "(", "passage_example", ",", "self", ".", "_tokenizer", ",", "\n", "max_length", "=", "self", ".", "_passage_max_seq_length", ")", "\n", "passage_feature_dict", "=", "{", "'passage_input_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "input_ids", ")", ",", "\n", "'passage_token_type_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "token_type_ids", ")", ",", "\n", "'passage_attention_mask'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "attention_mask", ")", ",", "\n", "'retrieval_label'", ":", "passage_feature", ".", "label", ",", "\n", "'example_id'", ":", "example_id", "}", "\n", "return_feature_dict", ".", "update", "(", "passage_feature_dict", ")", "\n", "\n", "", "else", ":", "\n", "                ", "batch", "=", "[", "]", "\n", "passage_examples", "=", "[", "]", "\n", "for", "i", ",", "(", "passage", ",", "retrieval_label", ")", "in", "enumerate", "(", "zip", "(", "passages", ",", "retrieval_labels", ")", ")", ":", "\n", "                    ", "example_id", "=", "'{}_{}'", ".", "format", "(", "qas_id", ",", "i", ")", "\n", "passage_example", "=", "RetrieverInputExample", "(", "\n", "guid", "=", "example_id", ",", "\n", "text_a", "=", "passage", ",", "\n", "label", "=", "retrieval_label", ")", "\n", "\n", "passage_feature", "=", "retriever_convert_example_to_feature", "(", "passage_example", ",", "self", ".", "_tokenizer", ",", "\n", "max_length", "=", "self", ".", "_passage_max_seq_length", ")", "\n", "batch_feature", "=", "{", "'passage_input_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "input_ids", ")", ",", "\n", "'passage_token_type_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "token_type_ids", ")", ",", "\n", "'passage_attention_mask'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "attention_mask", ")", ",", "\n", "'retrieval_label'", ":", "passage_feature", ".", "label", ",", "\n", "'example_id'", ":", "example_id", "}", "\n", "\n", "batch", ".", "append", "(", "batch_feature", ")", "\n", "\n", "", "collated", "=", "{", "}", "\n", "keys", "=", "batch", "[", "0", "]", ".", "keys", "(", ")", "\n", "for", "key", "in", "keys", ":", "\n", "                    ", "if", "key", "!=", "'example_id'", ":", "\n", "                        ", "collated", "[", "key", "]", "=", "np", ".", "vstack", "(", "[", "dic", "[", "key", "]", "for", "dic", "in", "batch", "]", ")", "\n", "", "", "if", "'example_id'", "in", "keys", ":", "\n", "                    ", "collated", "[", "'example_id'", "]", "=", "[", "dic", "[", "'example_id'", "]", "for", "dic", "in", "batch", "]", "\n", "\n", "", "return_feature_dict", ".", "update", "(", "collated", ")", "\n", "\n", "", "", "return", "return_feature_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.IctDataset.__init__": [[232, 244], ["spacy.load"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "tokenizer", ",", "\n", "load_small", ",", "query_max_seq_length", "=", "128", ",", "\n", "passage_max_seq_length", "=", "384", ",", "ict_remove_prob", "=", "0.9", ")", ":", "\n", "\n", "        ", "self", ".", "_filename", "=", "filename", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_load_small", "=", "load_small", "\n", "self", ".", "_query_max_seq_length", "=", "query_max_seq_length", "\n", "self", ".", "_passage_max_seq_length", "=", "passage_max_seq_length", "\n", "self", ".", "_total_data", "=", "50", "if", "self", ".", "_load_small", "else", "11377951", "# count the lines in all_blocks.txt ", "\n", "self", ".", "_nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "self", ".", "_ict_remove_prob", "=", "ict_remove_prob", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.IctDataset.__len__": [[245, 247], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_total_data", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.IctDataset.__getitem__": [[248, 297], ["linecache.getline", "json.loads", "retriever_utils.IctDataset._nlp", "retriever_utils.RetrieverInputExample", "retriever_utils.retriever_convert_example_to_feature", "return_feature_dict.update", "retriever_utils.RetrieverInputExample", "retriever_utils.retriever_convert_example_to_feature", "return_feature_dict.update", "linecache.getline.strip", "str", "numpy.random.choice", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.random.choice", "sents.pop", "numpy.asarray", "numpy.asarray", "numpy.asarray", "len"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.retriever_convert_example_to_feature", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.retriever_convert_example_to_feature"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"read a line of all_blocks.txt\"\"\"", "\n", "line", "=", "linecache", ".", "getline", "(", "self", ".", "_filename", ",", "idx", "+", "1", ")", "\n", "entry", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "text", "=", "entry", "[", "'text'", "]", "\n", "qas_id", "=", "entry", "[", "'id'", "]", "\n", "\n", "doc", "=", "self", ".", "_nlp", "(", "str", "(", "text", ")", ")", "\n", "sents", "=", "doc", ".", "sents", "\n", "sents", "=", "[", "sent", ".", "text", "for", "sent", "in", "sents", "]", "\n", "sent_idx", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "sents", ")", ",", "1", ")", "[", "0", "]", "\n", "\n", "return_feature_dict", "=", "{", "}", "\n", "\n", "# for question:", "\n", "question_text", "=", "sents", "[", "sent_idx", "]", "\n", "query_example", "=", "RetrieverInputExample", "(", "guid", "=", "qas_id", ",", "text_a", "=", "question_text", ")", "\n", "query_feature", "=", "retriever_convert_example_to_feature", "(", "query_example", ",", "self", ".", "_tokenizer", ",", "\n", "max_length", "=", "self", ".", "_query_max_seq_length", ")", "\n", "query_feature_dict", "=", "{", "'query_input_ids'", ":", "np", ".", "asarray", "(", "query_feature", ".", "input_ids", ")", ",", "\n", "'query_token_type_ids'", ":", "np", ".", "asarray", "(", "query_feature", ".", "token_type_ids", ")", ",", "\n", "'query_attention_mask'", ":", "np", ".", "asarray", "(", "query_feature", ".", "attention_mask", ")", ",", "\n", "'qid'", ":", "qas_id", "}", "\n", "return_feature_dict", ".", "update", "(", "query_feature_dict", ")", "\n", "\n", "# for passage   ", "\n", "remove_sent_flag", "=", "np", ".", "random", ".", "choice", "(", "[", "True", ",", "False", "]", ",", "1", ",", "\n", "p", "=", "[", "self", ".", "_ict_remove_prob", ",", "1", "-", "self", ".", "_ict_remove_prob", "]", ")", "[", "0", "]", "\n", "if", "remove_sent_flag", ":", "\n", "            ", "sents", ".", "pop", "(", "sent_idx", ")", "\n", "\n", "", "passage", "=", "' '", ".", "join", "(", "sents", ")", "\n", "example_id", "=", "'{}_{}'", ".", "format", "(", "qas_id", ",", "0", ")", "\n", "passage_example", "=", "RetrieverInputExample", "(", "\n", "guid", "=", "example_id", ",", "\n", "text_a", "=", "passage", ",", "\n", "label", "=", "1", ")", "\n", "\n", "passage_feature", "=", "retriever_convert_example_to_feature", "(", "passage_example", ",", "self", ".", "_tokenizer", ",", "\n", "max_length", "=", "self", ".", "_passage_max_seq_length", ")", "\n", "passage_feature_dict", "=", "{", "'passage_input_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "input_ids", ")", ",", "\n", "'passage_token_type_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "token_type_ids", ")", ",", "\n", "'passage_attention_mask'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "attention_mask", ")", ",", "\n", "'retrieval_label'", ":", "passage_feature", ".", "label", ",", "\n", "'example_id'", ":", "example_id", "}", "\n", "return_feature_dict", ".", "update", "(", "passage_feature_dict", ")", "\n", "# print('question:', question_text)", "\n", "# print('passage:', passage)", "\n", "return", "return_feature_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.GenPassageRepDataset.__init__": [[300, 314], ["io.open", "len", "f.readlines"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "tokenizer", ",", "\n", "load_small", ",", "passage_max_seq_length", "=", "386", ")", ":", "\n", "\n", "        ", "self", ".", "_filename", "=", "filename", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_load_small", "=", "load_small", "\n", "self", ".", "_passage_max_seq_length", "=", "passage_max_seq_length", "\n", "\n", "self", ".", "_total_data", "=", "0", "\n", "if", "self", ".", "_load_small", ":", "\n", "            ", "self", ".", "_total_data", "=", "100", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "self", ".", "_total_data", "=", "len", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.GenPassageRepDataset.__len__": [[315, 317], ["None"], "methods", ["None"], ["", "", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_total_data", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.GenPassageRepDataset.__getitem__": [[318, 334], ["linecache.getline", "json.loads", "retriever_utils.RetrieverInputExample", "retriever_utils.retriever_convert_example_to_feature", "linecache.getline.strip", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.retriever_convert_example_to_feature"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"read a line of preprocessed open-retrieval quac file into a quac example\"\"\"", "\n", "line", "=", "linecache", ".", "getline", "(", "self", ".", "_filename", ",", "idx", "+", "1", ")", "\n", "entry", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "example_id", "=", "entry", "[", "\"id\"", "]", "\n", "passage", "=", "entry", "[", "'text'", "]", "\n", "\n", "passage_example", "=", "RetrieverInputExample", "(", "guid", "=", "example_id", ",", "text_a", "=", "passage", ")", "\n", "passage_feature", "=", "retriever_convert_example_to_feature", "(", "passage_example", ",", "self", ".", "_tokenizer", ",", "\n", "max_length", "=", "self", ".", "_passage_max_seq_length", ")", "\n", "batch_feature", "=", "{", "'passage_input_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "input_ids", ")", ",", "\n", "'passage_token_type_ids'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "token_type_ids", ")", ",", "\n", "'passage_attention_mask'", ":", "np", ".", "asarray", "(", "passage_feature", ".", "attention_mask", ")", ",", "\n", "'example_id'", ":", "example_id", "}", "\n", "\n", "return", "batch_feature", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.retriever_utils.retriever_convert_example_to_feature": [[335, 400], ["tokenizer.encode_plus", "retriever_utils.RetrieverInputFeatures", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "str", "str", "str"], "function", ["None"], ["", "", "def", "retriever_convert_example_to_feature", "(", "example", ",", "tokenizer", ",", "\n", "max_length", "=", "512", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Loads a data file into a list of ``InputFeatures``\n    Args:\n        examples: List of ``InputExamples`` or ``tf.data.Dataset`` containing the examples.\n        tokenizer: Instance of a tokenizer that will tokenize the examples\n        max_length: Maximum example length\n        pad_token: Padding token\n        pad_token_segment_id: The segment ID for the padding token (It is usually 0, but can vary such as for XLNet where it is 4)\n        mask_padding_with_zero: If set to ``True``, the attention mask will be filled by ``1`` for actual values\n            and by ``0`` for padded values. If set to ``False``, inverts it (``1`` for padded values, ``0`` for\n            actual values)\n    Returns:\n        If the ``examples`` input is a ``tf.data.Dataset``, will return a ``tf.data.Dataset``\n        containing the task-specific features. If the input is a list of ``InputExamples``, will return\n        a list of task-specific ``InputFeatures`` which can be fed to the model.\n    \"\"\"", "\n", "\n", "\n", "inputs", "=", "tokenizer", ".", "encode_plus", "(", "\n", "example", ".", "text_a", ",", "\n", "example", ".", "text_b", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "max_length", "=", "max_length", ",", "\n", ")", "\n", "input_ids", ",", "token_type_ids", "=", "inputs", "[", "\"input_ids\"", "]", ",", "inputs", "[", "\"token_type_ids\"", "]", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "attention_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "        ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "attention_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "attention_mask", "\n", "token_type_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "token_type_ids", "\n", "", "else", ":", "\n", "        ", "input_ids", "=", "input_ids", "+", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "attention_mask", "=", "attention_mask", "+", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "token_type_ids", "=", "token_type_ids", "+", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "input_ids", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "attention_mask", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "attention_mask", ")", ",", "max_length", ")", "\n", "assert", "len", "(", "token_type_ids", ")", "==", "max_length", ",", "\"Error with input length {} vs {}\"", ".", "format", "(", "len", "(", "token_type_ids", ")", ",", "max_length", ")", "\n", "\n", "if", "False", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", "%", "(", "example", ".", "guid", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"attention_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "attention_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_type_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "token_type_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label: %s\"", "%", "(", "example", ".", "label", ")", ")", "\n", "\n", "", "feature", "=", "RetrieverInputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "label", "=", "example", ".", "label", ")", "\n", "\n", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.set_seed": [[63, 69], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.to_list": [[70, 72], ["tensor.detach().cpu().tolist", "tensor.detach().cpu", "tensor.detach"], "function", ["None"], ["", "", "def", "to_list", "(", "tensor", ")", ":", "\n", "    ", "return", "tensor", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.str2bool": [[73, 82], ["isinstance", "v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "isinstance", "(", "v", ",", "bool", ")", ":", "\n", "        ", "return", "v", "\n", "", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.train": [[87, 238], ["torch.utils.data.DataLoader", "transformers.AdamW", "int", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "train_weak_supervisor.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "os.path.join", "torch.nn.parallel.DistributedDataParallel.train", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "v.to", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "batch.items", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "SummaryWriter.add_scalar", "SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "train_weak_supervisor.evaluate", "evaluate.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.set_seed", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.train", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'logs'", ")", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "\n", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "\n", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ",", "num_workers", "=", "args", ".", "num_workers", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "\n", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "\n", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "\n", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "\n", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "\n", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "args", ".", "warmup_steps", "=", "int", "(", "t_total", "*", "args", ".", "warmup_portion", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\n", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "\n", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "\n", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "\n", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "1", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "\n", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "# Added here for reproductibility (even between python 2 and 3)", "\n", "set_seed", "(", "args", ")", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "\n", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "args", ".", "device", ")", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "}", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "'input_ids'", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "'input_mask'", "]", ",", "\n", "'start_positions'", ":", "batch", "[", "'start_position'", "]", ",", "\n", "'end_positions'", ":", "batch", "[", "'end_position'", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "'distilbert'", ":", "\n", "                ", "inputs", "[", "'token_type_ids'", "]", "=", "None", "if", "args", ".", "model_type", "==", "'xlm'", "else", "batch", "[", "'segment_ids'", "]", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "# model outputs are always tuple in transformers (see doc)", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel (not distributed) training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "\n", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\n", "'eval_{}'", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\n", "'lr'", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\n", "'loss'", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "# Take care of distributed/parallel training", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "\n", "model", ",", "'module'", ")", "else", "model", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "\n", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.evaluate": [[243, 336], ["DatasetClass", "os.path.join", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "timeit.default_timer", "tqdm.tqdm", "logger.info", "os.path.join", "os.path.join", "os.path.join", "utils.write_predictions", "utils.write_weak_supervisor_predictions", "utils.weak_supervisor_eval", "os.path.join", "os.makedirs", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "enumerate", "timeit.default_timer", "os.path.join", "open", "json.dump", "os.path.exists", "os.path.exists", "v.to", "torch.no_grad", "torch.nn.DataParallel.", "utils.RawResult", "all_results.append", "len", "batch.items", "train_weak_supervisor.to_list", "train_weak_supervisor.to_list"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_predictions", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_weak_supervisor_predictions", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.weak_supervisor_eval", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.to_list", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.to_list"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "if", "prefix", "==", "'test'", ":", "\n", "        ", "eval_file", "=", "args", ".", "test_file", "\n", "", "else", ":", "\n", "        ", "eval_file", "=", "args", ".", "dev_file", "\n", "\n", "", "DatasetClass", "=", "WeakSupervisorDataset", "\n", "dataset", "=", "DatasetClass", "(", "eval_file", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "\n", "args", ".", "load_small", ",", "is_training", "=", "False", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "", "predict_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'predictions'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "predict_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "predict_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "# eval_sampler = SequentialSampler(", "\n", "#     dataset) if args.local_rank == -1 else DistributedSampler(dataset)", "\n", "eval_sampler", "=", "SequentialSampler", "(", "dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "\n", "dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "all_results", "=", "[", "]", "\n", "start_time", "=", "timeit", ".", "default_timer", "(", ")", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "\n", "example_ids", "=", "batch", "[", "'example_id'", "]", "\n", "batch", "=", "{", "k", ":", "v", ".", "to", "(", "args", ".", "device", ")", "\n", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", "if", "k", "!=", "'example_id'", "}", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "'input_ids'", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "'input_mask'", "]", "\n", "}", "\n", "if", "args", ".", "model_type", "!=", "'distilbert'", ":", "\n", "# XLM don't use segment_ids", "\n", "                ", "inputs", "[", "'token_type_ids'", "]", "=", "None", "if", "args", ".", "model_type", "==", "'xlm'", "else", "batch", "[", "'segment_ids'", "]", "\n", "# example_ids = batch['example_id']", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "\n", "", "for", "i", ",", "example_id", "in", "enumerate", "(", "example_ids", ")", ":", "\n", "            ", "result", "=", "RawResult", "(", "unique_id", "=", "example_id", ",", "\n", "start_logits", "=", "to_list", "(", "outputs", "[", "0", "]", "[", "i", "]", ")", ",", "\n", "end_logits", "=", "to_list", "(", "outputs", "[", "1", "]", "[", "i", "]", ")", ",", "\n", "retrieval_logits", "=", "[", "1", "]", ")", "# retrieval_logits is not used            ", "\n", "all_results", ".", "append", "(", "result", ")", "\n", "\n", "", "", "examples", "=", "dataset", ".", "all_examples", "\n", "features", "=", "dataset", ".", "all_features", "\n", "# assert len(examples) == len(dataset), (len(examples), len(dataset))", "\n", "# assert len(features) == len(dataset), (len(features), len(dataset))", "\n", "\n", "evalTime", "=", "timeit", ".", "default_timer", "(", ")", "-", "start_time", "\n", "logger", ".", "info", "(", "\"  Evaluation done in total %f secs (%f sec per example)\"", ",", "\n", "evalTime", ",", "evalTime", "/", "len", "(", "dataset", ")", ")", "\n", "\n", "# Compute predictions", "\n", "output_prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"instance_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_nbest_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"instance_nbest_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "output_final_prediction_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"final_predictions_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "if", "args", ".", "version_2_with_negative", ":", "\n", "        ", "output_null_log_odds_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"instance_null_odds_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "", "else", ":", "\n", "        ", "output_null_log_odds_file", "=", "None", "\n", "\n", "\n", "", "all_predictions", "=", "write_predictions", "(", "examples", ",", "features", ",", "all_results", ",", "args", ".", "n_best_size", ",", "\n", "args", ".", "max_answer_length", ",", "args", ".", "do_lower_case", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "output_null_log_odds_file", ",", "args", ".", "verbose_logging", ",", "\n", "args", ".", "version_2_with_negative", ",", "args", ".", "null_score_diff_threshold", ")", "\n", "write_weak_supervisor_predictions", "(", "all_predictions", ",", "output_final_prediction_file", ")", "\n", "eval_metrics", "=", "weak_supervisor_eval", "(", "eval_file", ",", "output_final_prediction_file", ")", "\n", "\n", "metrics_file", "=", "os", ".", "path", ".", "join", "(", "\n", "predict_dir", ",", "\"metrics_{}.json\"", ".", "format", "(", "prefix", ")", ")", "\n", "with", "open", "(", "metrics_file", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "json", ".", "dump", "(", "eval_metrics", ",", "fout", ")", "\n", "\n", "", "return", "eval_metrics", "\n", "# python scorer.py --val_file /mnt/scratch/chenqu/orconvqa/v3/quac/original/val_v0.2.json --model_output /mnt/scratch/chenqu/orconvqa_output/final_predictions_.json --o eval.json", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.QuacExample.__init__": [[46, 71], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "example_id", ",", "\n", "qas_id", ",", "\n", "question_text", ",", "\n", "doc_tokens", ",", "\n", "orig_answer_text", "=", "None", ",", "\n", "start_position", "=", "None", ",", "\n", "end_position", "=", "None", ",", "\n", "is_impossible", "=", "None", ",", "\n", "followup", "=", "None", ",", "\n", "yesno", "=", "None", ",", "\n", "retrieval_label", "=", "None", ",", "\n", "history", "=", "None", ")", ":", "\n", "        ", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "qas_id", "=", "qas_id", "\n", "self", ".", "question_text", "=", "question_text", "\n", "self", ".", "doc_tokens", "=", "doc_tokens", "\n", "self", ".", "orig_answer_text", "=", "orig_answer_text", "\n", "self", ".", "start_position", "=", "start_position", "\n", "self", ".", "end_position", "=", "end_position", "\n", "self", ".", "is_impossible", "=", "is_impossible", "\n", "self", ".", "followup", "=", "followup", "\n", "self", ".", "yesno", "=", "yesno", "\n", "self", ".", "retrieval_label", "=", "retrieval_label", "\n", "self", ".", "history", "=", "history", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.QuacExample.__str__": [[72, 74], ["utils.QuacExample.__repr__"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.QuacExample.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.QuacExample.__repr__": [[75, 95], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "s", "=", "\"\"", "\n", "s", "+=", "\"example_id: %s\"", "%", "(", "self", ".", "example_id", ")", "\n", "s", "+=", "\"qas_id: %s\"", "%", "(", "self", ".", "qas_id", ")", "\n", "s", "+=", "\", question_text: %s\"", "%", "(", "\n", "self", ".", "question_text", ")", "\n", "s", "+=", "\", doc_tokens: [%s]\"", "%", "(", "\" \"", ".", "join", "(", "self", ".", "doc_tokens", ")", ")", "\n", "if", "self", ".", "start_position", ":", "\n", "            ", "s", "+=", "\", start_position: %d\"", "%", "(", "self", ".", "start_position", ")", "\n", "", "if", "self", ".", "end_position", ":", "\n", "            ", "s", "+=", "\", end_position: %d\"", "%", "(", "self", ".", "end_position", ")", "\n", "", "if", "self", ".", "is_impossible", ":", "\n", "            ", "s", "+=", "\", is_impossible: %r\"", "%", "(", "self", ".", "is_impossible", ")", "\n", "", "s", "+=", "', followup: {}'", ".", "format", "(", "self", ".", "followup", ")", "\n", "s", "+=", "', yesno: {}'", ".", "format", "(", "self", ".", "yesno", ")", "\n", "if", "self", ".", "retrieval_label", ":", "\n", "            ", "s", "+=", "', retrieval_label: {}'", ".", "format", "(", "self", ".", "retrieval_label", ")", "\n", "", "s", "+=", "', history: {}'", ".", "format", "(", "self", ".", "history", ")", "\n", "\n", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.InputFeatures.__init__": [[100, 135], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "unique_id", ",", "\n", "example_id", ",", "\n", "doc_span_index", ",", "\n", "tokens", ",", "\n", "token_to_orig_map", ",", "\n", "token_is_max_context", ",", "\n", "input_ids", ",", "\n", "input_mask", ",", "\n", "segment_ids", ",", "\n", "cls_index", ",", "\n", "p_mask", ",", "\n", "paragraph_len", ",", "\n", "start_position", "=", "None", ",", "\n", "end_position", "=", "None", ",", "\n", "is_impossible", "=", "None", ",", "\n", "retrieval_label", "=", "None", ")", ":", "\n", "# we have exactly 1 feature for every example,", "\n", "# so the unique id is the same with the example id", "\n", "        ", "self", ".", "unique_id", "=", "unique_id", "\n", "self", ".", "example_id", "=", "example_id", "\n", "self", ".", "doc_span_index", "=", "doc_span_index", "\n", "self", ".", "tokens", "=", "tokens", "\n", "self", ".", "token_to_orig_map", "=", "token_to_orig_map", "\n", "self", ".", "token_is_max_context", "=", "token_is_max_context", "\n", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "cls_index", "=", "cls_index", "\n", "self", ".", "p_mask", "=", "p_mask", "\n", "self", ".", "paragraph_len", "=", "paragraph_len", "\n", "self", ".", "start_position", "=", "start_position", "\n", "self", ".", "end_position", "=", "end_position", "\n", "self", ".", "is_impossible", "=", "is_impossible", "\n", "self", ".", "retrieval_label", "=", "retrieval_label", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.LazyQuacDataset.__init__": [[137, 161], ["io.open", "len", "f.readlines"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "max_seq_length", ",", "tokenizer", ",", "\n", "load_small", ",", "history_num", ",", "prepend_history_questions", ",", "\n", "prepend_history_answers", ",", "embed_history_answers", ",", "\n", "is_training", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "_filename", "=", "filename", "\n", "self", ".", "_max_seq_length", "=", "max_seq_length", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_load_small", "=", "load_small", "\n", "self", ".", "_history_num", "=", "history_num", "\n", "self", ".", "_is_training", "=", "is_training", "\n", "self", ".", "_prepend_history_questions", "=", "prepend_history_questions", "\n", "self", ".", "_prepend_history_answers", "=", "prepend_history_answers", "\n", "self", ".", "_embed_history_answers", "=", "embed_history_answers", "\n", "\n", "self", ".", "all_examples", "=", "{", "}", "\n", "self", ".", "all_features", "=", "{", "}", "\n", "\n", "self", ".", "_total_data", "=", "0", "\n", "if", "self", ".", "_load_small", ":", "\n", "            ", "self", ".", "_total_data", "=", "100", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "self", ".", "_total_data", "=", "len", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.LazyQuacDataset.__getitem__": [[162, 274], ["linecache.getline", "json.loads", "question_text_list.append", "utils.QuacExample", "utils.convert_example_to_feature", "linecache.getline.strip", "utils.is_whitespace", "char_to_word_offset.append", "len", "int", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "doc_tokens.append", "len", "question_text_list.append", "question_text_list.append", "transformers.tokenization_bert.whitespace_tokenize", "actual_text.find", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.convert_example_to_feature", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.is_whitespace"], ["", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"read a line of preprocessed open-retrieval quac file into a quac example\"\"\"", "\n", "\n", "line", "=", "linecache", ".", "getline", "(", "self", ".", "_filename", ",", "idx", "+", "1", ")", "\n", "entry", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "example_id", "=", "entry", "[", "'unique_id'", "]", "\n", "\n", "paragraph_text", "=", "entry", "[", "'evidence'", "]", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "            ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "prev_is_whitespace", ":", "\n", "                    ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                    ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "qas_id", "=", "entry", "[", "\"qid\"", "]", "\n", "\n", "\n", "orig_question_text", "=", "entry", "[", "\"question\"", "]", "\n", "\n", "# TODO: fix the bug when history_num = 0", "\n", "history", "=", "entry", "[", "'history'", "]", "\n", "question_text_list", "=", "[", "]", "\n", "if", "self", ".", "_history_num", ">", "0", ":", "\n", "            ", "for", "turn", "in", "history", "[", "-", "self", ".", "_history_num", ":", "]", ":", "\n", "                ", "if", "self", ".", "_prepend_history_questions", ":", "\n", "                    ", "question_text_list", ".", "append", "(", "turn", "[", "'question'", "]", ")", "\n", "", "if", "self", ".", "_prepend_history_answers", ":", "\n", "                    ", "question_text_list", ".", "append", "(", "turn", "[", "'answer'", "]", "[", "'text'", "]", ")", "\n", "", "", "", "question_text_list", ".", "append", "(", "orig_question_text", ")", "\n", "question_text", "=", "' [SEP] '", ".", "join", "(", "question_text_list", ")", "\n", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "is_impossible", "=", "False", "\n", "\n", "if", "self", ".", "_is_training", ":", "\n", "\n", "            ", "if", "entry", "[", "'answer'", "]", "[", "'text'", "]", "in", "[", "'CANNOTANSWER'", ",", "'NOTRECOVERED'", "]", ":", "\n", "                ", "is_impossible", "=", "True", "\n", "\n", "", "if", "not", "is_impossible", ":", "\n", "                ", "answer", "=", "entry", "[", "'answer'", "]", "\n", "orig_answer_text", "=", "answer", "[", "\"text\"", "]", "\n", "answer_offset", "=", "answer", "[", "\"answer_start\"", "]", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "answer_length", "-", "1", "]", "\n", "# Only add answers where the text can be exactly recovered from the", "\n", "# document. If this CAN'T happen it's likely due to weird Unicode", "\n", "# stuff so we will just skip the example.", "\n", "#", "\n", "# Note that this means for training mode, every example is NOT", "\n", "# guaranteed to be preserved.", "\n", "actual_text", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "cleaned_answer_text", "=", "\" \"", ".", "join", "(", "\n", "whitespace_tokenize", "(", "orig_answer_text", ")", ")", "\n", "if", "actual_text", ".", "find", "(", "cleaned_answer_text", ")", "==", "-", "1", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Could not find answer: '%s' vs. '%s'\"", ",", "\n", "actual_text", ",", "cleaned_answer_text", ")", "\n", "", "", "else", ":", "\n", "                ", "start_position", "=", "-", "1", "\n", "end_position", "=", "-", "1", "\n", "orig_answer_text", "=", "\"\"", "\n", "\n", "", "", "example", "=", "QuacExample", "(", "\n", "example_id", "=", "example_id", ",", "\n", "qas_id", "=", "qas_id", ",", "\n", "question_text", "=", "question_text", ",", "\n", "doc_tokens", "=", "doc_tokens", ",", "\n", "orig_answer_text", "=", "orig_answer_text", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "is_impossible", ",", "\n", "followup", "=", "entry", "[", "'followup'", "]", ",", "\n", "yesno", "=", "entry", "[", "'yesno'", "]", ",", "\n", "retrieval_label", "=", "int", "(", "entry", "[", "'retrieval_label'", "]", ")", ",", "\n", "history", "=", "history", ")", "\n", "\n", "feature", "=", "convert_example_to_feature", "(", "example", ",", "self", ".", "_tokenizer", ",", "is_training", "=", "self", ".", "_is_training", ")", "\n", "\n", "# when evaluating, we save all examples and features", "\n", "# so that we can recover answer texts", "\n", "if", "not", "self", ".", "_is_training", ":", "\n", "            ", "self", ".", "all_examples", "[", "example_id", "]", "=", "example", "\n", "self", ".", "all_features", "[", "example_id", "]", "=", "feature", "\n", "\n", "\n", "", "if", "self", ".", "_is_training", ":", "\n", "            ", "return", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index, ", "\n", "# 'p_mask': feature.p_mask, ", "\n", "'start_position'", ":", "feature", ".", "start_position", ",", "\n", "'end_position'", ":", "feature", ".", "end_position", ",", "\n", "'retrieval_label'", ":", "feature", ".", "retrieval_label", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index, ", "\n", "# 'p_mask': feature.p_mask, ", "\n", "'example_id'", ":", "feature", ".", "example_id", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.LazyQuacDataset.__len__": [[276, 278], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_total_data", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.LazyQuacDatasetGlobal.__getitem__": [[284, 420], ["linecache.getline", "json.loads", "question_text_list.append", "enumerate", "batch[].keys", "linecache.getline.strip", "zip", "utils.QuacExample", "utils.convert_example_to_feature", "batch.append", "utils.is_whitespace", "char_to_word_offset.append", "numpy.vstack", "question_text_list.append", "question_text_list.append", "len", "numpy.asarray", "numpy.asarray", "numpy.asarray", "doc_tokens.append", "len", "transformers.tokenization_bert.whitespace_tokenize", "actual_text.find", "logger.warning", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.convert_example_to_feature", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.is_whitespace"], ["    ", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"read a line of preprocessed open-retrieval quac file into a quac example\"\"\"", "\n", "line", "=", "linecache", ".", "getline", "(", "self", ".", "_filename", ",", "idx", "+", "1", ")", "\n", "entry", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "qas_id", "=", "entry", "[", "\"qid\"", "]", "\n", "orig_question_text", "=", "entry", "[", "\"question\"", "]", "\n", "retrieval_labels", "=", "entry", "[", "'retrieval_labels'", "]", "\n", "history", "=", "entry", "[", "'history'", "]", "\n", "question_text_list", "=", "[", "]", "\n", "if", "self", ".", "_history_num", ">", "0", ":", "\n", "            ", "for", "turn", "in", "history", "[", "-", "self", ".", "_history_num", ":", "]", ":", "\n", "                ", "if", "self", ".", "_prepend_history_questions", ":", "\n", "                    ", "question_text_list", ".", "append", "(", "turn", "[", "'question'", "]", ")", "\n", "", "if", "self", ".", "_prepend_history_answers", ":", "\n", "                    ", "question_text_list", ".", "append", "(", "turn", "[", "'answer'", "]", "[", "'text'", "]", ")", "\n", "", "", "", "question_text_list", ".", "append", "(", "orig_question_text", ")", "\n", "question_text", "=", "' [SEP] '", ".", "join", "(", "question_text_list", ")", "\n", "\n", "batch", "=", "[", "]", "\n", "paragraph_texts", "=", "entry", "[", "'evidences'", "]", "\n", "for", "i", ",", "(", "paragraph_text", ",", "retrieval_label", ")", "in", "enumerate", "(", "zip", "(", "paragraph_texts", ",", "retrieval_labels", ")", ")", ":", "\n", "            ", "example_id", "=", "'{}_{}'", ".", "format", "(", "qas_id", ",", "i", ")", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "                ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                    ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                    ", "if", "prev_is_whitespace", ":", "\n", "                        ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                        ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "is_impossible", "=", "False", "\n", "\n", "\n", "if", "self", ".", "_is_training", ":", "\n", "                ", "if", "entry", "[", "'answer'", "]", "[", "'text'", "]", "in", "[", "'CANNOTANSWER'", ",", "'NOTRECOVERED'", "]", "or", "retrieval_label", "==", "0", ":", "\n", "                    ", "is_impossible", "=", "True", "\n", "\n", "", "if", "not", "is_impossible", ":", "\n", "                    ", "answer", "=", "entry", "[", "'answer'", "]", "\n", "orig_answer_text", "=", "answer", "[", "\"text\"", "]", "\n", "answer_offset", "=", "answer", "[", "\"answer_start\"", "]", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "answer_length", "-", "1", "]", "\n", "# Only add answers where the text can be exactly recovered from the", "\n", "# document. If this CAN'T happen it's likely due to weird Unicode", "\n", "# stuff so we will just skip the example.", "\n", "#", "\n", "# Note that this means for training mode, every example is NOT", "\n", "# guaranteed to be preserved.", "\n", "actual_text", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "cleaned_answer_text", "=", "\" \"", ".", "join", "(", "\n", "whitespace_tokenize", "(", "orig_answer_text", ")", ")", "\n", "if", "actual_text", ".", "find", "(", "cleaned_answer_text", ")", "==", "-", "1", ":", "\n", "                        ", "logger", ".", "warning", "(", "\"Could not find answer: '%s' vs. '%s'\"", ",", "\n", "actual_text", ",", "cleaned_answer_text", ")", "\n", "", "", "else", ":", "\n", "                    ", "start_position", "=", "-", "1", "\n", "end_position", "=", "-", "1", "\n", "orig_answer_text", "=", "\"\"", "\n", "\n", "", "", "example", "=", "QuacExample", "(", "\n", "example_id", "=", "example_id", ",", "\n", "qas_id", "=", "qas_id", ",", "\n", "question_text", "=", "question_text", ",", "\n", "doc_tokens", "=", "doc_tokens", ",", "\n", "orig_answer_text", "=", "orig_answer_text", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "is_impossible", ",", "\n", "followup", "=", "entry", "[", "'followup'", "]", ",", "\n", "yesno", "=", "entry", "[", "'yesno'", "]", ",", "\n", "retrieval_label", "=", "retrieval_label", ",", "\n", "history", "=", "history", ")", "\n", "\n", "feature", "=", "convert_example_to_feature", "(", "example", ",", "self", ".", "_tokenizer", ",", "is_training", "=", "self", ".", "_is_training", ")", "\n", "\n", "# when evaluating, we save all examples and features", "\n", "# so that we can recover answer texts", "\n", "if", "not", "self", ".", "_is_training", ":", "\n", "                ", "self", ".", "all_examples", "[", "example_id", "]", "=", "example", "\n", "self", ".", "all_features", "[", "example_id", "]", "=", "feature", "\n", "\n", "\n", "", "if", "self", ".", "_is_training", ":", "\n", "                ", "if", "retrieval_label", ":", "\n", "                    ", "batch_feature", "=", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index, ", "\n", "# 'p_mask': feature.p_mask, ", "\n", "# the true passge might be at any position", "\n", "'start_position'", ":", "feature", ".", "start_position", "+", "i", "*", "self", ".", "_max_seq_length", ",", "\n", "'end_position'", ":", "feature", ".", "end_position", "+", "i", "*", "self", ".", "_max_seq_length", ",", "\n", "'retrieval_label'", ":", "feature", ".", "retrieval_label", "}", "\n", "\n", "\n", "", "else", ":", "\n", "                    ", "batch_feature", "=", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index, ", "\n", "# 'p_mask': feature.p_mask, ", "\n", "'start_position'", ":", "-", "1", ",", "\n", "'end_position'", ":", "-", "1", ",", "\n", "'retrieval_label'", ":", "feature", ".", "retrieval_label", "}", "\n", "", "", "else", ":", "\n", "                ", "batch_feature", "=", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index, ", "\n", "# 'p_mask': feature.p_mask, ", "\n", "'example_id'", ":", "feature", ".", "example_id", "}", "\n", "\n", "", "batch", ".", "append", "(", "batch_feature", ")", "\n", "\n", "", "collated", "=", "{", "}", "\n", "\n", "keys", "=", "batch", "[", "0", "]", ".", "keys", "(", ")", "\n", "for", "key", "in", "keys", ":", "\n", "            ", "if", "key", "!=", "'example_id'", ":", "\n", "                ", "collated", "[", "key", "]", "=", "np", ".", "vstack", "(", "[", "dic", "[", "key", "]", "for", "dic", "in", "batch", "]", ")", "\n", "", "", "if", "'example_id'", "in", "keys", ":", "\n", "            ", "collated", "[", "'example_id'", "]", "=", "[", "dic", "[", "'example_id'", "]", "for", "dic", "in", "batch", "]", "\n", "# print(collated)", "\n", "# print(collated['input_ids'].shape)", "\n", "", "return", "collated", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__init__": [[422, 440], ["io.open", "len", "f.readlines"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "max_seq_length", ",", "tokenizer", ",", "\n", "load_small", ",", "is_training", "=", "True", ")", ":", "\n", "\n", "        ", "self", ".", "_filename", "=", "filename", "\n", "self", ".", "_max_seq_length", "=", "max_seq_length", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "\n", "self", ".", "_load_small", "=", "load_small", "\n", "self", ".", "_is_training", "=", "is_training", "\n", "\n", "self", ".", "all_examples", "=", "{", "}", "\n", "self", ".", "all_features", "=", "{", "}", "\n", "\n", "self", ".", "_total_data", "=", "0", "\n", "if", "self", ".", "_load_small", ":", "\n", "            ", "self", ".", "_total_data", "=", "100", "\n", "", "else", ":", "\n", "            ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "self", ".", "_total_data", "=", "len", "(", "f", ".", "readlines", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__getitem__": [[441, 531], ["linecache.getline", "json.loads", "utils.QuacExample", "utils.convert_example_to_feature", "linecache.getline.strip", "utils.is_whitespace", "char_to_word_offset.append", "len", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "doc_tokens.append", "len", "transformers.tokenization_bert.whitespace_tokenize", "actual_text.find", "logger.warning"], "methods", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.convert_example_to_feature", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.is_whitespace"], ["", "", "", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "\"\"\"read a line of preprocessed open-retrieval quac file into a quac example\"\"\"", "\n", "\n", "line", "=", "linecache", ".", "getline", "(", "self", ".", "_filename", ",", "idx", "+", "1", ")", "\n", "entry", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "qid", "=", "entry", "[", "\"qid\"", "]", "\n", "has_answer", "=", "entry", "[", "'has_answer'", "]", "\n", "example_id", "=", "'{}*{}'", ".", "format", "(", "qid", ",", "has_answer", ")", "\n", "\n", "paragraph_text", "=", "entry", "[", "'passage'", "]", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "            ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "prev_is_whitespace", ":", "\n", "                    ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                    ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "# the \"question\" in this MC-style model is actually the paraphrase of the known answer", "\n", "", "question_text", "=", "entry", "[", "\"paraphrase\"", "]", "\n", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "is_impossible", "=", "False", "\n", "\n", "if", "self", ".", "_is_training", ":", "\n", "\n", "            ", "if", "has_answer", "==", "0", ":", "\n", "                ", "is_impossible", "=", "True", "\n", "\n", "", "if", "not", "is_impossible", ":", "\n", "                ", "orig_answer_text", "=", "entry", "[", "\"answer_text\"", "]", "\n", "answer_offset", "=", "entry", "[", "\"answer_start\"", "]", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "answer_length", "-", "1", "]", "\n", "# Only add answers where the text can be exactly recovered from the", "\n", "# document. If this CAN'T happen it's likely due to weird Unicode", "\n", "# stuff so we will just skip the example.", "\n", "#", "\n", "# Note that this means for training mode, every example is NOT", "\n", "# guaranteed to be preserved.", "\n", "actual_text", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "cleaned_answer_text", "=", "\" \"", ".", "join", "(", "\n", "whitespace_tokenize", "(", "orig_answer_text", ")", ")", "\n", "if", "actual_text", ".", "find", "(", "cleaned_answer_text", ")", "==", "-", "1", ":", "\n", "                    ", "logger", ".", "warning", "(", "\"Could not find answer: '%s' vs. '%s'\"", ",", "\n", "actual_text", ",", "cleaned_answer_text", ")", "\n", "", "", "else", ":", "\n", "                ", "start_position", "=", "-", "1", "\n", "end_position", "=", "-", "1", "\n", "orig_answer_text", "=", "\"\"", "\n", "\n", "", "", "example", "=", "QuacExample", "(", "\n", "example_id", "=", "example_id", ",", "\n", "qas_id", "=", "example_id", ",", "# qas_id is the same with example id to keep it unique", "\n", "question_text", "=", "question_text", ",", "\n", "doc_tokens", "=", "doc_tokens", ",", "\n", "orig_answer_text", "=", "orig_answer_text", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "is_impossible", ")", "\n", "\n", "feature", "=", "convert_example_to_feature", "(", "example", ",", "self", ".", "_tokenizer", ",", "is_training", "=", "self", ".", "_is_training", ")", "\n", "\n", "# when evaluating, we save all examples and features", "\n", "# so that we can recover answer texts", "\n", "if", "not", "self", ".", "_is_training", ":", "\n", "            ", "self", ".", "all_examples", "[", "example_id", "]", "=", "example", "\n", "self", ".", "all_features", "[", "example_id", "]", "=", "feature", "\n", "\n", "\n", "", "if", "self", ".", "_is_training", ":", "\n", "            ", "return", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "'start_position'", ":", "feature", ".", "start_position", ",", "\n", "'end_position'", ":", "feature", ".", "end_position", "}", "\n", "", "else", ":", "\n", "            ", "return", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "'example_id'", ":", "feature", ".", "example_id", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.WeakSupervisorDataset.__len__": [[533, 535], ["None"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_total_data", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.is_whitespace": [[538, 543], ["ord", "ord"], "function", ["None"], ["", "", "def", "is_whitespace", "(", "c", ")", ":", "\n", "    ", "if", "c", "==", "\" \"", "or", "c", "==", "\"\\t\"", "or", "c", "==", "\"\\r\"", "or", "c", "==", "\"\\n\"", "or", "ord", "(", "c", ")", "==", "0x202F", "or", "ord", "(", "c", ")", "==", "160", ":", "\n", "# 160 is for the nonbreaking space in coqa", "\n", "        ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.convert_example_to_feature": [[545, 775], ["tokenizer.tokenize", "enumerate", "collections.namedtuple", "enumerate", "len", "orig_to_tok_index.append", "tokenizer.tokenize", "utils._improve_answer_span", "len", "doc_spans.append", "min", "len", "range", "tokens.append", "segment_ids.append", "p_mask.append", "tokenizer.convert_tokens_to_ids", "utils.InputFeatures", "len", "tok_to_orig_index.append", "all_doc_tokens.append", "len", "len", "collections.namedtuple.", "len", "tokens.append", "segment_ids.append", "p_mask.append", "tokens.append", "segment_ids.append", "p_mask.append", "utils._check_is_max_context", "tokens.append", "p_mask.append", "tokens.append", "segment_ids.append", "p_mask.append", "tokens.append", "segment_ids.append", "p_mask.append", "len", "len", "tokenizer.convert_tokens_to_ids.append", "input_mask.append", "segment_ids.append", "p_mask.append", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "len", "len", "segment_ids.append", "segment_ids.append", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "len", "len", "len", "str", "str", "str", "token_to_orig_map.items", "token_is_max_context.items"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._improve_answer_span", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._check_is_max_context"], ["", "def", "convert_example_to_feature", "(", "example", ",", "tokenizer", ",", "max_seq_length", "=", "512", ",", "\n", "doc_stride", "=", "384", ",", "max_query_length", "=", "125", ",", "is_training", "=", "True", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "'[CLS]'", ",", "sep_token", "=", "'[SEP]'", ",", "pad_token", "=", "0", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "sequence_b_segment_id", "=", "1", ",", "\n", "cls_token_segment_id", "=", "0", ",", "pad_token_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ",", "\n", "sequence_a_is_doc", "=", "False", ")", ":", "\n", "    ", "\"\"\"Convert a single QuacExample to features (model input)\"\"\"", "\n", "\n", "query_tokens", "=", "tokenizer", ".", "tokenize", "(", "example", ".", "question_text", ")", "\n", "\n", "if", "len", "(", "query_tokens", ")", ">", "max_query_length", ":", "\n", "        ", "query_tokens", "=", "query_tokens", "[", "-", "max_query_length", ":", "]", "\n", "\n", "", "tok_to_orig_index", "=", "[", "]", "\n", "orig_to_tok_index", "=", "[", "]", "\n", "all_doc_tokens", "=", "[", "]", "\n", "for", "(", "i", ",", "token", ")", "in", "enumerate", "(", "example", ".", "doc_tokens", ")", ":", "\n", "        ", "orig_to_tok_index", ".", "append", "(", "len", "(", "all_doc_tokens", ")", ")", "\n", "sub_tokens", "=", "tokenizer", ".", "tokenize", "(", "token", ")", "\n", "for", "sub_token", "in", "sub_tokens", ":", "\n", "            ", "tok_to_orig_index", ".", "append", "(", "i", ")", "\n", "all_doc_tokens", ".", "append", "(", "sub_token", ")", "\n", "\n", "", "", "tok_start_position", "=", "None", "\n", "tok_end_position", "=", "None", "\n", "if", "is_training", "and", "example", ".", "is_impossible", ":", "\n", "        ", "tok_start_position", "=", "-", "1", "\n", "tok_end_position", "=", "-", "1", "\n", "", "if", "is_training", "and", "not", "example", ".", "is_impossible", ":", "\n", "        ", "tok_start_position", "=", "orig_to_tok_index", "[", "example", ".", "start_position", "]", "\n", "if", "example", ".", "end_position", "<", "len", "(", "example", ".", "doc_tokens", ")", "-", "1", ":", "\n", "            ", "tok_end_position", "=", "orig_to_tok_index", "[", "example", ".", "end_position", "+", "1", "]", "-", "1", "\n", "", "else", ":", "\n", "            ", "tok_end_position", "=", "len", "(", "all_doc_tokens", ")", "-", "1", "\n", "", "(", "tok_start_position", ",", "tok_end_position", ")", "=", "_improve_answer_span", "(", "\n", "all_doc_tokens", ",", "tok_start_position", ",", "tok_end_position", ",", "tokenizer", ",", "\n", "example", ".", "orig_answer_text", ")", "\n", "\n", "# The -3 accounts for [CLS], [SEP] and [SEP]", "\n", "", "max_tokens_for_doc", "=", "max_seq_length", "-", "len", "(", "query_tokens", ")", "-", "3", "\n", "assert", "max_tokens_for_doc", ">=", "384", ",", "max_tokens_for_doc", "\n", "\n", "# We can have documents that are longer than the maximum sequence length.", "\n", "# To deal with this we do a sliding window approach, where we take chunks", "\n", "# of the up to our max length with a stride of `doc_stride`.", "\n", "\n", "# we set the doc_stride to 384, which is the max length of evidence text,", "\n", "# meaning that each evidence has exactly one _DocSpan", "\n", "_DocSpan", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"DocSpan\"", ",", "[", "\"start\"", ",", "\"length\"", "]", ")", "\n", "doc_spans", "=", "[", "]", "\n", "start_offset", "=", "0", "\n", "while", "start_offset", "<", "len", "(", "all_doc_tokens", ")", ":", "\n", "        ", "length", "=", "len", "(", "all_doc_tokens", ")", "-", "start_offset", "\n", "if", "length", ">", "max_tokens_for_doc", ":", "\n", "            ", "length", "=", "max_tokens_for_doc", "\n", "", "doc_spans", ".", "append", "(", "_DocSpan", "(", "start", "=", "start_offset", ",", "length", "=", "length", ")", ")", "\n", "if", "start_offset", "+", "length", "==", "len", "(", "all_doc_tokens", ")", ":", "\n", "            ", "break", "\n", "", "start_offset", "+=", "min", "(", "length", ",", "doc_stride", ")", "\n", "\n", "# comment the assertion for weak supervisor pretraining of coqa", "\n", "# assert len(doc_spans) == 1, (max_tokens_for_doc, example)", "\n", "# for reader, len(doc_span) will natually be one, but for coqa weak supervisor pretraining, it could be > 1", "\n", "# but we only keep the first doc_span for simplicity", "\n", "", "if", "len", "(", "doc_spans", ")", ">", "1", ":", "\n", "# print(len(doc_spans), example)", "\n", "        ", "doc_spans", "=", "[", "doc_spans", "[", "0", "]", "]", "\n", "\n", "", "for", "(", "doc_span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "        ", "tokens", "=", "[", "]", "\n", "token_to_orig_map", "=", "{", "}", "\n", "token_is_max_context", "=", "{", "}", "\n", "segment_ids", "=", "[", "]", "\n", "\n", "# p_mask: mask with 1 for token than cannot be in the answer (0 for token which can be in an answer)", "\n", "# Original TF implem also keep the classification token (set to 0) (not sure why...)", "\n", "p_mask", "=", "[", "]", "\n", "\n", "# CLS token at the beginning", "\n", "if", "not", "cls_token_at_end", ":", "\n", "            ", "tokens", ".", "append", "(", "cls_token", ")", "\n", "segment_ids", ".", "append", "(", "cls_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "cls_index", "=", "0", "\n", "\n", "# XLNet: P SEP Q SEP CLS", "\n", "# Others: CLS Q SEP P SEP", "\n", "", "if", "not", "sequence_a_is_doc", ":", "\n", "# Query", "\n", "            ", "tokens", "+=", "query_tokens", "\n", "segment_ids", "+=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "query_tokens", ")", "\n", "p_mask", "+=", "[", "1", "]", "*", "len", "(", "query_tokens", ")", "\n", "\n", "# SEP token", "\n", "tokens", ".", "append", "(", "sep_token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_a_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# Paragraph", "\n", "", "for", "i", "in", "range", "(", "doc_span", ".", "length", ")", ":", "\n", "            ", "split_token_index", "=", "doc_span", ".", "start", "+", "i", "\n", "token_to_orig_map", "[", "len", "(", "tokens", ")", "]", "=", "tok_to_orig_index", "[", "split_token_index", "]", "\n", "\n", "is_max_context", "=", "_check_is_max_context", "(", "doc_spans", ",", "doc_span_index", ",", "\n", "split_token_index", ")", "\n", "token_is_max_context", "[", "len", "(", "tokens", ")", "]", "=", "is_max_context", "\n", "tokens", ".", "append", "(", "all_doc_tokens", "[", "split_token_index", "]", ")", "\n", "if", "not", "sequence_a_is_doc", ":", "\n", "                ", "segment_ids", ".", "append", "(", "sequence_b_segment_id", ")", "\n", "", "else", ":", "\n", "                ", "segment_ids", ".", "append", "(", "sequence_a_segment_id", ")", "\n", "", "p_mask", ".", "append", "(", "0", ")", "\n", "", "paragraph_len", "=", "doc_span", ".", "length", "\n", "\n", "if", "sequence_a_is_doc", ":", "\n", "# SEP token", "\n", "            ", "tokens", ".", "append", "(", "sep_token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_a_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "tokens", "+=", "query_tokens", "\n", "segment_ids", "+=", "[", "sequence_b_segment_id", "]", "*", "len", "(", "query_tokens", ")", "\n", "p_mask", "+=", "[", "1", "]", "*", "len", "(", "query_tokens", ")", "\n", "\n", "# SEP token", "\n", "", "tokens", ".", "append", "(", "sep_token", ")", "\n", "segment_ids", ".", "append", "(", "sequence_b_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "# CLS token at the end", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", ".", "append", "(", "cls_token", ")", "\n", "segment_ids", ".", "append", "(", "cls_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "0", ")", "\n", "cls_index", "=", "len", "(", "tokens", ")", "-", "1", "# Index of classification token", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "while", "len", "(", "input_ids", ")", "<", "max_seq_length", ":", "\n", "            ", "input_ids", ".", "append", "(", "pad_token", ")", "\n", "input_mask", ".", "append", "(", "0", "if", "mask_padding_with_zero", "else", "1", ")", "\n", "segment_ids", ".", "append", "(", "pad_token_segment_id", ")", "\n", "p_mask", ".", "append", "(", "1", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "\n", "span_is_impossible", "=", "example", ".", "is_impossible", "\n", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "if", "is_training", "and", "not", "span_is_impossible", ":", "\n", "# For training, if our document chunk does not contain an annotation", "\n", "# we throw it out, since there is nothing to predict.", "\n", "            ", "doc_start", "=", "doc_span", ".", "start", "\n", "doc_end", "=", "doc_span", ".", "start", "+", "doc_span", ".", "length", "-", "1", "\n", "out_of_span", "=", "False", "\n", "if", "not", "(", "tok_start_position", ">=", "doc_start", "and", "\n", "tok_end_position", "<=", "doc_end", ")", ":", "\n", "                ", "out_of_span", "=", "True", "\n", "", "if", "out_of_span", ":", "\n", "                ", "start_position", "=", "0", "\n", "end_position", "=", "0", "\n", "span_is_impossible", "=", "True", "\n", "", "else", ":", "\n", "                ", "if", "sequence_a_is_doc", ":", "\n", "                    ", "doc_offset", "=", "0", "\n", "", "else", ":", "\n", "                    ", "doc_offset", "=", "len", "(", "query_tokens", ")", "+", "2", "\n", "", "start_position", "=", "tok_start_position", "-", "doc_start", "+", "doc_offset", "\n", "end_position", "=", "tok_end_position", "-", "doc_start", "+", "doc_offset", "\n", "\n", "", "", "if", "is_training", "and", "span_is_impossible", ":", "\n", "            ", "start_position", "=", "cls_index", "\n", "end_position", "=", "cls_index", "\n", "\n", "", "if", "False", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"unique_id: %s\"", "%", "(", "example", ".", "example_id", ")", ")", "\n", "logger", ".", "info", "(", "\"example_id: %s\"", "%", "(", "example", ".", "example_id", ")", ")", "\n", "logger", ".", "info", "(", "\"qid of the example: %s\"", "%", "(", "example", ".", "qas_id", ")", ")", "\n", "logger", ".", "info", "(", "\"doc_span_index: %s\"", "%", "(", "doc_span_index", ")", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", "%", "\" \"", ".", "join", "(", "tokens", ")", ")", "\n", "logger", ".", "info", "(", "\"token_to_orig_map: %s\"", "%", "\" \"", ".", "join", "(", "[", "\n", "\"%d:%d\"", "%", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "token_to_orig_map", ".", "items", "(", ")", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"token_is_max_context: %s\"", "%", "\" \"", ".", "join", "(", "[", "\n", "\"%d:%s\"", "%", "(", "x", ",", "y", ")", "for", "(", "x", ",", "y", ")", "in", "token_is_max_context", ".", "items", "(", ")", "\n", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"input_mask: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"segment_ids: %s\"", "%", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "if", "is_training", "and", "span_is_impossible", ":", "\n", "                ", "logger", ".", "info", "(", "\"impossible example\"", ")", "\n", "", "if", "is_training", "and", "not", "span_is_impossible", ":", "\n", "                ", "answer_text", "=", "\" \"", ".", "join", "(", "tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "logger", ".", "info", "(", "\"start_position: %d\"", "%", "(", "start_position", ")", ")", "\n", "logger", ".", "info", "(", "\"end_position: %d\"", "%", "(", "end_position", ")", ")", "\n", "logger", ".", "info", "(", "\"retrieval_label: %d\"", "%", "(", "example", ".", "retrieval_label", ")", ")", "\n", "logger", ".", "info", "(", "\n", "\"answer: %s\"", "%", "(", "answer_text", ")", ")", "\n", "\n", "", "", "feature", "=", "InputFeatures", "(", "\n", "unique_id", "=", "example", ".", "example_id", ",", "\n", "example_id", "=", "example", ".", "example_id", ",", "\n", "doc_span_index", "=", "doc_span_index", ",", "\n", "tokens", "=", "tokens", ",", "\n", "token_to_orig_map", "=", "token_to_orig_map", ",", "\n", "token_is_max_context", "=", "token_is_max_context", ",", "\n", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "cls_index", "=", "cls_index", ",", "\n", "p_mask", "=", "p_mask", ",", "\n", "paragraph_len", "=", "paragraph_len", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "span_is_impossible", ",", "\n", "retrieval_label", "=", "example", ".", "retrieval_label", ")", "\n", "\n", "", "return", "feature", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.gen_reader_features": [[777, 917], ["zip", "batch_features[].keys", "enumerate", "per_query_features[].keys", "batch_features.append", "zip", "utils.QuacExample", "utils.convert_example_to_feature", "per_query_features.append", "numpy.stack", "torch.from_numpy", "batch[].extend", "utils.is_whitespace", "char_to_word_offset.append", "numpy.vstack", "len", "numpy.asarray", "numpy.asarray", "numpy.asarray", "doc_tokens.append", "len", "transformers.tokenization_bert.whitespace_tokenize", "actual_text.find", "logger.warning", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.convert_example_to_feature", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.is_whitespace"], ["", "def", "gen_reader_features", "(", "qids", ",", "question_texts", ",", "answer_texts", ",", "answer_starts", ",", "passage_ids", ",", "\n", "passages", ",", "all_retrieval_labels", ",", "reader_tokenizer", ",", "max_seq_length", ",", "is_training", "=", "False", ")", ":", "\n", "# print('all_retrieval_labels', all_retrieval_labels, type(all_retrieval_labels))", "\n", "    ", "batch_features", "=", "[", "]", "\n", "all_examples", ",", "all_features", "=", "{", "}", ",", "{", "}", "\n", "for", "(", "qas_id", ",", "question_text", ",", "answer_text", ",", "answer_start", ",", "pids_per_query", ",", "\n", "paragraph_texts", ",", "retrieval_labels", ")", "in", "zip", "(", "qids", ",", "question_texts", ",", "answer_texts", ",", "answer_starts", ",", "\n", "passage_ids", ",", "passages", ",", "all_retrieval_labels", ")", ":", "\n", "# print('retrieval_labels', retrieval_labels)", "\n", "        ", "per_query_features", "=", "[", "]", "\n", "for", "i", ",", "(", "pid", ",", "paragraph_text", ",", "retrieval_label", ")", "in", "enumerate", "(", "zip", "(", "pids_per_query", ",", "paragraph_texts", ",", "retrieval_labels", ")", ")", ":", "\n", "# print('retrieval_label', retrieval_label)", "\n", "            ", "example_id", "=", "f'{qas_id}*{pid}'", "\n", "doc_tokens", "=", "[", "]", "\n", "char_to_word_offset", "=", "[", "]", "\n", "prev_is_whitespace", "=", "True", "\n", "for", "c", "in", "paragraph_text", ":", "\n", "                ", "if", "is_whitespace", "(", "c", ")", ":", "\n", "                    ", "prev_is_whitespace", "=", "True", "\n", "", "else", ":", "\n", "                    ", "if", "prev_is_whitespace", ":", "\n", "                        ", "doc_tokens", ".", "append", "(", "c", ")", "\n", "", "else", ":", "\n", "                        ", "doc_tokens", "[", "-", "1", "]", "+=", "c", "\n", "", "prev_is_whitespace", "=", "False", "\n", "", "char_to_word_offset", ".", "append", "(", "len", "(", "doc_tokens", ")", "-", "1", ")", "\n", "\n", "", "start_position", "=", "None", "\n", "end_position", "=", "None", "\n", "orig_answer_text", "=", "None", "\n", "is_impossible", "=", "False", "\n", "\n", "if", "is_training", ":", "\n", "                ", "if", "answer_text", "in", "[", "'CANNOTANSWER'", ",", "'NOTRECOVERED'", "]", "or", "retrieval_label", "==", "0", ":", "\n", "                    ", "is_impossible", "=", "True", "\n", "\n", "", "if", "not", "is_impossible", ":", "\n", "                    ", "orig_answer_text", "=", "answer_text", "\n", "answer_offset", "=", "answer_start", "\n", "answer_length", "=", "len", "(", "orig_answer_text", ")", "\n", "start_position", "=", "char_to_word_offset", "[", "answer_offset", "]", "\n", "end_position", "=", "char_to_word_offset", "[", "answer_offset", "+", "\n", "answer_length", "-", "1", "]", "\n", "# Only add answers where the text can be exactly recovered from the", "\n", "# document. If this CAN'T happen it's likely due to weird Unicode", "\n", "# stuff so we will just skip the example.", "\n", "#", "\n", "# Note that this means for training mode, every example is NOT", "\n", "# guaranteed to be preserved.", "\n", "actual_text", "=", "\" \"", ".", "join", "(", "\n", "doc_tokens", "[", "start_position", ":", "(", "end_position", "+", "1", ")", "]", ")", "\n", "cleaned_answer_text", "=", "\" \"", ".", "join", "(", "\n", "whitespace_tokenize", "(", "orig_answer_text", ")", ")", "\n", "if", "actual_text", ".", "find", "(", "cleaned_answer_text", ")", "==", "-", "1", ":", "\n", "                        ", "logger", ".", "warning", "(", "\"Could not find answer: '%s' vs. '%s'\"", ",", "\n", "actual_text", ",", "cleaned_answer_text", ")", "\n", "", "", "else", ":", "\n", "                    ", "start_position", "=", "-", "1", "\n", "end_position", "=", "-", "1", "\n", "orig_answer_text", "=", "\"\"", "\n", "\n", "", "", "example", "=", "QuacExample", "(", "\n", "example_id", "=", "example_id", ",", "\n", "qas_id", "=", "qas_id", ",", "\n", "question_text", "=", "question_text", ",", "\n", "doc_tokens", "=", "doc_tokens", ",", "\n", "orig_answer_text", "=", "orig_answer_text", ",", "\n", "start_position", "=", "start_position", ",", "\n", "end_position", "=", "end_position", ",", "\n", "is_impossible", "=", "is_impossible", ",", "\n", "retrieval_label", "=", "retrieval_label", ")", "\n", "\n", "feature", "=", "convert_example_to_feature", "(", "\n", "example", ",", "reader_tokenizer", ",", "is_training", "=", "is_training", ")", "\n", "\n", "# when evaluating, we save all examples and features", "\n", "# so that we can recover answer texts", "\n", "if", "not", "is_training", ":", "\n", "                ", "all_examples", "[", "example_id", "]", "=", "example", "\n", "all_features", "[", "example_id", "]", "=", "feature", "\n", "\n", "", "if", "is_training", ":", "\n", "                ", "if", "retrieval_label", ":", "\n", "                    ", "per_query_feature", "=", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index,", "\n", "# 'p_mask': feature.p_mask,", "\n", "# the true passge might be at any position", "\n", "'start_position'", ":", "feature", ".", "start_position", "+", "i", "*", "max_seq_length", ",", "\n", "'end_position'", ":", "feature", ".", "end_position", "+", "i", "*", "max_seq_length", ",", "\n", "'retrieval_label'", ":", "feature", ".", "retrieval_label", "}", "\n", "\n", "", "else", ":", "\n", "                    ", "per_query_feature", "=", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index,", "\n", "# 'p_mask': feature.p_mask,", "\n", "'start_position'", ":", "-", "1", ",", "\n", "'end_position'", ":", "-", "1", ",", "\n", "'retrieval_label'", ":", "feature", ".", "retrieval_label", "}", "\n", "", "", "else", ":", "\n", "                ", "per_query_feature", "=", "{", "'input_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "input_ids", ")", ",", "\n", "'segment_ids'", ":", "np", ".", "asarray", "(", "feature", ".", "segment_ids", ")", ",", "\n", "'input_mask'", ":", "np", ".", "asarray", "(", "feature", ".", "input_mask", ")", ",", "\n", "# 'cls_index': feature.cls_index,", "\n", "# 'p_mask': feature.p_mask,", "\n", "'example_id'", ":", "feature", ".", "example_id", "}", "\n", "\n", "", "per_query_features", ".", "append", "(", "per_query_feature", ")", "\n", "\n", "", "collated", "=", "{", "}", "\n", "\n", "keys", "=", "per_query_features", "[", "0", "]", ".", "keys", "(", ")", "\n", "for", "key", "in", "keys", ":", "\n", "            ", "if", "key", "!=", "'example_id'", ":", "\n", "                ", "collated", "[", "key", "]", "=", "np", ".", "vstack", "(", "[", "dic", "[", "key", "]", "for", "dic", "in", "per_query_features", "]", ")", "\n", "", "", "if", "'example_id'", "in", "keys", ":", "\n", "            ", "collated", "[", "'example_id'", "]", "=", "[", "dic", "[", "'example_id'", "]", "for", "dic", "in", "per_query_features", "]", "\n", "# print('collated', collated)", "\n", "# print(collated['input_ids'].shape)", "\n", "", "batch_features", ".", "append", "(", "collated", ")", "\n", "\n", "# print('batch_features', batch_features)", "\n", "", "batch", "=", "{", "}", "\n", "keys", "=", "batch_features", "[", "0", "]", ".", "keys", "(", ")", "\n", "for", "key", "in", "keys", ":", "\n", "        ", "if", "key", "!=", "'example_id'", ":", "\n", "            ", "batch", "[", "key", "]", "=", "np", ".", "stack", "(", "[", "dic", "[", "key", "]", "for", "dic", "in", "batch_features", "]", ",", "axis", "=", "0", ")", "\n", "batch", "[", "key", "]", "=", "torch", ".", "from_numpy", "(", "batch", "[", "key", "]", ")", "\n", "", "", "if", "'example_id'", "in", "keys", ":", "\n", "        ", "batch", "[", "'example_id'", "]", "=", "[", "]", "\n", "for", "item", "in", "batch_features", ":", "\n", "            ", "batch", "[", "'example_id'", "]", ".", "extend", "(", "item", "[", "'example_id'", "]", ")", "\n", "# print('batch', batch)", "\n", "", "", "if", "is_training", ":", "\n", "        ", "return", "batch", "\n", "", "else", ":", "\n", "        ", "return", "batch", ",", "all_examples", ",", "all_features", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._improve_answer_span": [[919, 954], ["range", "tokenizer.tokenize", "range"], "function", ["None"], ["", "", "def", "_improve_answer_span", "(", "doc_tokens", ",", "input_start", ",", "input_end", ",", "tokenizer", ",", "\n", "orig_answer_text", ")", ":", "\n", "    ", "\"\"\"Returns tokenized answer spans that better match the annotated answer.\"\"\"", "\n", "\n", "# The SQuAD annotations are character based. We first project them to", "\n", "# whitespace-tokenized words. But then after WordPiece tokenization, we can", "\n", "# often find a \"better match\". For example:", "\n", "#", "\n", "#   Question: What year was John Smith born?", "\n", "#   Context: The leader was John Smith (1895-1943).", "\n", "#   Answer: 1895", "\n", "#", "\n", "# The original whitespace-tokenized answer will be \"(1895-1943).\". However", "\n", "# after tokenization, our tokens will be \"( 1895 - 1943 ) .\". So we can match", "\n", "# the exact answer, 1895.", "\n", "#", "\n", "# However, this is not always possible. Consider the following:", "\n", "#", "\n", "#   Question: What country is the top exporter of electornics?", "\n", "#   Context: The Japanese electronics industry is the lagest in the world.", "\n", "#   Answer: Japan", "\n", "#", "\n", "# In this case, the annotator chose \"Japan\" as a character sub-span of", "\n", "# the word \"Japanese\". Since our WordPiece tokenizer does not split", "\n", "# \"Japanese\", we just use \"Japanese\" as the annotation. This is fairly rare", "\n", "# in SQuAD, but does happen.", "\n", "tok_answer_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_answer_text", ")", ")", "\n", "\n", "for", "new_start", "in", "range", "(", "input_start", ",", "input_end", "+", "1", ")", ":", "\n", "        ", "for", "new_end", "in", "range", "(", "input_end", ",", "new_start", "-", "1", ",", "-", "1", ")", ":", "\n", "            ", "text_span", "=", "\" \"", ".", "join", "(", "doc_tokens", "[", "new_start", ":", "(", "new_end", "+", "1", ")", "]", ")", "\n", "if", "text_span", "==", "tok_answer_text", ":", "\n", "                ", "return", "(", "new_start", ",", "new_end", ")", "\n", "\n", "", "", "", "return", "(", "input_start", ",", "input_end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._check_is_max_context": [[956, 991], ["enumerate", "min"], "function", ["None"], ["", "def", "_check_is_max_context", "(", "doc_spans", ",", "cur_span_index", ",", "position", ")", ":", "\n", "    ", "\"\"\"Check if this is the 'max context' doc span for the token.\"\"\"", "\n", "\n", "# Because of the sliding window approach taken to scoring documents, a single", "\n", "# token can appear in multiple documents. E.g.", "\n", "#  Doc: the man went to the store and bought a gallon of milk", "\n", "#  Span A: the man went to the", "\n", "#  Span B: to the store and bought", "\n", "#  Span C: and bought a gallon of", "\n", "#  ...", "\n", "#", "\n", "# Now the word 'bought' will have two scores from spans B and C. We only", "\n", "# want to consider the score with \"maximum context\", which we define as", "\n", "# the *minimum* of its left and right context (the *sum* of left and", "\n", "# right context will always be the same, of course).", "\n", "#", "\n", "# In the example the maximum context for 'bought' would be span C since", "\n", "# it has 1 left context and 3 right context, while span B has 4 left context", "\n", "# and 0 right context.", "\n", "best_score", "=", "None", "\n", "best_span_index", "=", "None", "\n", "for", "(", "span_index", ",", "doc_span", ")", "in", "enumerate", "(", "doc_spans", ")", ":", "\n", "        ", "end", "=", "doc_span", ".", "start", "+", "doc_span", ".", "length", "-", "1", "\n", "if", "position", "<", "doc_span", ".", "start", ":", "\n", "            ", "continue", "\n", "", "if", "position", ">", "end", ":", "\n", "            ", "continue", "\n", "", "num_left_context", "=", "position", "-", "doc_span", ".", "start", "\n", "num_right_context", "=", "end", "-", "position", "\n", "score", "=", "min", "(", "num_left_context", ",", "num_right_context", ")", "+", "0.01", "*", "doc_span", ".", "length", "\n", "if", "best_score", "is", "None", "or", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_span_index", "=", "span_index", "\n", "\n", "", "", "return", "cur_span_index", "==", "best_span_index", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_predictions": [[997, 1241], ["collections.namedtuple", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "all_examples.items", "utils._get_best_indexes", "utils._get_best_indexes", "sorted", "collections.namedtuple", "utils._compute_softmax", "enumerate", "io.open", "writer.write", "io.open", "writer.write", "sorted.append", "nbest.append", "nbest.append", "len", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "enumerate", "len", "all_predictions[].append", "io.open", "writer.write", "sorted.append", "collections.namedtuple.", "len", "tok_text.strip.replace", "tok_text.strip.replace", "tok_text.strip.strip", "utils.get_final_text", "collections.namedtuple.", "nbest.append", "len", "nbest.insert", "collections.namedtuple.", "json.dumps", "json.dumps", "len", "len", "feature.token_is_max_context.get", "collections.namedtuple.", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._get_best_indexes", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._get_best_indexes", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._compute_softmax", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.get_final_text"], ["def", "write_predictions", "(", "all_examples", ",", "all_features", ",", "all_results", ",", "n_best_size", ",", "\n", "max_answer_length", ",", "do_lower_case", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "output_null_log_odds_file", ",", "verbose_logging", ",", "\n", "version_2_with_negative", ",", "null_score_diff_threshold", ")", ":", "\n", "    ", "\"\"\"Write final predictions to the json file and log-odds of null if needed.\"\"\"", "\n", "# logger.info(\"Writing predictions to: %s\" % (output_prediction_file))", "\n", "# logger.info(\"Writing nbest to: %s\" % (output_nbest_file))", "\n", "\n", "# example_id_to_features = collections.defaultdict(list)", "\n", "# for feature in all_features:", "\n", "#     example_id_to_features[feature.example_id].append(feature)", "\n", "\n", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "\n", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\"start_logit\"", ",", "\"end_logit\"", ",", "'retrieval_logit'", ",", "'retriever_prob'", "]", ")", "\n", "\n", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "# for (example_id, example) in enumerate(all_examples):", "\n", "for", "example_id", ",", "example", "in", "all_examples", ".", "items", "(", ")", ":", "\n", "# features = example_id_to_features[example_id]", "\n", "        ", "feature", "=", "all_features", "[", "example_id", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "min_null_feature_index", "=", "0", "# the paragraph slice with min null score", "\n", "null_start_logit", "=", "0", "# the start logit at the slice with min null score", "\n", "null_end_logit", "=", "0", "# the end logit at the slice with min null score", "\n", "# for (feature_index, feature) in enumerate(features):", "\n", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "start_indexes", "=", "_get_best_indexes", "(", "result", ".", "start_logits", ",", "n_best_size", ")", "\n", "end_indexes", "=", "_get_best_indexes", "(", "result", ".", "end_logits", ",", "n_best_size", ")", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "if", "version_2_with_negative", ":", "\n", "            ", "feature_null_score", "=", "result", ".", "start_logits", "[", "0", "]", "+", "result", ".", "end_logits", "[", "0", "]", "\n", "if", "feature_null_score", "<", "score_null", ":", "\n", "                ", "score_null", "=", "feature_null_score", "\n", "min_null_feature_index", "=", "0", "\n", "null_start_logit", "=", "result", ".", "start_logits", "[", "0", "]", "\n", "null_end_logit", "=", "result", ".", "end_logits", "[", "0", "]", "\n", "null_retrieval_logit", "=", "result", ".", "retrieval_logits", "[", "-", "1", "]", "\n", "null_retriever_prob", "=", "result", ".", "retriever_prob", "\n", "", "", "for", "start_index", "in", "start_indexes", ":", "\n", "            ", "for", "end_index", "in", "end_indexes", ":", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "                ", "if", "start_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "end_index", ">=", "len", "(", "feature", ".", "tokens", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "start_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                    ", "continue", "\n", "", "if", "end_index", "not", "in", "feature", ".", "token_to_orig_map", ":", "\n", "                    ", "continue", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                    ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                    ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                    ", "continue", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "0", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_logit", "=", "result", ".", "start_logits", "[", "start_index", "]", ",", "\n", "end_logit", "=", "result", ".", "end_logits", "[", "end_index", "]", ",", "\n", "retrieval_logit", "=", "result", ".", "retrieval_logits", "[", "-", "1", "]", ",", "\n", "retriever_prob", "=", "result", ".", "retriever_prob", ")", ")", "\n", "", "", "if", "version_2_with_negative", ":", "\n", "            ", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "0", ",", "# min_null_feature_index", "\n", "start_index", "=", "0", ",", "\n", "end_index", "=", "0", ",", "\n", "start_logit", "=", "null_start_logit", ",", "\n", "end_logit", "=", "null_end_logit", ",", "\n", "retrieval_logit", "=", "null_retrieval_logit", ",", "\n", "retriever_prob", "=", "null_retriever_prob", ")", ")", "\n", "", "prelim_predictions", "=", "sorted", "(", "\n", "prelim_predictions", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_logit", "+", "x", ".", "end_logit", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_logit\"", ",", "\"end_logit\"", ",", "'retrieval_logit'", ",", "'retriever_prob'", "]", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "# feature = features[pred.feature_index]", "\n", "", "if", "pred", ".", "start_index", ">", "0", ":", "# this is a non-null prediction", "\n", "                ", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_tokens", ")", "\n", "\n", "# De-tokenize WordPieces that have been split off.", "\n", "tok_text", "=", "tok_text", ".", "replace", "(", "\" ##\"", ",", "\"\"", ")", "\n", "tok_text", "=", "tok_text", ".", "replace", "(", "\"##\"", ",", "\"\"", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", ")", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                    ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "", "else", ":", "\n", "                ", "final_text", "=", "\"CANNOTANSWER\"", "\n", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "\n", "text", "=", "final_text", ",", "\n", "start_logit", "=", "pred", ".", "start_logit", ",", "\n", "end_logit", "=", "pred", ".", "end_logit", ",", "\n", "retrieval_logit", "=", "pred", ".", "retrieval_logit", ",", "\n", "retriever_prob", "=", "pred", ".", "retriever_prob", ")", ")", "\n", "# if we didn't include the empty option in the n-best, include it", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "if", "\"CANNOTANSWER\"", "not", "in", "seen_predictions", ":", "\n", "                ", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "\n", "text", "=", "\"CANNOTANSWER\"", ",", "\n", "start_logit", "=", "null_start_logit", ",", "\n", "end_logit", "=", "null_end_logit", ",", "\n", "retrieval_logit", "=", "null_retrieval_logit", ",", "\n", "retriever_prob", "=", "null_retriever_prob", ")", ")", "\n", "\n", "# In very rare edge cases we could only have single null prediction.", "\n", "# So we just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "len", "(", "nbest", ")", "==", "1", ":", "\n", "                ", "nbest", ".", "insert", "(", "0", ",", "\n", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ",", "\n", "retrieval_logit", "=", "0.0", ",", "retriever_prob", "=", "0.0", ")", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "text", "=", "\"empty\"", ",", "start_logit", "=", "0.0", ",", "end_logit", "=", "0.0", ",", "retrieval_logit", "=", "0.0", ",", "retriever_prob", "=", "0.0", ")", ")", "\n", "\n", "", "assert", "len", "(", "nbest", ")", ">=", "1", "\n", "\n", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_logit", "+", "entry", ".", "end_logit", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "if", "entry", ".", "text", "!=", "'CANNOTANSWER'", ":", "\n", "                    ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_logit\"", "]", "=", "entry", ".", "start_logit", "\n", "output", "[", "\"end_logit\"", "]", "=", "entry", ".", "end_logit", "\n", "output", "[", "'retrieval_logit'", "]", "=", "entry", ".", "retrieval_logit", "\n", "output", "[", "'retriever_prob'", "]", "=", "entry", ".", "retriever_prob", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "            ", "best_non_null_entry_prob", ",", "null_prob", "=", "0.0", ",", "0.0", "\n", "for", "i", ",", "total_score", "in", "enumerate", "(", "total_scores", ")", ":", "\n", "                ", "if", "best_non_null_entry", ".", "start_logit", "+", "best_non_null_entry", ".", "end_logit", "==", "total_score", ":", "\n", "                    ", "best_non_null_entry_prob", "=", "probs", "[", "i", "]", "\n", "", "if", "null_start_logit", "+", "null_end_logit", "==", "total_score", ":", "\n", "                    ", "null_prob", "=", "probs", "[", "i", "]", "\n", "", "", "assert", "best_non_null_entry_prob", "!=", "0.0", "\n", "assert", "null_prob", "!=", "0.0", "\n", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "\n", "if", "not", "version_2_with_negative", ":", "\n", "# all_predictions[example.qas_id] = nbest_json[0][\"text\"]", "\n", "# all_predictions[example.example_id] = nbest_json[0][\"text\"]", "\n", "            ", "example_prediction", "=", "{", "'text'", ":", "best_non_null_entry", ".", "text", ",", "\n", "'start_logit'", ":", "best_non_null_entry", ".", "start_logit", ",", "\n", "'end_logit'", ":", "best_non_null_entry", ".", "end_logit", ",", "\n", "'retrieval_logit'", ":", "best_non_null_entry", ".", "retrieval_logit", ",", "\n", "'retriever_prob'", ":", "best_non_null_entry", ".", "retriever_prob", ",", "\n", "'example_id'", ":", "example", ".", "example_id", "}", "\n", "", "else", ":", "\n", "# predict \"\" iff the null score - the score of best non-null > threshold", "\n", "            ", "score_diff", "=", "(", "score_null", "-", "\n", "best_non_null_entry", ".", "start_logit", "-", "\n", "best_non_null_entry", ".", "end_logit", ")", "\n", "scores_diff_json", "[", "example", ".", "example_id", "]", "=", "score_diff", "\n", "if", "score_diff", ">", "null_score_diff_threshold", ":", "\n", "                ", "example_prediction", "=", "{", "'text'", ":", "'CANNOTANSWER'", ",", "\n", "'start_logit'", ":", "null_start_logit", ",", "\n", "'end_logit'", ":", "null_end_logit", ",", "\n", "'retrieval_logit'", ":", "null_retrieval_logit", ",", "\n", "'retriever_prob'", ":", "null_retriever_prob", ",", "\n", "'example_id'", ":", "example", ".", "example_id", ",", "\n", "'prob'", ":", "null_prob", "}", "\n", "", "else", ":", "\n", "                ", "example_prediction", "=", "{", "'text'", ":", "best_non_null_entry", ".", "text", ",", "\n", "'start_logit'", ":", "best_non_null_entry", ".", "start_logit", ",", "\n", "'end_logit'", ":", "best_non_null_entry", ".", "end_logit", ",", "\n", "'retrieval_logit'", ":", "best_non_null_entry", ".", "retrieval_logit", ",", "\n", "'retriever_prob'", ":", "best_non_null_entry", ".", "retriever_prob", ",", "\n", "'example_id'", ":", "example", ".", "example_id", ",", "\n", "'prob'", ":", "best_non_null_entry_prob", "}", "\n", "\n", "", "", "if", "example", ".", "qas_id", "in", "all_predictions", ":", "\n", "            ", "all_predictions", "[", "example", ".", "qas_id", "]", ".", "append", "(", "example_prediction", ")", "\n", "", "else", ":", "\n", "            ", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "[", "example_prediction", "]", "\n", "\n", "", "all_nbest_json", "[", "example", ".", "example_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "return", "all_predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_final_predictions": [[1242, 1308], ["logger.info", "turn_level_preds.items", "dialog_level_preds.values", "all_predictions.items", "all_predictions.items", "io.open", "dialog_level_preds.values", "numpy.argmax", "numpy.asarray", "numpy.asarray", "numpy.argmax", "qid.split", "[].append", "[].append", "[].append", "[].append", "[].append", "fout.write", "qa_scores.append", "qa_scores.append", "rerank_scores.append", "utils._compute_softmax", "utils._compute_softmax", "pred[].split", "json.dumps"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._compute_softmax", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._compute_softmax"], ["", "def", "write_final_predictions", "(", "all_predictions", ",", "final_prediction_file", ",", "\n", "use_rerank_prob", "=", "True", ",", "use_retriever_prob", "=", "False", ",", "\n", "real_joint_learn", "=", "False", ",", "involve_rerank_in_real_joint_learn", "=", "False", ")", ":", "\n", "    ", "\"\"\"convert instance level predictions to quac predictions\"\"\"", "\n", "logger", ".", "info", "(", "\"Writing final predictions to: %s\"", "%", "(", "final_prediction_file", ")", ")", "\n", "\n", "turn_level_preds", "=", "{", "}", "\n", "\n", "if", "real_joint_learn", ":", "\n", "        ", "for", "qid", ",", "preds", "in", "all_predictions", ".", "items", "(", ")", ":", "\n", "            ", "qa_scores", "=", "[", "]", "\n", "rerank_scores", "=", "[", "]", "\n", "for", "pred", "in", "preds", ":", "\n", "# retriever_prob is retriever_logit in this case", "\n", "                ", "each_score", "=", "pred", "[", "'start_logit'", "]", "+", "pred", "[", "'end_logit'", "]", "+", "pred", "[", "'retriever_prob'", "]", "\n", "if", "involve_rerank_in_real_joint_learn", ":", "\n", "                    ", "each_score", "+=", "pred", "[", "'retrieval_logit'", "]", "\n", "", "qa_scores", ".", "append", "(", "each_score", ")", "\n", "\n", "", "best_idx", "=", "np", ".", "argmax", "(", "qa_scores", ")", "\n", "turn_level_preds", "[", "qid", "]", "=", "preds", "[", "best_idx", "]", "\n", "", "", "else", ":", "\n", "        ", "for", "qid", ",", "preds", "in", "all_predictions", ".", "items", "(", ")", ":", "\n", "            ", "qa_scores", "=", "[", "]", "\n", "rerank_scores", "=", "[", "]", "\n", "for", "pred", "in", "preds", ":", "\n", "                ", "qa_scores", ".", "append", "(", "pred", "[", "'start_logit'", "]", "+", "pred", "[", "'end_logit'", "]", ")", "\n", "rerank_scores", ".", "append", "(", "pred", "[", "'retrieval_logit'", "]", ")", "\n", "", "qa_probs", "=", "np", ".", "asarray", "(", "_compute_softmax", "(", "qa_scores", ")", ")", "\n", "rerank_probs", "=", "np", ".", "asarray", "(", "_compute_softmax", "(", "rerank_scores", ")", ")", "\n", "\n", "total_scores", "=", "qa_probs", "\n", "if", "use_rerank_prob", ":", "\n", "                ", "total_scores", "=", "total_scores", "*", "rerank_probs", "\n", "", "if", "use_retriever_prob", ":", "\n", "                ", "total_scores", "=", "total_scores", "*", "pred", "[", "'retriever_prob'", "]", "\n", "\n", "", "best_idx", "=", "np", ".", "argmax", "(", "total_scores", ")", "\n", "turn_level_preds", "[", "qid", "]", "=", "preds", "[", "best_idx", "]", "\n", "\n", "", "", "dialog_level_preds", "=", "{", "}", "\n", "for", "qid", ",", "pred", "in", "turn_level_preds", ".", "items", "(", ")", ":", "\n", "        ", "dialog_id", "=", "qid", ".", "split", "(", "'#'", ")", "[", "0", "]", "\n", "try", ":", "\n", "            ", "pid", "=", "pred", "[", "'example_id'", "]", ".", "split", "(", "'*'", ")", "[", "1", "]", "\n", "", "except", ":", "\n", "            ", "pid", "=", "pred", "[", "'example_id'", "]", "\n", "", "if", "dialog_id", "in", "dialog_level_preds", ":", "\n", "            ", "dialog_level_preds", "[", "dialog_id", "]", "[", "'best_span_str'", "]", ".", "append", "(", "pred", "[", "'text'", "]", ")", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'qid'", "]", ".", "append", "(", "qid", ")", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'yesno'", "]", ".", "append", "(", "'x'", ")", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'followup'", "]", ".", "append", "(", "'y'", ")", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'pid'", "]", ".", "append", "(", "pid", ")", "\n", "", "else", ":", "\n", "            ", "dialog_level_preds", "[", "dialog_id", "]", "=", "{", "}", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'best_span_str'", "]", "=", "[", "pred", "[", "'text'", "]", "]", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'qid'", "]", "=", "[", "qid", "]", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'yesno'", "]", "=", "[", "'x'", "]", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'followup'", "]", "=", "[", "'y'", "]", "\n", "dialog_level_preds", "[", "dialog_id", "]", "[", "'pid'", "]", "=", "[", "pid", "]", "\n", "\n", "", "", "with", "open", "(", "final_prediction_file", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "pred", "in", "dialog_level_preds", ".", "values", "(", ")", ":", "\n", "            ", "fout", ".", "write", "(", "json", ".", "dumps", "(", "pred", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "return", "dialog_level_preds", ".", "values", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_weak_supervisor_predictions": [[1309, 1324], ["io.open", "all_predictions.items", "output_dicts.append", "fout.write", "len", "json.dumps"], "function", ["None"], ["", "def", "write_weak_supervisor_predictions", "(", "all_predictions", ",", "final_prediction_file", ")", ":", "\n", "# logger.info(\"Writing final predictions to: %s\" % (final_prediction_file))", "\n", "    ", "output_dicts", "=", "[", "]", "\n", "with", "open", "(", "final_prediction_file", ",", "'w'", ")", "as", "fout", ":", "\n", "        ", "for", "qid", ",", "preds", "in", "all_predictions", ".", "items", "(", ")", ":", "\n", "            ", "assert", "len", "(", "preds", ")", "==", "1", "\n", "pred", "=", "preds", "[", "0", "]", "\n", "output_dict", "=", "{", "'qid'", ":", "qid", ",", "\n", "'weak_answer'", ":", "pred", "[", "'text'", "]", ",", "\n", "'score'", ":", "pred", "[", "'start_logit'", "]", "+", "pred", "[", "'end_logit'", "]", ",", "\n", "# 'score': pred['prob'],", "\n", "}", "\n", "output_dicts", ".", "append", "(", "output_dict", ")", "\n", "fout", ".", "write", "(", "json", ".", "dumps", "(", "output_dict", ")", "+", "'\\n'", ")", "\n", "", "", "return", "output_dicts", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.write_predictions_extended": [[1332, 1520], ["collections.namedtuple", "collections.namedtuple", "logger.info", "collections.defaultdict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "make_qid_to_has_ans", "get_raw_scores", "find_all_best_thresh_v2", "example_id_to_features[].append", "enumerate", "sorted", "utils._compute_softmax", "enumerate", "io.open", "writer.write", "io.open", "writer.write", "io.open", "min", "range", "tokenizer.convert_tokens_to_string", "tok_text.strip.strip", "utils.get_final_text", "nbest.append", "nbest.append", "total_scores.append", "collections.OrderedDict", "nbest_json.append", "len", "io.open", "writer.write", "json.load", "make_qid_to_has_ans.items", "make_qid_to_has_ans.items", "range", "len", "tok_text.strip.split", "collections.namedtuple.", "collections.namedtuple.", "json.dumps", "json.dumps", "sorted.append", "json.dumps", "feature.token_is_max_context.get", "collections.namedtuple."], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._compute_softmax", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.get_final_text"], ["def", "write_predictions_extended", "(", "all_examples", ",", "all_features", ",", "all_results", ",", "n_best_size", ",", "\n", "max_answer_length", ",", "output_prediction_file", ",", "\n", "output_nbest_file", ",", "\n", "output_null_log_odds_file", ",", "orig_data_file", ",", "\n", "start_n_top", ",", "end_n_top", ",", "version_2_with_negative", ",", "\n", "tokenizer", ",", "verbose_logging", ")", ":", "\n", "    ", "\"\"\" XLNet write prediction logic (more complex than Bert's).\n        Write final predictions to the json file and log-odds of null if needed.\n        Requires utils_squad_evaluate.py\n    \"\"\"", "\n", "_PrelimPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"PrelimPrediction\"", ",", "\n", "[", "\"feature_index\"", ",", "\"start_index\"", ",", "\"end_index\"", ",", "\n", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", ")", "\n", "\n", "_NbestPrediction", "=", "collections", ".", "namedtuple", "(", "# pylint: disable=invalid-name", "\n", "\"NbestPrediction\"", ",", "[", "\"text\"", ",", "\"start_log_prob\"", ",", "\"end_log_prob\"", "]", ")", "\n", "\n", "logger", ".", "info", "(", "\"Writing predictions to: %s\"", ",", "output_prediction_file", ")", "\n", "# logger.info(\"Writing nbest to: %s\" % (output_nbest_file))", "\n", "\n", "example_id_to_features", "=", "collections", ".", "defaultdict", "(", "list", ")", "\n", "for", "feature", "in", "all_features", ":", "\n", "        ", "example_id_to_features", "[", "feature", ".", "example_id", "]", ".", "append", "(", "feature", ")", "\n", "\n", "", "unique_id_to_result", "=", "{", "}", "\n", "for", "result", "in", "all_results", ":", "\n", "        ", "unique_id_to_result", "[", "result", ".", "unique_id", "]", "=", "result", "\n", "\n", "", "all_predictions", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "all_nbest_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "scores_diff_json", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "\n", "for", "(", "example_index", ",", "example", ")", "in", "enumerate", "(", "all_examples", ")", ":", "\n", "        ", "features", "=", "example_index_to_features", "[", "example_index", "]", "\n", "\n", "prelim_predictions", "=", "[", "]", "\n", "# keep track of the minimum score of null start+end of position 0", "\n", "score_null", "=", "1000000", "# large and positive", "\n", "\n", "for", "(", "feature_index", ",", "feature", ")", "in", "enumerate", "(", "features", ")", ":", "\n", "            ", "result", "=", "unique_id_to_result", "[", "feature", ".", "unique_id", "]", "\n", "\n", "cur_null_score", "=", "result", ".", "cls_logits", "\n", "\n", "# if we could have irrelevant answers, get the min score of irrelevant", "\n", "score_null", "=", "min", "(", "score_null", ",", "cur_null_score", ")", "\n", "\n", "for", "i", "in", "range", "(", "start_n_top", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "end_n_top", ")", ":", "\n", "                    ", "start_log_prob", "=", "result", ".", "start_top_log_probs", "[", "i", "]", "\n", "start_index", "=", "result", ".", "start_top_index", "[", "i", "]", "\n", "\n", "j_index", "=", "i", "*", "end_n_top", "+", "j", "\n", "\n", "end_log_prob", "=", "result", ".", "end_top_log_probs", "[", "j_index", "]", "\n", "end_index", "=", "result", ".", "end_top_index", "[", "j_index", "]", "\n", "\n", "# We could hypothetically create invalid predictions, e.g., predict", "\n", "# that the start of the span is in the question. We throw out all", "\n", "# invalid predictions.", "\n", "if", "start_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", ">=", "feature", ".", "paragraph_len", "-", "1", ":", "\n", "                        ", "continue", "\n", "\n", "", "if", "not", "feature", ".", "token_is_max_context", ".", "get", "(", "start_index", ",", "False", ")", ":", "\n", "                        ", "continue", "\n", "", "if", "end_index", "<", "start_index", ":", "\n", "                        ", "continue", "\n", "", "length", "=", "end_index", "-", "start_index", "+", "1", "\n", "if", "length", ">", "max_answer_length", ":", "\n", "                        ", "continue", "\n", "\n", "", "prelim_predictions", ".", "append", "(", "\n", "_PrelimPrediction", "(", "\n", "feature_index", "=", "feature_index", ",", "\n", "start_index", "=", "start_index", ",", "\n", "end_index", "=", "end_index", ",", "\n", "start_log_prob", "=", "start_log_prob", ",", "\n", "end_log_prob", "=", "end_log_prob", ")", ")", "\n", "\n", "", "", "", "prelim_predictions", "=", "sorted", "(", "\n", "prelim_predictions", ",", "\n", "key", "=", "lambda", "x", ":", "(", "x", ".", "start_log_prob", "+", "x", ".", "end_log_prob", ")", ",", "\n", "reverse", "=", "True", ")", "\n", "\n", "seen_predictions", "=", "{", "}", "\n", "nbest", "=", "[", "]", "\n", "for", "pred", "in", "prelim_predictions", ":", "\n", "            ", "if", "len", "(", "nbest", ")", ">=", "n_best_size", ":", "\n", "                ", "break", "\n", "", "feature", "=", "features", "[", "pred", ".", "feature_index", "]", "\n", "\n", "# XLNet un-tokenizer", "\n", "# Let's keep it simple for now and see if we need all this later.", "\n", "# ", "\n", "# tok_start_to_orig_index = feature.tok_start_to_orig_index", "\n", "# tok_end_to_orig_index = feature.tok_end_to_orig_index", "\n", "# start_orig_pos = tok_start_to_orig_index[pred.start_index]", "\n", "# end_orig_pos = tok_end_to_orig_index[pred.end_index]", "\n", "# paragraph_text = example.paragraph_text", "\n", "# final_text = paragraph_text[start_orig_pos: end_orig_pos + 1].strip()", "\n", "\n", "# Previously used Bert untokenizer", "\n", "tok_tokens", "=", "feature", ".", "tokens", "[", "pred", ".", "start_index", ":", "(", "pred", ".", "end_index", "+", "1", ")", "]", "\n", "orig_doc_start", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "start_index", "]", "\n", "orig_doc_end", "=", "feature", ".", "token_to_orig_map", "[", "pred", ".", "end_index", "]", "\n", "orig_tokens", "=", "example", ".", "doc_tokens", "[", "orig_doc_start", ":", "(", "orig_doc_end", "+", "1", ")", "]", "\n", "tok_text", "=", "tokenizer", ".", "convert_tokens_to_string", "(", "tok_tokens", ")", "\n", "\n", "# Clean whitespace", "\n", "tok_text", "=", "tok_text", ".", "strip", "(", ")", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tok_text", ".", "split", "(", ")", ")", "\n", "orig_text", "=", "\" \"", ".", "join", "(", "orig_tokens", ")", "\n", "\n", "final_text", "=", "get_final_text", "(", "tok_text", ",", "orig_text", ",", "tokenizer", ".", "do_lower_case", ",", "\n", "verbose_logging", ")", "\n", "\n", "if", "final_text", "in", "seen_predictions", ":", "\n", "                ", "continue", "\n", "\n", "", "seen_predictions", "[", "final_text", "]", "=", "True", "\n", "\n", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "\n", "text", "=", "final_text", ",", "\n", "start_log_prob", "=", "pred", ".", "start_log_prob", ",", "\n", "end_log_prob", "=", "pred", ".", "end_log_prob", ")", ")", "\n", "\n", "# In very rare edge cases we could have no valid predictions. So we", "\n", "# just create a nonce prediction in this case to avoid failure.", "\n", "", "if", "not", "nbest", ":", "\n", "            ", "nbest", ".", "append", "(", "\n", "_NbestPrediction", "(", "text", "=", "\"\"", ",", "start_log_prob", "=", "-", "1e6", ",", "\n", "end_log_prob", "=", "-", "1e6", ")", ")", "\n", "\n", "", "total_scores", "=", "[", "]", "\n", "best_non_null_entry", "=", "None", "\n", "for", "entry", "in", "nbest", ":", "\n", "            ", "total_scores", ".", "append", "(", "entry", ".", "start_log_prob", "+", "entry", ".", "end_log_prob", ")", "\n", "if", "not", "best_non_null_entry", ":", "\n", "                ", "best_non_null_entry", "=", "entry", "\n", "\n", "", "", "probs", "=", "_compute_softmax", "(", "total_scores", ")", "# the prob of being the best answer among nbest answers", "\n", "\n", "nbest_json", "=", "[", "]", "\n", "for", "(", "i", ",", "entry", ")", "in", "enumerate", "(", "nbest", ")", ":", "\n", "            ", "output", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "output", "[", "\"text\"", "]", "=", "entry", ".", "text", "\n", "output", "[", "\"probability\"", "]", "=", "probs", "[", "i", "]", "\n", "output", "[", "\"start_log_prob\"", "]", "=", "entry", ".", "start_log_prob", "\n", "output", "[", "\"end_log_prob\"", "]", "=", "entry", ".", "end_log_prob", "\n", "nbest_json", ".", "append", "(", "output", ")", "\n", "\n", "", "assert", "len", "(", "nbest_json", ")", ">=", "1", "\n", "assert", "best_non_null_entry", "is", "not", "None", "\n", "\n", "score_diff", "=", "score_null", "\n", "scores_diff_json", "[", "example", ".", "qas_id", "]", "=", "score_diff", "\n", "# note(zhiliny): always predict best_non_null_entry", "\n", "# and the evaluation script will search for the best threshold", "\n", "all_predictions", "[", "example", ".", "qas_id", "]", "=", "best_non_null_entry", ".", "text", "\n", "\n", "all_nbest_json", "[", "example", ".", "qas_id", "]", "=", "nbest_json", "\n", "\n", "", "with", "open", "(", "output_prediction_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_predictions", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "with", "open", "(", "output_nbest_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "all_nbest_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "if", "version_2_with_negative", ":", "\n", "        ", "with", "open", "(", "output_null_log_odds_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "scores_diff_json", ",", "indent", "=", "4", ")", "+", "\"\\n\"", ")", "\n", "\n", "", "", "with", "open", "(", "orig_data_file", ",", "\"r\"", ",", "encoding", "=", "'utf-8'", ")", "as", "reader", ":", "\n", "        ", "orig_data", "=", "json", ".", "load", "(", "reader", ")", "[", "\"data\"", "]", "\n", "\n", "", "qid_to_has_ans", "=", "make_qid_to_has_ans", "(", "orig_data", ")", "\n", "has_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "v", "]", "\n", "no_ans_qids", "=", "[", "k", "for", "k", ",", "v", "in", "qid_to_has_ans", ".", "items", "(", ")", "if", "not", "v", "]", "\n", "exact_raw", ",", "f1_raw", "=", "get_raw_scores", "(", "orig_data", ",", "all_predictions", ")", "\n", "out_eval", "=", "{", "}", "\n", "\n", "find_all_best_thresh_v2", "(", "out_eval", ",", "all_predictions", ",", "exact_raw", ",", "f1_raw", ",", "scores_diff_json", ",", "qid_to_has_ans", ")", "\n", "\n", "return", "out_eval", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.get_final_text": [[1522, 1616], ["transformers.tokenization_bert.BasicTokenizer", "tok_text.find", "utils.get_final_text._strip_spaces"], "function", ["None"], ["", "def", "get_final_text", "(", "pred_text", ",", "orig_text", ",", "do_lower_case", ",", "verbose_logging", "=", "False", ")", ":", "\n", "    ", "\"\"\"Project the tokenized prediction back to the original text.\"\"\"", "\n", "\n", "# When we created the data, we kept track of the alignment between original", "\n", "# (whitespace tokenized) tokens and our WordPiece tokenized tokens. So", "\n", "# now `orig_text` contains the span of our original text corresponding to the", "\n", "# span that we predicted.", "\n", "#", "\n", "# However, `orig_text` may contain extra characters that we don't want in", "\n", "# our prediction.", "\n", "#", "\n", "# For example, let's say:", "\n", "#   pred_text = steve smith", "\n", "#   orig_text = Steve Smith's", "\n", "#", "\n", "# We don't want to return `orig_text` because it contains the extra \"'s\".", "\n", "#", "\n", "# We don't want to return `pred_text` because it's already been normalized", "\n", "# (the SQuAD eval script also does punctuation stripping/lower casing but", "\n", "# our tokenizer does additional normalization like stripping accent", "\n", "# characters).", "\n", "#", "\n", "# What we really want to return is \"Steve Smith\".", "\n", "#", "\n", "# Therefore, we have to apply a semi-complicated alignment heuristic between", "\n", "# `pred_text` and `orig_text` to get a character-to-character alignment. This", "\n", "# can fail in certain cases in which case we just return `orig_text`.", "\n", "\n", "def", "_strip_spaces", "(", "text", ")", ":", "\n", "        ", "ns_chars", "=", "[", "]", "\n", "ns_to_s_map", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "(", "i", ",", "c", ")", "in", "enumerate", "(", "text", ")", ":", "\n", "            ", "if", "c", "==", "\" \"", ":", "\n", "                ", "continue", "\n", "", "ns_to_s_map", "[", "len", "(", "ns_chars", ")", "]", "=", "i", "\n", "ns_chars", ".", "append", "(", "c", ")", "\n", "", "ns_text", "=", "\"\"", ".", "join", "(", "ns_chars", ")", "\n", "return", "(", "ns_text", ",", "ns_to_s_map", ")", "\n", "\n", "# We first tokenize `orig_text`, strip whitespace from the result", "\n", "# and `pred_text`, and check if they are the same length. If they are", "\n", "# NOT the same length, the heuristic has failed. If they are the same", "\n", "# length, we assume the characters are one-to-one aligned.", "\n", "", "tokenizer", "=", "BasicTokenizer", "(", "do_lower_case", "=", "do_lower_case", ")", "\n", "\n", "tok_text", "=", "\" \"", ".", "join", "(", "tokenizer", ".", "tokenize", "(", "orig_text", ")", ")", "\n", "\n", "start_position", "=", "tok_text", ".", "find", "(", "pred_text", ")", "\n", "if", "start_position", "==", "-", "1", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "\"Unable to find text: '%s' in '%s'\"", "%", "(", "pred_text", ",", "orig_text", ")", ")", "\n", "", "return", "orig_text", "\n", "", "end_position", "=", "start_position", "+", "len", "(", "pred_text", ")", "-", "1", "\n", "\n", "(", "orig_ns_text", ",", "orig_ns_to_s_map", ")", "=", "_strip_spaces", "(", "orig_text", ")", "\n", "(", "tok_ns_text", ",", "tok_ns_to_s_map", ")", "=", "_strip_spaces", "(", "tok_text", ")", "\n", "\n", "if", "len", "(", "orig_ns_text", ")", "!=", "len", "(", "tok_ns_text", ")", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Length not equal after stripping spaces: '%s' vs '%s'\"", ",", "\n", "orig_ns_text", ",", "tok_ns_text", ")", "\n", "", "return", "orig_text", "\n", "\n", "# We then project the characters in `pred_text` back to `orig_text` using", "\n", "# the character-to-character alignment.", "\n", "", "tok_s_to_ns_map", "=", "{", "}", "\n", "for", "(", "i", ",", "tok_index", ")", "in", "tok_ns_to_s_map", ".", "items", "(", ")", ":", "\n", "        ", "tok_s_to_ns_map", "[", "tok_index", "]", "=", "i", "\n", "\n", "", "orig_start_position", "=", "None", "\n", "if", "start_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_start_position", "=", "tok_s_to_ns_map", "[", "start_position", "]", "\n", "if", "ns_start_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_start_position", "=", "orig_ns_to_s_map", "[", "ns_start_position", "]", "\n", "\n", "", "", "if", "orig_start_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map start position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "orig_end_position", "=", "None", "\n", "if", "end_position", "in", "tok_s_to_ns_map", ":", "\n", "        ", "ns_end_position", "=", "tok_s_to_ns_map", "[", "end_position", "]", "\n", "if", "ns_end_position", "in", "orig_ns_to_s_map", ":", "\n", "            ", "orig_end_position", "=", "orig_ns_to_s_map", "[", "ns_end_position", "]", "\n", "\n", "", "", "if", "orig_end_position", "is", "None", ":", "\n", "        ", "if", "verbose_logging", ":", "\n", "            ", "logger", ".", "info", "(", "\"Couldn't map end position\"", ")", "\n", "", "return", "orig_text", "\n", "\n", "", "output_text", "=", "orig_text", "[", "orig_start_position", ":", "(", "orig_end_position", "+", "1", ")", "]", "\n", "return", "output_text", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._get_best_indexes": [[1618, 1628], ["sorted", "range", "enumerate", "len", "best_indexes.append"], "function", ["None"], ["", "def", "_get_best_indexes", "(", "logits", ",", "n_best_size", ")", ":", "\n", "    ", "\"\"\"Get the n-best logits from a list.\"\"\"", "\n", "index_and_score", "=", "sorted", "(", "enumerate", "(", "logits", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "best_indexes", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "index_and_score", ")", ")", ":", "\n", "        ", "if", "i", ">=", "n_best_size", ":", "\n", "            ", "break", "\n", "", "best_indexes", ".", "append", "(", "index_and_score", "[", "i", "]", "[", "0", "]", ")", "\n", "", "return", "best_indexes", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils._compute_softmax": [[1630, 1651], ["math.exp", "exp_scores.append", "probs.append"], "function", ["None"], ["", "def", "_compute_softmax", "(", "scores", ")", ":", "\n", "    ", "\"\"\"Compute softmax probability over raw logits.\"\"\"", "\n", "if", "not", "scores", ":", "\n", "        ", "return", "[", "]", "\n", "\n", "", "max_score", "=", "None", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "if", "max_score", "is", "None", "or", "score", ">", "max_score", ":", "\n", "            ", "max_score", "=", "score", "\n", "\n", "", "", "exp_scores", "=", "[", "]", "\n", "total_sum", "=", "0.0", "\n", "for", "score", "in", "scores", ":", "\n", "        ", "x", "=", "math", ".", "exp", "(", "score", "-", "max_score", ")", "\n", "exp_scores", ".", "append", "(", "x", ")", "\n", "total_sum", "+=", "x", "\n", "\n", "", "probs", "=", "[", "]", "\n", "for", "score", "in", "exp_scores", ":", "\n", "        ", "probs", ".", "append", "(", "score", "/", "total_sum", ")", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.get_retrieval_metrics": [[1652, 1680], ["all_predictions.items", "evaluator.evaluate", "numpy.average", "numpy.average", "all_predictions.items", "evaluator.evaluate", "return_dict.update", "evaluator.evaluate.values", "evaluator.evaluate.values", "evaluator.evaluate.values", "evaluator.evaluate.values", "numpy.average", "numpy.average", "pred[].split", "pred[].split"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.evaluate", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.train_weak_supervisor.evaluate"], ["", "def", "get_retrieval_metrics", "(", "evaluator", ",", "all_predictions", ",", "eval_retriever_probs", "=", "False", ")", ":", "\n", "    ", "rerank_run", "=", "{", "}", "\n", "for", "qid", ",", "preds", "in", "all_predictions", ".", "items", "(", ")", ":", "\n", "        ", "rerank_run", "[", "qid", "]", "=", "{", "}", "\n", "for", "pred", "in", "preds", ":", "\n", "            ", "pid", "=", "pred", "[", "'example_id'", "]", ".", "split", "(", "'*'", ")", "[", "1", "]", "if", "eval_retriever_probs", "else", "pred", "[", "'example_id'", "]", "\n", "rerank_run", "[", "qid", "]", "[", "pid", "]", "=", "pred", "[", "'retrieval_logit'", "]", "\n", "# print('rerank_run', rerank_run)", "\n", "", "", "rerank_metrics", "=", "evaluator", ".", "evaluate", "(", "rerank_run", ")", "\n", "rerank_mrr_list", "=", "[", "v", "[", "'recip_rank'", "]", "for", "v", "in", "rerank_metrics", ".", "values", "(", ")", "]", "\n", "rerank_recall_list", "=", "[", "v", "[", "'recall_5'", "]", "for", "v", "in", "rerank_metrics", ".", "values", "(", ")", "]", "\n", "return_dict", "=", "{", "'rerank_mrr'", ":", "np", ".", "average", "(", "rerank_mrr_list", ")", ",", "'rerank_recall'", ":", "np", ".", "average", "(", "rerank_recall_list", ")", "}", "\n", "\n", "if", "eval_retriever_probs", ":", "\n", "        ", "retriever_run", "=", "{", "}", "\n", "for", "qid", ",", "preds", "in", "all_predictions", ".", "items", "(", ")", ":", "\n", "            ", "retriever_run", "[", "qid", "]", "=", "{", "}", "\n", "for", "pred", "in", "preds", ":", "\n", "                ", "pid", "=", "pred", "[", "'example_id'", "]", ".", "split", "(", "'*'", ")", "[", "1", "]", "\n", "retriever_run", "[", "qid", "]", "[", "pid", "]", "=", "pred", "[", "'retriever_prob'", "]", "\n", "# print('retriever_run', retriever_run)", "\n", "", "", "retriever_metrics", "=", "evaluator", ".", "evaluate", "(", "retriever_run", ")", "\n", "retriever_mrr_list", "=", "[", "v", "[", "'recip_rank'", "]", "for", "v", "in", "retriever_metrics", ".", "values", "(", ")", "]", "\n", "retriever_recall_list", "=", "[", "v", "[", "'recall_5'", "]", "for", "v", "in", "retriever_metrics", ".", "values", "(", ")", "]", "\n", "return_dict", ".", "update", "(", "{", "'retriever_mrr'", ":", "np", ".", "average", "(", "retriever_mrr_list", ")", ",", "\n", "'retriever_recall'", ":", "np", ".", "average", "(", "retriever_recall_list", ")", "}", ")", "\n", "\n", "", "return", "return_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.get_train_retriever_run": [[1681, 1693], ["zip", "zip", "float", "float"], "function", ["None"], ["", "def", "get_train_retriever_run", "(", "qids", ",", "pids", ",", "labels", ")", ":", "\n", "    ", "training_run", "=", "{", "}", "# evaluate retriever recall during training", "\n", "gold_passage_hit_run", "=", "{", "}", "# measure how many positive passages identified by weak supervision are gold passages", "\n", "\n", "for", "qid", ",", "pids_per_query", ",", "labels_per_query", "in", "zip", "(", "qids", ",", "pids", ",", "labels", ")", ":", "\n", "        ", "training_run", "[", "qid", "]", "=", "{", "}", "\n", "gold_passage_hit_run", "[", "qid", "]", "=", "{", "}", "\n", "for", "pid", ",", "label", "in", "zip", "(", "pids_per_query", ",", "labels_per_query", ")", ":", "\n", "            ", "training_run", "[", "qid", "]", "[", "pid", "]", "=", "float", "(", "label", ")", "\n", "if", "label", "==", "1", ":", "\n", "                ", "gold_passage_hit_run", "[", "qid", "]", "[", "pid", "]", "=", "float", "(", "label", ")", "\n", "", "", "", "return", "training_run", ",", "gold_passage_hit_run", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.utils.weak_supervisor_eval": [[1694, 1729], ["answer_dict.items", "io.open", "io.open", "int", "f1s.append", "numpy.average", "numpy.average", "numpy.average", "json.loads", "json.loads", "scorer.f1_score", "overlap_f1s.append", "cannotanswer_f1s.append", "line.strip", "line.strip", "qid.split"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.f1_score"], ["", "def", "weak_supervisor_eval", "(", "eval_file", ",", "model_output_file", ")", ":", "\n", "    ", "weak_answer_dict", "=", "{", "}", "\n", "with", "open", "(", "model_output_file", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "dic", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "weak_answer_dict", "[", "dic", "[", "'qid'", "]", "]", "=", "dic", "[", "'weak_answer'", "]", "\n", "\n", "", "", "answer_dict", "=", "{", "}", "\n", "with", "open", "(", "eval_file", ")", "as", "fin", ":", "\n", "        ", "for", "line", "in", "fin", ":", "\n", "            ", "dic", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "qid", "=", "'{}*{}'", ".", "format", "(", "dic", "[", "'qid'", "]", ",", "dic", "[", "'has_answer'", "]", ")", "\n", "answer_dict", "[", "qid", "]", "=", "dic", "[", "'answer_text'", "]", "\n", "\n", "", "", "f1s", "=", "[", "]", "\n", "overlap_f1s", "=", "[", "]", "\n", "cannotanswer_f1s", "=", "[", "]", "\n", "for", "qid", ",", "answer", "in", "answer_dict", ".", "items", "(", ")", ":", "\n", "        ", "has_answer", "=", "int", "(", "qid", ".", "split", "(", "'*'", ")", "[", "-", "1", "]", ")", "\n", "if", "qid", "in", "weak_answer_dict", ":", "\n", "            ", "weak_answer", "=", "weak_answer_dict", "[", "qid", "]", "\n", "", "else", ":", "\n", "            ", "continue", "\n", "\n", "", "if", "has_answer", ":", "\n", "            ", "f1", "=", "f1_score", "(", "weak_answer", ",", "answer", ")", "\n", "overlap_f1s", ".", "append", "(", "f1", ")", "\n", "", "else", ":", "\n", "            ", "f1", "=", "1.0", "if", "weak_answer", "==", "'CANNOTANSWER'", "else", "0.0", "\n", "cannotanswer_f1s", ".", "append", "(", "f1", ")", "\n", "", "f1s", ".", "append", "(", "f1", ")", "\n", "\n", "", "return", "{", "'f1'", ":", "np", ".", "average", "(", "f1s", ")", ",", "\n", "'overlap_f1'", ":", "np", ".", "average", "(", "overlap_f1s", ")", ",", "\n", "'cannotanswer_f1'", ":", "np", ".", "average", "(", "cannotanswer_f1s", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.is_overlapping": [[6, 8], ["max", "min"], "function", ["None"], ["def", "is_overlapping", "(", "x1", ",", "x2", ",", "y1", ",", "y2", ")", ":", "\n", "  ", "return", "max", "(", "x1", ",", "y1", ")", "<=", "min", "(", "x2", ",", "y2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.normalize_answer": [[9, 21], ["scorer.normalize_answer.white_space_fix"], "function", ["None"], ["", "def", "normalize_answer", "(", "s", ")", ":", "\n", "  ", "\"\"\"Lower text and remove punctuation, articles and extra whitespace.\"\"\"", "\n", "def", "remove_articles", "(", "text", ")", ":", "\n", "    ", "return", "re", ".", "sub", "(", "r'\\b(a|an|the)\\b'", ",", "' '", ",", "text", ")", "\n", "", "def", "white_space_fix", "(", "text", ")", ":", "\n", "    ", "return", "' '", ".", "join", "(", "text", ".", "split", "(", ")", ")", "\n", "", "def", "remove_punc", "(", "text", ")", ":", "\n", "    ", "exclude", "=", "set", "(", "string", ".", "punctuation", ")", "\n", "return", "''", ".", "join", "(", "ch", "for", "ch", "in", "text", "if", "ch", "not", "in", "exclude", ")", "\n", "", "def", "lower", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "lower", "(", ")", "\n", "", "return", "white_space_fix", "(", "remove_articles", "(", "remove_punc", "(", "lower", "(", "s", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.f1_score": [[22, 33], ["normalize_answer().split", "normalize_answer().split", "sum", "collections.Counter", "collections.Counter", "common.values", "len", "len", "scorer.normalize_answer", "scorer.normalize_answer"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.normalize_answer", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.normalize_answer"], ["", "def", "f1_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "  ", "prediction_tokens", "=", "normalize_answer", "(", "prediction", ")", ".", "split", "(", ")", "\n", "ground_truth_tokens", "=", "normalize_answer", "(", "ground_truth", ")", ".", "split", "(", ")", "\n", "common", "=", "Counter", "(", "prediction_tokens", ")", "&", "Counter", "(", "ground_truth_tokens", ")", "\n", "num_same", "=", "sum", "(", "common", ".", "values", "(", ")", ")", "\n", "if", "num_same", "==", "0", ":", "\n", "    ", "return", "0", "\n", "", "precision", "=", "1.0", "*", "num_same", "/", "len", "(", "prediction_tokens", ")", "\n", "recall", "=", "1.0", "*", "num_same", "/", "len", "(", "ground_truth_tokens", ")", "\n", "f1", "=", "(", "2", "*", "precision", "*", "recall", ")", "/", "(", "precision", "+", "recall", ")", "\n", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.exact_match_score": [[34, 36], ["scorer.normalize_answer", "scorer.normalize_answer"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.normalize_answer", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.normalize_answer"], ["", "def", "exact_match_score", "(", "prediction", ",", "ground_truth", ")", ":", "\n", "  ", "return", "(", "normalize_answer", "(", "prediction", ")", "==", "normalize_answer", "(", "ground_truth", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.display_counter": [[37, 45], ["print", "c.most_common", "print", "print", "sum", "sum", "c.values", "sum", "len", "c.values", "sum", "c.values", "sum", "c.values"], "function", ["None"], ["", "def", "display_counter", "(", "title", ",", "c", ",", "c2", "=", "None", ")", ":", "\n", "  ", "print", "(", "title", ")", "\n", "for", "key", ",", "_", "in", "c", ".", "most_common", "(", ")", ":", "\n", "    ", "if", "c2", ":", "\n", "      ", "print", "(", "'%s: %d / %d, %.1f%%, F1: %.1f'", "%", "(", "\n", "key", ",", "c", "[", "key", "]", ",", "sum", "(", "c", ".", "values", "(", ")", ")", ",", "c", "[", "key", "]", "*", "100.", "/", "sum", "(", "c", ".", "values", "(", ")", ")", ",", "sum", "(", "c2", "[", "key", "]", ")", "*", "100.", "/", "len", "(", "c2", "[", "key", "]", ")", ")", ")", "\n", "", "else", ":", "\n", "      ", "print", "(", "'%s: %d / %d, %.1f%%'", "%", "(", "key", ",", "c", "[", "key", "]", ",", "sum", "(", "c", ".", "values", "(", ")", ")", ",", "c", "[", "key", "]", "*", "100.", "/", "sum", "(", "c", ".", "values", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.leave_one_out_max": [[46, 58], ["len", "range", "len", "scorer.metric_max_over_ground_truths", "len", "list", "list.pop", "t_f1.append", "sum", "range", "len", "scorer.metric_max_over_ground_truths"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.metric_max_over_ground_truths"], ["", "", "", "def", "leave_one_out_max", "(", "prediction", ",", "ground_truths", ",", "article", ")", ":", "\n", "  ", "if", "len", "(", "ground_truths", ")", "==", "1", ":", "\n", "    ", "return", "metric_max_over_ground_truths", "(", "prediction", ",", "ground_truths", ",", "article", ")", "[", "1", "]", "\n", "", "else", ":", "\n", "    ", "t_f1", "=", "[", "]", "\n", "# leave out one ref every time", "\n", "for", "i", "in", "range", "(", "len", "(", "ground_truths", ")", ")", ":", "\n", "      ", "idxes", "=", "list", "(", "range", "(", "len", "(", "ground_truths", ")", ")", ")", "\n", "idxes", ".", "pop", "(", "i", ")", "\n", "refs", "=", "[", "ground_truths", "[", "z", "]", "for", "z", "in", "idxes", "]", "\n", "t_f1", ".", "append", "(", "metric_max_over_ground_truths", "(", "prediction", ",", "refs", ",", "article", ")", "[", "1", "]", ")", "\n", "", "", "return", "1.0", "*", "sum", "(", "t_f1", ")", "/", "len", "(", "t_f1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.metric_max_over_ground_truths": [[60, 66], ["max", "scorer.compute_span_overlap", "scores_for_ground_truths.append"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.compute_span_overlap"], ["", "def", "metric_max_over_ground_truths", "(", "prediction", ",", "ground_truths", ",", "article", ")", ":", "\n", "  ", "scores_for_ground_truths", "=", "[", "]", "\n", "for", "ground_truth", "in", "ground_truths", ":", "\n", "    ", "score", "=", "compute_span_overlap", "(", "prediction", ",", "ground_truth", ",", "article", ")", "\n", "scores_for_ground_truths", ".", "append", "(", "score", ")", "\n", "", "return", "max", "(", "scores_for_ground_truths", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.handle_cannot": [[68, 81], ["None"], "function", ["None"], ["", "def", "handle_cannot", "(", "refs", ")", ":", "\n", "  ", "num_cannot", "=", "0", "\n", "num_spans", "=", "0", "\n", "for", "ref", "in", "refs", ":", "\n", "    ", "if", "ref", "==", "'CANNOTANSWER'", ":", "\n", "      ", "num_cannot", "+=", "1", "\n", "", "else", ":", "\n", "      ", "num_spans", "+=", "1", "\n", "", "", "if", "num_cannot", ">=", "num_spans", ":", "\n", "    ", "refs", "=", "[", "'CANNOTANSWER'", "]", "\n", "", "else", ":", "\n", "    ", "refs", "=", "[", "x", "for", "x", "in", "refs", "if", "x", "!=", "'CANNOTANSWER'", "]", "\n", "", "return", "refs", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.leave_one_out": [[83, 100], ["range", "len", "splits.append", "len", "range", "len", "r.split", "len", "scorer.f1_score"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.f1_score"], ["", "def", "leave_one_out", "(", "refs", ")", ":", "\n", "  ", "if", "len", "(", "refs", ")", "==", "1", ":", "\n", "    ", "return", "1.", "\n", "", "splits", "=", "[", "]", "\n", "for", "r", "in", "refs", ":", "\n", "    ", "splits", ".", "append", "(", "r", ".", "split", "(", ")", ")", "\n", "", "t_f1", "=", "0.0", "\n", "for", "i", "in", "range", "(", "len", "(", "refs", ")", ")", ":", "\n", "    ", "m_f1", "=", "0", "\n", "for", "j", "in", "range", "(", "len", "(", "refs", ")", ")", ":", "\n", "      ", "if", "i", "==", "j", ":", "\n", "        ", "continue", "\n", "", "f1_ij", "=", "f1_score", "(", "refs", "[", "i", "]", ",", "refs", "[", "j", "]", ")", "\n", "if", "f1_ij", ">", "m_f1", ":", "\n", "        ", "m_f1", "=", "f1_ij", "\n", "", "", "t_f1", "+=", "m_f1", "\n", "", "return", "t_f1", "/", "len", "(", "refs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.compute_span_overlap": [[102, 126], ["scorer.f1_score", "text.find", "text.find", "scorer.f1_score", "scorer.is_overlapping", "scorer.exact_match_score", "len", "len"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.f1_score", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.f1_score", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.is_overlapping", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.exact_match_score"], ["", "def", "compute_span_overlap", "(", "pred_span", ",", "gt_span", ",", "text", ")", ":", "\n", "  ", "if", "gt_span", "==", "'CANNOTANSWER'", ":", "\n", "    ", "if", "pred_span", "==", "'CANNOTANSWER'", ":", "\n", "      ", "return", "'Exact match'", ",", "1.0", "\n", "", "return", "'No overlap'", ",", "0.", "\n", "", "fscore", "=", "f1_score", "(", "pred_span", ",", "gt_span", ")", "\n", "pred_start", "=", "text", ".", "find", "(", "pred_span", ")", "\n", "gt_start", "=", "text", ".", "find", "(", "gt_span", ")", "\n", "\n", "if", "pred_start", "==", "-", "1", "or", "gt_start", "==", "-", "1", ":", "\n", "    ", "return", "'Span indexing error'", ",", "fscore", "\n", "\n", "", "pred_end", "=", "pred_start", "+", "len", "(", "pred_span", ")", "\n", "gt_end", "=", "gt_start", "+", "len", "(", "gt_span", ")", "\n", "\n", "fscore", "=", "f1_score", "(", "pred_span", ",", "gt_span", ")", "\n", "overlap", "=", "is_overlapping", "(", "pred_start", ",", "pred_end", ",", "gt_start", ",", "gt_end", ")", "\n", "\n", "if", "exact_match_score", "(", "pred_span", ",", "gt_span", ")", ":", "\n", "    ", "return", "'Exact match'", ",", "fscore", "\n", "", "if", "overlap", ":", "\n", "    ", "return", "'Partial overlap'", ",", "fscore", "\n", "", "else", ":", "\n", "    ", "return", "'No overlap'", ",", "fscore", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.eval_fn": [[128, 225], ["collections.Counter", "collections.defaultdict", "sum", "print", "print", "print", "print", "print", "print", "print", "print", "print", "print", "collections.defaultdict.values", "len", "len", "len", "len", "print", "scorer.display_counter", "sum", "sum", "sum", "sum", "len", "len", "len", "scorer.handle_cannot", "scorer.leave_one_out", "scorer.metric_max_over_ground_truths", "scorer.leave_one_out_max", "unfiltered_f1s.append", "human_f1.append", "yes_nos.append", "followups.append", "f1_stats[].append", "sum", "len", "f1_stats[].append", "yes_nos.append", "followups.append", "unfiltered_f1s.append", "unanswerables.append", "print", "print", "print", "print", "print", "sum", "unanswerables.append", "human_f1.append"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.display_counter", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.handle_cannot", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.leave_one_out", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.leave_one_out_max"], ["", "", "def", "eval_fn", "(", "val_results", ",", "model_results", ",", "verbose", ")", ":", "\n", "  ", "span_overlap_stats", "=", "Counter", "(", ")", "\n", "sentence_overlap", "=", "0.", "\n", "para_overlap", "=", "0.", "\n", "total_qs", "=", "0.", "\n", "f1_stats", "=", "defaultdict", "(", "list", ")", "\n", "unfiltered_f1s", "=", "[", "]", "\n", "human_f1", "=", "[", "]", "\n", "HEQ", "=", "0.", "\n", "DHEQ", "=", "0.", "\n", "total_dials", "=", "0.", "\n", "yes_nos", "=", "[", "]", "\n", "followups", "=", "[", "]", "\n", "unanswerables", "=", "[", "]", "\n", "for", "p", "in", "val_results", ":", "\n", "    ", "for", "par", "in", "p", "[", "'paragraphs'", "]", ":", "\n", "      ", "did", "=", "par", "[", "'id'", "]", "\n", "qa_list", "=", "par", "[", "'qas'", "]", "\n", "good_dial", "=", "1.", "\n", "for", "qa", "in", "qa_list", ":", "\n", "        ", "q_idx", "=", "qa", "[", "'id'", "]", "\n", "val_spans", "=", "[", "anss", "[", "'text'", "]", "for", "anss", "in", "qa", "[", "'answers'", "]", "]", "\n", "val_spans", "=", "handle_cannot", "(", "val_spans", ")", "\n", "hf1", "=", "leave_one_out", "(", "val_spans", ")", "\n", "\n", "if", "did", "not", "in", "model_results", "or", "q_idx", "not", "in", "model_results", "[", "did", "]", ":", "\n", "# print(did, q_idx, 'no prediction for this dialogue id')", "\n", "          ", "good_dial", "=", "0", "\n", "f1_stats", "[", "'NO ANSWER'", "]", ".", "append", "(", "0.0", ")", "\n", "yes_nos", ".", "append", "(", "False", ")", "\n", "followups", ".", "append", "(", "False", ")", "\n", "if", "val_spans", "==", "[", "'CANNOTANSWER'", "]", ":", "\n", "            ", "unanswerables", ".", "append", "(", "0.0", ")", "\n", "", "total_qs", "+=", "1", "\n", "unfiltered_f1s", ".", "append", "(", "0.0", ")", "\n", "if", "hf1", ">=", "0.4", ":", "# args.min_f1:", "\n", "            ", "human_f1", ".", "append", "(", "hf1", ")", "\n", "", "continue", "\n", "\n", "", "pred_span", ",", "pred_yesno", ",", "pred_followup", "=", "model_results", "[", "did", "]", "[", "q_idx", "]", "\n", "\n", "max_overlap", ",", "_", "=", "metric_max_over_ground_truths", "(", "pred_span", ",", "val_spans", ",", "par", "[", "'context'", "]", ")", "\n", "max_f1", "=", "leave_one_out_max", "(", "pred_span", ",", "val_spans", ",", "par", "[", "'context'", "]", ")", "\n", "unfiltered_f1s", ".", "append", "(", "max_f1", ")", "\n", "\n", "# dont eval on low agreement instances", "\n", "if", "hf1", "<", "0.4", ":", "# args.min_f1:", "\n", "          ", "continue", "\n", "\n", "", "human_f1", ".", "append", "(", "hf1", ")", "\n", "yes_nos", ".", "append", "(", "pred_yesno", "==", "qa", "[", "'yesno'", "]", ")", "\n", "followups", ".", "append", "(", "pred_followup", "==", "qa", "[", "'followup'", "]", ")", "\n", "if", "val_spans", "==", "[", "'CANNOTANSWER'", "]", ":", "\n", "          ", "unanswerables", ".", "append", "(", "max_f1", ")", "\n", "", "if", "verbose", ":", "\n", "          ", "print", "(", "\"-\"", "*", "20", ")", "\n", "print", "(", "pred_span", ")", "\n", "print", "(", "val_spans", ")", "\n", "print", "(", "max_f1", ")", "\n", "print", "(", "\"-\"", "*", "20", ")", "\n", "", "if", "max_f1", ">=", "hf1", ":", "\n", "          ", "HEQ", "+=", "1.", "\n", "", "else", ":", "\n", "          ", "good_dial", "=", "0.", "\n", "", "span_overlap_stats", "[", "max_overlap", "]", "+=", "1", "\n", "f1_stats", "[", "max_overlap", "]", ".", "append", "(", "max_f1", ")", "\n", "total_qs", "+=", "1.", "\n", "", "DHEQ", "+=", "good_dial", "\n", "total_dials", "+=", "1", "\n", "", "", "DHEQ_score", "=", "100.0", "*", "DHEQ", "/", "total_dials", "\n", "HEQ_score", "=", "100.0", "*", "HEQ", "/", "total_qs", "\n", "all_f1s", "=", "sum", "(", "f1_stats", ".", "values", "(", ")", ",", "[", "]", ")", "\n", "overall_f1", "=", "100.0", "*", "sum", "(", "all_f1s", ")", "/", "len", "(", "all_f1s", ")", "\n", "unfiltered_f1", "=", "100.0", "*", "sum", "(", "unfiltered_f1s", ")", "/", "len", "(", "unfiltered_f1s", ")", "\n", "yesno_score", "=", "(", "100.0", "*", "sum", "(", "yes_nos", ")", "/", "len", "(", "yes_nos", ")", ")", "\n", "followup_score", "=", "(", "100.0", "*", "sum", "(", "followups", ")", "/", "len", "(", "followups", ")", ")", "\n", "try", ":", "\n", "    ", "unanswerable_score", "=", "(", "100.0", "*", "sum", "(", "unanswerables", ")", "/", "len", "(", "unanswerables", ")", ")", "\n", "", "except", ":", "\n", "    ", "unanswerable_score", "=", "0.0", "\n", "", "metric_json", "=", "{", "\"unfiltered_f1\"", ":", "unfiltered_f1", ",", "\"f1\"", ":", "overall_f1", ",", "\"HEQ\"", ":", "HEQ_score", ",", "\"DHEQ\"", ":", "DHEQ_score", ",", "\"yes/no\"", ":", "yesno_score", ",", "\"followup\"", ":", "followup_score", ",", "\"unanswerable_acc\"", ":", "unanswerable_score", "}", "\n", "if", "verbose", ":", "\n", "    ", "print", "(", "\"=======================\"", ")", "\n", "display_counter", "(", "'Overlap Stats'", ",", "span_overlap_stats", ",", "f1_stats", ")", "\n", "", "print", "(", "\"=======================\"", ")", "\n", "print", "(", "'Overall F1: %.1f'", "%", "overall_f1", ")", "\n", "print", "(", "'Yes/No Accuracy : %.1f'", "%", "yesno_score", ")", "\n", "print", "(", "'Followup Accuracy : %.1f'", "%", "followup_score", ")", "\n", "print", "(", "'Unfiltered F1 ({0:d} questions): {1:.1f}'", ".", "format", "(", "len", "(", "unfiltered_f1s", ")", ",", "unfiltered_f1", ")", ")", "\n", "print", "(", "'Accuracy On Unanswerable Questions: {0:.1f} %% ({1:d} questions)'", ".", "format", "(", "unanswerable_score", ",", "len", "(", "unanswerables", ")", ")", ")", "\n", "print", "(", "'Human F1: %.1f'", "%", "(", "100.0", "*", "sum", "(", "human_f1", ")", "/", "len", "(", "human_f1", ")", ")", ")", "\n", "print", "(", "'Model F1 >= Human F1 (Questions): %d / %d, %.1f%%'", "%", "(", "HEQ", ",", "total_qs", ",", "100.0", "*", "HEQ", "/", "total_qs", ")", ")", "\n", "print", "(", "'Model F1 >= Human F1 (Dialogs): %d / %d, %.1f%%'", "%", "(", "DHEQ", ",", "total_dials", ",", "100.0", "*", "DHEQ", "/", "total_dials", ")", ")", "\n", "print", "(", "\"=======================\"", ")", "\n", "return", "metric_json", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.eval_fn_for_sig_test": [[226, 322], ["collections.Counter", "collections.defaultdict", "sum", "collections.defaultdict.values", "len", "len", "len", "len", "len", "print", "scorer.display_counter", "sum", "sum", "sum", "sum", "sum", "scorer.handle_cannot", "scorer.leave_one_out", "scorer.metric_max_over_ground_truths", "scorer.leave_one_out_max", "unfiltered_f1s.append", "human_f1.append", "yes_nos.append", "followups.append", "f1_stats[].append", "filtered_f1s.append", "f1_stats[].append", "yes_nos.append", "followups.append", "unfiltered_f1s.append", "unanswerables.append", "print", "print", "print", "print", "print", "unanswerables.append", "human_f1.append"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.display_counter", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.handle_cannot", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.leave_one_out", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.metric_max_over_ground_truths", "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.leave_one_out_max"], ["", "def", "eval_fn_for_sig_test", "(", "val_results", ",", "model_results", ",", "verbose", ")", ":", "\n", "  ", "span_overlap_stats", "=", "Counter", "(", ")", "\n", "sentence_overlap", "=", "0.", "\n", "para_overlap", "=", "0.", "\n", "total_qs", "=", "0.", "\n", "f1_stats", "=", "defaultdict", "(", "list", ")", "\n", "unfiltered_f1s", "=", "[", "]", "\n", "filtered_f1s", "=", "[", "]", "\n", "human_f1", "=", "[", "]", "\n", "HEQ", "=", "0.", "\n", "DHEQ", "=", "0.", "\n", "total_dials", "=", "0.", "\n", "yes_nos", "=", "[", "]", "\n", "followups", "=", "[", "]", "\n", "unanswerables", "=", "[", "]", "\n", "for", "p", "in", "val_results", ":", "\n", "    ", "for", "par", "in", "p", "[", "'paragraphs'", "]", ":", "\n", "      ", "did", "=", "par", "[", "'id'", "]", "\n", "qa_list", "=", "par", "[", "'qas'", "]", "\n", "good_dial", "=", "1.", "\n", "for", "qa", "in", "qa_list", ":", "\n", "        ", "q_idx", "=", "qa", "[", "'id'", "]", "\n", "val_spans", "=", "[", "anss", "[", "'text'", "]", "for", "anss", "in", "qa", "[", "'answers'", "]", "]", "\n", "val_spans", "=", "handle_cannot", "(", "val_spans", ")", "\n", "hf1", "=", "leave_one_out", "(", "val_spans", ")", "\n", "\n", "if", "did", "not", "in", "model_results", "or", "q_idx", "not", "in", "model_results", "[", "did", "]", ":", "\n", "# print(did, q_idx, 'no prediction for this dialogue id')", "\n", "          ", "good_dial", "=", "0", "\n", "f1_stats", "[", "'NO ANSWER'", "]", ".", "append", "(", "0.0", ")", "\n", "yes_nos", ".", "append", "(", "False", ")", "\n", "followups", ".", "append", "(", "False", ")", "\n", "if", "val_spans", "==", "[", "'CANNOTANSWER'", "]", ":", "\n", "            ", "unanswerables", ".", "append", "(", "0.0", ")", "\n", "", "total_qs", "+=", "1", "\n", "unfiltered_f1s", ".", "append", "(", "0.0", ")", "\n", "if", "hf1", ">=", "0.4", ":", "# args.min_f1:", "\n", "            ", "human_f1", ".", "append", "(", "hf1", ")", "\n", "", "continue", "\n", "\n", "", "pred_span", ",", "pred_yesno", ",", "pred_followup", "=", "model_results", "[", "did", "]", "[", "q_idx", "]", "\n", "\n", "max_overlap", ",", "_", "=", "metric_max_over_ground_truths", "(", "pred_span", ",", "val_spans", ",", "par", "[", "'context'", "]", ")", "\n", "max_f1", "=", "leave_one_out_max", "(", "pred_span", ",", "val_spans", ",", "par", "[", "'context'", "]", ")", "\n", "unfiltered_f1s", ".", "append", "(", "max_f1", ")", "\n", "\n", "# dont eval on low agreement instances", "\n", "if", "hf1", "<", "0.4", ":", "# args.min_f1:", "\n", "          ", "continue", "\n", "\n", "", "human_f1", ".", "append", "(", "hf1", ")", "\n", "yes_nos", ".", "append", "(", "pred_yesno", "==", "qa", "[", "'yesno'", "]", ")", "\n", "followups", ".", "append", "(", "pred_followup", "==", "qa", "[", "'followup'", "]", ")", "\n", "if", "val_spans", "==", "[", "'CANNOTANSWER'", "]", ":", "\n", "          ", "unanswerables", ".", "append", "(", "max_f1", ")", "\n", "", "if", "verbose", ":", "\n", "          ", "print", "(", "\"-\"", "*", "20", ")", "\n", "print", "(", "pred_span", ")", "\n", "print", "(", "val_spans", ")", "\n", "print", "(", "max_f1", ")", "\n", "print", "(", "\"-\"", "*", "20", ")", "\n", "", "if", "max_f1", ">=", "hf1", ":", "\n", "          ", "HEQ", "+=", "1.", "\n", "", "else", ":", "\n", "          ", "good_dial", "=", "0.", "\n", "", "span_overlap_stats", "[", "max_overlap", "]", "+=", "1", "\n", "f1_stats", "[", "max_overlap", "]", ".", "append", "(", "max_f1", ")", "\n", "filtered_f1s", ".", "append", "(", "max_f1", ")", "\n", "total_qs", "+=", "1.", "\n", "", "DHEQ", "+=", "good_dial", "\n", "total_dials", "+=", "1", "\n", "", "", "DHEQ_score", "=", "100.0", "*", "DHEQ", "/", "total_dials", "\n", "HEQ_score", "=", "100.0", "*", "HEQ", "/", "total_qs", "\n", "all_f1s", "=", "sum", "(", "f1_stats", ".", "values", "(", ")", ",", "[", "]", ")", "\n", "overall_f1", "=", "100.0", "*", "sum", "(", "all_f1s", ")", "/", "len", "(", "all_f1s", ")", "\n", "unfiltered_f1", "=", "100.0", "*", "sum", "(", "unfiltered_f1s", ")", "/", "len", "(", "unfiltered_f1s", ")", "\n", "yesno_score", "=", "(", "100.0", "*", "sum", "(", "yes_nos", ")", "/", "len", "(", "yes_nos", ")", ")", "\n", "followup_score", "=", "(", "100.0", "*", "sum", "(", "followups", ")", "/", "len", "(", "followups", ")", ")", "\n", "unanswerable_score", "=", "(", "100.0", "*", "sum", "(", "unanswerables", ")", "/", "len", "(", "unanswerables", ")", ")", "\n", "metric_json", "=", "{", "\"unfiltered_f1\"", ":", "unfiltered_f1", ",", "\"f1\"", ":", "overall_f1", ",", "\"HEQ\"", ":", "HEQ_score", ",", "\"DHEQ\"", ":", "DHEQ_score", ",", "\"yes/no\"", ":", "yesno_score", ",", "\"followup\"", ":", "followup_score", ",", "\"unanswerable_acc\"", ":", "unanswerable_score", "}", "\n", "if", "verbose", ":", "\n", "    ", "print", "(", "\"=======================\"", ")", "\n", "display_counter", "(", "'Overlap Stats'", ",", "span_overlap_stats", ",", "f1_stats", ")", "\n", "#   print(\"=======================\")", "\n", "#   print('Overall F1: %.1f' % overall_f1)", "\n", "#   print('Yes/No Accuracy : %.1f' % yesno_score)", "\n", "#   print('Followup Accuracy : %.1f' % followup_score)", "\n", "#   print('Unfiltered F1 ({0:d} questions): {1:.1f}'.format(len(unfiltered_f1s), unfiltered_f1))", "\n", "#   print('Accuracy On Unanswerable Questions: {0:.1f} %% ({1:d} questions)'.format(unanswerable_score, len(unanswerables)))", "\n", "#   print('Human F1: %.1f' % (100.0 * sum(human_f1) / len(human_f1)))", "\n", "#   print('Model F1 >= Human F1 (Questions): %d / %d, %.1f%%' % (HEQ, total_qs, 100.0 * HEQ / total_qs))", "\n", "#   print('Model F1 >= Human F1 (Dialogs): %d / %d, %.1f%%' % (DHEQ, total_dials, 100.0 * DHEQ / total_dials))", "\n", "#   print(\"=======================\")", "\n", "", "return", "metric_json", ",", "unfiltered_f1s", ",", "filtered_f1s", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.quac_eval": [[323, 353], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "collections.defaultdict", "open", "scorer.eval_fn", "json.load", "line.strip", "open", "json.loads", "zip", "len", "open", "json.dump", "line.strip", "[].split"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.eval_fn"], ["", "def", "quac_eval", "(", "val_file", ",", "output_final_prediction_file", ")", ":", "\n", "  ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--val_file'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'file containing validation results'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_output'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'Path to model output.'", ")", "\n", "parser", ".", "add_argument", "(", "'--o'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'Path to save score json'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_f1'", ",", "type", "=", "float", ",", "default", "=", "0.4", ",", "help", "=", "'file containing validation results'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'print individual scores'", ")", "\n", "args", ",", "unknown", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "val", "=", "json", ".", "load", "(", "open", "(", "val_file", ",", "'r'", ")", ")", "[", "'data'", "]", "\n", "preds", "=", "defaultdict", "(", "dict", ")", "\n", "total", "=", "0", "\n", "val_total", "=", "0", "\n", "for", "line", "in", "open", "(", "output_final_prediction_file", ",", "'r'", ")", ":", "\n", "    ", "if", "line", ".", "strip", "(", ")", ":", "\n", "      ", "pred_idx", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "dia_id", "=", "pred_idx", "[", "'qid'", "]", "[", "0", "]", ".", "split", "(", "\"_q#\"", ")", "[", "0", "]", "\n", "for", "qid", ",", "qspan", ",", "qyesno", ",", "qfollowup", "in", "zip", "(", "pred_idx", "[", "'qid'", "]", ",", "pred_idx", "[", "'best_span_str'", "]", ",", "pred_idx", "[", "'yesno'", "]", ",", "pred_idx", "[", "'followup'", "]", ")", ":", "\n", "        ", "preds", "[", "dia_id", "]", "[", "qid", "]", "=", "qspan", ",", "qyesno", ",", "qfollowup", "\n", "total", "+=", "1", "\n", "", "", "", "for", "p", "in", "val", ":", "\n", "    ", "for", "par", "in", "p", "[", "'paragraphs'", "]", ":", "\n", "      ", "did", "=", "par", "[", "'id'", "]", "\n", "qa_list", "=", "par", "[", "'qas'", "]", "\n", "val_total", "+=", "len", "(", "qa_list", ")", "\n", "", "", "metric_json", "=", "eval_fn", "(", "val", ",", "preds", ",", "args", ".", "verbose", ")", "\n", "if", "args", ".", "o", ":", "\n", "    ", "with", "open", "(", "args", ".", "o", ",", "'w'", ")", "as", "fout", ":", "\n", "      ", "json", ".", "dump", "(", "metric_json", ",", "fout", ")", "\n", "\n", "", "", "return", "metric_json", "\n", "\n"]], "home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.quac_eval_for_sig_test": [[354, 384], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_known_args", "collections.defaultdict", "open", "scorer.eval_fn_for_sig_test", "json.load", "line.strip", "open", "json.loads", "zip", "len", "open", "json.dump", "line.strip", "[].split"], "function", ["home.repos.pwc.inspect_result.prdwb_ws-orconvqa.None.scorer.eval_fn_for_sig_test"], ["", "def", "quac_eval_for_sig_test", "(", "val_file", ",", "output_final_prediction_file", ")", ":", "\n", "  ", "parser", "=", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'--val_file'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'file containing validation results'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_output'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'Path to model output.'", ")", "\n", "parser", ".", "add_argument", "(", "'--o'", ",", "type", "=", "str", ",", "required", "=", "False", ",", "help", "=", "'Path to save score json'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_f1'", ",", "type", "=", "float", ",", "default", "=", "0.4", ",", "help", "=", "'file containing validation results'", ")", "\n", "parser", ".", "add_argument", "(", "'--verbose'", ",", "action", "=", "'store_true'", ",", "help", "=", "'print individual scores'", ")", "\n", "args", ",", "unknown", "=", "parser", ".", "parse_known_args", "(", ")", "\n", "val", "=", "json", ".", "load", "(", "open", "(", "val_file", ",", "'r'", ")", ")", "[", "'data'", "]", "\n", "preds", "=", "defaultdict", "(", "dict", ")", "\n", "total", "=", "0", "\n", "val_total", "=", "0", "\n", "for", "line", "in", "open", "(", "output_final_prediction_file", ",", "'r'", ")", ":", "\n", "    ", "if", "line", ".", "strip", "(", ")", ":", "\n", "      ", "pred_idx", "=", "json", ".", "loads", "(", "line", ".", "strip", "(", ")", ")", "\n", "dia_id", "=", "pred_idx", "[", "'qid'", "]", "[", "0", "]", ".", "split", "(", "\"_q#\"", ")", "[", "0", "]", "\n", "for", "qid", ",", "qspan", ",", "qyesno", ",", "qfollowup", "in", "zip", "(", "pred_idx", "[", "'qid'", "]", ",", "pred_idx", "[", "'best_span_str'", "]", ",", "pred_idx", "[", "'yesno'", "]", ",", "pred_idx", "[", "'followup'", "]", ")", ":", "\n", "        ", "preds", "[", "dia_id", "]", "[", "qid", "]", "=", "qspan", ",", "qyesno", ",", "qfollowup", "\n", "total", "+=", "1", "\n", "", "", "", "for", "p", "in", "val", ":", "\n", "    ", "for", "par", "in", "p", "[", "'paragraphs'", "]", ":", "\n", "      ", "did", "=", "par", "[", "'id'", "]", "\n", "qa_list", "=", "par", "[", "'qas'", "]", "\n", "val_total", "+=", "len", "(", "qa_list", ")", "\n", "", "", "metric_json", ",", "unfiltered_f1s", ",", "filtered_f1s", "=", "eval_fn_for_sig_test", "(", "val", ",", "preds", ",", "args", ".", "verbose", ")", "\n", "if", "args", ".", "o", ":", "\n", "    ", "with", "open", "(", "args", ".", "o", ",", "'w'", ")", "as", "fout", ":", "\n", "      ", "json", ".", "dump", "(", "metric_json", ",", "fout", ")", "\n", "\n", "", "", "return", "metric_json", ",", "unfiltered_f1s", ",", "filtered_f1s", "\n", "\n"]]}