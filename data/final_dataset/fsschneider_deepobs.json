{"home.repos.pwc.inspect_result.fsschneider_deepobs.None.setup.readme": [[7, 10], ["open", "f.read"], "function", ["None"], ["def", "readme", "(", ")", ":", "\n", "    ", "with", "open", "(", "\"README.md\"", ")", "as", "f", ":", "\n", "        ", "return", "f", ".", "read", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_tolstoi.TolstoiTest.setUp": [[18, 22], ["deepobs.tensorflow.datasets.tolstoi"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Tolstoi dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "tolstoi", "=", "datasets", ".", "tolstoi", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_tolstoi.TolstoiTest.test_phase_not_trainable": [[23, 27], ["test_tolstoi.TolstoiTest.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "tolstoi", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_tolstoi.TolstoiTest.test_init_ops": [[28, 44], ["tensorflow.Session", "sess.run", "sess.run", "test_tolstoi.TolstoiTest.assertEqual", "test_tolstoi.TolstoiTest.assertEqual", "sess.run", "numpy.roll", "test_tolstoi.TolstoiTest.assertTrue", "numpy.allclose"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "tolstoi", ".", "train_init_op", ",", "self", ".", "tolstoi", ".", "test_init_op", ",", "\n", "self", ".", "tolstoi", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "tolstoi", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "self", ".", "tolstoi", ".", "_seq_length", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "self", ".", "tolstoi", ".", "_seq_length", ")", ")", "\n", "#  check if y is x shifted by one", "\n", "x_next", ",", "_", "=", "sess", ".", "run", "(", "self", ".", "tolstoi", ".", "batch", ")", "\n", "x_shift", "=", "np", ".", "roll", "(", "x_", ",", "-", "1", ",", "axis", "=", "1", ")", "\n", "x_shift", "[", ":", ",", "-", "1", "]", "=", "x_next", "[", ":", ",", "0", "]", "\n", "self", ".", "assertTrue", "(", "np", ".", "allclose", "(", "x_shift", ",", "y_", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_quadratic.QuadraticTest.setUp": [[17, 21], ["deepobs.tensorflow.datasets.quadratic"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Quadratic dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "quadratic", "=", "datasets", ".", "quadratic", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_quadratic.QuadraticTest.test_phase_not_trainable": [[22, 26], ["test_quadratic.QuadraticTest.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "quadratic", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_quadratic.QuadraticTest.test_init_ops": [[27, 37], ["tensorflow.Session", "sess.run", "sess.run", "test_quadratic.QuadraticTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "quadratic", ".", "train_init_op", ",", "self", ".", "quadratic", ".", "test_init_op", ",", "\n", "self", ".", "quadratic", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", "=", "sess", ".", "run", "(", "self", ".", "quadratic", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "self", ".", "quadratic", ".", "_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_cifar100.Cifar100Test.setUp": [[18, 22], ["deepobs.tensorflow.datasets.cifar100"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-100 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "200", "\n", "self", ".", "cifar100", "=", "datasets", ".", "cifar100", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_cifar100.Cifar100Test.test_phase_not_trainable": [[23, 27], ["test_cifar100.Cifar100Test.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "cifar100", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_cifar100.Cifar100Test.test_init_ops": [[28, 41], ["tensorflow.Session", "sess.run", "sess.run", "test_cifar100.Cifar100Test.assertEqual", "test_cifar100.Cifar100Test.assertEqual", "test_cifar100.Cifar100Test.assertTrue", "numpy.allclose", "numpy.sum", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "cifar100", ".", "train_init_op", ",", "self", ".", "cifar100", ".", "test_init_op", ",", "\n", "self", ".", "cifar100", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "cifar100", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "100", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "np", ".", "sum", "(", "y_", ",", "axis", "=", "1", ")", ",", "np", ".", "ones", "(", "self", ".", "batch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_text_datasets.IdentityDict.__missing__": [[85, 87], ["None"], "methods", ["None"], ["def", "__missing__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_text_datasets.display_text": [[17, 61], ["tensorflow.reset_default_graph", "dataset_cls", "display_text_datasets.load_label_dict", "matplotlib.figure", "range", "plt.figure.tight_layout", "plt.figure.suptitle", "plt.figure.show", "tensorflow.Session", "sess.run", "sess.run", "sess.run", "plt.figure.add_subplot", "fig.add_subplot.text", "fig.add_subplot.axis", "ValueError", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_image_datasets.load_label_dict", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["def", "display_text", "(", "dataset_cls", ",", "grid_size", "=", "5", ",", "phase", "=", "\"train\"", ")", ":", "\n", "    ", "\"\"\"Display text from a DeepOBS text dataset.\n\n  Args:\n    dataset_cls: The DeepOBS dataset class to display text from. Is assumed to\n        yield a tuple (x, y) of input and output text.\n    phase (str): Images from this phase ('train', 'train_eval', 'test') will be\n        displayed.\n  \"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "dataset", "=", "dataset_cls", "(", "batch_size", "=", "grid_size", "*", "grid_size", ")", "\n", "x", ",", "y", "=", "dataset", ".", "batch", "\n", "if", "phase", "==", "\"train\"", ":", "\n", "        ", "init_op", "=", "dataset", ".", "train_init_op", "\n", "", "elif", "phase", "==", "\"train_eval\"", ":", "\n", "        ", "init_op", "=", "dataset", ".", "train_eval_init_op", "\n", "", "elif", "phase", "==", "\"test\"", ":", "\n", "        ", "init_op", "=", "dataset", ".", "test_init_op", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Choose 'phase' from ['train', 'train_eval', 'test'].\"", ")", "\n", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "[", "x", ",", "y", "]", ")", "\n", "x_next", ",", "y_next", "=", "sess", ".", "run", "(", "[", "x", ",", "y", "]", ")", "# Next batch, will be plotted in red", "\n", "", "label_dict", "=", "load_label_dict", "(", "dataset_cls", ".", "__name__", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "i", "in", "range", "(", "grid_size", "*", "grid_size", ")", ":", "\n", "        ", "axis", "=", "fig", ".", "add_subplot", "(", "grid_size", ",", "grid_size", ",", "i", "+", "1", ")", "\n", "input_txt", "=", "''", ".", "join", "(", "[", "label_dict", "[", "char", "]", "for", "char", "in", "np", ".", "squeeze", "(", "x_", "[", "i", "]", ")", "]", ")", "\n", "output_txt", "=", "''", ".", "join", "(", "[", "label_dict", "[", "char", "]", "for", "char", "in", "np", ".", "squeeze", "(", "y_", "[", "i", "]", ")", "]", ")", "\n", "# Next Batch, to check if text continues", "\n", "input_next_txt", "=", "''", ".", "join", "(", "\n", "[", "label_dict", "[", "char", "]", "for", "char", "in", "np", ".", "squeeze", "(", "x_next", "[", "i", "]", ")", "]", ")", "\n", "output_next_txt", "=", "''", ".", "join", "(", "\n", "[", "label_dict", "[", "char", "]", "for", "char", "in", "np", ".", "squeeze", "(", "y_next", "[", "i", "]", ")", "]", ")", "\n", "txt", "=", "\"*INPUT* \\n\"", "+", "input_txt", "+", "\"\\n \\n *OUTPUT* \\n\"", "+", "output_txt", "+", "\"\\n \\n \\n *INPUT NEXT BATCH* \\n\"", "+", "input_next_txt", "+", "\"\\n \\n *OUTPUT NEXT BATCH* \\n\"", "+", "output_next_txt", "\n", "axis", ".", "text", "(", "0", ",", "0", ",", "txt", ",", "fontsize", "=", "10", ")", "\n", "axis", ".", "axis", "(", "\"off\"", ")", "\n", "", "fig", ".", "tight_layout", "(", "pad", "=", "0", ",", "w_pad", "=", "0", ",", "h_pad", "=", "0", ")", "\n", "fig", ".", "suptitle", "(", "dataset_cls", ".", "__name__", "+", "\" (\"", "+", "phase", "+", "\")\"", ")", "\n", "fig", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_text_datasets.load_label_dict": [[63, 80], ["os.path.join", "pickle.load", "display_text_datasets.IdentityDict", "deepobs.get_data_dir", "open"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "def", "load_label_dict", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"Get dict that translates from label number to humanly-readable class\n    (e.g. from 1 -> automobile on cifar 10)\n\n    Args:\n        dataset (str): Name of the dataset.\n\n    Returns:\n        dict: Dictionary that translates from class number to class label.\n\n    \"\"\"", "\n", "if", "dataset", "==", "\"tolstoi\"", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"tolstoi/vocab.pkl\"", ")", "\n", "label_dict", "=", "pickle", ".", "load", "(", "open", "(", "filepath", ",", "\"rb\"", ")", ")", "\n", "", "else", ":", "\n", "        ", "label_dict", "=", "IdentityDict", "(", ")", "\n", "", "return", "label_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_fmnist.FMNISTTest.setUp": [[18, 22], ["deepobs.tensorflow.datasets.fmnist"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Fashion-MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "fmnist", "=", "datasets", ".", "fmnist", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_fmnist.FMNISTTest.test_phase_not_trainable": [[23, 27], ["test_fmnist.FMNISTTest.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "fmnist", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_fmnist.FMNISTTest.test_init_ops": [[28, 41], ["tensorflow.Session", "sess.run", "sess.run", "test_fmnist.FMNISTTest.assertEqual", "test_fmnist.FMNISTTest.assertEqual", "test_fmnist.FMNISTTest.assertTrue", "numpy.allclose", "numpy.sum", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "fmnist", ".", "train_init_op", ",", "self", ".", "fmnist", ".", "test_init_op", ",", "\n", "self", ".", "fmnist", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "fmnist", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "10", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "np", ".", "sum", "(", "y_", ",", "axis", "=", "1", ")", ",", "np", ".", "ones", "(", "self", ".", "batch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_image_datasets.IdentityDict.__missing__": [[109, 111], ["None"], "methods", ["None"], ["def", "__missing__", "(", "self", ",", "key", ")", ":", "\n", "        ", "return", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_image_datasets.denormalize_image": [[16, 22], ["numpy.min", "numpy.max", "numpy.round().astype", "numpy.round"], "function", ["None"], ["def", "denormalize_image", "(", "img", ")", ":", "\n", "    ", "\"\"\"Convert a normalized (float) image back to unsigned 8-bit images.\"\"\"", "\n", "img", "-=", "np", ".", "min", "(", "img", ")", "\n", "img", "/=", "np", ".", "max", "(", "img", ")", "\n", "img", "*=", "255.0", "\n", "return", "np", ".", "round", "(", "img", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_image_datasets.display_images": [[24, 61], ["tensorflow.reset_default_graph", "dataset_cls", "display_image_datasets.load_label_dict", "matplotlib.figure", "range", "plt.figure.tight_layout", "plt.figure.suptitle", "plt.figure.show", "tensorflow.Session", "sess.run", "sess.run", "plt.figure.add_subplot", "numpy.squeeze", "fig.add_subplot.imshow", "fig.add_subplot.set_title", "fig.add_subplot.axis", "display_image_datasets.denormalize_image", "ValueError", "numpy.argmax"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_image_datasets.load_label_dict", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_image_datasets.denormalize_image"], ["", "def", "display_images", "(", "dataset_cls", ",", "grid_size", "=", "5", ",", "phase", "=", "\"train\"", ")", ":", "\n", "    ", "\"\"\"Display images from a DeepOBS data set.\n\n  Args:\n    dataset_cls: The DeepOBS dataset class to display images from. Is assumed to\n        yield a tuple (x, y) of images and one-hot label vectors.\n    grid_size (int): Will display grid_size**2 number of images.\n    phase (str): Images from this phase ('train', 'train_eval', 'test') will be\n        displayed.\n  \"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "dataset", "=", "dataset_cls", "(", "batch_size", "=", "grid_size", "*", "grid_size", ")", "\n", "x", ",", "y", "=", "dataset", ".", "batch", "\n", "if", "phase", "==", "\"train\"", ":", "\n", "        ", "init_op", "=", "dataset", ".", "train_init_op", "\n", "", "elif", "phase", "==", "\"train_eval\"", ":", "\n", "        ", "init_op", "=", "dataset", ".", "train_eval_init_op", "\n", "", "elif", "phase", "==", "\"test\"", ":", "\n", "        ", "init_op", "=", "dataset", ".", "test_init_op", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Choose 'phase' from ['train', 'train_eval', 'test'].\"", ")", "\n", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "[", "x", ",", "y", "]", ")", "\n", "", "label_dict", "=", "load_label_dict", "(", "dataset_cls", ".", "__name__", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "i", "in", "range", "(", "grid_size", "*", "grid_size", ")", ":", "\n", "        ", "axis", "=", "fig", ".", "add_subplot", "(", "grid_size", ",", "grid_size", ",", "i", "+", "1", ")", "\n", "img", "=", "np", ".", "squeeze", "(", "denormalize_image", "(", "x_", "[", "i", "]", ")", ")", "\n", "axis", ".", "imshow", "(", "img", ")", "\n", "# axis.set_title(\"Label {0:d}\".format(np.argmax(y_[i])))", "\n", "axis", ".", "set_title", "(", "label_dict", "[", "np", ".", "argmax", "(", "y_", "[", "i", "]", ")", "]", ")", "\n", "axis", ".", "axis", "(", "\"off\"", ")", "\n", "", "fig", ".", "tight_layout", "(", "pad", "=", "0", ",", "w_pad", "=", "0", ",", "h_pad", "=", "0", ")", "\n", "fig", ".", "suptitle", "(", "dataset_cls", ".", "__name__", "+", "\" (\"", "+", "phase", "+", "\")\"", ")", "\n", "fig", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.display_image_datasets.load_label_dict": [[63, 104], ["open", "lookup_file.readlines", "os.path.join", "open", "lookup_file.readlines", "dict", "deepobs.get_data_dir", "os.path.join", "os.path.join", "display_image_datasets.IdentityDict", "deepobs.get_data_dir", "os.path.realpath", "open", "os.path.join", "line.rstrip", "os.getcwd", "os.path.dirname"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "def", "load_label_dict", "(", "dataset", ")", ":", "\n", "    ", "\"\"\"Get dict that translates from label number to humanly-readable class\n    (e.g. from 1 -> automobile on cifar 10)\n\n    Args:\n        dataset (str): Name of the dataset.\n\n    Returns:\n        dict: Dictionary that translates from class number to class label.\n\n    \"\"\"", "\n", "if", "dataset", "==", "\"cifar10\"", ":", "\n", "        ", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\n", "\"cifar-10/batches.meta.txt\"", ")", ")", "as", "lookup_file", ":", "\n", "            ", "label_dict", "=", "lookup_file", ".", "readlines", "(", ")", "\n", "", "", "elif", "dataset", "==", "\"cifar100\"", ":", "\n", "        ", "with", "open", "(", "\n", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\n", "\"cifar-100/fine_label_names.txt\"", ")", ")", "as", "lookup_file", ":", "\n", "            ", "label_dict", "=", "lookup_file", ".", "readlines", "(", ")", "\n", "", "", "elif", "dataset", "==", "\"fmnist\"", ":", "\n", "        ", "label_dict", "=", "dict", "(", "[", "(", "0", ",", "\"T-shirt\"", ")", ",", "(", "1", ",", "\"Trouser\"", ")", ",", "(", "2", ",", "\"Pullover\"", ")", ",", "\n", "(", "3", ",", "\"Dress\"", ")", ",", "(", "4", ",", "\"Coat\"", ")", ",", "(", "5", ",", "\"Sandal\"", ")", ",", "\n", "(", "6", ",", "\"Shirt\"", ")", ",", "(", "7", ",", "\"Sneaker\"", ")", ",", "(", "8", ",", "\"Bag\"", ")", ",", "\n", "(", "9", ",", "\"Ankle boot\"", ")", "]", ")", "\n", "", "elif", "dataset", "==", "\"imagenet\"", ":", "\n", "        ", "label_file", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "realpath", "(", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "os", ".", "path", ".", "dirname", "(", "__file__", ")", ")", ")", ",", "\n", "\"imagenet_labels.txt\"", ")", "\n", "# Read from text file", "\n", "label_dict", "=", "{", "}", "\n", "i", "=", "0", "\n", "with", "open", "(", "label_file", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "label_dict", "[", "i", "]", "=", "line", ".", "rstrip", "(", ")", "\n", "i", "+=", "1", "\n", "", "", "", "else", ":", "\n", "        ", "label_dict", "=", "IdentityDict", "(", ")", "\n", "", "return", "label_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_mnist.MNISTTest.setUp": [[18, 22], ["deepobs.tensorflow.datasets.mnist"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "mnist", "=", "datasets", ".", "mnist", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_mnist.MNISTTest.test_phase_not_trainable": [[23, 27], ["test_mnist.MNISTTest.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "mnist", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_mnist.MNISTTest.test_init_ops": [[28, 41], ["tensorflow.Session", "sess.run", "sess.run", "test_mnist.MNISTTest.assertEqual", "test_mnist.MNISTTest.assertEqual", "test_mnist.MNISTTest.assertTrue", "numpy.allclose", "numpy.sum", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "mnist", ".", "train_init_op", ",", "self", ".", "mnist", ".", "test_init_op", ",", "\n", "self", ".", "mnist", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "mnist", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "28", ",", "28", ",", "1", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "10", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "np", ".", "sum", "(", "y_", ",", "axis", "=", "1", ")", ",", "np", ".", "ones", "(", "self", ".", "batch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_svhn.SVHNTest.setUp": [[18, 22], ["deepobs.tensorflow.datasets.svhn"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up SVHN dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "25", "\n", "self", ".", "svhn", "=", "datasets", ".", "svhn", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_svhn.SVHNTest.test_phase_not_trainable": [[23, 27], ["test_svhn.SVHNTest.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "svhn", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_svhn.SVHNTest.test_init_ops": [[28, 41], ["tensorflow.Session", "sess.run", "sess.run", "test_svhn.SVHNTest.assertEqual", "test_svhn.SVHNTest.assertEqual", "test_svhn.SVHNTest.assertTrue", "numpy.allclose", "numpy.sum", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "svhn", ".", "train_init_op", ",", "self", ".", "svhn", ".", "test_init_op", ",", "\n", "self", ".", "svhn", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "svhn", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "10", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "np", ".", "sum", "(", "y_", ",", "axis", "=", "1", ")", ",", "np", ".", "ones", "(", "self", ".", "batch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_cifar10.Cifar10Test.setUp": [[18, 22], ["deepobs.tensorflow.datasets.cifar10"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-10 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar10", "=", "datasets", ".", "cifar10", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_cifar10.Cifar10Test.test_phase_not_trainable": [[23, 27], ["test_cifar10.Cifar10Test.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "cifar10", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_cifar10.Cifar10Test.test_init_ops": [[28, 41], ["tensorflow.Session", "sess.run", "sess.run", "test_cifar10.Cifar10Test.assertEqual", "test_cifar10.Cifar10Test.assertEqual", "test_cifar10.Cifar10Test.assertTrue", "numpy.allclose", "numpy.sum", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "cifar10", ".", "train_init_op", ",", "self", ".", "cifar10", ".", "test_init_op", ",", "\n", "self", ".", "cifar10", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "cifar10", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "32", ",", "32", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "10", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "np", ".", "sum", "(", "y_", ",", "axis", "=", "1", ")", ",", "np", ".", "ones", "(", "self", ".", "batch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_imagenet.ImagenetTest.setUp": [[18, 22], ["deepobs.tensorflow.datasets.imagenet"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up ImageNet dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "1000", "\n", "self", ".", "imagenet", "=", "datasets", ".", "imagenet", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_imagenet.ImagenetTest.test_phase_not_trainable": [[23, 27], ["test_imagenet.ImagenetTest.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "imagenet", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_imagenet.ImagenetTest.test_init_ops": [[28, 41], ["tensorflow.Session", "sess.run", "sess.run", "test_imagenet.ImagenetTest.assertEqual", "test_imagenet.ImagenetTest.assertEqual", "test_imagenet.ImagenetTest.assertTrue", "numpy.allclose", "numpy.sum", "numpy.ones"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "imagenet", ".", "train_init_op", ",", "self", ".", "imagenet", ".", "test_init_op", ",", "\n", "self", ".", "imagenet", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "imagenet", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "224", ",", "224", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", "1001", ")", ")", "\n", "self", ".", "assertTrue", "(", "\n", "np", ".", "allclose", "(", "np", ".", "sum", "(", "y_", ",", "axis", "=", "1", ")", ",", "np", ".", "ones", "(", "self", ".", "batch_size", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_two_d.Two_dTest.setUp": [[17, 21], ["deepobs.tensorflow.datasets.two_d"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up 2D dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "two_d", "=", "datasets", ".", "two_d", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_two_d.Two_dTest.test_phase_not_trainable": [[22, 26], ["test_two_d.Two_dTest.assertFalse"], "methods", ["None"], ["", "def", "test_phase_not_trainable", "(", "self", ")", ":", "\n", "        ", "\"\"\"Makes sure the ``phase`` variable is not trainable.\"\"\"", "\n", "phase", "=", "self", ".", "two_d", ".", "phase", "\n", "self", ".", "assertFalse", "(", "phase", ".", "trainable", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.test_two_d.Two_dTest.test_init_ops": [[27, 38], ["tensorflow.Session", "sess.run", "sess.run", "test_two_d.Two_dTest.assertEqual", "test_two_d.Two_dTest.assertEqual"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "for", "init_op", "in", "[", "\n", "self", ".", "two_d", ".", "train_init_op", ",", "self", ".", "two_d", ".", "test_init_op", ",", "\n", "self", ".", "two_d", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "x_", ",", "y_", "=", "sess", ".", "run", "(", "self", ".", "two_d", ".", "batch", ")", "\n", "self", ".", "assertEqual", "(", "x_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertEqual", "(", "y_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.tolstoi.tolstoi.__init__": [[41, 57], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "seq_length", "=", "50", ",", "train_eval_size", "=", "653237", ")", ":", "\n", "        ", "\"\"\"Creates a new Tolstoi instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size the remainder is dropped in each\n          epoch (after shuffling).\n      seq_length (int): Sequence length to be modeled in each step.\n          Defaults to ``50``.\n      train_eval_size (int): Size of the train eval dataset.\n          Defaults to ``653 237``, the size of the test set.\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"tolstoi\"", "\n", "self", ".", "_seq_length", "=", "seq_length", "\n", "self", ".", "_train_eval_size", "=", "train_eval_size", "\n", "super", "(", "tolstoi", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.tolstoi.tolstoi._make_dataset": [[58, 95], ["numpy.load", "int", "numpy.split", "numpy.split", "numpy.array", "numpy.array", "numpy.floor", "ValueError", "x.reshape", "y.reshape", "tensorflow.name_scope", "tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "data.prefetch.prefetch.prefetch", "numpy.size"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ",", "filepath", ")", ":", "\n", "        ", "\"\"\"Creates a Tolstoi data set (helper used by ``.make_*_datset`` below).\n\n    Args:\n        filepath (str): Filepath to the .npy file containing the data set.\n\n    Returns:\n        A tf.data.Dataset yielding batches of Tolstoi data.\n    \"\"\"", "\n", "# Load the array of character ids, determine the number of batches that", "\n", "# can be produced, given batch size and sequence lengh", "\n", "arr", "=", "np", ".", "load", "(", "filepath", ")", "\n", "num_batches", "=", "int", "(", "\n", "np", ".", "floor", "(", "\n", "(", "np", ".", "size", "(", "arr", ")", "-", "1", ")", "/", "(", "self", ".", "_batch_size", "*", "self", ".", "_seq_length", ")", ")", ")", "\n", "if", "num_batches", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"This dataset is to small to use with this batch size \"", "\n", "\"and sequence length.\"", ")", "\n", "\n", "# Create input and output, where output is the text shifted by one", "\n", "# character", "\n", "", "x", "=", "arr", "[", ":", "num_batches", "*", "self", ".", "_batch_size", "*", "self", ".", "_seq_length", "]", "\n", "y", "=", "arr", "[", "1", ":", "num_batches", "*", "self", ".", "_batch_size", "*", "self", ".", "_seq_length", "+", "1", "]", "\n", "\n", "# Split into batches and put into arrays X, Y, such that X[i,:] is the", "\n", "# i-th batch", "\n", "x_batches", "=", "np", ".", "split", "(", "x", ".", "reshape", "(", "self", ".", "_batch_size", ",", "-", "1", ")", ",", "num_batches", ",", "1", ")", "\n", "y_batches", "=", "np", ".", "split", "(", "y", ".", "reshape", "(", "self", ".", "_batch_size", ",", "-", "1", ")", ",", "num_batches", ",", "1", ")", "\n", "X", "=", "np", ".", "array", "(", "x_batches", ")", "\n", "Y", "=", "np", ".", "array", "(", "y_batches", ")", "\n", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "X", ",", "Y", ")", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.tolstoi.tolstoi._make_train_dataset": [[96, 104], ["os.path.join", "tolstoi.tolstoi._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the Tolstoi training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"tolstoi\"", ",", "\"train.npy\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "filepath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.tolstoi.tolstoi._make_train_eval_dataset": [[105, 113], ["tolstoi.tolstoi._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the Tolstoi train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "\n", "self", ".", "_train_eval_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.tolstoi.tolstoi._make_test_dataset": [[114, 122], ["os.path.join", "tolstoi.tolstoi._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the Tolstoi test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"tolstoi\"", ",", "\"test.npy\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "filepath", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar100.cifar100.__init__": [[40, 60], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "\n", "batch_size", ",", "\n", "data_augmentation", "=", "True", ",", "\n", "train_eval_size", "=", "10000", ")", ":", "\n", "        ", "\"\"\"Creates a new CIFAR-100 instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size (``50 000`` for train, ``10 000``\n          for test) the remainder is dropped in each epoch (after shuffling).\n      data_augmentation (bool): If ``True`` some data augmentation operations\n          (random crop window, horizontal flipping, lighting augmentation) are\n          applied to the training data (but not the test data).\n      train_eval_size (int): Size of the train eval data set.\n          Defaults to ``10 000`` the size of the test set.\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"cifar100\"", "\n", "self", ".", "_data_augmentation", "=", "data_augmentation", "\n", "self", ".", "_train_eval_size", "=", "train_eval_size", "\n", "super", "(", "cifar100", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar100.cifar100._make_dataset": [[61, 130], ["tensorflow.reshape", "tensorflow.cast", "tensorflow.reshape", "tensorflow.cast", "tensorflow.image.per_image_standardization", "tensorflow.squeeze", "tensorflow.name_scope", "tensorflow.decode_raw", "tensorflow.slice", "tensorflow.slice", "tensorflow.transpose", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_contrast", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.one_hot", "tensorflow.device", "tensorflow.matching_files", "tensorflow.random_shuffle", "tensorflow.data.FixedLengthRecordDataset", "data.shuffle.shuffle.map", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ",", "\n", "binaries_fname_pattern", ",", "\n", "data_augmentation", "=", "False", ",", "\n", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates a CIFAR-100 data set (helper used by ``.make_*_datset`` below).\n\n    Args:\n        binaries_fname_pattern (str): Pattern of the ``.bin`` files from which\n            to load images and labels (e.g. ``some/path/data_batch_*.bin``).\n        data_augmentation (bool): Whether to apply data augmentation operations.\n        shuffle (bool):  Switch to turn on or off shuffling of the data set.\n            Defaults to ``True``.\n\n    Returns:\n        A tf.data.Dataset yielding batches of CIFAR-100 data.\n    \"\"\"", "\n", "# Set number of bytes to read.", "\n", "label_bytes", "=", "1", "\n", "label_offset", "=", "1", "\n", "num_classes", "=", "100", "\n", "depth", "=", "3", "\n", "image_size", "=", "32", "\n", "image_bytes", "=", "image_size", "*", "image_size", "*", "depth", "\n", "record_bytes", "=", "label_bytes", "+", "label_offset", "+", "image_bytes", "\n", "\n", "def", "parse_func", "(", "raw_record", ")", ":", "\n", "            ", "\"\"\"Function parsing data from raw binary records.\"\"\"", "\n", "# Decode raw_record.", "\n", "record", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "decode_raw", "(", "raw_record", ",", "tf", ".", "uint8", ")", ",", "[", "record_bytes", "]", ")", "\n", "label", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "slice", "(", "record", ",", "[", "label_offset", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "depth_major", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "slice", "(", "record", ",", "[", "label_bytes", "]", ",", "[", "image_bytes", "]", ")", ",", "\n", "[", "depth", ",", "image_size", ",", "image_size", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "tf", ".", "transpose", "(", "depth_major", ",", "[", "1", ",", "2", ",", "0", "]", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "# Add image pre-processing.", "\n", "if", "data_augmentation", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "\n", "image", ",", "image_size", "+", "4", ",", "image_size", "+", "4", ")", "\n", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "32", ",", "32", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "63.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "", "else", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "32", ",", "32", ")", "\n", "\n", "", "image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", "\n", "label", "=", "tf", ".", "squeeze", "(", "tf", ".", "one_hot", "(", "label", ",", "depth", "=", "num_classes", ")", ")", "\n", "return", "image", ",", "label", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "filenames", "=", "tf", ".", "matching_files", "(", "binaries_fname_pattern", ")", "\n", "filenames", "=", "tf", ".", "random_shuffle", "(", "filenames", ")", "\n", "data", "=", "tf", ".", "data", ".", "FixedLengthRecordDataset", "(", "\n", "filenames", "=", "filenames", ",", "record_bytes", "=", "record_bytes", ")", "\n", "data", "=", "data", ".", "map", "(", "\n", "parse_func", ",", "\n", "num_parallel_calls", "=", "(", "8", "if", "data_augmentation", "else", "4", ")", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "\n", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "\n", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar100.cifar100._make_train_dataset": [[131, 140], ["os.path.join", "cifar100.cifar100._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the CIFAR-100 training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"cifar-100\"", ",", "\"train.bin\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "data_augmentation", "=", "self", ".", "_data_augmentation", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar100.cifar100._make_train_eval_dataset": [[141, 149], ["cifar100.cifar100._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the CIFAR-100 train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "\n", "self", ".", "_train_eval_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar100.cifar100._make_test_dataset": [[150, 159], ["os.path.join", "cifar100.cifar100._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the CIFAR-100 test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"cifar-100\"", ",", "\"test.bin\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "data_augmentation", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist.__init__": [[41, 56], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "\n", "batch_size", ",", "\n", "train_eval_size", "=", "10000", ")", ":", "\n", "        ", "\"\"\"Creates a new MNIST instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size (``60 000`` for train, ``10 000``\n          for test) the remainder is dropped in each epoch (after shuffling).\n      train_eval_size (int): Size of the train eval data set.\n          Defaults to ``10 000`` the size of the test set.\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"mnist\"", "\n", "self", ".", "_train_eval_size", "=", "train_eval_size", "\n", "super", "(", "mnist", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist._make_dataset": [[57, 78], ["mnist.mnist._read_mnist_data", "tensorflow.name_scope", "tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read_mnist_data"], ["", "def", "_make_dataset", "(", "self", ",", "images_file", ",", "labels_file", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates a MNIST data set (helper used by ``.make_*_datset`` below).\n\n    Args:\n        images_file (str): Path to the images in compressed ``.gz`` files.\n        labels_file (str): Path to the labels in compressed ``.gz`` files.\n        shuffle (bool):  Switch to turn on or off shuffling of the data set.\n            Defaults to ``True``.\n\n    Returns:\n        A tf.data.Dataset yielding batches of MNIST data.\n    \"\"\"", "\n", "X", ",", "y", "=", "self", ".", "_read_mnist_data", "(", "images_file", ",", "labels_file", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"mnist\"", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "X", ",", "y", ")", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist._make_train_dataset": [[79, 92], ["config.get_data_dir", "os.path.join", "os.path.join", "mnist.mnist._make_dataset"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the MNIST training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "data_dir", "=", "config", ".", "get_data_dir", "(", ")", "\n", "train_images_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"mnist\"", ",", "\n", "\"train-images-idx3-ubyte.gz\"", ")", "\n", "train_labels_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"mnist\"", ",", "\n", "\"train-labels-idx1-ubyte.gz\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "train_images_file", ",", "train_labels_file", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist._make_train_eval_dataset": [[93, 101], ["mnist.mnist._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the MNIST train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "\n", "self", ".", "_train_eval_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist._make_test_dataset": [[102, 116], ["config.get_data_dir", "os.path.join", "os.path.join", "mnist.mnist._make_dataset"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the MNIST test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "data_dir", "=", "config", ".", "get_data_dir", "(", ")", "\n", "test_images_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"mnist\"", ",", "\n", "\"t10k-images-idx3-ubyte.gz\"", ")", "\n", "test_labels_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"mnist\"", ",", "\n", "\"t10k-labels-idx1-ubyte.gz\"", ")", "\n", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "test_images_file", ",", "test_labels_file", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist._read_mnist_data": [[119, 161], ["tensorflow.gfile.Open", "print", "tensorflow.gfile.Open", "print", "gzip.GzipFile", "mnist.mnist._read32", "mnist.mnist._read32", "mnist.mnist._read32", "mnist.mnist._read32", "bytestream.read", "numpy.frombuffer", "numpy.frombuffer.reshape", "gzip.GzipFile", "mnist.mnist._read32", "mnist.mnist._read32", "bytestream.read", "numpy.frombuffer", "mnist.mnist._dense_to_one_hot", "y.astype.astype.astype", "ValueError", "np.frombuffer.reshape.astype", "ValueError"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._dense_to_one_hot"], ["", "def", "_read_mnist_data", "(", "self", ",", "images_file", ",", "labels_file", ")", ":", "\n", "        ", "\"\"\"Read the MNIST images and labels from the downloaded files.\n\n        Args:\n            images_file (str): Path to the images in compressed ``.gz`` files.\n            labels_file (str): Path to the labels in compressed ``.gz`` files.\n\n        Returns:\n            tupel: Tupel consisting of all the images (`X`) and the labels (`y`).\n\n        \"\"\"", "\n", "# Load images from images_file", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "images_file", ",", "'rb'", ")", "as", "img_file", ":", "\n", "            ", "print", "(", "'Extracting %s'", "%", "img_file", ".", "name", ")", "\n", "with", "gzip", ".", "GzipFile", "(", "fileobj", "=", "img_file", ")", "as", "bytestream", ":", "\n", "                ", "magic", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "if", "magic", "!=", "2051", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'Invalid magic number %d in MNIST image file: %s'", "%", "\n", "(", "magic", ",", "img_file", ".", "name", ")", ")", "\n", "", "num_images", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "rows", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "cols", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "rows", "*", "cols", "*", "num_images", ")", "\n", "data", "=", "np", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "X", "=", "data", ".", "reshape", "(", "num_images", ",", "rows", ",", "cols", ",", "1", ")", "\n", "X", "=", "X", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.0", "\n", "# Load labels from labels file", "\n", "", "", "with", "tf", ".", "gfile", ".", "Open", "(", "labels_file", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "print", "(", "'Extracting %s'", "%", "f", ".", "name", ")", "\n", "with", "gzip", ".", "GzipFile", "(", "fileobj", "=", "f", ")", "as", "bytestream", ":", "\n", "                ", "magic", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "if", "magic", "!=", "2049", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'Invalid magic number %d in MNIST label file: %s'", "%", "\n", "(", "magic", ",", "f", ".", "name", ")", ")", "\n", "", "num_items", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "num_items", ")", "\n", "y", "=", "np", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "y", "=", "self", ".", "_dense_to_one_hot", "(", "y", ",", "10", ")", "\n", "y", "=", "y", ".", "astype", "(", "np", ".", "int32", ")", "\n", "", "", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist._read32": [[162, 174], ["numpy.dtype().newbyteorder", "numpy.frombuffer", "numpy.dtype", "bytestream.read"], "methods", ["None"], ["", "def", "_read32", "(", "self", ",", "bytestream", ")", ":", "\n", "        ", "\"\"\"Helper function to read a bytestream.\n\n        Args:\n            bytestream (bytestream): Input bytestream.\n\n        Returns:\n            np.array: Bytestream as a np array.\n\n        \"\"\"", "\n", "dtype", "=", "np", ".", "dtype", "(", "np", ".", "uint32", ")", ".", "newbyteorder", "(", "'>'", ")", "\n", "return", "np", ".", "frombuffer", "(", "bytestream", ".", "read", "(", "4", ")", ",", "dtype", "=", "dtype", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.mnist.mnist._dense_to_one_hot": [[175, 182], ["numpy.zeros", "numpy.arange", "labels_dense.ravel"], "methods", ["None"], ["", "def", "_dense_to_one_hot", "(", "self", ",", "labels_dense", ",", "num_classes", ")", ":", "\n", "        ", "\"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"", "\n", "num_labels", "=", "labels_dense", ".", "shape", "[", "0", "]", "\n", "index_offset", "=", "np", ".", "arange", "(", "num_labels", ")", "*", "num_classes", "\n", "labels_one_hot", "=", "np", ".", "zeros", "(", "(", "num_labels", ",", "num_classes", ")", ")", "\n", "labels_one_hot", ".", "flat", "[", "index_offset", "+", "labels_dense", ".", "ravel", "(", ")", "]", "=", "1", "\n", "return", "labels_one_hot", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet.__init__": [[44, 63], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "\n", "batch_size", ",", "\n", "data_augmentation", "=", "True", ",", "\n", "train_eval_size", "=", "50000", ")", ":", "\n", "        ", "\"\"\"Creates a new ImageNet instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size the remainder is dropped in each\n          epoch (after shuffling).\n      data_augmentation (bool): If ``True`` some data augmentation operations\n          (random crop window, horizontal flipping, lighting augmentation) are\n          applied to the training data (but not the test data).\n      train_eval_size (int): Size of the train eval dataset (default: 10k).\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"imagenet\"", "\n", "self", ".", "_data_augmentation", "=", "data_augmentation", "\n", "self", ".", "_train_eval_size", "=", "train_eval_size", "\n", "super", "(", "imagenet", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._make_dataset": [[64, 143], ["imagenet.imagenet._parse_example_proto", "imagenet.imagenet._decode_jpeg", "imagenet.imagenet._aspect_preserving_resize", "tensorflow.reshape", "tensorflow.squeeze", "tensorflow.name_scope", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.random_crop", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.image.random_flip_left_right", "imagenet.imagenet._color_distortion", "tensorflow.image.per_image_standardization", "tensorflow.one_hot", "tensorflow.device", "tensorflow.matching_files", "tensorflow.random_shuffle", "tensorflow.data.TFRecordDataset", "data.shuffle.shuffle.map", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._parse_example_proto", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._decode_jpeg", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._aspect_preserving_resize", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._color_distortion"], ["", "def", "_make_dataset", "(", "self", ",", "\n", "pattern", ",", "\n", "per_image_standardization", "=", "True", ",", "\n", "random_crop", "=", "False", ",", "\n", "random_flip_left_right", "=", "False", ",", "\n", "distort_color", "=", "False", ",", "\n", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates an ImageNet data set (helper used by ``.make_*_datset`` below).\n\n        Args:\n            pattern (str): Pattern of the files from which\n                to load images and labels (e.g. ``some/path/train-00000-of-01024``).\n            per_image_standardization (bool): Switch to standardize each image\n                to have zero mean and unit norm. Defaults to ``True``.\n            random_crop (bool): Switch if random crops should be used.\n                Defaults to ``False``.\n            random_flip_left_right (bool): Switch to randomly flip the images\n                horizontally. Defaults to ``False``.\n            distort_color (bool): Switch to use random brightness, saturation,\n                hue and contrast on each image. Defaults to ``False``.\n            shuffle (bool):  Switch to turn on or off shuffling of the data set.\n                Defaults to ``True``.\n\n        Returns:\n            A tf.data.Dataset yielding batches of ImageNet data.\n        \"\"\"", "\n", "num_classes", "=", "1001", "# Class 0 is for Background. Therefore we have 1001", "\n", "\n", "def", "parse_func", "(", "example_serialized", ")", ":", "\n", "            ", "\"\"\"Parse function depending on the above arguments and map the\n            data set through it\n            \"\"\"", "\n", "# Parse example proto, decode image and resize while preserving aspect", "\n", "image_buffer", ",", "label", ",", "_", "=", "self", ".", "_parse_example_proto", "(", "\n", "example_serialized", ")", "\n", "image", "=", "self", ".", "_decode_jpeg", "(", "image_buffer", ")", "\n", "image", "=", "self", ".", "_aspect_preserving_resize", "(", "\n", "image", ",", "target_smaller_side", "=", "256", ")", "\n", "\n", "# Crop to 224x224, either randomly or centered according to arguments", "\n", "if", "random_crop", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "256", ",", "256", ")", "\n", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "224", ",", "224", ",", "3", "]", ")", "\n", "", "else", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "224", ",", "224", ")", "\n", "\n", "# Optionally perform random flip", "\n", "", "if", "random_flip_left_right", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "\n", "# Optionally distort color", "\n", "", "if", "distort_color", ":", "\n", "                ", "image", "=", "self", ".", "_color_distortion", "(", "image", ")", "\n", "\n", "# Normalize", "\n", "", "if", "per_image_standardization", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", "\n", "\n", "# Convert label to shape [] (instead of) [1,] such that the label vector for", "\n", "# a mini-batch will later be of shape [batch_size,]", "\n", "", "label", "=", "tf", ".", "reshape", "(", "label", ",", "[", "]", ")", "\n", "# Label to one-hot vector", "\n", "label", "=", "tf", ".", "squeeze", "(", "tf", ".", "one_hot", "(", "label", ",", "depth", "=", "num_classes", ")", ")", "\n", "\n", "return", "image", ",", "label", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "filenames", "=", "tf", ".", "matching_files", "(", "pattern", ")", "\n", "filenames", "=", "tf", ".", "random_shuffle", "(", "filenames", ")", "\n", "data", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "filenames", ")", "\n", "data", "=", "data", ".", "map", "(", "\n", "parse_func", ",", "\n", "num_parallel_calls", "=", "(", "8", "if", "self", ".", "_data_augmentation", "else", "4", ")", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._make_train_dataset": [[144, 158], ["os.path.join", "imagenet.imagenet._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the ImageNet training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"imagenet\"", ",", "\"train-*\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "\n", "per_image_standardization", "=", "True", ",", "\n", "random_crop", "=", "self", ".", "_data_augmentation", ",", "\n", "random_flip_left_right", "=", "self", ".", "_data_augmentation", ",", "\n", "distort_color", "=", "False", ",", "\n", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._make_train_eval_dataset": [[159, 167], ["imagenet.imagenet._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the ImageNet train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "\n", "self", ".", "_train_eval_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._make_test_dataset": [[168, 183], ["os.path.join", "imagenet.imagenet._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the ImageNet test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"imagenet\"", ",", "\n", "\"validation-*\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "\n", "per_image_standardization", "=", "True", ",", "\n", "random_crop", "=", "False", ",", "\n", "random_flip_left_right", "=", "False", ",", "\n", "distort_color", "=", "False", ",", "\n", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._parse_example_proto": [[184, 223], ["tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature"], "methods", ["None"], ["", "def", "_parse_example_proto", "(", "self", ",", "example_serialized", ")", ":", "\n", "        ", "\"\"\"Parses an Example proto containing a training example of an image.\n        The output of the build_image_data.py image preprocessing script is a\n        dataset containing serialized Example protocol buffers. Each Example\n        proto contains the following fields:\n        image/height: 462\n        image/width: 581\n        image/colorspace: 'RGB'\n        image/channels: 3\n        image/class/label: 615\n        image/class/synset: 'n03623198'\n        image/class/text: 'knee pad'\n        image/format: 'JPEG'\n        image/filename: 'ILSVRC2012_val_00041207.JPEG'\n        image/encoded: <JPEG encoded string>\n\n        Args:\n          example_serialized (tf.string): Scalar Tensor tf.string containing a\n          serialized Example protocol buffer.\n\n        Returns:\n          tupel: Tupel of image_buffer (tf.string) containing the contents of a\n          JPEG file, the label (tf.int32) containing the label and text\n          (tf.string) containing the human-readable label.\n        \"\"\"", "\n", "# Dense features in Example proto.", "\n", "feature_map", "=", "{", "\n", "'image/encoded'", ":", "\n", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "'image/class/label'", ":", "\n", "tf", ".", "FixedLenFeature", "(", "[", "1", "]", ",", "dtype", "=", "tf", ".", "int64", ",", "default_value", "=", "-", "1", ")", ",", "\n", "'image/class/text'", ":", "\n", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "dtype", "=", "tf", ".", "string", ",", "default_value", "=", "''", ")", ",", "\n", "}", "\n", "\n", "features", "=", "tf", ".", "parse_single_example", "(", "example_serialized", ",", "feature_map", ")", "\n", "label", "=", "tf", ".", "cast", "(", "features", "[", "'image/class/label'", "]", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "\n", "return", "features", "[", "'image/encoded'", "]", ",", "label", ",", "features", "[", "'image/class/text'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._decode_jpeg": [[224, 246], ["tensorflow.name_scope", "tensorflow.image.decode_jpeg", "tensorflow.image.convert_image_dtype"], "methods", ["None"], ["", "def", "_decode_jpeg", "(", "self", ",", "image_buffer", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"Decode a JPEG string into one 3-D float image Tensor.\n\n        Args:\n          image_buffer (tf.string): scalar string Tensor.\n          scope (str): Optional scope for name_scope.\n        Returns:\n          tf.Tensor: 3-D float Tensor with values ranging from [0, 1).\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\n", "values", "=", "[", "image_buffer", "]", ",", "name", "=", "scope", ",", "default_name", "=", "'decode_jpeg'", ")", ":", "\n", "# Decode the string as an RGB JPEG.", "\n", "# Note that the resulting image contains an unknown height and width", "\n", "# that is set dynamically by _decode_jpeg. In other words, the height", "\n", "# and width of image is unknown at compile-time.", "\n", "            ", "image", "=", "tf", ".", "image", ".", "decode_jpeg", "(", "image_buffer", ",", "channels", "=", "3", ")", "\n", "\n", "# After this point, all image pixels reside in [0,1)", "\n", "# until the very end, when they're rescaled to (-1, 1).  The various", "\n", "# adjust_* ops all require this range for dtype float.", "\n", "image", "=", "tf", ".", "image", ".", "convert_image_dtype", "(", "image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._aspect_preserving_resize": [[247, 270], ["tensorflow.shape", "tensorflow.to_float", "tensorflow.to_float", "tensorflow.reduce_min", "tensorflow.divide", "tensorflow.to_int32", "tensorflow.to_int32", "tensorflow.image.resize_images", "tensorflow.to_float", "tensorflow.round", "tensorflow.round"], "methods", ["None"], ["", "", "def", "_aspect_preserving_resize", "(", "self", ",", "image", ",", "target_smaller_side", ")", ":", "\n", "        ", "\"\"\"\"Resize image such that the smaller size has size\n        ``target_smaller_sider`` while preserving the aspect ratio.\n\n        Args:\n            image (tf.Tensor): Tensor containing the image to resize.\n            target_smaller_side (int): Target size for the smaller side in pixel.\n\n        Returns:\n            tf.Tensor: The resized image, with the same aspect ratio as the input.\n\n        \"\"\"", "\n", "\n", "shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "height", "=", "tf", ".", "to_float", "(", "shape", "[", "0", "]", ")", "\n", "width", "=", "tf", ".", "to_float", "(", "shape", "[", "1", "]", ")", "\n", "smaller_side", "=", "tf", ".", "reduce_min", "(", "shape", "[", "0", ":", "2", "]", ")", "\n", "scale", "=", "tf", ".", "divide", "(", "target_smaller_side", ",", "tf", ".", "to_float", "(", "smaller_side", ")", ")", "\n", "new_height", "=", "tf", ".", "to_int32", "(", "tf", ".", "round", "(", "scale", "*", "height", ")", ")", "\n", "new_width", "=", "tf", ".", "to_int32", "(", "tf", ".", "round", "(", "scale", "*", "width", ")", ")", "\n", "resized_image", "=", "tf", ".", "image", ".", "resize_images", "(", "image", ",", "[", "new_height", ",", "new_width", "]", ")", "\n", "\n", "return", "resized_image", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.imagenet.imagenet._color_distortion": [[271, 291], ["tensorflow.name_scope", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_hue", "tensorflow.image.random_contrast", "tensorflow.clip_by_value"], "methods", ["None"], ["", "def", "_color_distortion", "(", "self", ",", "image", ",", "scope", "=", "None", ")", ":", "\n", "        ", "\"\"\"Distort the color of the image.\n\n        Args:\n          image (tf.Tensor): Tensor containing single image.\n          scope (str): Optional scope for name_scope.\n\n        Returns:\n          tf.Tensor: The color-distorted image.\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "\n", "values", "=", "[", "image", "]", ",", "name", "=", "scope", ",", "default_name", "=", "'distort_color'", ")", ":", "\n", "            ", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "32.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_hue", "(", "image", ",", "max_delta", "=", "0.2", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "\n", "# The random_* ops do not necessarily clamp.", "\n", "image", "=", "tf", ".", "clip_by_value", "(", "image", ",", "0.0", ",", "1.0", ")", "\n", "return", "image", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.dataset.DataSet.__init__": [[29, 62], ["dataset.DataSet._make_train_dataset", "dataset.DataSet._make_train_eval_dataset", "dataset.DataSet._make_test_dataset", "tensorflow.data.Iterator.from_structure", "dataset.DataSet._iterator.get_next", "tensorflow.Variable", "tensorflow.group", "tensorflow.group", "tensorflow.group", "dataset.DataSet._iterator.make_initializer", "tensorflow.assign", "dataset.DataSet._iterator.make_initializer", "tensorflow.assign", "dataset.DataSet._iterator.make_initializer", "tensorflow.assign"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_train_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_train_eval_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_test_dataset"], ["def", "__init__", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"Creates a new DataSet instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use.\n    \"\"\"", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_train_dataset", "=", "self", ".", "_make_train_dataset", "(", ")", "\n", "self", ".", "_train_eval_dataset", "=", "self", ".", "_make_train_eval_dataset", "(", ")", "\n", "self", ".", "_test_dataset", "=", "self", ".", "_make_test_dataset", "(", ")", "\n", "\n", "# Reinitializable iterator given types and shapes of the outputs", "\n", "# (needs to be the same for train and test of course).", "\n", "self", ".", "_iterator", "=", "tf", ".", "data", ".", "Iterator", ".", "from_structure", "(", "\n", "self", ".", "_train_dataset", ".", "output_types", ",", "\n", "self", ".", "_train_dataset", ".", "output_shapes", ")", "\n", "self", ".", "batch", "=", "self", ".", "_iterator", ".", "get_next", "(", ")", "\n", "\n", "# Operations to switch phases (reinitialize iterator and assign value to", "\n", "# phase variable)", "\n", "self", ".", "phase", "=", "tf", ".", "Variable", "(", "\"train\"", ",", "name", "=", "\"phase\"", ",", "trainable", "=", "False", ")", "\n", "self", ".", "train_init_op", "=", "tf", ".", "group", "(", "[", "\n", "self", ".", "_iterator", ".", "make_initializer", "(", "self", ".", "_train_dataset", ")", ",", "\n", "tf", ".", "assign", "(", "self", ".", "phase", ",", "\"train\"", ")", "\n", "]", ",", "name", "=", "\"train_init_op\"", ")", "\n", "self", ".", "train_eval_init_op", "=", "tf", ".", "group", "(", "[", "\n", "self", ".", "_iterator", ".", "make_initializer", "(", "self", ".", "_train_eval_dataset", ")", ",", "\n", "tf", ".", "assign", "(", "self", ".", "phase", ",", "\"train_eval\"", ")", "\n", "]", ",", "name", "=", "\"train_eval_init_op\"", ")", "\n", "self", ".", "test_init_op", "=", "tf", ".", "group", "(", "[", "\n", "self", ".", "_iterator", ".", "make_initializer", "(", "self", ".", "_test_dataset", ")", ",", "\n", "tf", ".", "assign", "(", "self", ".", "phase", ",", "\"test\"", ")", "\n", "]", ",", "name", "=", "\"test_init_op\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.dataset.DataSet._make_train_dataset": [[63, 72], ["NotImplementedError"], "methods", ["None"], ["", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "\n", "\"\"\"'DataSet' is an abstract base class, please use\n        one of the sub-classes.\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.dataset.DataSet._make_train_eval_dataset": [[73, 82], ["NotImplementedError"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "\n", "\"\"\"'DataSet' is an abstract base class, please use\n        one of the sub-classes.\"\"\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.dataset.DataSet._make_test_dataset": [[83, 92], ["NotImplementedError"], "methods", ["None"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "\n", "\"\"\"'DataSet' is an abstract base class, please use\n        one of the sub-classes.\"\"\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.two_d.two_d.__init__": [[41, 58], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "train_size", "=", "10000", ",", "noise_level", "=", "1.0", ")", ":", "\n", "        ", "\"\"\"Creates a new 2D instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size (1k for train and test) the\n          remainder is dropped in each epoch (after shuffling).\n      train_size (int): Size of the training data set. This will also be used as\n          the train_eval and test set size. Defaults to ``1000``.\n      noise_level (float): Standard deviation of the data points around the mean.\n          The data points are drawn from a Gaussian distribution. Defaults to\n          ``1.0``.\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"two_d\"", "\n", "self", ".", "_train_size", "=", "train_size", "\n", "self", ".", "_noise_level", "=", "noise_level", "\n", "super", "(", "two_d", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.two_d.two_d._make_dataset": [[59, 81], ["tensorflow.name_scope", "tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ",", "data_x", ",", "data_y", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates a 2D data set (helper used by ``.make_*_datset`` below).\n\n        Args:\n          data_x (np.array): Numpy array containing the ``X`` values of the\n            data points.\n          data_y (np.array): Numpy array containing the ``y`` values of the\n            data points.\n          shuffle (bool): Switch to turn on or off shuffling of the data set.\n            Defaults to ``True``.\n\n        Returns:\n            A tf.data.Dataset yielding batches of 2D data.\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "data_x", ",", "data_y", ")", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.two_d.two_d._make_train_dataset": [[82, 96], ["numpy.random.RandomState", "numpy.random.RandomState.normal", "numpy.random.RandomState.normal", "numpy.float32", "numpy.float32", "two_d.two_d._make_dataset"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the 2D training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "# Draw data from a random generator with a fixed seed to always get the", "\n", "# same data.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "\n", "data_x", "=", "rng", ".", "normal", "(", "0.0", ",", "self", ".", "_noise_level", ",", "self", ".", "_train_size", ")", "\n", "data_y", "=", "rng", ".", "normal", "(", "0.0", ",", "self", ".", "_noise_level", ",", "self", ".", "_train_size", ")", "\n", "data_x", "=", "np", ".", "float32", "(", "data_x", ")", "\n", "data_y", "=", "np", ".", "float32", "(", "data_y", ")", "\n", "return", "self", ".", "_make_dataset", "(", "data_x", ",", "data_y", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.two_d.two_d._make_train_eval_dataset": [[97, 104], ["two_d.two_d._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the 2D train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "self", ".", "_train_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.two_d.two_d._make_test_dataset": [[105, 116], ["numpy.float32", "numpy.float32", "two_d.two_d._make_dataset", "numpy.zeros", "numpy.zeros"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the 2D test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "# recovers the deterministic 2D function using zeros", "\n", "data_x", ",", "data_y", "=", "np", ".", "zeros", "(", "self", ".", "_train_size", ")", ",", "np", ".", "zeros", "(", "self", ".", "_train_size", ")", "\n", "data_x", "=", "np", ".", "float32", "(", "data_x", ")", "\n", "data_y", "=", "np", ".", "float32", "(", "data_y", ")", "\n", "return", "self", ".", "_make_dataset", "(", "data_x", ",", "data_y", ",", "shuffle", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.quadratic.quadratic.__init__": [[43, 62], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "dim", "=", "100", ",", "train_size", "=", "1000", ",", "noise_level", "=", "0.6", ")", ":", "\n", "        ", "\"\"\"Creates a new Quadratic instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size (``1000`` for train and test) the\n          remainder is dropped in each epoch (after shuffling).\n      dim (int): Dimensionality of the quadratic. Defaults to ``100``.\n      train_size (int): Size of the dataset; will be used for train, train eval\n          and test datasets. Defaults to ``1000``.\n      noise_level (float): Standard deviation of the data points around the mean.\n          The data points are drawn from a Gaussian distribution.\n          Defaults to ``0.6``.\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"quadratic\"", "\n", "self", ".", "_dim", "=", "dim", "\n", "self", ".", "_train_size", "=", "train_size", "\n", "self", ".", "_noise_level", "=", "noise_level", "\n", "super", "(", "quadratic", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.quadratic.quadratic._make_dataset": [[63, 83], ["tensorflow.name_scope", "tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ",", "X", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates a quadratic data set (helper used by ``.make_*_datset`` below).\n\n        Args:\n            X (np.array): Numpy array containing the ``x`` values of the data points.\n            data_y (np.array): Numpy array containing the ``y`` values of the data points.\n            shuffle (bool):  Switch to turn on or off shuffling of the data set.\n                Defaults to ``True``.\n\n        Returns:\n            A tf.data.Dataset yielding batches of quadratic data.\n        \"\"\"", "\n", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "X", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.quadratic.quadratic._make_train_dataset": [[84, 96], ["numpy.random.RandomState", "numpy.random.RandomState.normal", "numpy.float32", "quadratic.quadratic._make_dataset"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the quadratic training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "# Draw data from a random generator with a fixed seed to always get the", "\n", "# same data.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "\n", "X", "=", "rng", ".", "normal", "(", "0.0", ",", "self", ".", "_noise_level", ",", "(", "self", ".", "_train_size", ",", "self", ".", "_dim", ")", ")", "\n", "X", "=", "np", ".", "float32", "(", "X", ")", "\n", "return", "self", ".", "_make_dataset", "(", "X", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.quadratic.quadratic._make_train_eval_dataset": [[97, 104], ["quadratic.quadratic._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the quadratic train eval dataset.\n\n        Returns:\n            A tf.data.Dataset instance with batches of training eval data.\n        \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "-", "1", ")", "# Take all.", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.quadratic.quadratic._make_test_dataset": [[105, 117], ["numpy.random.RandomState", "numpy.random.RandomState.normal", "numpy.float32", "quadratic.quadratic._make_dataset"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the quadratic test dataset.\n\n        Returns:\n            A tf.data.Dataset instance with batches of test data.\n        \"\"\"", "\n", "# Draw data from a random generator with a fixed seed to always get the", "\n", "# same data.", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "43", ")", "\n", "X", "=", "rng", ".", "normal", "(", "0.0", ",", "self", ".", "_noise_level", ",", "(", "self", ".", "_train_size", ",", "self", ".", "_dim", ")", ")", "\n", "X", "=", "np", ".", "float32", "(", "X", ")", "\n", "return", "self", ".", "_make_dataset", "(", "X", ",", "shuffle", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar10.cifar10.__init__": [[40, 60], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "\n", "batch_size", ",", "\n", "data_augmentation", "=", "True", ",", "\n", "train_eval_size", "=", "10000", ")", ":", "\n", "        ", "\"\"\"Creates a new CIFAR-10 instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size (``50 000`` for train, ``10 000``\n          for test) the remainder is dropped in each epoch (after shuffling).\n      data_augmentation (bool): If ``True`` some data augmentation operations\n          (random crop window, horizontal flipping, lighting augmentation) are\n          applied to the training data (but not the test data).\n      train_eval_size (int): Size of the train eval data set.\n          Defaults to ``10 000`` the size of the test set.\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"cifar10\"", "\n", "self", ".", "_data_augmentation", "=", "data_augmentation", "\n", "self", ".", "_train_eval_size", "=", "train_eval_size", "\n", "super", "(", "cifar10", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar10.cifar10._make_dataset": [[61, 128], ["tensorflow.reshape", "tensorflow.cast", "tensorflow.reshape", "tensorflow.cast", "tensorflow.image.per_image_standardization", "tensorflow.squeeze", "tensorflow.name_scope", "tensorflow.decode_raw", "tensorflow.slice", "tensorflow.slice", "tensorflow.transpose", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.random_crop", "tensorflow.image.random_flip_left_right", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_contrast", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.one_hot", "tensorflow.device", "tensorflow.matching_files", "tensorflow.random_shuffle", "tensorflow.data.FixedLengthRecordDataset", "data.shuffle.shuffle.map", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ",", "\n", "binaries_fname_pattern", ",", "\n", "data_augmentation", "=", "False", ",", "\n", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates a CIFAR-10 data set (helper used by ``.make_*_datset`` below).\n\n    Args:\n        binaries_fname_pattern (str): Pattern of the ``.bin`` files from which\n            to load images and labels (e.g. ``some/path/data_batch_*.bin``).\n        data_augmentation (bool): Whether to apply data augmentation operations.\n        shuffle (bool):  Switch to turn on or off shuffling of the data set.\n            Defaults to ``True``.\n\n    Returns:\n        A tf.data.Dataset yielding batches of CIFAR-10 data.\n    \"\"\"", "\n", "# Set number of bytes to read.", "\n", "label_bytes", "=", "1", "\n", "label_offset", "=", "0", "\n", "num_classes", "=", "10", "\n", "depth", "=", "3", "\n", "image_size", "=", "32", "\n", "image_bytes", "=", "image_size", "*", "image_size", "*", "depth", "\n", "record_bytes", "=", "label_bytes", "+", "label_offset", "+", "image_bytes", "\n", "\n", "def", "parse_func", "(", "raw_record", ")", ":", "\n", "            ", "\"\"\"Function parsing data from raw binary records.\"\"\"", "\n", "# Decode raw_record.", "\n", "record", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "decode_raw", "(", "raw_record", ",", "tf", ".", "uint8", ")", ",", "[", "record_bytes", "]", ")", "\n", "label", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "slice", "(", "record", ",", "[", "label_offset", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "depth_major", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "slice", "(", "record", ",", "[", "label_bytes", "]", ",", "[", "image_bytes", "]", ")", ",", "\n", "[", "depth", ",", "image_size", ",", "image_size", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "tf", ".", "transpose", "(", "depth_major", ",", "[", "1", ",", "2", ",", "0", "]", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "# Add image pre-processing.", "\n", "if", "data_augmentation", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "\n", "image", ",", "image_size", "+", "4", ",", "image_size", "+", "4", ")", "\n", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "32", ",", "32", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_flip_left_right", "(", "image", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "63.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "", "else", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "32", ",", "32", ")", "\n", "\n", "", "image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", "\n", "label", "=", "tf", ".", "squeeze", "(", "tf", ".", "one_hot", "(", "label", ",", "depth", "=", "num_classes", ")", ")", "\n", "return", "image", ",", "label", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "filenames", "=", "tf", ".", "matching_files", "(", "binaries_fname_pattern", ")", "\n", "filenames", "=", "tf", ".", "random_shuffle", "(", "filenames", ")", "\n", "data", "=", "tf", ".", "data", ".", "FixedLengthRecordDataset", "(", "\n", "filenames", "=", "filenames", ",", "record_bytes", "=", "record_bytes", ")", "\n", "data", "=", "data", ".", "map", "(", "\n", "parse_func", ",", "\n", "num_parallel_calls", "=", "(", "8", "if", "data_augmentation", "else", "4", ")", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar10.cifar10._make_train_dataset": [[129, 139], ["os.path.join", "cifar10.cifar10._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the CIFAR-10 training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"cifar-10\"", ",", "\n", "\"data_batch_*.bin\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "data_augmentation", "=", "self", ".", "_data_augmentation", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar10.cifar10._make_train_eval_dataset": [[140, 148], ["cifar10.cifar10._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the CIFAR-10 train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "\n", "self", ".", "_train_eval_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.cifar10.cifar10._make_test_dataset": [[149, 159], ["os.path.join", "cifar10.cifar10._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the CIFAR-10 test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"cifar-10\"", ",", "\n", "\"test_batch.bin\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "data_augmentation", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist.__init__": [[41, 54], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "train_eval_size", "=", "10000", ")", ":", "\n", "        ", "\"\"\"Creates a new Fashion-MNIST instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size (``60 000`` for train, ``10 000``\n          for test) the remainder is dropped in each epoch (after shuffling).\n      train_eval_size (int): Size of the train eval data set.\n          Defaults to ``10 000`` the size of the test set.\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"fmnist\"", "\n", "self", ".", "_train_eval_size", "=", "train_eval_size", "\n", "super", "(", "fmnist", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._make_dataset": [[55, 76], ["fmnist.fmnist._read_mnist_data", "tensorflow.name_scope", "tensorflow.device", "tensorflow.data.Dataset.from_tensor_slices", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read_mnist_data"], ["", "def", "_make_dataset", "(", "self", ",", "images_file", ",", "labels_file", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates a Fashion-MNIST data set (helper used by ``.make_*_datset`` below).\n\n    Args:\n        images_file (str): Path to the images in compressed ``.gz`` files.\n        labels_file (str): Path to the labels in compressed ``.gz`` files.\n        shuffle (bool):  Switch to turn on or off shuffling of the data set.\n            Defaults to ``True``.\n\n    Returns:\n        A tf.data.Dataset yielding batches of Fashion-MNIST data.\n    \"\"\"", "\n", "X", ",", "y", "=", "self", ".", "_read_mnist_data", "(", "images_file", ",", "labels_file", ")", "\n", "with", "tf", ".", "name_scope", "(", "\"fmnist\"", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "from_tensor_slices", "(", "(", "X", ",", "y", ")", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._make_train_dataset": [[77, 90], ["config.get_data_dir", "os.path.join", "os.path.join", "fmnist.fmnist._make_dataset"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the Fashion-MNIST training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "data_dir", "=", "config", ".", "get_data_dir", "(", ")", "\n", "train_images_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"fmnist\"", ",", "\n", "\"train-images-idx3-ubyte.gz\"", ")", "\n", "train_labels_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"fmnist\"", ",", "\n", "\"train-labels-idx1-ubyte.gz\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "train_images_file", ",", "train_labels_file", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._make_train_eval_dataset": [[91, 99], ["fmnist.fmnist._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the Fashion-MNIST train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "\n", "self", ".", "_train_eval_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._make_test_dataset": [[100, 114], ["config.get_data_dir", "os.path.join", "os.path.join", "fmnist.fmnist._make_dataset"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the Fashion-MNIST test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "data_dir", "=", "config", ".", "get_data_dir", "(", ")", "\n", "test_images_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"fmnist\"", ",", "\n", "\"t10k-images-idx3-ubyte.gz\"", ")", "\n", "test_labels_file", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"fmnist\"", ",", "\n", "\"t10k-labels-idx1-ubyte.gz\"", ")", "\n", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "test_images_file", ",", "test_labels_file", ",", "shuffle", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read_mnist_data": [[117, 159], ["tensorflow.gfile.Open", "print", "tensorflow.gfile.Open", "print", "gzip.GzipFile", "fmnist.fmnist._read32", "fmnist.fmnist._read32", "fmnist.fmnist._read32", "fmnist.fmnist._read32", "bytestream.read", "numpy.frombuffer", "numpy.frombuffer.reshape", "gzip.GzipFile", "fmnist.fmnist._read32", "fmnist.fmnist._read32", "bytestream.read", "numpy.frombuffer", "fmnist.fmnist._dense_to_one_hot", "y.astype.astype.astype", "ValueError", "np.frombuffer.reshape.astype", "ValueError"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32", "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._dense_to_one_hot"], ["", "def", "_read_mnist_data", "(", "self", ",", "images_file", ",", "labels_file", ")", ":", "\n", "        ", "\"\"\"Read the Fashion-MNIST images and labels from the downloaded files.\n\n        Args:\n            images_file (str): Path to the images in compressed ``.gz`` files.\n            labels_file (str): Path to the labels in compressed ``.gz`` files.\n\n        Returns:\n            tupel: Tupel consisting of all the images (`X`) and the labels (`y`).\n\n        \"\"\"", "\n", "# Load images from images_file", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "images_file", ",", "'rb'", ")", "as", "img_file", ":", "\n", "            ", "print", "(", "'Extracting %s'", "%", "img_file", ".", "name", ")", "\n", "with", "gzip", ".", "GzipFile", "(", "fileobj", "=", "img_file", ")", "as", "bytestream", ":", "\n", "                ", "magic", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "if", "magic", "!=", "2051", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'Invalid magic number %d in Fashion-MNIST image file: %s'", "\n", "%", "(", "magic", ",", "img_file", ".", "name", ")", ")", "\n", "", "num_images", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "rows", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "cols", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "rows", "*", "cols", "*", "num_images", ")", "\n", "data", "=", "np", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "X", "=", "data", ".", "reshape", "(", "num_images", ",", "rows", ",", "cols", ",", "1", ")", "\n", "X", "=", "X", ".", "astype", "(", "np", ".", "float32", ")", "/", "255.0", "\n", "# Load labels from labels file", "\n", "", "", "with", "tf", ".", "gfile", ".", "Open", "(", "labels_file", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "print", "(", "'Extracting %s'", "%", "f", ".", "name", ")", "\n", "with", "gzip", ".", "GzipFile", "(", "fileobj", "=", "f", ")", "as", "bytestream", ":", "\n", "                ", "magic", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "if", "magic", "!=", "2049", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "'Invalid magic number %d in Fashion-MNIST label file: %s'", "\n", "%", "(", "magic", ",", "f", ".", "name", ")", ")", "\n", "", "num_items", "=", "self", ".", "_read32", "(", "bytestream", ")", "\n", "buf", "=", "bytestream", ".", "read", "(", "num_items", ")", "\n", "y", "=", "np", ".", "frombuffer", "(", "buf", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "y", "=", "self", ".", "_dense_to_one_hot", "(", "y", ",", "10", ")", "\n", "y", "=", "y", ".", "astype", "(", "np", ".", "int32", ")", "\n", "", "", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._read32": [[160, 172], ["numpy.dtype().newbyteorder", "numpy.frombuffer", "numpy.dtype", "bytestream.read"], "methods", ["None"], ["", "def", "_read32", "(", "self", ",", "bytestream", ")", ":", "\n", "        ", "\"\"\"Helper function to read a bytestream.\n\n        Args:\n            bytestream (bytestream): Input bytestream.\n\n        Returns:\n            np.array: Bytestream as a np array.\n\n        \"\"\"", "\n", "dtype", "=", "np", ".", "dtype", "(", "np", ".", "uint32", ")", ".", "newbyteorder", "(", "'>'", ")", "\n", "return", "np", ".", "frombuffer", "(", "bytestream", ".", "read", "(", "4", ")", ",", "dtype", "=", "dtype", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.fmnist.fmnist._dense_to_one_hot": [[173, 180], ["numpy.zeros", "numpy.arange", "labels_dense.ravel"], "methods", ["None"], ["", "def", "_dense_to_one_hot", "(", "self", ",", "labels_dense", ",", "num_classes", ")", ":", "\n", "        ", "\"\"\"Convert class labels from scalars to one-hot vectors.\"\"\"", "\n", "num_labels", "=", "labels_dense", ".", "shape", "[", "0", "]", "\n", "index_offset", "=", "np", ".", "arange", "(", "num_labels", ")", "*", "num_classes", "\n", "labels_one_hot", "=", "np", ".", "zeros", "(", "(", "num_labels", ",", "num_classes", ")", ")", "\n", "labels_one_hot", ".", "flat", "[", "index_offset", "+", "labels_dense", ".", "ravel", "(", ")", "]", "=", "1", "\n", "return", "labels_one_hot", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn.__init__": [[40, 60], ["dataset.DataSet.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "\n", "batch_size", ",", "\n", "data_augmentation", "=", "True", ",", "\n", "train_eval_size", "=", "26032", ")", ":", "\n", "        ", "\"\"\"Creates a new SVHN instance.\n\n    Args:\n      batch_size (int): The mini-batch size to use. Note that, if ``batch_size``\n          is not a divider of the dataset size (73k for train, 26k for test)\n          the remainder is dropped in each epoch (after shuffling).\n      data_augmentation (bool): If ``True`` some data augmentation operations\n          (random crop window, lighting augmentation) are applied to the\n          training data (but not the test data).\n      train_eval_size (int): Size of the train eval dataset (default: 26k the\n          size of the test set).\n    \"\"\"", "\n", "self", ".", "_name", "=", "\"svhn\"", "\n", "self", ".", "_data_augmentation", "=", "data_augmentation", "\n", "self", ".", "_train_eval_size", "=", "train_eval_size", "\n", "super", "(", "svhn", ",", "self", ")", ".", "__init__", "(", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset": [[61, 127], ["tensorflow.reshape", "tensorflow.cast", "tensorflow.reshape", "tensorflow.cast", "tensorflow.image.per_image_standardization", "tensorflow.squeeze", "tensorflow.name_scope", "tensorflow.decode_raw", "tensorflow.slice", "tensorflow.slice", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.random_crop", "tensorflow.image.random_brightness", "tensorflow.image.random_saturation", "tensorflow.image.random_contrast", "tensorflow.image.resize_image_with_crop_or_pad", "tensorflow.one_hot", "tensorflow.device", "tensorflow.matching_files", "tensorflow.random_shuffle", "tensorflow.data.FixedLengthRecordDataset", "data.shuffle.shuffle.map", "data.shuffle.shuffle.batch", "data.shuffle.shuffle.prefetch", "data.shuffle.shuffle.shuffle"], "methods", ["None"], ["", "def", "_make_dataset", "(", "self", ",", "\n", "binaries_fname_pattern", ",", "\n", "data_augmentation", "=", "False", ",", "\n", "shuffle", "=", "True", ")", ":", "\n", "        ", "\"\"\"Creates a SVHN dataset (helper used by ``.make_*_datset`` below).\n\n    Args:\n        binaries_fname_pattern (str): Pattern of the ``.bin`` files from which\n            to load images and labels (e.g. ``some/path/data_batch_*.bin``).\n        data_augmentation (bool): Whether to apply data augmentation operations.\n        shuffle (bool):  Switch to turn on or off shuffling of the data set.\n            Defaults to ``True``.\n\n    Returns:\n        A tf.data.Dataset yielding batches of SVHN data.\n    \"\"\"", "\n", "# Set number of bytes to read.", "\n", "label_bytes", "=", "1", "\n", "label_offset", "=", "0", "\n", "num_classes", "=", "10", "\n", "depth", "=", "3", "\n", "image_size", "=", "32", "\n", "image_bytes", "=", "image_size", "*", "image_size", "*", "depth", "\n", "record_bytes", "=", "label_bytes", "+", "label_offset", "+", "image_bytes", "\n", "\n", "def", "parse_func", "(", "raw_record", ")", ":", "\n", "            ", "\"\"\"Function parsing data from raw binary records.\"\"\"", "\n", "# Decode raw_record.", "\n", "record", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "decode_raw", "(", "raw_record", ",", "tf", ".", "uint8", ")", ",", "[", "record_bytes", "]", ")", "\n", "label", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "slice", "(", "record", ",", "[", "label_offset", "]", ",", "[", "label_bytes", "]", ")", ",", "tf", ".", "int32", ")", "\n", "image", "=", "tf", ".", "reshape", "(", "\n", "tf", ".", "slice", "(", "record", ",", "[", "label_bytes", "]", ",", "[", "image_bytes", "]", ")", ",", "\n", "[", "image_size", ",", "image_size", ",", "depth", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "\n", "\n", "# Add image pre-processing.", "\n", "if", "data_augmentation", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "\n", "image", ",", "image_size", "+", "4", ",", "image_size", "+", "4", ")", "\n", "image", "=", "tf", ".", "random_crop", "(", "image", ",", "[", "32", ",", "32", ",", "3", "]", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_brightness", "(", "image", ",", "max_delta", "=", "63.", "/", "255.", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "image", "=", "tf", ".", "image", ".", "random_contrast", "(", "image", ",", "lower", "=", "0.2", ",", "upper", "=", "1.8", ")", "\n", "", "else", ":", "\n", "                ", "image", "=", "tf", ".", "image", ".", "resize_image_with_crop_or_pad", "(", "image", ",", "32", ",", "32", ")", "\n", "\n", "", "image", "=", "tf", ".", "image", ".", "per_image_standardization", "(", "image", ")", "\n", "label", "=", "tf", ".", "squeeze", "(", "tf", ".", "one_hot", "(", "label", ",", "depth", "=", "num_classes", ")", ")", "\n", "return", "image", ",", "label", "\n", "\n", "", "with", "tf", ".", "name_scope", "(", "self", ".", "_name", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "'/cpu:0'", ")", ":", "\n", "                ", "filenames", "=", "tf", ".", "matching_files", "(", "binaries_fname_pattern", ")", "\n", "filenames", "=", "tf", ".", "random_shuffle", "(", "filenames", ")", "\n", "data", "=", "tf", ".", "data", ".", "FixedLengthRecordDataset", "(", "\n", "filenames", "=", "filenames", ",", "record_bytes", "=", "record_bytes", ")", "\n", "data", "=", "data", ".", "map", "(", "\n", "parse_func", ",", "\n", "num_parallel_calls", "=", "(", "8", "if", "data_augmentation", "else", "4", ")", ")", "\n", "if", "shuffle", ":", "\n", "                    ", "data", "=", "data", ".", "shuffle", "(", "buffer_size", "=", "20000", ")", "\n", "", "data", "=", "data", ".", "batch", "(", "self", ".", "_batch_size", ",", "drop_remainder", "=", "True", ")", "\n", "data", "=", "data", ".", "prefetch", "(", "buffer_size", "=", "4", ")", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_train_dataset": [[128, 138], ["os.path.join", "svhn.svhn._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "", "", "def", "_make_train_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the SVHN training dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"svhn\"", ",", "\n", "\"data_batch_*.bin\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "data_augmentation", "=", "self", ".", "_data_augmentation", ",", "shuffle", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_train_eval_dataset": [[139, 147], ["svhn.svhn._train_dataset.take"], "methods", ["None"], ["", "def", "_make_train_eval_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the SVHN train eval dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of training eval data.\n    \"\"\"", "\n", "return", "self", ".", "_train_dataset", ".", "take", "(", "\n", "self", ".", "_train_eval_size", "//", "self", ".", "_batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_test_dataset": [[148, 157], ["os.path.join", "svhn.svhn._make_dataset", "config.get_data_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.datasets.svhn.svhn._make_dataset", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir"], ["", "def", "_make_test_dataset", "(", "self", ")", ":", "\n", "        ", "\"\"\"Creates the SVHN test dataset.\n\n    Returns:\n      A tf.data.Dataset instance with batches of test data.\n    \"\"\"", "\n", "pattern", "=", "os", ".", "path", ".", "join", "(", "config", ".", "get_data_dir", "(", ")", ",", "\"svhn\"", ",", "\"test_batch.bin\"", ")", "\n", "return", "self", ".", "_make_dataset", "(", "\n", "pattern", ",", "data_augmentation", "=", "False", ",", "shuffle", "=", "False", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_2c2d.FMNIST_2c2dTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.fmnist_2c2d"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Fashion-MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "fmnist_2c2d", "=", "testproblems", ".", "fmnist_2c2d", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_2c2d.FMNIST_2c2dTest.test_init_ops": [[23, 57], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_fmnist_2c2d.FMNIST_2c2dTest.fmnist_2c2d.set_up", "tensorflow.Session", "sess.run", "test_fmnist_2c2d.FMNIST_2c2dTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_fmnist_2c2d.FMNIST_2c2dTest.assertEqual", "test_fmnist_2c2d.FMNIST_2c2dTest.assertIsInstance", "test_fmnist_2c2d.FMNIST_2c2dTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "fmnist_2c2d", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "1", "*", "32", "*", "5", "*", "5", ",", "32", ",", "32", "*", "64", "*", "5", "*", "5", ",", "64", ",", "7", "*", "7", "*", "64", "*", "1024", ",", "\n", "1024", ",", "1024", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "fmnist_2c2d", ".", "train_init_op", ",", "\n", "self", ".", "fmnist_2c2d", ".", "test_init_op", ",", "\n", "self", ".", "fmnist_2c2d", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "fmnist_2c2d", ".", "losses", ",", "self", ".", "fmnist_2c2d", ".", "regularizer", ",", "\n", "self", ".", "fmnist_2c2d", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar10_vgg16.Cifar10_VGG16Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar10_vgg16"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-10 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar10_vgg16", "=", "testproblems", ".", "cifar10_vgg16", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar10_vgg16.Cifar10_VGG16Test.test_init_ops": [[23, 62], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar10_vgg16.Cifar10_VGG16Test.cifar10_vgg16.set_up", "tensorflow.Session", "sess.run", "test_cifar10_vgg16.Cifar10_VGG16Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar10_vgg16.Cifar10_VGG16Test.assertEqual", "test_cifar10_vgg16.Cifar10_VGG16Test.assertIsInstance", "test_cifar10_vgg16.Cifar10_VGG16Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar10_vgg16", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "7", "*", "7", "*", "4096", ",", "4096", ",", "4096", "*", "4096", ",", "4096", ",", "4096", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar10_vgg16", ".", "train_init_op", ",", "\n", "self", ".", "cifar10_vgg16", ".", "test_init_op", ",", "\n", "self", ".", "cifar10_vgg16", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar10_vgg16", ".", "losses", ",", "self", ".", "cifar10_vgg16", ".", "regularizer", ",", "\n", "self", ".", "cifar10_vgg16", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_wrn404.Cifar100_WRN404Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar100_wrn404"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-100 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar100_wrn404", "=", "testproblems", ".", "cifar100_wrn404", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_wrn404.Cifar100_WRN404Test.test_init_ops": [[23, 76], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar100_wrn404.Cifar100_WRN404Test.cifar100_wrn404.set_up", "tensorflow.Session", "sess.run", "test_cifar100_wrn404.Cifar100_WRN404Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar100_wrn404.Cifar100_WRN404Test.assertEqual", "test_cifar100_wrn404.Cifar100_WRN404Test.assertIsInstance", "test_cifar100_wrn404.Cifar100_WRN404Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar100_wrn404", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "16", "*", "3", "*", "3", ",", "16", ",", "16", ",", "16", "*", "64", "*", "1", "*", "1", ",", "16", "*", "64", "*", "3", "*", "3", ",", "64", ",", "\n", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "\n", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "\n", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "\n", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "\n", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "\n", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "128", "*", "1", "*", "1", ",", "64", "*", "128", "*", "3", "*", "3", ",", "\n", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "256", "*", "1", "*", "1", ",", "\n", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "100", ",", "100", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar100_wrn404", ".", "train_init_op", ",", "\n", "self", ".", "cifar100_wrn404", ".", "test_init_op", ",", "\n", "self", ".", "cifar100_wrn404", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar100_wrn404", ".", "losses", ",", "\n", "self", ".", "cifar100_wrn404", ".", "regularizer", ",", "\n", "self", ".", "cifar100_wrn404", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_vae.MNIST_VAETest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.mnist_vae"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "mnist_vae", "=", "testproblems", ".", "mnist_vae", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_vae.MNIST_VAETest.test_init_ops": [[23, 56], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_mnist_vae.MNIST_VAETest.mnist_vae.set_up", "tensorflow.Session", "sess.run", "test_mnist_vae.MNIST_VAETest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_mnist_vae.MNIST_VAETest.assertEqual", "test_mnist_vae.MNIST_VAETest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "mnist_vae", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "1", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "\n", "7", "*", "7", "*", "64", "*", "8", ",", "8", ",", "7", "*", "7", "*", "64", "*", "8", ",", "8", ",", "8", "*", "24", ",", "24", ",", "24", "*", "49", ",", "49", ",", "\n", "1", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "\n", "14", "*", "14", "*", "64", "*", "28", "*", "28", ",", "28", "*", "28", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "mnist_vae", ".", "train_init_op", ",", "\n", "self", ".", "mnist_vae", ".", "test_init_op", ",", "\n", "self", ".", "mnist_vae", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "mnist_vae", ".", "losses", ",", "self", ".", "mnist_vae", ".", "regularizer", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_imagenet_vgg19.Imagenet_VGG19Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.imagenet_vgg19"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up ImageNet dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "imagenet_vgg19", "=", "testproblems", ".", "imagenet_vgg19", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_imagenet_vgg19.Imagenet_VGG19Test.test_init_ops": [[23, 64], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_imagenet_vgg19.Imagenet_VGG19Test.imagenet_vgg19.set_up", "tensorflow.Session", "sess.run", "test_imagenet_vgg19.Imagenet_VGG19Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_imagenet_vgg19.Imagenet_VGG19Test.assertEqual", "test_imagenet_vgg19.Imagenet_VGG19Test.assertIsInstance", "test_imagenet_vgg19.Imagenet_VGG19Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "imagenet_vgg19", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "7", "*", "7", "*", "4096", ",", "4096", ",", "4096", "*", "4096", ",", "\n", "4096", ",", "4096", "*", "1001", ",", "1001", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "imagenet_vgg19", ".", "train_init_op", ",", "\n", "self", ".", "imagenet_vgg19", ".", "test_init_op", ",", "\n", "self", ".", "imagenet_vgg19", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "imagenet_vgg19", ".", "losses", ",", "self", ".", "imagenet_vgg19", ".", "regularizer", ",", "\n", "self", ".", "imagenet_vgg19", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_logreg.MNIST_LogRegTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.mnist_logreg"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "mnist_logreg", "=", "testproblems", ".", "mnist_logreg", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_logreg.MNIST_LogRegTest.test_init_ops": [[23, 55], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_mnist_logreg.MNIST_LogRegTest.mnist_logreg.set_up", "tensorflow.Session", "sess.run", "test_mnist_logreg.MNIST_LogRegTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_mnist_logreg.MNIST_LogRegTest.assertEqual", "test_mnist_logreg.MNIST_LogRegTest.assertIsInstance", "test_mnist_logreg.MNIST_LogRegTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "mnist_logreg", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "784", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "mnist_logreg", ".", "train_init_op", ",", "self", ".", "mnist_logreg", ".", "test_init_op", ",", "\n", "self", ".", "mnist_logreg", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "mnist_logreg", ".", "losses", ",", "self", ".", "mnist_logreg", ".", "regularizer", ",", "\n", "self", ".", "mnist_logreg", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_vgg19.Cifar100_VGG19Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar100_vgg19"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-100 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar100_vgg19", "=", "testproblems", ".", "cifar100_vgg19", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_vgg19.Cifar100_VGG19Test.test_init_ops": [[23, 64], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar100_vgg19.Cifar100_VGG19Test.cifar100_vgg19.set_up", "tensorflow.Session", "sess.run", "test_cifar100_vgg19.Cifar100_VGG19Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar100_vgg19.Cifar100_VGG19Test.assertEqual", "test_cifar100_vgg19.Cifar100_VGG19Test.assertIsInstance", "test_cifar100_vgg19.Cifar100_VGG19Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar100_vgg19", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "7", "*", "7", "*", "4096", ",", "4096", ",", "4096", "*", "4096", ",", "\n", "4096", ",", "4096", "*", "100", ",", "100", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar100_vgg19", ".", "train_init_op", ",", "\n", "self", ".", "cifar100_vgg19", ".", "test_init_op", ",", "\n", "self", ".", "cifar100_vgg19", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar100_vgg19", ".", "losses", ",", "self", ".", "cifar100_vgg19", ".", "regularizer", ",", "\n", "self", ".", "cifar100_vgg19", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_two_d_rosenbrock.Two_d_RosenbrockTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.two_d_rosenbrock"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the 2D dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "two_d_rosenbrock", "=", "testproblems", ".", "two_d_rosenbrock", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_two_d_rosenbrock.Two_d_RosenbrockTest.test_init_ops": [[23, 54], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_two_d_rosenbrock.Two_d_RosenbrockTest.two_d_rosenbrock.set_up", "tensorflow.Session", "sess.run", "test_two_d_rosenbrock.Two_d_RosenbrockTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_two_d_rosenbrock.Two_d_RosenbrockTest.assertEqual", "test_two_d_rosenbrock.Two_d_RosenbrockTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "two_d_rosenbrock", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "1", ",", "1", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "two_d_rosenbrock", ".", "train_init_op", ",", "\n", "self", ".", "two_d_rosenbrock", ".", "test_init_op", ",", "\n", "self", ".", "two_d_rosenbrock", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "two_d_rosenbrock", ".", "losses", ",", "self", ".", "two_d_rosenbrock", ".", "regularizer", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_two_d_branin.Two_d_BraninTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.two_d_branin"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the 2D dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "two_d_branin", "=", "testproblems", ".", "two_d_branin", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_two_d_branin.Two_d_BraninTest.test_init_ops": [[23, 54], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_two_d_branin.Two_d_BraninTest.two_d_branin.set_up", "tensorflow.Session", "sess.run", "test_two_d_branin.Two_d_BraninTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_two_d_branin.Two_d_BraninTest.assertEqual", "test_two_d_branin.Two_d_BraninTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "two_d_branin", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "1", ",", "1", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "two_d_branin", ".", "train_init_op", ",", "\n", "self", ".", "two_d_branin", ".", "test_init_op", ",", "\n", "self", ".", "two_d_branin", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "two_d_branin", ".", "losses", ",", "self", ".", "two_d_branin", ".", "regularizer", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_tolstoi_char_rnn.Tolstoi_Char_RNNTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.tolstoi_char_rnn"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Tolstoi dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "tolstoi_char_rnn", "=", "testproblems", ".", "tolstoi_char_rnn", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_tolstoi_char_rnn.Tolstoi_Char_RNNTest.test_init_ops": [[23, 58], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_tolstoi_char_rnn.Tolstoi_Char_RNNTest.tolstoi_char_rnn.set_up", "tensorflow.Session", "sess.run", "test_tolstoi_char_rnn.Tolstoi_Char_RNNTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_tolstoi_char_rnn.Tolstoi_Char_RNNTest.assertEqual", "test_tolstoi_char_rnn.Tolstoi_Char_RNNTest.assertIsInstance", "test_tolstoi_char_rnn.Tolstoi_Char_RNNTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "tolstoi_char_rnn", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "83", "*", "128", ",", "4", "*", "(", "128", "*", "128", "+", "128", "*", "128", ")", ",", "4", "*", "128", ",", "\n", "4", "*", "(", "128", "*", "128", "+", "128", "*", "128", ")", ",", "4", "*", "128", ",", "83", "*", "128", ",", "83", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "tolstoi_char_rnn", ".", "train_init_op", ",", "\n", "self", ".", "tolstoi_char_rnn", ".", "test_init_op", ",", "\n", "self", ".", "tolstoi_char_rnn", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "tolstoi_char_rnn", ".", "losses", ",", "\n", "self", ".", "tolstoi_char_rnn", ".", "regularizer", ",", "\n", "self", ".", "tolstoi_char_rnn", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_logreg.FMNIST_LogRegTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.fmnist_logreg"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Fashion-MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "fmnist_logreg", "=", "testproblems", ".", "fmnist_logreg", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_logreg.FMNIST_LogRegTest.test_init_ops": [[23, 55], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_fmnist_logreg.FMNIST_LogRegTest.fmnist_logreg.set_up", "tensorflow.Session", "sess.run", "test_fmnist_logreg.FMNIST_LogRegTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_fmnist_logreg.FMNIST_LogRegTest.assertEqual", "test_fmnist_logreg.FMNIST_LogRegTest.assertIsInstance", "test_fmnist_logreg.FMNIST_LogRegTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "fmnist_logreg", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "784", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "fmnist_logreg", ".", "train_init_op", ",", "self", ".", "fmnist_logreg", ".", "test_init_op", ",", "\n", "self", ".", "fmnist_logreg", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "fmnist_logreg", ".", "losses", ",", "self", ".", "fmnist_logreg", ".", "regularizer", ",", "\n", "self", ".", "fmnist_logreg", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_vae.FMNIST_VAETest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.fmnist_vae"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Fashion-MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "fmnist_vae", "=", "testproblems", ".", "fmnist_vae", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_vae.FMNIST_VAETest.test_init_ops": [[23, 56], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_fmnist_vae.FMNIST_VAETest.fmnist_vae.set_up", "tensorflow.Session", "sess.run", "test_fmnist_vae.FMNIST_VAETest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_fmnist_vae.FMNIST_VAETest.assertEqual", "test_fmnist_vae.FMNIST_VAETest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "fmnist_vae", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "1", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "\n", "7", "*", "7", "*", "64", "*", "8", ",", "8", ",", "7", "*", "7", "*", "64", "*", "8", ",", "8", ",", "8", "*", "24", ",", "24", ",", "24", "*", "49", ",", "49", ",", "\n", "1", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "64", "*", "64", "*", "4", "*", "4", ",", "64", ",", "\n", "14", "*", "14", "*", "64", "*", "28", "*", "28", ",", "28", "*", "28", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "fmnist_vae", ".", "train_init_op", ",", "\n", "self", ".", "fmnist_vae", ".", "test_init_op", ",", "\n", "self", ".", "fmnist_vae", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", "=", "sess", ".", "run", "(", "\n", "[", "self", ".", "fmnist_vae", ".", "losses", ",", "self", ".", "fmnist_vae", ".", "regularizer", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.display_vae.generate": [[15, 39], ["tensorflow.get_default_graph().get_tensor_by_name", "tensorflow.get_default_graph().get_tensor_by_name", "sess.run", "matplotlib.figure", "range", "numpy.reshape", "plt.figure.add_subplot", "fig.add_subplot.imshow", "fig.add_subplot.axis", "tensorflow.get_default_graph", "tensorflow.get_default_graph", "range"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["def", "generate", "(", "sess", ",", "sampled_z", ",", "grid_size", "=", "5", ")", ":", "\n", "    ", "\"\"\"Function to generate images using the decoder.\n\n    Args:\n        sess (tf.Session): A TensorFlow session.\n        sampled_z (tf.Variable): Sampled ``z`` with dimensions ``latent size``\n            times ``number of examples``.\n        grid_size (int): Will display grid_size**2 number of generated images.\n\n    \"\"\"", "\n", "z", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "\"encoder/z:0\"", ")", "\n", "\n", "dec", "=", "tf", ".", "get_default_graph", "(", ")", ".", "get_tensor_by_name", "(", "\"decoder/decoder_op:0\"", ")", "\n", "imgs", "=", "sess", ".", "run", "(", "dec", ",", "feed_dict", "=", "{", "z", ":", "sampled_z", "}", ")", "\n", "imgs", "=", "[", "\n", "np", ".", "reshape", "(", "imgs", "[", "i", "]", ",", "[", "28", ",", "28", "]", ")", "for", "i", "in", "range", "(", "grid_size", "*", "grid_size", ")", "\n", "]", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "for", "i", "in", "range", "(", "grid_size", "*", "grid_size", ")", ":", "\n", "        ", "axis", "=", "fig", ".", "add_subplot", "(", "grid_size", ",", "grid_size", ",", "i", "+", "1", ")", "\n", "axis", ".", "imshow", "(", "imgs", "[", "i", "]", ",", "cmap", "=", "'gray'", ")", "\n", "axis", ".", "axis", "(", "\"off\"", ")", "\n", "", "return", "fig", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.display_vae.display_images": [[41, 81], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "numpy.random.seed", "testproblem_cls", "testproblem_cls.set_up", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.Session", "tf.Session.run", "tf.Session.run", "display_vae.generate", "generate.suptitle", "generate.show", "range", "numpy.random.normal", "tensorflow.reduce_mean", "tensorflow.global_variables_initializer", "display_vae.generate", "generate.suptitle", "generate.show", "range", "tensorflow.train.AdamOptimizer", "tf.Session.run", "str"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.display_vae.generate", "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.display_vae.generate", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "display_images", "(", "testproblem_cls", ",", "grid_size", "=", "5", ",", "num_epochs", "=", "1", ")", ":", "\n", "    ", "\"\"\"Display images from a DeepOBS data set.\n\n  Args:\n    testproblem_cls: The DeepOBS VAE testproblem class.\n    grid_size (int): Will display grid_size**2 number of generated images.\n  \"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "np", ".", "random", ".", "seed", "(", "42", ")", "\n", "sampled_z", "=", "[", "\n", "np", ".", "random", ".", "normal", "(", "0", ",", "1", ",", "8", ")", "for", "_", "in", "range", "(", "grid_size", "*", "grid_size", ")", "\n", "]", "\n", "\n", "testprob", "=", "testproblem_cls", "(", "batch_size", "=", "grid_size", "*", "grid_size", ")", "\n", "testprob", ".", "set_up", "(", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "testprob", ".", "losses", ")", "+", "testprob", ".", "regularizer", "\n", "train_step", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "0.0005", ")", ".", "minimize", "(", "loss", ")", "\n", "\n", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "sess", ".", "run", "(", "testprob", ".", "train_init_op", ")", "\n", "\n", "# Epoch 0", "\n", "fig", "=", "generate", "(", "sess", ",", "sampled_z", ",", "grid_size", "=", "grid_size", ")", "\n", "fig", ".", "suptitle", "(", "testproblem_cls", ".", "__name__", "+", "\" epoch 0\"", ")", "\n", "# fig.tight_layout(pad=0, w_pad=0, h_pad=0)", "\n", "fig", ".", "show", "(", ")", "\n", "# Train Loop", "\n", "for", "i", "in", "range", "(", "num_epochs", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "sess", ".", "run", "(", "train_step", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                ", "break", "\n", "", "", "fig", "=", "generate", "(", "sess", ",", "sampled_z", ",", "grid_size", "=", "grid_size", ")", "\n", "fig", ".", "suptitle", "(", "testproblem_cls", ".", "__name__", "+", "\" epoch \"", "+", "str", "(", "i", "+", "1", ")", ")", "\n", "# fig.tight_layout(pad=0, w_pad=0, h_pad=0)", "\n", "fig", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_mlp.MNIST_MLPTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.mnist_mlp"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "mnist_mlp", "=", "testproblems", ".", "mnist_mlp", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_mlp.MNIST_MLPTest.test_init_ops": [[23, 56], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_mnist_mlp.MNIST_MLPTest.mnist_mlp.set_up", "tensorflow.Session", "sess.run", "test_mnist_mlp.MNIST_MLPTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_mnist_mlp.MNIST_MLPTest.assertEqual", "test_mnist_mlp.MNIST_MLPTest.assertIsInstance", "test_mnist_mlp.MNIST_MLPTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "mnist_mlp", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "28", "*", "28", "*", "1000", ",", "1000", ",", "1000", "*", "500", ",", "500", ",", "500", "*", "100", ",", "100", ",", "\n", "100", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "mnist_mlp", ".", "train_init_op", ",", "self", ".", "mnist_mlp", ".", "test_init_op", ",", "\n", "self", ".", "mnist_mlp", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "mnist_mlp", ".", "losses", ",", "self", ".", "mnist_mlp", ".", "regularizer", ",", "\n", "self", ".", "mnist_mlp", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_imagenet_vgg16.Imagenet_VGG16Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.imagenet_vgg16"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up ImageNet dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "imagenet_vgg16", "=", "testproblems", ".", "imagenet_vgg16", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_imagenet_vgg16.Imagenet_VGG16Test.test_init_ops": [[23, 63], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_imagenet_vgg16.Imagenet_VGG16Test.imagenet_vgg16.set_up", "tensorflow.Session", "sess.run", "test_imagenet_vgg16.Imagenet_VGG16Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_imagenet_vgg16.Imagenet_VGG16Test.assertEqual", "test_imagenet_vgg16.Imagenet_VGG16Test.assertIsInstance", "test_imagenet_vgg16.Imagenet_VGG16Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "imagenet_vgg16", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "7", "*", "7", "*", "4096", ",", "4096", ",", "4096", "*", "4096", ",", "4096", ",", "4096", "*", "1001", ",", "1001", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "imagenet_vgg16", ".", "train_init_op", ",", "\n", "self", ".", "imagenet_vgg16", ".", "test_init_op", ",", "\n", "self", ".", "imagenet_vgg16", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "imagenet_vgg16", ".", "losses", ",", "\n", "self", ".", "imagenet_vgg16", ".", "regularizer", ",", "\n", "self", ".", "imagenet_vgg16", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_two_d_beale.Two_d_BealeTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.two_d_beale"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the 2D dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "two_d_beale", "=", "testproblems", ".", "two_d_beale", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_two_d_beale.Two_d_BealeTest.test_init_ops": [[23, 54], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_two_d_beale.Two_d_BealeTest.two_d_beale.set_up", "tensorflow.Session", "sess.run", "test_two_d_beale.Two_d_BealeTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_two_d_beale.Two_d_BealeTest.assertEqual", "test_two_d_beale.Two_d_BealeTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "two_d_beale", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "1", ",", "1", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "two_d_beale", ".", "train_init_op", ",", "\n", "self", ".", "two_d_beale", ".", "test_init_op", ",", "\n", "self", ".", "two_d_beale", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "two_d_beale", ".", "losses", ",", "self", ".", "two_d_beale", ".", "regularizer", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar10_3c3d.Cifar10_3c3dTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar10_3c3d"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-10 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar10_3c3d", "=", "testproblems", ".", "cifar10_3c3d", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar10_3c3d.Cifar10_3c3dTest.test_init_ops": [[23, 57], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar10_3c3d.Cifar10_3c3dTest.cifar10_3c3d.set_up", "tensorflow.Session", "sess.run", "test_cifar10_3c3d.Cifar10_3c3dTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar10_3c3d.Cifar10_3c3dTest.assertEqual", "test_cifar10_3c3d.Cifar10_3c3dTest.assertIsInstance", "test_cifar10_3c3d.Cifar10_3c3dTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar10_3c3d", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "5", "*", "5", ",", "64", ",", "64", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "3", "*", "3", "*", "128", "*", "512", ",", "512", ",", "512", "*", "256", ",", "256", ",", "256", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar10_3c3d", ".", "train_init_op", ",", "\n", "self", ".", "cifar10_3c3d", ".", "test_init_op", ",", "\n", "self", ".", "cifar10_3c3d", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar10_3c3d", ".", "losses", ",", "self", ".", "cifar10_3c3d", ".", "regularizer", ",", "\n", "self", ".", "cifar10_3c3d", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_mlp.FMNIST_MLPTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.fmnist_mlp"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up Fashion-MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "fmnist_mlp", "=", "testproblems", ".", "fmnist_mlp", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_fmnist_mlp.FMNIST_MLPTest.test_init_ops": [[23, 56], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_fmnist_mlp.FMNIST_MLPTest.fmnist_mlp.set_up", "tensorflow.Session", "sess.run", "test_fmnist_mlp.FMNIST_MLPTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_fmnist_mlp.FMNIST_MLPTest.assertEqual", "test_fmnist_mlp.FMNIST_MLPTest.assertIsInstance", "test_fmnist_mlp.FMNIST_MLPTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "fmnist_mlp", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "28", "*", "28", "*", "1000", ",", "1000", ",", "1000", "*", "500", ",", "500", ",", "500", "*", "100", ",", "100", ",", "\n", "100", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "fmnist_mlp", ".", "train_init_op", ",", "self", ".", "fmnist_mlp", ".", "test_init_op", ",", "\n", "self", ".", "fmnist_mlp", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "fmnist_mlp", ".", "losses", ",", "self", ".", "fmnist_mlp", ".", "regularizer", ",", "\n", "self", ".", "fmnist_mlp", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_imagenet_inception_v3.Imagenet_Inception_v3Test.setUp": [[21, 26], ["deepobs.tensorflow.testproblems.imagenet_inception_v3"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up ImageNet dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "1", "\n", "self", ".", "imagenet_inception_v3", "=", "testproblems", ".", "imagenet_inception_v3", "(", "\n", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_imagenet_inception_v3.Imagenet_Inception_v3Test.test_init_ops": [[27, 130], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_imagenet_inception_v3.Imagenet_Inception_v3Test.imagenet_inception_v3.set_up", "tensorflow.Session", "sess.run", "test_imagenet_inception_v3.Imagenet_Inception_v3Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_imagenet_inception_v3.Imagenet_Inception_v3Test.assertEqual", "test_imagenet_inception_v3.Imagenet_Inception_v3Test.assertIsInstance", "test_imagenet_inception_v3.Imagenet_Inception_v3Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "imagenet_inception_v3", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "\n", "num_param", ",", "[", "\n", "3", "*", "32", "*", "3", "*", "3", ",", "32", ",", "32", ",", "32", "*", "32", "*", "3", "*", "3", ",", "32", ",", "32", ",", "\n", "32", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "80", "*", "1", "*", "1", ",", "80", ",", "80", ",", "\n", "80", "*", "192", "*", "3", "*", "3", ",", "192", ",", "192", ",", "192", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "\n", "192", "*", "32", "*", "1", "*", "1", ",", "32", ",", "32", ",", "192", "*", "48", "*", "1", "*", "1", ",", "48", ",", "48", ",", "\n", "48", "*", "64", "*", "5", "*", "5", ",", "64", ",", "64", ",", "192", "*", "64", "*", "1", "*", "1", ",", "\n", "64", ",", "64", ",", "64", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", ",", "96", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", ",", "\n", "(", "64", "+", "32", "+", "64", "+", "96", ")", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "\n", "(", "64", "+", "32", "+", "64", "+", "96", ")", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "\n", "(", "64", "+", "32", "+", "64", "+", "96", ")", "*", "48", "*", "1", "*", "1", ",", "48", ",", "48", ",", "48", "*", "64", "*", "5", "*", "5", ",", "\n", "64", ",", "64", ",", "(", "64", "+", "32", "+", "64", "+", "96", ")", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "\n", "64", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", ",", "96", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", ",", "\n", "(", "64", "+", "64", "+", "64", "+", "96", ")", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "\n", "(", "64", "+", "64", "+", "64", "+", "96", ")", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "\n", "(", "64", "+", "64", "+", "64", "+", "96", ")", "*", "48", "*", "1", "*", "1", ",", "48", ",", "48", ",", "48", "*", "64", "*", "5", "*", "5", ",", "\n", "64", ",", "64", ",", "(", "64", "+", "64", "+", "64", "+", "96", ")", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "\n", "64", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", ",", "96", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", ",", "\n", "(", "64", "+", "64", "+", "64", "+", "96", ")", "*", "384", "*", "3", "*", "3", ",", "384", ",", "384", ",", "\n", "(", "64", "+", "64", "+", "64", "+", "96", ")", "*", "64", "*", "1", "*", "1", ",", "64", ",", "64", ",", "64", "*", "96", "*", "3", "*", "3", ",", "\n", "96", ",", "96", ",", "96", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", ",", "\n", "(", "(", "64", "+", "64", "+", "64", "+", "96", ")", "+", "384", "+", "96", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "(", "64", "+", "64", "+", "64", "+", "96", ")", "+", "384", "+", "96", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "(", "64", "+", "64", "+", "64", "+", "96", ")", "+", "384", "+", "96", ")", "*", "128", "*", "1", "*", "1", ",", "128", ",", "128", ",", "\n", "128", "*", "128", "*", "1", "*", "7", ",", "128", ",", "128", ",", "128", "*", "192", "*", "7", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "(", "64", "+", "64", "+", "64", "+", "96", ")", "+", "384", "+", "96", ")", "*", "128", "*", "1", "*", "1", ",", "128", ",", "128", ",", "\n", "128", "*", "128", "*", "7", "*", "1", ",", "128", ",", "128", ",", "128", "*", "128", "*", "1", "*", "7", ",", "128", ",", "128", ",", "\n", "128", "*", "128", "*", "7", "*", "1", ",", "128", ",", "128", ",", "128", "*", "192", "*", "1", "*", "7", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "160", "*", "1", "*", "1", ",", "160", ",", "160", ",", "\n", "160", "*", "160", "*", "1", "*", "7", ",", "160", ",", "160", ",", "160", "*", "192", "*", "7", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "160", "*", "1", "*", "1", ",", "160", ",", "160", ",", "\n", "160", "*", "160", "*", "7", "*", "1", ",", "160", ",", "160", ",", "160", "*", "160", "*", "1", "*", "7", ",", "160", ",", "160", ",", "\n", "160", "*", "160", "*", "7", "*", "1", ",", "160", ",", "160", ",", "160", "*", "192", "*", "1", "*", "7", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "160", "*", "1", "*", "1", ",", "160", ",", "160", ",", "\n", "160", "*", "160", "*", "1", "*", "7", ",", "160", ",", "160", ",", "160", "*", "192", "*", "7", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "160", "*", "1", "*", "1", ",", "160", ",", "160", ",", "\n", "160", "*", "160", "*", "7", "*", "1", ",", "160", ",", "160", ",", "160", "*", "160", "*", "1", "*", "7", ",", "160", ",", "160", ",", "\n", "160", "*", "160", "*", "7", "*", "1", ",", "160", ",", "160", ",", "160", "*", "192", "*", "1", "*", "7", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "192", "*", "192", "*", "1", "*", "7", ",", "192", ",", "192", ",", "192", "*", "192", "*", "7", "*", "1", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "192", "*", "192", "*", "7", "*", "1", ",", "192", ",", "192", ",", "192", "*", "192", "*", "1", "*", "7", ",", "192", ",", "192", ",", "\n", "192", "*", "192", "*", "7", "*", "1", ",", "192", ",", "192", ",", "192", "*", "192", "*", "1", "*", "7", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "128", "*", "1", "*", "1", ",", "128", ",", "128", ",", "\n", "128", "*", "768", "*", "5", "*", "5", ",", "768", ",", "768", ",", "768", "*", "1001", ",", "1001", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "192", "*", "192", "*", "1", "*", "7", ",", "192", ",", "192", ",", "192", "*", "192", "*", "7", "*", "1", ",", "\n", "192", ",", "192", ",", "192", "*", "192", "*", "3", "*", "3", ",", "192", ",", "192", ",", "\n", "(", "192", "+", "192", "+", "192", "+", "192", ")", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", ",", "\n", "192", "*", "320", "*", "3", "*", "3", ",", "320", ",", "320", ",", "\n", "(", "4", "*", "192", "+", "192", "+", "320", ")", "*", "320", "*", "1", "*", "1", ",", "320", ",", "320", ",", "\n", "(", "4", "*", "192", "+", "192", "+", "320", ")", "*", "384", "*", "1", "*", "1", ",", "384", ",", "384", ",", "\n", "384", "*", "384", "*", "1", "*", "3", ",", "384", ",", "384", ",", "384", "*", "384", "*", "3", "*", "1", ",", "384", ",", "384", ",", "\n", "(", "4", "*", "192", "+", "192", "+", "320", ")", "*", "448", "*", "1", "*", "1", ",", "448", ",", "448", ",", "\n", "448", "*", "384", "*", "3", "*", "3", ",", "384", ",", "384", ",", "\n", "384", "*", "384", "*", "1", "*", "3", ",", "384", ",", "384", ",", "384", "*", "384", "*", "3", "*", "1", ",", "384", ",", "384", ",", "\n", "(", "4", "*", "192", "+", "192", "+", "320", ")", "*", "192", ",", "192", ",", "192", ",", "\n", "(", "320", "+", "384", "*", "2", "+", "384", "*", "2", "+", "192", ")", "*", "320", "*", "1", "*", "1", ",", "320", ",", "320", ",", "\n", "(", "320", "+", "384", "*", "2", "+", "384", "*", "2", "+", "192", ")", "*", "384", "*", "1", "*", "1", ",", "384", ",", "384", ",", "\n", "384", "*", "384", "*", "1", "*", "3", ",", "384", ",", "384", ",", "384", "*", "384", "*", "3", "*", "1", ",", "384", ",", "384", ",", "\n", "(", "320", "+", "384", "*", "2", "+", "384", "*", "2", "+", "192", ")", "*", "448", "*", "1", "*", "1", ",", "448", ",", "448", ",", "\n", "448", "*", "384", "*", "3", "*", "3", ",", "384", ",", "384", ",", "384", "*", "384", "*", "1", "*", "3", ",", "384", ",", "\n", "384", ",", "384", "*", "384", "*", "3", "*", "1", ",", "384", ",", "384", ",", "\n", "(", "320", "+", "384", "*", "2", "+", "384", "*", "2", "+", "192", ")", "*", "192", ",", "192", ",", "192", ",", "\n", "2048", "*", "1001", ",", "1001", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "imagenet_inception_v3", ".", "train_init_op", ",", "\n", "self", ".", "imagenet_inception_v3", ".", "test_init_op", ",", "\n", "self", ".", "imagenet_inception_v3", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "imagenet_inception_v3", ".", "losses", ",", "\n", "self", ".", "imagenet_inception_v3", ".", "regularizer", ",", "\n", "self", ".", "imagenet_inception_v3", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar10_vgg19.Cifar10_VGG19Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar10_vgg19"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-10 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar10_vgg19", "=", "testproblems", ".", "cifar10_vgg19", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar10_vgg19.Cifar10_VGG19Test.test_init_ops": [[23, 64], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar10_vgg19.Cifar10_VGG19Test.cifar10_vgg19.set_up", "tensorflow.Session", "sess.run", "test_cifar10_vgg19.Cifar10_VGG19Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar10_vgg19.Cifar10_VGG19Test.assertEqual", "test_cifar10_vgg19.Cifar10_VGG19Test.assertIsInstance", "test_cifar10_vgg19.Cifar10_VGG19Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar10_vgg19", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "7", "*", "7", "*", "4096", ",", "4096", ",", "4096", "*", "4096", ",", "\n", "4096", ",", "4096", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar10_vgg19", ".", "train_init_op", ",", "\n", "self", ".", "cifar10_vgg19", ".", "test_init_op", ",", "\n", "self", ".", "cifar10_vgg19", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar10_vgg19", ".", "losses", ",", "self", ".", "cifar10_vgg19", ".", "regularizer", ",", "\n", "self", ".", "cifar10_vgg19", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_svhn_wrn164.SVHN_WRN164Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.svhn_wrn164"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up SVHN dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "svhn_wrn164", "=", "testproblems", ".", "svhn_wrn164", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_svhn_wrn164.SVHN_WRN164Test.test_init_ops": [[23, 63], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_svhn_wrn164.SVHN_WRN164Test.svhn_wrn164.set_up", "tensorflow.Session", "sess.run", "test_svhn_wrn164.SVHN_WRN164Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_svhn_wrn164.SVHN_WRN164Test.assertEqual", "test_svhn_wrn164.SVHN_WRN164Test.assertIsInstance", "test_svhn_wrn164.SVHN_WRN164Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "svhn_wrn164", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "16", "*", "3", "*", "3", ",", "16", ",", "16", ",", "16", "*", "64", "*", "1", "*", "1", ",", "16", "*", "64", "*", "3", "*", "3", ",", "64", ",", "\n", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "\n", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", ",", "64", "*", "128", "*", "1", "*", "1", ",", "64", "*", "128", "*", "3", "*", "3", ",", "\n", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", ",", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", ",", "128", "*", "256", "*", "1", "*", "1", ",", "\n", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", ",", "\n", "256", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "svhn_wrn164", ".", "train_init_op", ",", "\n", "self", ".", "svhn_wrn164", ".", "test_init_op", ",", "\n", "self", ".", "svhn_wrn164", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "svhn_wrn164", ".", "losses", ",", "self", ".", "svhn_wrn164", ".", "regularizer", ",", "\n", "self", ".", "svhn_wrn164", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_2c2d.MNIST_2c2dTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.mnist_2c2d"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up MNIST dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "mnist_2c2d", "=", "testproblems", ".", "mnist_2c2d", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_mnist_2c2d.MNIST_2c2dTest.test_init_ops": [[23, 57], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_mnist_2c2d.MNIST_2c2dTest.mnist_2c2d.set_up", "tensorflow.Session", "sess.run", "test_mnist_2c2d.MNIST_2c2dTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_mnist_2c2d.MNIST_2c2dTest.assertEqual", "test_mnist_2c2d.MNIST_2c2dTest.assertIsInstance", "test_mnist_2c2d.MNIST_2c2dTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "mnist_2c2d", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "1", "*", "32", "*", "5", "*", "5", ",", "32", ",", "32", "*", "64", "*", "5", "*", "5", ",", "64", ",", "7", "*", "7", "*", "64", "*", "1024", ",", "\n", "1024", ",", "1024", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "mnist_2c2d", ".", "train_init_op", ",", "\n", "self", ".", "mnist_2c2d", ".", "test_init_op", ",", "\n", "self", ".", "mnist_2c2d", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "mnist_2c2d", ".", "losses", ",", "self", ".", "mnist_2c2d", ".", "regularizer", ",", "\n", "self", ".", "mnist_2c2d", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_svhn_3c3d.SVHN_3c3dTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.svhn_3c3d"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up SVHN dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "svhn_3c3d", "=", "testproblems", ".", "svhn_3c3d", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_svhn_3c3d.SVHN_3c3dTest.test_init_ops": [[23, 57], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_svhn_3c3d.SVHN_3c3dTest.svhn_3c3d.set_up", "tensorflow.Session", "sess.run", "test_svhn_3c3d.SVHN_3c3dTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_svhn_3c3d.SVHN_3c3dTest.assertEqual", "test_svhn_3c3d.SVHN_3c3dTest.assertIsInstance", "test_svhn_3c3d.SVHN_3c3dTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "svhn_3c3d", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "5", "*", "5", ",", "64", ",", "64", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "3", "*", "3", "*", "128", "*", "512", ",", "512", ",", "512", "*", "256", ",", "256", ",", "256", "*", "10", ",", "10", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "svhn_3c3d", ".", "train_init_op", ",", "\n", "self", ".", "svhn_3c3d", ".", "test_init_op", ",", "\n", "self", ".", "svhn_3c3d", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "svhn_3c3d", ".", "losses", ",", "self", ".", "svhn_3c3d", ".", "regularizer", ",", "\n", "self", ".", "svhn_3c3d", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_vgg16.Cifar100_VGG16Test.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar100_vgg16"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-100 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar100_vgg16", "=", "testproblems", ".", "cifar100_vgg16", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_vgg16.Cifar100_VGG16Test.test_init_ops": [[23, 62], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar100_vgg16.Cifar100_VGG16Test.cifar100_vgg16.set_up", "tensorflow.Session", "sess.run", "test_cifar100_vgg16.Cifar100_VGG16Test.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar100_vgg16.Cifar100_VGG16Test.assertEqual", "test_cifar100_vgg16.Cifar100_VGG16Test.assertIsInstance", "test_cifar100_vgg16.Cifar100_VGG16Test.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar100_vgg16", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "64", "*", "3", "*", "3", ",", "64", ",", "64", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "128", "*", "128", "*", "3", "*", "3", ",", "128", ",", "128", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "256", "*", "256", "*", "3", "*", "3", ",", "256", ",", "\n", "256", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "512", "*", "512", "*", "3", "*", "3", ",", "512", ",", "\n", "512", "*", "7", "*", "7", "*", "4096", ",", "4096", ",", "4096", "*", "4096", ",", "4096", ",", "4096", "*", "100", ",", "100", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar100_vgg16", ".", "train_init_op", ",", "\n", "self", ".", "cifar100_vgg16", ".", "test_init_op", ",", "\n", "self", ".", "cifar100_vgg16", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar100_vgg16", ".", "losses", ",", "self", ".", "cifar100_vgg16", ".", "regularizer", ",", "\n", "self", ".", "cifar100_vgg16", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_quadratic_deep.Quadratic_DeepTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.quadratic_deep"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the quadratic dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "10", "\n", "self", ".", "quadratic_deep", "=", "testproblems", ".", "quadratic_deep", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_quadratic_deep.Quadratic_DeepTest.test_init_ops": [[23, 54], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_quadratic_deep.Quadratic_DeepTest.quadratic_deep.set_up", "tensorflow.Session", "sess.run", "test_quadratic_deep.Quadratic_DeepTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_quadratic_deep.Quadratic_DeepTest.assertEqual", "test_quadratic_deep.Quadratic_DeepTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "quadratic_deep", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "100", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "quadratic_deep", ".", "train_init_op", ",", "\n", "self", ".", "quadratic_deep", ".", "test_init_op", ",", "\n", "self", ".", "quadratic_deep", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "quadratic_deep", ".", "losses", ",", "self", ".", "quadratic_deep", ".", "regularizer", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_quadratic_deep.Quadratic_DeepTest.test_repeatability": [[55, 61], ["deepobs.tensorflow.testproblems.quadratic_deep", "deepobs.tensorflow.testproblems.quadratic_deep", "numpy.testing.assert_almost_equal"], "methods", ["None"], ["", "", "", "def", "test_repeatability", "(", "self", ")", ":", "\n", "\n", "        ", "quadratic_deep_1", "=", "testproblems", ".", "quadratic_deep", "(", "batch_size", "=", "1", ")", "\n", "quadratic_deep_2", "=", "testproblems", ".", "quadratic_deep", "(", "batch_size", "=", "1", ")", "\n", "\n", "np", ".", "testing", ".", "assert_almost_equal", "(", "quadratic_deep_1", ".", "_hessian", ",", "quadratic_deep_2", ".", "_hessian", ",", "decimal", "=", "5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_3c3d.Cifar100_3c3dTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar100_3c3d"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-100 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar100_3c3d", "=", "testproblems", ".", "cifar100_3c3d", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_3c3d.Cifar100_3c3dTest.test_init_ops": [[23, 57], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar100_3c3d.Cifar100_3c3dTest.cifar100_3c3d.set_up", "tensorflow.Session", "sess.run", "test_cifar100_3c3d.Cifar100_3c3dTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar100_3c3d.Cifar100_3c3dTest.assertEqual", "test_cifar100_3c3d.Cifar100_3c3dTest.assertIsInstance", "test_cifar100_3c3d.Cifar100_3c3dTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar100_3c3d", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "64", "*", "5", "*", "5", ",", "64", ",", "64", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", "*", "128", "*", "3", "*", "3", ",", "128", ",", "\n", "3", "*", "3", "*", "128", "*", "512", ",", "512", ",", "512", "*", "256", ",", "256", ",", "256", "*", "100", ",", "100", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar100_3c3d", ".", "train_init_op", ",", "\n", "self", ".", "cifar100_3c3d", ".", "test_init_op", ",", "\n", "self", ".", "cifar100_3c3d", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar100_3c3d", ".", "losses", ",", "self", ".", "cifar100_3c3d", ".", "regularizer", ",", "\n", "self", ".", "cifar100_3c3d", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_allcnnc.Cifar100_AllCNNCTest.setUp": [[18, 22], ["deepobs.tensorflow.testproblems.cifar100_allcnnc"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up CIFAR-100 dataset for the tests.\"\"\"", "\n", "self", ".", "batch_size", "=", "100", "\n", "self", ".", "cifar100_allcnnc", "=", "testproblems", ".", "cifar100_allcnnc", "(", "self", ".", "batch_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.test_cifar100_allcnnc.Cifar100_AllCNNCTest.test_init_ops": [[23, 60], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "test_cifar100_allcnnc.Cifar100_AllCNNCTest.cifar100_allcnnc.set_up", "tensorflow.Session", "sess.run", "test_cifar100_allcnnc.Cifar100_AllCNNCTest.assertEqual", "tensorflow.global_variables_initializer", "numpy.prod", "sess.run", "sess.run", "test_cifar100_allcnnc.Cifar100_AllCNNCTest.assertEqual", "test_cifar100_allcnnc.Cifar100_AllCNNCTest.assertIsInstance", "test_cifar100_allcnnc.Cifar100_AllCNNCTest.assertIsInstance", "v.get_shape().as_list", "tensorflow.trainable_variables", "v.get_shape"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run"], ["", "def", "test_init_ops", "(", "self", ")", ":", "\n", "        ", "\"\"\"Tests all three initialization operations.\"\"\"", "\n", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "42", ")", "\n", "self", ".", "cifar100_allcnnc", ".", "set_up", "(", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "num_param", "=", "[", "\n", "np", ".", "prod", "(", "v", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", "\n", "]", "\n", "# Check if number of parameters per \"layer\" is equal to what we expect", "\n", "# We will write them in the following form:", "\n", "# - Conv layer: [input_filter*output_filter*kernel[0]*kernel[1]]", "\n", "# - Batch norm: [input, input] (for beta and gamma)", "\n", "# - Fully connected: [input*output]", "\n", "# - Bias: [dim]", "\n", "self", ".", "assertEqual", "(", "num_param", ",", "[", "\n", "3", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", "*", "96", "*", "3", "*", "3", ",", "96", ",", "96", "*", "96", "*", "3", "*", "3", ",", "96", ",", "\n", "96", "*", "192", "*", "3", "*", "3", ",", "192", ",", "192", "*", "192", "*", "3", "*", "3", ",", "192", ",", "\n", "192", "*", "192", "*", "3", "*", "3", ",", "192", ",", "192", "*", "192", "*", "3", "*", "3", ",", "192", ",", "\n", "192", "*", "192", "*", "1", "*", "1", ",", "192", ",", "192", "*", "100", "*", "1", "*", "1", ",", "100", "\n", "]", ")", "\n", "for", "init_op", "in", "[", "\n", "self", ".", "cifar100_allcnnc", ".", "train_init_op", ",", "\n", "self", ".", "cifar100_allcnnc", ".", "test_init_op", ",", "\n", "self", ".", "cifar100_allcnnc", ".", "train_eval_init_op", "\n", "]", ":", "\n", "                ", "sess", ".", "run", "(", "init_op", ")", "\n", "losses_", ",", "regularizer_", ",", "accuracy_", "=", "sess", ".", "run", "(", "[", "\n", "self", ".", "cifar100_allcnnc", ".", "losses", ",", "\n", "self", ".", "cifar100_allcnnc", ".", "regularizer", ",", "\n", "self", ".", "cifar100_allcnnc", ".", "accuracy", "\n", "]", ")", "\n", "self", ".", "assertEqual", "(", "losses_", ".", "shape", ",", "(", "self", ".", "batch_size", ",", ")", ")", "\n", "self", ".", "assertIsInstance", "(", "regularizer_", ",", "np", ".", "float32", ")", "\n", "self", ".", "assertIsInstance", "(", "accuracy_", ",", "np", ".", "float32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._logreg._logreg": [[11, 26], ["tensorflow.reshape", "_logreg._logreg.dense"], "function", ["None"], ["def", "_logreg", "(", "x", ",", "num_outputs", ")", ":", "\n", "    ", "def", "dense", "(", "inputs", ",", "units", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for max pool layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", ",", "\n", "units", ",", "\n", "activation", "=", "None", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.0", ")", ",", "\n", "kernel_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.0", ")", ")", "\n", "\n", "", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "784", "]", ")", "\n", "\n", "linear_outputs", "=", "dense", "(", "x", ",", "num_outputs", ")", "\n", "\n", "return", "linear_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._3c3d._3c3d": [[11, 62], ["_3c3d._3c3d.conv2d"], "function", ["None"], ["def", "_3c3d", "(", "x", ",", "num_outputs", ",", "weight_decay", ")", ":", "\n", "    ", "def", "conv2d", "(", "inputs", ",", "filters", ",", "kernel_size", "=", "3", ",", "padding", "=", "\"same\"", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for conv layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "(", "1", ",", "1", ")", ",", "\n", "padding", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.0", ")", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "glorot_normal", "(", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", ")", "\n", "\n", "", "def", "max_pool", "(", "inputs", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for max pool layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "\n", "inputs", ",", "\n", "pool_size", "=", "3", ",", "\n", "strides", "=", "2", ",", "\n", "padding", "=", "'same'", ",", "\n", ")", "\n", "\n", "", "def", "dense", "(", "inputs", ",", "units", ",", "activation", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for max pool layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", ",", "\n", "units", ",", "\n", "activation", ",", "\n", "kernel_initializer", "=", "tf", ".", "initializers", ".", "glorot_uniform", "(", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.0", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", ")", "\n", "\n", "", "x", "=", "conv2d", "(", "x", ",", "64", ",", "5", ",", "\"valid\"", ")", "\n", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "96", ",", "3", ",", "\"valid\"", ")", "\n", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "128", ",", "3", ",", "\"same\"", ")", "\n", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "stack", "(", "[", "-", "1", ",", "3", "*", "3", "*", "128", "]", ")", ")", "\n", "\n", "x", "=", "dense", "(", "x", ",", "512", ",", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "x", "=", "dense", "(", "x", ",", "256", ",", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "linear_outputs", "=", "dense", "(", "x", ",", "num_outputs", ",", "None", ")", "\n", "\n", "return", "linear_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_3c3d.svhn_3c3d.__init__": [[46, 55], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "0.002", ")", ":", "\n", "        ", "\"\"\"Create a new 3c3d test problem instance on SVHN.\n\n        Args:\n            batch_size (int): Batch size to use.\n            weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n                is used on the weights but not the biases. Defaults to ``0.002``.\n        \"\"\"", "\n", "super", "(", "svhn_3c3d", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_3c3d.svhn_3c3d.set_up": [[56, 78], ["datasets.svhn.svhn", "_3c3d._3c3d._3c3d", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._3c3d._3c3d"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the vanilla CNN test problem on SVHN.\"\"\"", "\n", "self", ".", "dataset", "=", "svhn", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_3c3d", "(", "\n", "x", ",", "num_outputs", "=", "10", ",", "weight_decay", "=", "self", ".", "_weight_decay", "\n", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", "\n", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn.__init__": [[49, 63], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new Char RNN test problem instance on Tolstoi.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "tolstoi_char_rnn", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn.set_up": [[65, 159], ["datasets.tolstoi.tolstoi", "tensorflow.cond", "tensorflow.cond", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.split", "range", "tensorflow.contrib.rnn.MultiRNNCell", "tolstoi_char_rnn.tolstoi_char_rnn._get_state_variables", "tensorflow.nn.static_rnn", "tensorflow.reshape", "tensorflow.contrib.seq2seq.sequence_loss", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.group", "tensorflow.group", "tensorflow.group", "tensorflow.equal", "tensorflow.equal", "tensorflow.squeeze", "tensorflow.contrib.rnn.LSTMCell", "tensorflow.contrib.rnn.DropoutWrapper", "cells.append", "tensorflow.control_dependencies", "tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op", "tensorflow.control_dependencies", "tensorflow.reshape", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.matmul", "tensorflow.cast", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.concat", "tensorflow.ones", "tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op", "tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op", "tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn._get_state_variables", "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op", "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op", "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op", "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the Char RNN test problem instance on Tolstoi.\"\"\"", "\n", "self", ".", "dataset", "=", "tolstoi", "(", "self", ".", "_batch_size", ")", "\n", "\n", "seq_length", "=", "50", "\n", "vocab_size", "=", "83", "# For War and Peace", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "\n", "num_layers", "=", "2", "\n", "rnn_size", "=", "128", "\n", "\n", "input_keep_prob", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "tf", ".", "constant", "(", "\"train\"", ")", ")", ",", "\n", "lambda", ":", "tf", ".", "constant", "(", "0.8", ")", ",", "lambda", ":", "tf", ".", "constant", "(", "1.0", ")", ")", "\n", "output_keep_prob", "=", "tf", ".", "cond", "(", "\n", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "tf", ".", "constant", "(", "\"train\"", ")", ")", ",", "\n", "lambda", ":", "tf", ".", "constant", "(", "0.8", ")", ",", "lambda", ":", "tf", ".", "constant", "(", "1.0", ")", ")", "\n", "\n", "# Create an embedding matrix, look up embedding of input", "\n", "embedding", "=", "tf", ".", "get_variable", "(", "\"embedding\"", ",", "[", "vocab_size", ",", "rnn_size", "]", ")", "\n", "inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "embedding", ",", "x", ")", "\n", "\n", "# Split batch of input sequences along time, such that inputs[i] is a", "\n", "# batch_size x embedding_size representation of the batch of characters", "\n", "# at position i of this batch of sequences", "\n", "inputs", "=", "tf", ".", "split", "(", "inputs", ",", "seq_length", ",", "axis", "=", "1", ")", "\n", "inputs", "=", "[", "tf", ".", "squeeze", "(", "input_", ",", "[", "1", "]", ")", "for", "input_", "in", "inputs", "]", "\n", "\n", "# Make Multi LSTM cell", "\n", "cells", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "num_layers", ")", ":", "\n", "            ", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "LSTMCell", "(", "rnn_size", ")", "\n", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "DropoutWrapper", "(", "\n", "cell", ",", "\n", "input_keep_prob", "=", "input_keep_prob", ",", "\n", "output_keep_prob", "=", "output_keep_prob", ")", "\n", "cells", ".", "append", "(", "cell", ")", "\n", "", "cell", "=", "tf", ".", "contrib", ".", "rnn", ".", "MultiRNNCell", "(", "cells", ",", "state_is_tuple", "=", "True", ")", "\n", "\n", "# Create RNN using the cell defined above, (including operations that store)", "\n", "# the state in variables", "\n", "self", ".", "state_variables", ",", "self", ".", "zero_states", "=", "self", ".", "_get_state_variables", "(", "\n", "self", ".", "_batch_size", ",", "cell", ")", "\n", "\n", "outputs", ",", "new_states", "=", "tf", ".", "nn", ".", "static_rnn", "(", "\n", "cell", ",", "inputs", ",", "initial_state", "=", "self", ".", "state_variables", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "outputs", ")", ":", "\n", "            ", "state_update_op", "=", "self", ".", "_get_state_update_op", "(", "self", ".", "state_variables", ",", "\n", "new_states", ")", "\n", "\n", "# Reshape RNN output for multiplication with softmax layer", "\n", "# print \"Shape of outputs\", [output.get_shape() for output in outputs]", "\n", "", "with", "tf", ".", "control_dependencies", "(", "state_update_op", ")", ":", "\n", "            ", "output", "=", "tf", ".", "reshape", "(", "tf", ".", "concat", "(", "outputs", ",", "1", ")", ",", "[", "-", "1", ",", "rnn_size", "]", ")", "\n", "# print \"Shape of output\", output.get_shape()", "\n", "\n", "# Apply softmax layer", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"rnnlm\"", ")", ":", "\n", "            ", "softmax_w", "=", "tf", ".", "get_variable", "(", "\"softmax_w\"", ",", "[", "rnn_size", ",", "vocab_size", "]", ")", "\n", "softmax_b", "=", "tf", ".", "get_variable", "(", "\"softmax_b\"", ",", "[", "vocab_size", "]", ")", "\n", "", "logits", "=", "tf", ".", "matmul", "(", "output", ",", "softmax_w", ")", "+", "softmax_b", "\n", "# print logits.get_shape()", "\n", "\n", "# Reshape logits to batch_size x seq_length x vocab size", "\n", "reshaped_logits", "=", "tf", ".", "reshape", "(", "\n", "logits", ",", "[", "self", ".", "_batch_size", ",", "seq_length", ",", "vocab_size", "]", ")", "\n", "# print \"Shape of reshaped logits\", reshaped_logits.get_shape()", "\n", "\n", "# Create vector of losses", "\n", "self", ".", "losses", "=", "tf", ".", "contrib", ".", "seq2seq", ".", "sequence_loss", "(", "\n", "reshaped_logits", ",", "\n", "y", ",", "\n", "weights", "=", "tf", ".", "ones", "(", "[", "self", ".", "_batch_size", ",", "seq_length", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "average_across_timesteps", "=", "True", ",", "\n", "average_across_batch", "=", "False", ")", "\n", "\n", "predictions", "=", "tf", ".", "argmax", "(", "reshaped_logits", ",", "2", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "predictions", ",", "y", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "\n", "self", ".", "train_init_op", "=", "tf", ".", "group", "(", "[", "\n", "self", ".", "dataset", ".", "train_init_op", ",", "\n", "self", ".", "_get_state_update_op", "(", "self", ".", "state_variables", ",", "self", ".", "zero_states", ")", "\n", "]", ")", "\n", "self", ".", "train_eval_init_op", "=", "tf", ".", "group", "(", "[", "\n", "self", ".", "dataset", ".", "train_eval_init_op", ",", "\n", "self", ".", "_get_state_update_op", "(", "self", ".", "state_variables", ",", "self", ".", "zero_states", ")", "\n", "]", ")", "\n", "self", ".", "test_init_op", "=", "tf", ".", "group", "(", "[", "\n", "self", ".", "dataset", ".", "test_init_op", ",", "\n", "self", ".", "_get_state_update_op", "(", "self", ".", "state_variables", ",", "self", ".", "zero_states", ")", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn._get_state_variables": [[161, 184], ["cell.zero_state", "state_variables.append", "tuple", "tensorflow.contrib.rnn.LSTMStateTuple", "tensorflow.Variable", "tensorflow.Variable"], "methods", ["None"], ["", "def", "_get_state_variables", "(", "self", ",", "batch_size", ",", "cell", ")", ":", "\n", "        ", "\"\"\"For each layer, get the initial state and make a variable out of it\n        to enable updating its value.\n\n        Args:\n            batch_size (int): Batch size.\n            cell (tf.BasicLSTMCell): LSTM cell to get the initial state for.\n\n        Returns:\n            tupel: Tupel of the state variables and there zero states.\n\n        \"\"\"", "\n", "# For each layer, get the initial state and make a variable out of it", "\n", "# to enable updating its value.", "\n", "zero_state", "=", "cell", ".", "zero_state", "(", "batch_size", ",", "tf", ".", "float32", ")", "\n", "state_variables", "=", "[", "]", "\n", "for", "state_c", ",", "state_h", "in", "zero_state", ":", "\n", "            ", "state_variables", ".", "append", "(", "\n", "tf", ".", "contrib", ".", "rnn", ".", "LSTMStateTuple", "(", "\n", "tf", ".", "Variable", "(", "state_c", ",", "trainable", "=", "False", ")", ",", "\n", "tf", ".", "Variable", "(", "state_h", ",", "trainable", "=", "False", ")", ")", ")", "\n", "# Return as a tuple, so that it can be fed to dynamic_rnn as an initial state", "\n", "", "return", "tuple", "(", "state_variables", ")", ",", "zero_state", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.tolstoi_char_rnn.tolstoi_char_rnn._get_state_update_op": [[185, 208], ["zip", "tensorflow.tuple", "update_ops.extend", "state_variable[].assign", "state_variable[].assign"], "methods", ["None"], ["", "def", "_get_state_update_op", "(", "self", ",", "state_variables", ",", "new_states", ")", ":", "\n", "        ", "\"\"\"Add an operation to update the train states with the last state tensors\n\n        Args:\n            state_variables (tf.Variable): State variables to be updated\n            new_states (tf.Variable): New state of the state variable.\n\n        Returns:\n            tf.Operation: Return a tuple in order to combine all update_ops into a\n            single operation. The tuple's actual value should not be used.\n\n        \"\"\"", "\n", "# Add an operation to update the train states with the last state tensors", "\n", "update_ops", "=", "[", "]", "\n", "for", "state_variable", ",", "new_state", "in", "zip", "(", "state_variables", ",", "new_states", ")", ":", "\n", "# Assign the new state to the state variables on this layer", "\n", "            ", "update_ops", ".", "extend", "(", "[", "\n", "state_variable", "[", "0", "]", ".", "assign", "(", "new_state", "[", "0", "]", ")", ",", "\n", "state_variable", "[", "1", "]", ".", "assign", "(", "new_state", "[", "1", "]", ")", "\n", "]", ")", "\n", "# Return a tuple in order to combine all update_ops into a single operation.", "\n", "# The tuple's actual value should not be used.", "\n", "", "return", "tf", ".", "tuple", "(", "update_ops", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.imagenet_vgg16.imagenet_vgg16.__init__": [[41, 51], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Create a new VGG 16 test problem instance on ImageNet.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "imagenet_vgg16", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.imagenet_vgg16.imagenet_vgg16.set_up": [[52, 76], ["datasets.imagenet.imagenet", "tensorflow.equal", "_vgg._vgg._vgg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vgg._vgg"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the VGG 16 test problem on ImageNet.\"\"\"", "\n", "self", ".", "dataset", "=", "imagenet", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_vgg", "(", "\n", "x", ",", "\n", "training", ",", "\n", "variant", "=", "16", ",", "\n", "num_outputs", "=", "1001", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.two_d_rosenbrock.two_d_rosenbrock.__init__": [[44, 58], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new 2D Rosenbrock Test Problem instance.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "two_d_rosenbrock", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.two_d_rosenbrock.two_d_rosenbrock.set_up": [[60, 88], ["datasets.two_d.two_d", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.losses.get_regularization_loss", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "methods", ["None"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the stochastic two-dimensional Rosenbrock test problem.\n        Using ``-0.5`` and ``1.5`` as a starting point for the weights ``u``\n        and ``v``.\n        \"\"\"", "\n", "self", ".", "dataset", "=", "two_d", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "\n", "# Set starting point", "\n", "starting_point", "=", "[", "-", "0.5", ",", "1.5", "]", "\n", "\n", "# Set model weights", "\n", "u", "=", "tf", ".", "get_variable", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "starting_point", "[", "0", "]", ")", ")", "\n", "v", "=", "tf", ".", "get_variable", "(", "\n", "\"bias\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "starting_point", "[", "1", "]", ")", ")", "\n", "\n", "self", ".", "losses", "=", "(", "1", "-", "u", ")", "**", "2", "+", "100", "*", "(", "v", "-", "u", "**", "2", ")", "**", "2", "+", "u", "*", "x", "+", "v", "*", "y", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._wrn._wrn": [[11, 112], ["_wrn._wrn.conv2d"], "function", ["None"], ["def", "_wrn", "(", "x", ",", "\n", "training", ",", "\n", "num_residual_units", ",", "\n", "widening_factor", ",", "\n", "num_outputs", ",", "\n", "weight_decay", ",", "\n", "bn_momentum", "=", "0.9", ")", ":", "\n", "    ", "def", "conv2d", "(", "inputs", ",", "filters", ",", "kernel_size", ",", "strides", "=", "1", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for conv layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "strides", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "tf", ".", "initializers", ".", "glorot_uniform", "(", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", ")", "\n", "\n", "", "def", "batch_normalization", "(", "inputs", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for batch norm.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "batch_normalization", "(", "\n", "inputs", ",", "\n", "axis", "=", "-", "1", ",", "\n", "momentum", "=", "bn_momentum", ",", "\n", "epsilon", "=", "1e-5", ",", "\n", "training", "=", "training", ")", "\n", "\n", "# Number of filter channels and stride for the blocks", "\n", "", "filters", "=", "[", "\n", "16", ",", "16", "*", "widening_factor", ",", "32", "*", "widening_factor", ",", "64", "*", "widening_factor", "\n", "]", "\n", "strides", "=", "[", "1", ",", "2", ",", "2", "]", "\n", "\n", "# Initial convolution layer", "\n", "x", "=", "conv2d", "(", "x", ",", "16", ",", "3", ")", "\n", "\n", "# Loop over three residual blocks", "\n", "for", "i", "in", "range", "(", "1", ",", "4", ",", "1", ")", ":", "\n", "\n", "# First residual unit", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "'unit_%d_0'", "%", "i", ")", ":", "\n", "            ", "x", "=", "batch_normalization", "(", "x", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "# Shortcut", "\n", "if", "filters", "[", "i", "-", "1", "]", "==", "filters", "[", "i", "]", ":", "\n", "                ", "if", "strides", "[", "i", "-", "1", "]", "==", "1", ":", "\n", "                    ", "shortcut", "=", "tf", ".", "identity", "(", "x", ")", "\n", "", "else", ":", "\n", "                    ", "shortcut", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "x", ",", "strides", "[", "i", "-", "1", "]", ",", "\n", "strides", "[", "i", "-", "1", "]", ")", "\n", "\n", "\n", "#          shortcut = tf.nn.max_pool(x, [1, strides[i - 1], strides[i - 1], 1],", "\n", "#                                    [1, strides[i - 1], strides[i - 1], 1], 'VALID')", "\n", "", "", "else", ":", "\n", "                ", "shortcut", "=", "conv2d", "(", "x", ",", "filters", "[", "i", "]", ",", "1", ",", "strides", "=", "strides", "[", "i", "-", "1", "]", ")", "\n", "# Residual", "\n", "", "x", "=", "conv2d", "(", "x", ",", "filters", "[", "i", "]", ",", "3", ",", "strides", "[", "i", "-", "1", "]", ")", "\n", "x", "=", "batch_normalization", "(", "x", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "filters", "[", "i", "]", ",", "3", ",", "1", ")", "\n", "\n", "# Merge", "\n", "x", "=", "x", "+", "shortcut", "\n", "\n", "# further residual units", "\n", "", "for", "j", "in", "range", "(", "1", ",", "num_residual_units", ",", "1", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "'unit_%d_%d'", "%", "(", "i", ",", "j", ")", ")", ":", "\n", "# Shortcut", "\n", "                ", "shortcut", "=", "x", "\n", "\n", "# Residual", "\n", "x", "=", "batch_normalization", "(", "x", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "filters", "[", "i", "]", ",", "3", ",", "1", ")", "\n", "x", "=", "batch_normalization", "(", "x", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "filters", "[", "i", "]", ",", "3", ",", "1", ")", "\n", "\n", "# Merge", "\n", "x", "=", "x", "+", "shortcut", "\n", "\n", "# Last unit", "\n", "", "", "", "with", "tf", ".", "variable_scope", "(", "'unit_last'", ")", ":", "\n", "        ", "x", "=", "batch_normalization", "(", "x", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "x", "=", "tf", ".", "reduce_mean", "(", "x", ",", "[", "1", ",", "2", "]", ")", "\n", "\n", "# Reshaping and final fully-connected layer", "\n", "", "with", "tf", ".", "variable_scope", "(", "'fully-connected'", ")", ":", "\n", "        ", "x_shape", "=", "x", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "x_shape", "[", "1", "]", "]", ")", "\n", "linear_outputs", "=", "tf", ".", "layers", ".", "dense", "(", "\n", "x", ",", "\n", "num_outputs", ",", "\n", "kernel_initializer", "=", "tf", ".", "initializers", ".", "glorot_uniform", "(", ")", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.0", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", ")", "\n", "\n", "", "return", "linear_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_logreg.fmnist_logreg.__init__": [[37, 51], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new logistic regression test problem instance on Fashion-MNIST.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "fmnist_logreg", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_logreg.fmnist_logreg.set_up": [[53, 72], ["datasets.fmnist.fmnist", "_logreg._logreg._logreg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._logreg._logreg"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the logistic regression test problem on Fashion-MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "fmnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_logreg", "(", "x", ",", "num_outputs", "=", "10", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._inception_v3._inception_v3": [[6, 263], ["tensorflow.image.resize_images", "_inception_v3._inception_v3.inception_block5"], "function", ["None"], ["def", "_inception_v3", "(", "x", ",", "training", ",", "weight_decay", ")", ":", "\n", "    ", "def", "conv2d_BN", "(", "inputs", ",", "filters", ",", "kernel_size", ",", "strides", ",", "padding", ",", "training", ")", ":", "\n", "        ", "\"\"\"Creates a convolutional layer, followed by a batch normalization layer\n        and a ReLU activation.\n\n        Args:\n            inputs (tf.Tensor): Input tensor to the layer.\n            filters (int): Number of filters for the conv layer.\n                No default specified.\n            kernel_size (int): Size of the conv filter. No default specified.\n            strides (int): Stride for the convolutions. No default specified.\n            padding (str): Padding of the convolutional layers. Can be ``SAME``\n                or ``VALID``. No default specified.\n            training (tf.bool): Switch to determine if we are in training\n                (or evaluation) mode.\n\n        Returns:\n            tf.Tenors: Output after the conv and batch norm layer.\n\n        \"\"\"", "\n", "# We use the fixed set up described in the github implementation", "\n", "# https://github.com/tensorflow/models/blob/master/research/inception/inception/slim/inception_model.py", "\n", "# which uses the non-default batch norm momentum of 0.9997", "\n", "# with tf.variable_scope(\"conv2d_BN\"):", "\n", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "strides", ",", "\n", "padding", ",", "\n", "activation", "=", "None", ",", "\n", "use_bias", "=", "False", ",", "\n", "kernel_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", ")", "\n", "x", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "\n", "x", ",", "momentum", "=", "0.9997", ",", "training", "=", "training", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x", ")", "\n", "return", "x", "\n", "\n", "", "def", "inception_block5", "(", "inputs", ",", "variant", ",", "training", ",", "name", "=", "\"inception_block5\"", ")", ":", "\n", "        ", "\"\"\"Defines the Inception block 5.\n\n        Args:\n            inputs (tf.Tensor): Input to the inception block.\n            variant (str): Describes which variant of the inception block 5 to\n                use. Can be ``a`` or ``b``.\n            training (tf.bool): Switch to determine if we are in training\n                (or evaluation) mode.\n            name (str): Name of the block. Defaults to ``inception_block5``.\n\n        Returns:\n            tf.Tenors: Output after the inception block.\n\n        \"\"\"", "\n", "# Switch between the two versions", "\n", "if", "variant", "==", "'a'", ":", "\n", "            ", "num_filters", "=", "32", "\n", "", "elif", "variant", "==", "'b'", ":", "\n", "            ", "num_filters", "=", "64", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'requested variant of the inception block not known'", ")", "\n", "# Build block", "\n", "", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"branch0\"", ")", ":", "\n", "                ", "branch0_1x1", "=", "conv2d_BN", "(", "inputs", ",", "64", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch1\"", ")", ":", "\n", "                ", "branch1_pool", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "inputs", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ")", "\n", "branch1_1x1", "=", "conv2d_BN", "(", "branch1_pool", ",", "num_filters", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch2\"", ")", ":", "\n", "                ", "branch2_1x1", "=", "conv2d_BN", "(", "inputs", ",", "48", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_5x5", "=", "conv2d_BN", "(", "branch2_1x1", ",", "64", ",", "5", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch3\"", ")", ":", "\n", "                ", "branch3_1x1", "=", "conv2d_BN", "(", "inputs", ",", "64", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch3_3x3_0", "=", "conv2d_BN", "(", "branch3_1x1", ",", "96", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch3_3x3_1", "=", "conv2d_BN", "(", "branch3_3x3_0", ",", "96", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "output", "=", "tf", ".", "concat", "(", "[", "branch0_1x1", ",", "branch1_1x1", ",", "branch2_5x5", ",", "branch3_3x3_1", "]", ",", "3", ")", "\n", "", "return", "output", "\n", "", "def", "inception_block10", "(", "inputs", ",", "training", ",", "name", "=", "\"inception_block10\"", ")", ":", "\n", "        ", "\"\"\"Defines the Inception block 10.\n\n        Args:\n            inputs (tf.Tensor): Input to the inception block.\n            training (tf.bool): Switch to determine if we are in training\n                (or evaluation) mode.\n            name (str): Name of the block. Defaults to ``inception_block5``.\n\n        Returns:\n            tf.Tenors: Output after the inception block.\n\n        \"\"\"", "\n", "# Build block", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"branch0\"", ")", ":", "\n", "                ", "branch0_pool", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "inputs", ",", "3", ",", "(", "2", ",", "2", ")", ",", "'VALID'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch1\"", ")", ":", "\n", "                ", "branch1_3x3", "=", "conv2d_BN", "(", "inputs", ",", "384", ",", "3", ",", "(", "2", ",", "2", ")", ",", "'VALID'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch2\"", ")", ":", "\n", "                ", "branch2_1x1", "=", "conv2d_BN", "(", "inputs", ",", "64", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_3x3_0", "=", "conv2d_BN", "(", "branch2_1x1", ",", "96", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_3x3_1", "=", "conv2d_BN", "(", "branch2_3x3_0", ",", "96", ",", "3", ",", "(", "2", ",", "2", ")", ",", "'VALID'", ",", "training", ")", "\n", "", "output", "=", "tf", ".", "concat", "(", "[", "branch0_pool", ",", "branch1_3x3", ",", "branch2_3x3_1", "]", ",", "3", ")", "\n", "", "return", "output", "\n", "\n", "", "def", "inception_block6", "(", "inputs", ",", "variant", ",", "training", ",", "name", "=", "\"inception_block6\"", ")", ":", "\n", "        ", "\"\"\"Defines the Inception block 6.\n\n        Args:\n            inputs (tf.Tensor): Input to the inception block.\n            variant (str): Describes which variant of the inception block 6 to use.\n                Can be ``a``, ``b`` or ``c``.\n            training (bool): Switch to determine if we are in training\n                (or evaluation) mode.\n            name (str): Name of the block. Defaults to ``inception_block5``.\n\n        Returns:\n            tf.Tenors: Output after the inception block.\n\n        \"\"\"", "\n", "# Switch between the two versions", "\n", "if", "variant", "==", "'a'", ":", "\n", "            ", "num_filters", "=", "128", "\n", "", "elif", "variant", "==", "'b'", ":", "\n", "            ", "num_filters", "=", "160", "\n", "", "elif", "variant", "==", "'c'", ":", "\n", "            ", "num_filters", "=", "192", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'requested variant of the inception block not known'", ")", "\n", "# Build block", "\n", "", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"branch0\"", ")", ":", "\n", "                ", "branch0_1x1", "=", "conv2d_BN", "(", "inputs", ",", "192", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch1\"", ")", ":", "\n", "                ", "branch1_pool", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "inputs", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ")", "\n", "branch1_1x1", "=", "conv2d_BN", "(", "branch1_pool", ",", "192", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch2\"", ")", ":", "\n", "                ", "branch2_1x1", "=", "conv2d_BN", "(", "inputs", ",", "num_filters", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_1x7", "=", "conv2d_BN", "(", "branch2_1x1", ",", "num_filters", ",", "[", "1", ",", "7", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_7x1", "=", "conv2d_BN", "(", "branch2_1x7", ",", "192", ",", "[", "7", ",", "1", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch3\"", ")", ":", "\n", "                ", "branch3_1x1", "=", "conv2d_BN", "(", "inputs", ",", "num_filters", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch3_7x1_0", "=", "conv2d_BN", "(", "branch3_1x1", ",", "num_filters", ",", "[", "7", ",", "1", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch3_1x7_0", "=", "conv2d_BN", "(", "branch3_7x1_0", ",", "num_filters", ",", "[", "1", ",", "7", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch3_7x1_1", "=", "conv2d_BN", "(", "branch3_1x7_0", ",", "num_filters", ",", "[", "7", ",", "1", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch3_1x7_1", "=", "conv2d_BN", "(", "branch3_7x1_1", ",", "192", ",", "[", "1", ",", "7", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "output", "=", "tf", ".", "concat", "(", "[", "branch0_1x1", ",", "branch1_1x1", ",", "branch2_7x1", ",", "branch3_1x7_1", "]", ",", "3", ")", "\n", "", "return", "output", "\n", "\n", "", "def", "inception_blockD", "(", "inputs", ",", "training", ",", "name", "=", "\"inception_blockD\"", ")", ":", "\n", "        ", "\"\"\"Defines the Inception block D.\n\n        Args:\n            inputs (tf.Tensor): Input to the inception block.\n            training (bool): Switch to determine if we are in training\n                (or evaluation) mode.\n            name (str): Name of the block. Defaults to ``inception_block5``.\n\n        Returns:\n            tf.Tenors: Output after the inception block.\n\n        \"\"\"", "\n", "# Build block", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"branch0\"", ")", ":", "\n", "                ", "branch0_pool", "=", "tf", ".", "layers", ".", "max_pooling2d", "(", "inputs", ",", "3", ",", "(", "2", ",", "2", ")", ",", "'VALID'", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch1\"", ")", ":", "\n", "                ", "branch1_1x1", "=", "conv2d_BN", "(", "inputs", ",", "192", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch1_1x7", "=", "conv2d_BN", "(", "branch1_1x1", ",", "192", ",", "[", "1", ",", "7", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch1_7x1", "=", "conv2d_BN", "(", "branch1_1x7", ",", "192", ",", "[", "7", ",", "1", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch1_3x3", "=", "conv2d_BN", "(", "branch1_7x1", ",", "192", ",", "3", ",", "(", "2", ",", "2", ")", ",", "'VALID'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch2\"", ")", ":", "\n", "                ", "branch2_1x1", "=", "conv2d_BN", "(", "inputs", ",", "192", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_3x3", "=", "conv2d_BN", "(", "branch2_1x1", ",", "320", ",", "3", ",", "(", "2", ",", "2", ")", ",", "'VALID'", ",", "training", ")", "\n", "", "output", "=", "tf", ".", "concat", "(", "[", "branch0_pool", ",", "branch1_3x3", ",", "branch2_3x3", "]", ",", "3", ")", "\n", "", "return", "output", "\n", "\n", "", "def", "inception_block7", "(", "inputs", ",", "training", ",", "name", "=", "\"inception_block7\"", ")", ":", "\n", "        ", "\"\"\"Defines the Inception block 7.\n\n        Args:\n            inputs (tf.Tensor): Input to the inception block.\n            training (bool): Switch to determine if we are in training\n                (or evaluation) mode.\n            name (str): Name of the block. Defaults to ``inception_block5``.\n\n        Returns:\n            tf.Tenors: Output after the inception block.\n\n        \"\"\"", "\n", "# Build block", "\n", "with", "tf", ".", "variable_scope", "(", "name", ")", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "\"branch0\"", ")", ":", "\n", "                ", "branch0_1x1", "=", "conv2d_BN", "(", "inputs", ",", "320", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch1\"", ")", ":", "\n", "                ", "branch1_1x1", "=", "conv2d_BN", "(", "inputs", ",", "384", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch1_1x3", "=", "conv2d_BN", "(", "branch1_1x1", ",", "384", ",", "[", "1", ",", "3", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch1_3x1", "=", "conv2d_BN", "(", "branch1_1x1", ",", "384", ",", "[", "3", ",", "1", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch1_concat", "=", "tf", ".", "concat", "(", "[", "branch1_1x3", ",", "branch1_3x1", "]", ",", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch2\"", ")", ":", "\n", "                ", "branch2_1x1", "=", "conv2d_BN", "(", "inputs", ",", "448", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_3x3", "=", "conv2d_BN", "(", "branch2_1x1", ",", "384", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_1x3", "=", "conv2d_BN", "(", "branch2_3x3", ",", "384", ",", "[", "1", ",", "3", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_3x1", "=", "conv2d_BN", "(", "branch2_3x3", ",", "384", ",", "[", "3", ",", "1", "]", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "branch2_concat", "=", "tf", ".", "concat", "(", "[", "branch2_1x3", ",", "branch2_3x1", "]", ",", "3", ")", "\n", "", "with", "tf", ".", "variable_scope", "(", "\"branch3\"", ")", ":", "\n", "                ", "branch3_pool", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "inputs", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ")", "\n", "branch3_1x1", "=", "conv2d_BN", "(", "branch3_pool", ",", "192", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "", "output", "=", "tf", ".", "concat", "(", "[", "branch0_1x1", ",", "branch1_concat", ",", "branch2_concat", ",", "branch3_1x1", "]", ",", "3", ")", "\n", "", "return", "output", "\n", "\n", "", "num_classes", "=", "1001", "# since we have a class for 'background'", "\n", "\n", "# we resize to 299x299 again, as this is the input size for inception-v3.", "\n", "# Our dataset returns always the cropped 224x224 versions", "\n", "x", "=", "tf", ".", "image", ".", "resize_images", "(", "x", ",", "[", "299", ",", "299", "]", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"stem\"", ")", ":", "\n", "        ", "x", "=", "conv2d_BN", "(", "x", ",", "32", ",", "3", ",", "(", "2", ",", "2", ")", ",", "'VALID'", ",", "training", ")", "\n", "x", "=", "conv2d_BN", "(", "x", ",", "32", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'VALID'", ",", "training", ")", "\n", "x", "=", "conv2d_BN", "(", "x", ",", "64", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "x", "=", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'VALID'", ")", "\n", "\n", "x", "=", "conv2d_BN", "(", "x", ",", "80", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'VALID'", ",", "training", ")", "\n", "x", "=", "conv2d_BN", "(", "x", ",", "192", ",", "3", ",", "(", "1", ",", "1", ")", ",", "'VALID'", ",", "training", ")", "\n", "x", "=", "tf", ".", "nn", ".", "max_pool", "(", "x", ",", "[", "1", ",", "3", ",", "3", ",", "1", "]", ",", "[", "1", ",", "2", ",", "2", ",", "1", "]", ",", "'VALID'", ")", "\n", "\n", "", "x", "=", "inception_block5", "(", "x", ",", "'a'", ",", "training", ",", "\"inception_block5a\"", ")", "\n", "x", "=", "inception_block5", "(", "x", ",", "'b'", ",", "training", ",", "\"inception_block5b_0\"", ")", "\n", "x", "=", "inception_block5", "(", "x", ",", "'b'", ",", "training", ",", "\"inception_block5b_1\"", ")", "\n", "\n", "x", "=", "inception_block10", "(", "x", ",", "training", ")", "\n", "\n", "x", "=", "inception_block6", "(", "x", ",", "'a'", ",", "training", ",", "\"inception_block6a\"", ")", "\n", "x", "=", "inception_block6", "(", "x", ",", "'b'", ",", "training", ",", "\"inception_block6b_0\"", ")", "\n", "x", "=", "inception_block6", "(", "x", ",", "'b'", ",", "training", ",", "\"inception_block6b_1\"", ")", "\n", "x", "=", "inception_block6", "(", "x", ",", "'c'", ",", "training", ",", "\"inception_block6c\"", ")", "\n", "\n", "# Auxiliary head", "\n", "with", "tf", ".", "variable_scope", "(", "\"aux_head\"", ")", ":", "\n", "        ", "x_aux", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "x", ",", "5", ",", "(", "3", ",", "3", ")", ",", "'VALID'", ")", "\n", "x_aux", "=", "conv2d_BN", "(", "x_aux", ",", "128", ",", "1", ",", "(", "1", ",", "1", ")", ",", "'SAME'", ",", "training", ")", "\n", "x_aux", "=", "conv2d_BN", "(", "x_aux", ",", "768", ",", "5", ",", "(", "1", ",", "1", ")", ",", "'VALID'", ",", "training", ")", "\n", "x_aux", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "x_aux", ")", "\n", "aux_linear_outputs", "=", "tf", ".", "layers", ".", "dense", "(", "x_aux", ",", "num_classes", ",", "None", ",", "True", ")", "\n", "\n", "", "x", "=", "inception_blockD", "(", "x", ",", "training", ",", "\"inception_blockD\"", ")", "\n", "\n", "x", "=", "inception_block7", "(", "x", ",", "training", ",", "\"inception_block7_0\"", ")", "\n", "x", "=", "inception_block7", "(", "x", ",", "training", ",", "\"inception_block7_1\"", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "\"output\"", ")", ":", "\n", "        ", "x", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "x", ",", "8", ",", "(", "1", ",", "1", ")", ",", "'VALID'", ")", "\n", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "0.8", ",", "training", ")", "\n", "x", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "x", ")", "\n", "\n", "linear_outputs", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "num_classes", ",", "None", ",", "True", ")", "\n", "\n", "", "return", "linear_outputs", ",", "aux_linear_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_mlp.mnist_mlp.__init__": [[46, 60], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new multi-layer perceptron test problem instance on MNIST.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "mnist_mlp", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_mlp.mnist_mlp.set_up": [[63, 82], ["datasets.mnist.mnist", "_mlp._mlp._mlp", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._mlp._mlp"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the multi-layer perceptron test problem instance on MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "mnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_mlp", "(", "x", ",", "num_outputs", "=", "10", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_3c3d.cifar100_3c3d.__init__": [[46, 55], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "0.002", ")", ":", "\n", "        ", "\"\"\"Create a new 3c3d test problem instance on Cifar-100.\n\n        Args:\n            batch_size (int): Batch size to use.\n            weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n                is used on the weights but not the biases. Defaults to ``0.002``.\n        \"\"\"", "\n", "super", "(", "cifar100_3c3d", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_3c3d.cifar100_3c3d.set_up": [[56, 78], ["datasets.cifar100.cifar100", "_3c3d._3c3d._3c3d", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._3c3d._3c3d"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the vanilla CNN test problem on Cifar-100.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar100", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_3c3d", "(", "\n", "x", ",", "num_outputs", "=", "100", ",", "weight_decay", "=", "self", ".", "_weight_decay", "\n", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", "\n", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar10_vgg19.cifar10_vgg19.__init__": [[44, 54], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Create a new VGG 19 test problem instance on Cifar-10.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "cifar10_vgg19", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar10_vgg19.cifar10_vgg19.set_up": [[55, 79], ["datasets.cifar10.cifar10", "tensorflow.equal", "_vgg._vgg._vgg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vgg._vgg"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the VGG 19 test problem on Cifar-10.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar10", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_vgg", "(", "\n", "x", ",", "\n", "training", ",", "\n", "variant", "=", "19", ",", "\n", "num_outputs", "=", "10", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.two_d_beale.two_d_beale.__init__": [[45, 59], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new 2D Beale Test Problem instance.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "two_d_beale", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.two_d_beale.two_d_beale.set_up": [[61, 90], ["datasets.two_d.two_d", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.losses.get_regularization_loss", "tensorflow.constant_initializer", "tensorflow.constant_initializer"], "methods", ["None"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the stochastic two-dimensional Beale test problem.\n        Using ``-4.5`` and ``4.5`` as a starting point for the weights ``u``\n        and ``v``.\n        \"\"\"", "\n", "self", ".", "dataset", "=", "two_d", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "\n", "# Set starting point", "\n", "starting_point", "=", "[", "-", "4.5", ",", "4.5", "]", "\n", "\n", "# Set model weights", "\n", "u", "=", "tf", ".", "get_variable", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "starting_point", "[", "0", "]", ")", ")", "\n", "v", "=", "tf", ".", "get_variable", "(", "\n", "\"bias\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "starting_point", "[", "1", "]", ")", ")", "\n", "\n", "self", ".", "losses", "=", "(", "(", "1.5", "-", "u", "+", "u", "*", "v", ")", "**", "2", "+", "(", "2.25", "-", "u", "+", "u", "*", "v", "**", "2", ")", "**", "2", "+", "\n", "(", "2.625", "-", "u", "+", "u", "*", "v", "**", "3", ")", "**", "2", ")", "+", "u", "*", "x", "+", "v", "*", "y", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vae._vae": [[11, 133], ["tensorflow.reshape", "_vae._vae.encoder"], "function", ["None"], ["def", "_vae", "(", "x", ",", "training", ",", "n_latent", "=", "8", ")", ":", "\n", "    ", "def", "conv2d", "(", "inputs", ",", "filters", ",", "kernel_size", ",", "strides", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for conv layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "strides", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "activation", "=", "activation", ")", "\n", "\n", "", "def", "conv2d_transpose", "(", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "strides", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for conv layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "conv2d_transpose", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "strides", ",", "\n", "padding", "=", "'same'", ",", "\n", "activation", "=", "activation", ")", "\n", "\n", "", "def", "lrelu", "(", "x", ",", "alpha", "=", "0.3", ")", ":", "\n", "        ", "\"\"\"Leaky ReLU activation function.\n\n        Args:\n            x (tf.Variable): Input to the activation function.\n            alpha (float): Factor of the leaky ReLU. Defines how `leaky` it is.\n                Defauylts to ``0.3``.\n\n        Returns:\n            tf.Variable: Output after the activation function.\n\n        \"\"\"", "\n", "return", "tf", ".", "maximum", "(", "x", ",", "tf", ".", "multiply", "(", "x", ",", "alpha", ")", ")", "\n", "\n", "", "def", "encoder", "(", "x", ",", "training", ",", "n_latent", "=", "8", ")", ":", "\n", "        ", "\"\"\"Encoder of the VAE. It consists of three convolutional and one dense\n        layers. The convolutional layers use the leaky ReLU activation function.\n        After each convolutional layer dropout is appleid with a keep probability\n        of ``0.8``.\n\n        Args:\n            x (tf.Variable): Input to the encoder.\n            training (tf.Bool): Bool variable, determining if we are in\n                training or evaluation mode.\n            n_latent (int): Size of the latent space of the encoder.\n                Defaults to ``8``.\n\n        Returns:\n            tupel: Output of the encoder, ``z``, the mean and the standard deviation.\n\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"encoder\"", ",", "reuse", "=", "None", ")", ":", "\n", "            ", "x", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "-", "1", ",", "28", ",", "28", ",", "1", "]", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "64", ",", "4", ",", "2", ",", "activation", "=", "lrelu", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.2", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "64", ",", "4", ",", "2", ",", "activation", "=", "lrelu", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.2", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "64", ",", "4", ",", "1", ",", "activation", "=", "lrelu", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.2", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "x", ")", "\n", "\n", "mean", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "units", "=", "n_latent", ")", "\n", "std_dev", "=", "0.5", "*", "tf", ".", "layers", ".", "dense", "(", "x", ",", "units", "=", "n_latent", ")", "\n", "epsilon", "=", "tf", ".", "random_normal", "(", "tf", ".", "stack", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ",", "n_latent", "]", ")", ")", "\n", "z", "=", "tf", ".", "add", "(", "mean", ",", "tf", ".", "multiply", "(", "epsilon", ",", "tf", ".", "exp", "(", "std_dev", ")", ")", ",", "name", "=", "\"z\"", ")", "\n", "\n", "return", "z", ",", "mean", ",", "std_dev", "\n", "\n", "", "", "def", "decoder", "(", "sampled_z", ",", "training", ")", ":", "\n", "        ", "\"\"\"The decoder for the VAE. It uses two dense layers, followed by three\n        deconvolutional layers (each with dropout= ``0.8``) a final dense layer.\n        The dense layers use the leaky ReLU activation (except the last one,\n        which uses softmax), while the deconvolutional ones use regular ReLU.\n\n        Args:\n            sampled_z (tf.Variable): Sampled ``z`` from the encoder of the size\n                ``n_latent``.\n            training (tf.Bool): Bool variable, determining if we are in\n                training or evaluation mode.\n\n        Returns:\n            tf.Variable: A tensor of the same size as the original images\n                (``28`` by ``28``).\n\n        \"\"\"", "\n", "with", "tf", ".", "variable_scope", "(", "\"decoder\"", ",", "reuse", "=", "None", ")", ":", "\n", "            ", "x", "=", "tf", ".", "layers", ".", "dense", "(", "sampled_z", ",", "units", "=", "24", ",", "activation", "=", "lrelu", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "units", "=", "24", "*", "2", "+", "1", ",", "activation", "=", "lrelu", ")", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "7", ",", "7", ",", "1", "]", ")", "\n", "\n", "x", "=", "conv2d_transpose", "(", "x", ",", "64", ",", "4", ",", "2", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.2", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "conv2d_transpose", "(", "x", ",", "64", ",", "4", ",", "1", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.2", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "conv2d_transpose", "(", "x", ",", "64", ",", "4", ",", "1", ")", "\n", "\n", "x", "=", "tf", ".", "contrib", ".", "layers", ".", "flatten", "(", "x", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "units", "=", "28", "*", "28", ",", "activation", "=", "tf", ".", "nn", ".", "sigmoid", ")", "\n", "\n", "img", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "-", "1", ",", "28", ",", "28", "]", ",", "name", "=", "\"decoder_op\"", ")", "\n", "\n", "return", "img", "\n", "\n", "", "", "x", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "-", "1", ",", "28", "*", "28", "]", ")", "\n", "\n", "sampled_z", ",", "mean", ",", "std_dev", "=", "encoder", "(", "x", ",", "training", ",", "n_latent", "=", "n_latent", ")", "\n", "img", "=", "decoder", "(", "sampled_z", ",", "training", ")", "\n", "\n", "\n", "return", "img", ",", "mean", ",", "std_dev", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_2c2d.mnist_2c2d.__init__": [[47, 61], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new 2c2d test problem instance on MNIST.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "mnist_2c2d", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_2c2d.mnist_2c2d.set_up": [[64, 85], ["datasets.mnist.mnist", "_2c2d._2c2d._2c2d", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._2c2d._2c2d"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the vanilla CNN test problem on MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "mnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_2c2d", "(", "\n", "x", ",", "\n", "num_outputs", "=", "10", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_2c2d.fmnist_2c2d.__init__": [[47, 61], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new 2c2d test problem instance on Fashion-MNIST.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "fmnist_2c2d", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_2c2d.fmnist_2c2d.set_up": [[63, 82], ["datasets.fmnist.fmnist", "_2c2d._2c2d._2c2d", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._2c2d._2c2d"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the vanilla CNN test problem on Fashion-MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "fmnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_2c2d", "(", "x", ",", "num_outputs", "=", "10", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_vae.mnist_vae.__init__": [[50, 64], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new VAE test problem instance on MNIST.\n\n        Args:\n            batch_size (type): Batch size to use.\n            weight_decay (type): No weight decay (L2-regularization) is used in this\n                test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "mnist_vae", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_vae.mnist_vae.set_up": [[66, 90], ["datasets.mnist.mnist", "tensorflow.equal", "_vae._vae._vae", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.losses.get_regularization_loss", "tensorflow.squared_difference", "tensorflow.reduce_sum", "tensorflow.exp", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vae._vae"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the VAE test problem on MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "mnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "_", "=", "self", ".", "dataset", ".", "batch", "\n", "img", ",", "mean", ",", "std_dev", "=", "_vae", "(", "\n", "x", ",", "\n", "training", ",", "\n", "n_latent", "=", "8", ")", "\n", "\n", "# Define Loss", "\n", "flatten_img", "=", "tf", ".", "reshape", "(", "img", ",", "[", "-", "1", ",", "28", "*", "28", "]", ")", "\n", "x_flat", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "-", "1", ",", "28", "*", "28", "]", ")", "\n", "img_loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "squared_difference", "(", "flatten_img", ",", "x_flat", ")", ",", "1", ")", "\n", "latent_loss", "=", "-", "0.5", "*", "tf", ".", "reduce_sum", "(", "1.0", "+", "2.0", "*", "std_dev", "-", "tf", ".", "square", "(", "mean", ")", "-", "\n", "tf", ".", "exp", "(", "2.0", "*", "std_dev", ")", ",", "1", ")", "\n", "self", ".", "losses", "=", "img_loss", "+", "latent_loss", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_allcnnc.cifar100_allcnnc.__init__": [[49, 59], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "0.0005", ")", ":", "\n", "        ", "\"\"\"Create a new All CNN C test problem instance on Cifar-100.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "cifar100_allcnnc", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_allcnnc.cifar100_allcnnc.set_up": [[60, 112], ["datasets.cifar100.cifar100", "tensorflow.equal", "tensorflow.layers.dropout", "cifar100_allcnnc.cifar100_allcnnc.set_up.conv2d"], "methods", ["None"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the All CNN C test problem on Cifar-100.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar100", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "def", "conv2d", "(", "inputs", ",", "filters", ",", "kernel_size", "=", "3", ",", "strides", "=", "(", "1", ",", "1", ")", ",", "padding", "=", "\"same\"", ")", ":", "\n", "            ", "\"\"\"Convenience wrapper for conv layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "strides", ",", "\n", "padding", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.1", ")", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "glorot_normal", "(", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "self", ".", "_weight_decay", ")", ")", "\n", "\n", "", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.2", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "96", ",", "3", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "96", ",", "3", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "96", ",", "3", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.5", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "192", ",", "3", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "192", ",", "3", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "192", ",", "3", ",", "strides", "=", "(", "2", ",", "2", ")", ")", "\n", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.5", ",", "training", "=", "training", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "192", ",", "3", ",", "padding", "=", "\"valid\"", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "192", ",", "1", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "100", ",", "1", ")", "\n", "\n", "linear_outputs", "=", "tf", ".", "reduce_mean", "(", "x", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._2c2d._2c2d": [[11, 54], ["_2c2d._2c2d.conv2d"], "function", ["None"], ["def", "_2c2d", "(", "x", ",", "num_outputs", ")", ":", "\n", "    ", "def", "conv2d", "(", "inputs", ",", "filters", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for conv layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", "=", "5", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.05", ")", ",", "\n", "kernel_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.05", ")", ")", "\n", "\n", "", "def", "max_pool", "(", "inputs", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for max pool layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "\n", "inputs", ",", "\n", "pool_size", "=", "2", ",", "\n", "strides", "=", "2", ",", "\n", "padding", "=", "'same'", ",", "\n", ")", "\n", "\n", "", "def", "dense", "(", "inputs", ",", "units", ",", "activation", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for max pool layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", ",", "\n", "units", ",", "\n", "activation", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.05", ")", ",", "\n", "kernel_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "0.05", ")", ")", "\n", "\n", "", "x", "=", "conv2d", "(", "x", ",", "32", ")", "\n", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "x", "=", "conv2d", "(", "x", ",", "64", ")", "\n", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "x", "=", "tf", ".", "reshape", "(", "x", ",", "tf", ".", "stack", "(", "[", "-", "1", ",", "7", "*", "7", "*", "64", "]", ")", ")", "\n", "\n", "x", "=", "dense", "(", "x", ",", "1024", ",", "tf", ".", "nn", ".", "relu", ")", "\n", "\n", "linear_outputs", "=", "dense", "(", "x", ",", "num_outputs", ",", "None", ")", "\n", "\n", "return", "linear_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar10_3c3d.cifar10_3c3d.__init__": [[49, 58], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "0.002", ")", ":", "\n", "        ", "\"\"\"Create a new 3c3d test problem instance on Cifar-10.\n\n        Args:\n            batch_size (int): Batch size to use.\n            weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n                is used on the weights but not the biases. Defaults to ``0.002``.\n        \"\"\"", "\n", "super", "(", "cifar10_3c3d", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar10_3c3d.cifar10_3c3d.set_up": [[59, 81], ["datasets.cifar10.cifar10", "_3c3d._3c3d._3c3d", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._3c3d._3c3d"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the vanilla CNN test problem on Cifar-10.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar10", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_3c3d", "(", "\n", "x", ",", "num_outputs", "=", "10", ",", "weight_decay", "=", "self", ".", "_weight_decay", "\n", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", "\n", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_wrn404.cifar100_wrn404.__init__": [[46, 56], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "0.0005", ")", ":", "\n", "        ", "\"\"\"Create a new WRN 40-4 test problem instance on Cifar-100.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "cifar100_wrn404", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_wrn404.cifar100_wrn404.set_up": [[57, 82], ["datasets.cifar100.cifar100", "tensorflow.equal", "_wrn._wrn._wrn", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._wrn._wrn"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the Wide ResNet 40-4 test problem on Cifar-100.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar100", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_wrn", "(", "\n", "x", ",", "\n", "training", ",", "\n", "num_residual_units", "=", "6", ",", "\n", "widening_factor", "=", "4", ",", "\n", "num_outputs", "=", "100", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._quadratic._quadratic_base.__init__": [[44, 60], ["numpy.eye", "testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ",", "hessian", "=", "np", ".", "eye", "(", "100", ")", ")", ":", "\n", "        ", "\"\"\"Create a new quadratic test problem instance.\n\n        Args:\n            batch_size (int): Batch size to use.\n            weight_decay (float): No weight decay (L2-regularization) is used in this\n                test problem. Defaults to ``None`` and any input here is ignored.\n            hessian (np.array): Hessian of the quadratic problem.\n                Defaults to the ``100`` dimensional identity.\n        \"\"\"", "\n", "super", "(", "_quadratic_base", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "self", ".", "_hessian", "=", "hessian", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._quadratic._quadratic_base.set_up": [[62, 80], ["datasets.quadratic.quadratic", "tensorflow.convert_to_tensor", "tensorflow.get_variable", "tensorflow.linalg.tensor_diag_part", "tensorflow.losses.get_regularization_loss", "tensorflow.constant_initializer", "tensorflow.matmul", "tensorflow.subtract", "tensorflow.matmul", "tensorflow.transpose", "tensorflow.subtract"], "methods", ["None"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the stochastic quadratic test problem. The parameter ``Theta``\n        will be initialized to (a vector of) ``1.0``.\n        \"\"\"", "\n", "self", ".", "dataset", "=", "quadratic", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", "=", "self", ".", "dataset", ".", "batch", "\n", "hessian", "=", "tf", ".", "convert_to_tensor", "(", "self", ".", "_hessian", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "theta", "=", "tf", ".", "get_variable", "(", "\"theta\"", ",", "shape", "=", "(", "1", ",", "hessian", ".", "shape", "[", "0", "]", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "1.0", ")", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "linalg", ".", "tensor_diag_part", "(", "0.5", "*", "tf", ".", "matmul", "(", "\n", "tf", ".", "subtract", "(", "theta", ",", "x", ")", ",", "\n", "tf", ".", "matmul", "(", "hessian", ",", "tf", ".", "transpose", "(", "tf", ".", "subtract", "(", "theta", ",", "x", ")", ")", ")", ")", ")", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_mlp.fmnist_mlp.__init__": [[46, 61], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new multi-layer perceptron test problem instance on \\\n        Fashion-MNIST.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "fmnist_mlp", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_mlp.fmnist_mlp.set_up": [[63, 83], ["datasets.mnist.mnist", "_mlp._mlp._mlp", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._mlp._mlp"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the multi-layer perceptron test problem instance on\n        Fashion-MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "mnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_mlp", "(", "x", ",", "num_outputs", "=", "10", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_vgg19.cifar100_vgg19.__init__": [[44, 54], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Create a new VGG 19 test problem instance on Cifar-100.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "cifar100_vgg19", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_vgg19.cifar100_vgg19.set_up": [[55, 79], ["datasets.cifar100.cifar100", "tensorflow.equal", "_vgg._vgg._vgg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vgg._vgg"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the VGG 19 test problem on Cifar-100.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar100", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_vgg", "(", "\n", "x", ",", "\n", "training", ",", "\n", "variant", "=", "19", ",", "\n", "num_outputs", "=", "100", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.imagenet_vgg19.imagenet_vgg19.__init__": [[41, 51], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Create a new VGG 19 test problem instance on ImageNet.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "imagenet_vgg19", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.imagenet_vgg19.imagenet_vgg19.set_up": [[52, 76], ["datasets.imagenet.imagenet", "tensorflow.equal", "_vgg._vgg._vgg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vgg._vgg"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the VGG 19 test problem on ImageNet.\"\"\"", "\n", "self", ".", "dataset", "=", "imagenet", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_vgg", "(", "\n", "x", ",", "\n", "training", ",", "\n", "variant", "=", "19", ",", "\n", "num_outputs", "=", "1001", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_vgg16.cifar100_vgg16.__init__": [[44, 54], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Create a new VGG 16 test problem instance on Cifar-100.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "cifar100_vgg16", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar100_vgg16.cifar100_vgg16.set_up": [[55, 79], ["datasets.cifar100.cifar100", "tensorflow.equal", "_vgg._vgg._vgg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vgg._vgg"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the VGG 16 test problem on Cifar-100.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar100", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_vgg", "(", "\n", "x", ",", "\n", "training", ",", "\n", "variant", "=", "16", ",", "\n", "num_outputs", "=", "100", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_vae.fmnist_vae.__init__": [[51, 65], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new VAE test problem instance on Fashion-MNIST.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "fmnist_vae", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.fmnist_vae.fmnist_vae.set_up": [[67, 91], ["datasets.fmnist.fmnist", "tensorflow.equal", "_vae._vae._vae", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.losses.get_regularization_loss", "tensorflow.squared_difference", "tensorflow.reduce_sum", "tensorflow.exp", "tensorflow.square"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vae._vae"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the VAE test problem on MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "fmnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "_", "=", "self", ".", "dataset", ".", "batch", "\n", "img", ",", "mean", ",", "std_dev", "=", "_vae", "(", "\n", "x", ",", "\n", "training", ",", "\n", "n_latent", "=", "8", ")", "\n", "\n", "# Define Loss", "\n", "flatten_img", "=", "tf", ".", "reshape", "(", "img", ",", "[", "-", "1", ",", "28", "*", "28", "]", ")", "\n", "x_flat", "=", "tf", ".", "reshape", "(", "x", ",", "shape", "=", "[", "-", "1", ",", "28", "*", "28", "]", ")", "\n", "img_loss", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "squared_difference", "(", "flatten_img", ",", "x_flat", ")", ",", "1", ")", "\n", "latent_loss", "=", "-", "0.5", "*", "tf", ".", "reduce_sum", "(", "1.0", "+", "2.0", "*", "std_dev", "-", "tf", ".", "square", "(", "mean", ")", "-", "\n", "tf", ".", "exp", "(", "2.0", "*", "std_dev", ")", ",", "1", ")", "\n", "self", ".", "losses", "=", "img_loss", "+", "latent_loss", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_logreg.mnist_logreg.__init__": [[36, 50], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new logistic regression test problem instance on MNIST.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "mnist_logreg", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.mnist_logreg.mnist_logreg.set_up": [[52, 71], ["datasets.mnist.mnist", "_logreg._logreg._logreg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._logreg._logreg"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the logistic regression test problem on MNIST.\"\"\"", "\n", "self", ".", "dataset", "=", "mnist", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_logreg", "(", "x", ",", "num_outputs", "=", "10", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar10_vgg16.cifar10_vgg16.__init__": [[44, 54], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Create a new VGG 16 test problem instance on Cifar-10.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "cifar10_vgg16", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.cifar10_vgg16.cifar10_vgg16.set_up": [[55, 79], ["datasets.cifar10.cifar10", "tensorflow.equal", "_vgg._vgg._vgg", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vgg._vgg"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the VGG 16 test problem on Cifar-10.\"\"\"", "\n", "self", ".", "dataset", "=", "cifar10", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_vgg", "(", "\n", "x", ",", "\n", "training", ",", "\n", "variant", "=", "16", ",", "\n", "num_outputs", "=", "10", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.imagenet_inception_v3.imagenet_inception_v3.__init__": [[54, 64], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "5e-4", ")", ":", "\n", "        ", "\"\"\"Create a new Inception v3 test problem instance on ImageNet.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "imagenet_inception_v3", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.imagenet_inception_v3.imagenet_inception_v3.set_up": [[65, 106], ["datasets.imagenet.imagenet", "tensorflow.equal", "_inception_v3._inception_v3._inception_v3", "tensorflow.losses.softmax_cross_entropy", "tensorflow.losses.softmax_cross_entropy", "tensorflow.cond", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast", "tensorflow.add", "tensorflow.add"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._inception_v3._inception_v3"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the Inception v3 test problem on ImageNet.\"\"\"", "\n", "self", ".", "dataset", "=", "imagenet", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "\n", "linear_outputs", ",", "aux_linear_outputs", "=", "_inception_v3", "(", "\n", "x", ",", "training", ",", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "# Compute two components of losses", "\n", "# reduction=tf.losses.Reduction.None means output will have size", "\n", "# ``batch_size``", "\n", "aux_losses", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "\n", "onehot_labels", "=", "y", ",", "\n", "logits", "=", "aux_linear_outputs", ",", "\n", "weights", "=", "0.4", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "reduction", "=", "tf", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "main_losses", "=", "tf", ".", "losses", ".", "softmax_cross_entropy", "(", "\n", "onehot_labels", "=", "y", ",", "\n", "logits", "=", "linear_outputs", ",", "\n", "label_smoothing", "=", "0.1", ",", "\n", "reduction", "=", "tf", ".", "losses", ".", "Reduction", ".", "NONE", ")", "\n", "\n", "# Add main_loss and aux_loss if we are training", "\n", "self", ".", "losses", "=", "tf", ".", "cond", "(", "\n", "training", ",", "\n", "lambda", ":", "tf", ".", "add", "(", "main_losses", ",", "aux_losses", ")", ",", "\n", "lambda", ":", "tf", ".", "add", "(", "main_losses", ",", "0.0", ")", ",", "\n", "name", "=", "\"losses\"", ")", "\n", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.testproblem.TestProblem.__init__": [[30, 52], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Creates a new test problem instance.\n\n    Args:\n      batch_size (int): Batch size to use.\n      weight_decay (float): Weight decay (L2-regularization) factor to use. If\n          not specified, the test problems revert to their respective defaults.\n          Note: Some test problems do not use regularization and this value will\n          be ignored in such a case.\n    \"\"\"", "\n", "self", ".", "_batch_size", "=", "batch_size", "\n", "self", ".", "_weight_decay", "=", "weight_decay", "\n", "\n", "# Public attributes by which to interact with test problems. These have to", "\n", "# be created by the set_up function of sub-classes.", "\n", "self", ".", "dataset", "=", "None", "\n", "self", ".", "train_init_op", "=", "None", "\n", "self", ".", "train_eval_init_op", "=", "None", "\n", "self", ".", "test_init_op", "=", "None", "\n", "self", ".", "losses", "=", "None", "\n", "self", ".", "regularizer", "=", "None", "\n", "self", ".", "accuracy", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.testproblem.TestProblem.set_up": [[53, 63], ["NotImplementedError"], "methods", ["None"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the test problem.\n\n    This includes setting up the data loading pipeline for the data set and\n    creating the tensorflow computation graph for this test problem\n    (e.g. creating the neural network).\n    \"\"\"", "\n", "raise", "NotImplementedError", "(", "\n", "\"\"\"'TestProblem' is an abstract base class, please\n        use one of the sub-classes.\"\"\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.quadratic_deep.quadratic_deep.__init__": [[87, 104], ["numpy.random.RandomState", "numpy.concatenate", "numpy.diag", "quadratic_deep.random_rotation", "numpy.matmul", "_quadratic._quadratic_base.__init__", "numpy.transpose", "numpy.matmul", "numpy.random.RandomState.uniform", "numpy.random.RandomState.uniform"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.quadratic_deep.random_rotation", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new quadratic deep test problem instance.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "\n", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "\n", "\n", "eigenvalues", "=", "np", ".", "concatenate", "(", "\n", "(", "rng", ".", "uniform", "(", "0.", ",", "1.", ",", "90", ")", ",", "rng", ".", "uniform", "(", "30.", ",", "60.", ",", "10", ")", ")", ",", "axis", "=", "0", ")", "\n", "D", "=", "np", ".", "diag", "(", "eigenvalues", ")", "\n", "R", "=", "random_rotation", "(", "D", ".", "shape", "[", "0", "]", ",", "rng", ")", "\n", "hessian", "=", "np", ".", "matmul", "(", "np", ".", "transpose", "(", "R", ")", ",", "np", ".", "matmul", "(", "D", ",", "R", ")", ")", "\n", "super", "(", "quadratic_deep", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ",", "hessian", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.quadratic_deep.random_rotation": [[12, 52], ["int", "range", "numpy.negative", "numpy.random.RandomState", "np.random.RandomState.uniform", "np.random.RandomState.normal", "numpy.divide", "numpy.concatenate", "numpy.divide", "numpy.vstack", "numpy.cos", "numpy.sin", "numpy.cos", "numpy.sqrt", "numpy.sqrt", "numpy.sin", "numpy.transpose().dot", "numpy.array", "numpy.zeros", "numpy.transpose().dot", "numpy.hstack", "numpy.hstack", "numpy.outer", "numpy.transpose().dot", "numpy.transpose", "numpy.transpose", "numpy.zeros", "numpy.zeros", "numpy.transpose"], "function", ["None"], ["def", "random_rotation", "(", "D", ",", "rng", "=", "None", ")", ":", "\n", "    ", "\"\"\"Produces a rotation matrix R in SO(D) (the special orthogonal\n    group SO(D), or orthogonal matrices with unit determinant, drawn uniformly\n    from the Haar measure.\n    The algorithm used is the subgroup algorithm as originally proposed by\n    P. Diaconis & M. Shahshahani, \"The subgroup algorithm for generating\n    uniform random variables\". Probability in the Engineering and\n    Informational Sciences 1: 15?32 (1987)\n\n    Args:\n        D (int): Dimensionality of the matrix.\n\n    Returns:\n        np.array: Random rotation matrix ``R``.\n\n    \"\"\"", "\n", "if", "rng", "is", "None", ":", "\n", "        ", "rng", "=", "np", ".", "random", ".", "RandomState", "(", "42", ")", "\n", "", "assert", "D", ">=", "2", "\n", "D", "=", "int", "(", "D", ")", "# make sure that the dimension is an integer", "\n", "\n", "# induction start: uniform draw from D=2 Haar measure", "\n", "t", "=", "2", "*", "np", ".", "pi", "*", "rng", ".", "uniform", "(", ")", "\n", "R", "=", "[", "[", "np", ".", "cos", "(", "t", ")", ",", "np", ".", "sin", "(", "t", ")", "]", ",", "[", "-", "np", ".", "sin", "(", "t", ")", ",", "np", ".", "cos", "(", "t", ")", "]", "]", "\n", "\n", "for", "d", "in", "range", "(", "2", ",", "D", ")", ":", "\n", "        ", "v", "=", "rng", ".", "normal", "(", "size", "=", "(", "d", "+", "1", ",", "1", ")", ")", "\n", "# draw on S_d the unit sphere", "\n", "v", "=", "np", ".", "divide", "(", "v", ",", "np", ".", "sqrt", "(", "np", ".", "transpose", "(", "v", ")", ".", "dot", "(", "v", ")", ")", ")", "\n", "e", "=", "np", ".", "concatenate", "(", "(", "np", ".", "array", "(", "[", "[", "1.0", "]", "]", ")", ",", "np", ".", "zeros", "(", "(", "d", ",", "1", ")", ")", ")", ",", "axis", "=", "0", ")", "\n", "# random coset location of SO(d-1) in SO(d)", "\n", "x", "=", "np", ".", "divide", "(", "(", "e", "-", "v", ")", ",", "(", "np", ".", "sqrt", "(", "np", ".", "transpose", "(", "e", "-", "v", ")", ".", "dot", "(", "e", "-", "v", ")", ")", ")", ")", "\n", "\n", "D", "=", "np", ".", "vstack", "(", "[", "\n", "np", ".", "hstack", "(", "[", "[", "[", "1.0", "]", "]", ",", "np", ".", "zeros", "(", "(", "1", ",", "d", ")", ")", "]", ")", ",", "\n", "np", ".", "hstack", "(", "[", "np", ".", "zeros", "(", "(", "d", ",", "1", ")", ")", ",", "R", "]", ")", "\n", "]", ")", "\n", "R", "=", "D", "-", "2", "*", "np", ".", "outer", "(", "x", ",", "np", ".", "transpose", "(", "x", ")", ".", "dot", "(", "D", ")", ")", "\n", "# return negative to fix determinant", "\n", "", "return", "np", ".", "negative", "(", "R", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.two_d_branin.two_d_branin.__init__": [[46, 60], ["testproblem.TestProblem.__init__", "print"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "None", ")", ":", "\n", "        ", "\"\"\"Create a new 2D Branin test problem instance.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): No weight decay (L2-regularization) is used in this\n              test problem. Defaults to ``None`` and any input here is ignored.\n        \"\"\"", "\n", "super", "(", "two_d_branin", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "print", "(", "\n", "\"WARNING: Weight decay is non-zero but no weight decay is used\"", ",", "\n", "\"for this model.\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.two_d_branin.two_d_branin.set_up": [[62, 99], ["datasets.two_d.two_d", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.losses.get_regularization_loss", "tensorflow.constant_initializer", "tensorflow.constant_initializer", "tensorflow.cos"], "methods", ["None"], ["", "", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Sets up the stochastic two-dimensional Branin test problem.\n        Using ``2.5`` and ``12.5`` as a starting point for the weights ``u``\n        and ``v``.\n        \"\"\"", "\n", "self", ".", "dataset", "=", "two_d", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "\n", "# Set starting point", "\n", "starting_point", "=", "[", "2.5", ",", "12.5", "]", "\n", "\n", "# Set model weights", "\n", "u", "=", "tf", ".", "get_variable", "(", "\n", "\"weight\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "starting_point", "[", "0", "]", ")", ")", "\n", "v", "=", "tf", ".", "get_variable", "(", "\n", "\"bias\"", ",", "\n", "shape", "=", "(", ")", ",", "\n", "initializer", "=", "tf", ".", "constant_initializer", "(", "starting_point", "[", "1", "]", ")", ")", "\n", "\n", "# Define some constants.", "\n", "a", "=", "1.", "\n", "b", "=", "5.1", "/", "(", "4.", "*", "np", ".", "pi", "**", "2", ")", "\n", "c", "=", "5", "/", "np", ".", "pi", "\n", "r", "=", "6.", "\n", "s", "=", "10.", "\n", "t", "=", "1", "/", "(", "8.", "*", "np", ".", "pi", ")", "\n", "\n", "self", ".", "losses", "=", "a", "*", "(", "v", "-", "b", "*", "u", "**", "2", "+", "c", "*", "u", "-", "r", ")", "**", "2", "+", "s", "*", "(", "\n", "1", "-", "t", ")", "*", "tf", ".", "cos", "(", "u", ")", "+", "s", "+", "u", "*", "x", "+", "v", "*", "y", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.__init__": [[46, 56], ["testproblem.TestProblem.__init__"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__"], ["def", "__init__", "(", "self", ",", "batch_size", ",", "weight_decay", "=", "0.0005", ")", ":", "\n", "        ", "\"\"\"Create a new WRN 16-4 test problem instance on SVHN.\n\n        Args:\n          batch_size (int): Batch size to use.\n          weight_decay (float): Weight decay factor. Weight decay (L2-regularization)\n              is used on the weights but not the biases.\n              Defaults to ``5e-4``.\n        \"\"\"", "\n", "super", "(", "svhn_wrn164", ",", "self", ")", ".", "__init__", "(", "batch_size", ",", "weight_decay", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up": [[57, 82], ["datasets.svhn.svhn", "tensorflow.equal", "_wrn._wrn._wrn", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.argmax", "tensorflow.argmax", "tensorflow.equal", "tensorflow.reduce_mean", "tensorflow.losses.get_regularization_loss", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._wrn._wrn"], ["", "def", "set_up", "(", "self", ")", ":", "\n", "        ", "\"\"\"Set up the Wide ResNet 16-4 test problem on SVHN.\"\"\"", "\n", "self", ".", "dataset", "=", "svhn", "(", "self", ".", "_batch_size", ")", "\n", "self", ".", "train_init_op", "=", "self", ".", "dataset", ".", "train_init_op", "\n", "self", ".", "train_eval_init_op", "=", "self", ".", "dataset", ".", "train_eval_init_op", "\n", "self", ".", "test_init_op", "=", "self", ".", "dataset", ".", "test_init_op", "\n", "\n", "training", "=", "tf", ".", "equal", "(", "self", ".", "dataset", ".", "phase", ",", "\"train\"", ")", "\n", "x", ",", "y", "=", "self", ".", "dataset", ".", "batch", "\n", "linear_outputs", "=", "_wrn", "(", "\n", "x", ",", "\n", "training", ",", "\n", "num_residual_units", "=", "2", ",", "\n", "widening_factor", "=", "4", ",", "\n", "num_outputs", "=", "10", ",", "\n", "weight_decay", "=", "self", ".", "_weight_decay", ")", "\n", "\n", "self", ".", "losses", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "\n", "labels", "=", "y", ",", "logits", "=", "linear_outputs", ")", "\n", "y_pred", "=", "tf", ".", "argmax", "(", "linear_outputs", ",", "1", ")", "\n", "y_correct", "=", "tf", ".", "argmax", "(", "y", ",", "1", ")", "\n", "correct_prediction", "=", "tf", ".", "equal", "(", "y_pred", ",", "y_correct", ")", "\n", "self", ".", "accuracy", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "cast", "(", "correct_prediction", ",", "tf", ".", "float32", ")", ")", "\n", "\n", "self", ".", "regularizer", "=", "tf", ".", "losses", ".", "get_regularization_loss", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._vgg._vgg": [[11, 81], ["tensorflow.image.resize_images", "_vgg._vgg.conv2d"], "function", ["None"], ["def", "_vgg", "(", "x", ",", "training", ",", "variant", ",", "num_outputs", ",", "weight_decay", ")", ":", "\n", "    ", "def", "conv2d", "(", "inputs", ",", "filters", ",", "kernel_size", "=", "3", ",", "strides", "=", "(", "1", ",", "1", ")", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for conv layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "conv2d", "(", "\n", "inputs", ",", "\n", "filters", ",", "\n", "kernel_size", ",", "\n", "strides", ",", "\n", "padding", "=", "\"same\"", ",", "\n", "activation", "=", "tf", ".", "nn", ".", "relu", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.0", ")", ",", "\n", "kernel_initializer", "=", "tf", ".", "keras", ".", "initializers", ".", "glorot_normal", "(", ")", ",", "\n", "kernel_regularizer", "=", "tf", ".", "contrib", ".", "layers", ".", "l2_regularizer", "(", "weight_decay", ")", ")", "\n", "", "def", "max_pool", "(", "inputs", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for max pool layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "max_pooling2d", "(", "\n", "inputs", ",", "\n", "pool_size", "=", "[", "2", ",", "2", "]", ",", "\n", "strides", "=", "[", "2", ",", "2", "]", ",", "\n", "padding", "=", "'same'", ",", "\n", ")", "\n", "\n", "# for now padd to 224x224 image size for VGG", "\n", "", "x", "=", "tf", ".", "image", ".", "resize_images", "(", "x", ",", "size", "=", "[", "224", ",", "224", "]", ")", "\n", "\n", "# conv1_1 and conv1_2", "\n", "x", "=", "conv2d", "(", "x", ",", "64", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "64", ")", "\n", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "# conv2_1 and conv2_2", "\n", "x", "=", "conv2d", "(", "x", ",", "128", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "128", ")", "\n", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "# conv3_1, conv3_2 and conv3_3 (and possibly conv3_4)", "\n", "x", "=", "conv2d", "(", "x", ",", "256", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "256", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "256", ")", "\n", "if", "variant", "==", "19", ":", "\n", "        ", "x", "=", "conv2d", "(", "x", ",", "256", ")", "\n", "", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "# conv4_1, conv4_2 and conv4_3 (and possibly conv4_4)", "\n", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "if", "variant", "==", "19", ":", "\n", "        ", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "", "x", "=", "max_pool", "(", "x", ")", "\n", "\n", "# conv5_1, conv5_2 and conv5_3 (and possibly conv5_4)", "\n", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "if", "variant", "==", "19", ":", "\n", "        ", "x", "=", "conv2d", "(", "x", ",", "512", ")", "\n", "", "x", "=", "max_pool", "(", "x", ")", "\n", "x", "=", "tf", ".", "layers", ".", "flatten", "(", "x", ")", "\n", "\n", "# fc_1", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "4096", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.5", ",", "training", "=", "training", ")", "\n", "# fc_2", "\n", "x", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "4096", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", "\n", "x", "=", "tf", ".", "layers", ".", "dropout", "(", "x", ",", "rate", "=", "0.5", ",", "training", "=", "training", ")", "\n", "# fc_3", "\n", "linear_outputs", "=", "tf", ".", "layers", ".", "dense", "(", "x", ",", "num_outputs", ")", "\n", "\n", "return", "linear_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems._mlp._mlp": [[11, 29], ["tensorflow.reshape", "_mlp._mlp.dense"], "function", ["None"], ["def", "_mlp", "(", "x", ",", "num_outputs", ")", ":", "\n", "    ", "def", "dense", "(", "inputs", ",", "units", ",", "activation", "=", "tf", ".", "nn", ".", "relu", ")", ":", "\n", "        ", "\"\"\"Convenience wrapper for max pool layers.\"\"\"", "\n", "return", "tf", ".", "layers", ".", "dense", "(", "\n", "inputs", ",", "\n", "units", ",", "\n", "activation", ",", "\n", "bias_initializer", "=", "tf", ".", "initializers", ".", "constant", "(", "0.0", ")", ",", "\n", "kernel_initializer", "=", "tf", ".", "truncated_normal_initializer", "(", "stddev", "=", "3e-2", ")", ")", "\n", "\n", "", "x", "=", "tf", ".", "reshape", "(", "x", ",", "[", "-", "1", ",", "784", "]", ")", "\n", "\n", "x", "=", "dense", "(", "x", ",", "1000", ")", "\n", "x", "=", "dense", "(", "x", ",", "500", ")", "\n", "x", "=", "dense", "(", "x", ",", "100", ")", "\n", "linear_outputs", "=", "dense", "(", "x", ",", "num_outputs", ",", "None", ")", "\n", "\n", "return", "linear_outputs", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_data_dir": [[10, 12], ["None"], "function", ["None"], ["def", "get_data_dir", "(", ")", ":", "\n", "    ", "return", "DATA_DIR", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.set_data_dir": [[14, 17], ["None"], "function", ["None"], ["", "def", "set_data_dir", "(", "data_dir", ")", ":", "\n", "    ", "global", "DATA_DIR", "\n", "DATA_DIR", "=", "data_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_baseline_dir": [[19, 21], ["None"], "function", ["None"], ["", "def", "get_baseline_dir", "(", ")", ":", "\n", "    ", "return", "BASELINE_DIR", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.set_baseline_dir": [[23, 26], ["None"], "function", ["None"], ["", "def", "set_baseline_dir", "(", "baseline_dir", ")", ":", "\n", "    ", "global", "BASELINE_DIR", "\n", "BASELINE_DIR", "=", "baseline_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_float_dtype": [[28, 30], ["None"], "function", ["None"], ["", "def", "get_float_dtype", "(", ")", ":", "\n", "    ", "return", "TF_FLOAT_DTYPE", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.set_float_dtype": [[32, 35], ["None"], "function", ["None"], ["", "def", "set_float_dtype", "(", "dtype", ")", ":", "\n", "    ", "global", "TF_FLOAT_DTYPE", "\n", "TF_FLOAT_DTYPE", "=", "dtype", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.float2str": [[7, 11], ["s.split", "mantissa.rstrip"], "function", ["None"], ["def", "float2str", "(", "x", ")", ":", "\n", "    ", "s", "=", "\"{:.10e}\"", ".", "format", "(", "x", ")", "\n", "mantissa", ",", "exponent", "=", "s", ".", "split", "(", "\"e\"", ")", "\n", "return", "mantissa", ".", "rstrip", "(", "\"0\"", ")", "+", "\"e\"", "+", "exponent", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.make_run_name": [[13, 60], ["sorted", "time.strftime", "optimizer_hyperparams.items", "zip", "str", "runner_utils.float2str", "runner_utils.float2str", "runner_utils.float2str", "isinstance", "runner_utils.float2str", "str", "runner_utils.float2str", "str"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.float2str", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.float2str", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.float2str", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.float2str", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.float2str"], ["", "def", "make_run_name", "(", "weight_decay", ",", "batch_size", ",", "num_epochs", ",", "learning_rate", ",", "\n", "lr_sched_epochs", ",", "lr_sched_factors", ",", "random_seed", ",", "\n", "**", "optimizer_hyperparams", ")", ":", "\n", "    ", "\"\"\"Creates a name for the output file of an optimizer run.\n\n  Args:\n    weight_decay (float): The weight decay factor used (or ``None`` to signify\n        the testproblem's default).\n    batch_size (int): The mini-batch size used.\n    num_epochs (int): The number of epochs trained.\n    learning_rate (float): The learning rate used.\n    lr_sched_epochs (list): A list of epoch numbers (positive integers) that\n        mark learning rate changes.\n    lr_sched_factors (list): A list of factors (floats) by which to change the\n        learning rate.\n    random_seed (int): Random seed used.\n\n  Returns:\n    run_folder_name: Name for the run folder consisting of num_epochs,\n        batch_size, weight_decay, all the optimizer hyperparameters, and the\n        learning rate (schedule).\n    file_name: Name for the output file, consisting of random seed and a time\n        stamp.\n  \"\"\"", "\n", "run_folder_name", "=", "\"num_epochs__\"", "+", "str", "(", "\n", "num_epochs", ")", "+", "\"__batch_size__\"", "+", "str", "(", "batch_size", ")", "+", "\"__\"", "\n", "if", "weight_decay", "is", "not", "None", ":", "\n", "        ", "run_folder_name", "+=", "\"weight_decay__{0:s}__\"", ".", "format", "(", "\n", "float2str", "(", "weight_decay", ")", ")", "\n", "\n", "# Add all hyperparameters to the name (sorted alphabetically).", "\n", "", "for", "hp_name", ",", "hp_value", "in", "sorted", "(", "optimizer_hyperparams", ".", "items", "(", ")", ")", ":", "\n", "        ", "run_folder_name", "+=", "\"{0:s}__\"", ".", "format", "(", "hp_name", ")", "\n", "run_folder_name", "+=", "\"{0:s}__\"", ".", "format", "(", "\n", "float2str", "(", "hp_value", ")", "if", "isinstance", "(", "hp_value", ",", "float", "\n", ")", "else", "str", "(", "hp_value", ")", ")", "\n", "", "if", "lr_sched_epochs", "is", "None", ":", "\n", "        ", "run_folder_name", "+=", "\"lr__{0:s}\"", ".", "format", "(", "float2str", "(", "learning_rate", ")", ")", "\n", "", "else", ":", "\n", "        ", "run_folder_name", "+=", "(", "\"lr_schedule__{0:d}_{1:s}\"", ".", "format", "(", "\n", "0", ",", "float2str", "(", "learning_rate", ")", ")", ")", "\n", "for", "epoch", ",", "factor", "in", "zip", "(", "lr_sched_epochs", ",", "lr_sched_factors", ")", ":", "\n", "            ", "run_folder_name", "+=", "(", "\"_{0:d}_{1:s}\"", ".", "format", "(", "\n", "epoch", ",", "float2str", "(", "factor", "*", "learning_rate", ")", ")", ")", "\n", "", "", "file_name", "=", "\"random_seed__{0:d}__\"", ".", "format", "(", "random_seed", ")", "\n", "file_name", "+=", "time", ".", "strftime", "(", "\"%Y-%m-%d-%H-%M-%S\"", ")", "\n", "return", "run_folder_name", ",", "file_name", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.make_lr_schedule": [[62, 105], ["TypeError", "ValueError", "isinstance", "isinstance", "len", "len", "zip"], "function", ["None"], ["", "def", "make_lr_schedule", "(", "lr_base", ",", "lr_sched_epochs", ",", "lr_sched_factors", ")", ":", "\n", "    ", "\"\"\"Creates a learning rate schedule in the form of a dictionary.\n\n  After ``lr_sched_epochs[i]`` epochs of training, the learning rate will be set\n  to ``lr_sched_factors[i] * lr_base``. The schedule is given as a dictionary\n  mapping epoch number to learning rate. The learning rate for epoch 0 (that is\n  ``lr_base``) will automatically be added to the schedule.\n\n  Examples:\n    - ``make_schedule(0.3, [50, 100], [0.1, 0.01])`` yields\n      ``{0: 0.3, 50: 0.03, 100: 0.003}``.\n    - ``make_schedule(0.3)`` yields ``{0: 0.3}``.\n    - ``make_schedule(0.3, [], [])`` yields ``{0: 0.3}``.\n\n  Args:\n    lr_base: A base learning rate (float).\n    lr_sched_epochs: A (possibly empty) list of integers, specifying epochs at\n        which to decrease the learning rate.\n    lr_sched_factors: A (possibly empty) list of floats, specifying factors by\n        which to decrease the learning rate.\n\n  Returns:\n    sched: A dictionary mapping epoch numbers to learning rates.\n  \"\"\"", "\n", "\n", "if", "lr_sched_epochs", "is", "None", "and", "lr_sched_factors", "is", "None", ":", "\n", "        ", "return", "{", "0", ":", "lr_base", "}", "\n", "\n", "# Make sure learning rate schedule has been properly specified", "\n", "", "if", "lr_sched_epochs", "is", "None", "or", "lr_sched_factors", "is", "None", ":", "\n", "        ", "raise", "TypeError", "(", "\n", "\"\"\"Specifiy *both* lr_sched_epochs and lr_sched_factors.\"\"\"", ")", "\n", "", "if", "(", "(", "not", "isinstance", "(", "lr_sched_epochs", ",", "list", ")", ")", "\n", "or", "(", "not", "isinstance", "(", "lr_sched_factors", ",", "list", ")", ")", "\n", "or", "(", "len", "(", "lr_sched_epochs", ")", "!=", "len", "(", "lr_sched_factors", ")", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"\"\"lr_sched_epochs and lr_sched_factors must be lists of\n                     the same length.\"\"\"", ")", "\n", "\n", "# Create schedule as dictionary epoch->factor; add value for epoch 0.", "\n", "", "sched", "=", "{", "n", ":", "f", "*", "lr_base", "for", "n", ",", "f", "in", "zip", "(", "lr_sched_epochs", ",", "lr_sched_factors", ")", "}", "\n", "sched", "[", "0", "]", "=", "lr_base", "\n", "return", "sched", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.__init__": [[47, 75], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer_class", ",", "hyperparams", ")", ":", "\n", "        ", "\"\"\"Creates a new StandardRunner.\n\n    Args:\n      optimizer_class: Optimizer class, which should inherit from\n          tf.train.Optimizer and/or obey the same interface for ``.minimize()``.\n      hyperparams: A list describing the optimizer's hyperparameters other\n          than learning rate. Each entry of the list is a dictionary describing\n          one of the hyperparameters. This dictionary is expected to have the\n          following two fields:\n            - hyperparams[\"name\"] must contain the name of the parameter (i.e.,\n              the exact name of the corresponding keyword argument to the\n              optimizer class' init function.\n            - hyperparams[\"type\"] specifies the type of the parameter (e.g.,\n              ``int``, ``float``, ``bool``).\n          Optionally, the dictionary can have a third field indexed by the key\n          \"default\", which specifies a default value for the hyperparameter.\n\n    Example:\n        optimizer_class = tf.train.MomentumOptimizer\n        hyperparams = [\n            {\"name\": \"momentum\", \"type\": float},\n            {\"name\": \"use_nesterov\", \"type\": bool, \"default\": False}]\n        runner = StandardRunner(optimizer_class, hyperparms)\n    \"\"\"", "\n", "self", ".", "_optimizer_class", "=", "optimizer_class", "\n", "self", ".", "_optimizer_name", "=", "optimizer_class", ".", "__name__", "\n", "self", ".", "_hyperparams", "=", "hyperparams", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run": [[78, 348], ["argparse.ArgumentParser", "vars", "args.update", "standard_runner.StandardRunner._run", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner._run", "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.parse_args"], ["", "def", "run", "(", "self", ",", "\n", "testproblem", "=", "None", ",", "\n", "weight_decay", "=", "None", ",", "\n", "batch_size", "=", "None", ",", "\n", "num_epochs", "=", "None", ",", "\n", "learning_rate", "=", "None", ",", "\n", "lr_sched_epochs", "=", "None", ",", "\n", "lr_sched_factors", "=", "None", ",", "\n", "random_seed", "=", "None", ",", "\n", "data_dir", "=", "None", ",", "\n", "output_dir", "=", "None", ",", "\n", "train_log_interval", "=", "None", ",", "\n", "print_train_iter", "=", "None", ",", "\n", "tf_logging", "=", "None", ",", "\n", "no_logs", "=", "None", ",", "\n", "**", "optimizer_hyperparams", ")", ":", "\n", "        ", "\"\"\"Runs a given optimizer on a DeepOBS testproblem.\n\n    This method receives all relevant options to run the optimizer on a DeepOBS\n    testproblem, including the hyperparameters of the optimizers, which can be\n    passed as keyword arguments (based on the names provided via ``hyperparams``\n    in the init function).\n\n    Options which are *not* passed here will\n    automatically be added as command line arguments. (Some of those will be\n    required, others will have defaults; run the script with the ``--help`` flag\n    to see a description of the command line interface.)\n\n    Training statistics (train/test loss/accuracy) are collected and will be\n    saved to a ``JSON`` output file, together with metadata. The training\n    statistics can optionally also be saved in TensorFlow output files and read\n    during training using `Tensorboard`.\n\n    Args:\n      testproblem (str): Name of a DeepOBS test problem.\n      weight_decay (float): The weight decay factor to use.\n      batch_size (int): The mini-batch size to use.\n      num_epochs (int): The number of epochs to train.\n      learning_rate (float): The learning rate to use. This will function as the\n          base learning rate when implementing a schedule using\n          ``lr_sched_epochs`` and ``lr_sched_factors`` (see below).\n      lr_sched_epochs (list): A list of epoch numbers (positive integers) that\n          mark learning rate changes. The base learning rate is passed via\n          ``learning_rate`` and the factors by which to change are passed via\n          ``lr_sched_factors``.\n          Example: ``learning_rate=0.3``, ``lr_sched_epochs=[50, 100]``,\n          ``lr_sched_factors=[0.1 0.01]`` will start with a learning rate of\n          ``0.3``, then decrease to ``0.1*0.3=0.03`` after training for ``50``\n          epochs, and decrease to ``0.01*0.3=0.003`` after training for ``100``\n          epochs.\n      lr_sched_factors (list): A list of factors (floats) by which to change the\n          learning rate. The base learning rate has to be passed via\n          ``learing_rate`` and the epochs at which to change the learning rate\n          have to be passed via ``lr_sched_factors``.\n          Example: ``learning_rate=0.3``, ``lr_sched_epochs=[50, 100]``,\n          ``lr_sched_factors=[0.1 0.01]`` will start with a learning rate of\n          ``0.3``, then decrease to ``0.1*0.3=0.03`` after training for ``50``\n          epochs, and decrease to ``0.01*0.3=0.003`` after training for ``100``\n          epochs.\n      random_seed (int): Random seed to use. If unspecified, it defaults to\n          ``42``.\n      data_dir (str): Path to the DeepOBS data directory. If unspecified,\n          DeepOBS uses its default `/data_deepobs`.\n      output_dir (str): Path to the output directory. Within this directory,\n          subfolders for the testproblem and the optimizer are automatically\n          created. If unspecified, defaults to '/results'.\n      train_log_interval (int): Interval of steps at which to log training loss.\n          If unspecified it defaults to ``10``.\n      print_train_iter (bool): If ``True``, training loss is printed to screen.\n          If unspecified it defaults to ``False``.\n      tf_logging (bool): If ``True`` log all statistics with tensorflow summaries,\n          which can be viewed in real time with tensorboard. If unspecified it\n          defaults to ``False``.\n      no_logs (bool): If ``True`` no ``JSON`` files are created. If unspecified\n          it defaults to ``False``.\n      optimizer_hyperparams (dict): Keyword arguments for the hyperparameters of\n          the optimizer. These are the ones specified in the ``hyperparams``\n          dictionary passed to the ``__init__``.\n    \"\"\"", "\n", "# We will go through all the arguments, check whether they have been passed", "\n", "# to this function. If yes, we collect the (name, value) pairs  in ``args``.", "\n", "# If not, we add corresponding command line arguments.", "\n", "args", "=", "{", "}", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Run {0:s} on a DeepOBS test problem.\"", ".", "format", "(", "\n", "self", ".", "_optimizer_name", ")", ")", "\n", "\n", "if", "testproblem", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"testproblem\"", ",", "\n", "help", "=", "\"\"\"Name of the DeepOBS testproblem\n          (e.g. 'cifar10_3c3d'\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"testproblem\"", "]", "=", "testproblem", "\n", "\n", "", "if", "weight_decay", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--weight_decay\"", ",", "\n", "\"--wd\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\"\"\"Factor\n          used for the weight_deacy. If not given, the default weight decay for\n          this model is used. Note that not all models use weight decay and this\n          value will be ignored in such a case.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"weight_decay\"", "]", "=", "weight_decay", "\n", "\n", "", "if", "batch_size", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--batch_size\"", ",", "\n", "\"--bs\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The batch size (positive integer).\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"batch_size\"", "]", "=", "batch_size", "\n", "\n", "", "if", "num_epochs", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"-N\"", ",", "\n", "\"--num_epochs\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs.\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"num_epochs\"", "]", "=", "num_epochs", "\n", "\n", "", "if", "learning_rate", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--learning_rate\"", ",", "\n", "\"--lr\"", ",", "\n", "required", "=", "True", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\n", "\"\"\"Learning rate (positive float) to use. Can be used as the base\n          of a learning rate schedule when used in conjunction with\n          --lr_sched_epochs and --lr_sched_factors.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"learning_rate\"", "]", "=", "learning_rate", "\n", "\n", "", "if", "lr_sched_epochs", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--lr_sched_epochs\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"\"\"One or more epoch numbers (positive integers) that mark\n          learning rate changes. The base learning rate has to be passed via\n          '--learing_rate' and the factors by which to change have to be passed\n          via '--lr_sched_factors'. Example: '--lr 0.3 --lr_sched_epochs 50 100\n          --lr_sched_factors 0.1 0.01' will start with a learning rate of 0.3,\n          then decrease to 0.1*0.3=0.03 after training for 50 epochs, and\n          decrease to 0.01*0.3=0.003' after training for 100 epochs.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"lr_sched_epochs\"", "]", "=", "lr_sched_epochs", "\n", "\n", "", "if", "lr_sched_factors", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--lr_sched_factors\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "type", "=", "float", ",", "\n", "help", "=", "\n", "\"\"\"One or more factors (floats) by which to change the learning\n          rate. The base learning rate has to be passed via '--learing_rate' and\n          the epochs at which to change the learning rate have to be passed via\n          '--lr_sched_factors'. Example: '--lr 0.3 --lr_sched_epochs 50 100\n          --lr_sched_factors 0.1 0.01' will start with a learning rate of 0.3,\n          then decrease to 0.1*0.3=0.03 after training for 50 epochs, and\n          decrease to 0.01*0.3=0.003' after training for 100 epochs.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"lr_sched_factors\"", "]", "=", "lr_sched_factors", "\n", "\n", "", "if", "random_seed", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"-r\"", ",", "\n", "\"--random_seed\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "42", ",", "\n", "help", "=", "\"An integer to set as tensorflow's random seed.\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"random_seed\"", "]", "=", "random_seed", "\n", "\n", "", "if", "data_dir", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "help", "=", "\"\"\"Path to the base data dir. If\n      not specified, DeepOBS uses its default.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"data_dir\"", "]", "=", "data_dir", "\n", "\n", "", "if", "output_dir", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"results\"", ",", "\n", "help", "=", "\"\"\"Path to the base directory in which output files will be\n          stored. Results will automatically be sorted into subdirectories of\n          the form 'testproblem/optimizer'.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"output_dir\"", "]", "=", "output_dir", "\n", "\n", "", "if", "train_log_interval", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--train_log_interval\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "10", ",", "\n", "help", "=", "\"Interval of steps at which training loss is logged.\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"train_log_interval\"", "]", "=", "train_log_interval", "\n", "\n", "", "if", "print_train_iter", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--print_train_iter\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"\"\"Add this flag to print mini-batch training loss to\n          stdout on each (logged) interation.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"print_train_iter\"", "]", "=", "print_train_iter", "\n", "\n", "", "if", "tf_logging", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--tf_logging\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"\"\"Add this flag to log statistics using tensorflow\n          (to view in tensorboard).\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"tf_logging\"", "]", "=", "tf_logging", "\n", "\n", "", "if", "no_logs", "is", "None", ":", "\n", "            ", "parser", ".", "add_argument", "(", "\n", "\"--no_logs\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"\"\"Add this flag to not save any json logging files.\"\"\"", ")", "\n", "", "else", ":", "\n", "            ", "args", "[", "\"no_logs\"", "]", "=", "no_logs", "\n", "\n", "# Optimizer hyperparams", "\n", "", "for", "hp", "in", "self", ".", "_hyperparams", ":", "\n", "            ", "hp_name", "=", "hp", "[", "\"name\"", "]", "\n", "if", "hp_name", "in", "optimizer_hyperparams", ":", "\n", "                ", "args", "[", "hp_name", "]", "=", "optimizer_hyperparams", "[", "hp_name", "]", "\n", "", "else", ":", "# hp_name not in optimizer_hyperparams", "\n", "                ", "hp_type", "=", "hp", "[", "\"type\"", "]", "\n", "if", "\"default\"", "in", "hp", ":", "\n", "                    ", "hp_default", "=", "hp", "[", "\"default\"", "]", "\n", "parser", ".", "add_argument", "(", "\n", "\"--{0:s}\"", ".", "format", "(", "hp_name", ")", ",", "\n", "type", "=", "hp_type", ",", "\n", "default", "=", "hp_default", ",", "\n", "help", "=", "\"\"\"Hyperparameter {0:s} of {1:s} ({2:s};\n              defaults to {3:s}).\"\"\"", ".", "format", "(", "hp_name", ",", "self", ".", "_optimizer_name", ",", "\n", "str", "(", "hp_type", ")", ",", "str", "(", "hp_default", ")", ")", ")", "\n", "", "else", ":", "\n", "                    ", "parser", ".", "add_argument", "(", "\n", "\"--{0:s}\"", ".", "format", "(", "hp_name", ")", ",", "\n", "type", "=", "hp_type", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"Hyperparameter {0:s} of {1:s} ({2:s}).\"", ".", "format", "(", "\n", "hp_name", ",", "self", ".", "_optimizer_name", ",", "str", "(", "hp_type", ")", ")", ")", "\n", "\n", "# Get the command line arguments and add them to the ``args`` dict. Then", "\n", "# call the _run function with those arguments.", "\n", "", "", "", "cmdline_args", "=", "vars", "(", "parser", ".", "parse_args", "(", ")", ")", "\n", "args", ".", "update", "(", "cmdline_args", ")", "\n", "self", ".", "_run", "(", "**", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner._run": [[349, 566], ["tensorflow.reset_default_graph", "tensorflow.set_random_seed", "getattr.set_up", "tensorflow.Variable", "tensorflow.Variable", "standard_runner.StandardRunner._optimizer_class", "runner_utils.make_lr_schedule", "tensorflow.Session", "tensorflow.Session.run", "range", "tensorflow.Session.close", "config.set_data_dir", "importlib.import_module", "getattr", "print", "getattr.", "getattr.", "tensorflow.reduce_mean", "tensorflow.control_dependencies", "standard_runner.StandardRunner.minimize", "runner_utils.make_run_name", "os.path.join", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.merge_all", "tensorflow.summary.merge_all", "tensorflow.summary.FileWriter", "tensorflow.global_variables_initializer", "loss_list.append", "acc_list.append", "print", "print", "print", "standard_runner.StandardRunner._run.evaluate"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.testproblems.svhn_wrn164.svhn_wrn164.set_up", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.make_lr_schedule", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner.run", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.set_data_dir", "home.repos.pwc.inspect_result.fsschneider_deepobs.runners.runner_utils.make_run_name"], ["", "def", "_run", "(", "self", ",", "testproblem", ",", "weight_decay", ",", "batch_size", ",", "num_epochs", ",", "\n", "learning_rate", ",", "lr_sched_epochs", ",", "lr_sched_factors", ",", "random_seed", ",", "\n", "data_dir", ",", "output_dir", ",", "train_log_interval", ",", "print_train_iter", ",", "\n", "tf_logging", ",", "no_logs", ",", "**", "optimizer_hyperparams", ")", ":", "\n", "        ", "\"\"\"Performs the actual run, given all the arguments.\"\"\"", "\n", "\n", "# Set data directory of DeepOBS.", "\n", "if", "data_dir", "is", "not", "None", ":", "\n", "            ", "config", ".", "set_data_dir", "(", "data_dir", ")", "\n", "\n", "# Find testproblem by name and instantiate with batch size and weight decay.", "\n", "", "try", ":", "\n", "            ", "testproblem_mod", "=", "importlib", ".", "import_module", "(", "testproblem", ")", "\n", "testproblem_cls", "=", "getattr", "(", "testproblem_mod", ",", "testproblem", ")", "\n", "print", "(", "\"Loading local testproblem.\"", ")", "\n", "", "except", ":", "\n", "            ", "testproblem_cls", "=", "getattr", "(", "testproblems", ",", "testproblem", ")", "\n", "", "if", "weight_decay", "is", "not", "None", ":", "\n", "            ", "tproblem", "=", "testproblem_cls", "(", "batch_size", ",", "weight_decay", ")", "\n", "", "else", ":", "\n", "            ", "tproblem", "=", "testproblem_cls", "(", "batch_size", ")", "\n", "\n", "# Set up the testproblem.", "\n", "", "tf", ".", "reset_default_graph", "(", ")", "\n", "tf", ".", "set_random_seed", "(", "random_seed", ")", "\n", "tproblem", ".", "set_up", "(", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "tproblem", ".", "losses", ")", "+", "tproblem", ".", "regularizer", "\n", "\n", "# Set up the optimizer and create learning rate schedule.", "\n", "global_step", "=", "tf", ".", "Variable", "(", "0", ",", "trainable", "=", "False", ")", "\n", "learning_rate_var", "=", "tf", ".", "Variable", "(", "learning_rate", ",", "trainable", "=", "False", ")", "\n", "opt", "=", "self", ".", "_optimizer_class", "(", "learning_rate_var", ",", "**", "optimizer_hyperparams", ")", "\n", "lr_schedule", "=", "runner_utils", ".", "make_lr_schedule", "(", "\n", "learning_rate", ",", "lr_sched_epochs", ",", "lr_sched_factors", ")", "\n", "\n", "# Call optimizer's minimize on loss to update all variables in the", "\n", "# TRAINABLE_VARIABLES collection (with a dependency on performing all ops", "\n", "# in the collection UPDATE_OPS collection for batch norm, etc).", "\n", "with", "tf", ".", "control_dependencies", "(", "\n", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", ")", ":", "\n", "            ", "step", "=", "opt", ".", "minimize", "(", "loss", ",", "global_step", "=", "global_step", ")", "\n", "\n", "# Create output folder", "\n", "", "if", "not", "no_logs", ":", "\n", "            ", "run_folder_name", ",", "file_name", "=", "runner_utils", ".", "make_run_name", "(", "\n", "weight_decay", ",", "batch_size", ",", "num_epochs", ",", "learning_rate", ",", "\n", "lr_sched_epochs", ",", "lr_sched_factors", ",", "random_seed", ",", "\n", "**", "optimizer_hyperparams", ")", "\n", "directory", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "testproblem", ",", "self", ".", "_optimizer_name", ",", "\n", "run_folder_name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "directory", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "directory", ")", "\n", "\n", "# Lists to track train/test loss and accuracy.", "\n", "", "", "train_losses", "=", "[", "]", "\n", "test_losses", "=", "[", "]", "\n", "minibatch_train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "test_accuracies", "=", "[", "]", "\n", "\n", "# Tensorboard summaries", "\n", "if", "tf_logging", ":", "\n", "# per iteration", "\n", "            ", "mb_train_loss_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\n", "\"training/minibatch_train_losses\"", ",", "\n", "loss", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "SUMMARIES", ",", "\"per_iteration\"", "]", ")", "\n", "# per epoch", "\n", "lr_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\n", "\"hyperparams/learning_rate\"", ",", "\n", "learning_rate_var", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "SUMMARIES", ",", "\"per_epoch\"", "]", ")", "\n", "batch_summary", "=", "tf", ".", "summary", ".", "scalar", "(", "\n", "\"hyperparams/batch_size\"", ",", "\n", "batch_size", ",", "\n", "collections", "=", "[", "tf", ".", "GraphKeys", ".", "SUMMARIES", ",", "\"per_epoch\"", "]", ")", "\n", "\n", "per_iter_summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", "key", "=", "\"per_iteration\"", ")", "\n", "per_epoch_summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", "key", "=", "\"per_epoch\"", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "directory", ")", "\n", "\n", "# Start tensorflow session and initialize variables.", "\n", "", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "\n", "# Wrapper functions for the evaluation phase.", "\n", "def", "evaluate", "(", "test", "=", "True", ")", ":", "\n", "            ", "\"\"\"Computes average loss and accuracy in the evaluation phase.\"\"\"", "\n", "if", "test", ":", "\n", "                ", "sess", ".", "run", "(", "tproblem", ".", "test_init_op", ")", "\n", "msg", "=", "\"TEST:\"", "\n", "loss_list", "=", "test_losses", "\n", "acc_list", "=", "test_accuracies", "\n", "", "else", ":", "\n", "                ", "sess", ".", "run", "(", "tproblem", ".", "train_eval_init_op", ")", "\n", "msg", "=", "\"TRAIN:\"", "\n", "loss_list", "=", "train_losses", "\n", "acc_list", "=", "train_accuracies", "\n", "\n", "# Compute average loss and (if applicable) accuracy.", "\n", "", "loss_", "=", "0.0", "\n", "num_iters", "=", "0.0", "\n", "acc_", "=", "0.0", "\n", "if", "tproblem", ".", "accuracy", "is", "not", "None", ":", "\n", "                ", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "l_", ",", "a_", "=", "sess", ".", "run", "(", "[", "loss", ",", "tproblem", ".", "accuracy", "]", ")", "\n", "loss_", "+=", "l_", "\n", "acc_", "+=", "a_", "\n", "num_iters", "+=", "1.0", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "break", "\n", "", "", "", "else", ":", "# accuracy is None", "\n", "                ", "acc_", "=", "0.0", "\n", "while", "True", ":", "\n", "                    ", "try", ":", "\n", "                        ", "l_", "=", "sess", ".", "run", "(", "loss", ")", "\n", "loss_", "+=", "l_", "\n", "num_iters", "+=", "1.0", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                        ", "break", "\n", "", "", "", "loss_", "/=", "num_iters", "\n", "acc_", "/=", "num_iters", "\n", "\n", "# Print and log the results.", "\n", "loss_list", ".", "append", "(", "loss_", ")", "\n", "acc_list", ".", "append", "(", "acc_", ")", "\n", "# Log results to tensorflow summaries", "\n", "if", "tf_logging", ":", "\n", "                ", "if", "test", ":", "\n", "                    ", "tag", "=", "\"epoch/test_\"", "\n", "", "else", ":", "\n", "                    ", "tag", "=", "\"epoch/train_\"", "\n", "", "summary", "=", "tf", ".", "Summary", "(", ")", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "tag", "+", "\"loss_\"", ",", "simple_value", "=", "loss_", ")", "\n", "summary", ".", "value", ".", "add", "(", "tag", "=", "tag", "+", "\"acc_\"", ",", "simple_value", "=", "acc_", ")", "\n", "per_epoch_summary_", "=", "sess", ".", "run", "(", "per_epoch_summaries", ")", "\n", "summary_writer", ".", "add_summary", "(", "per_epoch_summary_", ",", "\n", "len", "(", "loss_list", ")", "-", "1", ")", "\n", "summary_writer", ".", "add_summary", "(", "summary", ",", "len", "(", "loss_list", ")", "-", "1", ")", "\n", "summary_writer", ".", "flush", "(", ")", "\n", "\n", "", "print", "(", "\"{0:s} loss {1:g}, acc {2:f}\"", ".", "format", "(", "msg", ",", "loss_", ",", "acc_", ")", ")", "\n", "\n", "# Start of training loop.", "\n", "", "for", "n", "in", "range", "(", "num_epochs", "+", "1", ")", ":", "\n", "# Evaluate at beginning of epoch.", "\n", "            ", "print", "(", "\"********************************\"", ")", "\n", "print", "(", "\"Evaluating after {0:d} of {1:d} epochs...\"", ".", "format", "(", "\n", "n", ",", "num_epochs", ")", ")", "\n", "evaluate", "(", "test", "=", "False", ")", "\n", "evaluate", "(", "test", "=", "True", ")", "\n", "print", "(", "\"********************************\"", ")", "\n", "\n", "# Break from train loop after the last round of evaluation", "\n", "if", "n", "==", "num_epochs", ":", "\n", "                ", "break", "\n", "\n", "# Training", "\n", "", "if", "n", "in", "lr_schedule", ":", "\n", "                ", "sess", ".", "run", "(", "learning_rate_var", ".", "assign", "(", "lr_schedule", "[", "n", "]", ")", ")", "\n", "print", "(", "\"Setting learning rate to {0:f}\"", ".", "format", "(", "lr_schedule", "[", "n", "]", ")", ")", "\n", "", "sess", ".", "run", "(", "tproblem", ".", "train_init_op", ")", "\n", "s", "=", "0", "\n", "while", "True", ":", "\n", "                ", "try", ":", "\n", "# Training step, with logging if we hit the train_log_interval", "\n", "                    ", "if", "s", "%", "train_log_interval", "==", "0", ":", "\n", "                        ", "if", "tf_logging", ":", "\n", "                            ", "_", ",", "loss_", ",", "per_iter_summary_", "=", "sess", ".", "run", "(", "\n", "[", "step", ",", "loss", ",", "per_iter_summaries", "]", ")", "\n", "summary_writer", ".", "add_summary", "(", "per_iter_summary_", ",", "\n", "sess", ".", "run", "(", "global_step", ")", ")", "\n", "", "else", ":", "\n", "                            ", "_", ",", "loss_", "=", "sess", ".", "run", "(", "[", "step", ",", "loss", "]", ")", "\n", "", "minibatch_train_losses", ".", "append", "(", "loss_", ".", "astype", "(", "float", ")", ")", "\n", "if", "print_train_iter", ":", "\n", "                            ", "print", "(", "\"Epoch {0:d}, step {1:d}: loss {2:g}\"", ".", "format", "(", "\n", "n", ",", "s", ",", "loss_", ")", ")", "\n", "", "", "else", ":", "\n", "                        ", "sess", ".", "run", "(", "step", ")", "\n", "", "s", "+=", "1", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "sess", ".", "close", "(", ")", "\n", "# --- End of training loop.", "\n", "\n", "# Put results into output dictionary.", "\n", "output", "=", "{", "\n", "\"train_losses\"", ":", "train_losses", ",", "\n", "\"test_losses\"", ":", "test_losses", ",", "\n", "\"minibatch_train_losses\"", ":", "minibatch_train_losses", "\n", "}", "\n", "if", "tproblem", ".", "accuracy", "is", "not", "None", ":", "\n", "            ", "output", "[", "\"train_accuracies\"", "]", "=", "train_accuracies", "\n", "output", "[", "\"test_accuracies\"", "]", "=", "test_accuracies", "\n", "\n", "# Put all run parameters into output dictionary.", "\n", "", "output", "[", "\"optimizer\"", "]", "=", "self", ".", "_optimizer_name", "\n", "output", "[", "\"testproblem\"", "]", "=", "testproblem", "\n", "output", "[", "\"weight_decay\"", "]", "=", "weight_decay", "\n", "output", "[", "\"batch_size\"", "]", "=", "batch_size", "\n", "output", "[", "\"num_epochs\"", "]", "=", "num_epochs", "\n", "output", "[", "\"learning_rate\"", "]", "=", "learning_rate", "\n", "output", "[", "\"lr_sched_epochs\"", "]", "=", "lr_sched_epochs", "\n", "output", "[", "\"lr_sched_factors\"", "]", "=", "lr_sched_factors", "\n", "output", "[", "\"random_seed\"", "]", "=", "random_seed", "\n", "output", "[", "\"train_log_interval\"", "]", "=", "train_log_interval", "\n", "\n", "# Add optimizer hyperparameters as a sub-dictionary.", "\n", "output", "[", "\"hyperparams\"", "]", "=", "optimizer_hyperparams", "\n", "\n", "# Dump output into json file.", "\n", "if", "not", "no_logs", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "file_name", "+", "\".json\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "                ", "json", ".", "dump", "(", "output", ",", "f", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts._tolstoi_preprocess.preprocess": [[19, 68], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "collections.Counter", "sorted", "zip", "print", "dict", "numpy.array", "int", "numpy.save", "numpy.save", "ValueError", "os.path.exists", "os.path.exists", "ValueError", "codecs.open", "inp_file.read", "collections.Counter.items", "len", "zip", "open", "six.moves.cPickle.dump", "list", "numpy.ceil", "range", "map", "len", "numpy.size"], "function", ["None"], ["def", "preprocess", "(", "file_path", "=", "\"\"", ",", "\n", "encoding", "=", "\"utf-8\"", ",", "\n", "test_size", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"Short summary.\n\n    Args:\n        file_path (type): Description of parameter `file_path`.\n        encoding (type): Description of parameter `encoding`.\n        test_size (type): Description of parameter `test_size`.\n\n    Returns:\n        type: Description of returned object.\n\n    \"\"\"", "\n", "# Paths for the input and output files", "\n", "input_file", "=", "os", ".", "path", ".", "join", "(", "file_path", ",", "\"input.txt\"", ")", "\n", "vocab_file", "=", "os", ".", "path", ".", "join", "(", "file_path", ",", "\"vocab.pkl\"", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "file_path", ",", "\"train.npy\"", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "file_path", ",", "\"test.npy\"", ")", "\n", "\n", "# Make sure input file exists and the npy and pkl files don't", "\n", "assert", "os", ".", "path", ".", "exists", "(", "input_file", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "vocab_file", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Found existing vocabulary file\"", ")", "\n", "", "if", "os", ".", "path", ".", "exists", "(", "train_file", ")", "or", "os", ".", "path", ".", "exists", "(", "test_file", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\"Found existing array file\"", ")", "\n", "\n", "# Parse text and create vocavbulary", "\n", "", "with", "codecs", ".", "open", "(", "input_file", ",", "\"r\"", ",", "encoding", "=", "encoding", ")", "as", "inp_file", ":", "\n", "        ", "data", "=", "inp_file", ".", "read", "(", ")", "\n", "", "counter", "=", "collections", ".", "Counter", "(", "data", ")", "\n", "count_pairs", "=", "sorted", "(", "counter", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "-", "x", "[", "1", "]", ")", "\n", "chars", ",", "_", "=", "zip", "(", "*", "count_pairs", ")", "\n", "print", "(", "\"Vocab size\"", ",", "len", "(", "chars", ")", ")", "\n", "vocab", "=", "dict", "(", "zip", "(", "chars", ",", "range", "(", "len", "(", "chars", ")", ")", ")", ")", "\n", "\n", "# Save vocabulary file", "\n", "with", "open", "(", "vocab_file", ",", "'wb'", ")", "as", "voc_file", ":", "\n", "        ", "cPickle", ".", "dump", "(", "chars", ",", "voc_file", ")", "\n", "\n", "# Create array of chharacter ids", "\n", "", "array", "=", "np", ".", "array", "(", "list", "(", "map", "(", "vocab", ".", "get", ",", "data", ")", ")", ")", "\n", "\n", "# Split in train and test and save to .npy files", "\n", "train_size", "=", "int", "(", "np", ".", "ceil", "(", "(", "1.0", "-", "test_size", ")", "*", "np", ".", "size", "(", "array", ")", ")", ")", "\n", "train", "=", "array", "[", "0", ":", "train_size", "]", "\n", "test", "=", "array", "[", "train_size", ":", "]", "\n", "np", ".", "save", "(", "train_file", ",", "train", ")", "\n", "np", ".", "save", "(", "test_file", ",", "test", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_plot_results.parse_args": [[9, 50], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Plotting tool for DeepOBS.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"path\"", ",", "help", "=", "\"Path to the results folder\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--get_best_run\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Return best hyperparameter setting per optimizer and testproblem.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--plot_lr_sensitivity\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Plot 'sensitivity' plot for the learning rates.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--plot_performance\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Plot performance plot compared to the baselines.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--plot_table\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\n", "\"Plot overall performance table including speed and hyperparameters.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--full\"", ",", "\n", "action", "=", "\"store_const\"", ",", "\n", "const", "=", "True", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Run a full analysis and plot all figures.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--baseline_path\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"baselines_deepobs\"", ",", "\n", "help", "=", "\"Path to baseline folder.\"", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_plot_results.read_args": [[52, 56], ["deepobs_plot_results.parse_args", "parse_args.parse_args"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.parse_args", "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.parse_args"], ["", "def", "read_args", "(", ")", ":", "\n", "    ", "parser", "=", "parse_args", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_plot_results.main": [[58, 86], ["argparse.Namespace", "print", "deepobs.analyzer.analyze_utils.Analyzer", "print", "deepobs.tensorflow.config.set_baseline_dir", "deepobs.analyzer.analyze_utils.Analyzer", "deepobs.analyzer.analyze.get_best_run", "deepobs.analyzer.analyze.plot_lr_sensitivity", "deepobs.analyzer.analyze.plot_performance", "deepobs.analyzer.analyze.plot_table", "locals", "deepobs.tensorflow.config.get_baseline_dir"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.set_baseline_dir", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.get_best_run", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_lr_sensitivity", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_baseline_dir"], ["", "def", "main", "(", "path", ",", "get_best_run", ",", "plot_lr_sensitivity", ",", "plot_performance", ",", "plot_table", ",", "\n", "full", ",", "baseline_path", ")", ":", "\n", "# Put all input arguments back into an args variable, so I can use it as", "\n", "# before (without the main function)", "\n", "    ", "args", "=", "argparse", ".", "Namespace", "(", "**", "locals", "(", ")", ")", "\n", "# Parse whole baseline folder", "\n", "if", "args", ".", "baseline_path", ":", "\n", "        ", "print", "(", "\"Parsing baseline folder\"", ")", "\n", "deepobs", ".", "tensorflow", ".", "config", ".", "set_baseline_dir", "(", "args", ".", "baseline_path", ")", "\n", "baseline_parser", "=", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "Analyzer", "(", "\n", "deepobs", ".", "tensorflow", ".", "config", ".", "get_baseline_dir", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "baseline_parser", "=", "None", "\n", "\n", "# Parse path folder", "\n", "", "print", "(", "\"Parsing results folder\"", ")", "\n", "folder_parser", "=", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "Analyzer", "(", "args", ".", "path", ")", "\n", "\n", "if", "args", ".", "get_best_run", "or", "args", ".", "full", ":", "\n", "        ", "deepobs", ".", "analyzer", ".", "analyze", ".", "get_best_run", "(", "folder_parser", ")", "\n", "", "if", "args", ".", "plot_lr_sensitivity", "or", "args", ".", "full", ":", "\n", "        ", "deepobs", ".", "analyzer", ".", "analyze", ".", "plot_lr_sensitivity", "(", "folder_parser", ",", "\n", "baseline_parser", ")", "\n", "", "if", "args", ".", "plot_performance", "or", "args", ".", "full", ":", "\n", "        ", "deepobs", ".", "analyzer", ".", "analyze", ".", "plot_performance", "(", "folder_parser", ",", "\n", "baseline_parser", ")", "\n", "", "if", "args", ".", "plot_table", "or", "args", ".", "full", ":", "\n", "        ", "deepobs", ".", "analyzer", ".", "analyze", ".", "plot_table", "(", "folder_parser", ",", "baseline_parser", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.parse_args": [[19, 70], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "function", ["None"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Run a new run script and compare its runtime to SGD.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"run_script\"", ",", "help", "=", "\"Path to the new run_script.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--test_problem\"", ",", "\n", "default", "=", "'mnist_mlp'", ",", "\n", "help", "=", "\"Name of the test problem to run both scripts.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--data_dir\"", ",", "\n", "default", "=", "'data_deepobs'", ",", "\n", "help", "=", "\"Path to the base data dir. If not set, deepobs uses its default.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--bs\"", ",", "\n", "\"--batch_size\"", ",", "\n", "default", "=", "128", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"The batch size (positive integer).\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--lr\"", ",", "\n", "\"--learning_rate\"", ",", "\n", "default", "=", "1e-5", ",", "\n", "help", "=", "\n", "\"The learning rate of both SGD and the new optimizer, defaults to 1e-5.\"", "\n", ")", "\n", "# Number of steps and checkpoint interval", "\n", "parser", ".", "add_argument", "(", "\n", "\"-N\"", ",", "\n", "\"--num_epochs\"", ",", "\n", "default", "=", "3", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of training epochs per run.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_runs\"", ",", "\n", "default", "=", "5", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Total number of runs for each optimizer.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--saveto\"", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Folder for saving a txt files with a summary.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--optimizer_args\"", ",", "\n", "help", "=", "\"Additional arguments for the new optimizer\"", ",", "\n", "type", "=", "str", ")", "\n", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.read_args": [[72, 76], ["deepobs_estimate_runtime.parse_args", "parse_args.parse_args"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.parse_args", "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.parse_args"], ["", "def", "read_args", "(", ")", ":", "\n", "    ", "parser", "=", "parse_args", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts.deepobs_estimate_runtime.main": [[78, 151], ["argparse.Namespace", "range", "numpy.divide", "print", "print", "print", "time.time", "deepobs.runners.StandardRunner", "tfobs.runners.StandardRunner._run", "time.time", "SGD_times.append", "print", "print", "time.time", "os.system", "time.time", "New_opt_times.append", "print", "str", "locals", "argparse.Namespace.optimizer_args.split", "filter", "numpy.std", "str", "numpy.mean", "str", "str", "str", "str", "str", "numpy.mean", "str", "numpy.mean"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.runners.standard_runner.StandardRunner._run"], ["", "def", "main", "(", "run_script", ",", "\n", "optimizer_args", ",", "\n", "test_problem", "=", "\"mnist.mnist_mlp\"", ",", "\n", "data_dir", "=", "\"data_deepobs\"", ",", "\n", "bs", "=", "128", ",", "\n", "lr", "=", "1e-5", ",", "\n", "num_epochs", "=", "3", ",", "\n", "num_runs", "=", "5", ",", "\n", "saveto", "=", "None", ")", ":", "\n", "# Put all input arguments back into an args variable, so I can use it as before (without the main function)", "\n", "    ", "args", "=", "argparse", ".", "Namespace", "(", "**", "locals", "(", ")", ")", "\n", "SGD_times", "=", "[", "]", "\n", "New_opt_times", "=", "[", "]", "\n", "\n", "for", "i", "in", "range", "(", "args", ".", "num_runs", ")", ":", "\n", "        ", "print", "(", "\"** Start Run: \"", ",", "i", "+", "1", ",", "\"of\"", ",", "args", ".", "num_runs", ")", "\n", "\n", "# SGD", "\n", "\n", "print", "(", "\"Running SGD\"", ")", "\n", "start_SGD", "=", "time", ".", "time", "(", ")", "\n", "runner", "=", "tfobs", ".", "runners", ".", "StandardRunner", "(", "\n", "tf", ".", "train", ".", "GradientDescentOptimizer", ",", "[", "]", ")", "\n", "runner", ".", "_run", "(", "\n", "testproblem", "=", "args", ".", "test_problem", ",", "\n", "weight_decay", "=", "None", ",", "\n", "batch_size", "=", "args", ".", "bs", ",", "\n", "num_epochs", "=", "args", ".", "num_epochs", ",", "\n", "learning_rate", "=", "args", ".", "lr", ",", "\n", "lr_sched_epochs", "=", "None", ",", "\n", "lr_sched_factors", "=", "None", ",", "\n", "random_seed", "=", "42", ",", "\n", "data_dir", "=", "args", ".", "data_dir", ",", "\n", "output_dir", "=", "None", ",", "\n", "train_log_interval", "=", "10", ",", "\n", "print_train_iter", "=", "False", ",", "\n", "tf_logging", "=", "False", ",", "\n", "no_logs", "=", "True", ")", "\n", "end_SGD", "=", "time", ".", "time", "(", ")", "\n", "\n", "SGD_times", ".", "append", "(", "end_SGD", "-", "start_SGD", ")", "\n", "print", "(", "\"Time for SGD run \"", ",", "i", "+", "1", ",", "\": \"", ",", "SGD_times", "[", "-", "1", "]", ")", "\n", "\n", "# New Optimizer", "\n", "run_script", "=", "\"python \"", "+", "args", ".", "run_script", "+", "\" \"", "+", "args", ".", "test_problem", "+", "\" --lr=\"", "+", "str", "(", "\n", "args", ".", "lr", ")", "+", "\" --bs=\"", "+", "str", "(", "args", ".", "bs", ")", "+", "\" --num_epochs=\"", "+", "str", "(", "\n", "args", ".", "\n", "num_epochs", ")", "+", "\" --data_dir=\"", "+", "args", ".", "data_dir", "+", "\" --no_logs\"", "\n", "# add optimizer_args if necessary", "\n", "if", "args", ".", "optimizer_args", "is", "not", "None", ":", "\n", "            ", "optimizer_args", "=", "args", ".", "optimizer_args", ".", "split", "(", "'--'", ")", "\n", "optimizer_args_clear", "=", "filter", "(", "None", ",", "optimizer_args", ")", "\n", "for", "arg", "in", "optimizer_args_clear", ":", "\n", "                ", "run_script", "+=", "\" --\"", "+", "arg", "\n", "\n", "", "", "print", "(", "\"Running...\"", ",", "run_script", ")", "\n", "start_script", "=", "time", ".", "time", "(", ")", "\n", "os", ".", "system", "(", "run_script", ")", "\n", "end_script", "=", "time", ".", "time", "(", ")", "\n", "\n", "New_opt_times", ".", "append", "(", "end_script", "-", "start_script", ")", "\n", "print", "(", "\"Time for new optimizer run \"", ",", "i", "+", "1", ",", "\": \"", ",", "New_opt_times", "[", "-", "1", "]", ")", "\n", "\n", "", "overhead", "=", "np", ".", "divide", "(", "New_opt_times", ",", "SGD_times", ")", "\n", "\n", "output", "=", "\"** Mean run time SGD: \"", "+", "str", "(", "\n", "np", ".", "mean", "(", "SGD_times", ")", ")", "+", "\"\\n\"", "+", "\"** Mean run time new optimizer: \"", "+", "str", "(", "\n", "np", ".", "mean", "(", "New_opt_times", ")", ")", "+", "\"\\n\"", "+", "\"** Overhead per run: \"", "+", "str", "(", "\n", "overhead", ")", "+", "\"\\n\"", "+", "\"** Mean overhead: \"", "+", "str", "(", "\n", "np", ".", "mean", "(", "overhead", ")", ")", "+", "\" Standard deviation: \"", "+", "str", "(", "\n", "np", ".", "std", "(", "overhead", ")", ")", "\n", "\n", "print", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.scripts._svhn_preprocess.preprocess": [[11, 55], ["os.path.join", "scipy.io.loadmat", "open", "range", "open.close", "os.path.join", "scipy.io.loadmat", "open", "range", "open.close", "[].astype().tofile", "[].astype().tofile", "[].astype().tofile", "[].astype().tofile", "open.close", "open", "[].astype", "[].astype", "[].astype", "[].astype"], "function", ["None"], ["def", "preprocess", "(", "file_path", "=", "\"\"", ",", "save_path", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"Preprocesses the train and test dataset of the street view house numbers\n    from mat files to a CIFAR-style binary format.\n\n    Args:\n        file_path (str): Path to the .mat files.\n        save_path (str): Path where the function should save the .bin files to.\n    \"\"\"", "\n", "# Convert train images", "\n", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "file_path", ",", "\"train_32x32.mat\"", ")", "\n", "read_input", "=", "scipy", ".", "io", ".", "loadmat", "(", "train_file", ")", "\n", "j", "=", "0", "\n", "output_file", "=", "open", "(", "save_path", "+", "'/data_batch_%d.bin'", "%", "j", ",", "'ab'", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "64000", ")", ":", "\n", "\n", "# create new bin file", "\n", "        ", "if", "i", ">", "0", "and", "i", "%", "12800", "==", "0", ":", "\n", "            ", "output_file", ".", "close", "(", ")", "\n", "j", "=", "j", "+", "1", "\n", "output_file", "=", "open", "(", "save_path", "+", "'/data_batch_%d.bin'", "%", "j", ",", "'ab'", ")", "\n", "\n", "# Write to bin file", "\n", "", "if", "read_input", "[", "'y'", "]", "[", "i", "]", "==", "10", ":", "\n", "            ", "read_input", "[", "'y'", "]", "[", "i", "]", "=", "0", "\n", "", "read_input", "[", "'y'", "]", "[", "i", "]", ".", "astype", "(", "'uint8'", ")", ".", "tofile", "(", "output_file", ")", "\n", "read_input", "[", "'X'", "]", "[", ":", ",", ":", ",", ":", ",", "i", "]", ".", "astype", "(", "'uint8'", ")", ".", "tofile", "(", "output_file", ")", "\n", "\n", "", "output_file", ".", "close", "(", ")", "\n", "\n", "# Convert test images", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "file_path", ",", "\"test_32x32.mat\"", ")", "\n", "read_input", "=", "scipy", ".", "io", ".", "loadmat", "(", "test_file", ")", "\n", "output_file", "=", "open", "(", "save_path", "+", "'/test_batch.bin'", ",", "'ab'", ")", "\n", "\n", "for", "i", "in", "range", "(", "0", ",", "26032", ")", ":", "\n", "# Write to bin file", "\n", "        ", "if", "read_input", "[", "'y'", "]", "[", "i", "]", "==", "10", ":", "\n", "            ", "read_input", "[", "'y'", "]", "[", "i", "]", "=", "0", "\n", "", "read_input", "[", "'y'", "]", "[", "i", "]", ".", "astype", "(", "'uint8'", ")", ".", "tofile", "(", "output_file", ")", "\n", "read_input", "[", "'X'", "]", "[", ":", ",", ":", ",", ":", ",", "i", "]", ".", "astype", "(", "'uint8'", ")", ".", "tofile", "(", "output_file", ")", "\n", "\n", "", "output_file", ".", "close", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.Analyzer.__init__": [[23, 32], ["analyze_utils.Analyzer._read_testproblems"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.Analyzer._read_testproblems"], ["def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Initializes a new Analyzer instance.\n\n        Args:\n            path (str): Path to the results folder. This folder should contain one\n                or multiple testproblem folders.\n        \"\"\"", "\n", "self", ".", "path", "=", "path", "\n", "self", ".", "testproblems", "=", "self", ".", "_read_testproblems", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.Analyzer._read_testproblems": [[33, 47], ["dict", "os.listdir", "os.path.isdir", "os.path.join", "analyze_utils.TestProblemAnalyzer"], "methods", ["None"], ["", "def", "_read_testproblems", "(", "self", ")", ":", "\n", "        ", "\"\"\"Read all test problems (folders) in this results folder.\n\n        Returns:\n            dict: Dictionary of test problems, where the key is the test\n            problem's name and the value is an instance of the\n            TestProblemAnalyzer class.\n\n        \"\"\"", "\n", "testproblems", "=", "dict", "(", ")", "\n", "for", "tp", "in", "os", ".", "listdir", "(", "self", ".", "path", ")", ":", "\n", "            ", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path", ",", "tp", ")", ")", ":", "\n", "                ", "testproblems", "[", "tp", "]", "=", "TestProblemAnalyzer", "(", "self", ".", "path", ",", "tp", ")", "\n", "", "", "return", "testproblems", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.TestProblemAnalyzer.__init__": [[72, 89], ["os.path.join", "print", "analyze_utils.TestProblemAnalyzer._get_conv_perf", "analyze_utils.TestProblemAnalyzer._read_optimizer"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.TestProblemAnalyzer._get_conv_perf", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.TestProblemAnalyzer._read_optimizer"], ["def", "__init__", "(", "self", ",", "path", ",", "tp", ")", ":", "\n", "        ", "\"\"\"Initializes a new TestProblemAnalyzer instance.\n\n        Args:\n            path (str): Path to the parent folder of the test problem (i.e. the\n                results folder).\n            tp (str): Name of the test problem (same as the folder name).\n        \"\"\"", "\n", "self", ".", "_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "tp", ")", "\n", "self", ".", "name", "=", "tp", "\n", "print", "(", "\"Setting up\"", ",", "self", ".", "name", ")", "\n", "self", ".", "conv_perf", "=", "self", ".", "_get_conv_perf", "(", ")", "\n", "if", "tp", "==", "'quadratic_deep'", "or", "tp", "==", "'mnist_vae'", "or", "tp", "==", "'fmnist_vae'", ":", "\n", "            ", "self", ".", "metric", "=", "\"test_losses\"", "\n", "", "else", ":", "\n", "            ", "self", ".", "metric", "=", "\"test_accuracies\"", "\n", "", "self", ".", "optimizers", "=", "self", ".", "_read_optimizer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.TestProblemAnalyzer._read_optimizer": [[90, 103], ["dict", "os.listdir", "analyze_utils.OptimizerAnalyzer"], "methods", ["None"], ["", "def", "_read_optimizer", "(", "self", ")", ":", "\n", "        ", "\"\"\"Read all optimizer (folders) in a test problem (folder).\n\n        Returns:\n            dict: Dictionary of optimizers, where the key is the optimizer's name\n                and the value is an instance of the OptimizerAnalyzer class.\n\n        \"\"\"", "\n", "optimizers", "=", "dict", "(", ")", "\n", "for", "opt", "in", "os", ".", "listdir", "(", "self", ".", "_path", ")", ":", "\n", "            ", "optimizers", "[", "opt", "]", "=", "OptimizerAnalyzer", "(", "self", ".", "_path", ",", "opt", ",", "self", ".", "metric", ",", "\n", "self", ".", "name", ",", "self", ".", "conv_perf", ")", "\n", "", "return", "optimizers", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.TestProblemAnalyzer._get_conv_perf": [[104, 119], ["open", "print", "os.path.join", "json.load", "tensorflow.config.get_baseline_dir"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.tensorflow.config.get_baseline_dir"], ["", "def", "_get_conv_perf", "(", "self", ")", ":", "\n", "        ", "\"\"\"Read the convergence performance for this test problem from a\n        dictionary in the baseline folder.\n\n        Returns:\n            float: Convergence performance for this test problem\n\n        \"\"\"", "\n", "try", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "tensorflow", ".", "config", ".", "get_baseline_dir", "(", ")", ",", "\n", "\"convergence_performance.json\"", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "return", "json", ".", "load", "(", "f", ")", "[", "self", ".", "name", "]", "\n", "", "", "except", "IOError", ":", "\n", "            ", "print", "(", "\"Warning: Could not find a convergence performance file.\"", ")", "\n", "return", "0.0", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.__init__": [[153, 177], ["os.path.join", "analyze_utils.OptimizerAnalyzer._read_settings", "len"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer._read_settings"], ["def", "__init__", "(", "self", ",", "path", ",", "opt", ",", "metric", ",", "testproblem", ",", "conv_perf", ")", ":", "\n", "        ", "\"\"\"Initializes a new OptimizerAnalyzer instance.\n\n        Args:\n            path (str): Path to the parent folder of the optimizer folder (i.e.\n                the test problem folder).\n            opt (str): Name of the optimizer (folder).\n            metric (str): Metric to use for this test problem. If available this\n                will be ``test_accuracies``, otherwise ``test_losses``.\n            testproblem (str): Name of the test problem this optimizer (folder)\n                belongs to.\n            conv_perf (float): Convergence performance of the test problem this\n                optimizer (folder) belongs to.\n\n        \"\"\"", "\n", "self", ".", "_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "opt", ")", "\n", "self", ".", "name", "=", "opt", "\n", "self", ".", "metric", "=", "metric", "\n", "self", ".", "testproblem", "=", "testproblem", "\n", "self", ".", "conv_perf", "=", "conv_perf", "\n", "self", ".", "settings", "=", "self", ".", "_read_settings", "(", ")", "\n", "self", ".", "num_settings", "=", "len", "(", "self", ".", "settings", ")", "\n", "self", ".", "_best_setting_final", "=", "None", "\n", "self", ".", "_best_setting_best", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer._read_settings": [[178, 191], ["dict", "os.listdir", "analyze_utils.SettingAnalyzer"], "methods", ["None"], ["", "def", "_read_settings", "(", "self", ")", ":", "\n", "        ", "\"\"\"Read all settings (folders) in a optimizer (folder).\n\n        Returns:\n            dict: Dictionary of settings, where the key is the setting's name\n                and the value is an instance of the SettingAnalyzer class.\n\n        \"\"\"", "\n", "settings", "=", "dict", "(", ")", "\n", "for", "sett", "in", "os", ".", "listdir", "(", "self", ".", "_path", ")", ":", "\n", "            ", "settings", "[", "sett", "]", "=", "SettingAnalyzer", "(", "self", ".", "_path", ",", "sett", ",", "self", ".", "metric", ",", "\n", "self", ".", "testproblem", ",", "self", ".", "conv_perf", ")", "\n", "", "return", "settings", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_final": [[192, 221], ["analyze_utils.OptimizerAnalyzer.settings.items", "better", "RuntimeError"], "methods", ["None"], ["", "def", "get_best_setting_final", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the setting for this optimizer that has the best final\n        performance using the metric (``test_losses`` or ``test_accuracies``)\n        defined for this test problem.\n\n        Returns:\n            SettingAnalyzer: Instance of the SettingAnalyzer class with the best\n            final performance\n\n        \"\"\"", "\n", "if", "self", ".", "_best_setting_final", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_best_setting_final", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "metric", "==", "'test_losses'", "or", "self", ".", "metric", "==", "'train_losses'", ":", "\n", "                ", "current_best", "=", "np", ".", "inf", "\n", "better", "=", "lambda", "x", ",", "y", ":", "x", "<", "y", "\n", "", "elif", "self", ".", "metric", "==", "'test_accuracies'", "or", "self", ".", "metric", "==", "'train_accuracies'", ":", "\n", "                ", "current_best", "=", "-", "np", ".", "inf", "\n", "better", "=", "lambda", "x", ",", "y", ":", "x", ">", "y", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Metric unknown\"", ")", "\n", "", "best_sett", "=", "None", "\n", "for", "_", ",", "sett", "in", "self", ".", "settings", ".", "items", "(", ")", ":", "\n", "                ", "val", "=", "sett", ".", "aggregate", ".", "final_value", "\n", "if", "better", "(", "val", ",", "current_best", ")", ":", "\n", "                    ", "current_best", "=", "val", "\n", "best_ind", "=", "sett", "\n", "", "", "self", ".", "_best_setting_final", "=", "best_ind", "\n", "return", "best_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_best": [[222, 253], ["analyze_utils.OptimizerAnalyzer.settings.items", "better", "RuntimeError"], "methods", ["None"], ["", "", "def", "get_best_setting_best", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the setting for this optimizer that has the best overall\n        performance using the metric (``test_losses`` or ``test_accuracies``)\n        defined for this test problem. In contrast to ``get_best_setting_final``\n        in not only looks at the final performance per setting, but the best\n        performance per setting.\n\n        Returns:\n            SettingAnalyzer: Instance of the SettingAnalyzer class with the best\n            overall performance\n\n        \"\"\"", "\n", "if", "self", ".", "_best_setting_best", "is", "not", "None", ":", "\n", "            ", "return", "self", ".", "_best_setting_best", "\n", "", "else", ":", "\n", "            ", "if", "self", ".", "metric", "==", "'test_losses'", "or", "self", ".", "metric", "==", "'train_losses'", ":", "\n", "                ", "current_best", "=", "np", ".", "inf", "\n", "better", "=", "lambda", "x", ",", "y", ":", "x", "<", "y", "\n", "", "elif", "self", ".", "metric", "==", "'test_accuracies'", "or", "self", ".", "metric", "==", "'train_accuracies'", ":", "\n", "                ", "current_best", "=", "-", "np", ".", "inf", "\n", "better", "=", "lambda", "x", ",", "y", ":", "x", ">", "y", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Metric unknown\"", ")", "\n", "", "best_sett", "=", "None", "\n", "for", "_", ",", "sett", "in", "self", ".", "settings", ".", "items", "(", ")", ":", "\n", "                ", "val", "=", "sett", ".", "aggregate", ".", "best_value", "\n", "if", "better", "(", "val", ",", "current_best", ")", ":", "\n", "                    ", "current_best", "=", "val", "\n", "best_ind", "=", "sett", "\n", "", "", "self", ".", "_best_setting_best", "=", "best_ind", "\n", "return", "best_ind", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_setting_most_runs": [[254, 269], ["analyze_utils.OptimizerAnalyzer.settings.items"], "methods", ["None"], ["", "", "def", "get_setting_most_runs", "(", "self", ")", ":", "\n", "        ", "\"\"\"Returns the setting with the most repeated runs (with the same\n        setting, but probably different seeds).\n\n        Returns:\n            SettingAnalyzer: Instance of the SettingAnalyzer class with the most\n            repeated runs.\n\n        \"\"\"", "\n", "most_runs", "=", "0", "\n", "for", "_", ",", "sett", "in", "self", ".", "settings", ".", "items", "(", ")", ":", "\n", "            ", "if", "sett", ".", "aggregate", ".", "num_runs", ">", "most_runs", ":", "\n", "                ", "most_runs", "=", "sett", ".", "aggregate", ".", "num_runs", "\n", "most_run_setting", "=", "sett", "\n", "", "", "return", "most_run_setting", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.plot_lr_sensitivity": [[270, 309], ["analyze_utils.OptimizerAnalyzer.settings.items", "numpy.nan_to_num", "numpy.array().transpose", "ax.plot", "ax.set_xscale", "ax.set_ylim", "lr.append", "numpy.array().transpose.append", "numpy.array", "rel_perf[].argsort", "RuntimeError", "numpy.array().transpose.append", "RuntimeError", "numpy.vstack", "analyze_utils.OptimizerAnalyzer.get_best_setting_final", "analyze_utils.OptimizerAnalyzer.get_best_setting_best"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_final", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_best"], ["", "def", "plot_lr_sensitivity", "(", "self", ",", "ax", ",", "mode", "=", "'final'", ")", ":", "\n", "        ", "\"\"\"Generates the ``learning rate`` sensitivity plot for this optimizer.\n        This plots the relative performance (relative to the best setting for\n        this optimizer) against the ``learning rate`` used in this setting.\n\n        This assumes that all settings or otherwise equal and only different in\n        the ``learning rate``.\n\n        Args:\n            ax (matplotlib.axes): Handle to a matplotlib axis to plot the\n                ``learning rate`` sensitivity onto.\n            mode (str): Whether to use the final (``final``) performance or the\n                best (``best``) when evaluating each setting.\n                Defaults to ``final``.\n        \"\"\"", "\n", "rel_perf", "=", "[", "]", "\n", "lr", "=", "[", "]", "\n", "for", "_", ",", "sett", "in", "self", ".", "settings", ".", "items", "(", ")", ":", "\n", "            ", "if", "mode", "==", "'final'", ":", "\n", "                ", "val", "=", "sett", ".", "aggregate", ".", "final_value", "\n", "best", "=", "self", ".", "get_best_setting_final", "(", ")", ".", "aggregate", ".", "final_value", "\n", "", "elif", "mode", "==", "'best'", ":", "\n", "                ", "val", "=", "sett", ".", "aggregate", ".", "best_value", "\n", "best", "=", "self", ".", "get_best_setting_best", "(", ")", ".", "aggregate", ".", "best_value", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Mode unknown\"", ")", "\n", "", "if", "self", ".", "metric", "==", "'test_losses'", "or", "self", ".", "metric", "==", "'train_losses'", ":", "\n", "                ", "rel_perf", ".", "append", "(", "best", "/", "val", ")", "\n", "", "elif", "self", ".", "metric", "==", "'test_accuracies'", "or", "self", ".", "metric", "==", "'train_accuracies'", ":", "\n", "                ", "rel_perf", ".", "append", "(", "val", "/", "best", ")", "\n", "", "else", ":", "\n", "                ", "raise", "RuntimeError", "(", "\"Metric unknown\"", ")", "\n", "", "lr", ".", "append", "(", "sett", ".", "aggregate", ".", "output", "[", "'learning_rate'", "]", ")", "\n", "", "rel_perf", "=", "np", ".", "nan_to_num", "(", "rel_perf", ")", "# replace NaN with zero", "\n", "rel_perf", "=", "np", ".", "array", "(", "np", ".", "vstack", "(", "(", "rel_perf", ",", "lr", ")", ")", ")", ".", "transpose", "(", ")", "\n", "rel_perf", "=", "rel_perf", "[", "rel_perf", "[", ":", ",", "1", "]", ".", "argsort", "(", ")", "]", "\n", "ax", ".", "plot", "(", "rel_perf", "[", ":", ",", "1", "]", ",", "rel_perf", "[", ":", ",", "0", "]", ",", "label", "=", "self", ".", "name", ")", "\n", "ax", ".", "set_xscale", "(", "'log'", ")", "\n", "ax", ".", "set_ylim", "(", "[", "0.0", ",", "1.0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.plot_performance": [[310, 356], ["enumerate", "analyze_utils.OptimizerAnalyzer.get_best_setting_final", "ax[].plot", "ax[].fill_between", "analyze_utils.OptimizerAnalyzer.get_best_setting_best", "range", "analyze_utils.OptimizerAnalyzer.get_setting_most_runs", "print", "RuntimeError", "[].get_color", "ax[].get_lines"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_final", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_best", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_setting_most_runs"], ["", "def", "plot_performance", "(", "self", ",", "ax", ",", "mode", "=", "'most'", ")", ":", "\n", "        ", "\"\"\"Generates a performance plot for this optimzer using one\n        hyperparameter setting.\n\n        Can either use the setting with the best final performance, the best\n        overall performance or the setting with the most runs.\n\n        This function will plot all four possible performance metrics\n        (``test_losses``, ``train_losses``, ``test_accuracies`` and\n        ``train_accuracies``).\n\n\n        Args:\n            ax (list): List of four matplotlib axis to plot the performancs\n                metrics onto.\n            mode (str): Whether to use the setting with the best final\n                (``final``) performance, the best overall (``best``) performance\n                or the setting with the most runs (``most``) when plotting.\n                Defaults to ``most``.\n\n        \"\"\"", "\n", "if", "mode", "==", "'final'", ":", "\n", "            ", "run", "=", "self", ".", "get_best_setting_final", "(", ")", "\n", "", "elif", "mode", "==", "'best'", ":", "\n", "            ", "run", "=", "self", ".", "get_best_setting_best", "(", ")", "\n", "", "elif", "mode", "==", "'most'", ":", "\n", "            ", "run", "=", "self", ".", "get_setting_most_runs", "(", ")", "\n", "print", "(", "\"Plotting\"", ",", "run", ".", "aggregate", ".", "num_runs", ",", "\"runs for \"", ",", "self", ".", "name", ",", "\n", "\"on\"", ",", "run", ".", "aggregate", ".", "output", "[", "'testproblem'", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Mode unknown\"", ")", "\n", "", "for", "idx", ",", "metric", "in", "enumerate", "(", "[", "\n", "'test_losses'", ",", "'train_losses'", ",", "'test_accuracies'", ",", "\n", "'train_accuracies'", "\n", "]", ")", ":", "\n", "            ", "ax", "[", "idx", "]", ".", "plot", "(", "\n", "run", ".", "aggregate", ".", "output", "[", "metric", "]", "[", "'mean'", "]", ",", "\n", "label", "=", "run", ".", "aggregate", ".", "output", "[", "'optimizer'", "]", ")", "\n", "ax", "[", "idx", "]", ".", "fill_between", "(", "\n", "range", "(", "run", ".", "aggregate", ".", "output", "[", "metric", "]", "[", "'mean'", "]", ".", "size", ")", ",", "\n", "run", ".", "aggregate", ".", "output", "[", "metric", "]", "[", "'mean'", "]", "-", "\n", "run", ".", "aggregate", ".", "output", "[", "metric", "]", "[", "'std'", "]", ",", "\n", "run", ".", "aggregate", ".", "output", "[", "metric", "]", "[", "'mean'", "]", "+", "\n", "run", ".", "aggregate", ".", "output", "[", "metric", "]", "[", "'std'", "]", ",", "\n", "color", "=", "ax", "[", "idx", "]", ".", "get_lines", "(", ")", "[", "-", "1", "]", ".", "get_color", "(", ")", ",", "\n", "alpha", "=", "0.2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_bm_table": [[357, 392], ["analyze_utils.OptimizerAnalyzer.get_best_setting_final", "analyze_utils.OptimizerAnalyzer.get_best_setting_best", "analyze_utils.OptimizerAnalyzer.get_setting_most_runs"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_final", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_best", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_setting_most_runs"], ["", "", "def", "get_bm_table", "(", "self", ",", "perf_table", ",", "mode", "=", "'most'", ")", ":", "\n", "        ", "\"\"\"Generates the overall performance table for this optimizer.\n\n        This includes metrics for the performance, speed and tuneability of this\n        optimizer (on this test problem).\n\n        Args:\n            perf_table (dict): A dictionary with three keys: ``Performance``,\n                ``Speed`` and ``Tuneability``.\n            mode (str): Whether to use the setting with the best final\n                (``final``) performance, the best overall (``best``) performance\n                or the setting with the most runs (``most``).\n                Defaults to ``most``.\n\n        Returns:\n            dict: Dictionary with holding the performance, speed and tuneability\n            measure for this optimizer.\n\n        \"\"\"", "\n", "if", "mode", "==", "'final'", ":", "\n", "            ", "run", "=", "self", ".", "get_best_setting_final", "(", ")", "\n", "", "elif", "mode", "==", "'best'", ":", "\n", "            ", "run", "=", "self", ".", "get_best_setting_best", "(", ")", "\n", "", "elif", "mode", "==", "'most'", ":", "\n", "            ", "run", "=", "self", ".", "get_setting_most_runs", "(", ")", "\n", "", "perf_table", "[", "'Performance'", "]", "[", "self", ".", "name", "]", "=", "run", ".", "aggregate", ".", "output", "[", "\n", "self", ".", "metric", "]", "[", "'mean'", "]", "[", "-", "1", "]", "\n", "perf_table", "[", "'Speed'", "]", "[", "self", ".", "name", "]", "=", "run", ".", "aggregate", ".", "output", "[", "'speed'", "]", "\n", "perf_table", "[", "'Tuneability'", "]", "[", "self", ".", "name", "]", "=", "{", "\n", "**", "{", "\n", "'lr'", ":", "'{:0.2e}'", ".", "format", "(", "run", ".", "aggregate", ".", "output", "[", "'learning_rate'", "]", ")", "\n", "}", ",", "\n", "**", "run", ".", "aggregate", ".", "output", "[", "'hyperparams'", "]", "\n", "}", "\n", "return", "perf_table", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.SettingAnalyzer.__init__": [[418, 438], ["os.path.join", "analyze_utils.SettingAnalyzer._get_aggregate"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.SettingAnalyzer._get_aggregate"], ["def", "__init__", "(", "self", ",", "path", ",", "sett", ",", "metric", ",", "testproblem", ",", "conv_perf", ")", ":", "\n", "        ", "\"\"\"Initializes a new SettingAnalyzer instance.\n\n        Args:\n            name (str): Path to the parent folder of the setting folder (i.e. the\n                optimizer folder).\n            sett (str): Name of the setting (folder).\n            metric (str): Metric to use for this test problem. If available this\n                will be ``test_accuracies``, otherwise ``test_losses``.\n            testproblem (str): Name of the test problem this setting (folder)\n                belongs to.\n            conv_perf (float): Convergence performance of the test problem this\n                setting (folder) belongs to.\n        \"\"\"", "\n", "self", ".", "_path", "=", "os", ".", "path", ".", "join", "(", "path", ",", "sett", ")", "\n", "self", ".", "name", "=", "sett", "\n", "self", ".", "metric", "=", "metric", "\n", "self", ".", "testproblem", "=", "testproblem", "\n", "self", ".", "conv_perf", "=", "conv_perf", "\n", "self", ".", "aggregate", "=", "self", ".", "_get_aggregate", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.SettingAnalyzer._get_aggregate": [[439, 453], ["os.listdir", "analyze_utils.AggregateRun", "r.endswith", "runs.append"], "methods", ["None"], ["", "def", "_get_aggregate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Create aggregate run for all runs in this setting folder.\n\n        Returns:\n            AggregateRun: Instance of the AggregateRun class holding the\n            aggregate information of all runs with these settings.\n\n        \"\"\"", "\n", "runs", "=", "[", "]", "\n", "for", "r", "in", "os", ".", "listdir", "(", "self", ".", "_path", ")", ":", "\n", "            ", "if", "r", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "                ", "runs", ".", "append", "(", "r", ")", "\n", "", "", "return", "AggregateRun", "(", "self", ".", "_path", ",", "runs", ",", "self", ".", "name", ",", "self", ".", "metric", ",", "\n", "self", ".", "testproblem", ",", "self", ".", "conv_perf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun.__init__": [[487, 512], ["len", "analyze_utils.AggregateRun._aggregate", "analyze_utils.AggregateRun._get_final_value", "analyze_utils.AggregateRun._get_best_value"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._aggregate", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._get_final_value", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._get_best_value"], ["def", "__init__", "(", "self", ",", "path", ",", "runs", ",", "name", ",", "metric", ",", "testproblem", ",", "conv_perf", ")", ":", "\n", "        ", "\"\"\"Initializes a new AggregateRun class.\n\n        Args:\n            path (str): Path to the parent folder of the aggregate run folder (i.e.\n                the settings folder).\n            runs (list): List of run names all with the same setting.\n            name (str): Name of the aggregate run (folder).\n            metric (str): Metric to use for this test problem. If available this\n                will be ``test_accuracies``, otherwise ``test_losses``.\n            testproblem (str): Name of the test problem this aggregate run (folder)\n                belongs to.\n            conv_perf (float): Convergence performance of the test problem this\n                aggregate run (folder) belongs to.\n        \"\"\"", "\n", "self", ".", "_path", "=", "path", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "testproblem", "=", "testproblem", "\n", "self", ".", "conv_perf", "=", "conv_perf", "\n", "self", ".", "runs", "=", "runs", "\n", "self", ".", "num_runs", "=", "len", "(", "runs", ")", "\n", "self", ".", "metric", "=", "metric", "\n", "self", ".", "output", "=", "self", ".", "_aggregate", "(", ")", "\n", "self", ".", "final_value", "=", "self", ".", "_get_final_value", "(", ")", "\n", "self", ".", "best_value", "=", "self", ".", "_get_best_value", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._aggregate": [[513, 566], ["dict", "numpy.array", "dict.pop", "analyze_utils.AggregateRun._load_json", "train_losses.append", "test_losses.append", "eval", "numpy.mean", "os.path.join", "train_accuracies.append", "test_accuracies.append", "numpy.mean", "numpy.mean", "numpy.std", "numpy.argmax", "eval", "eval", "numpy.invert", "numpy.argmax", "numpy.max", "numpy.invert", "numpy.max"], "methods", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._load_json"], ["", "def", "_aggregate", "(", "self", ")", ":", "\n", "        ", "\"\"\"Aggregate performance data over all runs.\n\n        Returns:\n            dict: Dictionary including all aggregate information of the\n            runs with this setting. All performance metrics have a mean and a\n            standard deviation (can be zero if there is only one run with this\n            setting).\n\n        \"\"\"", "\n", "train_losses", "=", "[", "]", "\n", "train_accuracies", "=", "[", "]", "\n", "test_losses", "=", "[", "]", "\n", "test_accuracies", "=", "[", "]", "\n", "meta_loaded", "=", "False", "\n", "for", "run", "in", "self", ".", "runs", ":", "\n", "            ", "output", "=", "self", ".", "_load_json", "(", "os", ".", "path", ".", "join", "(", "self", ".", "_path", ",", "run", ")", ")", "\n", "# Get meta data from first run", "\n", "if", "not", "meta_loaded", ":", "\n", "                ", "meta", "=", "output", "\n", "meta_loaded", "=", "True", "\n", "", "train_losses", ".", "append", "(", "output", "[", "'train_losses'", "]", ")", "\n", "test_losses", ".", "append", "(", "output", "[", "'test_losses'", "]", ")", "\n", "if", "'train_accuracies'", "in", "output", ":", "\n", "                ", "train_accuracies", ".", "append", "(", "output", "[", "'train_accuracies'", "]", ")", "\n", "test_accuracies", ".", "append", "(", "output", "[", "'test_accuracies'", "]", ")", "\n", "", "", "aggregate", "=", "dict", "(", ")", "\n", "# compute speed", "\n", "perf", "=", "np", ".", "array", "(", "eval", "(", "self", ".", "metric", ")", ")", "\n", "if", "self", ".", "metric", "==", "\"test_losses\"", "or", "self", ".", "metric", "==", "\"train_losses\"", ":", "\n", "# average over first time they reach conv perf (use num_epochs if conv perf is not reached)", "\n", "            ", "aggregate", "[", "'speed'", "]", "=", "np", ".", "mean", "(", "\n", "np", ".", "argmax", "(", "perf", "<=", "self", ".", "conv_perf", ",", "axis", "=", "1", ")", "+", "\n", "np", ".", "invert", "(", "np", ".", "max", "(", "perf", "<=", "self", ".", "conv_perf", ",", "axis", "=", "1", ")", ")", "*", "\n", "perf", ".", "shape", "[", "1", "]", ")", "\n", "", "elif", "self", ".", "metric", "==", "\"test_accuracies\"", "or", "self", ".", "metric", "==", "\"train_accuracies\"", ":", "\n", "            ", "aggregate", "[", "'speed'", "]", "=", "np", ".", "mean", "(", "\n", "np", ".", "argmax", "(", "perf", ">=", "self", ".", "conv_perf", ",", "axis", "=", "1", ")", "+", "\n", "np", ".", "invert", "(", "np", ".", "max", "(", "perf", ">=", "self", ".", "conv_perf", ",", "axis", "=", "1", ")", ")", "*", "\n", "perf", ".", "shape", "[", "1", "]", ")", "\n", "# build dict", "\n", "", "for", "m", "in", "[", "\n", "'train_losses'", ",", "'test_losses'", ",", "'train_accuracies'", ",", "\n", "'test_accuracies'", "\n", "]", ":", "\n", "            ", "aggregate", "[", "m", "]", "=", "{", "\n", "'mean'", ":", "np", ".", "mean", "(", "eval", "(", "m", ")", ",", "axis", "=", "0", ")", ",", "\n", "'std'", ":", "np", ".", "std", "(", "eval", "(", "m", ")", ",", "axis", "=", "0", ")", "\n", "}", "\n", "# merge meta and aggregate (aggregate replaces)", "\n", "", "aggregate", "=", "{", "**", "meta", ",", "**", "aggregate", "}", "\n", "aggregate", ".", "pop", "(", "'minibatch_train_losses'", ",", "None", ")", "\n", "return", "aggregate", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._load_json": [[567, 579], ["open", "json.load"], "methods", ["None"], ["", "def", "_load_json", "(", "self", ",", "path", ")", ":", "\n", "        ", "\"\"\"Load the ``JSON`` file of the given path.\n\n        Args:\n            path (str): Path to a ``JSON`` file.\n\n        Returns:\n            dict: Dictionary from the ``JSON`` file.\n\n        \"\"\"", "\n", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "return", "json", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._get_final_value": [[580, 588], ["None"], "methods", ["None"], ["", "", "def", "_get_final_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get final (mean) value of the metric used in this test problem.\n\n        Returns:\n            float: Final (mean) value of the test problem's metric.\n\n        \"\"\"", "\n", "return", "self", ".", "output", "[", "self", ".", "metric", "]", "[", "'mean'", "]", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.AggregateRun._get_best_value": [[589, 602], ["min", "max", "RuntimeError"], "methods", ["None"], ["", "def", "_get_best_value", "(", "self", ")", ":", "\n", "        ", "\"\"\"Get best (mean) value of the metric used in this test problem.\n\n        Returns:\n            float: Best (mean) value of the test problem's metric.\n\n        \"\"\"", "\n", "if", "self", ".", "metric", "==", "'test_losses'", "or", "self", ".", "metric", "==", "'train_losses'", ":", "\n", "            ", "return", "min", "(", "self", ".", "output", "[", "self", ".", "metric", "]", "[", "'mean'", "]", ")", "\n", "", "elif", "self", ".", "metric", "==", "'test_accuracies'", "or", "self", ".", "metric", "==", "'train_accuracies'", ":", "\n", "            ", "return", "max", "(", "self", ".", "output", "[", "self", ".", "metric", "]", "[", "'mean'", "]", ")", "\n", "", "else", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Metric unknown\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_lr_sensitivity": [[604, 636], ["fig.suptitle", "range", "range", "[].get_yaxis().set_visible", "[].spines[].set_visible", "[].spines[].set_visible", "[].spines[].set_visible", "[].get_xaxis().set_visible", "[].set_xlabel", "[].get_yaxis", "[].get_xaxis"], "function", ["None"], ["", "", "", "def", "beautify_lr_sensitivity", "(", "fig", ",", "ax", ")", ":", "\n", "    ", "\"\"\"Beautify a learning rate sensitivity plot.\n\n    This function adds axis labels and removes spines to create a nicer learning\n    rate sensitivity plot.\n\n    Args:\n        fig (matplotlib.figure): Handle to the matplotlib figure of the learning\n            rate sensitivity plot.\n        ax (list): List of lists of matplotlib axis of the learning rate\n            sensitivity plots.\n\n    Returns:\n        matplotlib.figure: Handle to the beautified matplotlib figure of the\n        learning rate sensitivity plot.\n        list: List of lists of the beautified matplotlib axis of the learning\n        rate sensitivity plots.\n\n    \"\"\"", "\n", "fig", ".", "suptitle", "(", "\"Learning rate sensitivity\"", ",", "fontsize", "=", "20", ")", "\n", "for", "i", "in", "range", "(", "ax", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "ax", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "ax", "[", "i", "]", "[", "j", "]", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "ax", "[", "i", "]", "[", "j", "]", ".", "spines", "[", "'top'", "]", ".", "set_visible", "(", "False", ")", "\n", "ax", "[", "i", "]", "[", "j", "]", ".", "spines", "[", "'right'", "]", ".", "set_visible", "(", "False", ")", "\n", "#     ax[i][j].spines['bottom'].set_visible(False)", "\n", "ax", "[", "i", "]", "[", "j", "]", ".", "spines", "[", "'left'", "]", ".", "set_visible", "(", "False", ")", "\n", "if", "i", "==", "0", ":", "\n", "                ", "ax", "[", "i", "]", "[", "j", "]", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "", "if", "i", "==", "1", ":", "\n", "                ", "ax", "[", "i", "]", "[", "j", "]", ".", "set_xlabel", "(", "'Learning Rate'", ")", "\n", "", "", "", "return", "fig", ",", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_lr_sensitivity": [[638, 685], ["matplotlib2tikz.get_tikz_code", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "open", "file.write"], "function", ["None"], ["", "def", "texify_lr_sensitivity", "(", "fig", ",", "ax", ")", ":", "\n", "    ", "\"\"\"Write a ``.tex`` file with the learning rate sensitivity plot.\n\n    The function will create a file named `tuning_plot.tex` with the latex code\n    for the learning rate sensitivity plot.\n\n    Args:\n        fig (matplotlib.figure): Handle to the matplotlib figure of the learning\n            rate sensitivity plot.\n        ax (list): List of lists of matplotlib axis of the learning rate\n            sensitivity plots.\n\n    Returns:\n        str: String of the latex code for the learning rate sensitivity plot.\n\n    \"\"\"", "\n", "tikz_code", "=", "get_tikz_code", "(", "\n", "'tuning_plot_new.tex'", ",", "\n", "figureheight", "=", "'\\\\figureheight'", ",", "\n", "figurewidth", "=", "'0.33\\\\figurewidth'", ")", "\n", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'\\\\begin{groupplot}[group style={group size=4 by 2}]'", ",", "\n", "'\\\\begin{groupplot}[group style={group size=4 by 2, horizontal sep=0.02\\\\figurewidth, vertical sep=0.15cm}]'", "\n", ")", "\n", "tikz_code", "=", "r\"\\pgfplotsset{every axis/.append style={label style={font=\\tiny}, tick label style={font=\\tiny}, legend style={font=\\tiny, line width=1pt}}}\"", "+", "tikz_code", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'minor'", ",", "'%minor'", ")", "# comment minor tick", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'x grid'", ",", "\n", "'%x grid'", ")", "# remove grid xmajorticks=false,", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'y grid'", ",", "'%y grid'", ")", "# remove grid", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'tick align'", ",", "\n", "'%tick align'", ")", "# ugly outside ticks", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'nextgroupplot['", ",", "'nextgroupplot[axis x line*=bottom,\\nhide y axis,'", "\n", ")", "# ugly outside ticks", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'(current bounding box.south west)!0.98!(current bounding box.north west)'", ",", "\n", "'(current bounding box.south west)!1.05!(current bounding box.north west)'", "\n", ")", "# position title higher", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'title={'", ",", "\n", "'title={\\small '", ")", "# shrink title size", "\n", "\n", "# Write the file out again", "\n", "with", "open", "(", "'tuning_plot.tex'", ",", "'w'", ")", "as", "file", ":", "\n", "        ", "file", ".", "write", "(", "tikz_code", ")", "\n", "\n", "", "return", "tikz_code", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.rescale_ax": [[687, 713], ["y_limits.append", "y_limits.append", "ax.margins", "ax.set_ylim", "line.get_label", "y_data.append", "y_limits.append", "numpy.percentile", "numpy.percentile", "[].tolist", "numpy.min", "numpy.max", "ax.set_ylim", "line.get_ydata", "numpy.array", "numpy.array", "line.get_ydata", "max", "numpy.array"], "function", ["None"], ["", "def", "rescale_ax", "(", "ax", ")", ":", "\n", "    ", "\"\"\"Rescale an axis to include the most important data.\n\n    Args:\n        ax (matplotlib.axis): Handle to a matplotlib axis.\n\n    \"\"\"", "\n", "lines", "=", "ax", ".", "lines", "\n", "y_data", "=", "[", "]", "\n", "y_limits", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "if", "line", ".", "get_label", "(", ")", "!=", "\"convergence_performance\"", ":", "\n", "            ", "y_data", ".", "append", "(", "line", ".", "get_ydata", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "y_limits", ".", "append", "(", "line", ".", "get_ydata", "(", ")", "[", "0", "]", ")", "\n", "", "", "if", "y_data", ":", "\n", "        ", "y_limits", ".", "append", "(", "np", ".", "percentile", "(", "np", ".", "array", "(", "y_data", ")", ",", "20", ")", ")", "\n", "y_limits", ".", "append", "(", "np", ".", "percentile", "(", "np", ".", "array", "(", "y_data", ")", ",", "80", ")", ")", "\n", "y_limits", "=", "y_limits", "+", "(", "np", ".", "array", "(", "y_data", ")", "[", ":", ",", "-", "1", "]", ".", "tolist", "(", ")", ")", "\n", "y_limits", "=", "[", "np", ".", "min", "(", "y_limits", ")", ",", "np", ".", "max", "(", "y_limits", ")", "]", "\n", "y_limits", "=", "[", "y_limits", "[", "0", "]", "*", "0.9", ",", "y_limits", "[", "1", "]", "*", "1.1", "]", "\n", "if", "y_limits", "[", "0", "]", "!=", "y_limits", "[", "1", "]", ":", "\n", "            ", "ax", ".", "set_ylim", "(", "[", "max", "(", "1e-10", ",", "y_limits", "[", "0", "]", ")", ",", "y_limits", "[", "1", "]", "]", ")", "\n", "", "ax", ".", "margins", "(", "x", "=", "0", ")", "\n", "", "else", ":", "\n", "        ", "ax", ".", "set_ylim", "(", "[", "1.0", ",", "2.0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_plot_performance": [[715, 824], ["fig.subplots_adjust", "matplotlib.sca", "matplotlib.cla", "matplotlib.sca", "matplotlib.cla", "[].axis", "[].axis", "[].set_xlabel", "[].set_xlabel", "[].set_ylabel", "[].set_ylabel", "[].tick_params", "[].get_legend_handles_labels", "[].legend", "enumerate", "fig.suptitle", "matplotlib.sca", "matplotlib.cla", "matplotlib.sca", "matplotlib.cla", "matplotlib.sca", "matplotlib.cla", "[].axis", "[].axis", "[].set_xlabel", "[].set_xlabel", "[].set_ylabel", "[].set_ylabel", "[].tick_params", "enumerate", "ax[].set_title", "fig.suptitle", "[].set_xlabel", "[].set_xlabel", "[].set_ylabel", "[].set_ylabel", "enumerate", "analyze_utils.rescale_ax", "[].axhline", "[].axhline"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.rescale_ax"], ["", "", "def", "beautify_plot_performance", "(", "fig", ",", "ax", ",", "folder_parser", ",", "problem_set", ")", ":", "\n", "    ", "\"\"\"Beautify a performance plot.\n\n    This function adds axis labels, sets titles and more to create a nicer\n    performance plot.\n\n    Args:\n        fig (matplotlib.figure): Handle to the matplotlib figure of the\n            performance plot.\n        ax (list): List of lists of matplotlib axis of the performance plot.\n        folder_parser (Analyzer): An instance of the DeepOBS Analyzer class\n            to plot the performance from.\n        problem_set (str): Can either be ``small`` or ``large`` to switch\n            between which benchmark set is being plotted.\n\n    Returns:\n        matplotlib.figure: Handle to the beautified matplotlib figure of the\n        performance plot.\n        list: List of lists of the beautified matplotlib axis of the performance\n        plots.\n\n    \"\"\"", "\n", "fig", ".", "subplots_adjust", "(", "hspace", "=", "0.4", ")", "\n", "if", "problem_set", "==", "\"small\"", ":", "\n", "        ", "fig", ".", "suptitle", "(", "\"Benchmark Set Small\"", ",", "fontsize", "=", "20", ")", "\n", "titles", "=", "[", "\n", "\"P1 Quadratic Deep\"", ",", "\"P2 MNIST - VAE\"", ",", "\"P3 F-MNIST - CNN\"", ",", "\n", "\"P4 CIFAR-10 - CNN\"", "\n", "]", "\n", "# clear axis (needed for matplotlib2tikz)", "\n", "plt", ".", "sca", "(", "ax", "[", "2", "]", "[", "0", "]", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "plt", ".", "sca", "(", "ax", "[", "2", "]", "[", "1", "]", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "plt", ".", "sca", "(", "ax", "[", "3", "]", "[", "1", "]", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "axis", "(", "'off'", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "axis", "(", "'off'", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlabel", "(", "\"Epochs\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "set_xlabel", "(", "\"Epochs\"", ")", "\n", "ax", "[", "2", "]", "[", "2", "]", ".", "set_ylabel", "(", "\"Test Accuracy\"", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_ylabel", "(", "\"Train Accuracy\"", ")", "\n", "ax", "[", "1", "]", "[", "1", "]", ".", "tick_params", "(", "\n", "axis", "=", "'x'", ",", "which", "=", "'major'", ",", "bottom", "=", "False", ",", "\n", "labelbottom", "=", "True", ")", "# show x axis", "\n", "# Add convergence performance line", "\n", "for", "idx", ",", "tp", "in", "enumerate", "(", "\n", "[", "\"quadratic_deep\"", ",", "\"mnist_vae\"", ",", "\"fmnist_2c2d\"", ",", "\"cifar10_3c3d\"", "]", ")", ":", "\n", "            ", "if", "tp", "in", "folder_parser", ".", "testproblems", ":", "\n", "                ", "metric", "=", "folder_parser", ".", "testproblems", "[", "tp", "]", ".", "metric", "\n", "conv_perf", "=", "folder_parser", ".", "testproblems", "[", "tp", "]", ".", "conv_perf", "\n", "if", "metric", "==", "\"test_losses\"", ":", "\n", "                    ", "ax_row", "=", "0", "\n", "", "elif", "metric", "==", "\"test_accuracies\"", ":", "\n", "                    ", "ax_row", "=", "2", "\n", "", "ax", "[", "ax_row", "]", "[", "idx", "]", ".", "axhline", "(", "\n", "conv_perf", ",", "color", "=", "'#AFB3B7'", ",", "label", "=", "\"convergence_performance\"", ")", "\n", "", "", "", "elif", "problem_set", "==", "\"large\"", ":", "\n", "        ", "fig", ".", "suptitle", "(", "\"Benchmark Set Large\"", ",", "fontsize", "=", "20", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_xlabel", "(", "\"Epochs\"", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_xlabel", "(", "\"Epochs\"", ")", "\n", "ax", "[", "2", "]", "[", "1", "]", ".", "set_ylabel", "(", "\"Test Accuracy\"", ")", "\n", "ax", "[", "3", "]", "[", "1", "]", ".", "set_ylabel", "(", "\"Train Accuracy\"", ")", "\n", "titles", "=", "[", "\n", "\"P5 F-MNIST - VAE\"", ",", "\"P6 CIFAR 100 - All CNN C\"", ",", "\n", "\"P7 SVHN - Wide ResNet 16-4\"", ",", "\"P8 Tolstoi - Char RNN\"", "\n", "]", "\n", "# Add convergence performance line", "\n", "for", "idx", ",", "tp", "in", "enumerate", "(", "[", "\n", "\"fmnist_vae\"", ",", "\"cifar100_allcnnc\"", ",", "\"svhn_wrn164\"", ",", "\n", "\"tolstoi_char_rnn\"", "\n", "]", ")", ":", "\n", "            ", "if", "tp", "in", "folder_parser", ".", "testproblems", ":", "\n", "                ", "metric", "=", "folder_parser", ".", "testproblems", "[", "tp", "]", ".", "metric", "\n", "conv_perf", "=", "folder_parser", ".", "testproblems", "[", "tp", "]", ".", "conv_perf", "\n", "if", "metric", "==", "\"test_losses\"", ":", "\n", "                    ", "ax_row", "=", "0", "\n", "", "elif", "metric", "==", "\"test_accuracies\"", ":", "\n", "                    ", "ax_row", "=", "2", "\n", "", "ax", "[", "ax_row", "]", "[", "idx", "]", ".", "axhline", "(", "\n", "conv_perf", ",", "color", "=", "'#AFB3B7'", ",", "label", "=", "\"convergence_performance\"", ")", "\n", "# clear axis (needed for matplotlib2tikz)", "\n", "", "", "", "plt", ".", "sca", "(", "ax", "[", "2", "]", "[", "0", "]", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "plt", ".", "sca", "(", "ax", "[", "3", "]", "[", "0", "]", ")", "\n", "plt", ".", "cla", "(", ")", "\n", "ax", "[", "2", "]", "[", "0", "]", ".", "axis", "(", "'off'", ")", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "axis", "(", "'off'", ")", "\n", "ax", "[", "3", "]", "[", "2", "]", ".", "set_xlabel", "(", "\"Epochs\"", ")", "\n", "ax", "[", "3", "]", "[", "3", "]", ".", "set_xlabel", "(", "\"Epochs\"", ")", "\n", "ax", "[", "0", "]", "[", "0", "]", ".", "set_ylabel", "(", "\"Test Loss\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "set_ylabel", "(", "\"Train Loss\"", ")", "\n", "ax", "[", "1", "]", "[", "0", "]", ".", "tick_params", "(", "\n", "axis", "=", "'x'", ",", "which", "=", "'major'", ",", "bottom", "=", "False", ",", "labelbottom", "=", "True", ")", "# show x axis", "\n", "# automatic rescaling", "\n", "for", "axlist", "in", "ax", ":", "\n", "        ", "for", "a", "in", "axlist", ":", "\n", "            ", "a", "=", "rescale_ax", "(", "a", ")", "\n", "# Legend", "\n", "", "", "handles", ",", "labels", "=", "ax", "[", "0", "]", "[", "3", "]", ".", "get_legend_handles_labels", "(", ")", "\n", "#     labels_tex = [tfobs.plot_utils.texify(l) for l in labels]", "\n", "ax", "[", "3", "]", "[", "0", "]", ".", "legend", "(", "\n", "handles", ",", "\n", "labels", ",", "\n", "loc", "=", "'upper right'", ",", "\n", "bbox_to_anchor", "=", "(", "0.2", ",", "1.1", ",", "0.5", ",", "0.5", ")", ")", "\n", "for", "idx", ",", "title", "in", "enumerate", "(", "titles", ")", ":", "\n", "        ", "ax", "[", "0", ",", "idx", "]", ".", "set_title", "(", "title", ")", "\n", "", "return", "fig", ",", "ax", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_plot_performance": [[826, 898], ["matplotlib2tikz.get_tikz_code", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "tikz_code.replace.replace", "open", "file.write", "str"], "function", ["None"], ["", "def", "texify_plot_performance", "(", "fig", ",", "ax", ",", "problem_set", ")", ":", "\n", "    ", "\"\"\"Write a ``.tex`` file with the performance plot.\n\n    The function will create a file named `benchmark_small.tex` or\n    `benchmark_large.tex` with the latex code for the performance plot.\n\n    Args:\n        fig (matplotlib.figure): Handle to the matplotlib figure of the\n            performance plot.\n        ax (list): List of lists of matplotlib axis of the performance plot.\n        problem_set (str): Can either be ``small`` or ``large`` to switch\n            between which benchmark set is being plotted.\n\n    Returns:\n        str: String of the latex code for the learning rate sensitivity plot.\n\n    \"\"\"", "\n", "file_name", "=", "'benchmark_'", "+", "str", "(", "problem_set", ")", "+", "'.tex'", "\n", "tikz_code", "=", "get_tikz_code", "(", "\n", "file_name", ",", "figureheight", "=", "'\\\\figureheight'", ",", "figurewidth", "=", "'\\\\figurewidth'", ")", "\n", "\n", "tikz_code", "=", "r\"\\pgfplotsset{every axis/.append style={label style={font=\\tiny}, tick label style={font=\\tiny}, legend style={font=\\tiny, line width=1pt}}}\"", "+", "tikz_code", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'minor'", ",", "'%minor'", ")", "# comment minor tick", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'x grid'", ",", "'%x grid'", ")", "# remove grid", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'y grid'", ",", "'%y grid'", ")", "# remove grid", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'tick align'", ",", "\n", "'%tick align'", ")", "# ugly outside ticks", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'nextgroupplot['", ",", "\n", "'nextgroupplot[axis x line*=bottom,\\naxis y line*=left,'", "\n", ")", "# ugly outside ticks", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'xlabel={Epochs},\\nxmajorticks=false,'", ",", "\n", "'xlabel={Epochs},\\nxmajorticks=true,'", "\n", ")", "# if x label is epoch, show ticks", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'ymajorticks=false,'", ",", "\n", "'ymajorticks=true,'", ")", "# show y labels", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'\\mathdefault'", ",", "\n", "''", ")", "# remove mathdefault in labels", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'\\path [draw=white!80.0!black, fill opacity=0]'", ",", "\n", "'%\\path [draw=white!80.0!black, fill opacity=0]'", "\n", ")", "# remove lines that are created for some reason", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'(current bounding box.south west)!0.98!(current bounding box.north west)'", ",", "\n", "'(current bounding box.south west)!1.05!(current bounding box.north west)'", "\n", ")", "# position title higher", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "'title={'", ",", "\n", "'title={\\small '", ")", "# shrink title size", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'group style={group size=4 by 4'", ",", "\n", "'group style={group size=4 by 4, horizontal sep=1cm, vertical sep=0.4cm '", "\n", ")", "# reduce separation between plots", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'ylabel={Test Loss}'", ",", "r'ylabel style={align=left}, ylabel=Test\\\\Loss'", "\n", ")", "# y label in two lines", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'ylabel={Test Accuracy}'", ",", "\n", "r'ylabel style={align=left}, ylabel=Test\\\\Accuracy'", "\n", ")", "# y label in two lines", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'ylabel={Train Loss}'", ",", "r'ylabel style={align=left}, ylabel=Train\\\\Loss'", "\n", ")", "# y label in two lines", "\n", "tikz_code", "=", "tikz_code", ".", "replace", "(", "\n", "'ylabel={Train Accuracy}'", ",", "\n", "r'ylabel style={align=left}, ylabel=Train\\\\Accuracy'", "\n", ")", "# y label in two lines", "\n", "\n", "# Write the file out again", "\n", "with", "open", "(", "file_name", ",", "'w'", ")", "as", "file", ":", "\n", "        ", "file", ".", "write", "(", "tikz_code", ")", "\n", "\n", "", "return", "tikz_code", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_plot_table": [[900, 925], ["list", "bm_table_pd.reindex.reindex", "print", "pandas.DataFrame.from_dict", "list.insert", "list.insert", "list.insert", "list.pop", "list.pop", "list.pop", "list.index", "list.index", "list.index", "bm_table.keys", "bm_table[].keys"], "function", ["None"], ["", "def", "beautify_plot_table", "(", "bm_table", ")", ":", "\n", "    ", "\"\"\"Beautify a performance table.\n\n    This function makes a few changes to the performance table to make it nicer.\n\n    Args:\n        bm_table (dict): Dictionary holding all the information for the\n            performance table.\n\n    Returns:\n        pandas.dataframe: A pandas data frame for the performance table.\n    \"\"\"", "\n", "bm_table_pd", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "{", "(", "i", ",", "j", ")", ":", "bm_table", "[", "i", "]", "[", "j", "]", "\n", "for", "i", "in", "bm_table", ".", "keys", "(", ")", "\n", "for", "j", "in", "bm_table", "[", "i", "]", ".", "keys", "(", ")", "}", ")", ".", "T", "\n", "cols", "=", "list", "(", "bm_table_pd", ".", "columns", ".", "values", ")", "\n", "if", "'AdamOptimizer'", "in", "cols", ":", "\n", "        ", "cols", ".", "insert", "(", "0", ",", "cols", ".", "pop", "(", "cols", ".", "index", "(", "'AdamOptimizer'", ")", ")", ")", "\n", "", "if", "'MomentumOptimizer'", "in", "cols", ":", "\n", "        ", "cols", ".", "insert", "(", "0", ",", "cols", ".", "pop", "(", "cols", ".", "index", "(", "'MomentumOptimizer'", ")", ")", ")", "\n", "", "if", "'GradientDescentOptimizer'", "in", "cols", ":", "\n", "        ", "cols", ".", "insert", "(", "0", ",", "cols", ".", "pop", "(", "cols", ".", "index", "(", "'GradientDescentOptimizer'", ")", ")", ")", "\n", "", "bm_table_pd", "=", "bm_table_pd", ".", "reindex", "(", "columns", "=", "cols", ")", "\n", "print", "(", "bm_table_pd", ")", "\n", "return", "bm_table_pd", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_plot_table": [[927, 960], ["pandas.set_option", "perf_table_pd.apply", "perf_table_pd_n_str.columns.str.replace", "perf_table_pd.apply.applymap", "perf_table_pd.applymap", "open", "tex_file.write", "perf_table_pd_n_str.to_latex"], "function", ["None"], ["", "def", "texify_plot_table", "(", "perf_table_pd", ",", "problem_set", ")", ":", "\n", "    ", "\"\"\"Write a ``.tex`` file with the performance table.\n\n    The function will create a file named `performance_table_small.tex` or\n    `performance_table_large.tex` with the latex code for the performance table.\n\n    Args:\n        perf_table_pd (pandas.dataframe): Pandas data frame for the performance\n            table.\n        problem_set (str): Can either be ``small`` or ``large`` to switch\n            between which benchmark set is being plotted.\n\n    Returns:\n        str: String of the latex code for the performance table.\n\n    \"\"\"", "\n", "if", "not", "perf_table_pd", ".", "empty", ":", "\n", "# Postprocessing for Latex Output", "\n", "        ", "pd", ".", "set_option", "(", "'display.max_colwidth'", ",", "-", "1", ")", "\n", "perf_table_pd_n", "=", "perf_table_pd", ".", "apply", "(", "\n", "norm", ",", "axis", "=", "1", ")", "# normalize between 0 and 100", "\n", "perf_table_pd_n_str", "=", "perf_table_pd_n", ".", "applymap", "(", "\n", "add_color_coding_tex", ")", "+", "perf_table_pd", ".", "applymap", "(", "\n", "latex", ")", "# combine normalise version with latex color code command", "\n", "perf_table_pd_n_str", ".", "columns", "=", "perf_table_pd_n_str", ".", "columns", ".", "str", ".", "replace", "(", "\n", "'_'", ",", "r'\\_'", ")", "# Texify the column headers", "\n", "tikz_code", "=", "r\"\\def\\cca#1#2{\\cellcolor{green!#1!red}\\ifnum #1<50\\color{white}\\fi{#2}}\"", "+", "\"\\n\"", "+", "r\"\\resizebox{\\textwidth}{!}{%\"", "+", "\"\\n\"", "+", "perf_table_pd_n_str", ".", "to_latex", "(", "escape", "=", "False", ")", "+", "r\"}\"", "\n", "with", "open", "(", "'performance_table_'", "+", "problem_set", "+", "'.tex'", ",", "'w'", ")", "as", "tex_file", ":", "\n", "            ", "tex_file", ".", "write", "(", "tikz_code", ")", "\n", "\n", "", "return", "tikz_code", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.norm": [[962, 977], ["x.min", "x.max", "numpy.abs", "numpy.abs", "numpy.abs", "x.min", "x.max", "x.min", "x.max", "x.max", "x.min", "x.max", "x.min", "x.max", "x.min"], "function", ["None"], ["", "", "def", "norm", "(", "x", ")", ":", "\n", "    ", "\"\"\"Normalize the input of x, depending on the name (higher is better if\n    test_acc is used, otherwise lower is better)\"\"\"", "\n", "if", "x", ".", "name", "[", "1", "]", "==", "'Tuneability'", ":", "\n", "        ", "return", "x", "\n", "", "if", "x", ".", "min", "(", ")", "==", "x", ".", "max", "(", ")", ":", "\n", "        ", "return", "x", "-", "x", ".", "min", "(", ")", "+", "50.0", "\n", "", "if", "x", ".", "name", "[", "1", "]", "==", "'Performance'", ":", "\n", "        ", "if", "x", ".", "name", "[", "0", "]", "==", "\"quadratic_deep\"", "or", "x", ".", "name", "[", "0", "]", "==", "\"mnist_vae\"", "or", "x", ".", "name", "[", "\n", "0", "]", "==", "\"fmnist_vae\"", ":", "\n", "            ", "return", "np", ".", "abs", "(", "(", "x", "-", "x", ".", "max", "(", ")", ")", "/", "(", "x", ".", "min", "(", ")", "-", "x", ".", "max", "(", ")", ")", "*", "100", ")", "\n", "", "else", ":", "\n", "            ", "return", "np", ".", "abs", "(", "(", "x", "-", "x", ".", "min", "(", ")", ")", "/", "(", "x", ".", "max", "(", ")", "-", "x", ".", "min", "(", ")", ")", "*", "100", ")", "\n", "", "", "else", ":", "\n", "        ", "return", "np", ".", "abs", "(", "(", "x", "-", "x", ".", "max", "(", ")", ")", "/", "(", "x", ".", "min", "(", ")", "-", "x", ".", "max", "(", ")", ")", "*", "100", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.latex": [[979, 991], ["isinstance", "isinstance", "isinstance", "str", "str().replace().replace().replace().replace", "str", "str().replace().replace().replace", "str().replace().replace", "str().replace", "str"], "function", ["None"], ["", "", "def", "latex", "(", "input", ")", ":", "\n", "    ", "\"\"\"Create the latex output version of the input.\"\"\"", "\n", "if", "isinstance", "(", "input", ",", "float", ")", ":", "\n", "        ", "input", "=", "\"%.4f\"", "%", "input", "\n", "return", "\"{\"", "+", "str", "(", "input", ")", "+", "\"}\"", "\n", "", "elif", "isinstance", "(", "input", ",", "int", ")", ":", "\n", "        ", "return", "\"{\"", "+", "str", "(", "input", ")", "+", "\"}\"", "\n", "", "elif", "isinstance", "(", "input", ",", "dict", ")", ":", "\n", "        ", "return", "str", "(", "input", ")", ".", "replace", "(", "'{'", ",", "''", ")", ".", "replace", "(", "'}'", ",", "''", ")", ".", "replace", "(", "\n", "\"'\"", ",", "''", ")", ".", "replace", "(", "'_'", ",", "''", ")", "\n", "", "else", ":", "\n", "        ", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.add_color_coding_tex": [[993, 1000], ["isinstance", "isinstance", "isinstance", "numpy.isnan", "str", "int"], "function", ["None"], ["", "", "def", "add_color_coding_tex", "(", "input", ")", ":", "\n", "    ", "\"\"\"Adds the latex command for color coding to the input\"\"\"", "\n", "if", "isinstance", "(", "input", ",", "str", ")", "or", "isinstance", "(", "input", ",", "int", ")", "or", "isinstance", "(", "\n", "input", ",", "float", ")", "and", "not", "np", ".", "isnan", "(", "input", ")", ":", "\n", "        ", "return", "\"\\cca{\"", "+", "str", "(", "int", "(", "input", ")", ")", "+", "\"}\"", "\n", "", "else", ":", "\n", "        ", "return", "\"\"", "\n", "", "", ""]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.get_best_run": [[18, 36], ["print", "folder_pars.testproblems.items", "print", "print", "print", "testprob.optimizers.items", "print", "opt.get_best_setting_final", "opt.get_best_setting_best", "print", "print"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_final", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_best_setting_best"], ["def", "get_best_run", "(", "folder_pars", ")", ":", "\n", "    ", "print", "(", "\"Get best run\\n\\n\"", ")", "\n", "for", "_", ",", "testprob", "in", "folder_pars", ".", "testproblems", ".", "items", "(", ")", ":", "\n", "        ", "print", "(", "\"***********************\"", ")", "\n", "print", "(", "\"Analyzing\"", ",", "testprob", ".", "name", ")", "\n", "print", "(", "\"***********************\"", ")", "\n", "for", "_", ",", "opt", "in", "testprob", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "#         print(\"Analyzing\", opt.name)", "\n", "            ", "print", "(", "\"Checked\"", ",", "opt", ".", "num_settings", ",", "\"settings for\"", ",", "opt", ".", "name", ",", "\n", "\"and found the following\"", ")", "\n", "setting_final", "=", "opt", ".", "get_best_setting_final", "(", ")", "\n", "setting_best", "=", "opt", ".", "get_best_setting_best", "(", ")", "\n", "print", "(", "\"Best Setting (Final Value)\"", ",", "setting_final", ".", "name", ",", "\n", "\"with final performance of\"", ",", "\n", "setting_final", ".", "aggregate", ".", "final_value", ")", "\n", "print", "(", "\"Best Setting (Best Value)\"", ",", "setting_best", ".", "name", ",", "\n", "\"with best performance of\"", ",", "\n", "setting_best", ".", "aggregate", ".", "best_value", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_lr_sensitivity": [[38, 86], ["print", "matplotlib.subplots", "deepobs.analyzer.analyze_utils.beautify_lr_sensitivity", "deepobs.analyzer.analyze_utils.texify_lr_sensitivity", "matplotlib.show", "folder_pars.testproblems[].optimizers.items", "folder_pars.testproblems[].optimizers.items", "opt.plot_lr_sensitivity", "baseline_pars.testproblems[].optimizers.items", "opt.plot_lr_sensitivity", "baseline_pars.testproblems[].optimizers.items", "opt.plot_lr_sensitivity", "opt.plot_lr_sensitivity"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_lr_sensitivity", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_lr_sensitivity", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_lr_sensitivity", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_lr_sensitivity", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_lr_sensitivity", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_lr_sensitivity"], ["", "", "", "def", "plot_lr_sensitivity", "(", "folder_pars", ",", "baseline_pars", "=", "None", ",", "mode", "=", "'final'", ")", ":", "\n", "    ", "print", "(", "\"Plot learning rate sensitivity plot\"", ")", "\n", "fig", ",", "axis", "=", "plt", ".", "subplots", "(", "2", ",", "4", ",", "figsize", "=", "(", "35", ",", "4", ")", ")", "\n", "\n", "ax_row", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"quadratic_deep\"", ",", "\"mnist_vae\"", ",", "\"fmnist_2c2d\"", ",", "\"cifar10_3c3d\"", "\n", "]", ":", "\n", "        ", "if", "testprob", "in", "folder_pars", ".", "testproblems", ":", "\n", "            ", "for", "_", ",", "opt", "in", "folder_pars", ".", "testproblems", "[", "testprob", "]", ".", "optimizers", ".", "items", "(", "\n", ")", ":", "\n", "                ", "opt", ".", "plot_lr_sensitivity", "(", "axis", "[", "0", "]", "[", "ax_row", "]", ",", "mode", "=", "mode", ")", "\n", "", "ax_row", "+=", "1", "\n", "", "", "if", "baseline_pars", "is", "not", "None", ":", "\n", "        ", "ax_row", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"quadratic_deep\"", ",", "\"mnist_vae\"", ",", "\"fmnist_2c2d\"", ",", "\"cifar10_3c3d\"", "\n", "]", ":", "\n", "            ", "if", "testprob", "in", "baseline_pars", ".", "testproblems", ":", "\n", "                ", "for", "_", ",", "opt", "in", "baseline_pars", ".", "testproblems", "[", "\n", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                    ", "opt", ".", "plot_lr_sensitivity", "(", "axis", "[", "0", "]", "[", "ax_row", "]", ",", "mode", "=", "mode", ")", "\n", "", "ax_row", "+=", "1", "\n", "", "", "", "ax_row", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"fmnist_vae\"", ",", "\"cifar100_allcnnc\"", ",", "\"svhn_wrn164\"", ",", "\"tolstoi_char_rnn\"", "\n", "]", ":", "\n", "        ", "if", "testprob", "in", "folder_pars", ".", "testproblems", ":", "\n", "            ", "for", "_", ",", "opt", "in", "folder_pars", ".", "testproblems", "[", "testprob", "]", ".", "optimizers", ".", "items", "(", "\n", ")", ":", "\n", "                ", "opt", ".", "plot_lr_sensitivity", "(", "axis", "[", "1", "]", "[", "ax_row", "]", ",", "mode", "=", "mode", ")", "\n", "", "ax_row", "+=", "1", "\n", "", "", "if", "baseline_pars", "is", "not", "None", ":", "\n", "        ", "ax_row", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"fmnist_vae\"", ",", "\"cifar100_allcnnc\"", ",", "\"svhn_wrn164\"", ",", "\n", "\"tolstoi_char_rnn\"", "\n", "]", ":", "\n", "            ", "if", "testprob", "in", "baseline_pars", ".", "testproblems", ":", "\n", "                ", "for", "_", ",", "opt", "in", "baseline_pars", ".", "testproblems", "[", "\n", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                    ", "opt", ".", "plot_lr_sensitivity", "(", "axis", "[", "1", "]", "[", "ax_row", "]", ",", "mode", "=", "mode", ")", "\n", "", "ax_row", "+=", "1", "\n", "\n", "", "", "", "fig", ",", "axis", "=", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "beautify_lr_sensitivity", "(", "\n", "fig", ",", "axis", ")", "\n", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "texify_lr_sensitivity", "(", "fig", ",", "axis", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_performance": [[88, 142], ["matplotlib.subplots", "deepobs.analyzer.analyze_utils.beautify_plot_performance", "deepobs.analyzer.analyze_utils.texify_plot_performance", "matplotlib.show", "matplotlib.subplots", "deepobs.analyzer.analyze_utils.beautify_plot_performance", "deepobs.analyzer.analyze_utils.texify_plot_performance", "matplotlib.show", "folder_pars.testproblems[].optimizers.items", "folder_pars.testproblems[].optimizers.items", "opt.plot_performance", "baseline_pars.testproblems[].optimizers.items", "opt.plot_performance", "baseline_pars.testproblems[].optimizers.items", "opt.plot_performance", "opt.plot_performance"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_performance", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_performance"], ["", "def", "plot_performance", "(", "folder_pars", ",", "baseline_pars", "=", "None", ",", "mode", "=", "\"most\"", ")", ":", "\n", "# Small Benchmark", "\n", "    ", "fig", ",", "axis", "=", "plt", ".", "subplots", "(", "4", ",", "4", ",", "sharex", "=", "'col'", ",", "figsize", "=", "(", "25", ",", "8", ")", ")", "\n", "\n", "ax_col", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"quadratic_deep\"", ",", "\"mnist_vae\"", ",", "\"fmnist_2c2d\"", ",", "\"cifar10_3c3d\"", "\n", "]", ":", "\n", "        ", "if", "testprob", "in", "folder_pars", ".", "testproblems", ":", "\n", "            ", "for", "_", ",", "opt", "in", "folder_pars", ".", "testproblems", "[", "testprob", "]", ".", "optimizers", ".", "items", "(", "\n", ")", ":", "\n", "                ", "opt", ".", "plot_performance", "(", "axis", "[", ":", ",", "ax_col", "]", ",", "mode", "=", "mode", ")", "\n", "", "ax_col", "+=", "1", "\n", "", "", "if", "baseline_pars", "is", "not", "None", ":", "\n", "        ", "ax_col", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"quadratic_deep\"", ",", "\"mnist_vae\"", ",", "\"fmnist_2c2d\"", ",", "\"cifar10_3c3d\"", "\n", "]", ":", "\n", "            ", "if", "testprob", "in", "baseline_pars", ".", "testproblems", ":", "\n", "                ", "for", "_", ",", "opt", "in", "baseline_pars", ".", "testproblems", "[", "\n", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                    ", "opt", ".", "plot_performance", "(", "axis", "[", ":", ",", "ax_col", "]", ",", "mode", "=", "'most'", ")", "\n", "", "ax_col", "+=", "1", "\n", "", "", "", "fig", ",", "axis", "=", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "beautify_plot_performance", "(", "\n", "fig", ",", "axis", ",", "folder_pars", ",", "\"small\"", ")", "\n", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "texify_plot_performance", "(", "fig", ",", "axis", ",", "\"small\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "# Large Benchmark", "\n", "fig", ",", "axis", "=", "plt", ".", "subplots", "(", "4", ",", "4", ",", "sharex", "=", "'col'", ",", "figsize", "=", "(", "25", ",", "8", ")", ")", "\n", "\n", "ax_col", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"fmnist_vae\"", ",", "\"cifar100_allcnnc\"", ",", "\"svhn_wrn164\"", ",", "\"tolstoi_char_rnn\"", "\n", "]", ":", "\n", "        ", "if", "testprob", "in", "folder_pars", ".", "testproblems", ":", "\n", "            ", "for", "_", ",", "opt", "in", "folder_pars", ".", "testproblems", "[", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                ", "opt", ".", "plot_performance", "(", "axis", "[", ":", ",", "ax_col", "]", ",", "mode", "=", "mode", ")", "\n", "", "ax_col", "+=", "1", "\n", "", "", "if", "baseline_pars", "is", "not", "None", ":", "\n", "        ", "ax_col", "=", "0", "\n", "for", "testprob", "in", "[", "\n", "\"fmnist_vae\"", ",", "\"cifar100_allcnnc\"", ",", "\"svhn_wrn164\"", ",", "\n", "\"tolstoi_char_rnn\"", "\n", "]", ":", "\n", "            ", "if", "testprob", "in", "baseline_pars", ".", "testproblems", ":", "\n", "                ", "for", "_", ",", "opt", "in", "baseline_pars", ".", "testproblems", "[", "\n", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                    ", "opt", ".", "plot_performance", "(", "axis", "[", ":", ",", "ax_col", "]", ",", "mode", "=", "'most'", ")", "\n", "", "ax_col", "+=", "1", "\n", "", "", "", "fig", ",", "axis", "=", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "beautify_plot_performance", "(", "\n", "fig", ",", "axis", ",", "folder_pars", ",", "\"large\"", ")", "\n", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "texify_plot_performance", "(", "fig", ",", "axis", ",", "\"large\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze.plot_table": [[144, 192], ["print", "dict", "deepobs.analyzer.analyze_utils.beautify_plot_table", "deepobs.analyzer.analyze_utils.texify_plot_table", "dict", "deepobs.analyzer.analyze_utils.beautify_plot_table", "deepobs.analyzer.analyze_utils.texify_plot_table", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "folder_pars.testproblems[].optimizers.items", "folder_pars.testproblems[].optimizers.items", "opt.get_bm_table", "baseline_pars.testproblems[].optimizers.items", "opt.get_bm_table", "baseline_pars.testproblems[].optimizers.items", "opt.get_bm_table", "opt.get_bm_table"], "function", ["home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_plot_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_plot_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.beautify_plot_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.texify_plot_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_bm_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_bm_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_bm_table", "home.repos.pwc.inspect_result.fsschneider_deepobs.analyzer.analyze_utils.OptimizerAnalyzer.get_bm_table"], ["", "def", "plot_table", "(", "folder_pars", ",", "baseline_pars", "=", "None", ")", ":", "\n", "    ", "print", "(", "\"Plot overall performance table\"", ")", "\n", "\n", "bm_table_small", "=", "dict", "(", ")", "\n", "for", "testprob", "in", "[", "\n", "\"quadratic_deep\"", ",", "\"mnist_vae\"", ",", "\"fmnist_2c2d\"", ",", "\"cifar10_3c3d\"", "\n", "]", ":", "\n", "        ", "bm_table_small", "[", "testprob", "]", "=", "dict", "(", ")", "\n", "bm_table_small", "[", "testprob", "]", "[", "'Performance'", "]", "=", "dict", "(", ")", "\n", "bm_table_small", "[", "testprob", "]", "[", "'Speed'", "]", "=", "dict", "(", ")", "\n", "bm_table_small", "[", "testprob", "]", "[", "'Tuneability'", "]", "=", "dict", "(", ")", "\n", "if", "testprob", "in", "folder_pars", ".", "testproblems", ":", "\n", "            ", "for", "_", ",", "opt", "in", "folder_pars", ".", "testproblems", "[", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                ", "bm_table_small", "[", "testprob", "]", "=", "opt", ".", "get_bm_table", "(", "\n", "bm_table_small", "[", "testprob", "]", ")", "\n", "", "", "if", "baseline_pars", "is", "not", "None", ":", "\n", "            ", "if", "testprob", "in", "baseline_pars", ".", "testproblems", ":", "\n", "                ", "for", "_", ",", "opt", "in", "baseline_pars", ".", "testproblems", "[", "\n", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                    ", "bm_table_small", "[", "testprob", "]", "=", "opt", ".", "get_bm_table", "(", "\n", "bm_table_small", "[", "testprob", "]", ")", "\n", "", "", "", "", "bm_table_small_pd", "=", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "beautify_plot_table", "(", "\n", "bm_table_small", ")", "\n", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "texify_plot_table", "(", "bm_table_small_pd", ",", "\n", "\"small\"", ")", "\n", "\n", "bm_table_large", "=", "dict", "(", ")", "\n", "for", "testprob", "in", "[", "\n", "\"fmnist_vae\"", ",", "\"cifar100_allcnnc\"", ",", "\"svhn_wrn164\"", ",", "\"tolstoi_char_rnn\"", "\n", "]", ":", "\n", "        ", "bm_table_large", "[", "testprob", "]", "=", "dict", "(", ")", "\n", "bm_table_large", "[", "testprob", "]", "[", "'Performance'", "]", "=", "dict", "(", ")", "\n", "bm_table_large", "[", "testprob", "]", "[", "'Speed'", "]", "=", "dict", "(", ")", "\n", "bm_table_large", "[", "testprob", "]", "[", "'Tuneability'", "]", "=", "dict", "(", ")", "\n", "if", "testprob", "in", "folder_pars", ".", "testproblems", ":", "\n", "            ", "for", "_", ",", "opt", "in", "folder_pars", ".", "testproblems", "[", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                ", "bm_table_large", "[", "testprob", "]", "=", "opt", ".", "get_bm_table", "(", "\n", "bm_table_large", "[", "testprob", "]", ")", "\n", "", "", "if", "baseline_pars", "is", "not", "None", ":", "\n", "            ", "if", "testprob", "in", "baseline_pars", ".", "testproblems", ":", "\n", "                ", "for", "_", ",", "opt", "in", "baseline_pars", ".", "testproblems", "[", "\n", "testprob", "]", ".", "optimizers", ".", "items", "(", ")", ":", "\n", "                    ", "bm_table_large", "[", "testprob", "]", "=", "opt", ".", "get_bm_table", "(", "\n", "bm_table_large", "[", "testprob", "]", ")", "\n", "", "", "", "", "bm_table_large_pd", "=", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "beautify_plot_table", "(", "\n", "bm_table_large", ")", "\n", "deepobs", ".", "analyzer", ".", "analyze_utils", ".", "texify_plot_table", "(", "bm_table_large_pd", ",", "\n", "\"large\"", ")", "\n", "", ""]]}