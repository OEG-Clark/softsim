{"home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.qa_nli_predictor.QaNliPredictor.predict": [[13, 23], ["qa_nli_predictor.QaNliPredictor._dataset_reader.text_to_instance", "qa_nli_predictor.QaNliPredictor.predict_instance"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance"], ["    ", "def", "predict", "(", "self", ",", "premise", ":", "str", ",", "hypothesis", ":", "str", ",", "answer_score", ":", "float", "=", "None", ")", "->", "JsonDict", ":", "\n", "        ", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "premise", ",", "\n", "hypothesis", ",", "\n", "answer_score", "\n", ")", "\n", "if", "instance", ":", "\n", "            ", "return", "self", ".", "predict_instance", "(", "instance", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.qa_nli_predictor.QaNliPredictor.predict_batch": [[24, 49], ["qa_nli_predictor.QaNliPredictor.predict_batch_instance", "zip", "zip", "qa_nli_predictor.QaNliPredictor._dataset_reader.text_to_instance", "qa_nli_predictor.QaNliPredictor._dataset_reader.text_to_instance", "instances.append", "instances.append"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance"], ["", "", "def", "predict_batch", "(", "self", ",", "premises", ":", "List", "[", "str", "]", ",", "hypothesises", ":", "List", "[", "str", "]", ",", "\n", "answer_scores", ":", "List", "[", "float", "]", "=", "None", ")", ":", "\n", "        ", "instances", "=", "[", "]", "\n", "if", "answer_scores", "is", "None", ":", "\n", "            ", "for", "premise", ",", "hypothesis", "in", "zip", "(", "premises", ",", "hypothesises", ")", ":", "\n", "                ", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "premise", ",", "\n", "hypothesis", "\n", ")", "\n", "if", "instance", ":", "\n", "                    ", "instances", ".", "append", "(", "instance", ")", "\n", "", "", "", "else", ":", "\n", "            ", "for", "premise", ",", "hypothesis", ",", "answer_score", "in", "zip", "(", "premises", ",", "\n", "hypothesises", ",", "\n", "answer_scores", "\n", ")", ":", "\n", "                ", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "premise", ",", "\n", "hypothesis", ",", "\n", "answer_score", "=", "answer_score", "\n", ")", "\n", "if", "instance", ":", "\n", "                    ", "instances", ".", "append", "(", "instance", ")", "\n", "", "", "", "outputs", "=", "self", ".", "predict_batch_instance", "(", "instances", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.qa_nli_predictor.QaNliPredictor.predictions_to_labeled_instances": [[50, 61], ["instance.duplicate", "numpy.argmax", "instance.duplicate.add_field", "allennlp.data.fields.LabelField", "int"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "predictions_to_labeled_instances", "(", "\n", "self", ",", "instance", ":", "Instance", ",", "outputs", ":", "Dict", "[", "str", ",", "numpy", ".", "ndarray", "]", "\n", ")", "->", "List", "[", "Instance", "]", ":", "\n", "# This function is used to to compute gradients of what the model predicted.", "\n", "        ", "new_instance", "=", "instance", ".", "duplicate", "(", ")", "\n", "label", "=", "numpy", ".", "argmax", "(", "outputs", "[", "\"logits\"", "]", ")", "\n", "# Skip indexing, we have integer representations of the strings \"entailment\", etc.", "\n", "new_instance", ".", "add_field", "(", "\"label\"", ",", "\n", "LabelField", "(", "int", "(", "label", ")", ",", "skip_indexing", "=", "True", ")", ")", "\n", "return", "[", "new_instance", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.qa_nli_predictor.QaNliPredictor._json_to_instance": [[62, 71], ["qa_nli_predictor.QaNliPredictor._dataset_reader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "premise", "=", "json_dict", "[", "\"premise\"", "]", "\n", "hypothesis", "=", "json_dict", "[", "\"hypothesis\"", "]", "\n", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "premise", ",", "\n", "hypothesis", "\n", ")", "\n", "return", "instance", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.mnli_predictor.MNliPredictor.predict": [[17, 26], ["mnli_predictor.MNliPredictor._dataset_reader.text_to_instance", "mnli_predictor.MNliPredictor.predict_instance"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance"], ["def", "predict", "(", "self", ",", "premise", ":", "str", ",", "hypothesis", ":", "str", ",", "label", ":", "str", "=", "None", ")", "->", "JsonDict", ":", "\n", "        ", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "premise", ",", "\n", "hypothesis", ",", "\n", ")", "\n", "if", "instance", ":", "\n", "            ", "return", "self", ".", "predict_instance", "(", "instance", ")", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.mnli_predictor.MNliPredictor.predictions_to_labeled_instances": [[27, 38], ["instance.duplicate", "numpy.argmax", "instance.duplicate.add_field", "allennlp.data.fields.LabelField", "int"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "predictions_to_labeled_instances", "(", "\n", "self", ",", "instance", ":", "Instance", ",", "outputs", ":", "Dict", "[", "str", ",", "numpy", ".", "ndarray", "]", "\n", ")", "->", "List", "[", "Instance", "]", ":", "\n", "# This function is used to to compute gradients of what the model predicted.", "\n", "        ", "new_instance", "=", "instance", ".", "duplicate", "(", ")", "\n", "label", "=", "numpy", ".", "argmax", "(", "outputs", "[", "\"logits\"", "]", ")", "\n", "# Skip indexing, we have integer representations of the strings \"entailment\", etc.", "\n", "new_instance", ".", "add_field", "(", "\"label\"", ",", "\n", "LabelField", "(", "int", "(", "label", ")", ",", "skip_indexing", "=", "True", ")", ")", "\n", "return", "[", "new_instance", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.mnli_predictor.MNliPredictor._json_to_instance": [[39, 48], ["mnli_predictor.MNliPredictor._dataset_reader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_json_to_instance", "(", "self", ",", "json_dict", ":", "JsonDict", ")", "->", "Instance", ":", "\n", "        ", "premise", "=", "json_dict", "[", "\"premise\"", "]", "\n", "hypothesis", "=", "json_dict", "[", "\"hypothesis\"", "]", "\n", "instance", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "premise", ",", "\n", "hypothesis", "\n", ")", "\n", "return", "instance", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.__init__": [[22, 54], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "isinstance", "allennlp.data.tokenizers.SpacyTokenizer", "isinstance", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.models.qa_nli_model.QaNliClassifier.__init__"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "tokenizer", ":", "Optional", "[", "Tokenizer", "]", "=", "None", ",", "\n", "token_indexers", ":", "Dict", "[", "str", ",", "TokenIndexer", "]", "=", "None", ",", "\n", "combine_input_fields", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "use_full_context", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "use_decontext", ":", "Optional", "[", "bool", "]", "=", "True", ",", "\n", "joint_training", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "joint_eval", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "use_answer_score", ":", "Optional", "[", "bool", "]", "=", "False", ",", "\n", "max_source_length", ":", "Optional", "[", "int", "]", "=", "512", ",", "\n", "mnli_path", ":", "str", "=", "None", ",", "\n", "qa_example_ratio", ":", "float", "=", "1", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "manual_distributed_sharding", "=", "True", ",", "**", "kwargs", ")", "\n", "self", ".", "_tokenizer", "=", "tokenizer", "or", "SpacyTokenizer", "(", ")", "\n", "if", "isinstance", "(", "self", ".", "_tokenizer", ",", "PretrainedTransformerTokenizer", ")", ":", "\n", "            ", "assert", "not", "self", ".", "_tokenizer", ".", "_add_special_tokens", "\n", "", "self", ".", "_token_indexers", "=", "token_indexers", "or", "{", "\"tokens\"", ":", "SingleIdTokenIndexer", "(", ")", "}", "\n", "if", "combine_input_fields", "is", "not", "None", ":", "\n", "            ", "self", ".", "_combine_input_fields", "=", "combine_input_fields", "\n", "", "else", ":", "\n", "            ", "self", ".", "_combine_input_fields", "=", "isinstance", "(", "self", ".", "_tokenizer", ",", "PretrainedTransformerTokenizer", ")", "\n", "", "self", ".", "use_full_context", "=", "use_full_context", "\n", "self", ".", "use_decontext", "=", "use_decontext", "\n", "self", ".", "joint_training", "=", "joint_training", "\n", "self", ".", "joint_eval", "=", "joint_eval", "\n", "self", ".", "use_answer_scores", "=", "use_answer_score", "\n", "self", ".", "max_source_length", "=", "max_source_length", "\n", "self", ".", "mnli_path", "=", "mnli_path", "\n", "self", ".", "qa_example_ratio", "=", "qa_example_ratio", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader._read": [[55, 113], ["allennlp.common.file_utils.cached_path", "open", "len", "json.loads", "random.shuffle", "qa_nli_reader.QaNliReader.text_to_instance", "open", "mnli_examples.append", "example.keys", "json.loads", "int", "int", "int"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance"], ["", "@", "overrides", "\n", "def", "_read", "(", "self", ",", "file_path", ":", "str", ")", ":", "\n", "        ", "file_path", "=", "cached_path", "(", "file_path", ")", "\n", "\n", "with", "open", "(", "file_path", ",", "\"r\"", ")", "as", "qed_nli_file", ":", "\n", "            ", "qa_nli_examples", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "qed_nli_file", "]", "\n", "num_qa_nli_examples", "=", "len", "(", "qa_nli_examples", ")", "\n", "mnli_examples", "=", "[", "]", "\n", "if", "self", ".", "mnli_path", ":", "\n", "                ", "with", "open", "(", "self", ".", "mnli_path", ")", "as", "fin", ":", "\n", "                    ", "for", "line", "in", "fin", ":", "\n", "                        ", "mnli_examples", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "\n", "", "", "", "if", "'train'", "in", "file_path", ":", "\n", "                ", "if", "self", ".", "joint_training", ":", "\n", "                    ", "all_examples", "=", "mnli_examples", "[", ":", "int", "(", "1", "*", "num_qa_nli_examples", ")", "]", "+", "qa_nli_examples", "[", ":", "int", "(", "self", ".", "qa_example_ratio", "*", "num_qa_nli_examples", ")", "]", "\n", "", "else", ":", "\n", "                    ", "all_examples", "=", "qa_nli_examples", "\n", "", "random", ".", "shuffle", "(", "all_examples", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "joint_eval", ":", "\n", "                    ", "all_examples", "=", "mnli_examples", "+", "qa_nli_examples", "[", ":", "int", "(", "self", ".", "qa_example_ratio", "*", "num_qa_nli_examples", ")", "]", "\n", "", "else", ":", "\n", "                    ", "all_examples", "=", "qa_nli_examples", "\n", "\n", "", "", "count", "=", "0", "\n", "for", "example", "in", "all_examples", ":", "\n", "                ", "label", "=", "\"entail\"", "if", "example", "[", "\"is_correct\"", "]", "else", "\"not_entail\"", "\n", "# using the whole paragraph as premise or just the answering sent", "\n", "if", "self", ".", "use_full_context", ":", "\n", "                    ", "premise", "=", "example", "[", "\"paragraph_text\"", "]", "\n", "", "else", ":", "\n", "                    ", "if", "self", ".", "use_decontext", ":", "\n", "# premise = example['decontext_answer_sent_text']", "\n", "                        ", "premise", "=", "example", "[", "'decontext_answer_sent_text'", "]", "\n", "", "else", ":", "\n", "                        ", "premise", "=", "example", "[", "'answer_sent_text'", "]", "\n", "", "", "count", "+=", "1", "\n", "# if self.joint_training and count == 1000:", "\n", "#     break", "\n", "hypothesis", "=", "example", "[", "\"question_statement_text\"", "]", "\n", "if", "self", ".", "use_answer_scores", ":", "\n", "                    ", "if", "'answer_score'", "in", "example", ".", "keys", "(", ")", ":", "\n", "                        ", "answer_score", "=", "example", "[", "'answer_score'", "]", "\n", "", "else", ":", "\n", "# raise ValueError('answer score not found')", "\n", "                        ", "answer_score", "=", "0", "\n", "", "", "else", ":", "\n", "                    ", "answer_score", "=", "None", "\n", "# assert answer_score is not None", "\n", "", "instance", "=", "self", ".", "text_to_instance", "(", "premise", ",", "\n", "hypothesis", ",", "\n", "label", ",", "\n", "answer_score", ")", "\n", "if", "instance", ":", "\n", "                    ", "yield", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.dataset_readers.qa_nli_reader.QaNliReader.text_to_instance": [[114, 151], ["qa_nli_reader.QaNliReader._tokenizer.tokenize", "qa_nli_reader.QaNliReader._tokenizer.tokenize", "allennlp.data.instance.Instance", "allennlp.data.fields.ArrayField", "qa_nli_reader.QaNliReader._tokenizer.add_special_tokens", "allennlp.data.fields.TextField", "qa_nli_reader.QaNliReader._tokenizer.add_special_tokens", "qa_nli_reader.QaNliReader._tokenizer.add_special_tokens", "allennlp.data.fields.TextField", "allennlp.data.fields.TextField", "allennlp.data.fields.MetadataField", "allennlp.data.fields.LabelField", "numpy.array", "len"], "methods", ["None"], ["", "", "", "", "@", "overrides", "\n", "def", "text_to_instance", "(", "\n", "self", ",", "# type: ignore", "\n", "premise", ":", "str", ",", "\n", "hypothesis", ":", "str", ",", "\n", "label", ":", "str", "=", "None", ",", "\n", "answer_score", ":", "float", "=", "None", "\n", ")", "->", "Instance", ":", "\n", "\n", "        ", "fields", ":", "Dict", "[", "str", ",", "Field", "]", "=", "{", "}", "\n", "premise", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "premise", ")", "\n", "hypothesis", "=", "self", ".", "_tokenizer", ".", "tokenize", "(", "hypothesis", ")", "\n", "if", "answer_score", "is", "not", "None", ":", "\n", "            ", "fields", "[", "'answer_scores'", "]", "=", "ArrayField", "(", "np", ".", "array", "(", "answer_score", ")", ")", "\n", "", "if", "self", ".", "_combine_input_fields", ":", "\n", "            ", "tokens", "=", "self", ".", "_tokenizer", ".", "add_special_tokens", "(", "premise", ",", "hypothesis", ")", "\n", "if", "len", "(", "tokens", ")", ">", "self", ".", "max_source_length", ":", "\n", "                ", "tokens", "=", "tokens", "[", ":", "self", ".", "max_source_length", "]", "\n", "", "fields", "[", "\"tokens\"", "]", "=", "TextField", "(", "tokens", ",", "self", ".", "_token_indexers", ")", "\n", "", "else", ":", "\n", "            ", "premise_tokens", "=", "self", ".", "_tokenizer", ".", "add_special_tokens", "(", "premise", ")", "\n", "hypothesis_tokens", "=", "self", ".", "_tokenizer", ".", "add_special_tokens", "(", "hypothesis", ")", "\n", "fields", "[", "\"premise\"", "]", "=", "TextField", "(", "premise_tokens", ",", "self", ".", "_token_indexers", ")", "\n", "fields", "[", "\"hypothesis\"", "]", "=", "TextField", "(", "hypothesis_tokens", ",", "self", ".", "_token_indexers", ")", "\n", "\n", "metadata", "=", "{", "\n", "\"premise_tokens\"", ":", "[", "x", ".", "text", "for", "x", "in", "premise_tokens", "]", ",", "\n", "\"hypothesis_tokens\"", ":", "[", "x", ".", "text", "for", "x", "in", "hypothesis_tokens", "]", ",", "\n", "}", "\n", "fields", "[", "\"metadata\"", "]", "=", "MetadataField", "(", "metadata", ")", "\n", "# if len(fields[\"tokens\"]) > 512:", "\n", "#     fields[\"tokens\"] = fields[\"tokens\"][:512]", "\n", "\n", "", "if", "label", ":", "\n", "            ", "fields", "[", "\"label\"", "]", "=", "LabelField", "(", "label", ")", "\n", "\n", "", "return", "Instance", "(", "fields", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.models.qa_nli_model.QaNliClassifier.__init__": [[48, 106], ["allennlp.models.model.Model.__init__", "allennlp.common.Params", "allennlp.modules.FeedForward.from_params", "torch.nn.Linear", "allennlp.training.metrics.CategoricalAccuracy", "allennlp.training.metrics.F1Measure", "torch.nn.CrossEntropyLoss", "feedforward.get_output_dim", "qa_nli_model.QaNliClassifier._seq2vec_encoder.get_output_dim", "torch.nn.Dropout", "vocab.get_vocab_size", "initializer"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.models.qa_nli_model.QaNliClassifier.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "text_field_embedder", ":", "TextFieldEmbedder", ",", "\n", "seq2vec_encoder", ":", "Seq2VecEncoder", ",", "\n", "seq2seq_encoder", ":", "Seq2SeqEncoder", "=", "None", ",", "\n", "feedforward", ":", "Optional", "[", "FeedForward", "]", "=", "None", ",", "\n", "dropout", ":", "float", "=", "None", ",", "\n", "num_labels", ":", "int", "=", "None", ",", "\n", "label_namespace", ":", "str", "=", "\"labels\"", ",", "\n", "namespace", ":", "str", "=", "\"tokens\"", ",", "\n", "initializer", ":", "Optional", "[", "InitializerApplicator", "]", "=", "None", ",", "\n", "use_answer_score", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "**", "kwargs", ",", "\n", ")", "->", "None", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "**", "kwargs", ")", "\n", "self", ".", "_text_field_embedder", "=", "text_field_embedder", "\n", "self", ".", "_seq2seq_encoder", "=", "seq2seq_encoder", "\n", "self", ".", "_seq2vec_encoder", "=", "seq2vec_encoder", "\n", "\n", "self", ".", "_use_answer_score", "=", "use_answer_score", "\n", "\n", "params", "=", "Params", "(", "{", "\n", "'input_dim'", ":", "1025", "if", "use_answer_score", "else", "1024", ",", "\n", "'hidden_dims'", ":", "1025", "if", "use_answer_score", "else", "1024", ",", "\n", "'activations'", ":", "'tanh'", ",", "\n", "'num_layers'", ":", "1", "\n", "}", ")", "\n", "\n", "self", ".", "_feedforward", "=", "FeedForward", ".", "from_params", "(", "params", ")", "\n", "\n", "if", "feedforward", "is", "not", "None", ":", "\n", "            ", "self", ".", "_classifier_input_dim", "=", "feedforward", ".", "get_output_dim", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_classifier_input_dim", "=", "self", ".", "_seq2vec_encoder", ".", "get_output_dim", "(", ")", "\n", "", "if", "self", ".", "_use_answer_score", ":", "\n", "            ", "self", ".", "_classifier_input_dim", "+=", "1", "\n", "\n", "\n", "", "if", "dropout", ":", "\n", "            ", "self", ".", "_dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "_dropout", "=", "None", "\n", "", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "self", ".", "_namespace", "=", "namespace", "\n", "\n", "if", "num_labels", ":", "\n", "            ", "self", ".", "_num_labels", "=", "num_labels", "\n", "", "else", ":", "\n", "            ", "self", ".", "_num_labels", "=", "vocab", ".", "get_vocab_size", "(", "namespace", "=", "self", ".", "_label_namespace", ")", "\n", "\n", "", "self", ".", "_classification_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "self", ".", "_classifier_input_dim", ",", "self", ".", "_num_labels", ")", "\n", "self", ".", "_accuracy", "=", "CategoricalAccuracy", "(", ")", "\n", "self", ".", "_f1", "=", "F1Measure", "(", "positive_label", "=", "0", ")", "\n", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "if", "initializer", "is", "not", "None", ":", "\n", "            ", "initializer", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.models.qa_nli_model.QaNliClassifier.forward": [[107, 164], ["qa_nli_model.QaNliClassifier._text_field_embedder", "allennlp.nn.util.get_text_field_mask", "qa_nli_model.QaNliClassifier._seq2vec_encoder", "qa_nli_model.QaNliClassifier._classification_layer", "torch.nn.functional.softmax", "qa_nli_model.QaNliClassifier.make_output_human_readable", "qa_nli_model.QaNliClassifier._seq2seq_encoder", "qa_nli_model.QaNliClassifier._dropout", "torch.unsqueeze", "torch.cat", "qa_nli_model.QaNliClassifier._feedforward", "allennlp.nn.util.get_token_ids_from_text_field_tensors", "qa_nli_model.QaNliClassifier._loss", "qa_nli_model.QaNliClassifier._accuracy", "qa_nli_model.QaNliClassifier._f1", "label.long().view", "label.long"], "methods", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.models.qa_nli_model.QaNliClassifier.make_output_human_readable"], ["", "", "def", "forward", "(", "# type: ignore", "\n", "self", ",", "\n", "tokens", ":", "TextFieldTensors", ",", "\n", "label", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "answer_scores", ":", "torch", ".", "FloatTensor", "=", "None", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "\n", "        ", "\"\"\"\n        # Parameters\n        tokens : `TextFieldTensors`\n            From a `TextField`\n        label : `torch.IntTensor`, optional (default = `None`)\n            From a `LabelField`\n        # Returns\n        An output dictionary consisting of:\n            - `logits` (`torch.FloatTensor`) :\n                A tensor of shape `(batch_size, num_labels)` representing\n                unnormalized log probabilities of the label.\n            - `probs` (`torch.FloatTensor`) :\n                A tensor of shape `(batch_size, num_labels)` representing\n                probabilities of the label.\n            - `loss` : (`torch.FloatTensor`, optional) :\n                A scalar loss to be optimised.\n        \"\"\"", "\n", "\n", "embedded_text", "=", "self", ".", "_text_field_embedder", "(", "tokens", ")", "\n", "mask", "=", "get_text_field_mask", "(", "tokens", ")", "\n", "if", "self", ".", "_seq2seq_encoder", ":", "\n", "            ", "embedded_text", "=", "self", ".", "_seq2seq_encoder", "(", "embedded_text", ",", "mask", "=", "mask", ")", "\n", "\n", "", "embedded_text", "=", "self", ".", "_seq2vec_encoder", "(", "embedded_text", ",", "mask", "=", "mask", ")", "\n", "\n", "if", "self", ".", "_dropout", ":", "\n", "            ", "embedded_text", "=", "self", ".", "_dropout", "(", "embedded_text", ")", "\n", "\n", "", "if", "self", ".", "_use_answer_score", ":", "\n", "            ", "answer_scores", "=", "torch", ".", "unsqueeze", "(", "answer_scores", ",", "1", ")", "\n", "embedded_text", "=", "torch", ".", "cat", "(", "[", "embedded_text", ",", "answer_scores", "]", ",", "\n", "dim", "=", "-", "1", ")", "\n", "\n", "", "if", "self", ".", "_feedforward", "is", "not", "None", ":", "\n", "            ", "embedded_text", "=", "self", ".", "_feedforward", "(", "embedded_text", ")", "\n", "\n", "", "logits", "=", "self", ".", "_classification_layer", "(", "embedded_text", ")", "\n", "probs", "=", "torch", ".", "nn", ".", "functional", ".", "softmax", "(", "logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "output_dict", "=", "{", "\"logits\"", ":", "logits", ",", "\"probs\"", ":", "probs", ",", "\n", "\"token_ids\"", ":", "util", ".", "get_token_ids_from_text_field_tensors", "(", "\n", "tokens", ")", "}", "\n", "self", ".", "make_output_human_readable", "(", "output_dict", ")", "\n", "if", "label", "is", "not", "None", ":", "\n", "            ", "loss", "=", "self", ".", "_loss", "(", "logits", ",", "label", ".", "long", "(", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "output_dict", "[", "\"loss\"", "]", "=", "loss", "\n", "self", ".", "_accuracy", "(", "logits", ",", "label", ")", "\n", "self", ".", "_f1", "(", "logits", ",", "label", ")", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.models.qa_nli_model.QaNliClassifier.make_output_human_readable": [[165, 196], ["predictions.dim", "prediction.argmax().item", "qa_nli_model.QaNliClassifier.vocab.get_index_to_token_vocabulary().get", "classes.append", "tokens.append", "str", "range", "prediction.argmax", "qa_nli_model.QaNliClassifier.vocab.get_index_to_token_vocabulary", "qa_nli_model.QaNliClassifier.vocab.get_token_from_index", "token_id.item"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "make_output_human_readable", "(", "\n", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", "\n", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Does a simple argmax over the probabilities, converts index to string label, and\n        add `\"label\"` key to the dictionary with the result.\n        \"\"\"", "\n", "predictions", "=", "output_dict", "[", "\"probs\"", "]", "\n", "if", "predictions", ".", "dim", "(", ")", "==", "2", ":", "\n", "            ", "predictions_list", "=", "[", "predictions", "[", "i", "]", "for", "i", "in", "range", "(", "predictions", ".", "shape", "[", "0", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "predictions_list", "=", "[", "predictions", "]", "\n", "", "classes", "=", "[", "]", "\n", "for", "prediction", "in", "predictions_list", ":", "\n", "            ", "label_idx", "=", "prediction", ".", "argmax", "(", "dim", "=", "-", "1", ")", ".", "item", "(", ")", "\n", "label_str", "=", "self", ".", "vocab", ".", "get_index_to_token_vocabulary", "(", "self", ".", "_label_namespace", ")", ".", "get", "(", "\n", "label_idx", ",", "str", "(", "label_idx", ")", "\n", ")", "\n", "classes", ".", "append", "(", "label_str", ")", "\n", "", "output_dict", "[", "\"label\"", "]", "=", "classes", "\n", "tokens", "=", "[", "]", "\n", "for", "instance_tokens", "in", "output_dict", "[", "\"token_ids\"", "]", ":", "\n", "            ", "tokens", ".", "append", "(", "\n", "[", "\n", "self", ".", "vocab", ".", "get_token_from_index", "(", "token_id", ".", "item", "(", ")", ",", "namespace", "=", "self", ".", "_namespace", ")", "\n", "for", "token_id", "in", "instance_tokens", "\n", "]", "\n", ")", "\n", "", "output_dict", "[", "\"tokens\"", "]", "=", "tokens", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.models.qa_nli_model.QaNliClassifier.get_metrics": [[197, 205], ["qa_nli_model.QaNliClassifier._accuracy.get_metric", "qa_nli_model.QaNliClassifier._f1.get_metric"], "methods", ["None"], ["", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "acc", "=", "self", ".", "_accuracy", ".", "get_metric", "(", "reset", ")", "\n", "f1_metric", "=", "self", ".", "_f1", ".", "get_metric", "(", "reset", ")", "\n", "metrics", "=", "{", "\"accuracy\"", ":", "acc", ",", "\n", "\"precision\"", ":", "f1_metric", "[", "'precision'", "]", ",", "\n", "\"recall\"", ":", "f1_metric", "[", "'recall'", "]", ",", "\n", "\"f1\"", ":", "f1_metric", "[", "'f1'", "]", "}", "\n", "return", "metrics", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.scripts.run_qa_nli.write_to_csv_file": [[63, 77], ["open", "csv.writer", "csv.writer.writerow", "zip", "predictor.predict", "csv.writer.writerow"], "function", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.mnli_predictor.MNliPredictor.predict"], ["def", "write_to_csv_file", "(", "raw_questions", ":", "List", "[", "Text", "]", ",", "parsed_questions", ":", "List", "[", "Text", "]", ",", "\n", "selected_sents", ":", "List", "[", "Text", "]", ",", "predictor", ")", ":", "\n", "    ", "csv_file", "=", "open", "(", "FLAGS", ".", "output_csv_path", ",", "'w'", ",", "newline", "=", "''", ")", "\n", "csv_writer", "=", "csv", ".", "writer", "(", "csv_file", ",", "delimiter", "=", "','", ")", "\n", "csv_writer", ".", "writerow", "(", "csv_fileds", ")", "\n", "for", "rq", ",", "pq", ",", "sent", "in", "zip", "(", "\n", "raw_questions", ",", "\n", "parsed_questions", ",", "\n", "selected_sents", ")", ":", "\n", "        ", "result", "=", "predictor", ".", "predict", "(", "\n", "hypothesis", "=", "pq", ",", "\n", "premise", "=", "sent", "\n", ")", "\n", "csv_writer", ".", "writerow", "(", "[", "rq", ",", "pq", ",", "sent", ",", "result", "[", "'label'", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.scripts.run_qa_nli.main": [[79, 218], ["allennlp.common.util.import_module_and_submodules", "absl.logging.info", "print", "allennlp.predictors.predictor.Predictor.from_path", "open", "csv.writer", "csv.writer.writerow", "set", "print", "answer_status.sort", "raw_answer_status.sort", "open", "tqdm.tqdm", "csv.writer.writerow", "json.loads", "set.add", "premises.append", "hypothesises.append", "examples.append", "answer_scores.append", "open", "hypothesises.append", "zip", "json.dump", "fout.write", "Predictor.from_path.predict_batch", "answer_status.append", "csv_data.append", "raw_answer_status.append", "predicted_examples.append", "gold_labels.append", "Predictor.from_path.predict", "json.loads.keys", "json.loads.keys", "predictions.append", "predictions.append"], "function", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.qa_nli_predictor.QaNliPredictor.predict_batch", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.mnli_predictor.MNliPredictor.predict"], ["", "", "def", "main", "(", "_", ")", ":", "\n", "    ", "import_module_and_submodules", "(", "\"src\"", ")", "\n", "file_path", "=", "FLAGS", ".", "qa_nli_path", "\n", "logging", ".", "info", "(", "\"reading data from {} ...\"", ".", "format", "(", "file_path", ")", ")", "\n", "print", "(", "FLAGS", ".", "predictor_name", ")", "\n", "predictor", "=", "Predictor", ".", "from_path", "(", "\n", "FLAGS", ".", "entailment_model_path", ",", "\n", "FLAGS", ".", "predictor_name", ")", "\n", "\n", "csv_file", "=", "open", "(", "FLAGS", ".", "output_csv_path", ",", "'w'", ",", "newline", "=", "''", ")", "\n", "csv_writer", "=", "csv", ".", "writer", "(", "csv_file", ",", "delimiter", "=", "','", ")", "\n", "csv_writer", ".", "writerow", "(", "csv_fileds", ")", "\n", "answer_status", "=", "[", "]", "\n", "raw_answer_status", "=", "[", "]", "\n", "unique_ids", "=", "set", "(", ")", "\n", "predictions", "=", "[", "]", "\n", "gold_labels", "=", "[", "]", "\n", "predicted_examples", "=", "[", "]", "\n", "csv_data", "=", "[", "]", "\n", "print", "(", "\"reading file ..................\"", ")", "\n", "with", "open", "(", "file_path", ")", "as", "fin", ":", "\n", "        ", "premises", "=", "[", "]", "\n", "hypothesises", "=", "[", "]", "\n", "examples", "=", "[", "]", "\n", "answer_scores", "=", "[", "]", "\n", "instance_count", "=", "0", "\n", "for", "line", "in", "tqdm", "(", "fin", ")", ":", "\n", "            ", "example", "=", "json", ".", "loads", "(", "line", ")", "\n", "if", "example", "[", "'example_id'", "]", "in", "unique_ids", ":", "\n", "                ", "continue", "\n", "", "unique_ids", ".", "add", "(", "example", "[", "'example_id'", "]", ")", "\n", "if", "FLAGS", ".", "use_full_context", ":", "\n", "                ", "premise", "=", "example", "[", "'paragraph_text'", "]", "\n", "", "else", ":", "\n", "                ", "if", "FLAGS", ".", "use_decontext", ":", "\n", "                    ", "premise", "=", "example", "[", "'decontext_answer_sent_text'", "]", "\n", "", "else", ":", "\n", "                    ", "premise", "=", "example", "[", "'answer_sent_text'", "]", "\n", "\n", "", "", "premises", ".", "append", "(", "premise", ")", "\n", "if", "FLAGS", ".", "use_qa_concat", ":", "\n", "                ", "hypothesises", ".", "append", "(", "\"{} </s> {}\"", ".", "format", "(", "\n", "example", "[", "'question_text'", "]", ",", "\n", "example", "[", "'answer_text'", "]", "\n", ")", ")", "\n", "\n", "", "hypothesises", ".", "append", "(", "example", "[", "'question_statement_text'", "]", ")", "\n", "examples", ".", "append", "(", "example", ")", "\n", "answer_scores", ".", "append", "(", "example", "[", "'answer_score'", "]", ")", "\n", "instance_count", "+=", "1", "\n", "\n", "if", "instance_count", "==", "FLAGS", ".", "batch_size", ":", "\n", "                ", "if", "FLAGS", ".", "predictor_name", "==", "'textual_entailment'", ":", "\n", "                    ", "results", "=", "[", "predictor", ".", "predict", "(", "\n", "premise", "=", "premises", "[", "0", "]", ",", "\n", "hypothesis", "=", "hypothesises", "[", "0", "]", "\n", ")", "]", "\n", "", "else", ":", "\n", "                    ", "results", "=", "predictor", ".", "predict_batch", "(", "\n", "premises", "=", "premises", ",", "\n", "hypothesises", "=", "hypothesises", ",", "\n", "answer_scores", "=", "answer_scores", "if", "FLAGS", ".", "use_answer_score", "else", "None", "\n", ")", "\n", "", "for", "result", ",", "example", "in", "zip", "(", "results", ",", "examples", ")", ":", "\n", "                    ", "if", "not", "result", ":", "\n", "                        ", "continue", "\n", "", "if", "'f1'", "in", "example", ".", "keys", "(", ")", ":", "\n", "                        ", "f1", "=", "example", "[", "'f1'", "]", "if", "example", "[", "'f1'", "]", "else", "0", "\n", "is_correct", "=", "True", "if", "f1", ">=", "FLAGS", ".", "f1_threshold", "else", "False", "\n", "", "else", ":", "\n", "                        ", "is_correct", "=", "example", "[", "'is_correct'", "]", "\n", "\n", "", "answer_status", ".", "append", "(", "[", "example", "[", "'has_gold'", "]", ",", "\n", "True", ",", "\n", "is_correct", ",", "\n", "result", "[", "'logits'", "]", "[", "0", "]", "]", "\n", ")", "\n", "\n", "if", "'gold_answers'", "in", "example", ".", "keys", "(", ")", ":", "\n", "                        ", "gold_answers", "=", "' | '", ".", "join", "(", "example", "[", "'gold_answers'", "]", ")", "\n", "", "else", ":", "\n", "                        ", "gold_answers", "=", "''", "\n", "\n", "", "csv_data", ".", "append", "(", "\n", "[", "\n", "example", "[", "'question_text'", "]", ",", "\n", "example", "[", "'question_statement_text'", "]", ",", "\n", "example", "[", "'answer_sent_text'", "]", ",", "\n", "example", "[", "'decontext_answer_sent_text'", "]", ",", "\n", "example", "[", "'paragraph_text'", "]", ",", "\n", "example", "[", "'answer_text'", "]", ",", "\n", "gold_answers", ",", "\n", "result", "[", "'label'", "]", ",", "\n", "is_correct", ",", "\n", "example", "[", "'has_gold'", "]", ",", "\n", "result", "[", "'logits'", "]", "[", "0", "]", "\n", "]", "\n", ")", "\n", "\n", "raw_answer_status", ".", "append", "(", "[", "example", "[", "'has_gold'", "]", ",", "\n", "True", ",", "\n", "is_correct", ",", "\n", "example", "[", "'answer_score'", "]", "]", "\n", ")", "\n", "\n", "example", "[", "'label'", "]", "=", "result", "[", "'label'", "]", "\n", "example", "[", "'confidence_score'", "]", "=", "result", "[", "'logits'", "]", "[", "0", "]", "\n", "predicted_examples", ".", "append", "(", "example", ")", "\n", "\n", "if", "result", "[", "'label'", "]", "==", "'entailment'", "or", "result", "[", "'label'", "]", "==", "'entail'", ":", "\n", "                        ", "predictions", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                        ", "predictions", ".", "append", "(", "0", ")", "\n", "", "gold_label", "=", "1", "if", "is_correct", "else", "0", "\n", "gold_labels", ".", "append", "(", "gold_label", ")", "\n", "\n", "", "premises", "=", "[", "]", "\n", "hypothesises", "=", "[", "]", "\n", "examples", "=", "[", "]", "\n", "instance_count", "=", "0", "\n", "\n", "# p = precision_score(gold_labels, predictions)", "\n", "# r = recall_score(gold_labels, predictions)", "\n", "# f1 = f1_score(gold_labels, predictions)", "\n", "# print('Precision:', p)", "\n", "# print('Recall:', r)", "\n", "# print('f1:', f1)", "\n", "\n", "# csv_data.sort(key=lambda x: x[-1], reverse=True)", "\n", "", "", "", "for", "row", "in", "csv_data", ":", "\n", "        ", "csv_writer", ".", "writerow", "(", "row", ")", "\n", "", "answer_status", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "raw_answer_status", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "-", "1", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "if", "FLAGS", ".", "output_json_path", "is", "not", "None", ":", "\n", "        ", "with", "open", "(", "FLAGS", ".", "output_json_path", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "example", "in", "predicted_examples", ":", "\n", "                ", "json", ".", "dump", "(", "example", ",", "fout", ")", "\n", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.seq2seq_converter.DataTrainingArguments.__post_init__": [[210, 226], ["ValueError"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "dataset_name", "is", "None", "and", "self", ".", "train_file", "is", "None", "and", "self", ".", "validation_file", "is", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"Need either a dataset name or a training/validation file.\"", ")", "\n", "# else:", "\n", "#     if self.train_file is not None:", "\n", "#         extension = self.train_file.split(\".\")[-1]", "\n", "#         assert extension in [\"csv\", \"json\", \"jsonl\"], \"`train_file` should be a csv or a json file.\"", "\n", "#     if self.validation_file is not None:", "\n", "#         extension = self.validation_file.split(\".\")[-1]", "\n", "#         assert extension in [\"csv\", \"json\", \"jsonl\"], \"`validation_file` should be a csv or a json file.\"", "\n", "# if not self.task.startswith(\"decontext\") and not self.task.startswith(\"question_convert\"):", "\n", "#     raise ValueError(", "\n", "#         \"`task` should be decontext or question convert\"", "\n", "#     )", "\n", "", "if", "self", ".", "val_max_target_length", "is", "None", ":", "\n", "            ", "self", ".", "val_max_target_length", "=", "self", ".", "max_target_length", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.seq2seq_converter.main": [[243, 638], ["transformers.HfArgumentParser", "logging.basicConfig", "logger.setLevel", "logger.warning", "transformers.trainer_utils.is_main_process", "logger.info", "transformers.set_seed", "transformers.AutoConfig.from_pretrained", "transformers.AutoTokenizer.from_pretrained", "transformers.AutoModelForSeq2SeqLM.from_pretrained", "print", "datasets.load_metric", "sys.argv[].endswith", "transformers.HfArgumentParser.parse_json_file", "transformers.HfArgumentParser.parse_args_into_dataclasses", "print", "print", "print", "os.path.isdir", "transformers.trainer_utils.get_last_checkpoint", "transformers.utils.logging.set_verbosity_info", "datasets.load_dataset", "datasets.load_dataset", "datasets.load_dataset", "isinstance", "ValueError", "data_args.task.startswith", "AutoTokenizer.from_pretrained.", "print", "train_dataset.select.map", "eval_dataset.select.map", "raw_prediction_dataset.select.map", "transformers.DataCollatorForSeq2Seq", "data_args.task.startswith", "isinstance", "AutoTokenizer.from_pretrained.batch_decode", "AutoTokenizer.from_pretrained.batch_decode", "datasets.load_metric.compute", "numpy.mean", "transformers.Seq2SeqTrainer", "transformers.Seq2SeqTrainer.train", "transformers.Seq2SeqTrainer.save_model", "os.path.join", "transformers.Seq2SeqTrainer.is_world_process_zero", "logger.info", "transformers.Seq2SeqTrainer.evaluate", "os.path.join", "transformers.Seq2SeqTrainer.is_world_process_zero", "logger.info", "transformers.Seq2SeqTrainer.predict", "AutoTokenizer.from_pretrained.batch_decode", "data_args.task.startswith", "data_args.task.startswith", "data_args.task.startswith", "len", "ValueError", "transformers.trainer_utils.is_main_process", "data_args.train_file.split", "extension.startswith", "data_args.validation_file.split", "extension.startswith", "data_args.prediction_file.split", "extension.startswith", "bool", "data_args.task.startswith", "AutoTokenizer.from_pretrained.as_target_tokenizer", "AutoTokenizer.from_pretrained.", "train_dataset.select.select", "eval_dataset.select.select", "datasets.load_dataset.select", "numpy.where", "pred.strip", "label.strip", "numpy.count_nonzero", "transformers.Seq2SeqTrainer", "os.path.isdir", "transformers.Seq2SeqTrainer.state.save_to_json", "write_decontext_predictions_out", "write_question_converter_predictions_out", "write_esnli_predictions_out", "os.path.abspath", "len", "logger.info", "logging.StreamHandler", "process_decontext_qanli", "process_decontext_train_and_dev", "range", "range", "range", "pred.split", "open", "logger.info", "sorted", "os.path.join", "open", "logger.info", "sorted", "os.listdir", "bool", "process_question_converter_qanli", "process_question_converter_train_and_dev", "process_esnli_qanli", "process_esnli_train_and_dev", "label.split", "metric.compute.items", "trainer.train.metrics.items", "logger.info", "writer.write", "trainer.predict.items", "logger.info", "writer.write"], "function", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.predictors.mnli_predictor.MNliPredictor.predict", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.write_decontext_predictions_out", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.write_question_converter_predictions_out", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.write_esnli_predictions_out", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_decontext_qanli", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_decontext_train_and_dev", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_question_converter_qanli", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_question_converter_train_and_dev", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_esnli_qanli", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_esnli_train_and_dev"], ["def", "main", "(", ")", ":", "\n", "# See all possible arguments in src/transformers/training_args.py", "\n", "# or by passing the --help flag to this script.", "\n", "# We now keep distinct sets of args, for a cleaner separation of concerns.", "\n", "\n", "    ", "parser", "=", "HfArgumentParser", "(", "(", "ModelArguments", ",", "DataTrainingArguments", ",", "Seq2SeqTrainingArguments", ")", ")", "\n", "if", "len", "(", "sys", ".", "argv", ")", "==", "2", "and", "sys", ".", "argv", "[", "1", "]", ".", "endswith", "(", "\".json\"", ")", ":", "\n", "# If we pass only one argument to the script and it's the path to a json file,", "\n", "# let's parse it to get our arguments.", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_json_file", "(", "json_file", "=", "os", ".", "path", ".", "abspath", "(", "sys", ".", "argv", "[", "1", "]", ")", ")", "\n", "", "else", ":", "\n", "        ", "model_args", ",", "data_args", ",", "training_args", "=", "parser", ".", "parse_args_into_dataclasses", "(", ")", "\n", "print", "(", "model_args", ")", "\n", "print", "(", "data_args", ")", "\n", "print", "(", "training_args", ")", "\n", "# Detecting last checkpoint.", "\n", "", "last_checkpoint", "=", "None", "\n", "if", "os", ".", "path", ".", "isdir", "(", "training_args", ".", "output_dir", ")", "and", "training_args", ".", "do_train", "and", "not", "training_args", ".", "overwrite_output_dir", ":", "\n", "        ", "last_checkpoint", "=", "get_last_checkpoint", "(", "training_args", ".", "output_dir", ")", "\n", "if", "last_checkpoint", "is", "None", "and", "len", "(", "os", ".", "listdir", "(", "training_args", ".", "output_dir", ")", ")", ">", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "f\"Output directory ({training_args.output_dir}) already exists and is not empty. \"", "\n", "\"Use --overwrite_output_dir to overcome.\"", "\n", ")", "\n", "", "elif", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Checkpoint detected, resuming training at {last_checkpoint}. To avoid this behavior, change \"", "\n", "\"the `--output_dir` or add `--overwrite_output_dir` to train from scratch.\"", "\n", ")", "\n", "\n", "# Setup logging", "\n", "", "", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "handlers", "=", "[", "logging", ".", "StreamHandler", "(", "sys", ".", "stdout", ")", "]", ",", "\n", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", "else", "logging", ".", "WARN", ")", "\n", "\n", "# Log on each process the small summary:", "\n", "logger", ".", "warning", "(", "\n", "f\"Process rank: {training_args.local_rank}, device: {training_args.device}, n_gpu: {training_args.n_gpu}\"", "\n", "+", "f\"distributed training: {bool(training_args.local_rank != -1)}, 16-bits training: {training_args.fp16}\"", "\n", ")", "\n", "# Set the verbosity to info of the Transformers logger (on main process only):", "\n", "if", "is_main_process", "(", "training_args", ".", "local_rank", ")", ":", "\n", "        ", "transformers", ".", "utils", ".", "logging", ".", "set_verbosity_info", "(", ")", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "training_args", ")", "\n", "\n", "# Set seed before initializing model.", "\n", "set_seed", "(", "training_args", ".", "seed", ")", "\n", "\n", "# Get the datasets: you can either provide your own CSV/JSON training and evaluation files (see below)", "\n", "# or just provide the name of one of the public datasets available on the hub at https://huggingface.co/datasets/", "\n", "# (the dataset will be downloaded automatically from the datasets Hub).", "\n", "#", "\n", "# For CSV/JSON files in the summarization task, this script will use the first column for the full texts and the", "\n", "# second column for the summaries (unless you specify column names for this with the `text_column` and", "\n", "# `summary_column` arguments).", "\n", "# For translation, only JSON files are supported, with one field named \"translation\" containing two keys for the", "\n", "# source and target languages (unless you adapt what follows).", "\n", "#", "\n", "# In distributed training, the load_dataset function guarantee that only one local process can concurrently", "\n", "# download the dataset.", "\n", "\n", "data_files", "=", "{", "}", "\n", "if", "data_args", ".", "train_file", "is", "not", "None", ":", "\n", "        ", "extension", "=", "data_args", ".", "train_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "not", "extension", ".", "startswith", "(", "'csv'", ")", ":", "\n", "            ", "extension", "=", "'json'", "\n", "", "train_dataset", "=", "load_dataset", "(", "extension", ",", "\n", "data_files", "=", "data_args", ".", "train_file", ",", "\n", "split", "=", "\"train\"", ")", "\n", "\n", "", "if", "data_args", ".", "validation_file", "is", "not", "None", ":", "\n", "        ", "extension", "=", "data_args", ".", "validation_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "not", "extension", ".", "startswith", "(", "'csv'", ")", ":", "\n", "            ", "extension", "=", "'json'", "\n", "", "eval_dataset", "=", "load_dataset", "(", "extension", ",", "\n", "data_files", "=", "data_args", ".", "validation_file", ",", "\n", "split", "=", "\"train\"", ")", "\n", "\n", "", "if", "data_args", ".", "prediction_file", "is", "not", "None", ":", "\n", "        ", "extension", "=", "data_args", ".", "prediction_file", ".", "split", "(", "\".\"", ")", "[", "-", "1", "]", "\n", "if", "not", "extension", ".", "startswith", "(", "'csv'", ")", ":", "\n", "            ", "extension", "=", "'json'", "\n", "# print(extension)", "\n", "# input()", "\n", "", "raw_prediction_dataset", "=", "load_dataset", "(", "\n", "extension", ",", "\n", "data_files", "=", "data_args", ".", "prediction_file", ",", "\n", "split", "=", "\"train\"", "\n", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "#", "\n", "# Distributed training:", "\n", "# The .from_pretrained methods guarantee that only one local process can concurrently", "\n", "# download model & vocab.", "\n", "", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "\n", "model_args", ".", "config_name", "if", "model_args", ".", "config_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "# additional_tokens = ['<ans>, </ans>']", "\n", "# for i in range(150):", "\n", "#     additional_tokens.append('<extra_id_{}>'.format(i))", "\n", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\n", "model_args", ".", "tokenizer_name", "if", "model_args", ".", "tokenizer_name", "else", "model_args", ".", "model_name_or_path", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "use_fast", "=", "model_args", ".", "use_fast_tokenizer", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "model", "=", "AutoModelForSeq2SeqLM", ".", "from_pretrained", "(", "\n", "model_args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "model_args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "model_args", ".", "cache_dir", ",", "\n", "revision", "=", "model_args", ".", "model_revision", ",", "\n", "use_auth_token", "=", "True", "if", "model_args", ".", "use_auth_token", "else", "None", ",", "\n", ")", "\n", "\n", "# Set decoder_start_token_id", "\n", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", "and", "isinstance", "(", "tokenizer", ",", "MBartTokenizer", ")", ":", "\n", "        ", "model", ".", "config", ".", "decoder_start_token_id", "=", "tokenizer", ".", "lang_code_to_id", "[", "data_args", ".", "target_lang", "]", "\n", "", "if", "model", ".", "config", ".", "decoder_start_token_id", "is", "None", ":", "\n", "        ", "raise", "ValueError", "(", "\"Make sure that `config.decoder_start_token_id` is correctly defined\"", ")", "\n", "", "print", "(", "'decoder start token id:'", ",", "model", ".", "config", ".", "decoder_start_token_id", ")", "\n", "# Get the default prefix if None is passed.", "\n", "# if data_args.source_prefix is None:", "\n", "#     task_specific_params = model.config.task_specific_params", "\n", "#     if task_specific_params is not None:", "\n", "#         prefix = task_specific_params.get(\"prefix\", \"\")", "\n", "#     else:", "\n", "#         prefix = \"\"", "\n", "# else:", "\n", "#     prefix = data_args.source_prefix", "\n", "\n", "# To serialize preprocess_function below, each of those four variables needs to be defined (even if we won't use", "\n", "# them all).", "\n", "# Temporarily set max_target_length for training.", "\n", "max_target_length", "=", "data_args", ".", "max_target_length", "\n", "padding", "=", "\"max_length\"", "if", "data_args", ".", "pad_to_max_length", "else", "False", "\n", "\n", "def", "preprocess_function", "(", "examples", ")", ":", "\n", "        ", "inputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "if", "data_args", ".", "task", ".", "startswith", "(", "\"decontext\"", ")", ":", "\n", "            ", "if", "data_args", ".", "data_source", "==", "\"qa-nli\"", ":", "\n", "                ", "inputs", ",", "targets", "=", "process_decontext_qanli", "(", "examples", ")", "\n", "", "else", ":", "\n", "                ", "inputs", ",", "targets", "=", "process_decontext_train_and_dev", "(", "examples", ")", "\n", "", "", "elif", "data_args", ".", "task", ".", "startswith", "(", "\"question_convert\"", ")", ":", "\n", "# ensure both questions and answers are not none", "\n", "            ", "if", "data_args", ".", "data_source", "==", "'qa-nli'", ":", "\n", "                ", "inputs", ",", "targets", "=", "process_question_converter_qanli", "(", "examples", ")", "\n", "", "else", ":", "\n", "                ", "inputs", ",", "targets", "=", "process_question_converter_train_and_dev", "(", "examples", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "data_args", ".", "data_source", "==", "'qa-nli'", ":", "\n", "                ", "inputs", ",", "targets", "=", "process_esnli_qanli", "(", "examples", ")", "\n", "", "else", ":", "\n", "                ", "inputs", ",", "targets", "=", "process_esnli_train_and_dev", "(", "examples", ")", "\n", "\n", "# for ipt, tgt in zip(inputs, targets):", "\n", "#     print(ipt)", "\n", "#     print(tgt)", "\n", "\n", "", "", "model_inputs", "=", "tokenizer", "(", "text", "=", "inputs", ",", "\n", "max_length", "=", "data_args", ".", "max_source_length", ",", "\n", "padding", "=", "padding", ",", "\n", "truncation", "=", "True", ",", "\n", "add_special_tokens", "=", "True", "\n", ")", "\n", "\n", "# Setup the tokenizer for targets", "\n", "with", "tokenizer", ".", "as_target_tokenizer", "(", ")", ":", "\n", "            ", "labels", "=", "tokenizer", "(", "targets", ",", "\n", "max_length", "=", "max_target_length", ",", "\n", "padding", "=", "padding", ",", "\n", "truncation", "=", "True", "\n", ")", "\n", "# print(labels)", "\n", "# decoded_labels = tokenizer.batch_decode(labels.input_ids,", "\n", "#                                         skip_special_tokens=False)", "\n", "# print(decoded_labels)", "\n", "# input()", "\n", "# If we are padding here, replace all tokenizer.pad_token_id in the labels by -100 when we want to ignore", "\n", "# padding in the loss.", "\n", "", "if", "padding", "==", "\"max_length\"", "and", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "            ", "labels", "[", "\"input_ids\"", "]", "=", "[", "\n", "[", "(", "l", "if", "l", "!=", "tokenizer", ".", "pad_token_id", "else", "-", "100", ")", "for", "l", "in", "label", "]", "\n", "for", "label", "in", "labels", "[", "\"input_ids\"", "]", "\n", "]", "\n", "", "model_inputs", "[", "\"labels\"", "]", "=", "labels", "[", "\"input_ids\"", "]", "\n", "return", "model_inputs", "\n", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "# train_dataset = datasets[\"train\"]", "\n", "        ", "column_names", "=", "train_dataset", ".", "column_names", "\n", "if", "data_args", ".", "max_train_samples", "is", "not", "None", ":", "\n", "            ", "train_dataset", "=", "train_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_train_samples", ")", ")", "\n", "", "print", "(", "\"training data features:\"", ",", "train_dataset", ")", "\n", "train_dataset", "=", "train_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "max_target_length", "=", "data_args", ".", "val_max_target_length", "\n", "column_names", "=", "eval_dataset", ".", "column_names", "\n", "# eval_dataset = datasets[\"validation\"]", "\n", "if", "data_args", ".", "max_val_samples", "is", "not", "None", ":", "\n", "            ", "eval_dataset", "=", "eval_dataset", ".", "select", "(", "range", "(", "data_args", ".", "max_val_samples", ")", ")", "\n", "", "eval_dataset", "=", "eval_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", ")", "\n", "\n", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "max_target_length", "=", "data_args", ".", "val_max_target_length", "\n", "column_names", "=", "raw_prediction_dataset", ".", "column_names", "\n", "if", "data_args", ".", "max_val_samples", "is", "not", "None", ":", "\n", "            ", "prediction_dataset", "=", "raw_prediction_dataset", ".", "select", "(", "\n", "range", "(", "data_args", ".", "max_val_samples", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "prediction_dataset", "=", "raw_prediction_dataset", "\n", "\n", "", "prediction_dataset", "=", "prediction_dataset", ".", "map", "(", "\n", "preprocess_function", ",", "\n", "batched", "=", "True", ",", "\n", "num_proc", "=", "data_args", ".", "preprocessing_num_workers", ",", "\n", "remove_columns", "=", "column_names", ",", "\n", "load_from_cache_file", "=", "not", "data_args", ".", "overwrite_cache", ",", "\n", "batch_size", "=", "1000", "\n", ")", "\n", "\n", "# Data collator", "\n", "", "label_pad_token_id", "=", "-", "100", "if", "data_args", ".", "ignore_pad_token_for_loss", "else", "tokenizer", ".", "pad_token_id", "\n", "if", "data_args", ".", "pad_to_max_length", ":", "\n", "        ", "data_collator", "=", "default_data_collator", "\n", "", "else", ":", "\n", "        ", "data_collator", "=", "DataCollatorForSeq2Seq", "(", "\n", "tokenizer", ",", "\n", "label_pad_token_id", "=", "label_pad_token_id", ",", "\n", "pad_to_multiple_of", "=", "8", "if", "training_args", ".", "fp16", "else", "None", ",", "\n", ")", "\n", "\n", "# Metric", "\n", "", "metric_name", "=", "\"bleu\"", "if", "data_args", ".", "task", ".", "startswith", "(", "\"question_convert\"", ")", "else", "\"rouge\"", "\n", "metric", "=", "load_metric", "(", "metric_name", ")", "\n", "\n", "def", "compute_metrics", "(", "eval_preds", ")", ":", "\n", "        ", "preds", ",", "labels", "=", "eval_preds", "\n", "if", "isinstance", "(", "preds", ",", "tuple", ")", ":", "\n", "            ", "preds", "=", "preds", "[", "0", "]", "\n", "", "decoded_preds", "=", "tokenizer", ".", "batch_decode", "(", "preds", ",", "skip_special_tokens", "=", "True", ")", "\n", "if", "data_args", ".", "ignore_pad_token_for_loss", ":", "\n", "# Replace -100 in the labels as we can't decode them.", "\n", "            ", "labels", "=", "np", ".", "where", "(", "labels", "!=", "-", "100", ",", "labels", ",", "tokenizer", ".", "pad_token_id", ")", "\n", "", "decoded_labels", "=", "tokenizer", ".", "batch_decode", "(", "labels", ",", "skip_special_tokens", "=", "True", ")", "\n", "\n", "# Some simple post-processing", "\n", "decoded_preds", "=", "[", "pred", ".", "strip", "(", ")", "for", "pred", "in", "decoded_preds", "]", "\n", "decoded_labels", "=", "[", "label", ".", "strip", "(", ")", "for", "label", "in", "decoded_labels", "]", "\n", "\n", "if", "metric_name", "==", "\"bleu\"", ":", "\n", "            ", "decoded_labels", "=", "[", "[", "label", ".", "split", "(", ")", "]", "for", "label", "in", "decoded_labels", "]", "\n", "decoded_preds", "=", "[", "pred", ".", "split", "(", ")", "for", "pred", "in", "decoded_preds", "]", "\n", "\n", "# for pred, lable in zip(decoded_preds, decoded_labels):", "\n", "#     print(pred)", "\n", "#     print(lable)", "\n", "#     input()", "\n", "\n", "", "result", "=", "metric", ".", "compute", "(", "predictions", "=", "decoded_preds", ",", "references", "=", "decoded_labels", ")", "\n", "# print(result)", "\n", "# Extract a few results from ROUGE", "\n", "if", "metric_name", "==", "\"rouge\"", ":", "\n", "            ", "result", "=", "{", "key", ":", "value", ".", "mid", ".", "fmeasure", "*", "100", "for", "key", ",", "value", "in", "result", ".", "items", "(", ")", "}", "\n", "", "else", ":", "\n", "            ", "result", "=", "{", "\"bleu\"", ":", "result", "[", "\"bleu\"", "]", "}", "\n", "\n", "", "prediction_lens", "=", "[", "np", ".", "count_nonzero", "(", "pred", "!=", "tokenizer", ".", "pad_token_id", ")", "for", "pred", "in", "preds", "]", "\n", "result", "[", "\"gen_len\"", "]", "=", "np", ".", "mean", "(", "prediction_lens", ")", "\n", "\n", "return", "result", "\n", "\n", "# Initialize our Trainer", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "trainer", "=", "Seq2SeqTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "train_dataset", "if", "training_args", ".", "do_train", "else", "None", ",", "\n", "eval_dataset", "=", "eval_dataset", "if", "training_args", ".", "do_eval", "else", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "compute_metrics", "=", "compute_metrics", "if", "training_args", ".", "predict_with_generate", "else", "None", ",", "\n", ")", "\n", "", "elif", "training_args", ".", "do_predict", ":", "\n", "        ", "trainer", "=", "Seq2SeqTrainer", "(", "\n", "model", "=", "model", ",", "\n", "args", "=", "training_args", ",", "\n", "train_dataset", "=", "None", ",", "\n", "eval_dataset", "=", "None", ",", "\n", "tokenizer", "=", "tokenizer", ",", "\n", "data_collator", "=", "data_collator", ",", "\n", "compute_metrics", "=", "None", "\n", ")", "\n", "\n", "# Training", "\n", "", "if", "training_args", ".", "do_train", ":", "\n", "        ", "if", "last_checkpoint", "is", "not", "None", ":", "\n", "            ", "model_path", "=", "last_checkpoint", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "model_args", ".", "model_name_or_path", ")", ":", "\n", "            ", "model_path", "=", "model_args", ".", "model_name_or_path", "\n", "", "else", ":", "\n", "            ", "model_path", "=", "None", "\n", "", "train_result", "=", "trainer", ".", "train", "(", "model_path", "=", "model_path", ")", "\n", "trainer", ".", "save_model", "(", ")", "# Saves the tokenizer too for easy upload", "\n", "\n", "output_train_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"train_results.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_train_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Train results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "train_result", ".", "metrics", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "# Need to save the state, since Trainer.save_model saves only the tokenizer with the model", "\n", "", "", "trainer", ".", "state", ".", "save_to_json", "(", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"trainer_state.json\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "", "results", "=", "{", "}", "\n", "if", "training_args", ".", "do_eval", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Evaluate ***\"", ")", "\n", "\n", "results", "=", "trainer", ".", "evaluate", "(", "num_beams", "=", "data_args", ".", "beam_size", ",", "\n", "max_length", "=", "data_args", ".", "max_target_length", "\n", ")", "\n", "# predictions = trainer.predict()", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "training_args", ".", "output_dir", ",", "\"eval_results_seq2seq.txt\"", ")", "\n", "if", "trainer", ".", "is_world_process_zero", "(", ")", ":", "\n", "            ", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "logger", ".", "info", "(", "\"***** Eval results *****\"", ")", "\n", "for", "key", ",", "value", "in", "sorted", "(", "results", ".", "items", "(", ")", ")", ":", "\n", "                    ", "logger", ".", "info", "(", "f\"  {key} = {value}\"", ")", "\n", "writer", ".", "write", "(", "f\"{key} = {value}\\n\"", ")", "\n", "\n", "", "", "", "", "if", "training_args", ".", "do_predict", ":", "\n", "        ", "logger", ".", "info", "(", "\"*** Begin prediction ***\"", ")", "\n", "results", "=", "trainer", ".", "predict", "(", "test_dataset", "=", "prediction_dataset", ",", "\n", "num_beams", "=", "data_args", ".", "beam_size", ",", "\n", "max_length", "=", "data_args", ".", "max_target_length", ")", "\n", "predictions", ",", "label_ids", ",", "metrics", "=", "results", "[", "0", "]", ",", "results", "[", "1", "]", ",", "results", "[", "2", "]", "\n", "# print('prediction:', predictions)", "\n", "# print('prediction_dataset:', prediction_dataset)", "\n", "decoded_preds", "=", "tokenizer", ".", "batch_decode", "(", "predictions", ",", "\n", "skip_special_tokens", "=", "True", ")", "\n", "if", "data_args", ".", "task", ".", "startswith", "(", "'decontext'", ")", ":", "\n", "            ", "write_decontext_predictions_out", "(", "raw_prediction_dataset", ",", "\n", "decoded_preds", ",", "\n", "data_args", ".", "output_path", ",", "\n", "output_format", "=", "data_args", ".", "output_format", ",", "\n", "data_source", "=", "data_args", ".", "data_source", ")", "\n", "\n", "", "if", "data_args", ".", "task", ".", "startswith", "(", "'question_convert'", ")", ":", "\n", "            ", "write_question_converter_predictions_out", "(", "\n", "raw_prediction_dataset", ",", "\n", "decoded_preds", ",", "\n", "data_args", ".", "output_path", ",", "\n", "output_format", "=", "data_args", ".", "output_format", ",", "\n", "data_source", "=", "data_args", ".", "data_source", "\n", ")", "\n", "\n", "", "if", "data_args", ".", "task", ".", "startswith", "(", "\"esnli\"", ")", ":", "\n", "            ", "write_esnli_predictions_out", "(", "\n", "raw_prediction_dataset", ",", "\n", "decoded_preds", ",", "\n", "data_args", ".", "output_path", ",", "\n", "output_format", "=", "data_args", ".", "output_format", ",", "\n", "data_source", "=", "data_args", ".", "data_source", "\n", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.seq2seq_converter._mp_fn": [[640, 643], ["seq2seq_converter.main"], "function", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.seq2seq_converter.main"], ["", "def", "_mp_fn", "(", "index", ")", ":", "\n", "# For xla_spawn (TPUs)", "\n", "    ", "main", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.form_decontext_train_input": [[10, 21], ["paragraph_text.replace.replace"], "function", ["None"], ["def", "form_decontext_train_input", "(", "paragraph_text", ":", "Text", ",", "\n", "answer_sentence", ":", "Text", ",", "\n", "page_tile", ":", "Text", "=", "None", "\n", ")", ":", "\n", "    ", "marked_answer_sent", "=", "\"</s> {} </s>\"", ".", "format", "(", "answer_sentence", ")", "\n", "paragraph_text", "=", "paragraph_text", ".", "replace", "(", "\n", "answer_sentence", ",", "\n", "marked_answer_sent", "\n", ")", "\n", "paragraph_text", "=", "\"{} </s> {}\"", ".", "format", "(", "page_tile", ",", "paragraph_text", ")", "\n", "return", "paragraph_text", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.form_decontext_train_output": [[23, 31], ["None"], "function", ["None"], ["", "def", "form_decontext_train_output", "(", "answer_sentence", ":", "Text", ",", "\n", "decontext_sentence", ":", "Text", ",", "\n", "category", ":", "Text", "\n", ")", ":", "\n", "    ", "if", "category", "==", "'DONE'", ":", "\n", "        ", "return", "\"DONE ### {}\"", ".", "format", "(", "decontext_sentence", ")", "\n", "", "else", ":", "\n", "        ", "return", "\"{} ### {}\"", ".", "format", "(", "category", ",", "answer_sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.form_esnil_train_output": [[33, 41], ["None"], "function", ["None"], ["", "", "def", "form_esnil_train_output", "(", "label", ":", "Text", ",", "\n", "spans_text", ":", "List", "[", "Text", "]", ",", "\n", "explanation", ":", "Text", ")", ":", "\n", "    ", "output", "=", "label", "\n", "for", "sp_text", "in", "spans_text", ":", "\n", "        ", "output", "=", "\"{} {} {}\"", ".", "format", "(", "output", ",", "OUTPUT_SEP", ",", "sp_text", ")", "\n", "", "output", "=", "\"{} {} {}\"", ".", "format", "(", "output", ",", "OUTPUT_SEP", ",", "explanation", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.write_decontext_predictions_out": [[43, 78], ["open", "csv.writer", "csv.writer.writerow", "zip", "open", "zip", "csv.writer.writerow", "cat.strip", "json.dump", "fout.write", "pred.split", "sent.strip", "sent.strip"], "function", ["None"], ["", "def", "write_decontext_predictions_out", "(", "dataset", ",", "\n", "predictions", ":", "List", "[", "str", "]", ",", "\n", "output_path", ":", "str", ",", "\n", "output_format", ":", "str", "=", "None", ",", "\n", "data_source", ":", "str", "=", "None", "\n", ")", ":", "\n", "    ", "if", "output_format", "==", "\"csv\"", ":", "\n", "        ", "csv_file", "=", "open", "(", "output_path", ",", "'w'", ",", "newline", "=", "''", ")", "\n", "csv_writer", "=", "csv", ".", "writer", "(", "csv_file", ",", "delimiter", "=", "','", ")", "\n", "if", "data_source", "==", "'qa-nli'", ":", "\n", "            ", "csv_fields", "=", "[", "'example_id'", ",", "'question'", ",", "'question_statement'", ",", "\n", "'answer_sent'", ",", "'decontext_answer_sent'", ",", "'paragraph'", "]", "\n", "csv_writer", ".", "writerow", "(", "csv_fields", ")", "\n", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "csv_writer", ".", "writerow", "(", "[", "data", "[", "'example_id'", "]", ",", "\n", "data", "[", "'question_text'", "]", ",", "\n", "data", "[", "'question_statement_text'", "]", ",", "\n", "data", "[", "'answer_sent_text'", "]", ",", "\n", "pred", ",", "\n", "data", "[", "'paragraph_text'", "]", "]", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "cat", ",", "sent", "=", "pred", ".", "split", "(", "'###'", ")", "\n", "", "except", "ValueError", ":", "\n", "                    ", "cat", "=", "'IMPOSSIBLE'", "\n", "sent", "=", "data", "[", "'answer_sent_text'", "]", "\n", "", "if", "data_source", "==", "'qa-nli'", ":", "\n", "                    ", "data", "[", "'decontext_answer_sent_text'", "]", "=", "sent", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "                    ", "data", "[", "'decontextualized_sentence'", "]", "=", "sent", ".", "strip", "(", ")", "\n", "", "data", "[", "'category'", "]", "=", "cat", ".", "strip", "(", ")", "\n", "json", ".", "dump", "(", "data", ",", "fout", ")", "\n", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.write_question_converter_predictions_out": [[80, 111], ["open", "csv.writer", "csv.writer.writerow", "zip", "csv.writer.writerow", "zip", "open", "zip", "csv.writer.writerow", "csv.writer.writerow", "json.dump", "fout.write"], "function", ["None"], ["", "", "", "", "def", "write_question_converter_predictions_out", "(", "dataset", ",", "\n", "predictions", ":", "List", "[", "str", "]", ",", "\n", "output_path", ":", "str", ",", "\n", "output_format", ":", "str", "=", "None", ",", "\n", "data_source", ":", "str", "=", "None", "\n", ")", ":", "\n", "    ", "if", "output_format", "==", "'csv'", ":", "\n", "        ", "csv_file", "=", "open", "(", "output_path", ",", "'w'", ",", "newline", "=", "''", ")", "\n", "csv_writer", "=", "csv", ".", "writer", "(", "csv_file", ",", "delimiter", "=", "','", ")", "\n", "if", "data_source", "==", "'qa-nli'", ":", "\n", "            ", "csv_fields", "=", "[", "'example_id'", ",", "'question'", ",", "'answer'", ",", "'question_statement'", "]", "\n", "csv_writer", ".", "writerow", "(", "csv_fields", ")", "\n", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "csv_writer", ".", "writerow", "(", "[", "data", "[", "'example_id'", "]", ",", "\n", "data", "[", "'question_text'", "]", ",", "\n", "data", "[", "'answer_text'", "]", ",", "\n", "pred", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "csv_fields", "=", "[", "'question'", ",", "'answer'", ",", "'question_statement'", ",", "'turker_answer'", "]", "\n", "csv_writer", ".", "writerow", "(", "csv_fields", ")", "\n", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "csv_writer", ".", "writerow", "(", "[", "data", "[", "'question'", "]", ",", "\n", "data", "[", "'answer'", "]", ",", "\n", "pred", ",", "\n", "data", "[", "'turker_answer'", "]", "]", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "data", "[", "'question_statement_text'", "]", "=", "pred", "\n", "json", ".", "dump", "(", "data", ",", "fout", ")", "\n", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.write_esnli_predictions_out": [[113, 165], ["open", "csv.writer", "csv.writer.writerow", "zip", "csv.writer.writerow", "zip", "open", "zip", "pred.split", "csv.writer.writerow", "pred.split", "csv.writer.writerow", "pred.split", "json.dump", "fout.write", "len", "pred.split"], "function", ["None"], ["", "", "", "", "def", "write_esnli_predictions_out", "(", "dataset", ",", "\n", "predictions", ":", "List", "[", "str", "]", ",", "\n", "output_path", ":", "str", ",", "\n", "output_format", ":", "str", "=", "None", ",", "\n", "data_source", ":", "str", "=", "None", "\n", ")", ":", "\n", "    ", "if", "output_format", "==", "'csv'", ":", "\n", "        ", "csv_file", "=", "open", "(", "output_path", ",", "'w'", ",", "newline", "=", "''", ")", "\n", "csv_writer", "=", "csv", ".", "writer", "(", "csv_file", ",", "delimiter", "=", "','", ")", "\n", "if", "data_source", "==", "'qa-nli'", ":", "\n", "            ", "csv_fields", "=", "[", "\n", "'question_statement'", ",", "'decontext_answer_sent'", ",", "\n", "'highlights1'", ",", "'highlights2'", ",", "'explanation'", "\n", "]", "\n", "csv_writer", ".", "writerow", "(", "csv_fields", ")", "\n", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "items", "=", "pred", ".", "split", "(", "'###'", ")", "\n", "if", "len", "(", "items", ")", "<", "4", ":", "\n", "                    ", "high_lights1", "=", "INVALID_PREDICTION", "\n", "high_lights2", "=", "INVALID_PREDICTION", "\n", "explanation", "=", "INVALID_PREDICTION", "\n", "", "else", ":", "\n", "                    ", "label", ",", "high_lights1", ",", "high_lights2", ",", "explanation", "=", "pred", ".", "split", "(", "'###'", ")", "\n", "\n", "", "csv_writer", ".", "writerow", "(", "[", "data", "[", "'converted_question'", "]", ",", "\n", "data", "[", "'decontext_answer_sent'", "]", ",", "\n", "high_lights1", ",", "\n", "high_lights2", ",", "\n", "explanation", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "csv_fields", "=", "[", "'sentence1'", ",", "'sentence2'", ",", "'highlights1'", ",", "\n", "'highlights2'", ",", "'explanation'", "]", "\n", "csv_writer", ".", "writerow", "(", "csv_fields", ")", "\n", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "label", ",", "high_lights1", ",", "high_lights2", ",", "explanation", "=", "pred", ".", "split", "(", "'###'", ")", "\n", "csv_writer", ".", "writerow", "(", "[", "data", "[", "'Sentence1'", "]", ",", "\n", "data", "[", "'Sentence2'", "]", ",", "\n", "high_lights1", ",", "\n", "high_lights2", ",", "\n", "explanation", "]", ")", "\n", "", "", "", "else", ":", "\n", "        ", "with", "open", "(", "output_path", ",", "'w'", ")", "as", "fout", ":", "\n", "            ", "for", "data", ",", "pred", "in", "zip", "(", "dataset", ",", "predictions", ")", ":", "\n", "                ", "label", ",", "high_lights1", ",", "high_lights2", ",", "explanation", "=", "pred", ".", "split", "(", "'###'", ")", "\n", "data", "[", "'highlights1'", "]", "=", "high_lights1", "\n", "data", "[", "'highlights2'", "]", "=", "high_lights2", "\n", "data", "[", "'pred_label'", "]", "=", "label", "\n", "data", "[", "'explanation'", "]", "=", "explanation", "\n", "json", ".", "dump", "(", "data", ",", "fout", ")", "\n", "fout", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_decontext_train_and_dev": [[167, 189], ["zip", "inputs.append", "targets.append", "utils.form_decontext_train_input", "utils.form_decontext_train_output"], "function", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.form_decontext_train_input", "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.form_decontext_train_output"], ["", "", "", "", "def", "process_decontext_train_and_dev", "(", "examples", ":", "Dict", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "for", "para", ",", "answer_sent", ",", "title", ",", "annots", "in", "zip", "(", "\n", "examples", "[", "'paragraph_text'", "]", ",", "\n", "examples", "[", "'original_sentence'", "]", ",", "\n", "examples", "[", "'page_title'", "]", ",", "\n", "examples", "[", "'annotations'", "]", "\n", ")", ":", "\n", "        ", "if", "not", "annots", ":", "\n", "            ", "continue", "\n", "", "inputs", ".", "append", "(", "\n", "form_decontext_train_input", "(", "para", ",", "answer_sent", ",", "title", ")", "\n", ")", "\n", "# for training and a preliminary evaluation", "\n", "first_annot", "=", "annots", "[", "0", "]", "\n", "decontext_sent", "=", "first_annot", "[", "'decontextualized_sentence'", "]", "\n", "category", "=", "first_annot", "[", "'category'", "]", "\n", "targets", ".", "append", "(", "form_decontext_train_output", "(", "answer_sent", ",", "\n", "decontext_sent", ",", "\n", "category", ")", ")", "\n", "", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_decontext_qanli": [[191, 210], ["zip", "inputs.append", "targets.append", "utils.form_decontext_train_input"], "function", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.form_decontext_train_input"], ["", "def", "process_decontext_qanli", "(", "examples", ":", "Dict", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "for", "para", ",", "answer_sent", ",", "title", "in", "zip", "(", "\n", "examples", "[", "'paragraph_text'", "]", ",", "\n", "examples", "[", "'answer_sent_text'", "]", ",", "\n", "examples", "[", "'title_text'", "]", "\n", ")", ":", "\n", "# if not para or not answer_sent or not title:", "\n", "#     print(para)", "\n", "#     print(answer_sent)", "\n", "#     print(title)", "\n", "#     input()", "\n", "        ", "inputs", ".", "append", "(", "\n", "form_decontext_train_input", "(", "para", ",", "answer_sent", ",", "title", ")", "\n", ")", "\n", "# for training and a preliminary evaluation", "\n", "targets", ".", "append", "(", "\"DUMB LABEL\"", ")", "\n", "", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_question_converter_train_and_dev": [[212, 224], ["zip", "inputs.append", "targets.append"], "function", ["None"], ["", "def", "process_question_converter_train_and_dev", "(", "examples", ":", "Dict", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "for", "a", ",", "q", ",", "t", "in", "zip", "(", "examples", "[", "'answer'", "]", ",", "\n", "examples", "[", "'question'", "]", ",", "\n", "examples", "[", "'turker_answer'", "]", ")", ":", "\n", "        ", "if", "a", "and", "q", "and", "t", ":", "\n", "            ", "inputs", ".", "append", "(", "\n", "\"{} </s> {}\"", ".", "format", "(", "q", ",", "a", ")", "\n", ")", "\n", "targets", ".", "append", "(", "t", ")", "\n", "", "", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_question_converter_qanli": [[226, 237], ["zip", "inputs.append", "targets.append"], "function", ["None"], ["", "def", "process_question_converter_qanli", "(", "examples", ":", "Dict", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "for", "a", ",", "q", "in", "zip", "(", "examples", "[", "'answer_text'", "]", ",", "\n", "examples", "[", "'question_text'", "]", ")", ":", "\n", "        ", "if", "a", "and", "q", ":", "\n", "            ", "inputs", ".", "append", "(", "\n", "\"{} </s> {}\"", ".", "format", "(", "q", ",", "a", ")", "\n", ")", "\n", "targets", ".", "append", "(", "'DUMB LABEL'", ")", "\n", "", "", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_esnli_train_and_dev": [[239, 281], ["zip", "inputs.append", "s1.split.split", "s2.split.split", "sorted", "sorted", "targets.append", "sorted.split", "sorted.split", "utils.form_esnil_train_output", "int", "int", "int", "len", "int", "len"], "function", ["home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.form_esnil_train_output"], ["", "def", "process_esnli_train_and_dev", "(", "examples", ":", "Dict", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "# TODO: try all annotations", "\n", "for", "s1", ",", "s2", ",", "label", ",", "sp1h1", ",", "sp2h1", ",", "explain1", "in", "zip", "(", "examples", "[", "'Sentence1'", "]", ",", "\n", "examples", "[", "'Sentence2'", "]", ",", "\n", "examples", "[", "'gold_label'", "]", ",", "\n", "examples", "[", "'Sentence1_Highlighted_1'", "]", ",", "\n", "examples", "[", "'Sentence2_Highlighted_1'", "]", ",", "\n", "examples", "[", "'Explanation_1'", "]", ")", ":", "\n", "        ", "if", "s1", "and", "s2", "and", "sp1h1", "and", "sp2h1", ":", "\n", "            ", "inputs", ".", "append", "(", "\n", "\"{} </s> {}\"", ".", "format", "(", "s1", ",", "s2", ")", "\n", ")", "\n", "# concat all the highlights for now", "\n", "# TODO: try separating the non-consecutive highlights", "\n", "\n", "s1", "=", "s1", ".", "split", "(", ")", "\n", "s2", "=", "s2", ".", "split", "(", ")", "\n", "\n", "sp1h1", "=", "sorted", "(", "sp1h1", ".", "split", "(", "','", ")", ")", "\n", "sp2h1", "=", "sorted", "(", "sp2h1", ".", "split", "(", "','", ")", ")", "\n", "\n", "if", "sp1h1", "[", "0", "]", "!=", "EMPTY_ANNOTATION", ":", "\n", "                ", "sp1h1", "=", "[", "int", "(", "i", ")", "for", "i", "in", "sp1h1", "if", "int", "(", "i", ")", "<", "len", "(", "s1", ")", "]", "\n", "sp1h1_text", "=", "\" \"", ".", "join", "(", "[", "s1", "[", "i", "]", "for", "i", "in", "sp1h1", "]", ")", "\n", "", "else", ":", "\n", "                ", "sp1h1_text", "=", "\"EMPTY\"", "\n", "\n", "", "if", "sp2h1", "[", "0", "]", "!=", "EMPTY_ANNOTATION", ":", "\n", "                ", "sp2h1", "=", "[", "int", "(", "i", ")", "for", "i", "in", "sp2h1", "if", "int", "(", "i", ")", "<", "len", "(", "s2", ")", "]", "\n", "sp2h1_text", "=", "\" \"", ".", "join", "(", "[", "s2", "[", "i", "]", "for", "i", "in", "sp2h1", "]", ")", "\n", "", "else", ":", "\n", "                ", "sp2h1_text", "=", "\"EMPTY\"", "\n", "\n", "", "targets", ".", "append", "(", "form_esnil_train_output", "(", "label", ",", "\n", "[", "sp1h1_text", ",", "sp2h1_text", "]", ",", "\n", "explain1", ")", "\n", ")", "\n", "\n", "", "", "return", "inputs", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.jifan-chen_qa-verification-via-nli.seq2seq_converter.utils.process_esnli_qanli": [[283, 296], ["zip", "inputs.append", "targets.append"], "function", ["None"], ["", "def", "process_esnli_qanli", "(", "examples", ":", "Dict", ")", ":", "\n", "    ", "inputs", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "for", "hypothesis", ",", "premise", "in", "zip", "(", "\n", "examples", "[", "'converted_question'", "]", ",", "\n", "examples", "[", "'decontext_answer_sent'", "]", "\n", ")", ":", "\n", "        ", "inputs", ".", "append", "(", "\n", "\"{} </s> {}\"", ".", "format", "(", "premise", ",", "hypothesis", ")", "\n", ")", "\n", "# for training and a preliminary evaluation", "\n", "targets", ".", "append", "(", "\"DUMB LABEL\"", ")", "\n", "", "return", "inputs", ",", "targets", "\n", "", ""]]}