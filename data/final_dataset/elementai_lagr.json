{"home.repos.pwc.inspect_result.elementai_lagr.src.cfq_train.train": [[77, 144], ["src.utils.setup_data", "len", "len", "src.utils.CustomDataset", "src.utils.CustomDataset", "src.utils.CustomDataset", "src.utils.make_collator", "src.utils.make_collator", "src.utils.make_collator", "torch.randint", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "print", "src.utils._create_name", "src.utils._maybe_fetch_ckpt", "src.utils._ckpt_callback", "pytorch_lightning.Trainer", "pl.Trainer.fit", "pl.Trainer.test", "print", "len", "torch.utils.data.SubsetRandomSampler", "pytorch_lightning.loggers.WandbLogger", "src.model.Parser.load_from_checkpoint", "src.model.Parser", "int", "len", "len", "os.environ.get", "len"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.setup_data", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._create_name", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._maybe_fetch_ckpt", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._ckpt_callback", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.get"], ["def", "train", "(", ")", ":", "\n", "\n", "\t", "datasets", ",", "vocabs", ",", "preprocessor", "=", "setup_data", "(", "cl_args", ")", "\n", "src_vocab", ",", "tgt_vocab", "=", "vocabs", "\n", "cl_args", ".", "vocab_size", "=", "len", "(", "src_vocab", ")", "# includes PAD", "\n", "cl_args", ".", "tgt_vocab_size", "=", "len", "(", "tgt_vocab", ")", "\n", "cl_args", ".", "src_vocab", "=", "src_vocab", "\n", "cl_args", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "cl_args", ".", "preprocessor", "=", "preprocessor", "\n", "\n", "training_set", "=", "CustomDataset", "(", "datasets", "[", "'train'", "]", ")", "\n", "test_set", "=", "CustomDataset", "(", "datasets", "[", "'test'", "]", ")", "\n", "val_set", "=", "CustomDataset", "(", "datasets", "[", "'validation'", "]", ")", "\n", "\n", "train_collator", "=", "make_collator", "(", ")", "\n", "test_collator", "=", "make_collator", "(", ")", "\n", "val_collator", "=", "make_collator", "(", ")", "\n", "\n", "train_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "batch_size", ",", "'shuffle'", ":", "True", ",", "'drop_last'", ":", "True", ",", "'num_workers'", ":", "8", "}", "\n", "test_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "gen_batch_size", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "8", "}", "\n", "val_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "batch_size", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "8", "}", "\n", "sample_ids", "=", "torch", ".", "randint", "(", "len", "(", "training_set", ")", ",", "(", "int", "(", "len", "(", "training_set", ")", "*", "0.1", ")", ",", ")", ")", "\n", "train_val_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "batch_size", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "8", ",", "'sampler'", ":", "SubsetRandomSampler", "(", "sample_ids", ")", "}", "\n", "\n", "train_loader", "=", "DataLoader", "(", "training_set", ",", "**", "train_params", ",", "collate_fn", "=", "train_collator", ")", "\n", "test_loader", "=", "DataLoader", "(", "test_set", ",", "**", "test_params", ",", "collate_fn", "=", "test_collator", ")", "\n", "val_loader", "=", "DataLoader", "(", "val_set", ",", "**", "val_params", ",", "collate_fn", "=", "val_collator", ")", "\n", "train_val_loader", "=", "DataLoader", "(", "training_set", ",", "**", "train_val_params", ",", "collate_fn", "=", "val_collator", ")", "\n", "\n", "optimizer_args", "=", "{", "'lr'", ":", "cl_args", ".", "lr", ",", "'betas'", ":", "(", "cl_args", ".", "beta1", ",", "cl_args", ".", "beta2", ")", ",", "'eps'", ":", "cl_args", ".", "eps", ",", "'weight_decay'", ":", "cl_args", ".", "weight_decay", "}", "\n", "num_training_steps", "=", "len", "(", "training_set", ")", "/", "(", "cl_args", ".", "batch_size", "*", "cl_args", ".", "accum_grad", ")", "*", "cl_args", ".", "epochs", "\n", "cl_args", ".", "expected_cache_size", "=", "len", "(", "training_set", ")", "\n", "print", "(", "f'Size of trainset: {len(training_set)} - Num train steps: {num_training_steps}'", ")", "\n", "\n", "scheduler_args", "=", "{", "'num_warmup_steps'", ":", "cl_args", ".", "num_warmup_steps", ",", "'num_training_steps'", ":", "num_training_steps", "}", "\n", "cl_args", ".", "optimizer_args", "=", "optimizer_args", "\n", "cl_args", ".", "scheduler_args", "=", "scheduler_args", "\n", "\n", "exp_name", ",", "run_name", "=", "_create_name", "(", "cl_args", ")", "\n", "cl_args", ".", "ckpt", ",", "possible_run_id", "=", "_maybe_fetch_ckpt", "(", "cl_args", ",", "exp_name", ",", "run_name", ")", "# if resumed, try fetching last best ckpt", "\n", "\n", "# No wandb in interactive mode", "\n", "if", "not", "cl_args", ".", "interactive", ":", "\n", "\t\t", "logger", "=", "WandbLogger", "(", "name", "=", "run_name", ",", "group", "=", "exp_name", ",", "project", "=", "\"lagr\"", ",", "entity", "=", "'dorajam'", ",", "config", "=", "cl_args", ",", "resume", "=", "\"allow\"", ",", "id", "=", "os", ".", "environ", ".", "get", "(", "\"EAI_JOB_ID\"", ",", "''", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "logger", "=", "None", "\n", "\n", "", "if", "cl_args", ".", "ckpt", ":", "\n", "\t\t", "model", "=", "Parser", ".", "load_from_checkpoint", "(", "cl_args", ".", "ckpt", ")", "\n", "", "else", ":", "\n", "\t\t", "model", "=", "Parser", "(", "cl_args", ")", "\n", "\n", "", "checkpoint_callback", "=", "_ckpt_callback", "(", "cl_args", ",", "exp_name", ",", "run_name", ",", "possible_run_id", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "cl_args", ".", "epochs", ",", "\n", "gradient_clip_val", "=", "cl_args", ".", "max_grad_norm", ",", "\n", "# deterministic=True,      # reproducibility", "\n", "gpus", "=", "1", ",", "# run on gpu", "\n", "precision", "=", "cl_args", ".", "precision", ",", "\n", "check_val_every_n_epoch", "=", "cl_args", ".", "eval_every", ",", "\n", "num_sanity_val_steps", "=", "0", ",", "\n", "logger", "=", "logger", ",", "# log on wandb", "\n", "callbacks", "=", "[", "checkpoint_callback", "]", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_loader", ",", "val_dataloaders", "=", "[", "val_loader", ",", "train_val_loader", "]", ",", "ckpt_path", "=", "cl_args", ".", "ckpt", ")", "# resume if ckpt is provided", "\n", "test_result", "=", "trainer", ".", "test", "(", "model", ",", "test_dataloaders", "=", "[", "train_loader", ",", "test_loader", "]", ",", "ckpt_path", "=", "'best'", ")", "\n", "print", "(", "test_result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.train.train": [[71, 145], ["src.utils.setup_data", "len", "len", "src.utils.CustomDataset", "src.utils.CustomDataset", "src.utils.CustomDataset", "src.utils.CustomDataset", "src.utils.make_collator", "src.utils.make_collator", "src.utils.make_collator", "src.utils.make_collator", "torch.randint", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "len", "print", "src.utils._create_name", "src.utils._maybe_fetch_ckpt", "src.utils._ckpt_callback", "pytorch_lightning.Trainer", "pl.Trainer.fit", "pl.Trainer.test", "print", "sys.exit", "len", "torch.utils.data.SubsetRandomSampler", "pytorch_lightning.loggers.WandbLogger", "src.model.Parser.load_from_checkpoint", "src.model.Parser", "int", "len", "len", "os.environ.get", "len"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.setup_data", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._create_name", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._maybe_fetch_ckpt", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._ckpt_callback", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.get"], ["def", "train", "(", ")", ":", "\n", "\n", "\t", "datasets", ",", "vocabs", ",", "preprocessor", "=", "setup_data", "(", "cl_args", ")", "\n", "src_vocab", ",", "tgt_vocab", "=", "vocabs", "\n", "cl_args", ".", "vocab_size", "=", "len", "(", "src_vocab", ")", "# includes PAD", "\n", "cl_args", ".", "tgt_vocab_size", "=", "len", "(", "tgt_vocab", ")", "\n", "cl_args", ".", "src_vocab", "=", "src_vocab", "\n", "cl_args", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "cl_args", ".", "preprocessor", "=", "preprocessor", "\n", "\n", "training_set", "=", "CustomDataset", "(", "datasets", "[", "'train'", "]", ")", "\n", "val_set", "=", "CustomDataset", "(", "datasets", "[", "'gen_dev'", "]", ")", "\n", "gen_set", "=", "CustomDataset", "(", "datasets", "[", "'gen'", "]", ")", "\n", "test_set", "=", "CustomDataset", "(", "datasets", "[", "'test'", "]", ")", "\n", "\n", "train_collator", "=", "make_collator", "(", ")", "\n", "val_collator", "=", "make_collator", "(", ")", "\n", "test_collator", "=", "make_collator", "(", ")", "\n", "gen_collator", "=", "make_collator", "(", ")", "\n", "\n", "train_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "batch_size", ",", "'shuffle'", ":", "True", ",", "'drop_last'", ":", "True", ",", "'num_workers'", ":", "8", "}", "\n", "val_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "batch_size", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "8", "}", "\n", "test_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "gen_batch_size", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "8", "}", "\n", "gen_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "gen_batch_size", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "8", "}", "\n", "sample_ids", "=", "torch", ".", "randint", "(", "len", "(", "training_set", ")", ",", "(", "int", "(", "len", "(", "training_set", ")", "*", "0.1", ")", ",", ")", ")", "\n", "train_val_params", "=", "{", "'batch_size'", ":", "cl_args", ".", "batch_size", ",", "'shuffle'", ":", "False", ",", "'num_workers'", ":", "8", ",", "'sampler'", ":", "SubsetRandomSampler", "(", "sample_ids", ")", "}", "\n", "\n", "train_loader", "=", "DataLoader", "(", "training_set", ",", "**", "train_params", ",", "collate_fn", "=", "train_collator", ")", "\n", "val_loader", "=", "DataLoader", "(", "val_set", ",", "**", "val_params", ",", "collate_fn", "=", "val_collator", ")", "\n", "test_loader", "=", "DataLoader", "(", "test_set", ",", "**", "test_params", ",", "collate_fn", "=", "test_collator", ")", "\n", "gen_loader", "=", "DataLoader", "(", "gen_set", ",", "**", "gen_params", ",", "collate_fn", "=", "gen_collator", ")", "\n", "train_val_loader", "=", "DataLoader", "(", "training_set", ",", "**", "train_val_params", ",", "collate_fn", "=", "val_collator", ")", "\n", "\n", "optimizer_args", "=", "{", "'lr'", ":", "cl_args", ".", "lr", ",", "'betas'", ":", "(", "cl_args", ".", "beta1", ",", "cl_args", ".", "beta2", ")", ",", "'eps'", ":", "cl_args", ".", "eps", ",", "'weight_decay'", ":", "cl_args", ".", "weight_decay", "}", "\n", "num_training_steps", "=", "len", "(", "training_set", ")", "/", "(", "cl_args", ".", "batch_size", "*", "cl_args", ".", "accum_grad", ")", "*", "cl_args", ".", "epochs", "\n", "cl_args", ".", "expected_cache_size", "=", "len", "(", "training_set", ")", "\n", "print", "(", "f'Size of trainset: {len(training_set)} - Num train steps: {num_training_steps}'", ")", "\n", "\n", "scheduler_args", "=", "{", "'num_warmup_steps'", ":", "cl_args", ".", "num_warmup_steps", ",", "'num_training_steps'", ":", "num_training_steps", "}", "\n", "cl_args", ".", "optimizer_args", "=", "optimizer_args", "\n", "cl_args", ".", "scheduler_args", "=", "scheduler_args", "\n", "\n", "exp_name", ",", "run_name", "=", "_create_name", "(", "cl_args", ")", "\n", "cl_args", ".", "ckpt", ",", "possible_run_id", "=", "_maybe_fetch_ckpt", "(", "cl_args", ",", "exp_name", ",", "run_name", ")", "# if resumed, try fetching last best ckpt", "\n", "\n", "# No wandb in interactive mode", "\n", "if", "not", "cl_args", ".", "interactive", ":", "\n", "\t\t", "logger", "=", "WandbLogger", "(", "name", "=", "run_name", ",", "group", "=", "exp_name", ",", "project", "=", "\"lagr\"", ",", "entity", "=", "'dorajam'", ",", "config", "=", "cl_args", ",", "resume", "=", "\"allow\"", ",", "id", "=", "os", ".", "environ", ".", "get", "(", "\"EAI_JOB_ID\"", ",", "''", ")", ")", "\n", "", "else", ":", "\n", "\t\t", "logger", "=", "None", "\n", "\n", "", "if", "cl_args", ".", "ckpt", ":", "\n", "\t\t", "model", "=", "Parser", ".", "load_from_checkpoint", "(", "cl_args", ".", "ckpt", ")", "\n", "", "else", ":", "\n", "\t\t", "model", "=", "Parser", "(", "cl_args", ")", "\n", "\n", "", "checkpoint_callback", "=", "_ckpt_callback", "(", "cl_args", ",", "exp_name", ",", "run_name", ",", "possible_run_id", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "max_epochs", "=", "cl_args", ".", "epochs", ",", "\n", "gradient_clip_val", "=", "cl_args", ".", "max_grad_norm", ",", "\n", "# deterministic=True,      # reproducibility", "\n", "gpus", "=", "1", ",", "# run on gpu", "\n", "precision", "=", "cl_args", ".", "precision", ",", "\n", "check_val_every_n_epoch", "=", "cl_args", ".", "eval_every", ",", "\n", "num_sanity_val_steps", "=", "0", ",", "\n", "logger", "=", "logger", ",", "# log on wandb", "\n", "callbacks", "=", "[", "checkpoint_callback", "]", "\n", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_loader", ",", "val_dataloaders", "=", "[", "val_loader", ",", "train_val_loader", "]", ",", "ckpt_path", "=", "cl_args", ".", "ckpt", ")", "# resume if ckpt is provided", "\n", "test_result", "=", "trainer", ".", "test", "(", "model", ",", "test_dataloaders", "=", "[", "train_loader", ",", "test_loader", ",", "gen_loader", "]", ",", "ckpt_path", "=", "'best'", ")", "\n", "print", "(", "test_result", ")", "\n", "\n", "# exit code for random restart", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase.__init__": [[16, 26], ["super().__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "state_size", ":", "int", ",", "n_heads", ":", "int", ",", "dropout", ":", "float", "=", "0.1", ")", ":", "\n", "        ", "assert", "state_size", "%", "n_heads", "==", "0", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "state_size", "=", "state_size", "\n", "self", ".", "projection_size", "=", "state_size", "//", "n_heads", "\n", "self", ".", "n_heads", "=", "n_heads", "\n", "self", ".", "scale", "=", "1.0", "/", "math", ".", "sqrt", "(", "self", ".", "projection_size", ")", "\n", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "multi_head_merge", "=", "torch", ".", "nn", ".", "Linear", "(", "n_heads", "*", "self", ".", "projection_size", ",", "state_size", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase._masked_softmax": [[27, 44], ["logits.masked_fill.masked_fill.view", "torch.softmax", "torch.softmax", "torch.softmax", "logits.masked_fill.masked_fill.view", "torch.softmax", "torch.softmax", "torch.softmax", "logits.masked_fill.masked_fill.masked_fill", "logits.masked_fill.masked_fill.masked_fill", "mask.position_mask.unsqueeze().unsqueeze", "float", "mask.src_length_mask.unsqueeze().unsqueeze", "float", "mask.position_mask.unsqueeze", "mask.src_length_mask.unsqueeze"], "methods", ["None"], ["", "def", "_masked_softmax", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "mask", ":", "Optional", "[", "AttentionMask", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "if", "mask", "is", "None", "or", "(", "mask", ".", "src_length_mask", "is", "None", "and", "mask", ".", "position_mask", "is", "None", ")", ":", "\n", "            ", "return", "F", ".", "softmax", "(", "logits", ",", "-", "1", ")", "\n", "\n", "# Output shape: [n_batch * n_heads, n_time_dest, n_time_src]", "\n", "", "bb", ",", "n_time_dest", ",", "n_time_src", "=", "logits", ".", "shape", "\n", "\n", "logits", "=", "logits", ".", "view", "(", "bb", "//", "self", ".", "n_heads", ",", "self", ".", "n_heads", ",", "n_time_dest", ",", "n_time_src", ")", "\n", "\n", "if", "mask", ".", "position_mask", "is", "not", "None", ":", "\n", "            ", "logits", "=", "logits", ".", "masked_fill", "(", "mask", ".", "position_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "\n", "", "if", "mask", ".", "src_length_mask", "is", "not", "None", ":", "\n", "            ", "logits", "=", "logits", ".", "masked_fill", "(", "mask", ".", "src_length_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ",", "float", "(", "\"-inf\"", ")", ")", "\n", "\n", "", "logits", "=", "F", ".", "softmax", "(", "logits", ",", "-", "1", ")", "\n", "return", "logits", ".", "view", "(", "bb", ",", "n_time_dest", ",", "n_time_src", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase._attention_read": [[45, 54], ["attention.MultiHeadAttentionBase._masked_softmax", "attention.MultiHeadAttentionBase.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "attention.MultiHeadAttentionBase.view"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase._masked_softmax"], ["", "def", "_attention_read", "(", "self", ",", "mask", ":", "Optional", "[", "AttentionMask", "]", ",", "logits", ":", "torch", ".", "Tensor", ",", "v", ":", "torch", ".", "Tensor", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "# logits: [n_batch * n_heads, n_out, n_in]", "\n", "# v: [n_nbatch * n_heads, n_in]", "\n", "# Output data shape [n_batch * n_heads, n_time_dest, data_size]", "\n", "# Out attention score shape: [n_batch, n_heads, n_time_dest, n_time_src]", "\n", "        ", "scores", "=", "self", ".", "_masked_softmax", "(", "logits", "*", "self", ".", "scale", ",", "mask", ")", "\n", "scores", "=", "self", ".", "dropout", "(", "scores", ")", "\n", "return", "torch", ".", "bmm", "(", "scores", ",", "v", ")", ",", "scores", ".", "view", "(", "-", "1", ",", "self", ".", "n_heads", ",", "*", "scores", ".", "shape", "[", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase.merged_attention": [[55, 64], ["attention.MultiHeadAttentionBase._attention", "data.view().permute().contiguous().view.view().permute().contiguous().view.view().permute().contiguous().view", "attention.MultiHeadAttentionBase.multi_head_merge", "data.view().permute().contiguous().view.view().permute().contiguous().view.view().permute().contiguous", "data.view().permute().contiguous().view.view().permute().contiguous().view.view().permute", "data.view().permute().contiguous().view.view().permute().contiguous().view.view"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.attention.AbsPosAttentionBase._attention"], ["", "def", "merged_attention", "(", "self", ",", "n_batch", ":", "int", ",", "n_out_steps", ":", "int", ",", "*", "args", ",", "need_weights", ":", "bool", "=", "False", ",", "**", "kwargs", ")", "->", "Union", "[", "torch", ".", "Tensor", ",", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "\n", "        ", "data", ",", "scores", "=", "self", ".", "_attention", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "data", "=", "data", ".", "view", "(", "n_batch", ",", "self", ".", "n_heads", ",", "n_out_steps", ",", "-", "1", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", ".", "view", "(", "n_batch", ",", "n_out_steps", ",", "-", "1", ")", "\n", "\n", "return", "self", ".", "multi_head_merge", "(", "data", ")", ",", "scores", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase.transform_data": [[65, 73], ["proj().view().permute().contiguous().view", "proj().view().permute().contiguous().view.unbind", "proj().view().permute().contiguous", "proj().view().permute", "proj().view", "proj"], "methods", ["None"], ["", "def", "transform_data", "(", "self", ",", "input", ":", "torch", ".", "Tensor", ",", "proj", ":", "Callable", "[", "[", "torch", ".", "Tensor", "]", ",", "torch", ".", "Tensor", "]", ",", "\n", "n_projs", ":", "int", ")", "->", "List", "[", "torch", ".", "Tensor", "]", ":", "\n", "# Input shape: [n_batch, n_steps, n_channels]", "\n", "# Output: Tuple of n_projs tensors of dimension: [n_batch * n_heads, n_steps, projection_size]", "\n", "        ", "n_batch", ",", "n_steps", ",", "_", "=", "input", ".", "shape", "\n", "transformed", "=", "proj", "(", "input", ")", ".", "view", "(", "n_batch", ",", "n_steps", ",", "self", ".", "n_heads", ",", "n_projs", ",", "self", ".", "projection_size", ")", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ",", "4", ")", ".", "contiguous", "(", ")", ".", "view", "(", "n_batch", "*", "self", ".", "n_heads", ",", "n_steps", ",", "n_projs", ",", "self", ".", "projection_size", ")", "\n", "return", "transformed", ".", "unbind", "(", "dim", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase.reset_parameters": [[74, 76], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "multi_head_merge", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.AbsPosAttentionBase._attention": [[79, 84], ["attention.AbsPosAttentionBase._attention_read", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "k.transpose"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase._attention_read"], ["    ", "def", "_attention", "(", "self", ",", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", ",", "q", ":", "torch", ".", "Tensor", ",", "k", ":", "torch", ".", "Tensor", ",", "v", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "# all inputs should have a shape of [n_batch, n_steps, data_size]", "\n", "# Output shape [n_batch * n_heads, n_time_dest, data_size]", "\n", "        ", "return", "self", ".", "_attention_read", "(", "mask", ",", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttention.__init__": [[87, 93], ["attention.MultiHeadAttentionBase.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "attention.MultiHeadAttention.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.reset_parameters"], ["    ", "def", "__init__", "(", "self", ",", "state_size", ":", "int", ",", "n_heads", ":", "int", ",", "dropout", ":", "float", "=", "0.1", ",", "input_size", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "state_size", ",", "n_heads", ",", "dropout", ")", "\n", "self", ".", "data_to_kv", "=", "torch", ".", "nn", ".", "Linear", "(", "state_size", ",", "2", "*", "n_heads", "*", "self", ".", "projection_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "data_to_q", "=", "torch", ".", "nn", ".", "Linear", "(", "state_size", "if", "input_size", "is", "None", "else", "input_size", ",", "\n", "n_heads", "*", "self", ".", "projection_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttention.forward": [[94, 106], ["attention.MultiHeadAttention.transform_data", "attention.MultiHeadAttention.transform_data", "attention.MultiHeadAttention.merged_attention", "scores.mean"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase.transform_data", "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase.transform_data", "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttentionBase.merged_attention"], ["", "def", "forward", "(", "self", ",", "curr_state", ":", "torch", ".", "Tensor", ",", "attend_to", ":", "torch", ".", "Tensor", ",", "mask", ":", "Optional", "[", "AttentionMask", "]", ",", "\n", "need_weights", ":", "bool", "=", "False", ")", ":", "\n", "# Input and output shape: [n_batch, n_steps, data_size]", "\n", "        ", "k", ",", "v", "=", "self", ".", "transform_data", "(", "attend_to", ",", "self", ".", "data_to_kv", ",", "2", ")", "\n", "q", ",", "=", "self", ".", "transform_data", "(", "curr_state", ",", "self", ".", "data_to_q", ",", "1", ")", "\n", "\n", "data", ",", "scores", "=", "self", ".", "merged_attention", "(", "curr_state", ".", "shape", "[", "0", "]", ",", "q", ".", "shape", "[", "1", "]", ",", "mask", ",", "q", ",", "k", ",", "v", ")", "\n", "if", "need_weights", ":", "\n", "# Calculate the mean over the heads", "\n", "            ", "return", "data", ",", "scores", ".", "mean", "(", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.attention.MultiHeadAttention.reset_parameters": [[107, 113], ["attention.MultiHeadAttentionBase.reset_parameters", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.reset_parameters"], ["", "", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "reset_parameters", "(", ")", "\n", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "data_to_q", ".", "weight", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "data_to_kv", ".", "weight", "[", ":", "self", ".", "data_to_kv", ".", "weight", ".", "shape", "[", "0", "]", "//", "2", "]", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "data_to_kv", ".", "weight", "[", "self", ".", "data_to_kv", ".", "weight", ".", "shape", "[", "0", "]", "//", "2", ":", "]", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.__init__": [[81, 85], ["pytorch_lightning.LightningModule.__init__", "model.Parser.save_hyperparameters", "model.Parser._create_model"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._create_model"], ["\t", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "self", ".", "_create_model", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._create_model": [[86, 132], ["vars", "src.utils.statistics.Metrics", "src.transformer.TransformerEncDecModel", "Exception"], "methods", ["None"], ["", "def", "_create_model", "(", "self", ",", "args", ")", ":", "\n", "\n", "\t\t", "self", ".", "args", "=", "vars", "(", "args", ")", "\n", "self", ".", "data", "=", "args", ".", "data", "\n", "self", ".", "weakly", "=", "args", ".", "weak_supervision", "\n", "self", ".", "model_type", "=", "args", ".", "model_type", "\n", "self", ".", "flags", "=", "[", "'train_final'", ",", "'test'", ",", "'gen'", "]", "if", "self", ".", "data", "==", "'cogs'", "else", "[", "'train_final'", ",", "'test'", "]", "# hacky but a way to name the test outputs", "\n", "\n", "self", ".", "k", "=", "args", ".", "k", "\n", "self", ".", "noise", "=", "args", ".", "noise", "\n", "self", ".", "stats", "=", "Metrics", "(", "args", ".", "preprocessor", ",", "args", ".", "tgt_vocab", ",", "decoder_sos_eos", "=", "args", ".", "tgt_vocab_size", ")", "\n", "self", ".", "graph_accuracy", "=", "self", ".", "stats", ".", "cfq_graph_accuracy", "if", "self", ".", "data", "==", "'cfq'", "else", "self", ".", "stats", ".", "cogs_graph_accuracy", "\n", "# os.makedirs(os.path.join(self.data, args.log_dir), exist_ok=True)", "\n", "# self.saved_predictions = open(os.path.join(self.data, args.log_dir, args.log_file), mode='w+', encoding='utf-8')", "\n", "\n", "self", ".", "cached_alignments", "=", "{", "}", "\n", "self", ".", "expected_cache_size", "=", "args", ".", "expected_cache_size", "\n", "\n", "# Baseline Transformer", "\n", "if", "self", ".", "model_type", "==", "\"transformer_baseline\"", ":", "\n", "\t\t\t", "model", "=", "Transformer", "\n", "", "elif", "self", ".", "model_type", "==", "\"transformer_lagr\"", ":", "\n", "\t\t\t", "if", "self", ".", "args", "[", "\"share_encoder\"", "]", ":", "\n", "\t\t\t\t", "model", "=", "TransformerWithSharedEncoderLAGr", "\n", "", "else", ":", "\n", "\t\t\t\t", "model", "=", "TransformerWithSeparateEncoderLAGr", "\n", "", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"{self.model_type} is an unknown model type.\"", ")", "\n", "\n", "", "self", ".", "model", "=", "TransformerEncDecModel", "(", "\n", "n_input_tokens", "=", "self", ".", "args", "[", "\"vocab_size\"", "]", ",", "\n", "n_out_tokens", "=", "self", ".", "args", "[", "\"tgt_vocab_size\"", "]", ",", "\n", "state_size", "=", "self", ".", "args", "[", "\"dim\"", "]", ",", "\n", "ff_multiplier", "=", "self", ".", "args", "[", "\"transformer.ff_multiplier\"", "]", ",", "\n", "nhead", "=", "self", ".", "args", "[", "\"transformer.n_heads\"", "]", ",", "\n", "num_encoder_layers", "=", "self", ".", "args", "[", "\"transformer.encoder_n_layers\"", "]", ",", "\n", "num_decoder_layers", "=", "self", ".", "args", "[", "\"transformer.decoder_n_layers\"", "]", "or", "self", ".", "args", "[", "\"transformer.encoder_n_layers\"", "]", ",", "\n", "dropout", "=", "self", ".", "args", "[", "\"dropout\"", "]", ",", "\n", "transformer", "=", "model", ",", "\n", "n_graph_layers", "=", "self", ".", "args", "[", "'n_graph_layers'", "]", ",", "\n", "n_node_labels", "=", "self", ".", "args", "[", "'n_node_labels'", "]", ",", "\n", "n_edge_labels", "=", "self", ".", "args", "[", "'n_edge_labels'", "]", ",", "\n", "tied_embedding", "=", "self", ".", "args", "[", "\"transformer.tied_embedding\"", "]", ",", "\n", "embedding_init", "=", "\"kaiming\"", ",", "\n", "scale_mode", "=", "\"down\"", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.on_post_move_to_device": [[134, 138], ["None"], "methods", ["None"], ["", "def", "on_post_move_to_device", "(", "self", ")", ":", "\n", "\t\t", "if", "self", ".", "args", "[", "\"share_layers\"", "]", ":", "\n", "\t\t\t", "for", "mod", "in", "self", ".", "encoder", ".", "layers", ":", "\n", "\t\t\t\t", "mod", ".", "weight", "=", "self", ".", "encoder", ".", "layers", "[", "0", "]", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.configure_optimizers": [[139, 154], ["opt", "model.Parser.parameters", "transformers.get_linear_schedule_with_warmup", "get_tf_schedule"], "methods", ["None"], ["", "", "", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "# We will support Adam or AdamW as optimizers.", "\n", "\t\t", "if", "self", ".", "args", "[", "\"optimizer\"", "]", "==", "\"AdamW\"", ":", "\n", "\t\t\t", "opt", "=", "AdamW", "\n", "", "elif", "self", ".", "args", "[", "\"optimizer\"", "]", "==", "\"Adam\"", ":", "\n", "\t\t\t", "opt", "=", "Adam", "\n", "", "optimizer", "=", "opt", "(", "self", ".", "parameters", "(", ")", ",", "**", "self", ".", "args", "[", "\"optimizer_args\"", "]", ")", "\n", "\n", "# We will reduce the learning rate by 0.1 after 100 and 150 epochs", "\n", "if", "self", ".", "args", "[", "\"scheduler\"", "]", "==", "\"linear_warmup\"", ":", "\n", "\t\t\t", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "**", "self", ".", "args", "[", "\"scheduler_args\"", "]", ")", "\n", "", "elif", "self", ".", "args", "[", "\"scheduler\"", "]", "==", "\"tf\"", ":", "\n", "\t\t\t", "scheduler", "=", "get_tf_schedule", "(", "optimizer", ")", "\n", "\n", "", "return", "{", "\"optimizer\"", ":", "optimizer", ",", "\"lr_scheduler\"", ":", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.loss": [[155, 165], ["model.cross_entropy", "cross_entropy.reshape_as", "cross_entropy.sum", "mask.sum"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.model.cross_entropy"], ["", "def", "loss", "(", "self", ",", "outputs", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ",", "ignore_index", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "\"\"\"\n\t\toutputs: log probability scores\n\t\ttargets: target tokens\n\t\tmask: bool mask with True for non-pad tokens\n\t\t\"\"\"", "\n", "l", "=", "cross_entropy", "(", "outputs", ",", "targets", ",", "reduction", "=", "\"none\"", ",", "smoothing", "=", "0", ",", "ignore_index", "=", "ignore_index", ")", "\n", "l", "=", "l", ".", "reshape_as", "(", "targets", ")", "*", "mask", "\n", "l", "=", "l", ".", "sum", "(", ")", "/", "mask", ".", "sum", "(", ")", "\n", "return", "l", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._calculate_loss": [[166, 193], ["src.utils.add_eos", "src.utils.add_eos", "model.Parser.model", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "model.Parser.loss", "model.Parser.loss", "model.Parser.loss", "tgt_length_with_eos.max().item", "model.Parser.model.generate_len_mask", "batch[].ne", "batch[].ne", "tgt_length_with_eos.max"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.loss", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.loss", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.loss", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.generate_len_mask"], ["", "def", "_calculate_loss", "(", "self", ",", "batch", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tRuns model, and returns raw scores and loss\n\t\t\"\"\"", "\n", "src_tokens", "=", "add_eos", "(", "batch", "[", "\"src\"", "]", ",", "batch", "[", "\"src_len\"", "]", ",", "self", ".", "model", ".", "encoder_eos", ")", "\n", "tgt_tokens", "=", "add_eos", "(", "batch", "[", "\"tgt\"", "]", ",", "batch", "[", "\"tgt_len\"", "]", ",", "self", ".", "model", ".", "decoder_sos_eos", ")", "\n", "src_length_with_eos", "=", "batch", "[", "\"src_len\"", "]", "+", "1", "\n", "tgt_length_with_eos", "=", "batch", "[", "\"tgt_len\"", "]", "+", "1", "\n", "result", "=", "self", ".", "model", "(", "src_tokens", ",", "src_length_with_eos", ",", "tgt_tokens", ",", "tgt_length_with_eos", ",", "\n", "teacher_forcing", "=", "self", ".", "training", ",", "max_len", "=", "tgt_length_with_eos", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "if", "self", ".", "model_type", "==", "\"transformer_baseline\"", ":", "\n", "# assumes SL x BS shape", "\n", "\t\t\t", "max_len", "=", "tgt_tokens", ".", "shape", "[", "1", "]", "\n", "train_eos", "=", "True", "\n", "len_mask", "=", "~", "self", ".", "model", ".", "generate_len_mask", "(", "max_len", ",", "tgt_length_with_eos", "if", "train_eos", "else", "(", "tgt_length", ")", ")", "\n", "result", "=", "F", ".", "log_softmax", "(", "result", ",", "-", "1", ")", "\n", "loss", "=", "self", ".", "loss", "(", "result", ",", "tgt_tokens", ",", "len_mask", ",", "ignore_index", "=", "PAD_TOKEN", ")", "\n", "\n", "# LAGr", "\n", "", "else", ":", "\n", "\t\t\t", "node_scores", ",", "edge_scores", "=", "result", "\n", "node_loss", "=", "self", ".", "loss", "(", "node_scores", ",", "batch", "[", "\"node_tgt\"", "]", ",", "batch", "[", "\"node_tgt\"", "]", ".", "ne", "(", "GRAPH_PAD_TOKEN", ")", ",", "ignore_index", "=", "GRAPH_PAD_TOKEN", ")", "\n", "edge_loss", "=", "self", ".", "loss", "(", "edge_scores", ",", "batch", "[", "\"edge_tgt\"", "]", ",", "batch", "[", "\"edge_tgt\"", "]", ".", "ne", "(", "GRAPH_PAD_TOKEN", ")", ",", "ignore_index", "=", "GRAPH_PAD_TOKEN", ")", "\n", "loss", "=", "node_loss", "+", "edge_loss", "\n", "\n", "", "return", "loss", ",", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.training_step": [[194, 205], ["model.Parser.lr_schedulers", "model.Parser.log", "model.Parser._weakly_sup_loss", "model.Parser._calculate_loss", "model.Parser.log"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._weakly_sup_loss", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._calculate_loss"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "\t\t", "if", "self", ".", "weakly", ":", "\n", "\t\t\t", "loss", ",", "scores", ",", "preds", ",", "alignment_changes", "=", "self", ".", "_weakly_sup_loss", "(", "batch", ")", "\n", "if", "alignment_changes", ">=", "0", ":", "self", ".", "log", "(", "\"align_changes\"", ",", "alignment_changes", ",", "prog_bar", "=", "True", ")", "# only track once it's trackable", "\n", "", "else", ":", "\n", "\t\t\t", "loss", ",", "scores", "=", "self", ".", "_calculate_loss", "(", "batch", ")", "\n", "\n", "", "scheduler", "=", "self", ".", "lr_schedulers", "(", ")", "\n", "self", ".", "log", "(", "\"train_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ")", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.infer_alignment": [[206, 295], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "model.Parser.find_k_maximum_matching", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.argmin", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "torch.gather().squeeze", "k_losses.append", "k_node_preds.append", "k_edge_preds.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.gather().view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.cat.transpose", "torch.cat.transpose", "torch.cat.transpose", "node_targets.ne", "edge_targets.ne", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "float", "node_targets.unsqueeze", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.gather", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.stack().transpose().view", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.argmin.view", "torch.argmin.view", "torch.argmin.view", "torch.gather.unsqueeze", "torch.gather.unsqueeze", "torch.gather.unsqueeze", "alignment.unsqueeze", "torch.gather.unsqueeze", "torch.gather.unsqueeze", "torch.gather.unsqueeze", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.argmin.view", "torch.argmin.view", "torch.argmin.view", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.stack().transpose", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.find_k_maximum_matching"], ["", "def", "infer_alignment", "(", "self", ",", "node_scores", ",", "edge_scores", ",", "node_targets", ",", "edge_targets", ",", "input_tokens", ",", "freeze_alignments", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tArgs:\n\t\t\tnode_scores: log scores (BS, SL, # node labels)\n\t\t\tedge_scores: log scores (BS, SL, SL, # of edge labels)\n\t\t\tnode_targets: node labels (BS, SL)\n\t\t\tedge_targets: edge labels (BS, SL, SL)\n\t\t\tinput_token = input sequences (BS x SL)\n\n\t\tReturns:\n\t\t\tPerforms Maximum Flow Minimum cost using log probabilities to infer best alignment,\n\t\t\tthen returns\n\t\t\t> aligned node_scores and edge_scores\n\t\t\t> node and edge predictions\n\t\t\t> loss\n\t\t\t> best_alignment\n\t\t\"\"\"", "\n", "batch_size", ",", "seq_len", "=", "node_targets", ".", "shape", "\n", "\n", "# Get scores for Bipartite Matching", "\n", "###################################", "\n", "# repeat each label for each input pos, i.e., along the 1st axis", "\n", "node_targets_tmp", "=", "torch", ".", "cat", "(", "[", "node_targets", ".", "unsqueeze", "(", "1", ")", "]", "*", "seq_len", ",", "1", ")", "# BS, SL -> BS, SL, SL ", "\n", "\n", "# Selects predicted scores for true labels", "\n", "relevant_node_scores", "=", "torch", ".", "gather", "(", "node_scores", ",", "2", ",", "node_targets_tmp", ")", "# BS, SL, token_dim -> BS,  SL, SL", "\n", "\n", "# Perform maximum bipartite matching", "\n", "###################################", "\n", "k_alignments", ",", "k_alignment_changes", ",", "repeated_example_ids", "=", "self", ".", "find_k_maximum_matching", "(", "\n", "relevant_node_scores", ",", "input_tokens", "=", "input_tokens", ",", "node_targets", "=", "node_targets", ",", "\n", ")", "\n", "k_losses", ",", "k_node_preds", ",", "k_edge_preds", "=", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "\n", "# if repeated_example_ids:", "\n", "#     import ipdb;ipdb.set_trace()", "\n", "\n", "# Permute log probabilities with each alignment", "\n", "###################################", "\n", "for", "alignment", "in", "k_alignments", ":", "\n", "# NODES", "\n", "# node preds: permute node targets with alignment", "\n", "\t\t\t", "node_preds", "=", "torch", ".", "gather", "(", "node_targets", ",", "-", "1", ",", "alignment", ")", "\n", "aligned_node_scores", "=", "torch", ".", "gather", "(", "node_scores", ",", "-", "1", ",", "node_preds", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "-", "1", ")", "# BS, SL, #tokens -> BS, SL", "\n", "\n", "# EDGES", "\n", "# edge label preds: permute edge targets with alignment", "\n", "align", "=", "torch", ".", "cat", "(", "[", "alignment", ".", "unsqueeze", "(", "1", ")", "]", "*", "seq_len", ",", "1", ")", "\n", "column_permuted", "=", "torch", ".", "gather", "(", "edge_targets", ",", "-", "1", ",", "align", ")", "\n", "edge_preds", "=", "torch", ".", "gather", "(", "column_permuted", ",", "1", ",", "align", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "aligned_edge_scores", "=", "torch", ".", "gather", "(", "edge_scores", ",", "-", "1", ",", "edge_preds", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", "\n", "-", "1", ")", "# BS, SL, SL, #tokens -> BS, SL, SL", "\n", "\n", "# LOSS UNDER INFERRED ALIGNMENT", "\n", "masked_node_losses", "=", "node_targets", ".", "ne", "(", "GRAPH_PAD_TOKEN", ")", "*", "aligned_node_scores", "\n", "masked_edge_losses", "=", "edge_targets", ".", "ne", "(", "GRAPH_PAD_TOKEN", ")", "*", "aligned_edge_scores", "\n", "loss", "=", "torch", ".", "sum", "(", "-", "masked_node_losses", ",", "axis", "=", "-", "1", ")", "+", "torch", ".", "sum", "(", "torch", ".", "sum", "(", "-", "masked_edge_losses", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", "\n", "\n", "k_losses", ".", "append", "(", "loss", ")", "\n", "k_node_preds", ".", "append", "(", "node_preds", ")", "\n", "k_edge_preds", ".", "append", "(", "edge_preds", ")", "\n", "\n", "# Select alignment with the smallest cost", "\n", "##############", "\n", "", "best_k", "=", "torch", ".", "argmin", "(", "torch", ".", "stack", "(", "k_losses", ")", ",", "axis", "=", "0", ")", "# gives best index among the k alignments for each example (bs)", "\n", "best_loss", "=", "torch", ".", "mean", "(", "torch", ".", "gather", "(", "torch", ".", "stack", "(", "k_losses", ")", ",", "0", ",", "best_k", ".", "view", "(", "1", ",", "-", "1", ")", ")", ".", "view", "(", "-", "1", ")", ")", "\n", "best_alignments", "=", "torch", ".", "gather", "(", "\n", "torch", ".", "stack", "(", "k_alignments", ")", ",", "0", ",", "torch", ".", "stack", "(", "\n", "[", "best_k", "]", "*", "seq_len", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "view", "(", "1", ",", "-", "1", ",", "seq_len", ")", "# bs, seq_len", "\n", ")", "\n", "best_node_preds", "=", "torch", ".", "gather", "(", "\n", "torch", ".", "stack", "(", "k_node_preds", ")", ",", "0", ",", "torch", ".", "stack", "(", "\n", "[", "best_k", "]", "*", "seq_len", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "view", "(", "1", ",", "-", "1", ",", "seq_len", ")", "\n", ")", ".", "view", "(", "-", "1", ",", "seq_len", ")", "# bs, seq_len", "\n", "\n", "best_edge_preds", "=", "torch", ".", "gather", "(", "\n", "torch", ".", "stack", "(", "k_edge_preds", ")", ",", "0", ",", "torch", ".", "stack", "(", "\n", "[", "best_k", "]", "*", "seq_len", "*", "seq_len", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "view", "(", "1", ",", "-", "1", ",", "seq_len", ",", "seq_len", ")", "\n", ")", ".", "view", "(", "-", "1", ",", "seq_len", ",", "seq_len", ")", "# bs, seq_len, seq_len", "\n", "\n", "# pick alignment changes for corresponding alignment", "\n", "if", "k_alignment_changes", ":", "\n", "\t\t\t", "actual_alignment_changes", "=", "torch", ".", "sum", "(", "\n", "torch", ".", "gather", "(", "torch", ".", "tensor", "(", "k_alignment_changes", ")", ".", "to", "(", "DEVICE", ")", ",", "0", ",", "best_k", ".", "view", "(", "1", ",", "-", "1", ")", ")", ")", "\n", "alignment_changes", "=", "actual_alignment_changes", "/", "float", "(", "batch_size", ")", "\n", "", "else", ":", "\n", "\t\t\t", "alignment_changes", "=", "-", "1.", "\n", "\n", "", "return", "(", "best_node_preds", ",", "best_edge_preds", ")", ",", "best_loss", ",", "best_alignments", ",", "alignment_changes", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._lookup_alignments": [[296, 309], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "tuple", "model.Parser.cached_alignments.get", "batch_of_indices.append", "Exception"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.get"], ["", "def", "_lookup_alignments", "(", "self", ",", "src", ")", ":", "\n", "\t\t", "\"\"\"Looks up cached alignment for each input sequence\"\"\"", "\n", "batch_of_indices", "=", "[", "]", "\n", "for", "sequence", "in", "src", ":", "\n", "\t\t\t", "example_key", "=", "tuple", "(", "sequence", "[", "sequence", "!=", "PAD_TOKEN", "]", ")", "\n", "alignment", "=", "self", ".", "cached_alignments", ".", "get", "(", "example_key", ",", "None", ")", "\n", "if", "not", "alignment", ":", "\n", "\t\t\t\t", "raise", "Exception", "(", "f\"{example_key} still missing from cached alignments. This needs to be built first\"", ")", "\n", "", "batch_of_indices", ".", "append", "(", "alignment", ")", "\n", "\n", "", "alignment", "=", "torch", ".", "tensor", "(", "batch_of_indices", ")", "\n", "alignment_changes", "=", "[", "0.", "]", "*", "bs", "\n", "return", "alignment", ",", "alignment_changes", ",", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.find_k_maximum_matching": [[310, 340], ["range", "len", "model.Parser._lookup_alignments", "model.Parser.find_maximum_matching", "top_k_alignments.append", "alignment.to", "k_alignment_changes.append", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand", "torch.rand"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._lookup_alignments", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.find_maximum_matching"], ["", "def", "find_k_maximum_matching", "(", "self", ",", "relevant_node_scores", ",", "input_tokens", "=", "None", ",", "node_targets", "=", "None", ",", "freeze_alignments", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tEstimates K approximate alignment candidates with noisy node scores.\n\t\t\"\"\"", "\n", "check_alignment_changes", "=", "False", "\n", "if", "len", "(", "self", ".", "cached_alignments", ")", "==", "self", ".", "expected_cache_size", ":", "\n", "\t\t\t", "check_alignment_changes", "=", "True", "\n", "\n", "", "if", "freeze_alignments", ":", "\n", "\t\t\t", "return", "self", ".", "_lookup_alignments", "(", "input_tokens", ")", "\n", "\n", "", "top_k_alignments", "=", "[", "]", "\n", "k_alignment_changes", "=", "[", "]", "\n", "\n", "for", "_", "in", "range", "(", "self", ".", "k", ")", ":", "\n", "# Adds noise to node scores", "\n", "\t\t\t", "noise", "=", "(", "torch", ".", "rand", "(", "relevant_node_scores", ".", "shape", ")", "*", "(", "self", ".", "noise", ")", ")", ".", "to", "(", "DEVICE", ")", "\n", "noisy_scores", "=", "relevant_node_scores", "+", "noise", "\n", "\n", "# Calculate approx alignment with noisy scores", "\n", "alignment", ",", "alignment_changes", ",", "repeated_example_ids", "=", "self", ".", "find_maximum_matching", "(", "\n", "noisy_scores", ",", "input_tokens", ",", "node_targets", ",", "check_alignment_changes", "=", "check_alignment_changes", ")", "\n", "\n", "# Save alignment for later", "\n", "top_k_alignments", ".", "append", "(", "alignment", ".", "to", "(", "DEVICE", ")", ")", "\n", "if", "check_alignment_changes", ":", "\n", "\t\t\t\t", "k_alignment_changes", ".", "append", "(", "alignment_changes", ")", "\n", "\n", "", "", "return", "top_k_alignments", ",", "k_alignment_changes", ",", "repeated_example_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.find_maximum_matching": [[341, 398], ["src.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "relevant_node_scores.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "node_targets.detach().cpu().numpy.detach().cpu().numpy.detach().cpu().numpy", "enumerate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "relevant_node_scores[].copy", "collections.Counter", "numpy.any", "tuple", "scipy.optimize.linear_sum_assignment", "numpy.arange", "batch_of_indices.append", "src.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "relevant_node_scores.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "node_targets.detach().cpu().numpy.detach().cpu().numpy.detach().cpu", "repeated_example_ids.append", "numpy.where", "src.detach().cpu().numpy.utils.compare_alignments", "src.detach().cpu().numpy.detach().cpu().numpy.detach", "relevant_node_scores.detach().cpu().numpy.detach().cpu().numpy.detach", "node_targets.detach().cpu().numpy.detach().cpu().numpy.detach", "collections.Counter.items"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.compare_alignments"], ["", "def", "find_maximum_matching", "(", "self", ",", "relevant_node_scores", ",", "src", ",", "node_targets", ",", "check_alignment_changes", "=", "False", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tBuilds bipartite graph and finds the maximum matching, i.e. the best alignment that maximizes the log probabilities.\n\t\tArgs:\n\t\t\trelevant_node_scores:  (BS x SL x SL)\n\t\t\tsrc: (BS x SL)\n\t\tReturns:\n\t\t\tbatch of alignment indices where an index denotes the position in the target sequence.\n\t\t\"\"\"", "\n", "bs", "=", "node_targets", ".", "shape", "[", "0", "]", "\n", "src", "=", "src", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "batch_of_indices", "=", "[", "]", "\n", "\n", "# num_layers = int(relevant_node_scores[0].shape[0] / src[0].shape[0])", "\n", "relevant_node_scores", "=", "relevant_node_scores", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "node_targets", "=", "node_targets", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "repeated_example_ids", "=", "[", "]", "\n", "alignment_changes", "=", "[", "]", "\n", "\n", "for", "example_id", ",", "cost", "in", "enumerate", "(", "relevant_node_scores", ")", ":", "\n", "\t\t\t", "cost", "=", "relevant_node_scores", "[", "example_id", "]", ".", "copy", "(", ")", "\n", "node_targ_seq", "=", "node_targets", "[", "example_id", "]", "\n", "counter", "=", "Counter", "(", "node_targ_seq", ")", "\n", "repeated_labels_example", "=", "np", ".", "any", "(", "[", "True", "for", "k", ",", "v", "in", "counter", ".", "items", "(", ")", "if", "v", ">", "1", "and", "k", "!=", "0", "]", ")", "\n", "if", "repeated_labels_example", ":", "\n", "\t\t\t\t", "repeated_example_ids", ".", "append", "(", "example_id", ")", "\n", "\n", "# example id for caching alignments and constraining", "\n", "", "in_sequence", "=", "src", "[", "example_id", "]", "\n", "# remove padding from inp sequence", "\n", "example_key", "=", "tuple", "(", "in_sequence", "[", "in_sequence", "!=", "PAD_TOKEN", "]", ")", "\n", "\n", "# relevant_positions = np.where((node_targ_seq != GRAPH_PAD_TOKEN) & (node_targ_seq != NULL_TOKEN))[0]", "\n", "relevant_positions", "=", "np", ".", "where", "(", "node_targ_seq", "!=", "GRAPH_PAD_TOKEN", ")", "[", "0", "]", "\n", "\n", "non_pad_cost", "=", "cost", "[", "relevant_positions", "]", "[", ":", ",", "relevant_positions", "]", "\n", "_", ",", "col_ids", "=", "linear_sum_assignment", "(", "-", "non_pad_cost", ")", "\n", "col_ids", "+=", "1", "*", "self", ".", "args", "[", "\"n_graph_layers\"", "]", "# shift to right by n_graph_layers (due to padding for BOS token)", "\n", "\n", "all_col_ids", "=", "np", ".", "arange", "(", "node_targ_seq", ".", "shape", "[", "0", "]", ")", "\n", "all_col_ids", "[", "relevant_positions", "]", "=", "col_ids", "# keep nulls and pads at their original place, only permute actual nodes", "\n", "\n", "batch_of_indices", ".", "append", "(", "all_col_ids", ")", "\n", "\n", "# Calculate % of examples where alignment changes", "\n", "if", "check_alignment_changes", ":", "\n", "\t\t\t\t", "prev_alignment", "=", "self", ".", "cached_alignments", "[", "example_key", "]", "\n", "alignment_changes", "+=", "compare_alignments", "(", "prev_alignment", ",", "col_ids", ",", "node_targ_seq", ")", "\n", "\n", "# Save latest alignment in cache", "\n", "", "self", ".", "cached_alignments", "[", "example_key", "]", "=", "col_ids", "\n", "\n", "", "alignment", "=", "torch", ".", "tensor", "(", "batch_of_indices", ")", "\n", "\n", "return", "alignment", ",", "alignment_changes", ",", "repeated_example_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._weakly_sup_loss": [[399, 414], ["src.utils.add_eos", "src.utils.add_eos", "model.Parser.model", "model.Parser.infer_alignment", "tgt_length_with_eos.max().item", "tgt_length_with_eos.max"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.infer_alignment"], ["", "def", "_weakly_sup_loss", "(", "self", ",", "batch", ")", ":", "\n", "# Adds EOS to src and tgt", "\n", "\t\t", "src_tokens", "=", "add_eos", "(", "batch", "[", "\"src\"", "]", ",", "batch", "[", "\"src_len\"", "]", ",", "self", ".", "model", ".", "encoder_eos", ")", "\n", "tgt_tokens", "=", "add_eos", "(", "batch", "[", "\"tgt\"", "]", ",", "batch", "[", "\"tgt_len\"", "]", ",", "self", ".", "model", ".", "decoder_sos_eos", ")", "\n", "src_length_with_eos", "=", "batch", "[", "\"src_len\"", "]", "+", "1", "\n", "tgt_length_with_eos", "=", "batch", "[", "\"tgt_len\"", "]", "+", "1", "\n", "\n", "# Runs model", "\n", "result", "=", "self", ".", "model", "(", "src_tokens", ",", "src_length_with_eos", ",", "tgt_tokens", ",", "tgt_length_with_eos", ",", "\n", "teacher_forcing", "=", "self", ".", "training", ",", "max_len", "=", "tgt_length_with_eos", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "aligned_preds", ",", "loss", ",", "_", ",", "alignment_changes", "=", "self", ".", "infer_alignment", "(", "\n", "*", "result", ",", "batch", "[", "\"node_tgt\"", "]", ",", "batch", "[", "\"edge_tgt\"", "]", ",", "input_tokens", "=", "batch", "[", "\"src\"", "]", ")", "\n", "\n", "return", "loss", ",", "result", ",", "aligned_preds", ",", "alignment_changes", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.validation_step": [[415, 421], ["model.Parser._eval_model"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._eval_model"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "_", ",", "dataset_idx", ")", ":", "\n", "\t\t", "if", "dataset_idx", "==", "0", ":", "\n", "\t\t\t", "flag", "=", "'val'", "\n", "", "else", ":", "\n", "\t\t\t", "flag", "=", "'train_val'", "\n", "", "self", ".", "_eval_model", "(", "batch", ",", "flag", "=", "flag", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser.test_step": [[422, 424], ["model.Parser._eval_model"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._eval_model"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "_", ",", "dataset_idx", ")", ":", "\n", "\t\t", "self", ".", "_eval_model", "(", "batch", ",", "flag", "=", "self", ".", "flags", "[", "dataset_idx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._eval_model": [[425, 468], ["model.Parser._calculate_loss", "model.Parser.stats._compute_acc", "model.Parser.log", "model.Parser.log", "model.Parser.log", "Exception", "model.Parser._calculate_loss", "model.Parser.stats.strongly_sup_metrics", "model.Parser.log", "model.Parser.log", "model.Parser.log", "model.Parser.log", "model.Parser.log", "model.Parser.log", "src.utils.add_eos", "src.utils.add_eos", "model.Parser.model", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "model.Parser.graph_accuracy", "model.Parser.log", "print", "sys.exit", "batch[].max().item", "batch[].max"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._calculate_loss", "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._compute_acc", "home.repos.pwc.inspect_result.elementai_lagr.src.model.Parser._calculate_loss", "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.strongly_sup_metrics", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos"], ["", "def", "_eval_model", "(", "self", ",", "batch", ",", "flag", ")", ":", "\n", "\t\t", "\"\"\"Evaluates current model on given batch of data. Returns loss, and accuracy.\"\"\"", "\n", "\n", "if", "self", ".", "model_type", "==", "\"transformer_baseline\"", ":", "\n", "\t\t\t", "loss", ",", "scores", "=", "self", ".", "_calculate_loss", "(", "batch", ")", "\n", "exact_acc", ",", "acc", "=", "self", ".", "stats", ".", "_compute_acc", "(", "batch", "[", "\"tgt\"", "]", ",", "batch", "[", "\"tgt_len\"", "]", ",", "scores", ")", "\n", "\n", "self", ".", "log", "(", "f\"{flag}_exact_acc\"", ",", "exact_acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "self", ".", "log", "(", "f\"{flag}_acc\"", ",", "acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "self", ".", "log", "(", "f\"{flag}_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "\n", "", "elif", "self", ".", "model_type", "==", "\"transformer_lagr\"", ":", "\n", "\t\t\t", "if", "not", "self", ".", "weakly", ":", "\n", "\t\t\t\t", "loss", ",", "scores", "=", "self", ".", "_calculate_loss", "(", "batch", ")", "\n", "node_acc", ",", "edge_acc", ",", "node_exact_acc", ",", "edge_exact_acc", ",", "exact_acc", "=", "self", ".", "stats", ".", "strongly_sup_metrics", "(", "batch", ",", "*", "scores", ")", "\n", "\n", "self", ".", "log", "(", "f\"{flag}_loss\"", ",", "loss", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "self", ".", "log", "(", "f\"{flag}_node_acc\"", ",", "node_acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "self", ".", "log", "(", "f\"{flag}_edge_acc\"", ",", "edge_acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "self", ".", "log", "(", "f\"{flag}_node_exact_acc\"", ",", "node_exact_acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "self", ".", "log", "(", "f\"{flag}_edge_exact_acc\"", ",", "edge_exact_acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "self", ".", "log", "(", "f\"{flag}_exact_acc\"", ",", "exact_acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "src_tokens", "=", "add_eos", "(", "batch", "[", "\"src\"", "]", ",", "batch", "[", "\"src_len\"", "]", ",", "self", ".", "model", ".", "encoder_eos", ")", "\n", "tgt_tokens", "=", "add_eos", "(", "batch", "[", "\"tgt\"", "]", ",", "batch", "[", "\"tgt_len\"", "]", ",", "self", ".", "model", ".", "decoder_sos_eos", ")", "\n", "# Runs model", "\n", "(", "node_scores", ",", "edge_scores", ")", "=", "self", ".", "model", "(", "src_tokens", ",", "batch", "[", "\"src_len\"", "]", "+", "1", ",", "tgt_tokens", ",", "batch", "[", "\"tgt_len\"", "]", "+", "1", ",", "\n", "max_len", "=", "batch", "[", "\"tgt_len\"", "]", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ")", "\n", "\n", "# Argmax inference", "\n", "node_preds", "=", "torch", ".", "argmax", "(", "node_scores", ",", "axis", "=", "-", "1", ")", "\n", "edge_preds", "=", "torch", ".", "argmax", "(", "edge_scores", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Graph accuracy - For CFQ only exact acc is available", "\n", "_", ",", "_", ",", "_", ",", "_", ",", "exact_acc", "=", "self", ".", "graph_accuracy", "(", "node_preds", ",", "edge_preds", ",", "batch", ")", "\n", "self", ".", "log", "(", "f\"{flag}_exact_acc\"", ",", "exact_acc", ",", "prog_bar", "=", "True", ",", "add_dataloader_idx", "=", "False", ")", "\n", "\n", "# Restarts job if not converging on train graph accuracy", "\n", "if", "self", ".", "data", "==", "'cogs'", "and", "flag", "==", "'train_val'", "and", "exact_acc", "<", ".98", "and", "self", ".", "global_step", ">", "15000", ":", "\n", "\t\t\t\t\t", "print", "(", "f'Model not converging on training set w exact acc of {exact_acc} at step={self.global_step}.'", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "", "", "", "else", ":", "\n", "\t\t\t", "raise", "Exception", "(", "f\"Unknown model: {self.model_type}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.model.cross_entropy": [[35, 78], ["target.flatten().long", "input.flatten", "input.flatten.gather().squeeze", "torch.NLLLoss", "nn.NLLLoss.", "input.flatten.sum", "torch.where", "torch.where", "torch.where", "tmask.float().sum", "target.flatten().long.nelement", "torch.where.view_as", "target.flatten", "torch.where.view_as", "input.flatten.gather", "torch.zeros", "torch.zeros", "torch.zeros", "target.flatten().long.unsqueeze", "math.log", "math.log", "tmask.float", "torch.where.sum", "torch.where.sum"], "function", ["None"], ["def", "cross_entropy", "(", "input", ":", "torch", ".", "Tensor", ",", "target", ":", "torch", ".", "Tensor", ",", "reduction", ":", "str", "=", "\"mean\"", ",", "smoothing", ":", "float", "=", "0", ",", "\n", "ignore_index", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "# Flatten inputs to 2D", "\n", "\t", "t2", "=", "target", ".", "flatten", "(", ")", ".", "long", "(", ")", "\n", "i2", "=", "input", ".", "flatten", "(", "end_dim", "=", "-", "2", ")", "\n", "\n", "# If no smoothing, use built-in negative log loss", "\n", "if", "smoothing", "==", "0", ":", "\n", "\t\t", "criterion", "=", "nn", ".", "NLLLoss", "(", "ignore_index", "=", "-", "100", "if", "ignore_index", "is", "None", "else", "ignore_index", ",", "reduction", "=", "reduction", ")", "\n", "loss", "=", "criterion", "(", "i2", ",", "t2", ")", "\n", "if", "reduction", "==", "\"none\"", ":", "\n", "\t\t\t", "return", "loss", ".", "view_as", "(", "target", ")", "\n", "", "else", ":", "\n", "\t\t\t", "return", "loss", "\n", "\n", "# Calculate the softmax cross entropy loss", "\n", "", "", "right_class", "=", "i2", ".", "gather", "(", "-", "1", ",", "t2", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "squeeze", "(", ")", "\n", "others", "=", "i2", ".", "sum", "(", "-", "1", ")", "-", "right_class", "\n", "\n", "# KL divergence", "\n", "loss", "=", "(", "smoothing", "-", "1.0", ")", "*", "right_class", "-", "others", "*", "smoothing", "\n", "optimal_loss", "=", "-", "(", "(", "1.0", "-", "smoothing", ")", "*", "math", ".", "log", "(", "1", "-", "smoothing", ")", "+", "(", "i2", ".", "shape", "[", "1", "]", "-", "1", ")", "*", "smoothing", "*", "math", ".", "log", "(", "smoothing", ")", ")", "\n", "\n", "loss", "=", "loss", "-", "optimal_loss", "\n", "\n", "# Handle masking if igonore_index is specified", "\n", "if", "ignore_index", "is", "not", "None", ":", "\n", "\t\t", "tmask", "=", "t2", "!=", "ignore_index", "\n", "loss", "=", "torch", ".", "where", "(", "tmask", ",", "loss", ",", "torch", ".", "zeros", "(", "[", "1", "]", ",", "dtype", "=", "loss", ".", "dtype", ",", "device", "=", "loss", ".", "device", ")", ")", "\n", "n_total", "=", "tmask", ".", "float", "(", ")", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "\t\t", "n_total", "=", "t2", ".", "nelement", "(", ")", "\n", "\n", "# Reduction", "\n", "", "if", "reduction", "==", "\"none\"", ":", "\n", "\t\t", "return", "loss", ".", "view_as", "(", "target", ")", "\n", "", "elif", "reduction", "==", "\"mean\"", ":", "\n", "\t\t", "return", "loss", ".", "sum", "(", ")", "/", "n_total", "\n", "", "elif", "reduction", "==", "\"sum\"", ":", "\n", "\t\t", "return", "loss", ".", "sum", "(", ")", "\n", "", "else", ":", "\n", "\t\t", "assert", "False", ",", "f\"Invalid reduction {reduction}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.__init__": [[44, 55], ["super().__init__", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "pe.unsqueeze.unsqueeze.unsqueeze", "transformer.PositionalEncoding.register_buffer", "transformer.sinusoidal_pos_embedding"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.sinusoidal_pos_embedding"], ["def", "__init__", "(", "self", ",", "d_model", ":", "int", ",", "dropout", ":", "float", "=", "0.1", ",", "max_len", ":", "int", "=", "5000", ",", "batch_first", ":", "bool", "=", "False", ",", "\n", "scale", ":", "float", "=", "1", ")", ":", "\n", "\t\t", "super", "(", "PositionalEncoding", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "\n", "pe", "=", "sinusoidal_pos_embedding", "(", "d_model", ",", "max_len", ",", "0", ")", "*", "scale", "\n", "\n", "self", ".", "batch_dim", "=", "0", "if", "batch_first", "else", "1", "\n", "pe", "=", "pe", ".", "unsqueeze", "(", "self", ".", "batch_dim", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'pe'", ",", "pe", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.get": [[56, 58], ["transformer.PositionalEncoding.pe.narrow"], "methods", ["None"], ["", "def", "get", "(", "self", ",", "n", ":", "int", ",", "offset", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "return", "self", ".", "pe", ".", "narrow", "(", "1", "-", "self", ".", "batch_dim", ",", "start", "=", "offset", ",", "length", "=", "n", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.forward": [[59, 62], ["transformer.PositionalEncoding.dropout", "transformer.PositionalEncoding.get", "x.size"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.get"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "offset", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "x", "=", "x", "+", "self", ".", "get", "(", "x", ".", "size", "(", "1", "-", "self", ".", "batch_dim", ")", ",", "offset", ")", "\n", "return", "self", ".", "dropout", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TiedEmbedding.__init__": [[65, 71], ["super().__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "weights", ":", "torch", ".", "Tensor", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# Hack: won't save it as a parameter", "\n", "self", ".", "w", "=", "[", "weights", "]", "\n", "self", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "w", "[", "0", "]", ".", "shape", "[", "0", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TiedEmbedding.forward": [[72, 74], ["torch.linear", "torch.linear", "torch.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "t", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "return", "F", ".", "linear", "(", "t", ",", "self", ".", "w", "[", "0", "]", ",", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoderLayer.__init__": [[77, 91], ["super().__init__", "src.attention.MultiHeadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "transformer.TransformerEncoderLayer.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.reset_parameters"], ["\t", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", ",", "dim_feedforward", "=", "2048", ",", "dropout", "=", "0.1", ",", "activation", ":", "ActivationFunction", "=", "F", ".", "relu", ")", ":", "\n", "\t\t", "super", "(", "TransformerEncoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "self_attn", "=", "MultiHeadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "linear1", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model", ",", "dim_feedforward", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear2", "=", "torch", ".", "nn", ".", "Linear", "(", "dim_feedforward", ",", "d_model", ")", "\n", "\n", "self", ".", "norm1", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout1", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoderLayer.forward": [[92, 100], ["transformer.TransformerEncoderLayer.self_attn", "transformer.TransformerEncoderLayer.norm1", "transformer.TransformerEncoderLayer.linear2", "transformer.TransformerEncoderLayer.norm2", "transformer.TransformerEncoderLayer.attention.AttentionMask", "transformer.TransformerEncoderLayer.dropout1", "transformer.TransformerEncoderLayer.dropout", "transformer.TransformerEncoderLayer.dropout2", "transformer.TransformerEncoderLayer.activation", "transformer.TransformerEncoderLayer.linear1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "src2", "=", "self", ".", "self_attn", "(", "src", ",", "src", ",", "AttentionMask", "(", "mask", ",", "None", ")", ")", "\n", "src", "=", "src", "+", "self", ".", "dropout1", "(", "src2", ")", "\n", "src", "=", "self", ".", "norm1", "(", "src", ")", "\n", "src2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "src", ")", ")", ")", ")", "\n", "src", "=", "src", "+", "self", ".", "dropout2", "(", "src2", ")", "\n", "src", "=", "self", ".", "norm2", "(", "src", ")", "\n", "return", "src", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoderLayer.reset_parameters": [[101, 105], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "\t\t", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "linear1", ".", "weight", ",", "gain", "=", "torch", ".", "nn", ".", "init", ".", "calculate_gain", "(", "'relu'", ")", "\n", "if", "self", ".", "activation", "is", "F", ".", "relu", "else", "1.0", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "linear2", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderLayer.__init__": [[108, 126], ["super().__init__", "src.attention.MultiHeadAttention", "src.attention.MultiHeadAttention", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.LayerNorm", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "torch.nn.Dropout", "transformer.TransformerDecoderLayer.reset_parameters"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.reset_parameters"], ["\t", "def", "__init__", "(", "self", ",", "d_model", ",", "nhead", ",", "dim_feedforward", "=", "2048", ",", "dropout", "=", "0.1", ",", "activation", ":", "ActivationFunction", "=", "F", ".", "relu", ")", ":", "\n", "\t\t", "super", "(", "TransformerDecoderLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "self_attn", "=", "MultiHeadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "multihead_attn", "=", "MultiHeadAttention", "(", "d_model", ",", "nhead", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "linear1", "=", "torch", ".", "nn", ".", "Linear", "(", "d_model", ",", "dim_feedforward", ")", "\n", "self", ".", "dropout", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "linear2", "=", "torch", ".", "nn", ".", "Linear", "(", "dim_feedforward", ",", "d_model", ")", "\n", "\n", "self", ".", "norm1", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm2", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "norm3", "=", "torch", ".", "nn", ".", "LayerNorm", "(", "d_model", ")", "\n", "self", ".", "dropout1", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout2", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "self", ".", "dropout3", "=", "torch", ".", "nn", ".", "Dropout", "(", "dropout", ")", "\n", "\n", "self", ".", "activation", "=", "activation", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderLayer.forward": [[127, 142], ["transformer.TransformerDecoderLayer.self_attn", "transformer.TransformerDecoderLayer.norm1", "transformer.TransformerDecoderLayer.multihead_attn", "transformer.TransformerDecoderLayer.norm2", "transformer.TransformerDecoderLayer.linear2", "transformer.TransformerDecoderLayer.norm3", "transformer.TransformerDecoderLayer.dropout1", "transformer.TransformerDecoderLayer.dropout2", "transformer.TransformerDecoderLayer.dropout", "transformer.TransformerDecoderLayer.dropout3", "src.attention.AttentionMask", "src.attention.AttentionMask", "transformer.TransformerDecoderLayer.activation", "transformer.TransformerDecoderLayer.linear1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tgt", ":", "torch", ".", "Tensor", ",", "memory", ":", "torch", ".", "Tensor", ",", "tgt_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "memory_key_padding_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "full_target", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "pos_offset", ":", "int", "=", "0", ")", "->", "torch", ".", "Tensor", ":", "\n", "\n", "\t\t", "assert", "pos_offset", "==", "0", "or", "tgt_mask", "is", "None", "\n", "tgt2", "=", "self", ".", "self_attn", "(", "tgt", ",", "tgt", "if", "full_target", "is", "None", "else", "full_target", ",", "mask", "=", "AttentionMask", "(", "None", ",", "tgt_mask", ")", ")", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout1", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm1", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "multihead_attn", "(", "tgt", ",", "memory", ",", "mask", "=", "AttentionMask", "(", "memory_key_padding_mask", ",", "None", ")", ")", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout2", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm2", "(", "tgt", ")", "\n", "tgt2", "=", "self", ".", "linear2", "(", "self", ".", "dropout", "(", "self", ".", "activation", "(", "self", ".", "linear1", "(", "tgt", ")", ")", ")", ")", "\n", "tgt", "=", "tgt", "+", "self", ".", "dropout3", "(", "tgt2", ")", "\n", "tgt", "=", "self", ".", "norm3", "(", "tgt", ")", "\n", "return", "tgt", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderLayer.reset_parameters": [[143, 147], ["torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.xavier_uniform_", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain", "torch.nn.init.calculate_gain"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "\t\t", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "linear1", ".", "weight", ",", "gain", "=", "torch", ".", "nn", ".", "init", ".", "calculate_gain", "(", "'relu'", ")", "\n", "if", "self", ".", "activation", "is", "F", ".", "relu", "else", "1.0", ")", "\n", "torch", ".", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "linear2", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderBase.__init__": [[155, 158], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["", "def", "__init__", "(", "self", ",", "d_model", ":", "int", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d_model", "=", "d_model", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderBase.create_state": [[159, 162], ["transformer.TransformerDecoderBase.State", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "torch.empty", "range", "len"], "methods", ["None"], ["", "def", "create_state", "(", "self", ",", "batch_size", ":", "int", ",", "max_length", ":", "int", ",", "device", ":", "torch", ".", "device", ")", "->", "State", ":", "\n", "\t\t", "return", "self", ".", "State", "(", "0", ",", "{", "i", ":", "torch", ".", "empty", "(", "[", "batch_size", ",", "max_length", ",", "self", ".", "d_model", "]", ",", "device", "=", "device", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "self", ".", "layers", ")", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderBase.one_step_forward": [[163, 174], ["enumerate", "l"], "methods", ["None"], ["", "def", "one_step_forward", "(", "self", ",", "state", ":", "State", ",", "data", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "assert", "data", ".", "shape", "[", "1", "]", "==", "1", ",", "f\"For one-step forward should have one timesteps, but shape is {data.shape}\"", "\n", "assert", "state", ".", "step", "<", "state", ".", "state", "[", "0", "]", ".", "shape", "[", "1", "]", "\n", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "self", ".", "layers", ")", ":", "\n", "\t\t\t", "state", ".", "state", "[", "i", "]", "[", ":", ",", "state", ".", "step", ":", "state", ".", "step", "+", "1", "]", "=", "data", "\n", "data", "=", "l", "(", "data", ",", "*", "args", ",", "**", "kwargs", ",", "full_target", "=", "state", ".", "state", "[", "i", "]", "[", ":", ",", ":", "state", ".", "step", "+", "1", "]", ",", "\n", "pos_offset", "=", "state", ".", "step", ")", "\n", "\n", "", "state", ".", "step", "+=", "1", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoder.__init__": [[177, 180], ["super().__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "layer", "range"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "layer", ",", "n_layers", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "layer", "(", "*", "args", ",", "**", "kwargs", ")", "for", "_", "in", "range", "(", "n_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoder.forward": [[181, 185], ["l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "data", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "for", "l", "in", "self", ".", "layers", ":", "\n", "\t\t\t", "data", "=", "l", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoder.__init__": [[188, 191], ["transformer.TransformerDecoderBase.__init__", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.nn.ModuleList", "layer", "range"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "layer", ",", "n_layers", ":", "int", ",", "d_model", ":", "int", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", "d_model", ")", "\n", "self", ".", "layers", "=", "torch", ".", "nn", ".", "ModuleList", "(", "[", "layer", "(", "d_model", ",", "*", "args", ",", "**", "kwargs", ")", "for", "_", "in", "range", "(", "n_layers", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoder.forward": [[192, 196], ["l"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "data", ":", "torch", ".", "Tensor", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "for", "l", "in", "self", ".", "layers", ":", "\n", "\t\t\t", "data", "=", "l", "(", "data", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.Transformer.__init__": [[207, 217], ["transformer.TransformerEncoderWithLayer", "transformer.TransformerDecoderWithLayer", "super().__init__", "encoder_layer", "decoder_layer"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoderWithLayer", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderWithLayer", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "d_model", ":", "int", "=", "512", ",", "nhead", ":", "int", "=", "8", ",", "num_encoder_layers", ":", "int", "=", "6", ",", "\n", "num_decoder_layers", ":", "int", "=", "6", ",", "dim_feedforward", ":", "int", "=", "2048", ",", "dropout", ":", "float", "=", "0.1", ",", "\n", "activation", ":", "ActivationFunction", "=", "F", ".", "relu", ",", "encoder_layer", "=", "TransformerEncoderWithLayer", "(", ")", ",", "\n", "decoder_layer", "=", "TransformerDecoderWithLayer", "(", ")", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder", "=", "encoder_layer", "(", "num_encoder_layers", ",", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "\n", "dropout", ",", "activation", ")", "\n", "self", ".", "decoder", "=", "decoder_layer", "(", "num_decoder_layers", ",", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "\n", "dropout", ",", "activation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.Transformer.forward": [[218, 223], ["transformer.Transformer.encoder", "transformer.Transformer.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "tgt", ":", "torch", ".", "Tensor", ",", "tgt_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ",", "\n", "src_length_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "\n", "\t\t", "memory", "=", "self", ".", "encoder", "(", "src", ",", "src_length_mask", ")", "\n", "return", "self", ".", "decoder", "(", "tgt", ",", "memory", ",", "tgt_mask", ",", "src_length_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.Transformer.generate_square_subsequent_mask": [[224, 226], ["torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.triu", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["None"], ["", "def", "generate_square_subsequent_mask", "(", "self", ",", "sz", ":", "int", ",", "device", ":", "torch", ".", "device", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "return", "torch", ".", "triu", "(", "torch", ".", "ones", "(", "sz", ",", "sz", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", ",", "diagonal", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerWithSeparateEncoderLAGr.__init__": [[229, 240], ["transformer.TransformerEncoderWithLayer", "torch.Module.__init__", "encoder_layer", "encoder_layer", "transformer.LAGr"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoderWithLayer", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "d_model", ":", "int", "=", "512", ",", "n_graph_layers", ":", "int", "=", "1", ",", "n_node_labels", ":", "int", "=", "646", ",", "n_edge_labels", ":", "int", "=", "11", ",", "\n", "nhead", "=", "4", ",", "num_encoder_layers", ":", "int", "=", "6", ",", "dim_feedforward", "=", "2048", ",", "dropout", ":", "float", "=", "0.4", ",", "\n", "activation", ":", "ActivationFunction", "=", "F", ".", "relu", ",", "encoder_layer", "=", "TransformerEncoderWithLayer", "(", ")", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "node_encoder", "=", "encoder_layer", "(", "num_encoder_layers", ",", "d_model", ",", "nhead", "=", "nhead", ",", "dim_feedforward", "=", "dim_feedforward", ",", "\n", "dropout", "=", "dropout", ",", "activation", "=", "F", ".", "relu", ")", "\n", "self", ".", "edge_encoder", "=", "encoder_layer", "(", "num_encoder_layers", ",", "d_model", ",", "nhead", "=", "nhead", ",", "dim_feedforward", "=", "dim_feedforward", ",", "\n", "dropout", "=", "dropout", ",", "activation", "=", "F", ".", "relu", ")", "\n", "\n", "self", ".", "decoder", "=", "LAGr", "(", "n_node_labels", "=", "n_node_labels", ",", "n_edge_labels", "=", "n_edge_labels", ",", "dim", "=", "d_model", ",", "n_graph_layers", "=", "n_graph_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerWithSeparateEncoderLAGr.forward": [[241, 247], ["transformer.TransformerWithSeparateEncoderLAGr.node_encoder", "transformer.TransformerWithSeparateEncoderLAGr.edge_encoder", "transformer.TransformerWithSeparateEncoderLAGr.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "src_length_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "\t\t", "node_embeds", "=", "self", ".", "node_encoder", "(", "src", ",", "src_length_mask", ")", "\n", "edge_embeds", "=", "self", ".", "edge_encoder", "(", "src", ",", "src_length_mask", ")", "\n", "node_scores", ",", "edge_scores", "=", "self", ".", "decoder", "(", "node_embeds", ",", "edge_embeds", ")", "\n", "\n", "return", "(", "node_scores", ",", "edge_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerWithSharedEncoderLAGr.__init__": [[250, 257], ["transformer.TransformerEncoderWithLayer", "torch.Module.__init__", "encoder_layer", "transformer.LAGr"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoderWithLayer", "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "d_model", ":", "int", "=", "512", ",", "n_graph_layers", ":", "int", "=", "1", ",", "n_node_labels", ":", "int", "=", "646", ",", "n_edge_labels", ":", "int", "=", "11", ",", "\n", "nhead", ":", "int", "=", "8", ",", "num_encoder_layers", ":", "int", "=", "6", ",", "dim_feedforward", ":", "int", "=", "2048", ",", "dropout", ":", "float", "=", "0.1", ",", "\n", "activation", ":", "ActivationFunction", "=", "F", ".", "relu", ",", "encoder_layer", "=", "TransformerEncoderWithLayer", "(", ")", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "encoder", "=", "encoder_layer", "(", "num_encoder_layers", ",", "d_model", ",", "nhead", ",", "dim_feedforward", ",", "dropout", ",", "activation", "=", "activation", ")", "\n", "self", ".", "decoder", "=", "LAGr", "(", "n_node_labels", "=", "n_node_labels", ",", "n_edge_labels", "=", "n_edge_labels", ",", "dim", "=", "d_model", ",", "n_graph_layers", "=", "n_graph_layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerWithSharedEncoderLAGr.forward": [[258, 264], ["transformer.TransformerWithSharedEncoderLAGr.encoder", "transformer.TransformerWithSharedEncoderLAGr.decoder"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "src_length_mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "\n", "\t\t", "memory", "=", "self", ".", "encoder", "(", "src", ",", "src_length_mask", ")", "\n", "node_embeds", ",", "edge_embeds", "=", "memory", ",", "memory", "\n", "node_scores", ",", "edge_scores", "=", "self", ".", "decoder", "(", "node_embeds", ",", "edge_embeds", ")", "\n", "return", "(", "node_scores", ",", "edge_scores", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.__init__": [[267, 312], ["torch.Module.__init__", "transformer.TransformerEncDecModel.register_buffer", "transformer.TransformerEncDecModel.construct", "transformer.TransformerEncDecModel.reset_parameters", "transformer.PositionalEncoding", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.sqrt"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.construct", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.reset_parameters"], ["\t", "def", "__init__", "(", "self", ",", "n_input_tokens", ":", "int", ",", "n_out_tokens", ":", "int", ",", "state_size", ":", "int", "=", "512", ",", "ff_multiplier", ":", "float", "=", "4", ",", "\n", "max_len", ":", "int", "=", "5000", ",", "transformer", "=", "Transformer", ",", "n_graph_layers", ":", "int", "=", "1", ",", "n_node_labels", ":", "int", "=", "646", ",", "\n", "n_edge_labels", ":", "int", "=", "11", ",", "tied_embedding", ":", "bool", "=", "False", ",", "\n", "pos_embeddig", ":", "Optional", "[", "Callable", "[", "[", "torch", ".", "Tensor", ",", "int", "]", ",", "torch", ".", "Tensor", "]", "]", "=", "None", ",", "\n", "encoder_sos", ":", "bool", "=", "True", ",", "same_enc_dec_embedding", ":", "bool", "=", "False", ",", "embedding_init", ":", "str", "=", "\"pytorch\"", ",", "\n", "in_embedding_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "out_embedding_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "scale_mode", ":", "str", "=", "\"none\"", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "'''\n\t\tTransformer encoder-decoder.\n\t\t:param n_input_tokens: Number of channels for the input vectors\n\t\t:param n_out_tokens: Number of channels for the output vectors\n\t\t:param state_size: The size of the internal state of the transformer\n\t\t'''", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "assert", "scale_mode", "in", "[", "\"none\"", ",", "\"opennmt\"", ",", "\"down\"", "]", "\n", "assert", "embedding_init", "in", "[", "\"pytorch\"", ",", "\"xavier\"", ",", "\"kaiming\"", "]", "\n", "\n", "assert", "(", "not", "same_enc_dec_embedding", ")", "or", "(", "n_input_tokens", "==", "n_out_tokens", ")", "\n", "\n", "self", ".", "tied_embedding", "=", "tied_embedding", "\n", "\n", "self", ".", "decoder_sos_eos", "=", "n_out_tokens", "# weird name seems to be the EOS token for the decoder", "\n", "self", ".", "encoder_eos", "=", "n_input_tokens", "\n", "self", ".", "encoder_sos", "=", "n_input_tokens", "+", "1", "if", "encoder_sos", "else", "None", "\n", "self", ".", "state_size", "=", "state_size", "\n", "self", ".", "embedding_init", "=", "embedding_init", "\n", "\n", "self", ".", "n_graph_layers", "=", "n_graph_layers", "\n", "self", ".", "n_node_labels", "=", "n_node_labels", "\n", "self", ".", "n_edge_labels", "=", "n_edge_labels", "\n", "\n", "self", ".", "ff_multiplier", "=", "ff_multiplier", "\n", "self", ".", "n_input_tokens", "=", "n_input_tokens", "\n", "self", ".", "n_out_tokens", "=", "n_out_tokens", "\n", "self", ".", "in_embedding_size", "=", "in_embedding_size", "\n", "self", ".", "out_embedding_size", "=", "out_embedding_size", "\n", "self", ".", "same_enc_dec_embedding", "=", "same_enc_dec_embedding", "\n", "self", ".", "scale_mode", "=", "scale_mode", "\n", "self", ".", "pos", "=", "pos_embeddig", "or", "PositionalEncoding", "(", "state_size", ",", "max_len", "=", "max_len", ",", "batch_first", "=", "True", ",", "\n", "scale", "=", "(", "1.0", "/", "math", ".", "sqrt", "(", "state_size", ")", ")", "if", "scale_mode", "==", "\"down\"", "else", "1.0", ")", "\n", "\n", "self", ".", "register_buffer", "(", "'int_seq'", ",", "torch", ".", "arange", "(", "max_len", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "self", ".", "construct", "(", "transformer", ",", "**", "kwargs", ")", "\n", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.pos_embed": [[313, 318], ["transformer.TransformerEncDecModel.pos", "math.sqrt"], "methods", ["None"], ["", "def", "pos_embed", "(", "self", ",", "t", ":", "torch", ".", "Tensor", ",", "offset", ":", "int", ",", "scale_offset", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "if", "self", ".", "scale_mode", "==", "\"opennmt\"", ":", "\n", "\t\t\t", "t", "=", "t", "*", "math", ".", "sqrt", "(", "t", ".", "shape", "[", "-", "1", "]", ")", "\n", "\n", "", "return", "self", ".", "pos", "(", "t", ",", "offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.construct": [[319, 341], ["torch.Embedding", "torch.Embedding", "torch.Embedding", "transformer", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "transformer.TiedEmbedding", "torch.Linear", "torch.Linear", "torch.Linear", "int", "int"], "methods", ["None"], ["", "def", "construct", "(", "self", ",", "transformer", ",", "**", "kwargs", ")", ":", "\n", "\t\t", "self", ".", "input_embedding", "=", "nn", ".", "Embedding", "(", "self", ".", "n_input_tokens", "+", "1", "+", "int", "(", "self", ".", "encoder_sos", "is", "not", "None", ")", ",", "\n", "self", ".", "in_embedding_size", "or", "self", ".", "state_size", ")", "\n", "self", ".", "output_embedding", "=", "self", ".", "input_embedding", "if", "self", ".", "same_enc_dec_embedding", "else", "nn", ".", "Embedding", "(", "self", ".", "n_out_tokens", "+", "1", ",", "self", ".", "out_embedding_size", "or", "self", ".", "state_size", ")", "\n", "\n", "if", "self", ".", "in_embedding_size", "is", "not", "None", ":", "\n", "\t\t\t", "self", ".", "in_embedding_upscale", "=", "nn", ".", "Linear", "(", "self", ".", "in_embedding_size", ",", "self", ".", "state_size", ")", "\n", "\n", "", "if", "self", ".", "out_embedding_size", "is", "not", "None", ":", "\n", "\t\t\t", "self", ".", "out_embedding_upscale", "=", "nn", ".", "Linear", "(", "self", ".", "out_embedding_size", ",", "self", ".", "state_size", ")", "\n", "\n", "", "if", "self", ".", "tied_embedding", ":", "\n", "\t\t\t", "assert", "self", ".", "out_embedding_size", "is", "None", "\n", "self", ".", "output_map", "=", "TiedEmbedding", "(", "self", ".", "output_embedding", ".", "weight", ")", "\n", "", "else", ":", "\n", "\t\t\t", "self", ".", "output_map", "=", "nn", ".", "Linear", "(", "self", ".", "state_size", ",", "self", ".", "n_out_tokens", "+", "1", ")", "\n", "\n", "", "self", ".", "trafo", "=", "transformer", "(", "\n", "d_model", "=", "self", ".", "state_size", ",", "dim_feedforward", "=", "int", "(", "self", ".", "ff_multiplier", "*", "self", ".", "state_size", ")", ",", "\n", "n_graph_layers", "=", "self", ".", "n_graph_layers", ",", "n_node_labels", "=", "self", ".", "n_node_labels", ",", "\n", "n_edge_labels", "=", "self", ".", "n_edge_labels", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.reset_parameters": [[342, 352], ["torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.xavier_uniform_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_", "torch.init.kaiming_normal_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "\t\t", "if", "self", ".", "embedding_init", "==", "\"xavier\"", ":", "\n", "\t\t\t", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "input_embedding", ".", "weight", ")", "\n", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "output_embedding", ".", "weight", ")", "\n", "", "elif", "self", ".", "embedding_init", "==", "\"kaiming\"", ":", "\n", "\t\t\t", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "input_embedding", ".", "weight", ")", "\n", "nn", ".", "init", ".", "kaiming_normal_", "(", "self", ".", "output_embedding", ".", "weight", ")", "\n", "\n", "", "if", "not", "self", ".", "tied_embedding", ":", "\n", "\t\t\t", "nn", ".", "init", ".", "xavier_uniform_", "(", "self", ".", "output_map", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.generate_len_mask": [[353, 355], ["len.unsqueeze"], "methods", ["None"], ["", "", "def", "generate_len_mask", "(", "self", ",", "max_len", ":", "int", ",", "len", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "return", "self", ".", "int_seq", "[", ":", "max_len", "]", ">=", "len", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.output_embed": [[356, 361], ["transformer.TransformerEncDecModel.output_embedding", "transformer.TransformerEncDecModel.out_embedding_upscale"], "methods", ["None"], ["", "def", "output_embed", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "o", "=", "self", ".", "output_embedding", "(", "x", ")", "\n", "if", "self", ".", "out_embedding_size", "is", "not", "None", ":", "\n", "\t\t\t", "o", "=", "self", ".", "out_embedding_upscale", "(", "o", ")", "\n", "", "return", "o", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.run_greedy": [[362, 392], ["transformer.TransformerEncDecModel.generate_len_mask", "transformer.TransformerEncDecModel.trafo.encoder", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "transformer.TransformerEncDecModel.pos_embed", "transformer.TransformerEncDecModel.trafo.decoder.create_state", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "transformer.TransformerEncDecModel.output_embed", "transformer.TransformerEncDecModel.trafo.decoder.one_step_forward", "transformer.TransformerEncDecModel.output_map", "all_outputs.append", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "transformer.TransformerEncDecModel.pos_embed", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "torch.full", "transformer.TransformerEncDecModel.output_embed().unsqueeze", "transformer.TransformerEncDecModel.output_embed"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.generate_len_mask", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.pos_embed", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderBase.create_state", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.output_embed", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderBase.one_step_forward", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.pos_embed", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.output_embed"], ["", "def", "run_greedy", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "src_len", ":", "torch", ".", "Tensor", ",", "max_len", ":", "int", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "batch_size", "=", "src", ".", "shape", "[", "0", "]", "\n", "n_steps", "=", "src", ".", "shape", "[", "1", "]", "\n", "\n", "in_len_mask", "=", "self", ".", "generate_len_mask", "(", "n_steps", ",", "src_len", ")", "\n", "memory", "=", "self", ".", "trafo", ".", "encoder", "(", "src", ",", "mask", "=", "in_len_mask", ")", "\n", "\n", "running", "=", "torch", ".", "ones", "(", "[", "batch_size", "]", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "src", ".", "device", ")", "\n", "out_len", "=", "torch", ".", "zeros_like", "(", "running", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "next_tgt", "=", "self", ".", "pos_embed", "(", "self", ".", "output_embed", "(", "\n", "torch", ".", "full", "(", "[", "batch_size", ",", "1", "]", ",", "self", ".", "decoder_sos_eos", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "src", ".", "device", ")", "\n", ")", ",", "0", ",", "1", ")", "\n", "\n", "all_outputs", "=", "[", "]", "\n", "state", "=", "self", ".", "trafo", ".", "decoder", ".", "create_state", "(", "src", ".", "shape", "[", "0", "]", ",", "max_len", ",", "src", ".", "device", ")", "\n", "\n", "for", "i", "in", "range", "(", "max_len", ")", ":", "\n", "\t\t\t", "output", "=", "self", ".", "trafo", ".", "decoder", ".", "one_step_forward", "(", "state", ",", "next_tgt", ",", "memory", ",", "memory_key_padding_mask", "=", "in_len_mask", ")", "\n", "\n", "output", "=", "self", ".", "output_map", "(", "output", ")", "\n", "all_outputs", ".", "append", "(", "output", ")", "\n", "\n", "out_token", "=", "torch", ".", "argmax", "(", "output", "[", ":", ",", "-", "1", "]", ",", "-", "1", ")", "# BS x prediction for given seq_len position", "\n", "running", "&=", "out_token", "!=", "self", ".", "decoder_sos_eos", "# BS x 1", "\n", "\n", "out_len", "[", "running", "]", "=", "i", "+", "1", "\n", "next_tgt", "=", "self", ".", "pos_embed", "(", "self", ".", "output_embed", "(", "out_token", ")", ".", "unsqueeze", "(", "1", ")", ",", "i", "+", "1", ",", "1", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "all_outputs", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.run_teacher_forcing": [[393, 405], ["transformer.TransformerEncDecModel.output_embed", "transformer.TransformerEncDecModel.pos_embed", "transformer.TransformerEncDecModel.generate_len_mask", "transformer.TransformerEncDecModel.trafo", "transformer.TransformerEncDecModel.output_map", "torch.pad().long", "torch.pad().long", "torch.pad().long", "transformer.TransformerEncDecModel.trafo.generate_square_subsequent_mask", "torch.pad", "torch.pad", "torch.pad"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.output_embed", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.pos_embed", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.generate_len_mask", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.Transformer.generate_square_subsequent_mask"], ["", "def", "run_teacher_forcing", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "src_len", ":", "torch", ".", "Tensor", ",", "target", ":", "torch", ".", "Tensor", ",", "\n", "target_len", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "# Adds SOS token to target sequence", "\n", "\t\t", "target", "=", "self", ".", "output_embed", "(", "F", ".", "pad", "(", "target", "[", ":", ",", ":", "-", "1", "]", ",", "(", "1", ",", "0", ")", ",", "value", "=", "self", ".", "decoder_sos_eos", ")", ".", "long", "(", ")", ")", "\n", "target", "=", "self", ".", "pos_embed", "(", "target", ",", "0", ",", "1", ")", "\n", "\n", "in_len_mask", "=", "self", ".", "generate_len_mask", "(", "src", ".", "shape", "[", "1", "]", ",", "src_len", ")", "\n", "\n", "res", "=", "self", ".", "trafo", "(", "src", ",", "target", ",", "src_length_mask", "=", "in_len_mask", ",", "\n", "tgt_mask", "=", "self", ".", "trafo", ".", "generate_square_subsequent_mask", "(", "target", ".", "shape", "[", "1", "]", ",", "src", ".", "device", ")", ")", "\n", "\n", "return", "self", ".", "output_map", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.input_embed": [[406, 411], ["transformer.TransformerEncDecModel.input_embedding", "x.long", "transformer.TransformerEncDecModel.in_embedding_upscale"], "methods", ["None"], ["", "def", "input_embed", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "src", "=", "self", ".", "input_embedding", "(", "x", ".", "long", "(", ")", ")", "\n", "if", "self", ".", "in_embedding_size", "is", "not", "None", ":", "\n", "\t\t\t", "src", "=", "self", ".", "in_embedding_upscale", "(", "src", ")", "\n", "", "return", "src", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.forward": [[412, 444], ["transformer.TransformerEncDecModel.pos_embed", "torch.pad", "torch.pad", "torch.pad", "transformer.TransformerEncDecModel.input_embed", "isinstance", "transformer.TransformerEncDecModel.generate_len_mask", "transformer.TransformerEncDecModel.trafo", "transformer.TransformerEncDecModel.run_teacher_forcing", "transformer.TransformerEncDecModel.run_greedy", "target_len.max().item", "target_len.max"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.pos_embed", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.input_embed", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.generate_len_mask", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.run_teacher_forcing", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncDecModel.run_greedy"], ["", "def", "forward", "(", "self", ",", "src", ":", "torch", ".", "Tensor", ",", "src_len", ":", "torch", ".", "Tensor", ",", "target", ":", "torch", ".", "Tensor", ",", "\n", "target_len", ":", "torch", ".", "Tensor", ",", "teacher_forcing", ":", "bool", "=", "False", ",", "max_len", ":", "Optional", "[", "int", "]", "=", "None", ")", "->", "torch", ".", "Tensor", ":", "\n", "\t\t", "'''\n\t\tRun transformer encoder-decoder on some input/output pair\n\t\t:param src: source tensor. Shape: [N, S], where S in the in sequence length, N is the batch size\n\t\t:param src_len: length of source sequences. Shape: [N], N is the batch size\n\t\t:param target: target tensor. Shape: [N, S], where T in the in sequence length, N is the batch size\n\t\t:param target_len: length of target sequences. Shape: [N], N is the batch size\n\t\t:param teacher_forcing: use teacher forcing or greedy decoding\n\t\t:param max_len: overwrite autodetected max length. Useful for parallel execution\n\t\t:return: prediction of the target tensor. Shape [N, T, C_out]\n\t\t'''", "\n", "\n", "if", "self", ".", "encoder_sos", "is", "not", "None", ":", "\n", "# Adds SOS to src", "\n", "\t\t\t", "src", "=", "F", ".", "pad", "(", "src", ",", "(", "1", ",", "0", ")", ",", "value", "=", "self", ".", "encoder_sos", ")", "\n", "src_len", "=", "src_len", "+", "1", "\n", "\n", "", "src", "=", "self", ".", "pos_embed", "(", "self", ".", "input_embed", "(", "src", ")", ",", "0", ",", "0", ")", "\n", "\n", "# if transformer baseline", "\n", "if", "not", "isinstance", "(", "self", ".", "trafo", ".", "decoder", ",", "LAGr", ")", ":", "\n", "\n", "\t\t\t", "if", "teacher_forcing", ":", "\n", "\t\t\t\t", "return", "self", ".", "run_teacher_forcing", "(", "src", ",", "src_len", ",", "target", ",", "target_len", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "return", "self", ".", "run_greedy", "(", "src", ",", "src_len", ",", "max_len", "or", "target_len", ".", "max", "(", ")", ".", "item", "(", ")", ")", "\n", "\n", "# if transformer lagr ", "\n", "", "", "else", ":", "\n", "\t\t\t", "in_len_mask", "=", "self", ".", "generate_len_mask", "(", "src", ".", "shape", "[", "1", "]", ",", "src_len", ")", "# True for padding", "\n", "return", "self", ".", "trafo", "(", "src", ",", "src_length_mask", "=", "in_len_mask", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr.__init__": [[448, 472], ["torch.Module.__init__", "torch.Identity", "torch.Identity", "torch.Identity", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__"], ["\t", "def", "__init__", "(", "self", ",", "n_node_labels", "=", "644", "+", "2", ",", "n_edge_labels", "=", "9", "+", "2", ",", "dim", "=", "512", ",", "n_graph_layers", "=", "1", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tArgs:\n\t\t\tencoder: Chosen encoder used for both node and edge predictions.\n\t\t\tn_node_labels: Node label vocabulary size.\n\t\t\tn_edge_labels: Edge label vocabulary size.\n\t\t\tdim: Encoder dimension.\n\t\t\tn_graph_layers: Number of graph layers to use.\n\t\t\"\"\"", "\n", "super", "(", "LAGr", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "dim", "=", "dim", "\n", "\n", "self", ".", "n_node_labels", "=", "n_node_labels", "\n", "self", ".", "n_edge_labels", "=", "n_edge_labels", "\n", "self", ".", "n_graph_layers", "=", "n_graph_layers", "\n", "self", ".", "grapy_layer_transform", "=", "nn", ".", "Identity", "(", ")", "\n", "\n", "self", ".", "head_dim", "=", "self", ".", "dim", "//", "self", ".", "n_edge_labels", "\n", "self", ".", "out_dim", "=", "self", ".", "head_dim", "*", "self", ".", "n_edge_labels", "\n", "\n", "self", ".", "node_model", "=", "nn", ".", "Linear", "(", "self", ".", "n_graph_layers", "*", "self", ".", "dim", ",", "self", ".", "n_graph_layers", "*", "self", ".", "n_node_labels", ")", "\n", "self", ".", "linear_keys", "=", "nn", ".", "Linear", "(", "self", ".", "n_graph_layers", "*", "self", ".", "dim", ",", "self", ".", "n_graph_layers", "*", "self", ".", "out_dim", ")", "\n", "self", ".", "linear_query", "=", "nn", ".", "Linear", "(", "self", ".", "n_graph_layers", "*", "self", ".", "dim", ",", "self", ".", "n_graph_layers", "*", "self", ".", "out_dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr.forward": [[473, 477], ["transformer.LAGr._forward"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._forward"], ["", "def", "forward", "(", "self", ",", "node_embeds", ",", "edge_embeds", ")", ":", "\n", "\t\t", "node_log_softmax", ",", "edge_log_softmax", "=", "self", ".", "_forward", "(", "node_embeds", ",", "edge_embeds", ")", "\n", "\n", "return", "(", "node_log_softmax", ",", "edge_log_softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._predict_nodes": [[478, 492], ["transformer.LAGr.node_model", "out.view.view.view", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax"], "methods", ["None"], ["", "def", "_predict_nodes", "(", "self", ",", "node_embeds", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tArgs:\n\t\t\tnode_embeds: Node embeddings, i.e., output of node encoder model.\n\t\tReturns:\n\t\t\tnode_log_softmax: softmax scores over all node labels.\n\t\t\"\"\"", "\n", "bs", ",", "seq_len", ",", "_", "=", "node_embeds", ".", "shape", "\n", "\n", "out", "=", "self", ".", "node_model", "(", "node_embeds", ")", "# [bs, seq_len, n_graph_layers x n_node_labels]", "\n", "out", "=", "out", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_node_labels", ")", "# [bs, seq_len * n_graph_layers, n_node_labels]", "\n", "\n", "node_log_softmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "(", "out", ")", "\n", "return", "node_log_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._predict_edges": [[493, 518], ["transformer.LAGr.linear_keys", "key.transpose().transpose.transpose().transpose.view", "key.transpose().transpose.transpose().transpose.transpose().transpose", "transformer.LAGr.linear_query", "query.transpose.transpose.view", "query.transpose.transpose.transpose", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "dot.transpose.transpose.transpose", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.Size", "torch.LogSoftmax", "torch.LogSoftmax", "torch.LogSoftmax", "key.transpose().transpose.transpose().transpose.transpose"], "methods", ["None"], ["", "def", "_predict_edges", "(", "self", ",", "edge_embeds", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tArgs:\n\t\t\tedge_embeds: Edge embeddings, i.e., output of edge encoder model.\n\t\tReturns:\n\t\t\tedge_log_softmax: softmax scores over all edge labels.\n\t\t\"\"\"", "\n", "bs", ",", "seq_len", ",", "_", "=", "edge_embeds", ".", "shape", "\n", "new_length", "=", "seq_len", "*", "self", ".", "n_graph_layers", "\n", "\n", "key", "=", "self", ".", "linear_keys", "(", "edge_embeds", ")", "# [bs, seq_len, n_graph_layers * n_heads * n_edge_labels]", "\n", "key", "=", "key", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_edge_labels", ",", "self", ".", "head_dim", ")", "# [bs, seq_len * n_graph_layers, n_edge_labels, n_heads]", "\n", "key", "=", "key", ".", "transpose", "(", "1", ",", "2", ")", ".", "transpose", "(", "2", ",", "3", ")", "# [bs, n_edge_labels, n_heads, seq_len * n_graph_layers]", "\n", "\n", "query", "=", "self", ".", "linear_query", "(", "edge_embeds", ")", "\n", "query", "=", "query", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "n_edge_labels", ",", "self", ".", "head_dim", ")", "\n", "query", "=", "query", ".", "transpose", "(", "1", ",", "2", ")", "# [bs, n_edge_labels, seq_len * n_graph_layers, n_heads]", "\n", "\n", "# switch num_heads, heads_dim in keys", "\n", "dot", "=", "torch", ".", "matmul", "(", "query", ",", "key", ")", "\n", "assert", "dot", ".", "shape", "==", "torch", ".", "Size", "(", "[", "bs", ",", "self", ".", "n_edge_labels", ",", "new_length", ",", "new_length", "]", ")", "\n", "\n", "dot", "=", "dot", ".", "transpose", "(", "1", ",", "3", ")", "\n", "edge_log_softmax", "=", "nn", ".", "LogSoftmax", "(", "dim", "=", "-", "1", ")", "(", "dot", ")", "# [bs, new_length, new_length, n_edge_labels]", "\n", "return", "edge_log_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._forward": [[519, 528], ["transformer.LAGr._interleave", "transformer.LAGr._predict_nodes", "transformer.LAGr._predict_edges"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._interleave", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._predict_nodes", "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._predict_edges"], ["", "def", "_forward", "(", "self", ",", "node_embeds", ",", "edge_embeds", ")", ":", "\n", "# Populates graph layers", "\n", "\t\t", "node_embeds", ",", "edge_embeds", "=", "self", ".", "_interleave", "(", "node_embeds", ",", "edge_embeds", ")", "\n", "\n", "# Graph predictions", "\n", "node_log_softmax", "=", "self", ".", "_predict_nodes", "(", "node_embeds", ")", "\n", "edge_log_softmax", "=", "self", ".", "_predict_edges", "(", "edge_embeds", ")", "\n", "\n", "return", "(", "node_log_softmax", ",", "edge_log_softmax", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.LAGr._interleave": [[529, 539], ["node_embeds.repeat().view.repeat().view.repeat().view", "edge_embeds.repeat().view.repeat().view.repeat().view", "node_embeds.repeat().view.repeat().view.repeat", "edge_embeds.repeat().view.repeat().view.repeat"], "methods", ["None"], ["", "def", "_interleave", "(", "self", ",", "node_embeds", ",", "edge_embeds", ")", ":", "\n", "\t\t", "\"\"\"\n\t\tTakes node and edge embeddings of dim [seq_len, bs, dim], and populates all graph layers.\n\t\tCurrently, done by repeating the same embedding. E.g. [a,b,c] x 2 -> [a,a,b,b,c,c]\n\t\t\"\"\"", "\n", "bs", ",", "seq_len", ",", "dim", "=", "node_embeds", ".", "shape", "\n", "node_embeds", "=", "node_embeds", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_graph_layers", ")", ".", "view", "(", "bs", ",", "seq_len", ",", "dim", "*", "self", ".", "n_graph_layers", ")", "\n", "edge_embeds", "=", "edge_embeds", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "n_graph_layers", ")", ".", "view", "(", "bs", ",", "seq_len", ",", "dim", "*", "self", ".", "n_graph_layers", ")", "\n", "\n", "return", "node_embeds", ",", "edge_embeds", "", "", "", ""]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.sinusoidal_pos_embedding": [[16, 24], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.exp", "torch.exp", "torch.exp", "torch.sin", "torch.sin", "torch.sin", "torch.cos", "torch.cos", "torch.cos", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange().unsqueeze", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "math.log"], "function", ["None"], ["def", "sinusoidal_pos_embedding", "(", "d_model", ":", "int", ",", "max_len", ":", "int", "=", "5000", ",", "pos_offset", ":", "int", "=", "0", ",", "\n", "device", ":", "Optional", "[", "torch", ".", "device", "]", "=", "None", ")", ":", "\n", "\t", "pe", "=", "torch", ".", "zeros", "(", "max_len", ",", "d_model", ",", "device", "=", "device", ")", "\n", "position", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", ".", "unsqueeze", "(", "1", ")", "+", "pos_offset", "\n", "div_term", "=", "torch", ".", "exp", "(", "torch", ".", "arange", "(", "0", ",", "d_model", ",", "2", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "*", "(", "-", "math", ".", "log", "(", "10000.0", ")", "/", "d_model", ")", ")", "\n", "pe", "[", ":", ",", "0", ":", ":", "2", "]", "=", "torch", ".", "sin", "(", "position", "*", "div_term", ")", "\n", "pe", "[", ":", ",", "1", ":", ":", "2", "]", "=", "torch", ".", "cos", "(", "position", "*", "div_term", ")", "\n", "return", "pe", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerEncoderWithLayer": [[198, 200], ["transformer.TransformerEncoder"], "function", ["None"], ["", "", "def", "TransformerEncoderWithLayer", "(", "layer", "=", "TransformerEncoderLayer", ")", ":", "\n", "\t", "return", "lambda", "*", "args", ",", "**", "kwargs", ":", "TransformerEncoder", "(", "layer", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.src.transformer.TransformerDecoderWithLayer": [[202, 204], ["transformer.TransformerDecoder"], "function", ["None"], ["", "def", "TransformerDecoderWithLayer", "(", "layer", "=", "TransformerDecoderLayer", ")", ":", "\n", "\t", "return", "lambda", "*", "args", ",", "**", "kwargs", ":", "TransformerDecoder", "(", "layer", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.__init__": [[18, 23], ["None"], "methods", ["None"], ["\t", "def", "__init__", "(", "self", ",", "preprocessor", ",", "tgt_vocab", ",", "decoder_sos_eos", ")", ":", "\n", "\n", "\t\t", "self", ".", "preprocessor", "=", "preprocessor", "\n", "self", ".", "tgt_vocab", "=", "tgt_vocab", "\n", "self", ".", "decoder_sos_eos", "=", "decoder_sos_eos", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.cogs_graph_accuracy": [[24, 56], ["node_results.sum().item", "float", "node_preds.eq().bitwise_or().all().sum().item", "edge_results.sum().item", "float", "edge_preds.eq().bitwise_or().all().all().sum().item", "float", "statistics.Metrics.lambda_accuracy", "node_preds.eq", "node_results.size", "edge_preds.eq", "edge_results.size", "node_results.sum", "node_preds.eq().bitwise_or().all().sum", "edge_results.sum", "edge_preds.eq().bitwise_or().all().all().sum", "node_preds.eq().bitwise_or().all", "edge_preds.eq().bitwise_or().all().all", "node_preds.eq().bitwise_or", "edge_preds.eq().bitwise_or().all", "node_preds.eq", "edge_preds.eq().bitwise_or", "edge_preds.eq"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.lambda_accuracy"], ["", "def", "cogs_graph_accuracy", "(", "self", ",", "node_preds", ",", "edge_preds", ",", "batch", ")", ":", "\n", "\t\t", "lmbd_tgt", ",", "node_tgt", ",", "edge_tgt", "=", "batch", "[", "\"tgt\"", "]", ",", "batch", "[", "\"node_tgt\"", "]", ",", "batch", "[", "\"edge_tgt\"", "]", "\n", "\n", "# Node Accuracy", "\n", "node_results", "=", "node_preds", ".", "eq", "(", "node_tgt", ")", "[", "node_tgt", "!=", "GRAPH_PAD_TOKEN", "]", "\n", "n_correct_nodes", "=", "node_results", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_nodes", "=", "float", "(", "node_results", ".", "size", "(", "0", ")", ")", "\n", "n_exact_node_matches", "=", "(", "\n", "node_preds", ".", "eq", "(", "node_tgt", ")", "\n", ".", "bitwise_or", "(", "node_tgt", "==", "GRAPH_PAD_TOKEN", ")", "\n", ".", "all", "(", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "\n", "# Edge Accuracy", "\n", "edge_results", "=", "edge_preds", ".", "eq", "(", "edge_tgt", ")", "[", "edge_tgt", "!=", "GRAPH_PAD_TOKEN", "]", "\n", "n_correct_edges", "=", "edge_results", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_edges", "=", "float", "(", "edge_results", ".", "size", "(", "0", ")", ")", "\n", "n_exact_edge_matches", "=", "(", "\n", "edge_preds", ".", "eq", "(", "edge_tgt", ")", "\n", ".", "bitwise_or", "(", "edge_tgt", "==", "GRAPH_PAD_TOKEN", ")", "\n", ".", "all", "(", "1", ")", ".", "all", "(", "1", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "n_examples", "=", "float", "(", "lmbd_tgt", ".", "shape", "[", "0", "]", ")", "\n", "\n", "n_correct_lmbd", "=", "self", ".", "lambda_accuracy", "(", "node_preds", ",", "edge_preds", ",", "lmbd_tgt", ",", "node_tgt", ",", "edge_tgt", ")", "\n", "\n", "return", "(", "\n", "n_correct_nodes", "/", "n_nodes", ",", "\n", "n_correct_edges", "/", "n_edges", ",", "\n", "n_exact_node_matches", "/", "n_examples", ",", "\n", "n_exact_edge_matches", "/", "n_examples", ",", "\n", "n_correct_lmbd", "/", "n_examples", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._serialized_graph": [[58, 91], ["zip", "n_edges.eq", "zip", "torch.where", "triples.append", "triples.append", "n_edges.eq", "pred_edges.eq", "triples.append"], "methods", ["None"], ["", "def", "_serialized_graph", "(", "self", ",", "nodes", ",", "edges", ")", ":", "\n", "\t\t", "triples", "=", "[", "]", "\n", "for", "node", ",", "n_edges", "in", "zip", "(", "nodes", ",", "edges", ")", ":", "\n", "# if node in [NULL_TOKEN, GRAPH_PAD_TOKEN]:", "\n", "# \tcontinue", "\n", "\n", "\t\t\t", "agents", "=", "n_edges", ".", "eq", "(", "self", ".", "preprocessor", ".", "edge_vocab", ".", "stoi", "[", "'agent'", "]", ")", "\n", "predicates", "=", "nodes", "[", "agents", "]", "# predicate of the given subject", "\n", "positions", "=", "torch", ".", "where", "(", "agents", ")", "[", "0", "]", "\n", "for", "idx", ",", "pred", "in", "zip", "(", "positions", ",", "predicates", ")", ":", "\n", "\t\t\t\t", "pred_edges", "=", "edges", "[", "idx", ",", ":", "]", "# get destination edges for predicate node", "\n", "destination_nodes", "=", "nodes", "[", "pred_edges", ".", "eq", "(", "self", ".", "preprocessor", ".", "edge_vocab", ".", "stoi", "[", "'theme'", "]", ")", "]", "\n", "if", "destination_nodes", ".", "shape", "[", "0", "]", ">", "0", ":", "\n", "\t\t\t\t\t", "for", "dest", "in", "destination_nodes", ":", "\n", "\t\t\t\t\t\t", "triples", ".", "append", "(", "' '", ".", "join", "(", "[", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "node", "]", ",", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "pred", "]", ",", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "dest", "]", "]", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "\t\t\t\t\t", "triples", ".", "append", "(", "' '", ".", "join", "(", "[", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "node", "]", ",", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "pred", "]", "]", ")", "\n", ")", "\n", "# check for filters", "\n", "", "", "filter_clauses", "=", "nodes", "[", "n_edges", ".", "eq", "(", "self", ".", "preprocessor", ".", "edge_vocab", ".", "stoi", "[", "'FILTER'", "]", ")", "]", "# predicate of the given subject", "\n", "for", "filter_node", "in", "filter_clauses", ":", "\n", "\t\t\t\t", "triples", ".", "append", "(", "'FILTER '", "+", "' '", ".", "join", "(", "[", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "node", "]", ",", "\n", "'!='", ",", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "filter_node", "]", "]", ")", "\n", ")", "\n", "", "", "return", "triples", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._create_graph": [[92, 116], ["torch.where", "edges_for_predicted_nodes[].detach().cpu().numpy", "statistics.Metrics._serialized_graph", "valid_nodes[].detach().cpu().numpy", "valid_nodes[].detach().cpu().numpy", "networkx.DiGraph", "zip", "sorted", "nodes.ne", "nodes.ne", "edges_for_predicted_nodes.ne", "edges_for_predicted_nodes.ne", "edges_for_predicted_nodes[].detach().cpu", "valid_nodes[].detach().cpu", "valid_nodes[].detach().cpu", "networkx.DiGraph.add_edge", "Exception", "edges_for_predicted_nodes[].detach", "valid_nodes[].detach", "valid_nodes[].detach"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._serialized_graph"], ["", "def", "_create_graph", "(", "self", ",", "nodes", ",", "edges", ",", "pad_mask", ",", "true", "=", "False", ")", ":", "\n", "# take edge predictions for valid nodes", "\n", "\t\t", "mask", "=", "nodes", ".", "ne", "(", "NULL_TOKEN", ")", "&", "nodes", ".", "ne", "(", "GRAPH_PAD_TOKEN", ")", "&", "pad_mask", "\n", "valid_nodes", "=", "nodes", "[", "mask", "]", "\n", "edges_for_predicted_nodes", "=", "edges", "[", "mask", "]", "[", ":", ",", "mask", "]", "\n", "\n", "# destination nodes for each predicted node", "\n", "edge_positions", "=", "torch", ".", "where", "(", "edges_for_predicted_nodes", ".", "ne", "(", "NULL_TOKEN", ")", "&", "edges_for_predicted_nodes", ".", "ne", "(", "GRAPH_PAD_TOKEN", ")", ")", "# non null or padding", "\n", "predicted_labels", "=", "edges_for_predicted_nodes", "[", "edge_positions", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "triples", "=", "self", ".", "_serialized_graph", "(", "valid_nodes", ",", "edges_for_predicted_nodes", ")", "\n", "\n", "src_nodes", "=", "valid_nodes", "[", "edge_positions", "[", "0", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "dest_nodes", "=", "valid_nodes", "[", "edge_positions", "[", "1", "]", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "G", "=", "nx", ".", "DiGraph", "(", ")", "\n", "for", "node1", ",", "node2", ",", "label", "in", "zip", "(", "src_nodes", ",", "dest_nodes", ",", "predicted_labels", ")", ":", "\n", "\t\t\t", "if", "node1", "not", "in", "[", "NULL_TOKEN", ",", "GRAPH_PAD_TOKEN", "]", "and", "node2", "not", "in", "[", "NULL_TOKEN", ",", "GRAPH_PAD_TOKEN", "]", ":", "\n", "\t\t\t\t", "G", ".", "add_edge", "(", "node1", ",", "node2", ",", "label", "=", "label", ")", "\n", "", "else", ":", "\n", "# should never be 0 or 1", "\n", "\t\t\t\t", "raise", "Exception", "(", "'should never be 0 or 1'", ")", "\n", "\n", "", "", "return", "G", ",", "sorted", "(", "triples", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.cfq_graph_accuracy": [[117, 174], ["len", "zip", "batch[].detach().cpu().numpy", "true_nodes.ne", "statistics.Metrics._create_graph", "statistics.Metrics._create_graph", "len", "len", "len", "len", "networkx.algorithms.isomorphism.categorical_edge_match", "networkx.is_isomorphic", "batch[].detach().cpu", "G_pred.edges", "networkx.is_empty", "networkx.is_empty", "G_true.edges", "G_pred.edges", "inputs.repeat().view().transpose().reshape().detach().cpu().numpy", "statistics.Metrics._get_str", "statistics.Metrics._get_str", "out_file.write", "out_file.write", "out_file.write", "out_file.write", "out_file.write", "out_file.flush", "batch[].detach", "G_true.edges", "out_file.write", "out_file.write", "out_file.write", "out_file.write", "inputs.repeat().view().transpose().reshape().detach().cpu", "G_pred.edges.data", "G_true.edges.data", "int", "inputs.repeat().view().transpose().reshape().detach", "G_true.edges.data", "G_pred.edges.data", "int", "inputs.repeat().view().transpose().reshape", "zip", "inputs.repeat().view().transpose", "int", "int", "inputs.repeat().view", "inputs.repeat"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._create_graph", "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._create_graph", "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._get_str", "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._get_str"], ["", "def", "cfq_graph_accuracy", "(", "self", ",", "node_preds", ",", "edge_preds", ",", "batch", ",", "out_file", "=", "None", ")", ":", "\n", "\t\t", "src", ",", "node_tgt", ",", "edge_tgt", "=", "batch", "[", "\"src\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "batch", "[", "\"node_tgt\"", "]", ",", "batch", "[", "\"edge_tgt\"", "]", "\n", "\n", "n_correct_graphs", "=", "0.", "\n", "n_correct_nodes", ",", "n_correct_edges", "=", "0.", ",", "0.", "\n", "n_nodes", ",", "n_edges", "=", "0.", ",", "0.", "\n", "n_graphs", "=", "len", "(", "node_preds", ")", "\n", "\n", "for", "nodes", ",", "edges", ",", "true_nodes", ",", "true_edges", ",", "inputs", "in", "zip", "(", "node_preds", ",", "edge_preds", ",", "node_tgt", ",", "edge_tgt", ",", "src", ")", ":", "\n", "\t\t\t", "pad_mask", "=", "true_nodes", ".", "ne", "(", "GRAPH_PAD_TOKEN", ")", "\n", "G_pred", ",", "serialized_pred", "=", "self", ".", "_create_graph", "(", "nodes", ",", "edges", ",", "pad_mask", ",", "true", "=", "False", ")", "\n", "G_true", ",", "serialized_true", "=", "self", ".", "_create_graph", "(", "true_nodes", ",", "true_edges", ",", "pad_mask", ",", "true", "=", "True", ")", "\n", "\n", "tmp", "=", "[", "e", "for", "e", "in", "G_pred", ".", "edges", "(", "data", "=", "True", ")", "if", "e", "in", "G_true", ".", "edges", "(", "data", "=", "True", ")", "]", "\n", "n_correct_nodes", "+=", "len", "(", "[", "n", "for", "n", "in", "G_pred", ".", "nodes", "if", "n", "in", "G_true", ".", "nodes", "]", ")", "\n", "n_correct_edges", "+=", "len", "(", "[", "e", "for", "e", "in", "G_pred", ".", "edges", "(", "data", "=", "True", ")", "if", "e", "in", "G_true", ".", "edges", "(", "data", "=", "True", ")", "]", ")", "\n", "n_nodes", "+=", "len", "(", "G_true", ".", "nodes", ")", "\n", "n_edges", "+=", "len", "(", "G_true", ".", "edges", ")", "\n", "\n", "if", "not", "nx", ".", "is_empty", "(", "G_pred", ")", "and", "not", "nx", ".", "is_empty", "(", "G_true", ")", ":", "\n", "\t\t\t\t", "nm", "=", "nx", ".", "algorithms", ".", "isomorphism", ".", "categorical_edge_match", "(", "'label'", ",", "'label'", ")", "\n", "if", "nx", ".", "is_isomorphic", "(", "G_pred", ",", "G_true", ",", "edge_match", "=", "nm", ")", ":", "\n", "\t\t\t\t\t", "n_correct_graphs", "+=", "1.", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "if", "out_file", ":", "\n", "\t\t\t\t\t\t", "question_str", "=", "' '", ".", "join", "(", "[", "self", ".", "src_vocab", ".", "itos", "[", "int", "(", "n", ")", "]", "for", "n", "in", "inputs", "if", "self", ".", "src_vocab", ".", "itos", "[", "int", "(", "n", ")", "]", "!=", "'<blank>'", "]", ")", "\n", "inp_seq", "=", "inputs", ".", "repeat", "(", "2", ")", ".", "view", "(", "-", "1", ",", "inputs", ".", "shape", "[", "0", "]", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "reshape", "(", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "redundant_nodes", "=", "' '", ".", "join", "(", "[", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "e", "]", "for", "e", "in", "G_pred", ".", "nodes", "if", "e", "not", "in", "G_true", ".", "nodes", "]", ")", "\n", "missing_nodes", "=", "' '", ".", "join", "(", "[", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "e", "]", "for", "e", "in", "G_true", ".", "nodes", "if", "e", "not", "in", "G_pred", ".", "nodes", "]", ")", "\n", "redundant_edges", "=", "self", ".", "_get_str", "(", "[", "e", "for", "e", "in", "G_pred", ".", "edges", ".", "data", "(", ")", "if", "e", "not", "in", "G_true", ".", "edges", ".", "data", "(", ")", "]", ")", "\n", "missing_edges", "=", "self", ".", "_get_str", "(", "[", "e", "for", "e", "in", "G_true", ".", "edges", ".", "data", "(", ")", "if", "e", "not", "in", "G_pred", ".", "edges", ".", "data", "(", ")", "]", ")", "\n", "\n", "out_file", ".", "write", "(", "'QUESTION : '", "+", "question_str", "+", "'\\n'", ")", "\n", "if", "missing_nodes", ":", "\n", "\t\t\t\t\t\t\t", "out_file", ".", "write", "(", "'MISSING nodes: \\n'", "+", "missing_nodes", "+", "'\\n'", ")", "\n", "", "if", "redundant_nodes", ":", "\n", "\t\t\t\t\t\t\t", "out_file", ".", "write", "(", "'REDUNDANT nodes: \\n'", "+", "redundant_nodes", "+", "'\\n'", ")", "\n", "\n", "", "if", "missing_edges", ":", "\n", "\t\t\t\t\t\t\t", "out_file", ".", "write", "(", "'MISSING edges: \\n'", "+", "missing_edges", "+", "'\\n'", ")", "\n", "", "if", "redundant_edges", ":", "\n", "\t\t\t\t\t\t\t", "out_file", ".", "write", "(", "'REDUNDANT edges: \\n'", "+", "redundant_edges", "+", "'\\n'", ")", "\n", "\n", "# predicted_nodes_str = ' '.join([self.preprocessor.node_vocab.itos[n] for n in nodes[nodes.ne(0) & nodes.ne(1)]])", "\n", "# out_file.write('PREDICTED_NODES: \\n' + predicted_nodes_str + '\\n')", "\n", "", "out_file", ".", "write", "(", "'PREDICTED: \\n'", "+", "'\\n'", ".", "join", "(", "serialized_pred", ")", "+", "'\\n'", ")", "\n", "out_file", ".", "write", "(", "'ACTUAL:    \\n'", "+", "'\\n'", ".", "join", "(", "serialized_true", ")", "+", "'\\n'", ")", "\n", "out_file", ".", "write", "(", "'INP to PRED: '", "+", "' '", ".", "join", "(", "[", "\n", "self", ".", "src_vocab", ".", "itos", "[", "int", "(", "n", ")", "]", "+", "':'", "+", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "e", "]", "\n", "for", "n", ",", "e", "in", "zip", "(", "inp_seq", ",", "nodes", ")", "if", "self", ".", "src_vocab", ".", "itos", "[", "int", "(", "n", ")", "]", "!=", "'<blank>'", "\n", "]", ")", "+", "'\\n'", ")", "\n", "out_file", ".", "write", "(", "'###############\\n'", ")", "\n", "out_file", ".", "flush", "(", ")", "\n", "\n", "", "", "", "", "exact_acc", "=", "n_correct_graphs", "/", "n_graphs", "\n", "return", "n_correct_nodes", "/", "n_nodes", ",", "n_correct_edges", "/", "n_edges", ",", "-", "1.", ",", "-", "1.", ",", "exact_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._get_str": [[175, 182], ["None"], "methods", ["None"], ["", "def", "_get_str", "(", "self", ",", "edges", ")", ":", "\n", "\t\t", "return", "' '", ".", "join", "(", "[", "\n", "' '", ".", "join", "(", "[", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "e", "[", "0", "]", "]", ",", "\n", "self", ".", "preprocessor", ".", "edge_vocab", ".", "itos", "[", "e", "[", "2", "]", "[", "'label'", "]", "]", ",", "\n", "self", ".", "preprocessor", ".", "node_vocab", ".", "itos", "[", "e", "[", "1", "]", "]", "\n", "]", ")", "for", "e", "in", "edges", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.strongly_sup_metrics": [[183, 191], ["torch.argmax", "torch.argmax", "statistics.Metrics.cogs_graph_accuracy"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.cogs_graph_accuracy"], ["", "def", "strongly_sup_metrics", "(", "self", ",", "batch", ",", "node_scores", ",", "edge_scores", ")", ":", "\n", "\t\t", "node_preds", "=", "torch", ".", "argmax", "(", "node_scores", ",", "-", "1", ")", "\n", "edge_preds", "=", "torch", ".", "argmax", "(", "edge_scores", ",", "-", "1", ")", "\n", "\n", "# Node, edge, exact lambda accuracies", "\n", "node_acc", ",", "edge_acc", ",", "node_exact_acc", ",", "edge_exact_acc", ",", "lmbda_exact_acc", "=", "self", ".", "cogs_graph_accuracy", "(", "node_preds", ",", "edge_preds", ",", "batch", ")", "\n", "\n", "return", "node_acc", ",", "edge_acc", ",", "node_exact_acc", ",", "edge_exact_acc", ",", "lmbda_exact_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics.lambda_accuracy": [[192, 234], ["statistics.Metrics.preprocessor.scores_to_graph", "statistics.Metrics.preprocessor.graph_to_lambda", "range", "lmbd_tgt[].view", "torch.all", "torch.all", "statistics.split_and_sort_clauses", "statistics.split_and_sort_clauses", "true_lambda.append", "node_preds[].eq().bitwise_or", "edge_preds[].eq().bitwise_or", "token.item", "node_preds[].eq", "edge_preds[].eq"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.scores_to_graph", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.graph_to_lambda", "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.split_and_sort_clauses", "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.split_and_sort_clauses"], ["", "def", "lambda_accuracy", "(", "self", ",", "node_preds", ",", "edge_preds", ",", "lmbd_tgt", ",", "node_tgt", ",", "edge_tgt", ")", ":", "\n", "\t\t", "\"\"\"Calculates if the predicted graph matches the exact lambda calculus \"\"\"", "\n", "\n", "node_sets", ",", "edge_sets", ",", "edge_labels", "=", "self", ".", "preprocessor", ".", "scores_to_graph", "(", "\n", "node_preds", ",", "edge_preds", ",", "node_tgt", ",", "edge_tgt", ")", "\n", "\n", "# graph to lambda str expressions", "\n", "predicted_lambdas", "=", "self", ".", "preprocessor", ".", "graph_to_lambda", "(", "node_sets", ",", "edge_sets", ",", "edge_labels", ")", "\n", "\n", "n_exact_lambda_match", "=", "0", "\n", "\n", "# iter through each example", "\n", "for", "batch_idx", "in", "range", "(", "lmbd_tgt", ".", "shape", "[", "0", "]", ")", ":", "\n", "\n", "\t\t\t", "pred", "=", "predicted_lambdas", "[", "batch_idx", "]", "\n", "tgt", "=", "lmbd_tgt", "[", "batch_idx", "]", ".", "view", "(", "-", "1", ")", "\n", "tgt", "=", "tgt", "[", "tgt", "!=", "PAD_TOKEN", "]", "\n", "\n", "# convert target tokens to lambda form", "\n", "true_lambda", "=", "[", "]", "\n", "for", "token", "in", "tgt", ":", "\n", "\t\t\t\t", "word", "=", "self", ".", "tgt_vocab", ".", "itos", "[", "token", ".", "item", "(", ")", "]", "\n", "if", "word", "in", "[", "\"<s>\"", ",", "\"</s>\"", ",", "\"<blank>\"", "]", ":", "\n", "\t\t\t\t\t", "continue", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "true_lambda", ".", "append", "(", "word", ")", "\n", "", "", "true_lambda", "=", "\" \"", ".", "join", "(", "true_lambda", ")", "\n", "\n", "# primitive type questions won\"t be serialized into a lambda. These will be considered correct", "\n", "# if graph is correct", "\n", "if", "pred", "==", "\"NA\"", ":", "\n", "# check if primitive example", "\n", "\t\t\t\t", "all_nodes_true", "=", "torch", ".", "all", "(", "node_preds", "[", "batch_idx", "]", ".", "eq", "(", "node_tgt", "[", "batch_idx", "]", ")", ".", "bitwise_or", "(", "node_tgt", "[", "batch_idx", "]", "==", "GRAPH_PAD_TOKEN", ")", ")", "\n", "all_edges_true", "=", "torch", ".", "all", "(", "edge_preds", "[", "batch_idx", "]", ".", "eq", "(", "edge_tgt", "[", "batch_idx", "]", ")", ".", "bitwise_or", "(", "edge_tgt", "[", "batch_idx", "]", "==", "GRAPH_PAD_TOKEN", ")", ")", "\n", "\n", "if", "all_nodes_true", "and", "all_edges_true", ":", "\n", "\t\t\t\t\t", "n_exact_lambda_match", "+=", "1", "\n", "\n", "", "", "if", "split_and_sort_clauses", "(", "true_lambda", ")", "==", "split_and_sort_clauses", "(", "pred", ")", ":", "\n", "\t\t\t\t", "n_exact_lambda_match", "+=", "1", "\n", "\n", "", "", "return", "n_exact_lambda_match", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.Metrics._compute_acc": [[235, 253], ["src.utils.add_eos", "src.utils.add_eos.eq", "predictions.eq().masked_select", "predictions.eq().masked_select.sum().item", "correct_sequences.sum().item", "scores.max", "predictions.eq().masked_select.size", "correct_sequences.size", "predictions.eq", "predictions.eq().masked_select.sum", "correct_sequences.sum", "predictions.eq"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos"], ["", "def", "_compute_acc", "(", "self", ",", "target", ",", "tgt_lengths", ",", "scores", ")", ":", "\n", "\t\t", "predictions", "=", "scores", ".", "max", "(", "-", "1", ")", "[", "1", "]", "\n", "target", "=", "add_eos", "(", "target", ",", "tgt_lengths", ",", "self", ".", "decoder_sos_eos", ")", "\n", "\n", "mask", "=", "target", ".", "eq", "(", "PAD_TOKEN", ")", "# bool", "\n", "\n", "correct_tokens", "=", "predictions", ".", "eq", "(", "target", ")", ".", "masked_select", "(", "~", "mask", ")", "\n", "n_correct_tokens", "=", "correct_tokens", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "acc", "=", "n_correct_tokens", "/", "correct_tokens", ".", "size", "(", "0", ")", "\n", "\n", "correct_sequences", "=", "(", "predictions", ".", "eq", "(", "target", ")", "|", "mask", ")", ".", "all", "(", "1", ")", "# correct sequences", "\n", "num_correct_sequence", "=", "correct_sequences", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "exact_acc", "=", "num_correct_sequence", "/", "correct_sequences", ".", "size", "(", "0", ")", "\n", "\n", "# tokens it missed to predict correctly", "\n", "# c = Counter(target.masked_select(target.ne(predictions)).cpu().numpy())", "\n", "\n", "return", "exact_acc", ",", "acc", "", "", "", ""]], "home.repos.pwc.inspect_result.elementai_lagr.utils.statistics.split_and_sort_clauses": [[12, 14], ["sorted", "re.split"], "function", ["None"], ["def", "split_and_sort_clauses", "(", "lambd", ")", ":", "\n", "\t", "return", "sorted", "(", "re", ".", "split", "(", "\" AND | ; \"", ",", "lambd", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.__init__": [[28, 38], ["graph_utils.Preprocessor.tokenize", "graph_utils.Preprocessor.word_to_token", "graph_utils.Preprocessor.word_to_token", "graph_utils.Preprocessor.word_to_token", "graph_utils.Preprocessor.word_to_token", "graph_utils.Preprocessor.data_dir.split"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.tokenize", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", "=", "'data/graph/'", ",", "graph_layers", "=", "1", ")", ":", "\n", "        ", "self", ".", "data_dir", "=", "data_dir", "\n", "self", ".", "node_vocab", ",", "self", ".", "edge_vocab", "=", "self", ".", "tokenize", "(", ")", "\n", "self", ".", "graph_layers", "=", "graph_layers", "\n", "self", ".", "root", "=", "'/'", ".", "join", "(", "self", ".", "data_dir", ".", "split", "(", "'/'", ")", "[", ":", "-", "1", "]", ")", "\n", "\n", "assert", "self", ".", "word_to_token", "(", "'<pad>'", ")", "==", "GRAPH_PAD_TOKEN", ",", "f'<pad> token needs to be mapped to 1, but got {GRAPH_PAD_TOKEN}'", "\n", "assert", "self", ".", "word_to_token", "(", "'null'", ")", "==", "NULL_TOKEN", ",", "f'Null token needs to be mapped to 0, but got {NULL_TOKEN}'", "\n", "assert", "self", ".", "word_to_token", "(", "'<pad>'", ",", "'edges'", ")", "==", "GRAPH_PAD_TOKEN", ",", "f'<pad> token needs to be mapped to 1, but got {GRAPH_PAD_TOKEN}'", "\n", "assert", "self", ".", "word_to_token", "(", "'null'", ",", "'edges'", ")", "==", "NULL_TOKEN", ",", "f'Null token needs to be mapped to 0, but got {NULL_TOKEN}'", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.tokenize": [[39, 53], ["torchtext.vocab.Vocab", "torchtext.vocab.Vocab", "open", "collections.Counter", "open", "collections.Counter", "os.path.join", "line.rstrip", "os.path.join", "line.rstrip"], "methods", ["None"], ["", "def", "tokenize", "(", "self", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'nodes.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "nodes", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "# vocab will use null token:0, <pad>_token:1", "\n", "", "node_vocab", "=", "torchtext", ".", "vocab", ".", "Vocab", "(", "Counter", "(", "nodes", ")", ",", "specials", "=", "[", "'null'", ",", "'<pad>'", "]", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'edges.txt'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "edges", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "f", "]", "\n", "\n", "# vocab will use null token:0, <pad>_token:1", "\n", "", "edge_vocab", "=", "torchtext", ".", "vocab", ".", "Vocab", "(", "Counter", "(", "edges", ")", ",", "specials", "=", "[", "'null'", ",", "'<pad>'", "]", ")", "\n", "\n", "return", "node_vocab", ",", "edge_vocab", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token": [[54, 58], ["None"], "methods", ["None"], ["", "def", "word_to_token", "(", "self", ",", "word", ",", "vocab", "=", "'nodes'", ")", ":", "\n", "        ", "if", "vocab", "==", "'nodes'", ":", "\n", "            ", "return", "self", ".", "node_vocab", ".", "stoi", "[", "word", "]", "\n", "", "return", "self", ".", "edge_vocab", ".", "stoi", "[", "word", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.token_to_word": [[59, 63], ["None"], "methods", ["None"], ["", "def", "token_to_word", "(", "self", ",", "token", ",", "vocab", "=", "'nodes'", ")", ":", "\n", "        ", "if", "vocab", "==", "'nodes'", ":", "\n", "            ", "return", "self", ".", "node_vocab", ".", "itos", "[", "token", "]", "\n", "", "return", "self", ".", "edge_vocab", ".", "itos", "[", "token", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.scores_to_graph": [[64, 111], ["zip", "zip", "enumerate", "node_sets.append", "range", "edge_sets.append", "edge_label_sets.append", "zip", "token.item.item.item", "graph_utils.Preprocessor.token_to_word", "range", "graph_utils.Preprocessor.token_to_word", "graph_utils.Preprocessor.token_to_word", "edges.append", "edge_labels.append"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.token_to_word", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.token_to_word", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.token_to_word"], ["", "def", "scores_to_graph", "(", "self", ",", "node_preds", ",", "edge_preds", ",", "node_targets", ",", "edge_targets", ")", ":", "\n", "        ", "\"\"\" returns the batch of nodes, edges and edge labels where all three include null nodes and null edges, but exclude pad predictions.\"\"\"", "\n", "\n", "assert", "node_preds", ".", "shape", "[", "0", "]", "==", "edge_preds", ".", "shape", "[", "0", "]", ",", "f'Expected batch first, but got {node_preds.shape[0]}, {edge_preds.shape[0]}'", "\n", "\n", "assert", "node_preds", ".", "shape", "==", "node_targets", ".", "shape", "\n", "\n", "node_sets", "=", "[", "]", "\n", "for", "sequence", ",", "target_seq", "in", "zip", "(", "node_preds", ",", "node_targets", ")", ":", "# BS, seq_len", "\n", "            ", "nodes", "=", "{", "}", "\n", "for", "idx", ",", "(", "token", ",", "target_token", ")", "in", "enumerate", "(", "zip", "(", "sequence", ",", "target_seq", ")", ")", ":", "# seq_len", "\n", "                ", "token", "=", "token", ".", "item", "(", ")", "\n", "node", "=", "self", ".", "token_to_word", "(", "token", ",", "vocab", "=", "'nodes'", ")", "\n", "\n", "# if the target is a pad token, or if the prediction is pad, ignore it", "\n", "if", "node", "==", "'<pad>'", "or", "target_token", "==", "GRAPH_PAD_TOKEN", ":", "\n", "                    ", "continue", "\n", "", "else", ":", "\n", "                    ", "nodes", "[", "f'x_{idx}'", "]", "=", "node", "\n", "", "", "node_sets", ".", "append", "(", "nodes", ")", "\n", "\n", "", "edge_sets", "=", "[", "]", "\n", "edge_label_sets", "=", "[", "]", "\n", "for", "sequence", ",", "target_seq", "in", "zip", "(", "edge_preds", ",", "edge_targets", ")", ":", "# BS, seq_len, seq_len", "\n", "            ", "edges", "=", "[", "]", "\n", "edge_labels", "=", "[", "]", "\n", "\n", "for", "token_i", "in", "range", "(", "sequence", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "for", "token_j", "in", "range", "(", "sequence", ".", "shape", "[", "0", "]", ")", ":", "\n", "\n", "                    ", "predicted_token", "=", "sequence", "[", "token_i", ",", "token_j", "]", "\n", "edge_label", "=", "self", ".", "token_to_word", "(", "predicted_token", ",", "vocab", "=", "'edges'", ")", "\n", "true_token", "=", "target_seq", "[", "token_i", ",", "token_j", "]", "\n", "true_label", "=", "self", ".", "token_to_word", "(", "true_token", ",", "vocab", "=", "'edges'", ")", "\n", "\n", "if", "edge_label", "==", "'<pad>'", "or", "true_label", "==", "'<pad>'", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "edge", "=", "[", "f'x_{token_i}'", ",", "f'x_{token_j}'", "]", "\n", "edges", ".", "append", "(", "edge", ")", "\n", "edge_labels", ".", "append", "(", "edge_label", ")", "\n", "\n", "", "", "", "edge_sets", ".", "append", "(", "edges", ")", "\n", "edge_label_sets", ".", "append", "(", "edge_labels", ")", "\n", "\n", "", "return", "node_sets", ",", "edge_sets", ",", "edge_label_sets", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.graph_to_lambda": [[112, 131], ["zip", "len", "lambdas.append", "zip", "graph_utils.Preprocessor._graph_to_lambda", "nodes.items", "zip"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor._graph_to_lambda"], ["", "def", "graph_to_lambda", "(", "self", ",", "node_sets", ",", "edge_sets", ",", "edge_labels", ")", ":", "\n", "        ", "\"\"\"\n        Returns predicted serialized lambda string or NA if graph could not be serialized.\n        \"\"\"", "\n", "lambdas", "=", "[", "]", "\n", "for", "nodes", ",", "edges", ",", "labels", "in", "zip", "(", "node_sets", ",", "edge_sets", ",", "edge_labels", ")", ":", "\n", "# removes null nodes", "\n", "            ", "length", "=", "len", "(", "nodes", ")", "\n", "nodes", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "nodes", ".", "items", "(", ")", "if", "nodes", "[", "k", "]", "!=", "'null'", "}", "\n", "try", ":", "\n", "# removes null edges", "\n", "                ", "edges", ",", "labels", "=", "zip", "(", "*", "[", "(", "edge", ",", "label", ")", "for", "edge", ",", "label", "in", "zip", "(", "edges", ",", "labels", ")", "if", "label", "!=", "'null'", "]", ")", "\n", "lmbd", "=", "self", ".", "_graph_to_lambda", "(", "nodes", ",", "edges", ",", "labels", ",", "length", ")", "\n", "", "except", ":", "\n", "# skip example if there are no non-null edges", "\n", "                ", "lmbd", "=", "'NA'", "\n", "\n", "", "lambdas", ".", "append", "(", "lmbd", ")", "\n", "", "return", "lambdas", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor._graph_to_lambda": [[132, 242], ["nodes.items", "enumerate", "collections.OrderedDict", "collections.OrderedDict", "enumerate", "sorted", "sorted", "final.replace().replace().replace().replace", "zip", "zip", "e1.replace.replace.replace", "e2.replace.replace.replace", "node_label1[].isupper", "sorted", "node_label1[].isupper", "node_label2[].isupper", "print", "node_label2[].isupper", "int", "int", "final.replace().replace().replace", "nodes.get", "range", "collections.OrderedDict.keys", "collections.OrderedDict.items", "int", "event_clauses[].keys", "str", "final.replace().replace", "str", "len", "numpy.any", "final.replace", "str", "event_clauses[].values", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.get"], ["", "def", "_graph_to_lambda", "(", "self", ",", "nodes", ",", "edges", ",", "edge_labels", ")", ":", "\n", "        ", "\"\"\"\n        Turns a graph into a set of clauses serialized in the same way as COGS does.\n        \"\"\"", "\n", "# containing * word clauses - always goes to the beginning", "\n", "new", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "nodes", ".", "items", "(", ")", ":", "\n", "            ", "if", "k", "==", "'*'", ":", "\n", "                ", "continue", "\n", "", "new", "[", "k", "]", "=", "v", "\n", "\n", "", "for", "idx", ",", "items", "in", "enumerate", "(", "zip", "(", "edges", ",", "edge_labels", ")", ")", ":", "\n", "            ", "(", "e1", ",", "e2", ")", ",", "label", "=", "items", "\n", "if", "label", "==", "'article'", "and", "nodes", ".", "get", "(", "e1", ")", "==", "'*'", ":", "\n", "                ", "new", "[", "e2", "]", "=", "f'* {nodes[e2]}'", "\n", "\n", "", "", "nodes", "=", "new", "\n", "definite_clauses", "=", "OrderedDict", "(", ")", "\n", "\n", "\n", "# containing rest of the clauses - ordered primarily by arg1 and by arg2, if available", "\n", "event_clauses", "=", "OrderedDict", "(", "{", "f'x_{idx}'", ":", "{", "}", "for", "idx", "in", "range", "(", "40", ")", "}", ")", "\n", "\n", "for", "idx", ",", "items", "in", "enumerate", "(", "zip", "(", "edges", ",", "edge_labels", ")", ")", ":", "\n", "            ", "edge", ",", "label", "=", "items", "\n", "# e.g. x _ 1, x _ 3", "\n", "e1", ",", "e2", "=", "edge", "\n", "\n", "if", "label", "==", "'article'", ":", "\n", "                ", "continue", "\n", "\n", "# retrieves node labels, except if they are null nodes", "\n", "", "try", ":", "\n", "                ", "node_label1", "=", "nodes", "[", "e1", "]", "\n", "node_label2", "=", "nodes", "[", "e2", "]", "\n", "", "except", ":", "\n", "                ", "continue", "\n", "\n", "# reformat to x_1, x_3", "\n", "", "e1", "=", "e1", ".", "replace", "(", "' '", ",", "''", ")", "\n", "e2", "=", "e2", ".", "replace", "(", "' '", ",", "''", ")", "\n", "\n", "# if edge contains named entity, only produce one clause", "\n", "if", "node_label1", "[", "0", "]", ".", "isupper", "(", ")", "and", "node_label2", "[", "0", "]", ".", "isupper", "(", ")", ":", "\n", "                ", "print", "(", "'Edge connects two named entities. Unexpected behavior.'", ")", "\n", "continue", "\n", "", "if", "node_label1", "[", "0", "]", ".", "isupper", "(", ")", ":", "\n", "                ", "named_entity", "=", "node_label1", "\n", "event_clauses", "[", "e2", "]", "[", "e1", "]", "=", "node_label2", "+", "' . '", "+", "label", "+", "' ('", "+", "e2", "+", "', '", "+", "named_entity", "+", "') '", "\n", "", "elif", "node_label2", "[", "0", "]", ".", "isupper", "(", ")", ":", "\n", "                ", "named_entity", "=", "node_label2", "\n", "event_clauses", "[", "e1", "]", "[", "e2", "]", "=", "node_label1", "+", "' . '", "+", "label", "+", "' ('", "+", "e1", "+", "', '", "+", "named_entity", "+", "') '", "\n", "# if not named entity", "\n", "", "else", ":", "\n", "## if * word appears, modify its name in the arg", "\n", "                ", "if", "'*'", "in", "node_label1", "and", "'*'", "in", "node_label2", ":", "\n", "# print('Two definite articles connected. Unexpected behavior')", "\n", "# import ipdb;ipdb.set_trace()", "\n", "\n", "                    ", "definite_clauses", "[", "e1", "]", "=", "node_label1", "+", "' ('", "+", "e1", "+", "')'", "\n", "definite_clauses", "[", "e2", "]", "=", "node_label2", "+", "' ('", "+", "e2", "+", "')'", "\n", "node_label1", "=", "node_label1", "[", "2", ":", "]", "\n", "#             node_label2 = node_label2[2:]", "\n", "event_clauses", "[", "e1", "]", "[", "e2", "]", "=", "node_label1", "+", "' . '", "+", "label", "+", "' ('", "+", "e1", "+", "', '", "+", "e2", "+", "')'", "\n", "\n", "", "elif", "'*'", "in", "node_label1", ":", "\n", "                    ", "definite_clauses", "[", "e1", "]", "=", "node_label1", "+", "' ('", "+", "e1", "+", "')'", "\n", "node_label1", "=", "node_label1", "[", "2", ":", "]", "\n", "event_clauses", "[", "e1", "]", "[", "e2", "]", "=", "node_label1", "+", "' . '", "+", "label", "+", "' ('", "+", "e1", "+", "', '", "+", "e2", "+", "')'", "\n", "event_clauses", "[", "e2", "]", "=", "{", "'_'", ":", "node_label2", "+", "' ('", "+", "e2", "+", "')'", "}", "\n", "\n", "", "elif", "'*'", "in", "node_label2", ":", "\n", "                    ", "definite_clauses", "[", "e2", "]", "=", "node_label2", "+", "' ('", "+", "e2", "+", "')'", "\n", "node_label2", "=", "node_label2", "[", "2", ":", "]", "\n", "event_clauses", "[", "e1", "]", "[", "e2", "]", "=", "node_label1", "+", "' . '", "+", "label", "+", "' ('", "+", "e1", "+", "', '", "+", "e2", "+", "')'", "\n", "\n", "", "else", ":", "\n", "                    ", "event_clauses", "[", "e1", "]", "[", "e2", "]", "=", "node_label1", "+", "' . '", "+", "label", "+", "' ('", "+", "e1", "+", "', '", "+", "e2", "+", "')'", "\n", "event_clauses", "[", "e2", "]", "=", "{", "'_'", ":", "node_label2", "+", "' ('", "+", "e2", "+", "')'", "}", "\n", "\n", "# produces serialized output", "\n", "", "", "", "final", "=", "''", "\n", "definite_clause_keys", "=", "sorted", "(", "[", "int", "(", "k", "[", "2", ":", "]", ")", "for", "k", "in", "definite_clauses", ".", "keys", "(", ")", "]", ")", "\n", "for", "key", "in", "definite_clause_keys", ":", "\n", "            ", "final", "+=", "definite_clauses", "[", "'x_'", "+", "str", "(", "key", ")", "]", "+", "' ; '", "\n", "\n", "", "event_clause_keys", "=", "sorted", "(", "[", "int", "(", "k", "[", "2", ":", "]", ")", "for", "k", ",", "v", "in", "event_clauses", ".", "items", "(", ")", "if", "v", "!=", "{", "}", "]", ")", "\n", "\n", "for", "key", "in", "event_clause_keys", ":", "\n", "            ", "subkeys", "=", "sorted", "(", "[", "int", "(", "k", "[", "2", ":", "]", ")", "if", "k", "!=", "'_'", "else", "-", "1", "for", "k", "in", "event_clauses", "[", "'x_'", "+", "str", "(", "key", ")", "]", ".", "keys", "(", ")", "]", ")", "\n", "\n", "for", "clause_key", "in", "subkeys", ":", "\n", "                ", "clause_key", "=", "'x_'", "+", "str", "(", "clause_key", ")", "if", "clause_key", "!=", "-", "1", "else", "'_'", "\n", "\n", "if", "clause_key", "==", "'_'", ":", "\n", "                    ", "if", "len", "(", "event_clauses", "[", "'x_'", "+", "str", "(", "key", ")", "]", ")", ">", "1", "and", "not", "np", ".", "any", "(", "[", "'nmod'", "in", "val", "for", "val", "in", "event_clauses", "[", "'x_'", "+", "str", "(", "key", ")", "]", ".", "values", "(", ")", "]", ")", ":", "\n", "                        ", "continue", "\n", "\n", "", "", "final", "+=", "event_clauses", "[", "'x_'", "+", "str", "(", "key", ")", "]", "[", "clause_key", "]", "+", "' AND '", "\n", "\n", "#     removes AND from the end", "\n", "", "", "try", ":", "\n", "            ", "final", "=", "final", "[", ":", "-", "5", "]", "\n", "if", "final", "[", "-", "1", "]", "==", "' '", ":", "\n", "                ", "final", "=", "final", "[", ":", "-", "1", "]", "\n", "", "", "except", ":", "\n", "            ", "return", "'NA'", "\n", "\n", "", "return", "final", ".", "replace", "(", "'x_'", ",", "' x _ '", ")", ".", "replace", "(", "')'", ",", "' )'", ")", ".", "replace", "(", "'  '", ",", "' '", ")", ".", "replace", "(", "','", ",", "' ,'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cogs_build_graph": [[244, 248], ["graph_utils._cogs_nodes_to_node_seq", "graph_utils._cogs_edges_to_edge_seq"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cogs_nodes_to_node_seq", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cogs_edges_to_edge_seq"], ["", "", "def", "_cogs_build_graph", "(", "graph", ",", "preprocessor", ",", "length", ",", "n_special_tokens", ")", ":", "\n", "    ", "node_tgt_tensor", "=", "_cogs_nodes_to_node_seq", "(", "graph", "[", "'nodes'", "]", ",", "length", ",", "preprocessor", ",", "n_special_tokens", ")", "\n", "edge_tgt_tensor", "=", "_cogs_edges_to_edge_seq", "(", "graph", "[", "'edges'", "]", ",", "graph", "[", "'edge_labels'", "]", ",", "length", ",", "preprocessor", ",", "n_special_tokens", ")", "\n", "return", "node_tgt_tensor", ",", "edge_tgt_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cfq_build_graph": [[250, 255], ["graph_utils._cfq_nodes_to_node_seq", "graph_utils._cfq_edges_to_edge_seq"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cfq_nodes_to_node_seq", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cfq_edges_to_edge_seq"], ["", "def", "_cfq_build_graph", "(", "graph", ",", "preprocessor", ",", "length", ",", "n_special_tokens", ")", ":", "\n", "    ", "node_tgt_tensor", "=", "_cfq_nodes_to_node_seq", "(", "graph", "[", "'nodes'", "]", ",", "length", ",", "preprocessor", ",", "n_special_tokens", ")", "\n", "edge_tgt_tensor", "=", "_cfq_edges_to_edge_seq", "(", "graph", "[", "'edges'", "]", ",", "graph", "[", "'edge_labels'", "]", ",", "\n", "graph", "[", "'nodes'", "]", ",", "graph", "[", "'outputs_triples'", "]", ",", "length", ",", "preprocessor", ",", "n_special_tokens", ")", "\n", "return", "node_tgt_tensor", ",", "edge_tgt_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cogs_nodes_to_node_seq": [[257, 274], ["torch.LongTensor", "nodes.items", "torch.tensor", "torch.cat", "preprocessor.word_to_token", "range", "int"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token"], ["", "def", "_cogs_nodes_to_node_seq", "(", "nodes", ",", "input_length", ",", "preprocessor", ",", "n_special_tokens", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Takes nodes dict and turns it into a sequence of node tags for each input token.\n    nodes = {'x_1': node1, 'x_2': node2}\n    input_length: length of ['some', input, sentence]\n    preprocessor = object containing graph vocabulary\n    returns\n            - node token sequence (torch.LongTensor) ( corresponding to [null, node1, node2] )\n    \"\"\"", "\n", "node_sequence", "=", "torch", ".", "LongTensor", "(", "[", "NULL_TOKEN", "for", "_", "in", "range", "(", "input_length", ")", "]", ")", "\n", "\n", "for", "node", ",", "node_label", "in", "nodes", ".", "items", "(", ")", ":", "\n", "        ", "node_sequence", "[", "int", "(", "node", "[", "2", ":", "]", ")", "]", "=", "preprocessor", ".", "word_to_token", "(", "node_label", ")", "\n", "\n", "# Adds padding for SOS and EOS tokens", "\n", "", "pad", "=", "torch", ".", "tensor", "(", "[", "GRAPH_PAD_TOKEN", "]", "*", "preprocessor", ".", "graph_layers", ")", "\n", "return", "torch", ".", "cat", "(", "[", "pad", ",", "node_sequence", ",", "pad", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cogs_edges_to_edge_seq": [[275, 302], ["torch.LongTensor().view", "zip", "torch.LongTensor().view", "preprocessor.word_to_token", "torch.LongTensor", "int", "torch.LongTensor"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token"], ["", "def", "_cogs_edges_to_edge_seq", "(", "edges", ",", "edge_labels", ",", "N", ",", "preprocessor", ",", "n_special_tokens", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Takes edges and turns it into a sequence of set of edge tags for each input token.\n    nodes = {'x_0': word0, 'x_1': word1, 'x_2': Levi}\n    edges = [['x_1', 'x_0'], ['x_2', 'x_1']]\n    N: length of ['some', input, sentence]\n    edge_labols = [theme, agent]\n    preprocessor = object containing graph vocabulary\n\n    returns\n        torch tensor [[1,1,0,0], [1,1,0,0], [0,0,1,1], [0,0,1,0]]\n    \"\"\"", "\n", "\n", "# default edge type: null (no edge)", "\n", "final_edges", "=", "torch", ".", "LongTensor", "(", "[", "NULL_TOKEN", "]", "*", "N", "*", "N", ")", ".", "view", "(", "N", ",", "N", ")", "\n", "\n", "for", "edge", ",", "label", "in", "zip", "(", "edges", ",", "edge_labels", ")", ":", "\n", "        ", "e1", ",", "e2", "=", "[", "int", "(", "e", "[", "2", ":", "]", ")", "for", "e", "in", "edge", "]", "\n", "label_token", "=", "preprocessor", ".", "word_to_token", "(", "label", ",", "vocab", "=", "'edges'", ")", "\n", "final_edges", "[", "e1", ",", "e2", "]", "=", "label_token", "\n", "\n", "# add padding for SOS and EOS tokens", "\n", "", "N", "=", "N", "+", "n_special_tokens", "*", "preprocessor", ".", "graph_layers", "\n", "padding_tokens", "=", "torch", ".", "LongTensor", "(", "[", "GRAPH_PAD_TOKEN", "]", "*", "N", "*", "N", ")", ".", "view", "(", "N", ",", "N", ")", "\n", "padding_tokens", "[", "1", ":", "-", "1", ",", "1", ":", "-", "1", "]", "=", "final_edges", "\n", "\n", "return", "padding_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cfq_nodes_to_node_seq": [[304, 315], ["torch.LongTensor", "range", "torch.tensor", "torch.cat", "len", "preprocessor.word_to_token", "range"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token"], ["", "def", "_cfq_nodes_to_node_seq", "(", "nodes", ",", "num_nodes", ",", "preprocessor", ",", "n_special_tokens", "=", "0", ")", ":", "\n", "    ", "padding", "=", "num_nodes", "-", "len", "(", "nodes", ")", "\n", "nodes", "=", "nodes", "+", "[", "'null'", "]", "*", "padding", "\n", "node_sequence", "=", "torch", ".", "LongTensor", "(", "[", "NULL_TOKEN", "for", "_", "in", "range", "(", "num_nodes", ")", "]", ")", "\n", "\n", "for", "pos", "in", "range", "(", "num_nodes", ")", ":", "\n", "        ", "node_sequence", "[", "pos", "]", "=", "preprocessor", ".", "word_to_token", "(", "nodes", "[", "pos", "]", ")", "\n", "\n", "# Adds padding for SOS and EOS tokens", "\n", "", "pad", "=", "torch", ".", "tensor", "(", "[", "GRAPH_PAD_TOKEN", "]", "*", "preprocessor", ".", "graph_layers", ")", "\n", "return", "torch", ".", "cat", "(", "[", "pad", ",", "node_sequence", ",", "pad", "]", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils._cfq_edges_to_edge_seq": [[317, 394], ["torch.LongTensor().view", "collections.Counter", "zip", "torch.LongTensor().view", "len", "preprocessor.word_to_token", "len", "torch.LongTensor", "collections.Counter.items", "enumerate", "enumerate", "nodes.index", "enumerate", "enumerate", "nodes.index", "torch.LongTensor", "relevant_edges.append", "Exception", "preprocessor.word_to_token"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token", "home.repos.pwc.inspect_result.elementai_lagr.utils.graph_utils.Preprocessor.word_to_token"], ["", "def", "_cfq_edges_to_edge_seq", "(", "edges", ",", "edge_labels", ",", "nodes", ",", "output_triples", ",", "N", ",", "preprocessor", ",", "n_special_tokens", "=", "0", ")", ":", "\n", "\n", "    ", "assert", "len", "(", "nodes", ")", "<=", "N", ",", "f\"Too many nodes ({len(nodes)}) for the number of node predictions ({N})\"", "\n", "\n", "# default edge type: null (no edge)", "\n", "final_edges", "=", "torch", ".", "LongTensor", "(", "[", "preprocessor", ".", "word_to_token", "(", "'null'", ",", "vocab", "=", "'edges'", ")", "]", "*", "N", "*", "N", ")", ".", "view", "(", "N", ",", "N", ")", "\n", "node_counter", "=", "Counter", "(", "nodes", ")", "\n", "repeating_nodes", "=", "[", "node", "for", "node", ",", "freq", "in", "node_counter", ".", "items", "(", ")", "if", "freq", ">", "1", "]", "\n", "relevant_edges", "=", "[", "]", "\n", "for", "tri", "in", "output_triples", ":", "\n", "        ", "for", "node", "in", "repeating_nodes", ":", "\n", "            ", "if", "tri", "[", "1", "]", "==", "node", ":", "\n", "                ", "relevant_edges", ".", "append", "(", "tri", ")", "\n", "\n", "", "", "", "for", "edge", ",", "label", "in", "zip", "(", "edges", ",", "edge_labels", ")", ":", "\n", "        ", "src", ",", "dest", "=", "edge", "# edge contains str node labels", "\n", "pred_id", "=", "None", "\n", "\n", "if", "src", "in", "repeating_nodes", "and", "dest", "in", "repeating_nodes", ":", "\n", "            ", "raise", "(", "f'This should never happen, but got src: {src}, and obj: {obj}'", ")", "\n", "\n", "# handle repeated node labels", "\n", "", "if", "src", "in", "repeating_nodes", ":", "\n", "            ", "objects", "=", "[", "e", "[", "-", "1", "]", "for", "e", "in", "relevant_edges", "if", "e", "[", "1", "]", "==", "src", "]", "\n", "for", "idx", ",", "objs", "in", "enumerate", "(", "objects", ")", ":", "\n", "                ", "for", "obj", "in", "objs", ":", "\n", "                    ", "if", "dest", "==", "obj", ":", "\n", "                        ", "pred_id", "=", "idx", "\n", "break", "\n", "", "", "if", "pred_id", ":", "\n", "                    ", "break", "\n", "\n", "", "", "pointer", "=", "0", "\n", "for", "idx", ",", "n", "in", "enumerate", "(", "nodes", ")", ":", "\n", "                ", "if", "n", "==", "src", ":", "\n", "                    ", "if", "pointer", "==", "pred_id", ":", "\n", "                        ", "src_id", "=", "idx", "\n", "break", "\n", "", "else", ":", "\n", "                        ", "pointer", "+=", "1", "\n", "", "", "", "", "else", ":", "\n", "            ", "src_id", "=", "nodes", ".", "index", "(", "src", ")", "\n", "\n", "", "if", "dest", "in", "repeating_nodes", ":", "\n", "            ", "subjects", "=", "[", "e", "[", "0", "]", "for", "e", "in", "relevant_edges", "if", "e", "[", "1", "]", "==", "dest", "]", "\n", "for", "idx", ",", "subjs", "in", "enumerate", "(", "subjects", ")", ":", "\n", "                ", "for", "sub", "in", "subjs", ":", "\n", "                    ", "if", "src", "==", "sub", ":", "\n", "                        ", "pred_id", "=", "idx", "\n", "break", "\n", "", "", "if", "pred_id", ":", "\n", "                    ", "break", "\n", "\n", "", "", "pointer", "=", "0", "\n", "for", "idx", ",", "n", "in", "enumerate", "(", "nodes", ")", ":", "\n", "                ", "if", "n", "==", "dest", ":", "\n", "                    ", "if", "pointer", "==", "pred_id", ":", "\n", "                        ", "dest_id", "=", "idx", "\n", "break", "\n", "", "else", ":", "\n", "                        ", "pointer", "+=", "1", "\n", "", "", "", "", "else", ":", "\n", "            ", "dest_id", "=", "nodes", ".", "index", "(", "dest", ")", "\n", "\n", "", "label_token", "=", "preprocessor", ".", "word_to_token", "(", "label", ",", "vocab", "=", "'edges'", ")", "\n", "try", ":", "\n", "            ", "final_edges", "[", "src_id", ",", "dest_id", "]", "=", "label_token", "\n", "", "except", ":", "\n", "            ", "raise", "Exception", "(", "'Unexpected behavior.'", ")", "\n", "\n", "# Adds padding for src sequence's SOS and EOS", "\n", "", "", "N", "=", "N", "+", "n_special_tokens", "*", "preprocessor", ".", "graph_layers", "\n", "padding_tokens", "=", "torch", ".", "LongTensor", "(", "[", "GRAPH_PAD_TOKEN", "]", "*", "N", "*", "N", ")", ".", "view", "(", "N", ",", "N", ")", "\n", "skip", "=", "preprocessor", ".", "graph_layers", "\n", "padding_tokens", "[", "skip", ":", "-", "skip", ",", "skip", ":", "-", "skip", "]", "=", "final_edges", "\n", "\n", "return", "padding_tokens", "", "", ""]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.two_place_predicates_without_nmod": [[10, 24], ["re.findall", "result.append"], "function", ["None"], ["def", "two_place_predicates_without_nmod", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    Takes s and looks for the following pattern:\n      word . word (arg1, arg2) \n    Excludes word . word . word (...) patterns.\n\n    Returns: \n      [word, word, arg1, arg2]\n    \"\"\"", "\n", "pattern", "=", "re", ".", "findall", "(", "r\"(?:^|\\W)(?<!(\\.\\ ))(\\w+)\\ \\.\\ (\\w+)\\ \\((.*?)\\)\"", ",", "s", ")", "\n", "result", "=", "[", "]", "\n", "for", "p", "in", "pattern", ":", "\n", "        ", "result", ".", "append", "(", "p", "[", "1", ":", "]", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.two_place_predicates_with_nmod": [[26, 40], ["re.findall", "result.append", "len"], "function", ["None"], ["", "def", "two_place_predicates_with_nmod", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    Takes s and looks for the following pattern:\n      word . word (arg1, arg2) \n    Returns: \n      [word, word, arg1, arg2]\n    \"\"\"", "\n", "pattern", "=", "re", ".", "findall", "(", "r\"(\\w+)\\ \\.\\ (\\w+)\\ \\.\\ (\\w+).*? \\((.*?)\\)\"", ",", "s", ")", "\n", "result", "=", "[", "]", "\n", "for", "p", "in", "pattern", ":", "\n", "        ", "res", "=", "(", "p", "[", "0", "]", ",", "p", "[", "1", "]", "+", "' . '", "+", "p", "[", "2", "]", ",", "p", "[", "3", "]", ")", "\n", "assert", "len", "(", "p", ")", "==", "4", ",", "f\"Should be nmod clause, but got {p}\"", "\n", "result", ".", "append", "(", "res", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.one_place_definite_predicate": [[42, 50], ["re.findall"], "function", ["None"], ["", "def", "one_place_definite_predicate", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    Takes s and looks for the following pattern:\n      * cake (x _ 3)\n    Returns:\n      [('* ', 'cake', 'x _ 3')]\n    \"\"\"", "\n", "return", "re", ".", "findall", "(", "r\"(?:^|\\W)(?<=(\\*\\ ))(\\w+) \\((.*?)\\)\"", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.one_place_indefinite_predicate": [[52, 60], ["re.findall"], "function", ["None"], ["", "def", "one_place_indefinite_predicate", "(", "s", ")", ":", "\n", "    ", "\"\"\"\n    Takes s and looks for the following pattern:\n      word (x _ 1) \n    Returns:\n      ['', '', 'word', 'x _ 1']\n    \"\"\"", "\n", "return", "re", ".", "findall", "(", "r\"(?:^|\\W)(?<!(\\.\\ )|(\\*\\ ))(\\w+) \\((.*?)\\)\"", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.extract_graph_components": [[62, 93], ["p[].replace().split", "edges.append", "edge_labels.append", "len", "len", "Exception", "nodes.get", "len", "p[].replace", "arg2[].isupper", "len", "str", "enumerate"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.src.transformer.PositionalEncoding.get"], ["", "def", "extract_graph_components", "(", "pattern", ",", "nodes", ",", "edges", ",", "edge_labels", ",", "inp_text", ")", ":", "\n", "    ", "for", "p", "in", "pattern", ":", "\n", "        ", "assert", "len", "(", "p", ")", "==", "3", ",", "f'should be 3 components to account for 2-arg predicates, but got {len(p)} for {p}'", "\n", "\n", "node_label", "=", "p", "[", "0", "]", "\n", "edge_type", "=", "p", "[", "1", "]", "\n", "args", "=", "p", "[", "2", "]", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "','", ")", "\n", "arg1", "=", "args", "[", "0", "]", "\n", "arg2", "=", "args", "[", "1", "]", "\n", "\n", "if", "len", "(", "args", ")", "!=", "2", ":", "\n", "            ", "raise", "Exception", "(", "f\"You likely didn\\'t exclude primite types. Your out_text does not follow the regular parse patterns.\"", ")", "\n", "\n", "", "if", "not", "nodes", ".", "get", "(", "arg1", ")", ":", "\n", "            ", "nodes", "[", "arg1", "]", "=", "node_label", "\n", "\n", "# if not x_id arg, but named entity", "\n", "", "if", "'x_'", "not", "in", "arg2", ":", "\n", "            ", "assert", "arg2", "[", "0", "]", ".", "isupper", "(", ")", "==", "True", ",", "f\"Named entity doesnt start with capital, {arg2}.\"", "\n", "\n", "matched_indices", "=", "[", "idx", "for", "idx", ",", "w", "in", "enumerate", "(", "inp_text", ")", "if", "w", "==", "arg2", "]", "\n", "assert", "len", "(", "matched_indices", ")", "==", "1", ",", "f'{arg2} has multiple matches in {inp_text}.'", "\n", "idx", "=", "matched_indices", "[", "0", "]", "\n", "node", "=", "arg2", "\n", "arg2", "=", "'x_'", "+", "str", "(", "idx", ")", "\n", "nodes", "[", "arg2", "]", "=", "node", "\n", "\n", "", "edges", ".", "append", "(", "(", "arg1", ",", "arg2", ")", ")", "\n", "edge_labels", ".", "append", "(", "edge_type", ")", "\n", "\n", "", "return", "nodes", ",", "edges", ",", "edge_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.primitive_res": [[95, 101], ["None"], "function", ["None"], ["", "def", "primitive_res", "(", "inp_text", ")", ":", "\n", "    ", "return", "{", "\n", "'original_inp'", ":", "' '", ".", "join", "(", "inp_text", ")", ",", "\n", "'nodes'", ":", "{", "'x_0'", ":", "inp_text", "[", "0", "]", "}", ",", "\n", "'edges'", ":", "[", "[", "]", "]", ",", "\n", "'edge_labels'", ":", "[", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.parse": [[104, 166], ["parser.two_place_predicates_without_nmod", "parser.extract_graph_components", "parser.one_place_definite_predicate", "parser.one_place_indefinite_predicate", "parser.primitive_res", "parser.two_place_predicates_with_nmod", "parser.extract_graph_components", "p[].replace", "edges.append", "edge_labels.append", "p[].replace", "len", "len", "str", "int"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.parser.two_place_predicates_without_nmod", "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.extract_graph_components", "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.one_place_definite_predicate", "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.one_place_indefinite_predicate", "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.primitive_res", "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.two_place_predicates_with_nmod", "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.extract_graph_components"], ["", "def", "parse", "(", "inp_text", ",", "out_text", ",", "type", ")", ":", "\n", "    ", "\"\"\"\n    Takes lambda expression and parses it into a set of nodes, edges, and edge_labels as follows:\n    word.other(x_idx1, x_idx2) -> word is x_idx1 node, with word node label\n                               -> x_idx2 will have node label from input_seq[idx2]\n                               -> other is edge label between x_idx1 and x_idx2\n    word.other(x_idx1, word2)  -> word2 is node, with node label from a \"searching the index of word\" in the input.\n    word(x_idx1)               -> word is x_idx1 label\n    * word(x_idx1)             -> '* word' is x_idx1 label\n    \n    The above pattern break if:\n    - word2 isn't exactly mentioned in the input sequence.\n    \"\"\"", "\n", "if", "type", "==", "'primitive'", ":", "\n", "        ", "return", "primitive_res", "(", "inp_text", ")", "\n", "\n", "", "nodes", "=", "{", "}", "\n", "edges", "=", "[", "]", "\n", "edge_labels", "=", "[", "]", "\n", "\n", "# inp: word . word (arg1, arg2) out: [word, word, arg1, arg2]", "\n", "# e.g. [(forward, theme, arg1, arg2), (forward, agent, arg1, arg2)]", "\n", "pattern", "=", "two_place_predicates_without_nmod", "(", "out_text", ")", "\n", "nodes", ",", "edges", ",", "edge_labels", "=", "extract_graph_components", "(", "pattern", ",", "nodes", ",", "edges", ",", "edge_labels", ",", "inp_text", ")", "\n", "\n", "if", "'nmod'", "in", "out_text", ":", "\n", "        ", "pattern", "=", "two_place_predicates_with_nmod", "(", "out_text", ")", "\n", "nodes", ",", "edges", ",", "edge_labels", "=", "extract_graph_components", "(", "pattern", ",", "nodes", ",", "edges", ",", "edge_labels", ",", "inp_text", ")", "\n", "\n", "\n", "# finds * cake (x _ 3) -> [('* ', 'cake', 'x _ 3')]", "\n", "", "pattern", "=", "one_place_definite_predicate", "(", "out_text", ")", "\n", "\n", "for", "p", "in", "pattern", ":", "\n", "        ", "assert", "p", "[", "0", "]", "==", "'* '", ",", "f'Didn\\'t extract * in {p}'", "\n", "assert", "len", "(", "p", ")", "==", "3", ",", "'Missing patterns. Likely to be the wrong pattern.'", "\n", "node", "=", "p", "[", "1", "]", "\n", "node_id", "=", "p", "[", "2", "]", ".", "replace", "(", "' '", ",", "''", ")", "\n", "nodes", "[", "node_id", "]", "=", "node", "\n", "# save star as a separate node, indexed one before the node label", "\n", "star_position", "=", "f'x_{str(int(node_id[2:]) - 1)}'", "\n", "nodes", "[", "star_position", "]", "=", "'*'", "\n", "edges", ".", "append", "(", "(", "star_position", ",", "node_id", ")", ")", "\n", "edge_labels", ".", "append", "(", "(", "'article'", ")", ")", "\n", "\n", "# word (x _ 1) not preceded by . => ['', '', 'word', 'x _ 1']", "\n", "", "pattern3", "=", "one_place_indefinite_predicate", "(", "out_text", ")", "\n", "pattern3", "=", "[", "e", "[", "2", ":", "]", "for", "e", "in", "pattern3", "]", "\n", "\n", "for", "p", "in", "pattern3", ":", "\n", "        ", "assert", "len", "(", "p", ")", "==", "2", ",", "f'Should only have 1 arg, but extracted {p}.'", "\n", "node", "=", "p", "[", "0", "]", "\n", "node_id", "=", "p", "[", "1", "]", ".", "replace", "(", "' '", ",", "''", ")", "\n", "nodes", "[", "node_id", "]", "=", "node", "\n", "\n", "", "results", "=", "{", "\n", "'original_inp'", ":", "' '", ".", "join", "(", "inp_text", ")", ",", "\n", "'nodes'", ":", "nodes", ",", "\n", "'edges'", ":", "edges", ",", "\n", "'edge_labels'", ":", "edge_labels", "\n", "}", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.show_parsed": [[168, 177], ["enumerate", "print", "print", "print", "print", "print", "print", "print"], "function", ["None"], ["", "def", "show_parsed", "(", "original", ",", "parsed", ",", "N", "=", "1", ")", ":", "\n", "    ", "for", "idx", ",", "orig", "in", "enumerate", "(", "original", "[", ":", "N", "]", ")", ":", "\n", "        ", "print", "(", "'original input:\\n'", ",", "orig", "[", "0", "]", ")", "\n", "print", "(", "'original output:\\n'", ",", "orig", "[", "1", "]", ")", "\n", "print", "(", "'Parsed: \\n'", ")", "\n", "print", "(", "'nodes       '", ",", "parsed", "[", "idx", "]", "[", "'nodes'", "]", ")", "\n", "print", "(", "'edges       '", ",", "parsed", "[", "idx", "]", "[", "'edges'", "]", ")", "\n", "print", "(", "'edge_labels '", ",", "parsed", "[", "idx", "]", "[", "'edge_labels'", "]", ")", "\n", "print", "(", "'\\n########'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.parser.build_vocabularies": [[179, 239], ["set", "json.load", "json.load", "json.load", "json.load", "list", "set", "json.load", "json.load", "json.load", "json.load", "list", "open", "d[].values", "open", "d[].values", "open", "d[].values", "open", "d[].values", "open", "open", "open", "open", "open", "open", "list.add", "list.add", "list.add", "list.add", "list.add", "list.add", "list.add", "list.add", "f.write", "f.write", "str", "str"], "function", ["None"], ["", "", "def", "build_vocabularies", "(", "dir", ")", ":", "\n", "    ", "nodes_vocab", "=", "set", "(", ")", "\n", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/train_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "nodes", "=", "d", "[", "'nodes'", "]", ".", "values", "(", ")", "\n", "for", "n", "in", "nodes", ":", "\n", "            ", "nodes_vocab", ".", "add", "(", "n", ")", "\n", "", "", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/test_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "nodes", "=", "d", "[", "'nodes'", "]", ".", "values", "(", ")", "\n", "for", "n", "in", "nodes", ":", "\n", "            ", "nodes_vocab", ".", "add", "(", "n", ")", "\n", "", "", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/dev_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "nodes", "=", "d", "[", "'nodes'", "]", ".", "values", "(", ")", "\n", "for", "n", "in", "nodes", ":", "\n", "            ", "nodes_vocab", ".", "add", "(", "n", ")", "\n", "", "", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/gen_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "nodes", "=", "d", "[", "'nodes'", "]", ".", "values", "(", ")", "\n", "for", "n", "in", "nodes", ":", "\n", "            ", "nodes_vocab", ".", "add", "(", "n", ")", "\n", "\n", "", "", "nodes_vocab", "=", "list", "(", "nodes_vocab", ")", "\n", "\n", "edges_vocab", "=", "set", "(", ")", "\n", "\n", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/train_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "edges", "=", "d", "[", "'edge_labels'", "]", "\n", "for", "e", "in", "edges", ":", "\n", "            ", "edges_vocab", ".", "add", "(", "e", ")", "\n", "\n", "", "", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/test_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "edges", "=", "d", "[", "'edge_labels'", "]", "\n", "for", "e", "in", "edges", ":", "\n", "            ", "edges_vocab", ".", "add", "(", "e", ")", "\n", "\n", "", "", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/dev_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "edges", "=", "d", "[", "'edge_labels'", "]", "\n", "for", "e", "in", "edges", ":", "\n", "            ", "edges_vocab", ".", "add", "(", "e", ")", "\n", "\n", "", "", "data", "=", "json", ".", "load", "(", "open", "(", "f'{dir}/graph/gen_parsed.json'", ",", "'r'", ")", ")", "\n", "for", "d", "in", "data", ":", "\n", "        ", "edges", "=", "d", "[", "'edge_labels'", "]", "\n", "for", "e", "in", "edges", ":", "\n", "            ", "edges_vocab", ".", "add", "(", "e", ")", "\n", "\n", "", "", "edges_vocab", "=", "list", "(", "edges_vocab", ")", "\n", "\n", "with", "open", "(", "f'{dir}/graph/edges.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "w", "in", "edges_vocab", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "w", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "f'{dir}/graph/nodes.txt'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "w", "in", "nodes_vocab", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "w", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.Vocab.__init__": [[323, 326], ["vocab_dict.items"], "methods", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.Vocab.__len__": [[327, 329], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__init__": [[333, 338], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__len__": [[339, 341], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.CustomDataset.__getitem__": [[342, 351], ["torch.LongTensor", "torch.LongTensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._create_name": [[46, 66], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._ckpt_callback": [[68, 84], ["os.path.join", "pytorch_lightning.callbacks.model_checkpoint.ModelCheckpoint", "datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.make_collator": [[87, 101], ["__init__.pad_tensors"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.pad_tensors"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__._maybe_fetch_ckpt": [[103, 118], ["os.path.join", "os.listdir", "os.listdir.sort", "os.path.join", "print", "print", "datetime.datetime.strptime"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.parse_args": [[120, 129], ["parser.parse_args", "yaml.safe_load.items", "open", "yaml.safe_load", "setattr"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.parse_args"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.set_random_seed": [[131, 137], ["torch.manual_seed", "torch.cuda.manual_seed_all", "pytorch_lightning.seed_everything"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.setup_data": [[139, 265], ["typing.DefaultDict", "typing.DefaultDict", "typing.DefaultDict", "src.utils.graph_utils.Preprocessor", "list", "print", "os.path.exists", "os.makedirs", "os.path.join", "json.load", "pandas.DataFrame", "pd.DataFrame.set_index().agg().to_dict", "types.SimpleNamespace", "typing.DefaultDict.keys", "open", "list", "os.path.join", "os.path.join", "Exception", "open", "f.readlines", "open", "line.rstrip().split", "source_lines.append", "target_lines.append", "source.split", "target.split", "build_graph", "node_tgt_tensors.append", "edge_tgt_tensors.append", "src_tensors.append", "tgt_tensors.append", "open", "wf.writelines", "open", "wf.writelines", "os.path.join", "wf.write", "wf.write", "__init__.Vocab", "__init__.Vocab", "os.path.join", "pd.DataFrame.set_index().agg", "len", "src_tensor.append", "tgt_tensor.append", "os.path.join", "os.path.join", "line.rstrip", "pd.DataFrame.set_index"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.add_eos": [[267, 271], ["torch.cat", "torch.cat.scatter_", "lengths.unsqueeze().long", "torch.zeros_like", "lengths.unsqueeze"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.pad_tensors": [[273, 302], ["torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.stack", "torch.sum", "torch.sum", "torch.LongTensor().view", "res.append", "torch.LongTensor"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.utils.__init__.compare_alignments": [[304, 320], ["sorted", "numpy.where", "numpy.where", "numpy.where"], "function", ["None"], []], "home.repos.pwc.inspect_result.elementai_lagr.cfq.preprocess_cfq.create_tsv": [[10, 40], ["tensorflow_datasets.load", "tensorflow_datasets.as_numpy", "os.path.join", "os.makedirs", "print", "list", "list", "print", "print", "os.path.join", "preprocess_cfq._clean_and_convert_to_df", "print", "df.to_csv", "set", "set", "open", "open", "os.path.join", "os.path.join", "f.write", "os.path.join", "f.write", "len", "len", "set", "str", "str"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.cfq.preprocess_cfq._clean_and_convert_to_df"], ["def", "create_tsv", "(", "split_name", ",", "dir", ")", ":", "\n", "\t", "ds", "=", "tfds", ".", "load", "(", "'cfq/'", "+", "split_name", ")", "\n", "ds", "=", "tfds", ".", "as_numpy", "(", "ds", ")", "\n", "dir", "=", "os", ".", "path", ".", "join", "(", "dir", ",", "split_name", ")", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "'graph'", ")", ",", "exist_ok", "=", "True", ")", "\n", "nodes", ",", "edges", "=", "[", "]", ",", "[", "]", "\n", "\n", "# saves split as tsv", "\n", "for", "split", "in", "[", "'train'", ",", "'test'", ",", "'validation'", "]", ":", "\n", "\t\t", "df", ",", "new_nodes", ",", "new_edges", "=", "_clean_and_convert_to_df", "(", "ds", ",", "split", ")", "\n", "nodes", "+=", "new_nodes", "\n", "edges", "+=", "new_edges", "\n", "print", "(", "f\"Saving {split_name}\\'s {split} set as tsv ...\"", ")", "\n", "df", ".", "to_csv", "(", "\n", "os", ".", "path", ".", "join", "(", "dir", ",", "split", "+", "'.tsv'", ")", ",", "sep", "=", "\"\\t\"", ",", "header", "=", "False", ",", "index", "=", "False", ",", "encoding", "=", "'utf-8'", ")", "\n", "\n", "", "print", "(", "f'Saving nodes and edges under {dir} for {split_name} split ....'", ")", "\n", "nodes", "=", "list", "(", "set", "(", "nodes", ")", ")", "\n", "edges", "=", "list", "(", "set", "(", "edges", ")", ")", "\n", "\n", "print", "(", "f'Extracted {len(nodes)} node labels.'", ")", "\n", "print", "(", "f'Extracted {len(set(edges))} edges.'", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "'graph/nodes.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t", "for", "w", "in", "nodes", ":", "\n", "\t\t\t", "f", ".", "write", "(", "str", "(", "w", ")", "+", "'\\n'", ")", "\n", "\n", "", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "'graph/edges.txt'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "\t\t", "for", "w", "in", "edges", ":", "\n", "\t\t\t", "f", ".", "write", "(", "str", "(", "w", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.cfq.preprocess_cfq._clean_and_convert_to_df": [[42, 88], ["pandas.DataFrame", "example[].decode", "questions.append", "query.split.split", "queries.append", "len", "zip", "example[].decode", "nodes[].append", "tmp_query.append", "triple.split", "nodes[].append", "nodes[].append"], "function", ["None"], ["", "", "", "def", "_clean_and_convert_to_df", "(", "ds", ",", "split", ")", ":", "\n", "\t", "\"\"\"\n\tConverts byte string to strings, and removes parts of query that aren't needed,\n\tand extracts nodes and edges for vocabulary.\n\t\"\"\"", "\n", "\n", "questions", ",", "queries", "=", "[", "]", ",", "[", "]", "\n", "nodes", ",", "edges", "=", "{", "'vars'", ":", "[", "]", ",", "'preds'", ":", "[", "]", "}", ",", "[", "'agent'", ",", "'theme'", ",", "'FILTER'", "]", "\n", "\n", "for", "example", "in", "ds", "[", "split", "]", ":", "\n", "\t\t", "query", "=", "example", "[", "'query'", "]", ".", "decode", "(", "\"utf-8\"", ")", "\n", "questions", ".", "append", "(", "example", "[", "'question'", "]", ".", "decode", "(", "\"utf-8\"", ")", ")", "\n", "query", "=", "query", ".", "split", "(", "'\\n'", ")", "\n", "\n", "# process question type", "\n", "question_type", "=", "query", "[", "0", "]", "\n", "if", "'?x0'", "in", "question_type", ":", "\n", "\t\t\t", "nodes", "[", "'vars'", "]", ".", "append", "(", "'select_?x0'", ")", "\n", "\n", "# process triple clauses", "\n", "", "query", "=", "query", "[", "1", ":", "-", "1", "]", "# list of strings containing triples", "\n", "tmp_query", "=", "[", "]", "\n", "for", "triple", "in", "query", ":", "\n", "\t\t\t", "tmp_query", ".", "append", "(", "triple", ")", "\n", "\n", "# Don't add new nodes from FILTER clauses. This should only induce a new edge across existing nodes", "\n", "if", "'FILTER'", "not", "in", "triple", ":", "\n", "\t\t\t\t", "stripped", "=", "triple", ".", "split", "(", "' '", ")", "\n", "for", "entity", "in", "stripped", ":", "\n", "\n", "\t\t\t\t\t", "if", "'ns:'", "in", "entity", "and", "'ns:m'", "not", "in", "entity", "and", "'ns:g'", "not", "in", "entity", ":", "\n", "\t\t\t\t\t\t", "if", "'^'", "in", "entity", ":", "\n", "# correct parsing error", "\n", "\t\t\t\t\t\t\t", "entity", "=", "entity", "[", "1", ":", "]", "\n", "", "nodes", "[", "'preds'", "]", ".", "append", "(", "entity", ")", "\n", "", "elif", "entity", "not", "in", "[", "'.'", ",", "'a'", "]", ":", "\n", "\t\t\t\t\t\t", "nodes", "[", "'vars'", "]", ".", "append", "(", "entity", ")", "\n", "\n", "", "", "", "", "query", "=", "' '", ".", "join", "(", "[", "question_type", "+", "' .'", "]", "+", "tmp_query", ")", "\n", "queries", ".", "append", "(", "query", ")", "\n", "\n", "", "nodes", "=", "nodes", "[", "'vars'", "]", "+", "nodes", "[", "'preds'", "]", "\n", "\n", "placeholders", "=", "[", "None", "]", "*", "len", "(", "questions", ")", "\n", "df", "=", "pd", ".", "DataFrame", "(", "zip", "(", "questions", ",", "queries", ",", "placeholders", ")", ",", "columns", "=", "[", "'question'", ",", "'query'", ",", "'type'", "]", ")", "\n", "return", "df", ",", "nodes", ",", "edges", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.cfq.graph_parser._maybe_adjust_label": [[7, 11], ["None"], "function", ["None"], ["def", "_maybe_adjust_label", "(", "node", ",", "q_type", ")", ":", "\n", "    ", "if", "node", "==", "'?x0'", "and", "q_type", "==", "'select_?x0'", ":", "\n", "        ", "return", "'select_?x0'", "\n", "", "return", "node", "\n", "\n"]], "home.repos.pwc.inspect_result.elementai_lagr.cfq.graph_parser.parse": [[13, 97], ["out_text.split.split", "triple.split.split", "pandas.DataFrame().groupby().agg().reset_index().groupby().agg().reset_index", "pandas.DataFrame", "pandas.concat", "df[].values.tolist", "filters.append", "graph_parser._maybe_adjust_label", "len", "triple.split.split", "graph_parser._maybe_adjust_label", "graph_parser._maybe_adjust_label", "edges.append", "nodes.append", "ent.replace", "pandas.DataFrame().groupby().agg().reset_index().groupby().agg", "pandas.DataFrame", "edges.append", "nodes.append", "nodes.append", "edges.append", "pandas.DataFrame().groupby().agg().reset_index().groupby", "tuple", "pandas.DataFrame().groupby().agg().reset_index", "pandas.DataFrame().groupby().agg", "pandas.DataFrame().groupby", "tuple", "pandas.DataFrame"], "function", ["home.repos.pwc.inspect_result.elementai_lagr.cfq.graph_parser._maybe_adjust_label", "home.repos.pwc.inspect_result.elementai_lagr.cfq.graph_parser._maybe_adjust_label", "home.repos.pwc.inspect_result.elementai_lagr.cfq.graph_parser._maybe_adjust_label"], ["", "def", "parse", "(", "inp_text", ",", "out_text", ")", ":", "\n", "    ", "\"\"\"\n    Takes input sequence and logical form, and identifies all nodes, edges, and their edge labels.\n    \"\"\"", "\n", "# splits logical form into triples", "\n", "out_text", "=", "out_text", ".", "split", "(", "' . '", ")", "\n", "\n", "triples", "=", "[", "]", "\n", "filters", "=", "[", "]", "\n", "subj_only", "=", "[", "]", "\n", "q_type", "=", "'count(*)'", "\n", "\n", "for", "triple", "in", "out_text", ":", "\n", "        ", "if", "'SELECT'", "in", "triple", ":", "\n", "            ", "if", "'DISTINCT'", "in", "triple", ":", "\n", "                ", "q_type", "=", "'select_?x0'", "\n", "", "continue", "\n", "\n", "", "if", "'FILTER'", "in", "triple", ":", "\n", "            ", "filters", ".", "append", "(", "triple", ")", "\n", "continue", "\n", "\n", "# splits triple into entities", "\n", "", "triple", "=", "triple", ".", "split", "(", "' '", ")", "\n", "triple", "=", "[", "_maybe_adjust_label", "(", "ent", ".", "replace", "(", "'^'", ",", "''", ")", ",", "q_type", ")", "for", "ent", "in", "triple", "if", "ent", "not", "in", "[", "'a'", ",", "'.'", "]", "]", "\n", "# don't compress graph for nodes that only have a subject", "\n", "if", "len", "(", "triple", ")", "==", "2", ":", "\n", "            ", "subj_only", "+=", "[", "[", "(", "triple", "[", "0", "]", ",", ")", ",", "triple", "[", "1", "]", ",", "(", "None", ",", ")", "]", "]", "\n", "", "else", ":", "\n", "            ", "triples", "+=", "[", "triple", "]", "\n", "\n", "# reformat CFQ representation -> group by subject and predicate", "\n", "", "", "if", "triples", ":", "\n", "        ", "df", "=", "(", "\n", "pd", ".", "DataFrame", "(", "triples", ",", "columns", "=", "[", "'subj'", ",", "'pred'", ",", "'obj'", "]", ")", "\n", ".", "groupby", "(", "[", "'pred'", ",", "'subj'", "]", ")", "\n", ".", "agg", "(", "{", "'obj'", ":", "lambda", "x", ":", "tuple", "(", "x", ")", "}", ")", "\n", ".", "reset_index", "(", ")", "\n", ".", "groupby", "(", "[", "'pred'", ",", "'obj'", "]", ")", "\n", ".", "agg", "(", "{", "'subj'", ":", "lambda", "x", ":", "tuple", "(", "x", ")", "}", ")", "\n", ".", "reset_index", "(", ")", "\n", ")", "\n", "", "else", ":", "\n", "        ", "df", "=", "pd", ".", "DataFrame", "(", "triples", ",", "columns", "=", "[", "'subj'", ",", "'pred'", ",", "'obj'", "]", ")", "\n", "", "if", "subj_only", ":", "\n", "        ", "df", "=", "pd", ".", "concat", "(", "[", "df", ",", "pd", ".", "DataFrame", "(", "subj_only", ",", "columns", "=", "[", "'subj'", ",", "'pred'", ",", "'obj'", "]", ")", "]", ")", "\n", "", "reformated_triples", "=", "df", "[", "[", "'subj'", ",", "'pred'", ",", "'obj'", "]", "]", ".", "values", ".", "tolist", "(", ")", "+", "filters", "\n", "\n", "nodes", "=", "[", "]", "\n", "edges", "=", "[", "]", "\n", "edge_labels", "=", "[", "]", "\n", "for", "triple", "in", "reformated_triples", ":", "\n", "        ", "if", "'FILTER'", "in", "triple", ":", "\n", "            ", "triple", "=", "triple", ".", "split", "(", "' '", ")", "\n", "triple", "[", "2", "]", "=", "_maybe_adjust_label", "(", "triple", "[", "2", "]", ",", "q_type", ")", "\n", "triple", "[", "4", "]", "=", "_maybe_adjust_label", "(", "triple", "[", "4", "]", ",", "q_type", ")", "\n", "edges", ".", "append", "(", "[", "triple", "[", "2", "]", ",", "triple", "[", "4", "]", "]", ")", "\n", "edge_labels", "+=", "[", "'FILTER'", "]", "\n", "", "else", ":", "\n", "            ", "subjs", ",", "pred", ",", "objs", "=", "triple", "\n", "for", "sub", "in", "subjs", ":", "\n", "# change label if question is about x0", "\n", "                ", "if", "sub", "not", "in", "nodes", ":", "\n", "                    ", "nodes", ".", "append", "(", "sub", ")", "\n", "", "edges", ".", "append", "(", "[", "sub", ",", "pred", "]", ")", "\n", "edge_labels", "+=", "[", "'agent'", "]", "\n", "", "nodes", ".", "append", "(", "pred", ")", "\n", "\n", "for", "obj", "in", "objs", ":", "\n", "# change label if question is about x0", "\n", "                ", "if", "obj", "not", "in", "nodes", "and", "obj", ":", "\n", "                    ", "nodes", ".", "append", "(", "obj", ")", "\n", "", "if", "obj", ":", "\n", "                    ", "edges", ".", "append", "(", "[", "pred", ",", "obj", "]", ")", "\n", "edge_labels", "+=", "[", "'theme'", "]", "\n", "\n", "", "", "", "", "results", "=", "{", "\n", "'original_inp'", ":", "' '", ".", "join", "(", "inp_text", ")", ",", "\n", "'nodes'", ":", "nodes", ",", "\n", "'edges'", ":", "edges", ",", "\n", "'edge_labels'", ":", "edge_labels", ",", "\n", "'outputs_triples'", ":", "reformated_triples", "\n", "}", "\n", "return", "results", "\n", "\n"]]}