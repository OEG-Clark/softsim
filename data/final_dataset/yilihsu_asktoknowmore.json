{"home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.get_ngrams": [[106, 109], ["nltk.util.ngrams", "nltk.tokenize.word_tokenize"], "function", ["None"], ["def", "get_ngrams", "(", "text", ",", "n", ")", ":", "\n", "    ", "n_grams", "=", "ngrams", "(", "word_tokenize", "(", "text", ")", ",", "n", ")", "\n", "return", "[", "' '", ".", "join", "(", "grams", ")", "for", "grams", "in", "n_grams", "]", "\n", "", "def", "replace", "(", "old", ",", "new", ",", "str", ",", "caseinsentive", "=", "False", ")", ":", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.replace": [[109, 114], ["str.replace", "re.sub", "re.escape"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.replace"], ["", "def", "replace", "(", "old", ",", "new", ",", "str", ",", "caseinsentive", "=", "False", ")", ":", "\n", "    ", "if", "caseinsentive", ":", "\n", "        ", "return", "str", ".", "replace", "(", "old", ",", "new", ")", "\n", "", "else", ":", "\n", "        ", "return", "re", ".", "sub", "(", "re", ".", "escape", "(", "old", ")", ",", "new", ",", "str", ",", "flags", "=", "re", ".", "IGNORECASE", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.QGen.__init__": [[38, 55], ["transformers.T5Tokenizer.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "torch.device", "transformers.T5ForConditionalGeneration.from_pretrained.to", "spacy.load", "sense2vec.Sense2Vec().from_disk", "nltk.FreqDist", "similarity.normalized_levenshtein.NormalizedLevenshtein", "main.QGen.set_seed", "nltk.corpus.brown.words", "torch.cuda.is_available", "sense2vec.Sense2Vec"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.set_seed"], ["output", "=", "qg", ".", "predict_mcq", "(", "payload", ")", "\n", "if", "len", "(", "output", ")", "!=", "0", ":", "\n", "        ", "for", "q", "in", "output", "[", "'questions'", "]", ":", "\n", "            ", "print", "(", "\"==MCQ questions==\"", ")", "\n", "print", "(", "q", "[", "'question_statement'", "]", ")", "\n", "questions", ".", "add", "(", "q", "[", "'question_statement'", "]", ")", "\n", "# generate FAQ questions", "\n", "", "", "output", "=", "qg", ".", "predict_shortq", "(", "payload", ")", "\n", "if", "len", "(", "output", ")", "!=", "0", ":", "\n", "        ", "for", "q", "in", "output", "[", "'questions'", "]", ":", "\n", "            ", "print", "(", "\"==FAQ questions==\"", ")", "\n", "print", "(", "q", "[", "'Question'", "]", ")", "\n", "questions", ".", "add", "(", "q", "[", "'Question'", "]", ")", "\n", "", "", "try", ":", "\n", "        ", "claim_question", "[", "str", "(", "count", ")", "+", "\"_\"", "+", "claim", "]", "=", "list", "(", "dict", ".", "fromkeys", "(", "questions", ")", ")", "\n", "", "except", ":", "\n", "        ", "print", "(", "claim", ",", "list", "(", "dict", ".", "fromkeys", "(", "questions", ")", ")", ")", "\n", "", "questions", "=", "set", "(", ")", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.QGen.set_seed": [[56, 61], ["numpy.random.seed", "numpy.random.seed", "numpy.random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed_all"], "methods", ["None"], ["count", "=", "count", "+", "1", "\n", "div", ",", "mod", "=", "divmod", "(", "count", ",", "100", ")", "\n", "if", "mod", "==", "0", ":", "\n", "        ", "with", "open", "(", "out_dir", "+", "\"question_\"", "+", "str", "(", "div", ")", "+", "\".json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "claim_question", ",", "outfile", ")", "\n", "claim_question", "=", "{", "}", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.QGen.predict_mcq": [[62, 107], ["time.time", "time.time", "time.time", "time.time", "Questgen.mcq.mcq.get_keywords", "Questgen.mcq.mcq.get_sentences_for_keyword", "Questgen.mcq.mcq.get_sentences_for_keyword.keys", "payload.get", "payload.get", "len", "time.time", "time.time", "time.time", "time.time", "Questgen.mcq.mcq.get_sentences_for_keyword.keys", "Questgen.mcq.mcq.generate_questions_mcq", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_keywords", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_sentences_for_keyword", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.generate_questions_mcq"], ["", "", "", "with", "open", "(", "out_dir", "+", "\"question_\"", "+", "str", "(", "div", "+", "1", ")", "+", "\".json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "    ", "json", ".", "dump", "(", "claim_question", ",", "outfile", ")", "\n", "claim_question", "=", "{", "}", "\n", "\n", "\n", "", "Questions_df", "=", "pd", ".", "read_json", "(", "\"questions/question_1.json\"", ",", "orient", "=", "'index'", ",", "encoding", "=", "'utf8'", ")", "\n", "for", "i", "in", "range", "(", "2", ",", "31", ")", ":", "\n", "    ", "df1", "=", "pd", ".", "read_json", "(", "\"questions/question_\"", "+", "str", "(", "i", ")", "+", "\".json\"", ",", "orient", "=", "'index'", ",", "encoding", "=", "'utf8'", ")", "\n", "Questions_df", "=", "pd", ".", "concat", "(", "[", "Questions_df", ",", "df1", "]", ")", "\n", "", "Questions_df", "=", "Questions_df", ".", "reset_index", "(", ")", "\n", "Questions_df", ".", "columns", "=", "[", "'claim'", ",", "'q1'", ",", "'q2'", ",", "'q3'", ",", "'q4'", ",", "'q5'", ",", "'q6'", ",", "'q7'", ",", "'q8'", ",", "'q9'", ",", "'q10'", "]", "#'q11','q12','q13','q14','q15','q16','q17']", "\n", "Questions_df", "[", "\"claim\"", "]", "=", "Questions_df", "[", "\"claim\"", "]", ".", "str", ".", "replace", "(", "\"\u201c\"", ",", "\"\"", ")", ".", "replace", "(", "\"\u201d\"", ",", "\"\"", ")", ".", "replace", "(", "r\"\\d+_\"", ",", "\"\"", ",", "regex", "=", "True", ")", "\n", "\n", "\n", "qc_df", "=", "Questions_df", "\n", "qc_df", "=", "qc_df", ".", "fillna", "(", "\"None\"", ")", "\n", "\n", "answer", "=", "main", ".", "AnswerPredictor", "(", ")", "\n", "\n", "out_dir", "=", "\"QAs/\"", "\n", "os", ".", "makedirs", "(", "out_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "QA", "=", "{", "\n", "\"question\"", ":", "\"\"", ",", "\n", "\"answer\"", ":", "\"\"", "\n", "}", "\n", "\n", "payload", "=", "{", "\n", "\"input_text\"", ":", "'''At its greatest extent , the state expanded into territories that today comprise most of Iran , Iraq , Armenia , Azerbaijan , Georgia , Turkmenistan , Turkey , western Afghanistan , and southwestern Pakistan .'''", ",", "\n", "\"input_question\"", ":", "\"Who is the husband of Randy Couture?\"", "\n", "\n", "}", "\n", "\n", "output_dic", "=", "{", "}", "\n", "Answer_dic", "=", "{", "}", "\n", "count", "=", "0", "\n", "for", "i", ",", "evidence", "in", "tqdm", "(", "enumerate", "(", "claim_evidence_df", "[", "\"evidences\"", "]", "[", "count", ":", "]", ")", ")", ":", "\n", "# truncate the text into the length of 512", "\n", "    ", "payload", "[", "\"input_text\"", "]", "=", "evidence", "[", ":", "512", "]", "\n", "Answer_row", "=", "[", "]", "\n", "for", "q", "in", "qc_df", ".", "iloc", "[", "count", "+", "i", "]", "[", "1", ":", "]", ":", "#q1 start from 1th column", "\n", "        ", "payload", "[", "\"input_question\"", "]", "=", "q", "\n", "if", "q", "==", "\"None\"", ":", "\n", "            ", "a", "=", "\"None\"", "\n", "", "else", ":", "\n", "            ", "a", "=", "answer", ".", "predict_answer", "(", "payload", ")", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.QGen.predict_shortq": [[108, 148], ["Questgen.mcq.mcq.get_keywords", "Questgen.mcq.mcq.get_sentences_for_keyword", "Questgen.mcq.mcq.get_sentences_for_keyword.keys", "payload.get", "payload.get", "len", "print", "Questgen.mcq.mcq.generate_normal_questions", "print", "torch.cuda.empty_cache", "Questgen.mcq.mcq.get_sentences_for_keyword.keys"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_keywords", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_sentences_for_keyword", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.generate_normal_questions"], ["", "copy_QA", "=", "copy", ".", "deepcopy", "(", "QA", ")", "\n", "copy_QA", "[", "\"question\"", "]", "=", "q", "\n", "copy_QA", "[", "\"answer\"", "]", "=", "a", "\n", "\n", "Answer_row", ".", "append", "(", "copy_QA", ")", "\n", "copy_Answer_dic", "=", "copy", ".", "deepcopy", "(", "Answer_dic", ")", "\n", "copy_Answer_dic", "[", "\"evidences\"", "]", "=", "evidence", "\n", "copy_Answer_dic", "[", "\"claim\"", "]", "=", "qc_df", ".", "iloc", "[", "count", "+", "i", "]", "[", "\"claim\"", "]", "\n", "copy_Answer_dic", "[", "\"QA\"", "]", "=", "Answer_row", "\n", "\n", "", "output_dic", "[", "count", "+", "i", "]", "=", "copy_Answer_dic", "\n", "\n", "div", ",", "mod", "=", "divmod", "(", "count", "+", "i", "+", "1", ",", "100", ")", "\n", "if", "mod", "==", "0", ":", "\n", "        ", "with", "open", "(", "out_dir", "+", "\"output_dic_\"", "+", "str", "(", "div", ")", "+", "\".json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "            ", "json", ".", "dump", "(", "output_dic", ",", "outfile", ")", "\n", "output_dic", "=", "{", "}", "\n", "", "", "", "with", "open", "(", "out_dir", "+", "\"output_dic_\"", "+", "str", "(", "div", "+", "1", ")", "+", "\".json\"", ",", "\"w\"", ")", "as", "outfile", ":", "\n", "    ", "json", ".", "dump", "(", "output_dic", ",", "outfile", ")", "\n", "output_dic", "=", "{", "}", "\n", "\n", "", "df", "=", "pd", ".", "read_json", "(", "\"QAs/output_dic_1.json\"", ",", "orient", "=", "'index'", ")", "\n", "for", "i", "in", "range", "(", "2", ",", "31", ")", ":", "\n", "    ", "df1", "=", "pd", ".", "read_json", "(", "\"QAs/output_dic_\"", "+", "str", "(", "i", ")", "+", "\".json\"", ",", "orient", "=", "'index'", ")", "\n", "df", "=", "pd", ".", "concat", "(", "[", "df", ",", "df1", "]", ")", "\n", "\n", "#Entailment Checker (picking the best answer)", "\n", "", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "\"roberta-large-mnli\"", ")", "\n", "model", "=", "AutoModelForSequenceClassification", ".", "from_pretrained", "(", "\"roberta-large-mnli\"", ")", "\n", "\n", "answers", "=", "[", "]", "\n", "no_accpect", "=", "[", "\"TRUE\"", ",", "\"yes\"", ",", "\"FALSE\"", ",", "\"True\"", ",", "\"Yes\"", ",", "\"False\"", ",", "\"No\"", ",", "\"None\"", "]", "\n", "os", ".", "makedirs", "(", "\"best_answers/\"", ",", "exist_ok", "=", "True", ")", "\n", "for", "i", ",", "claim", "in", "tqdm", "(", "enumerate", "(", "df", "[", "\"claim\"", "]", "[", ":", "]", ")", ")", ":", "\n", "    ", "ans_strings", "=", "[", "]", "\n", "in_strings", "=", "[", "]", "\n", "#in_strings_backup = []", "\n", "for", "qa", "in", "df", ".", "iloc", "[", "i", "]", "[", "\"QA\"", "]", ":", "\n", "        ", "if", "qa", "[", "\"question\"", "]", "!=", "None", "and", "qa", "[", "\"answer\"", "]", "not", "in", "no_accpect", ":", "\n", "            ", "string", "=", "claim", "+", "\"</s></s>\"", "+", "qa", "[", "\"answer\"", "]", "\n", "ans_strings", ".", "append", "(", "qa", "[", "\"answer\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.QGen.paraphrase": [[150, 198], ["time.time", "time.time", "time.time", "time.time", "main.QGen.tokenizer.encode_plus", "main.QGen.model.generate", "enumerate", "payload.get", "payload.get", "encoding[].to", "encoding[].to", "main.QGen.tokenizer.decode", "print", "torch.cuda.empty_cache", "final_outputs.append", "main.QGen.lower", "main.QGen.sentence.lower"], "methods", ["None"], ["", "", "if", "len", "(", "in_strings", ")", "!=", "0", ":", "\n", "        ", "inputs", "=", "tokenizer", "(", "in_strings", ",", "padding", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "print", "(", "in_strings", ")", "\n", "print", "(", "outputs", ")", "\n", "#pred = outputs.logits.max(1).indices", "\n", "outputs_np", "=", "outputs", "[", "0", "]", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "max_contra_id", "=", "np", ".", "argmax", "(", "outputs_np", ".", "T", "[", "0", "]", ",", "axis", "=", "0", ")", "\n", "#    answers.append(df.iloc[i][\"QA\"][max_contra_id][\"answer\"])", "\n", "answers", ".", "append", "(", "ans_strings", "[", "max_contra_id", "]", ")", "\n", "", "else", ":", "\n", "        ", "answers", ".", "append", "(", "\" \"", ")", "\n", "", "div", ",", "mod", "=", "divmod", "(", "i", "+", "1", ",", "100", ")", "\n", "#    answers.append(df.iloc[i][\"QA\"][max_contra_id][\"answer\"])", "\n", "if", "mod", "==", "0", ":", "\n", "        ", "answers_df", "=", "pd", ".", "DataFrame", "(", "answers", ")", "\n", "answers", "=", "[", "]", "\n", "answers_df", ".", "to_csv", "(", "\"best_answers/output_\"", "+", "str", "(", "div", ")", "+", "\".csv\"", ")", "\n", "", "", "answers_df", "=", "pd", ".", "DataFrame", "(", "answers", ")", "\n", "answers", "=", "[", "]", "\n", "answers_df", ".", "to_csv", "(", "\"best_answers/output_\"", "+", "str", "(", "div", "+", "1", ")", "+", "\".csv\"", ")", "\n", "\n", "df", "=", "pd", ".", "read_json", "(", "\"QAs/output_dic_1.json\"", ",", "orient", "=", "'index'", ")", "\n", "for", "i", "in", "range", "(", "2", ",", "31", ")", ":", "\n", "    ", "df1", "=", "pd", ".", "read_json", "(", "\"QAs/output_dic_\"", "+", "str", "(", "i", ")", "+", "\".json\"", ",", "orient", "=", "'index'", ")", "\n", "df", "=", "pd", ".", "concat", "(", "[", "df", ",", "df1", "]", ")", "\n", "\n", "", "df2", "=", "pd", ".", "read_csv", "(", "\"best_answers/output_1.csv\"", ",", "names", "=", "[", "'best answer'", "]", ",", "header", "=", "0", ")", "\n", "for", "i", "in", "range", "(", "2", ",", "31", ")", ":", "\n", "    ", "df1", "=", "pd", ".", "read_csv", "(", "\"best_answers/output_\"", "+", "str", "(", "i", ")", "+", "\".csv\"", ",", "names", "=", "[", "'best answer'", "]", ",", "header", "=", "0", ")", "\n", "df2", "=", "pd", ".", "concat", "(", "[", "df2", ",", "df1", "]", ",", "ignore_index", "=", "True", ")", "\n", "\n", "", "df", "=", "df", ".", "join", "(", "df2", ")", "\n", "QA_df", "=", "df", "\n", "\n", "a1", "=", "[", "]", "\n", "a2", "=", "[", "]", "\n", "a3", "=", "[", "]", "\n", "a4", "=", "[", "]", "\n", "a5", "=", "[", "]", "\n", "a6", "=", "[", "]", "\n", "a7", "=", "[", "]", "\n", "a8", "=", "[", "]", "\n", "a9", "=", "[", "]", "\n", "a10", "=", "[", "]", "\n", "\n", "q1", "=", "[", "]", "\n", "q2", "=", "[", "]", "\n", "q3", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.BoolQGen.__init__": [[202, 211], ["transformers.T5Tokenizer.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "torch.device", "transformers.T5ForConditionalGeneration.from_pretrained.to", "main.BoolQGen.set_seed", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.set_seed"], ["q7", "=", "[", "]", "\n", "q8", "=", "[", "]", "\n", "q9", "=", "[", "]", "\n", "q10", "=", "[", "]", "\n", "\n", "for", "qa", "in", "QA_df", "[", "\"QA\"", "]", ":", "\n", "    ", "a1", ".", "append", "(", "qa", "[", "0", "]", "[", "\"answer\"", "]", ")", "\n", "a2", ".", "append", "(", "qa", "[", "1", "]", "[", "\"answer\"", "]", ")", "\n", "a3", ".", "append", "(", "qa", "[", "2", "]", "[", "\"answer\"", "]", ")", "\n", "a4", ".", "append", "(", "qa", "[", "3", "]", "[", "\"answer\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.BoolQGen.set_seed": [[212, 217], ["numpy.random.seed", "numpy.random.seed", "numpy.random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed_all"], "methods", ["None"], ["a5", ".", "append", "(", "qa", "[", "4", "]", "[", "\"answer\"", "]", ")", "\n", "a6", ".", "append", "(", "qa", "[", "5", "]", "[", "\"answer\"", "]", ")", "\n", "a7", ".", "append", "(", "qa", "[", "6", "]", "[", "\"answer\"", "]", ")", "\n", "a8", ".", "append", "(", "qa", "[", "7", "]", "[", "\"answer\"", "]", ")", "\n", "a9", ".", "append", "(", "qa", "[", "8", "]", "[", "\"answer\"", "]", ")", "\n", "a10", ".", "append", "(", "qa", "[", "9", "]", "[", "\"answer\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.BoolQGen.random_choice": [[218, 221], ["random.choice", "bool"], "methods", ["None"], ["\n", "q1", ".", "append", "(", "qa", "[", "0", "]", "[", "\"question\"", "]", ")", "\n", "q2", ".", "append", "(", "qa", "[", "1", "]", "[", "\"question\"", "]", ")", "\n", "q3", ".", "append", "(", "qa", "[", "2", "]", "[", "\"question\"", "]", ")", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.BoolQGen.predict_boolq": [[223, 252], ["time.time", "time.time", "time.time", "time.time", "main.BoolQGen.random_choice", "main.BoolQGen.tokenizer.encode_plus", "Questgen.encoding.encoding.beam_search_decoding", "payload.get", "payload.get", "encoding[].to", "encoding[].to", "torch.cuda.empty_cache"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.random_choice", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.encoding.encoding.beam_search_decoding"], ["q5", ".", "append", "(", "qa", "[", "4", "]", "[", "\"question\"", "]", ")", "\n", "q6", ".", "append", "(", "qa", "[", "5", "]", "[", "\"question\"", "]", ")", "\n", "q7", ".", "append", "(", "qa", "[", "6", "]", "[", "\"question\"", "]", ")", "\n", "q8", ".", "append", "(", "qa", "[", "7", "]", "[", "\"question\"", "]", ")", "\n", "q9", ".", "append", "(", "qa", "[", "8", "]", "[", "\"question\"", "]", ")", "\n", "q10", ".", "append", "(", "qa", "[", "9", "]", "[", "\"question\"", "]", ")", "\n", "\n", "", "QA_df", "[", "\"Q1\"", "]", "=", "q1", "\n", "QA_df", "[", "\"Q2\"", "]", "=", "q2", "\n", "QA_df", "[", "\"Q3\"", "]", "=", "q3", "\n", "QA_df", "[", "\"Q4\"", "]", "=", "q4", "\n", "QA_df", "[", "\"Q5\"", "]", "=", "q5", "\n", "QA_df", "[", "\"Q6\"", "]", "=", "q6", "\n", "QA_df", "[", "\"Q7\"", "]", "=", "q7", "\n", "QA_df", "[", "\"Q8\"", "]", "=", "q8", "\n", "QA_df", "[", "\"Q9\"", "]", "=", "q9", "\n", "QA_df", "[", "\"Q10\"", "]", "=", "q10", "\n", "\n", "QA_df", "[", "\"A1\"", "]", "=", "a1", "\n", "QA_df", "[", "\"A2\"", "]", "=", "a2", "\n", "QA_df", "[", "\"A3\"", "]", "=", "a3", "\n", "QA_df", "[", "\"A4\"", "]", "=", "a4", "\n", "QA_df", "[", "\"A5\"", "]", "=", "a5", "\n", "QA_df", "[", "\"A6\"", "]", "=", "a6", "\n", "QA_df", "[", "\"A7\"", "]", "=", "a7", "\n", "QA_df", "[", "\"A8\"", "]", "=", "a8", "\n", "QA_df", "[", "\"A9\"", "]", "=", "a9", "\n", "QA_df", "[", "\"A10\"", "]", "=", "a10", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.AnswerPredictor.__init__": [[255, 264], ["transformers.T5Tokenizer.from_pretrained", "transformers.T5ForConditionalGeneration.from_pretrained", "torch.device", "transformers.T5ForConditionalGeneration.from_pretrained.to", "main.AnswerPredictor.set_seed", "torch.cuda.is_available"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.set_seed"], ["model_args", "=", "Seq2SeqArgs", "(", ")", "\n", "model_args", ".", "max_length", "=", "1000", "\n", "\n", "QA2D_model", "=", "Seq2SeqModel", "(", "\n", "encoder_decoder_type", "=", "\"bart\"", ",", "\n", "encoder_decoder_name", "=", "\"./QA2D\"", ",", "\n", "cuda_device", "=", "0", ",", "\n", "args", "=", "model_args", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.AnswerPredictor.set_seed": [[265, 270], ["numpy.random.seed", "numpy.random.seed", "numpy.random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed_all"], "methods", ["None"], ["r", "=", "re", ".", "compile", "(", "r'[.]$'", ")", "\n", "df", "=", "df", ".", "replace", "(", "np", ".", "nan", ",", "''", ",", "regex", "=", "True", ")", "\n", "\n", "d", "=", "{", "\n", "\"A1\"", ":", "\"Q1\"", ",", "\n", "\"A2\"", ":", "\"Q2\"", ",", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.AnswerPredictor.greedy_decoding": [[271, 275], ["model.generate", "tokenizer.decode", "tokenizer.decode.strip().capitalize", "tokenizer.decode.strip"], "methods", ["None"], ["\"A3\"", ":", "\"Q3\"", ",", "\n", "\"A4\"", ":", "\"Q4\"", ",", "\n", "\"A5\"", ":", "\"Q5\"", ",", "\n", "\"A6\"", ":", "\"Q6\"", ",", "\n", "\"A7\"", ":", "\"Q7\"", ",", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.Questgen.main.AnswerPredictor.predict_answer": [[276, 294], ["time.time", "time.time", "time.time", "time.time", "main.AnswerPredictor.tokenizer.encode_plus", "main.AnswerPredictor.model.generate", "main.AnswerPredictor.tokenizer.decode", "main.AnswerPredictor.strip().capitalize", "payload.get", "payload.get", "encoding[].to", "encoding[].to", "main.AnswerPredictor.strip"], "methods", ["None"], ["\"A8\"", ":", "\"Q8\"", ",", "\n", "\"A9\"", ":", "\"Q9\"", ",", "\n", "\"A10\"", ":", "\"Q10\"", "\n", "}", "\n", "\n", "counta", "=", "0", "\n", "output", "=", "[", "]", "\n", "results", "=", "[", "]", "\n", "wrong_id", "=", "[", "]", "\n", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "for", "index", ",", "row", "in", "df", ".", "iterrows", "(", ")", ":", "\n", "    ", "counta", "=", "0", "\n", "for", "answer_col", "in", "d", ":", "\n", "        ", "if", "row", "[", "\"best answer\"", "]", "==", "row", "[", "answer_col", "]", ":", "\n", "#if row[d[answer_col]] == \"\":", "\n", "            ", "doc", "=", "nlp", "(", "row", "[", "\"best answer\"", "]", ")", "\n", "sent", "=", "False", "\n", "for", "token", "in", "doc", ":", "\n", "                ", "if", "token", ".", "dep_", "==", "\"nsubj\"", ":", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.encoding.encoding.greedy_decoding": [[5, 9], ["model.generate", "tokenizer.decode", "tokenizer.decode.strip().capitalize", "tokenizer.decode.strip"], "function", ["None"], ["def", "greedy_decoding", "(", "inp_ids", ",", "attn_mask", ",", "model", ",", "tokenizer", ")", ":", "\n", "  ", "greedy_output", "=", "model", ".", "generate", "(", "input_ids", "=", "inp_ids", ",", "attention_mask", "=", "attn_mask", ",", "max_length", "=", "256", ")", "\n", "Question", "=", "tokenizer", ".", "decode", "(", "greedy_output", "[", "0", "]", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "return", "Question", ".", "strip", "(", ")", ".", "capitalize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.encoding.encoding.beam_search_decoding": [[11, 23], ["model.generate", "tokenizer.decode", "Question.strip().capitalize", "Question.strip"], "function", ["None"], ["", "def", "beam_search_decoding", "(", "inp_ids", ",", "attn_mask", ",", "model", ",", "tokenizer", ")", ":", "\n", "  ", "beam_output", "=", "model", ".", "generate", "(", "input_ids", "=", "inp_ids", ",", "\n", "attention_mask", "=", "attn_mask", ",", "\n", "max_length", "=", "256", ",", "\n", "num_beams", "=", "10", ",", "\n", "num_return_sequences", "=", "3", ",", "\n", "no_repeat_ngram_size", "=", "2", ",", "\n", "early_stopping", "=", "True", "\n", ")", "\n", "Questions", "=", "[", "tokenizer", ".", "decode", "(", "out", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "for", "out", "in", "\n", "beam_output", "]", "\n", "return", "[", "Question", ".", "strip", "(", ")", ".", "capitalize", "(", ")", "for", "Question", "in", "Questions", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.encoding.encoding.topkp_decoding": [[25, 38], ["model.generate", "tokenizer.decode", "Question.strip().capitalize", "Question.strip"], "function", ["None"], ["", "def", "topkp_decoding", "(", "inp_ids", ",", "attn_mask", ",", "model", ",", "tokenizer", ")", ":", "\n", "  ", "topkp_output", "=", "model", ".", "generate", "(", "input_ids", "=", "inp_ids", ",", "\n", "attention_mask", "=", "attn_mask", ",", "\n", "max_length", "=", "256", ",", "\n", "do_sample", "=", "True", ",", "\n", "top_k", "=", "40", ",", "\n", "top_p", "=", "0.80", ",", "\n", "num_return_sequences", "=", "3", ",", "\n", "no_repeat_ngram_size", "=", "2", ",", "\n", "early_stopping", "=", "True", "\n", ")", "\n", "Questions", "=", "[", "tokenizer", ".", "decode", "(", "out", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "for", "out", "in", "topkp_output", "]", "\n", "return", "[", "Question", ".", "strip", "(", ")", ".", "capitalize", "(", ")", "for", "Question", "in", "Questions", "]", "\n", "", ""]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.MCQs_available": [[28, 35], ["word.replace.replace", "s2v.get_best_sense"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.replace"], ["def", "MCQs_available", "(", "word", ",", "s2v", ")", ":", "\n", "    ", "word", "=", "word", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "sense", "=", "s2v", ".", "get_best_sense", "(", "word", ")", "\n", "if", "sense", "is", "not", "None", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.edits": [[37, 46], ["set", "range", "len", "len"], "function", ["None"], ["", "", "def", "edits", "(", "word", ")", ":", "\n", "    ", "\"All edits that are one edit away from `word`.\"", "\n", "letters", "=", "'abcdefghijklmnopqrstuvwxyz '", "+", "string", ".", "punctuation", "\n", "splits", "=", "[", "(", "word", "[", ":", "i", "]", ",", "word", "[", "i", ":", "]", ")", "for", "i", "in", "range", "(", "len", "(", "word", ")", "+", "1", ")", "]", "\n", "deletes", "=", "[", "L", "+", "R", "[", "1", ":", "]", "for", "L", ",", "R", "in", "splits", "if", "R", "]", "\n", "transposes", "=", "[", "L", "+", "R", "[", "1", "]", "+", "R", "[", "0", "]", "+", "R", "[", "2", ":", "]", "for", "L", ",", "R", "in", "splits", "if", "len", "(", "R", ")", ">", "1", "]", "\n", "replaces", "=", "[", "L", "+", "c", "+", "R", "[", "1", ":", "]", "for", "L", ",", "R", "in", "splits", "if", "R", "for", "c", "in", "letters", "]", "\n", "inserts", "=", "[", "L", "+", "c", "+", "R", "for", "L", ",", "R", "in", "splits", "for", "c", "in", "letters", "]", "\n", "return", "set", "(", "deletes", "+", "transposes", "+", "replaces", "+", "inserts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.sense2vec_get_words": [[48, 75], ["word.replace.translate", "word_preprocessed.lower.lower", "mcq.edits", "word.replace.replace", "s2v.get_best_sense", "s2v.most_similar", "list", "word.replace.maketrans", "[].replace", "append_word.strip.strip", "append_word.strip.lower", "append_word_processed.translate.translate", "collections.OrderedDict.fromkeys", "append_word_processed.translate.maketrans", "output.append", "compare_list.append", "append_word.strip.title", "each_word[].split"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.edits", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.replace", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.replace"], ["", "def", "sense2vec_get_words", "(", "word", ",", "s2v", ")", ":", "\n", "    ", "output", "=", "[", "]", "\n", "\n", "word_preprocessed", "=", "word", ".", "translate", "(", "word", ".", "maketrans", "(", "\"\"", ",", "\"\"", ",", "string", ".", "punctuation", ")", ")", "\n", "word_preprocessed", "=", "word_preprocessed", ".", "lower", "(", ")", "\n", "\n", "word_edits", "=", "edits", "(", "word_preprocessed", ")", "\n", "\n", "word", "=", "word", ".", "replace", "(", "\" \"", ",", "\"_\"", ")", "\n", "\n", "sense", "=", "s2v", ".", "get_best_sense", "(", "word", ")", "\n", "most_similar", "=", "s2v", ".", "most_similar", "(", "sense", ",", "n", "=", "15", ")", "\n", "\n", "compare_list", "=", "[", "word_preprocessed", "]", "\n", "for", "each_word", "in", "most_similar", ":", "\n", "        ", "append_word", "=", "each_word", "[", "0", "]", ".", "split", "(", "\"|\"", ")", "[", "0", "]", ".", "replace", "(", "\"_\"", ",", "\" \"", ")", "\n", "append_word", "=", "append_word", ".", "strip", "(", ")", "\n", "append_word_processed", "=", "append_word", ".", "lower", "(", ")", "\n", "append_word_processed", "=", "append_word_processed", ".", "translate", "(", "append_word_processed", ".", "maketrans", "(", "\"\"", ",", "\"\"", ",", "string", ".", "punctuation", ")", ")", "\n", "if", "append_word_processed", "not", "in", "compare_list", "and", "word_preprocessed", "not", "in", "append_word_processed", "and", "append_word_processed", "not", "in", "word_edits", ":", "\n", "            ", "output", ".", "append", "(", "append_word", ".", "title", "(", ")", ")", "\n", "compare_list", ".", "append", "(", "append_word_processed", ")", "\n", "\n", "\n", "", "", "out", "=", "list", "(", "OrderedDict", ".", "fromkeys", "(", "output", ")", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_options": [[76, 89], ["mcq.sense2vec_get_words", "len", "print", "print"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.sense2vec_get_words"], ["", "def", "get_options", "(", "answer", ",", "s2v", ")", ":", "\n", "    ", "distractors", "=", "[", "]", "\n", "\n", "try", ":", "\n", "        ", "distractors", "=", "sense2vec_get_words", "(", "answer", ",", "s2v", ")", "\n", "if", "len", "(", "distractors", ")", ">", "0", ":", "\n", "            ", "print", "(", "\" Sense2vec_distractors successful for word : \"", ",", "answer", ")", "\n", "return", "distractors", ",", "\"sense2vec\"", "\n", "", "", "except", ":", "\n", "        ", "print", "(", "\" Sense2vec_distractors failed for word : \"", ",", "answer", ")", "\n", "\n", "\n", "", "return", "distractors", ",", "\"None\"", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.tokenize_sentences": [[90, 96], ["nltk.tokenize.sent_tokenize", "sentence.strip", "len"], "function", ["None"], ["", "def", "tokenize_sentences", "(", "text", ")", ":", "\n", "    ", "sentences", "=", "[", "sent_tokenize", "(", "text", ")", "]", "\n", "sentences", "=", "[", "y", "for", "x", "in", "sentences", "for", "y", "in", "x", "]", "\n", "# Remove any short sentences less than 20 letters.", "\n", "sentences", "=", "[", "sentence", ".", "strip", "(", ")", "for", "sentence", "in", "sentences", "if", "len", "(", "sentence", ")", ">", "20", "]", "\n", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_sentences_for_keyword": [[98, 123], ["flashtext.KeywordProcessor", "keyword_sentences.keys", "keyword_sentences.keys", "word.strip.strip", "flashtext.KeywordProcessor.add_keyword", "flashtext.KeywordProcessor.extract_keywords", "sorted", "keyword_sentences[].append", "len", "delete_keys.append"], "function", ["None"], ["", "def", "get_sentences_for_keyword", "(", "keywords", ",", "sentences", ")", ":", "\n", "    ", "keyword_processor", "=", "KeywordProcessor", "(", ")", "\n", "keyword_sentences", "=", "{", "}", "\n", "for", "word", "in", "keywords", ":", "\n", "        ", "word", "=", "word", ".", "strip", "(", ")", "\n", "keyword_sentences", "[", "word", "]", "=", "[", "]", "\n", "keyword_processor", ".", "add_keyword", "(", "word", ")", "\n", "", "for", "sentence", "in", "sentences", ":", "\n", "        ", "keywords_found", "=", "keyword_processor", ".", "extract_keywords", "(", "sentence", ")", "\n", "for", "key", "in", "keywords_found", ":", "\n", "            ", "keyword_sentences", "[", "key", "]", ".", "append", "(", "sentence", ")", "\n", "\n", "", "", "for", "key", "in", "keyword_sentences", ".", "keys", "(", ")", ":", "\n", "        ", "values", "=", "keyword_sentences", "[", "key", "]", "\n", "values", "=", "sorted", "(", "values", ",", "key", "=", "len", ",", "reverse", "=", "True", ")", "\n", "keyword_sentences", "[", "key", "]", "=", "values", "\n", "\n", "", "delete_keys", "=", "[", "]", "\n", "for", "k", "in", "keyword_sentences", ".", "keys", "(", ")", ":", "\n", "        ", "if", "len", "(", "keyword_sentences", "[", "k", "]", ")", "==", "0", ":", "\n", "            ", "delete_keys", ".", "append", "(", "k", ")", "\n", "", "", "for", "del_key", "in", "delete_keys", ":", "\n", "        ", "del", "keyword_sentences", "[", "del_key", "]", "\n", "\n", "", "return", "keyword_sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.is_far": [[125, 134], ["score_list.append", "min", "normalized_levenshtein.distance", "word.lower", "currentword.lower"], "function", ["None"], ["", "def", "is_far", "(", "words_list", ",", "currentword", ",", "thresh", ",", "normalized_levenshtein", ")", ":", "\n", "    ", "threshold", "=", "thresh", "\n", "score_list", "=", "[", "]", "\n", "for", "word", "in", "words_list", ":", "\n", "        ", "score_list", ".", "append", "(", "normalized_levenshtein", ".", "distance", "(", "word", ".", "lower", "(", ")", ",", "currentword", ".", "lower", "(", ")", ")", ")", "\n", "", "if", "min", "(", "score_list", ")", ">=", "threshold", ":", "\n", "        ", "return", "True", "\n", "", "else", ":", "\n", "        ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.filter_phrases": [[135, 145], ["len", "filtered_phrases.append", "mcq.is_far", "filtered_phrases.append", "len"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.is_far"], ["", "", "def", "filter_phrases", "(", "phrase_keys", ",", "max", ",", "normalized_levenshtein", ")", ":", "\n", "    ", "filtered_phrases", "=", "[", "]", "\n", "if", "len", "(", "phrase_keys", ")", ">", "0", ":", "\n", "        ", "filtered_phrases", ".", "append", "(", "phrase_keys", "[", "0", "]", ")", "\n", "for", "ph", "in", "phrase_keys", "[", "1", ":", "]", ":", "\n", "            ", "if", "is_far", "(", "filtered_phrases", ",", "ph", ",", "0.7", ",", "normalized_levenshtein", ")", ":", "\n", "                ", "filtered_phrases", ".", "append", "(", "ph", ")", "\n", "", "if", "len", "(", "filtered_phrases", ")", ">=", "max", ":", "\n", "                ", "break", "\n", "", "", "", "return", "filtered_phrases", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_nouns_multipartite": [[147, 172], ["pke.unsupervised.MultipartiteRank", "pke.unsupervised.MultipartiteRank.load_document", "list", "nltk.corpus.stopwords.words", "pke.unsupervised.MultipartiteRank.candidate_selection", "pke.unsupervised.MultipartiteRank.get_n_best", "pke.unsupervised.MultipartiteRank.candidate_weighting", "out.append"], "function", ["None"], ["", "def", "get_nouns_multipartite", "(", "text", ")", ":", "\n", "    ", "out", "=", "[", "]", "\n", "\n", "extractor", "=", "pke", ".", "unsupervised", ".", "MultipartiteRank", "(", ")", "\n", "extractor", ".", "load_document", "(", "input", "=", "text", ",", "language", "=", "'en'", ")", "\n", "pos", "=", "{", "'PROPN'", ",", "'NOUN'", ",", "'ADJ'", ",", "'NUM'", ",", "'ADV'", ",", "'DET'", "}", "\n", "stoplist", "=", "list", "(", "string", ".", "punctuation", ")", "\n", "stoplist", "+=", "stopwords", ".", "words", "(", "'english'", ")", "\n", "extractor", ".", "candidate_selection", "(", "pos", "=", "pos", ",", "stoplist", "=", "stoplist", ")", "\n", "# 4. build the Multipartite graph and rank candidates using random walk,", "\n", "#    alpha controls the weight adjustment mechanism, see TopicRank for", "\n", "#    threshold/method parameters.", "\n", "try", ":", "\n", "        ", "extractor", ".", "candidate_weighting", "(", "alpha", "=", "1.1", ",", "\n", "threshold", "=", "0.75", ",", "\n", "method", "=", "'average'", ")", "\n", "", "except", ":", "\n", "        ", "return", "out", "\n", "\n", "", "keyphrases", "=", "extractor", ".", "get_n_best", "(", "n", "=", "10", ")", "\n", "\n", "for", "key", "in", "keyphrases", ":", "\n", "        ", "out", ".", "append", "(", "key", "[", "0", "]", ")", "\n", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_phrases": [[174, 189], ["list", "sorted", "len", "phrases.keys", "phrase.split", "len"], "function", ["None"], ["", "def", "get_phrases", "(", "doc", ")", ":", "\n", "    ", "phrases", "=", "{", "}", "\n", "for", "np", "in", "doc", ".", "noun_chunks", ":", "\n", "        ", "phrase", "=", "np", ".", "text", "\n", "len_phrase", "=", "len", "(", "phrase", ".", "split", "(", ")", ")", "\n", "if", "len_phrase", ">=", "1", ":", "\n", "            ", "if", "phrase", "not", "in", "phrases", ":", "\n", "                ", "phrases", "[", "phrase", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "phrases", "[", "phrase", "]", "=", "phrases", "[", "phrase", "]", "+", "1", "\n", "\n", "", "", "", "phrase_keys", "=", "list", "(", "phrases", ".", "keys", "(", ")", ")", "\n", "phrase_keys", "=", "sorted", "(", "phrase_keys", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ",", "reverse", "=", "True", ")", "\n", "phrase_keys", "=", "phrase_keys", "[", ":", "50", "]", "\n", "return", "phrase_keys", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_keywords": [[192, 215], ["nlp", "int", "mcq.get_nouns_multipartite", "sorted", "mcq.filter_phrases", "mcq.get_phrases", "mcq.filter_phrases", "mcq.filter_phrases", "min", "answers.append"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_nouns_multipartite", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.filter_phrases", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.get_phrases", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.filter_phrases", "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.filter_phrases"], ["", "def", "get_keywords", "(", "nlp", ",", "text", ",", "max_keywords", ",", "s2v", ",", "fdist", ",", "normalized_levenshtein", ",", "no_of_sentences", ")", ":", "\n", "    ", "doc", "=", "nlp", "(", "text", ")", "\n", "max_keywords", "=", "int", "(", "max_keywords", ")", "\n", "\n", "keywords", "=", "get_nouns_multipartite", "(", "text", ")", "\n", "keywords", "=", "sorted", "(", "keywords", ",", "key", "=", "lambda", "x", ":", "fdist", "[", "x", "]", ")", "\n", "keywords", "=", "filter_phrases", "(", "keywords", ",", "max_keywords", ",", "normalized_levenshtein", ")", "\n", "\n", "phrase_keys", "=", "get_phrases", "(", "doc", ")", "\n", "filtered_phrases", "=", "filter_phrases", "(", "phrase_keys", ",", "max_keywords", ",", "normalized_levenshtein", ")", "\n", "\n", "total_phrases", "=", "keywords", "+", "filtered_phrases", "\n", "\n", "total_phrases_filtered", "=", "filter_phrases", "(", "total_phrases", ",", "min", "(", "max_keywords", ",", "2", "*", "no_of_sentences", ")", ",", "normalized_levenshtein", ")", "\n", "\n", "\n", "answers", "=", "[", "]", "\n", "for", "answer", "in", "total_phrases_filtered", ":", "\n", "        ", "if", "answer", "not", "in", "answers", ":", "#and MCQs_available(answer,s2v):", "\n", "            ", "answers", ".", "append", "(", "answer", ")", "\n", "\n", "", "", "answers", "=", "answers", "[", ":", "max_keywords", "]", "\n", "return", "answers", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.generate_questions_mcq": [[217, 263], ["keyword_sent_mapping.keys", "tokenizer.batch_encode_plus", "print", "enumerate", "batch_text.append", "encoding[].to", "encoding[].to", "torch.no_grad", "model.generate", "tokenizer.decode", "tokenizer.decode.replace", "Question.strip.strip", "output_array[].append"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.replace"], ["", "def", "generate_questions_mcq", "(", "keyword_sent_mapping", ",", "device", ",", "tokenizer", ",", "model", ",", "sense2vec", ",", "normalized_levenshtein", ")", ":", "\n", "    ", "batch_text", "=", "[", "]", "\n", "answers", "=", "keyword_sent_mapping", ".", "keys", "(", ")", "\n", "for", "answer", "in", "answers", ":", "\n", "        ", "txt", "=", "keyword_sent_mapping", "[", "answer", "]", "\n", "context", "=", "\"context: \"", "+", "txt", "\n", "text", "=", "context", "+", "\" \"", "+", "\"answer: \"", "+", "answer", "+", "\" </s>\"", "\n", "batch_text", ".", "append", "(", "text", ")", "\n", "\n", "", "encoding", "=", "tokenizer", ".", "batch_encode_plus", "(", "batch_text", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "\n", "\n", "print", "(", "\"Running model for generation\"", ")", "\n", "input_ids", ",", "attention_masks", "=", "encoding", "[", "\"input_ids\"", "]", ".", "to", "(", "device", ")", ",", "encoding", "[", "\"attention_mask\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outs", "=", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_masks", ",", "\n", "max_length", "=", "150", ")", "\n", "\n", "", "output_array", "=", "{", "}", "\n", "output_array", "[", "\"questions\"", "]", "=", "[", "]", "\n", "#     print(outs)", "\n", "for", "index", ",", "val", "in", "enumerate", "(", "answers", ")", ":", "\n", "        ", "individual_question", "=", "{", "}", "\n", "out", "=", "outs", "[", "index", ",", ":", "]", "\n", "dec", "=", "tokenizer", ".", "decode", "(", "out", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "\n", "Question", "=", "dec", ".", "replace", "(", "\"question:\"", ",", "\"\"", ")", "\n", "Question", "=", "Question", ".", "strip", "(", ")", "\n", "individual_question", "[", "\"question_statement\"", "]", "=", "Question", "\n", "individual_question", "[", "\"question_type\"", "]", "=", "\"MCQ\"", "\n", "individual_question", "[", "\"answer\"", "]", "=", "val", "\n", "individual_question", "[", "\"id\"", "]", "=", "index", "+", "1", "\n", "#        individual_question[\"options\"], individual_question[\"options_algorithm\"] = get_options(val, sense2vec)", "\n", "\n", "#        individual_question[\"options\"] =  filter_phrases(individual_question[\"options\"], 10,normalized_levenshtein)", "\n", "index", "=", "3", "\n", "#        individual_question[\"extra_options\"]= individual_question[\"options\"][index:]", "\n", "#        individual_question[\"options\"] = individual_question[\"options\"][:index]", "\n", "individual_question", "[", "\"context\"", "]", "=", "keyword_sent_mapping", "[", "val", "]", "\n", "\n", "#        if len(individual_question[\"options\"])>0:", "\n", "output_array", "[", "\"questions\"", "]", ".", "append", "(", "individual_question", ")", "\n", "\n", "", "return", "output_array", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.generate_normal_questions": [[264, 303], ["keyword_sent_mapping.keys", "tokenizer.batch_encode_plus", "print", "enumerate", "batch_text.append", "encoding[].to", "encoding[].to", "torch.no_grad", "model.generate", "tokenizer.decode", "tokenizer.decode.replace", "Question.strip.strip", "output_array[].append"], "function", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.None.counterfactual_generation.replace"], ["", "def", "generate_normal_questions", "(", "keyword_sent_mapping", ",", "device", ",", "tokenizer", ",", "model", ")", ":", "#for normal one word questions", "\n", "    ", "batch_text", "=", "[", "]", "\n", "answers", "=", "keyword_sent_mapping", ".", "keys", "(", ")", "\n", "for", "answer", "in", "answers", ":", "\n", "        ", "txt", "=", "keyword_sent_mapping", "[", "answer", "]", "\n", "context", "=", "\"context: \"", "+", "txt", "\n", "text", "=", "context", "+", "\" \"", "+", "\"answer: \"", "+", "answer", "+", "\" </s>\"", "\n", "batch_text", ".", "append", "(", "text", ")", "\n", "\n", "", "encoding", "=", "tokenizer", ".", "batch_encode_plus", "(", "batch_text", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", ")", "\n", "\n", "\n", "print", "(", "\"Running model for generation\"", ")", "\n", "input_ids", ",", "attention_masks", "=", "encoding", "[", "\"input_ids\"", "]", ".", "to", "(", "device", ")", ",", "encoding", "[", "\"attention_mask\"", "]", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "outs", "=", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "\n", "attention_mask", "=", "attention_masks", ",", "\n", "max_length", "=", "150", ")", "\n", "\n", "", "output_array", "=", "{", "}", "\n", "output_array", "[", "\"questions\"", "]", "=", "[", "]", "\n", "\n", "for", "index", ",", "val", "in", "enumerate", "(", "answers", ")", ":", "\n", "        ", "individual_quest", "=", "{", "}", "\n", "out", "=", "outs", "[", "index", ",", ":", "]", "\n", "dec", "=", "tokenizer", ".", "decode", "(", "out", ",", "skip_special_tokens", "=", "True", ",", "clean_up_tokenization_spaces", "=", "True", ")", "\n", "\n", "Question", "=", "dec", ".", "replace", "(", "'question:'", ",", "''", ")", "\n", "Question", "=", "Question", ".", "strip", "(", ")", "\n", "\n", "individual_quest", "[", "'Question'", "]", "=", "Question", "\n", "individual_quest", "[", "'Answer'", "]", "=", "val", "\n", "individual_quest", "[", "\"id\"", "]", "=", "index", "+", "1", "\n", "individual_quest", "[", "\"context\"", "]", "=", "keyword_sent_mapping", "[", "val", "]", "\n", "\n", "output_array", "[", "\"questions\"", "]", ".", "append", "(", "individual_quest", ")", "\n", "\n", "", "return", "output_array", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.mcq.mcq.random_choice": [[304, 307], ["random.choice", "bool"], "function", ["None"], ["", "def", "random_choice", "(", ")", ":", "\n", "    ", "a", "=", "random", ".", "choice", "(", "[", "0", ",", "1", "]", ")", "\n", "return", "bool", "(", "a", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.__init__": [[41, 47], ["pytorch_lightning.LightningModule.__init__", "transformers.T5ForConditionalGeneration.from_pretrained", "transformers.T5Tokenizer.from_pretrained"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.BooleanDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hparams", ")", ":", "\n", "        ", "super", "(", "T5FineTuner", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hparams", "=", "hparams", "\n", "\n", "self", ".", "model", "=", "T5ForConditionalGeneration", ".", "from_pretrained", "(", "hparams", ".", "model_name_or_path", ")", "\n", "self", ".", "tokenizer", "=", "T5Tokenizer", ".", "from_pretrained", "(", "hparams", ".", "tokenizer_name_or_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.is_logger": [[48, 50], ["None"], "methods", ["None"], ["", "def", "is_logger", "(", "self", ")", ":", "\n", "        ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.forward": [[51, 60], ["train_gpu.T5FineTuner.model"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "input_ids", ",", "attention_mask", "=", "None", ",", "decoder_input_ids", "=", "None", ",", "decoder_attention_mask", "=", "None", ",", "lm_labels", "=", "None", "\n", ")", ":", "\n", "        ", "return", "self", ".", "model", "(", "\n", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_attention_mask", "=", "decoder_attention_mask", ",", "\n", "lm_labels", "=", "lm_labels", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner._step": [[62, 76], ["train_gpu.T5FineTuner."], "methods", ["None"], ["", "def", "_step", "(", "self", ",", "batch", ")", ":", "\n", "        ", "lm_labels", "=", "batch", "[", "\"target_ids\"", "]", "\n", "lm_labels", "[", "lm_labels", "[", ":", ",", ":", "]", "==", "self", ".", "tokenizer", ".", "pad_token_id", "]", "=", "-", "100", "\n", "\n", "outputs", "=", "self", "(", "\n", "input_ids", "=", "batch", "[", "\"source_ids\"", "]", ",", "\n", "attention_mask", "=", "batch", "[", "\"source_mask\"", "]", ",", "\n", "lm_labels", "=", "lm_labels", ",", "\n", "decoder_attention_mask", "=", "batch", "[", "'target_mask'", "]", "\n", ")", "\n", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.training_step": [[77, 82], ["train_gpu.T5FineTuner._step"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner._step"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "_step", "(", "batch", ")", "\n", "\n", "tensorboard_logs", "=", "{", "\"train_loss\"", ":", "loss", "}", "\n", "return", "{", "\"loss\"", ":", "loss", ",", "\"log\"", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.training_epoch_end": [[83, 87], ["torch.stack().mean", "torch.stack"], "methods", ["None"], ["", "def", "training_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_train_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "tensorboard_logs", "=", "{", "\"avg_train_loss\"", ":", "avg_train_loss", "}", "\n", "return", "{", "\"avg_train_loss\"", ":", "avg_train_loss", ",", "\"log\"", ":", "tensorboard_logs", ",", "'progress_bar'", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.validation_step": [[88, 91], ["train_gpu.T5FineTuner._step"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner._step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "loss", "=", "self", ".", "_step", "(", "batch", ")", "\n", "return", "{", "\"val_loss\"", ":", "loss", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.validation_epoch_end": [[92, 96], ["torch.stack().mean", "torch.stack"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "\"val_loss\"", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", "\n", "tensorboard_logs", "=", "{", "\"val_loss\"", ":", "avg_loss", "}", "\n", "return", "{", "\"avg_val_loss\"", ":", "avg_loss", ",", "\"log\"", ":", "tensorboard_logs", ",", "'progress_bar'", ":", "tensorboard_logs", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.configure_optimizers": [[97, 115], ["transformers.AdamW", "model.named_parameters", "model.named_parameters", "any", "any"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "\"Prepare optimizer and schedule (linear warmup and decay)\"", "\n", "\n", "model", "=", "self", ".", "model", "\n", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "self", ".", "hparams", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "0.0", ",", "\n", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "self", ".", "hparams", ".", "learning_rate", ",", "eps", "=", "self", ".", "hparams", ".", "adam_epsilon", ")", "\n", "self", ".", "opt", "=", "optimizer", "\n", "return", "[", "optimizer", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.optimizer_step": [[116, 123], ["optimizer.zero_grad", "train_gpu.T5FineTuner.lr_scheduler.step", "xm.optimizer_step", "optimizer.step"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.optimizer_step"], ["", "def", "optimizer_step", "(", "self", ",", "epoch", ",", "batch_idx", ",", "optimizer", ",", "optimizer_idx", ",", "second_order_closure", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "trainer", ".", "use_tpu", ":", "\n", "            ", "xm", ".", "optimizer_step", "(", "optimizer", ")", "\n", "", "else", ":", "\n", "            ", "optimizer", ".", "step", "(", ")", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "lr_scheduler", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.get_tqdm_dict": [[124, 128], ["train_gpu.T5FineTuner.lr_scheduler.get_last_lr"], "methods", ["None"], ["", "def", "get_tqdm_dict", "(", "self", ")", ":", "\n", "        ", "tqdm_dict", "=", "{", "\"loss\"", ":", "\"{:.3f}\"", ".", "format", "(", "self", ".", "trainer", ".", "avg_loss", ")", ",", "\"lr\"", ":", "self", ".", "lr_scheduler", ".", "get_last_lr", "(", ")", "[", "-", "1", "]", "}", "\n", "\n", "return", "tqdm_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.train_dataloader": [[129, 143], ["train_gpu.get_dataset", "torch.utils.data.DataLoader", "transformers.get_linear_schedule_with_warmup", "float", "len", "max"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.get_dataset"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "train_dataset", "=", "get_dataset", "(", "tokenizer", "=", "self", ".", "tokenizer", ",", "type_path", "=", "\"boolq_train\"", ",", "args", "=", "self", ".", "hparams", ")", "\n", "dataloader", "=", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "self", ".", "hparams", ".", "train_batch_size", ",", "drop_last", "=", "True", ",", "shuffle", "=", "True", ",", "\n", "num_workers", "=", "4", ")", "\n", "t_total", "=", "(", "\n", "(", "len", "(", "dataloader", ".", "dataset", ")", "//", "(", "self", ".", "hparams", ".", "train_batch_size", "*", "max", "(", "1", ",", "self", ".", "hparams", ".", "n_gpu", ")", ")", ")", "\n", "//", "self", ".", "hparams", ".", "gradient_accumulation_steps", "\n", "*", "float", "(", "self", ".", "hparams", ".", "num_train_epochs", ")", "\n", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "self", ".", "opt", ",", "num_warmup_steps", "=", "self", ".", "hparams", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "self", ".", "lr_scheduler", "=", "scheduler", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.val_dataloader": [[144, 147], ["train_gpu.get_dataset", "torch.utils.data.DataLoader"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.get_dataset"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "val_dataset", "=", "get_dataset", "(", "tokenizer", "=", "self", ".", "tokenizer", ",", "type_path", "=", "\"boolq_val\"", ",", "args", "=", "self", ".", "hparams", ")", "\n", "return", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "self", ".", "hparams", ".", "eval_batch_size", ",", "num_workers", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.LoggingCallback.on_validation_end": [[151, 159], ["logger.info", "pl_module.is_logger", "sorted", "logger.info", "str"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.is_logger"], ["  ", "def", "on_validation_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"***** Validation results *****\"", ")", "\n", "if", "pl_module", ".", "is_logger", "(", ")", ":", "\n", "      ", "metrics", "=", "trainer", ".", "callback_metrics", "\n", "# Log results", "\n", "for", "key", "in", "sorted", "(", "metrics", ")", ":", "\n", "        ", "if", "key", "not", "in", "[", "\"log\"", ",", "\"progress_bar\"", "]", ":", "\n", "          ", "logger", ".", "info", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.LoggingCallback.on_test_end": [[160, 173], ["logger.info", "pl_module.is_logger", "os.path.join", "open", "sorted", "logger.info", "writer.write", "str", "str"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.T5FineTuner.is_logger"], ["", "", "", "", "def", "on_test_end", "(", "self", ",", "trainer", ",", "pl_module", ")", ":", "\n", "    ", "logger", ".", "info", "(", "\"***** Test results *****\"", ")", "\n", "\n", "if", "pl_module", ".", "is_logger", "(", ")", ":", "\n", "      ", "metrics", "=", "trainer", ".", "callback_metrics", "\n", "\n", "# Log and save results to file", "\n", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "pl_module", ".", "hparams", ".", "output_dir", ",", "\"test_results.txt\"", ")", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "for", "key", "in", "sorted", "(", "metrics", ")", ":", "\n", "          ", "if", "key", "not", "in", "[", "\"log\"", ",", "\"progress_bar\"", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "metrics", "[", "key", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.BooleanDataset.__init__": [[206, 221], ["os.path.join", "pandas.read_csv", "train_gpu.BooleanDataset._build"], "methods", ["home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.BooleanDataset._build"], ["    ", "def", "__init__", "(", "self", ",", "tokenizer", ",", "data_dir", ",", "type_path", ",", "max_len", "=", "256", ")", ":", "\n", "        ", "self", ".", "path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "type_path", "+", "'.csv'", ")", "\n", "\n", "self", ".", "passage_column", "=", "\"passage\"", "\n", "self", ".", "true_false", "=", "\"answer\"", "\n", "self", ".", "target_column", "=", "\"question\"", "\n", "self", ".", "title", "=", "\"title\"", "\n", "self", ".", "data", "=", "pd", ".", "read_csv", "(", "self", ".", "path", ")", "\n", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "inputs", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n", "self", ".", "_build", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.BooleanDataset.__len__": [[222, 224], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "inputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.BooleanDataset.__getitem__": [[225, 233], ["[].squeeze", "[].squeeze", "[].squeeze", "[].squeeze"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "source_ids", "=", "self", ".", "inputs", "[", "index", "]", "[", "\"input_ids\"", "]", ".", "squeeze", "(", ")", "\n", "target_ids", "=", "self", ".", "targets", "[", "index", "]", "[", "\"input_ids\"", "]", ".", "squeeze", "(", ")", "\n", "\n", "src_mask", "=", "self", ".", "inputs", "[", "index", "]", "[", "\"attention_mask\"", "]", ".", "squeeze", "(", ")", "# might need to squeeze", "\n", "target_mask", "=", "self", ".", "targets", "[", "index", "]", "[", "\"attention_mask\"", "]", ".", "squeeze", "(", ")", "# might need to squeeze", "\n", "\n", "return", "{", "\"source_ids\"", ":", "source_ids", ",", "\"source_mask\"", ":", "src_mask", ",", "\"target_ids\"", ":", "target_ids", ",", "\"target_mask\"", ":", "target_mask", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.BooleanDataset._build": [[234, 257], ["range", "len", "str", "train_gpu.BooleanDataset.tokenizer.batch_encode_plus", "train_gpu.BooleanDataset.tokenizer.batch_encode_plus", "train_gpu.BooleanDataset.inputs.append", "train_gpu.BooleanDataset.targets.append", "str.lower"], "methods", ["None"], ["", "def", "_build", "(", "self", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "len", "(", "self", ".", "data", ")", ")", ":", "\n", "            ", "passage", ",", "true_false", ",", "target", "=", "self", ".", "data", ".", "loc", "[", "idx", ",", "self", ".", "passage_column", "]", ",", "self", ".", "data", ".", "loc", "[", "idx", ",", "self", ".", "true_false", "]", ",", "self", ".", "data", ".", "loc", "[", "idx", ",", "self", ".", "target_column", "]", "\n", "true_false", "=", "str", "(", "true_false", ")", "\n", "if", "true_false", ".", "lower", "(", ")", "==", "\"true\"", ":", "\n", "                ", "true_false", "=", "\"yes\"", "\n", "", "else", ":", "\n", "                ", "true_false", "=", "\"no\"", "\n", "# input_ = \"paraphrase: \"+ input_ + ' </s>'", "\n", "", "input_", "=", "\"truefalse: %s passage: %s </s>\"", "%", "(", "true_false", ",", "passage", ")", "\n", "target", "=", "target", "+", "\" </s>\"", "\n", "\n", "# tokenize inputs", "\n", "tokenized_inputs", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "input_", "]", ",", "max_length", "=", "self", ".", "max_len", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", "\n", ")", "\n", "# tokenize targets", "\n", "tokenized_targets", "=", "self", ".", "tokenizer", ".", "batch_encode_plus", "(", "\n", "[", "target", "]", ",", "max_length", "=", "self", ".", "max_len", ",", "pad_to_max_length", "=", "True", ",", "return_tensors", "=", "\"pt\"", "\n", ")", "\n", "\n", "self", ".", "inputs", ".", "append", "(", "tokenized_inputs", ")", "\n", "self", ".", "targets", ".", "append", "(", "tokenized_targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.set_seed": [[30, 36], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "seed", ")", ":", "\n", "  ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "    ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.yilihsu_asktoknowmore.train.train_gpu.get_dataset": [[289, 291], ["train_gpu.BooleanDataset"], "function", ["None"], ["def", "get_dataset", "(", "tokenizer", ",", "type_path", ",", "args", ")", ":", "\n", "  ", "return", "BooleanDataset", "(", "tokenizer", "=", "tokenizer", ",", "data_dir", "=", "args", ".", "data_dir", ",", "type_path", "=", "type_path", ",", "max_len", "=", "args", ".", "max_seq_length", ")", "\n", "\n"]]}