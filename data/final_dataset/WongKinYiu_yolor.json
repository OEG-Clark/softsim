{"home.repos.pwc.inspect_result.WongKinYiu_yolor.None.train.train": [[44, 455], ["logger.info", "wdir.mkdir", "utils.general.init_seeds", "weights.endswith", "max", "dict().items", "optim.SGD.add_param_group", "optim.SGD.add_param_group", "logger.info", "torch.LambdaLR", "utils.datasets.create_dataloader", "[].max", "len", "utils.general.labels_to_class_weights().to", "time.time", "max", "numpy.zeros", "torch.cuda.amp.GradScaler", "logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "range", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "pathlib.Path", "open", "yaml.dump", "open", "yaml.dump", "open", "yaml.load", "utils.torch_utils.torch_distributed_zero_first", "utils.general.check_dataset", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "models.models.Darknet().to", "torch.nn.parallel.DistributedDataParallel.load_state_dict", "print", "models.models.Darknet().to", "round", "torch.Adam", "torch.SGD", "wandb.init", "utils.general.check_img_size", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "logger.info", "utils.torch_utils.ModelEMA", "torch.nn.parallel.DistributedDataParallel", "round", "torch.nn.parallel.DistributedDataParallel.train", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "logger.info", "optim.SGD.zero_grad", "lr_scheduler.LambdaLR.step", "zip", "logger.info", "torch.destroy_process_group", "wandb.run.finish", "vars", "int", "len", "utils.torch_utils.torch_distributed_zero_first", "models.models.attempt_download", "dict", "pg2.append", "optim.SGD.load_state_dict", "torch.load.get", "logger.info", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "utils.datasets.create_dataloader", "numpy.concatenate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils.general.labels_to_class_weights", "dataloader.sampler.set_epoch", "tqdm.tqdm", "amp.GradScaler.scale().backward", "zip", "utils.general.fitness", "utils.general.fitness_p", "utils.general.fitness_r", "utils.general.fitness_ap50", "utils.general.fitness_ap", "opt.name.isnumeric", "f1.exists", "utils.plots.plot_results", "models.models.Darknet", "ckpt[].items", "models.models.Darknet", "torch.nn.parallel.DistributedDataParallel.named_parameters", "pg1.append", "len", "len", "len", "open", "file.write", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "numpy.concatenate", "utils.plots.plot_labels", "utils.general.labels_to_image_weights", "random.choices", "torch.broadcast", "F.interpolate.to().float", "max", "enumerate", "torch.cuda.amp.autocast", "torch.nn.parallel.DistributedDataParallel", "utils.loss.compute_loss", "amp.GradScaler.step", "amp.GradScaler.update", "optim.SGD.zero_grad", "tqdm.tqdm.set_description", "ema.update_attr", "open", "f.write", "len", "os.system", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "utils.general.fitness_f", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.rename", "str().endswith", "wandb.log", "[].numel", "v.numel", "len", "len", "pg1.append", "torch.load.get", "tb_writer.add_histogram", "wandb.log", "torch.nn.parallel.DistributedDataParallel.class_weights.cpu().numpy", "range", "indices.cpu().numpy", "numpy.interp().round", "numpy.interp", "max", "torch.interpolate", "targets.to", "amp.GradScaler.scale", "ema.update", "utils.plots.plot_images", "test.test", "tb_writer.add_scalar", "wandb.log", "numpy.array().reshape", "open", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "utils.general.strip_optimizer", "torch.nn.parallel.DistributedDataParallel.state_dict", "pg1.append", "pg0.append", "math.cos", "pathlib.Path", "locals", "F.interpolate.to", "numpy.interp", "random.randrange", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "wandb.log", "list", "list", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "f.read", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "str", "os.system", "torch.nn.parallel.DistributedDataParallel.class_weights.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "indices.cpu", "numpy.interp", "math.ceil", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "numpy.array", "hasattr", "ema.ema.module.state_dict", "ema.ema.state_dict", "optim.SGD.state_dict", "wandb.Image", "time.time", "torch.nn.parallel.DistributedDataParallel.state_dict", "wandb.Image", "lf", "hasattr", "str", "str", "save_dir.glob", "wandb.Image", "str", "save_dir.glob"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.init_seeds", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_dataloader", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.torch_distributed_zero_first", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_dataset", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_img_size", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.tune.train", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.torch_distributed_zero_first", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.attempt_download", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_dataloader", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.labels_to_class_weights", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MishImplementation.backward", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_p", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_r", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_ap50", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_ap", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_results", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_labels", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.labels_to_image_weights", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.compute_loss", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.update", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.ModelEMA.update_attr", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_f", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.update", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_images", "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.test.test", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.strip_optimizer"], ["", "def", "train", "(", "hyp", ",", "opt", ",", "device", ",", "tb_writer", "=", "None", ",", "wandb", "=", "None", ")", ":", "\n", "    ", "logger", ".", "info", "(", "f'Hyperparameters {hyp}'", ")", "\n", "save_dir", ",", "epochs", ",", "batch_size", ",", "total_batch_size", ",", "weights", ",", "rank", "=", "Path", "(", "opt", ".", "save_dir", ")", ",", "opt", ".", "epochs", ",", "opt", ".", "batch_size", ",", "opt", ".", "total_batch_size", ",", "opt", ".", "weights", ",", "opt", ".", "global_rank", "\n", "\n", "# Directories", "\n", "wdir", "=", "save_dir", "/", "'weights'", "\n", "wdir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# make dir", "\n", "last", "=", "wdir", "/", "'last.pt'", "\n", "best", "=", "wdir", "/", "'best.pt'", "\n", "results_file", "=", "save_dir", "/", "'results.txt'", "\n", "\n", "# Save run settings", "\n", "with", "open", "(", "save_dir", "/", "'hyp.yaml'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "yaml", ".", "dump", "(", "hyp", ",", "f", ",", "sort_keys", "=", "False", ")", "\n", "", "with", "open", "(", "save_dir", "/", "'opt.yaml'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "yaml", ".", "dump", "(", "vars", "(", "opt", ")", ",", "f", ",", "sort_keys", "=", "False", ")", "\n", "\n", "# Configure", "\n", "", "plots", "=", "not", "opt", ".", "evolve", "# create plots", "\n", "cuda", "=", "device", ".", "type", "!=", "'cpu'", "\n", "init_seeds", "(", "2", "+", "rank", ")", "\n", "with", "open", "(", "opt", ".", "data", ")", "as", "f", ":", "\n", "        ", "data_dict", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "# data dict", "\n", "", "with", "torch_distributed_zero_first", "(", "rank", ")", ":", "\n", "        ", "check_dataset", "(", "data_dict", ")", "# check", "\n", "", "train_path", "=", "data_dict", "[", "'train'", "]", "\n", "test_path", "=", "data_dict", "[", "'val'", "]", "\n", "nc", ",", "names", "=", "(", "1", ",", "[", "'item'", "]", ")", "if", "opt", ".", "single_cls", "else", "(", "int", "(", "data_dict", "[", "'nc'", "]", ")", ",", "data_dict", "[", "'names'", "]", ")", "# number classes, names", "\n", "assert", "len", "(", "names", ")", "==", "nc", ",", "'%g names found for nc=%g dataset in %s'", "%", "(", "len", "(", "names", ")", ",", "nc", ",", "opt", ".", "data", ")", "# check", "\n", "\n", "# Model", "\n", "pretrained", "=", "weights", ".", "endswith", "(", "'.pt'", ")", "\n", "if", "pretrained", ":", "\n", "        ", "with", "torch_distributed_zero_first", "(", "rank", ")", ":", "\n", "            ", "attempt_download", "(", "weights", ")", "# download if not found locally", "\n", "", "ckpt", "=", "torch", ".", "load", "(", "weights", ",", "map_location", "=", "device", ")", "# load checkpoint", "\n", "model", "=", "Darknet", "(", "opt", ".", "cfg", ")", ".", "to", "(", "device", ")", "# create", "\n", "state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "ckpt", "[", "'model'", "]", ".", "items", "(", ")", "if", "model", ".", "state_dict", "(", ")", "[", "k", "]", ".", "numel", "(", ")", "==", "v", ".", "numel", "(", ")", "}", "\n", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "print", "(", "'Transferred %g/%g items from %s'", "%", "(", "len", "(", "state_dict", ")", ",", "len", "(", "model", ".", "state_dict", "(", ")", ")", ",", "weights", ")", ")", "# report", "\n", "", "else", ":", "\n", "        ", "model", "=", "Darknet", "(", "opt", ".", "cfg", ")", ".", "to", "(", "device", ")", "# create", "\n", "\n", "# Optimizer", "\n", "", "nbs", "=", "64", "# nominal batch size", "\n", "accumulate", "=", "max", "(", "round", "(", "nbs", "/", "total_batch_size", ")", ",", "1", ")", "# accumulate loss before optimizing", "\n", "hyp", "[", "'weight_decay'", "]", "*=", "total_batch_size", "*", "accumulate", "/", "nbs", "# scale weight_decay", "\n", "\n", "pg0", ",", "pg1", ",", "pg2", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# optimizer parameter groups", "\n", "for", "k", ",", "v", "in", "dict", "(", "model", ".", "named_parameters", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "        ", "if", "'.bias'", "in", "k", ":", "\n", "            ", "pg2", ".", "append", "(", "v", ")", "# biases", "\n", "", "elif", "'Conv2d.weight'", "in", "k", ":", "\n", "            ", "pg1", ".", "append", "(", "v", ")", "# apply weight_decay", "\n", "", "elif", "'m.weight'", "in", "k", ":", "\n", "            ", "pg1", ".", "append", "(", "v", ")", "# apply weight_decay", "\n", "", "elif", "'w.weight'", "in", "k", ":", "\n", "            ", "pg1", ".", "append", "(", "v", ")", "# apply weight_decay", "\n", "", "else", ":", "\n", "            ", "pg0", ".", "append", "(", "v", ")", "# all else", "\n", "\n", "", "", "if", "opt", ".", "adam", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "pg0", ",", "lr", "=", "hyp", "[", "'lr0'", "]", ",", "betas", "=", "(", "hyp", "[", "'momentum'", "]", ",", "0.999", ")", ")", "# adjust beta1 to momentum", "\n", "", "else", ":", "\n", "        ", "optimizer", "=", "optim", ".", "SGD", "(", "pg0", ",", "lr", "=", "hyp", "[", "'lr0'", "]", ",", "momentum", "=", "hyp", "[", "'momentum'", "]", ",", "nesterov", "=", "True", ")", "\n", "\n", "", "optimizer", ".", "add_param_group", "(", "{", "'params'", ":", "pg1", ",", "'weight_decay'", ":", "hyp", "[", "'weight_decay'", "]", "}", ")", "# add pg1 with weight_decay", "\n", "optimizer", ".", "add_param_group", "(", "{", "'params'", ":", "pg2", "}", ")", "# add pg2 (biases)", "\n", "logger", ".", "info", "(", "'Optimizer groups: %g .bias, %g conv.weight, %g other'", "%", "(", "len", "(", "pg2", ")", ",", "len", "(", "pg1", ")", ",", "len", "(", "pg0", ")", ")", ")", "\n", "del", "pg0", ",", "pg1", ",", "pg2", "\n", "\n", "# Scheduler https://arxiv.org/pdf/1812.01187.pdf", "\n", "# https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR", "\n", "lf", "=", "lambda", "x", ":", "(", "(", "1", "+", "math", ".", "cos", "(", "x", "*", "math", ".", "pi", "/", "epochs", ")", ")", "/", "2", ")", "*", "(", "1", "-", "hyp", "[", "'lrf'", "]", ")", "+", "hyp", "[", "'lrf'", "]", "# cosine", "\n", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lf", ")", "\n", "# plot_lr_scheduler(optimizer, scheduler, epochs)", "\n", "\n", "# Logging", "\n", "if", "wandb", "and", "wandb", ".", "run", "is", "None", ":", "\n", "        ", "opt", ".", "hyp", "=", "hyp", "# add hyperparameters", "\n", "wandb_run", "=", "wandb", ".", "init", "(", "config", "=", "opt", ",", "resume", "=", "\"allow\"", ",", "\n", "project", "=", "'YOLOR'", "if", "opt", ".", "project", "==", "'runs/train'", "else", "Path", "(", "opt", ".", "project", ")", ".", "stem", ",", "\n", "name", "=", "save_dir", ".", "stem", ",", "\n", "id", "=", "ckpt", ".", "get", "(", "'wandb_id'", ")", "if", "'ckpt'", "in", "locals", "(", ")", "else", "None", ")", "\n", "\n", "# Resume", "\n", "", "start_epoch", ",", "best_fitness", "=", "0", ",", "0.0", "\n", "best_fitness_p", ",", "best_fitness_r", ",", "best_fitness_ap50", ",", "best_fitness_ap", ",", "best_fitness_f", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "\n", "if", "pretrained", ":", "\n", "# Optimizer", "\n", "        ", "if", "ckpt", "[", "'optimizer'", "]", "is", "not", "None", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer'", "]", ")", "\n", "best_fitness", "=", "ckpt", "[", "'best_fitness'", "]", "\n", "best_fitness_p", "=", "ckpt", "[", "'best_fitness_p'", "]", "\n", "best_fitness_r", "=", "ckpt", "[", "'best_fitness_r'", "]", "\n", "best_fitness_ap50", "=", "ckpt", "[", "'best_fitness_ap50'", "]", "\n", "best_fitness_ap", "=", "ckpt", "[", "'best_fitness_ap'", "]", "\n", "best_fitness_f", "=", "ckpt", "[", "'best_fitness_f'", "]", "\n", "\n", "# Results", "\n", "", "if", "ckpt", ".", "get", "(", "'training_results'", ")", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "results_file", ",", "'w'", ")", "as", "file", ":", "\n", "                ", "file", ".", "write", "(", "ckpt", "[", "'training_results'", "]", ")", "# write results.txt", "\n", "\n", "# Epochs", "\n", "", "", "start_epoch", "=", "ckpt", "[", "'epoch'", "]", "+", "1", "\n", "if", "opt", ".", "resume", ":", "\n", "            ", "assert", "start_epoch", ">", "0", ",", "'%s training to %g epochs is finished, nothing to resume.'", "%", "(", "weights", ",", "epochs", ")", "\n", "", "if", "epochs", "<", "start_epoch", ":", "\n", "            ", "logger", ".", "info", "(", "'%s has been trained for %g epochs. Fine-tuning for %g additional epochs.'", "%", "\n", "(", "weights", ",", "ckpt", "[", "'epoch'", "]", ",", "epochs", ")", ")", "\n", "epochs", "+=", "ckpt", "[", "'epoch'", "]", "# finetune additional epochs", "\n", "\n", "", "del", "ckpt", ",", "state_dict", "\n", "\n", "# Image sizes", "\n", "", "gs", "=", "64", "#int(max(model.stride))  # grid size (max stride)", "\n", "imgsz", ",", "imgsz_test", "=", "[", "check_img_size", "(", "x", ",", "gs", ")", "for", "x", "in", "opt", ".", "img_size", "]", "# verify imgsz are gs-multiples", "\n", "\n", "# DP mode", "\n", "if", "cuda", "and", "rank", "==", "-", "1", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# SyncBatchNorm", "\n", "", "if", "opt", ".", "sync_bn", "and", "cuda", "and", "rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "SyncBatchNorm", ".", "convert_sync_batchnorm", "(", "model", ")", ".", "to", "(", "device", ")", "\n", "logger", ".", "info", "(", "'Using SyncBatchNorm()'", ")", "\n", "\n", "# EMA", "\n", "", "ema", "=", "ModelEMA", "(", "model", ")", "if", "rank", "in", "[", "-", "1", ",", "0", "]", "else", "None", "\n", "\n", "# DDP mode", "\n", "if", "cuda", "and", "rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "DDP", "(", "model", ",", "device_ids", "=", "[", "opt", ".", "local_rank", "]", ",", "output_device", "=", "opt", ".", "local_rank", ")", "\n", "\n", "# Trainloader", "\n", "", "dataloader", ",", "dataset", "=", "create_dataloader", "(", "train_path", ",", "imgsz", ",", "batch_size", ",", "gs", ",", "opt", ",", "\n", "hyp", "=", "hyp", ",", "augment", "=", "True", ",", "cache", "=", "opt", ".", "cache_images", ",", "rect", "=", "opt", ".", "rect", ",", "\n", "rank", "=", "rank", ",", "world_size", "=", "opt", ".", "world_size", ",", "workers", "=", "opt", ".", "workers", ")", "\n", "mlc", "=", "np", ".", "concatenate", "(", "dataset", ".", "labels", ",", "0", ")", "[", ":", ",", "0", "]", ".", "max", "(", ")", "# max label class", "\n", "nb", "=", "len", "(", "dataloader", ")", "# number of batches", "\n", "assert", "mlc", "<", "nc", ",", "'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g'", "%", "(", "mlc", ",", "nc", ",", "opt", ".", "data", ",", "nc", "-", "1", ")", "\n", "\n", "# Process 0", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "ema", ".", "updates", "=", "start_epoch", "*", "nb", "//", "accumulate", "# set EMA updates", "\n", "testloader", "=", "create_dataloader", "(", "test_path", ",", "imgsz_test", ",", "batch_size", "*", "2", ",", "gs", ",", "opt", ",", "\n", "hyp", "=", "hyp", ",", "cache", "=", "opt", ".", "cache_images", "and", "not", "opt", ".", "notest", ",", "rect", "=", "True", ",", "\n", "rank", "=", "-", "1", ",", "world_size", "=", "opt", ".", "world_size", ",", "workers", "=", "opt", ".", "workers", ")", "[", "0", "]", "# testloader", "\n", "\n", "if", "not", "opt", ".", "resume", ":", "\n", "            ", "labels", "=", "np", ".", "concatenate", "(", "dataset", ".", "labels", ",", "0", ")", "\n", "c", "=", "torch", ".", "tensor", "(", "labels", "[", ":", ",", "0", "]", ")", "# classes", "\n", "# cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency", "\n", "# model._initialize_biases(cf.to(device))", "\n", "if", "plots", ":", "\n", "                ", "plot_labels", "(", "labels", ",", "save_dir", "=", "save_dir", ")", "\n", "if", "tb_writer", ":", "\n", "                    ", "tb_writer", ".", "add_histogram", "(", "'classes'", ",", "c", ",", "0", ")", "\n", "", "if", "wandb", ":", "\n", "                    ", "wandb", ".", "log", "(", "{", "\"Labels\"", ":", "[", "wandb", ".", "Image", "(", "str", "(", "x", ")", ",", "caption", "=", "x", ".", "name", ")", "for", "x", "in", "save_dir", ".", "glob", "(", "'*labels*.png'", ")", "]", "}", ")", "\n", "\n", "# Anchors", "\n", "# if not opt.noautoanchor:", "\n", "#     check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)", "\n", "\n", "# Model parameters", "\n", "", "", "", "", "hyp", "[", "'cls'", "]", "*=", "nc", "/", "80.", "# scale coco-tuned hyp['cls'] to current dataset", "\n", "model", ".", "nc", "=", "nc", "# attach number of classes to model", "\n", "model", ".", "hyp", "=", "hyp", "# attach hyperparameters to model", "\n", "model", ".", "gr", "=", "1.0", "# iou loss ratio (obj_loss = 1.0 or iou)", "\n", "model", ".", "class_weights", "=", "labels_to_class_weights", "(", "dataset", ".", "labels", ",", "nc", ")", ".", "to", "(", "device", ")", "# attach class weights", "\n", "model", ".", "names", "=", "names", "\n", "\n", "# Start training", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "nw", "=", "max", "(", "round", "(", "hyp", "[", "'warmup_epochs'", "]", "*", "nb", ")", ",", "1000", ")", "# number of warmup iterations, max(3 epochs, 1k iterations)", "\n", "# nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to < 1/2 of training", "\n", "maps", "=", "np", ".", "zeros", "(", "nc", ")", "# mAP per class", "\n", "results", "=", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ")", "# P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)", "\n", "scheduler", ".", "last_epoch", "=", "start_epoch", "-", "1", "# do not move", "\n", "scaler", "=", "amp", ".", "GradScaler", "(", "enabled", "=", "cuda", ")", "\n", "logger", ".", "info", "(", "'Image sizes %g train, %g test\\n'", "\n", "'Using %g dataloader workers\\nLogging results to %s\\n'", "\n", "'Starting training for %g epochs...'", "%", "(", "imgsz", ",", "imgsz_test", ",", "dataloader", ".", "num_workers", ",", "save_dir", ",", "epochs", ")", ")", "\n", "\n", "torch", ".", "save", "(", "model", ",", "wdir", "/", "'init.pt'", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "epochs", ")", ":", "# epoch ------------------------------------------------------------------", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "# Update image weights (optional)", "\n", "if", "opt", ".", "image_weights", ":", "\n", "# Generate indices", "\n", "            ", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "cw", "=", "model", ".", "class_weights", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "*", "(", "1", "-", "maps", ")", "**", "2", "# class weights", "\n", "iw", "=", "labels_to_image_weights", "(", "dataset", ".", "labels", ",", "nc", "=", "nc", ",", "class_weights", "=", "cw", ")", "# image weights", "\n", "dataset", ".", "indices", "=", "random", ".", "choices", "(", "range", "(", "dataset", ".", "n", ")", ",", "weights", "=", "iw", ",", "k", "=", "dataset", ".", "n", ")", "# rand weighted idx", "\n", "# Broadcast if DDP", "\n", "", "if", "rank", "!=", "-", "1", ":", "\n", "                ", "indices", "=", "(", "torch", ".", "tensor", "(", "dataset", ".", "indices", ")", "if", "rank", "==", "0", "else", "torch", ".", "zeros", "(", "dataset", ".", "n", ")", ")", ".", "int", "(", ")", "\n", "dist", ".", "broadcast", "(", "indices", ",", "0", ")", "\n", "if", "rank", "!=", "0", ":", "\n", "                    ", "dataset", ".", "indices", "=", "indices", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Update mosaic border", "\n", "# b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)", "\n", "# dataset.mosaic_border = [b - imgsz, -b]  # height, width borders", "\n", "\n", "", "", "", "mloss", "=", "torch", ".", "zeros", "(", "4", ",", "device", "=", "device", ")", "# mean losses", "\n", "if", "rank", "!=", "-", "1", ":", "\n", "            ", "dataloader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "pbar", "=", "enumerate", "(", "dataloader", ")", "\n", "logger", ".", "info", "(", "(", "'\\n'", "+", "'%10s'", "*", "8", ")", "%", "(", "'Epoch'", ",", "'gpu_mem'", ",", "'box'", ",", "'obj'", ",", "'cls'", ",", "'total'", ",", "'targets'", ",", "'img_size'", ")", ")", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "pbar", "=", "tqdm", "(", "pbar", ",", "total", "=", "nb", ")", "# progress bar", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "i", ",", "(", "imgs", ",", "targets", ",", "paths", ",", "_", ")", "in", "pbar", ":", "# batch -------------------------------------------------------------", "\n", "            ", "ni", "=", "i", "+", "nb", "*", "epoch", "# number integrated batches (since train start)", "\n", "imgs", "=", "imgs", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", ".", "float", "(", ")", "/", "255.0", "# uint8 to float32, 0-255 to 0.0-1.0", "\n", "\n", "# Warmup", "\n", "if", "ni", "<=", "nw", ":", "\n", "                ", "xi", "=", "[", "0", ",", "nw", "]", "# x interp", "\n", "# model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)", "\n", "accumulate", "=", "max", "(", "1", ",", "np", ".", "interp", "(", "ni", ",", "xi", ",", "[", "1", ",", "nbs", "/", "total_batch_size", "]", ")", ".", "round", "(", ")", ")", "\n", "for", "j", ",", "x", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "# bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0", "\n", "                    ", "x", "[", "'lr'", "]", "=", "np", ".", "interp", "(", "ni", ",", "xi", ",", "[", "hyp", "[", "'warmup_bias_lr'", "]", "if", "j", "==", "2", "else", "0.0", ",", "x", "[", "'initial_lr'", "]", "*", "lf", "(", "epoch", ")", "]", ")", "\n", "if", "'momentum'", "in", "x", ":", "\n", "                        ", "x", "[", "'momentum'", "]", "=", "np", ".", "interp", "(", "ni", ",", "xi", ",", "[", "hyp", "[", "'warmup_momentum'", "]", ",", "hyp", "[", "'momentum'", "]", "]", ")", "\n", "\n", "# Multi-scale", "\n", "", "", "", "if", "opt", ".", "multi_scale", ":", "\n", "                ", "sz", "=", "random", ".", "randrange", "(", "imgsz", "*", "0.5", ",", "imgsz", "*", "1.5", "+", "gs", ")", "//", "gs", "*", "gs", "# size", "\n", "sf", "=", "sz", "/", "max", "(", "imgs", ".", "shape", "[", "2", ":", "]", ")", "# scale factor", "\n", "if", "sf", "!=", "1", ":", "\n", "                    ", "ns", "=", "[", "math", ".", "ceil", "(", "x", "*", "sf", "/", "gs", ")", "*", "gs", "for", "x", "in", "imgs", ".", "shape", "[", "2", ":", "]", "]", "# new shape (stretched to gs-multiple)", "\n", "imgs", "=", "F", ".", "interpolate", "(", "imgs", ",", "size", "=", "ns", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "\n", "# Forward", "\n", "", "", "with", "amp", ".", "autocast", "(", "enabled", "=", "cuda", ")", ":", "\n", "                ", "pred", "=", "model", "(", "imgs", ")", "# forward", "\n", "loss", ",", "loss_items", "=", "compute_loss", "(", "pred", ",", "targets", ".", "to", "(", "device", ")", ",", "model", ")", "# loss scaled by batch_size", "\n", "if", "rank", "!=", "-", "1", ":", "\n", "                    ", "loss", "*=", "opt", ".", "world_size", "# gradient averaged between devices in DDP mode", "\n", "\n", "# Backward", "\n", "", "", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "# Optimize", "\n", "if", "ni", "%", "accumulate", "==", "0", ":", "\n", "                ", "scaler", ".", "step", "(", "optimizer", ")", "# optimizer.step", "\n", "scaler", ".", "update", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "ema", ":", "\n", "                    ", "ema", ".", "update", "(", "model", ")", "\n", "\n", "# Print", "\n", "", "", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "mloss", "=", "(", "mloss", "*", "i", "+", "loss_items", ")", "/", "(", "i", "+", "1", ")", "# update mean losses", "\n", "mem", "=", "'%.3gG'", "%", "(", "torch", ".", "cuda", ".", "memory_reserved", "(", ")", "/", "1E9", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "0", ")", "# (GB)", "\n", "s", "=", "(", "'%10s'", "*", "2", "+", "'%10.4g'", "*", "6", ")", "%", "(", "\n", "'%g/%g'", "%", "(", "epoch", ",", "epochs", "-", "1", ")", ",", "mem", ",", "*", "mloss", ",", "targets", ".", "shape", "[", "0", "]", ",", "imgs", ".", "shape", "[", "-", "1", "]", ")", "\n", "pbar", ".", "set_description", "(", "s", ")", "\n", "\n", "# Plot", "\n", "if", "plots", "and", "ni", "<", "3", ":", "\n", "                    ", "f", "=", "save_dir", "/", "f'train_batch{ni}.jpg'", "# filename", "\n", "plot_images", "(", "images", "=", "imgs", ",", "targets", "=", "targets", ",", "paths", "=", "paths", ",", "fname", "=", "f", ")", "\n", "# if tb_writer:", "\n", "#     tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)", "\n", "#     tb_writer.add_graph(model, imgs)  # add model to tensorboard", "\n", "", "elif", "plots", "and", "ni", "==", "3", "and", "wandb", ":", "\n", "                    ", "wandb", ".", "log", "(", "{", "\"Mosaics\"", ":", "[", "wandb", ".", "Image", "(", "str", "(", "x", ")", ",", "caption", "=", "x", ".", "name", ")", "for", "x", "in", "save_dir", ".", "glob", "(", "'train*.jpg'", ")", "]", "}", ")", "\n", "\n", "# end batch ------------------------------------------------------------------------------------------------", "\n", "# end epoch ----------------------------------------------------------------------------------------------------", "\n", "\n", "# Scheduler", "\n", "", "", "", "lr", "=", "[", "x", "[", "'lr'", "]", "for", "x", "in", "optimizer", ".", "param_groups", "]", "# for tensorboard", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# DDP process 0 or single-GPU", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# mAP", "\n", "            ", "if", "ema", ":", "\n", "                ", "ema", ".", "update_attr", "(", "model", ")", "\n", "", "final_epoch", "=", "epoch", "+", "1", "==", "epochs", "\n", "if", "not", "opt", ".", "notest", "or", "final_epoch", ":", "# Calculate mAP", "\n", "                ", "if", "epoch", ">=", "3", ":", "\n", "                    ", "results", ",", "maps", ",", "times", "=", "test", ".", "test", "(", "opt", ".", "data", ",", "\n", "batch_size", "=", "batch_size", "*", "2", ",", "\n", "imgsz", "=", "imgsz_test", ",", "\n", "model", "=", "ema", ".", "ema", ".", "module", "if", "hasattr", "(", "ema", ".", "ema", ",", "'module'", ")", "else", "ema", ".", "ema", ",", "\n", "single_cls", "=", "opt", ".", "single_cls", ",", "\n", "dataloader", "=", "testloader", ",", "\n", "save_dir", "=", "save_dir", ",", "\n", "plots", "=", "plots", "and", "final_epoch", ",", "\n", "log_imgs", "=", "opt", ".", "log_imgs", "if", "wandb", "else", "0", ")", "\n", "\n", "# Write", "\n", "", "", "with", "open", "(", "results_file", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "s", "+", "'%10.4g'", "*", "7", "%", "results", "+", "'\\n'", ")", "# P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)", "\n", "", "if", "len", "(", "opt", ".", "name", ")", "and", "opt", ".", "bucket", ":", "\n", "                ", "os", ".", "system", "(", "'gsutil cp %s gs://%s/results/results%s.txt'", "%", "(", "results_file", ",", "opt", ".", "bucket", ",", "opt", ".", "name", ")", ")", "\n", "\n", "# Log", "\n", "", "tags", "=", "[", "'train/box_loss'", ",", "'train/obj_loss'", ",", "'train/cls_loss'", ",", "# train loss", "\n", "'metrics/precision'", ",", "'metrics/recall'", ",", "'metrics/mAP_0.5'", ",", "'metrics/mAP_0.5:0.95'", ",", "\n", "'val/box_loss'", ",", "'val/obj_loss'", ",", "'val/cls_loss'", ",", "# val loss", "\n", "'x/lr0'", ",", "'x/lr1'", ",", "'x/lr2'", "]", "# params", "\n", "for", "x", ",", "tag", "in", "zip", "(", "list", "(", "mloss", "[", ":", "-", "1", "]", ")", "+", "list", "(", "results", ")", "+", "lr", ",", "tags", ")", ":", "\n", "                ", "if", "tb_writer", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "tag", ",", "x", ",", "epoch", ")", "# tensorboard", "\n", "", "if", "wandb", ":", "\n", "                    ", "wandb", ".", "log", "(", "{", "tag", ":", "x", "}", ")", "# W&B", "\n", "\n", "# Update best mAP", "\n", "", "", "fi", "=", "fitness", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_p", "=", "fitness_p", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_r", "=", "fitness_r", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_ap50", "=", "fitness_ap50", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_ap", "=", "fitness_ap", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "if", "(", "fi_p", ">", "0.0", ")", "or", "(", "fi_r", ">", "0.0", ")", ":", "\n", "                ", "fi_f", "=", "fitness_f", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "", "else", ":", "\n", "                ", "fi_f", "=", "0.0", "\n", "", "if", "fi", ">", "best_fitness", ":", "\n", "                ", "best_fitness", "=", "fi", "\n", "", "if", "fi_p", ">", "best_fitness_p", ":", "\n", "                ", "best_fitness_p", "=", "fi_p", "\n", "", "if", "fi_r", ">", "best_fitness_r", ":", "\n", "                ", "best_fitness_r", "=", "fi_r", "\n", "", "if", "fi_ap50", ">", "best_fitness_ap50", ":", "\n", "                ", "best_fitness_ap50", "=", "fi_ap50", "\n", "", "if", "fi_ap", ">", "best_fitness_ap", ":", "\n", "                ", "best_fitness_ap", "=", "fi_ap", "\n", "", "if", "fi_f", ">", "best_fitness_f", ":", "\n", "                ", "best_fitness_f", "=", "fi_f", "\n", "\n", "# Save model", "\n", "", "save", "=", "(", "not", "opt", ".", "nosave", ")", "or", "(", "final_epoch", "and", "not", "opt", ".", "evolve", ")", "\n", "if", "save", ":", "\n", "                ", "with", "open", "(", "results_file", ",", "'r'", ")", "as", "f", ":", "# create checkpoint", "\n", "                    ", "ckpt", "=", "{", "'epoch'", ":", "epoch", ",", "\n", "'best_fitness'", ":", "best_fitness", ",", "\n", "'best_fitness_p'", ":", "best_fitness_p", ",", "\n", "'best_fitness_r'", ":", "best_fitness_r", ",", "\n", "'best_fitness_ap50'", ":", "best_fitness_ap50", ",", "\n", "'best_fitness_ap'", ":", "best_fitness_ap", ",", "\n", "'best_fitness_f'", ":", "best_fitness_f", ",", "\n", "'training_results'", ":", "f", ".", "read", "(", ")", ",", "\n", "'model'", ":", "ema", ".", "ema", ".", "module", ".", "state_dict", "(", ")", "if", "hasattr", "(", "ema", ",", "'module'", ")", "else", "ema", ".", "ema", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "None", "if", "final_epoch", "else", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'wandb_id'", ":", "wandb_run", ".", "id", "if", "wandb", "else", "None", "}", "\n", "\n", "# Save last, best and delete", "\n", "", "torch", ".", "save", "(", "ckpt", ",", "last", ")", "\n", "if", "best_fitness", "==", "fi", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "best", ")", "\n", "", "if", "(", "best_fitness", "==", "fi", ")", "and", "(", "epoch", ">=", "200", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "if", "best_fitness", "==", "fi", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_overall.pt'", ")", "\n", "", "if", "best_fitness_p", "==", "fi_p", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_p.pt'", ")", "\n", "", "if", "best_fitness_r", "==", "fi_r", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_r.pt'", ")", "\n", "", "if", "best_fitness_ap50", "==", "fi_ap50", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_ap50.pt'", ")", "\n", "", "if", "best_fitness_ap", "==", "fi_ap", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_ap.pt'", ")", "\n", "", "if", "best_fitness_f", "==", "fi_f", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_f.pt'", ")", "\n", "", "if", "epoch", "==", "0", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'epoch_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "if", "(", "(", "epoch", "+", "1", ")", "%", "25", ")", "==", "0", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'epoch_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "if", "epoch", ">=", "(", "epochs", "-", "5", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'last_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "elif", "epoch", ">=", "420", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'last_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "del", "ckpt", "\n", "# end epoch ----------------------------------------------------------------------------------------------------", "\n", "# end training", "\n", "\n", "", "", "", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# Strip optimizers", "\n", "        ", "n", "=", "opt", ".", "name", "if", "opt", ".", "name", ".", "isnumeric", "(", ")", "else", "''", "\n", "fresults", ",", "flast", ",", "fbest", "=", "save_dir", "/", "f'results{n}.txt'", ",", "wdir", "/", "f'last{n}.pt'", ",", "wdir", "/", "f'best{n}.pt'", "\n", "for", "f1", ",", "f2", "in", "zip", "(", "[", "wdir", "/", "'last.pt'", ",", "wdir", "/", "'best.pt'", ",", "results_file", "]", ",", "[", "flast", ",", "fbest", ",", "fresults", "]", ")", ":", "\n", "            ", "if", "f1", ".", "exists", "(", ")", ":", "\n", "                ", "os", ".", "rename", "(", "f1", ",", "f2", ")", "# rename", "\n", "if", "str", "(", "f2", ")", ".", "endswith", "(", "'.pt'", ")", ":", "# is *.pt", "\n", "                    ", "strip_optimizer", "(", "f2", ")", "# strip optimizer", "\n", "os", ".", "system", "(", "'gsutil cp %s gs://%s/weights'", "%", "(", "f2", ",", "opt", ".", "bucket", ")", ")", "if", "opt", ".", "bucket", "else", "None", "# upload", "\n", "# Finish", "\n", "", "", "", "if", "plots", ":", "\n", "            ", "plot_results", "(", "save_dir", "=", "save_dir", ")", "# save as results.png", "\n", "if", "wandb", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "\"Results\"", ":", "[", "wandb", ".", "Image", "(", "str", "(", "save_dir", "/", "x", ")", ",", "caption", "=", "x", ")", "for", "x", "in", "\n", "[", "'results.png'", ",", "'precision-recall_curve.png'", "]", "]", "}", ")", "\n", "", "", "logger", ".", "info", "(", "'%g epochs completed in %.3f hours.\\n'", "%", "(", "epoch", "-", "start_epoch", "+", "1", ",", "(", "time", ".", "time", "(", ")", "-", "t0", ")", "/", "3600", ")", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "destroy_process_group", "(", ")", "\n", "\n", "", "wandb", ".", "run", ".", "finish", "(", ")", "if", "wandb", "and", "wandb", ".", "run", "else", "None", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.test.load_classes": [[23, 28], ["list", "open", "f.read().split", "filter", "f.read"], "function", ["None"], ["def", "load_classes", "(", "path", ")", ":", "\n", "# Loads *.names file at 'path'", "\n", "    ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "names", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "return", "list", "(", "filter", "(", "None", ",", "names", ")", ")", "# filter removes empty strings (such as last line)", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.test.test": [[30, 290], ["pathlib.Path", "Darknet().to.eval", "yaml.load.endswith", "utils.general.check_dataset", "torch.linspace().to", "torch.linspace().to.numel", "utils.general.coco80_to_coco91_class", "torch.zeros", "enumerate", "print", "Darknet().to.float", "enumerate", "utils.general.set_logging", "utils.torch_utils.select_device", "pathlib.Path", "models.models.Darknet().to", "utils.general.check_img_size", "Darknet().to.half", "open", "yaml.load", "int", "min", "torch.zeros", "tqdm.tqdm", "img.to.to", "targets.to.to", "torch.Tensor().to", "enumerate", "numpy.concatenate", "len", "stats[].any", "utils.metrics.ap_per_class", "numpy.bincount", "torch.zeros", "wandb.log", "wandb.log", "len", "enumerate", "tuple", "print", "len", "str", "print", "print", "numpy.zeros", "next", "utils.general.increment_path", "torch.load", "Darknet().to.load_state_dict", "torch.linspace", "Darknet().to.", "utils.datasets.create_dataloader", "hasattr", "test.load_classes", "img.to.half", "img.to.float", "torch.no_grad", "utils.torch_utils.time_synchronized", "Darknet().to.", "utils.torch_utils.time_synchronized", "utils.general.non_max_suppression", "len", "pathlib.Path", "utils.general.clip_coords", "torch.zeros", "stats.append", "utils.plots.plot_images", "utils.plots.plot_images", "zip", "ap.mean", "p.mean", "r.mean", "ap50.mean", "ap.mean", "stats[].astype", "print", "glob.glob", "open", "json.dump", "COCO", "COCO.loadRes", "COCOeval", "COCOeval.evaluate", "COCOeval.accumulate", "COCOeval.summarize", "Darknet().to.parameters", "models.models.Darknet", "models.models.load_darknet_weights", "torch.Tensor", "utils.torch_utils.time_synchronized", "utils.torch_utils.time_synchronized", "labels[].tolist", "len", "anno.loadRes.clone", "utils.general.scale_coords", "wandb_images.append", "pred[].clone", "utils.general.scale_coords", "utils.general.xyxy2xywh", "zip", "torch.unique", "utils.plots.output_to_target", "torch.zeros.sum", "pathlib.Path", "print", "pathlib.Path", "ckpt[].items", "img.to.half", "stats.append", "torch.tensor", "len", "wandb.Image", "pathlib.Path.stem.isnumeric", "int", "anno.loadRes.tolist", "utils.general.xyxy2xywh.tolist", "jdict.append", "utils.general.xywh2xyxy", "torch.zeros.cpu", "pred[].cpu", "pred[].cpu", "wandb.Image", "int", "[].numel", "v.numel", "utils.loss.compute_loss", "open", "f.write", "int", "anno.loadRes.tolist", "utils.general.box_iou().max", "set", "str", "sorted", "isinstance", "torch.zeros", "torch.Tensor", "torch.Tensor", "round", "pathlib.Path.glob", "pathlib.Path", "torch.zeros.cpu", "len", "pred.clone.float", "int", "round", "utils.general.box_iou", "d.item", "set.add", "detected.append", "Darknet().to.state_dict", "d.item", "len", "utils.general.xyxy2xywh", "int", "torch.tensor().view", "len", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_dataset", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.coco80_to_coco91_class", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.set_logging", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.select_device", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_img_size", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.ap_per_class", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.increment_path", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_dataloader", "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.detect.load_classes", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.time_synchronized", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.time_synchronized", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.non_max_suppression", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.clip_coords", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_images", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_images", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.load_darknet_weights", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.time_synchronized", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.time_synchronized", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.scale_coords", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.scale_coords", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.output_to_target", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xywh2xyxy", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.compute_loss", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.box_iou", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh"], ["", "def", "test", "(", "data", ",", "\n", "weights", "=", "None", ",", "\n", "batch_size", "=", "16", ",", "\n", "imgsz", "=", "640", ",", "\n", "conf_thres", "=", "0.001", ",", "\n", "iou_thres", "=", "0.6", ",", "# for NMS", "\n", "save_json", "=", "False", ",", "\n", "single_cls", "=", "False", ",", "\n", "augment", "=", "False", ",", "\n", "verbose", "=", "False", ",", "\n", "model", "=", "None", ",", "\n", "dataloader", "=", "None", ",", "\n", "save_dir", "=", "Path", "(", "''", ")", ",", "# for saving images", "\n", "save_txt", "=", "False", ",", "# for auto-labelling", "\n", "save_conf", "=", "False", ",", "\n", "plots", "=", "True", ",", "\n", "log_imgs", "=", "0", ")", ":", "# number of logged images", "\n", "\n", "# Initialize/load model and set device", "\n", "    ", "training", "=", "model", "is", "not", "None", "\n", "if", "training", ":", "# called by train.py", "\n", "        ", "device", "=", "next", "(", "model", ".", "parameters", "(", ")", ")", ".", "device", "# get model device", "\n", "\n", "", "else", ":", "# called directly", "\n", "        ", "set_logging", "(", ")", "\n", "device", "=", "select_device", "(", "opt", ".", "device", ",", "batch_size", "=", "batch_size", ")", "\n", "save_txt", "=", "opt", ".", "save_txt", "# save *.txt labels", "\n", "\n", "# Directories", "\n", "save_dir", "=", "Path", "(", "increment_path", "(", "Path", "(", "opt", ".", "project", ")", "/", "opt", ".", "name", ",", "exist_ok", "=", "opt", ".", "exist_ok", ")", ")", "# increment run", "\n", "(", "save_dir", "/", "'labels'", "if", "save_txt", "else", "save_dir", ")", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# make dir", "\n", "\n", "# Load model", "\n", "model", "=", "Darknet", "(", "opt", ".", "cfg", ")", ".", "to", "(", "device", ")", "\n", "\n", "# load model", "\n", "try", ":", "\n", "            ", "ckpt", "=", "torch", ".", "load", "(", "weights", "[", "0", "]", ",", "map_location", "=", "device", ")", "# load checkpoint", "\n", "ckpt", "[", "'model'", "]", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "ckpt", "[", "'model'", "]", ".", "items", "(", ")", "if", "model", ".", "state_dict", "(", ")", "[", "k", "]", ".", "numel", "(", ")", "==", "v", ".", "numel", "(", ")", "}", "\n", "model", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "", "except", ":", "\n", "            ", "load_darknet_weights", "(", "model", ",", "weights", "[", "0", "]", ")", "\n", "", "imgsz", "=", "check_img_size", "(", "imgsz", ",", "s", "=", "64", ")", "# check img_size", "\n", "\n", "# Half", "\n", "", "half", "=", "device", ".", "type", "!=", "'cpu'", "# half precision only supported on CUDA", "\n", "if", "half", ":", "\n", "        ", "model", ".", "half", "(", ")", "\n", "\n", "# Configure", "\n", "", "model", ".", "eval", "(", ")", "\n", "is_coco", "=", "data", ".", "endswith", "(", "'coco.yaml'", ")", "# is COCO dataset", "\n", "with", "open", "(", "data", ")", "as", "f", ":", "\n", "        ", "data", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "# model dict", "\n", "", "check_dataset", "(", "data", ")", "# check", "\n", "nc", "=", "1", "if", "single_cls", "else", "int", "(", "data", "[", "'nc'", "]", ")", "# number of classes", "\n", "iouv", "=", "torch", ".", "linspace", "(", "0.5", ",", "0.95", ",", "10", ")", ".", "to", "(", "device", ")", "# iou vector for mAP@0.5:0.95", "\n", "niou", "=", "iouv", ".", "numel", "(", ")", "\n", "\n", "# Logging", "\n", "log_imgs", ",", "wandb", "=", "min", "(", "log_imgs", ",", "100", ")", ",", "None", "# ceil", "\n", "try", ":", "\n", "        ", "import", "wandb", "# Weights & Biases", "\n", "", "except", "ImportError", ":", "\n", "        ", "log_imgs", "=", "0", "\n", "\n", "# Dataloader", "\n", "", "if", "not", "training", ":", "\n", "        ", "img", "=", "torch", ".", "zeros", "(", "(", "1", ",", "3", ",", "imgsz", ",", "imgsz", ")", ",", "device", "=", "device", ")", "# init img", "\n", "_", "=", "model", "(", "img", ".", "half", "(", ")", "if", "half", "else", "img", ")", "if", "device", ".", "type", "!=", "'cpu'", "else", "None", "# run once", "\n", "path", "=", "data", "[", "'test'", "]", "if", "opt", ".", "task", "==", "'test'", "else", "data", "[", "'val'", "]", "# path to val/test images", "\n", "dataloader", "=", "create_dataloader", "(", "path", ",", "imgsz", ",", "batch_size", ",", "64", ",", "opt", ",", "pad", "=", "0.5", ",", "rect", "=", "True", ")", "[", "0", "]", "\n", "\n", "", "seen", "=", "0", "\n", "try", ":", "\n", "        ", "names", "=", "model", ".", "names", "if", "hasattr", "(", "model", ",", "'names'", ")", "else", "model", ".", "module", ".", "names", "\n", "", "except", ":", "\n", "        ", "names", "=", "load_classes", "(", "opt", ".", "names", ")", "\n", "", "coco91class", "=", "coco80_to_coco91_class", "(", ")", "\n", "s", "=", "(", "'%20s'", "+", "'%12s'", "*", "6", ")", "%", "(", "'Class'", ",", "'Images'", ",", "'Targets'", ",", "'P'", ",", "'R'", ",", "'mAP@.5'", ",", "'mAP@.5:.95'", ")", "\n", "p", ",", "r", ",", "f1", ",", "mp", ",", "mr", ",", "map50", ",", "map", ",", "t0", ",", "t1", "=", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", ",", "0.", "\n", "loss", "=", "torch", ".", "zeros", "(", "3", ",", "device", "=", "device", ")", "\n", "jdict", ",", "stats", ",", "ap", ",", "ap_class", ",", "wandb_images", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "for", "batch_i", ",", "(", "img", ",", "targets", ",", "paths", ",", "shapes", ")", "in", "enumerate", "(", "tqdm", "(", "dataloader", ",", "desc", "=", "s", ")", ")", ":", "\n", "        ", "img", "=", "img", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", "\n", "img", "=", "img", ".", "half", "(", ")", "if", "half", "else", "img", ".", "float", "(", ")", "# uint8 to fp16/32", "\n", "img", "/=", "255.0", "# 0 - 255 to 0.0 - 1.0", "\n", "targets", "=", "targets", ".", "to", "(", "device", ")", "\n", "nb", ",", "_", ",", "height", ",", "width", "=", "img", ".", "shape", "# batch size, channels, height, width", "\n", "whwh", "=", "torch", ".", "Tensor", "(", "[", "width", ",", "height", ",", "width", ",", "height", "]", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Disable gradients", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Run model", "\n", "            ", "t", "=", "time_synchronized", "(", ")", "\n", "inf_out", ",", "train_out", "=", "model", "(", "img", ",", "augment", "=", "augment", ")", "# inference and training outputs", "\n", "t0", "+=", "time_synchronized", "(", ")", "-", "t", "\n", "\n", "# Compute loss", "\n", "if", "training", ":", "# if model has loss hyperparameters", "\n", "                ", "loss", "+=", "compute_loss", "(", "[", "x", ".", "float", "(", ")", "for", "x", "in", "train_out", "]", ",", "targets", ",", "model", ")", "[", "1", "]", "[", ":", "3", "]", "# box, obj, cls", "\n", "\n", "# Run NMS", "\n", "", "t", "=", "time_synchronized", "(", ")", "\n", "output", "=", "non_max_suppression", "(", "inf_out", ",", "conf_thres", "=", "conf_thres", ",", "iou_thres", "=", "iou_thres", ")", "\n", "t1", "+=", "time_synchronized", "(", ")", "-", "t", "\n", "\n", "# Statistics per image", "\n", "", "for", "si", ",", "pred", "in", "enumerate", "(", "output", ")", ":", "\n", "            ", "labels", "=", "targets", "[", "targets", "[", ":", ",", "0", "]", "==", "si", ",", "1", ":", "]", "\n", "nl", "=", "len", "(", "labels", ")", "\n", "tcls", "=", "labels", "[", ":", ",", "0", "]", ".", "tolist", "(", ")", "if", "nl", "else", "[", "]", "# target class", "\n", "seen", "+=", "1", "\n", "\n", "if", "len", "(", "pred", ")", "==", "0", ":", "\n", "                ", "if", "nl", ":", "\n", "                    ", "stats", ".", "append", "(", "(", "torch", ".", "zeros", "(", "0", ",", "niou", ",", "dtype", "=", "torch", ".", "bool", ")", ",", "torch", ".", "Tensor", "(", ")", ",", "torch", ".", "Tensor", "(", ")", ",", "tcls", ")", ")", "\n", "", "continue", "\n", "\n", "# Append to text file", "\n", "", "path", "=", "Path", "(", "paths", "[", "si", "]", ")", "\n", "if", "save_txt", ":", "\n", "                ", "gn", "=", "torch", ".", "tensor", "(", "shapes", "[", "si", "]", "[", "0", "]", ")", "[", "[", "1", ",", "0", ",", "1", ",", "0", "]", "]", "# normalization gain whwh", "\n", "x", "=", "pred", ".", "clone", "(", ")", "\n", "x", "[", ":", ",", ":", "4", "]", "=", "scale_coords", "(", "img", "[", "si", "]", ".", "shape", "[", "1", ":", "]", ",", "x", "[", ":", ",", ":", "4", "]", ",", "shapes", "[", "si", "]", "[", "0", "]", ",", "shapes", "[", "si", "]", "[", "1", "]", ")", "# to original", "\n", "for", "*", "xyxy", ",", "conf", ",", "cls", "in", "x", ":", "\n", "                    ", "xywh", "=", "(", "xyxy2xywh", "(", "torch", ".", "tensor", "(", "xyxy", ")", ".", "view", "(", "1", ",", "4", ")", ")", "/", "gn", ")", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "# normalized xywh", "\n", "line", "=", "(", "cls", ",", "*", "xywh", ",", "conf", ")", "if", "save_conf", "else", "(", "cls", ",", "*", "xywh", ")", "# label format", "\n", "with", "open", "(", "save_dir", "/", "'labels'", "/", "(", "path", ".", "stem", "+", "'.txt'", ")", ",", "'a'", ")", "as", "f", ":", "\n", "                        ", "f", ".", "write", "(", "(", "'%g '", "*", "len", "(", "line", ")", ")", ".", "rstrip", "(", ")", "%", "line", "+", "'\\n'", ")", "\n", "\n", "# W&B logging", "\n", "", "", "", "if", "plots", "and", "len", "(", "wandb_images", ")", "<", "log_imgs", ":", "\n", "                ", "box_data", "=", "[", "{", "\"position\"", ":", "{", "\"minX\"", ":", "xyxy", "[", "0", "]", ",", "\"minY\"", ":", "xyxy", "[", "1", "]", ",", "\"maxX\"", ":", "xyxy", "[", "2", "]", ",", "\"maxY\"", ":", "xyxy", "[", "3", "]", "}", ",", "\n", "\"class_id\"", ":", "int", "(", "cls", ")", ",", "\n", "\"box_caption\"", ":", "\"%s %.3f\"", "%", "(", "names", "[", "cls", "]", ",", "conf", ")", ",", "\n", "\"scores\"", ":", "{", "\"class_score\"", ":", "conf", "}", ",", "\n", "\"domain\"", ":", "\"pixel\"", "}", "for", "*", "xyxy", ",", "conf", ",", "cls", "in", "pred", ".", "tolist", "(", ")", "]", "\n", "boxes", "=", "{", "\"predictions\"", ":", "{", "\"box_data\"", ":", "box_data", ",", "\"class_labels\"", ":", "names", "}", "}", "\n", "wandb_images", ".", "append", "(", "wandb", ".", "Image", "(", "img", "[", "si", "]", ",", "boxes", "=", "boxes", ",", "caption", "=", "path", ".", "name", ")", ")", "\n", "\n", "# Clip boxes to image bounds", "\n", "", "clip_coords", "(", "pred", ",", "(", "height", ",", "width", ")", ")", "\n", "\n", "# Append to pycocotools JSON dictionary", "\n", "if", "save_json", ":", "\n", "# [{\"image_id\": 42, \"category_id\": 18, \"bbox\": [258.15, 41.29, 348.26, 243.78], \"score\": 0.236}, ...", "\n", "                ", "image_id", "=", "int", "(", "path", ".", "stem", ")", "if", "path", ".", "stem", ".", "isnumeric", "(", ")", "else", "path", ".", "stem", "\n", "box", "=", "pred", "[", ":", ",", ":", "4", "]", ".", "clone", "(", ")", "# xyxy", "\n", "scale_coords", "(", "img", "[", "si", "]", ".", "shape", "[", "1", ":", "]", ",", "box", ",", "shapes", "[", "si", "]", "[", "0", "]", ",", "shapes", "[", "si", "]", "[", "1", "]", ")", "# to original shape", "\n", "box", "=", "xyxy2xywh", "(", "box", ")", "# xywh", "\n", "box", "[", ":", ",", ":", "2", "]", "-=", "box", "[", ":", ",", "2", ":", "]", "/", "2", "# xy center to top-left corner", "\n", "for", "p", ",", "b", "in", "zip", "(", "pred", ".", "tolist", "(", ")", ",", "box", ".", "tolist", "(", ")", ")", ":", "\n", "                    ", "jdict", ".", "append", "(", "{", "'image_id'", ":", "image_id", ",", "\n", "'category_id'", ":", "coco91class", "[", "int", "(", "p", "[", "5", "]", ")", "]", "if", "is_coco", "else", "int", "(", "p", "[", "5", "]", ")", ",", "\n", "'bbox'", ":", "[", "round", "(", "x", ",", "3", ")", "for", "x", "in", "b", "]", ",", "\n", "'score'", ":", "round", "(", "p", "[", "4", "]", ",", "5", ")", "}", ")", "\n", "\n", "# Assign all predictions as incorrect", "\n", "", "", "correct", "=", "torch", ".", "zeros", "(", "pred", ".", "shape", "[", "0", "]", ",", "niou", ",", "dtype", "=", "torch", ".", "bool", ",", "device", "=", "device", ")", "\n", "if", "nl", ":", "\n", "                ", "detected", "=", "[", "]", "# target indices", "\n", "tcls_tensor", "=", "labels", "[", ":", ",", "0", "]", "\n", "\n", "# target boxes", "\n", "tbox", "=", "xywh2xyxy", "(", "labels", "[", ":", ",", "1", ":", "5", "]", ")", "*", "whwh", "\n", "\n", "# Per target class", "\n", "for", "cls", "in", "torch", ".", "unique", "(", "tcls_tensor", ")", ":", "\n", "                    ", "ti", "=", "(", "cls", "==", "tcls_tensor", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "view", "(", "-", "1", ")", "# prediction indices", "\n", "pi", "=", "(", "cls", "==", "pred", "[", ":", ",", "5", "]", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "view", "(", "-", "1", ")", "# target indices", "\n", "\n", "# Search for detections", "\n", "if", "pi", ".", "shape", "[", "0", "]", ":", "\n", "# Prediction to target ious", "\n", "                        ", "ious", ",", "i", "=", "box_iou", "(", "pred", "[", "pi", ",", ":", "4", "]", ",", "tbox", "[", "ti", "]", ")", ".", "max", "(", "1", ")", "# best ious, indices", "\n", "\n", "# Append detections", "\n", "detected_set", "=", "set", "(", ")", "\n", "for", "j", "in", "(", "ious", ">", "iouv", "[", "0", "]", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ":", "\n", "                            ", "d", "=", "ti", "[", "i", "[", "j", "]", "]", "# detected target", "\n", "if", "d", ".", "item", "(", ")", "not", "in", "detected_set", ":", "\n", "                                ", "detected_set", ".", "add", "(", "d", ".", "item", "(", ")", ")", "\n", "detected", ".", "append", "(", "d", ")", "\n", "correct", "[", "pi", "[", "j", "]", "]", "=", "ious", "[", "j", "]", ">", "iouv", "# iou_thres is 1xn", "\n", "if", "len", "(", "detected", ")", "==", "nl", ":", "# all targets already located in image", "\n", "                                    ", "break", "\n", "\n", "# Append statistics (correct, conf, pcls, tcls)", "\n", "", "", "", "", "", "", "stats", ".", "append", "(", "(", "correct", ".", "cpu", "(", ")", ",", "pred", "[", ":", ",", "4", "]", ".", "cpu", "(", ")", ",", "pred", "[", ":", ",", "5", "]", ".", "cpu", "(", ")", ",", "tcls", ")", ")", "\n", "\n", "# Plot images", "\n", "", "if", "plots", "and", "batch_i", "<", "3", ":", "\n", "            ", "f", "=", "save_dir", "/", "f'test_batch{batch_i}_labels.jpg'", "# filename", "\n", "plot_images", "(", "img", ",", "targets", ",", "paths", ",", "f", ",", "names", ")", "# labels", "\n", "f", "=", "save_dir", "/", "f'test_batch{batch_i}_pred.jpg'", "\n", "plot_images", "(", "img", ",", "output_to_target", "(", "output", ",", "width", ",", "height", ")", ",", "paths", ",", "f", ",", "names", ")", "# predictions", "\n", "\n", "# Compute statistics", "\n", "", "", "stats", "=", "[", "np", ".", "concatenate", "(", "x", ",", "0", ")", "for", "x", "in", "zip", "(", "*", "stats", ")", "]", "# to numpy", "\n", "if", "len", "(", "stats", ")", "and", "stats", "[", "0", "]", ".", "any", "(", ")", ":", "\n", "        ", "p", ",", "r", ",", "ap", ",", "f1", ",", "ap_class", "=", "ap_per_class", "(", "*", "stats", ",", "plot", "=", "plots", ",", "fname", "=", "save_dir", "/", "'precision-recall_curve.png'", ")", "\n", "p", ",", "r", ",", "ap50", ",", "ap", "=", "p", "[", ":", ",", "0", "]", ",", "r", "[", ":", ",", "0", "]", ",", "ap", "[", ":", ",", "0", "]", ",", "ap", ".", "mean", "(", "1", ")", "# [P, R, AP@0.5, AP@0.5:0.95]", "\n", "mp", ",", "mr", ",", "map50", ",", "map", "=", "p", ".", "mean", "(", ")", ",", "r", ".", "mean", "(", ")", ",", "ap50", ".", "mean", "(", ")", ",", "ap", ".", "mean", "(", ")", "\n", "nt", "=", "np", ".", "bincount", "(", "stats", "[", "3", "]", ".", "astype", "(", "np", ".", "int64", ")", ",", "minlength", "=", "nc", ")", "# number of targets per class", "\n", "", "else", ":", "\n", "        ", "nt", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "# W&B logging", "\n", "", "if", "plots", "and", "wandb", ":", "\n", "        ", "wandb", ".", "log", "(", "{", "\"Images\"", ":", "wandb_images", "}", ")", "\n", "wandb", ".", "log", "(", "{", "\"Validation\"", ":", "[", "wandb", ".", "Image", "(", "str", "(", "x", ")", ",", "caption", "=", "x", ".", "name", ")", "for", "x", "in", "sorted", "(", "save_dir", ".", "glob", "(", "'test*.jpg'", ")", ")", "]", "}", ")", "\n", "\n", "# Print results", "\n", "", "pf", "=", "'%20s'", "+", "'%12.3g'", "*", "6", "# print format", "\n", "print", "(", "pf", "%", "(", "'all'", ",", "seen", ",", "nt", ".", "sum", "(", ")", ",", "mp", ",", "mr", ",", "map50", ",", "map", ")", ")", "\n", "\n", "# Print results per class", "\n", "if", "verbose", "and", "nc", ">", "1", "and", "len", "(", "stats", ")", ":", "\n", "        ", "for", "i", ",", "c", "in", "enumerate", "(", "ap_class", ")", ":", "\n", "            ", "print", "(", "pf", "%", "(", "names", "[", "c", "]", ",", "seen", ",", "nt", "[", "c", "]", ",", "p", "[", "i", "]", ",", "r", "[", "i", "]", ",", "ap50", "[", "i", "]", ",", "ap", "[", "i", "]", ")", ")", "\n", "\n", "# Print speeds", "\n", "", "", "t", "=", "tuple", "(", "x", "/", "seen", "*", "1E3", "for", "x", "in", "(", "t0", ",", "t1", ",", "t0", "+", "t1", ")", ")", "+", "(", "imgsz", ",", "imgsz", ",", "batch_size", ")", "# tuple", "\n", "if", "not", "training", ":", "\n", "        ", "print", "(", "'Speed: %.1f/%.1f/%.1f ms inference/NMS/total per %gx%g image at batch-size %g'", "%", "t", ")", "\n", "\n", "# Save JSON", "\n", "", "if", "save_json", "and", "len", "(", "jdict", ")", ":", "\n", "        ", "w", "=", "Path", "(", "weights", "[", "0", "]", "if", "isinstance", "(", "weights", ",", "list", ")", "else", "weights", ")", ".", "stem", "if", "weights", "is", "not", "None", "else", "''", "# weights", "\n", "anno_json", "=", "glob", ".", "glob", "(", "'../coco/annotations/instances_val*.json'", ")", "[", "0", "]", "# annotations json", "\n", "pred_json", "=", "str", "(", "save_dir", "/", "f\"{w}_predictions.json\"", ")", "# predictions json", "\n", "print", "(", "'\\nEvaluating pycocotools mAP... saving %s...'", "%", "pred_json", ")", "\n", "with", "open", "(", "pred_json", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "jdict", ",", "f", ")", "\n", "\n", "", "try", ":", "# https://github.com/cocodataset/cocoapi/blob/master/PythonAPI/pycocoEvalDemo.ipynb", "\n", "            ", "from", "pycocotools", ".", "coco", "import", "COCO", "\n", "from", "pycocotools", ".", "cocoeval", "import", "COCOeval", "\n", "\n", "anno", "=", "COCO", "(", "anno_json", ")", "# init annotations api", "\n", "pred", "=", "anno", ".", "loadRes", "(", "pred_json", ")", "# init predictions api", "\n", "eval", "=", "COCOeval", "(", "anno", ",", "pred", ",", "'bbox'", ")", "\n", "if", "is_coco", ":", "\n", "                ", "eval", ".", "params", ".", "imgIds", "=", "[", "int", "(", "Path", "(", "x", ")", ".", "stem", ")", "for", "x", "in", "dataloader", ".", "dataset", ".", "img_files", "]", "# image IDs to evaluate", "\n", "", "eval", ".", "evaluate", "(", ")", "\n", "eval", ".", "accumulate", "(", ")", "\n", "eval", ".", "summarize", "(", ")", "\n", "map", ",", "map50", "=", "eval", ".", "stats", "[", ":", "2", "]", "# update results (mAP@0.5:0.95, mAP@0.5)", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'ERROR: pycocotools unable to run: %s'", "%", "e", ")", "\n", "\n", "# Return results", "\n", "", "", "if", "not", "training", ":", "\n", "        ", "print", "(", "'Results saved to %s'", "%", "save_dir", ")", "\n", "", "model", ".", "float", "(", ")", "# for training", "\n", "maps", "=", "np", ".", "zeros", "(", "nc", ")", "+", "map", "\n", "for", "i", ",", "c", "in", "enumerate", "(", "ap_class", ")", ":", "\n", "        ", "maps", "[", "c", "]", "=", "ap", "[", "i", "]", "\n", "", "return", "(", "mp", ",", "mr", ",", "map50", ",", "map", ",", "*", "(", "loss", ".", "cpu", "(", ")", "/", "len", "(", "dataloader", ")", ")", ".", "tolist", "(", ")", ")", ",", "maps", ",", "t", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.detect.load_classes": [[24, 29], ["list", "open", "f.read().split", "filter", "f.read"], "function", ["None"], ["def", "load_classes", "(", "path", ")", ":", "\n", "# Loads *.names file at 'path'", "\n", "    ", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "names", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "return", "list", "(", "filter", "(", "None", ",", "names", ")", ")", "# filter removes empty strings (such as last line)", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.detect.detect": [[30, 158], ["utils.torch_utils.select_device", "os.path.exists", "os.makedirs", "models.models.Darknet().cuda", "Darknet().cuda.load_state_dict", "Darknet().cuda.to().eval", "detect.load_classes", "time.time", "torch.zeros", "torch.zeros", "print", "source.startswith", "source.startswith", "source.endswith", "shutil.rmtree", "Darknet().cuda.half", "utils.torch_utils.load_classifier", "utils.torch_utils.load_classifier.load_state_dict", "utils.torch_utils.load_classifier.to().eval", "utils.datasets.LoadStreams", "utils.datasets.LoadImages", "Darknet().cuda.", "torch.from_numpy().to", "torch.from_numpy().to", "utils.torch_utils.time_synchronized", "utils.general.non_max_suppression", "utils.torch_utils.time_synchronized", "enumerate", "print", "models.models.Darknet", "torch.load", "torch.load", "Darknet().cuda.to", "numpy.random.randint", "range", "img.unsqueeze.half", "img.unsqueeze.float", "img.unsqueeze.ndimension", "img.unsqueeze.unsqueeze", "Darknet().cuda.", "utils.general.apply_classifier", "str", "print", "os.system", "torch.load", "torch.load", "utils.torch_utils.load_classifier.to", "range", "len", "img.unsqueeze.half", "torch.from_numpy", "torch.from_numpy", "str", "torch.tensor", "torch.tensor", "len", "utils.general.scale_coords().round", "det[].unique", "cv2.imshow", "pathlib.Path", "time.time", "im0s[].copy", "pathlib.Path", "cv2.waitKey", "ord", "cv2.imwrite", "cv2.VideoWriter.write", "pathlib.Path", "pathlib.Path", "utils.general.scale_coords", "utils.plots.plot_one_box", "isinstance", "vid_cap.get", "int", "int", "cv2.VideoWriter", "pathlib.Path", "open", "f.write", "cv2.VideoWriter.release", "vid_cap.get", "vid_cap.get", "cv2.VideoWriter_fourcc", "int", "int", "int", "utils.general.xyxy2xywh", "torch.tensor().view", "torch.tensor().view", "torch.tensor", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.select_device", "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.detect.load_classes", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.load_classifier", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.time_synchronized", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.non_max_suppression", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.time_synchronized", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.apply_classifier", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.scale_coords", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_one_box", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh"], ["", "def", "detect", "(", "save_img", "=", "False", ")", ":", "\n", "    ", "out", ",", "source", ",", "weights", ",", "view_img", ",", "save_txt", ",", "imgsz", ",", "cfg", ",", "names", "=", "opt", ".", "output", ",", "opt", ".", "source", ",", "opt", ".", "weights", ",", "opt", ".", "view_img", ",", "opt", ".", "save_txt", ",", "opt", ".", "img_size", ",", "opt", ".", "cfg", ",", "opt", ".", "names", "\n", "webcam", "=", "source", "==", "'0'", "or", "source", ".", "startswith", "(", "'rtsp'", ")", "or", "source", ".", "startswith", "(", "'http'", ")", "or", "source", ".", "endswith", "(", "'.txt'", ")", "\n", "\n", "# Initialize", "\n", "device", "=", "select_device", "(", "opt", ".", "device", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "out", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "out", ")", "# delete output folder", "\n", "", "os", ".", "makedirs", "(", "out", ")", "# make new output folder", "\n", "half", "=", "device", ".", "type", "!=", "'cpu'", "# half precision only supported on CUDA", "\n", "\n", "# Load model", "\n", "model", "=", "Darknet", "(", "cfg", ",", "imgsz", ")", ".", "cuda", "(", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "weights", "[", "0", "]", ",", "map_location", "=", "device", ")", "[", "'model'", "]", ")", "\n", "#model = attempt_load(weights, map_location=device)  # load FP32 model", "\n", "#imgsz = check_img_size(imgsz, s=model.stride.max())  # check img_size", "\n", "model", ".", "to", "(", "device", ")", ".", "eval", "(", ")", "\n", "if", "half", ":", "\n", "        ", "model", ".", "half", "(", ")", "# to FP16", "\n", "\n", "# Second-stage classifier", "\n", "", "classify", "=", "False", "\n", "if", "classify", ":", "\n", "        ", "modelc", "=", "load_classifier", "(", "name", "=", "'resnet101'", ",", "n", "=", "2", ")", "# initialize", "\n", "modelc", ".", "load_state_dict", "(", "torch", ".", "load", "(", "'weights/resnet101.pt'", ",", "map_location", "=", "device", ")", "[", "'model'", "]", ")", "# load weights", "\n", "modelc", ".", "to", "(", "device", ")", ".", "eval", "(", ")", "\n", "\n", "# Set Dataloader", "\n", "", "vid_path", ",", "vid_writer", "=", "None", ",", "None", "\n", "if", "webcam", ":", "\n", "        ", "view_img", "=", "True", "\n", "cudnn", ".", "benchmark", "=", "True", "# set True to speed up constant image size inference", "\n", "dataset", "=", "LoadStreams", "(", "source", ",", "img_size", "=", "imgsz", ")", "\n", "", "else", ":", "\n", "        ", "save_img", "=", "True", "\n", "dataset", "=", "LoadImages", "(", "source", ",", "img_size", "=", "imgsz", ",", "auto_size", "=", "64", ")", "\n", "\n", "# Get names and colors", "\n", "", "names", "=", "load_classes", "(", "names", ")", "\n", "colors", "=", "[", "[", "random", ".", "randint", "(", "0", ",", "255", ")", "for", "_", "in", "range", "(", "3", ")", "]", "for", "_", "in", "range", "(", "len", "(", "names", ")", ")", "]", "\n", "\n", "# Run inference", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "img", "=", "torch", ".", "zeros", "(", "(", "1", ",", "3", ",", "imgsz", ",", "imgsz", ")", ",", "device", "=", "device", ")", "# init img", "\n", "_", "=", "model", "(", "img", ".", "half", "(", ")", "if", "half", "else", "img", ")", "if", "device", ".", "type", "!=", "'cpu'", "else", "None", "# run once", "\n", "for", "path", ",", "img", ",", "im0s", ",", "vid_cap", "in", "dataset", ":", "\n", "        ", "img", "=", "torch", ".", "from_numpy", "(", "img", ")", ".", "to", "(", "device", ")", "\n", "img", "=", "img", ".", "half", "(", ")", "if", "half", "else", "img", ".", "float", "(", ")", "# uint8 to fp16/32", "\n", "img", "/=", "255.0", "# 0 - 255 to 0.0 - 1.0", "\n", "if", "img", ".", "ndimension", "(", ")", "==", "3", ":", "\n", "            ", "img", "=", "img", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# Inference", "\n", "", "t1", "=", "time_synchronized", "(", ")", "\n", "pred", "=", "model", "(", "img", ",", "augment", "=", "opt", ".", "augment", ")", "[", "0", "]", "\n", "\n", "# Apply NMS", "\n", "pred", "=", "non_max_suppression", "(", "pred", ",", "opt", ".", "conf_thres", ",", "opt", ".", "iou_thres", ",", "classes", "=", "opt", ".", "classes", ",", "agnostic", "=", "opt", ".", "agnostic_nms", ")", "\n", "t2", "=", "time_synchronized", "(", ")", "\n", "\n", "# Apply Classifier", "\n", "if", "classify", ":", "\n", "            ", "pred", "=", "apply_classifier", "(", "pred", ",", "modelc", ",", "img", ",", "im0s", ")", "\n", "\n", "# Process detections", "\n", "", "for", "i", ",", "det", "in", "enumerate", "(", "pred", ")", ":", "# detections per image", "\n", "            ", "if", "webcam", ":", "# batch_size >= 1", "\n", "                ", "p", ",", "s", ",", "im0", "=", "path", "[", "i", "]", ",", "'%g: '", "%", "i", ",", "im0s", "[", "i", "]", ".", "copy", "(", ")", "\n", "", "else", ":", "\n", "                ", "p", ",", "s", ",", "im0", "=", "path", ",", "''", ",", "im0s", "\n", "\n", "", "save_path", "=", "str", "(", "Path", "(", "out", ")", "/", "Path", "(", "p", ")", ".", "name", ")", "\n", "txt_path", "=", "str", "(", "Path", "(", "out", ")", "/", "Path", "(", "p", ")", ".", "stem", ")", "+", "(", "'_%g'", "%", "dataset", ".", "frame", "if", "dataset", ".", "mode", "==", "'video'", "else", "''", ")", "\n", "s", "+=", "'%gx%g '", "%", "img", ".", "shape", "[", "2", ":", "]", "# print string", "\n", "gn", "=", "torch", ".", "tensor", "(", "im0", ".", "shape", ")", "[", "[", "1", ",", "0", ",", "1", ",", "0", "]", "]", "# normalization gain whwh", "\n", "if", "det", "is", "not", "None", "and", "len", "(", "det", ")", ":", "\n", "# Rescale boxes from img_size to im0 size", "\n", "                ", "det", "[", ":", ",", ":", "4", "]", "=", "scale_coords", "(", "img", ".", "shape", "[", "2", ":", "]", ",", "det", "[", ":", ",", ":", "4", "]", ",", "im0", ".", "shape", ")", ".", "round", "(", ")", "\n", "\n", "# Print results", "\n", "for", "c", "in", "det", "[", ":", ",", "-", "1", "]", ".", "unique", "(", ")", ":", "\n", "                    ", "n", "=", "(", "det", "[", ":", ",", "-", "1", "]", "==", "c", ")", ".", "sum", "(", ")", "# detections per class", "\n", "s", "+=", "'%g %ss, '", "%", "(", "n", ",", "names", "[", "int", "(", "c", ")", "]", ")", "# add to string", "\n", "\n", "# Write results", "\n", "", "for", "*", "xyxy", ",", "conf", ",", "cls", "in", "det", ":", "\n", "                    ", "if", "save_txt", ":", "# Write to file", "\n", "                        ", "xywh", "=", "(", "xyxy2xywh", "(", "torch", ".", "tensor", "(", "xyxy", ")", ".", "view", "(", "1", ",", "4", ")", ")", "/", "gn", ")", ".", "view", "(", "-", "1", ")", ".", "tolist", "(", ")", "# normalized xywh", "\n", "with", "open", "(", "txt_path", "+", "'.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "                            ", "f", ".", "write", "(", "(", "'%g '", "*", "5", "+", "'\\n'", ")", "%", "(", "cls", ",", "*", "xywh", ")", ")", "# label format", "\n", "\n", "", "", "if", "save_img", "or", "view_img", ":", "# Add bbox to image", "\n", "                        ", "label", "=", "'%s %.2f'", "%", "(", "names", "[", "int", "(", "cls", ")", "]", ",", "conf", ")", "\n", "plot_one_box", "(", "xyxy", ",", "im0", ",", "label", "=", "label", ",", "color", "=", "colors", "[", "int", "(", "cls", ")", "]", ",", "line_thickness", "=", "3", ")", "\n", "\n", "# Print time (inference + NMS)", "\n", "", "", "", "print", "(", "'%sDone. (%.3fs)'", "%", "(", "s", ",", "t2", "-", "t1", ")", ")", "\n", "\n", "# Stream results", "\n", "if", "view_img", ":", "\n", "                ", "cv2", ".", "imshow", "(", "p", ",", "im0", ")", "\n", "if", "cv2", ".", "waitKey", "(", "1", ")", "==", "ord", "(", "'q'", ")", ":", "# q to quit", "\n", "                    ", "raise", "StopIteration", "\n", "\n", "# Save results (image with detections)", "\n", "", "", "if", "save_img", ":", "\n", "                ", "if", "dataset", ".", "mode", "==", "'images'", ":", "\n", "                    ", "cv2", ".", "imwrite", "(", "save_path", ",", "im0", ")", "\n", "", "else", ":", "\n", "                    ", "if", "vid_path", "!=", "save_path", ":", "# new video", "\n", "                        ", "vid_path", "=", "save_path", "\n", "if", "isinstance", "(", "vid_writer", ",", "cv2", ".", "VideoWriter", ")", ":", "\n", "                            ", "vid_writer", ".", "release", "(", ")", "# release previous video writer", "\n", "\n", "", "fourcc", "=", "'mp4v'", "# output video codec", "\n", "fps", "=", "vid_cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "\n", "w", "=", "int", "(", "vid_cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "h", "=", "int", "(", "vid_cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "vid_writer", "=", "cv2", ".", "VideoWriter", "(", "save_path", ",", "cv2", ".", "VideoWriter_fourcc", "(", "*", "fourcc", ")", ",", "fps", ",", "(", "w", ",", "h", ")", ")", "\n", "", "vid_writer", ".", "write", "(", "im0", ")", "\n", "\n", "", "", "", "", "if", "save_txt", "or", "save_img", ":", "\n", "        ", "print", "(", "'Results saved to %s'", "%", "Path", "(", "out", ")", ")", "\n", "if", "platform", "==", "'darwin'", "and", "not", "opt", ".", "update", ":", "# MacOS", "\n", "            ", "os", ".", "system", "(", "'open '", "+", "save_path", ")", "\n", "\n", "", "", "print", "(", "'Done. (%.3fs)'", "%", "(", "time", ".", "time", "(", ")", "-", "t0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.tune.train": [[44, 455], ["logger.info", "wdir.mkdir", "utils.general.init_seeds", "weights.endswith", "max", "dict().items", "optim.SGD.add_param_group", "optim.SGD.add_param_group", "logger.info", "torch.LambdaLR", "utils.datasets.create_dataloader9", "[].max", "len", "utils.general.labels_to_class_weights().to", "time.time", "max", "numpy.zeros", "torch.cuda.amp.GradScaler", "logger.info", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "range", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "torch.cuda.empty_cache", "pathlib.Path", "open", "yaml.dump", "open", "yaml.dump", "open", "yaml.load", "utils.torch_utils.torch_distributed_zero_first", "utils.general.check_dataset", "len", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "models.models.Darknet().to", "torch.nn.parallel.DistributedDataParallel.load_state_dict", "print", "models.models.Darknet().to", "round", "torch.Adam", "torch.SGD", "wandb.init", "utils.general.check_img_size", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "torch.nn.SyncBatchNorm.convert_sync_batchnorm().to", "logger.info", "utils.torch_utils.ModelEMA", "torch.nn.parallel.DistributedDataParallel", "round", "torch.nn.parallel.DistributedDataParallel.train", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "enumerate", "logger.info", "optim.SGD.zero_grad", "lr_scheduler.LambdaLR.step", "zip", "logger.info", "torch.destroy_process_group", "wandb.run.finish", "vars", "int", "len", "utils.torch_utils.torch_distributed_zero_first", "models.models.attempt_download", "dict", "pg2.append", "optim.SGD.load_state_dict", "torch.load.get", "logger.info", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "utils.datasets.create_dataloader9", "numpy.concatenate", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "utils.general.labels_to_class_weights", "dataloader.sampler.set_epoch", "tqdm.tqdm", "amp.GradScaler.scale().backward", "zip", "utils.general.fitness", "utils.general.fitness_p", "utils.general.fitness_r", "utils.general.fitness_ap50", "utils.general.fitness_ap", "opt.name.isnumeric", "f1.exists", "utils.plots.plot_results", "models.models.Darknet", "ckpt[].items", "models.models.Darknet", "torch.nn.parallel.DistributedDataParallel.named_parameters", "pg1.append", "len", "len", "len", "open", "file.write", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "numpy.concatenate", "utils.plots.plot_labels", "utils.general.labels_to_image_weights", "random.choices", "torch.broadcast", "F.interpolate.to().float", "max", "enumerate", "torch.cuda.amp.autocast", "torch.nn.parallel.DistributedDataParallel", "utils.loss.compute_loss", "amp.GradScaler.step", "amp.GradScaler.update", "optim.SGD.zero_grad", "tqdm.tqdm.set_description", "ema.update_attr", "open", "f.write", "len", "os.system", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "numpy.array().reshape", "utils.general.fitness_f", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "os.rename", "str().endswith", "wandb.log", "[].numel", "v.numel", "len", "len", "pg1.append", "torch.load.get", "tb_writer.add_histogram", "wandb.log", "torch.nn.parallel.DistributedDataParallel.class_weights.cpu().numpy", "range", "indices.cpu().numpy", "numpy.interp().round", "numpy.interp", "max", "torch.interpolate", "targets.to", "amp.GradScaler.scale", "ema.update", "utils.plots.plot_images", "test.test", "tb_writer.add_scalar", "wandb.log", "numpy.array().reshape", "open", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "utils.general.strip_optimizer", "torch.nn.parallel.DistributedDataParallel.state_dict", "pg1.append", "pg0.append", "math.cos", "pathlib.Path", "locals", "F.interpolate.to", "numpy.interp", "random.randrange", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "wandb.log", "list", "list", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "f.read", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "str", "os.system", "torch.nn.parallel.DistributedDataParallel.class_weights.cpu", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "indices.cpu", "numpy.interp", "math.ceil", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "torch.cuda.memory_reserved", "numpy.array", "hasattr", "ema.ema.module.state_dict", "ema.ema.state_dict", "optim.SGD.state_dict", "wandb.Image", "time.time", "torch.nn.parallel.DistributedDataParallel.state_dict", "wandb.Image", "lf", "hasattr", "str", "str", "save_dir.glob", "wandb.Image", "str", "save_dir.glob"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.init_seeds", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_dataloader9", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.torch_distributed_zero_first", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_dataset", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_img_size", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.tune.train", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.torch_distributed_zero_first", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.attempt_download", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_dataloader9", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.labels_to_class_weights", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MishImplementation.backward", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_p", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_r", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_ap50", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_ap", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_results", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_labels", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.labels_to_image_weights", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.compute_loss", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.update", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.ModelEMA.update_attr", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_f", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.update", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_images", "home.repos.pwc.inspect_result.WongKinYiu_yolor.None.test.test", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.strip_optimizer"], ["", "def", "train", "(", "hyp", ",", "opt", ",", "device", ",", "tb_writer", "=", "None", ",", "wandb", "=", "None", ")", ":", "\n", "    ", "logger", ".", "info", "(", "f'Hyperparameters {hyp}'", ")", "\n", "save_dir", ",", "epochs", ",", "batch_size", ",", "total_batch_size", ",", "weights", ",", "rank", "=", "Path", "(", "opt", ".", "save_dir", ")", ",", "opt", ".", "epochs", ",", "opt", ".", "batch_size", ",", "opt", ".", "total_batch_size", ",", "opt", ".", "weights", ",", "opt", ".", "global_rank", "\n", "\n", "# Directories", "\n", "wdir", "=", "save_dir", "/", "'weights'", "\n", "wdir", ".", "mkdir", "(", "parents", "=", "True", ",", "exist_ok", "=", "True", ")", "# make dir", "\n", "last", "=", "wdir", "/", "'last.pt'", "\n", "best", "=", "wdir", "/", "'best.pt'", "\n", "results_file", "=", "save_dir", "/", "'results.txt'", "\n", "\n", "# Save run settings", "\n", "with", "open", "(", "save_dir", "/", "'hyp.yaml'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "yaml", ".", "dump", "(", "hyp", ",", "f", ",", "sort_keys", "=", "False", ")", "\n", "", "with", "open", "(", "save_dir", "/", "'opt.yaml'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "yaml", ".", "dump", "(", "vars", "(", "opt", ")", ",", "f", ",", "sort_keys", "=", "False", ")", "\n", "\n", "# Configure", "\n", "", "plots", "=", "not", "opt", ".", "evolve", "# create plots", "\n", "cuda", "=", "device", ".", "type", "!=", "'cpu'", "\n", "init_seeds", "(", "2", "+", "rank", ")", "\n", "with", "open", "(", "opt", ".", "data", ")", "as", "f", ":", "\n", "        ", "data_dict", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "# data dict", "\n", "", "with", "torch_distributed_zero_first", "(", "rank", ")", ":", "\n", "        ", "check_dataset", "(", "data_dict", ")", "# check", "\n", "", "train_path", "=", "data_dict", "[", "'train'", "]", "\n", "test_path", "=", "data_dict", "[", "'val'", "]", "\n", "nc", ",", "names", "=", "(", "1", ",", "[", "'item'", "]", ")", "if", "opt", ".", "single_cls", "else", "(", "int", "(", "data_dict", "[", "'nc'", "]", ")", ",", "data_dict", "[", "'names'", "]", ")", "# number classes, names", "\n", "assert", "len", "(", "names", ")", "==", "nc", ",", "'%g names found for nc=%g dataset in %s'", "%", "(", "len", "(", "names", ")", ",", "nc", ",", "opt", ".", "data", ")", "# check", "\n", "\n", "# Model", "\n", "pretrained", "=", "weights", ".", "endswith", "(", "'.pt'", ")", "\n", "if", "pretrained", ":", "\n", "        ", "with", "torch_distributed_zero_first", "(", "rank", ")", ":", "\n", "            ", "attempt_download", "(", "weights", ")", "# download if not found locally", "\n", "", "ckpt", "=", "torch", ".", "load", "(", "weights", ",", "map_location", "=", "device", ")", "# load checkpoint", "\n", "model", "=", "Darknet", "(", "opt", ".", "cfg", ")", ".", "to", "(", "device", ")", "# create", "\n", "state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "ckpt", "[", "'model'", "]", ".", "items", "(", ")", "if", "model", ".", "state_dict", "(", ")", "[", "k", "]", ".", "numel", "(", ")", "==", "v", ".", "numel", "(", ")", "}", "\n", "model", ".", "load_state_dict", "(", "state_dict", ",", "strict", "=", "False", ")", "\n", "print", "(", "'Transferred %g/%g items from %s'", "%", "(", "len", "(", "state_dict", ")", ",", "len", "(", "model", ".", "state_dict", "(", ")", ")", ",", "weights", ")", ")", "# report", "\n", "", "else", ":", "\n", "        ", "model", "=", "Darknet", "(", "opt", ".", "cfg", ")", ".", "to", "(", "device", ")", "# create", "\n", "\n", "# Optimizer", "\n", "", "nbs", "=", "64", "# nominal batch size", "\n", "accumulate", "=", "max", "(", "round", "(", "nbs", "/", "total_batch_size", ")", ",", "1", ")", "# accumulate loss before optimizing", "\n", "hyp", "[", "'weight_decay'", "]", "*=", "total_batch_size", "*", "accumulate", "/", "nbs", "# scale weight_decay", "\n", "\n", "pg0", ",", "pg1", ",", "pg2", "=", "[", "]", ",", "[", "]", ",", "[", "]", "# optimizer parameter groups", "\n", "for", "k", ",", "v", "in", "dict", "(", "model", ".", "named_parameters", "(", ")", ")", ".", "items", "(", ")", ":", "\n", "        ", "if", "'.bias'", "in", "k", ":", "\n", "            ", "pg2", ".", "append", "(", "v", ")", "# biases", "\n", "", "elif", "'Conv2d.weight'", "in", "k", ":", "\n", "            ", "pg1", ".", "append", "(", "v", ")", "# apply weight_decay", "\n", "", "elif", "'m.weight'", "in", "k", ":", "\n", "            ", "pg1", ".", "append", "(", "v", ")", "# apply weight_decay", "\n", "", "elif", "'w.weight'", "in", "k", ":", "\n", "            ", "pg1", ".", "append", "(", "v", ")", "# apply weight_decay", "\n", "", "else", ":", "\n", "            ", "pg0", ".", "append", "(", "v", ")", "# all else", "\n", "\n", "", "", "if", "opt", ".", "adam", ":", "\n", "        ", "optimizer", "=", "optim", ".", "Adam", "(", "pg0", ",", "lr", "=", "hyp", "[", "'lr0'", "]", ",", "betas", "=", "(", "hyp", "[", "'momentum'", "]", ",", "0.999", ")", ")", "# adjust beta1 to momentum", "\n", "", "else", ":", "\n", "        ", "optimizer", "=", "optim", ".", "SGD", "(", "pg0", ",", "lr", "=", "hyp", "[", "'lr0'", "]", ",", "momentum", "=", "hyp", "[", "'momentum'", "]", ",", "nesterov", "=", "True", ")", "\n", "\n", "", "optimizer", ".", "add_param_group", "(", "{", "'params'", ":", "pg1", ",", "'weight_decay'", ":", "hyp", "[", "'weight_decay'", "]", "}", ")", "# add pg1 with weight_decay", "\n", "optimizer", ".", "add_param_group", "(", "{", "'params'", ":", "pg2", "}", ")", "# add pg2 (biases)", "\n", "logger", ".", "info", "(", "'Optimizer groups: %g .bias, %g conv.weight, %g other'", "%", "(", "len", "(", "pg2", ")", ",", "len", "(", "pg1", ")", ",", "len", "(", "pg0", ")", ")", ")", "\n", "del", "pg0", ",", "pg1", ",", "pg2", "\n", "\n", "# Scheduler https://arxiv.org/pdf/1812.01187.pdf", "\n", "# https://pytorch.org/docs/stable/_modules/torch/optim/lr_scheduler.html#OneCycleLR", "\n", "lf", "=", "lambda", "x", ":", "(", "(", "1", "+", "math", ".", "cos", "(", "x", "*", "math", ".", "pi", "/", "epochs", ")", ")", "/", "2", ")", "*", "(", "1", "-", "hyp", "[", "'lrf'", "]", ")", "+", "hyp", "[", "'lrf'", "]", "# cosine", "\n", "scheduler", "=", "lr_scheduler", ".", "LambdaLR", "(", "optimizer", ",", "lr_lambda", "=", "lf", ")", "\n", "# plot_lr_scheduler(optimizer, scheduler, epochs)", "\n", "\n", "# Logging", "\n", "if", "wandb", "and", "wandb", ".", "run", "is", "None", ":", "\n", "        ", "opt", ".", "hyp", "=", "hyp", "# add hyperparameters", "\n", "wandb_run", "=", "wandb", ".", "init", "(", "config", "=", "opt", ",", "resume", "=", "\"allow\"", ",", "\n", "project", "=", "'YOLOR'", "if", "opt", ".", "project", "==", "'runs/train'", "else", "Path", "(", "opt", ".", "project", ")", ".", "stem", ",", "\n", "name", "=", "save_dir", ".", "stem", ",", "\n", "id", "=", "ckpt", ".", "get", "(", "'wandb_id'", ")", "if", "'ckpt'", "in", "locals", "(", ")", "else", "None", ")", "\n", "\n", "# Resume", "\n", "", "start_epoch", ",", "best_fitness", "=", "0", ",", "0.0", "\n", "best_fitness_p", ",", "best_fitness_r", ",", "best_fitness_ap50", ",", "best_fitness_ap", ",", "best_fitness_f", "=", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", ",", "0.0", "\n", "if", "pretrained", ":", "\n", "# Optimizer", "\n", "        ", "if", "ckpt", "[", "'optimizer'", "]", "is", "not", "None", ":", "\n", "            ", "optimizer", ".", "load_state_dict", "(", "ckpt", "[", "'optimizer'", "]", ")", "\n", "best_fitness", "=", "ckpt", "[", "'best_fitness'", "]", "\n", "best_fitness_p", "=", "ckpt", "[", "'best_fitness_p'", "]", "\n", "best_fitness_r", "=", "ckpt", "[", "'best_fitness_r'", "]", "\n", "best_fitness_ap50", "=", "ckpt", "[", "'best_fitness_ap50'", "]", "\n", "best_fitness_ap", "=", "ckpt", "[", "'best_fitness_ap'", "]", "\n", "best_fitness_f", "=", "ckpt", "[", "'best_fitness_f'", "]", "\n", "\n", "# Results", "\n", "", "if", "ckpt", ".", "get", "(", "'training_results'", ")", "is", "not", "None", ":", "\n", "            ", "with", "open", "(", "results_file", ",", "'w'", ")", "as", "file", ":", "\n", "                ", "file", ".", "write", "(", "ckpt", "[", "'training_results'", "]", ")", "# write results.txt", "\n", "\n", "# Epochs", "\n", "", "", "start_epoch", "=", "ckpt", "[", "'epoch'", "]", "+", "1", "\n", "if", "opt", ".", "resume", ":", "\n", "            ", "assert", "start_epoch", ">", "0", ",", "'%s training to %g epochs is finished, nothing to resume.'", "%", "(", "weights", ",", "epochs", ")", "\n", "", "if", "epochs", "<", "start_epoch", ":", "\n", "            ", "logger", ".", "info", "(", "'%s has been trained for %g epochs. Fine-tuning for %g additional epochs.'", "%", "\n", "(", "weights", ",", "ckpt", "[", "'epoch'", "]", ",", "epochs", ")", ")", "\n", "epochs", "+=", "ckpt", "[", "'epoch'", "]", "# finetune additional epochs", "\n", "\n", "", "del", "ckpt", ",", "state_dict", "\n", "\n", "# Image sizes", "\n", "", "gs", "=", "64", "#int(max(model.stride))  # grid size (max stride)", "\n", "imgsz", ",", "imgsz_test", "=", "[", "check_img_size", "(", "x", ",", "gs", ")", "for", "x", "in", "opt", ".", "img_size", "]", "# verify imgsz are gs-multiples", "\n", "\n", "# DP mode", "\n", "if", "cuda", "and", "rank", "==", "-", "1", "and", "torch", ".", "cuda", ".", "device_count", "(", ")", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# SyncBatchNorm", "\n", "", "if", "opt", ".", "sync_bn", "and", "cuda", "and", "rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "SyncBatchNorm", ".", "convert_sync_batchnorm", "(", "model", ")", ".", "to", "(", "device", ")", "\n", "logger", ".", "info", "(", "'Using SyncBatchNorm()'", ")", "\n", "\n", "# EMA", "\n", "", "ema", "=", "ModelEMA", "(", "model", ")", "if", "rank", "in", "[", "-", "1", ",", "0", "]", "else", "None", "\n", "\n", "# DDP mode", "\n", "if", "cuda", "and", "rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "DDP", "(", "model", ",", "device_ids", "=", "[", "opt", ".", "local_rank", "]", ",", "output_device", "=", "opt", ".", "local_rank", ")", "\n", "\n", "# Trainloader", "\n", "", "dataloader", ",", "dataset", "=", "create_dataloader", "(", "train_path", ",", "imgsz", ",", "batch_size", ",", "gs", ",", "opt", ",", "\n", "hyp", "=", "hyp", ",", "augment", "=", "True", ",", "cache", "=", "opt", ".", "cache_images", ",", "rect", "=", "opt", ".", "rect", ",", "\n", "rank", "=", "rank", ",", "world_size", "=", "opt", ".", "world_size", ",", "workers", "=", "opt", ".", "workers", ")", "\n", "mlc", "=", "np", ".", "concatenate", "(", "dataset", ".", "labels", ",", "0", ")", "[", ":", ",", "0", "]", ".", "max", "(", ")", "# max label class", "\n", "nb", "=", "len", "(", "dataloader", ")", "# number of batches", "\n", "assert", "mlc", "<", "nc", ",", "'Label class %g exceeds nc=%g in %s. Possible class labels are 0-%g'", "%", "(", "mlc", ",", "nc", ",", "opt", ".", "data", ",", "nc", "-", "1", ")", "\n", "\n", "# Process 0", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "ema", ".", "updates", "=", "start_epoch", "*", "nb", "//", "accumulate", "# set EMA updates", "\n", "testloader", "=", "create_dataloader", "(", "test_path", ",", "imgsz_test", ",", "batch_size", "*", "2", ",", "gs", ",", "opt", ",", "\n", "hyp", "=", "hyp", ",", "cache", "=", "opt", ".", "cache_images", "and", "not", "opt", ".", "notest", ",", "rect", "=", "True", ",", "\n", "rank", "=", "-", "1", ",", "world_size", "=", "opt", ".", "world_size", ",", "workers", "=", "opt", ".", "workers", ")", "[", "0", "]", "# testloader", "\n", "\n", "if", "not", "opt", ".", "resume", ":", "\n", "            ", "labels", "=", "np", ".", "concatenate", "(", "dataset", ".", "labels", ",", "0", ")", "\n", "c", "=", "torch", ".", "tensor", "(", "labels", "[", ":", ",", "0", "]", ")", "# classes", "\n", "# cf = torch.bincount(c.long(), minlength=nc) + 1.  # frequency", "\n", "# model._initialize_biases(cf.to(device))", "\n", "if", "plots", ":", "\n", "                ", "plot_labels", "(", "labels", ",", "save_dir", "=", "save_dir", ")", "\n", "if", "tb_writer", ":", "\n", "                    ", "tb_writer", ".", "add_histogram", "(", "'classes'", ",", "c", ",", "0", ")", "\n", "", "if", "wandb", ":", "\n", "                    ", "wandb", ".", "log", "(", "{", "\"Labels\"", ":", "[", "wandb", ".", "Image", "(", "str", "(", "x", ")", ",", "caption", "=", "x", ".", "name", ")", "for", "x", "in", "save_dir", ".", "glob", "(", "'*labels*.png'", ")", "]", "}", ")", "\n", "\n", "# Anchors", "\n", "# if not opt.noautoanchor:", "\n", "#     check_anchors(dataset, model=model, thr=hyp['anchor_t'], imgsz=imgsz)", "\n", "\n", "# Model parameters", "\n", "", "", "", "", "hyp", "[", "'cls'", "]", "*=", "nc", "/", "80.", "# scale coco-tuned hyp['cls'] to current dataset", "\n", "model", ".", "nc", "=", "nc", "# attach number of classes to model", "\n", "model", ".", "hyp", "=", "hyp", "# attach hyperparameters to model", "\n", "model", ".", "gr", "=", "1.0", "# iou loss ratio (obj_loss = 1.0 or iou)", "\n", "model", ".", "class_weights", "=", "labels_to_class_weights", "(", "dataset", ".", "labels", ",", "nc", ")", ".", "to", "(", "device", ")", "# attach class weights", "\n", "model", ".", "names", "=", "names", "\n", "\n", "# Start training", "\n", "t0", "=", "time", ".", "time", "(", ")", "\n", "nw", "=", "max", "(", "round", "(", "hyp", "[", "'warmup_epochs'", "]", "*", "nb", ")", ",", "1000", ")", "# number of warmup iterations, max(3 epochs, 1k iterations)", "\n", "# nw = min(nw, (epochs - start_epoch) / 2 * nb)  # limit warmup to < 1/2 of training", "\n", "maps", "=", "np", ".", "zeros", "(", "nc", ")", "# mAP per class", "\n", "results", "=", "(", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ")", "# P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)", "\n", "scheduler", ".", "last_epoch", "=", "start_epoch", "-", "1", "# do not move", "\n", "scaler", "=", "amp", ".", "GradScaler", "(", "enabled", "=", "cuda", ")", "\n", "logger", ".", "info", "(", "'Image sizes %g train, %g test\\n'", "\n", "'Using %g dataloader workers\\nLogging results to %s\\n'", "\n", "'Starting training for %g epochs...'", "%", "(", "imgsz", ",", "imgsz_test", ",", "dataloader", ".", "num_workers", ",", "save_dir", ",", "epochs", ")", ")", "\n", "\n", "torch", ".", "save", "(", "model", ",", "wdir", "/", "'init.pt'", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "epochs", ")", ":", "# epoch ------------------------------------------------------------------", "\n", "        ", "model", ".", "train", "(", ")", "\n", "\n", "# Update image weights (optional)", "\n", "if", "opt", ".", "image_weights", ":", "\n", "# Generate indices", "\n", "            ", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "cw", "=", "model", ".", "class_weights", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "*", "(", "1", "-", "maps", ")", "**", "2", "# class weights", "\n", "iw", "=", "labels_to_image_weights", "(", "dataset", ".", "labels", ",", "nc", "=", "nc", ",", "class_weights", "=", "cw", ")", "# image weights", "\n", "dataset", ".", "indices", "=", "random", ".", "choices", "(", "range", "(", "dataset", ".", "n", ")", ",", "weights", "=", "iw", ",", "k", "=", "dataset", ".", "n", ")", "# rand weighted idx", "\n", "# Broadcast if DDP", "\n", "", "if", "rank", "!=", "-", "1", ":", "\n", "                ", "indices", "=", "(", "torch", ".", "tensor", "(", "dataset", ".", "indices", ")", "if", "rank", "==", "0", "else", "torch", ".", "zeros", "(", "dataset", ".", "n", ")", ")", ".", "int", "(", ")", "\n", "dist", ".", "broadcast", "(", "indices", ",", "0", ")", "\n", "if", "rank", "!=", "0", ":", "\n", "                    ", "dataset", ".", "indices", "=", "indices", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# Update mosaic border", "\n", "# b = int(random.uniform(0.25 * imgsz, 0.75 * imgsz + gs) // gs * gs)", "\n", "# dataset.mosaic_border = [b - imgsz, -b]  # height, width borders", "\n", "\n", "", "", "", "mloss", "=", "torch", ".", "zeros", "(", "4", ",", "device", "=", "device", ")", "# mean losses", "\n", "if", "rank", "!=", "-", "1", ":", "\n", "            ", "dataloader", ".", "sampler", ".", "set_epoch", "(", "epoch", ")", "\n", "", "pbar", "=", "enumerate", "(", "dataloader", ")", "\n", "logger", ".", "info", "(", "(", "'\\n'", "+", "'%10s'", "*", "8", ")", "%", "(", "'Epoch'", ",", "'gpu_mem'", ",", "'box'", ",", "'obj'", ",", "'cls'", ",", "'total'", ",", "'targets'", ",", "'img_size'", ")", ")", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "pbar", "=", "tqdm", "(", "pbar", ",", "total", "=", "nb", ")", "# progress bar", "\n", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "for", "i", ",", "(", "imgs", ",", "targets", ",", "paths", ",", "_", ")", "in", "pbar", ":", "# batch -------------------------------------------------------------", "\n", "            ", "ni", "=", "i", "+", "nb", "*", "epoch", "# number integrated batches (since train start)", "\n", "imgs", "=", "imgs", ".", "to", "(", "device", ",", "non_blocking", "=", "True", ")", ".", "float", "(", ")", "/", "255.0", "# uint8 to float32, 0-255 to 0.0-1.0", "\n", "\n", "# Warmup", "\n", "if", "ni", "<=", "nw", ":", "\n", "                ", "xi", "=", "[", "0", ",", "nw", "]", "# x interp", "\n", "# model.gr = np.interp(ni, xi, [0.0, 1.0])  # iou loss ratio (obj_loss = 1.0 or iou)", "\n", "accumulate", "=", "max", "(", "1", ",", "np", ".", "interp", "(", "ni", ",", "xi", ",", "[", "1", ",", "nbs", "/", "total_batch_size", "]", ")", ".", "round", "(", ")", ")", "\n", "for", "j", ",", "x", "in", "enumerate", "(", "optimizer", ".", "param_groups", ")", ":", "\n", "# bias lr falls from 0.1 to lr0, all other lrs rise from 0.0 to lr0", "\n", "                    ", "x", "[", "'lr'", "]", "=", "np", ".", "interp", "(", "ni", ",", "xi", ",", "[", "hyp", "[", "'warmup_bias_lr'", "]", "if", "j", "==", "2", "else", "0.0", ",", "x", "[", "'initial_lr'", "]", "*", "lf", "(", "epoch", ")", "]", ")", "\n", "if", "'momentum'", "in", "x", ":", "\n", "                        ", "x", "[", "'momentum'", "]", "=", "np", ".", "interp", "(", "ni", ",", "xi", ",", "[", "hyp", "[", "'warmup_momentum'", "]", ",", "hyp", "[", "'momentum'", "]", "]", ")", "\n", "\n", "# Multi-scale", "\n", "", "", "", "if", "opt", ".", "multi_scale", ":", "\n", "                ", "sz", "=", "random", ".", "randrange", "(", "imgsz", "*", "0.5", ",", "imgsz", "*", "1.5", "+", "gs", ")", "//", "gs", "*", "gs", "# size", "\n", "sf", "=", "sz", "/", "max", "(", "imgs", ".", "shape", "[", "2", ":", "]", ")", "# scale factor", "\n", "if", "sf", "!=", "1", ":", "\n", "                    ", "ns", "=", "[", "math", ".", "ceil", "(", "x", "*", "sf", "/", "gs", ")", "*", "gs", "for", "x", "in", "imgs", ".", "shape", "[", "2", ":", "]", "]", "# new shape (stretched to gs-multiple)", "\n", "imgs", "=", "F", ".", "interpolate", "(", "imgs", ",", "size", "=", "ns", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "\n", "# Forward", "\n", "", "", "with", "amp", ".", "autocast", "(", "enabled", "=", "cuda", ")", ":", "\n", "                ", "pred", "=", "model", "(", "imgs", ")", "# forward", "\n", "loss", ",", "loss_items", "=", "compute_loss", "(", "pred", ",", "targets", ".", "to", "(", "device", ")", ",", "model", ")", "# loss scaled by batch_size", "\n", "if", "rank", "!=", "-", "1", ":", "\n", "                    ", "loss", "*=", "opt", ".", "world_size", "# gradient averaged between devices in DDP mode", "\n", "\n", "# Backward", "\n", "", "", "scaler", ".", "scale", "(", "loss", ")", ".", "backward", "(", ")", "\n", "\n", "# Optimize", "\n", "if", "ni", "%", "accumulate", "==", "0", ":", "\n", "                ", "scaler", ".", "step", "(", "optimizer", ")", "# optimizer.step", "\n", "scaler", ".", "update", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "ema", ":", "\n", "                    ", "ema", ".", "update", "(", "model", ")", "\n", "\n", "# Print", "\n", "", "", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "mloss", "=", "(", "mloss", "*", "i", "+", "loss_items", ")", "/", "(", "i", "+", "1", ")", "# update mean losses", "\n", "mem", "=", "'%.3gG'", "%", "(", "torch", ".", "cuda", ".", "memory_reserved", "(", ")", "/", "1E9", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "0", ")", "# (GB)", "\n", "s", "=", "(", "'%10s'", "*", "2", "+", "'%10.4g'", "*", "6", ")", "%", "(", "\n", "'%g/%g'", "%", "(", "epoch", ",", "epochs", "-", "1", ")", ",", "mem", ",", "*", "mloss", ",", "targets", ".", "shape", "[", "0", "]", ",", "imgs", ".", "shape", "[", "-", "1", "]", ")", "\n", "pbar", ".", "set_description", "(", "s", ")", "\n", "\n", "# Plot", "\n", "if", "plots", "and", "ni", "<", "3", ":", "\n", "                    ", "f", "=", "save_dir", "/", "f'train_batch{ni}.jpg'", "# filename", "\n", "plot_images", "(", "images", "=", "imgs", ",", "targets", "=", "targets", ",", "paths", "=", "paths", ",", "fname", "=", "f", ")", "\n", "# if tb_writer:", "\n", "#     tb_writer.add_image(f, result, dataformats='HWC', global_step=epoch)", "\n", "#     tb_writer.add_graph(model, imgs)  # add model to tensorboard", "\n", "", "elif", "plots", "and", "ni", "==", "3", "and", "wandb", ":", "\n", "                    ", "wandb", ".", "log", "(", "{", "\"Mosaics\"", ":", "[", "wandb", ".", "Image", "(", "str", "(", "x", ")", ",", "caption", "=", "x", ".", "name", ")", "for", "x", "in", "save_dir", ".", "glob", "(", "'train*.jpg'", ")", "]", "}", ")", "\n", "\n", "# end batch ------------------------------------------------------------------------------------------------", "\n", "# end epoch ----------------------------------------------------------------------------------------------------", "\n", "\n", "# Scheduler", "\n", "", "", "", "lr", "=", "[", "x", "[", "'lr'", "]", "for", "x", "in", "optimizer", ".", "param_groups", "]", "# for tensorboard", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# DDP process 0 or single-GPU", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# mAP", "\n", "            ", "if", "ema", ":", "\n", "                ", "ema", ".", "update_attr", "(", "model", ")", "\n", "", "final_epoch", "=", "epoch", "+", "1", "==", "epochs", "\n", "if", "not", "opt", ".", "notest", "or", "final_epoch", ":", "# Calculate mAP", "\n", "                ", "if", "epoch", ">=", "3", ":", "\n", "                    ", "results", ",", "maps", ",", "times", "=", "test", ".", "test", "(", "opt", ".", "data", ",", "\n", "batch_size", "=", "batch_size", "*", "2", ",", "\n", "imgsz", "=", "imgsz_test", ",", "\n", "model", "=", "ema", ".", "ema", ".", "module", "if", "hasattr", "(", "ema", ".", "ema", ",", "'module'", ")", "else", "ema", ".", "ema", ",", "\n", "single_cls", "=", "opt", ".", "single_cls", ",", "\n", "dataloader", "=", "testloader", ",", "\n", "save_dir", "=", "save_dir", ",", "\n", "plots", "=", "plots", "and", "final_epoch", ",", "\n", "log_imgs", "=", "opt", ".", "log_imgs", "if", "wandb", "else", "0", ")", "\n", "\n", "# Write", "\n", "", "", "with", "open", "(", "results_file", ",", "'a'", ")", "as", "f", ":", "\n", "                ", "f", ".", "write", "(", "s", "+", "'%10.4g'", "*", "7", "%", "results", "+", "'\\n'", ")", "# P, R, mAP@.5, mAP@.5-.95, val_loss(box, obj, cls)", "\n", "", "if", "len", "(", "opt", ".", "name", ")", "and", "opt", ".", "bucket", ":", "\n", "                ", "os", ".", "system", "(", "'gsutil cp %s gs://%s/results/results%s.txt'", "%", "(", "results_file", ",", "opt", ".", "bucket", ",", "opt", ".", "name", ")", ")", "\n", "\n", "# Log", "\n", "", "tags", "=", "[", "'train/box_loss'", ",", "'train/obj_loss'", ",", "'train/cls_loss'", ",", "# train loss", "\n", "'metrics/precision'", ",", "'metrics/recall'", ",", "'metrics/mAP_0.5'", ",", "'metrics/mAP_0.5:0.95'", ",", "\n", "'val/box_loss'", ",", "'val/obj_loss'", ",", "'val/cls_loss'", ",", "# val loss", "\n", "'x/lr0'", ",", "'x/lr1'", ",", "'x/lr2'", "]", "# params", "\n", "for", "x", ",", "tag", "in", "zip", "(", "list", "(", "mloss", "[", ":", "-", "1", "]", ")", "+", "list", "(", "results", ")", "+", "lr", ",", "tags", ")", ":", "\n", "                ", "if", "tb_writer", ":", "\n", "                    ", "tb_writer", ".", "add_scalar", "(", "tag", ",", "x", ",", "epoch", ")", "# tensorboard", "\n", "", "if", "wandb", ":", "\n", "                    ", "wandb", ".", "log", "(", "{", "tag", ":", "x", "}", ")", "# W&B", "\n", "\n", "# Update best mAP", "\n", "", "", "fi", "=", "fitness", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_p", "=", "fitness_p", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_r", "=", "fitness_r", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_ap50", "=", "fitness_ap50", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "fi_ap", "=", "fitness_ap", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "if", "(", "fi_p", ">", "0.0", ")", "or", "(", "fi_r", ">", "0.0", ")", ":", "\n", "                ", "fi_f", "=", "fitness_f", "(", "np", ".", "array", "(", "results", ")", ".", "reshape", "(", "1", ",", "-", "1", ")", ")", "# weighted combination of [P, R, mAP@.5, mAP@.5-.95]", "\n", "", "else", ":", "\n", "                ", "fi_f", "=", "0.0", "\n", "", "if", "fi", ">", "best_fitness", ":", "\n", "                ", "best_fitness", "=", "fi", "\n", "", "if", "fi_p", ">", "best_fitness_p", ":", "\n", "                ", "best_fitness_p", "=", "fi_p", "\n", "", "if", "fi_r", ">", "best_fitness_r", ":", "\n", "                ", "best_fitness_r", "=", "fi_r", "\n", "", "if", "fi_ap50", ">", "best_fitness_ap50", ":", "\n", "                ", "best_fitness_ap50", "=", "fi_ap50", "\n", "", "if", "fi_ap", ">", "best_fitness_ap", ":", "\n", "                ", "best_fitness_ap", "=", "fi_ap", "\n", "", "if", "fi_f", ">", "best_fitness_f", ":", "\n", "                ", "best_fitness_f", "=", "fi_f", "\n", "\n", "# Save model", "\n", "", "save", "=", "(", "not", "opt", ".", "nosave", ")", "or", "(", "final_epoch", "and", "not", "opt", ".", "evolve", ")", "\n", "if", "save", ":", "\n", "                ", "with", "open", "(", "results_file", ",", "'r'", ")", "as", "f", ":", "# create checkpoint", "\n", "                    ", "ckpt", "=", "{", "'epoch'", ":", "epoch", ",", "\n", "'best_fitness'", ":", "best_fitness", ",", "\n", "'best_fitness_p'", ":", "best_fitness_p", ",", "\n", "'best_fitness_r'", ":", "best_fitness_r", ",", "\n", "'best_fitness_ap50'", ":", "best_fitness_ap50", ",", "\n", "'best_fitness_ap'", ":", "best_fitness_ap", ",", "\n", "'best_fitness_f'", ":", "best_fitness_f", ",", "\n", "'training_results'", ":", "f", ".", "read", "(", ")", ",", "\n", "'model'", ":", "ema", ".", "ema", ".", "module", ".", "state_dict", "(", ")", "if", "hasattr", "(", "ema", ",", "'module'", ")", "else", "ema", ".", "ema", ".", "state_dict", "(", ")", ",", "\n", "'optimizer'", ":", "None", "if", "final_epoch", "else", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "'wandb_id'", ":", "wandb_run", ".", "id", "if", "wandb", "else", "None", "}", "\n", "\n", "# Save last, best and delete", "\n", "", "torch", ".", "save", "(", "ckpt", ",", "last", ")", "\n", "if", "best_fitness", "==", "fi", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "best", ")", "\n", "", "if", "(", "best_fitness", "==", "fi", ")", "and", "(", "epoch", ">=", "200", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "if", "best_fitness", "==", "fi", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_overall.pt'", ")", "\n", "", "if", "best_fitness_p", "==", "fi_p", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_p.pt'", ")", "\n", "", "if", "best_fitness_r", "==", "fi_r", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_r.pt'", ")", "\n", "", "if", "best_fitness_ap50", "==", "fi_ap50", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_ap50.pt'", ")", "\n", "", "if", "best_fitness_ap", "==", "fi_ap", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_ap.pt'", ")", "\n", "", "if", "best_fitness_f", "==", "fi_f", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'best_f.pt'", ")", "\n", "", "if", "epoch", "==", "0", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'epoch_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "if", "(", "(", "epoch", "+", "1", ")", "%", "25", ")", "==", "0", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'epoch_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "if", "epoch", ">=", "(", "epochs", "-", "5", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'last_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "elif", "epoch", ">=", "420", ":", "\n", "                    ", "torch", ".", "save", "(", "ckpt", ",", "wdir", "/", "'last_{:03d}.pt'", ".", "format", "(", "epoch", ")", ")", "\n", "", "del", "ckpt", "\n", "# end epoch ----------------------------------------------------------------------------------------------------", "\n", "# end training", "\n", "\n", "", "", "", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "# Strip optimizers", "\n", "        ", "n", "=", "opt", ".", "name", "if", "opt", ".", "name", ".", "isnumeric", "(", ")", "else", "''", "\n", "fresults", ",", "flast", ",", "fbest", "=", "save_dir", "/", "f'results{n}.txt'", ",", "wdir", "/", "f'last{n}.pt'", ",", "wdir", "/", "f'best{n}.pt'", "\n", "for", "f1", ",", "f2", "in", "zip", "(", "[", "wdir", "/", "'last.pt'", ",", "wdir", "/", "'best.pt'", ",", "results_file", "]", ",", "[", "flast", ",", "fbest", ",", "fresults", "]", ")", ":", "\n", "            ", "if", "f1", ".", "exists", "(", ")", ":", "\n", "                ", "os", ".", "rename", "(", "f1", ",", "f2", ")", "# rename", "\n", "if", "str", "(", "f2", ")", ".", "endswith", "(", "'.pt'", ")", ":", "# is *.pt", "\n", "                    ", "strip_optimizer", "(", "f2", ")", "# strip optimizer", "\n", "os", ".", "system", "(", "'gsutil cp %s gs://%s/weights'", "%", "(", "f2", ",", "opt", ".", "bucket", ")", ")", "if", "opt", ".", "bucket", "else", "None", "# upload", "\n", "# Finish", "\n", "", "", "", "if", "plots", ":", "\n", "            ", "plot_results", "(", "save_dir", "=", "save_dir", ")", "# save as results.png", "\n", "if", "wandb", ":", "\n", "                ", "wandb", ".", "log", "(", "{", "\"Results\"", ":", "[", "wandb", ".", "Image", "(", "str", "(", "save_dir", "/", "x", ")", ",", "caption", "=", "x", ")", "for", "x", "in", "\n", "[", "'results.png'", ",", "'precision-recall_curve.png'", "]", "]", "}", ")", "\n", "", "", "logger", ".", "info", "(", "'%g epochs completed in %.3f hours.\\n'", "%", "(", "epoch", "-", "start_epoch", "+", "1", ",", "(", "time", ".", "time", "(", ")", "-", "t0", ")", "/", "3600", ")", ")", "\n", "", "else", ":", "\n", "        ", "dist", ".", "destroy_process_group", "(", ")", "\n", "\n", "", "wandb", ".", "run", ".", "finish", "(", ")", "if", "wandb", "and", "wandb", ".", "run", "else", "None", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.color_list": [[26, 32], ["tuple", "plots.color_list.hex2rgb"], "function", ["None"], ["def", "color_list", "(", ")", ":", "\n", "# Return first 10 plt colors as (r,g,b) https://stackoverflow.com/questions/51350872/python-from-color-name-to-rgb", "\n", "    ", "def", "hex2rgb", "(", "h", ")", ":", "\n", "        ", "return", "tuple", "(", "int", "(", "h", "[", "1", "+", "i", ":", "1", "+", "i", "+", "2", "]", ",", "16", ")", "for", "i", "in", "(", "0", ",", "2", ",", "4", ")", ")", "\n", "\n", "", "return", "[", "hex2rgb", "(", "h", ")", "for", "h", "in", "plt", ".", "rcParams", "[", "'axes.prop_cycle'", "]", ".", "by_key", "(", ")", "[", "'color'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.hist2d": [[34, 41], ["numpy.histogram2d", "numpy.clip", "numpy.clip", "numpy.log", "numpy.linspace", "numpy.linspace", "x.min", "x.max", "y.min", "y.max", "numpy.digitize", "numpy.digitize"], "function", ["None"], ["", "def", "hist2d", "(", "x", ",", "y", ",", "n", "=", "100", ")", ":", "\n", "# 2d histogram used in labels.png and evolve.png", "\n", "    ", "xedges", ",", "yedges", "=", "np", ".", "linspace", "(", "x", ".", "min", "(", ")", ",", "x", ".", "max", "(", ")", ",", "n", ")", ",", "np", ".", "linspace", "(", "y", ".", "min", "(", ")", ",", "y", ".", "max", "(", ")", ",", "n", ")", "\n", "hist", ",", "xedges", ",", "yedges", "=", "np", ".", "histogram2d", "(", "x", ",", "y", ",", "(", "xedges", ",", "yedges", ")", ")", "\n", "xidx", "=", "np", ".", "clip", "(", "np", ".", "digitize", "(", "x", ",", "xedges", ")", "-", "1", ",", "0", ",", "hist", ".", "shape", "[", "0", "]", "-", "1", ")", "\n", "yidx", "=", "np", ".", "clip", "(", "np", ".", "digitize", "(", "y", ",", "yedges", ")", "-", "1", ",", "0", ",", "hist", ".", "shape", "[", "1", "]", "-", "1", ")", "\n", "return", "np", ".", "log", "(", "hist", "[", "xidx", ",", "yidx", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.butter_lowpass_filtfilt": [[43, 52], ["plots.butter_lowpass_filtfilt.butter_lowpass"], "function", ["None"], ["", "def", "butter_lowpass_filtfilt", "(", "data", ",", "cutoff", "=", "1500", ",", "fs", "=", "50000", ",", "order", "=", "5", ")", ":", "\n", "# https://stackoverflow.com/questions/28536191/how-to-filter-smooth-with-scipy-numpy", "\n", "    ", "def", "butter_lowpass", "(", "cutoff", ",", "fs", ",", "order", ")", ":", "\n", "        ", "nyq", "=", "0.5", "*", "fs", "\n", "normal_cutoff", "=", "cutoff", "/", "nyq", "\n", "return", "butter", "(", "order", ",", "normal_cutoff", ",", "btype", "=", "'low'", ",", "analog", "=", "False", ")", "\n", "\n", "", "b", ",", "a", "=", "butter_lowpass", "(", "cutoff", ",", "fs", ",", "order", "=", "order", ")", "\n", "return", "filtfilt", "(", "b", ",", "a", ",", "data", ")", "# forward-backward filter", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_one_box": [[54, 66], ["cv2.rectangle", "max", "cv2.rectangle", "cv2.putText", "round", "random.randint", "int", "int", "int", "int", "cv2.getTextSize", "range"], "function", ["None"], ["", "def", "plot_one_box", "(", "x", ",", "img", ",", "color", "=", "None", ",", "label", "=", "None", ",", "line_thickness", "=", "None", ")", ":", "\n", "# Plots one bounding box on image img", "\n", "    ", "tl", "=", "line_thickness", "or", "round", "(", "0.002", "*", "(", "img", ".", "shape", "[", "0", "]", "+", "img", ".", "shape", "[", "1", "]", ")", "/", "2", ")", "+", "1", "# line/font thickness", "\n", "color", "=", "color", "or", "[", "random", ".", "randint", "(", "0", ",", "255", ")", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "c1", ",", "c2", "=", "(", "int", "(", "x", "[", "0", "]", ")", ",", "int", "(", "x", "[", "1", "]", ")", ")", ",", "(", "int", "(", "x", "[", "2", "]", ")", ",", "int", "(", "x", "[", "3", "]", ")", ")", "\n", "cv2", ".", "rectangle", "(", "img", ",", "c1", ",", "c2", ",", "color", ",", "thickness", "=", "tl", ",", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "if", "label", ":", "\n", "        ", "tf", "=", "max", "(", "tl", "-", "1", ",", "1", ")", "# font thickness", "\n", "t_size", "=", "cv2", ".", "getTextSize", "(", "label", ",", "0", ",", "fontScale", "=", "tl", "/", "3", ",", "thickness", "=", "tf", ")", "[", "0", "]", "\n", "c2", "=", "c1", "[", "0", "]", "+", "t_size", "[", "0", "]", ",", "c1", "[", "1", "]", "-", "t_size", "[", "1", "]", "-", "3", "\n", "cv2", ".", "rectangle", "(", "img", ",", "c1", ",", "c2", ",", "color", ",", "-", "1", ",", "cv2", ".", "LINE_AA", ")", "# filled", "\n", "cv2", ".", "putText", "(", "img", ",", "label", ",", "(", "c1", "[", "0", "]", ",", "c1", "[", "1", "]", "-", "2", ")", ",", "0", ",", "tl", "/", "3", ",", "[", "225", ",", "255", ",", "255", "]", ",", "thickness", "=", "tf", ",", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_wh_methods": [[68, 87], ["numpy.arange", "numpy.exp", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.plot", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.grid", "matplotlib.legend", "plt.figure.tight_layout", "plt.figure.savefig", "torch.sigmoid().numpy", "torch.sigmoid", "torch.from_numpy"], "function", ["None"], ["", "", "def", "plot_wh_methods", "(", ")", ":", "# from utils.general import *; plot_wh_methods()", "\n", "# Compares the two methods for width-height anchor multiplication", "\n", "# https://github.com/ultralytics/yolov3/issues/168", "\n", "    ", "x", "=", "np", ".", "arange", "(", "-", "4.0", ",", "4.0", ",", ".1", ")", "\n", "ya", "=", "np", ".", "exp", "(", "x", ")", "\n", "yb", "=", "torch", ".", "sigmoid", "(", "torch", ".", "from_numpy", "(", "x", ")", ")", ".", "numpy", "(", ")", "*", "2", "\n", "\n", "fig", "=", "plt", ".", "figure", "(", "figsize", "=", "(", "6", ",", "3", ")", ",", "dpi", "=", "150", ")", "\n", "plt", ".", "plot", "(", "x", ",", "ya", ",", "'.-'", ",", "label", "=", "'YOLO'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "yb", "**", "2", ",", "'.-'", ",", "label", "=", "'YOLO ^2'", ")", "\n", "plt", ".", "plot", "(", "x", ",", "yb", "**", "1.6", ",", "'.-'", ",", "label", "=", "'YOLO ^1.6'", ")", "\n", "plt", ".", "xlim", "(", "left", "=", "-", "4", ",", "right", "=", "4", ")", "\n", "plt", ".", "ylim", "(", "bottom", "=", "0", ",", "top", "=", "6", ")", "\n", "plt", ".", "xlabel", "(", "'input'", ")", "\n", "plt", ".", "ylabel", "(", "'output'", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "'comparison.png'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.output_to_target": [[89, 109], ["isinstance", "enumerate", "numpy.array", "output.cpu().numpy.cpu().numpy", "output.cpu().numpy.cpu", "int", "targets.append"], "function", ["None"], ["", "def", "output_to_target", "(", "output", ",", "width", ",", "height", ")", ":", "\n", "# Convert model output to target format [batch_id, class_id, x, y, w, h, conf]", "\n", "    ", "if", "isinstance", "(", "output", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "output", "=", "output", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "", "targets", "=", "[", "]", "\n", "for", "i", ",", "o", "in", "enumerate", "(", "output", ")", ":", "\n", "        ", "if", "o", "is", "not", "None", ":", "\n", "            ", "for", "pred", "in", "o", ":", "\n", "                ", "box", "=", "pred", "[", ":", "4", "]", "\n", "w", "=", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "/", "width", "\n", "h", "=", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "/", "height", "\n", "x", "=", "box", "[", "0", "]", "/", "width", "+", "w", "/", "2", "\n", "y", "=", "box", "[", "1", "]", "/", "height", "+", "h", "/", "2", "\n", "conf", "=", "pred", "[", "4", "]", "\n", "cls", "=", "int", "(", "pred", "[", "5", "]", ")", "\n", "\n", "targets", ".", "append", "(", "[", "i", ",", "cls", ",", "x", ",", "y", ",", "w", ",", "h", ",", "conf", "]", ")", "\n", "\n", "", "", "", "return", "np", ".", "array", "(", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_images": [[111, 184], ["isinstance", "isinstance", "max", "min", "numpy.ceil", "plots.color_list", "numpy.full", "enumerate", "images.cpu().float().numpy.cpu().float().numpy", "targets.cpu().numpy.cpu().numpy", "numpy.max", "max", "math.ceil", "math.ceil", "int", "int", "cv2.resize.transpose", "cv2.rectangle", "min", "cv2.resize", "PIL.Image.fromarray().save", "int", "int", "cv2.resize", "len", "image_targets[].astype", "enumerate", "cv2.putText", "images.cpu().float().numpy.cpu().float", "targets.cpu().numpy.cpu", "utils.general.xywh2xyxy", "int", "cv2.getTextSize", "int", "int", "PIL.Image.fromarray", "plots.plot_one_box", "pathlib.Path", "max", "images.cpu().float().numpy.cpu", "len"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.color_list", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xywh2xyxy", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_one_box"], ["", "def", "plot_images", "(", "images", ",", "targets", ",", "paths", "=", "None", ",", "fname", "=", "'images.jpg'", ",", "names", "=", "None", ",", "max_size", "=", "640", ",", "max_subplots", "=", "16", ")", ":", "\n", "# Plot image grid with labels", "\n", "\n", "    ", "if", "isinstance", "(", "images", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "images", "=", "images", ".", "cpu", "(", ")", ".", "float", "(", ")", ".", "numpy", "(", ")", "\n", "", "if", "isinstance", "(", "targets", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "targets", "=", "targets", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "# un-normalise", "\n", "", "if", "np", ".", "max", "(", "images", "[", "0", "]", ")", "<=", "1", ":", "\n", "        ", "images", "*=", "255", "\n", "\n", "", "tl", "=", "3", "# line thickness", "\n", "tf", "=", "max", "(", "tl", "-", "1", ",", "1", ")", "# font thickness", "\n", "bs", ",", "_", ",", "h", ",", "w", "=", "images", ".", "shape", "# batch size, _, height, width", "\n", "bs", "=", "min", "(", "bs", ",", "max_subplots", ")", "# limit plot images", "\n", "ns", "=", "np", ".", "ceil", "(", "bs", "**", "0.5", ")", "# number of subplots (square)", "\n", "\n", "# Check if we should resize", "\n", "scale_factor", "=", "max_size", "/", "max", "(", "h", ",", "w", ")", "\n", "if", "scale_factor", "<", "1", ":", "\n", "        ", "h", "=", "math", ".", "ceil", "(", "scale_factor", "*", "h", ")", "\n", "w", "=", "math", ".", "ceil", "(", "scale_factor", "*", "w", ")", "\n", "\n", "", "colors", "=", "color_list", "(", ")", "# list of colors", "\n", "mosaic", "=", "np", ".", "full", "(", "(", "int", "(", "ns", "*", "h", ")", ",", "int", "(", "ns", "*", "w", ")", ",", "3", ")", ",", "255", ",", "dtype", "=", "np", ".", "uint8", ")", "# init", "\n", "for", "i", ",", "img", "in", "enumerate", "(", "images", ")", ":", "\n", "        ", "if", "i", "==", "max_subplots", ":", "# if last batch has fewer images than we expect", "\n", "            ", "break", "\n", "\n", "", "block_x", "=", "int", "(", "w", "*", "(", "i", "//", "ns", ")", ")", "\n", "block_y", "=", "int", "(", "h", "*", "(", "i", "%", "ns", ")", ")", "\n", "\n", "img", "=", "img", ".", "transpose", "(", "1", ",", "2", ",", "0", ")", "\n", "if", "scale_factor", "<", "1", ":", "\n", "            ", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "w", ",", "h", ")", ")", "\n", "\n", "", "mosaic", "[", "block_y", ":", "block_y", "+", "h", ",", "block_x", ":", "block_x", "+", "w", ",", ":", "]", "=", "img", "\n", "if", "len", "(", "targets", ")", ">", "0", ":", "\n", "            ", "image_targets", "=", "targets", "[", "targets", "[", ":", ",", "0", "]", "==", "i", "]", "\n", "boxes", "=", "xywh2xyxy", "(", "image_targets", "[", ":", ",", "2", ":", "6", "]", ")", ".", "T", "\n", "classes", "=", "image_targets", "[", ":", ",", "1", "]", ".", "astype", "(", "'int'", ")", "\n", "labels", "=", "image_targets", ".", "shape", "[", "1", "]", "==", "6", "# labels if no conf column", "\n", "conf", "=", "None", "if", "labels", "else", "image_targets", "[", ":", ",", "6", "]", "# check for confidence presence (label vs pred)", "\n", "\n", "boxes", "[", "[", "0", ",", "2", "]", "]", "*=", "w", "\n", "boxes", "[", "[", "0", ",", "2", "]", "]", "+=", "block_x", "\n", "boxes", "[", "[", "1", ",", "3", "]", "]", "*=", "h", "\n", "boxes", "[", "[", "1", ",", "3", "]", "]", "+=", "block_y", "\n", "for", "j", ",", "box", "in", "enumerate", "(", "boxes", ".", "T", ")", ":", "\n", "                ", "cls", "=", "int", "(", "classes", "[", "j", "]", ")", "\n", "color", "=", "colors", "[", "cls", "%", "len", "(", "colors", ")", "]", "\n", "cls", "=", "names", "[", "cls", "]", "if", "names", "else", "cls", "\n", "if", "labels", "or", "conf", "[", "j", "]", ">", "0.25", ":", "# 0.25 conf thresh", "\n", "                    ", "label", "=", "'%s'", "%", "cls", "if", "labels", "else", "'%s %.1f'", "%", "(", "cls", ",", "conf", "[", "j", "]", ")", "\n", "plot_one_box", "(", "box", ",", "mosaic", ",", "label", "=", "label", ",", "color", "=", "color", ",", "line_thickness", "=", "tl", ")", "\n", "\n", "# Draw image filename labels", "\n", "", "", "", "if", "paths", ":", "\n", "            ", "label", "=", "Path", "(", "paths", "[", "i", "]", ")", ".", "name", "[", ":", "40", "]", "# trim to 40 char", "\n", "t_size", "=", "cv2", ".", "getTextSize", "(", "label", ",", "0", ",", "fontScale", "=", "tl", "/", "3", ",", "thickness", "=", "tf", ")", "[", "0", "]", "\n", "cv2", ".", "putText", "(", "mosaic", ",", "label", ",", "(", "block_x", "+", "5", ",", "block_y", "+", "t_size", "[", "1", "]", "+", "5", ")", ",", "0", ",", "tl", "/", "3", ",", "[", "220", ",", "220", ",", "220", "]", ",", "thickness", "=", "tf", ",", "\n", "lineType", "=", "cv2", ".", "LINE_AA", ")", "\n", "\n", "# Image border", "\n", "", "cv2", ".", "rectangle", "(", "mosaic", ",", "(", "block_x", ",", "block_y", ")", ",", "(", "block_x", "+", "w", ",", "block_y", "+", "h", ")", ",", "(", "255", ",", "255", ",", "255", ")", ",", "thickness", "=", "3", ")", "\n", "\n", "", "if", "fname", ":", "\n", "        ", "r", "=", "min", "(", "1280.", "/", "max", "(", "h", ",", "w", ")", "/", "ns", ",", "1.0", ")", "# ratio to limit image size", "\n", "mosaic", "=", "cv2", ".", "resize", "(", "mosaic", ",", "(", "int", "(", "ns", "*", "w", "*", "r", ")", ",", "int", "(", "ns", "*", "h", "*", "r", ")", ")", ",", "interpolation", "=", "cv2", ".", "INTER_AREA", ")", "\n", "# cv2.imwrite(fname, cv2.cvtColor(mosaic, cv2.COLOR_BGR2RGB))  # cv2 save", "\n", "Image", ".", "fromarray", "(", "mosaic", ")", ".", "save", "(", "fname", ")", "# PIL save", "\n", "", "return", "mosaic", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_lr_scheduler": [[186, 201], ["range", "matplotlib.plot", "matplotlib.xlabel", "matplotlib.ylabel", "matplotlib.grid", "matplotlib.xlim", "matplotlib.ylim", "matplotlib.tight_layout", "matplotlib.savefig", "copy.copy", "copy.copy", "scheduler.step", "y.append", "pathlib.Path"], "function", ["None"], ["", "def", "plot_lr_scheduler", "(", "optimizer", ",", "scheduler", ",", "epochs", "=", "300", ",", "save_dir", "=", "''", ")", ":", "\n", "# Plot LR simulating training for full epochs", "\n", "    ", "optimizer", ",", "scheduler", "=", "copy", "(", "optimizer", ")", ",", "copy", "(", "scheduler", ")", "# do not modify originals", "\n", "y", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "scheduler", ".", "step", "(", ")", "\n", "y", ".", "append", "(", "optimizer", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ")", "\n", "", "plt", ".", "plot", "(", "y", ",", "'.-'", ",", "label", "=", "'LR'", ")", "\n", "plt", ".", "xlabel", "(", "'epoch'", ")", "\n", "plt", ".", "ylabel", "(", "'LR'", ")", "\n", "plt", ".", "grid", "(", ")", "\n", "plt", ".", "xlim", "(", "0", ",", "epochs", ")", "\n", "plt", ".", "ylim", "(", "0", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "Path", "(", "save_dir", ")", "/", "'LR.png'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_test_txt": [[203, 218], ["numpy.loadtxt", "utils.general.xyxy2xywh", "matplotlib.subplots", "ax.hist2d", "ax.set_aspect", "matplotlib.savefig", "matplotlib.subplots", "ax[].hist", "ax[].hist", "matplotlib.savefig"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.hist2d"], ["", "def", "plot_test_txt", "(", ")", ":", "# from utils.general import *; plot_test()", "\n", "# Plot test.txt histograms", "\n", "    ", "x", "=", "np", ".", "loadtxt", "(", "'test.txt'", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "box", "=", "xyxy2xywh", "(", "x", "[", ":", ",", ":", "4", "]", ")", "\n", "cx", ",", "cy", "=", "box", "[", ":", ",", "0", "]", ",", "box", "[", ":", ",", "1", "]", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "6", ",", "6", ")", ",", "tight_layout", "=", "True", ")", "\n", "ax", ".", "hist2d", "(", "cx", ",", "cy", ",", "bins", "=", "600", ",", "cmax", "=", "10", ",", "cmin", "=", "0", ")", "\n", "ax", ".", "set_aspect", "(", "'equal'", ")", "\n", "plt", ".", "savefig", "(", "'hist2d.png'", ",", "dpi", "=", "300", ")", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "2", ",", "figsize", "=", "(", "12", ",", "6", ")", ",", "tight_layout", "=", "True", ")", "\n", "ax", "[", "0", "]", ".", "hist", "(", "cx", ",", "bins", "=", "600", ")", "\n", "ax", "[", "1", "]", ".", "hist", "(", "cy", ",", "bins", "=", "600", ")", "\n", "plt", ".", "savefig", "(", "'hist1d.png'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_targets_txt": [[220, 231], ["matplotlib.subplots", "ax.ravel.ravel", "range", "matplotlib.savefig", "numpy.loadtxt", "ax[].hist", "ax[].legend", "ax[].set_title", "x[].mean", "x[].std"], "function", ["None"], ["", "def", "plot_targets_txt", "(", ")", ":", "# from utils.general import *; plot_targets_txt()", "\n", "# Plot targets.txt histograms", "\n", "    ", "x", "=", "np", ".", "loadtxt", "(", "'targets.txt'", ",", "dtype", "=", "np", ".", "float32", ")", ".", "T", "\n", "s", "=", "[", "'x targets'", ",", "'y targets'", ",", "'width targets'", ",", "'height targets'", "]", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "2", ",", "2", ",", "figsize", "=", "(", "8", ",", "8", ")", ",", "tight_layout", "=", "True", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "ax", "[", "i", "]", ".", "hist", "(", "x", "[", "i", "]", ",", "bins", "=", "100", ",", "label", "=", "'%.3g +/- %.3g'", "%", "(", "x", "[", "i", "]", ".", "mean", "(", ")", ",", "x", "[", "i", "]", ".", "std", "(", ")", ")", ")", "\n", "ax", "[", "i", "]", ".", "legend", "(", ")", "\n", "ax", "[", "i", "]", ".", "set_title", "(", "s", "[", "i", "]", ")", "\n", "", "plt", ".", "savefig", "(", "'targets.jpg'", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_study_txt": [[233, 263], ["matplotlib.subplots", "ax.ravel.ravel", "matplotlib.subplots", "ax2.plot", "ax2.grid", "ax2.set_xlim", "ax2.set_ylim", "ax2.set_yticks", "ax2.set_xlabel", "ax2.set_ylabel", "ax2.legend", "matplotlib.savefig", "matplotlib.savefig", "range", "ax2.plot", "numpy.arange", "f.replace", "numpy.loadtxt", "numpy.arange", "numpy.array", "ax[].plot", "ax[].set_title", "y[].argmax", "numpy.array", "pathlib.Path().stem.replace().replace", "pathlib.Path().stem.replace", "pathlib.Path"], "function", ["None"], ["", "def", "plot_study_txt", "(", "f", "=", "'study.txt'", ",", "x", "=", "None", ")", ":", "# from utils.general import *; plot_study_txt()", "\n", "# Plot study.txt generated by test.py", "\n", "    ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "2", ",", "4", ",", "figsize", "=", "(", "10", ",", "6", ")", ",", "tight_layout", "=", "True", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "\n", "fig2", ",", "ax2", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "8", ",", "4", ")", ",", "tight_layout", "=", "True", ")", "\n", "for", "f", "in", "[", "'study/study_coco_yolo%s.txt'", "%", "x", "for", "x", "in", "[", "'s'", ",", "'m'", ",", "'l'", ",", "'x'", "]", "]", ":", "\n", "        ", "y", "=", "np", ".", "loadtxt", "(", "f", ",", "dtype", "=", "np", ".", "float32", ",", "usecols", "=", "[", "0", ",", "1", ",", "2", ",", "3", ",", "7", ",", "8", ",", "9", "]", ",", "ndmin", "=", "2", ")", ".", "T", "\n", "x", "=", "np", ".", "arange", "(", "y", ".", "shape", "[", "1", "]", ")", "if", "x", "is", "None", "else", "np", ".", "array", "(", "x", ")", "\n", "s", "=", "[", "'P'", ",", "'R'", ",", "'mAP@.5'", ",", "'mAP@.5:.95'", ",", "'t_inference (ms/img)'", ",", "'t_NMS (ms/img)'", ",", "'t_total (ms/img)'", "]", "\n", "for", "i", "in", "range", "(", "7", ")", ":", "\n", "            ", "ax", "[", "i", "]", ".", "plot", "(", "x", ",", "y", "[", "i", "]", ",", "'.-'", ",", "linewidth", "=", "2", ",", "markersize", "=", "8", ")", "\n", "ax", "[", "i", "]", ".", "set_title", "(", "s", "[", "i", "]", ")", "\n", "\n", "", "j", "=", "y", "[", "3", "]", ".", "argmax", "(", ")", "+", "1", "\n", "ax2", ".", "plot", "(", "y", "[", "6", ",", ":", "j", "]", ",", "y", "[", "3", ",", ":", "j", "]", "*", "1E2", ",", "'.-'", ",", "linewidth", "=", "2", ",", "markersize", "=", "8", ",", "\n", "label", "=", "Path", "(", "f", ")", ".", "stem", ".", "replace", "(", "'study_coco_'", ",", "''", ")", ".", "replace", "(", "'yolo'", ",", "'YOLO'", ")", ")", "\n", "\n", "", "ax2", ".", "plot", "(", "1E3", "/", "np", ".", "array", "(", "[", "209", ",", "140", ",", "97", ",", "58", ",", "35", ",", "18", "]", ")", ",", "[", "34.6", ",", "40.5", ",", "43.0", ",", "47.5", ",", "49.7", ",", "51.5", "]", ",", "\n", "'k.-'", ",", "linewidth", "=", "2", ",", "markersize", "=", "8", ",", "alpha", "=", ".25", ",", "label", "=", "'EfficientDet'", ")", "\n", "\n", "ax2", ".", "grid", "(", ")", "\n", "ax2", ".", "set_xlim", "(", "0", ",", "30", ")", "\n", "ax2", ".", "set_ylim", "(", "28", ",", "50", ")", "\n", "ax2", ".", "set_yticks", "(", "np", ".", "arange", "(", "30", ",", "55", ",", "5", ")", ")", "\n", "ax2", ".", "set_xlabel", "(", "'GPU Speed (ms/img)'", ")", "\n", "ax2", ".", "set_ylabel", "(", "'COCO AP val'", ")", "\n", "ax2", ".", "legend", "(", "loc", "=", "'lower right'", ")", "\n", "plt", ".", "savefig", "(", "'study_mAP_latency.png'", ",", "dpi", "=", "300", ")", "\n", "plt", ".", "savefig", "(", "f", ".", "replace", "(", "'.txt'", ",", "'.png'", ")", ",", "dpi", "=", "300", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_labels": [[265, 295], ["int", "matplotlib.subplots", "ax.ravel.ravel", "ax[].hist", "ax[].set_xlabel", "ax[].scatter", "ax[].set_xlabel", "ax[].set_ylabel", "ax[].scatter", "ax[].set_xlabel", "ax[].set_ylabel", "matplotlib.savefig", "matplotlib.close", "labels[].transpose", "pd.DataFrame", "sns.pairplot", "matplotlib.savefig", "matplotlib.close", "c.max", "plots.hist2d", "plots.hist2d", "pathlib.Path", "b.transpose", "numpy.linspace", "dict", "dict", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.hist2d", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.hist2d"], ["", "def", "plot_labels", "(", "labels", ",", "save_dir", "=", "''", ")", ":", "\n", "# plot dataset labels", "\n", "    ", "c", ",", "b", "=", "labels", "[", ":", ",", "0", "]", ",", "labels", "[", ":", ",", "1", ":", "]", ".", "transpose", "(", ")", "# classes, boxes", "\n", "nc", "=", "int", "(", "c", ".", "max", "(", ")", "+", "1", ")", "# number of classes", "\n", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "2", ",", "2", ",", "figsize", "=", "(", "8", ",", "8", ")", ",", "tight_layout", "=", "True", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "ax", "[", "0", "]", ".", "hist", "(", "c", ",", "bins", "=", "np", ".", "linspace", "(", "0", ",", "nc", ",", "nc", "+", "1", ")", "-", "0.5", ",", "rwidth", "=", "0.8", ")", "\n", "ax", "[", "0", "]", ".", "set_xlabel", "(", "'classes'", ")", "\n", "ax", "[", "1", "]", ".", "scatter", "(", "b", "[", "0", "]", ",", "b", "[", "1", "]", ",", "c", "=", "hist2d", "(", "b", "[", "0", "]", ",", "b", "[", "1", "]", ",", "90", ")", ",", "cmap", "=", "'jet'", ")", "\n", "ax", "[", "1", "]", ".", "set_xlabel", "(", "'x'", ")", "\n", "ax", "[", "1", "]", ".", "set_ylabel", "(", "'y'", ")", "\n", "ax", "[", "2", "]", ".", "scatter", "(", "b", "[", "2", "]", ",", "b", "[", "3", "]", ",", "c", "=", "hist2d", "(", "b", "[", "2", "]", ",", "b", "[", "3", "]", ",", "90", ")", ",", "cmap", "=", "'jet'", ")", "\n", "ax", "[", "2", "]", ".", "set_xlabel", "(", "'width'", ")", "\n", "ax", "[", "2", "]", ".", "set_ylabel", "(", "'height'", ")", "\n", "plt", ".", "savefig", "(", "Path", "(", "save_dir", ")", "/", "'labels.png'", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n", "# seaborn correlogram", "\n", "try", ":", "\n", "        ", "import", "seaborn", "as", "sns", "\n", "import", "pandas", "as", "pd", "\n", "x", "=", "pd", ".", "DataFrame", "(", "b", ".", "transpose", "(", ")", ",", "columns", "=", "[", "'x'", ",", "'y'", ",", "'width'", ",", "'height'", "]", ")", "\n", "sns", ".", "pairplot", "(", "x", ",", "corner", "=", "True", ",", "diag_kind", "=", "'hist'", ",", "kind", "=", "'scatter'", ",", "markers", "=", "'o'", ",", "\n", "plot_kws", "=", "dict", "(", "s", "=", "3", ",", "edgecolor", "=", "None", ",", "linewidth", "=", "1", ",", "alpha", "=", "0.02", ")", ",", "\n", "diag_kws", "=", "dict", "(", "bins", "=", "50", ")", ")", "\n", "plt", ".", "savefig", "(", "Path", "(", "save_dir", ")", "/", "'labels_correlogram.png'", ",", "dpi", "=", "200", ")", "\n", "plt", ".", "close", "(", ")", "\n", "", "except", "Exception", "as", "e", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_evolution": [[297, 319], ["numpy.loadtxt", "utils.metrics.fitness", "matplotlib.figure", "matplotlib.rc", "matplotlib.rc", "enumerate", "matplotlib.savefig", "print", "open", "yaml.load", "yaml.load.items", "matplotlib.subplot", "matplotlib.scatter", "matplotlib.plot", "matplotlib.title", "print", "utils.metrics.fitness.max", "matplotlib.yticks", "utils.metrics.fitness.argmax", "plots.hist2d"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.hist2d"], ["", "", "def", "plot_evolution", "(", "yaml_file", "=", "'data/hyp.finetune.yaml'", ")", ":", "# from utils.general import *; plot_evolution()", "\n", "# Plot hyperparameter evolution results in evolve.txt", "\n", "    ", "with", "open", "(", "yaml_file", ")", "as", "f", ":", "\n", "        ", "hyp", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "\n", "", "x", "=", "np", ".", "loadtxt", "(", "'evolve.txt'", ",", "ndmin", "=", "2", ")", "\n", "f", "=", "fitness", "(", "x", ")", "\n", "# weights = (f - f.min()) ** 2  # for weighted results", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "10", ",", "12", ")", ",", "tight_layout", "=", "True", ")", "\n", "matplotlib", ".", "rc", "(", "'font'", ",", "**", "{", "'size'", ":", "8", "}", ")", "\n", "for", "i", ",", "(", "k", ",", "v", ")", "in", "enumerate", "(", "hyp", ".", "items", "(", ")", ")", ":", "\n", "        ", "y", "=", "x", "[", ":", ",", "i", "+", "7", "]", "\n", "# mu = (y * weights).sum() / weights.sum()  # best weighted result", "\n", "mu", "=", "y", "[", "f", ".", "argmax", "(", ")", "]", "# best single result", "\n", "plt", ".", "subplot", "(", "6", ",", "5", ",", "i", "+", "1", ")", "\n", "plt", ".", "scatter", "(", "y", ",", "f", ",", "c", "=", "hist2d", "(", "y", ",", "f", ",", "20", ")", ",", "cmap", "=", "'viridis'", ",", "alpha", "=", ".8", ",", "edgecolors", "=", "'none'", ")", "\n", "plt", ".", "plot", "(", "mu", ",", "f", ".", "max", "(", ")", ",", "'k+'", ",", "markersize", "=", "15", ")", "\n", "plt", ".", "title", "(", "'%s = %.3g'", "%", "(", "k", ",", "mu", ")", ",", "fontdict", "=", "{", "'size'", ":", "9", "}", ")", "# limit to 40 characters", "\n", "if", "i", "%", "5", "!=", "0", ":", "\n", "            ", "plt", ".", "yticks", "(", "[", "]", ")", "\n", "", "print", "(", "'%15s: %.3g'", "%", "(", "k", ",", "mu", ")", ")", "\n", "", "plt", ".", "savefig", "(", "'evolve.png'", ",", "dpi", "=", "200", ")", "\n", "print", "(", "'\\nPlot saved as evolve.png'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_results_overlay": [[321, 342], ["sorted", "range", "matplotlib.subplots", "ax.ravel.ravel", "range", "fig.savefig", "glob.glob", "glob.glob", "numpy.loadtxt", "ax[].set_title", "ax[].legend", "f.replace", "min", "ax[].plot", "ax[].set_ylabel"], "function", ["None"], ["", "def", "plot_results_overlay", "(", "start", "=", "0", ",", "stop", "=", "0", ")", ":", "# from utils.general import *; plot_results_overlay()", "\n", "# Plot training 'results*.txt', overlaying train and val losses", "\n", "    ", "s", "=", "[", "'train'", ",", "'train'", ",", "'train'", ",", "'Precision'", ",", "'mAP@0.5'", ",", "'val'", ",", "'val'", ",", "'val'", ",", "'Recall'", ",", "'mAP@0.5:0.95'", "]", "# legends", "\n", "t", "=", "[", "'Box'", ",", "'Objectness'", ",", "'Classification'", ",", "'P-R'", ",", "'mAP-F1'", "]", "# titles", "\n", "for", "f", "in", "sorted", "(", "glob", ".", "glob", "(", "'results*.txt'", ")", "+", "glob", ".", "glob", "(", "'../../Downloads/results*.txt'", ")", ")", ":", "\n", "        ", "results", "=", "np", ".", "loadtxt", "(", "f", ",", "usecols", "=", "[", "2", ",", "3", ",", "4", ",", "8", ",", "9", ",", "12", ",", "13", ",", "14", ",", "10", ",", "11", "]", ",", "ndmin", "=", "2", ")", ".", "T", "\n", "n", "=", "results", ".", "shape", "[", "1", "]", "# number of rows", "\n", "x", "=", "range", "(", "start", ",", "min", "(", "stop", ",", "n", ")", "if", "stop", "else", "n", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "5", ",", "figsize", "=", "(", "14", ",", "3.5", ")", ",", "tight_layout", "=", "True", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "for", "i", "in", "range", "(", "5", ")", ":", "\n", "            ", "for", "j", "in", "[", "i", ",", "i", "+", "5", "]", ":", "\n", "                ", "y", "=", "results", "[", "j", ",", "x", "]", "\n", "ax", "[", "i", "]", ".", "plot", "(", "x", ",", "y", ",", "marker", "=", "'.'", ",", "label", "=", "s", "[", "j", "]", ")", "\n", "# y_smooth = butter_lowpass_filtfilt(y)", "\n", "# ax[i].plot(x, np.gradient(y_smooth), marker='.', label=s[j])", "\n", "\n", "", "ax", "[", "i", "]", ".", "set_title", "(", "t", "[", "i", "]", ")", "\n", "ax", "[", "i", "]", ".", "legend", "(", ")", "\n", "ax", "[", "i", "]", ".", "set_ylabel", "(", "f", ")", "if", "i", "==", "0", "else", "None", "# add filename", "\n", "", "fig", ".", "savefig", "(", "f", ".", "replace", "(", "'.txt'", ",", "'.png'", ")", ",", "dpi", "=", "200", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.plots.plot_results": [[344, 381], ["matplotlib.subplots", "ax.ravel.ravel", "len", "enumerate", "fig.tight_layout", "ax[].legend", "fig.savefig", "os.system", "os.path.abspath", "tuple", "glob.glob", "glob.glob", "range", "range", "pathlib.Path", "str", "numpy.loadtxt", "ax[].plot", "ax[].set_title", "print", "min", "len", "len", "pathlib.Path", "pathlib.Path"], "function", ["None"], ["", "", "def", "plot_results", "(", "start", "=", "0", ",", "stop", "=", "0", ",", "bucket", "=", "''", ",", "id", "=", "(", ")", ",", "labels", "=", "(", ")", ",", "save_dir", "=", "''", ")", ":", "\n", "# from utils.general import *; plot_results(save_dir='runs/train/exp0')", "\n", "# Plot training 'results*.txt'", "\n", "    ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "2", ",", "5", ",", "figsize", "=", "(", "12", ",", "6", ")", ")", "\n", "ax", "=", "ax", ".", "ravel", "(", ")", "\n", "s", "=", "[", "'Box'", ",", "'Objectness'", ",", "'Classification'", ",", "'Precision'", ",", "'Recall'", ",", "\n", "'val Box'", ",", "'val Objectness'", ",", "'val Classification'", ",", "'mAP@0.5'", ",", "'mAP@0.5:0.95'", "]", "\n", "if", "bucket", ":", "\n", "# os.system('rm -rf storage.googleapis.com')", "\n", "# files = ['https://storage.googleapis.com/%s/results%g.txt' % (bucket, x) for x in id]", "\n", "        ", "files", "=", "[", "'%g.txt'", "%", "x", "for", "x", "in", "id", "]", "\n", "c", "=", "(", "'gsutil cp '", "+", "'%s '", "*", "len", "(", "files", ")", "+", "'.'", ")", "%", "tuple", "(", "'gs://%s/%g.txt'", "%", "(", "bucket", ",", "x", ")", "for", "x", "in", "id", ")", "\n", "os", ".", "system", "(", "c", ")", "\n", "", "else", ":", "\n", "        ", "files", "=", "glob", ".", "glob", "(", "str", "(", "Path", "(", "save_dir", ")", "/", "'*.txt'", ")", ")", "+", "glob", ".", "glob", "(", "'../../Downloads/results*.txt'", ")", "\n", "", "assert", "len", "(", "files", ")", ",", "'No results.txt files found in %s, nothing to plot.'", "%", "os", ".", "path", ".", "abspath", "(", "save_dir", ")", "\n", "for", "fi", ",", "f", "in", "enumerate", "(", "files", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "results", "=", "np", ".", "loadtxt", "(", "f", ",", "usecols", "=", "[", "2", ",", "3", ",", "4", ",", "8", ",", "9", ",", "12", ",", "13", ",", "14", ",", "10", ",", "11", "]", ",", "ndmin", "=", "2", ")", ".", "T", "\n", "n", "=", "results", ".", "shape", "[", "1", "]", "# number of rows", "\n", "x", "=", "range", "(", "start", ",", "min", "(", "stop", ",", "n", ")", "if", "stop", "else", "n", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "                ", "y", "=", "results", "[", "i", ",", "x", "]", "\n", "if", "i", "in", "[", "0", ",", "1", ",", "2", ",", "5", ",", "6", ",", "7", "]", ":", "\n", "                    ", "y", "[", "y", "==", "0", "]", "=", "np", ".", "nan", "# don't show zero loss values", "\n", "# y /= y[0]  # normalize", "\n", "", "label", "=", "labels", "[", "fi", "]", "if", "len", "(", "labels", ")", "else", "Path", "(", "f", ")", ".", "stem", "\n", "ax", "[", "i", "]", ".", "plot", "(", "x", ",", "y", ",", "marker", "=", "'.'", ",", "label", "=", "label", ",", "linewidth", "=", "1", ",", "markersize", "=", "6", ")", "\n", "ax", "[", "i", "]", ".", "set_title", "(", "s", "[", "i", "]", ")", "\n", "# if i in [5, 6, 7]:  # share train and val loss y axes", "\n", "#     ax[i].get_shared_y_axes().join(ax[i], ax[i - 5])", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "'Warning: Plotting error for %s; %s'", "%", "(", "f", ",", "e", ")", ")", "\n", "\n", "", "", "fig", ".", "tight_layout", "(", ")", "\n", "ax", "[", "1", "]", ".", "legend", "(", ")", "\n", "fig", ".", "savefig", "(", "Path", "(", "save_dir", ")", "/", "'results.png'", ",", "dpi", "=", "200", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness": [[7, 11], ["None"], "function", ["None"], ["def", "fitness", "(", "x", ")", ":", "\n", "# Model fitness as a weighted combination of metrics", "\n", "    ", "w", "=", "[", "0.0", ",", "0.0", ",", "0.1", ",", "0.9", "]", "# weights for [P, R, mAP@0.5, mAP@0.5:0.95]", "\n", "return", "(", "x", "[", ":", ",", ":", "4", "]", "*", "w", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_p": [[13, 17], ["None"], "function", ["None"], ["", "def", "fitness_p", "(", "x", ")", ":", "\n", "# Model fitness as a weighted combination of metrics", "\n", "    ", "w", "=", "[", "1.0", ",", "0.0", ",", "0.0", ",", "0.0", "]", "# weights for [P, R, mAP@0.5, mAP@0.5:0.95]", "\n", "return", "(", "x", "[", ":", ",", ":", "4", "]", "*", "w", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_r": [[19, 23], ["None"], "function", ["None"], ["", "def", "fitness_r", "(", "x", ")", ":", "\n", "# Model fitness as a weighted combination of metrics", "\n", "    ", "w", "=", "[", "0.0", ",", "1.0", ",", "0.0", ",", "0.0", "]", "# weights for [P, R, mAP@0.5, mAP@0.5:0.95]", "\n", "return", "(", "x", "[", ":", ",", ":", "4", "]", "*", "w", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_ap50": [[25, 29], ["None"], "function", ["None"], ["", "def", "fitness_ap50", "(", "x", ")", ":", "\n", "# Model fitness as a weighted combination of metrics", "\n", "    ", "w", "=", "[", "0.0", ",", "0.0", ",", "1.0", ",", "0.0", "]", "# weights for [P, R, mAP@0.5, mAP@0.5:0.95]", "\n", "return", "(", "x", "[", ":", ",", ":", "4", "]", "*", "w", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_ap": [[31, 35], ["None"], "function", ["None"], ["", "def", "fitness_ap", "(", "x", ")", ":", "\n", "# Model fitness as a weighted combination of metrics", "\n", "    ", "w", "=", "[", "0.0", ",", "0.0", ",", "0.0", ",", "1.0", "]", "# weights for [P, R, mAP@0.5, mAP@0.5:0.95]", "\n", "return", "(", "x", "[", ":", ",", ":", "4", "]", "*", "w", ")", ".", "sum", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness_f": [[37, 41], ["None"], "function", ["None"], ["", "def", "fitness_f", "(", "x", ")", ":", "\n", "# Model fitness as a weighted combination of metrics", "\n", "#w = [0.0, 0.0, 0.0, 1.0]  # weights for [P, R, mAP@0.5, mAP@0.5:0.95]", "\n", "    ", "return", "(", "(", "x", "[", ":", ",", "0", "]", "*", "x", "[", ":", ",", "1", "]", ")", "/", "(", "x", "[", ":", ",", "0", "]", "+", "x", "[", ":", ",", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.ap_per_class": [[43, 112], ["numpy.argsort", "numpy.unique", "enumerate", "numpy.linspace", "numpy.zeros", "numpy.zeros", "numpy.zeros", "np.argsort.sum", "numpy.stack", "matplotlib.subplots", "ax.plot", "ax.plot", "ax.set_xlabel", "ax.set_ylabel", "ax.set_xlim", "ax.set_ylim", "matplotlib.legend", "fig.tight_layout", "fig.savefig", "np.unique.astype", "tp[].cumsum", "numpy.interp", "numpy.interp", "range", "np.stack.mean", "metrics.compute_ap", "np.stack.append", "ap[].mean", "numpy.interp"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.compute_ap"], ["", "def", "ap_per_class", "(", "tp", ",", "conf", ",", "pred_cls", ",", "target_cls", ",", "plot", "=", "False", ",", "fname", "=", "'precision-recall_curve.png'", ")", ":", "\n", "    ", "\"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rafaelpadilla/Object-Detection-Metrics.\n    # Arguments\n        tp:  True positives (nparray, nx1 or nx10).\n        conf:  Objectness value from 0-1 (nparray).\n        pred_cls:  Predicted object classes (nparray).\n        target_cls:  True object classes (nparray).\n        plot:  Plot precision-recall curve at mAP@0.5\n        fname:  Plot filename\n    # Returns\n        The average precision as computed in py-faster-rcnn.\n    \"\"\"", "\n", "\n", "# Sort by objectness", "\n", "i", "=", "np", ".", "argsort", "(", "-", "conf", ")", "\n", "tp", ",", "conf", ",", "pred_cls", "=", "tp", "[", "i", "]", ",", "conf", "[", "i", "]", ",", "pred_cls", "[", "i", "]", "\n", "\n", "# Find unique classes", "\n", "unique_classes", "=", "np", ".", "unique", "(", "target_cls", ")", "\n", "\n", "# Create Precision-Recall curve and compute AP for each class", "\n", "px", ",", "py", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "1000", ")", ",", "[", "]", "# for plotting", "\n", "pr_score", "=", "0.1", "# score to evaluate P and R https://github.com/ultralytics/yolov3/issues/898", "\n", "s", "=", "[", "unique_classes", ".", "shape", "[", "0", "]", ",", "tp", ".", "shape", "[", "1", "]", "]", "# number class, number iou thresholds (i.e. 10 for mAP0.5...0.95)", "\n", "ap", ",", "p", ",", "r", "=", "np", ".", "zeros", "(", "s", ")", ",", "np", ".", "zeros", "(", "s", ")", ",", "np", ".", "zeros", "(", "s", ")", "\n", "for", "ci", ",", "c", "in", "enumerate", "(", "unique_classes", ")", ":", "\n", "        ", "i", "=", "pred_cls", "==", "c", "\n", "n_l", "=", "(", "target_cls", "==", "c", ")", ".", "sum", "(", ")", "# number of labels", "\n", "n_p", "=", "i", ".", "sum", "(", ")", "# number of predictions", "\n", "\n", "if", "n_p", "==", "0", "or", "n_l", "==", "0", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "# Accumulate FPs and TPs", "\n", "            ", "fpc", "=", "(", "1", "-", "tp", "[", "i", "]", ")", ".", "cumsum", "(", "0", ")", "\n", "tpc", "=", "tp", "[", "i", "]", ".", "cumsum", "(", "0", ")", "\n", "\n", "# Recall", "\n", "recall", "=", "tpc", "/", "(", "n_l", "+", "1e-16", ")", "# recall curve", "\n", "r", "[", "ci", "]", "=", "np", ".", "interp", "(", "-", "pr_score", ",", "-", "conf", "[", "i", "]", ",", "recall", "[", ":", ",", "0", "]", ")", "# r at pr_score, negative x, xp because xp decreases", "\n", "\n", "# Precision", "\n", "precision", "=", "tpc", "/", "(", "tpc", "+", "fpc", ")", "# precision curve", "\n", "p", "[", "ci", "]", "=", "np", ".", "interp", "(", "-", "pr_score", ",", "-", "conf", "[", "i", "]", ",", "precision", "[", ":", ",", "0", "]", ")", "# p at pr_score", "\n", "\n", "# AP from recall-precision curve", "\n", "for", "j", "in", "range", "(", "tp", ".", "shape", "[", "1", "]", ")", ":", "\n", "                ", "ap", "[", "ci", ",", "j", "]", ",", "mpre", ",", "mrec", "=", "compute_ap", "(", "recall", "[", ":", ",", "j", "]", ",", "precision", "[", ":", ",", "j", "]", ")", "\n", "if", "j", "==", "0", ":", "\n", "                    ", "py", ".", "append", "(", "np", ".", "interp", "(", "px", ",", "mrec", ",", "mpre", ")", ")", "# precision at mAP@0.5", "\n", "\n", "# Compute F1 score (harmonic mean of precision and recall)", "\n", "", "", "", "", "f1", "=", "2", "*", "p", "*", "r", "/", "(", "p", "+", "r", "+", "1e-16", ")", "\n", "\n", "if", "plot", ":", "\n", "        ", "py", "=", "np", ".", "stack", "(", "py", ",", "axis", "=", "1", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "5", ",", "5", ")", ")", "\n", "ax", ".", "plot", "(", "px", ",", "py", ",", "linewidth", "=", "0.5", ",", "color", "=", "'grey'", ")", "# plot(recall, precision)", "\n", "ax", ".", "plot", "(", "px", ",", "py", ".", "mean", "(", "1", ")", ",", "linewidth", "=", "2", ",", "color", "=", "'blue'", ",", "label", "=", "'all classes %.3f mAP@0.5'", "%", "ap", "[", ":", ",", "0", "]", ".", "mean", "(", ")", ")", "\n", "ax", ".", "set_xlabel", "(", "'Recall'", ")", "\n", "ax", ".", "set_ylabel", "(", "'Precision'", ")", "\n", "ax", ".", "set_xlim", "(", "0", ",", "1", ")", "\n", "ax", ".", "set_ylim", "(", "0", ",", "1", ")", "\n", "plt", ".", "legend", "(", ")", "\n", "fig", ".", "tight_layout", "(", ")", "\n", "fig", ".", "savefig", "(", "fname", ",", "dpi", "=", "200", ")", "\n", "\n", "", "return", "p", ",", "r", ",", "ap", ",", "f1", ",", "unique_classes", ".", "astype", "(", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.compute_ap": [[114, 141], ["numpy.concatenate", "numpy.concatenate", "numpy.flip", "numpy.maximum.accumulate", "numpy.linspace", "numpy.trapz", "numpy.sum", "numpy.flip", "numpy.interp", "numpy.where"], "function", ["None"], ["", "def", "compute_ap", "(", "recall", ",", "precision", ")", ":", "\n", "    ", "\"\"\" Compute the average precision, given the recall and precision curves.\n    Source: https://github.com/rbgirshick/py-faster-rcnn.\n    # Arguments\n        recall:    The recall curve (list).\n        precision: The precision curve (list).\n    # Returns\n        The average precision as computed in py-faster-rcnn.\n    \"\"\"", "\n", "\n", "# Append sentinel values to beginning and end", "\n", "mrec", "=", "np", ".", "concatenate", "(", "(", "[", "0.0", "]", ",", "recall", ",", "[", "1.0", "]", ")", ")", "\n", "mpre", "=", "np", ".", "concatenate", "(", "(", "[", "1.0", "]", ",", "precision", ",", "[", "0.0", "]", ")", ")", "\n", "\n", "# Compute the precision envelope", "\n", "mpre", "=", "np", ".", "flip", "(", "np", ".", "maximum", ".", "accumulate", "(", "np", ".", "flip", "(", "mpre", ")", ")", ")", "\n", "\n", "# Integrate area under curve", "\n", "method", "=", "'interp'", "# methods: 'continuous', 'interp'", "\n", "if", "method", "==", "'interp'", ":", "\n", "        ", "x", "=", "np", ".", "linspace", "(", "0", ",", "1", ",", "101", ")", "# 101-point interp (COCO)", "\n", "ap", "=", "np", ".", "trapz", "(", "np", ".", "interp", "(", "x", ",", "mrec", ",", "mpre", ")", ",", "x", ")", "# integrate", "\n", "", "else", ":", "# 'continuous'", "\n", "        ", "i", "=", "np", ".", "where", "(", "mrec", "[", "1", ":", "]", "!=", "mrec", "[", ":", "-", "1", "]", ")", "[", "0", "]", "# points where x axis (recall) changes", "\n", "ap", "=", "np", ".", "sum", "(", "(", "mrec", "[", "i", "+", "1", "]", "-", "mrec", "[", "i", "]", ")", "*", "mpre", "[", "i", "+", "1", "]", ")", "# area under curve", "\n", "\n", "", "return", "ap", ",", "mpre", ",", "mrec", "\n", "", ""]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.gsutil_getsize": [[12, 16], ["subprocess.check_output().decode", "len", "eval", "subprocess.check_output", "subprocess.check_output().decode.split"], "function", ["None"], ["def", "gsutil_getsize", "(", "url", "=", "''", ")", ":", "\n", "# gs://bucket/file size https://cloud.google.com/storage/docs/gsutil/commands/du", "\n", "    ", "s", "=", "subprocess", ".", "check_output", "(", "'gsutil du %s'", "%", "url", ",", "shell", "=", "True", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "return", "eval", "(", "s", ".", "split", "(", "' '", ")", "[", "0", "]", ")", "if", "len", "(", "s", ")", "else", "0", "# bytes", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.attempt_download": [[18, 36], ["weights.strip().replace.strip().replace", "pathlib.Path", "weights.strip().replace.strip", "os.path.isfile", "print", "torch.hub.download_url_to_file", "os.path.exists", "print", "print", "os.path.getsize"], "function", ["None"], ["", "def", "attempt_download", "(", "weights", ")", ":", "\n", "# Attempt to download pretrained weights if not found locally", "\n", "    ", "weights", "=", "weights", ".", "strip", "(", ")", ".", "replace", "(", "\"'\"", ",", "''", ")", "\n", "file", "=", "Path", "(", "weights", ")", ".", "name", "\n", "\n", "msg", "=", "weights", "+", "' missing, try downloading from https://github.com/WongKinYiu/yolor/releases/'", "\n", "models", "=", "[", "'yolor_p6.pt'", ",", "'yolor_w6.pt'", "]", "# available models", "\n", "\n", "if", "file", "in", "models", "and", "not", "os", ".", "path", ".", "isfile", "(", "weights", ")", ":", "\n", "\n", "        ", "try", ":", "# GitHub", "\n", "            ", "url", "=", "'https://github.com/WongKinYiu/yolor/releases/download/v1.0/'", "+", "file", "\n", "print", "(", "'Downloading %s to %s...'", "%", "(", "url", ",", "weights", ")", ")", "\n", "torch", ".", "hub", ".", "download_url_to_file", "(", "url", ",", "weights", ")", "\n", "assert", "os", ".", "path", ".", "exists", "(", "weights", ")", "and", "os", ".", "path", ".", "getsize", "(", "weights", ")", ">", "1E6", "# check", "\n", "", "except", "Exception", "as", "e", ":", "# GCP", "\n", "            ", "print", "(", "'ERROR: Download failure.'", ")", "\n", "print", "(", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.attempt_load": [[38, 52], ["Ensemble", "isinstance", "google_utils.attempt_download", "Ensemble.append", "len", "print", "[].float().fuse().eval", "setattr", "getattr", "[].float().fuse", "[].float", "torch.load"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.attempt_download", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.fuse"], ["", "", "", "def", "attempt_load", "(", "weights", ",", "map_location", "=", "None", ")", ":", "\n", "# Loads an ensemble of models weights=[a,b,c] or a single model weights=[a] or weights=a", "\n", "    ", "model", "=", "Ensemble", "(", ")", "\n", "for", "w", "in", "weights", "if", "isinstance", "(", "weights", ",", "list", ")", "else", "[", "weights", "]", ":", "\n", "        ", "attempt_download", "(", "w", ")", "\n", "model", ".", "append", "(", "torch", ".", "load", "(", "w", ",", "map_location", "=", "map_location", ")", "[", "'model'", "]", ".", "float", "(", ")", ".", "fuse", "(", ")", ".", "eval", "(", ")", ")", "# load FP32 model", "\n", "\n", "", "if", "len", "(", "model", ")", "==", "1", ":", "\n", "        ", "return", "model", "[", "-", "1", "]", "# return model", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Ensemble created with %s\\n'", "%", "weights", ")", "\n", "for", "k", "in", "[", "'names'", ",", "'stride'", "]", ":", "\n", "            ", "setattr", "(", "model", ",", "k", ",", "getattr", "(", "model", "[", "-", "1", "]", ",", "k", ")", ")", "\n", "", "return", "model", "# return ensemble", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.gdrive_download": [[54, 86], ["time.time", "print", "os.system", "os.path.exists", "os.system", "name.endswith", "print", "os.path.exists", "os.remove", "os.path.exists", "os.remove", "os.path.exists", "os.remove", "print", "print", "os.system", "os.remove", "platform.system", "os.path.exists", "os.remove", "google_utils.get_token", "time.time"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.get_token"], ["", "", "def", "gdrive_download", "(", "id", "=", "'1n_oKgR81BJtqk75b00eAjdv03qVCQn2f'", ",", "name", "=", "'coco128.zip'", ")", ":", "\n", "# Downloads a file from Google Drive. from utils.google_utils import *; gdrive_download()", "\n", "    ", "t", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'Downloading https://drive.google.com/uc?export=download&id=%s as %s... '", "%", "(", "id", ",", "name", ")", ",", "end", "=", "''", ")", "\n", "os", ".", "remove", "(", "name", ")", "if", "os", ".", "path", ".", "exists", "(", "name", ")", "else", "None", "# remove existing", "\n", "os", ".", "remove", "(", "'cookie'", ")", "if", "os", ".", "path", ".", "exists", "(", "'cookie'", ")", "else", "None", "\n", "\n", "# Attempt file download", "\n", "out", "=", "\"NUL\"", "if", "platform", ".", "system", "(", ")", "==", "\"Windows\"", "else", "\"/dev/null\"", "\n", "os", ".", "system", "(", "'curl -c ./cookie -s -L \"drive.google.com/uc?export=download&id=%s\" > %s '", "%", "(", "id", ",", "out", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "'cookie'", ")", ":", "# large file", "\n", "        ", "s", "=", "'curl -Lb ./cookie \"drive.google.com/uc?export=download&confirm=%s&id=%s\" -o %s'", "%", "(", "get_token", "(", ")", ",", "id", ",", "name", ")", "\n", "", "else", ":", "# small file", "\n", "        ", "s", "=", "'curl -s -L -o %s \"drive.google.com/uc?export=download&id=%s\"'", "%", "(", "name", ",", "id", ")", "\n", "", "r", "=", "os", ".", "system", "(", "s", ")", "# execute, capture return", "\n", "os", ".", "remove", "(", "'cookie'", ")", "if", "os", ".", "path", ".", "exists", "(", "'cookie'", ")", "else", "None", "\n", "\n", "# Error check", "\n", "if", "r", "!=", "0", ":", "\n", "        ", "os", ".", "remove", "(", "name", ")", "if", "os", ".", "path", ".", "exists", "(", "name", ")", "else", "None", "# remove partial", "\n", "print", "(", "'Download error '", ")", "# raise Exception('Download error')", "\n", "return", "r", "\n", "\n", "# Unzip if archive", "\n", "", "if", "name", ".", "endswith", "(", "'.zip'", ")", ":", "\n", "        ", "print", "(", "'unzipping... '", ",", "end", "=", "''", ")", "\n", "os", ".", "system", "(", "'unzip -q %s'", "%", "name", ")", "# unzip", "\n", "os", ".", "remove", "(", "name", ")", "# remove zip to free space", "\n", "\n", "", "print", "(", "'Done (%.1fs)'", "%", "(", "time", ".", "time", "(", ")", "-", "t", ")", ")", "\n", "return", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.get_token": [[88, 94], ["open", "line.split"], "function", ["None"], ["", "def", "get_token", "(", "cookie", "=", "\"./cookie\"", ")", ":", "\n", "    ", "with", "open", "(", "cookie", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "if", "\"download\"", "in", "line", ":", "\n", "                ", "return", "line", ".", "split", "(", ")", "[", "-", "1", "]", "\n", "", "", "", "return", "\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.autoanchor.check_anchor_order": [[10, 19], ["m.anchor_grid.prod().view", "da.sign", "ds.sign", "print", "m.anchors.flip", "m.anchor_grid.flip", "m.anchor_grid.prod"], "function", ["None"], ["def", "check_anchor_order", "(", "m", ")", ":", "\n", "# Check anchor order against stride order for YOLOv5 Detect() module m, and correct if necessary", "\n", "    ", "a", "=", "m", ".", "anchor_grid", ".", "prod", "(", "-", "1", ")", ".", "view", "(", "-", "1", ")", "# anchor area", "\n", "da", "=", "a", "[", "-", "1", "]", "-", "a", "[", "0", "]", "# delta a", "\n", "ds", "=", "m", ".", "stride", "[", "-", "1", "]", "-", "m", ".", "stride", "[", "0", "]", "# delta s", "\n", "if", "da", ".", "sign", "(", ")", "!=", "ds", ".", "sign", "(", ")", ":", "# same order", "\n", "        ", "print", "(", "'Reversing anchor order'", ")", "\n", "m", ".", "anchors", "[", ":", "]", "=", "m", ".", "anchors", ".", "flip", "(", "0", ")", "\n", "m", ".", "anchor_grid", "[", ":", "]", "=", "m", ".", "anchor_grid", ".", "flip", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.autoanchor.check_anchors": [[21, 53], ["print", "numpy.random.uniform", "torch.tensor().float", "autoanchor.check_anchors.metric"], "function", ["None"], ["", "", "def", "check_anchors", "(", "dataset", ",", "model", ",", "thr", "=", "4.0", ",", "imgsz", "=", "640", ")", ":", "\n", "# Check anchor fit to data, recompute if necessary", "\n", "    ", "print", "(", "'\\nAnalyzing anchors... '", ",", "end", "=", "''", ")", "\n", "m", "=", "model", ".", "module", ".", "model", "[", "-", "1", "]", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", ".", "model", "[", "-", "1", "]", "# Detect()", "\n", "shapes", "=", "imgsz", "*", "dataset", ".", "shapes", "/", "dataset", ".", "shapes", ".", "max", "(", "1", ",", "keepdims", "=", "True", ")", "\n", "scale", "=", "np", ".", "random", ".", "uniform", "(", "0.9", ",", "1.1", ",", "size", "=", "(", "shapes", ".", "shape", "[", "0", "]", ",", "1", ")", ")", "# augment scale", "\n", "wh", "=", "torch", ".", "tensor", "(", "np", ".", "concatenate", "(", "[", "l", "[", ":", ",", "3", ":", "5", "]", "*", "s", "for", "s", ",", "l", "in", "zip", "(", "shapes", "*", "scale", ",", "dataset", ".", "labels", ")", "]", ")", ")", ".", "float", "(", ")", "# wh", "\n", "\n", "def", "metric", "(", "k", ")", ":", "# compute metric", "\n", "        ", "r", "=", "wh", "[", ":", ",", "None", "]", "/", "k", "[", "None", "]", "\n", "x", "=", "torch", ".", "min", "(", "r", ",", "1.", "/", "r", ")", ".", "min", "(", "2", ")", "[", "0", "]", "# ratio metric", "\n", "best", "=", "x", ".", "max", "(", "1", ")", "[", "0", "]", "# best_x", "\n", "aat", "=", "(", "x", ">", "1.", "/", "thr", ")", ".", "float", "(", ")", ".", "sum", "(", "1", ")", ".", "mean", "(", ")", "# anchors above threshold", "\n", "bpr", "=", "(", "best", ">", "1.", "/", "thr", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "# best possible recall", "\n", "return", "bpr", ",", "aat", "\n", "\n", "", "bpr", ",", "aat", "=", "metric", "(", "m", ".", "anchor_grid", ".", "clone", "(", ")", ".", "cpu", "(", ")", ".", "view", "(", "-", "1", ",", "2", ")", ")", "\n", "print", "(", "'anchors/target = %.2f, Best Possible Recall (BPR) = %.4f'", "%", "(", "aat", ",", "bpr", ")", ",", "end", "=", "''", ")", "\n", "if", "bpr", "<", "0.98", ":", "# threshold to recompute", "\n", "        ", "print", "(", "'. Attempting to improve anchors, please wait...'", ")", "\n", "na", "=", "m", ".", "anchor_grid", ".", "numel", "(", ")", "//", "2", "# number of anchors", "\n", "new_anchors", "=", "kmean_anchors", "(", "dataset", ",", "n", "=", "na", ",", "img_size", "=", "imgsz", ",", "thr", "=", "thr", ",", "gen", "=", "1000", ",", "verbose", "=", "False", ")", "\n", "new_bpr", "=", "metric", "(", "new_anchors", ".", "reshape", "(", "-", "1", ",", "2", ")", ")", "[", "0", "]", "\n", "if", "new_bpr", ">", "bpr", ":", "# replace anchors", "\n", "            ", "new_anchors", "=", "torch", ".", "tensor", "(", "new_anchors", ",", "device", "=", "m", ".", "anchors", ".", "device", ")", ".", "type_as", "(", "m", ".", "anchors", ")", "\n", "m", ".", "anchor_grid", "[", ":", "]", "=", "new_anchors", ".", "clone", "(", ")", ".", "view_as", "(", "m", ".", "anchor_grid", ")", "# for inference", "\n", "m", ".", "anchors", "[", ":", "]", "=", "new_anchors", ".", "clone", "(", ")", ".", "view_as", "(", "m", ".", "anchors", ")", "/", "m", ".", "stride", ".", "to", "(", "m", ".", "anchors", ".", "device", ")", ".", "view", "(", "-", "1", ",", "1", ",", "1", ")", "# loss", "\n", "check_anchor_order", "(", "m", ")", "\n", "print", "(", "'New anchors saved to model. Update model *.yaml to use these anchors in the future.'", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Original anchors better than new anchors. Proceeding with original anchors.'", ")", "\n", "", "", "print", "(", "''", ")", "# newline", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.autoanchor.kmean_anchors": [[55, 153], ["isinstance", "numpy.concatenate", "print", "torch.tensor.std", "scipy.cluster.vq.kmeans", "torch.tensor", "torch.tensor", "autoanchor.kmean_anchors.print_results"], "function", ["None"], ["", "def", "kmean_anchors", "(", "path", "=", "'./data/coco128.yaml'", ",", "n", "=", "9", ",", "img_size", "=", "640", ",", "thr", "=", "4.0", ",", "gen", "=", "1000", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "\"\"\" Creates kmeans-evolved anchors from training dataset\n\n        Arguments:\n            path: path to dataset *.yaml, or a loaded dataset\n            n: number of anchors\n            img_size: image size used for training\n            thr: anchor-label wh ratio threshold hyperparameter hyp['anchor_t'] used for training, default=4.0\n            gen: generations to evolve anchors using genetic algorithm\n            verbose: print all results\n\n        Return:\n            k: kmeans evolved anchors\n\n        Usage:\n            from utils.general import *; _ = kmean_anchors()\n    \"\"\"", "\n", "thr", "=", "1.", "/", "thr", "\n", "\n", "def", "metric", "(", "k", ",", "wh", ")", ":", "# compute metrics", "\n", "        ", "r", "=", "wh", "[", ":", ",", "None", "]", "/", "k", "[", "None", "]", "\n", "x", "=", "torch", ".", "min", "(", "r", ",", "1.", "/", "r", ")", ".", "min", "(", "2", ")", "[", "0", "]", "# ratio metric", "\n", "# x = wh_iou(wh, torch.tensor(k))  # iou metric", "\n", "return", "x", ",", "x", ".", "max", "(", "1", ")", "[", "0", "]", "# x, best_x", "\n", "\n", "", "def", "anchor_fitness", "(", "k", ")", ":", "# mutation fitness", "\n", "        ", "_", ",", "best", "=", "metric", "(", "torch", ".", "tensor", "(", "k", ",", "dtype", "=", "torch", ".", "float32", ")", ",", "wh", ")", "\n", "return", "(", "best", "*", "(", "best", ">", "thr", ")", ".", "float", "(", ")", ")", ".", "mean", "(", ")", "# fitness", "\n", "\n", "", "def", "print_results", "(", "k", ")", ":", "\n", "        ", "k", "=", "k", "[", "np", ".", "argsort", "(", "k", ".", "prod", "(", "1", ")", ")", "]", "# sort small to large", "\n", "x", ",", "best", "=", "metric", "(", "k", ",", "wh0", ")", "\n", "bpr", ",", "aat", "=", "(", "best", ">", "thr", ")", ".", "float", "(", ")", ".", "mean", "(", ")", ",", "(", "x", ">", "thr", ")", ".", "float", "(", ")", ".", "mean", "(", ")", "*", "n", "# best possible recall, anch > thr", "\n", "print", "(", "'thr=%.2f: %.4f best possible recall, %.2f anchors past thr'", "%", "(", "thr", ",", "bpr", ",", "aat", ")", ")", "\n", "print", "(", "'n=%g, img_size=%s, metric_all=%.3f/%.3f-mean/best, past_thr=%.3f-mean: '", "%", "\n", "(", "n", ",", "img_size", ",", "x", ".", "mean", "(", ")", ",", "best", ".", "mean", "(", ")", ",", "x", "[", "x", ">", "thr", "]", ".", "mean", "(", ")", ")", ",", "end", "=", "''", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "k", ")", ":", "\n", "            ", "print", "(", "'%i,%i'", "%", "(", "round", "(", "x", "[", "0", "]", ")", ",", "round", "(", "x", "[", "1", "]", ")", ")", ",", "end", "=", "',  '", "if", "i", "<", "len", "(", "k", ")", "-", "1", "else", "'\\n'", ")", "# use in *.cfg", "\n", "", "return", "k", "\n", "\n", "", "if", "isinstance", "(", "path", ",", "str", ")", ":", "# *.yaml file", "\n", "        ", "with", "open", "(", "path", ")", "as", "f", ":", "\n", "            ", "data_dict", "=", "yaml", ".", "load", "(", "f", ",", "Loader", "=", "yaml", ".", "FullLoader", ")", "# model dict", "\n", "", "from", "utils", ".", "datasets", "import", "LoadImagesAndLabels", "\n", "dataset", "=", "LoadImagesAndLabels", "(", "data_dict", "[", "'train'", "]", ",", "augment", "=", "True", ",", "rect", "=", "True", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "path", "# dataset", "\n", "\n", "# Get label wh", "\n", "", "shapes", "=", "img_size", "*", "dataset", ".", "shapes", "/", "dataset", ".", "shapes", ".", "max", "(", "1", ",", "keepdims", "=", "True", ")", "\n", "wh0", "=", "np", ".", "concatenate", "(", "[", "l", "[", ":", ",", "3", ":", "5", "]", "*", "s", "for", "s", ",", "l", "in", "zip", "(", "shapes", ",", "dataset", ".", "labels", ")", "]", ")", "# wh", "\n", "\n", "# Filter", "\n", "i", "=", "(", "wh0", "<", "3.0", ")", ".", "any", "(", "1", ")", ".", "sum", "(", ")", "\n", "if", "i", ":", "\n", "        ", "print", "(", "'WARNING: Extremely small objects found. '", "\n", "'%g of %g labels are < 3 pixels in width or height.'", "%", "(", "i", ",", "len", "(", "wh0", ")", ")", ")", "\n", "", "wh", "=", "wh0", "[", "(", "wh0", ">=", "2.0", ")", ".", "any", "(", "1", ")", "]", "# filter > 2 pixels", "\n", "\n", "# Kmeans calculation", "\n", "print", "(", "'Running kmeans for %g anchors on %g points...'", "%", "(", "n", ",", "len", "(", "wh", ")", ")", ")", "\n", "s", "=", "wh", ".", "std", "(", "0", ")", "# sigmas for whitening", "\n", "k", ",", "dist", "=", "kmeans", "(", "wh", "/", "s", ",", "n", ",", "iter", "=", "30", ")", "# points, mean distance", "\n", "k", "*=", "s", "\n", "wh", "=", "torch", ".", "tensor", "(", "wh", ",", "dtype", "=", "torch", ".", "float32", ")", "# filtered", "\n", "wh0", "=", "torch", ".", "tensor", "(", "wh0", ",", "dtype", "=", "torch", ".", "float32", ")", "# unfiltered", "\n", "k", "=", "print_results", "(", "k", ")", "\n", "\n", "# Plot", "\n", "# k, d = [None] * 20, [None] * 20", "\n", "# for i in tqdm(range(1, 21)):", "\n", "#     k[i-1], d[i-1] = kmeans(wh / s, i)  # points, mean distance", "\n", "# fig, ax = plt.subplots(1, 2, figsize=(14, 7))", "\n", "# ax = ax.ravel()", "\n", "# ax[0].plot(np.arange(1, 21), np.array(d) ** 2, marker='.')", "\n", "# fig, ax = plt.subplots(1, 2, figsize=(14, 7))  # plot wh", "\n", "# ax[0].hist(wh[wh[:, 0]<100, 0],400)", "\n", "# ax[1].hist(wh[wh[:, 1]<100, 1],400)", "\n", "# fig.tight_layout()", "\n", "# fig.savefig('wh.png', dpi=200)", "\n", "\n", "# Evolve", "\n", "npr", "=", "np", ".", "random", "\n", "f", ",", "sh", ",", "mp", ",", "s", "=", "anchor_fitness", "(", "k", ")", ",", "k", ".", "shape", ",", "0.9", ",", "0.1", "# fitness, generations, mutation prob, sigma", "\n", "pbar", "=", "tqdm", "(", "range", "(", "gen", ")", ",", "desc", "=", "'Evolving anchors with Genetic Algorithm'", ")", "# progress bar", "\n", "for", "_", "in", "pbar", ":", "\n", "        ", "v", "=", "np", ".", "ones", "(", "sh", ")", "\n", "while", "(", "v", "==", "1", ")", ".", "all", "(", ")", ":", "# mutate until a change occurs (prevent duplicates)", "\n", "            ", "v", "=", "(", "(", "npr", ".", "random", "(", "sh", ")", "<", "mp", ")", "*", "npr", ".", "random", "(", ")", "*", "npr", ".", "randn", "(", "*", "sh", ")", "*", "s", "+", "1", ")", ".", "clip", "(", "0.3", ",", "3.0", ")", "\n", "", "kg", "=", "(", "k", ".", "copy", "(", ")", "*", "v", ")", ".", "clip", "(", "min", "=", "2.0", ")", "\n", "fg", "=", "anchor_fitness", "(", "kg", ")", "\n", "if", "fg", ">", "f", ":", "\n", "            ", "f", ",", "k", "=", "fg", ",", "kg", ".", "copy", "(", ")", "\n", "pbar", ".", "desc", "=", "'Evolving anchors with Genetic Algorithm: fitness = %.4f'", "%", "f", "\n", "if", "verbose", ":", "\n", "                ", "print_results", "(", "k", ")", "\n", "\n", "", "", "", "return", "print_results", "(", "k", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Reorg.forward": [[36, 38], ["torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "x", "[", "...", ",", ":", ":", "2", ",", ":", ":", "2", "]", ",", "x", "[", "...", ",", "1", ":", ":", "2", ",", ":", ":", "2", "]", ",", "x", "[", "...", ",", ":", ":", "2", ",", "1", ":", ":", "2", "]", ",", "x", "[", "...", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Flatten.forward": [[48, 50], ["x.view", "x.size"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Concat.__init__": [[54, 57], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dimension", "=", "1", ")", ":", "\n", "        ", "super", "(", "Concat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "d", "=", "dimension", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Concat.forward": [[58, 60], ["torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "x", ",", "self", ".", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat.__init__": [[63, 67], ["torch.nn.Module.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "FeatureConcat", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "self", ".", "multiple", "=", "len", "(", "layers", ")", ">", "1", "# multiple layers flag", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat.forward": [[68, 70], ["torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "outputs", "[", "i", "]", "for", "i", "in", "self", ".", "layers", "]", ",", "1", ")", "if", "self", ".", "multiple", "else", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat2.__init__": [[73, 77], ["torch.nn.Module.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "FeatureConcat2", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "self", ".", "multiple", "=", "len", "(", "layers", ")", ">", "1", "# multiple layers flag", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat2.forward": [[78, 80], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "outputs[].detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", ",", "outputs", "[", "self", ".", "layers", "[", "1", "]", "]", ".", "detach", "(", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat3.__init__": [[83, 87], ["torch.nn.Module.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "FeatureConcat3", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "self", ".", "multiple", "=", "len", "(", "layers", ")", ">", "1", "# multiple layers flag", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat3.forward": [[88, 90], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "outputs[].detach", "outputs[].detach"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", ",", "outputs", "[", "self", ".", "layers", "[", "1", "]", "]", ".", "detach", "(", ")", ",", "outputs", "[", "self", ".", "layers", "[", "2", "]", "]", ".", "detach", "(", ")", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat_l.__init__": [[93, 97], ["torch.nn.Module.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "FeatureConcat_l", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "self", ".", "multiple", "=", "len", "(", "layers", ")", ">", "1", "# multiple layers flag", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.FeatureConcat_l.forward": [[98, 100], ["torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "outputs", "[", "i", "]", "[", ":", ",", ":", "outputs", "[", "i", "]", ".", "shape", "[", "1", "]", "//", "2", ",", ":", ",", ":", "]", "for", "i", "in", "self", ".", "layers", "]", ",", "1", ")", "if", "self", ".", "multiple", "else", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "[", ":", ",", ":", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", ".", "shape", "[", "1", "]", "//", "2", ",", ":", ",", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.WeightedFeatureFusion.__init__": [[103, 110], ["torch.nn.Module.__init__", "len", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ",", "weight", "=", "False", ")", ":", "\n", "        ", "super", "(", "WeightedFeatureFusion", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "self", ".", "weight", "=", "weight", "# apply weights boolean", "\n", "self", ".", "n", "=", "len", "(", "layers", ")", "+", "1", "# number of layers", "\n", "if", "weight", ":", "\n", "            ", "self", ".", "w", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "self", ".", "n", ")", ",", "requires_grad", "=", "True", ")", "# layer weights", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.WeightedFeatureFusion.forward": [[111, 132], ["range", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "# Weights", "\n", "        ", "if", "self", ".", "weight", ":", "\n", "            ", "w", "=", "torch", ".", "sigmoid", "(", "self", ".", "w", ")", "*", "(", "2", "/", "self", ".", "n", ")", "# sigmoid weights (0-1)", "\n", "x", "=", "x", "*", "w", "[", "0", "]", "\n", "\n", "# Fusion", "\n", "", "nx", "=", "x", ".", "shape", "[", "1", "]", "# input channels", "\n", "for", "i", "in", "range", "(", "self", ".", "n", "-", "1", ")", ":", "\n", "            ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "i", "]", "]", "*", "w", "[", "i", "+", "1", "]", "if", "self", ".", "weight", "else", "outputs", "[", "self", ".", "layers", "[", "i", "]", "]", "# feature to add", "\n", "na", "=", "a", ".", "shape", "[", "1", "]", "# feature channels", "\n", "\n", "# Adjust channels", "\n", "if", "nx", "==", "na", ":", "# same shape", "\n", "                ", "x", "=", "x", "+", "a", "\n", "", "elif", "nx", ">", "na", ":", "# slice input", "\n", "                ", "x", "[", ":", ",", ":", "na", "]", "=", "x", "[", ":", ",", ":", "na", "]", "+", "a", "# or a = nn.ZeroPad2d((0, 0, 0, 0, 0, dc))(a); x = x + a", "\n", "", "else", ":", "# slice feature", "\n", "                ", "x", "=", "x", "+", "a", "[", ":", ",", ":", "nx", "]", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MixConv2d.__init__": [[135, 157], ["torch.nn.Module.__init__", "len", "torch.nn.ModuleList", "torch.nn.ModuleList", "torch.linspace().floor", "torch.linspace().floor", "torch.linspace().floor", "torch.linspace().floor", "np.eye", "np.roll", "[].round().astype", "np.array", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.linspace", "torch.linspace", "torch.linspace", "torch.linspace", "range", "[].round", "range", "np.linalg.lstsq"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_ch", ",", "out_ch", ",", "k", "=", "(", "3", ",", "5", ",", "7", ")", ",", "stride", "=", "1", ",", "dilation", "=", "1", ",", "bias", "=", "True", ",", "method", "=", "'equal_params'", ")", ":", "\n", "        ", "super", "(", "MixConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "groups", "=", "len", "(", "k", ")", "\n", "if", "method", "==", "'equal_ch'", ":", "# equal channels per group", "\n", "            ", "i", "=", "torch", ".", "linspace", "(", "0", ",", "groups", "-", "1E-6", ",", "out_ch", ")", ".", "floor", "(", ")", "# out_ch indices", "\n", "ch", "=", "[", "(", "i", "==", "g", ")", ".", "sum", "(", ")", "for", "g", "in", "range", "(", "groups", ")", "]", "\n", "", "else", ":", "# 'equal_params': equal parameter count per group", "\n", "            ", "b", "=", "[", "out_ch", "]", "+", "[", "0", "]", "*", "groups", "\n", "a", "=", "np", ".", "eye", "(", "groups", "+", "1", ",", "groups", ",", "k", "=", "-", "1", ")", "\n", "a", "-=", "np", ".", "roll", "(", "a", ",", "1", ",", "axis", "=", "1", ")", "\n", "a", "*=", "np", ".", "array", "(", "k", ")", "**", "2", "\n", "a", "[", "0", "]", "=", "1", "\n", "ch", "=", "np", ".", "linalg", ".", "lstsq", "(", "a", ",", "b", ",", "rcond", "=", "None", ")", "[", "0", "]", ".", "round", "(", ")", ".", "astype", "(", "int", ")", "# solve for equal weight indices, ax = b", "\n", "\n", "", "self", ".", "m", "=", "nn", ".", "ModuleList", "(", "[", "nn", ".", "Conv2d", "(", "in_channels", "=", "in_ch", ",", "\n", "out_channels", "=", "ch", "[", "g", "]", ",", "\n", "kernel_size", "=", "k", "[", "g", "]", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "k", "[", "g", "]", "//", "2", ",", "# 'same' pad", "\n", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ")", "for", "g", "in", "range", "(", "groups", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MixConv2d.forward": [[158, 160], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "m"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "cat", "(", "[", "m", "(", "x", ")", "for", "m", "in", "self", ".", "m", "]", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.SwishImplementation.forward": [[164, 168], ["ctx.save_for_backward", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "x", ")", "\n", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.SwishImplementation.backward": [[169, 174], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "x", "=", "ctx", ".", "saved_tensors", "[", "0", "]", "\n", "sx", "=", "torch", ".", "sigmoid", "(", "x", ")", "# sigmoid(ctx)", "\n", "return", "grad_output", "*", "(", "sx", "*", "(", "1", "+", "x", "*", "(", "1", "-", "sx", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MishImplementation.forward": [[177, 181], ["ctx.save_for_backward", "x.mul", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.softplus", "torch.softplus"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "ctx", ",", "x", ")", ":", "\n", "        ", "ctx", ".", "save_for_backward", "(", "x", ")", "\n", "return", "x", ".", "mul", "(", "torch", ".", "tanh", "(", "F", ".", "softplus", "(", "x", ")", ")", ")", "# x * tanh(ln(1 + exp(x)))", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MishImplementation.backward": [[182, 188], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.softplus().tanh", "torch.softplus().tanh", "torch.softplus", "torch.softplus"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "backward", "(", "ctx", ",", "grad_output", ")", ":", "\n", "        ", "x", "=", "ctx", ".", "saved_tensors", "[", "0", "]", "\n", "sx", "=", "torch", ".", "sigmoid", "(", "x", ")", "\n", "fx", "=", "F", ".", "softplus", "(", "x", ")", ".", "tanh", "(", ")", "\n", "return", "grad_output", "*", "(", "fx", "+", "x", "*", "sx", "*", "(", "1", "-", "fx", "*", "fx", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MemoryEfficientSwish.forward": [[191, 193], ["SwishImplementation.apply"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "SwishImplementation", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.MemoryEfficientMish.forward": [[196, 198], ["MishImplementation.apply"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "MishImplementation", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Swish.forward": [[201, 203], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.HardSwish.forward": [[206, 208], ["torch.hardtanh", "torch.hardtanh"], "methods", ["None"], ["    ", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "*", "F", ".", "hardtanh", "(", "x", "+", "3", ",", "0.", ",", "6.", ",", "True", ")", "/", "6.", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d.__init__": [[211, 232], ["torch.nn.Module.__init__", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.constant_", "torch.nn.init.constant_", "layers.DeformConv2d.p_conv.register_backward_hook", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.init.constant_", "torch.nn.init.constant_", "layers.DeformConv2d.m_conv.register_backward_hook"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "inc", ",", "outc", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "1", ",", "bias", "=", "None", ",", "modulation", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            modulation (bool, optional): If True, Modulated Defomable Convolution (Deformable ConvNets v2).\n        \"\"\"", "\n", "super", "(", "DeformConv2d", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "padding", "=", "padding", "\n", "self", ".", "stride", "=", "stride", "\n", "self", ".", "zero_padding", "=", "nn", ".", "ZeroPad2d", "(", "padding", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "inc", ",", "outc", ",", "kernel_size", "=", "kernel_size", ",", "stride", "=", "kernel_size", ",", "bias", "=", "bias", ")", "\n", "\n", "self", ".", "p_conv", "=", "nn", ".", "Conv2d", "(", "inc", ",", "2", "*", "kernel_size", "*", "kernel_size", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "stride", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "p_conv", ".", "weight", ",", "0", ")", "\n", "self", ".", "p_conv", ".", "register_backward_hook", "(", "self", ".", "_set_lr", ")", "\n", "\n", "self", ".", "modulation", "=", "modulation", "\n", "if", "modulation", ":", "\n", "            ", "self", ".", "m_conv", "=", "nn", ".", "Conv2d", "(", "inc", ",", "kernel_size", "*", "kernel_size", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "stride", "=", "stride", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "self", ".", "m_conv", ".", "weight", ",", "0", ")", "\n", "self", ".", "m_conv", ".", "register_backward_hook", "(", "self", ".", "_set_lr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._set_lr": [[233, 237], ["range", "range", "len", "len"], "methods", ["None"], ["", "", "@", "staticmethod", "\n", "def", "_set_lr", "(", "module", ",", "grad_input", ",", "grad_output", ")", ":", "\n", "        ", "grad_input", "=", "(", "grad_input", "[", "i", "]", "*", "0.1", "for", "i", "in", "range", "(", "len", "(", "grad_input", ")", ")", ")", "\n", "grad_output", "=", "(", "grad_output", "[", "i", "]", "*", "0.1", "for", "i", "in", "range", "(", "len", "(", "grad_output", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d.forward": [[238, 295], ["layers.DeformConv2d.p_conv", "layers.DeformConv2d.data.type", "layers.DeformConv2d._get_p", "torch.cat.contiguous().permute", "torch.cat.contiguous().permute", "torch.cat.detach().floor", "torch.cat.detach().floor", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat().long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.DeformConv2d._get_x_q", "layers.DeformConv2d._get_x_q", "layers.DeformConv2d._get_x_q", "layers.DeformConv2d._get_x_q", "layers.DeformConv2d._reshape_x_offset", "layers.DeformConv2d.conv", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "layers.DeformConv2d.size", "layers.DeformConv2d.zero_padding", "torch.cat.contiguous().permute", "torch.cat.contiguous().permute", "torch.cat.unsqueeze", "torch.cat.unsqueeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layers.DeformConv2d.m_conv", "torch.cat.contiguous", "torch.cat.contiguous", "torch.cat.detach", "torch.cat.detach", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "g_rt.unsqueeze", "q_lt[].type_as", "q_lt[].type_as", "q_rb[].type_as", "q_rb[].type_as", "q_lb[].type_as", "q_lb[].type_as", "q_rt[].type_as", "q_rt[].type_as", "g_lb.unsqueeze", "torch.cat.contiguous", "torch.cat.contiguous", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "torch.clamp", "layers.DeformConv2d.size", "layers.DeformConv2d.size", "g_lt.unsqueeze", "g_rb.unsqueeze", "range", "layers.DeformConv2d.size", "layers.DeformConv2d.size", "layers.DeformConv2d.size", "layers.DeformConv2d.size", "layers.DeformConv2d.size"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_p", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_x_q", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_x_q", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_x_q", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_x_q", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._reshape_x_offset"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "offset", "=", "self", ".", "p_conv", "(", "x", ")", "\n", "if", "self", ".", "modulation", ":", "\n", "            ", "m", "=", "torch", ".", "sigmoid", "(", "self", ".", "m_conv", "(", "x", ")", ")", "\n", "\n", "", "dtype", "=", "offset", ".", "data", ".", "type", "(", ")", "\n", "ks", "=", "self", ".", "kernel_size", "\n", "N", "=", "offset", ".", "size", "(", "1", ")", "//", "2", "\n", "\n", "if", "self", ".", "padding", ":", "\n", "            ", "x", "=", "self", ".", "zero_padding", "(", "x", ")", "\n", "\n", "# (b, 2N, h, w)", "\n", "", "p", "=", "self", ".", "_get_p", "(", "offset", ",", "dtype", ")", "\n", "\n", "# (b, h, w, 2N)", "\n", "p", "=", "p", ".", "contiguous", "(", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "q_lt", "=", "p", ".", "detach", "(", ")", ".", "floor", "(", ")", "\n", "q_rb", "=", "q_lt", "+", "1", "\n", "\n", "q_lt", "=", "torch", ".", "cat", "(", "[", "torch", ".", "clamp", "(", "q_lt", "[", "...", ",", ":", "N", "]", ",", "0", ",", "x", ".", "size", "(", "2", ")", "-", "1", ")", ",", "torch", ".", "clamp", "(", "q_lt", "[", "...", ",", "N", ":", "]", ",", "0", ",", "x", ".", "size", "(", "3", ")", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", ".", "long", "(", ")", "\n", "q_rb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "clamp", "(", "q_rb", "[", "...", ",", ":", "N", "]", ",", "0", ",", "x", ".", "size", "(", "2", ")", "-", "1", ")", ",", "torch", ".", "clamp", "(", "q_rb", "[", "...", ",", "N", ":", "]", ",", "0", ",", "x", ".", "size", "(", "3", ")", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", ".", "long", "(", ")", "\n", "q_lb", "=", "torch", ".", "cat", "(", "[", "q_lt", "[", "...", ",", ":", "N", "]", ",", "q_rb", "[", "...", ",", "N", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "q_rt", "=", "torch", ".", "cat", "(", "[", "q_rb", "[", "...", ",", ":", "N", "]", ",", "q_lt", "[", "...", ",", "N", ":", "]", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# clip p", "\n", "p", "=", "torch", ".", "cat", "(", "[", "torch", ".", "clamp", "(", "p", "[", "...", ",", ":", "N", "]", ",", "0", ",", "x", ".", "size", "(", "2", ")", "-", "1", ")", ",", "torch", ".", "clamp", "(", "p", "[", "...", ",", "N", ":", "]", ",", "0", ",", "x", ".", "size", "(", "3", ")", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# bilinear kernel (b, h, w, N)", "\n", "g_lt", "=", "(", "1", "+", "(", "q_lt", "[", "...", ",", ":", "N", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", ":", "N", "]", ")", ")", "*", "(", "1", "+", "(", "q_lt", "[", "...", ",", "N", ":", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", "N", ":", "]", ")", ")", "\n", "g_rb", "=", "(", "1", "-", "(", "q_rb", "[", "...", ",", ":", "N", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", ":", "N", "]", ")", ")", "*", "(", "1", "-", "(", "q_rb", "[", "...", ",", "N", ":", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", "N", ":", "]", ")", ")", "\n", "g_lb", "=", "(", "1", "+", "(", "q_lb", "[", "...", ",", ":", "N", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", ":", "N", "]", ")", ")", "*", "(", "1", "-", "(", "q_lb", "[", "...", ",", "N", ":", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", "N", ":", "]", ")", ")", "\n", "g_rt", "=", "(", "1", "-", "(", "q_rt", "[", "...", ",", ":", "N", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", ":", "N", "]", ")", ")", "*", "(", "1", "+", "(", "q_rt", "[", "...", ",", "N", ":", "]", ".", "type_as", "(", "p", ")", "-", "p", "[", "...", ",", "N", ":", "]", ")", ")", "\n", "\n", "# (b, c, h, w, N)", "\n", "x_q_lt", "=", "self", ".", "_get_x_q", "(", "x", ",", "q_lt", ",", "N", ")", "\n", "x_q_rb", "=", "self", ".", "_get_x_q", "(", "x", ",", "q_rb", ",", "N", ")", "\n", "x_q_lb", "=", "self", ".", "_get_x_q", "(", "x", ",", "q_lb", ",", "N", ")", "\n", "x_q_rt", "=", "self", ".", "_get_x_q", "(", "x", ",", "q_rt", ",", "N", ")", "\n", "\n", "# (b, c, h, w, N)", "\n", "x_offset", "=", "g_lt", ".", "unsqueeze", "(", "dim", "=", "1", ")", "*", "x_q_lt", "+", "g_rb", ".", "unsqueeze", "(", "dim", "=", "1", ")", "*", "x_q_rb", "+", "g_lb", ".", "unsqueeze", "(", "dim", "=", "1", ")", "*", "x_q_lb", "+", "g_rt", ".", "unsqueeze", "(", "dim", "=", "1", ")", "*", "x_q_rt", "\n", "\n", "# modulation", "\n", "if", "self", ".", "modulation", ":", "\n", "            ", "m", "=", "m", ".", "contiguous", "(", ")", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "\n", "m", "=", "m", ".", "unsqueeze", "(", "dim", "=", "1", ")", "\n", "m", "=", "torch", ".", "cat", "(", "[", "m", "for", "_", "in", "range", "(", "x_offset", ".", "size", "(", "1", ")", ")", "]", ",", "dim", "=", "1", ")", "\n", "x_offset", "*=", "m", "\n", "\n", "", "x_offset", "=", "self", ".", "_reshape_x_offset", "(", "x_offset", ",", "ks", ")", "\n", "out", "=", "self", ".", "conv", "(", "x_offset", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_p_n": [[296, 305], ["torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "p_n.view().type.view().type.view().type", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "p_n.view().type.view().type.view"], "methods", ["None"], ["", "def", "_get_p_n", "(", "self", ",", "N", ",", "dtype", ")", ":", "\n", "        ", "p_n_x", ",", "p_n_y", "=", "torch", ".", "meshgrid", "(", "\n", "torch", ".", "arange", "(", "-", "(", "self", ".", "kernel_size", "-", "1", ")", "//", "2", ",", "(", "self", ".", "kernel_size", "-", "1", ")", "//", "2", "+", "1", ")", ",", "\n", "torch", ".", "arange", "(", "-", "(", "self", ".", "kernel_size", "-", "1", ")", "//", "2", ",", "(", "self", ".", "kernel_size", "-", "1", ")", "//", "2", "+", "1", ")", ")", "\n", "# (2N, 1)", "\n", "p_n", "=", "torch", ".", "cat", "(", "[", "torch", ".", "flatten", "(", "p_n_x", ")", ",", "torch", ".", "flatten", "(", "p_n_y", ")", "]", ",", "0", ")", "\n", "p_n", "=", "p_n", ".", "view", "(", "1", ",", "2", "*", "N", ",", "1", ",", "1", ")", ".", "type", "(", "dtype", ")", "\n", "\n", "return", "p_n", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_p_0": [[306, 315], ["torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.meshgrid", "torch.flatten().view().repeat", "torch.flatten().view().repeat", "torch.flatten().view().repeat", "torch.flatten().view().repeat", "torch.flatten().view().repeat", "torch.flatten().view().repeat", "torch.flatten().view().repeat", "torch.flatten().view().repeat", "torch.cat().type", "torch.cat().type", "torch.cat().type", "torch.cat().type", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "torch.flatten().view", "torch.flatten().view", "torch.flatten().view", "torch.flatten().view", "torch.flatten().view", "torch.flatten().view", "torch.flatten().view", "torch.flatten().view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten"], "methods", ["None"], ["", "def", "_get_p_0", "(", "self", ",", "h", ",", "w", ",", "N", ",", "dtype", ")", ":", "\n", "        ", "p_0_x", ",", "p_0_y", "=", "torch", ".", "meshgrid", "(", "\n", "torch", ".", "arange", "(", "1", ",", "h", "*", "self", ".", "stride", "+", "1", ",", "self", ".", "stride", ")", ",", "\n", "torch", ".", "arange", "(", "1", ",", "w", "*", "self", ".", "stride", "+", "1", ",", "self", ".", "stride", ")", ")", "\n", "p_0_x", "=", "torch", ".", "flatten", "(", "p_0_x", ")", ".", "view", "(", "1", ",", "1", ",", "h", ",", "w", ")", ".", "repeat", "(", "1", ",", "N", ",", "1", ",", "1", ")", "\n", "p_0_y", "=", "torch", ".", "flatten", "(", "p_0_y", ")", ".", "view", "(", "1", ",", "1", ",", "h", ",", "w", ")", ".", "repeat", "(", "1", ",", "N", ",", "1", ",", "1", ")", "\n", "p_0", "=", "torch", ".", "cat", "(", "[", "p_0_x", ",", "p_0_y", "]", ",", "1", ")", ".", "type", "(", "dtype", ")", "\n", "\n", "return", "p_0", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_p": [[316, 325], ["layers.DeformConv2d._get_p_n", "layers.DeformConv2d._get_p_0", "offset.size", "offset.size", "offset.size"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_p_n", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_p_0"], ["", "def", "_get_p", "(", "self", ",", "offset", ",", "dtype", ")", ":", "\n", "        ", "N", ",", "h", ",", "w", "=", "offset", ".", "size", "(", "1", ")", "//", "2", ",", "offset", ".", "size", "(", "2", ")", ",", "offset", ".", "size", "(", "3", ")", "\n", "\n", "# (1, 2N, 1, 1)", "\n", "p_n", "=", "self", ".", "_get_p_n", "(", "N", ",", "dtype", ")", "\n", "# (1, 2N, h, w)", "\n", "p_0", "=", "self", ".", "_get_p_0", "(", "h", ",", "w", ",", "N", ",", "dtype", ")", "\n", "p", "=", "p_0", "+", "p_n", "+", "offset", "\n", "return", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._get_x_q": [[326, 341], ["q.size", "x.contiguous().view.contiguous().view.size", "x.contiguous().view.contiguous().view.size", "x.contiguous().view.contiguous().view.contiguous().view", "index.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand().contiguous().view", "x.contiguous().view.contiguous().view.gather().contiguous().view", "x.contiguous().view.contiguous().view.contiguous", "index.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand().contiguous", "x.contiguous().view.contiguous().view.gather().contiguous", "index.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand", "x.contiguous().view.contiguous().view.gather", "index.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze", "index.contiguous().unsqueeze().expand().contiguous().view.contiguous().unsqueeze().expand().contiguous().view.contiguous"], "methods", ["None"], ["", "def", "_get_x_q", "(", "self", ",", "x", ",", "q", ",", "N", ")", ":", "\n", "        ", "b", ",", "h", ",", "w", ",", "_", "=", "q", ".", "size", "(", ")", "\n", "padded_w", "=", "x", ".", "size", "(", "3", ")", "\n", "c", "=", "x", ".", "size", "(", "1", ")", "\n", "# (b, c, h*w)", "\n", "x", "=", "x", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "c", ",", "-", "1", ")", "\n", "\n", "# (b, h, w, N)", "\n", "index", "=", "q", "[", "...", ",", ":", "N", "]", "*", "padded_w", "+", "q", "[", "...", ",", "N", ":", "]", "# offset_x*w + offset_y", "\n", "# (b, c, h*w*N)", "\n", "index", "=", "index", ".", "contiguous", "(", ")", ".", "unsqueeze", "(", "dim", "=", "1", ")", ".", "expand", "(", "-", "1", ",", "c", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "c", ",", "-", "1", ")", "\n", "\n", "x_offset", "=", "x", ".", "gather", "(", "dim", "=", "-", "1", ",", "index", "=", "index", ")", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "c", ",", "h", ",", "w", ",", "N", ")", "\n", "\n", "return", "x_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.DeformConv2d._reshape_x_offset": [[342, 349], ["x_offset.contiguous().view.contiguous().view.size", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "x_offset.contiguous().view.contiguous().view.contiguous().view", "x_offset[].contiguous().view", "x_offset.contiguous().view.contiguous().view.contiguous", "range", "x_offset[].contiguous"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_reshape_x_offset", "(", "x_offset", ",", "ks", ")", ":", "\n", "        ", "b", ",", "c", ",", "h", ",", "w", ",", "N", "=", "x_offset", ".", "size", "(", ")", "\n", "x_offset", "=", "torch", ".", "cat", "(", "[", "x_offset", "[", "...", ",", "s", ":", "s", "+", "ks", "]", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "c", ",", "h", ",", "w", "*", "ks", ")", "for", "s", "in", "range", "(", "0", ",", "N", ",", "ks", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "x_offset", "=", "x_offset", ".", "contiguous", "(", ")", ".", "view", "(", "b", ",", "c", ",", "h", "*", "ks", ",", "w", "*", "ks", ")", "\n", "\n", "return", "x_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.GAP.__init__": [[352, 355], ["torch.nn.Module.__init__", "torch.nn.AdaptiveAvgPool2d", "torch.nn.AdaptiveAvgPool2d"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "GAP", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "avg_pool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "1", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.GAP.forward": [[355, 358], ["layers.GAP.avg_pool"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "#b, c, _, _ = x.size()        ", "\n", "        ", "return", "self", ".", "avg_pool", "(", "x", ")", "#.view(b, c)", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Silence.__init__": [[361, 363], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "Silence", ",", "self", ")", ".", "__init__", "(", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Silence.forward": [[363, 365], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ScaleChannel.__init__": [[368, 371], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "ScaleChannel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ScaleChannel.forward": [[372, 375], ["x.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "\n", "return", "x", ".", "expand_as", "(", "a", ")", "*", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ShiftChannel.__init__": [[378, 381], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "ShiftChannel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ShiftChannel.forward": [[382, 385], ["a.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "\n", "return", "a", ".", "expand_as", "(", "x", ")", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ShiftChannel2D.__init__": [[388, 391], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "ShiftChannel2D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ShiftChannel2D.forward": [[392, 395], ["outputs[].view", "outputs[].view.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "a", ".", "expand_as", "(", "x", ")", "+", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ControlChannel.__init__": [[398, 401], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "ControlChannel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ControlChannel.forward": [[402, 405], ["a.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "\n", "return", "a", ".", "expand_as", "(", "x", ")", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ControlChannel2D.__init__": [[408, 411], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "ControlChannel2D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ControlChannel2D.forward": [[412, 415], ["outputs[].view", "outputs[].view.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "a", ".", "expand_as", "(", "x", ")", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.AlternateChannel.__init__": [[418, 421], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "AlternateChannel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.AlternateChannel.forward": [[422, 425], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "a.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "\n", "return", "torch", ".", "cat", "(", "[", "a", ".", "expand_as", "(", "x", ")", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.AlternateChannel2D.__init__": [[428, 431], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "AlternateChannel2D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.AlternateChannel2D.forward": [[432, 435], ["outputs[].view", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "outputs[].view.expand_as"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "torch", ".", "cat", "(", "[", "a", ".", "expand_as", "(", "x", ")", ",", "x", "]", ",", "dim", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.SelectChannel.__init__": [[438, 441], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "SelectChannel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.SelectChannel.forward": [[442, 445], ["a.sigmoid().expand_as", "a.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "\n", "return", "a", ".", "sigmoid", "(", ")", ".", "expand_as", "(", "x", ")", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.SelectChannel2D.__init__": [[448, 451], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "SelectChannel2D", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.SelectChannel2D.forward": [[452, 455], ["outputs[].view", "outputs[].view.sigmoid().expand_as", "outputs[].view.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", ".", "view", "(", "1", ",", "-", "1", ",", "1", ",", "1", ")", "\n", "return", "a", ".", "sigmoid", "(", ")", ".", "expand_as", "(", "x", ")", "*", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ScaleSpatial.__init__": [[458, 461], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "layers", ")", ":", "\n", "        ", "super", "(", "ScaleSpatial", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layers", "=", "layers", "# layer indices", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ScaleSpatial.forward": [[462, 465], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "outputs", ")", ":", "\n", "        ", "a", "=", "outputs", "[", "self", ".", "layers", "[", "0", "]", "]", "\n", "return", "x", "*", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ImplicitA.__init__": [[468, 473], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ")", ":", "\n", "        ", "super", "(", "ImplicitA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "implicit", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "channel", ",", "1", ",", "1", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "implicit", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ImplicitA.forward": [[474, 476], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "implicit", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ImplicitC.__init__": [[479, 484], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ")", ":", "\n", "        ", "super", "(", "ImplicitC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "implicit", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "channel", ",", "1", ",", "1", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "implicit", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ImplicitC.forward": [[485, 487], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "implicit", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ImplicitM.__init__": [[490, 495], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "channel", ")", ":", "\n", "        ", "super", "(", "ImplicitM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "implicit", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "channel", ",", "1", ",", "1", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "implicit", ",", "mean", "=", "1.", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.ImplicitM.forward": [[496, 498], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "implicit", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Implicit2DA.__init__": [[502, 507], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "atom", ",", "channel", ")", ":", "\n", "        ", "super", "(", "Implicit2DA", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "implicit", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "atom", ",", "channel", ",", "1", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "implicit", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Implicit2DA.forward": [[508, 510], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "implicit", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Implicit2DC.__init__": [[513, 518], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "atom", ",", "channel", ")", ":", "\n", "        ", "super", "(", "Implicit2DC", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "implicit", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "1", ",", "atom", ",", "channel", ",", "1", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "implicit", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Implicit2DC.forward": [[519, 521], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "implicit", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Implicit2DM.__init__": [[524, 529], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.init.normal_", "torch.nn.init.normal_", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "atom", ",", "channel", ")", ":", "\n", "        ", "super", "(", "Implicit2DM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "channel", "=", "channel", "\n", "self", ".", "implicit", "=", "nn", ".", "Parameter", "(", "torch", ".", "ones", "(", "1", ",", "atom", ",", "channel", ",", "1", ")", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "self", ".", "implicit", ",", "mean", "=", "1.", ",", "std", "=", ".02", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.Implicit2DM.forward": [[530, 532], ["None"], "methods", ["None"], ["", "def", "forward", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "implicit", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.layers.make_divisible": [[40, 44], ["math.ceil"], "function", ["None"], ["", "", "def", "make_divisible", "(", "v", ",", "divisor", ")", ":", "\n", "# Function ensures all layers have a channel number that is divisible by 8", "\n", "# https://github.com/tensorflow/models/blob/master/research/slim/nets/mobilenet/mobilenet.py", "\n", "    ", "return", "math", ".", "ceil", "(", "v", "/", "divisor", ")", "*", "divisor", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.BCEBlurWithLogitsLoss.__init__": [[17, 21], ["torch.Module.__init__", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "alpha", "=", "0.05", ")", ":", "\n", "        ", "super", "(", "BCEBlurWithLogitsLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_fcn", "=", "nn", ".", "BCEWithLogitsLoss", "(", "reduction", "=", "'none'", ")", "# must be nn.BCEWithLogitsLoss()", "\n", "self", ".", "alpha", "=", "alpha", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.BCEBlurWithLogitsLoss.forward": [[22, 30], ["loss.BCEBlurWithLogitsLoss.BCEBlurWithLogitsLoss.loss_fcn", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "loss.BCEBlurWithLogitsLoss.BCEBlurWithLogitsLoss.mean", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pred", ",", "true", ")", ":", "\n", "        ", "loss", "=", "self", ".", "loss_fcn", "(", "pred", ",", "true", ")", "\n", "pred", "=", "torch", ".", "sigmoid", "(", "pred", ")", "# prob from logits", "\n", "dx", "=", "pred", "-", "true", "# reduce only missing label effects", "\n", "# dx = (pred - true).abs()  # reduce missing label and false label effects", "\n", "alpha_factor", "=", "1", "-", "torch", ".", "exp", "(", "(", "dx", "-", "1", ")", "/", "(", "self", ".", "alpha", "+", "1e-4", ")", ")", "\n", "loss", "*=", "alpha_factor", "\n", "return", "loss", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.FocalLoss.__init__": [[34, 41], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "loss_fcn", ",", "gamma", "=", "1.5", ",", "alpha", "=", "0.25", ")", ":", "\n", "        ", "super", "(", "FocalLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "loss_fcn", "=", "loss_fcn", "# must be nn.BCEWithLogitsLoss()", "\n", "self", ".", "gamma", "=", "gamma", "\n", "self", ".", "alpha", "=", "alpha", "\n", "self", ".", "reduction", "=", "loss_fcn", ".", "reduction", "\n", "self", ".", "loss_fcn", ".", "reduction", "=", "'none'", "# required to apply FL to each element", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.FocalLoss.forward": [[42, 60], ["loss.FocalLoss.FocalLoss.loss_fcn", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "loss.FocalLoss.FocalLoss.mean", "loss.FocalLoss.FocalLoss.sum"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "pred", ",", "true", ")", ":", "\n", "        ", "loss", "=", "self", ".", "loss_fcn", "(", "pred", ",", "true", ")", "\n", "# p_t = torch.exp(-loss)", "\n", "# loss *= self.alpha * (1.000001 - p_t) ** self.gamma  # non-zero power for gradient stability", "\n", "\n", "# TF implementation https://github.com/tensorflow/addons/blob/v0.7.1/tensorflow_addons/losses/focal_loss.py", "\n", "pred_prob", "=", "torch", ".", "sigmoid", "(", "pred", ")", "# prob from logits", "\n", "p_t", "=", "true", "*", "pred_prob", "+", "(", "1", "-", "true", ")", "*", "(", "1", "-", "pred_prob", ")", "\n", "alpha_factor", "=", "true", "*", "self", ".", "alpha", "+", "(", "1", "-", "true", ")", "*", "(", "1", "-", "self", ".", "alpha", ")", "\n", "modulating_factor", "=", "(", "1.0", "-", "p_t", ")", "**", "self", ".", "gamma", "\n", "loss", "*=", "alpha_factor", "*", "modulating_factor", "\n", "\n", "if", "self", ".", "reduction", "==", "'mean'", ":", "\n", "            ", "return", "loss", ".", "mean", "(", ")", "\n", "", "elif", "self", ".", "reduction", "==", "'sum'", ":", "\n", "            ", "return", "loss", ".", "sum", "(", ")", "\n", "", "else", ":", "# 'none'", "\n", "            ", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.smooth_BCE": [[10, 13], ["None"], "function", ["None"], ["def", "smooth_BCE", "(", "eps", "=", "0.1", ")", ":", "# https://github.com/ultralytics/yolov3/issues/238#issuecomment-598028441", "\n", "# return positive, negative label smoothing BCE targets", "\n", "    ", "return", "1.0", "-", "0.5", "*", "eps", ",", "0.5", "*", "eps", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.compute_loss": [[62, 125], ["loss.build_targets", "torch.BCEWithLogitsLoss().to", "torch.BCEWithLogitsLoss().to", "loss.smooth_BCE", "len", "enumerate", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros_like", "torch.zeros_like", "torch.cat().detach", "torch.cat().detach", "torch.BCEWithLogitsLoss", "torch.BCEWithLogitsLoss", "loss.FocalLoss", "loss.FocalLoss", "torch.cat().to", "torch.cat().to", "utils.general.bbox_iou", "nn.BCEWithLogitsLoss().to.", "torch.full_like", "torch.full_like", "nn.BCEWithLogitsLoss().to.", "torch.cat", "torch.cat", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "ps[].sigmoid", "torch.cat", "torch.cat", "utils.general.bbox_iou.detach().clamp().type", "ps[].sigmoid", "utils.general.bbox_iou.detach().clamp", "range", "utils.general.bbox_iou.detach"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.build_targets", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.smooth_BCE", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.bbox_iou"], ["", "", "", "def", "compute_loss", "(", "p", ",", "targets", ",", "model", ")", ":", "# predictions, targets, model", "\n", "    ", "device", "=", "targets", ".", "device", "\n", "#print(device)", "\n", "lcls", ",", "lbox", ",", "lobj", "=", "torch", ".", "zeros", "(", "1", ",", "device", "=", "device", ")", ",", "torch", ".", "zeros", "(", "1", ",", "device", "=", "device", ")", ",", "torch", ".", "zeros", "(", "1", ",", "device", "=", "device", ")", "\n", "tcls", ",", "tbox", ",", "indices", ",", "anchors", "=", "build_targets", "(", "p", ",", "targets", ",", "model", ")", "# targets", "\n", "h", "=", "model", ".", "hyp", "# hyperparameters", "\n", "\n", "# Define criteria", "\n", "BCEcls", "=", "nn", ".", "BCEWithLogitsLoss", "(", "pos_weight", "=", "torch", ".", "Tensor", "(", "[", "h", "[", "'cls_pw'", "]", "]", ")", ")", ".", "to", "(", "device", ")", "\n", "BCEobj", "=", "nn", ".", "BCEWithLogitsLoss", "(", "pos_weight", "=", "torch", ".", "Tensor", "(", "[", "h", "[", "'obj_pw'", "]", "]", ")", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Class label smoothing https://arxiv.org/pdf/1902.04103.pdf eqn 3", "\n", "cp", ",", "cn", "=", "smooth_BCE", "(", "eps", "=", "0.0", ")", "\n", "\n", "# Focal loss", "\n", "g", "=", "h", "[", "'fl_gamma'", "]", "# focal loss gamma", "\n", "if", "g", ">", "0", ":", "\n", "        ", "BCEcls", ",", "BCEobj", "=", "FocalLoss", "(", "BCEcls", ",", "g", ")", ",", "FocalLoss", "(", "BCEobj", ",", "g", ")", "\n", "\n", "# Losses", "\n", "", "nt", "=", "0", "# number of targets", "\n", "no", "=", "len", "(", "p", ")", "# number of outputs", "\n", "balance", "=", "[", "4.0", ",", "1.0", ",", "0.4", "]", "if", "no", "==", "3", "else", "[", "4.0", ",", "1.0", ",", "0.4", ",", "0.1", "]", "# P3-5 or P3-6", "\n", "balance", "=", "[", "4.0", ",", "1.0", ",", "0.5", ",", "0.4", ",", "0.1", "]", "if", "no", "==", "5", "else", "balance", "\n", "for", "i", ",", "pi", "in", "enumerate", "(", "p", ")", ":", "# layer index, layer predictions", "\n", "        ", "b", ",", "a", ",", "gj", ",", "gi", "=", "indices", "[", "i", "]", "# image, anchor, gridy, gridx", "\n", "tobj", "=", "torch", ".", "zeros_like", "(", "pi", "[", "...", ",", "0", "]", ",", "device", "=", "device", ")", "# target obj", "\n", "\n", "n", "=", "b", ".", "shape", "[", "0", "]", "# number of targets", "\n", "if", "n", ":", "\n", "            ", "nt", "+=", "n", "# cumulative targets", "\n", "ps", "=", "pi", "[", "b", ",", "a", ",", "gj", ",", "gi", "]", "# prediction subset corresponding to targets", "\n", "\n", "# Regression", "\n", "pxy", "=", "ps", "[", ":", ",", ":", "2", "]", ".", "sigmoid", "(", ")", "*", "2.", "-", "0.5", "\n", "pwh", "=", "(", "ps", "[", ":", ",", "2", ":", "4", "]", ".", "sigmoid", "(", ")", "*", "2", ")", "**", "2", "*", "anchors", "[", "i", "]", "\n", "pbox", "=", "torch", ".", "cat", "(", "(", "pxy", ",", "pwh", ")", ",", "1", ")", ".", "to", "(", "device", ")", "# predicted box", "\n", "iou", "=", "bbox_iou", "(", "pbox", ".", "T", ",", "tbox", "[", "i", "]", ",", "x1y1x2y2", "=", "False", ",", "CIoU", "=", "True", ")", "# iou(prediction, target)", "\n", "lbox", "+=", "(", "1.0", "-", "iou", ")", ".", "mean", "(", ")", "# iou loss", "\n", "\n", "# Objectness", "\n", "tobj", "[", "b", ",", "a", ",", "gj", ",", "gi", "]", "=", "(", "1.0", "-", "model", ".", "gr", ")", "+", "model", ".", "gr", "*", "iou", ".", "detach", "(", ")", ".", "clamp", "(", "0", ")", ".", "type", "(", "tobj", ".", "dtype", ")", "# iou ratio", "\n", "\n", "# Classification", "\n", "if", "model", ".", "nc", ">", "1", ":", "# cls loss (only if multiple classes)", "\n", "                ", "t", "=", "torch", ".", "full_like", "(", "ps", "[", ":", ",", "5", ":", "]", ",", "cn", ",", "device", "=", "device", ")", "# targets", "\n", "t", "[", "range", "(", "n", ")", ",", "tcls", "[", "i", "]", "]", "=", "cp", "\n", "lcls", "+=", "BCEcls", "(", "ps", "[", ":", ",", "5", ":", "]", ",", "t", ")", "# BCE", "\n", "\n", "# Append targets to text file", "\n", "# with open('targets.txt', 'a') as file:", "\n", "#     [file.write('%11.5g ' * 4 % tuple(x) + '\\n') for x in torch.cat((txy[i], twh[i]), 1)]", "\n", "\n", "", "", "lobj", "+=", "BCEobj", "(", "pi", "[", "...", ",", "4", "]", ",", "tobj", ")", "*", "balance", "[", "i", "]", "# obj loss", "\n", "\n", "", "s", "=", "3", "/", "no", "# output count scaling", "\n", "lbox", "*=", "h", "[", "'box'", "]", "*", "s", "\n", "lobj", "*=", "h", "[", "'obj'", "]", "*", "s", "*", "(", "1.4", "if", "no", ">=", "4", "else", "1.", ")", "\n", "lcls", "*=", "h", "[", "'cls'", "]", "*", "s", "\n", "bs", "=", "tobj", ".", "shape", "[", "0", "]", "# batch size", "\n", "\n", "loss", "=", "lbox", "+", "lobj", "+", "lcls", "\n", "return", "loss", "*", "bs", ",", "torch", ".", "cat", "(", "(", "lbox", ",", "lobj", ",", "lcls", ",", "loss", ")", ")", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.loss.build_targets": [[127, 173], ["torch.ones", "torch.ones", "torch.tensor().float", "torch.tensor().float", "utils.torch_utils.is_parallel", "enumerate", "indices.append", "tbox.append", "anch.append", "tcls.append", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.zeros_like", "torch.zeros_like", "t[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "gj.clamp_", "gi.clamp_", "torch.arange().view", "torch.arange().view", "torch.max().max", "torch.max().max", "t.repeat", "torch.arange", "torch.arange", "torch.max", "torch.max"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.is_parallel"], ["", "def", "build_targets", "(", "p", ",", "targets", ",", "model", ")", ":", "\n", "    ", "nt", "=", "targets", ".", "shape", "[", "0", "]", "# number of anchors, targets", "\n", "tcls", ",", "tbox", ",", "indices", ",", "anch", "=", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", "\n", "gain", "=", "torch", ".", "ones", "(", "6", ",", "device", "=", "targets", ".", "device", ")", "# normalized to gridspace gain", "\n", "off", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "0", "]", ",", "[", "0", ",", "1", "]", ",", "[", "-", "1", ",", "0", "]", ",", "[", "0", ",", "-", "1", "]", "]", ",", "device", "=", "targets", ".", "device", ")", ".", "float", "(", ")", "# overlap offsets", "\n", "\n", "g", "=", "0.5", "# offset", "\n", "multi_gpu", "=", "is_parallel", "(", "model", ")", "\n", "for", "i", ",", "jj", "in", "enumerate", "(", "model", ".", "module", ".", "yolo_layers", "if", "multi_gpu", "else", "model", ".", "yolo_layers", ")", ":", "\n", "# get number of grid points and anchor vec for this yolo layer", "\n", "        ", "anchors", "=", "model", ".", "module", ".", "module_list", "[", "jj", "]", ".", "anchor_vec", "if", "multi_gpu", "else", "model", ".", "module_list", "[", "jj", "]", ".", "anchor_vec", "\n", "gain", "[", "2", ":", "]", "=", "torch", ".", "tensor", "(", "p", "[", "i", "]", ".", "shape", ")", "[", "[", "3", ",", "2", ",", "3", ",", "2", "]", "]", "# xyxy gain", "\n", "\n", "# Match targets to anchors", "\n", "a", ",", "t", ",", "offsets", "=", "[", "]", ",", "targets", "*", "gain", ",", "0", "\n", "if", "nt", ":", "\n", "            ", "na", "=", "anchors", ".", "shape", "[", "0", "]", "# number of anchors", "\n", "at", "=", "torch", ".", "arange", "(", "na", ")", ".", "view", "(", "na", ",", "1", ")", ".", "repeat", "(", "1", ",", "nt", ")", "# anchor tensor, same as .repeat_interleave(nt)", "\n", "r", "=", "t", "[", "None", ",", ":", ",", "4", ":", "6", "]", "/", "anchors", "[", ":", ",", "None", "]", "# wh ratio", "\n", "j", "=", "torch", ".", "max", "(", "r", ",", "1.", "/", "r", ")", ".", "max", "(", "2", ")", "[", "0", "]", "<", "model", ".", "hyp", "[", "'anchor_t'", "]", "# compare", "\n", "# j = wh_iou(anchors, t[:, 4:6]) > model.hyp['iou_t']  # iou(3,n) = wh_iou(anchors(3,2), gwh(n,2))", "\n", "a", ",", "t", "=", "at", "[", "j", "]", ",", "t", ".", "repeat", "(", "na", ",", "1", ",", "1", ")", "[", "j", "]", "# filter", "\n", "\n", "# overlaps", "\n", "gxy", "=", "t", "[", ":", ",", "2", ":", "4", "]", "# grid xy", "\n", "z", "=", "torch", ".", "zeros_like", "(", "gxy", ")", "\n", "j", ",", "k", "=", "(", "(", "gxy", "%", "1.", "<", "g", ")", "&", "(", "gxy", ">", "1.", ")", ")", ".", "T", "\n", "l", ",", "m", "=", "(", "(", "gxy", "%", "1.", ">", "(", "1", "-", "g", ")", ")", "&", "(", "gxy", "<", "(", "gain", "[", "[", "2", ",", "3", "]", "]", "-", "1.", ")", ")", ")", ".", "T", "\n", "a", ",", "t", "=", "torch", ".", "cat", "(", "(", "a", ",", "a", "[", "j", "]", ",", "a", "[", "k", "]", ",", "a", "[", "l", "]", ",", "a", "[", "m", "]", ")", ",", "0", ")", ",", "torch", ".", "cat", "(", "(", "t", ",", "t", "[", "j", "]", ",", "t", "[", "k", "]", ",", "t", "[", "l", "]", ",", "t", "[", "m", "]", ")", ",", "0", ")", "\n", "offsets", "=", "torch", ".", "cat", "(", "(", "z", ",", "z", "[", "j", "]", "+", "off", "[", "0", "]", ",", "z", "[", "k", "]", "+", "off", "[", "1", "]", ",", "z", "[", "l", "]", "+", "off", "[", "2", "]", ",", "z", "[", "m", "]", "+", "off", "[", "3", "]", ")", ",", "0", ")", "*", "g", "\n", "\n", "# Define", "\n", "", "b", ",", "c", "=", "t", "[", ":", ",", ":", "2", "]", ".", "long", "(", ")", ".", "T", "# image, class", "\n", "gxy", "=", "t", "[", ":", ",", "2", ":", "4", "]", "# grid xy", "\n", "gwh", "=", "t", "[", ":", ",", "4", ":", "6", "]", "# grid wh", "\n", "gij", "=", "(", "gxy", "-", "offsets", ")", ".", "long", "(", ")", "\n", "gi", ",", "gj", "=", "gij", ".", "T", "# grid xy indices", "\n", "\n", "# Append", "\n", "#indices.append((b, a, gj, gi))  # image, anchor, grid indices", "\n", "indices", ".", "append", "(", "(", "b", ",", "a", ",", "gj", ".", "clamp_", "(", "0", ",", "gain", "[", "3", "]", "-", "1", ")", ",", "gi", ".", "clamp_", "(", "0", ",", "gain", "[", "2", "]", "-", "1", ")", ")", ")", "# image, anchor, grid indices", "\n", "tbox", ".", "append", "(", "torch", ".", "cat", "(", "(", "gxy", "-", "gij", ",", "gwh", ")", ",", "1", ")", ")", "# box", "\n", "anch", ".", "append", "(", "anchors", "[", "a", "]", ")", "# anchors", "\n", "tcls", ".", "append", "(", "c", ")", "# class", "\n", "\n", "", "return", "tcls", ",", "tbox", ",", "indices", ",", "anch", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.parse_config.parse_model_cfg": [[6, 53], ["path.endswith", "os.path.exists", "open", "f.read().split", "x.rstrip().lstrip", "line.startswith", "any", "os.path.exists", "mdefs.append", "line[].rstrip", "line.split", "key.rstrip.rstrip", "f.append", "f.read", "x.rstrip", "numpy.array().reshape", "x.startswith", "val.strip.strip", "val.strip.isnumeric", "numpy.array", "int", "val.strip.split", "int", "float", "float", "val.strip.split", "int", "float"], "function", ["None"], ["def", "parse_model_cfg", "(", "path", ")", ":", "\n", "# Parse the yolo *.cfg file and return module definitions path may be 'cfg/yolov3.cfg', 'yolov3.cfg', or 'yolov3'", "\n", "    ", "if", "not", "path", ".", "endswith", "(", "'.cfg'", ")", ":", "# add .cfg suffix if omitted", "\n", "        ", "path", "+=", "'.cfg'", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", "and", "os", ".", "path", ".", "exists", "(", "'cfg'", "+", "os", ".", "sep", "+", "path", ")", ":", "# add cfg/ prefix if omitted", "\n", "        ", "path", "=", "'cfg'", "+", "os", ".", "sep", "+", "path", "\n", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "", "lines", "=", "[", "x", "for", "x", "in", "lines", "if", "x", "and", "not", "x", ".", "startswith", "(", "'#'", ")", "]", "\n", "lines", "=", "[", "x", ".", "rstrip", "(", ")", ".", "lstrip", "(", ")", "for", "x", "in", "lines", "]", "# get rid of fringe whitespaces", "\n", "mdefs", "=", "[", "]", "# module definitions", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "if", "line", ".", "startswith", "(", "'['", ")", ":", "# This marks the start of a new block", "\n", "            ", "mdefs", ".", "append", "(", "{", "}", ")", "\n", "mdefs", "[", "-", "1", "]", "[", "'type'", "]", "=", "line", "[", "1", ":", "-", "1", "]", ".", "rstrip", "(", ")", "\n", "if", "mdefs", "[", "-", "1", "]", "[", "'type'", "]", "==", "'convolutional'", ":", "\n", "                ", "mdefs", "[", "-", "1", "]", "[", "'batch_normalize'", "]", "=", "0", "# pre-populate with zeros (may be overwritten later)", "\n", "\n", "", "", "else", ":", "\n", "            ", "key", ",", "val", "=", "line", ".", "split", "(", "\"=\"", ")", "\n", "key", "=", "key", ".", "rstrip", "(", ")", "\n", "\n", "if", "key", "==", "'anchors'", ":", "# return nparray", "\n", "                ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "np", ".", "array", "(", "[", "float", "(", "x", ")", "for", "x", "in", "val", ".", "split", "(", "','", ")", "]", ")", ".", "reshape", "(", "(", "-", "1", ",", "2", ")", ")", "# np anchors", "\n", "", "elif", "(", "key", "in", "[", "'from'", ",", "'layers'", ",", "'mask'", "]", ")", "or", "(", "key", "==", "'size'", "and", "','", "in", "val", ")", ":", "# return array", "\n", "                ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "[", "int", "(", "x", ")", "for", "x", "in", "val", ".", "split", "(", "','", ")", "]", "\n", "", "else", ":", "\n", "                ", "val", "=", "val", ".", "strip", "(", ")", "\n", "if", "val", ".", "isnumeric", "(", ")", ":", "# return int or float", "\n", "                    ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "int", "(", "val", ")", "if", "(", "int", "(", "val", ")", "-", "float", "(", "val", ")", ")", "==", "0", "else", "float", "(", "val", ")", "\n", "", "else", ":", "\n", "                    ", "mdefs", "[", "-", "1", "]", "[", "key", "]", "=", "val", "# return string", "\n", "\n", "# Check all fields are supported", "\n", "", "", "", "", "supported", "=", "[", "'type'", ",", "'batch_normalize'", ",", "'filters'", ",", "'size'", ",", "'stride'", ",", "'pad'", ",", "'activation'", ",", "'layers'", ",", "'groups'", ",", "\n", "'from'", ",", "'mask'", ",", "'anchors'", ",", "'classes'", ",", "'num'", ",", "'jitter'", ",", "'ignore_thresh'", ",", "'truth_thresh'", ",", "'random'", ",", "\n", "'stride_x'", ",", "'stride_y'", ",", "'weights_type'", ",", "'weights_normalization'", ",", "'scale_x_y'", ",", "'beta_nms'", ",", "'nms_kind'", ",", "\n", "'iou_loss'", ",", "'iou_normalizer'", ",", "'cls_normalizer'", ",", "'iou_thresh'", ",", "'atoms'", ",", "'na'", ",", "'nc'", "]", "\n", "\n", "f", "=", "[", "]", "# fields", "\n", "for", "x", "in", "mdefs", "[", "1", ":", "]", ":", "\n", "        ", "[", "f", ".", "append", "(", "k", ")", "for", "k", "in", "x", "if", "k", "not", "in", "f", "]", "\n", "", "u", "=", "[", "x", "for", "x", "in", "f", "if", "x", "not", "in", "supported", "]", "# unsupported fields", "\n", "assert", "not", "any", "(", "u", ")", ",", "\"Unsupported fields %s in %s. See https://github.com/ultralytics/yolov3/issues/631\"", "%", "(", "u", ",", "path", ")", "\n", "\n", "return", "mdefs", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.parse_config.parse_data_cfg": [[55, 72], ["dict", "os.path.exists", "open", "f.readlines", "line.strip.strip", "line.strip.split", "val.strip", "os.path.exists", "line.strip.startswith", "key.strip"], "function", ["None"], ["", "def", "parse_data_cfg", "(", "path", ")", ":", "\n", "# Parses the data configuration file", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "path", ")", "and", "os", ".", "path", ".", "exists", "(", "'data'", "+", "os", ".", "sep", "+", "path", ")", ":", "# add data/ prefix if omitted", "\n", "        ", "path", "=", "'data'", "+", "os", ".", "sep", "+", "path", "\n", "\n", "", "with", "open", "(", "path", ",", "'r'", ")", "as", "f", ":", "\n", "        ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "options", "=", "dict", "(", ")", "\n", "for", "line", "in", "lines", ":", "\n", "        ", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "line", "==", "''", "or", "line", ".", "startswith", "(", "'#'", ")", ":", "\n", "            ", "continue", "\n", "", "key", ",", "val", "=", "line", ".", "split", "(", "'='", ")", "\n", "options", "[", "key", ".", "strip", "(", ")", "]", "=", "val", ".", "strip", "(", ")", "\n", "\n", "", "return", "options", "\n", "", ""]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.activations.Swish.forward": [[10, 13], ["torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "x", ")", ":", "\n", "        ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.activations.Hardswish.forward": [[16, 20], ["torch.hardtanh", "torch.hardtanh", "torch.hardtanh"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "x", ")", ":", "\n", "# return x * F.hardsigmoid(x)  # for torchscript and CoreML", "\n", "        ", "return", "x", "*", "F", ".", "hardtanh", "(", "x", "+", "3", ",", "0.", ",", "6.", ")", "/", "6.", "# for torchscript, CoreML and ONNX", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.activations.MemoryEfficientSwish.forward": [[35, 37], ["activations.MemoryEfficientSwish.F.apply"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "F", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.activations.Mish.forward": [[41, 44], ["torch.softplus().tanh", "torch.softplus().tanh", "torch.softplus().tanh", "torch.softplus", "torch.softplus", "torch.softplus"], "methods", ["None"], ["    ", "@", "staticmethod", "\n", "def", "forward", "(", "x", ")", ":", "\n", "        ", "return", "x", "*", "F", ".", "softplus", "(", "x", ")", ".", "tanh", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.activations.MemoryEfficientMish.forward": [[60, 62], ["activations.MemoryEfficientMish.F.apply"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "F", ".", "apply", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.activations.FReLU.__init__": [[66, 70], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "c1", ",", "k", "=", "3", ")", ":", "# ch_in, kernel", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv", "=", "nn", ".", "Conv2d", "(", "c1", ",", "c1", ",", "k", ",", "1", ",", "1", ",", "groups", "=", "c1", ")", "\n", "self", ".", "bn", "=", "nn", ".", "BatchNorm2d", "(", "c1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.activations.FReLU.forward": [[71, 73], ["torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "activations.FReLU.bn", "activations.FReLU.conv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "torch", ".", "max", "(", "x", ",", "self", ".", "bn", "(", "self", ".", "conv", "(", "x", ")", ")", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.ModelEMA.__init__": [[216, 225], ["copy.deepcopy().eval", "torch_utils.ModelEMA.ema.parameters", "p.requires_grad_", "copy.deepcopy", "math.exp", "torch_utils.is_parallel"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.is_parallel"], ["def", "__init__", "(", "self", ",", "model", ",", "decay", "=", "0.9999", ",", "updates", "=", "0", ")", ":", "\n", "# Create EMA", "\n", "        ", "self", ".", "ema", "=", "deepcopy", "(", "model", ".", "module", "if", "is_parallel", "(", "model", ")", "else", "model", ")", ".", "eval", "(", ")", "# FP32 EMA", "\n", "# if next(model.parameters()).device.type != 'cpu':", "\n", "#     self.ema.half()  # FP16 EMA", "\n", "self", ".", "updates", "=", "updates", "# number of EMA updates", "\n", "self", ".", "decay", "=", "lambda", "x", ":", "decay", "*", "(", "1", "-", "math", ".", "exp", "(", "-", "x", "/", "2000", ")", ")", "# decay exponential ramp (to help early epochs)", "\n", "for", "p", "in", "self", ".", "ema", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad_", "(", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.ModelEMA.update": [[226, 237], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch_utils.ModelEMA.decay", "torch_utils.ModelEMA.ema.state_dict().items", "torch_utils.is_parallel", "model.module.state_dict", "model.state_dict", "torch_utils.ModelEMA.ema.state_dict", "msd[].detach"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.is_parallel"], ["", "", "def", "update", "(", "self", ",", "model", ")", ":", "\n", "# Update EMA parameters", "\n", "        ", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "self", ".", "updates", "+=", "1", "\n", "d", "=", "self", ".", "decay", "(", "self", ".", "updates", ")", "\n", "\n", "msd", "=", "model", ".", "module", ".", "state_dict", "(", ")", "if", "is_parallel", "(", "model", ")", "else", "model", ".", "state_dict", "(", ")", "# model state_dict", "\n", "for", "k", ",", "v", "in", "self", ".", "ema", ".", "state_dict", "(", ")", ".", "items", "(", ")", ":", "\n", "                ", "if", "v", ".", "dtype", ".", "is_floating_point", ":", "\n", "                    ", "v", "*=", "d", "\n", "v", "+=", "(", "1.", "-", "d", ")", "*", "msd", "[", "k", "]", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.ModelEMA.update_attr": [[238, 241], ["torch_utils.copy_attr"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.copy_attr"], ["", "", "", "", "def", "update_attr", "(", "self", ",", "model", ",", "include", "=", "(", ")", ",", "exclude", "=", "(", "'process_group'", ",", "'reducer'", ")", ")", ":", "\n", "# Update EMA attributes", "\n", "        ", "copy_attr", "(", "self", ".", "ema", ",", "model", ",", "include", ",", "exclude", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.torch_distributed_zero_first": [[19, 29], ["torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier", "torch.distributed.barrier"], "function", ["None"], ["@", "contextmanager", "\n", "def", "torch_distributed_zero_first", "(", "local_rank", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Decorator to make all processes in distributed training wait for each local_master to do something.\n    \"\"\"", "\n", "if", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "", "yield", "\n", "if", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.init_torch_seeds": [[31, 40], ["torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed"], "function", ["None"], ["", "", "def", "init_torch_seeds", "(", "seed", "=", "0", ")", ":", "\n", "# Speed-reproducibility tradeoff https://pytorch.org/docs/stable/notes/randomness.html", "\n", "    ", "torch", ".", "manual_seed", "(", "seed", ")", "\n", "if", "seed", "==", "0", ":", "# slower, more reproducible", "\n", "        ", "cudnn", ".", "deterministic", "=", "True", "\n", "cudnn", ".", "benchmark", "=", "False", "\n", "", "else", ":", "# faster, less reproducible", "\n", "        ", "cudnn", ".", "deterministic", "=", "False", "\n", "cudnn", ".", "benchmark", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.select_device": [[42, 66], ["logger.info", "torch.device", "torch.device", "torch.device", "torch.device", "device.lower", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "range", "logger.info", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "torch.cuda.get_device_properties", "logger.info", "range", "len"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info"], ["", "", "def", "select_device", "(", "device", "=", "''", ",", "batch_size", "=", "None", ")", ":", "\n", "# device = 'cpu' or '0' or '0,1,2,3'", "\n", "    ", "cpu_request", "=", "device", ".", "lower", "(", ")", "==", "'cpu'", "\n", "if", "device", "and", "not", "cpu_request", ":", "# if device requested other than 'cpu'", "\n", "        ", "os", ".", "environ", "[", "'CUDA_VISIBLE_DEVICES'", "]", "=", "device", "# set environment variable", "\n", "assert", "torch", ".", "cuda", ".", "is_available", "(", ")", ",", "'CUDA unavailable, invalid device %s requested'", "%", "device", "# check availablity", "\n", "\n", "", "cuda", "=", "False", "if", "cpu_request", "else", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "cuda", ":", "\n", "        ", "c", "=", "1024", "**", "2", "# bytes to MB", "\n", "ng", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "if", "ng", ">", "1", "and", "batch_size", ":", "# check that batch_size is compatible with device_count", "\n", "            ", "assert", "batch_size", "%", "ng", "==", "0", ",", "'batch-size %g not multiple of GPU count %g'", "%", "(", "batch_size", ",", "ng", ")", "\n", "", "x", "=", "[", "torch", ".", "cuda", ".", "get_device_properties", "(", "i", ")", "for", "i", "in", "range", "(", "ng", ")", "]", "\n", "s", "=", "f'Using torch {torch.__version__} '", "\n", "for", "i", "in", "range", "(", "0", ",", "ng", ")", ":", "\n", "            ", "if", "i", "==", "1", ":", "\n", "                ", "s", "=", "' '", "*", "len", "(", "s", ")", "\n", "", "logger", ".", "info", "(", "\"%sCUDA:%g (%s, %dMB)\"", "%", "(", "s", ",", "i", ",", "x", "[", "i", "]", ".", "name", ",", "x", "[", "i", "]", ".", "total_memory", "/", "c", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "f'Using torch {torch.__version__} CPU'", ")", "\n", "\n", "", "logger", ".", "info", "(", "''", ")", "# skip a line", "\n", "return", "torch", ".", "device", "(", "'cuda:0'", "if", "cuda", "else", "'cpu'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.time_synchronized": [[68, 71], ["time.time", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize", "torch.cuda.synchronize"], "function", ["None"], ["", "def", "time_synchronized", "(", ")", ":", "\n", "    ", "torch", ".", "cuda", ".", "synchronize", "(", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "None", "\n", "return", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.is_parallel": [[73, 75], ["type"], "function", ["None"], ["", "def", "is_parallel", "(", "model", ")", ":", "\n", "    ", "return", "type", "(", "model", ")", "in", "(", "nn", ".", "parallel", ".", "DataParallel", ",", "nn", ".", "parallel", ".", "DistributedDataParallel", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.intersect_dicts": [[77, 80], ["da.items", "any"], "function", ["None"], ["", "def", "intersect_dicts", "(", "da", ",", "db", ",", "exclude", "=", "(", ")", ")", ":", "\n", "# Dictionary intersection of matching keys and shapes, omitting 'exclude' keys, using da values", "\n", "    ", "return", "{", "k", ":", "v", "for", "k", ",", "v", "in", "da", ".", "items", "(", ")", "if", "k", "in", "db", "and", "not", "any", "(", "x", "in", "k", "for", "x", "in", "exclude", ")", "and", "v", ".", "shape", "==", "db", "[", "k", "]", ".", "shape", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.initialize_weights": [[82, 92], ["model.modules", "type"], "function", ["None"], ["", "def", "initialize_weights", "(", "model", ")", ":", "\n", "    ", "for", "m", "in", "model", ".", "modules", "(", ")", ":", "\n", "        ", "t", "=", "type", "(", "m", ")", "\n", "if", "t", "is", "nn", ".", "Conv2d", ":", "\n", "            ", "pass", "# nn.init.kaiming_normal_(m.weight, mode='fan_out', nonlinearity='relu')", "\n", "", "elif", "t", "is", "nn", ".", "BatchNorm2d", ":", "\n", "            ", "m", ".", "eps", "=", "1e-3", "\n", "m", ".", "momentum", "=", "0.03", "\n", "", "elif", "t", "in", "[", "nn", ".", "Hardswish", ",", "nn", ".", "LeakyReLU", ",", "nn", ".", "ReLU", ",", "nn", ".", "ReLU6", "]", ":", "\n", "            ", "m", ".", "inplace", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.find_modules": [[94, 97], ["enumerate", "isinstance"], "function", ["None"], ["", "", "", "def", "find_modules", "(", "model", ",", "mclass", "=", "nn", ".", "Conv2d", ")", ":", "\n", "# Finds layer indices matching module class 'mclass'", "\n", "    ", "return", "[", "i", "for", "i", ",", "m", "in", "enumerate", "(", "model", ".", "module_list", ")", "if", "isinstance", "(", "m", ",", "mclass", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.sparsity": [[99, 106], ["model.parameters", "p.numel"], "function", ["None"], ["", "def", "sparsity", "(", "model", ")", ":", "\n", "# Return global model sparsity", "\n", "    ", "a", ",", "b", "=", "0.", ",", "0.", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "a", "+=", "p", ".", "numel", "(", ")", "\n", "b", "+=", "(", "p", "==", "0", ")", ".", "sum", "(", ")", "\n", "", "return", "b", "/", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.prune": [[108, 117], ["print", "model.named_modules", "print", "isinstance", "prune.l1_unstructured", "prune.remove", "torch_utils.sparsity"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.sparsity"], ["", "def", "prune", "(", "model", ",", "amount", "=", "0.3", ")", ":", "\n", "# Prune model to requested global sparsity", "\n", "    ", "import", "torch", ".", "nn", ".", "utils", ".", "prune", "as", "prune", "\n", "print", "(", "'Pruning model... '", ",", "end", "=", "''", ")", "\n", "for", "name", ",", "m", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "        ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "            ", "prune", ".", "l1_unstructured", "(", "m", ",", "name", "=", "'weight'", ",", "amount", "=", "amount", ")", "# prune", "\n", "prune", ".", "remove", "(", "m", ",", "'weight'", ")", "# make permanent", "\n", "", "", "print", "(", "' %.3g global sparsity'", "%", "sparsity", "(", "model", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.fuse_conv_and_bn": [[119, 140], ["torch.Conv2d().requires_grad_().to", "conv.weight.clone().view", "torch.diag", "torch.diag", "torch.diag", "torch.diag", "nn.Conv2d().requires_grad_().to.weight.copy_", "nn.Conv2d().requires_grad_().to.bias.copy_", "bn.weight.div", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.mm().view", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "bn.weight.mul().div", "torch.Conv2d().requires_grad_", "conv.weight.clone", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "nn.Conv2d().requires_grad_().to.weight.size", "conv.weight.size", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.sqrt", "torch.mm().reshape", "torch.mm().reshape", "torch.mm().reshape", "torch.mm().reshape", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "bn.weight.mul", "torch.Conv2d", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "b_conv.reshape"], "function", ["None"], ["", "def", "fuse_conv_and_bn", "(", "conv", ",", "bn", ")", ":", "\n", "# Fuse convolution and batchnorm layers https://tehnokv.com/posts/fusing-batchnorm-and-conv/", "\n", "    ", "fusedconv", "=", "nn", ".", "Conv2d", "(", "conv", ".", "in_channels", ",", "\n", "conv", ".", "out_channels", ",", "\n", "kernel_size", "=", "conv", ".", "kernel_size", ",", "\n", "stride", "=", "conv", ".", "stride", ",", "\n", "padding", "=", "conv", ".", "padding", ",", "\n", "groups", "=", "conv", ".", "groups", ",", "\n", "bias", "=", "True", ")", ".", "requires_grad_", "(", "False", ")", ".", "to", "(", "conv", ".", "weight", ".", "device", ")", "\n", "\n", "# prepare filters", "\n", "w_conv", "=", "conv", ".", "weight", ".", "clone", "(", ")", ".", "view", "(", "conv", ".", "out_channels", ",", "-", "1", ")", "\n", "w_bn", "=", "torch", ".", "diag", "(", "bn", ".", "weight", ".", "div", "(", "torch", ".", "sqrt", "(", "bn", ".", "eps", "+", "bn", ".", "running_var", ")", ")", ")", "\n", "fusedconv", ".", "weight", ".", "copy_", "(", "torch", ".", "mm", "(", "w_bn", ",", "w_conv", ")", ".", "view", "(", "fusedconv", ".", "weight", ".", "size", "(", ")", ")", ")", "\n", "\n", "# prepare spatial bias", "\n", "b_conv", "=", "torch", ".", "zeros", "(", "conv", ".", "weight", ".", "size", "(", "0", ")", ",", "device", "=", "conv", ".", "weight", ".", "device", ")", "if", "conv", ".", "bias", "is", "None", "else", "conv", ".", "bias", "\n", "b_bn", "=", "bn", ".", "bias", "-", "bn", ".", "weight", ".", "mul", "(", "bn", ".", "running_mean", ")", ".", "div", "(", "torch", ".", "sqrt", "(", "bn", ".", "running_var", "+", "bn", ".", "eps", ")", ")", "\n", "fusedconv", ".", "bias", ".", "copy_", "(", "torch", ".", "mm", "(", "w_bn", ",", "b_conv", ".", "reshape", "(", "-", "1", ",", "1", ")", ")", ".", "reshape", "(", "-", "1", ")", "+", "b_bn", ")", "\n", "\n", "return", "fusedconv", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.model_info": [[142, 162], ["sum", "sum", "logger.info", "print", "enumerate", "x.numel", "x.numel", "model.named_parameters", "name.replace.replace", "print", "isinstance", "model.parameters", "model.parameters", "len", "profile", "list", "p.numel", "list", "p.mean", "p.std", "copy.deepcopy", "model.modules", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info"], ["", "def", "model_info", "(", "model", ",", "verbose", "=", "False", ",", "img_size", "=", "640", ")", ":", "\n", "# Model information. img_size may be int or list, i.e. img_size=640 or img_size=[640, 320]", "\n", "    ", "n_p", "=", "sum", "(", "x", ".", "numel", "(", ")", "for", "x", "in", "model", ".", "parameters", "(", ")", ")", "# number parameters", "\n", "n_g", "=", "sum", "(", "x", ".", "numel", "(", ")", "for", "x", "in", "model", ".", "parameters", "(", ")", "if", "x", ".", "requires_grad", ")", "# number gradients", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'%5s %40s %9s %12s %20s %10s %10s'", "%", "(", "'layer'", ",", "'name'", ",", "'gradient'", ",", "'parameters'", ",", "'shape'", ",", "'mu'", ",", "'sigma'", ")", ")", "\n", "for", "i", ",", "(", "name", ",", "p", ")", "in", "enumerate", "(", "model", ".", "named_parameters", "(", ")", ")", ":", "\n", "            ", "name", "=", "name", ".", "replace", "(", "'module_list.'", ",", "''", ")", "\n", "print", "(", "'%5g %40s %9s %12g %20s %10.3g %10.3g'", "%", "\n", "(", "i", ",", "name", ",", "p", ".", "requires_grad", ",", "p", ".", "numel", "(", ")", ",", "list", "(", "p", ".", "shape", ")", ",", "p", ".", "mean", "(", ")", ",", "p", ".", "std", "(", ")", ")", ")", "\n", "\n", "", "", "try", ":", "# FLOPS", "\n", "        ", "from", "thop", "import", "profile", "\n", "flops", "=", "profile", "(", "deepcopy", "(", "model", ")", ",", "inputs", "=", "(", "torch", ".", "zeros", "(", "1", ",", "3", ",", "img_size", ",", "img_size", ")", ",", ")", ",", "verbose", "=", "False", ")", "[", "0", "]", "/", "1E9", "*", "2", "\n", "img_size", "=", "img_size", "if", "isinstance", "(", "img_size", ",", "list", ")", "else", "[", "img_size", ",", "img_size", "]", "# expand if int/float", "\n", "fs", "=", "', %.9f GFLOPS'", "%", "(", "flops", ")", "# 640x640 FLOPS", "\n", "", "except", "(", "ImportError", ",", "Exception", ")", ":", "\n", "        ", "fs", "=", "''", "\n", "\n", "", "logger", ".", "info", "(", "f\"Model Summary: {len(list(model.modules()))} layers, {n_p} parameters, {n_g} gradients{fs}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.load_classifier": [[164, 181], ["torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "function", ["None"], ["", "def", "load_classifier", "(", "name", "=", "'resnet101'", ",", "n", "=", "2", ")", ":", "\n", "# Loads a pretrained model reshaped to n-class output", "\n", "    ", "model", "=", "torchvision", ".", "models", ".", "__dict__", "[", "name", "]", "(", "pretrained", "=", "True", ")", "\n", "\n", "# ResNet model properties", "\n", "# input_size = [3, 224, 224]", "\n", "# input_space = 'RGB'", "\n", "# input_range = [0, 1]", "\n", "# mean = [0.485, 0.456, 0.406]", "\n", "# std = [0.229, 0.224, 0.225]", "\n", "\n", "# Reshape output to n classes", "\n", "filters", "=", "model", ".", "fc", ".", "weight", ".", "shape", "[", "1", "]", "\n", "model", ".", "fc", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "n", ")", ",", "requires_grad", "=", "True", ")", "\n", "model", ".", "fc", ".", "weight", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "n", ",", "filters", ")", ",", "requires_grad", "=", "True", ")", "\n", "model", ".", "fc", ".", "out_features", "=", "n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.scale_img": [[183, 195], ["torch.interpolate", "torch.pad", "int", "int", "math.ceil"], "function", ["None"], ["", "def", "scale_img", "(", "img", ",", "ratio", "=", "1.0", ",", "same_shape", "=", "False", ")", ":", "# img(16,3,256,416), r=ratio", "\n", "# scales img(bs,3,y,x) by ratio", "\n", "    ", "if", "ratio", "==", "1.0", ":", "\n", "        ", "return", "img", "\n", "", "else", ":", "\n", "        ", "h", ",", "w", "=", "img", ".", "shape", "[", "2", ":", "]", "\n", "s", "=", "(", "int", "(", "h", "*", "ratio", ")", ",", "int", "(", "w", "*", "ratio", ")", ")", "# new size", "\n", "img", "=", "F", ".", "interpolate", "(", "img", ",", "size", "=", "s", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "# resize", "\n", "if", "not", "same_shape", ":", "# pad/crop img", "\n", "            ", "gs", "=", "32", "# (pixels) grid size", "\n", "h", ",", "w", "=", "[", "math", ".", "ceil", "(", "x", "*", "ratio", "/", "gs", ")", "*", "gs", "for", "x", "in", "(", "h", ",", "w", ")", "]", "\n", "", "return", "F", ".", "pad", "(", "img", ",", "[", "0", ",", "w", "-", "s", "[", "1", "]", ",", "0", ",", "h", "-", "s", "[", "0", "]", "]", ",", "value", "=", "0.447", ")", "# value = imagenet mean", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.copy_attr": [[197, 204], ["b.__dict__.items", "k.startswith", "setattr", "len"], "function", ["None"], ["", "", "def", "copy_attr", "(", "a", ",", "b", ",", "include", "=", "(", ")", ",", "exclude", "=", "(", ")", ")", ":", "\n", "# Copy attributes from b to a, options to only include [...] and to exclude [...]", "\n", "    ", "for", "k", ",", "v", "in", "b", ".", "__dict__", ".", "items", "(", ")", ":", "\n", "        ", "if", "(", "len", "(", "include", ")", "and", "k", "not", "in", "include", ")", "or", "k", ".", "startswith", "(", "'_'", ")", "or", "k", "in", "exclude", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "setattr", "(", "a", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.set_logging": [[33, 37], ["logging.basicConfig"], "function", ["None"], ["def", "set_logging", "(", "rank", "=", "-", "1", ")", ":", "\n", "    ", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(message)s\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.init_seeds": [[39, 43], ["random.seed", "numpy.random.seed", "utils.torch_utils.init_torch_seeds"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.init_torch_seeds"], ["", "def", "init_seeds", "(", "seed", "=", "0", ")", ":", "\n", "    ", "random", ".", "seed", "(", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "seed", ")", "\n", "init_torch_seeds", "(", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.get_latest_run": [[45, 49], ["glob.glob", "max"], "function", ["None"], ["", "def", "get_latest_run", "(", "search_dir", "=", "'.'", ")", ":", "\n", "# Return path to most recent 'last.pt' in /runs (i.e. to --resume from)", "\n", "    ", "last_list", "=", "glob", ".", "glob", "(", "f'{search_dir}/**/last*.pt'", ",", "recursive", "=", "True", ")", "\n", "return", "max", "(", "last_list", ",", "key", "=", "os", ".", "path", ".", "getctime", ")", "if", "last_list", "else", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_git_status": [[51, 57], ["subprocess.check_output().decode", "platform.system", "os.path.isfile", "print", "subprocess.check_output", "subprocess.check_output().decode.find", "subprocess.check_output().decode.find"], "function", ["None"], ["", "def", "check_git_status", "(", ")", ":", "\n", "# Suggest 'git pull' if repo is out of date", "\n", "    ", "if", "platform", ".", "system", "(", ")", "in", "[", "'Linux'", ",", "'Darwin'", "]", "and", "not", "os", ".", "path", ".", "isfile", "(", "'/.dockerenv'", ")", ":", "\n", "        ", "s", "=", "subprocess", ".", "check_output", "(", "'if [ -d .git ]; then git fetch && git status -uno; fi'", ",", "shell", "=", "True", ")", ".", "decode", "(", "'utf-8'", ")", "\n", "if", "'Your branch is behind'", "in", "s", ":", "\n", "            ", "print", "(", "s", "[", "s", ".", "find", "(", "'Your branch is behind'", ")", ":", "s", ".", "find", "(", "'\\n\\n'", ")", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_img_size": [[59, 65], ["general.make_divisible", "int", "print"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.make_divisible"], ["", "", "", "def", "check_img_size", "(", "img_size", ",", "s", "=", "32", ")", ":", "\n", "# Verify img_size is a multiple of stride s", "\n", "    ", "new_size", "=", "make_divisible", "(", "img_size", ",", "int", "(", "s", ")", ")", "# ceil gs-multiple", "\n", "if", "new_size", "!=", "img_size", ":", "\n", "        ", "print", "(", "'WARNING: --img-size %g must be multiple of max stride %g, updating to %g'", "%", "(", "img_size", ",", "s", ",", "new_size", ")", ")", "\n", "", "return", "new_size", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_file": [[67, 76], ["os.path.isfile", "glob.glob", "len", "len"], "function", ["None"], ["", "def", "check_file", "(", "file", ")", ":", "\n", "# Search for file if not found", "\n", "    ", "if", "os", ".", "path", ".", "isfile", "(", "file", ")", "or", "file", "==", "''", ":", "\n", "        ", "return", "file", "\n", "", "else", ":", "\n", "        ", "files", "=", "glob", ".", "glob", "(", "'./**/'", "+", "file", ",", "recursive", "=", "True", ")", "# find file", "\n", "assert", "len", "(", "files", ")", ",", "'File Not Found: %s'", "%", "file", "# assert file was found", "\n", "assert", "len", "(", "files", ")", "==", "1", ",", "\"Multiple files match '%s', specify exact path: %s\"", "%", "(", "file", ",", "files", ")", "# assert unique", "\n", "return", "files", "[", "0", "]", "# return file", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.check_dataset": [[78, 96], ["dict.get", "dict.get", "len", "pathlib.Path().resolve", "all", "print", "len", "print", "print", "Exception", "pathlib.Path", "isinstance", "x.exists", "s.startswith", "s.endswith", "torch.hub.download_url_to_file", "os.system", "os.system", "str", "pathlib.Path", "x.exists"], "function", ["None"], ["", "", "def", "check_dataset", "(", "dict", ")", ":", "\n", "# Download dataset if not found locally", "\n", "    ", "val", ",", "s", "=", "dict", ".", "get", "(", "'val'", ")", ",", "dict", ".", "get", "(", "'download'", ")", "\n", "if", "val", "and", "len", "(", "val", ")", ":", "\n", "        ", "val", "=", "[", "Path", "(", "x", ")", ".", "resolve", "(", ")", "for", "x", "in", "(", "val", "if", "isinstance", "(", "val", ",", "list", ")", "else", "[", "val", "]", ")", "]", "# val path", "\n", "if", "not", "all", "(", "x", ".", "exists", "(", ")", "for", "x", "in", "val", ")", ":", "\n", "            ", "print", "(", "'\\nWARNING: Dataset not found, nonexistent paths: %s'", "%", "[", "str", "(", "x", ")", "for", "x", "in", "val", "if", "not", "x", ".", "exists", "(", ")", "]", ")", "\n", "if", "s", "and", "len", "(", "s", ")", ":", "# download script", "\n", "                ", "print", "(", "'Downloading %s ...'", "%", "s", ")", "\n", "if", "s", ".", "startswith", "(", "'http'", ")", "and", "s", ".", "endswith", "(", "'.zip'", ")", ":", "# URL", "\n", "                    ", "f", "=", "Path", "(", "s", ")", ".", "name", "# filename", "\n", "torch", ".", "hub", ".", "download_url_to_file", "(", "s", ",", "f", ")", "\n", "r", "=", "os", ".", "system", "(", "'unzip -q %s -d ../ && rm %s'", "%", "(", "f", ",", "f", ")", ")", "# unzip", "\n", "", "else", ":", "# bash script", "\n", "                    ", "r", "=", "os", ".", "system", "(", "s", ")", "\n", "", "print", "(", "'Dataset autodownload %s\\n'", "%", "(", "'success'", "if", "r", "==", "0", "else", "'failure'", ")", ")", "# analyze return value", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Dataset not found.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.make_divisible": [[98, 101], ["math.ceil"], "function", ["None"], ["", "", "", "", "def", "make_divisible", "(", "x", ",", "divisor", ")", ":", "\n", "# Returns x evenly divisible by divisor", "\n", "    ", "return", "math", ".", "ceil", "(", "x", "/", "divisor", ")", "*", "divisor", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.labels_to_class_weights": [[103, 120], ["numpy.concatenate", "labels[].astype", "numpy.bincount", "np.bincount.sum", "torch.from_numpy", "torch.Tensor"], "function", ["None"], ["", "def", "labels_to_class_weights", "(", "labels", ",", "nc", "=", "80", ")", ":", "\n", "# Get class weights (inverse frequency) from training labels", "\n", "    ", "if", "labels", "[", "0", "]", "is", "None", ":", "# no labels loaded", "\n", "        ", "return", "torch", ".", "Tensor", "(", ")", "\n", "\n", "", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "0", ")", "# labels.shape = (866643, 5) for COCO", "\n", "classes", "=", "labels", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "int", ")", "# labels = [class xywh]", "\n", "weights", "=", "np", ".", "bincount", "(", "classes", ",", "minlength", "=", "nc", ")", "# occurrences per class", "\n", "\n", "# Prepend gridpoint count (for uCE training)", "\n", "# gpi = ((320 / 32 * np.array([1, 2, 4])) ** 2 * 3).sum()  # gridpoints per image", "\n", "# weights = np.hstack([gpi * len(labels)  - weights.sum() * 9, weights * 9]) ** 0.5  # prepend gridpoints to start", "\n", "\n", "weights", "[", "weights", "==", "0", "]", "=", "1", "# replace empty bins with 1", "\n", "weights", "=", "1", "/", "weights", "# number of targets per class", "\n", "weights", "/=", "weights", ".", "sum", "(", ")", "# normalize", "\n", "return", "torch", ".", "from_numpy", "(", "weights", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.labels_to_image_weights": [[122, 129], ["numpy.ones", "len", "numpy.array", "numpy.bincount", "[].astype", "range", "class_weights.reshape"], "function", ["None"], ["", "def", "labels_to_image_weights", "(", "labels", ",", "nc", "=", "80", ",", "class_weights", "=", "np", ".", "ones", "(", "80", ")", ")", ":", "\n", "# Produces image weights based on class mAPs", "\n", "    ", "n", "=", "len", "(", "labels", ")", "\n", "class_counts", "=", "np", ".", "array", "(", "[", "np", ".", "bincount", "(", "labels", "[", "i", "]", "[", ":", ",", "0", "]", ".", "astype", "(", "np", ".", "int", ")", ",", "minlength", "=", "nc", ")", "for", "i", "in", "range", "(", "n", ")", "]", ")", "\n", "image_weights", "=", "(", "class_weights", ".", "reshape", "(", "1", ",", "nc", ")", "*", "class_counts", ")", ".", "sum", "(", "1", ")", "\n", "# index = random.choices(range(n), weights=image_weights, k=1)  # weight image sample", "\n", "return", "image_weights", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.coco80_to_coco91_class": [[131, 141], ["None"], "function", ["None"], ["", "def", "coco80_to_coco91_class", "(", ")", ":", "# converts 80-index (val2014) to 91-index (paper)", "\n", "# https://tech.amikelive.com/node-718/what-object-categories-labels-are-in-coco-dataset/", "\n", "# a = np.loadtxt('data/coco.names', dtype='str', delimiter='\\n')", "\n", "# b = np.loadtxt('data/coco_paper.names', dtype='str', delimiter='\\n')", "\n", "# x1 = [list(a[i] == b).index(True) + 1 for i in range(80)]  # darknet to coco", "\n", "# x2 = [list(b[i] == a).index(True) if any(b[i] == a) else None for i in range(91)]  # coco to darknet", "\n", "    ", "x", "=", "[", "1", ",", "2", ",", "3", ",", "4", ",", "5", ",", "6", ",", "7", ",", "8", ",", "9", ",", "10", ",", "11", ",", "13", ",", "14", ",", "15", ",", "16", ",", "17", ",", "18", ",", "19", ",", "20", ",", "21", ",", "22", ",", "23", ",", "24", ",", "25", ",", "27", ",", "28", ",", "31", ",", "32", ",", "33", ",", "34", ",", "\n", "35", ",", "36", ",", "37", ",", "38", ",", "39", ",", "40", ",", "41", ",", "42", ",", "43", ",", "44", ",", "46", ",", "47", ",", "48", ",", "49", ",", "50", ",", "51", ",", "52", ",", "53", ",", "54", ",", "55", ",", "56", ",", "57", ",", "58", ",", "59", ",", "60", ",", "61", ",", "62", ",", "63", ",", "\n", "64", ",", "65", ",", "67", ",", "70", ",", "72", ",", "73", ",", "74", ",", "75", ",", "76", ",", "77", ",", "78", ",", "79", ",", "80", ",", "81", ",", "82", ",", "84", ",", "85", ",", "86", ",", "87", ",", "88", ",", "89", ",", "90", "]", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh": [[143, 151], ["isinstance", "x.clone", "numpy.copy"], "function", ["None"], ["", "def", "xyxy2xywh", "(", "x", ")", ":", "\n", "# Convert nx4 boxes from [x1, y1, x2, y2] to [x, y, w, h] where xy1=top-left, xy2=bottom-right", "\n", "    ", "y", "=", "x", ".", "clone", "(", ")", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "else", "np", ".", "copy", "(", "x", ")", "\n", "y", "[", ":", ",", "0", "]", "=", "(", "x", "[", ":", ",", "0", "]", "+", "x", "[", ":", ",", "2", "]", ")", "/", "2", "# x center", "\n", "y", "[", ":", ",", "1", "]", "=", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", ")", "/", "2", "# y center", "\n", "y", "[", ":", ",", "2", "]", "=", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "0", "]", "# width", "\n", "y", "[", ":", ",", "3", "]", "=", "x", "[", ":", ",", "3", "]", "-", "x", "[", ":", ",", "1", "]", "# height", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xywh2xyxy": [[153, 161], ["isinstance", "x.clone", "numpy.copy"], "function", ["None"], ["", "def", "xywh2xyxy", "(", "x", ")", ":", "\n", "# Convert nx4 boxes from [x, y, w, h] to [x1, y1, x2, y2] where xy1=top-left, xy2=bottom-right", "\n", "    ", "y", "=", "x", ".", "clone", "(", ")", "if", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", "else", "np", ".", "copy", "(", "x", ")", "\n", "y", "[", ":", ",", "0", "]", "=", "x", "[", ":", ",", "0", "]", "-", "x", "[", ":", ",", "2", "]", "/", "2", "# top left x", "\n", "y", "[", ":", ",", "1", "]", "=", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", "# top left y", "\n", "y", "[", ":", ",", "2", "]", "=", "x", "[", ":", ",", "0", "]", "+", "x", "[", ":", ",", "2", "]", "/", "2", "# bottom right x", "\n", "y", "[", ":", ",", "3", "]", "=", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", "# bottom right y", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.scale_coords": [[163, 177], ["general.clip_coords", "min"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.clip_coords"], ["", "def", "scale_coords", "(", "img1_shape", ",", "coords", ",", "img0_shape", ",", "ratio_pad", "=", "None", ")", ":", "\n", "# Rescale coords (xyxy) from img1_shape to img0_shape", "\n", "    ", "if", "ratio_pad", "is", "None", ":", "# calculate from img0_shape", "\n", "        ", "gain", "=", "min", "(", "img1_shape", "[", "0", "]", "/", "img0_shape", "[", "0", "]", ",", "img1_shape", "[", "1", "]", "/", "img0_shape", "[", "1", "]", ")", "# gain  = old / new", "\n", "pad", "=", "(", "img1_shape", "[", "1", "]", "-", "img0_shape", "[", "1", "]", "*", "gain", ")", "/", "2", ",", "(", "img1_shape", "[", "0", "]", "-", "img0_shape", "[", "0", "]", "*", "gain", ")", "/", "2", "# wh padding", "\n", "", "else", ":", "\n", "        ", "gain", "=", "ratio_pad", "[", "0", "]", "[", "0", "]", "\n", "pad", "=", "ratio_pad", "[", "1", "]", "\n", "\n", "", "coords", "[", ":", ",", "[", "0", ",", "2", "]", "]", "-=", "pad", "[", "0", "]", "# x padding", "\n", "coords", "[", ":", ",", "[", "1", ",", "3", "]", "]", "-=", "pad", "[", "1", "]", "# y padding", "\n", "coords", "[", ":", ",", ":", "4", "]", "/=", "gain", "\n", "clip_coords", "(", "coords", ",", "img0_shape", ")", "\n", "return", "coords", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.clip_coords": [[179, 185], ["boxes[].clamp_", "boxes[].clamp_", "boxes[].clamp_", "boxes[].clamp_"], "function", ["None"], ["", "def", "clip_coords", "(", "boxes", ",", "img_shape", ")", ":", "\n", "# Clip bounding xyxy bounding boxes to image shape (height, width)", "\n", "    ", "boxes", "[", ":", ",", "0", "]", ".", "clamp_", "(", "0", ",", "img_shape", "[", "1", "]", ")", "# x1", "\n", "boxes", "[", ":", ",", "1", "]", ".", "clamp_", "(", "0", ",", "img_shape", "[", "0", "]", ")", "# y1", "\n", "boxes", "[", ":", ",", "2", "]", ".", "clamp_", "(", "0", ",", "img_shape", "[", "1", "]", ")", "# x2", "\n", "boxes", "[", ":", ",", "3", "]", ".", "clamp_", "(", "0", ",", "img_shape", "[", "0", "]", ")", "# y2", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.bbox_iou": [[187, 245], ["torch.max", "torch.min", "torch.max", "torch.min", "torch.min", "torch.max", "torch.min", "torch.max", "torch.pow", "torch.no_grad", "torch.atan", "torch.atan", "torch.pow", "torch.no_grad", "torch.atan", "torch.atan"], "function", ["None"], ["", "def", "bbox_iou", "(", "box1", ",", "box2", ",", "x1y1x2y2", "=", "True", ",", "GIoU", "=", "False", ",", "DIoU", "=", "False", ",", "CIoU", "=", "False", ",", "EIoU", "=", "False", ",", "ECIoU", "=", "False", ",", "eps", "=", "1e-9", ")", ":", "\n", "# Returns the IoU of box1 to box2. box1 is 4, box2 is nx4", "\n", "    ", "box2", "=", "box2", ".", "T", "\n", "\n", "# Get the coordinates of bounding boxes", "\n", "if", "x1y1x2y2", ":", "# x1, y1, x2, y2 = box1", "\n", "        ", "b1_x1", ",", "b1_y1", ",", "b1_x2", ",", "b1_y2", "=", "box1", "[", "0", "]", ",", "box1", "[", "1", "]", ",", "box1", "[", "2", "]", ",", "box1", "[", "3", "]", "\n", "b2_x1", ",", "b2_y1", ",", "b2_x2", ",", "b2_y2", "=", "box2", "[", "0", "]", ",", "box2", "[", "1", "]", ",", "box2", "[", "2", "]", ",", "box2", "[", "3", "]", "\n", "", "else", ":", "# transform from xywh to xyxy", "\n", "        ", "b1_x1", ",", "b1_x2", "=", "box1", "[", "0", "]", "-", "box1", "[", "2", "]", "/", "2", ",", "box1", "[", "0", "]", "+", "box1", "[", "2", "]", "/", "2", "\n", "b1_y1", ",", "b1_y2", "=", "box1", "[", "1", "]", "-", "box1", "[", "3", "]", "/", "2", ",", "box1", "[", "1", "]", "+", "box1", "[", "3", "]", "/", "2", "\n", "b2_x1", ",", "b2_x2", "=", "box2", "[", "0", "]", "-", "box2", "[", "2", "]", "/", "2", ",", "box2", "[", "0", "]", "+", "box2", "[", "2", "]", "/", "2", "\n", "b2_y1", ",", "b2_y2", "=", "box2", "[", "1", "]", "-", "box2", "[", "3", "]", "/", "2", ",", "box2", "[", "1", "]", "+", "box2", "[", "3", "]", "/", "2", "\n", "\n", "# Intersection area", "\n", "", "inter", "=", "(", "torch", ".", "min", "(", "b1_x2", ",", "b2_x2", ")", "-", "torch", ".", "max", "(", "b1_x1", ",", "b2_x1", ")", ")", ".", "clamp", "(", "0", ")", "*", "(", "torch", ".", "min", "(", "b1_y2", ",", "b2_y2", ")", "-", "torch", ".", "max", "(", "b1_y1", ",", "b2_y1", ")", ")", ".", "clamp", "(", "0", ")", "\n", "\n", "# Union Area", "\n", "w1", ",", "h1", "=", "b1_x2", "-", "b1_x1", ",", "b1_y2", "-", "b1_y1", "+", "eps", "\n", "w2", ",", "h2", "=", "b2_x2", "-", "b2_x1", ",", "b2_y2", "-", "b2_y1", "+", "eps", "\n", "union", "=", "w1", "*", "h1", "+", "w2", "*", "h2", "-", "inter", "+", "eps", "\n", "\n", "iou", "=", "inter", "/", "union", "\n", "if", "GIoU", "or", "DIoU", "or", "CIoU", "or", "EIoU", "or", "ECIoU", ":", "\n", "        ", "cw", "=", "torch", ".", "max", "(", "b1_x2", ",", "b2_x2", ")", "-", "torch", ".", "min", "(", "b1_x1", ",", "b2_x1", ")", "# convex (smallest enclosing box) width", "\n", "ch", "=", "torch", ".", "max", "(", "b1_y2", ",", "b2_y2", ")", "-", "torch", ".", "min", "(", "b1_y1", ",", "b2_y1", ")", "# convex height", "\n", "if", "CIoU", "or", "DIoU", "or", "EIoU", "or", "ECIoU", ":", "# Distance or Complete IoU https://arxiv.org/abs/1911.08287v1", "\n", "            ", "c2", "=", "cw", "**", "2", "+", "ch", "**", "2", "+", "eps", "# convex diagonal squared", "\n", "rho2", "=", "(", "(", "b2_x1", "+", "b2_x2", "-", "b1_x1", "-", "b1_x2", ")", "**", "2", "+", "\n", "(", "b2_y1", "+", "b2_y2", "-", "b1_y1", "-", "b1_y2", ")", "**", "2", ")", "/", "4", "# center distance squared", "\n", "if", "DIoU", ":", "\n", "                ", "return", "iou", "-", "rho2", "/", "c2", "# DIoU", "\n", "", "elif", "CIoU", ":", "# https://github.com/Zzh-tju/DIoU-SSD-pytorch/blob/master/utils/box/box_utils.py#L47", "\n", "                ", "v", "=", "(", "4", "/", "math", ".", "pi", "**", "2", ")", "*", "torch", ".", "pow", "(", "torch", ".", "atan", "(", "w2", "/", "h2", ")", "-", "torch", ".", "atan", "(", "w1", "/", "h1", ")", ",", "2", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "alpha", "=", "v", "/", "(", "(", "1", "+", "eps", ")", "-", "iou", "+", "v", ")", "\n", "", "return", "iou", "-", "(", "rho2", "/", "c2", "+", "v", "*", "alpha", ")", "# CIoU", "\n", "", "elif", "EIoU", ":", "# Efficient IoU https://arxiv.org/abs/2101.08158", "\n", "                ", "rho3", "=", "(", "w1", "-", "w2", ")", "**", "2", "\n", "c3", "=", "cw", "**", "2", "+", "eps", "\n", "rho4", "=", "(", "h1", "-", "h2", ")", "**", "2", "\n", "c4", "=", "ch", "**", "2", "+", "eps", "\n", "return", "iou", "-", "rho2", "/", "c2", "-", "rho3", "/", "c3", "-", "rho4", "/", "c4", "# EIoU", "\n", "", "elif", "ECIoU", ":", "\n", "                ", "v", "=", "(", "4", "/", "math", ".", "pi", "**", "2", ")", "*", "torch", ".", "pow", "(", "torch", ".", "atan", "(", "w2", "/", "h2", ")", "-", "torch", ".", "atan", "(", "w1", "/", "h1", ")", ",", "2", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                    ", "alpha", "=", "v", "/", "(", "(", "1", "+", "eps", ")", "-", "iou", "+", "v", ")", "\n", "", "rho3", "=", "(", "w1", "-", "w2", ")", "**", "2", "\n", "c3", "=", "cw", "**", "2", "+", "eps", "\n", "rho4", "=", "(", "h1", "-", "h2", ")", "**", "2", "\n", "c4", "=", "ch", "**", "2", "+", "eps", "\n", "return", "iou", "-", "v", "*", "alpha", "-", "rho2", "/", "c2", "-", "rho3", "/", "c3", "-", "rho4", "/", "c4", "# ECIoU", "\n", "", "", "else", ":", "# GIoU https://arxiv.org/pdf/1902.09630.pdf", "\n", "            ", "c_area", "=", "cw", "*", "ch", "+", "eps", "# convex area", "\n", "return", "iou", "-", "(", "c_area", "-", "union", ")", "/", "c_area", "# GIoU", "\n", "", "", "else", ":", "\n", "        ", "return", "iou", "# IoU", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.box_iou": [[247, 270], ["general.box_iou.box_area"], "function", ["None"], ["", "", "def", "box_iou", "(", "box1", ",", "box2", ")", ":", "\n", "# https://github.com/pytorch/vision/blob/master/torchvision/ops/boxes.py", "\n", "    ", "\"\"\"\n    Return intersection-over-union (Jaccard index) of boxes.\n    Both sets of boxes are expected to be in (x1, y1, x2, y2) format.\n    Arguments:\n        box1 (Tensor[N, 4])\n        box2 (Tensor[M, 4])\n    Returns:\n        iou (Tensor[N, M]): the NxM matrix containing the pairwise\n            IoU values for every element in boxes1 and boxes2\n    \"\"\"", "\n", "\n", "def", "box_area", "(", "box", ")", ":", "\n", "# box = 4xn", "\n", "        ", "return", "(", "box", "[", "2", "]", "-", "box", "[", "0", "]", ")", "*", "(", "box", "[", "3", "]", "-", "box", "[", "1", "]", ")", "\n", "\n", "", "area1", "=", "box_area", "(", "box1", ".", "T", ")", "\n", "area2", "=", "box_area", "(", "box2", ".", "T", ")", "\n", "\n", "# inter(N,M) = (rb(N,M,2) - lt(N,M,2)).clamp(0).prod(2)", "\n", "inter", "=", "(", "torch", ".", "min", "(", "box1", "[", ":", ",", "None", ",", "2", ":", "]", ",", "box2", "[", ":", ",", "2", ":", "]", ")", "-", "torch", ".", "max", "(", "box1", "[", ":", ",", "None", ",", ":", "2", "]", ",", "box2", "[", ":", ",", ":", "2", "]", ")", ")", ".", "clamp", "(", "0", ")", ".", "prod", "(", "2", ")", "\n", "return", "inter", "/", "(", "area1", "[", ":", ",", "None", "]", "+", "area2", "-", "inter", ")", "# iou = inter / (area1 + area2 - inter)", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.wh_iou": [[272, 278], ["torch.min().prod", "torch.min", "wh1.prod", "wh2.prod"], "function", ["None"], ["", "def", "wh_iou", "(", "wh1", ",", "wh2", ")", ":", "\n", "# Returns the nxm IoU matrix. wh1 is nx2, wh2 is mx2", "\n", "    ", "wh1", "=", "wh1", "[", ":", ",", "None", "]", "# [N,1,2]", "\n", "wh2", "=", "wh2", "[", "None", "]", "# [1,M,2]", "\n", "inter", "=", "torch", ".", "min", "(", "wh1", ",", "wh2", ")", ".", "prod", "(", "2", ")", "# [N,M]", "\n", "return", "inter", "/", "(", "wh1", ".", "prod", "(", "2", ")", "+", "wh2", ".", "prod", "(", "2", ")", "-", "inter", ")", "# iou = inter / (area1 + area2 - inter)", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.non_max_suppression": [[280, 357], ["time.time", "enumerate", "general.xywh2xyxy", "torch.ops.torchvision.nms", "torch.zeros", "torch.cat", "x[].max", "torch.cat", "general.box_iou", "torch.mm().float", "weights.sum", "time.time", "j[].float", "j.float", "conf.view", "torch.mm", "iou.sum", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xywh2xyxy", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.box_iou"], ["", "def", "non_max_suppression", "(", "prediction", ",", "conf_thres", "=", "0.1", ",", "iou_thres", "=", "0.6", ",", "merge", "=", "False", ",", "classes", "=", "None", ",", "agnostic", "=", "False", ")", ":", "\n", "    ", "\"\"\"Performs Non-Maximum Suppression (NMS) on inference results\n\n    Returns:\n         detections with shape: nx6 (x1, y1, x2, y2, conf, cls)\n    \"\"\"", "\n", "\n", "nc", "=", "prediction", "[", "0", "]", ".", "shape", "[", "1", "]", "-", "5", "# number of classes", "\n", "xc", "=", "prediction", "[", "...", ",", "4", "]", ">", "conf_thres", "# candidates", "\n", "\n", "# Settings", "\n", "min_wh", ",", "max_wh", "=", "2", ",", "4096", "# (pixels) minimum and maximum box width and height", "\n", "max_det", "=", "300", "# maximum number of detections per image", "\n", "time_limit", "=", "10.0", "# seconds to quit after", "\n", "redundant", "=", "True", "# require redundant detections", "\n", "multi_label", "=", "nc", ">", "1", "# multiple labels per box (adds 0.5ms/img)", "\n", "\n", "t", "=", "time", ".", "time", "(", ")", "\n", "output", "=", "[", "torch", ".", "zeros", "(", "0", ",", "6", ")", "]", "*", "prediction", ".", "shape", "[", "0", "]", "\n", "for", "xi", ",", "x", "in", "enumerate", "(", "prediction", ")", ":", "# image index, image inference", "\n", "# Apply constraints", "\n", "# x[((x[..., 2:4] < min_wh) | (x[..., 2:4] > max_wh)).any(1), 4] = 0  # width-height", "\n", "        ", "x", "=", "x", "[", "xc", "[", "xi", "]", "]", "# confidence", "\n", "\n", "# If none remain process next image", "\n", "if", "not", "x", ".", "shape", "[", "0", "]", ":", "\n", "            ", "continue", "\n", "\n", "# Compute conf", "\n", "", "x", "[", ":", ",", "5", ":", "]", "*=", "x", "[", ":", ",", "4", ":", "5", "]", "# conf = obj_conf * cls_conf", "\n", "\n", "# Box (center x, center y, width, height) to (x1, y1, x2, y2)", "\n", "box", "=", "xywh2xyxy", "(", "x", "[", ":", ",", ":", "4", "]", ")", "\n", "\n", "# Detections matrix nx6 (xyxy, conf, cls)", "\n", "if", "multi_label", ":", "\n", "            ", "i", ",", "j", "=", "(", "x", "[", ":", ",", "5", ":", "]", ">", "conf_thres", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "T", "\n", "x", "=", "torch", ".", "cat", "(", "(", "box", "[", "i", "]", ",", "x", "[", "i", ",", "j", "+", "5", ",", "None", "]", ",", "j", "[", ":", ",", "None", "]", ".", "float", "(", ")", ")", ",", "1", ")", "\n", "", "else", ":", "# best class only", "\n", "            ", "conf", ",", "j", "=", "x", "[", ":", ",", "5", ":", "]", ".", "max", "(", "1", ",", "keepdim", "=", "True", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "box", ",", "conf", ",", "j", ".", "float", "(", ")", ")", ",", "1", ")", "[", "conf", ".", "view", "(", "-", "1", ")", ">", "conf_thres", "]", "\n", "\n", "# Filter by class", "\n", "", "if", "classes", ":", "\n", "            ", "x", "=", "x", "[", "(", "x", "[", ":", ",", "5", ":", "6", "]", "==", "torch", ".", "tensor", "(", "classes", ",", "device", "=", "x", ".", "device", ")", ")", ".", "any", "(", "1", ")", "]", "\n", "\n", "# Apply finite constraint", "\n", "# if not torch.isfinite(x).all():", "\n", "#     x = x[torch.isfinite(x).all(1)]", "\n", "\n", "# If none remain process next image", "\n", "", "n", "=", "x", ".", "shape", "[", "0", "]", "# number of boxes", "\n", "if", "not", "n", ":", "\n", "            ", "continue", "\n", "\n", "# Sort by confidence", "\n", "# x = x[x[:, 4].argsort(descending=True)]", "\n", "\n", "# Batched NMS", "\n", "", "c", "=", "x", "[", ":", ",", "5", ":", "6", "]", "*", "(", "0", "if", "agnostic", "else", "max_wh", ")", "# classes", "\n", "boxes", ",", "scores", "=", "x", "[", ":", ",", ":", "4", "]", "+", "c", ",", "x", "[", ":", ",", "4", "]", "# boxes (offset by class), scores", "\n", "i", "=", "torch", ".", "ops", ".", "torchvision", ".", "nms", "(", "boxes", ",", "scores", ",", "iou_thres", ")", "\n", "if", "i", ".", "shape", "[", "0", "]", ">", "max_det", ":", "# limit detections", "\n", "            ", "i", "=", "i", "[", ":", "max_det", "]", "\n", "", "if", "merge", "and", "(", "1", "<", "n", "<", "3E3", ")", ":", "# Merge NMS (boxes merged using weighted mean)", "\n", "# update boxes as boxes(i,4) = weights(i,n) * boxes(n,4)", "\n", "            ", "iou", "=", "box_iou", "(", "boxes", "[", "i", "]", ",", "boxes", ")", ">", "iou_thres", "# iou matrix", "\n", "weights", "=", "iou", "*", "scores", "[", "None", "]", "# box weights", "\n", "x", "[", "i", ",", ":", "4", "]", "=", "torch", ".", "mm", "(", "weights", ",", "x", "[", ":", ",", ":", "4", "]", ")", ".", "float", "(", ")", "/", "weights", ".", "sum", "(", "1", ",", "keepdim", "=", "True", ")", "# merged boxes", "\n", "if", "redundant", ":", "\n", "                ", "i", "=", "i", "[", "iou", ".", "sum", "(", "1", ")", ">", "1", "]", "# require redundancy", "\n", "\n", "", "", "output", "[", "xi", "]", "=", "x", "[", "i", "]", "\n", "if", "(", "time", ".", "time", "(", ")", "-", "t", ")", ">", "time_limit", ":", "\n", "            ", "break", "# time limit exceeded", "\n", "\n", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.strip_optimizer": [[359, 371], ["torch.load", "torch.save", "print", "os.path.getsize", "torch.device"], "function", ["None"], ["", "def", "strip_optimizer", "(", "f", "=", "'weights/best.pt'", ",", "s", "=", "''", ")", ":", "# from utils.general import *; strip_optimizer()", "\n", "# Strip optimizer from 'f' to finalize training, optionally save as 's'", "\n", "    ", "x", "=", "torch", ".", "load", "(", "f", ",", "map_location", "=", "torch", ".", "device", "(", "'cpu'", ")", ")", "\n", "x", "[", "'optimizer'", "]", "=", "None", "\n", "x", "[", "'training_results'", "]", "=", "None", "\n", "x", "[", "'epoch'", "]", "=", "-", "1", "\n", "#x['model'].half()  # to FP16", "\n", "#for p in x['model'].parameters():", "\n", "#    p.requires_grad = False", "\n", "torch", ".", "save", "(", "x", ",", "s", "or", "f", ")", "\n", "mb", "=", "os", ".", "path", ".", "getsize", "(", "s", "or", "f", ")", "/", "1E6", "# filesize", "\n", "print", "(", "'Optimizer stripped from %s,%s %.1fMB'", "%", "(", "f", ",", "(", "' saved as %s,'", "%", "s", ")", "if", "s", "else", "''", ",", "mb", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.print_mutation": [[373, 402], ["print", "numpy.unique", "numpy.savetxt", "enumerate", "tuple", "tuple", "open", "f.write", "numpy.loadtxt", "hyp.keys", "float", "open", "tuple", "f.write", "yaml.dump", "os.system", "len", "hyp.keys", "len", "hyp.values", "len", "utils.google_utils.gsutil_getsize", "os.system", "numpy.argsort", "os.path.exists", "os.path.getsize", "len", "utils.metrics.fitness", "len"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.gsutil_getsize", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.metrics.fitness"], ["", "def", "print_mutation", "(", "hyp", ",", "results", ",", "yaml_file", "=", "'hyp_evolved.yaml'", ",", "bucket", "=", "''", ")", ":", "\n", "# Print mutation results to evolve.txt (for use with train.py --evolve)", "\n", "    ", "a", "=", "'%10s'", "*", "len", "(", "hyp", ")", "%", "tuple", "(", "hyp", ".", "keys", "(", ")", ")", "# hyperparam keys", "\n", "b", "=", "'%10.3g'", "*", "len", "(", "hyp", ")", "%", "tuple", "(", "hyp", ".", "values", "(", ")", ")", "# hyperparam values", "\n", "c", "=", "'%10.4g'", "*", "len", "(", "results", ")", "%", "results", "# results (P, R, mAP@0.5, mAP@0.5:0.95, val_losses x 3)", "\n", "print", "(", "'\\n%s\\n%s\\nEvolved fitness: %s\\n'", "%", "(", "a", ",", "b", ",", "c", ")", ")", "\n", "\n", "if", "bucket", ":", "\n", "        ", "url", "=", "'gs://%s/evolve.txt'", "%", "bucket", "\n", "if", "gsutil_getsize", "(", "url", ")", ">", "(", "os", ".", "path", ".", "getsize", "(", "'evolve.txt'", ")", "if", "os", ".", "path", ".", "exists", "(", "'evolve.txt'", ")", "else", "0", ")", ":", "\n", "            ", "os", ".", "system", "(", "'gsutil cp %s .'", "%", "url", ")", "# download evolve.txt if larger than local", "\n", "\n", "", "", "with", "open", "(", "'evolve.txt'", ",", "'a'", ")", "as", "f", ":", "# append result", "\n", "        ", "f", ".", "write", "(", "c", "+", "b", "+", "'\\n'", ")", "\n", "", "x", "=", "np", ".", "unique", "(", "np", ".", "loadtxt", "(", "'evolve.txt'", ",", "ndmin", "=", "2", ")", ",", "axis", "=", "0", ")", "# load unique rows", "\n", "x", "=", "x", "[", "np", ".", "argsort", "(", "-", "fitness", "(", "x", ")", ")", "]", "# sort", "\n", "np", ".", "savetxt", "(", "'evolve.txt'", ",", "x", ",", "'%10.3g'", ")", "# save sort by fitness", "\n", "\n", "# Save yaml", "\n", "for", "i", ",", "k", "in", "enumerate", "(", "hyp", ".", "keys", "(", ")", ")", ":", "\n", "        ", "hyp", "[", "k", "]", "=", "float", "(", "x", "[", "0", ",", "i", "+", "7", "]", ")", "\n", "", "with", "open", "(", "yaml_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "results", "=", "tuple", "(", "x", "[", "0", ",", ":", "7", "]", ")", "\n", "c", "=", "'%10.4g'", "*", "len", "(", "results", ")", "%", "results", "# results (P, R, mAP@0.5, mAP@0.5:0.95, val_losses x 3)", "\n", "f", ".", "write", "(", "'# Hyperparameter Evolution Results\\n# Generations: %g\\n# Metrics: '", "%", "len", "(", "x", ")", "+", "c", "+", "'\\n\\n'", ")", "\n", "yaml", ".", "dump", "(", "hyp", ",", "f", ",", "sort_keys", "=", "False", ")", "\n", "\n", "", "if", "bucket", ":", "\n", "        ", "os", ".", "system", "(", "'gsutil cp evolve.txt %s gs://%s'", "%", "(", "yaml_file", ",", "bucket", ")", ")", "# upload", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.apply_classifier": [[404, 437], ["enumerate", "isinstance", "len", "d.clone.clone", "general.xyxy2xywh", "[].unsqueeze", "xywh2xyxy().long", "general.scale_coords", "d[].long", "enumerate", "model().argmax", "cv2.resize", "im[].transpose", "numpy.ascontiguousarray", "ims.append", "general.xywh2xyxy", "model", "b[].max", "torch.Tensor().to", "int", "int", "int", "int", "torch.Tensor"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.scale_coords", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xywh2xyxy"], ["", "", "def", "apply_classifier", "(", "x", ",", "model", ",", "img", ",", "im0", ")", ":", "\n", "# applies a second stage classifier to yolo outputs", "\n", "    ", "im0", "=", "[", "im0", "]", "if", "isinstance", "(", "im0", ",", "np", ".", "ndarray", ")", "else", "im0", "\n", "for", "i", ",", "d", "in", "enumerate", "(", "x", ")", ":", "# per image", "\n", "        ", "if", "d", "is", "not", "None", "and", "len", "(", "d", ")", ":", "\n", "            ", "d", "=", "d", ".", "clone", "(", ")", "\n", "\n", "# Reshape and pad cutouts", "\n", "b", "=", "xyxy2xywh", "(", "d", "[", ":", ",", ":", "4", "]", ")", "# boxes", "\n", "b", "[", ":", ",", "2", ":", "]", "=", "b", "[", ":", ",", "2", ":", "]", ".", "max", "(", "1", ")", "[", "0", "]", ".", "unsqueeze", "(", "1", ")", "# rectangle to square", "\n", "b", "[", ":", ",", "2", ":", "]", "=", "b", "[", ":", ",", "2", ":", "]", "*", "1.3", "+", "30", "# pad", "\n", "d", "[", ":", ",", ":", "4", "]", "=", "xywh2xyxy", "(", "b", ")", ".", "long", "(", ")", "\n", "\n", "# Rescale boxes from img_size to im0 size", "\n", "scale_coords", "(", "img", ".", "shape", "[", "2", ":", "]", ",", "d", "[", ":", ",", ":", "4", "]", ",", "im0", "[", "i", "]", ".", "shape", ")", "\n", "\n", "# Classes", "\n", "pred_cls1", "=", "d", "[", ":", ",", "5", "]", ".", "long", "(", ")", "\n", "ims", "=", "[", "]", "\n", "for", "j", ",", "a", "in", "enumerate", "(", "d", ")", ":", "# per item", "\n", "                ", "cutout", "=", "im0", "[", "i", "]", "[", "int", "(", "a", "[", "1", "]", ")", ":", "int", "(", "a", "[", "3", "]", ")", ",", "int", "(", "a", "[", "0", "]", ")", ":", "int", "(", "a", "[", "2", "]", ")", "]", "\n", "im", "=", "cv2", ".", "resize", "(", "cutout", ",", "(", "224", ",", "224", ")", ")", "# BGR", "\n", "# cv2.imwrite('test%i.jpg' % j, cutout)", "\n", "\n", "im", "=", "im", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "im", "=", "np", ".", "ascontiguousarray", "(", "im", ",", "dtype", "=", "np", ".", "float32", ")", "# uint8 to float32", "\n", "im", "/=", "255.0", "# 0 - 255 to 0.0 - 1.0", "\n", "ims", ".", "append", "(", "im", ")", "\n", "\n", "", "pred_cls2", "=", "model", "(", "torch", ".", "Tensor", "(", "ims", ")", ".", "to", "(", "d", ".", "device", ")", ")", ".", "argmax", "(", "1", ")", "# classifier prediction", "\n", "x", "[", "i", "]", "=", "x", "[", "i", "]", "[", "pred_cls1", "==", "pred_cls2", "]", "# retain matching class detections", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.increment_path": [[439, 450], ["pathlib.Path", "str", "glob.glob", "pathlib.Path.exists", "pathlib.Path.exists", "re.search", "int", "max", "m.groups"], "function", ["None"], ["", "def", "increment_path", "(", "path", ",", "exist_ok", "=", "True", ",", "sep", "=", "''", ")", ":", "\n", "# Increment path, i.e. runs/exp --> runs/exp{sep}0, runs/exp{sep}1 etc.", "\n", "    ", "path", "=", "Path", "(", "path", ")", "# os-agnostic", "\n", "if", "(", "path", ".", "exists", "(", ")", "and", "exist_ok", ")", "or", "(", "not", "path", ".", "exists", "(", ")", ")", ":", "\n", "        ", "return", "str", "(", "path", ")", "\n", "", "else", ":", "\n", "        ", "dirs", "=", "glob", ".", "glob", "(", "f\"{path}{sep}*\"", ")", "# similar paths", "\n", "matches", "=", "[", "re", ".", "search", "(", "rf\"%s{sep}(\\d+)\"", "%", "path", ".", "stem", ",", "d", ")", "for", "d", "in", "dirs", "]", "\n", "i", "=", "[", "int", "(", "m", ".", "groups", "(", ")", "[", "0", "]", ")", "for", "m", "in", "matches", "if", "m", "]", "# indices", "\n", "n", "=", "max", "(", "i", ")", "+", "1", "if", "i", "else", "2", "# increment number", "\n", "return", "f\"{path}{sep}{n}\"", "# update path", "\n", "", "", ""]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.InfiniteDataLoader.__init__": [[118, 122], ["super().__init__", "object.__setattr__", "super().__iter__", "datasets._RepeatSampler"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.__iter__"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "object", ".", "__setattr__", "(", "self", ",", "'batch_sampler'", ",", "_RepeatSampler", "(", "self", ".", "batch_sampler", ")", ")", "\n", "self", ".", "iterator", "=", "super", "(", ")", ".", "__iter__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.InfiniteDataLoader.__len__": [[123, 125], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "batch_sampler", ".", "sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.InfiniteDataLoader.__iter__": [[126, 129], ["range", "len", "next"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "self", ")", ")", ":", "\n", "            ", "yield", "next", "(", "self", ".", "iterator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets._RepeatSampler.__init__": [[138, 140], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "sampler", ")", ":", "\n", "        ", "self", ".", "sampler", "=", "sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets._RepeatSampler.__iter__": [[141, 144], ["iter"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "while", "True", ":", "\n", "            ", "yield", "from", "iter", "(", "self", ".", "sampler", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImages.__init__": [[147, 175], ["str", "os.path.abspath", "any", "pathlib.Path", "sorted", "os.path.isdir", "len", "len", "datasets.LoadImages.new_video", "glob.glob", "sorted", "os.path.isfile", "glob.glob", "Exception", "[].lower", "[].lower", "os.path.join", "x.split", "x.split"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImages.new_video"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "img_size", "=", "640", ",", "auto_size", "=", "32", ")", ":", "\n", "        ", "p", "=", "str", "(", "Path", "(", "path", ")", ")", "# os-agnostic", "\n", "p", "=", "os", ".", "path", ".", "abspath", "(", "p", ")", "# absolute path", "\n", "if", "'*'", "in", "p", ":", "\n", "            ", "files", "=", "sorted", "(", "glob", ".", "glob", "(", "p", ",", "recursive", "=", "True", ")", ")", "# glob", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "p", ")", ":", "\n", "            ", "files", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "p", ",", "'*.*'", ")", ")", ")", "# dir", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "p", ")", ":", "\n", "            ", "files", "=", "[", "p", "]", "# files", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'ERROR: %s does not exist'", "%", "p", ")", "\n", "\n", "", "images", "=", "[", "x", "for", "x", "in", "files", "if", "x", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "in", "img_formats", "]", "\n", "videos", "=", "[", "x", "for", "x", "in", "files", "if", "x", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "in", "vid_formats", "]", "\n", "ni", ",", "nv", "=", "len", "(", "images", ")", ",", "len", "(", "videos", ")", "\n", "\n", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "auto_size", "=", "auto_size", "\n", "self", ".", "files", "=", "images", "+", "videos", "\n", "self", ".", "nf", "=", "ni", "+", "nv", "# number of files", "\n", "self", ".", "video_flag", "=", "[", "False", "]", "*", "ni", "+", "[", "True", "]", "*", "nv", "\n", "self", ".", "mode", "=", "'images'", "\n", "if", "any", "(", "videos", ")", ":", "\n", "            ", "self", ".", "new_video", "(", "videos", "[", "0", "]", ")", "# new video", "\n", "", "else", ":", "\n", "            ", "self", ".", "cap", "=", "None", "\n", "", "assert", "self", ".", "nf", ">", "0", ",", "'No images or videos found in %s. Supported formats are:\\nimages: %s\\nvideos: %s'", "%", "(", "p", ",", "img_formats", ",", "vid_formats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImages.__iter__": [[176, 179], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "0", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImages.__next__": [[180, 217], ["img[].transpose", "numpy.ascontiguousarray", "datasets.LoadImages.cap.read", "print", "cv2.imread", "print", "datasets.letterbox", "datasets.LoadImages.cap.release", "datasets.LoadImages.new_video", "datasets.LoadImages.cap.read"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.letterbox", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImages.new_video"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "count", "==", "self", ".", "nf", ":", "\n", "            ", "raise", "StopIteration", "\n", "", "path", "=", "self", ".", "files", "[", "self", ".", "count", "]", "\n", "\n", "if", "self", ".", "video_flag", "[", "self", ".", "count", "]", ":", "\n", "# Read video", "\n", "            ", "self", ".", "mode", "=", "'video'", "\n", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "if", "not", "ret_val", ":", "\n", "                ", "self", ".", "count", "+=", "1", "\n", "self", ".", "cap", ".", "release", "(", ")", "\n", "if", "self", ".", "count", "==", "self", ".", "nf", ":", "# last video", "\n", "                    ", "raise", "StopIteration", "\n", "", "else", ":", "\n", "                    ", "path", "=", "self", ".", "files", "[", "self", ".", "count", "]", "\n", "self", ".", "new_video", "(", "path", ")", "\n", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "\n", "", "", "self", ".", "frame", "+=", "1", "\n", "print", "(", "'video %g/%g (%g/%g) %s: '", "%", "(", "self", ".", "count", "+", "1", ",", "self", ".", "nf", ",", "self", ".", "frame", ",", "self", ".", "nframes", ",", "path", ")", ",", "end", "=", "''", ")", "\n", "\n", "", "else", ":", "\n", "# Read image", "\n", "            ", "self", ".", "count", "+=", "1", "\n", "img0", "=", "cv2", ".", "imread", "(", "path", ")", "# BGR", "\n", "assert", "img0", "is", "not", "None", ",", "'Image Not Found '", "+", "path", "\n", "print", "(", "'image %g/%g %s: '", "%", "(", "self", ".", "count", ",", "self", ".", "nf", ",", "path", ")", ",", "end", "=", "''", ")", "\n", "\n", "# Padded resize", "\n", "", "img", "=", "letterbox", "(", "img0", ",", "new_shape", "=", "self", ".", "img_size", ",", "auto_size", "=", "self", ".", "auto_size", ")", "[", "0", "]", "\n", "\n", "# Convert", "\n", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "path", ",", "img", ",", "img0", ",", "self", ".", "cap", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImages.new_video": [[218, 222], ["cv2.VideoCapture", "int", "datasets.LoadImages.cap.get"], "methods", ["None"], ["", "def", "new_video", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "frame", "=", "0", "\n", "self", ".", "cap", "=", "cv2", ".", "VideoCapture", "(", "path", ")", "\n", "self", ".", "nframes", "=", "int", "(", "self", ".", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_COUNT", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImages.__len__": [[223, 225], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "nf", "# number of files", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadWebcam.__init__": [[228, 240], ["eval.isnumeric", "cv2.VideoCapture", "datasets.LoadWebcam.cap.set", "eval"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "pipe", "=", "'0'", ",", "img_size", "=", "640", ")", ":", "\n", "        ", "self", ".", "img_size", "=", "img_size", "\n", "\n", "if", "pipe", ".", "isnumeric", "(", ")", ":", "\n", "            ", "pipe", "=", "eval", "(", "pipe", ")", "# local camera", "\n", "# pipe = 'rtsp://192.168.1.64/1'  # IP camera", "\n", "# pipe = 'rtsp://username:password@192.168.1.64/1'  # IP camera with login", "\n", "# pipe = 'http://wmccpinetop.axiscam.net/mjpg/video.mjpg'  # IP golf camera", "\n", "\n", "", "self", ".", "pipe", "=", "pipe", "\n", "self", ".", "cap", "=", "cv2", ".", "VideoCapture", "(", "pipe", ")", "# video capture object", "\n", "self", ".", "cap", ".", "set", "(", "cv2", ".", "CAP_PROP_BUFFERSIZE", ",", "3", ")", "# set buffer size", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadWebcam.__iter__": [[241, 244], ["None"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "-", "1", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadWebcam.__next__": [[245, 279], ["print", "img[].transpose", "numpy.ascontiguousarray", "cv2.waitKey", "ord", "datasets.LoadWebcam.cap.release", "cv2.destroyAllWindows", "datasets.LoadWebcam.cap.read", "cv2.flip", "datasets.letterbox", "datasets.LoadWebcam.cap.grab", "datasets.LoadWebcam.cap.retrieve"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.letterbox"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "+=", "1", "\n", "if", "cv2", ".", "waitKey", "(", "1", ")", "==", "ord", "(", "'q'", ")", ":", "# q to quit", "\n", "            ", "self", ".", "cap", ".", "release", "(", ")", "\n", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "# Read frame", "\n", "", "if", "self", ".", "pipe", "==", "0", ":", "# local camera", "\n", "            ", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "read", "(", ")", "\n", "img0", "=", "cv2", ".", "flip", "(", "img0", ",", "1", ")", "# flip left-right", "\n", "", "else", ":", "# IP camera", "\n", "            ", "n", "=", "0", "\n", "while", "True", ":", "\n", "                ", "n", "+=", "1", "\n", "self", ".", "cap", ".", "grab", "(", ")", "\n", "if", "n", "%", "30", "==", "0", ":", "# skip frames", "\n", "                    ", "ret_val", ",", "img0", "=", "self", ".", "cap", ".", "retrieve", "(", ")", "\n", "if", "ret_val", ":", "\n", "                        ", "break", "\n", "\n", "# Print", "\n", "", "", "", "", "assert", "ret_val", ",", "'Camera Error %s'", "%", "self", ".", "pipe", "\n", "img_path", "=", "'webcam.jpg'", "\n", "print", "(", "'webcam %g: '", "%", "self", ".", "count", ",", "end", "=", "''", ")", "\n", "\n", "# Padded resize", "\n", "img", "=", "letterbox", "(", "img0", ",", "new_shape", "=", "self", ".", "img_size", ")", "[", "0", "]", "\n", "\n", "# Convert", "\n", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "img_path", ",", "img", ",", "img0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadWebcam.__len__": [[280, 282], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.__init__": [[285, 317], ["os.path.isfile", "len", "enumerate", "print", "numpy.stack", "print", "cv2.VideoCapture", "cv2.VideoCapture.isOpened", "int", "int", "cv2.VideoCapture.read", "threading.Thread", "print", "threading.Thread.start", "print", "open", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "cv2.VideoCapture.get", "x.strip", "numpy.stack.isnumeric", "eval", "numpy.unique", "f.read().splitlines", "len", "datasets.letterbox", "x.strip", "f.read"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.letterbox"], ["    ", "def", "__init__", "(", "self", ",", "sources", "=", "'streams.txt'", ",", "img_size", "=", "640", ")", ":", "\n", "        ", "self", ".", "mode", "=", "'images'", "\n", "self", ".", "img_size", "=", "img_size", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "sources", ")", ":", "\n", "            ", "with", "open", "(", "sources", ",", "'r'", ")", "as", "f", ":", "\n", "                ", "sources", "=", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "if", "len", "(", "x", ".", "strip", "(", ")", ")", "]", "\n", "", "", "else", ":", "\n", "            ", "sources", "=", "[", "sources", "]", "\n", "\n", "", "n", "=", "len", "(", "sources", ")", "\n", "self", ".", "imgs", "=", "[", "None", "]", "*", "n", "\n", "self", ".", "sources", "=", "sources", "\n", "for", "i", ",", "s", "in", "enumerate", "(", "sources", ")", ":", "\n", "# Start the thread to read frames from the video stream", "\n", "            ", "print", "(", "'%g/%g: %s... '", "%", "(", "i", "+", "1", ",", "n", ",", "s", ")", ",", "end", "=", "''", ")", "\n", "cap", "=", "cv2", ".", "VideoCapture", "(", "eval", "(", "s", ")", "if", "s", ".", "isnumeric", "(", ")", "else", "s", ")", "\n", "assert", "cap", ".", "isOpened", "(", ")", ",", "'Failed to open %s'", "%", "s", "\n", "w", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_WIDTH", ")", ")", "\n", "h", "=", "int", "(", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FRAME_HEIGHT", ")", ")", "\n", "fps", "=", "cap", ".", "get", "(", "cv2", ".", "CAP_PROP_FPS", ")", "%", "100", "\n", "_", ",", "self", ".", "imgs", "[", "i", "]", "=", "cap", ".", "read", "(", ")", "# guarantee first frame", "\n", "thread", "=", "Thread", "(", "target", "=", "self", ".", "update", ",", "args", "=", "(", "[", "i", ",", "cap", "]", ")", ",", "daemon", "=", "True", ")", "\n", "print", "(", "' success (%gx%g at %.2f FPS).'", "%", "(", "w", ",", "h", ",", "fps", ")", ")", "\n", "thread", ".", "start", "(", ")", "\n", "", "print", "(", "''", ")", "# newline", "\n", "\n", "# check for common shapes", "\n", "s", "=", "np", ".", "stack", "(", "[", "letterbox", "(", "x", ",", "new_shape", "=", "self", ".", "img_size", ")", "[", "0", "]", ".", "shape", "for", "x", "in", "self", ".", "imgs", "]", ",", "0", ")", "# inference shapes", "\n", "self", ".", "rect", "=", "np", ".", "unique", "(", "s", ",", "axis", "=", "0", ")", ".", "shape", "[", "0", "]", "==", "1", "# rect inference if all shapes equal", "\n", "if", "not", "self", ".", "rect", ":", "\n", "            ", "print", "(", "'WARNING: Different stream shapes detected. For optimal performance supply similarly-shaped streams.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.update": [[318, 329], ["cap.isOpened", "cap.grab", "time.sleep", "cap.retrieve"], "methods", ["None"], ["", "", "def", "update", "(", "self", ",", "index", ",", "cap", ")", ":", "\n", "# Read next stream frame in a daemon thread", "\n", "        ", "n", "=", "0", "\n", "while", "cap", ".", "isOpened", "(", ")", ":", "\n", "            ", "n", "+=", "1", "\n", "# _, self.imgs[index] = cap.read()", "\n", "cap", ".", "grab", "(", ")", "\n", "if", "n", "==", "4", ":", "# read every 4th frame", "\n", "                ", "_", ",", "self", ".", "imgs", "[", "index", "]", "=", "cap", ".", "retrieve", "(", ")", "\n", "n", "=", "0", "\n", "", "time", ".", "sleep", "(", "0.01", ")", "# wait time", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.__iter__": [[330, 333], ["None"], "methods", ["None"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "=", "-", "1", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.__next__": [[334, 352], ["datasets.LoadStreams.imgs.copy", "numpy.stack", "img[].transpose", "numpy.ascontiguousarray", "cv2.waitKey", "ord", "cv2.destroyAllWindows", "datasets.letterbox"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.letterbox"], ["", "def", "__next__", "(", "self", ")", ":", "\n", "        ", "self", ".", "count", "+=", "1", "\n", "img0", "=", "self", ".", "imgs", ".", "copy", "(", ")", "\n", "if", "cv2", ".", "waitKey", "(", "1", ")", "==", "ord", "(", "'q'", ")", ":", "# q to quit", "\n", "            ", "cv2", ".", "destroyAllWindows", "(", ")", "\n", "raise", "StopIteration", "\n", "\n", "# Letterbox", "\n", "", "img", "=", "[", "letterbox", "(", "x", ",", "new_shape", "=", "self", ".", "img_size", ",", "auto", "=", "self", ".", "rect", ")", "[", "0", "]", "for", "x", "in", "img0", "]", "\n", "\n", "# Stack", "\n", "img", "=", "np", ".", "stack", "(", "img", ",", "0", ")", "\n", "\n", "# Convert", "\n", "img", "=", "img", "[", ":", ",", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "0", ",", "3", ",", "1", ",", "2", ")", "# BGR to RGB, to bsx3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "self", ".", "sources", ",", "img", ",", "img0", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadStreams.__len__": [[353, 355], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "0", "# 1E12 frames = 32 streams at 30 FPS for 30 years", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels.__init__": [[358, 512], ["datasets.LoadImagesAndLabels.__init__.img2label_paths"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "img_size", "=", "640", ",", "batch_size", "=", "16", ",", "augment", "=", "False", ",", "hyp", "=", "None", ",", "rect", "=", "False", ",", "image_weights", "=", "False", ",", "\n", "cache_images", "=", "False", ",", "single_cls", "=", "False", ",", "stride", "=", "32", ",", "pad", "=", "0.0", ",", "rank", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "augment", "=", "augment", "\n", "self", ".", "hyp", "=", "hyp", "\n", "self", ".", "image_weights", "=", "image_weights", "\n", "self", ".", "rect", "=", "False", "if", "image_weights", "else", "rect", "\n", "self", ".", "mosaic", "=", "self", ".", "augment", "and", "not", "self", ".", "rect", "# load 4 images at a time into a mosaic (only during training)", "\n", "self", ".", "mosaic_border", "=", "[", "-", "img_size", "//", "2", ",", "-", "img_size", "//", "2", "]", "\n", "self", ".", "stride", "=", "stride", "\n", "\n", "def", "img2label_paths", "(", "img_paths", ")", ":", "\n", "# Define label paths as a function of image paths", "\n", "            ", "sa", ",", "sb", "=", "os", ".", "sep", "+", "'images'", "+", "os", ".", "sep", ",", "os", ".", "sep", "+", "'labels'", "+", "os", ".", "sep", "# /images/, /labels/ substrings", "\n", "return", "[", "x", ".", "replace", "(", "sa", ",", "sb", ",", "1", ")", ".", "replace", "(", "x", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ",", "'txt'", ")", "for", "x", "in", "img_paths", "]", "\n", "\n", "", "try", ":", "\n", "            ", "f", "=", "[", "]", "# image files", "\n", "for", "p", "in", "path", "if", "isinstance", "(", "path", ",", "list", ")", "else", "[", "path", "]", ":", "\n", "                ", "p", "=", "Path", "(", "p", ")", "# os-agnostic", "\n", "if", "p", ".", "is_dir", "(", ")", ":", "# dir", "\n", "                    ", "f", "+=", "glob", ".", "glob", "(", "str", "(", "p", "/", "'**'", "/", "'*.*'", ")", ",", "recursive", "=", "True", ")", "\n", "", "elif", "p", ".", "is_file", "(", ")", ":", "# file", "\n", "                    ", "with", "open", "(", "p", ",", "'r'", ")", "as", "t", ":", "\n", "                        ", "t", "=", "t", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "parent", "=", "str", "(", "p", ".", "parent", ")", "+", "os", ".", "sep", "\n", "f", "+=", "[", "x", ".", "replace", "(", "'./'", ",", "parent", ")", "if", "x", ".", "startswith", "(", "'./'", ")", "else", "x", "for", "x", "in", "t", "]", "# local to global path", "\n", "", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'%s does not exist'", "%", "p", ")", "\n", "", "", "self", ".", "img_files", "=", "sorted", "(", "[", "x", ".", "replace", "(", "'/'", ",", "os", ".", "sep", ")", "for", "x", "in", "f", "if", "x", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "in", "img_formats", "]", ")", "\n", "assert", "self", ".", "img_files", ",", "'No images found'", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "'Error loading data from %s: %s\\nSee %s'", "%", "(", "path", ",", "e", ",", "help_url", ")", ")", "\n", "\n", "# Check cache", "\n", "", "self", ".", "label_files", "=", "img2label_paths", "(", "self", ".", "img_files", ")", "# labels", "\n", "cache_path", "=", "str", "(", "Path", "(", "self", ".", "label_files", "[", "0", "]", ")", ".", "parent", ")", "+", "'.cache3'", "# cached labels", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cache_path", ")", ":", "\n", "            ", "cache", "=", "torch", ".", "load", "(", "cache_path", ")", "# load", "\n", "if", "cache", "[", "'hash'", "]", "!=", "get_hash", "(", "self", ".", "label_files", "+", "self", ".", "img_files", ")", ":", "# dataset changed", "\n", "                ", "cache", "=", "self", ".", "cache_labels", "(", "cache_path", ")", "# re-cache", "\n", "", "", "else", ":", "\n", "            ", "cache", "=", "self", ".", "cache_labels", "(", "cache_path", ")", "# cache", "\n", "\n", "# Read cache", "\n", "", "cache", ".", "pop", "(", "'hash'", ")", "# remove hash", "\n", "labels", ",", "shapes", "=", "zip", "(", "*", "cache", ".", "values", "(", ")", ")", "\n", "self", ".", "labels", "=", "list", "(", "labels", ")", "\n", "self", ".", "shapes", "=", "np", ".", "array", "(", "shapes", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "img_files", "=", "list", "(", "cache", ".", "keys", "(", ")", ")", "# update", "\n", "self", ".", "label_files", "=", "img2label_paths", "(", "cache", ".", "keys", "(", ")", ")", "# update", "\n", "\n", "n", "=", "len", "(", "shapes", ")", "# number of images", "\n", "bi", "=", "np", ".", "floor", "(", "np", ".", "arange", "(", "n", ")", "/", "batch_size", ")", ".", "astype", "(", "np", ".", "int", ")", "# batch index", "\n", "nb", "=", "bi", "[", "-", "1", "]", "+", "1", "# number of batches", "\n", "self", ".", "batch", "=", "bi", "# batch index of image", "\n", "self", ".", "n", "=", "n", "\n", "\n", "# Rectangular Training", "\n", "if", "self", ".", "rect", ":", "\n", "# Sort by aspect ratio", "\n", "            ", "s", "=", "self", ".", "shapes", "# wh", "\n", "ar", "=", "s", "[", ":", ",", "1", "]", "/", "s", "[", ":", ",", "0", "]", "# aspect ratio", "\n", "irect", "=", "ar", ".", "argsort", "(", ")", "\n", "self", ".", "img_files", "=", "[", "self", ".", "img_files", "[", "i", "]", "for", "i", "in", "irect", "]", "\n", "self", ".", "label_files", "=", "[", "self", ".", "label_files", "[", "i", "]", "for", "i", "in", "irect", "]", "\n", "self", ".", "labels", "=", "[", "self", ".", "labels", "[", "i", "]", "for", "i", "in", "irect", "]", "\n", "self", ".", "shapes", "=", "s", "[", "irect", "]", "# wh", "\n", "ar", "=", "ar", "[", "irect", "]", "\n", "\n", "# Set training image shapes", "\n", "shapes", "=", "[", "[", "1", ",", "1", "]", "]", "*", "nb", "\n", "for", "i", "in", "range", "(", "nb", ")", ":", "\n", "                ", "ari", "=", "ar", "[", "bi", "==", "i", "]", "\n", "mini", ",", "maxi", "=", "ari", ".", "min", "(", ")", ",", "ari", ".", "max", "(", ")", "\n", "if", "maxi", "<", "1", ":", "\n", "                    ", "shapes", "[", "i", "]", "=", "[", "maxi", ",", "1", "]", "\n", "", "elif", "mini", ">", "1", ":", "\n", "                    ", "shapes", "[", "i", "]", "=", "[", "1", ",", "1", "/", "mini", "]", "\n", "\n", "", "", "self", ".", "batch_shapes", "=", "np", ".", "ceil", "(", "np", ".", "array", "(", "shapes", ")", "*", "img_size", "/", "stride", "+", "pad", ")", ".", "astype", "(", "np", ".", "int", ")", "*", "stride", "\n", "\n", "# Check labels", "\n", "", "create_datasubset", ",", "extract_bounding_boxes", ",", "labels_loaded", "=", "False", ",", "False", ",", "False", "\n", "nm", ",", "nf", ",", "ne", ",", "ns", ",", "nd", "=", "0", ",", "0", ",", "0", ",", "0", ",", "0", "# number missing, found, empty, datasubset, duplicate", "\n", "pbar", "=", "enumerate", "(", "self", ".", "label_files", ")", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "pbar", "=", "tqdm", "(", "pbar", ")", "\n", "", "for", "i", ",", "file", "in", "pbar", ":", "\n", "            ", "l", "=", "self", ".", "labels", "[", "i", "]", "# label", "\n", "if", "l", "is", "not", "None", "and", "l", ".", "shape", "[", "0", "]", ":", "\n", "                ", "assert", "l", ".", "shape", "[", "1", "]", "==", "5", ",", "'> 5 label columns: %s'", "%", "file", "\n", "assert", "(", "l", ">=", "0", ")", ".", "all", "(", ")", ",", "'negative labels: %s'", "%", "file", "\n", "assert", "(", "l", "[", ":", ",", "1", ":", "]", "<=", "1", ")", ".", "all", "(", ")", ",", "'non-normalized or out of bounds coordinate labels: %s'", "%", "file", "\n", "if", "np", ".", "unique", "(", "l", ",", "axis", "=", "0", ")", ".", "shape", "[", "0", "]", "<", "l", ".", "shape", "[", "0", "]", ":", "# duplicate rows", "\n", "                    ", "nd", "+=", "1", "# print('WARNING: duplicate rows in %s' % self.label_files[i])  # duplicate rows", "\n", "", "if", "single_cls", ":", "\n", "                    ", "l", "[", ":", ",", "0", "]", "=", "0", "# force dataset into single-class mode", "\n", "", "self", ".", "labels", "[", "i", "]", "=", "l", "\n", "nf", "+=", "1", "# file found", "\n", "\n", "# Create subdataset (a smaller dataset)", "\n", "if", "create_datasubset", "and", "ns", "<", "1E4", ":", "\n", "                    ", "if", "ns", "==", "0", ":", "\n", "                        ", "create_folder", "(", "path", "=", "'./datasubset'", ")", "\n", "os", ".", "makedirs", "(", "'./datasubset/images'", ")", "\n", "", "exclude_classes", "=", "43", "\n", "if", "exclude_classes", "not", "in", "l", "[", ":", ",", "0", "]", ":", "\n", "                        ", "ns", "+=", "1", "\n", "# shutil.copy(src=self.img_files[i], dst='./datasubset/images/')  # copy image", "\n", "with", "open", "(", "'./datasubset/images.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "                            ", "f", ".", "write", "(", "self", ".", "img_files", "[", "i", "]", "+", "'\\n'", ")", "\n", "\n", "# Extract object detection boxes for a second stage classifier", "\n", "", "", "", "if", "extract_bounding_boxes", ":", "\n", "                    ", "p", "=", "Path", "(", "self", ".", "img_files", "[", "i", "]", ")", "\n", "img", "=", "cv2", ".", "imread", "(", "str", "(", "p", ")", ")", "\n", "h", ",", "w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "for", "j", ",", "x", "in", "enumerate", "(", "l", ")", ":", "\n", "                        ", "f", "=", "'%s%sclassifier%s%g_%g_%s'", "%", "(", "p", ".", "parent", ".", "parent", ",", "os", ".", "sep", ",", "os", ".", "sep", ",", "x", "[", "0", "]", ",", "j", ",", "p", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "Path", "(", "f", ")", ".", "parent", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "Path", "(", "f", ")", ".", "parent", ")", "# make new output folder", "\n", "\n", "", "b", "=", "x", "[", "1", ":", "]", "*", "[", "w", ",", "h", ",", "w", ",", "h", "]", "# box", "\n", "b", "[", "2", ":", "]", "=", "b", "[", "2", ":", "]", ".", "max", "(", ")", "# rectangle to square", "\n", "b", "[", "2", ":", "]", "=", "b", "[", "2", ":", "]", "*", "1.3", "+", "30", "# pad", "\n", "b", "=", "xywh2xyxy", "(", "b", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", ".", "ravel", "(", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "b", "[", "[", "0", ",", "2", "]", "]", "=", "np", ".", "clip", "(", "b", "[", "[", "0", ",", "2", "]", "]", ",", "0", ",", "w", ")", "# clip boxes outside of image", "\n", "b", "[", "[", "1", ",", "3", "]", "]", "=", "np", ".", "clip", "(", "b", "[", "[", "1", ",", "3", "]", "]", ",", "0", ",", "h", ")", "\n", "assert", "cv2", ".", "imwrite", "(", "f", ",", "img", "[", "b", "[", "1", "]", ":", "b", "[", "3", "]", ",", "b", "[", "0", "]", ":", "b", "[", "2", "]", "]", ")", ",", "'Failure extracting classifier boxes'", "\n", "", "", "", "else", ":", "\n", "                ", "ne", "+=", "1", "# print('empty labels for image %s' % self.img_files[i])  # file empty", "\n", "# os.system(\"rm '%s' '%s'\" % (self.img_files[i], self.label_files[i]))  # remove", "\n", "\n", "", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "pbar", ".", "desc", "=", "'Scanning labels %s (%g found, %g missing, %g empty, %g duplicate, for %g images)'", "%", "(", "\n", "cache_path", ",", "nf", ",", "nm", ",", "ne", ",", "nd", ",", "n", ")", "\n", "", "", "if", "nf", "==", "0", ":", "\n", "            ", "s", "=", "'WARNING: No labels found in %s. See %s'", "%", "(", "os", ".", "path", ".", "dirname", "(", "file", ")", "+", "os", ".", "sep", ",", "help_url", ")", "\n", "print", "(", "s", ")", "\n", "assert", "not", "augment", ",", "'%s. Can not train without labels.'", "%", "s", "\n", "\n", "# Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)", "\n", "", "self", ".", "imgs", "=", "[", "None", "]", "*", "n", "\n", "if", "cache_images", ":", "\n", "            ", "gb", "=", "0", "# Gigabytes of cached images", "\n", "self", ".", "img_hw0", ",", "self", ".", "img_hw", "=", "[", "None", "]", "*", "n", ",", "[", "None", "]", "*", "n", "\n", "results", "=", "ThreadPool", "(", "8", ")", ".", "imap", "(", "lambda", "x", ":", "load_image", "(", "*", "x", ")", ",", "zip", "(", "repeat", "(", "self", ")", ",", "range", "(", "n", ")", ")", ")", "# 8 threads", "\n", "pbar", "=", "tqdm", "(", "enumerate", "(", "results", ")", ",", "total", "=", "n", ")", "\n", "for", "i", ",", "x", "in", "pbar", ":", "\n", "                ", "self", ".", "imgs", "[", "i", "]", ",", "self", ".", "img_hw0", "[", "i", "]", ",", "self", ".", "img_hw", "[", "i", "]", "=", "x", "# img, hw_original, hw_resized = load_image(self, i)", "\n", "gb", "+=", "self", ".", "imgs", "[", "i", "]", ".", "nbytes", "\n", "pbar", ".", "desc", "=", "'Caching images (%.1fGB)'", "%", "(", "gb", "/", "1E9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels.cache_labels": [[513, 536], ["tqdm.tqdm.tqdm", "datasets.get_hash", "torch.save", "zip", "len", "PIL.Image.open", "PIL.Image.open.verify", "datasets.exif_size", "os.path.isfile", "len", "numpy.zeros", "print", "open", "numpy.array", "x.split", "f.read().splitlines", "f.read"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.get_hash", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.exif_size"], ["", "", "", "def", "cache_labels", "(", "self", ",", "path", "=", "'labels.cache3'", ")", ":", "\n", "# Cache dataset labels, check images and read shapes", "\n", "        ", "x", "=", "{", "}", "# dict", "\n", "pbar", "=", "tqdm", "(", "zip", "(", "self", ".", "img_files", ",", "self", ".", "label_files", ")", ",", "desc", "=", "'Scanning images'", ",", "total", "=", "len", "(", "self", ".", "img_files", ")", ")", "\n", "for", "(", "img", ",", "label", ")", "in", "pbar", ":", "\n", "            ", "try", ":", "\n", "                ", "l", "=", "[", "]", "\n", "im", "=", "Image", ".", "open", "(", "img", ")", "\n", "im", ".", "verify", "(", ")", "# PIL verify", "\n", "shape", "=", "exif_size", "(", "im", ")", "# image size", "\n", "assert", "(", "shape", "[", "0", "]", ">", "9", ")", "&", "(", "shape", "[", "1", "]", ">", "9", ")", ",", "'image size <10 pixels'", "\n", "if", "os", ".", "path", ".", "isfile", "(", "label", ")", ":", "\n", "                    ", "with", "open", "(", "label", ",", "'r'", ")", "as", "f", ":", "\n", "                        ", "l", "=", "np", ".", "array", "(", "[", "x", ".", "split", "(", ")", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "# labels", "\n", "", "", "if", "len", "(", "l", ")", "==", "0", ":", "\n", "                    ", "l", "=", "np", ".", "zeros", "(", "(", "0", ",", "5", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "x", "[", "img", "]", "=", "[", "l", ",", "shape", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "'WARNING: Ignoring corrupted image and/or label %s: %s'", "%", "(", "img", ",", "e", ")", ")", "\n", "\n", "", "", "x", "[", "'hash'", "]", "=", "get_hash", "(", "self", ".", "label_files", "+", "self", ".", "img_files", ")", "\n", "torch", ".", "save", "(", "x", ",", "path", ")", "# save for next time", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels.__len__": [[537, 539], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels.__getitem__": [[546, 631], ["len", "torch.zeros", "img[].transpose", "numpy.ascontiguousarray", "datasets.load_mosaic", "datasets.load_image", "datasets.letterbox", "datasets.augment_hsv", "utils.general.xyxy2xywh", "torch.from_numpy", "torch.from_numpy", "random.random", "random.random", "datasets.load_mosaic", "numpy.random.beta", "numpy.concatenate", "x.copy", "datasets.random_perspective", "random.random", "numpy.flipud", "random.random", "numpy.fliplr", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_mosaic", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_image", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.letterbox", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.augment_hsv", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_mosaic", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.random_perspective"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "image_weights", ":", "\n", "            ", "index", "=", "self", ".", "indices", "[", "index", "]", "\n", "\n", "", "hyp", "=", "self", ".", "hyp", "\n", "mosaic", "=", "self", ".", "mosaic", "and", "random", ".", "random", "(", ")", "<", "hyp", "[", "'mosaic'", "]", "\n", "if", "mosaic", ":", "\n", "# Load mosaic", "\n", "            ", "img", ",", "labels", "=", "load_mosaic", "(", "self", ",", "index", ")", "\n", "#img, labels = load_mosaic9(self, index)", "\n", "shapes", "=", "None", "\n", "\n", "# MixUp https://arxiv.org/pdf/1710.09412.pdf", "\n", "if", "random", ".", "random", "(", ")", "<", "hyp", "[", "'mixup'", "]", ":", "\n", "                ", "img2", ",", "labels2", "=", "load_mosaic", "(", "self", ",", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "labels", ")", "-", "1", ")", ")", "\n", "#img2, labels2 = load_mosaic9(self, random.randint(0, len(self.labels) - 1))", "\n", "r", "=", "np", ".", "random", ".", "beta", "(", "8.0", ",", "8.0", ")", "# mixup ratio, alpha=beta=8.0", "\n", "img", "=", "(", "img", "*", "r", "+", "img2", "*", "(", "1", "-", "r", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "(", "labels", ",", "labels2", ")", ",", "0", ")", "\n", "\n", "", "", "else", ":", "\n", "# Load image", "\n", "            ", "img", ",", "(", "h0", ",", "w0", ")", ",", "(", "h", ",", "w", ")", "=", "load_image", "(", "self", ",", "index", ")", "\n", "\n", "# Letterbox", "\n", "shape", "=", "self", ".", "batch_shapes", "[", "self", ".", "batch", "[", "index", "]", "]", "if", "self", ".", "rect", "else", "self", ".", "img_size", "# final letterboxed shape", "\n", "img", ",", "ratio", ",", "pad", "=", "letterbox", "(", "img", ",", "shape", ",", "auto", "=", "False", ",", "scaleup", "=", "self", ".", "augment", ")", "\n", "shapes", "=", "(", "h0", ",", "w0", ")", ",", "(", "(", "h", "/", "h0", ",", "w", "/", "w0", ")", ",", "pad", ")", "# for COCO mAP rescaling", "\n", "\n", "# Load labels", "\n", "labels", "=", "[", "]", "\n", "x", "=", "self", ".", "labels", "[", "index", "]", "\n", "if", "x", ".", "size", ">", "0", ":", "\n", "# Normalized xywh to pixel xyxy format", "\n", "                ", "labels", "=", "x", ".", "copy", "(", ")", "\n", "labels", "[", ":", ",", "1", "]", "=", "ratio", "[", "0", "]", "*", "w", "*", "(", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "pad", "[", "0", "]", "# pad width", "\n", "labels", "[", ":", ",", "2", "]", "=", "ratio", "[", "1", "]", "*", "h", "*", "(", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pad", "[", "1", "]", "# pad height", "\n", "labels", "[", ":", ",", "3", "]", "=", "ratio", "[", "0", "]", "*", "w", "*", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "pad", "[", "0", "]", "\n", "labels", "[", ":", ",", "4", "]", "=", "ratio", "[", "1", "]", "*", "h", "*", "(", "x", "[", ":", ",", "2", "]", "+", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pad", "[", "1", "]", "\n", "\n", "", "", "if", "self", ".", "augment", ":", "\n", "# Augment imagespace", "\n", "            ", "if", "not", "mosaic", ":", "\n", "                ", "img", ",", "labels", "=", "random_perspective", "(", "img", ",", "labels", ",", "\n", "degrees", "=", "hyp", "[", "'degrees'", "]", ",", "\n", "translate", "=", "hyp", "[", "'translate'", "]", ",", "\n", "scale", "=", "hyp", "[", "'scale'", "]", ",", "\n", "shear", "=", "hyp", "[", "'shear'", "]", ",", "\n", "perspective", "=", "hyp", "[", "'perspective'", "]", ")", "\n", "\n", "# Augment colorspace", "\n", "", "augment_hsv", "(", "img", ",", "hgain", "=", "hyp", "[", "'hsv_h'", "]", ",", "sgain", "=", "hyp", "[", "'hsv_s'", "]", ",", "vgain", "=", "hyp", "[", "'hsv_v'", "]", ")", "\n", "\n", "# Apply cutouts", "\n", "# if random.random() < 0.9:", "\n", "#     labels = cutout(img, labels)", "\n", "\n", "", "nL", "=", "len", "(", "labels", ")", "# number of labels", "\n", "if", "nL", ":", "\n", "            ", "labels", "[", ":", ",", "1", ":", "5", "]", "=", "xyxy2xywh", "(", "labels", "[", ":", ",", "1", ":", "5", "]", ")", "# convert xyxy to xywh", "\n", "labels", "[", ":", ",", "[", "2", ",", "4", "]", "]", "/=", "img", ".", "shape", "[", "0", "]", "# normalized height 0-1", "\n", "labels", "[", ":", ",", "[", "1", ",", "3", "]", "]", "/=", "img", ".", "shape", "[", "1", "]", "# normalized width 0-1", "\n", "\n", "", "if", "self", ".", "augment", ":", "\n", "# flip up-down", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "hyp", "[", "'flipud'", "]", ":", "\n", "                ", "img", "=", "np", ".", "flipud", "(", "img", ")", "\n", "if", "nL", ":", "\n", "                    ", "labels", "[", ":", ",", "2", "]", "=", "1", "-", "labels", "[", ":", ",", "2", "]", "\n", "\n", "# flip left-right", "\n", "", "", "if", "random", ".", "random", "(", ")", "<", "hyp", "[", "'fliplr'", "]", ":", "\n", "                ", "img", "=", "np", ".", "fliplr", "(", "img", ")", "\n", "if", "nL", ":", "\n", "                    ", "labels", "[", ":", ",", "1", "]", "=", "1", "-", "labels", "[", ":", ",", "1", "]", "\n", "\n", "", "", "", "labels_out", "=", "torch", ".", "zeros", "(", "(", "nL", ",", "6", ")", ")", "\n", "if", "nL", ":", "\n", "            ", "labels_out", "[", ":", ",", "1", ":", "]", "=", "torch", ".", "from_numpy", "(", "labels", ")", "\n", "\n", "# Convert", "\n", "", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "img", ")", ",", "labels_out", ",", "self", ".", "img_files", "[", "index", "]", ",", "shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels.collate_fn": [[632, 638], ["zip", "enumerate", "torch.stack", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "img", ",", "label", ",", "path", ",", "shapes", "=", "zip", "(", "*", "batch", ")", "# transposed", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "l", "[", ":", ",", "0", "]", "=", "i", "# add target image index for build_targets()", "\n", "", "return", "torch", ".", "stack", "(", "img", ",", "0", ")", ",", "torch", ".", "cat", "(", "label", ",", "0", ")", ",", "path", ",", "shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels9.__init__": [[641, 795], ["datasets.LoadImagesAndLabels9.__init__.img2label_paths"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ",", "img_size", "=", "640", ",", "batch_size", "=", "16", ",", "augment", "=", "False", ",", "hyp", "=", "None", ",", "rect", "=", "False", ",", "image_weights", "=", "False", ",", "\n", "cache_images", "=", "False", ",", "single_cls", "=", "False", ",", "stride", "=", "32", ",", "pad", "=", "0.0", ",", "rank", "=", "-", "1", ")", ":", "\n", "        ", "self", ".", "img_size", "=", "img_size", "\n", "self", ".", "augment", "=", "augment", "\n", "self", ".", "hyp", "=", "hyp", "\n", "self", ".", "image_weights", "=", "image_weights", "\n", "self", ".", "rect", "=", "False", "if", "image_weights", "else", "rect", "\n", "self", ".", "mosaic", "=", "self", ".", "augment", "and", "not", "self", ".", "rect", "# load 4 images at a time into a mosaic (only during training)", "\n", "self", ".", "mosaic_border", "=", "[", "-", "img_size", "//", "2", ",", "-", "img_size", "//", "2", "]", "\n", "self", ".", "stride", "=", "stride", "\n", "\n", "def", "img2label_paths", "(", "img_paths", ")", ":", "\n", "# Define label paths as a function of image paths", "\n", "            ", "sa", ",", "sb", "=", "os", ".", "sep", "+", "'images'", "+", "os", ".", "sep", ",", "os", ".", "sep", "+", "'labels'", "+", "os", ".", "sep", "# /images/, /labels/ substrings", "\n", "return", "[", "x", ".", "replace", "(", "sa", ",", "sb", ",", "1", ")", ".", "replace", "(", "x", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ",", "'txt'", ")", "for", "x", "in", "img_paths", "]", "\n", "\n", "", "try", ":", "\n", "            ", "f", "=", "[", "]", "# image files", "\n", "for", "p", "in", "path", "if", "isinstance", "(", "path", ",", "list", ")", "else", "[", "path", "]", ":", "\n", "                ", "p", "=", "Path", "(", "p", ")", "# os-agnostic", "\n", "if", "p", ".", "is_dir", "(", ")", ":", "# dir", "\n", "                    ", "f", "+=", "glob", ".", "glob", "(", "str", "(", "p", "/", "'**'", "/", "'*.*'", ")", ",", "recursive", "=", "True", ")", "\n", "", "elif", "p", ".", "is_file", "(", ")", ":", "# file", "\n", "                    ", "with", "open", "(", "p", ",", "'r'", ")", "as", "t", ":", "\n", "                        ", "t", "=", "t", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "parent", "=", "str", "(", "p", ".", "parent", ")", "+", "os", ".", "sep", "\n", "f", "+=", "[", "x", ".", "replace", "(", "'./'", ",", "parent", ")", "if", "x", ".", "startswith", "(", "'./'", ")", "else", "x", "for", "x", "in", "t", "]", "# local to global path", "\n", "", "", "else", ":", "\n", "                    ", "raise", "Exception", "(", "'%s does not exist'", "%", "p", ")", "\n", "", "", "self", ".", "img_files", "=", "sorted", "(", "[", "x", ".", "replace", "(", "'/'", ",", "os", ".", "sep", ")", "for", "x", "in", "f", "if", "x", ".", "split", "(", "'.'", ")", "[", "-", "1", "]", ".", "lower", "(", ")", "in", "img_formats", "]", ")", "\n", "assert", "self", ".", "img_files", ",", "'No images found'", "\n", "", "except", "Exception", "as", "e", ":", "\n", "            ", "raise", "Exception", "(", "'Error loading data from %s: %s\\nSee %s'", "%", "(", "path", ",", "e", ",", "help_url", ")", ")", "\n", "\n", "# Check cache", "\n", "", "self", ".", "label_files", "=", "img2label_paths", "(", "self", ".", "img_files", ")", "# labels", "\n", "cache_path", "=", "str", "(", "Path", "(", "self", ".", "label_files", "[", "0", "]", ")", ".", "parent", ")", "+", "'.cache3'", "# cached labels", "\n", "if", "os", ".", "path", ".", "isfile", "(", "cache_path", ")", ":", "\n", "            ", "cache", "=", "torch", ".", "load", "(", "cache_path", ")", "# load", "\n", "if", "cache", "[", "'hash'", "]", "!=", "get_hash", "(", "self", ".", "label_files", "+", "self", ".", "img_files", ")", ":", "# dataset changed", "\n", "                ", "cache", "=", "self", ".", "cache_labels", "(", "cache_path", ")", "# re-cache", "\n", "", "", "else", ":", "\n", "            ", "cache", "=", "self", ".", "cache_labels", "(", "cache_path", ")", "# cache", "\n", "\n", "# Read cache", "\n", "", "cache", ".", "pop", "(", "'hash'", ")", "# remove hash", "\n", "labels", ",", "shapes", "=", "zip", "(", "*", "cache", ".", "values", "(", ")", ")", "\n", "self", ".", "labels", "=", "list", "(", "labels", ")", "\n", "self", ".", "shapes", "=", "np", ".", "array", "(", "shapes", ",", "dtype", "=", "np", ".", "float64", ")", "\n", "self", ".", "img_files", "=", "list", "(", "cache", ".", "keys", "(", ")", ")", "# update", "\n", "self", ".", "label_files", "=", "img2label_paths", "(", "cache", ".", "keys", "(", ")", ")", "# update", "\n", "\n", "n", "=", "len", "(", "shapes", ")", "# number of images", "\n", "bi", "=", "np", ".", "floor", "(", "np", ".", "arange", "(", "n", ")", "/", "batch_size", ")", ".", "astype", "(", "np", ".", "int", ")", "# batch index", "\n", "nb", "=", "bi", "[", "-", "1", "]", "+", "1", "# number of batches", "\n", "self", ".", "batch", "=", "bi", "# batch index of image", "\n", "self", ".", "n", "=", "n", "\n", "\n", "# Rectangular Training", "\n", "if", "self", ".", "rect", ":", "\n", "# Sort by aspect ratio", "\n", "            ", "s", "=", "self", ".", "shapes", "# wh", "\n", "ar", "=", "s", "[", ":", ",", "1", "]", "/", "s", "[", ":", ",", "0", "]", "# aspect ratio", "\n", "irect", "=", "ar", ".", "argsort", "(", ")", "\n", "self", ".", "img_files", "=", "[", "self", ".", "img_files", "[", "i", "]", "for", "i", "in", "irect", "]", "\n", "self", ".", "label_files", "=", "[", "self", ".", "label_files", "[", "i", "]", "for", "i", "in", "irect", "]", "\n", "self", ".", "labels", "=", "[", "self", ".", "labels", "[", "i", "]", "for", "i", "in", "irect", "]", "\n", "self", ".", "shapes", "=", "s", "[", "irect", "]", "# wh", "\n", "ar", "=", "ar", "[", "irect", "]", "\n", "\n", "# Set training image shapes", "\n", "shapes", "=", "[", "[", "1", ",", "1", "]", "]", "*", "nb", "\n", "for", "i", "in", "range", "(", "nb", ")", ":", "\n", "                ", "ari", "=", "ar", "[", "bi", "==", "i", "]", "\n", "mini", ",", "maxi", "=", "ari", ".", "min", "(", ")", ",", "ari", ".", "max", "(", ")", "\n", "if", "maxi", "<", "1", ":", "\n", "                    ", "shapes", "[", "i", "]", "=", "[", "maxi", ",", "1", "]", "\n", "", "elif", "mini", ">", "1", ":", "\n", "                    ", "shapes", "[", "i", "]", "=", "[", "1", ",", "1", "/", "mini", "]", "\n", "\n", "", "", "self", ".", "batch_shapes", "=", "np", ".", "ceil", "(", "np", ".", "array", "(", "shapes", ")", "*", "img_size", "/", "stride", "+", "pad", ")", ".", "astype", "(", "np", ".", "int", ")", "*", "stride", "\n", "\n", "# Check labels", "\n", "", "create_datasubset", ",", "extract_bounding_boxes", ",", "labels_loaded", "=", "False", ",", "False", ",", "False", "\n", "nm", ",", "nf", ",", "ne", ",", "ns", ",", "nd", "=", "0", ",", "0", ",", "0", ",", "0", ",", "0", "# number missing, found, empty, datasubset, duplicate", "\n", "pbar", "=", "enumerate", "(", "self", ".", "label_files", ")", "\n", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "pbar", "=", "tqdm", "(", "pbar", ")", "\n", "", "for", "i", ",", "file", "in", "pbar", ":", "\n", "            ", "l", "=", "self", ".", "labels", "[", "i", "]", "# label", "\n", "if", "l", "is", "not", "None", "and", "l", ".", "shape", "[", "0", "]", ":", "\n", "                ", "assert", "l", ".", "shape", "[", "1", "]", "==", "5", ",", "'> 5 label columns: %s'", "%", "file", "\n", "assert", "(", "l", ">=", "0", ")", ".", "all", "(", ")", ",", "'negative labels: %s'", "%", "file", "\n", "assert", "(", "l", "[", ":", ",", "1", ":", "]", "<=", "1", ")", ".", "all", "(", ")", ",", "'non-normalized or out of bounds coordinate labels: %s'", "%", "file", "\n", "if", "np", ".", "unique", "(", "l", ",", "axis", "=", "0", ")", ".", "shape", "[", "0", "]", "<", "l", ".", "shape", "[", "0", "]", ":", "# duplicate rows", "\n", "                    ", "nd", "+=", "1", "# print('WARNING: duplicate rows in %s' % self.label_files[i])  # duplicate rows", "\n", "", "if", "single_cls", ":", "\n", "                    ", "l", "[", ":", ",", "0", "]", "=", "0", "# force dataset into single-class mode", "\n", "", "self", ".", "labels", "[", "i", "]", "=", "l", "\n", "nf", "+=", "1", "# file found", "\n", "\n", "# Create subdataset (a smaller dataset)", "\n", "if", "create_datasubset", "and", "ns", "<", "1E4", ":", "\n", "                    ", "if", "ns", "==", "0", ":", "\n", "                        ", "create_folder", "(", "path", "=", "'./datasubset'", ")", "\n", "os", ".", "makedirs", "(", "'./datasubset/images'", ")", "\n", "", "exclude_classes", "=", "43", "\n", "if", "exclude_classes", "not", "in", "l", "[", ":", ",", "0", "]", ":", "\n", "                        ", "ns", "+=", "1", "\n", "# shutil.copy(src=self.img_files[i], dst='./datasubset/images/')  # copy image", "\n", "with", "open", "(", "'./datasubset/images.txt'", ",", "'a'", ")", "as", "f", ":", "\n", "                            ", "f", ".", "write", "(", "self", ".", "img_files", "[", "i", "]", "+", "'\\n'", ")", "\n", "\n", "# Extract object detection boxes for a second stage classifier", "\n", "", "", "", "if", "extract_bounding_boxes", ":", "\n", "                    ", "p", "=", "Path", "(", "self", ".", "img_files", "[", "i", "]", ")", "\n", "img", "=", "cv2", ".", "imread", "(", "str", "(", "p", ")", ")", "\n", "h", ",", "w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "for", "j", ",", "x", "in", "enumerate", "(", "l", ")", ":", "\n", "                        ", "f", "=", "'%s%sclassifier%s%g_%g_%s'", "%", "(", "p", ".", "parent", ".", "parent", ",", "os", ".", "sep", ",", "os", ".", "sep", ",", "x", "[", "0", "]", ",", "j", ",", "p", ".", "name", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "Path", "(", "f", ")", ".", "parent", ")", ":", "\n", "                            ", "os", ".", "makedirs", "(", "Path", "(", "f", ")", ".", "parent", ")", "# make new output folder", "\n", "\n", "", "b", "=", "x", "[", "1", ":", "]", "*", "[", "w", ",", "h", ",", "w", ",", "h", "]", "# box", "\n", "b", "[", "2", ":", "]", "=", "b", "[", "2", ":", "]", ".", "max", "(", ")", "# rectangle to square", "\n", "b", "[", "2", ":", "]", "=", "b", "[", "2", ":", "]", "*", "1.3", "+", "30", "# pad", "\n", "b", "=", "xywh2xyxy", "(", "b", ".", "reshape", "(", "-", "1", ",", "4", ")", ")", ".", "ravel", "(", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "\n", "b", "[", "[", "0", ",", "2", "]", "]", "=", "np", ".", "clip", "(", "b", "[", "[", "0", ",", "2", "]", "]", ",", "0", ",", "w", ")", "# clip boxes outside of image", "\n", "b", "[", "[", "1", ",", "3", "]", "]", "=", "np", ".", "clip", "(", "b", "[", "[", "1", ",", "3", "]", "]", ",", "0", ",", "h", ")", "\n", "assert", "cv2", ".", "imwrite", "(", "f", ",", "img", "[", "b", "[", "1", "]", ":", "b", "[", "3", "]", ",", "b", "[", "0", "]", ":", "b", "[", "2", "]", "]", ")", ",", "'Failure extracting classifier boxes'", "\n", "", "", "", "else", ":", "\n", "                ", "ne", "+=", "1", "# print('empty labels for image %s' % self.img_files[i])  # file empty", "\n", "# os.system(\"rm '%s' '%s'\" % (self.img_files[i], self.label_files[i]))  # remove", "\n", "\n", "", "if", "rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "                ", "pbar", ".", "desc", "=", "'Scanning labels %s (%g found, %g missing, %g empty, %g duplicate, for %g images)'", "%", "(", "\n", "cache_path", ",", "nf", ",", "nm", ",", "ne", ",", "nd", ",", "n", ")", "\n", "", "", "if", "nf", "==", "0", ":", "\n", "            ", "s", "=", "'WARNING: No labels found in %s. See %s'", "%", "(", "os", ".", "path", ".", "dirname", "(", "file", ")", "+", "os", ".", "sep", ",", "help_url", ")", "\n", "print", "(", "s", ")", "\n", "assert", "not", "augment", ",", "'%s. Can not train without labels.'", "%", "s", "\n", "\n", "# Cache images into memory for faster training (WARNING: large datasets may exceed system RAM)", "\n", "", "self", ".", "imgs", "=", "[", "None", "]", "*", "n", "\n", "if", "cache_images", ":", "\n", "            ", "gb", "=", "0", "# Gigabytes of cached images", "\n", "self", ".", "img_hw0", ",", "self", ".", "img_hw", "=", "[", "None", "]", "*", "n", ",", "[", "None", "]", "*", "n", "\n", "results", "=", "ThreadPool", "(", "8", ")", ".", "imap", "(", "lambda", "x", ":", "load_image", "(", "*", "x", ")", ",", "zip", "(", "repeat", "(", "self", ")", ",", "range", "(", "n", ")", ")", ")", "# 8 threads", "\n", "pbar", "=", "tqdm", "(", "enumerate", "(", "results", ")", ",", "total", "=", "n", ")", "\n", "for", "i", ",", "x", "in", "pbar", ":", "\n", "                ", "self", ".", "imgs", "[", "i", "]", ",", "self", ".", "img_hw0", "[", "i", "]", ",", "self", ".", "img_hw", "[", "i", "]", "=", "x", "# img, hw_original, hw_resized = load_image(self, i)", "\n", "gb", "+=", "self", ".", "imgs", "[", "i", "]", ".", "nbytes", "\n", "pbar", ".", "desc", "=", "'Caching images (%.1fGB)'", "%", "(", "gb", "/", "1E9", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels9.cache_labels": [[796, 819], ["tqdm.tqdm.tqdm", "datasets.get_hash", "torch.save", "zip", "len", "PIL.Image.open", "PIL.Image.open.verify", "datasets.exif_size", "os.path.isfile", "len", "numpy.zeros", "print", "open", "numpy.array", "x.split", "f.read().splitlines", "f.read"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.get_hash", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.exif_size"], ["", "", "", "def", "cache_labels", "(", "self", ",", "path", "=", "'labels.cache3'", ")", ":", "\n", "# Cache dataset labels, check images and read shapes", "\n", "        ", "x", "=", "{", "}", "# dict", "\n", "pbar", "=", "tqdm", "(", "zip", "(", "self", ".", "img_files", ",", "self", ".", "label_files", ")", ",", "desc", "=", "'Scanning images'", ",", "total", "=", "len", "(", "self", ".", "img_files", ")", ")", "\n", "for", "(", "img", ",", "label", ")", "in", "pbar", ":", "\n", "            ", "try", ":", "\n", "                ", "l", "=", "[", "]", "\n", "im", "=", "Image", ".", "open", "(", "img", ")", "\n", "im", ".", "verify", "(", ")", "# PIL verify", "\n", "shape", "=", "exif_size", "(", "im", ")", "# image size", "\n", "assert", "(", "shape", "[", "0", "]", ">", "9", ")", "&", "(", "shape", "[", "1", "]", ">", "9", ")", ",", "'image size <10 pixels'", "\n", "if", "os", ".", "path", ".", "isfile", "(", "label", ")", ":", "\n", "                    ", "with", "open", "(", "label", ",", "'r'", ")", "as", "f", ":", "\n", "                        ", "l", "=", "np", ".", "array", "(", "[", "x", ".", "split", "(", ")", "for", "x", "in", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "]", ",", "dtype", "=", "np", ".", "float32", ")", "# labels", "\n", "", "", "if", "len", "(", "l", ")", "==", "0", ":", "\n", "                    ", "l", "=", "np", ".", "zeros", "(", "(", "0", ",", "5", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "x", "[", "img", "]", "=", "[", "l", ",", "shape", "]", "\n", "", "except", "Exception", "as", "e", ":", "\n", "                ", "print", "(", "'WARNING: Ignoring corrupted image and/or label %s: %s'", "%", "(", "img", ",", "e", ")", ")", "\n", "\n", "", "", "x", "[", "'hash'", "]", "=", "get_hash", "(", "self", ".", "label_files", "+", "self", ".", "img_files", ")", "\n", "torch", ".", "save", "(", "x", ",", "path", ")", "# save for next time", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels9.__len__": [[820, 822], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "img_files", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels9.__getitem__": [[829, 914], ["len", "torch.zeros", "img[].transpose", "numpy.ascontiguousarray", "datasets.load_mosaic9", "datasets.load_image", "datasets.letterbox", "datasets.augment_hsv", "utils.general.xyxy2xywh", "torch.from_numpy", "torch.from_numpy", "random.random", "random.random", "datasets.load_mosaic9", "numpy.random.beta", "numpy.concatenate", "x.copy", "datasets.random_perspective", "random.random", "numpy.flipud", "random.random", "numpy.fliplr", "random.randint", "len"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_mosaic9", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_image", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.letterbox", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.augment_hsv", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.general.xyxy2xywh", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_mosaic9", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.random_perspective"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "if", "self", ".", "image_weights", ":", "\n", "            ", "index", "=", "self", ".", "indices", "[", "index", "]", "\n", "\n", "", "hyp", "=", "self", ".", "hyp", "\n", "mosaic", "=", "self", ".", "mosaic", "and", "random", ".", "random", "(", ")", "<", "hyp", "[", "'mosaic'", "]", "\n", "if", "mosaic", ":", "\n", "# Load mosaic", "\n", "#img, labels = load_mosaic(self, index)", "\n", "            ", "img", ",", "labels", "=", "load_mosaic9", "(", "self", ",", "index", ")", "\n", "shapes", "=", "None", "\n", "\n", "# MixUp https://arxiv.org/pdf/1710.09412.pdf", "\n", "if", "random", ".", "random", "(", ")", "<", "hyp", "[", "'mixup'", "]", ":", "\n", "#img2, labels2 = load_mosaic(self, random.randint(0, len(self.labels) - 1))", "\n", "                ", "img2", ",", "labels2", "=", "load_mosaic9", "(", "self", ",", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "labels", ")", "-", "1", ")", ")", "\n", "r", "=", "np", ".", "random", ".", "beta", "(", "8.0", ",", "8.0", ")", "# mixup ratio, alpha=beta=8.0", "\n", "img", "=", "(", "img", "*", "r", "+", "img2", "*", "(", "1", "-", "r", ")", ")", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "(", "labels", ",", "labels2", ")", ",", "0", ")", "\n", "\n", "", "", "else", ":", "\n", "# Load image", "\n", "            ", "img", ",", "(", "h0", ",", "w0", ")", ",", "(", "h", ",", "w", ")", "=", "load_image", "(", "self", ",", "index", ")", "\n", "\n", "# Letterbox", "\n", "shape", "=", "self", ".", "batch_shapes", "[", "self", ".", "batch", "[", "index", "]", "]", "if", "self", ".", "rect", "else", "self", ".", "img_size", "# final letterboxed shape", "\n", "img", ",", "ratio", ",", "pad", "=", "letterbox", "(", "img", ",", "shape", ",", "auto", "=", "False", ",", "scaleup", "=", "self", ".", "augment", ")", "\n", "shapes", "=", "(", "h0", ",", "w0", ")", ",", "(", "(", "h", "/", "h0", ",", "w", "/", "w0", ")", ",", "pad", ")", "# for COCO mAP rescaling", "\n", "\n", "# Load labels", "\n", "labels", "=", "[", "]", "\n", "x", "=", "self", ".", "labels", "[", "index", "]", "\n", "if", "x", ".", "size", ">", "0", ":", "\n", "# Normalized xywh to pixel xyxy format", "\n", "                ", "labels", "=", "x", ".", "copy", "(", ")", "\n", "labels", "[", ":", ",", "1", "]", "=", "ratio", "[", "0", "]", "*", "w", "*", "(", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "pad", "[", "0", "]", "# pad width", "\n", "labels", "[", ":", ",", "2", "]", "=", "ratio", "[", "1", "]", "*", "h", "*", "(", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pad", "[", "1", "]", "# pad height", "\n", "labels", "[", ":", ",", "3", "]", "=", "ratio", "[", "0", "]", "*", "w", "*", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "pad", "[", "0", "]", "\n", "labels", "[", ":", ",", "4", "]", "=", "ratio", "[", "1", "]", "*", "h", "*", "(", "x", "[", ":", ",", "2", "]", "+", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pad", "[", "1", "]", "\n", "\n", "", "", "if", "self", ".", "augment", ":", "\n", "# Augment imagespace", "\n", "            ", "if", "not", "mosaic", ":", "\n", "                ", "img", ",", "labels", "=", "random_perspective", "(", "img", ",", "labels", ",", "\n", "degrees", "=", "hyp", "[", "'degrees'", "]", ",", "\n", "translate", "=", "hyp", "[", "'translate'", "]", ",", "\n", "scale", "=", "hyp", "[", "'scale'", "]", ",", "\n", "shear", "=", "hyp", "[", "'shear'", "]", ",", "\n", "perspective", "=", "hyp", "[", "'perspective'", "]", ")", "\n", "\n", "# Augment colorspace", "\n", "", "augment_hsv", "(", "img", ",", "hgain", "=", "hyp", "[", "'hsv_h'", "]", ",", "sgain", "=", "hyp", "[", "'hsv_s'", "]", ",", "vgain", "=", "hyp", "[", "'hsv_v'", "]", ")", "\n", "\n", "# Apply cutouts", "\n", "# if random.random() < 0.9:", "\n", "#     labels = cutout(img, labels)", "\n", "\n", "", "nL", "=", "len", "(", "labels", ")", "# number of labels", "\n", "if", "nL", ":", "\n", "            ", "labels", "[", ":", ",", "1", ":", "5", "]", "=", "xyxy2xywh", "(", "labels", "[", ":", ",", "1", ":", "5", "]", ")", "# convert xyxy to xywh", "\n", "labels", "[", ":", ",", "[", "2", ",", "4", "]", "]", "/=", "img", ".", "shape", "[", "0", "]", "# normalized height 0-1", "\n", "labels", "[", ":", ",", "[", "1", ",", "3", "]", "]", "/=", "img", ".", "shape", "[", "1", "]", "# normalized width 0-1", "\n", "\n", "", "if", "self", ".", "augment", ":", "\n", "# flip up-down", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "hyp", "[", "'flipud'", "]", ":", "\n", "                ", "img", "=", "np", ".", "flipud", "(", "img", ")", "\n", "if", "nL", ":", "\n", "                    ", "labels", "[", ":", ",", "2", "]", "=", "1", "-", "labels", "[", ":", ",", "2", "]", "\n", "\n", "# flip left-right", "\n", "", "", "if", "random", ".", "random", "(", ")", "<", "hyp", "[", "'fliplr'", "]", ":", "\n", "                ", "img", "=", "np", ".", "fliplr", "(", "img", ")", "\n", "if", "nL", ":", "\n", "                    ", "labels", "[", ":", ",", "1", "]", "=", "1", "-", "labels", "[", ":", ",", "1", "]", "\n", "\n", "", "", "", "labels_out", "=", "torch", ".", "zeros", "(", "(", "nL", ",", "6", ")", ")", "\n", "if", "nL", ":", "\n", "            ", "labels_out", "[", ":", ",", "1", ":", "]", "=", "torch", ".", "from_numpy", "(", "labels", ")", "\n", "\n", "# Convert", "\n", "", "img", "=", "img", "[", ":", ",", ":", ",", ":", ":", "-", "1", "]", ".", "transpose", "(", "2", ",", "0", ",", "1", ")", "# BGR to RGB, to 3x416x416", "\n", "img", "=", "np", ".", "ascontiguousarray", "(", "img", ")", "\n", "\n", "return", "torch", ".", "from_numpy", "(", "img", ")", ",", "labels_out", ",", "self", ".", "img_files", "[", "index", "]", ",", "shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.LoadImagesAndLabels9.collate_fn": [[915, 921], ["zip", "enumerate", "torch.stack", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "batch", ")", ":", "\n", "        ", "img", ",", "label", ",", "path", ",", "shapes", "=", "zip", "(", "*", "batch", ")", "# transposed", "\n", "for", "i", ",", "l", "in", "enumerate", "(", "label", ")", ":", "\n", "            ", "l", "[", ":", ",", "0", "]", "=", "i", "# add target image index for build_targets()", "\n", "", "return", "torch", ".", "stack", "(", "img", ",", "0", ")", ",", "torch", ".", "cat", "(", "label", ",", "0", ")", ",", "path", ",", "shapes", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.get_hash": [[40, 43], ["sum", "os.path.getsize", "os.path.isfile"], "function", ["None"], ["", "", "def", "get_hash", "(", "files", ")", ":", "\n", "# Returns a single hash value of a list of files", "\n", "    ", "return", "sum", "(", "os", ".", "path", ".", "getsize", "(", "f", ")", "for", "f", "in", "files", "if", "os", ".", "path", ".", "isfile", "(", "f", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.exif_size": [[45, 58], ["dict", "img._getexif().items", "img._getexif"], "function", ["None"], ["", "def", "exif_size", "(", "img", ")", ":", "\n", "# Returns exif-corrected PIL size", "\n", "    ", "s", "=", "img", ".", "size", "# (width, height)", "\n", "try", ":", "\n", "        ", "rotation", "=", "dict", "(", "img", ".", "_getexif", "(", ")", ".", "items", "(", ")", ")", "[", "orientation", "]", "\n", "if", "rotation", "==", "6", ":", "# rotation 270", "\n", "            ", "s", "=", "(", "s", "[", "1", "]", ",", "s", "[", "0", "]", ")", "\n", "", "elif", "rotation", "==", "8", ":", "# rotation 90", "\n", "            ", "s", "=", "(", "s", "[", "1", "]", ",", "s", "[", "0", "]", ")", "\n", "", "", "except", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_dataloader": [[60, 84], ["min", "min", "datasets.InfiniteDataLoader", "utils.torch_utils.torch_distributed_zero_first", "datasets.LoadImagesAndLabels", "len", "torch.utils.data.distributed.DistributedSampler", "int", "os.cpu_count"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.torch_distributed_zero_first"], ["", "def", "create_dataloader", "(", "path", ",", "imgsz", ",", "batch_size", ",", "stride", ",", "opt", ",", "hyp", "=", "None", ",", "augment", "=", "False", ",", "cache", "=", "False", ",", "pad", "=", "0.0", ",", "rect", "=", "False", ",", "\n", "rank", "=", "-", "1", ",", "world_size", "=", "1", ",", "workers", "=", "8", ")", ":", "\n", "# Make sure only the first process in DDP process the dataset first, and the following others can use the cache", "\n", "    ", "with", "torch_distributed_zero_first", "(", "rank", ")", ":", "\n", "        ", "dataset", "=", "LoadImagesAndLabels", "(", "path", ",", "imgsz", ",", "batch_size", ",", "\n", "augment", "=", "augment", ",", "# augment images", "\n", "hyp", "=", "hyp", ",", "# augmentation hyperparameters", "\n", "rect", "=", "rect", ",", "# rectangular training", "\n", "cache_images", "=", "cache", ",", "\n", "single_cls", "=", "opt", ".", "single_cls", ",", "\n", "stride", "=", "int", "(", "stride", ")", ",", "\n", "pad", "=", "pad", ",", "\n", "rank", "=", "rank", ")", "\n", "\n", "", "batch_size", "=", "min", "(", "batch_size", ",", "len", "(", "dataset", ")", ")", "\n", "nw", "=", "min", "(", "[", "os", ".", "cpu_count", "(", ")", "//", "world_size", ",", "batch_size", "if", "batch_size", ">", "1", "else", "0", ",", "workers", "]", ")", "# number of workers", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "dataset", ")", "if", "rank", "!=", "-", "1", "else", "None", "\n", "dataloader", "=", "InfiniteDataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "nw", ",", "\n", "sampler", "=", "sampler", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "LoadImagesAndLabels", ".", "collate_fn", ")", "# torch.utils.data.DataLoader()", "\n", "return", "dataloader", ",", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_dataloader9": [[86, 110], ["min", "min", "datasets.InfiniteDataLoader", "utils.torch_utils.torch_distributed_zero_first", "datasets.LoadImagesAndLabels9", "len", "torch.utils.data.distributed.DistributedSampler", "int", "os.cpu_count"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.torch_distributed_zero_first"], ["", "def", "create_dataloader9", "(", "path", ",", "imgsz", ",", "batch_size", ",", "stride", ",", "opt", ",", "hyp", "=", "None", ",", "augment", "=", "False", ",", "cache", "=", "False", ",", "pad", "=", "0.0", ",", "rect", "=", "False", ",", "\n", "rank", "=", "-", "1", ",", "world_size", "=", "1", ",", "workers", "=", "8", ")", ":", "\n", "# Make sure only the first process in DDP process the dataset first, and the following others can use the cache", "\n", "    ", "with", "torch_distributed_zero_first", "(", "rank", ")", ":", "\n", "        ", "dataset", "=", "LoadImagesAndLabels9", "(", "path", ",", "imgsz", ",", "batch_size", ",", "\n", "augment", "=", "augment", ",", "# augment images", "\n", "hyp", "=", "hyp", ",", "# augmentation hyperparameters", "\n", "rect", "=", "rect", ",", "# rectangular training", "\n", "cache_images", "=", "cache", ",", "\n", "single_cls", "=", "opt", ".", "single_cls", ",", "\n", "stride", "=", "int", "(", "stride", ")", ",", "\n", "pad", "=", "pad", ",", "\n", "rank", "=", "rank", ")", "\n", "\n", "", "batch_size", "=", "min", "(", "batch_size", ",", "len", "(", "dataset", ")", ")", "\n", "nw", "=", "min", "(", "[", "os", ".", "cpu_count", "(", ")", "//", "world_size", ",", "batch_size", "if", "batch_size", ">", "1", "else", "0", ",", "workers", "]", ")", "# number of workers", "\n", "sampler", "=", "torch", ".", "utils", ".", "data", ".", "distributed", ".", "DistributedSampler", "(", "dataset", ")", "if", "rank", "!=", "-", "1", "else", "None", "\n", "dataloader", "=", "InfiniteDataLoader", "(", "dataset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "nw", ",", "\n", "sampler", "=", "sampler", ",", "\n", "pin_memory", "=", "True", ",", "\n", "collate_fn", "=", "LoadImagesAndLabels9", ".", "collate_fn", ")", "# torch.utils.data.DataLoader()", "\n", "return", "dataloader", ",", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_image": [[924, 939], ["cv2.imread", "max", "cv2.resize", "int", "int"], "function", ["None"], ["", "", "def", "load_image", "(", "self", ",", "index", ")", ":", "\n", "# loads 1 image from dataset, returns img, original hw, resized hw", "\n", "    ", "img", "=", "self", ".", "imgs", "[", "index", "]", "\n", "if", "img", "is", "None", ":", "# not cached", "\n", "        ", "path", "=", "self", ".", "img_files", "[", "index", "]", "\n", "img", "=", "cv2", ".", "imread", "(", "path", ")", "# BGR", "\n", "assert", "img", "is", "not", "None", ",", "'Image Not Found '", "+", "path", "\n", "h0", ",", "w0", "=", "img", ".", "shape", "[", ":", "2", "]", "# orig hw", "\n", "r", "=", "self", ".", "img_size", "/", "max", "(", "h0", ",", "w0", ")", "# resize image to img_size", "\n", "if", "r", "!=", "1", ":", "# always resize down, only resize up if training with augmentation", "\n", "            ", "interp", "=", "cv2", ".", "INTER_AREA", "if", "r", "<", "1", "and", "not", "self", ".", "augment", "else", "cv2", ".", "INTER_LINEAR", "\n", "img", "=", "cv2", ".", "resize", "(", "img", ",", "(", "int", "(", "w0", "*", "r", ")", ",", "int", "(", "h0", "*", "r", ")", ")", ",", "interpolation", "=", "interp", ")", "\n", "", "return", "img", ",", "(", "h0", ",", "w0", ")", ",", "img", ".", "shape", "[", ":", "2", "]", "# img, hw_original, hw_resized", "\n", "", "else", ":", "\n", "        ", "return", "self", ".", "imgs", "[", "index", "]", ",", "self", ".", "img_hw0", "[", "index", "]", ",", "self", ".", "img_hw", "[", "index", "]", "# img, hw_original, hw_resized", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.augment_hsv": [[941, 953], ["cv2.split", "numpy.arange", "numpy.clip().astype", "numpy.clip().astype", "cv2.merge().astype", "cv2.cvtColor", "cv2.cvtColor", "numpy.random.uniform", "numpy.clip", "numpy.clip", "cv2.merge", "cv2.LUT", "cv2.LUT", "cv2.LUT"], "function", ["None"], ["", "", "def", "augment_hsv", "(", "img", ",", "hgain", "=", "0.5", ",", "sgain", "=", "0.5", ",", "vgain", "=", "0.5", ")", ":", "\n", "    ", "r", "=", "np", ".", "random", ".", "uniform", "(", "-", "1", ",", "1", ",", "3", ")", "*", "[", "hgain", ",", "sgain", ",", "vgain", "]", "+", "1", "# random gains", "\n", "hue", ",", "sat", ",", "val", "=", "cv2", ".", "split", "(", "cv2", ".", "cvtColor", "(", "img", ",", "cv2", ".", "COLOR_BGR2HSV", ")", ")", "\n", "dtype", "=", "img", ".", "dtype", "# uint8", "\n", "\n", "x", "=", "np", ".", "arange", "(", "0", ",", "256", ",", "dtype", "=", "np", ".", "int16", ")", "\n", "lut_hue", "=", "(", "(", "x", "*", "r", "[", "0", "]", ")", "%", "180", ")", ".", "astype", "(", "dtype", ")", "\n", "lut_sat", "=", "np", ".", "clip", "(", "x", "*", "r", "[", "1", "]", ",", "0", ",", "255", ")", ".", "astype", "(", "dtype", ")", "\n", "lut_val", "=", "np", ".", "clip", "(", "x", "*", "r", "[", "2", "]", ",", "0", ",", "255", ")", ".", "astype", "(", "dtype", ")", "\n", "\n", "img_hsv", "=", "cv2", ".", "merge", "(", "(", "cv2", ".", "LUT", "(", "hue", ",", "lut_hue", ")", ",", "cv2", ".", "LUT", "(", "sat", ",", "lut_sat", ")", ",", "cv2", ".", "LUT", "(", "val", ",", "lut_val", ")", ")", ")", ".", "astype", "(", "dtype", ")", "\n", "cv2", ".", "cvtColor", "(", "img_hsv", ",", "cv2", ".", "COLOR_HSV2BGR", ",", "dst", "=", "img", ")", "# no return needed", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_mosaic": [[960, 1016], ["enumerate", "len", "datasets.random_perspective", "int", "datasets.load_image", "x.copy", "np.concatenate.append", "numpy.concatenate", "numpy.clip", "random.uniform", "random.randint", "numpy.full", "range", "max", "max", "len", "max", "min", "min", "max", "min", "min", "min", "min", "min", "min"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.random_perspective", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_image"], ["", "def", "load_mosaic", "(", "self", ",", "index", ")", ":", "\n", "# loads images in a mosaic", "\n", "\n", "    ", "labels4", "=", "[", "]", "\n", "s", "=", "self", ".", "img_size", "\n", "yc", ",", "xc", "=", "[", "int", "(", "random", ".", "uniform", "(", "-", "x", ",", "2", "*", "s", "+", "x", ")", ")", "for", "x", "in", "self", ".", "mosaic_border", "]", "# mosaic center x, y", "\n", "indices", "=", "[", "index", "]", "+", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "labels", ")", "-", "1", ")", "for", "_", "in", "range", "(", "3", ")", "]", "# 3 additional image indices", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "indices", ")", ":", "\n", "# Load image", "\n", "        ", "img", ",", "_", ",", "(", "h", ",", "w", ")", "=", "load_image", "(", "self", ",", "index", ")", "\n", "\n", "# place img in img4", "\n", "if", "i", "==", "0", ":", "# top left", "\n", "            ", "img4", "=", "np", ".", "full", "(", "(", "s", "*", "2", ",", "s", "*", "2", ",", "img", ".", "shape", "[", "2", "]", ")", ",", "114", ",", "dtype", "=", "np", ".", "uint8", ")", "# base image with 4 tiles", "\n", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "max", "(", "xc", "-", "w", ",", "0", ")", ",", "max", "(", "yc", "-", "h", ",", "0", ")", ",", "xc", ",", "yc", "# xmin, ymin, xmax, ymax (large image)", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "w", "-", "(", "x2a", "-", "x1a", ")", ",", "h", "-", "(", "y2a", "-", "y1a", ")", ",", "w", ",", "h", "# xmin, ymin, xmax, ymax (small image)", "\n", "", "elif", "i", "==", "1", ":", "# top right", "\n", "            ", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "xc", ",", "max", "(", "yc", "-", "h", ",", "0", ")", ",", "min", "(", "xc", "+", "w", ",", "s", "*", "2", ")", ",", "yc", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "0", ",", "h", "-", "(", "y2a", "-", "y1a", ")", ",", "min", "(", "w", ",", "x2a", "-", "x1a", ")", ",", "h", "\n", "", "elif", "i", "==", "2", ":", "# bottom left", "\n", "            ", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "max", "(", "xc", "-", "w", ",", "0", ")", ",", "yc", ",", "xc", ",", "min", "(", "s", "*", "2", ",", "yc", "+", "h", ")", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "w", "-", "(", "x2a", "-", "x1a", ")", ",", "0", ",", "w", ",", "min", "(", "y2a", "-", "y1a", ",", "h", ")", "\n", "", "elif", "i", "==", "3", ":", "# bottom right", "\n", "            ", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "xc", ",", "yc", ",", "min", "(", "xc", "+", "w", ",", "s", "*", "2", ")", ",", "min", "(", "s", "*", "2", ",", "yc", "+", "h", ")", "\n", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "0", ",", "0", ",", "min", "(", "w", ",", "x2a", "-", "x1a", ")", ",", "min", "(", "y2a", "-", "y1a", ",", "h", ")", "\n", "\n", "", "img4", "[", "y1a", ":", "y2a", ",", "x1a", ":", "x2a", "]", "=", "img", "[", "y1b", ":", "y2b", ",", "x1b", ":", "x2b", "]", "# img4[ymin:ymax, xmin:xmax]", "\n", "padw", "=", "x1a", "-", "x1b", "\n", "padh", "=", "y1a", "-", "y1b", "\n", "\n", "# Labels", "\n", "x", "=", "self", ".", "labels", "[", "index", "]", "\n", "labels", "=", "x", ".", "copy", "(", ")", "\n", "if", "x", ".", "size", ">", "0", ":", "# Normalized xywh to pixel xyxy format", "\n", "            ", "labels", "[", ":", ",", "1", "]", "=", "w", "*", "(", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "padw", "\n", "labels", "[", ":", ",", "2", "]", "=", "h", "*", "(", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "padh", "\n", "labels", "[", ":", ",", "3", "]", "=", "w", "*", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "padw", "\n", "labels", "[", ":", ",", "4", "]", "=", "h", "*", "(", "x", "[", ":", ",", "2", "]", "+", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "padh", "\n", "", "labels4", ".", "append", "(", "labels", ")", "\n", "\n", "# Concat/clip labels", "\n", "", "if", "len", "(", "labels4", ")", ":", "\n", "        ", "labels4", "=", "np", ".", "concatenate", "(", "labels4", ",", "0", ")", "\n", "np", ".", "clip", "(", "labels4", "[", ":", ",", "1", ":", "]", ",", "0", ",", "2", "*", "s", ",", "out", "=", "labels4", "[", ":", ",", "1", ":", "]", ")", "# use with random_perspective", "\n", "# img4, labels4 = replicate(img4, labels4)  # replicate", "\n", "\n", "# Augment", "\n", "", "img4", ",", "labels4", "=", "random_perspective", "(", "img4", ",", "labels4", ",", "\n", "degrees", "=", "self", ".", "hyp", "[", "'degrees'", "]", ",", "\n", "translate", "=", "self", ".", "hyp", "[", "'translate'", "]", ",", "\n", "scale", "=", "self", ".", "hyp", "[", "'scale'", "]", ",", "\n", "shear", "=", "self", ".", "hyp", "[", "'shear'", "]", ",", "\n", "perspective", "=", "self", ".", "hyp", "[", "'perspective'", "]", ",", "\n", "border", "=", "self", ".", "mosaic_border", ")", "# border to remove", "\n", "\n", "return", "img4", ",", "labels4", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_mosaic9": [[1018, 1090], ["enumerate", "len", "datasets.random_perspective", "datasets.load_image", "x.copy", "np.concatenate.append", "int", "numpy.concatenate", "numpy.clip", "random.randint", "numpy.full", "max", "random.uniform", "range", "len"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.random_perspective", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.load_image"], ["", "def", "load_mosaic9", "(", "self", ",", "index", ")", ":", "\n", "# loads images in a 9-mosaic", "\n", "\n", "    ", "labels9", "=", "[", "]", "\n", "s", "=", "self", ".", "img_size", "\n", "indices", "=", "[", "index", "]", "+", "[", "random", ".", "randint", "(", "0", ",", "len", "(", "self", ".", "labels", ")", "-", "1", ")", "for", "_", "in", "range", "(", "8", ")", "]", "# 8 additional image indices", "\n", "for", "i", ",", "index", "in", "enumerate", "(", "indices", ")", ":", "\n", "# Load image", "\n", "        ", "img", ",", "_", ",", "(", "h", ",", "w", ")", "=", "load_image", "(", "self", ",", "index", ")", "\n", "\n", "# place img in img9", "\n", "if", "i", "==", "0", ":", "# center", "\n", "            ", "img9", "=", "np", ".", "full", "(", "(", "s", "*", "3", ",", "s", "*", "3", ",", "img", ".", "shape", "[", "2", "]", ")", ",", "114", ",", "dtype", "=", "np", ".", "uint8", ")", "# base image with 4 tiles", "\n", "h0", ",", "w0", "=", "h", ",", "w", "\n", "c", "=", "s", ",", "s", ",", "s", "+", "w", ",", "s", "+", "h", "# xmin, ymin, xmax, ymax (base) coordinates", "\n", "", "elif", "i", "==", "1", ":", "# top", "\n", "            ", "c", "=", "s", ",", "s", "-", "h", ",", "s", "+", "w", ",", "s", "\n", "", "elif", "i", "==", "2", ":", "# top right", "\n", "            ", "c", "=", "s", "+", "wp", ",", "s", "-", "h", ",", "s", "+", "wp", "+", "w", ",", "s", "\n", "", "elif", "i", "==", "3", ":", "# right", "\n", "            ", "c", "=", "s", "+", "w0", ",", "s", ",", "s", "+", "w0", "+", "w", ",", "s", "+", "h", "\n", "", "elif", "i", "==", "4", ":", "# bottom right", "\n", "            ", "c", "=", "s", "+", "w0", ",", "s", "+", "hp", ",", "s", "+", "w0", "+", "w", ",", "s", "+", "hp", "+", "h", "\n", "", "elif", "i", "==", "5", ":", "# bottom", "\n", "            ", "c", "=", "s", "+", "w0", "-", "w", ",", "s", "+", "h0", ",", "s", "+", "w0", ",", "s", "+", "h0", "+", "h", "\n", "", "elif", "i", "==", "6", ":", "# bottom left", "\n", "            ", "c", "=", "s", "+", "w0", "-", "wp", "-", "w", ",", "s", "+", "h0", ",", "s", "+", "w0", "-", "wp", ",", "s", "+", "h0", "+", "h", "\n", "", "elif", "i", "==", "7", ":", "# left", "\n", "            ", "c", "=", "s", "-", "w", ",", "s", "+", "h0", "-", "h", ",", "s", ",", "s", "+", "h0", "\n", "", "elif", "i", "==", "8", ":", "# top left", "\n", "            ", "c", "=", "s", "-", "w", ",", "s", "+", "h0", "-", "hp", "-", "h", ",", "s", ",", "s", "+", "h0", "-", "hp", "\n", "\n", "", "padx", ",", "pady", "=", "c", "[", ":", "2", "]", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "[", "max", "(", "x", ",", "0", ")", "for", "x", "in", "c", "]", "# allocate coords", "\n", "\n", "# Labels", "\n", "x", "=", "self", ".", "labels", "[", "index", "]", "\n", "labels", "=", "x", ".", "copy", "(", ")", "\n", "if", "x", ".", "size", ">", "0", ":", "# Normalized xywh to pixel xyxy format", "\n", "            ", "labels", "[", ":", ",", "1", "]", "=", "w", "*", "(", "x", "[", ":", ",", "1", "]", "-", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "padx", "\n", "labels", "[", ":", ",", "2", "]", "=", "h", "*", "(", "x", "[", ":", ",", "2", "]", "-", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pady", "\n", "labels", "[", ":", ",", "3", "]", "=", "w", "*", "(", "x", "[", ":", ",", "1", "]", "+", "x", "[", ":", ",", "3", "]", "/", "2", ")", "+", "padx", "\n", "labels", "[", ":", ",", "4", "]", "=", "h", "*", "(", "x", "[", ":", ",", "2", "]", "+", "x", "[", ":", ",", "4", "]", "/", "2", ")", "+", "pady", "\n", "", "labels9", ".", "append", "(", "labels", ")", "\n", "\n", "# Image", "\n", "img9", "[", "y1", ":", "y2", ",", "x1", ":", "x2", "]", "=", "img", "[", "y1", "-", "pady", ":", ",", "x1", "-", "padx", ":", "]", "# img9[ymin:ymax, xmin:xmax]", "\n", "hp", ",", "wp", "=", "h", ",", "w", "# height, width previous", "\n", "\n", "# Offset", "\n", "", "yc", ",", "xc", "=", "[", "int", "(", "random", ".", "uniform", "(", "0", ",", "s", ")", ")", "for", "x", "in", "self", ".", "mosaic_border", "]", "# mosaic center x, y", "\n", "img9", "=", "img9", "[", "yc", ":", "yc", "+", "2", "*", "s", ",", "xc", ":", "xc", "+", "2", "*", "s", "]", "\n", "\n", "# Concat/clip labels", "\n", "if", "len", "(", "labels9", ")", ":", "\n", "        ", "labels9", "=", "np", ".", "concatenate", "(", "labels9", ",", "0", ")", "\n", "labels9", "[", ":", ",", "[", "1", ",", "3", "]", "]", "-=", "xc", "\n", "labels9", "[", ":", ",", "[", "2", ",", "4", "]", "]", "-=", "yc", "\n", "\n", "np", ".", "clip", "(", "labels9", "[", ":", ",", "1", ":", "]", ",", "0", ",", "2", "*", "s", ",", "out", "=", "labels9", "[", ":", ",", "1", ":", "]", ")", "# use with random_perspective", "\n", "# img9, labels9 = replicate(img9, labels9)  # replicate", "\n", "\n", "# Augment", "\n", "", "img9", ",", "labels9", "=", "random_perspective", "(", "img9", ",", "labels9", ",", "\n", "degrees", "=", "self", ".", "hyp", "[", "'degrees'", "]", ",", "\n", "translate", "=", "self", ".", "hyp", "[", "'translate'", "]", ",", "\n", "scale", "=", "self", ".", "hyp", "[", "'scale'", "]", ",", "\n", "shear", "=", "self", ".", "hyp", "[", "'shear'", "]", ",", "\n", "perspective", "=", "self", ".", "hyp", "[", "'perspective'", "]", ",", "\n", "border", "=", "self", ".", "mosaic_border", ")", "# border to remove", "\n", "\n", "return", "img9", ",", "labels9", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.replicate": [[1092, 1107], ["labels[].astype", "s.argsort", "numpy.append", "round", "int", "int", "random.uniform", "random.uniform"], "function", ["None"], ["", "def", "replicate", "(", "img", ",", "labels", ")", ":", "\n", "# Replicate labels", "\n", "    ", "h", ",", "w", "=", "img", ".", "shape", "[", ":", "2", "]", "\n", "boxes", "=", "labels", "[", ":", ",", "1", ":", "]", ".", "astype", "(", "int", ")", "\n", "x1", ",", "y1", ",", "x2", ",", "y2", "=", "boxes", ".", "T", "\n", "s", "=", "(", "(", "x2", "-", "x1", ")", "+", "(", "y2", "-", "y1", ")", ")", "/", "2", "# side length (pixels)", "\n", "for", "i", "in", "s", ".", "argsort", "(", ")", "[", ":", "round", "(", "s", ".", "size", "*", "0.5", ")", "]", ":", "# smallest indices", "\n", "        ", "x1b", ",", "y1b", ",", "x2b", ",", "y2b", "=", "boxes", "[", "i", "]", "\n", "bh", ",", "bw", "=", "y2b", "-", "y1b", ",", "x2b", "-", "x1b", "\n", "yc", ",", "xc", "=", "int", "(", "random", ".", "uniform", "(", "0", ",", "h", "-", "bh", ")", ")", ",", "int", "(", "random", ".", "uniform", "(", "0", ",", "w", "-", "bw", ")", ")", "# offset x, y", "\n", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "=", "[", "xc", ",", "yc", ",", "xc", "+", "bw", ",", "yc", "+", "bh", "]", "\n", "img", "[", "y1a", ":", "y2a", ",", "x1a", ":", "x2a", "]", "=", "img", "[", "y1b", ":", "y2b", ",", "x1b", ":", "x2b", "]", "# img4[ymin:ymax, xmin:xmax]", "\n", "labels", "=", "np", ".", "append", "(", "labels", ",", "[", "[", "labels", "[", "i", ",", "0", "]", ",", "x1a", ",", "y1a", ",", "x2a", ",", "y2a", "]", "]", ",", "axis", "=", "0", ")", "\n", "\n", "", "return", "img", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.letterbox": [[1109, 1140], ["isinstance", "min", "cv2.copyMakeBorder", "min", "int", "int", "cv2.resize", "int", "int", "int", "int", "round", "round", "numpy.mod", "numpy.mod", "round", "round", "round", "round"], "function", ["None"], ["", "def", "letterbox", "(", "img", ",", "new_shape", "=", "(", "640", ",", "640", ")", ",", "color", "=", "(", "114", ",", "114", ",", "114", ")", ",", "auto", "=", "True", ",", "scaleFill", "=", "False", ",", "scaleup", "=", "True", ",", "auto_size", "=", "32", ")", ":", "\n", "# Resize image to a 32-pixel-multiple rectangle https://github.com/ultralytics/yolov3/issues/232", "\n", "    ", "shape", "=", "img", ".", "shape", "[", ":", "2", "]", "# current shape [height, width]", "\n", "if", "isinstance", "(", "new_shape", ",", "int", ")", ":", "\n", "        ", "new_shape", "=", "(", "new_shape", ",", "new_shape", ")", "\n", "\n", "# Scale ratio (new / old)", "\n", "", "r", "=", "min", "(", "new_shape", "[", "0", "]", "/", "shape", "[", "0", "]", ",", "new_shape", "[", "1", "]", "/", "shape", "[", "1", "]", ")", "\n", "if", "not", "scaleup", ":", "# only scale down, do not scale up (for better test mAP)", "\n", "        ", "r", "=", "min", "(", "r", ",", "1.0", ")", "\n", "\n", "# Compute padding", "\n", "", "ratio", "=", "r", ",", "r", "# width, height ratios", "\n", "new_unpad", "=", "int", "(", "round", "(", "shape", "[", "1", "]", "*", "r", ")", ")", ",", "int", "(", "round", "(", "shape", "[", "0", "]", "*", "r", ")", ")", "\n", "dw", ",", "dh", "=", "new_shape", "[", "1", "]", "-", "new_unpad", "[", "0", "]", ",", "new_shape", "[", "0", "]", "-", "new_unpad", "[", "1", "]", "# wh padding", "\n", "if", "auto", ":", "# minimum rectangle", "\n", "        ", "dw", ",", "dh", "=", "np", ".", "mod", "(", "dw", ",", "auto_size", ")", ",", "np", ".", "mod", "(", "dh", ",", "auto_size", ")", "# wh padding", "\n", "", "elif", "scaleFill", ":", "# stretch", "\n", "        ", "dw", ",", "dh", "=", "0.0", ",", "0.0", "\n", "new_unpad", "=", "(", "new_shape", "[", "1", "]", ",", "new_shape", "[", "0", "]", ")", "\n", "ratio", "=", "new_shape", "[", "1", "]", "/", "shape", "[", "1", "]", ",", "new_shape", "[", "0", "]", "/", "shape", "[", "0", "]", "# width, height ratios", "\n", "\n", "", "dw", "/=", "2", "# divide padding into 2 sides", "\n", "dh", "/=", "2", "\n", "\n", "if", "shape", "[", ":", ":", "-", "1", "]", "!=", "new_unpad", ":", "# resize", "\n", "        ", "img", "=", "cv2", ".", "resize", "(", "img", ",", "new_unpad", ",", "interpolation", "=", "cv2", ".", "INTER_LINEAR", ")", "\n", "", "top", ",", "bottom", "=", "int", "(", "round", "(", "dh", "-", "0.1", ")", ")", ",", "int", "(", "round", "(", "dh", "+", "0.1", ")", ")", "\n", "left", ",", "right", "=", "int", "(", "round", "(", "dw", "-", "0.1", ")", ")", ",", "int", "(", "round", "(", "dw", "+", "0.1", ")", ")", "\n", "img", "=", "cv2", ".", "copyMakeBorder", "(", "img", ",", "top", ",", "bottom", ",", "left", ",", "right", ",", "cv2", ".", "BORDER_CONSTANT", ",", "value", "=", "color", ")", "# add border", "\n", "return", "img", ",", "ratio", ",", "(", "dw", ",", "dh", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.random_perspective": [[1142, 1227], ["numpy.eye", "numpy.eye", "random.uniform", "random.uniform", "numpy.eye", "random.uniform", "random.uniform", "cv2.getRotationMatrix2D", "numpy.eye", "math.tan", "math.tan", "numpy.eye", "len", "random.uniform", "random.uniform", "numpy.ones", "targets[].reshape", "xy[].clip", "xy[].clip", "datasets.box_candidates", "cv2.warpPerspective", "cv2.warpAffine", "xy[].reshape", "numpy.concatenate().reshape", "random.uniform", "random.uniform", "numpy.eye", "numpy.concatenate", "x.min", "y.min", "x.max", "y.max"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.box_candidates"], ["", "def", "random_perspective", "(", "img", ",", "targets", "=", "(", ")", ",", "degrees", "=", "10", ",", "translate", "=", ".1", ",", "scale", "=", ".1", ",", "shear", "=", "10", ",", "perspective", "=", "0.0", ",", "border", "=", "(", "0", ",", "0", ")", ")", ":", "\n", "# torchvision.transforms.RandomAffine(degrees=(-10, 10), translate=(.1, .1), scale=(.9, 1.1), shear=(-10, 10))", "\n", "# targets = [cls, xyxy]", "\n", "\n", "    ", "height", "=", "img", ".", "shape", "[", "0", "]", "+", "border", "[", "0", "]", "*", "2", "# shape(h,w,c)", "\n", "width", "=", "img", ".", "shape", "[", "1", "]", "+", "border", "[", "1", "]", "*", "2", "\n", "\n", "# Center", "\n", "C", "=", "np", ".", "eye", "(", "3", ")", "\n", "C", "[", "0", ",", "2", "]", "=", "-", "img", ".", "shape", "[", "1", "]", "/", "2", "# x translation (pixels)", "\n", "C", "[", "1", ",", "2", "]", "=", "-", "img", ".", "shape", "[", "0", "]", "/", "2", "# y translation (pixels)", "\n", "\n", "# Perspective", "\n", "P", "=", "np", ".", "eye", "(", "3", ")", "\n", "P", "[", "2", ",", "0", "]", "=", "random", ".", "uniform", "(", "-", "perspective", ",", "perspective", ")", "# x perspective (about y)", "\n", "P", "[", "2", ",", "1", "]", "=", "random", ".", "uniform", "(", "-", "perspective", ",", "perspective", ")", "# y perspective (about x)", "\n", "\n", "# Rotation and Scale", "\n", "R", "=", "np", ".", "eye", "(", "3", ")", "\n", "a", "=", "random", ".", "uniform", "(", "-", "degrees", ",", "degrees", ")", "\n", "# a += random.choice([-180, -90, 0, 90])  # add 90deg rotations to small rotations", "\n", "s", "=", "random", ".", "uniform", "(", "1", "-", "scale", ",", "1", "+", "scale", ")", "\n", "# s = 2 ** random.uniform(-scale, scale)", "\n", "R", "[", ":", "2", "]", "=", "cv2", ".", "getRotationMatrix2D", "(", "angle", "=", "a", ",", "center", "=", "(", "0", ",", "0", ")", ",", "scale", "=", "s", ")", "\n", "\n", "# Shear", "\n", "S", "=", "np", ".", "eye", "(", "3", ")", "\n", "S", "[", "0", ",", "1", "]", "=", "math", ".", "tan", "(", "random", ".", "uniform", "(", "-", "shear", ",", "shear", ")", "*", "math", ".", "pi", "/", "180", ")", "# x shear (deg)", "\n", "S", "[", "1", ",", "0", "]", "=", "math", ".", "tan", "(", "random", ".", "uniform", "(", "-", "shear", ",", "shear", ")", "*", "math", ".", "pi", "/", "180", ")", "# y shear (deg)", "\n", "\n", "# Translation", "\n", "T", "=", "np", ".", "eye", "(", "3", ")", "\n", "T", "[", "0", ",", "2", "]", "=", "random", ".", "uniform", "(", "0.5", "-", "translate", ",", "0.5", "+", "translate", ")", "*", "width", "# x translation (pixels)", "\n", "T", "[", "1", ",", "2", "]", "=", "random", ".", "uniform", "(", "0.5", "-", "translate", ",", "0.5", "+", "translate", ")", "*", "height", "# y translation (pixels)", "\n", "\n", "# Combined rotation matrix", "\n", "M", "=", "T", "@", "S", "@", "R", "@", "P", "@", "C", "# order of operations (right to left) is IMPORTANT", "\n", "if", "(", "border", "[", "0", "]", "!=", "0", ")", "or", "(", "border", "[", "1", "]", "!=", "0", ")", "or", "(", "M", "!=", "np", ".", "eye", "(", "3", ")", ")", ".", "any", "(", ")", ":", "# image changed", "\n", "        ", "if", "perspective", ":", "\n", "            ", "img", "=", "cv2", ".", "warpPerspective", "(", "img", ",", "M", ",", "dsize", "=", "(", "width", ",", "height", ")", ",", "borderValue", "=", "(", "114", ",", "114", ",", "114", ")", ")", "\n", "", "else", ":", "# affine", "\n", "            ", "img", "=", "cv2", ".", "warpAffine", "(", "img", ",", "M", "[", ":", "2", "]", ",", "dsize", "=", "(", "width", ",", "height", ")", ",", "borderValue", "=", "(", "114", ",", "114", ",", "114", ")", ")", "\n", "\n", "# Visualize", "\n", "# import matplotlib.pyplot as plt", "\n", "# ax = plt.subplots(1, 2, figsize=(12, 6))[1].ravel()", "\n", "# ax[0].imshow(img[:, :, ::-1])  # base", "\n", "# ax[1].imshow(img2[:, :, ::-1])  # warped", "\n", "\n", "# Transform label coordinates", "\n", "", "", "n", "=", "len", "(", "targets", ")", "\n", "if", "n", ":", "\n", "# warp points", "\n", "        ", "xy", "=", "np", ".", "ones", "(", "(", "n", "*", "4", ",", "3", ")", ")", "\n", "xy", "[", ":", ",", ":", "2", "]", "=", "targets", "[", ":", ",", "[", "1", ",", "2", ",", "3", ",", "4", ",", "1", ",", "4", ",", "3", ",", "2", "]", "]", ".", "reshape", "(", "n", "*", "4", ",", "2", ")", "# x1y1, x2y2, x1y2, x2y1", "\n", "xy", "=", "xy", "@", "M", ".", "T", "# transform", "\n", "if", "perspective", ":", "\n", "            ", "xy", "=", "(", "xy", "[", ":", ",", ":", "2", "]", "/", "xy", "[", ":", ",", "2", ":", "3", "]", ")", ".", "reshape", "(", "n", ",", "8", ")", "# rescale", "\n", "", "else", ":", "# affine", "\n", "            ", "xy", "=", "xy", "[", ":", ",", ":", "2", "]", ".", "reshape", "(", "n", ",", "8", ")", "\n", "\n", "# create new boxes", "\n", "", "x", "=", "xy", "[", ":", ",", "[", "0", ",", "2", ",", "4", ",", "6", "]", "]", "\n", "y", "=", "xy", "[", ":", ",", "[", "1", ",", "3", ",", "5", ",", "7", "]", "]", "\n", "xy", "=", "np", ".", "concatenate", "(", "(", "x", ".", "min", "(", "1", ")", ",", "y", ".", "min", "(", "1", ")", ",", "x", ".", "max", "(", "1", ")", ",", "y", ".", "max", "(", "1", ")", ")", ")", ".", "reshape", "(", "4", ",", "n", ")", ".", "T", "\n", "\n", "# # apply angle-based reduction of bounding boxes", "\n", "# radians = a * math.pi / 180", "\n", "# reduction = max(abs(math.sin(radians)), abs(math.cos(radians))) ** 0.5", "\n", "# x = (xy[:, 2] + xy[:, 0]) / 2", "\n", "# y = (xy[:, 3] + xy[:, 1]) / 2", "\n", "# w = (xy[:, 2] - xy[:, 0]) * reduction", "\n", "# h = (xy[:, 3] - xy[:, 1]) * reduction", "\n", "# xy = np.concatenate((x - w / 2, y - h / 2, x + w / 2, y + h / 2)).reshape(4, n).T", "\n", "\n", "# clip boxes", "\n", "xy", "[", ":", ",", "[", "0", ",", "2", "]", "]", "=", "xy", "[", ":", ",", "[", "0", ",", "2", "]", "]", ".", "clip", "(", "0", ",", "width", ")", "\n", "xy", "[", ":", ",", "[", "1", ",", "3", "]", "]", "=", "xy", "[", ":", ",", "[", "1", ",", "3", "]", "]", ".", "clip", "(", "0", ",", "height", ")", "\n", "\n", "# filter candidates", "\n", "i", "=", "box_candidates", "(", "box1", "=", "targets", "[", ":", ",", "1", ":", "5", "]", ".", "T", "*", "s", ",", "box2", "=", "xy", ".", "T", ")", "\n", "targets", "=", "targets", "[", "i", "]", "\n", "targets", "[", ":", ",", "1", ":", "5", "]", "=", "xy", "[", "i", "]", "\n", "\n", "", "return", "img", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.box_candidates": [[1229, 1235], ["numpy.maximum"], "function", ["None"], ["", "def", "box_candidates", "(", "box1", ",", "box2", ",", "wh_thr", "=", "2", ",", "ar_thr", "=", "20", ",", "area_thr", "=", "0.1", ")", ":", "# box1(4,n), box2(4,n)", "\n", "# Compute candidate boxes: box1 before augment, box2 after augment, wh_thr (pixels), aspect_ratio_thr, area_ratio", "\n", "    ", "w1", ",", "h1", "=", "box1", "[", "2", "]", "-", "box1", "[", "0", "]", ",", "box1", "[", "3", "]", "-", "box1", "[", "1", "]", "\n", "w2", ",", "h2", "=", "box2", "[", "2", "]", "-", "box2", "[", "0", "]", ",", "box2", "[", "3", "]", "-", "box2", "[", "1", "]", "\n", "ar", "=", "np", ".", "maximum", "(", "w2", "/", "(", "h2", "+", "1e-16", ")", ",", "h2", "/", "(", "w2", "+", "1e-16", ")", ")", "# aspect ratio", "\n", "return", "(", "w2", ">", "wh_thr", ")", "&", "(", "h2", ">", "wh_thr", ")", "&", "(", "w2", "*", "h2", "/", "(", "w1", "*", "h1", "+", "1e-16", ")", ">", "area_thr", ")", "&", "(", "ar", "<", "ar_thr", ")", "# candidates", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.cutout": [[1237, 1281], ["box2.transpose.transpose", "random.randint", "random.randint", "max", "max", "min", "min", "int", "int", "random.randint", "len", "numpy.array", "datasets.cutout.bbox_ioa"], "function", ["None"], ["", "def", "cutout", "(", "image", ",", "labels", ")", ":", "\n", "# Applies image cutout augmentation https://arxiv.org/abs/1708.04552", "\n", "    ", "h", ",", "w", "=", "image", ".", "shape", "[", ":", "2", "]", "\n", "\n", "def", "bbox_ioa", "(", "box1", ",", "box2", ")", ":", "\n", "# Returns the intersection over box2 area given box1, box2. box1 is 4, box2 is nx4. boxes are x1y1x2y2", "\n", "        ", "box2", "=", "box2", ".", "transpose", "(", ")", "\n", "\n", "# Get the coordinates of bounding boxes", "\n", "b1_x1", ",", "b1_y1", ",", "b1_x2", ",", "b1_y2", "=", "box1", "[", "0", "]", ",", "box1", "[", "1", "]", ",", "box1", "[", "2", "]", ",", "box1", "[", "3", "]", "\n", "b2_x1", ",", "b2_y1", ",", "b2_x2", ",", "b2_y2", "=", "box2", "[", "0", "]", ",", "box2", "[", "1", "]", ",", "box2", "[", "2", "]", ",", "box2", "[", "3", "]", "\n", "\n", "# Intersection area", "\n", "inter_area", "=", "(", "np", ".", "minimum", "(", "b1_x2", ",", "b2_x2", ")", "-", "np", ".", "maximum", "(", "b1_x1", ",", "b2_x1", ")", ")", ".", "clip", "(", "0", ")", "*", "(", "np", ".", "minimum", "(", "b1_y2", ",", "b2_y2", ")", "-", "np", ".", "maximum", "(", "b1_y1", ",", "b2_y1", ")", ")", ".", "clip", "(", "0", ")", "\n", "\n", "# box2 area", "\n", "box2_area", "=", "(", "b2_x2", "-", "b2_x1", ")", "*", "(", "b2_y2", "-", "b2_y1", ")", "+", "1e-16", "\n", "\n", "# Intersection over box2 area", "\n", "return", "inter_area", "/", "box2_area", "\n", "\n", "# create random masks", "\n", "", "scales", "=", "[", "0.5", "]", "*", "1", "+", "[", "0.25", "]", "*", "2", "+", "[", "0.125", "]", "*", "4", "+", "[", "0.0625", "]", "*", "8", "+", "[", "0.03125", "]", "*", "16", "# image size fraction", "\n", "for", "s", "in", "scales", ":", "\n", "        ", "mask_h", "=", "random", ".", "randint", "(", "1", ",", "int", "(", "h", "*", "s", ")", ")", "\n", "mask_w", "=", "random", ".", "randint", "(", "1", ",", "int", "(", "w", "*", "s", ")", ")", "\n", "\n", "# box", "\n", "xmin", "=", "max", "(", "0", ",", "random", ".", "randint", "(", "0", ",", "w", ")", "-", "mask_w", "//", "2", ")", "\n", "ymin", "=", "max", "(", "0", ",", "random", ".", "randint", "(", "0", ",", "h", ")", "-", "mask_h", "//", "2", ")", "\n", "xmax", "=", "min", "(", "w", ",", "xmin", "+", "mask_w", ")", "\n", "ymax", "=", "min", "(", "h", ",", "ymin", "+", "mask_h", ")", "\n", "\n", "# apply random color mask", "\n", "image", "[", "ymin", ":", "ymax", ",", "xmin", ":", "xmax", "]", "=", "[", "random", ".", "randint", "(", "64", ",", "191", ")", "for", "_", "in", "range", "(", "3", ")", "]", "\n", "\n", "# return unobscured labels", "\n", "if", "len", "(", "labels", ")", "and", "s", ">", "0.03", ":", "\n", "            ", "box", "=", "np", ".", "array", "(", "[", "xmin", ",", "ymin", ",", "xmax", ",", "ymax", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "ioa", "=", "bbox_ioa", "(", "box", ",", "labels", "[", ":", ",", "1", ":", "5", "]", ")", "# intersection over area", "\n", "labels", "=", "labels", "[", "ioa", "<", "0.60", "]", "# remove >60% obscured labels", "\n", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_folder": [[1283, 1288], ["os.path.exists", "os.makedirs", "shutil.rmtree"], "function", ["None"], ["", "def", "create_folder", "(", "path", "=", "'./new'", ")", ":", "\n", "# Create folder", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "path", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "path", ")", "# delete output folder", "\n", "", "os", ".", "makedirs", "(", "path", ")", "# make new output folder", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.flatten_recursive": [[1290, 1296], ["pathlib.Path", "datasets.create_folder", "tqdm.tqdm", "glob.glob", "shutil.copyfile", "str", "pathlib.Path", "pathlib.Path"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.datasets.create_folder"], ["", "def", "flatten_recursive", "(", "path", "=", "'../coco128'", ")", ":", "\n", "# Flatten a recursive directory by bringing all files to top level", "\n", "    ", "new_path", "=", "Path", "(", "path", "+", "'_flat'", ")", "\n", "create_folder", "(", "new_path", ")", "\n", "for", "file", "in", "tqdm", "(", "glob", ".", "glob", "(", "str", "(", "Path", "(", "path", ")", ")", "+", "'/**/*.*'", ",", "recursive", "=", "True", ")", ")", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "file", ",", "new_path", "/", "Path", "(", "file", ")", ".", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.YOLOLayer.__init__": [[340, 357], ["nn.Module.__init__", "torch.Tensor", "len", "len", "models.YOLOLayer.anchor_vec.view", "models.YOLOLayer.create_grids"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.create_grids"], ["    ", "def", "__init__", "(", "self", ",", "anchors", ",", "nc", ",", "img_size", ",", "yolo_index", ",", "layers", ",", "stride", ")", ":", "\n", "        ", "super", "(", "YOLOLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "anchors", "=", "torch", ".", "Tensor", "(", "anchors", ")", "\n", "self", ".", "index", "=", "yolo_index", "# index of this layer in layers", "\n", "self", ".", "layers", "=", "layers", "# model output layer indices", "\n", "self", ".", "stride", "=", "stride", "# layer stride", "\n", "self", ".", "nl", "=", "len", "(", "layers", ")", "# number of output layers (3)", "\n", "self", ".", "na", "=", "len", "(", "anchors", ")", "# number of anchors (3)", "\n", "self", ".", "nc", "=", "nc", "# number of classes (80)", "\n", "self", ".", "no", "=", "nc", "+", "5", "# number of outputs (85)", "\n", "self", ".", "nx", ",", "self", ".", "ny", ",", "self", ".", "ng", "=", "0", ",", "0", ",", "0", "# initialize number of x, y gridpoints", "\n", "self", ".", "anchor_vec", "=", "self", ".", "anchors", "/", "self", ".", "stride", "\n", "self", ".", "anchor_wh", "=", "self", ".", "anchor_vec", ".", "view", "(", "1", ",", "self", ".", "na", ",", "1", ",", "1", ",", "2", ")", "\n", "\n", "if", "ONNX_EXPORT", ":", "\n", "            ", "self", ".", "training", "=", "False", "\n", "self", ".", "create_grids", "(", "(", "img_size", "[", "1", "]", "//", "stride", ",", "img_size", "[", "0", "]", "//", "stride", ")", ")", "# number x, y grid points", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.YOLOLayer.create_grids": [[358, 370], ["torch.tensor", "torch.meshgrid", "torch.stack().view().float", "models.YOLOLayer.anchor_vec.to", "models.YOLOLayer.anchor_wh.to", "torch.arange", "torch.arange", "torch.stack().view", "torch.stack"], "methods", ["None"], ["", "", "def", "create_grids", "(", "self", ",", "ng", "=", "(", "13", ",", "13", ")", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "nx", ",", "self", ".", "ny", "=", "ng", "# x and y grid size", "\n", "self", ".", "ng", "=", "torch", ".", "tensor", "(", "ng", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# build xy offsets", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "yv", ",", "xv", "=", "torch", ".", "meshgrid", "(", "[", "torch", ".", "arange", "(", "self", ".", "ny", ",", "device", "=", "device", ")", ",", "torch", ".", "arange", "(", "self", ".", "nx", ",", "device", "=", "device", ")", "]", ")", "\n", "self", ".", "grid", "=", "torch", ".", "stack", "(", "(", "xv", ",", "yv", ")", ",", "2", ")", ".", "view", "(", "(", "1", ",", "1", ",", "self", ".", "ny", ",", "self", ".", "nx", ",", "2", ")", ")", ".", "float", "(", ")", "\n", "\n", "", "if", "self", ".", "anchor_vec", ".", "device", "!=", "device", ":", "\n", "            ", "self", ".", "anchor_vec", "=", "self", ".", "anchor_vec", ".", "to", "(", "device", ")", "\n", "self", ".", "anchor_wh", "=", "self", ".", "anchor_wh", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.YOLOLayer.forward": [[371, 430], ["p.view.view.view().permute().contiguous", "range", "models.YOLOLayer.create_grids", "torch.sigmoid", "p.view.view.view().permute", "models.YOLOLayer.grid.repeat().view", "p.view.view.view", "p.view.view.sigmoid", "models.YOLOLayer.create_grids", "models.YOLOLayer.ng.repeat", "models.YOLOLayer.anchor_wh.repeat().view", "torch.sigmoid", "torch.exp", "torch.sigmoid", "p.view.sigmoid.view", "F.interpolate", "p.view.view.view", "models.YOLOLayer.grid.repeat", "torch.sigmoid", "torch.sigmoid", "models.YOLOLayer.anchor_wh.repeat"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.create_grids", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.create_grids"], ["", "", "def", "forward", "(", "self", ",", "p", ",", "out", ")", ":", "\n", "        ", "ASFF", "=", "False", "# https://arxiv.org/abs/1911.09516", "\n", "if", "ASFF", ":", "\n", "            ", "i", ",", "n", "=", "self", ".", "index", ",", "self", ".", "nl", "# index in layers, number of layers", "\n", "p", "=", "out", "[", "self", ".", "layers", "[", "i", "]", "]", "\n", "bs", ",", "_", ",", "ny", ",", "nx", "=", "p", ".", "shape", "# bs, 255, 13, 13", "\n", "if", "(", "self", ".", "nx", ",", "self", ".", "ny", ")", "!=", "(", "nx", ",", "ny", ")", ":", "\n", "                ", "self", ".", "create_grids", "(", "(", "nx", ",", "ny", ")", ",", "p", ".", "device", ")", "\n", "\n", "# outputs and weights", "\n", "# w = F.softmax(p[:, -n:], 1)  # normalized weights", "\n", "", "w", "=", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "-", "n", ":", "]", ")", "*", "(", "2", "/", "n", ")", "# sigmoid weights (faster)", "\n", "# w = w / w.sum(1).unsqueeze(1)  # normalize across layer dimension", "\n", "\n", "# weighted ASFF sum", "\n", "p", "=", "out", "[", "self", ".", "layers", "[", "i", "]", "]", "[", ":", ",", ":", "-", "n", "]", "*", "w", "[", ":", ",", "i", ":", "i", "+", "1", "]", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "\n", "                    ", "p", "+=", "w", "[", ":", ",", "j", ":", "j", "+", "1", "]", "*", "F", ".", "interpolate", "(", "out", "[", "self", ".", "layers", "[", "j", "]", "]", "[", ":", ",", ":", "-", "n", "]", ",", "size", "=", "[", "ny", ",", "nx", "]", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "\n", "", "", "", "elif", "ONNX_EXPORT", ":", "\n", "            ", "bs", "=", "1", "# batch size", "\n", "", "else", ":", "\n", "            ", "bs", ",", "_", ",", "ny", ",", "nx", "=", "p", ".", "shape", "# bs, 255, 13, 13", "\n", "if", "(", "self", ".", "nx", ",", "self", ".", "ny", ")", "!=", "(", "nx", ",", "ny", ")", ":", "\n", "                ", "self", ".", "create_grids", "(", "(", "nx", ",", "ny", ")", ",", "p", ".", "device", ")", "\n", "\n", "# p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)", "\n", "", "", "p", "=", "p", ".", "view", "(", "bs", ",", "self", ".", "na", ",", "self", ".", "no", ",", "self", ".", "ny", ",", "self", ".", "nx", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", ".", "contiguous", "(", ")", "# prediction", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "p", "\n", "\n", "", "elif", "ONNX_EXPORT", ":", "\n", "# Avoid broadcasting for ANE operations", "\n", "            ", "m", "=", "self", ".", "na", "*", "self", ".", "nx", "*", "self", ".", "ny", "\n", "ng", "=", "1.", "/", "self", ".", "ng", ".", "repeat", "(", "m", ",", "1", ")", "\n", "grid", "=", "self", ".", "grid", ".", "repeat", "(", "1", ",", "self", ".", "na", ",", "1", ",", "1", ",", "1", ")", ".", "view", "(", "m", ",", "2", ")", "\n", "anchor_wh", "=", "self", ".", "anchor_wh", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "nx", ",", "self", ".", "ny", ",", "1", ")", ".", "view", "(", "m", ",", "2", ")", "*", "ng", "\n", "\n", "p", "=", "p", ".", "view", "(", "m", ",", "self", ".", "no", ")", "\n", "xy", "=", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "0", ":", "2", "]", ")", "+", "grid", "# x, y", "\n", "wh", "=", "torch", ".", "exp", "(", "p", "[", ":", ",", "2", ":", "4", "]", ")", "*", "anchor_wh", "# width, height", "\n", "p_cls", "=", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "4", ":", "5", "]", ")", "if", "self", ".", "nc", "==", "1", "else", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "5", ":", "self", ".", "no", "]", ")", "*", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "4", ":", "5", "]", ")", "# conf", "\n", "return", "p_cls", ",", "xy", "*", "ng", ",", "wh", "\n", "\n", "", "else", ":", "# inference", "\n", "            ", "io", "=", "p", ".", "sigmoid", "(", ")", "\n", "io", "[", "...", ",", ":", "2", "]", "=", "(", "io", "[", "...", ",", ":", "2", "]", "*", "2.", "-", "0.5", "+", "self", ".", "grid", ")", "\n", "io", "[", "...", ",", "2", ":", "4", "]", "=", "(", "io", "[", "...", ",", "2", ":", "4", "]", "*", "2", ")", "**", "2", "*", "self", ".", "anchor_wh", "\n", "io", "[", "...", ",", ":", "4", "]", "*=", "self", ".", "stride", "\n", "#io = p.clone()  # inference output", "\n", "#io[..., :2] = torch.sigmoid(io[..., :2]) + self.grid  # xy", "\n", "#io[..., 2:4] = torch.exp(io[..., 2:4]) * self.anchor_wh  # wh yolo method", "\n", "#io[..., :4] *= self.stride", "\n", "#torch.sigmoid_(io[..., 4:])", "\n", "return", "io", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "no", ")", ",", "p", "# view [1, 3, 13, 13, 85] as [1, 507, 85]", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.__init__": [[433, 450], ["nn.Module.__init__", "torch.Tensor", "len", "len", "models.JDELayer.anchor_vec.view", "models.JDELayer.create_grids"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.create_grids"], ["    ", "def", "__init__", "(", "self", ",", "anchors", ",", "nc", ",", "img_size", ",", "yolo_index", ",", "layers", ",", "stride", ")", ":", "\n", "        ", "super", "(", "JDELayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "anchors", "=", "torch", ".", "Tensor", "(", "anchors", ")", "\n", "self", ".", "index", "=", "yolo_index", "# index of this layer in layers", "\n", "self", ".", "layers", "=", "layers", "# model output layer indices", "\n", "self", ".", "stride", "=", "stride", "# layer stride", "\n", "self", ".", "nl", "=", "len", "(", "layers", ")", "# number of output layers (3)", "\n", "self", ".", "na", "=", "len", "(", "anchors", ")", "# number of anchors (3)", "\n", "self", ".", "nc", "=", "nc", "# number of classes (80)", "\n", "self", ".", "no", "=", "nc", "+", "5", "# number of outputs (85)", "\n", "self", ".", "nx", ",", "self", ".", "ny", ",", "self", ".", "ng", "=", "0", ",", "0", ",", "0", "# initialize number of x, y gridpoints", "\n", "self", ".", "anchor_vec", "=", "self", ".", "anchors", "/", "self", ".", "stride", "\n", "self", ".", "anchor_wh", "=", "self", ".", "anchor_vec", ".", "view", "(", "1", ",", "self", ".", "na", ",", "1", ",", "1", ",", "2", ")", "\n", "\n", "if", "ONNX_EXPORT", ":", "\n", "            ", "self", ".", "training", "=", "False", "\n", "self", ".", "create_grids", "(", "(", "img_size", "[", "1", "]", "//", "stride", ",", "img_size", "[", "0", "]", "//", "stride", ")", ")", "# number x, y grid points", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.create_grids": [[451, 463], ["torch.tensor", "torch.meshgrid", "torch.stack().view().float", "models.JDELayer.anchor_vec.to", "models.JDELayer.anchor_wh.to", "torch.arange", "torch.arange", "torch.stack().view", "torch.stack"], "methods", ["None"], ["", "", "def", "create_grids", "(", "self", ",", "ng", "=", "(", "13", ",", "13", ")", ",", "device", "=", "'cpu'", ")", ":", "\n", "        ", "self", ".", "nx", ",", "self", ".", "ny", "=", "ng", "# x and y grid size", "\n", "self", ".", "ng", "=", "torch", ".", "tensor", "(", "ng", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "# build xy offsets", "\n", "if", "not", "self", ".", "training", ":", "\n", "            ", "yv", ",", "xv", "=", "torch", ".", "meshgrid", "(", "[", "torch", ".", "arange", "(", "self", ".", "ny", ",", "device", "=", "device", ")", ",", "torch", ".", "arange", "(", "self", ".", "nx", ",", "device", "=", "device", ")", "]", ")", "\n", "self", ".", "grid", "=", "torch", ".", "stack", "(", "(", "xv", ",", "yv", ")", ",", "2", ")", ".", "view", "(", "(", "1", ",", "1", ",", "self", ".", "ny", ",", "self", ".", "nx", ",", "2", ")", ")", ".", "float", "(", ")", "\n", "\n", "", "if", "self", ".", "anchor_vec", ".", "device", "!=", "device", ":", "\n", "            ", "self", ".", "anchor_vec", "=", "self", ".", "anchor_vec", ".", "to", "(", "device", ")", "\n", "self", ".", "anchor_wh", "=", "self", ".", "anchor_wh", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.forward": [[464, 523], ["p.view.view.view().permute().contiguous", "range", "models.JDELayer.create_grids", "torch.sigmoid", "p.view.view.view().permute", "models.JDELayer.grid.repeat().view", "p.view.view.view", "p.view.view.clone", "F.softmax", "models.JDELayer.create_grids", "models.JDELayer.ng.repeat", "models.JDELayer.anchor_wh.repeat().view", "torch.sigmoid", "torch.exp", "torch.sigmoid", "p.view.clone.view", "F.interpolate", "p.view.view.view", "models.JDELayer.grid.repeat", "torch.sigmoid", "torch.sigmoid", "models.JDELayer.anchor_wh.repeat", "torch.sigmoid", "torch.sigmoid"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.create_grids", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.JDELayer.create_grids"], ["", "", "def", "forward", "(", "self", ",", "p", ",", "out", ")", ":", "\n", "        ", "ASFF", "=", "False", "# https://arxiv.org/abs/1911.09516", "\n", "if", "ASFF", ":", "\n", "            ", "i", ",", "n", "=", "self", ".", "index", ",", "self", ".", "nl", "# index in layers, number of layers", "\n", "p", "=", "out", "[", "self", ".", "layers", "[", "i", "]", "]", "\n", "bs", ",", "_", ",", "ny", ",", "nx", "=", "p", ".", "shape", "# bs, 255, 13, 13", "\n", "if", "(", "self", ".", "nx", ",", "self", ".", "ny", ")", "!=", "(", "nx", ",", "ny", ")", ":", "\n", "                ", "self", ".", "create_grids", "(", "(", "nx", ",", "ny", ")", ",", "p", ".", "device", ")", "\n", "\n", "# outputs and weights", "\n", "# w = F.softmax(p[:, -n:], 1)  # normalized weights", "\n", "", "w", "=", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "-", "n", ":", "]", ")", "*", "(", "2", "/", "n", ")", "# sigmoid weights (faster)", "\n", "# w = w / w.sum(1).unsqueeze(1)  # normalize across layer dimension", "\n", "\n", "# weighted ASFF sum", "\n", "p", "=", "out", "[", "self", ".", "layers", "[", "i", "]", "]", "[", ":", ",", ":", "-", "n", "]", "*", "w", "[", ":", ",", "i", ":", "i", "+", "1", "]", "\n", "for", "j", "in", "range", "(", "n", ")", ":", "\n", "                ", "if", "j", "!=", "i", ":", "\n", "                    ", "p", "+=", "w", "[", ":", ",", "j", ":", "j", "+", "1", "]", "*", "F", ".", "interpolate", "(", "out", "[", "self", ".", "layers", "[", "j", "]", "]", "[", ":", ",", ":", "-", "n", "]", ",", "size", "=", "[", "ny", ",", "nx", "]", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "False", ")", "\n", "\n", "", "", "", "elif", "ONNX_EXPORT", ":", "\n", "            ", "bs", "=", "1", "# batch size", "\n", "", "else", ":", "\n", "            ", "bs", ",", "_", ",", "ny", ",", "nx", "=", "p", ".", "shape", "# bs, 255, 13, 13", "\n", "if", "(", "self", ".", "nx", ",", "self", ".", "ny", ")", "!=", "(", "nx", ",", "ny", ")", ":", "\n", "                ", "self", ".", "create_grids", "(", "(", "nx", ",", "ny", ")", ",", "p", ".", "device", ")", "\n", "\n", "# p.view(bs, 255, 13, 13) -- > (bs, 3, 13, 13, 85)  # (bs, anchors, grid, grid, classes + xywh)", "\n", "", "", "p", "=", "p", ".", "view", "(", "bs", ",", "self", ".", "na", ",", "self", ".", "no", ",", "self", ".", "ny", ",", "self", ".", "nx", ")", ".", "permute", "(", "0", ",", "1", ",", "3", ",", "4", ",", "2", ")", ".", "contiguous", "(", ")", "# prediction", "\n", "\n", "if", "self", ".", "training", ":", "\n", "            ", "return", "p", "\n", "\n", "", "elif", "ONNX_EXPORT", ":", "\n", "# Avoid broadcasting for ANE operations", "\n", "            ", "m", "=", "self", ".", "na", "*", "self", ".", "nx", "*", "self", ".", "ny", "\n", "ng", "=", "1.", "/", "self", ".", "ng", ".", "repeat", "(", "m", ",", "1", ")", "\n", "grid", "=", "self", ".", "grid", ".", "repeat", "(", "1", ",", "self", ".", "na", ",", "1", ",", "1", ",", "1", ")", ".", "view", "(", "m", ",", "2", ")", "\n", "anchor_wh", "=", "self", ".", "anchor_wh", ".", "repeat", "(", "1", ",", "1", ",", "self", ".", "nx", ",", "self", ".", "ny", ",", "1", ")", ".", "view", "(", "m", ",", "2", ")", "*", "ng", "\n", "\n", "p", "=", "p", ".", "view", "(", "m", ",", "self", ".", "no", ")", "\n", "xy", "=", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "0", ":", "2", "]", ")", "+", "grid", "# x, y", "\n", "wh", "=", "torch", ".", "exp", "(", "p", "[", ":", ",", "2", ":", "4", "]", ")", "*", "anchor_wh", "# width, height", "\n", "p_cls", "=", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "4", ":", "5", "]", ")", "if", "self", ".", "nc", "==", "1", "else", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "5", ":", "self", ".", "no", "]", ")", "*", "torch", ".", "sigmoid", "(", "p", "[", ":", ",", "4", ":", "5", "]", ")", "# conf", "\n", "return", "p_cls", ",", "xy", "*", "ng", ",", "wh", "\n", "\n", "", "else", ":", "# inference", "\n", "#io = p.sigmoid()", "\n", "#io[..., :2] = (io[..., :2] * 2. - 0.5 + self.grid)", "\n", "#io[..., 2:4] = (io[..., 2:4] * 2) ** 2 * self.anchor_wh", "\n", "#io[..., :4] *= self.stride", "\n", "            ", "io", "=", "p", ".", "clone", "(", ")", "# inference output", "\n", "io", "[", "...", ",", ":", "2", "]", "=", "torch", ".", "sigmoid", "(", "io", "[", "...", ",", ":", "2", "]", ")", "*", "2.", "-", "0.5", "+", "self", ".", "grid", "# xy", "\n", "io", "[", "...", ",", "2", ":", "4", "]", "=", "(", "torch", ".", "sigmoid", "(", "io", "[", "...", ",", "2", ":", "4", "]", ")", "*", "2", ")", "**", "2", "*", "self", ".", "anchor_wh", "# wh yolo method", "\n", "io", "[", "...", ",", ":", "4", "]", "*=", "self", ".", "stride", "\n", "io", "[", "...", ",", "4", ":", "]", "=", "F", ".", "softmax", "(", "io", "[", "...", ",", "4", ":", "]", ")", "\n", "return", "io", ".", "view", "(", "bs", ",", "-", "1", ",", "self", ".", "no", ")", ",", "p", "# view [1, 3, 13, 13, 85] as [1, 507, 85]", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__": [[527, 539], ["nn.Module.__init__", "parse_model_cfg", "models.create_modules", "models.get_yolo_layers", "np.array", "np.array", "models.Darknet.info"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.__init__", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.parse_config.parse_model_cfg", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.create_modules", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.get_yolo_layers", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info"], ["    ", "def", "__init__", "(", "self", ",", "cfg", ",", "img_size", "=", "(", "416", ",", "416", ")", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "super", "(", "Darknet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "module_defs", "=", "parse_model_cfg", "(", "cfg", ")", "\n", "self", ".", "module_list", ",", "self", ".", "routs", "=", "create_modules", "(", "self", ".", "module_defs", ",", "img_size", ",", "cfg", ")", "\n", "self", ".", "yolo_layers", "=", "get_yolo_layers", "(", "self", ")", "\n", "# torch_utils.initialize_weights(self)", "\n", "\n", "# Darknet Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346", "\n", "self", ".", "version", "=", "np", ".", "array", "(", "[", "0", ",", "2", ",", "5", "]", ",", "dtype", "=", "np", ".", "int32", ")", "# (int32) version info: major, minor, revision", "\n", "self", ".", "seen", "=", "np", ".", "array", "(", "[", "0", "]", ",", "dtype", "=", "np", ".", "int64", ")", "# (int64) number of images seen during training", "\n", "self", ".", "info", "(", "verbose", ")", "if", "not", "ONNX_EXPORT", "else", "None", "# print model description", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.forward": [[540, 569], ["models.Darknet.forward_once", "enumerate", "torch.cat", "torch.cat.append", "utils.torch_utils.scale_img", "utils.torch_utils.scale_img", "x.flip", "models.Darknet.forward_once"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.forward_once", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.scale_img", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.scale_img", "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.forward_once"], ["", "def", "forward", "(", "self", ",", "x", ",", "augment", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "\n", "        ", "if", "not", "augment", ":", "\n", "            ", "return", "self", ".", "forward_once", "(", "x", ")", "\n", "", "else", ":", "# Augment images (inference and test only) https://github.com/ultralytics/yolov3/issues/931", "\n", "            ", "img_size", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "# height, width", "\n", "s", "=", "[", "0.83", ",", "0.67", "]", "# scales", "\n", "y", "=", "[", "]", "\n", "for", "i", ",", "xi", "in", "enumerate", "(", "(", "x", ",", "\n", "torch_utils", ".", "scale_img", "(", "x", ".", "flip", "(", "3", ")", ",", "s", "[", "0", "]", ",", "same_shape", "=", "False", ")", ",", "# flip-lr and scale", "\n", "torch_utils", ".", "scale_img", "(", "x", ",", "s", "[", "1", "]", ",", "same_shape", "=", "False", ")", ",", "# scale", "\n", ")", ")", ":", "\n", "# cv2.imwrite('img%g.jpg' % i, 255 * xi[0].numpy().transpose((1, 2, 0))[:, :, ::-1])", "\n", "                ", "y", ".", "append", "(", "self", ".", "forward_once", "(", "xi", ")", "[", "0", "]", ")", "\n", "\n", "", "y", "[", "1", "]", "[", "...", ",", ":", "4", "]", "/=", "s", "[", "0", "]", "# scale", "\n", "y", "[", "1", "]", "[", "...", ",", "0", "]", "=", "img_size", "[", "1", "]", "-", "y", "[", "1", "]", "[", "...", ",", "0", "]", "# flip lr", "\n", "y", "[", "2", "]", "[", "...", ",", ":", "4", "]", "/=", "s", "[", "1", "]", "# scale", "\n", "\n", "# for i, yi in enumerate(y):  # coco small, medium, large = < 32**2 < 96**2 <", "\n", "#     area = yi[..., 2:4].prod(2)[:, :, None]", "\n", "#     if i == 1:", "\n", "#         yi *= (area < 96. ** 2).float()", "\n", "#     elif i == 2:", "\n", "#         yi *= (area > 32. ** 2).float()", "\n", "#     y[i] = yi", "\n", "\n", "y", "=", "torch", ".", "cat", "(", "y", ",", "1", ")", "\n", "return", "y", ",", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.forward_once": [[570, 626], ["enumerate", "print", "torch.cat", "out.append", "module", "print", "zip", "torch.cat", "utils.torch_utils.scale_img", "utils.torch_utils.scale_img", "module", "list", "torch.cat", "torch.cat", "torch.split", "torch.cat", "module.flip", "yolo_out.append", "zip", "list", "list", "module", "yolo_out.append", "module", "len", "module", "zip"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.scale_img", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.scale_img"], ["", "", "def", "forward_once", "(", "self", ",", "x", ",", "augment", "=", "False", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "img_size", "=", "x", ".", "shape", "[", "-", "2", ":", "]", "# height, width", "\n", "yolo_out", ",", "out", "=", "[", "]", ",", "[", "]", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "'0'", ",", "x", ".", "shape", ")", "\n", "str", "=", "''", "\n", "\n", "# Augment images (inference and test only)", "\n", "", "if", "augment", ":", "# https://github.com/ultralytics/yolov3/issues/931", "\n", "            ", "nb", "=", "x", ".", "shape", "[", "0", "]", "# batch size", "\n", "s", "=", "[", "0.83", ",", "0.67", "]", "# scales", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "\n", "torch_utils", ".", "scale_img", "(", "x", ".", "flip", "(", "3", ")", ",", "s", "[", "0", "]", ")", ",", "# flip-lr and scale", "\n", "torch_utils", ".", "scale_img", "(", "x", ",", "s", "[", "1", "]", ")", ",", "# scale", "\n", ")", ",", "0", ")", "\n", "\n", "", "for", "i", ",", "module", "in", "enumerate", "(", "self", ".", "module_list", ")", ":", "\n", "            ", "name", "=", "module", ".", "__class__", ".", "__name__", "\n", "#print(name)", "\n", "if", "name", "in", "[", "'WeightedFeatureFusion'", ",", "'FeatureConcat'", ",", "'FeatureConcat2'", ",", "'FeatureConcat3'", ",", "'FeatureConcat_l'", ",", "'ScaleChannel'", ",", "'ShiftChannel'", ",", "'ShiftChannel2D'", ",", "'ControlChannel'", ",", "'ControlChannel2D'", ",", "'AlternateChannel'", ",", "'AlternateChannel2D'", ",", "'SelectChannel'", ",", "'SelectChannel2D'", ",", "'ScaleSpatial'", "]", ":", "# sum, concat", "\n", "                ", "if", "verbose", ":", "\n", "                    ", "l", "=", "[", "i", "-", "1", "]", "+", "module", ".", "layers", "# layers", "\n", "sh", "=", "[", "list", "(", "x", ".", "shape", ")", "]", "+", "[", "list", "(", "out", "[", "i", "]", ".", "shape", ")", "for", "i", "in", "module", ".", "layers", "]", "# shapes", "\n", "str", "=", "' >> '", "+", "' + '", ".", "join", "(", "[", "'layer %g %s'", "%", "x", "for", "x", "in", "zip", "(", "l", ",", "sh", ")", "]", ")", "\n", "", "x", "=", "module", "(", "x", ",", "out", ")", "# WeightedFeatureFusion(), FeatureConcat()", "\n", "", "elif", "name", "in", "[", "'ImplicitA'", ",", "'ImplicitM'", ",", "'ImplicitC'", ",", "'Implicit2DA'", ",", "'Implicit2DM'", ",", "'Implicit2DC'", "]", ":", "\n", "                ", "x", "=", "module", "(", ")", "\n", "", "elif", "name", "==", "'YOLOLayer'", ":", "\n", "                ", "yolo_out", ".", "append", "(", "module", "(", "x", ",", "out", ")", ")", "\n", "", "elif", "name", "==", "'JDELayer'", ":", "\n", "                ", "yolo_out", ".", "append", "(", "module", "(", "x", ",", "out", ")", ")", "\n", "", "else", ":", "# run module directly, i.e. mtype = 'convolutional', 'upsample', 'maxpool', 'batchnorm2d' etc.", "\n", "#print(module)", "\n", "#print(x.shape)", "\n", "                ", "x", "=", "module", "(", "x", ")", "\n", "\n", "", "out", ".", "append", "(", "x", "if", "self", ".", "routs", "[", "i", "]", "else", "[", "]", ")", "\n", "if", "verbose", ":", "\n", "                ", "print", "(", "'%g/%g %s -'", "%", "(", "i", ",", "len", "(", "self", ".", "module_list", ")", ",", "name", ")", ",", "list", "(", "x", ".", "shape", ")", ",", "str", ")", "\n", "str", "=", "''", "\n", "\n", "", "", "if", "self", ".", "training", ":", "# train", "\n", "            ", "return", "yolo_out", "\n", "", "elif", "ONNX_EXPORT", ":", "# export", "\n", "            ", "x", "=", "[", "torch", ".", "cat", "(", "x", ",", "0", ")", "for", "x", "in", "zip", "(", "*", "yolo_out", ")", "]", "\n", "return", "x", "[", "0", "]", ",", "torch", ".", "cat", "(", "x", "[", "1", ":", "3", "]", ",", "1", ")", "# scores, boxes: 3780x80, 3780x4", "\n", "", "else", ":", "# inference or test", "\n", "            ", "x", ",", "p", "=", "zip", "(", "*", "yolo_out", ")", "# inference output, training output", "\n", "x", "=", "torch", ".", "cat", "(", "x", ",", "1", ")", "# cat yolo outputs", "\n", "if", "augment", ":", "# de-augment results", "\n", "                ", "x", "=", "torch", ".", "split", "(", "x", ",", "nb", ",", "dim", "=", "0", ")", "\n", "x", "[", "1", "]", "[", "...", ",", ":", "4", "]", "/=", "s", "[", "0", "]", "# scale", "\n", "x", "[", "1", "]", "[", "...", ",", "0", "]", "=", "img_size", "[", "1", "]", "-", "x", "[", "1", "]", "[", "...", ",", "0", "]", "# flip lr", "\n", "x", "[", "2", "]", "[", "...", ",", ":", "4", "]", "/=", "s", "[", "1", "]", "# scale", "\n", "x", "=", "torch", ".", "cat", "(", "x", ",", "1", ")", "\n", "", "return", "x", ",", "p", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.fuse": [[627, 643], ["print", "nn.ModuleList", "list", "isinstance", "nn.ModuleList.append", "models.Darknet.info", "models.Darknet.children", "enumerate", "isinstance", "utils.torch_utils.fuse_conv_and_bn", "nn.Sequential", "list", "nn.Sequential.children"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info", "home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.fuse_conv_and_bn"], ["", "", "def", "fuse", "(", "self", ")", ":", "\n", "# Fuse Conv2d + BatchNorm2d layers throughout model", "\n", "        ", "print", "(", "'Fusing layers...'", ")", "\n", "fused_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "a", "in", "list", "(", "self", ".", "children", "(", ")", ")", "[", "0", "]", ":", "\n", "            ", "if", "isinstance", "(", "a", ",", "nn", ".", "Sequential", ")", ":", "\n", "                ", "for", "i", ",", "b", "in", "enumerate", "(", "a", ")", ":", "\n", "                    ", "if", "isinstance", "(", "b", ",", "nn", ".", "modules", ".", "batchnorm", ".", "BatchNorm2d", ")", ":", "\n", "# fuse this bn layer with the previous conv2d layer", "\n", "                        ", "conv", "=", "a", "[", "i", "-", "1", "]", "\n", "fused", "=", "torch_utils", ".", "fuse_conv_and_bn", "(", "conv", ",", "b", ")", "\n", "a", "=", "nn", ".", "Sequential", "(", "fused", ",", "*", "list", "(", "a", ".", "children", "(", ")", ")", "[", "i", "+", "1", ":", "]", ")", "\n", "break", "\n", "", "", "", "fused_list", ".", "append", "(", "a", ")", "\n", "", "self", ".", "module_list", "=", "fused_list", "\n", "self", ".", "info", "(", ")", "if", "not", "ONNX_EXPORT", "else", "None", "# yolov3-spp reduced from 225 to 152 layers", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.Darknet.info": [[644, 646], ["utils.torch_utils.model_info"], "methods", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.torch_utils.model_info"], ["", "def", "info", "(", "self", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "torch_utils", ".", "model_info", "(", "self", ",", "verbose", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.create_modules": [[9, 337], ["module_defs.pop", "nn.ModuleList", "enumerate", "isinstance", "nn.Sequential", "nn.ModuleList.append", "output_filters.append", "isinstance", "JDELayer.add_module", "JDELayer.add_module", "JDELayer.add_module", "routs.append", "JDELayer.add_module", "isinstance", "nn.Conv2d", "MixConv2d", "nn.BatchNorm2d", "nn.LeakyReLU", "JDELayer.add_module", "JDELayer.add_module", "JDELayer.add_module", "JDELayer.add_module", "routs.append", "JDELayer.add_module", "nn.Dropout", "Swish", "JDELayer.add_module", "DeformConv2d", "MixConv2d", "nn.BatchNorm2d", "nn.LeakyReLU", "JDELayer.add_module", "GAP", "Mish", "JDELayer.add_module", "Swish", "JDELayer.add_module", "Silence", "F.normalize", "JDELayer.add_module", "Mish", "JDELayer.add_module", "routs.extend", "ScaleChannel", "nn.Sigmoid", "JDELayer.add_module", "nn.SiLU", "routs.extend", "ShiftChannel", "nn.SiLU", "routs.extend", "ShiftChannel2D", "routs.extend", "ControlChannel", "routs.extend", "ControlChannel2D", "routs.extend", "AlternateChannel", "routs.extend", "AlternateChannel2D", "routs.extend", "SelectChannel", "routs.extend", "SelectChannel2D", "routs.extend", "ScaleSpatial", "nn.BatchNorm2d", "torch.tensor", "torch.tensor", "nn.MaxPool2d", "JDELayer.add_module", "JDELayer.add_module", "nn.AvgPool2d", "nn.ZeroPad2d", "JDELayer.add_module", "JDELayer.add_module", "nn.ZeroPad2d", "nn.Upsample", "nn.Upsample", "sum", "routs.extend", "FeatureConcat", "sum", "routs.extend", "FeatureConcat2", "tuple", "sum", "routs.extend", "FeatureConcat3", "routs.extend", "FeatureConcat_l", "int", "sum", "routs.extend", "WeightedFeatureFusion", "JDELayer.add_module", "Reorg", "JDELayer.add_module", "DWT", "ImplicitA", "ImplicitM", "ImplicitC", "Implicit2DA", "Implicit2DM", "Implicit2DC", "any", "models.YOLOLayer", "bias_[].view", "math.log", "math.log", "torch.nn.Parameter", "any", "models.JDELayer", "print", "print", "bias_[].view", "math.log", "math.log", "torch.nn.Parameter", "print"], "function", ["None"], ["def", "create_modules", "(", "module_defs", ",", "img_size", ",", "cfg", ")", ":", "\n", "# Constructs module list of layer blocks from module configuration in module_defs", "\n", "\n", "    ", "img_size", "=", "[", "img_size", "]", "*", "2", "if", "isinstance", "(", "img_size", ",", "int", ")", "else", "img_size", "# expand if necessary", "\n", "_", "=", "module_defs", ".", "pop", "(", "0", ")", "# cfg training hyperparams (unused)", "\n", "output_filters", "=", "[", "3", "]", "# input channels", "\n", "module_list", "=", "nn", ".", "ModuleList", "(", ")", "\n", "routs", "=", "[", "]", "# list of layers which rout to deeper layers", "\n", "yolo_index", "=", "-", "1", "\n", "\n", "for", "i", ",", "mdef", "in", "enumerate", "(", "module_defs", ")", ":", "\n", "        ", "modules", "=", "nn", ".", "Sequential", "(", ")", "\n", "\n", "if", "mdef", "[", "'type'", "]", "==", "'convolutional'", ":", "\n", "            ", "bn", "=", "mdef", "[", "'batch_normalize'", "]", "\n", "filters", "=", "mdef", "[", "'filters'", "]", "\n", "k", "=", "mdef", "[", "'size'", "]", "# kernel size", "\n", "stride", "=", "mdef", "[", "'stride'", "]", "if", "'stride'", "in", "mdef", "else", "(", "mdef", "[", "'stride_y'", "]", ",", "mdef", "[", "'stride_x'", "]", ")", "\n", "if", "isinstance", "(", "k", ",", "int", ")", ":", "# single-size conv", "\n", "                ", "modules", ".", "add_module", "(", "'Conv2d'", ",", "nn", ".", "Conv2d", "(", "in_channels", "=", "output_filters", "[", "-", "1", "]", ",", "\n", "out_channels", "=", "filters", ",", "\n", "kernel_size", "=", "k", ",", "\n", "stride", "=", "stride", ",", "\n", "padding", "=", "k", "//", "2", "if", "mdef", "[", "'pad'", "]", "else", "0", ",", "\n", "groups", "=", "mdef", "[", "'groups'", "]", "if", "'groups'", "in", "mdef", "else", "1", ",", "\n", "bias", "=", "not", "bn", ")", ")", "\n", "", "else", ":", "# multiple-size conv", "\n", "                ", "modules", ".", "add_module", "(", "'MixConv2d'", ",", "MixConv2d", "(", "in_ch", "=", "output_filters", "[", "-", "1", "]", ",", "\n", "out_ch", "=", "filters", ",", "\n", "k", "=", "k", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "not", "bn", ")", ")", "\n", "\n", "", "if", "bn", ":", "\n", "                ", "modules", ".", "add_module", "(", "'BatchNorm2d'", ",", "nn", ".", "BatchNorm2d", "(", "filters", ",", "momentum", "=", "0.03", ",", "eps", "=", "1E-4", ")", ")", "\n", "", "else", ":", "\n", "                ", "routs", ".", "append", "(", "i", ")", "# detection output (goes into yolo layer)", "\n", "\n", "", "if", "mdef", "[", "'activation'", "]", "==", "'leaky'", ":", "# activation study https://github.com/ultralytics/yolov3/issues/441", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "nn", ".", "LeakyReLU", "(", "0.1", ",", "inplace", "=", "True", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'swish'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "Swish", "(", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'mish'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "Mish", "(", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'emb'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "F", ".", "normalize", "(", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'logistic'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'silu'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "nn", ".", "SiLU", "(", ")", ")", "\n", "\n", "", "", "elif", "mdef", "[", "'type'", "]", "==", "'deformableconvolutional'", ":", "\n", "            ", "bn", "=", "mdef", "[", "'batch_normalize'", "]", "\n", "filters", "=", "mdef", "[", "'filters'", "]", "\n", "k", "=", "mdef", "[", "'size'", "]", "# kernel size", "\n", "stride", "=", "mdef", "[", "'stride'", "]", "if", "'stride'", "in", "mdef", "else", "(", "mdef", "[", "'stride_y'", "]", ",", "mdef", "[", "'stride_x'", "]", ")", "\n", "if", "isinstance", "(", "k", ",", "int", ")", ":", "# single-size conv", "\n", "                ", "modules", ".", "add_module", "(", "'DeformConv2d'", ",", "DeformConv2d", "(", "output_filters", "[", "-", "1", "]", ",", "\n", "filters", ",", "\n", "kernel_size", "=", "k", ",", "\n", "padding", "=", "k", "//", "2", "if", "mdef", "[", "'pad'", "]", "else", "0", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "not", "bn", ",", "\n", "modulation", "=", "True", ")", ")", "\n", "", "else", ":", "# multiple-size conv", "\n", "                ", "modules", ".", "add_module", "(", "'MixConv2d'", ",", "MixConv2d", "(", "in_ch", "=", "output_filters", "[", "-", "1", "]", ",", "\n", "out_ch", "=", "filters", ",", "\n", "k", "=", "k", ",", "\n", "stride", "=", "stride", ",", "\n", "bias", "=", "not", "bn", ")", ")", "\n", "\n", "", "if", "bn", ":", "\n", "                ", "modules", ".", "add_module", "(", "'BatchNorm2d'", ",", "nn", ".", "BatchNorm2d", "(", "filters", ",", "momentum", "=", "0.03", ",", "eps", "=", "1E-4", ")", ")", "\n", "", "else", ":", "\n", "                ", "routs", ".", "append", "(", "i", ")", "# detection output (goes into yolo layer)", "\n", "\n", "", "if", "mdef", "[", "'activation'", "]", "==", "'leaky'", ":", "# activation study https://github.com/ultralytics/yolov3/issues/441", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "nn", ".", "LeakyReLU", "(", "0.1", ",", "inplace", "=", "True", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'swish'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "Swish", "(", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'mish'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "Mish", "(", ")", ")", "\n", "", "elif", "mdef", "[", "'activation'", "]", "==", "'silu'", ":", "\n", "                ", "modules", ".", "add_module", "(", "'activation'", ",", "nn", ".", "SiLU", "(", ")", ")", "\n", "\n", "", "", "elif", "mdef", "[", "'type'", "]", "==", "'dropout'", ":", "\n", "            ", "p", "=", "mdef", "[", "'probability'", "]", "\n", "modules", "=", "nn", ".", "Dropout", "(", "p", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'avgpool'", ":", "\n", "            ", "modules", "=", "GAP", "(", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'silence'", ":", "\n", "            ", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "modules", "=", "Silence", "(", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'scale_channels'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "ScaleChannel", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'shift_channels'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "ShiftChannel", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'shift_channels_2d'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "ShiftChannel2D", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'control_channels'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "ControlChannel", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'control_channels_2d'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "ControlChannel2D", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'alternate_channels'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "*", "2", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "AlternateChannel", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'alternate_channels_2d'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "*", "2", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "AlternateChannel2D", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'select_channels'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "SelectChannel", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'select_channels_2d'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "SelectChannel2D", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'sam'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "ScaleSpatial", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'BatchNorm2d'", ":", "\n", "            ", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "modules", "=", "nn", ".", "BatchNorm2d", "(", "filters", ",", "momentum", "=", "0.03", ",", "eps", "=", "1E-4", ")", "\n", "if", "i", "==", "0", "and", "filters", "==", "3", ":", "# normalize RGB image", "\n", "# imagenet mean and var https://pytorch.org/docs/stable/torchvision/models.html#classification", "\n", "                ", "modules", ".", "running_mean", "=", "torch", ".", "tensor", "(", "[", "0.485", ",", "0.456", ",", "0.406", "]", ")", "\n", "modules", ".", "running_var", "=", "torch", ".", "tensor", "(", "[", "0.0524", ",", "0.0502", ",", "0.0506", "]", ")", "\n", "\n", "", "", "elif", "mdef", "[", "'type'", "]", "==", "'maxpool'", ":", "\n", "            ", "k", "=", "mdef", "[", "'size'", "]", "# kernel size", "\n", "stride", "=", "mdef", "[", "'stride'", "]", "\n", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "k", ",", "stride", "=", "stride", ",", "padding", "=", "(", "k", "-", "1", ")", "//", "2", ")", "\n", "if", "k", "==", "2", "and", "stride", "==", "1", ":", "# yolov3-tiny", "\n", "                ", "modules", ".", "add_module", "(", "'ZeroPad2d'", ",", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "1", ",", "0", ",", "1", ")", ")", ")", "\n", "modules", ".", "add_module", "(", "'MaxPool2d'", ",", "maxpool", ")", "\n", "", "else", ":", "\n", "                ", "modules", "=", "maxpool", "\n", "\n", "", "", "elif", "mdef", "[", "'type'", "]", "==", "'local_avgpool'", ":", "\n", "            ", "k", "=", "mdef", "[", "'size'", "]", "# kernel size", "\n", "stride", "=", "mdef", "[", "'stride'", "]", "\n", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "kernel_size", "=", "k", ",", "stride", "=", "stride", ",", "padding", "=", "(", "k", "-", "1", ")", "//", "2", ")", "\n", "if", "k", "==", "2", "and", "stride", "==", "1", ":", "# yolov3-tiny", "\n", "                ", "modules", ".", "add_module", "(", "'ZeroPad2d'", ",", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "1", ",", "0", ",", "1", ")", ")", ")", "\n", "modules", ".", "add_module", "(", "'AvgPool2d'", ",", "avgpool", ")", "\n", "", "else", ":", "\n", "                ", "modules", "=", "avgpool", "\n", "\n", "", "", "elif", "mdef", "[", "'type'", "]", "==", "'upsample'", ":", "\n", "            ", "if", "ONNX_EXPORT", ":", "# explicitly state size, avoid scale_factor", "\n", "                ", "g", "=", "(", "yolo_index", "+", "1", ")", "*", "2", "/", "32", "# gain", "\n", "modules", "=", "nn", ".", "Upsample", "(", "size", "=", "tuple", "(", "int", "(", "x", "*", "g", ")", "for", "x", "in", "img_size", ")", ")", "# img_size = (320, 192)", "\n", "", "else", ":", "\n", "                ", "modules", "=", "nn", ".", "Upsample", "(", "scale_factor", "=", "mdef", "[", "'stride'", "]", ")", "\n", "\n", "", "", "elif", "mdef", "[", "'type'", "]", "==", "'route'", ":", "# nn.Sequential() placeholder for 'route' layer", "\n", "            ", "layers", "=", "mdef", "[", "'layers'", "]", "\n", "filters", "=", "sum", "(", "[", "output_filters", "[", "l", "+", "1", "if", "l", ">", "0", "else", "l", "]", "for", "l", "in", "layers", "]", ")", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "FeatureConcat", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'route2'", ":", "# nn.Sequential() placeholder for 'route' layer", "\n", "            ", "layers", "=", "mdef", "[", "'layers'", "]", "\n", "filters", "=", "sum", "(", "[", "output_filters", "[", "l", "+", "1", "if", "l", ">", "0", "else", "l", "]", "for", "l", "in", "layers", "]", ")", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "FeatureConcat2", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'route3'", ":", "# nn.Sequential() placeholder for 'route' layer", "\n", "            ", "layers", "=", "mdef", "[", "'layers'", "]", "\n", "filters", "=", "sum", "(", "[", "output_filters", "[", "l", "+", "1", "if", "l", ">", "0", "else", "l", "]", "for", "l", "in", "layers", "]", ")", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "FeatureConcat3", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'route_lhalf'", ":", "# nn.Sequential() placeholder for 'route' layer", "\n", "            ", "layers", "=", "mdef", "[", "'layers'", "]", "\n", "filters", "=", "sum", "(", "[", "output_filters", "[", "l", "+", "1", "if", "l", ">", "0", "else", "l", "]", "for", "l", "in", "layers", "]", ")", "//", "2", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "FeatureConcat_l", "(", "layers", "=", "layers", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'shortcut'", ":", "# nn.Sequential() placeholder for 'shortcut' layer", "\n", "            ", "layers", "=", "mdef", "[", "'from'", "]", "\n", "filters", "=", "output_filters", "[", "-", "1", "]", "\n", "routs", ".", "extend", "(", "[", "i", "+", "l", "if", "l", "<", "0", "else", "l", "for", "l", "in", "layers", "]", ")", "\n", "modules", "=", "WeightedFeatureFusion", "(", "layers", "=", "layers", ",", "weight", "=", "'weights_type'", "in", "mdef", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'reorg3d'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "pass", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'reorg'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "filters", "=", "4", "*", "output_filters", "[", "-", "1", "]", "\n", "modules", ".", "add_module", "(", "'Reorg'", ",", "Reorg", "(", ")", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'dwt'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "filters", "=", "4", "*", "output_filters", "[", "-", "1", "]", "\n", "modules", ".", "add_module", "(", "'DWT'", ",", "DWT", "(", ")", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'implicit_add'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "filters", "=", "mdef", "[", "'filters'", "]", "\n", "modules", "=", "ImplicitA", "(", "channel", "=", "filters", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'implicit_mul'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "filters", "=", "mdef", "[", "'filters'", "]", "\n", "modules", "=", "ImplicitM", "(", "channel", "=", "filters", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'implicit_cat'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "filters", "=", "mdef", "[", "'filters'", "]", "\n", "modules", "=", "ImplicitC", "(", "channel", "=", "filters", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'implicit_add_2d'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "channels", "=", "mdef", "[", "'filters'", "]", "\n", "filters", "=", "mdef", "[", "'atoms'", "]", "\n", "modules", "=", "Implicit2DA", "(", "atom", "=", "filters", ",", "channel", "=", "channels", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'implicit_mul_2d'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "channels", "=", "mdef", "[", "'filters'", "]", "\n", "filters", "=", "mdef", "[", "'atoms'", "]", "\n", "modules", "=", "Implicit2DM", "(", "atom", "=", "filters", ",", "channel", "=", "channels", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'implicit_cat_2d'", ":", "# yolov3-spp-pan-scale", "\n", "            ", "channels", "=", "mdef", "[", "'filters'", "]", "\n", "filters", "=", "mdef", "[", "'atoms'", "]", "\n", "modules", "=", "Implicit2DC", "(", "atom", "=", "filters", ",", "channel", "=", "channels", ")", "\n", "\n", "", "elif", "mdef", "[", "'type'", "]", "==", "'yolo'", ":", "\n", "            ", "yolo_index", "+=", "1", "\n", "stride", "=", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", "# P3, P4, P5, P6, P7 strides", "\n", "if", "any", "(", "x", "in", "cfg", "for", "x", "in", "[", "'yolov4-tiny'", ",", "'fpn'", ",", "'yolov3'", "]", ")", ":", "# P5, P4, P3 strides", "\n", "                ", "stride", "=", "[", "32", ",", "16", ",", "8", "]", "\n", "", "layers", "=", "mdef", "[", "'from'", "]", "if", "'from'", "in", "mdef", "else", "[", "]", "\n", "modules", "=", "YOLOLayer", "(", "anchors", "=", "mdef", "[", "'anchors'", "]", "[", "mdef", "[", "'mask'", "]", "]", ",", "# anchor list", "\n", "nc", "=", "mdef", "[", "'classes'", "]", ",", "# number of classes", "\n", "img_size", "=", "img_size", ",", "# (416, 416)", "\n", "yolo_index", "=", "yolo_index", ",", "# 0, 1, 2...", "\n", "layers", "=", "layers", ",", "# output layers", "\n", "stride", "=", "stride", "[", "yolo_index", "]", ")", "\n", "\n", "# Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)", "\n", "try", ":", "\n", "                ", "j", "=", "layers", "[", "yolo_index", "]", "if", "'from'", "in", "mdef", "else", "-", "2", "\n", "bias_", "=", "module_list", "[", "j", "]", "[", "0", "]", ".", "bias", "# shape(255,)", "\n", "bias", "=", "bias_", "[", ":", "modules", ".", "no", "*", "modules", ".", "na", "]", ".", "view", "(", "modules", ".", "na", ",", "-", "1", ")", "# shape(3,85)", "\n", "#bias[:, 4] += -4.5  # obj", "\n", "bias", ".", "data", "[", ":", ",", "4", "]", "+=", "math", ".", "log", "(", "8", "/", "(", "640", "/", "stride", "[", "yolo_index", "]", ")", "**", "2", ")", "# obj (8 objects per 640 image)", "\n", "bias", ".", "data", "[", ":", ",", "5", ":", "]", "+=", "math", ".", "log", "(", "0.6", "/", "(", "modules", ".", "nc", "-", "0.99", ")", ")", "# cls (sigmoid(p) = 1/nc)", "\n", "module_list", "[", "j", "]", "[", "0", "]", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "bias_", ",", "requires_grad", "=", "bias_", ".", "requires_grad", ")", "\n", "\n", "#j = [-2, -5, -8]", "\n", "#for sj in j:", "\n", "#    bias_ = module_list[sj][0].bias", "\n", "#    bias = bias_[:modules.no * 1].view(1, -1)", "\n", "#    bias.data[:, 4] += math.log(8 / (640 / stride[yolo_index]) ** 2)", "\n", "#    bias.data[:, 5:] += math.log(0.6 / (modules.nc - 0.99))", "\n", "#    module_list[sj][0].bias = torch.nn.Parameter(bias_, requires_grad=bias_.requires_grad)", "\n", "", "except", ":", "\n", "                ", "print", "(", "'WARNING: smart bias initialization failure.'", ")", "\n", "\n", "", "", "elif", "mdef", "[", "'type'", "]", "==", "'jde'", ":", "\n", "            ", "yolo_index", "+=", "1", "\n", "stride", "=", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", "# P3, P4, P5, P6, P7 strides", "\n", "if", "any", "(", "x", "in", "cfg", "for", "x", "in", "[", "'yolov4-tiny'", ",", "'fpn'", ",", "'yolov3'", "]", ")", ":", "# P5, P4, P3 strides", "\n", "                ", "stride", "=", "[", "32", ",", "16", ",", "8", "]", "\n", "", "layers", "=", "mdef", "[", "'from'", "]", "if", "'from'", "in", "mdef", "else", "[", "]", "\n", "modules", "=", "JDELayer", "(", "anchors", "=", "mdef", "[", "'anchors'", "]", "[", "mdef", "[", "'mask'", "]", "]", ",", "# anchor list", "\n", "nc", "=", "mdef", "[", "'classes'", "]", ",", "# number of classes", "\n", "img_size", "=", "img_size", ",", "# (416, 416)", "\n", "yolo_index", "=", "yolo_index", ",", "# 0, 1, 2...", "\n", "layers", "=", "layers", ",", "# output layers", "\n", "stride", "=", "stride", "[", "yolo_index", "]", ")", "\n", "\n", "# Initialize preceding Conv2d() bias (https://arxiv.org/pdf/1708.02002.pdf section 3.3)", "\n", "try", ":", "\n", "                ", "j", "=", "layers", "[", "yolo_index", "]", "if", "'from'", "in", "mdef", "else", "-", "1", "\n", "bias_", "=", "module_list", "[", "j", "]", "[", "0", "]", ".", "bias", "# shape(255,)", "\n", "bias", "=", "bias_", "[", ":", "modules", ".", "no", "*", "modules", ".", "na", "]", ".", "view", "(", "modules", ".", "na", ",", "-", "1", ")", "# shape(3,85)", "\n", "#bias[:, 4] += -4.5  # obj", "\n", "bias", ".", "data", "[", ":", ",", "4", "]", "+=", "math", ".", "log", "(", "8", "/", "(", "640", "/", "stride", "[", "yolo_index", "]", ")", "**", "2", ")", "# obj (8 objects per 640 image)", "\n", "bias", ".", "data", "[", ":", ",", "5", ":", "]", "+=", "math", ".", "log", "(", "0.6", "/", "(", "modules", ".", "nc", "-", "0.99", ")", ")", "# cls (sigmoid(p) = 1/nc)", "\n", "module_list", "[", "j", "]", "[", "0", "]", ".", "bias", "=", "torch", ".", "nn", ".", "Parameter", "(", "bias_", ",", "requires_grad", "=", "bias_", ".", "requires_grad", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", "'WARNING: smart bias initialization failure.'", ")", "\n", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "'Warning: Unrecognized Layer Type: '", "+", "mdef", "[", "'type'", "]", ")", "\n", "\n", "# Register module list and number of output filters", "\n", "", "module_list", ".", "append", "(", "modules", ")", "\n", "output_filters", ".", "append", "(", "filters", ")", "\n", "\n", "", "routs_binary", "=", "[", "False", "]", "*", "(", "i", "+", "1", ")", "\n", "for", "i", "in", "routs", ":", "\n", "        ", "routs_binary", "[", "i", "]", "=", "True", "\n", "", "return", "module_list", ",", "routs_binary", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.get_yolo_layers": [[648, 650], ["enumerate"], "function", ["None"], ["", "", "def", "get_yolo_layers", "(", "model", ")", ":", "\n", "    ", "return", "[", "i", "for", "i", ",", "m", "in", "enumerate", "(", "model", ".", "module_list", ")", "if", "m", ".", "__class__", ".", "__name__", "in", "[", "'YOLOLayer'", ",", "'JDELayer'", "]", "]", "# [89, 101, 113]", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.load_darknet_weights": [[652, 700], ["enumerate", "Path", "open", "np.fromfile", "np.fromfile", "np.fromfile", "zip", "conv.weight.numel", "conv.weight.data.copy_", "bn.bias.numel", "bn.bias.data.copy_", "bn.weight.data.copy_", "bn.running_mean.data.copy_", "bn.running_var.data.copy_", "conv.bias.numel", "torch.from_numpy().view_as", "conv.bias.data.copy_", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy().view_as", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "function", ["None"], ["", "def", "load_darknet_weights", "(", "self", ",", "weights", ",", "cutoff", "=", "-", "1", ")", ":", "\n", "# Parses and loads the weights stored in 'weights'", "\n", "\n", "# Establish cutoffs (load layers between 0 and cutoff. if cutoff = -1 all are loaded)", "\n", "    ", "file", "=", "Path", "(", "weights", ")", ".", "name", "\n", "if", "file", "==", "'darknet53.conv.74'", ":", "\n", "        ", "cutoff", "=", "75", "\n", "", "elif", "file", "==", "'yolov3-tiny.conv.15'", ":", "\n", "        ", "cutoff", "=", "15", "\n", "\n", "# Read weights file", "\n", "", "with", "open", "(", "weights", ",", "'rb'", ")", "as", "f", ":", "\n", "# Read Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346", "\n", "        ", "self", ".", "version", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "int32", ",", "count", "=", "3", ")", "# (int32) version info: major, minor, revision", "\n", "self", ".", "seen", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "int64", ",", "count", "=", "1", ")", "# (int64) number of images seen during training", "\n", "\n", "weights", "=", "np", ".", "fromfile", "(", "f", ",", "dtype", "=", "np", ".", "float32", ")", "# the rest are weights", "\n", "\n", "", "ptr", "=", "0", "\n", "for", "i", ",", "(", "mdef", ",", "module", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "module_defs", "[", ":", "cutoff", "]", ",", "self", ".", "module_list", "[", ":", "cutoff", "]", ")", ")", ":", "\n", "        ", "if", "mdef", "[", "'type'", "]", "==", "'convolutional'", ":", "\n", "            ", "conv", "=", "module", "[", "0", "]", "\n", "if", "mdef", "[", "'batch_normalize'", "]", ":", "\n", "# Load BN bias, weights, running mean and running variance", "\n", "                ", "bn", "=", "module", "[", "1", "]", "\n", "nb", "=", "bn", ".", "bias", ".", "numel", "(", ")", "# number of biases", "\n", "# Bias", "\n", "bn", ".", "bias", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "weights", "[", "ptr", ":", "ptr", "+", "nb", "]", ")", ".", "view_as", "(", "bn", ".", "bias", ")", ")", "\n", "ptr", "+=", "nb", "\n", "# Weight", "\n", "bn", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "weights", "[", "ptr", ":", "ptr", "+", "nb", "]", ")", ".", "view_as", "(", "bn", ".", "weight", ")", ")", "\n", "ptr", "+=", "nb", "\n", "# Running Mean", "\n", "bn", ".", "running_mean", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "weights", "[", "ptr", ":", "ptr", "+", "nb", "]", ")", ".", "view_as", "(", "bn", ".", "running_mean", ")", ")", "\n", "ptr", "+=", "nb", "\n", "# Running Var", "\n", "bn", ".", "running_var", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "weights", "[", "ptr", ":", "ptr", "+", "nb", "]", ")", ".", "view_as", "(", "bn", ".", "running_var", ")", ")", "\n", "ptr", "+=", "nb", "\n", "", "else", ":", "\n", "# Load conv. bias", "\n", "                ", "nb", "=", "conv", ".", "bias", ".", "numel", "(", ")", "\n", "conv_b", "=", "torch", ".", "from_numpy", "(", "weights", "[", "ptr", ":", "ptr", "+", "nb", "]", ")", ".", "view_as", "(", "conv", ".", "bias", ")", "\n", "conv", ".", "bias", ".", "data", ".", "copy_", "(", "conv_b", ")", "\n", "ptr", "+=", "nb", "\n", "# Load conv. weights", "\n", "", "nw", "=", "conv", ".", "weight", ".", "numel", "(", ")", "# number of weights", "\n", "conv", ".", "weight", ".", "data", ".", "copy_", "(", "torch", ".", "from_numpy", "(", "weights", "[", "ptr", ":", "ptr", "+", "nw", "]", ")", ".", "view_as", "(", "conv", ".", "weight", ")", ")", "\n", "ptr", "+=", "nw", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.save_weights": [[702, 726], ["open", "models..version.tofile", "models..seen.tofile", "enumerate", "zip", "conv_layer.weight.data.cpu().numpy().tofile", "bn_layer.bias.data.cpu().numpy().tofile", "bn_layer.weight.data.cpu().numpy().tofile", "bn_layer.running_mean.data.cpu().numpy().tofile", "bn_layer.running_var.data.cpu().numpy().tofile", "conv_layer.bias.data.cpu().numpy().tofile", "conv_layer.weight.data.cpu().numpy", "bn_layer.bias.data.cpu().numpy", "bn_layer.weight.data.cpu().numpy", "bn_layer.running_mean.data.cpu().numpy", "bn_layer.running_var.data.cpu().numpy", "conv_layer.bias.data.cpu().numpy", "conv_layer.weight.data.cpu", "bn_layer.bias.data.cpu", "bn_layer.weight.data.cpu", "bn_layer.running_mean.data.cpu", "bn_layer.running_var.data.cpu", "conv_layer.bias.data.cpu"], "function", ["None"], ["", "", "", "def", "save_weights", "(", "self", ",", "path", "=", "'model.weights'", ",", "cutoff", "=", "-", "1", ")", ":", "\n", "# Converts a PyTorch model to Darket format (*.pt to *.weights)", "\n", "# Note: Does not work if model.fuse() is applied", "\n", "    ", "with", "open", "(", "path", ",", "'wb'", ")", "as", "f", ":", "\n", "# Write Header https://github.com/AlexeyAB/darknet/issues/2914#issuecomment-496675346", "\n", "        ", "self", ".", "version", ".", "tofile", "(", "f", ")", "# (int32) version info: major, minor, revision", "\n", "self", ".", "seen", ".", "tofile", "(", "f", ")", "# (int64) number of images seen during training", "\n", "\n", "# Iterate through layers", "\n", "for", "i", ",", "(", "mdef", ",", "module", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "module_defs", "[", ":", "cutoff", "]", ",", "self", ".", "module_list", "[", ":", "cutoff", "]", ")", ")", ":", "\n", "            ", "if", "mdef", "[", "'type'", "]", "==", "'convolutional'", ":", "\n", "                ", "conv_layer", "=", "module", "[", "0", "]", "\n", "# If batch norm, load bn first", "\n", "if", "mdef", "[", "'batch_normalize'", "]", ":", "\n", "                    ", "bn_layer", "=", "module", "[", "1", "]", "\n", "bn_layer", ".", "bias", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tofile", "(", "f", ")", "\n", "bn_layer", ".", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tofile", "(", "f", ")", "\n", "bn_layer", ".", "running_mean", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tofile", "(", "f", ")", "\n", "bn_layer", ".", "running_var", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tofile", "(", "f", ")", "\n", "# Load conv bias", "\n", "", "else", ":", "\n", "                    ", "conv_layer", ".", "bias", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tofile", "(", "f", ")", "\n", "# Load conv weights", "\n", "", "conv_layer", ".", "weight", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tofile", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.convert": [[728, 741], ["models.Darknet", "torch.load", "Darknet.load_state_dict", "models.save_weights", "print", "ckpt[].items", "[].numel", "v.numel", "Darknet.state_dict"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.save_weights"], ["", "", "", "", "def", "convert", "(", "cfg", "=", "'cfg/yolov3-spp.cfg'", ",", "weights", "=", "'weights/yolov3-spp.weights'", ",", "saveto", "=", "'converted.weights'", ")", ":", "\n", "# Converts between PyTorch and Darknet format per extension (i.e. *.weights convert to *.pt and vice versa)", "\n", "# from models import *; convert('cfg/yolov3-spp.cfg', 'weights/yolov3-spp.weights')", "\n", "\n", "# Initialize model", "\n", "    ", "model", "=", "Darknet", "(", "cfg", ")", "\n", "ckpt", "=", "torch", ".", "load", "(", "weights", ")", "# load checkpoint", "\n", "try", ":", "\n", "        ", "ckpt", "[", "'model'", "]", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "ckpt", "[", "'model'", "]", ".", "items", "(", ")", "if", "model", ".", "state_dict", "(", ")", "[", "k", "]", ".", "numel", "(", ")", "==", "v", ".", "numel", "(", ")", "}", "\n", "model", ".", "load_state_dict", "(", "ckpt", "[", "'model'", "]", ",", "strict", "=", "False", ")", "\n", "save_weights", "(", "model", ",", "path", "=", "saveto", ",", "cutoff", "=", "-", "1", ")", "\n", "", "except", "KeyError", "as", "e", ":", "\n", "        ", "print", "(", "e", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.WongKinYiu_yolor.models.models.attempt_download": [[742, 762], ["weights.strip.strip", "len", "os.path.isfile", "Path", "gdrive_download", "print", "os.system", "os.system", "Exception", "os.path.exists", "os.path.getsize"], "function", ["home.repos.pwc.inspect_result.WongKinYiu_yolor.utils.google_utils.gdrive_download"], ["", "", "def", "attempt_download", "(", "weights", ")", ":", "\n", "# Attempt to download pretrained weights if not found locally", "\n", "    ", "weights", "=", "weights", ".", "strip", "(", ")", "\n", "msg", "=", "weights", "+", "' missing, try downloading from https://drive.google.com/open?id=1LezFG5g3BCW6iYaV89B2i64cqEUZD7e0'", "\n", "\n", "if", "len", "(", "weights", ")", ">", "0", "and", "not", "os", ".", "path", ".", "isfile", "(", "weights", ")", ":", "\n", "        ", "d", "=", "{", "''", "}", "\n", "\n", "file", "=", "Path", "(", "weights", ")", ".", "name", "\n", "if", "file", "in", "d", ":", "\n", "            ", "r", "=", "gdrive_download", "(", "id", "=", "d", "[", "file", "]", ",", "name", "=", "weights", ")", "\n", "", "else", ":", "# download from pjreddie.com", "\n", "            ", "url", "=", "'https://pjreddie.com/media/files/'", "+", "file", "\n", "print", "(", "'Downloading '", "+", "url", ")", "\n", "r", "=", "os", ".", "system", "(", "'curl -f '", "+", "url", "+", "' -o '", "+", "weights", ")", "\n", "\n", "# Error check", "\n", "", "if", "not", "(", "r", "==", "0", "and", "os", ".", "path", ".", "exists", "(", "weights", ")", "and", "os", ".", "path", ".", "getsize", "(", "weights", ")", ">", "1E6", ")", ":", "# weights exist and > 1MB", "\n", "            ", "os", ".", "system", "(", "'rm '", "+", "weights", ")", "# remove partial downloads", "\n", "raise", "Exception", "(", "msg", ")", "\n", "", "", "", ""]]}