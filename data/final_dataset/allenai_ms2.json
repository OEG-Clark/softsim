{"home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.TargetSummary.read_summaries": [[80, 86], ["open", "map", "list"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "read_summaries", "(", "f", ":", "str", ")", "->", "List", "[", "'TargetSummary'", "]", ":", "\n", "        ", "with", "open", "(", "f", ",", "'r'", ")", "as", "inf", ":", "\n", "            ", "summaries", "=", "map", "(", "TargetSummary", ".", "from_json", ",", "inf", ")", "\n", "summaries", "=", "list", "(", "summaries", ")", "\n", "", "return", "summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.Review.__post_init__": [[165, 169], ["len", "utils.Review.abstract.strip"], "methods", ["None"], ["def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "docid", "is", "not", "None", "\n", "assert", "self", ".", "title", "is", "not", "None", "\n", "assert", "self", ".", "abstract", "is", "not", "None", "and", "len", "(", "self", ".", "abstract", ".", "strip", "(", ")", ")", ">", "0", "\n", "#assert len(self.structured_abstract) > 0", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.Review.extract_references": [[171, 181], ["itertools.chain.from_iterable", "itertools.chain.from_iterable", "map", "list"], "methods", ["None"], ["", "def", "extract_references", "(", "self", ")", "->", "List", "[", "Reference", "]", ":", "\n", "        ", "studies", "=", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "\n", "self", ".", "included_studies", ",", "\n", "self", ".", "ongoing_studies", ",", "\n", "self", ".", "excluded_studies", ",", "\n", "self", ".", "awaiting_studies", ",", "\n", "]", ")", "\n", "study_refs", "=", "itertools", ".", "chain", ".", "from_iterable", "(", "map", "(", "lambda", "x", ":", "x", ".", "references", ",", "studies", ")", ")", "\n", "all_refs", "=", "list", "(", "study_refs", ")", "+", "self", ".", "general_references", "+", "self", ".", "unattributed_references", "\n", "return", "all_refs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.Review.read_reviews": [[182, 189], ["open", "filter", "map", "list", "len", "line.strip"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "read_reviews", "(", "f", ")", "->", "List", "[", "'Review'", "]", ":", "\n", "        ", "with", "open", "(", "f", ",", "'r'", ")", "as", "inf", ":", "\n", "            ", "inf", "=", "filter", "(", "lambda", "line", ":", "len", "(", "line", ".", "strip", "(", ")", ")", ">", "0", ",", "inf", ")", "\n", "reviews", "=", "map", "(", "Review", ".", "from_json", ",", "inf", ")", "\n", "reviews", "=", "list", "(", "reviews", ")", "\n", "", "return", "reviews", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.get_tokenizer": [[45, 48], ["transformers.AutoTokenizer.from_pretrained"], "function", ["None"], ["def", "get_tokenizer", "(", "tokenizer_type", ":", "str", ")", ":", "\n", "    ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "tokenizer_type", ",", "additional_special_tokens", "=", "EXTRA_TOKENS", ")", "\n", "return", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedTagger.__init__": [[42, 47], ["pytorch_lightning.LightningModule.__init__", "transformers.BertModel.from_pretrained", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "bert_name", ",", "classes", ")", ":", "\n", "        ", "super", "(", "PubmedTagger", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert", "=", "BertModel", ".", "from_pretrained", "(", "bert_name", ")", "\n", "self", ".", "lin", "=", "nn", ".", "Linear", "(", "self", ".", "bert", ".", "config", ".", "hidden_size", ",", "len", "(", "classes", ")", ")", "\n", "self", ".", "classes", "=", "classes", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedTagger.forward": [[48, 78], ["pubmed_tagger.PubmedTagger.bert", "pubmed_tagger.PubmedTagger.lin", "torch.functional.binary_cross_entropy_with_logits", "torch.functional.binary_cross_entropy_with_logits"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "tokens", ",", "token_mask", ",", "labels", "=", "None", ",", "labels_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n\n        Args:\n            tokens (torch.LongTensor): bs * len token ids\n            token_mask (torch.FloatTensor): bs * len mask; elements are 1.0 for on, 0.0 for off\n            labels (torch.LongTensor, optional): bs * num_classes. The true classes associated with each instance in the batch. Defaults to None.\n            labels_mask (torch.LongTensor, optional): bs * num_classes. A mask for classes to ignore for each instance in the batch. Elements are 1.0 for on, 0.0 for off. Defaults to None.\n\n        Returns:\n            Tuple matching HuggingFace BERTs: (?loss, logits, hidden states, attentions)\n            loss (torch.FloatTensor of shape (1,), optional): returned when `labels` are present\n            logits (torch.FloatTensor of shape (bs * num_classes)): pre-sigmoid output from the multiclass layer\n            hidden states: as in HuggingFace BERT\n            attentions: as in HuggingFace BERT\n        \"\"\"", "\n", "bert_outputs", "=", "self", ".", "bert", "(", "tokens", ",", "token_mask", ")", "\n", "last_hidden_states", "=", "bert_outputs", "[", "0", "]", "\n", "cls_tokens", "=", "bert_outputs", "[", "0", "]", "[", ":", ",", "0", "]", "\n", "logits", "=", "self", ".", "lin", "(", "cls_tokens", ")", "\n", "outputs", "=", "(", "logits", ",", "bert_outputs", "[", "-", "2", "]", ",", "bert_outputs", "[", "-", "1", "]", ")", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "labels_mask", "is", "not", "None", ":", "\n", "                ", "logits", "*=", "labels_mask", "\n", "#logits = logits.to(dtype=torch.LongTensor)", "\n", "", "loss", "=", "nn", ".", "functional", ".", "binary_cross_entropy_with_logits", "(", "logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "else", ":", "\n", "            ", "loss", "=", "None", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedTagger.training_step": [[79, 101], ["text.to.to.to", "text.to.to.mask", "labels.to.to.to", "pubmed_tagger.PubmedTagger.forward", "torch.round", "torch.round", "torch.round", "torch.round", "sklearn.metrics.classification_report", "next", "torch.functional.sigmoid", "torch.functional.sigmoid", "labels.to.to.cpu().numpy", "torch.round.detach().cpu().numpy", "torch.round.detach().cpu().numpy", "sum", "labels_mask.sum", "loss.item", "labels_mask.sum().item", "pubmed_tagger.PubmedTagger.parameters", "loss.item", "loss.item", "labels.to.to.cpu", "torch.round.detach().cpu", "torch.round.detach().cpu", "torch.round.masked_select", "torch.round.masked_select", "labels.to.to.masked_select", "labels_mask.sum", "labels_mask.to", "labels_mask.to", "torch.round.detach", "torch.round.detach"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.mask", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "text", ":", "PaddedSequence", "\n", "labels", ":", "torch", ".", "LongTensor", "\n", "labels_mask", ":", "torch", ".", "FloatTensor", "\n", "text", ",", "labels", ",", "labels_mask", "=", "batch", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "text", "=", "text", ".", "to", "(", "device", "=", "device", ")", "\n", "mask", "=", "text", ".", "mask", "(", "on", "=", "1", ",", "off", "=", "0", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", "=", "device", ")", "\n", "loss", ",", "logits", ",", "_", ",", "_", "=", "self", ".", "forward", "(", "text", ".", "data", ",", "mask", ",", "labels", "=", "labels", ",", "labels_mask", "=", "labels_mask", ")", "\n", "preds", "=", "torch", ".", "round", "(", "nn", ".", "functional", ".", "sigmoid", "(", "logits", ")", ")", "\n", "report", "=", "classification_report", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "target_names", "=", "self", ".", "classes", ",", "output_dict", "=", "True", ",", "zero_division", "=", "0", ")", "\n", "acc", "=", "sum", "(", "preds", ".", "masked_select", "(", "labels_mask", ".", "to", "(", "torch", ".", "bool", ")", ")", "==", "labels", ".", "masked_select", "(", "labels_mask", ".", "to", "(", "torch", ".", "bool", ")", ")", ")", "/", "labels_mask", ".", "sum", "(", ")", "\n", "return", "{", "\n", "'batch_log_metrics'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'loss'", ":", "loss", ",", "\n", "'acc'", ":", "acc", ",", "\n", "'labels'", ":", "labels_mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "\n", "'log'", ":", "{", "\n", "'f1'", ":", "report", "[", "'macro avg'", "]", "[", "'f1-score'", "]", ",", "\n", "'loss'", ":", "loss", ".", "item", "(", ")", ",", "\n", "'train_loss'", ":", "loss", ".", "item", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedTagger.validation_step": [[104, 121], ["text.to.to.to", "text.to.to.mask", "labels.to.to.to", "pubmed_tagger.PubmedTagger.forward", "torch.round", "torch.round", "torch.round", "torch.round", "sklearn.metrics.classification_report", "next", "torch.functional.sigmoid", "torch.functional.sigmoid", "labels.to.to.cpu().numpy", "torch.round.detach().cpu().numpy", "torch.round.detach().cpu().numpy", "sum", "labels_mask.sum", "labels_mask.sum().item", "pubmed_tagger.PubmedTagger.parameters", "labels.to.to.cpu", "torch.round.detach().cpu", "torch.round.detach().cpu", "torch.round.masked_select", "torch.round.masked_select", "labels.to.to.masked_select", "labels_mask.sum", "labels_mask.to", "labels_mask.to", "torch.round.detach", "torch.round.detach"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.mask", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "text", ":", "PaddedSequence", "\n", "labels", ":", "torch", ".", "LongTensor", "\n", "labels_mask", ":", "torch", ".", "FloatTensor", "\n", "text", ",", "labels", ",", "labels_mask", "=", "batch", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "text", "=", "text", ".", "to", "(", "device", "=", "device", ")", "\n", "mask", "=", "text", ".", "mask", "(", "on", "=", "1", ",", "off", "=", "0", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "device", ")", "\n", "loss", ",", "logits", ",", "_", ",", "_", "=", "self", ".", "forward", "(", "text", ".", "data", ",", "mask", ",", "labels", "=", "labels", ",", "labels_mask", "=", "None", ")", "\n", "preds", "=", "torch", ".", "round", "(", "nn", ".", "functional", ".", "sigmoid", "(", "logits", ")", ")", "\n", "report", "=", "classification_report", "(", "labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "target_names", "=", "self", ".", "classes", ",", "output_dict", "=", "True", ",", "zero_division", "=", "0", ")", "\n", "acc", "=", "sum", "(", "preds", ".", "masked_select", "(", "labels_mask", ".", "to", "(", "torch", ".", "bool", ")", ")", "==", "labels", ".", "masked_select", "(", "labels_mask", ".", "to", "(", "torch", ".", "bool", ")", ")", ")", "/", "labels_mask", ".", "sum", "(", ")", "\n", "return", "{", "\n", "'val_loss'", ":", "loss", ",", "\n", "'val_acc'", ":", "acc", ",", "\n", "'labels'", ":", "labels_mask", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedTagger.validation_epoch_end": [[123, 128], ["sum", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "return", "{", "\n", "'val_loss'", ":", "sum", "(", "output", "[", "'val_loss'", "]", "for", "output", "in", "outputs", ")", ",", "\n", "'val_acc'", ":", "torch", ".", "mean", "(", "torch", ".", "tensor", "(", "[", "output", "[", "'val_acc'", "]", "for", "output", "in", "outputs", "]", ")", ")", ",", "\n", "'labels'", ":", "torch", ".", "sum", "(", "torch", ".", "tensor", "(", "[", "output", "[", "'labels'", "]", "for", "output", "in", "outputs", "]", ")", ")", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedTagger.configure_optimizers": [[130, 132], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "pubmed_tagger.PubmedTagger.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "1e-3", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedDataset.__init__": [[136, 172], ["dict", "glob.glob", "glob.glob", "random.shuffle", "list", "os.path.join", "positives.extend", "os.path.join", "random.sample.extend", "random.sample", "map", "pubmed_tagger.read_jsonl", "len", "logging.info", "pubmed_tagger.read_jsonl", "len", "logging.info", "len", "enumerate", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.read_jsonl", "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.read_jsonl"], ["    ", "def", "__init__", "(", "\n", "self", ",", "\n", "inputs_dir", ":", "str", ",", "\n", "sample_negatives", ":", "bool", ",", "\n", "tokenizer", ",", "\n", "classes", ":", "List", "[", "str", "]", ",", "\n", "max_length", ":", "int", ",", "\n", "truncate_extra", ":", "bool", "=", "True", ")", ":", "\n", "        ", "self", ".", "classes", "=", "classes", "\n", "self", ".", "intern_class", "=", "dict", "(", "(", "(", "x", ",", "i", ")", "for", "(", "i", ",", "x", ")", "in", "enumerate", "(", "classes", ")", ")", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "positives", "=", "[", "]", "\n", "negatives", "=", "[", "]", "\n", "for", "f", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "inputs_dir", ",", "'targets'", ",", "'*'", ")", ")", ":", "\n", "            ", "positives", ".", "extend", "(", "read_jsonl", "(", "f", ")", ")", "\n", "if", "len", "(", "positives", ")", ">", "1000000", ":", "\n", "                ", "logging", ".", "info", "(", "'not loading all data due to memory constraints'", ")", "\n", "break", "\n", "", "", "for", "f", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "inputs_dir", ",", "'etc'", ",", "'*'", ")", ")", ":", "\n", "            ", "negatives", ".", "extend", "(", "read_jsonl", "(", "f", ")", ")", "\n", "if", "len", "(", "negatives", ")", ">", "5", "*", "len", "(", "positives", ")", ":", "\n", "                ", "logging", ".", "info", "(", "'not loading all data due to memory constraints'", ")", "\n", "break", "\n", "", "", "for", "p", "in", "positives", ":", "\n", "            ", "p", "[", "'source'", "]", "=", "'positive'", "\n", "", "for", "n", "in", "negatives", ":", "\n", "            ", "n", "[", "'source'", "]", "=", "'negative'", "\n", "", "if", "sample_negatives", ":", "\n", "            ", "negatives", "=", "random", ".", "sample", "(", "negatives", ",", "len", "(", "positives", ")", ")", "\n", "", "self", ".", "positives", "=", "positives", "\n", "self", ".", "negatives", "=", "negatives", "\n", "all_data", "=", "positives", "+", "negatives", "\n", "random", ".", "shuffle", "(", "all_data", ")", "\n", "# turn the data into a list of [text, labels, label_mask]", "\n", "self", ".", "instances", "=", "list", "(", "map", "(", "self", ".", "_elem_to_training_instance", ",", "all_data", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedDataset.__len__": [[173, 175], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedDataset.__getitem__": [[176, 178], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "instances", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedDataset._elem_to_training_instance": [[179, 193], ["torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "list", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "map", "pubmed_tagger.PubmedDataset.tokenizer.convert_tokens_to_ids", "len", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "ValueError", "len"], "methods", ["None"], ["", "def", "_elem_to_training_instance", "(", "self", ",", "elem", ")", ":", "\n", "# auto trim instances", "\n", "        ", "text", "=", "torch", ".", "LongTensor", "(", "self", ".", "tokenizer", ".", "convert_tokens_to_ids", "(", "elem", "[", "'text'", "]", ")", "[", ":", "self", ".", "max_length", "]", ")", "\n", "publication_types", "=", "elem", "[", "'publication_types'", "]", "\n", "publication_types", "=", "list", "(", "map", "(", "lambda", "t", ":", "self", ".", "intern_class", "[", "t", "]", ",", "publication_types", ")", ")", "\n", "types", "=", "torch", ".", "zeros", "(", "(", "len", "(", "self", ".", "classes", ")", ",", ")", ")", "\n", "types", "[", "publication_types", "]", "=", "1", "\n", "if", "elem", "[", "'source'", "]", "==", "'positive'", ":", "\n", "            ", "mask", "=", "types", "\n", "", "elif", "elem", "[", "'source'", "]", "==", "'negative'", ":", "\n", "            ", "mask", "=", "torch", ".", "ones", "(", "(", "len", "(", "self", ".", "classes", ",", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'impossible state with unknown elem {}'", ".", "format", "(", "elem", ")", ")", "\n", "", "return", "text", ",", "types", ",", "mask", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.PubmedDataset.collate_fn": [[194, 201], ["zip", "ms2.models.utils.PaddedSequence.autopad", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.autopad"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "instances", ")", ":", "\n", "        ", "texts", ",", "labels", ",", "label_masks", "=", "zip", "(", "*", "instances", ")", "\n", "texts", "=", "PaddedSequence", ".", "autopad", "(", "texts", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ")", "\n", "labels", "=", "torch", ".", "stack", "(", "labels", ")", "\n", "label_masks", "=", "torch", ".", "stack", "(", "label_masks", ")", "\n", "return", "texts", ",", "labels", ",", "label_masks", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.read_jsonl": [[202, 205], ["open", "list", "map"], "function", ["None"], ["", "", "def", "read_jsonl", "(", "f", ":", "str", ")", "->", "List", "[", "Union", "[", "Dict", ",", "List", "]", "]", ":", "\n", "    ", "with", "open", "(", "f", ",", "'r'", ")", "as", "inf", ":", "\n", "        ", "return", "list", "(", "map", "(", "json", ".", "loads", ",", "inf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.pubmed_tagger.main": [[206, 244], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "json.loads", "logging.info", "pytorch_lightning.loggers.TensorBoardLogger", "logging.info", "pubmed_tagger.PubmedTagger", "model.cuda.cuda", "logging.info", "transformers.BertTokenizerFast.from_pretrained", "pubmed_tagger.PubmedDataset", "pubmed_tagger.PubmedDataset", "logging.info", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logging.info", "pytorch_lightning.Trainer", "logging.info", "pl.Trainer.fit", "_jsonnet.evaluate_file", "os.getcwd", "len", "len"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train and evaluate pubmed multiclass tagger'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "required", "=", "True", ",", "help", "=", "'Training dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "required", "=", "True", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "config", "=", "json", ".", "loads", "(", "_jsonnet", ".", "evaluate_file", "(", "args", ".", "config", ")", ")", "\n", "logging", ".", "info", "(", "config", ")", "\n", "\n", "model_name", "=", "config", "[", "'model_name'", "]", "\n", "train_dir", "=", "config", "[", "'train'", "]", "\n", "val_dir", "=", "config", "[", "'val'", "]", "\n", "batch_size", "=", "config", "[", "'batch_size'", "]", "\n", "max_epochs", "=", "config", "[", "'epochs'", "]", "\n", "classes", "=", "config", "[", "'classes'", "]", "\n", "max_length", "=", "config", "[", "'max_length'", "]", "\n", "\n", "logger", "=", "TensorBoardLogger", "(", "\n", "save_dir", "=", "os", ".", "getcwd", "(", ")", ",", "\n", "version", "=", "1", ",", "\n", "name", "=", "'lightning_logs'", "\n", ")", "\n", "\n", "logging", ".", "info", "(", "'Loading model'", ")", "\n", "model", "=", "PubmedTagger", "(", "model_name", ",", "classes", ")", "\n", "model", "=", "model", ".", "cuda", "(", ")", "\n", "\n", "logging", ".", "info", "(", "'Loading data'", ")", "\n", "tokenizer", "=", "BertTokenizerFast", ".", "from_pretrained", "(", "model_name", ")", "\n", "train_data", "=", "PubmedDataset", "(", "train_dir", ",", "True", ",", "tokenizer", ",", "classes", ",", "max_length", ")", "\n", "val_data", "=", "PubmedDataset", "(", "val_dir", ",", "False", ",", "tokenizer", ",", "classes", ",", "max_length", ")", "\n", "logging", ".", "info", "(", "'Loaded {} training examples, {} validation_examples'", ".", "format", "(", "len", "(", "train_data", ")", ",", "len", "(", "val_data", ")", ")", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "4", ",", "collate_fn", "=", "PubmedDataset", ".", "collate_fn", ")", "\n", "val_dataloader", "=", "DataLoader", "(", "val_data", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "4", ",", "collate_fn", "=", "PubmedDataset", ".", "collate_fn", ")", "\n", "logging", ".", "info", "(", "'Creating trainer'", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "default_root_dir", "=", "args", ".", "model_dir", ",", "max_epochs", "=", "max_epochs", ",", "gpus", "=", "1", ",", "logger", "=", "logger", ")", "\n", "# TODO resume from checkpoint!", "\n", "logging", ".", "info", "(", "'Training!'", ")", "\n", "trainer", ".", "fit", "(", "model", ",", "train_dataloader", ",", "val_dataloader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractTagger.__init__": [[38, 46], ["torch.Module.__init__", "transformers.AutoModel.from_pretrained", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "classes", ",", "tokenizer", ",", "model_dir", ")", ":", "\n", "        ", "super", "(", "AbstractTagger", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "AutoModel", ".", "from_pretrained", "(", "model_name", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "model", ".", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "model", ".", "config", ".", "hidden_size", ",", "len", "(", "classes", ")", ")", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "model_dir", "=", "model_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractTagger.forward": [[47, 61], ["abstract_classifier.AbstractTagger.model", "abstract_classifier.AbstractTagger.dropout", "abstract_classifier.AbstractTagger.classifier", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "flat_labels.size", "abstract_classifier.AbstractTagger.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "labels", "=", "None", ")", ":", "\n", "        ", "attention_mask", "=", "(", "input_ids", "!=", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "outputs", "=", "self", ".", "model", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ")", "\n", "sent_sep_embeddings", "=", "outputs", "[", "0", "]", "[", "input_ids", "==", "self", ".", "tokenizer", ".", "sep_token_id", "]", "\n", "sent_sep_embeddings", "=", "self", ".", "dropout", "(", "sent_sep_embeddings", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sent_sep_embeddings", ")", "\n", "loss", "=", "None", "\n", "flat_labels", "=", "labels", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "flat_labels", "=", "labels", "[", "labels", "!=", "-", "100", "]", "\n", "assert", "flat_labels", ".", "size", "(", "0", ")", "==", "sent_sep_embeddings", ".", "size", "(", "0", ")", "\n", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ",", "flat_labels", ")", "\n", "", "return", "loss", ",", "logits", ",", "flat_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractTagger.decode": [[62, 83], ["torch.nn.utils.rnn.pad_sequence().long", "torch.nn.utils.rnn.pad_sequence().long", "torch.nn.utils.rnn.pad_sequence().long", "torch.nn.utils.rnn.pad_sequence().long", "abstract_classifier.AbstractTagger.forward", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "abstract_classifier.AbstractTagger.tokenizer.encode", "torch.nn.utils.rnn.pad_sequence().long.extend", "torch.nn.utils.rnn.pad_sequence().long.extend", "len", "input_ids_list.append", "torch.nn.utils.rnn.pad_sequence().long.cuda", "torch.nn.utils.rnn.pad_sequence().long.cuda", "len", "len", "input_ids_list.append", "len", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "len", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda"], ["", "def", "decode", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ",", "max_length", ":", "int", ",", "group_in_one_abstract", ":", "bool", ")", ":", "\n", "        ", "input_ids_list", "=", "[", "]", "\n", "input_ids", "=", "[", "]", "\n", "for", "text", "in", "texts", ":", "\n", "            ", "tokens", "=", "self", ".", "tokenizer", ".", "encode", "(", "text", ",", "truncation", "=", "True", ",", "max_length", "=", "max_length", ")", "\n", "if", "len", "(", "input_ids", ")", "+", "len", "(", "tokens", ")", ">", "max_length", "or", "not", "group_in_one_abstract", ":", "\n", "                ", "input_ids_list", ".", "append", "(", "input_ids", ")", "\n", "input_ids", "=", "[", "]", "\n", "", "if", "len", "(", "input_ids", ")", ">", "0", ":", "\n", "                ", "tokens", "=", "tokens", "[", "1", ":", "]", "# drop the leading <s>", "\n", "", "input_ids", ".", "extend", "(", "tokens", ")", "\n", "", "if", "len", "(", "input_ids", ")", ">", "0", ":", "\n", "            ", "input_ids_list", ".", "append", "(", "input_ids", ")", "\n", "", "input_ids", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "t", ")", "for", "t", "in", "input_ids_list", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "self", ".", "tokenizer", ".", "pad_token_id", ")", ".", "long", "(", ")", "\n", "loss", ",", "logits", ",", "flat_labels", "=", "self", ".", "forward", "(", "input_ids", ".", "cuda", "(", ")", ")", "\n", "assert", "loss", "is", "None", "\n", "assert", "flat_labels", "is", "None", "\n", "pred_labels", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "dist", "=", "torch", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "assert", "len", "(", "pred_labels", ")", "==", "len", "(", "texts", ")", "\n", "return", "pred_labels", ",", "dist", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.__init__": [[87, 92], ["pytorch_lightning.LightningModule.__init__", "abstract_classifier.LightningAbstractTagger.save_hyperparameters", "abstract_classifier.AbstractTagger"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "model_name", ",", "classes", ",", "tokenizer", ",", "model_dir", ")", ":", "\n", "        ", "super", "(", "LightningAbstractTagger", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "model", "=", "AbstractTagger", "(", "model_name", ",", "classes", ",", "tokenizer", ",", "model_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.training_step": [[93, 116], ["abstract_classifier.LightningAbstractTagger.forward", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax", "sklearn.metrics.classification_report", "sklearn.metrics.accuracy_score", "flat_labels.cpu().numpy", "torch.argmax.detach().cpu().numpy", "torch.argmax.detach().cpu().numpy", "flat_labels.cpu().numpy", "torch.argmax.detach().cpu().numpy", "torch.argmax.detach().cpu().numpy", "torch.softmax().detach().cpu", "torch.softmax().detach().cpu", "torch.softmax().detach().cpu", "torch.softmax().detach().cpu", "list", "flat_labels.cpu", "torch.argmax.detach().cpu", "torch.argmax.detach().cpu", "range", "flat_labels.cpu", "torch.argmax.detach().cpu", "torch.argmax.detach().cpu", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "len", "torch.argmax.detach", "torch.argmax.detach", "torch.argmax.detach", "torch.argmax.detach", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "names", ",", "input_ids", ",", "labels", "=", "batch", "\n", "loss", ",", "logits", ",", "flat_labels", "=", "self", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "labels", "=", "labels", ")", "\n", "preds", "=", "torch", ".", "argmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", "report", "=", "classification_report", "(", "\n", "flat_labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "\n", "labels", "=", "list", "(", "range", "(", "len", "(", "self", ".", "model", ".", "classes", ")", ")", ")", ",", "\n", "target_names", "=", "self", ".", "model", ".", "classes", ",", "\n", "output_dict", "=", "True", ",", "\n", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "flat_labels", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "preds", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "return", "{", "\n", "'scores'", ":", "torch", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'loss'", ":", "loss", ",", "\n", "'preds'", ":", "preds", ",", "\n", "'labels'", ":", "flat_labels", ",", "\n", "'log'", ":", "{", "\n", "**", "report", "[", "'macro avg'", "]", ",", "\n", "'loss'", ":", "loss", ",", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.forward": [[119, 121], ["abstract_classifier.LightningAbstractTagger.model.forward"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", ",", "labels", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "forward", "(", "input_ids", "=", "input_ids", ",", "labels", "=", "labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode": [[122, 124], ["abstract_classifier.LightningAbstractTagger.model.decode"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode"], ["", "def", "decode", "(", "self", ",", "texts", ":", "List", "[", "str", "]", ",", "max_length", ":", "int", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "decode", "(", "texts", ",", "max_length", ",", "group_in_one_abstract", "=", "self", ".", "args", ".", "seq", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.configure_optimizers": [[125, 133], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "abstract_classifier.LightningAbstractTagger.train_dataloader.dataloader.dataset.__len__", "transformers.optimization.get_linear_schedule_with_warmup", "abstract_classifier.LightningAbstractTagger.parameters"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.__len__"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "parameters", "(", ")", ",", "lr", "=", "1e-5", ")", "\n", "dataset_size", "=", "self", ".", "train_dataloader", ".", "dataloader", ".", "dataset", ".", "__len__", "(", ")", "\n", "num_steps", "=", "dataset_size", "*", "self", ".", "args", ".", "epochs", "/", "self", ".", "args", ".", "grad_accum", "/", "self", ".", "args", ".", "batch_size", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "num_steps", "*", "0.1", ",", "num_training_steps", "=", "num_steps", "\n", ")", "\n", "return", "[", "optimizer", "]", ",", "[", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.validation_step": [[134, 136], ["abstract_classifier.LightningAbstractTagger.test_step"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.test_step"], ["", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "test_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.validation_epoch_end": [[137, 154], ["torch.stack().mean().cpu", "torch.stack().mean().cpu", "torch.stack().mean().cpu", "torch.stack().mean().cpu", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "sklearn.metrics.classification_report", "sklearn.metrics.accuracy_score", "logging.info", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "list", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len"], "methods", ["None"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "'loss'", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", ".", "cpu", "(", ")", "\n", "preds", "=", "torch", ".", "cat", "(", "[", "x", "[", "'preds'", "]", "for", "x", "in", "outputs", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "x", "[", "'labels'", "]", "for", "x", "in", "outputs", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "report", "=", "classification_report", "(", "\n", "labels", ",", "\n", "preds", ",", "\n", "labels", "=", "list", "(", "range", "(", "len", "(", "self", ".", "model", ".", "classes", ")", ")", ")", ",", "\n", "target_names", "=", "self", ".", "model", ".", "classes", ",", "\n", "output_dict", "=", "True", ",", "\n", "zero_division", "=", "0", ")", "\n", "accuracy", "=", "accuracy_score", "(", "labels", ",", "preds", ")", "\n", "logging", ".", "info", "(", "f'loss: {avg_loss}, accuracy: {accuracy}, macro avg: {report[\"macro avg\"]}'", ")", "\n", "return", "{", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'val_loss'", ":", "avg_loss", ",", "\n", "'log'", ":", "report", "[", "'macro avg'", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.test_step": [[156, 158], ["abstract_classifier.LightningAbstractTagger.training_step"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.training_step"], ["", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "return", "self", ".", "training_step", "(", "batch", ",", "batch_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.test_epoch_end": [[159, 213], ["torch.stack().mean().cpu", "torch.stack().mean().cpu", "torch.stack().mean().cpu", "torch.stack().mean().cpu", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "sklearn.metrics.classification_report", "sklearn.metrics.classification_report.items", "sklearn.metrics.confusion_matrix", "logging.info", "sklearn.metrics.accuracy_score", "logging.info", "len", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "sklearn.metrics.roc_auc_score", "logging.info", "sklearn.metrics.precision_recall_curve", "logging.info", "logging.info", "logging.info", "matplotlib.ioff", "matplotlib.subplots", "ax.plot", "ax.set", "matplotlib.savefig", "logging.info", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.stack().mean", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "os.path.join", "list", "type", "logging.info", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "torch.cat().cpu", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "avg_loss", "=", "torch", ".", "stack", "(", "[", "x", "[", "'loss'", "]", "for", "x", "in", "outputs", "]", ")", ".", "mean", "(", ")", ".", "cpu", "(", ")", "\n", "preds", "=", "torch", ".", "cat", "(", "[", "x", "[", "'preds'", "]", "for", "x", "in", "outputs", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "x", "[", "'labels'", "]", "for", "x", "in", "outputs", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "if", "len", "(", "self", ".", "model", ".", "classes", ")", "==", "2", ":", "\n", "            ", "scores", "=", "torch", ".", "cat", "(", "[", "x", "[", "'scores'", "]", "for", "x", "in", "outputs", "]", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "scores", "=", "scores", "[", ":", ",", "1", "]", "\n", "auc", "=", "roc_auc_score", "(", "\n", "labels", ",", "\n", "scores", ",", "\n", "average", "=", "'macro'", ")", "\n", "logging", ".", "info", "(", "'auc: {}'", ".", "format", "(", "auc", ")", ")", "\n", "precisions", ",", "recalls", ",", "thresholds", "=", "precision_recall_curve", "(", "\n", "labels", ",", "\n", "scores", ",", "\n", "pos_label", "=", "1", "\n", ")", "\n", "logging", ".", "info", "(", "'precisions: {}'", ".", "format", "(", "precisions", ")", ")", "\n", "logging", ".", "info", "(", "'recalls: {}'", ".", "format", "(", "recalls", ")", ")", "\n", "logging", ".", "info", "(", "'thresholds: {}'", ".", "format", "(", "thresholds", ")", ")", "\n", "plt", ".", "ioff", "(", ")", "\n", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", ")", "\n", "line_kwargs", "=", "{", "\"drawstyle\"", ":", "\"steps-post\"", ",", "'label'", ":", "'prf'", "}", "\n", "line_", "=", "ax", ".", "plot", "(", "recalls", ",", "precisions", ",", "**", "line_kwargs", ")", "\n", "ax", ".", "set", "(", "xlabel", "=", "\"Recall\"", ",", "ylabel", "=", "\"Precision\"", ")", "\n", "plt", ".", "savefig", "(", "os", ".", "path", ".", "join", "(", "self", ".", "model", ".", "model_dir", ",", "'test_prf.png'", ")", ")", "\n", "", "report", "=", "classification_report", "(", "\n", "labels", ",", "\n", "preds", ",", "\n", "labels", "=", "list", "(", "range", "(", "len", "(", "self", ".", "model", ".", "classes", ")", ")", ")", ",", "\n", "target_names", "=", "self", ".", "model", ".", "classes", ",", "\n", "output_dict", "=", "True", ",", "\n", "zero_division", "=", "0", ")", "\n", "for", "key", ",", "value", "in", "report", ".", "items", "(", ")", ":", "\n", "            ", "if", "type", "(", "value", ")", "!=", "dict", ":", "\n", "                ", "logging", ".", "info", "(", "f'{key}: {value:.2f}'", ")", "\n", "continue", "\n", "", "p", "=", "value", "[", "'precision'", "]", "\n", "r", "=", "value", "[", "'recall'", "]", "\n", "f", "=", "value", "[", "'f1-score'", "]", "\n", "s", "=", "value", "[", "'support'", "]", "\n", "logging", ".", "info", "(", "f'p: {p:.2f}, r: {r:.2f}, f: {f:.2f}, s: {s} - {key}'", ")", "\n", "\n", "", "conf", "=", "confusion_matrix", "(", "\n", "labels", ",", "\n", "preds", ",", "\n", "normalize", "=", "'true'", ")", "\n", "logging", ".", "info", "(", "'confusion matrix\\n{}'", ".", "format", "(", "conf", ")", ")", "\n", "accuracy", "=", "accuracy_score", "(", "labels", ",", "preds", ")", "\n", "logging", ".", "info", "(", "f'loss: {avg_loss}, accuracy: {accuracy}, macro avg: {report[\"macro avg\"]}'", ")", "\n", "return", "{", "\n", "'accuracy'", ":", "accuracy", ",", "\n", "'test_loss'", ":", "avg_loss", ",", "\n", "'log'", ":", "report", "[", "'macro avg'", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractsDataset.__init__": [[218, 282], ["torch.utils.data.Dataset.__init__", "pandas.read_csv().fillna", "list", "dict", "df[].itertuples", "set", "abstract_classifier.AbstractsDataset.instances.extend", "set", "merged_instances.append", "pandas.read_csv", "filter", "abstract_classifier.AbstractsDataset._elem_to_training_instance", "merged_tokens_one_instance.extend", "merged_labels_one_instance.extend", "instance[].clear", "instance[].extend", "enumerate", "set.add", "len", "merged_instances.append", "logging.error", "new_labels.append", "len", "len", "len", "merged_tokens_one_instance.count", "new_labels.append", "new_labels.append"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractsDataset._elem_to_training_instance"], ["def", "__init__", "(", "\n", "self", ",", "\n", "csv_path", ":", "str", ",", "\n", "instance_name_field", ":", "str", ",", "\n", "instance_text_field", ":", "str", ",", "\n", "instance_cls_field", ":", "str", ",", "\n", "tokenizer", ",", "\n", "classes", ":", "List", "[", "str", "]", ",", "\n", "max_length", ":", "int", ",", "\n", "seq", ":", "bool", ",", "\n", "limit_classes", ":", "bool", ")", ":", "\n", "        ", "super", "(", "AbstractsDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "df", "=", "pd", ".", "read_csv", "(", "csv_path", ")", ".", "fillna", "(", "value", "=", "\"MISSING!\"", ")", "\n", "df", "=", "df", "[", "df", "[", "instance_cls_field", "]", "!=", "\"MISSING!\"", "]", "\n", "if", "classes", "is", "None", ":", "\n", "            ", "classes", "=", "set", "(", "filter", "(", "lambda", "kls", ":", "','", "not", "in", "kls", ",", "df", "[", "instance_cls_field", "]", ")", ")", "\n", "", "self", ".", "classes", "=", "list", "(", "classes", ")", "\n", "self", ".", "intern_class", "=", "dict", "(", "(", "(", "x", ",", "i", ")", "for", "(", "i", ",", "x", ")", "in", "enumerate", "(", "classes", ")", ")", ")", "\n", "AbstractsDataset", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "max_length", "=", "max_length", "\n", "self", ".", "instances", "=", "[", "]", "\n", "for", "row", "in", "df", "[", "[", "instance_name_field", ",", "instance_text_field", ",", "instance_cls_field", "]", "]", ".", "itertuples", "(", "index", "=", "False", ")", ":", "\n", "            ", "self", ".", "instances", ".", "extend", "(", "self", ".", "_elem_to_training_instance", "(", "row", ")", ")", "\n", "", "if", "seq", ":", "\n", "            ", "merged_instances", "=", "[", "]", "\n", "prev_s2id", "=", "None", "\n", "found_ids", "=", "set", "(", ")", "\n", "merged_tokens_one_instance", "=", "[", "]", "\n", "merged_labels_one_instance", "=", "None", "\n", "for", "instance", "in", "self", ".", "instances", ":", "\n", "                ", "s2id", ",", "tokens", ",", "labels", "=", "instance", "\n", "if", "s2id", "!=", "prev_s2id", "or", "len", "(", "merged_tokens_one_instance", ")", "+", "len", "(", "tokens", ")", ">", "self", ".", "max_length", ":", "\n", "                    ", "if", "prev_s2id", "is", "not", "None", ":", "\n", "                        ", "assert", "len", "(", "merged_labels_one_instance", ")", "==", "merged_tokens_one_instance", ".", "count", "(", "self", ".", "tokenizer", ".", "sep_token_id", ")", "\n", "merged_instances", ".", "append", "(", "(", "s2id", ",", "merged_tokens_one_instance", ",", "merged_labels_one_instance", ")", ")", "\n", "\n", "", "merged_tokens_one_instance", "=", "[", "]", "\n", "merged_labels_one_instance", "=", "[", "]", "\n", "prev_s2id", "=", "s2id", "\n", "if", "s2id", "in", "found_ids", ":", "\n", "                        ", "logging", ".", "error", "(", "f'repeated s2id: {s2id}'", ")", "\n", "", "found_ids", ".", "add", "(", "s2id", ")", "\n", "", "if", "len", "(", "merged_tokens_one_instance", ")", ">", "0", ":", "\n", "                    ", "tokens", "=", "tokens", "[", "1", ":", "]", "# drop the leading <s>", "\n", "", "merged_tokens_one_instance", ".", "extend", "(", "tokens", ")", "\n", "merged_labels_one_instance", ".", "extend", "(", "labels", ")", "\n", "", "merged_instances", ".", "append", "(", "(", "s2id", ",", "merged_tokens_one_instance", ",", "merged_labels_one_instance", ")", ")", "\n", "self", ".", "instances", "=", "merged_instances", "\n", "\n", "", "if", "limit_classes", ":", "\n", "            ", "for", "instance", "in", "self", ".", "instances", ":", "\n", "                ", "labels", "=", "None", "\n", "new_labels", "=", "[", "]", "\n", "for", "label", "in", "instance", "[", "2", "]", ":", "\n", "                    ", "if", "label", "==", "self", ".", "intern_class", "[", "'BACKGROUND'", "]", "or", "label", "==", "self", ".", "intern_class", "[", "'GOAL'", "]", ":", "\n", "                        ", "new_labels", ".", "append", "(", "1", ")", "\n", "", "elif", "label", "==", "self", ".", "intern_class", "[", "'EFFECT'", "]", ":", "\n", "                        ", "new_labels", ".", "append", "(", "2", ")", "\n", "", "else", ":", "\n", "                        ", "new_labels", ".", "append", "(", "0", ")", "\n", "", "", "instance", "[", "2", "]", ".", "clear", "(", ")", "\n", "instance", "[", "2", "]", ".", "extend", "(", "new_labels", ")", "\n", "", "self", ".", "classes", "=", "[", "'ETC'", ",", "'BACKGROUND'", ",", "'EFFECT'", "]", "\n", "self", ".", "intern_class", "=", "{", "'ETC'", ":", "0", ",", "'BACKGROUND'", ":", "1", ",", "'EFFECT'", ":", "2", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractsDataset.__len__": [[283, 285], ["len"], "methods", ["None"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractsDataset.__getitem__": [[286, 288], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "instances", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractsDataset._elem_to_training_instance": [[289, 307], ["kls.split", "abstract_classifier.AbstractsDataset.tokenizer", "ret.append"], "methods", ["None"], ["", "def", "_elem_to_training_instance", "(", "self", ",", "elem", ")", ":", "\n", "        ", "name", ",", "text", ",", "kls", "=", "elem", "\n", "# in initial annotation of the abstract sentence classes, some contain a", "\n", "# mix of information so instead of making a decision we punted and gave", "\n", "# it two classes.", "\n", "# as that provides unclear signal, we omit these instances", "\n", "if", "','", "in", "kls", ":", "\n", "            ", "classes", "=", "kls", ".", "split", "(", "','", ")", "\n", "return", "[", "]", "\n", "", "else", ":", "\n", "            ", "classes", "=", "[", "kls", "]", "\n", "", "ret", "=", "[", "]", "\n", "# auto trim instances", "\n", "text", "=", "self", ".", "tokenizer", "(", "text", ",", "truncation", "=", "True", ",", "max_length", "=", "self", ".", "max_length", ")", "[", "'input_ids'", "]", "\n", "for", "kls", "in", "classes", ":", "\n", "            ", "kls", "=", "self", ".", "intern_class", "[", "kls", "]", "\n", "ret", ".", "append", "(", "(", "name", ",", "text", ",", "[", "kls", "]", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.AbstractsDataset.collate_fn": [[308, 316], ["zip", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.nn.utils.rnn.pad_sequence", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "collate_fn", "(", "instances", ")", ":", "\n", "        ", "pad_token_id", "=", "AbstractsDataset", ".", "tokenizer", ".", "pad_token_id", "\n", "(", "names", ",", "texts", ",", "kls", ")", "=", "zip", "(", "*", "instances", ")", "\n", "input_ids", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "t", ")", "for", "t", "in", "texts", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "pad_token_id", ")", "\n", "labels", "=", "torch", ".", "nn", ".", "utils", ".", "rnn", ".", "pad_sequence", "(", "[", "torch", ".", "tensor", "(", "x", ")", "for", "x", "in", "kls", "]", ",", "batch_first", "=", "True", ",", "padding_value", "=", "-", "100", ")", "\n", "\n", "return", "names", ",", "input_ids", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.main": [[318, 407], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "random.seed", "numpy.random.seed", "torch.manual_seed", "torch.manual_seed", "torch.cuda.is_available", "torch.cuda.is_available", "pytorch_lightning.loggers.TensorBoardLogger", "logging.info", "transformers.AutoTokenizer.from_pretrained", "abstract_classifier.AbstractsDataset", "collections.Counter", "logging.info", "abstract_classifier.AbstractsDataset", "collections.Counter", "logging.info", "logging.info", "abstract_classifier.LightningAbstractTagger", "logging.info", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "logging.info", "pytorch_lightning.Trainer", "logging.info", "pl.Trainer.fit", "pl.Trainer.test", "sample_abstract.split", "model.eval.eval", "model.eval.parameters", "model.eval.decode", "zip", "torch.cuda.manual_seed_all", "torch.cuda.manual_seed_all", "abstract_classifier.main.flatten_list_of_list"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'train and evaluate an abstract (or text) classifier from a CSV input'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_dir'", ",", "required", "=", "True", ",", "help", "=", "'Training dir'", ")", "\n", "parser", ".", "add_argument", "(", "'--train'", ",", "required", "=", "True", ",", "help", "=", "'Training dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "required", "=", "True", ",", "help", "=", "'Testing dataset'", ")", "\n", "parser", ".", "add_argument", "(", "'--name_field'", ",", "required", "=", "True", ",", "help", "=", "'Some field to grab an id'", ")", "\n", "parser", ".", "add_argument", "(", "'--text_field'", ",", "required", "=", "True", ",", "help", "=", "'Some field to grab text for classification'", ")", "\n", "parser", ".", "add_argument", "(", "'--label_field'", ",", "required", "=", "True", ",", "help", "=", "'Some field to grab the label'", ")", "\n", "parser", ".", "add_argument", "(", "'--model'", ",", "default", "=", "'roberta-large'", ",", "help", "=", "'BERT model?'", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "1234", ",", "help", "=", "\"Seed\"", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "default", "=", "16", ",", "type", "=", "int", ",", "help", "=", "'batch size'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_accum'", ",", "default", "=", "1", ",", "type", "=", "int", ",", "help", "=", "'gradient accumulation'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "5", ",", "type", "=", "int", ",", "help", "=", "'epochs'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_file'", ",", "required", "=", "False", ",", "help", "=", "'Where to save an output file'", ")", "\n", "parser", ".", "add_argument", "(", "'--seq'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Sequence labeling'", ")", "\n", "parser", ".", "add_argument", "(", "'--limit_classes'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Background, effect, etc'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "classes", "=", "None", "\n", "max_length", "=", "512", "\n", "\n", "logger", "=", "TensorBoardLogger", "(", "\n", "save_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "model_dir", ",", "'logs'", ")", "\n", ")", "\n", "logging", ".", "info", "(", "'Loading data'", ")", "\n", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "args", ".", "model", ",", "use_fast", "=", "True", ")", "\n", "\n", "def", "flatten_list_of_list", "(", "nested_list", ")", ":", "\n", "        ", "return", "[", "item", "for", "sublist", "in", "nested_list", "for", "item", "in", "sublist", "]", "\n", "\n", "", "train_data", "=", "AbstractsDataset", "(", "args", ".", "train", ",", "args", ".", "name_field", ",", "args", ".", "text_field", ",", "args", ".", "label_field", ",", "tokenizer", ",", "classes", ",", "max_length", ",", "args", ".", "seq", ",", "args", ".", "limit_classes", ")", "\n", "classes", "=", "train_data", ".", "classes", "\n", "training_distribution", "=", "Counter", "(", "flatten_list_of_list", "(", "[", "(", "train_data", ".", "classes", "[", "cls_id", "]", "for", "cls_id", "in", "inst", "[", "-", "1", "]", ")", "for", "inst", "in", "train_data", ".", "instances", "]", ")", ")", "\n", "logging", ".", "info", "(", "'Training distribution {}'", ".", "format", "(", "training_distribution", ")", ")", "\n", "\n", "if", "args", ".", "limit_classes", ":", "\n", "        ", "classes", "=", "None", "\n", "", "test_data", "=", "AbstractsDataset", "(", "args", ".", "test", ",", "args", ".", "name_field", ",", "args", ".", "text_field", ",", "args", ".", "label_field", ",", "tokenizer", ",", "classes", ",", "max_length", ",", "args", ".", "seq", ",", "args", ".", "limit_classes", ")", "\n", "if", "args", ".", "limit_classes", ":", "\n", "        ", "classes", "=", "train_data", ".", "classes", "\n", "assert", "train_data", ".", "classes", "==", "test_data", ".", "classes", "\n", "\n", "", "testing_distribution", "=", "Counter", "(", "flatten_list_of_list", "(", "[", "(", "train_data", ".", "classes", "[", "cls_id", "]", "for", "cls_id", "in", "inst", "[", "-", "1", "]", ")", "for", "inst", "in", "test_data", ".", "instances", "]", ")", ")", "\n", "logging", ".", "info", "(", "'Testing distribution {}'", ".", "format", "(", "testing_distribution", ")", ")", "\n", "\n", "logging", ".", "info", "(", "'Loading model'", ")", "\n", "model", "=", "LightningAbstractTagger", "(", "args", ",", "args", ".", "model", ",", "classes", ",", "tokenizer", ",", "args", ".", "model_dir", ")", "\n", "\n", "logging", ".", "info", "(", "'Loaded {} training examples, {} test examples'", ".", "format", "(", "len", "(", "train_data", ")", ",", "len", "(", "test_data", ")", ")", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "num_workers", "=", "0", ",", "collate_fn", "=", "AbstractsDataset", ".", "collate_fn", ")", "\n", "test_dataloader", "=", "DataLoader", "(", "test_data", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "False", ",", "num_workers", "=", "0", ",", "collate_fn", "=", "AbstractsDataset", ".", "collate_fn", ")", "\n", "logging", ".", "info", "(", "'Creating trainer'", ")", "\n", "trainer", "=", "pl", ".", "Trainer", "(", "\n", "distributed_backend", "=", "None", ",", "\n", "replace_sampler_ddp", "=", "False", ",", "\n", "default_root_dir", "=", "args", ".", "model_dir", ",", "\n", "max_epochs", "=", "args", ".", "epochs", ",", "\n", "gpus", "=", "1", ",", "\n", "logger", "=", "logger", ",", "\n", "show_progress_bar", "=", "True", ",", "\n", "log_save_interval", "=", "1", ",", "\n", "row_log_interval", "=", "1", ",", "\n", "precision", "=", "16", ",", "amp_level", "=", "'O2'", ",", "\n", "accumulate_grad_batches", "=", "args", ".", "grad_accum", ",", "\n", "checkpoint_callback", "=", "None", ",", "\n", ")", "\n", "# TODO resume from checkpoint!", "\n", "logging", ".", "info", "(", "'Training!'", ")", "\n", "trainer", ".", "fit", "(", "model", "=", "model", ",", "train_dataloader", "=", "train_dataloader", ",", "val_dataloaders", "=", "test_dataloader", ")", "# super cheating", "\n", "trainer", ".", "test", "(", "model", "=", "model", ",", "test_dataloaders", "=", "test_dataloader", ")", "\n", "if", "args", ".", "save_file", ":", "\n", "        ", "torch", ".", "save", "(", "model", ".", "model", ",", "args", ".", "save_file", ")", "\n", "\n", "", "sample_abstract", "=", "'From three trials in more severe OAG, there is some evidence that medication was associated with more progressive visual field loss and 3 to 8 mmHg less IOP lowering than surgery. In the longer-term (two trials) the risk of failure of the randomised treatment was greater with medication than trabeculectomy (OR 3.90, 95% CI 1.60 to 9.53; hazard ratio (HR) 7.27, 95% CI 2.23 to 25.71). Medications and surgery have evolved since these trials were undertaken. Evidence from one trial suggests that, beyond five years, the risk of needing cataract surgery did not differ according to initial treatment policy (OR 0.63, 95% CI 0.15 to 2.62). Methodological weaknesses were identified in all the trials. AUTHORS CONCLUSIONS\\nPrimary surgery lowers IOP more than primary medication but is associated with more eye discomfort. One trial suggests that visual field restriction at five years is not significantly different whether initial treatment is medication or trabeculectomy. There is some evidence from two small trials in more severe OAG, that initial medication (pilocarpine, now rarely used as first line medication) is associated with more glaucoma progression than surgery. Beyond five years, there is no evidence of a difference in the need for cataract surgery according to initial treatment. Further RCTs of current medical treatments compared with surgery are required, particularly for people with severe glaucoma and in black ethnic groups. Economic evaluations are required to inform treatment policy.'", "\n", "sentences", "=", "sample_abstract", ".", "split", "(", "'. '", ")", "\n", "sentences", "=", "[", "s", "+", "'.'", "for", "s", "in", "sentences", "]", "# pyt the period back", "\n", "model", "=", "model", ".", "eval", "(", ")", "\n", "for", "p", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "p", ".", "requires_grad", "=", "False", "\n", "", "labels", ",", "_", "=", "model", ".", "decode", "(", "sentences", ",", "max_length", ")", "\n", "for", "label_idx", ",", "sentence", "in", "zip", "(", "labels", ",", "sentences", ")", ":", "\n", "        ", "label", "=", "classes", "[", "label_idx", "]", "\n", "logging", ".", "info", "(", "f'{label} - {sentence}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.evidence_inference_models.BertClassifier.__init__": [[71, 97], ["torch.Module.__init__", "transformers.RobertaForSequenceClassification", "transformers.RobertaForSequenceClassification.from_pretrained", "bert.half.half.half"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__"], ["def", "__init__", "(", "self", ",", "\n", "bert_dir", ":", "Optional", "[", "str", "]", ",", "\n", "pad_token_id", ":", "int", ",", "\n", "cls_token_id", ":", "int", ",", "\n", "sep_token_id", ":", "int", ",", "\n", "num_labels", ":", "int", ",", "\n", "max_length", ":", "int", "=", "512", ",", "\n", "use_half_precision", "=", "False", ",", "\n", "config", ":", "Optional", "[", "PretrainedConfig", "]", "=", "None", ")", ":", "\n", "        ", "super", "(", "BertClassifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "bert_dir", "is", "None", ":", "\n", "            ", "assert", "config", "is", "not", "None", "\n", "assert", "config", ".", "num_labels", "==", "num_labels", "\n", "bert", "=", "RobertaForSequenceClassification", "(", "config", ")", "\n", "#bert = BertForSequenceClassification(config)", "\n", "", "else", ":", "\n", "            ", "bert", "=", "RobertaForSequenceClassification", ".", "from_pretrained", "(", "bert_dir", ",", "num_labels", "=", "num_labels", ")", "\n", "#bert = BertForSequenceClassification.from_pretrained(bert_dir, num_labels=num_labels)", "\n", "", "if", "use_half_precision", ":", "\n", "            ", "import", "apex", "\n", "bert", "=", "bert", ".", "half", "(", ")", "\n", "", "self", ".", "bert", "=", "bert", "\n", "self", ".", "pad_token_id", "=", "pad_token_id", "\n", "self", ".", "cls_token_id", "=", "cls_token_id", "\n", "self", ".", "sep_token_id", "=", "sep_token_id", "\n", "self", ".", "max_length", "=", "max_length", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.evidence_inference_models.BertClassifier.forward": [[98, 121], ["torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "zip", "ms2.models.utils.PaddedSequence.autopad", "ms2.models.utils.PaddedSequence.autopad", "evidence_inference_models.BertClassifier.bert", "torch.all", "torch.all", "torch.all", "torch.all", "len", "len", "next", "input_tensors.append", "position_ids.append", "evidence_inference_models.BertClassifier.parameters", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "ms2.models.utils.PaddedSequence.autopad.mask", "input_tensors[].size().numel", "len", "len", "d.to", "input_tensors[].size", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.autopad", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.autopad", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.mask", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to"], ["", "def", "forward", "(", "self", ",", "\n", "query", ":", "List", "[", "torch", ".", "tensor", "]", ",", "\n", "document_batch", ":", "List", "[", "torch", ".", "tensor", "]", ")", ":", "\n", "        ", "assert", "len", "(", "query", ")", "==", "len", "(", "document_batch", ")", "\n", "# note about device management:", "\n", "# since distributed training is enabled, the inputs to this module can be on *any* device (preferably cpu, since we wrap and unwrap the module)", "\n", "# we want to keep these params on the input device (assuming CPU) for as long as possible for cheap memory access", "\n", "target_device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "cls_token", "=", "torch", ".", "tensor", "(", "[", "self", ".", "cls_token_id", "]", ")", "#.to(device=document_batch[0].device)", "\n", "sep_token", "=", "torch", ".", "tensor", "(", "[", "self", ".", "sep_token_id", "]", ")", "#.to(device=document_batch[0].device)", "\n", "input_tensors", "=", "[", "]", "\n", "position_ids", "=", "[", "]", "\n", "for", "q", ",", "d", "in", "zip", "(", "query", ",", "document_batch", ")", ":", "\n", "            ", "if", "len", "(", "q", ")", "+", "len", "(", "d", ")", "+", "2", ">", "self", ".", "max_length", ":", "\n", "                ", "d", "=", "d", "[", ":", "(", "self", ".", "max_length", "-", "len", "(", "q", ")", "-", "2", ")", "]", "\n", "", "input_tensors", ".", "append", "(", "torch", ".", "cat", "(", "[", "cls_token", ",", "q", ",", "sep_token", ",", "d", ".", "to", "(", "dtype", "=", "q", ".", "dtype", ")", "]", ")", ")", "\n", "position_ids", ".", "append", "(", "torch", ".", "arange", "(", "0", ",", "input_tensors", "[", "-", "1", "]", ".", "size", "(", ")", ".", "numel", "(", ")", ")", ")", "\n", "#position_ids.append(torch.tensor(list(range(0, len(q) + 1)) + list(range(0, len(d) + 1))))", "\n", "", "bert_input", "=", "PaddedSequence", ".", "autopad", "(", "input_tensors", ",", "batch_first", "=", "True", ",", "padding_value", "=", "self", ".", "pad_token_id", ",", "device", "=", "target_device", ")", "\n", "positions", "=", "PaddedSequence", ".", "autopad", "(", "position_ids", ",", "batch_first", "=", "True", ",", "padding_value", "=", "0", ",", "device", "=", "target_device", ")", "\n", "(", "classes", ",", ")", "=", "self", ".", "bert", "(", "bert_input", ".", "data", ",", "attention_mask", "=", "bert_input", ".", "mask", "(", "on", "=", "1.0", ",", "off", "=", "0.0", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "target_device", ")", ",", "position_ids", "=", "positions", ".", "data", ")", "\n", "assert", "torch", ".", "all", "(", "classes", "==", "classes", ")", "# for nans", "\n", "return", "classes", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_ms2.models.evidence_inference_models.initialize_models": [[15, 68], ["transformers.RobertaTokenizer.from_pretrained", "dict", "bool", "RobertaTokenizer.from_pretrained.get_vocab", "dict", "params.get", "bool", "evidence_inference_models.BertClassifier", "bool", "evidence_inference_models.BertClassifier", "bool", "evidence_inference_models.BertClassifier", "bool", "evidence_inference_models.BertClassifier", "open", "inf.read", "transformers.PretrainedConfig.from_dict", "transformers.PretrainedConfig.from_dict", "params[].get", "params[].get", "params[].get", "params[].get", "enumerate", "json.loads", "json.loads", "len", "len", "tokenizer.get_vocab.items", "len"], "function", ["None"], ["def", "initialize_models", "(", "params", ":", "dict", ",", "unk_token", "=", "'<unk>'", ")", ":", "\n", "    ", "max_length", "=", "params", "[", "'max_length'", "]", "\n", "tokenizer", "=", "RobertaTokenizer", ".", "from_pretrained", "(", "params", "[", "'bert_vocab'", "]", ")", "\n", "#tokenizer = BertTokenizer.from_pretrained(params['bert_vocab'])", "\n", "pad_token_id", "=", "tokenizer", ".", "pad_token_id", "\n", "cls_token_id", "=", "tokenizer", ".", "cls_token_id", "\n", "sep_token_id", "=", "tokenizer", ".", "sep_token_id", "\n", "evidence_classes", "=", "dict", "(", "(", "y", ",", "x", ")", "for", "(", "x", ",", "y", ")", "in", "enumerate", "(", "params", "[", "'evidence_classifier'", "]", "[", "'classes'", "]", ")", ")", "\n", "if", "bool", "(", "params", ".", "get", "(", "'random_init'", ",", "0", ")", ")", ":", "\n", "        ", "with", "open", "(", "params", "[", "'bert_config'", "]", ",", "'r'", ")", "as", "inf", ":", "\n", "            ", "cfg", "=", "inf", ".", "read", "(", ")", "\n", "id_config", "=", "PretrainedConfig", ".", "from_dict", "(", "json", ".", "loads", "(", "cfg", ")", ",", "num_labels", "=", "2", ")", "\n", "cls_config", "=", "PretrainedConfig", ".", "from_dict", "(", "json", ".", "loads", "(", "cfg", ")", ",", "num_labels", "=", "len", "(", "evidence_classes", ")", ")", "\n", "", "use_half_precision", "=", "bool", "(", "params", "[", "'evidence_identifier'", "]", ".", "get", "(", "'use_half_precision'", ",", "0", ")", ")", "\n", "evidence_identifier", "=", "BertClassifier", "(", "bert_dir", "=", "None", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "cls_token_id", "=", "cls_token_id", ",", "\n", "sep_token_id", "=", "sep_token_id", ",", "\n", "num_labels", "=", "2", ",", "\n", "max_length", "=", "max_length", ",", "\n", "use_half_precision", "=", "use_half_precision", ",", "\n", "config", "=", "id_config", ")", "\n", "use_half_precision", "=", "bool", "(", "params", "[", "'evidence_classifier'", "]", ".", "get", "(", "'use_half_precision'", ",", "0", ")", ")", "\n", "evidence_classifier", "=", "BertClassifier", "(", "bert_dir", "=", "None", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "cls_token_id", "=", "cls_token_id", ",", "\n", "sep_token_id", "=", "sep_token_id", ",", "\n", "num_labels", "=", "len", "(", "evidence_classes", ")", ",", "\n", "max_length", "=", "max_length", ",", "\n", "use_half_precision", "=", "use_half_precision", ",", "\n", "config", "=", "cls_config", ")", "\n", "", "else", ":", "\n", "        ", "bert_dir", "=", "params", "[", "'bert_dir'", "]", "\n", "use_half_precision", "=", "bool", "(", "params", "[", "'evidence_identifier'", "]", ".", "get", "(", "'use_half_precision'", ",", "0", ")", ")", "\n", "evidence_identifier", "=", "BertClassifier", "(", "bert_dir", "=", "bert_dir", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "cls_token_id", "=", "cls_token_id", ",", "\n", "sep_token_id", "=", "sep_token_id", ",", "\n", "num_labels", "=", "2", ",", "\n", "max_length", "=", "max_length", ",", "\n", "use_half_precision", "=", "use_half_precision", ")", "\n", "use_half_precision", "=", "bool", "(", "params", "[", "'evidence_classifier'", "]", ".", "get", "(", "'use_half_precision'", ",", "0", ")", ")", "\n", "evidence_classifier", "=", "BertClassifier", "(", "bert_dir", "=", "bert_dir", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "cls_token_id", "=", "cls_token_id", ",", "\n", "sep_token_id", "=", "sep_token_id", ",", "\n", "num_labels", "=", "len", "(", "evidence_classes", ")", ",", "\n", "max_length", "=", "max_length", ",", "\n", "use_half_precision", "=", "use_half_precision", ")", "\n", "", "word_interner", "=", "tokenizer", ".", "get_vocab", "(", ")", "\n", "de_interner", "=", "dict", "(", "(", "x", ",", "y", ")", "for", "(", "y", ",", "x", ")", "in", "word_interner", ".", "items", "(", ")", ")", "\n", "#de_interner = tokenizer.ids_to_tokens", "\n", "return", "evidence_identifier", ",", "evidence_classifier", ",", "word_interner", ",", "de_interner", ",", "evidence_classes", ",", "tokenizer", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.autopad": [[93, 111], ["torch.nn.utils.rnn.pad_sequence", "utils.PaddedSequence.to", "data_.append", "torch.LongTensor", "any", "torch.LongTensor", "len", "d.unsqueeze.unsqueeze.unsqueeze", "ValueError", "utils.PaddedSequence", "d.unsqueeze.unsqueeze.size", "len", "x.size"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to"], ["\n", "identifiers", ":", "List", "[", "Dict", "[", "str", ",", "str", "]", "]", "\n", "metadata", ":", "Dict", "[", "str", ",", "str", "]", "\n", "title", ":", "Optional", "[", "str", "]", "=", "None", "\n", "doi", ":", "Optional", "[", "str", "]", "=", "None", "\n", "pmid", ":", "Optional", "[", "str", "]", "=", "None", "\n", "# these must be populated later", "\n", "s2id", ":", "Optional", "[", "str", "]", "=", "None", "\n", "s2hash", ":", "Optional", "[", "str", "]", "=", "None", "\n", "abstract", ":", "Optional", "[", "str", "]", "=", "None", "\n", "content", ":", "Optional", "[", "str", "]", "=", "None", "\n", "publication_types", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "significances", ":", "Optional", "[", "List", "[", "Significance", "]", "]", "=", "None", "\n", "interventions", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "outcomes", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "populations", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "in_doc_significances", ":", "Optional", "[", "List", "[", "Significance", "]", "]", "=", "None", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.pack_other": [[112, 114], ["torch.nn.utils.rnn.pack_padded_sequence"], "methods", ["None"], ["\n", "", "@", "dataclass_json", "\n", "@", "dataclass", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.from_packed_sequence": [[115, 119], ["torch.nn.utils.rnn.pad_packed_sequence", "utils.PaddedSequence"], "methods", ["None"], ["class", "Study", ":", "\n", "    "]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda": [[120, 122], ["utils.PaddedSequence", "utils.PaddedSequence.data.cuda", "utils.PaddedSequence.batch_sizes.cuda"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda"], []], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to": [[123, 129], ["utils.PaddedSequence", "utils.PaddedSequence.data.to", "utils.PaddedSequence.batch_sizes.to"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to"], ["\n", "references", ":", "List", "[", "Reference", "]", "\n", "identifiers", ":", "List", "[", "Dict", "[", "str", ",", "str", "]", "]", "\n", "metadata", ":", "Dict", "[", "str", ",", "str", "]", "\n", "pmid", ":", "Optional", "[", "str", "]", "=", "None", "\n", "doi", ":", "Optional", "[", "str", "]", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.mask": [[130, 144], ["int", "int", "torch.zeros", "torch.zeros.fill_", "torch.zeros.to", "utils.PaddedSequence.data.size", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to"], ["", "@", "dataclass_json", "\n", "@", "dataclass", "\n", "class", "Review", ":", "\n", "    ", "\"\"\"Systematic Review representation\n\n    All reviews should have a structured abstract, a document name, and title.\n    One would expect to be able to always have access to included studies, and\n    one would be wrong. At least one review exists in the data where no studies\n    could be found, and thus no review was performed\n    \"\"\"", "\n", "docid", ":", "str", "\n", "title", ":", "str", "\n", "authors", ":", "str", "\n", "abstract", ":", "str", "\n", "# the final field is an optional distribution over model labels", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.unpad": [[145, 154], ["isinstance", "zip", "out.append"], "methods", ["None"], ["structured_abstract", ":", "List", "[", "Tuple", "[", "str", ",", "str", ",", "Optional", "[", "Dict", "[", "str", ",", "float", "]", "]", "]", "]", "\n", "summary", ":", "Optional", "[", "str", "]", "\n", "structured_summary", ":", "List", "[", "Tuple", "[", "str", ",", "str", ",", "Optional", "[", "Dict", "[", "str", ",", "float", "]", "]", "]", "]", "\n", "included_studies", ":", "List", "[", "Study", "]", "\n", "ongoing_studies", ":", "List", "[", "Study", "]", "\n", "awaiting_studies", ":", "List", "[", "Study", "]", "\n", "excluded_studies", ":", "List", "[", "Study", "]", "\n", "general_references", ":", "List", "[", "Reference", "]", "\n", "unattributed_references", ":", "Optional", "[", "List", "[", "Reference", "]", "]", "=", "None", "\n", "content", ":", "Optional", "[", "str", "]", "=", "None", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.flip": [[155, 157], ["utils.PaddedSequence", "utils.PaddedSequence.data.transpose"], "methods", ["None"], ["doi", ":", "Optional", "[", "str", "]", "=", "None", "\n", "content", ":", "Optional", "[", "str", "]", "=", "None", "# separate from the abstract", "\n", "s2id", ":", "Optional", "[", "str", "]", "=", "None", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.rouge_scores": [[28, 64], ["rouge_score.rouge_scorer.RougeScorer", "zip", "zip", "refs.extend", "hyps.extend", "rouge_score.scoring.BootstrapAggregator", "isinstance", "isinstance", "rouge_scorer.RougeScorer.score", "scoring.BootstrapAggregator.aggregate", "len", "len", "tokenizer.decode().lower", "tokenizer.decode().lower", "scoring.BootstrapAggregator.add_scores", "scores.append", "list", "tokenizer.decode", "tokenizer.decode"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode"], ["SEP_TOKEN", "=", "'<sep>'", "\n", "EXTRA_TOKENS", "=", "[", "\n", "START_BACKGROUND", ",", "\n", "END_BACKGROUND", ",", "\n", "START_REFERENCE", ",", "\n", "END_REFERENCE", ",", "\n", "SEP_TOKEN", ",", "\n", "START_POPULATION", ",", "\n", "END_POPULATION", ",", "\n", "START_INTERVENTION", ",", "\n", "END_INTERVENTION", ",", "\n", "START_OUTCOME", ",", "\n", "END_OUTCOME", ",", "\n", "START_EVIDENCE", ",", "\n", "END_EVIDENCE", ",", "\n", "]", "\n", "\n", "def", "get_tokenizer", "(", "tokenizer_type", ":", "str", ")", ":", "\n", "    ", "tokenizer", "=", "AutoTokenizer", ".", "from_pretrained", "(", "tokenizer_type", ",", "additional_special_tokens", "=", "EXTRA_TOKENS", ")", "\n", "return", "tokenizer", "\n", "\n", "", "@", "dataclass_json", "\n", "@", "dataclass", "\n", "class", "Significance", ":", "\n", "    ", "intervention", ":", "str", "\n", "outcome", ":", "str", "\n", "classification", ":", "Dict", "[", "str", ",", "float", "]", "\n", "evidence_sentence", ":", "Optional", "[", "str", "]", "=", "None", "\n", "evidence_sentence_score", ":", "Optional", "[", "float", "]", "=", "None", "\n", "\n", "", "@", "dataclass_json", "\n", "@", "dataclass", "\n", "class", "TargetReference", ":", "\n", "    ", "title_abstract", ":", "Union", "[", "torch", ".", "Tensor", ",", "str", "]", "\n", "full_text", ":", "Optional", "[", "Union", "[", "torch", ".", "Tensor", ",", "List", "[", "int", "]", ",", "str", "]", "]", "\n", "s2id", ":", "Optional", "[", "str", "]", "\n", "s2hash", ":", "Optional", "[", "str", "]", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.pad_tensors": [[65, 73], ["torch.nn.utils.rnn.pad_sequence", "data_.append", "len", "d.unsqueeze.unsqueeze", "d.unsqueeze.size"], "function", ["None"], ["\n", "", "@", "dataclass_json", "\n", "@", "dataclass", "\n", "class", "TargetSummary", ":", "\n", "    ", "\"\"\"Target input/output for a summarization model\n\n    Preface:\n    \"\"\"", "\n", "preface", ":", "Optional", "[", "Union", "[", "str", ",", "List", "[", "int", "]", ",", "torch", ".", "Tensor", "]", "]", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.utils.mangle_bart_with_longformer": [[158, 212], ["enumerate", "torch.cat().clone", "LearnedPositionalEmbedding", "torch.nn.Parameter", "torch.cat().clone", "LearnedPositionalEmbedding", "torch.nn.Parameter", "len", "len", "utils.mangle_bart_with_longformer.replace_layers"], "function", ["None"], ["s2hash", ":", "Optional", "[", "str", "]", "=", "None", "\n", "pmid", ":", "Optional", "[", "str", "]", "=", "None", "\n", "interventions", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "outcomes", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "populations", ":", "Optional", "[", "List", "[", "str", "]", "]", "=", "None", "\n", "significances", ":", "Optional", "[", "List", "[", "Significance", "]", "]", "=", "None", "\n", "\n", "def", "__post_init__", "(", "self", ")", ":", "\n", "        ", "assert", "self", ".", "docid", "is", "not", "None", "\n", "assert", "self", ".", "title", "is", "not", "None", "\n", "assert", "self", ".", "abstract", "is", "not", "None", "and", "len", "(", "self", ".", "abstract", ".", "strip", "(", ")", ")", ">", "0", "\n", "#assert len(self.structured_abstract) > 0", "\n", "\n", "", "def", "extract_references", "(", "self", ")", "->", "List", "[", "Reference", "]", ":", "\n", "        ", "studies", "=", "itertools", ".", "chain", ".", "from_iterable", "(", "[", "\n", "self", ".", "included_studies", ",", "\n", "self", ".", "ongoing_studies", ",", "\n", "self", ".", "excluded_studies", ",", "\n", "self", ".", "awaiting_studies", ",", "\n", "]", ")", "\n", "study_refs", "=", "itertools", ".", "chain", ".", "from_iterable", "(", "map", "(", "lambda", "x", ":", "x", ".", "references", ",", "studies", ")", ")", "\n", "all_refs", "=", "list", "(", "study_refs", ")", "+", "self", ".", "general_references", "+", "self", ".", "unattributed_references", "\n", "return", "all_refs", "\n", "\n", "", "@", "staticmethod", "\n", "def", "read_reviews", "(", "f", ")", "->", "List", "[", "'Review'", "]", ":", "\n", "        ", "with", "open", "(", "f", ",", "'r'", ")", "as", "inf", ":", "\n", "            ", "inf", "=", "filter", "(", "lambda", "line", ":", "len", "(", "line", ".", "strip", "(", ")", ")", ">", "0", ",", "inf", ")", "\n", "reviews", "=", "map", "(", "Review", ".", "from_json", ",", "inf", ")", "\n", "reviews", "=", "list", "(", "reviews", ")", "\n", "", "return", "reviews", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.ReferenceInteractingBartSummarizer.__init__": [[42, 55], ["torch.Module.__init__", "transformers.AutoConfig.from_pretrained", "transformers.BartForConditionalGeneration.from_pretrained", "transformer_summarizer.ReferenceInteractingBartSummarizer.model.resize_token_embeddings", "len", "tokenizer.get_vocab"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_type", ",", "tokenizer", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "model_type", ")", "\n", "config", ".", "attention_dropout", "=", "args", ".", "attention_dropout", "\n", "config", ".", "gradient_checkpointing", "=", "args", ".", "grad_ckpt", "\n", "if", "model_type", "==", "'facebook/bart-base'", ":", "# bug in HF configuration", "\n", "            ", "config", ".", "encoder_attention_heads", "=", "12", "\n", "config", ".", "decoder_attention_heads", "=", "12", "\n", "", "self", ".", "model", "=", "BartForConditionalGeneration", ".", "from_pretrained", "(", "model_type", ",", "config", "=", "config", ")", "\n", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ".", "get_vocab", "(", ")", ")", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "config", "=", "self", ".", "model", ".", "config", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.ReferenceInteractingBartSummarizer._encode_multiple": [[56, 98], ["preamble.repeat.repeat.repeat", "transformer_summarizer.ReferenceInteractingBartSummarizer.model.model.encoder", "torch.masked_select().unsqueeze", "torch.masked_select().unsqueeze", "torch.masked_select().unsqueeze", "torch.masked_select().unsqueeze", "torch.masked_select().reshape", "torch.masked_select().reshape", "torch.masked_select().reshape", "torch.masked_select().reshape", "torch.any", "torch.any", "torch.any", "torch.any", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "len", "tuple", "tuple", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "RuntimeError", "inputs.size", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "encoded.size", "transformers.modeling_outputs.BaseModelOutput", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "torch.masked_select", "selection_mask.unsqueeze"], "methods", ["None"], ["", "def", "_encode_multiple", "(", "\n", "self", ",", "\n", "inputs", ":", "torch", ".", "LongTensor", ",", "\n", "preamble", ":", "torch", ".", "LongTensor", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "return_dict", "=", "False", "\n", ")", ":", "\n", "        ", "\"\"\"\n        inputs: Padded reference texts\n        preamble: single beginning/prompt\n        \"\"\"", "\n", "inputs", "=", "inputs", "[", ":", "self", ".", "args", ".", "max_num_refs", "]", "\n", "preamble", "=", "preamble", ".", "repeat", "(", "inputs", ".", "size", "(", ")", "[", "0", "]", ",", "1", ")", "\n", "encoder_input", "=", "torch", ".", "cat", "(", "[", "preamble", ",", "inputs", "]", ",", "dim", "=", "1", ")", "[", ":", ",", ":", "self", ".", "config", ".", "max_position_embeddings", "]", "\n", "encoder_outputs", "=", "self", ".", "model", ".", "model", ".", "encoder", "(", "\n", "encoder_input", ",", "\n", "output_attentions", "=", "output_attentions", ",", "\n", "output_hidden_states", "=", "output_hidden_states", ",", "\n", "attention_mask", "=", "None", ",", "\n", "return_dict", "=", "False", "\n", ")", "\n", "selection_mask", "=", "encoder_input", "!=", "self", ".", "config", ".", "pad_token_id", "\n", "input_ids", "=", "torch", ".", "masked_select", "(", "encoder_input", ",", "selection_mask", ")", ".", "unsqueeze", "(", "0", ")", "\n", "if", "len", "(", "encoder_outputs", ")", "==", "1", ":", "\n", "            ", "encoded", "=", "encoder_outputs", "[", "0", "]", "\n", "encoder_states", ",", "all_attentions", "=", "None", ",", "None", "\n", "", "else", ":", "\n", "            ", "encoded", ",", "encoder_states", ",", "all_attentions", "=", "encoder_outputs", "\n", "encoder_states", "=", "tuple", "(", "torch", ".", "masked_select", "(", "hs", ",", "selection_mask", ")", "for", "hs", "in", "encoder_states", ")", "\n", "all_attentions", "=", "tuple", "(", "torch", ".", "masked_select", "(", "attn", ",", "selection_mask", ")", "for", "attn", "in", "all_attentions", ")", "\n", "", "encoded_sequences", "=", "torch", ".", "masked_select", "(", "encoded", ",", "selection_mask", ".", "unsqueeze", "(", "-", "1", ")", ")", ".", "reshape", "(", "1", ",", "-", "1", ",", "encoded", ".", "size", "(", ")", "[", "-", "1", "]", ")", "\n", "if", "torch", ".", "any", "(", "torch", ".", "isnan", "(", "encoded", ")", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Found nans while encoding inputs!'", ")", "\n", "", "if", "return_dict", ":", "\n", "            ", "return", "input_ids", ",", "BaseModelOutput", "(", "\n", "last_hidden_state", "=", "encoded_sequences", ",", "\n", "hidden_states", "=", "encoder_states", ",", "\n", "attentions", "=", "all_attentions", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "return", "input_ids", ",", "(", "encoded_sequences", ",", "encoder_states", ",", "all_attentions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.ReferenceInteractingBartSummarizer.forward": [[99, 149], ["targets[].contiguous", "targets[].clone", "transformers.modeling_bart._prepare_bart_decoder_inputs", "transformer_summarizer.ReferenceInteractingBartSummarizer._encode_multiple", "torch.any", "torch.any", "torch.any", "torch.any", "transformer_summarizer.ReferenceInteractingBartSummarizer.model.model.decoder", "torch.any", "torch.any", "torch.any", "torch.any", "torch.nn.functional.linear", "torch.nn.functional.linear", "torch.any", "torch.any", "torch.any", "torch.any", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss.", "torch.any", "torch.any", "torch.any", "torch.any", "masked_lm_loss.mean.mean.mean", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "RuntimeError", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "RuntimeError", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "RuntimeError", "torch.nn.functional.linear.view", "targets[].clone.view", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.ReferenceInteractingBartSummarizer._encode_multiple"], ["", "", "def", "forward", "(", "self", ",", "inputs", ":", "torch", ".", "Tensor", ",", "preambles", ":", "torch", ".", "Tensor", ",", "targets", ":", "torch", ".", "Tensor", ")", ":", "\n", "# prep the decoder inputs and the loss labels and masks", "\n", "# Note that `lm_labels` is similar to `decoder_input_ids` but shifted one step to the left.", "\n", "# There's also a small difference in the use of <s> and </s> as shown in the following example", "\n", "# For example,", "\n", "#   decoder_input_ids = '<s> some text .'", "\n", "#   lm_labels         = ' some text .</s>'", "\n", "        ", "targets", "=", "targets", "[", ":", ",", ":", "self", ".", "args", ".", "max_length", "]", "# limit target length for memory", "\n", "decoder_input_ids", "=", "targets", "[", ":", ",", ":", "-", "1", "]", ".", "contiguous", "(", ")", "\n", "lm_labels", "=", "targets", "[", ":", ",", "1", ":", "]", ".", "clone", "(", ")", "\n", "\n", "decoder_input_ids", ",", "decoder_padding_mask", ",", "causal_mask", "=", "_prepare_bart_decoder_inputs", "(", "\n", "self", ".", "model", ".", "config", ",", "\n", "None", ",", "# this would be the input ids but we very much do not want them here", "\n", "decoder_input_ids", "=", "decoder_input_ids", ",", "\n", "decoder_padding_mask", "=", "None", ",", "\n", "causal_mask_dtype", "=", "self", ".", "model", ".", "model", ".", "shared", ".", "weight", ".", "dtype", ",", "\n", ")", "\n", "_", ",", "(", "encoded_sequences", ",", "_", ",", "_", ")", "=", "self", ".", "_encode_multiple", "(", "inputs", ",", "preambles", ",", "return_dict", "=", "False", ")", "\n", "if", "torch", ".", "any", "(", "torch", ".", "isnan", "(", "encoded_sequences", ".", "data", ")", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Found nans while encoding inputs!'", ")", "\n", "\n", "# decoder output!", "\n", "", "decoder_outputs", "=", "self", ".", "model", ".", "model", ".", "decoder", "(", "\n", "input_ids", "=", "decoder_input_ids", ",", "\n", "encoder_hidden_states", "=", "encoded_sequences", ",", "\n", "encoder_padding_mask", "=", "None", ",", "\n", "decoder_padding_mask", "=", "decoder_padding_mask", ",", "\n", "decoder_causal_mask", "=", "causal_mask", ",", "\n", "decoder_cached_states", "=", "None", ",", "\n", "output_attentions", "=", "False", ",", "\n", "output_hidden_states", "=", "False", ",", "\n", "use_cache", "=", "False", ",", "\n", ")", "\n", "if", "torch", ".", "any", "(", "torch", ".", "isnan", "(", "decoder_outputs", "[", "0", "]", ")", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Found nans while decoding!'", ")", "\n", "\n", "", "lm_logits", "=", "F", ".", "linear", "(", "decoder_outputs", "[", "0", "]", ",", "self", ".", "model", ".", "model", ".", "shared", ".", "weight", ",", "bias", "=", "self", ".", "model", ".", "final_logits_bias", ")", "\n", "if", "torch", ".", "any", "(", "torch", ".", "isnan", "(", "lm_logits", ")", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Found nans while predicting lm weights!'", ")", "\n", "", "outputs", "=", "(", "lm_logits", ",", ")", "+", "decoder_outputs", "[", "1", ":", "]", "# Add cache, hidden states and attention if they are here", "\n", "loss_fct", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "# Note: masking will need to be re-added if bs > 1 (currently not possible!)", "\n", "masked_lm_loss", "=", "loss_fct", "(", "lm_logits", ".", "view", "(", "-", "1", ",", "self", ".", "model", ".", "config", ".", "vocab_size", ")", ",", "lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "if", "torch", ".", "any", "(", "torch", ".", "isnan", "(", "masked_lm_loss", ")", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Invalid loss!'", ")", "\n", "", "masked_lm_loss", "=", "masked_lm_loss", ".", "mean", "(", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.ReferenceInteractingBartSummarizer.generate_summary": [[150, 414], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "isinstance", "isinstance", "isinstance", "hasattr", "hasattr", "callable", "transformer_summarizer.ReferenceInteractingBartSummarizer._encode_multiple", "transformer_summarizer.ReferenceInteractingBartSummarizer.model.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "logging.warning", "torch.full.unsqueeze().expand", "torch.full.unsqueeze().expand", "torch.full.contiguous().view", "torch.full.contiguous().view", "torch.full", "torch.full", "torch.full", "torch.full", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "torch.arange().view().repeat().view().to", "encoder_outputs.last_hidden_state.index_select", "transformer_summarizer.ReferenceInteractingBartSummarizer.model._generate_beam_search", "transformer_summarizer.ReferenceInteractingBartSummarizer.model._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "isinstance", "hasattr", "hasattr", "hasattr", "hasattr", "ValueError", "torch.full.unsqueeze", "torch.full.unsqueeze", "torch.full.contiguous", "torch.full.contiguous", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "torch.arange().view().repeat().view", "next", "transformer_summarizer.ReferenceInteractingBartSummarizer.parameters", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view().repeat", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange().view", "torch.arange", "torch.arange", "torch.arange", "torch.arange"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.ReferenceInteractingBartSummarizer._encode_multiple", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.to"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate_summary", "(", "\n", "self", ",", "\n", "inputs", ":", "torch", ".", "Tensor", ",", "\n", "preambles", ":", "torch", ".", "Tensor", ",", "\n", "max_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "min_length", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "do_sample", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "early_stopping", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "num_beams", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "temperature", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "top_k", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "top_p", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "repetition_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "bad_words_ids", ":", "Optional", "[", "Iterable", "[", "int", "]", "]", "=", "None", ",", "\n", "bos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "pad_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "eos_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "length_penalty", ":", "Optional", "[", "float", "]", "=", "None", ",", "\n", "no_repeat_ngram_size", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "num_return_sequences", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "attention_mask", ":", "Optional", "[", "torch", ".", "LongTensor", "]", "=", "None", ",", "\n", "decoder_start_token_id", ":", "Optional", "[", "int", "]", "=", "None", ",", "\n", "use_cache", ":", "Optional", "[", "bool", "]", "=", "None", ",", "\n", "**", "model_kwargs", "\n", ")", "->", "torch", ".", "LongTensor", ":", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "        ", "if", "self", ".", "model", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`, `XLMWithLMHeadModel`, `BartForConditionalGeneration` )\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "min_length", "=", "min_length", "if", "min_length", "is", "not", "None", "else", "self", ".", "config", ".", "min_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "early_stopping", "=", "early_stopping", "if", "early_stopping", "is", "not", "None", "else", "self", ".", "config", ".", "early_stopping", "\n", "use_cache", "=", "use_cache", "if", "use_cache", "is", "not", "None", "else", "self", ".", "config", ".", "use_cache", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_id", "=", "eos_token_id", "if", "eos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_id", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "no_repeat_ngram_size", "=", "(", "\n", "no_repeat_ngram_size", "if", "no_repeat_ngram_size", "is", "not", "None", "else", "self", ".", "config", ".", "no_repeat_ngram_size", "\n", ")", "\n", "bad_words_ids", "=", "bad_words_ids", "if", "bad_words_ids", "is", "not", "None", "else", "self", ".", "config", ".", "bad_words_ids", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "decoder_start_token_id", "=", "(", "\n", "decoder_start_token_id", "if", "decoder_start_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "decoder_start_token_id", "\n", ")", "\n", "\n", "# just decode one at a time for sanity's sake!", "\n", "batch_size", "=", "1", "\n", "#if input_ids is not None:", "\n", "#    batch_size = input_ids.shape[0]  # overriden by the input batch_size", "\n", "#else:", "\n", "#    batch_size = 1", "\n", "\n", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictly positive integer.\"", "\n", "assert", "isinstance", "(", "min_length", ",", "int", ")", "and", "min_length", ">=", "0", ",", "\"`min_length` should be a positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "early_stopping", ",", "bool", ")", ",", "\"`early_stopping` should be a boolean.\"", "\n", "assert", "isinstance", "(", "use_cache", ",", "bool", ")", ",", "\"`use_cache` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictly positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictly positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "inputs", "is", "not", "None", "or", "preambles", "is", "not", "None", "\n", "assert", "inputs", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If inputs is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_id", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_id", ",", "int", ")", "and", "(", "eos_token_id", ">=", "0", ")", "\n", ")", ",", "\"`eos_token_id` should be a positive integer.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictly positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "no_repeat_ngram_size", ",", "int", ")", "and", "no_repeat_ngram_size", ">=", "0", "\n", ")", ",", "\"`no_repeat_ngram_size` should be a positive integer.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictly positive integer.\"", "\n", "assert", "(", "\n", "bad_words_ids", "is", "None", "or", "isinstance", "(", "bad_words_ids", ",", "list", ")", "and", "isinstance", "(", "bad_words_ids", "[", "0", "]", ",", "list", ")", "\n", ")", ",", "\"`bad_words_ids` is either `None` or a list of lists of tokens that should not be generated\"", "\n", "\n", "# not allow to duplicate outputs when greedy decoding", "\n", "if", "do_sample", "is", "False", ":", "\n", "            ", "if", "num_beams", "==", "1", ":", "\n", "# no_beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_return_sequences", "==", "1", "\n", ")", ",", "\"Greedy decoding will always produce the same output for num_beams == 1 and num_return_sequences > 1. Please set num_return_sequences = 1\"", "\n", "\n", "", "else", ":", "\n", "# beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_beams", ">=", "num_return_sequences", "\n", ")", ",", "\"Greedy beam search decoding cannot return more sequences than it has beams. Please set num_beams >= num_return_sequences\"", "\n", "\n", "# create attention mask if necessary", "\n", "# TODO (PVP): this should later be handled by the forward fn() in each model in the future see PR 3140", "\n", "# if (attention_mask is None) and (pad_token_id is not None) and (pad_token_id in input_ids):", "\n", "#    attention_mask = input_ids.ne(pad_token_id).long()", "\n", "# elif attention_mask is None:", "\n", "#    attention_mask = input_ids.new_ones(input_ids.shape)", "\n", "\n", "# set pad_token_id to eos_token_id if not set. Important that this is done after", "\n", "# attention_mask is created", "\n", "", "", "if", "pad_token_id", "is", "None", "and", "eos_token_id", "is", "not", "None", ":", "\n", "            ", "logging", ".", "warning", "(", "\n", "\"Setting `pad_token_id` to {} (first `eos_token_id`) to generate sequence\"", ".", "format", "(", "eos_token_id", ")", "\n", ")", "\n", "pad_token_id", "=", "eos_token_id", "\n", "\n", "# current position and vocab size", "\n", "", "if", "hasattr", "(", "self", ".", "config", ",", "\"vocab_size\"", ")", ":", "\n", "            ", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "", "elif", "(", "\n", "self", ".", "config", ".", "is_encoder_decoder", "\n", "and", "hasattr", "(", "self", ".", "config", ",", "\"decoder\"", ")", "\n", "and", "hasattr", "(", "self", ".", "config", ".", "decoder", ",", "\"vocab_size\"", ")", "\n", ")", ":", "\n", "            ", "vocab_size", "=", "self", ".", "config", ".", "decoder", ".", "vocab_size", "\n", "\n", "# set effective batch size and effective batch multiplier according to do_sample", "\n", "", "if", "do_sample", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "effective_batch_mult", "=", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "effective_batch_mult", "=", "1", "\n", "\n", "", "assert", "self", ".", "config", ".", "is_encoder_decoder", "\n", "if", "decoder_start_token_id", "is", "None", ":", "\n", "# see if BOS token can be used for decoder_start_token_id", "\n", "            ", "if", "bos_token_id", "is", "not", "None", ":", "\n", "                ", "decoder_start_token_id", "=", "bos_token_id", "\n", "", "elif", "hasattr", "(", "self", ".", "config", ",", "\"decoder\"", ")", "and", "hasattr", "(", "self", ".", "config", ".", "decoder", ",", "\"bos_token_id\"", ")", ":", "\n", "                ", "decoder_start_token_id", "=", "self", ".", "config", ".", "decoder", ".", "bos_token_id", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "\n", "\"decoder_start_token_id or bos_token_id has to be defined for encoder-decoder generation\"", "\n", ")", "\n", "\n", "", "", "assert", "hasattr", "(", "self", ".", "model", ",", "\"get_encoder\"", ")", ",", "\"{} should have a 'get_encoder' function defined\"", ".", "format", "(", "self", ".", "model", ")", "\n", "assert", "callable", "(", "self", ".", "model", ".", "get_encoder", ")", ",", "\"{} should be a method\"", ".", "format", "(", "self", ".", "model", ".", "get_encoder", ")", "\n", "\n", "# get encoder and store encoder outputs", "\n", "encoder_outputs", ":", "ModelOutput", "\n", "input_ids", ",", "encoder_outputs", "=", "self", ".", "_encode_multiple", "(", "inputs", ",", "preambles", ",", "return_dict", "=", "True", ")", "\n", "\n", "# Expand input ids if num_beams > 1 or num_return_sequences > 1", "\n", "if", "num_return_sequences", ">", "1", "or", "num_beams", ">", "1", ":", "\n", "            ", "input_ids_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "effective_batch_mult", "*", "num_beams", ",", "input_ids_len", ")", "\n", "#attention_mask = attention_mask.unsqueeze(1).expand(", "\n", "#    batch_size, effective_batch_mult * num_beams, input_ids_len", "\n", "#)", "\n", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "effective_batch_size", "*", "num_beams", ",", "input_ids_len", "\n", ")", "# shape: (batch_size * num_return_sequences * num_beams, cur_len)", "\n", "#attention_mask = attention_mask.contiguous().view(", "\n", "#    effective_batch_size * num_beams, input_ids_len", "\n", "#)  # shape: (batch_size * num_return_sequences * num_beams, cur_len)", "\n", "\n", "", "attention_mask", "=", "None", "\n", "if", "self", ".", "config", ".", "is_encoder_decoder", ":", "\n", "# create empty decoder_input_ids", "\n", "            ", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "effective_batch_size", "*", "num_beams", ",", "1", ")", ",", "\n", "decoder_start_token_id", ",", "\n", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ",", "\n", ")", "\n", "cur_len", "=", "1", "\n", "\n", "assert", "(", "\n", "batch_size", "==", "encoder_outputs", ".", "last_hidden_state", ".", "shape", "[", "0", "]", "\n", ")", ",", "f\"expected encoder_outputs.last_hidden_state to have 1st dimension bs={batch_size}, got {encoder_outputs.last_hidden_state.shape[0]} \"", "\n", "\n", "# expand batch_idx to assign correct encoder output for expanded input_ids (due to num_beams > 1 and num_return_sequences > 1)", "\n", "expanded_batch_idxs", "=", "(", "\n", "torch", ".", "arange", "(", "batch_size", ")", "\n", ".", "view", "(", "-", "1", ",", "1", ")", "\n", ".", "repeat", "(", "1", ",", "num_beams", "*", "effective_batch_mult", ")", "\n", ".", "view", "(", "-", "1", ")", "\n", ".", "to", "(", "input_ids", ".", "device", ")", "\n", ")", "\n", "\n", "# expand encoder_outputs", "\n", "encoder_outputs", "[", "\"last_hidden_state\"", "]", "=", "encoder_outputs", ".", "last_hidden_state", ".", "index_select", "(", "\n", "0", ",", "expanded_batch_idxs", "\n", ")", "\n", "\n", "# save encoder_outputs in `model_kwargs`", "\n", "model_kwargs", "[", "\"encoder_outputs\"", "]", "=", "encoder_outputs", "\n", "\n", "", "else", ":", "\n", "            ", "cur_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "\n", "", "assert", "(", "\n", "cur_len", "<", "max_length", "\n", ")", ",", "f\"The context has {cur_len} number of tokens, but `max_length` is only {max_length}. Please make sure that `max_length` is bigger than the number of tokens, by setting either `generate(max_length=...,...)` or `config.max_length = ...`\"", "\n", "\n", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "model", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", "=", "cur_len", ",", "\n", "max_length", "=", "max_length", ",", "\n", "min_length", "=", "min_length", ",", "\n", "do_sample", "=", "do_sample", ",", "\n", "early_stopping", "=", "early_stopping", ",", "\n", "temperature", "=", "temperature", ",", "\n", "top_k", "=", "top_k", ",", "\n", "top_p", "=", "top_p", ",", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "batch_size", "=", "effective_batch_size", ",", "\n", "num_return_sequences", "=", "num_return_sequences", ",", "\n", "length_penalty", "=", "length_penalty", ",", "\n", "num_beams", "=", "num_beams", ",", "\n", "vocab_size", "=", "vocab_size", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "model_kwargs", "=", "model_kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "model", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", "=", "cur_len", ",", "\n", "max_length", "=", "max_length", ",", "\n", "min_length", "=", "min_length", ",", "\n", "do_sample", "=", "do_sample", ",", "\n", "temperature", "=", "temperature", ",", "\n", "top_k", "=", "top_k", ",", "\n", "top_p", "=", "top_p", ",", "\n", "repetition_penalty", "=", "repetition_penalty", ",", "\n", "no_repeat_ngram_size", "=", "no_repeat_ngram_size", ",", "\n", "bad_words_ids", "=", "bad_words_ids", ",", "\n", "pad_token_id", "=", "pad_token_id", ",", "\n", "eos_token_id", "=", "eos_token_id", ",", "\n", "batch_size", "=", "effective_batch_size", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "use_cache", "=", "use_cache", ",", "\n", "model_kwargs", "=", "model_kwargs", ",", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.ReferenceInteractingBartSummarizer.collate_fn": [[415, 418], ["inst.preface.unsqueeze", "inst.target.unsqueeze"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ":", "List", "[", "ReviewDataset", ".", "Instance", "]", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "(", "inst", ",", ")", "=", "batch", "\n", "return", "inst", ".", "refs", ",", "inst", ".", "preface", ".", "unsqueeze", "(", "0", ")", ",", "inst", ".", "target", ".", "unsqueeze", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.__init__": [[424, 447], ["pytorch_lightning.core.lightning.LightningModule.__init__", "transformer_summarizer.LightningBartSummarizer.save_hyperparameters", "ms2.utils.get_tokenizer", "transformer_summarizer.SingleStreamBartSummarizer", "transformer_summarizer.ReferenceInteractingBartSummarizer"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__", "home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.get_tokenizer"], ["    ", "def", "__init__", "(", "self", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "save_hyperparameters", "(", ")", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "tokenizer", "=", "get_tokenizer", "(", "'facebook/bart-base'", ")", "\n", "if", "'long'", "in", "args", ".", "model_name", ":", "\n", "            ", "self", ".", "summarizer", "=", "SingleStreamBartSummarizer", "(", "args", ".", "model_name", ",", "self", ".", "tokenizer", ",", "args", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "summarizer", "=", "ReferenceInteractingBartSummarizer", "(", "args", ".", "model_name", ",", "self", ".", "tokenizer", ",", "args", ")", "\n", "\n", "", "self", ".", "config", "=", "self", ".", "summarizer", ".", "config", "\n", "self", ".", "generation_params", "=", "{", "\n", "'num_beams'", ":", "args", ".", "num_beams", ",", "\n", "'length_penalty'", ":", "args", ".", "length_penalty", ",", "\n", "'no_repeat_ngram_size'", ":", "args", ".", "no_repeat_ngram_size", ",", "\n", "'early_stopping'", ":", "True", ",", "\n", "'decoder_start_token_id'", ":", "self", ".", "config", ".", "bos_token_id", ",", "\n", "'min_length'", ":", "args", ".", "min_length", ",", "\n", "'max_length'", ":", "args", ".", "max_length", ",", "\n", "'temperature'", ":", "args", ".", "temperature", ",", "\n", "'repetition_penalty'", ":", "args", ".", "repetition_penalty", ",", "\n", "}", "\n", "self", ".", "predictions_file", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.forward": [[448, 450], ["transformer_summarizer.LightningBartSummarizer.summarizer.forward"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "preambles", ",", "targets", ")", ":", "\n", "        ", "return", "self", ".", "summarizer", ".", "forward", "(", "inputs", "=", "inputs", ",", "preambles", "=", "preambles", ",", "targets", "=", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.generate_summary": [[451, 459], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "transformer_summarizer.LightningBartSummarizer.summarizer.parameters", "transformer_summarizer.LightningBartSummarizer.summarizer.generate_summary", "transformer_summarizer.LightningBartSummarizer.summarizer.parameters"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.generate_summary"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate_summary", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", "->", "torch", ".", "LongTensor", ":", "\n", "        ", "for", "p", "in", "self", ".", "summarizer", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "ret", "=", "self", ".", "summarizer", ".", "generate_summary", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "for", "p", "in", "self", ".", "summarizer", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "True", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.training_step": [[460, 472], ["transformer_summarizer.LightningBartSummarizer.forward", "loss.new_zeros"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward"], ["", "def", "training_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "forward", "(", "*", "batch", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "\n", "output", "=", "{", "\n", "'loss'", ":", "loss", ",", "\n", "'train_loss'", ":", "loss", ",", "\n", "'log'", ":", "{", "\n", "'train_loss'", ":", "loss", ",", "\n", "'lr'", ":", "loss", ".", "new_zeros", "(", "1", ")", "+", "self", ".", "trainer", ".", "optimizers", "[", "0", "]", ".", "param_groups", "[", "0", "]", "[", "'lr'", "]", ",", "\n", "}", ",", "\n", "}", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.validation_step": [[473, 501], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "transformer_summarizer.LightningBartSummarizer.summarizer.parameters", "transformer_summarizer.LightningBartSummarizer.forward", "transformer_summarizer.LightningBartSummarizer.summarizer.parameters", "transformer_summarizer.LightningBartSummarizer.generate_summary", "loss.cpu", "len", "len", "list", "list", "loss.cpu", "x.cpu", "torch.argmax().detach().cpu", "torch.argmax().detach().cpu", "torch.argmax().detach().cpu", "torch.argmax().detach().cpu", "map", "map", "x.cpu", "x.cpu", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax().detach", "torch.argmax", "torch.argmax", "torch.argmax", "torch.argmax"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward", "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.generate_summary"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "validation_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "for", "p", "in", "self", ".", "summarizer", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "outputs", "=", "self", ".", "forward", "(", "*", "batch", ")", "\n", "for", "p", "in", "self", ".", "summarizer", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "True", "\n", "", "loss", "=", "outputs", "[", "0", "]", "\n", "lm_logits", "=", "outputs", "[", "1", "]", "\n", "generations", "=", "self", ".", "generate_summary", "(", "\n", "batch", "[", "0", "]", ",", "\n", "batch", "[", "1", "]", ",", "\n", "**", "self", ".", "generation_params", ",", "\n", ")", "\n", "targets", "=", "batch", "[", "2", "]", "\n", "output", "=", "{", "\n", "'val_loss'", ":", "loss", ".", "cpu", "(", ")", ",", "\n", "'progress_bar'", ":", "{", "\n", "'val_loss'", ":", "loss", ".", "cpu", "(", ")", ",", "\n", "}", ",", "\n", "'preambles'", ":", "[", "x", ".", "cpu", "(", ")", "for", "x", "in", "batch", "[", "1", "]", "]", ",", "\n", "'generations'", ":", "[", "[", "x", ".", "cpu", "(", ")", "]", "for", "x", "in", "generations", "]", ",", "\n", "'teacher_forced_generations'", ":", "[", "torch", ".", "argmax", "(", "lm_logits", ",", "dim", "=", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", "]", ",", "\n", "'targets'", ":", "[", "[", "x", ".", "cpu", "(", ")", "]", "for", "x", "in", "targets", "]", ",", "\n", "}", "\n", "assert", "len", "(", "output", "[", "'generations'", "]", ")", "==", "len", "(", "output", "[", "'targets'", "]", ")", "\n", "assert", "list", "(", "map", "(", "len", ",", "output", "[", "'generations'", "]", ")", ")", "==", "list", "(", "map", "(", "len", ",", "output", "[", "'targets'", "]", ")", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.validation_epoch_end": [[502, 557], ["numpy.mean", "transformer_summarizer.LightningBartSummarizer._accumulate_generations", "ms2.models.utils.rouge_scores", "ms2.models.utils.rouge_scores", "transformer_summarizer.LightningBartSummarizer.items", "ms2.models.utils.rouge_scores.items", "output.items", "len", "transformer_summarizer.LightningBartSummarizer._evidence_inference_score", "transformer_summarizer.LightningBartSummarizer.items", "isinstance", "j.items"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._accumulate_generations", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.rouge_scores", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.rouge_scores", "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._evidence_inference_score"], ["", "def", "validation_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "losses", "=", "np", ".", "mean", "(", "[", "output", "[", "'val_loss'", "]", "for", "output", "in", "outputs", "]", ")", "\n", "generated", ",", "teacher_forced_generations", ",", "targets", "=", "self", ".", "_accumulate_generations", "(", "outputs", ")", "\n", "assert", "len", "(", "generated", ")", ">", "0", "\n", "scores", "=", "rouge_scores", "(", "generated", ",", "targets", ",", "self", ".", "summarizer", ".", "tokenizer", ",", "use_aggregator", "=", "True", ")", "\n", "tf_scores", "=", "rouge_scores", "(", "teacher_forced_generations", ",", "targets", ",", "self", ".", "summarizer", ".", "tokenizer", ",", "use_aggregator", "=", "True", ")", "\n", "# TODO: if self.use_ddp: sync val_loss and rouge scores across GPUs", "\n", "output", "=", "{", "\n", "'val_loss'", ":", "losses", ",", "\n", "'log'", ":", "{", "\n", "'val_loss'", ":", "losses", ",", "\n", "}", ",", "\n", "}", "\n", "for", "rouge_type", ",", "prf_scores", "in", "scores", ".", "items", "(", ")", ":", "\n", "            ", "output", "[", "'val_'", "+", "rouge_type", "+", "'_p'", "]", "=", "prf_scores", ".", "mid", ".", "precision", "\n", "output", "[", "'val_'", "+", "rouge_type", "+", "'_r'", "]", "=", "prf_scores", ".", "mid", ".", "recall", "\n", "output", "[", "'val_'", "+", "rouge_type", "+", "'_f'", "]", "=", "prf_scores", ".", "mid", ".", "fmeasure", "\n", "output", "[", "'log'", "]", "[", "'val_'", "+", "rouge_type", "+", "'_p'", "]", "=", "prf_scores", ".", "mid", ".", "precision", "\n", "output", "[", "'log'", "]", "[", "'val_'", "+", "rouge_type", "+", "'_r'", "]", "=", "prf_scores", ".", "mid", ".", "recall", "\n", "output", "[", "'log'", "]", "[", "'val_'", "+", "rouge_type", "+", "'_f'", "]", "=", "prf_scores", ".", "mid", ".", "fmeasure", "\n", "", "for", "rouge_type", ",", "prf_scores", "in", "tf_scores", ".", "items", "(", ")", ":", "\n", "            ", "output", "[", "'val_tf'", "+", "rouge_type", "+", "'_p'", "]", "=", "prf_scores", ".", "mid", ".", "precision", "\n", "output", "[", "'val_tf'", "+", "rouge_type", "+", "'_r'", "]", "=", "prf_scores", ".", "mid", ".", "recall", "\n", "output", "[", "'val_tf'", "+", "rouge_type", "+", "'_f'", "]", "=", "prf_scores", ".", "mid", ".", "fmeasure", "\n", "", "output", "[", "'progress_bar'", "]", "=", "{", "\n", "'val_loss'", ":", "losses", ",", "\n", "'val_rougeL_f'", ":", "output", "[", "'val_rougeL_f'", "]", ",", "\n", "'val_rougeLsum_f'", ":", "output", "[", "'val_rougeLsum_f'", "]", ",", "\n", "'val_rouge1_f'", ":", "output", "[", "'val_rouge1_f'", "]", ",", "\n", "'val_rouge2_f'", ":", "output", "[", "'val_rouge2_f'", "]", ",", "\n", "#'val_rougeL_r': output['val_rougeL_r'],", "\n", "#'val_rouge1_r': output['val_rouge1_r'],", "\n", "#'val_rouge2_r': output['val_rouge2_r'],", "\n", "#'val_rougeL_p': output['val_rougeL_p'],", "\n", "#'val_rouge1_p': output['val_rouge1_p'],", "\n", "#'val_rouge2_p': output['val_rouge2_p'],", "\n", "}", "\n", "for", "k", ",", "v", "in", "output", ".", "items", "(", ")", ":", "\n", "            ", "if", "'rouge'", "in", "k", ":", "\n", "                ", "output", "[", "'log'", "]", "[", "k", "]", "=", "v", "\n", "", "", "if", "self", ".", "args", ".", "evidence_inference_eval", ":", "\n", "            ", "scores", "=", "self", ".", "_evidence_inference_score", "(", "generated", ",", "targets", ")", "\n", "output", "[", "'progress_bar'", "]", "[", "'macro_f1'", "]", "=", "scores", "[", "'macro avg'", "]", "[", "'f1-score'", "]", "\n", "output", "[", "'log'", "]", "[", "'macro_f1'", "]", "=", "scores", "[", "'macro avg'", "]", "[", "'f1-score'", "]", "\n", "output", "[", "'log'", "]", "[", "'macro_r'", "]", "=", "scores", "[", "'macro avg'", "]", "[", "'recall'", "]", "\n", "output", "[", "'log'", "]", "[", "'macro_p'", "]", "=", "scores", "[", "'macro avg'", "]", "[", "'precision'", "]", "\n", "for", "i", ",", "j", "in", "scores", ".", "items", "(", ")", ":", "\n", "                ", "if", "not", "isinstance", "(", "j", ",", "dict", ")", ":", "\n", "                    ", "output", "[", "'log'", "]", "[", "i", "]", "=", "j", "\n", "", "else", ":", "\n", "                    ", "for", "k", ",", "l", "in", "j", ".", "items", "(", ")", ":", "\n", "                        ", "ik", "=", "i", "+", "'_'", "+", "k", "\n", "output", "[", "'log'", "]", "[", "ik", "]", "=", "l", "\n", "\n", "", "", "", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.test_step": [[558, 573], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "transformer_summarizer.LightningBartSummarizer.validation_step", "json.dumps", "transformer_summarizer.LightningBartSummarizer.predictions_file.write", "transformer_summarizer.LightningBartSummarizer.predictions_file.flush", "open", "transformer_summarizer.LightningBartSummarizer.tokenizer.decode", "transformer_summarizer.LightningBartSummarizer.tokenizer.decode", "transformer_summarizer.LightningBartSummarizer.tokenizer.decode", "os.path.join", "batch[].squeeze"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.validation_step", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "test_step", "(", "self", ",", "batch", ",", "batch_idx", ")", ":", "\n", "        ", "if", "self", ".", "predictions_file", "is", "None", ":", "\n", "            ", "self", ".", "predictions_file", "=", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "args", ".", "training_root", ",", "'predictions.json'", ")", ",", "'w'", ")", "\n", "", "output", "=", "self", ".", "validation_step", "(", "batch", ",", "batch_idx", ")", "\n", "data", "=", "{", "\n", "'batch_idx'", ":", "batch_idx", ",", "\n", "'preamble'", ":", "self", ".", "tokenizer", ".", "decode", "(", "batch", "[", "1", "]", ".", "squeeze", "(", ")", ",", "skip_special_tokens", "=", "False", ")", ",", "\n", "'generated'", ":", "self", ".", "tokenizer", ".", "decode", "(", "output", "[", "'generations'", "]", "[", "0", "]", "[", "0", "]", ",", "skip_special_tokens", "=", "False", ")", ",", "\n", "'target'", ":", "self", ".", "tokenizer", ".", "decode", "(", "output", "[", "'targets'", "]", "[", "0", "]", "[", "0", "]", ",", "skip_special_tokens", "=", "False", ")", "\n", "}", "\n", "json_record", "=", "json", ".", "dumps", "(", "data", ")", "\n", "self", ".", "predictions_file", ".", "write", "(", "json_record", "+", "'\\n'", ")", "\n", "self", ".", "predictions_file", ".", "flush", "(", ")", "\n", "return", "{", "'test_loss'", ":", "output", "[", "'val_loss'", "]", ",", "'progress_bar'", ":", "{", "'val_loss'", ":", "output", "[", "'val_loss'", "]", "}", ",", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.test_epoch_end": [[574, 576], ["transformer_summarizer.LightningBartSummarizer.predictions_file.close"], "methods", ["None"], ["", "def", "test_epoch_end", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "self", ".", "predictions_file", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._accumulate_generations": [[577, 592], ["output.get", "output.get", "len", "generated.extend", "teacher_forced_generations.extend", "output.get", "targets.extend", "len", "len"], "methods", ["None"], ["", "def", "_accumulate_generations", "(", "self", ",", "outputs", ")", "->", "Tuple", "[", "List", "[", "List", "[", "torch", ".", "IntTensor", "]", "]", ",", "List", "[", "List", "[", "torch", ".", "IntTensor", "]", "]", ",", "List", "[", "List", "[", "torch", ".", "IntTensor", "]", "]", "]", ":", "\n", "        ", "generated", "=", "[", "]", "\n", "teacher_forced_generations", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "for", "output", "in", "outputs", ":", "\n", "# both the generated and targets should be lists of lists of inttensors", "\n", "            ", "gen", "=", "output", ".", "get", "(", "'generations'", ",", "[", "]", ")", "\n", "tf", "=", "output", ".", "get", "(", "'teacher_forced_generations'", ",", "[", "]", ")", "\n", "if", "len", "(", "gen", ")", ">", "0", ":", "\n", "                ", "generated", ".", "extend", "(", "gen", ")", "\n", "teacher_forced_generations", ".", "extend", "(", "tf", ")", "\n", "tgt", "=", "output", ".", "get", "(", "'targets'", ",", "[", "]", ")", "\n", "targets", ".", "extend", "(", "tgt", ")", "\n", "assert", "len", "(", "tgt", ")", "==", "len", "(", "gen", ")", "\n", "", "", "return", "generated", ",", "teacher_forced_generations", ",", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._evidence_inference_score": [[593, 618], ["list", "list", "set", "sklearn.metrics.classification_report", "map", "map", "pretty_generations.append", "pretty_truths.append", "len", "len", "map", "map", "generations_mapping.get", "generations_mapping.get", "s.replace().replace", "map", "s.replace().replace", "map", "itertools.chain.from_iterable", "itertools.chain.from_iterable", "set", "set", "s.replace", "s.replace"], "methods", ["None"], ["", "def", "_evidence_inference_score", "(", "self", ",", "generations", ",", "truths", ")", ":", "\n", "        ", "generations_labels", "=", "[", "'significantly decreased'", ",", "'no significant difference'", ",", "'significantly increased'", ",", "'broken generation'", "]", "\n", "generations_mapping", "=", "{", "\n", "'significantly decreased'", ":", "0", ",", "\n", "'no significant difference'", ":", "1", ",", "\n", "'significantly increased'", ":", "2", ",", "\n", "'broken generation'", ":", "3", "\n", "}", "\n", "generations", "=", "list", "(", "map", "(", "lambda", "s", ":", "s", ".", "replace", "(", "'<s>'", ",", "''", ")", ".", "replace", "(", "'</s>'", ",", "''", ")", ",", "map", "(", "str", ".", "lower", ",", "map", "(", "self", ".", "tokenizer", ".", "decode", ",", "itertools", ".", "chain", ".", "from_iterable", "(", "generations", ")", ")", ")", ")", ")", "\n", "truths", "=", "list", "(", "map", "(", "lambda", "s", ":", "s", ".", "replace", "(", "'<s>'", ",", "''", ")", ".", "replace", "(", "'</s>'", ",", "''", ")", ",", "map", "(", "str", ".", "lower", ",", "map", "(", "self", ".", "tokenizer", ".", "decode", ",", "itertools", ".", "chain", ".", "from_iterable", "(", "truths", ")", ")", ")", ")", ")", "\n", "pretty_generations", "=", "[", "]", "\n", "pretty_truths", "=", "[", "]", "\n", "for", "gen", "in", "generations", ":", "\n", "            ", "pretty_generations", ".", "append", "(", "generations_mapping", ".", "get", "(", "gen", ",", "3", ")", ")", "\n", "", "for", "t", "in", "truths", ":", "\n", "            ", "pretty_truths", ".", "append", "(", "generations_mapping", ".", "get", "(", "t", ",", "3", ")", ")", "\n", "", "all_labels", "=", "set", "(", "generations_labels", "[", "x", "]", "for", "x", "in", "(", "set", "(", "pretty_generations", ")", "|", "set", "(", "pretty_truths", ")", ")", ")", "\n", "assert", "len", "(", "generations", ")", "==", "len", "(", "truths", ")", "\n", "return", "classification_report", "(", "\n", "pretty_truths", ",", "\n", "pretty_generations", ",", "\n", "target_names", "=", "all_labels", ",", "\n", "output_dict", "=", "True", ",", "\n", "digits", "=", "3", ",", "\n", "zero_division", "=", "0", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.configure_optimizers": [[620, 630], ["torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count", "transformers.optimization.get_linear_schedule_with_warmup", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "torch.optim.Adam", "transformer_summarizer.LightningBartSummarizer.summarizer.parameters", "transformer_summarizer.LightningBartSummarizer.summarizer.parameters"], "methods", ["None"], ["", "def", "configure_optimizers", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "debug", ":", "\n", "            ", "return", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "summarizer", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "lr", ")", "# const LR", "\n", "", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "summarizer", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "args", ".", "lr", ",", "eps", "=", "self", ".", "args", ".", "adam_epsilon", ")", "\n", "num_gpus", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "num_steps", "=", "self", ".", "args", ".", "dataset_size", "*", "self", ".", "args", ".", "epochs", "/", "num_gpus", "/", "self", ".", "args", ".", "grad_accum", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "self", ".", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "num_steps", "\n", ")", "\n", "return", "[", "optimizer", "]", ",", "[", "{", "\"scheduler\"", ":", "scheduler", ",", "\"interval\"", ":", "\"step\"", "}", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.configure_ddp": [[631, 639], ["pytorch_lightning.overrides.data_parallel.LightningDistributedDataParallel"], "methods", ["None"], ["", "def", "configure_ddp", "(", "self", ",", "model", ",", "device_ids", ")", ":", "\n", "# Needs to override the default ddp to set `find_unused_parameters=False` for gradient checkpointing to work", "\n", "        ", "model", "=", "LightningDistributedDataParallel", "(", "\n", "model", ",", "\n", "device_ids", "=", "device_ids", ",", "\n", "find_unused_parameters", "=", "False", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._get_loader": [[640, 657], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DistributedSampler", "torch.utils.data.DistributedSampler"], "methods", ["None"], ["", "def", "_get_loader", "(", "self", ",", "dataset", ",", "is_train", ")", ":", "\n", "        ", "if", "self", ".", "trainer", ".", "use_ddp", ":", "\n", "            ", "sampler", "=", "DistributedSampler", "(", "dataset", ",", "shuffle", "=", "is_train", ")", "\n", "shuffle", "=", "False", "\n", "", "else", ":", "\n", "            ", "sampler", "=", "None", "\n", "shuffle", "=", "is_train", "\n", "", "loader", "=", "DataLoader", "(", "\n", "dataset", ",", "\n", "batch_size", "=", "1", ",", "\n", "shuffle", "=", "shuffle", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "0", ",", "\n", "collate_fn", "=", "self", ".", "summarizer", ".", "collate_fn", ",", "\n", "drop_last", "=", "False", ",", "\n", ")", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.train_dataloader": [[658, 660], ["transformer_summarizer.LightningBartSummarizer._get_loader"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._get_loader"], ["", "def", "train_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_get_loader", "(", "self", ".", "train_dataset", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.val_dataloader": [[661, 663], ["transformer_summarizer.LightningBartSummarizer._get_loader"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._get_loader"], ["", "def", "val_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_get_loader", "(", "self", ".", "val_dataset", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.test_dataloader": [[664, 666], ["transformer_summarizer.LightningBartSummarizer._get_loader"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer._get_loader"], ["", "def", "test_dataloader", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_get_loader", "(", "self", ".", "val_dataset", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.grad_norm": [[667, 679], ["torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "float", "p.grad.data.pow().sum", "torch.zeros.add_", "torch.zeros.add_", "transformer_summarizer.LightningBartSummarizer.parameters", "p.grad.data.pow"], "methods", ["None"], ["", "def", "grad_norm", "(", "self", ",", "norm_type", ")", ":", "\n", "# Override PTL `grad_norm` function to only return `total_grad_norm` instead norms of individual params", "\n", "# TODO: grad_norm reporting needs to take fp16 loss scale into account", "\n", "        ", "parameters", "=", "[", "p", "for", "p", "in", "self", ".", "parameters", "(", ")", "if", "p", ".", "grad", "is", "not", "None", "]", "\n", "device", "=", "parameters", "[", "0", "]", ".", "device", "\n", "total_norm", "=", "torch", ".", "zeros", "(", "[", "]", ",", "device", "=", "device", "if", "parameters", "else", "None", ")", "\n", "norm_type", "=", "float", "(", "norm_type", ")", "\n", "for", "p", "in", "parameters", ":", "\n", "            ", "param_norm", "=", "p", ".", "grad", ".", "data", ".", "pow", "(", "norm_type", ")", ".", "sum", "(", ")", "\n", "total_norm", ".", "add_", "(", "param_norm", ")", "\n", "", "total_norm", "=", "(", "total_norm", "**", "(", "1.0", "/", "norm_type", ")", ")", "\n", "return", "{", "'total_grad_norm'", ":", "total_norm", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.add_args": [[680, 704], ["parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument", "parser.add_argument"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "add_args", "(", "cls", ",", "parser", ")", ":", "\n", "# generation args", "\n", "        ", "parser", ".", "add_argument", "(", "'--num_beams'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'How many beams to use when decoding during validation'", ")", "\n", "parser", ".", "add_argument", "(", "'--min_length'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "'Minimum summary lengths'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_length'", ",", "type", "=", "int", ",", "default", "=", "512", ",", "help", "=", "'Maximum target lengths'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_num_refs'", ",", "type", "=", "int", ",", "default", "=", "25", ",", "help", "=", "'Maximum number of reference text'", ")", "\n", "parser", ".", "add_argument", "(", "'--temperature'", ",", "type", "=", "float", ",", "help", "=", "\"Sampling temperature\"", ")", "\n", "parser", ".", "add_argument", "(", "'--repetition_penalty'", ",", "type", "=", "float", ",", "help", "=", "\"\"", ")", "\n", "parser", ".", "add_argument", "(", "'--length_penalty'", ",", "default", "=", "2.0", ",", "type", "=", "float", ",", "help", "=", "'Length penalty when decoding during validation'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_repeat_ngram_size'", ",", "default", "=", "3", ",", "type", "=", "int", ",", "help", "=", "'Size of ngram not to repeat when decoding during validation'", ")", "\n", "# training args", "\n", "parser", ".", "add_argument", "(", "'--train_rouge_eval_batches'", ",", "default", "=", "100", ",", "type", "=", "int", ",", "help", "=", "'How often (in batches) to generate in the training data for rouge scoring?'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_ckpt'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Enable gradient checkpointing to save memory'", ")", "\n", "# model args", "\n", "parser", ".", "add_argument", "(", "'--attention_dropout'", ",", "default", "=", "0.1", ",", "type", "=", "float", ",", "help", "=", "'Length penalty when decoding during validation'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "default", "=", "1e-5", ",", "type", "=", "float", ",", "help", "=", "'Learning rate'", ")", "\n", "parser", ".", "add_argument", "(", "'--adam_epsilon'", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "'Adam epsilon'", ")", "\n", "parser", ".", "add_argument", "(", "'--warmup_steps'", ",", "default", "=", "1000", ",", "type", "=", "int", ",", "help", "=", "'Batches for warmup'", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Use fp16'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_name'", ",", "default", "=", "'facebook/bart-base'", ",", "help", "=", "'name of path of a model'", ")", "\n", "parser", ".", "add_argument", "(", "'--evidence_inference_eval'", ",", "default", "=", "False", ",", "action", "=", "'store_true'", ",", "help", "=", "'When producing a significance classification, '", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--debug'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Debugging'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.__init__": [[708, 730], ["torch.Module.__init__", "longformer.LongformerEncoderDecoderConfig.from_pretrained", "logging.info", "longformer.LongformerEncoderDecoderForConditionalGeneration.from_pretrained", "transformer_summarizer.SingleStreamBartSummarizer.model.resize_token_embeddings", "len", "str", "tokenizer.get_vocab"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__"], ["    ", "def", "__init__", "(", "self", ",", "model_path", ",", "tokenizer", ",", "args", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# TODO(jayd) look into DistilBART https://github.com/huggingface/transformers/blob/5543b30aa6b52da3c8f7d9e525b0edc26226d717/examples/seq2seq/", "\n", "config", "=", "LongformerEncoderDecoderConfig", ".", "from_pretrained", "(", "\n", "model_path", ",", "\n", "attention_mode", "=", "'sliding_chunks_no_overlap'", ",", "\n", "attention_dropout", "=", "args", ".", "attention_dropout", ",", "\n", "gradient_checkpointing", "=", "args", ".", "grad_ckpt", ",", "\n", ")", "\n", "# with `sliding_chunks_no_overlap`, attention size is 3 * attention_window. Use 340 if total amount of attention is 1024 (as in BART) or use 170 if you feel 170*3=510 is the average length of ref. I used 340 in other experiments and it works well and haven't tried 170", "\n", "attention_size", "=", "340", "\n", "config", ".", "attention_window", "=", "[", "attention_size", "]", "*", "config", ".", "encoder_layers", "\n", "logging", ".", "info", "(", "'config:'", "+", "str", "(", "config", ")", ")", "\n", "self", ".", "model", "=", "LongformerEncoderDecoderForConditionalGeneration", ".", "from_pretrained", "(", "\n", "model_path", ",", "\n", "config", "=", "config", ",", "\n", ")", "\n", "self", ".", "max_input_length", "=", "(", "config", ".", "max_encoder_position_embeddings", "//", "(", "2", "*", "attention_size", ")", ")", "*", "2", "*", "attention_size", "\n", "self", ".", "model", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ".", "get_vocab", "(", ")", ")", ")", "\n", "self", ".", "tokenizer", "=", "tokenizer", "\n", "self", ".", "config", "=", "self", ".", "model", ".", "config", "\n", "self", ".", "args", "=", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer._prepare_input_ids": [[731, 743], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat.new_ones", "torch.cat.new_ones", "longformer.sliding_chunks.pad_to_window_size", "all", "inputs.size", "preambles.size", "list", "map", "torch.cat.size", "torch.cat.size", "preambles.size"], "methods", ["None"], ["", "def", "_prepare_input_ids", "(", "self", ",", "inputs", ",", "preambles", ")", ":", "\n", "# TODO fix the global attention mask", "\n", "        ", "assert", "inputs", ".", "size", "(", "0", ")", "==", "preambles", ".", "size", "(", "0", ")", "==", "1", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "preambles", ",", "inputs", "]", ",", "dim", "=", "1", ")", "# combine preamble and refs in one long sequence", "\n", "input_ids", "=", "input_ids", "[", ":", ",", ":", "self", ".", "max_input_length", "]", "# limit to max input size", "\n", "attention_mask", "=", "input_ids", ".", "new_ones", "(", "input_ids", ".", "shape", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "attention_mask", "[", "input_ids", "==", "self", ".", "tokenizer", ".", "pad_token_id", "]", "=", "0", "\n", "attention_mask", "[", "0", ",", ":", "preambles", ".", "size", "(", ")", "[", "1", "]", "]", "=", "2", "# global attention on preamble", "\n", "input_ids", ",", "attention_mask", "=", "pad_to_window_size", "(", "# ideally, should be moved inside the LongformerModel", "\n", "input_ids", ",", "attention_mask", ",", "self", ".", "config", ".", "attention_window", "[", "0", "]", ",", "self", ".", "tokenizer", ".", "pad_token_id", ")", "\n", "assert", "all", "(", "list", "(", "map", "(", "lambda", "x", ":", "x", "<=", "self", ".", "max_input_length", ",", "input_ids", ".", "size", "(", ")", ")", ")", ")", "\n", "return", "input_ids", ",", "attention_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.forward": [[744, 749], ["transformer_summarizer.SingleStreamBartSummarizer._prepare_input_ids", "transformer_summarizer.SingleStreamBartSummarizer.model"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer._prepare_input_ids"], ["", "def", "forward", "(", "self", ",", "inputs", ",", "preambles", ",", "targets", ")", ":", "\n", "        ", "input_ids", ",", "attention_mask", "=", "self", ".", "_prepare_input_ids", "(", "inputs", ",", "preambles", ")", "\n", "return", "self", ".", "model", "(", "\n", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "\n", "decoder_input_ids", "=", "targets", "[", ":", ",", ":", "-", "1", "]", ",", "labels", "=", "targets", "[", ":", ",", "1", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.collate_fn": [[750, 758], ["refs.masked_select.masked_select.masked_select", "len", "refs.masked_select.masked_select.unsqueeze", "preface.unsqueeze", "target.unsqueeze"], "methods", ["None"], ["", "def", "collate_fn", "(", "self", ",", "batch", ":", "List", "[", "ReviewDataset", ".", "Instance", "]", ")", "->", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "assert", "len", "(", "batch", ")", "==", "1", "\n", "instance", "=", "batch", "[", "0", "]", "\n", "refs", "=", "instance", ".", "refs", ".", "data", "\n", "refs", "=", "refs", ".", "masked_select", "(", "refs", "!=", "0", ")", "# remove padding and combine in one long sequence", "\n", "preface", "=", "instance", ".", "preface", "\n", "target", "=", "instance", ".", "target", "\n", "return", "refs", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "preface", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "target", ".", "unsqueeze", "(", "dim", "=", "0", ")", "# batch of size 1", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.generate_summary": [[759, 763], ["torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "transformer_summarizer.SingleStreamBartSummarizer._prepare_input_ids", "transformer_summarizer.SingleStreamBartSummarizer.model.generate"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer._prepare_input_ids"], ["", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate_summary", "(", "self", ",", "inputs", ",", "preambles", ",", "**", "kwargs", ")", ":", "\n", "        ", "input_ids", ",", "attention_mask", "=", "self", ".", "_prepare_input_ids", "(", "inputs", ",", "preambles", ")", "\n", "return", "self", ".", "model", ".", "generate", "(", "input_ids", "=", "input_ids", ",", "attention_mask", "=", "attention_mask", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.get_args": [[765, 778], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "transformer_summarizer.LightningBartSummarizer.add_args"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.add_args"], ["", "", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a BART based summarization model!'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "default", "=", "10", ",", "type", "=", "int", ",", "help", "=", "'Train for how many epochs?'", ")", "\n", "parser", ".", "add_argument", "(", "'--train'", ",", "required", "=", "True", ",", "help", "=", "'jsonl serialized training files'", ")", "\n", "parser", ".", "add_argument", "(", "'--val'", ",", "required", "=", "True", ")", "\n", "parser", ".", "add_argument", "(", "'--training_root'", ",", "required", "=", "True", ",", "help", "=", "'Where to save checkpoints, etc.'", ")", "\n", "parser", ".", "add_argument", "(", "'--grad_accum'", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "'Number of gradient accumulation steps'", ")", "\n", "parser", ".", "add_argument", "(", "'--test'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Skip training. Run prediction on the validation set'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_all_ckpts'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Skip training. Run prediction on the validation set over all ckpts'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset_size'", ",", "default", "=", "14607", ",", "type", "=", "int", ",", "help", "=", "'Number of instances in the training set'", ")", "# TODO: read from the data", "\n", "\n", "LightningBartSummarizer", ".", "add_args", "(", "parser", ")", "\n", "return", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.main": [[780, 835], ["transformer_summarizer.get_args", "get_args.parse_args", "transformer_summarizer.LightningBartSummarizer", "ms2.data.review_datasets.ReviewDataset.from_file", "logging.info", "glob.glob", "logging.info", "pytorch_lightning.callbacks.ModelCheckpoint", "pytorch_lightning.Trainer", "ms2.data.review_datasets.ReviewDataset.from_file", "os.path.join", "len", "map", "max", "logging.info", "pytorch_lightning.Trainer.fit", "ms2.data.review_datasets.ToUnflattenedModelInputsFunction", "len", "int", "glob.glob.keys", "os.path.join", "ms2.data.review_datasets.ToUnflattenedModelInputsFunction", "len", "len", "re.match().group", "zip", "pytorch_lightning.callbacks.LearningRateLogger", "re.match"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.get_args", "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.from_file", "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.from_file"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "get_args", "(", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "model", "=", "LightningBartSummarizer", "(", "args", ")", "\n", "\n", "if", "args", ".", "test", "or", "args", ".", "test_all_ckpts", ":", "\n", "# loading the training dataset is expensive and unnecessary if we're only evaluating", "\n", "        ", "model", ".", "train_dataset", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "model", ".", "train_dataset", "=", "ReviewDataset", ".", "from_file", "(", "args", ".", "train", ",", "format_function", "=", "ToUnflattenedModelInputsFunction", "(", "model", ".", "config", ".", "pad_token_id", ")", ")", "\n", "", "model", ".", "val_dataset", "=", "ReviewDataset", ".", "from_file", "(", "args", ".", "val", ",", "format_function", "=", "ToUnflattenedModelInputsFunction", "(", "model", ".", "config", ".", "pad_token_id", ")", ")", "\n", "logging", ".", "info", "(", "f'Loaded training dataset of length {len(model.train_dataset)}, val: {len(model.val_dataset)}'", ")", "\n", "\n", "resume_from_checkpoint", "=", "None", "\n", "ckpts", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "training_root", ",", "'*.ckpt'", ")", ")", "\n", "logging", ".", "info", "(", "'Found {} pre-existing checkpoints: {}'", ".", "format", "(", "len", "(", "ckpts", ")", ",", "ckpts", ")", ")", "\n", "if", "len", "(", "ckpts", ")", ">", "0", ":", "\n", "        ", "epochs", "=", "map", "(", "lambda", "ckpt", ":", "re", ".", "match", "(", "'.*_([0-9]+)\\.ckpt'", ",", "ckpt", ")", ".", "group", "(", "1", ")", ",", "ckpts", ")", "\n", "ckpts", "=", "{", "int", "(", "e", ")", ":", "c", "for", "(", "e", ",", "c", ")", "in", "zip", "(", "epochs", ",", "ckpts", ")", "}", "\n", "best", "=", "max", "(", "ckpts", ".", "keys", "(", ")", ")", "\n", "resume_from_checkpoint", "=", "ckpts", "[", "best", "]", "\n", "logging", ".", "info", "(", "'Resuming from existing checkpoint {}'", ".", "format", "(", "resume_from_checkpoint", ")", ")", "\n", "\n", "# single machine for the moment", "\n", "", "checkpoint_callback", "=", "ModelCheckpoint", "(", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "args", ".", "training_root", ",", "'model.ckpt'", ")", ",", "\n", "verbose", "=", "True", ",", "\n", "# save_best_only=False,", "\n", "save_top_k", "=", "-", "1", ",", "\n", "monitor", "=", "'val_loss'", ",", "\n", "mode", "=", "'min'", ",", "\n", ")", "\n", "trainer", "=", "Trainer", "(", "\n", "gpus", "=", "-", "1", ",", "\n", "num_sanity_val_steps", "=", "2", ",", "\n", "val_check_interval", "=", "0.5", "if", "not", "args", ".", "debug", "else", "1.0", ",", "\n", "check_val_every_n_epoch", "=", "1", "if", "not", "args", ".", "debug", "else", "10", ",", "\n", "distributed_backend", "=", "'ddp'", ",", "\n", "replace_sampler_ddp", "=", "False", ",", "\n", "num_nodes", "=", "1", ",", "\n", "default_root_dir", "=", "args", ".", "training_root", ",", "\n", "max_epochs", "=", "args", ".", "epochs", ",", "\n", "log_gpu_memory", "=", "True", ",", "\n", "show_progress_bar", "=", "True", ",", "\n", "log_save_interval", "=", "10", ",", "\n", "accumulate_grad_batches", "=", "args", ".", "grad_accum", ",", "\n", "precision", "=", "16", "if", "args", ".", "fp16", "else", "32", ",", "amp_level", "=", "'O2'", ",", "\n", "checkpoint_callback", "=", "checkpoint_callback", ",", "\n", "callbacks", "=", "[", "LearningRateLogger", "(", ")", "]", ",", "\n", "resume_from_checkpoint", "=", "resume_from_checkpoint", ",", "\n", "track_grad_norm", "=", "2", ",", "\n", ")", "\n", "\n", "if", "not", "(", "args", ".", "test", "or", "args", ".", "test_all_ckpts", ")", ":", "\n", "        ", "trainer", ".", "fit", "(", "model", ")", "\n", "# Possibly a CUDA/pytorch bug: it seems after a recent update of the S2 servers", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.__init__": [[27, 32], ["torch.utils.data.Dataset.__init__", "random.shuffle", "list", "itertools.chain.from_iterable", "map"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__"], ["def", "__init__", "(", "self", ",", "data", ":", "List", "[", "TargetSummary", "]", ",", "format_function", ")", ":", "\n", "        ", "super", "(", "ReviewDataset", ")", ".", "__init__", "(", ")", "\n", "self", ".", "data", "=", "data", "\n", "random", ".", "shuffle", "(", "self", ".", "data", ")", "\n", "self", ".", "instances", "=", "list", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "map", "(", "format_function", ",", "self", ".", "data", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.__len__": [[33, 35], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "instances", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.__getitem__": [[36, 38], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "return", "self", ".", "instances", "[", "idx", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.from_file": [[39, 63], ["ms2.utils.TargetSummary.read_summaries", "list", "review_datasets.ReviewDataset", "torch.LongTensor", "dataclasses.replace", "list", "list", "dataclasses.replace", "map", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "map", "map", "len"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.TargetSummary.read_summaries"], ["", "@", "staticmethod", "\n", "def", "from_file", "(", "f", ":", "str", ",", "format_function", ")", "->", "'ReviewDataset'", ":", "\n", "        ", "def", "tensorize_reference", "(", "reference", ":", "TargetReference", ")", "->", "TargetReference", ":", "\n", "            ", "title_abstract", "=", "torch", ".", "LongTensor", "(", "reference", ".", "title_abstract", ")", "\n", "full_text", "=", "torch", ".", "LongTensor", "(", "reference", ".", "full_text", ")", "if", "reference", ".", "full_text", "is", "not", "None", "else", "None", "\n", "return", "replace", "(", "reference", ",", "\n", "title_abstract", "=", "title_abstract", ",", "\n", "full_text", "=", "full_text", ",", "\n", ")", "\n", "", "def", "tensorize", "(", "summary", ":", "TargetSummary", ")", "->", "TargetSummary", ":", "\n", "# TODO what about summaries with no preface", "\n", "            ", "preface", "=", "torch", ".", "LongTensor", "(", "summary", ".", "preface", ")", "if", "summary", ".", "preface", "is", "not", "None", "and", "len", "(", "summary", ".", "preface", ")", ">", "0", "else", "torch", ".", "LongTensor", "(", "[", "0", "]", ")", "\n", "references", "=", "list", "(", "map", "(", "tensorize_reference", ",", "summary", ".", "references", ")", ")", "\n", "target_texts", "=", "list", "(", "map", "(", "torch", ".", "LongTensor", ",", "summary", ".", "target_texts", ")", ")", "\n", "return", "replace", "(", "\n", "summary", ",", "\n", "preface", "=", "preface", ",", "\n", "target_texts", "=", "target_texts", ",", "\n", "references", "=", "references", ",", "\n", ")", "\n", "\n", "", "summaries", "=", "TargetSummary", ".", "read_summaries", "(", "f", ")", "\n", "summaries", "=", "list", "(", "map", "(", "tensorize", ",", "summaries", ")", ")", "\n", "return", "ReviewDataset", "(", "summaries", ",", "format_function", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.to_flattened_model_inputs": [[64, 73], ["torch.cat", "ret.append", "ReviewDataset.Instance"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "to_flattened_model_inputs", "(", "instance", ":", "TargetSummary", ")", "->", "List", "[", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "# TODO this is a dumb concatenation. be smarter. add separators or something.", "\n", "        ", "ref_texts", "=", "torch", ".", "cat", "(", "[", "ref", ".", "title_abstract", "for", "ref", "in", "instance", ".", "references", "]", ",", "dim", "=", "0", ")", "\n", "preface", "=", "instance", ".", "preface", "\n", "ret", "=", "[", "]", "\n", "for", "txt", "in", "instance", ".", "target_texts", ":", "\n", "            ", "ret", ".", "append", "(", "ReviewDataset", ".", "Instance", "(", "ref_texts", ",", "preface", ",", "txt", ")", ")", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__init__": [[75, 77], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "padding_value", ")", ":", "\n", "        ", "self", ".", "padding_value", "=", "padding_value", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ToUnflattenedModelInputsFunction.__call__": [[78, 86], ["ms2.models.utils.pad_tensors", "ret.append", "ReviewDataset.Instance"], "methods", ["home.repos.pwc.inspect_result.allenai_ms2.models.utils.pad_tensors"], ["", "def", "__call__", "(", "self", ",", "instance", ":", "TargetSummary", ")", "->", "List", "[", "Tuple", "[", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", ",", "torch", ".", "Tensor", "]", "]", ":", "\n", "        ", "ref_texts", "=", "[", "ref", ".", "title_abstract", "for", "ref", "in", "instance", ".", "references", "]", "\n", "ref_texts", "=", "pad_tensors", "(", "ref_texts", ",", "padding_value", "=", "self", ".", "padding_value", ")", "\n", "preface", "=", "instance", ".", "preface", "\n", "ret", "=", "[", "]", "\n", "for", "txt", "in", "instance", ".", "target_texts", ":", "\n", "            ", "ret", ".", "append", "(", "(", "ReviewDataset", ".", "Instance", "(", "ref_texts", ",", "preface", ",", "txt", ")", ")", ")", "\n", "", "return", "ret", "", "", "", ""]], "home.repos.pwc.inspect_result.allenai_ms2.data.munge.insert_spaces": [[22, 28], ["re.sub", "re.sub"], "function", ["None"], ["def", "insert_spaces", "(", "s", ":", "str", ")", "->", "str", ":", "\n", "# surround any likely offending section headings or paragraph starts with spaces", "\n", "    ", "with_spaces", "=", "re", ".", "sub", "(", "fields_re", ",", "r' \\1 '", ",", "s", ")", "\n", "# replace all double (or n) space characters with a single matching one", "\n", "with_single_spaces", "=", "re", ".", "sub", "(", "spaces_re", ",", "r'\\1'", ",", "with_spaces", ")", "\n", "return", "with_single_spaces", "\n", "", ""]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.ios": [[30, 40], ["list", "list", "map", "map", "s.replace.replace", "re.findall", "re.findall"], "function", ["None"], ["def", "ios", "(", "preamble", ")", ":", "\n", "# we know that the reference abstract is already space tokenized", "\n", "    ", "start_stop_words", "=", "EXTRA_TOKENS", "+", "[", "'<s>'", ",", "'</s>'", "]", "\n", "def", "clean_str", "(", "s", ")", ":", "\n", "        ", "for", "w", "in", "start_stop_words", ":", "\n", "            ", "s", "=", "s", ".", "replace", "(", "w", ",", "''", ")", "\n", "", "return", "s", "\n", "", "outcomes", "=", "list", "(", "map", "(", "clean_str", ",", "re", ".", "findall", "(", "OUTCOME_RE", ",", "preamble", ")", ")", ")", "\n", "interventions", "=", "list", "(", "map", "(", "clean_str", ",", "re", ".", "findall", "(", "INTERVENTION_RE", ",", "preamble", ")", ")", ")", "\n", "return", "interventions", ",", "outcomes", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.evidence_inference_score": [[41, 63], ["consistency_scorer.ios", "itertools.product", "model", "torch.softmax().detach().cpu().squeeze().tolist", "dict", "ret.append", "evidence_inference_tokenizer", "model", "torch.softmax().detach().cpu().squeeze().tolist", "dict", "ret.append", "evidence_inference_tokenizer", "evidence_inference_tokenizer", "zip", "evidence_inference_tokenizer", "zip", "torch.softmax().detach().cpu().squeeze", "torch.softmax().detach().cpu().squeeze", "torch.softmax().detach().cpu", "torch.softmax().detach().cpu", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax", "torch.softmax"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.ios"], ["", "def", "evidence_inference_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "summary", ",", "preamble", ",", "use_ios", ")", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "if", "use_ios", ":", "\n", "        ", "interventions", ",", "outcomes", "=", "ios", "(", "preamble", ")", "\n", "summary", "=", "evidence_inference_tokenizer", "(", "summary", ",", "return_tensors", "=", "'pt'", ")", "[", "'input_ids'", "]", "\n", "for", "i", ",", "o", "in", "itertools", ".", "product", "(", "interventions", ",", "outcomes", ")", ":", "\n", "            ", "preamble", "=", "i", "+", "' '", "+", "evidence_inference_tokenizer", ".", "sep_token", "+", "' '", "+", "o", "\n", "ico", "=", "evidence_inference_tokenizer", "(", "preamble", ",", "return_tensors", "=", "'pt'", ")", "[", "'input_ids'", "]", "\n", "classes", "=", "model", "(", "ico", ",", "summary", ")", "\n", "classes", "=", "torch", ".", "softmax", "(", "classes", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "\n", "significance_distribution", "=", "dict", "(", "zip", "(", "[", "\"significantly decreased\"", ",", "\"no significant difference\"", ",", "\"significantly increased\"", "]", ",", "classes", ")", ")", "\n", "ret", ".", "append", "(", "significance_distribution", ")", "\n", "", "", "else", ":", "\n", "        ", "preamble", "=", "\"\"", "\n", "ico", "=", "evidence_inference_tokenizer", "(", "preamble", ",", "return_tensors", "=", "'pt'", ")", "[", "'input_ids'", "]", "\n", "summary", "=", "evidence_inference_tokenizer", "(", "summary", ",", "return_tensors", "=", "'pt'", ")", "[", "'input_ids'", "]", "\n", "classes", "=", "model", "(", "ico", ",", "summary", ")", "\n", "classes", "=", "torch", ".", "softmax", "(", "classes", ",", "dim", "=", "-", "1", ")", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "squeeze", "(", ")", ".", "tolist", "(", ")", "\n", "significance_distribution", "=", "dict", "(", "zip", "(", "[", "\"significantly decreased\"", ",", "\"no significant difference\"", ",", "\"significantly increased\"", "]", ",", "classes", ")", ")", "\n", "ret", ".", "append", "(", "significance_distribution", ")", "\n", "\n", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.jsd": [[65, 70], ["list", "scipy.spatial.distance.jensenshannon", "m1.get", "m2.get", "set", "set", "m1.keys", "m2.keys"], "function", ["None"], ["", "def", "jsd", "(", "m1", ",", "m2", ")", ":", "\n", "    ", "keys", "=", "list", "(", "set", "(", "m1", ".", "keys", "(", ")", ")", "|", "set", "(", "m2", ".", "keys", "(", ")", ")", ")", "\n", "m1", "=", "[", "m1", ".", "get", "(", "k", ",", "0", ")", "for", "k", "in", "keys", "]", "\n", "m2", "=", "[", "m2", ".", "get", "(", "k", ",", "0", ")", "for", "k", "in", "keys", "]", "\n", "return", "jensenshannon", "(", "m1", ",", "m2", ",", "base", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.entailment_score": [[71, 80], ["consistency_scorer.evidence_inference_score", "consistency_scorer.evidence_inference_score", "zip", "numpy.mean", "jsds.append", "len", "consistency_scorer.jsd"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.evidence_inference_score", "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.evidence_inference_score", "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.jsd"], ["", "def", "entailment_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "generated", ",", "target", ",", "preamble", ",", "use_ios", ")", ":", "\n", "    ", "generated_distributions", "=", "evidence_inference_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "generated", ",", "preamble", ",", "use_ios", ")", "\n", "summary_distributions", "=", "evidence_inference_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "target", ",", "preamble", ",", "use_ios", ")", "\n", "jsds", "=", "[", "]", "\n", "for", "generated_distribution", ",", "summary_distribution", "in", "zip", "(", "generated_distributions", ",", "summary_distributions", ")", ":", "\n", "        ", "jsds", ".", "append", "(", "jsd", "(", "generated_distribution", ",", "summary_distribution", ")", ")", "\n", "", "if", "len", "(", "jsds", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "return", "np", ".", "mean", "(", "jsds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.f1_score": [[81, 115], ["zip", "sklearn.metrics.classification_report", "consistency_scorer.evidence_inference_score", "consistency_scorer.evidence_inference_score", "zip", "in_doc_classifications.append", "numpy.array", "numpy.array", "enumerate", "sorted", "sorted", "in_doc_target.append", "summary_preds.append", "generated_preds.append", "in_doc_generated.append", "len", "sklearn.metrics.classification_report", "generated_distribution.items", "summary_distribution.items", "numpy.array", "numpy.array", "list", "range", "len"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.evidence_inference_score", "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.evidence_inference_score"], ["", "def", "f1_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "generateds", ",", "targets", ",", "preambles", ",", "use_ios", ")", ":", "\n", "    ", "summary_preds", "=", "[", "]", "\n", "generated_preds", "=", "[", "]", "\n", "in_doc_classifications", "=", "[", "]", "\n", "labels", "=", "[", "\"significantly decreased\"", ",", "\"no significant difference\"", ",", "\"significantly increased\"", "]", "\n", "mapping", "=", "{", "x", ":", "i", "for", "(", "i", ",", "x", ")", "in", "enumerate", "(", "labels", ")", "}", "\n", "for", "generated", ",", "target", ",", "preamble", "in", "zip", "(", "generateds", ",", "targets", ",", "preambles", ")", ":", "\n", "        ", "generated_distributions", "=", "evidence_inference_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "generated", ",", "preamble", ",", "use_ios", ")", "\n", "summary_distributions", "=", "evidence_inference_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "target", ",", "preamble", ",", "use_ios", ")", "\n", "in_doc_generated", "=", "[", "]", "\n", "in_doc_target", "=", "[", "]", "\n", "for", "generated_distribution", ",", "summary_distribution", "in", "zip", "(", "generated_distributions", ",", "summary_distributions", ")", ":", "\n", "            ", "generated_targets", "=", "sorted", "(", "generated_distribution", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "summary_targets", "=", "sorted", "(", "summary_distribution", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "best_summary_target", "=", "summary_targets", "[", "-", "1", "]", "[", "0", "]", "\n", "in_doc_target", ".", "append", "(", "best_summary_target", ")", "\n", "summary_preds", ".", "append", "(", "best_summary_target", ")", "\n", "generated_target", "=", "generated_targets", "[", "-", "1", "]", "[", "0", "]", "\n", "generated_preds", ".", "append", "(", "generated_target", ")", "\n", "in_doc_generated", ".", "append", "(", "generated_target", ")", "\n", "", "if", "len", "(", "in_doc_generated", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "in_doc_classifications", ".", "append", "(", "\n", "classification_report", "(", "\n", "np", ".", "array", "(", "[", "mapping", "[", "x", "]", "for", "x", "in", "in_doc_target", "]", ")", ",", "\n", "np", ".", "array", "(", "[", "mapping", "[", "x", "]", "for", "x", "in", "in_doc_generated", "]", ")", ",", "\n", "target_names", "=", "labels", ",", "\n", "labels", "=", "list", "(", "range", "(", "len", "(", "labels", ")", ")", ")", ",", "\n", "output_dict", "=", "True", ",", "\n", "digits", "=", "4", "\n", ")", "\n", ")", "\n", "", "res", "=", "classification_report", "(", "np", ".", "array", "(", "[", "mapping", "[", "x", "]", "for", "x", "in", "summary_preds", "]", ")", ",", "np", ".", "array", "(", "[", "mapping", "[", "x", "]", "for", "x", "in", "generated_preds", "]", ")", ",", "target_names", "=", "labels", ",", "output_dict", "=", "True", ",", "digits", "=", "4", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.jsd_uniform": [[117, 131], ["consistency_scorer.evidence_inference_score", "numpy.mean", "jsds.append", "len", "consistency_scorer.jsd"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.evidence_inference_score", "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.jsd"], ["", "def", "jsd_uniform", "(", "model", ",", "evidence_inference_tokenizer", ",", "target", ",", "preamble", ",", "use_ios", ")", ":", "\n", "    ", "summary_distributions", "=", "evidence_inference_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "target", ",", "preamble", ",", "use_ios", ")", "\n", "jsds", "=", "[", "]", "\n", "# baseline distributions", "\n", "generated_distribution", "=", "{", "\n", "'significantly decreased'", ":", ".134", ",", "\n", "'no significant difference'", ":", ".570", ",", "\n", "'significantly increased'", ":", ".296", ",", "\n", "}", "\n", "for", "summary_distribution", "in", "summary_distributions", ":", "\n", "        ", "jsds", ".", "append", "(", "jsd", "(", "generated_distribution", ",", "summary_distribution", ")", ")", "\n", "", "if", "len", "(", "jsds", ")", "==", "0", ":", "\n", "        ", "return", "None", "\n", "", "return", "np", ".", "mean", "(", "jsds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.entailment_scores": [[132, 147], ["consistency_scorer.f1_score", "list", "list", "list", "list", "numpy.mean", "numpy.std", "numpy.mean", "map", "filter", "map", "filter", "len", "zip", "zip", "consistency_scorer.entailment_score", "consistency_scorer.jsd_uniform"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.f1_score", "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.entailment_score", "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.jsd_uniform"], ["", "def", "entailment_scores", "(", "model", ",", "evidence_inference_tokenizer", ",", "generateds", ",", "targets", ",", "preambles", ",", "use_ios", ")", ":", "\n", "    ", "f1_scores", "=", "f1_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "generateds", ",", "targets", ",", "preambles", ",", "use_ios", ")", "\n", "scores", "=", "list", "(", "map", "(", "lambda", "x", ":", "entailment_score", "(", "model", ",", "evidence_inference_tokenizer", ",", "*", "x", ",", "use_ios", ")", ",", "zip", "(", "generateds", ",", "targets", ",", "preambles", ")", ")", ")", "\n", "scores", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "is", "not", "None", ",", "scores", ")", ")", "\n", "uniform_scores", "=", "list", "(", "map", "(", "lambda", "x", ":", "jsd_uniform", "(", "model", ",", "evidence_inference_tokenizer", ",", "*", "x", ",", "use_ios", ")", ",", "zip", "(", "targets", ",", "preambles", ")", ")", ")", "\n", "uniform_scores", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "is", "not", "None", ",", "uniform_scores", ")", ")", "\n", "assert", "len", "(", "scores", ")", ">", "0", "\n", "avg", "=", "np", ".", "mean", "(", "scores", ")", "\n", "s", "=", "np", ".", "std", "(", "scores", ")", "\n", "uniform_score", "=", "np", ".", "mean", "(", "uniform_scores", ")", "\n", "return", "{", "\n", "'average'", ":", "avg", ",", "\n", "'std'", ":", "s", ",", "\n", "'uniform_preds'", ":", "uniform_score", ",", "\n", "'f1_score'", ":", "f1_scores", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.clean": [[149, 154], ["s.replace.replace", "s.replace.replace"], "function", ["None"], ["", "def", "clean", "(", "s", ")", ":", "\n", "    ", "for", "t", "in", "EXTRA_TOKENS", "+", "[", "'<s>'", ",", "'</s>'", "]", ":", "\n", "        ", "s", "=", "s", ".", "replace", "(", "t", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.main": [[155, 203], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "list", "list", "ms2.utils.get_tokenizer", "ms2.models.utils.rouge_scores", "print", "print", "ms2.models.evidence_inference_models.initialize_models", "evidence_inference_classifier.load_state_dict", "evidence_inference_classifier.cuda", "consistency_scorer.entailment_scores", "print", "print", "open", "map", "map", "open", "json.loads", "os.path.join", "os.path.join", "torch.load", "open", "of.write", "of.write", "of.write", "of.write", "of.write", "of.write", "json.loads", "inf.read", "json.dumps", "json.dumps"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.get_tokenizer", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.rouge_scores", "home.repos.pwc.inspect_result.allenai_ms2.models.evidence_inference_models.initialize_models", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda", "home.repos.pwc.inspect_result.allenai_ms2.modeling.consistency_scorer.entailment_scores"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Score model outputs based on a consistency score between target and prediction'", ")", "\n", "parser", ".", "add_argument", "(", "'--model_outputs'", ",", "required", "=", "True", ",", "help", "=", "'json file of model outputs with \"target\", \"generated\", and \"preamble\" fields'", ")", "\n", "parser", ".", "add_argument", "(", "'--evidence_inference_dir'", ",", "required", "=", "True", ",", "help", "=", "'Directory containing trained evidence inference models'", ")", "\n", "parser", ".", "add_argument", "(", "'--evidence_inference_classifier_params'", ",", "required", "=", "True", ",", "help", "=", "'Params to initialize evidence inference models'", ")", "\n", "parser", ".", "add_argument", "(", "'--unconditioned_classifier'", ",", "action", "=", "'store_true'", ",", "help", "=", "'Use an unconditioned evidence inference classifier'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "True", ",", "help", "=", "'Output file for scores'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "model_outputs", ",", "'r'", ")", "as", "inf", ":", "\n", "        ", "outputs", "=", "[", "json", ".", "loads", "(", "line", ")", "for", "line", "in", "inf", "]", "\n", "generated", "=", "[", "x", "[", "'generated'", "]", "for", "x", "in", "outputs", "]", "\n", "targets", "=", "[", "x", "[", "'target'", "]", "for", "x", "in", "outputs", "]", "\n", "preambles", "=", "[", "x", "[", "'preamble'", "]", "for", "x", "in", "outputs", "]", "\n", "", "generated", "=", "list", "(", "map", "(", "clean", ",", "generated", ")", ")", "\n", "targets", "=", "list", "(", "map", "(", "clean", ",", "targets", ")", ")", "\n", "\n", "# rouge scoring", "\n", "tokenizer", "=", "get_tokenizer", "(", "'facebook/bart-base'", ")", "\n", "rouge_results", "=", "rouge_scores", "(", "[", "[", "x", "]", "for", "x", "in", "generated", "]", ",", "[", "[", "x", "]", "for", "x", "in", "targets", "]", ",", "tokenizer", ",", "use_aggregator", "=", "True", ")", "\n", "print", "(", "'Rouge'", ")", "\n", "print", "(", "rouge_results", ")", "\n", "\n", "# evidence inference scoring", "\n", "with", "open", "(", "args", ".", "evidence_inference_classifier_params", ",", "'r'", ")", "as", "inf", ":", "\n", "        ", "params", "=", "json", ".", "loads", "(", "inf", ".", "read", "(", ")", ")", "\n", "", "_", ",", "evidence_inference_classifier", ",", "_", ",", "_", ",", "_", ",", "evidence_inference_tokenizer", "=", "initialize_models", "(", "params", ")", "\n", "if", "args", ".", "unconditioned_classifier", ":", "\n", "        ", "classifier_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "evidence_inference_dir", ",", "'unconditioned_evidence_classifier'", ",", "'unconditioned_evidence_classifier.pt'", ")", "\n", "", "else", ":", "\n", "        ", "classifier_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "evidence_inference_dir", ",", "'evidence_classifier'", ",", "'evidence_classifier.pt'", ")", "\n", "#evidence_inference_classifier.load_state_dict(torch.load(classifier_file))", "\n", "# pooler parameters are added by default in an older transformers, so we have to ignore that those are uninitialized.", "\n", "", "evidence_inference_classifier", ".", "load_state_dict", "(", "torch", ".", "load", "(", "classifier_file", ")", ",", "strict", "=", "False", ")", "\n", "evidence_inference_classifier", ".", "cuda", "(", ")", "\n", "\n", "entailment_results", "=", "entailment_scores", "(", "evidence_inference_classifier", ",", "evidence_inference_tokenizer", ",", "generated", ",", "targets", ",", "preambles", ",", "use_ios", "=", "not", "args", ".", "unconditioned_classifier", ")", "\n", "print", "(", "'entailment'", ")", "\n", "print", "(", "entailment_results", ")", "\n", "\n", "assert", "args", ".", "output", "!=", "args", ".", "model_outputs", "\n", "with", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "of", ":", "\n", "        ", "of", ".", "write", "(", "'rouge\\n'", ")", "\n", "of", ".", "write", "(", "json", ".", "dumps", "(", "rouge_results", ")", ")", "\n", "of", ".", "write", "(", "'\\n\\n'", ")", "\n", "of", ".", "write", "(", "'entailment\\n'", ")", "\n", "of", ".", "write", "(", "json", ".", "dumps", "(", "entailment_results", ")", ")", "\n", "of", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.text_to_table_input_prep.process_review": [[53, 81], ["set", "map", "map", "list", "itertools.product", "filter", "tabular_summarizer_input_prep.sig_class", "len", "ret.append", "tabular_summarizer_input_prep.review_ios", "ms2.utils.TargetSummary"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.sig_class", "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.review_ios"], ["def", "process_review", "(", "review", ":", "Review", ")", "->", "List", "[", "TargetSummary", "]", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "review_io_parts", "=", "set", "(", "itertools", ".", "product", "(", "*", "review_ios", "(", "review", ")", ")", ")", "\n", "\n", "selected_study_references", "=", "map", "(", "select_reference_from_study", ",", "review", ".", "included_studies", ")", "\n", "processed_references", "=", "map", "(", "process_reference", ",", "selected_study_references", ")", "\n", "refs", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "is", "not", "None", ",", "processed_references", ")", ")", "\n", "\n", "for", "sig", "in", "review", ".", "significances", ":", "\n", "        ", "i", ",", "o", "=", "sig", ".", "intervention", ",", "sig", ".", "outcome", "\n", "if", "(", "i", ",", "o", ")", "not", "in", "review_io_parts", ":", "\n", "            ", "continue", "\n", "", "clazz", "=", "sig_class", "(", "sig", ".", "classification", ")", "\n", "if", "len", "(", "refs", ")", ">", "0", ":", "\n", "            ", "ret", ".", "append", "(", "TargetSummary", "(", "\n", "preface", "=", "'\\n'", ".", "join", "(", "[", "\n", "START_BACKGROUND", ",", "\n", "START_INTERVENTION", "+", "' '", "+", "i", "+", "' '", "+", "END_INTERVENTION", ",", "\n", "START_OUTCOME", "+", "' '", "+", "o", "+", "' '", "+", "END_OUTCOME", ",", "\n", "END_BACKGROUND", ",", "\n", "]", ")", ",", "\n", "target_texts", "=", "[", "clazz", "]", ",", "\n", "review_id", "=", "review", ".", "docid", "+", "'_int_'", "+", "i", "+", "'_out_'", "+", "o", ",", "\n", "references", "=", "refs", ",", "\n", "s2id", "=", "review", ".", "s2id", ",", "\n", "s2hash", "=", "review", ".", "s2hash", "\n", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.text_to_table_input_prep.main": [[82, 109], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "ms2.utils.get_tokenizer", "open", "open", "ms2.utils.Review.from_json", "text_to_table_input_prep.process_review", "list", "map", "list", "len", "filter", "functools.partial", "of.write", "of.write", "line.strip", "json.dumps", "dataclasses.asdict"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.get_tokenizer", "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.process_review"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Convert Reviews into TargetSummary objects'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "required", "=", "True", ",", "help", "=", "'jsonl serialized input reviews'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "True", ",", "help", "=", "'file for jsonl serialized output targets'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer'", ",", "required", "=", "True", ",", "help", "=", "'tokenizer type, e.g. BART'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_length'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "required", "=", "False", ",", "help", "=", "'truncate sequence lengths?'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "tokenizer", "=", "get_tokenizer", "(", "args", ".", "tokenizer", ")", "\n", "review_count", "=", "0", "\n", "written", "=", "0", "\n", "with", "open", "(", "args", ".", "input", ",", "'r'", ")", "as", "inf", ",", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "of", ":", "\n", "        ", "for", "line", "in", "inf", ":", "\n", "            ", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "review", "=", "Review", ".", "from_json", "(", "line", ")", "\n", "review_count", "+=", "1", "\n", "instances", "=", "process_review", "(", "review", ")", "\n", "instances", "=", "list", "(", "filter", "(", "valid_review", ",", "instances", ")", ")", "\n", "tensorized_reviews", "=", "map", "(", "functools", ".", "partial", "(", "tokenize_target_summary", ",", "tokenizer", "=", "tokenizer", ",", "max_length", "=", "args", ".", "max_length", ")", ",", "instances", ")", "\n", "tensorized_reviews", "=", "list", "(", "tensorized_reviews", ")", "\n", "for", "review", "in", "tensorized_reviews", ":", "\n", "                ", "of", ".", "write", "(", "json", ".", "dumps", "(", "asdict", "(", "review", ")", ")", ")", "\n", "of", ".", "write", "(", "'\\n'", ")", "\n", "written", "+=", "1", "\n", "", "", "", "assert", "written", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.f1_scorer.main": [[11, 56], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "sklearn.metrics.classification_report", "print", "sklearn.metrics.confusion_matrix", "print", "print", "open", "str_map.get", "s.replace.replace", "s.replace.replace", "json.loads", "generations.append", "targets.append", "print", "open", "of.write", "of.write", "of.write", "f1_scorer.main.fix_str"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Perform F1 scoring over textual versions of the output'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "required", "=", "True", ",", "help", "=", "'jsonl file of {generated: ..., target:...}'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "False", ",", "help", "=", "'output file'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "def", "fix_str", "(", "s", ")", ":", "\n", "        ", "for", "t", "in", "EXTRA_TOKENS", "+", "[", "SEP_TOKEN", ",", "'<s>'", ",", "'</s>'", "]", ":", "\n", "            ", "s", "=", "s", ".", "replace", "(", "t", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "", "return", "s", "\n", "\n", "", "generations", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "\n", "with", "open", "(", "args", ".", "input", ",", "'r'", ")", "as", "inf", ":", "\n", "        ", "for", "line", "in", "inf", ":", "\n", "            ", "content", "=", "json", ".", "loads", "(", "line", ")", "\n", "generations", ".", "append", "(", "fix_str", "(", "content", "[", "'generated'", "]", ")", ")", "\n", "targets", ".", "append", "(", "fix_str", "(", "content", "[", "'target'", "]", ")", ")", "\n", "\n", "", "", "str_map", "=", "{", "\n", "'significantly decreased'", ":", "0", ",", "\n", "'no significant difference'", ":", "1", ",", "\n", "'significantly increased'", ":", "2", ",", "\n", "'broken generation'", ":", "3", ",", "\n", "}", "\n", "\n", "for", "x", "in", "generations", ":", "\n", "        ", "if", "x", "not", "in", "str_map", ":", "\n", "            ", "print", "(", "x", ")", "\n", "", "", "generations", "=", "[", "str_map", ".", "get", "(", "x", ",", "str_map", "[", "'broken generation'", "]", ")", "for", "x", "in", "generations", "]", "\n", "targets", "=", "[", "str_map", "[", "x", "]", "for", "x", "in", "targets", "]", "\n", "\n", "scores", "=", "classification_report", "(", "targets", ",", "generations", ",", "digits", "=", "3", ",", "output_dict", "=", "True", ",", "target_names", "=", "list", "(", "str_map", ".", "keys", "(", ")", ")", "[", ":", "3", "]", ")", "\n", "print", "(", "scores", ")", "\n", "confusions", "=", "confusion_matrix", "(", "targets", ",", "generations", ",", "normalize", "=", "'true'", ")", "\n", "print", "(", "'confusion matrix'", ")", "\n", "print", "(", "confusions", ")", "\n", "if", "args", ".", "output", "is", "not", "None", ":", "\n", "        ", "assert", "args", ".", "output", "!=", "args", ".", "input", "\n", "with", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "of", ":", "\n", "            ", "of", ".", "write", "(", "json", ".", "dumps", "(", "scores", ")", ")", "\n", "of", ".", "write", "(", "'\\n'", ")", "\n", "of", ".", "write", "(", "json", ".", "dumps", "(", "confusions", ".", "tolist", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.decode.main": [[12, 54], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "ms2.models.transformer_summarizer.LightningBartSummarizer.add_args", "argparse.ArgumentParser.parse_args", "ms2.models.transformer_summarizer.LightningBartSummarizer", "ms2.models.transformer_summarizer.LightningBartSummarizer.load_state_dict", "ms2.models.transformer_summarizer.LightningBartSummarizer.cuda", "ms2.data.review_datasets.ReviewDataset.from_file", "logging.info", "open", "torch.load", "ms2.data.review_datasets.ToUnflattenedModelInputsFunction", "collate_fn", "ms2.models.transformer_summarizer.LightningBartSummarizer.summarizer.generate_summary", "ms2.models.transformer_summarizer.LightningBartSummarizer.tokenizer.decode", "ms2.models.transformer_summarizer.LightningBartSummarizer.tokenizer.decode", "logging.info", "logging.info", "output.write", "output.write", "output.flush", "outputs[].cpu", "json.dumps", "inputs.cuda", "preambles.cuda", "ms2.models.transformer_summarizer.LightningBartSummarizer.tokenizer.decode", "preambles.squeeze"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.LightningBartSummarizer.add_args", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda", "home.repos.pwc.inspect_result.allenai_ms2.data.review_datasets.ReviewDataset.from_file", "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.collate_fn", "home.repos.pwc.inspect_result.allenai_ms2.models.transformer_summarizer.SingleStreamBartSummarizer.generate_summary", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda", "home.repos.pwc.inspect_result.allenai_ms2.models.utils.PaddedSequence.cuda", "home.repos.pwc.inspect_result.allenai_ms2.models.abstract_classifier.LightningAbstractTagger.decode"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Summarize a document using a saved checkpoint'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "required", "=", "True", ",", "help", "=", "'Dataset for decoding'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "True", ",", "help", "=", "'Output file'", ")", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "required", "=", "True", ",", "help", "=", "'Saved checkpoint'", ")", "\n", "LightningBartSummarizer", ".", "add_args", "(", "parser", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "model", "=", "LightningBartSummarizer", "(", "args", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "args", ".", "checkpoint", ")", "[", "'state_dict'", "]", ")", "\n", "model", ".", "cuda", "(", ")", "\n", "collate_fn", "=", "model", ".", "summarizer", ".", "collate_fn", "\n", "dataset", "=", "ReviewDataset", ".", "from_file", "(", "args", ".", "input", ",", "format_function", "=", "ToUnflattenedModelInputsFunction", "(", "model", ".", "config", ".", "pad_token_id", ")", ")", "\n", "logging", ".", "info", "(", "f'Output file: {args.output}'", ")", "\n", "with", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "output", ":", "\n", "        ", "assert", "output", "is", "not", "None", "\n", "for", "instance", "in", "dataset", ":", "\n", "            ", "inputs", ",", "preambles", ",", "targets", "=", "collate_fn", "(", "[", "instance", "]", ")", "\n", "# defaults to try: https://github.com/huggingface/transformers/blob/v2.10.0/examples/summarization/bart/evaluate_cnn.py#L26-L40", "\n", "outputs", "=", "model", ".", "summarizer", ".", "generate_summary", "(", "\n", "inputs", "=", "inputs", ".", "cuda", "(", ")", ",", "\n", "preambles", "=", "preambles", ".", "cuda", "(", ")", ",", "\n", "num_beams", "=", "args", ".", "num_beams", ",", "\n", "length_penalty", "=", "args", ".", "length_penalty", ",", "\n", "max_length", "=", "args", ".", "max_length", ",", "\n", "min_length", "=", "args", ".", "min_length", ",", "\n", "no_repeat_ngram_size", "=", "args", ".", "no_repeat_ngram_size", ",", "\n", "early_stopping", "=", "True", ",", "\n", "decoder_start_token_id", "=", "model", ".", "config", ".", "bos_token_id", ",", "\n", "repetition_penalty", "=", "args", ".", "repetition_penalty", ",", "\n", "temperature", "=", "args", ".", "temperature", ",", "\n", ")", "\n", "generated", "=", "model", ".", "tokenizer", ".", "decode", "(", "outputs", "[", "0", "]", ".", "cpu", "(", ")", ",", "skip_special_tokens", "=", "False", ")", "\n", "target", "=", "model", ".", "tokenizer", ".", "decode", "(", "targets", ".", "data", "[", "0", "]", ",", "skip_special_tokens", "=", "False", ")", "\n", "logging", ".", "info", "(", "'Generated: {}'", ".", "format", "(", "generated", ")", ")", "\n", "logging", ".", "info", "(", "'Target:    {}'", ".", "format", "(", "target", ")", ")", "\n", "output", ".", "write", "(", "json", ".", "dumps", "(", "{", "\n", "'preamble'", ":", "model", ".", "tokenizer", ".", "decode", "(", "preambles", ".", "squeeze", "(", ")", ")", ",", "\n", "'generated'", ":", "generated", ",", "\n", "'target'", ":", "target", ",", "\n", "}", ")", ")", "\n", "output", ".", "write", "(", "'\\n'", ")", "\n", "output", ".", "flush", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.clean_str": [[53, 58], ["s.replace.replace", "s.replace.replace"], "function", ["None"], ["def", "clean_str", "(", "s", ")", ":", "\n", "    ", "for", "elem", "in", "EXTRA_TOKENS", ":", "\n", "        ", "s", "=", "s", ".", "replace", "(", "elem", ",", "''", ")", "\n", "s", "=", "s", ".", "replace", "(", "'  '", ",", "' '", ")", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.extract_non_target_parts": [[59, 65], ["set", "set.add"], "function", ["None"], ["", "def", "extract_non_target_parts", "(", "summary_parts", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ")", "->", "Set", "[", "str", "]", ":", "\n", "    ", "ret", "=", "set", "(", ")", "\n", "for", "field", ",", "value", ",", "_", "in", "summary_parts", ":", "\n", "        ", "if", "field", "not", "in", "TARGET_FIELDS", "and", "field", "not", "in", "{", "'FURTHER_STUDY'", ",", "'RECOMMENDATION'", ",", "'EVIDENCE_QUALITY'", ",", "'DETAILED_FINDINGS'", ",", "'RESULT'", "}", ":", "\n", "            ", "ret", ".", "add", "(", "value", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.review_ios": [[66, 73], ["tabular_summarizer_input_prep.extract_non_target_parts", "list", "list", "map", "map", "len", "map", "map", "re.findall", "re.findall"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.extract_non_target_parts"], ["", "def", "review_ios", "(", "review", ":", "Review", ")", "->", "Tuple", "[", "Set", "[", "str", "]", ",", "Set", "[", "str", "]", "]", ":", "\n", "    ", "assert", "review", ".", "structured_abstract", "is", "not", "None", "and", "len", "(", "review", ".", "structured_abstract", ")", ">", "0", "\n", "non_summary_inputs", "=", "extract_non_target_parts", "(", "review", ".", "structured_abstract", ")", "\n", "non_summary_inputs", "=", "'\\n'", ".", "join", "(", "non_summary_inputs", ")", "\n", "intervention_groups", "=", "list", "(", "map", "(", "str", ".", "strip", ",", "map", "(", "clean_str", ",", "re", ".", "findall", "(", "INTERVENTION_RE", ",", "non_summary_inputs", ")", ")", ")", ")", "\n", "outcome_groups", "=", "list", "(", "map", "(", "str", ".", "strip", ",", "map", "(", "clean_str", ",", "re", ".", "findall", "(", "OUTCOME_RE", ",", "non_summary_inputs", ")", ")", ")", ")", "\n", "return", "intervention_groups", ",", "outcome_groups", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.sig_class": [[74, 82], ["float", "dist.items"], "function", ["None"], ["", "def", "sig_class", "(", "dist", ":", "Dict", "[", "str", ",", "float", "]", ")", "->", "str", ":", "\n", "    ", "best_score", "=", "float", "(", "'-inf'", ")", "\n", "best_class", "=", "None", "\n", "for", "clazz", ",", "score", "in", "dist", ".", "items", "(", ")", ":", "\n", "        ", "if", "score", ">", "best_score", ":", "\n", "            ", "best_score", "=", "score", "\n", "best_class", "=", "clazz", "\n", "", "", "return", "best_class", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.process_review": [[83, 133], ["collections.defaultdict", "set", "review.extract_references", "itertools.product", "tabular_summarizer_input_prep.sig_class", "tabular_summarizer_input_prep.sig_class", "ref_opinions[].append", "len", "ret.append", "tabular_summarizer_input_prep.review_ios", "ms2.utils.TargetReference", "ms2.utils.TargetSummary"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.Review.extract_references", "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.sig_class", "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.sig_class", "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.review_ios"], ["", "def", "process_review", "(", "review", ":", "Review", ",", "evidence_threshold", ")", "->", "List", "[", "TargetSummary", "]", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "ref_opinions", "=", "defaultdict", "(", "list", ")", "\n", "review_io_parts", "=", "set", "(", "itertools", ".", "product", "(", "*", "review_ios", "(", "review", ")", ")", ")", "\n", "for", "ref", "in", "review", ".", "extract_references", "(", ")", ":", "\n", "        ", "if", "ref", ".", "significances", "is", "None", ":", "\n", "            ", "continue", "\n", "", "for", "sig", "in", "ref", ".", "significances", ":", "\n", "            ", "if", "sig", ".", "evidence_sentence_score", "<", "evidence_threshold", ":", "\n", "                ", "continue", "\n", "", "i", ",", "o", "=", "sig", ".", "intervention", ",", "sig", ".", "outcome", "\n", "if", "(", "i", ",", "o", ")", "not", "in", "review_io_parts", ":", "\n", "                ", "continue", "\n", "", "clazz", "=", "sig_class", "(", "sig", ".", "classification", ")", "\n", "fake_text", "=", "'\\n'", ".", "join", "(", "[", "\n", "START_REFERENCE", ",", "\n", "START_INTERVENTION", "+", "' '", "+", "i", "+", "' '", "+", "END_INTERVENTION", ",", "\n", "START_OUTCOME", "+", "' '", "+", "o", "+", "' '", "+", "END_OUTCOME", ",", "\n", "START_EVIDENCE", "+", "' '", "+", "sig", ".", "evidence_sentence", "+", "' '", "+", "END_EVIDENCE", ",", "\n", "SEP_TOKEN", "+", "' '", "+", "clazz", ",", "\n", "END_REFERENCE", ",", "\n", "]", ")", "\n", "ref_opinions", "[", "(", "i", ",", "o", ")", "]", ".", "append", "(", "TargetReference", "(", "\n", "title_abstract", "=", "fake_text", ",", "\n", "s2id", "=", "ref", ".", "s2id", ",", "\n", "s2hash", "=", "ref", ".", "s2hash", ",", "\n", "full_text", "=", "None", ",", "\n", ")", ")", "\n", "\n", "", "", "for", "sig", "in", "review", ".", "significances", ":", "\n", "       ", "i", ",", "o", "=", "sig", ".", "intervention", ",", "sig", ".", "outcome", "\n", "if", "(", "i", ",", "o", ")", "not", "in", "review_io_parts", ":", "\n", "           ", "continue", "\n", "", "clazz", "=", "sig_class", "(", "sig", ".", "classification", ")", "\n", "refs", "=", "ref_opinions", "[", "(", "i", ",", "o", ")", "]", "\n", "if", "len", "(", "refs", ")", ">", "0", ":", "\n", "           ", "ret", ".", "append", "(", "TargetSummary", "(", "\n", "preface", "=", "'\\n'", ".", "join", "(", "[", "\n", "START_BACKGROUND", ",", "\n", "START_INTERVENTION", "+", "' '", "+", "i", "+", "' '", "+", "END_INTERVENTION", ",", "\n", "START_OUTCOME", "+", "' '", "+", "o", "+", "' '", "+", "END_OUTCOME", ",", "\n", "END_BACKGROUND", ",", "\n", "]", ")", ",", "\n", "target_texts", "=", "[", "clazz", "]", ",", "\n", "review_id", "=", "review", ".", "docid", "+", "'_int_'", "+", "i", "+", "'_out_'", "+", "o", ",", "\n", "references", "=", "refs", ",", "\n", "s2id", "=", "review", ".", "s2id", ",", "\n", "s2hash", "=", "review", ".", "s2hash", "\n", ")", ")", "\n", "", "", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.main": [[134, 161], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "ms2.utils.get_tokenizer", "open", "open", "logging.info", "ms2.utils.Review.from_json", "tabular_summarizer_input_prep.process_review", "list", "map", "list", "len", "filter", "functools.partial", "of.write", "of.write", "line.strip", "json.dumps", "dataclasses.asdict"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.get_tokenizer", "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.process_review"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Convert Reviews into TargetSummary objects'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "required", "=", "True", ",", "help", "=", "'jsonl serialized input reviews'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "True", ",", "help", "=", "'file for jsonl serialized output targets'", ")", "\n", "parser", ".", "add_argument", "(", "'--evidence_sentence_threshold'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "'Evidence sentence score minimum thresholds'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer'", ",", "required", "=", "True", ",", "help", "=", "'tokenizer type, e.g. BART'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_length'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "required", "=", "False", ",", "help", "=", "'truncate sequence lengths?'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "tokenizer", "=", "get_tokenizer", "(", "args", ".", "tokenizer", ")", "\n", "review_count", "=", "0", "\n", "with", "open", "(", "args", ".", "input", ",", "'r'", ")", "as", "inf", ",", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "of", ":", "\n", "        ", "for", "line", "in", "inf", ":", "\n", "            ", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "review", "=", "Review", ".", "from_json", "(", "line", ")", "\n", "instances", "=", "process_review", "(", "review", ",", "evidence_threshold", "=", "args", ".", "evidence_sentence_threshold", ")", "\n", "instances", "=", "list", "(", "filter", "(", "valid_review", ",", "instances", ")", ")", "\n", "tensorized_reviews", "=", "map", "(", "functools", ".", "partial", "(", "tokenize_target_summary", ",", "tokenizer", "=", "tokenizer", ",", "max_length", "=", "args", ".", "max_length", ")", ",", "instances", ")", "\n", "tensorized_reviews", "=", "list", "(", "tensorized_reviews", ")", "\n", "for", "review", "in", "tensorized_reviews", ":", "\n", "                ", "of", ".", "write", "(", "json", ".", "dumps", "(", "asdict", "(", "review", ")", ")", ")", "\n", "of", ".", "write", "(", "'\\n'", ")", "\n", "review_count", "+=", "1", "\n", "", "", "logging", ".", "info", "(", "f'Wrote {review_count} instances'", ")", "\n", "assert", "review_count", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.select_reviews.main": [[4, 31], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "set", "print", "open", "set", "open", "parser.parse_args.input_reviews.split", "map", "open", "len", "json.loads", "content[].lower", "str", "of.write", "set.add"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Select a subset of a reviews file by s2id'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_reviews'", ",", "required", "=", "True", ",", "help", "=", "'Input reviews file, jsonl formatted'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_reviews'", ",", "required", "=", "True", ",", "help", "=", "'Output reviews file'", ")", "\n", "parser", ".", "add_argument", "(", "'--ids'", ",", "required", "=", "True", ",", "help", "=", "'s2ids file'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "with", "open", "(", "args", ".", "ids", ",", "'r'", ")", "as", "ids_file", ":", "\n", "        ", "ids", "=", "set", "(", "map", "(", "str", ".", "strip", ",", "ids_file", ")", ")", "\n", "\n", "", "already_written", "=", "set", "(", ")", "\n", "skipped", "=", "0", "\n", "with", "open", "(", "args", ".", "output_reviews", ",", "'w'", ")", "as", "of", ":", "\n", "        ", "for", "input_review", "in", "args", ".", "input_reviews", ".", "split", "(", "','", ")", ":", "\n", "            ", "with", "open", "(", "input_review", ",", "'r'", ")", "as", "inf", ":", "\n", "                ", "for", "line", "in", "inf", ":", "\n", "                    ", "content", "=", "json", ".", "loads", "(", "line", ")", "\n", "title", "=", "content", "[", "'title'", "]", ".", "lower", "(", ")", "\n", "if", "'redact'", "in", "title", "or", "'withdraw'", "in", "title", ":", "\n", "                        ", "skipped", "+=", "1", "\n", "continue", "\n", "", "eyeD", "=", "str", "(", "content", "[", "'s2id'", "]", ")", "\n", "if", "eyeD", "in", "ids", ":", "\n", "                        ", "if", "eyeD", "not", "in", "already_written", ":", "\n", "                            ", "of", ".", "write", "(", "line", ")", "\n", "already_written", ".", "add", "(", "eyeD", ")", "\n", "", "", "", "", "", "", "print", "(", "f'skipped {skipped} reviews as redacted or withdrawn, wrote {len(already_written)} reviews'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.table_to_text_summarizer_input.process_review": [[56, 96], ["set", "summarizer_input_prep.extract_summary_parts", "review.extract_references", "ret.append", "itertools.product", "ms2.utils.TargetSummary", "tabular_summarizer_input_prep.sig_class", "refs.append", "tabular_summarizer_input_prep.review_ios", "ms2.utils.TargetReference", "summarizer_input_prep.clean_targets"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.extract_summary_parts", "home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.Review.extract_references", "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.sig_class", "home.repos.pwc.inspect_result.allenai_ms2.modeling.tabular_summarizer_input_prep.review_ios", "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.clean_targets"], ["def", "process_review", "(", "review", ":", "Review", ",", "evidence_threshold", ")", "->", "List", "[", "TargetSummary", "]", ":", "\n", "    ", "ret", "=", "[", "]", "\n", "refs", "=", "[", "]", "\n", "review_io_parts", "=", "set", "(", "itertools", ".", "product", "(", "*", "review_ios", "(", "review", ")", ")", ")", "\n", "preface", ",", "target", ",", "_", "=", "extract_summary_parts", "(", "review", ".", "structured_abstract", ")", "\n", "for", "ref", "in", "review", ".", "extract_references", "(", ")", ":", "\n", "        ", "if", "ref", ".", "significances", "is", "None", ":", "\n", "            ", "continue", "\n", "", "for", "sig", "in", "ref", ".", "significances", ":", "\n", "            ", "if", "sig", ".", "evidence_sentence_score", "<", "evidence_threshold", ":", "\n", "                ", "continue", "\n", "", "i", ",", "o", "=", "sig", ".", "intervention", ",", "sig", ".", "outcome", "\n", "if", "(", "i", ",", "o", ")", "not", "in", "review_io_parts", ":", "\n", "                ", "continue", "\n", "#raise ValueError('Impossible!')", "\n", "", "clazz", "=", "sig_class", "(", "sig", ".", "classification", ")", "\n", "fake_text", "=", "'\\n'", ".", "join", "(", "[", "\n", "START_REFERENCE", ",", "\n", "START_INTERVENTION", "+", "' '", "+", "i", "+", "' '", "+", "END_INTERVENTION", ",", "\n", "START_OUTCOME", "+", "' '", "+", "o", "+", "' '", "+", "END_OUTCOME", ",", "\n", "START_EVIDENCE", "+", "' '", "+", "sig", ".", "evidence_sentence", "+", "' '", "+", "END_EVIDENCE", ",", "\n", "SEP_TOKEN", "+", "' '", "+", "clazz", ",", "\n", "END_REFERENCE", ",", "\n", "]", ")", "\n", "refs", ".", "append", "(", "TargetReference", "(", "\n", "title_abstract", "=", "fake_text", ",", "\n", "full_text", "=", "None", ",", "\n", "s2id", "=", "ref", ".", "s2id", ",", "\n", "s2hash", "=", "ref", ".", "s2hash", ",", "\n", ")", ")", "\n", "\n", "", "", "ret", ".", "append", "(", "TargetSummary", "(", "\n", "preface", "=", "START_BACKGROUND", "+", "' '", "+", "preface", "+", "' '", "+", "END_BACKGROUND", ",", "\n", "target_texts", "=", "clean_targets", "(", "[", "target", "]", ")", ",", "\n", "review_id", "=", "review", ".", "docid", ",", "\n", "references", "=", "refs", ",", "\n", "s2id", "=", "review", ".", "s2id", ",", "\n", "s2hash", "=", "review", ".", "s2hash", "\n", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.table_to_text_summarizer_input.main": [[97, 125], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "ms2.utils.get_tokenizer", "open", "open", "ms2.utils.Review.from_json", "table_to_text_summarizer_input.process_review", "list", "map", "list", "len", "filter", "functools.partial", "of.write", "of.write", "line.strip", "json.dumps", "dataclasses.asdict"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.get_tokenizer", "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.process_review"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Convert Reviews into TargetSummary objects'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "required", "=", "True", ",", "help", "=", "'jsonl serialized input reviews'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "True", ",", "help", "=", "'file for jsonl serialized output targets'", ")", "\n", "parser", ".", "add_argument", "(", "'--evidence_sentence_threshold'", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "'Evidence sentence score minimum thresholds'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer'", ",", "required", "=", "True", ",", "help", "=", "'tokenizer type, e.g. BART'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_length'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "required", "=", "False", ",", "help", "=", "'truncate sequence lengths?'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "tokenizer", "=", "get_tokenizer", "(", "args", ".", "tokenizer", ")", "\n", "review_count", "=", "0", "\n", "written", "=", "0", "\n", "with", "open", "(", "args", ".", "input", ",", "'r'", ")", "as", "inf", ",", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "of", ":", "\n", "        ", "for", "line", "in", "inf", ":", "\n", "            ", "if", "len", "(", "line", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "review", "=", "Review", ".", "from_json", "(", "line", ")", "\n", "review_count", "+=", "1", "\n", "instances", "=", "process_review", "(", "review", ",", "evidence_threshold", "=", "args", ".", "evidence_sentence_threshold", ")", "\n", "instances", "=", "list", "(", "filter", "(", "valid_review", ",", "instances", ")", ")", "\n", "tensorized_reviews", "=", "map", "(", "functools", ".", "partial", "(", "tokenize_target_summary", ",", "tokenizer", "=", "tokenizer", ",", "max_length", "=", "args", ".", "max_length", ")", ",", "instances", ")", "\n", "tensorized_reviews", "=", "list", "(", "tensorized_reviews", ")", "\n", "for", "review", "in", "tensorized_reviews", ":", "\n", "                ", "of", ".", "write", "(", "json", ".", "dumps", "(", "asdict", "(", "review", ")", ")", ")", "\n", "of", ".", "write", "(", "'\\n'", ")", "\n", "written", "+=", "1", "\n", "", "", "", "assert", "written", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.splits.main": [[5, 45], ["argparse.argumentparser", "argparse.argumentparser.add_argument", "argparse.argumentparser.add_argument", "argparse.argumentparser.add_argument", "argparse.argumentparser.add_argument", "argparse.argumentparser.add_argument", "argparse.argumentparser.parse_args", "splits.main.read_ids"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "argumentparser", "(", "description", "=", "'select a subset of a reviews file by s2id'", ")", "\n", "parser", ".", "add_argument", "(", "'--input_reviews'", ",", "required", "=", "True", ",", "help", "=", "'input reviews file, jsonl formatted'", ")", "\n", "parser", ".", "add_argument", "(", "'--output_dir'", ",", "required", "=", "True", ",", "help", "=", "'output reviews file'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_ids'", ",", "required", "=", "True", ",", "help", "=", "'s2ids file'", ")", "\n", "parser", ".", "add_argument", "(", "'--train_ids'", ",", "required", "=", "True", ",", "help", "=", "'s2ids file'", ")", "\n", "parser", ".", "add_argument", "(", "'--val_ids'", ",", "required", "=", "True", ",", "help", "=", "'s2ids file'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "def", "read_ids", "(", "ids_file", ")", ":", "\n", "        ", "with", "open", "(", "ids_file", ",", "'r'", ")", "as", "idf", ":", "\n", "            ", "ids", "=", "set", "(", "map", "(", "str", ".", "strip", ",", "idf", ")", ")", "\n", "return", "ids", "\n", "", "", "train_ids", "=", "read_ids", "(", "args", ".", "train_ids", ")", "\n", "val_ids", "=", "read_ids", "(", "args", ".", "val_ids", ")", "\n", "test_ids", "=", "read_ids", "(", "args", ".", "test_ids", ")", "\n", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'train.jsonl'", ")", "\n", "val_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'val.jsonl'", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'test.jsonl'", ")", "\n", "\n", "shared_ids", "=", "train_ids", "&", "val_ids", "&", "test_ids", "\n", "assert", "len", "(", "shared_ids", ")", "==", "0", "\n", "\n", "with", "open", "(", "train_file", ",", "'w'", ")", "as", "train_f", ",", "open", "(", "val_file", ",", "'w'", ")", "as", "val_f", ",", "open", "(", "test_file", ",", "'w'", ")", "as", "test_f", ":", "\n", "        ", "for", "input_review", "in", "args", ".", "input_reviews", ".", "split", "(", "','", ")", ":", "\n", "            ", "with", "open", "(", "input_review", ",", "'r'", ")", "as", "inf", ":", "\n", "                ", "for", "line", "in", "inf", ":", "\n", "                    ", "content", "=", "json", ".", "loads", "(", "line", ")", "\n", "eyeD", "=", "str", "(", "content", "[", "'s2id'", "]", ")", "\n", "if", "eyeD", "in", "train_ids", ":", "\n", "                        ", "train_f", ".", "write", "(", "line", ")", "\n", "", "elif", "eyeD", "in", "val_ids", ":", "\n", "                        ", "val_f", ".", "write", "(", "line", ")", "\n", "", "elif", "eyeD", "in", "test_ids", ":", "\n", "                        ", "test_f", ".", "write", "(", "line", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "f'Unknown id {eyeD}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.extract_summary_parts": [[56, 73], ["preambles.append", "targets.append", "unknown_fields.append"], "function", ["None"], ["def", "extract_summary_parts", "(", "summary_parts", ":", "List", "[", "Tuple", "[", "str", ",", "str", "]", "]", ")", "->", "Tuple", "[", "str", ",", "str", ",", "List", "[", "str", "]", "]", ":", "\n", "# TODO(jayd) filter for results-like, preamble-like, conclusions-line", "\n", "    ", "preambles", "=", "[", "]", "\n", "targets", "=", "[", "]", "\n", "unknown_fields", "=", "[", "]", "\n", "\n", "for", "field", ",", "value", ",", "_", "in", "summary_parts", ":", "\n", "        ", "if", "field", "in", "PREAMBLE_FIELDS", ":", "\n", "            ", "preambles", ".", "append", "(", "value", ")", "\n", "", "elif", "field", "in", "TARGET_FIELDS", ":", "\n", "            ", "targets", ".", "append", "(", "value", ")", "\n", "", "elif", "field", "in", "EXCLUDED_FIELDS", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "unknown_fields", ".", "append", "(", "field", ")", "\n", "\n", "", "", "return", "'\\n'", ".", "join", "(", "preambles", ")", ",", "'\\n'", ".", "join", "(", "targets", ")", ",", "unknown_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.select_reference_from_study": [[74, 87], ["len", "list", "list", "filter", "filter", "len", "len"], "function", ["None"], ["", "def", "select_reference_from_study", "(", "study", ":", "Study", ")", "->", "Optional", "[", "Reference", "]", ":", "\n", "    ", "if", "len", "(", "study", ".", "references", ")", "==", "1", ":", "\n", "        ", "return", "study", ".", "references", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "have_abstract", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "abstract", "is", "not", "None", ",", "study", ".", "references", ")", ")", "\n", "have_abstract_and_body", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", ".", "content", "is", "not", "None", ",", "have_abstract", ")", ")", "\n", "if", "len", "(", "have_abstract_and_body", ")", ">", "0", ":", "\n", "# TODO is there a better choice?", "\n", "            ", "return", "have_abstract_and_body", "[", "0", "]", "\n", "", "elif", "len", "(", "have_abstract", ")", ">", "0", ":", "\n", "            ", "return", "have_abstract", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.process_reference": [[88, 99], ["reference.title.strip", "reference.abstract.strip", "ms2.utils.TargetReference"], "function", ["None"], ["", "", "", "def", "process_reference", "(", "reference", ":", "Reference", ")", "->", "Optional", "[", "TargetReference", "]", ":", "\n", "    ", "if", "reference", ".", "abstract", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "title", "=", "reference", ".", "title", ".", "strip", "(", ")", "\n", "abstract", "=", "reference", ".", "abstract", ".", "strip", "(", ")", "\n", "title_abstract", "=", "START_REFERENCE", "+", "' '", "+", "title", "+", "' '", "+", "SEP_TOKEN", "+", "' '", "+", "abstract", "+", "' '", "+", "END_REFERENCE", "\n", "return", "TargetReference", "(", "\n", "title_abstract", "=", "title_abstract", ",", "\n", "full_text", "=", "None", ",", "\n", "s2id", "=", "reference", ".", "s2id", ",", "\n", "s2hash", "=", "reference", ".", "s2hash", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.process_review": [[101, 157], ["map", "map", "list", "summarizer_input_prep.clean_targets", "summarizer_input_prep.extract_summary_parts", "summarizer_input_prep.extract_summary_parts", "set", "set", "len", "logging.info", "clean_targets.append", "clean_targets.append", "len", "filter", "logging.info", "ms2.utils.TargetSummary", "len", "len", "len", "len", "len", "input_text.strip", "set", "len", "abs_preamble.strip", "len", "input_text.strip"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.clean_targets", "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.extract_summary_parts", "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.extract_summary_parts"], ["", "def", "process_review", "(", "review", ":", "Review", ",", "max_refs", ":", "int", ",", "tokenizer", ")", "->", "Tuple", "[", "Optional", "[", "TargetSummary", "]", ",", "Set", "[", "str", "]", "]", ":", "\n", "    ", "input_text", "=", "None", "\n", "target_texts", "=", "[", "]", "\n", "summaries", "=", "[", "]", "\n", "if", "review", ".", "structured_abstract", "is", "not", "None", "and", "len", "(", "review", ".", "structured_abstract", ")", ">", "1", ":", "\n", "        ", "abs_preamble", ",", "abs_target", ",", "abs_unknown_fields", "=", "extract_summary_parts", "(", "review", ".", "structured_abstract", ")", "\n", "if", "len", "(", "abs_preamble", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "abs_preamble", "=", "START_BACKGROUND", "+", "' '", "+", "abs_preamble", "+", "' '", "+", "END_BACKGROUND", "\n", "", "else", ":", "\n", "        ", "abs_preamble", ",", "abs_target", ",", "abs_unknown_fields", "=", "None", ",", "None", ",", "[", "]", "\n", "", "if", "review", ".", "structured_summary", "is", "not", "None", "and", "len", "(", "review", ".", "structured_summary", ")", ">", "1", ":", "\n", "        ", "sum_preamble", ",", "sum_target", ",", "sum_unknown_fields", "=", "extract_summary_parts", "(", "review", ".", "structured_summary", ")", "\n", "sum_preamble", "=", "START_BACKGROUND", "+", "' '", "+", "sum_preamble", "+", "' '", "+", "END_BACKGROUND", "\n", "", "else", ":", "\n", "        ", "sum_preamble", ",", "sum_target", ",", "sum_unknown_fields", "=", "None", ",", "None", ",", "[", "]", "\n", "\n", "", "unknown_fields", "=", "set", "(", "abs_unknown_fields", ")", "or", "set", "(", "sum_unknown_fields", ")", "\n", "if", "len", "(", "unknown_fields", ")", ">", "0", ":", "\n", "        ", "logging", ".", "info", "(", "f'For review {review.docid}, found unknown fields {unknown_fields} in abstract and summary!'", ")", "\n", "\n", "", "if", "abs_target", "is", "None", "and", "sum_target", "is", "None", ":", "\n", "        ", "return", "None", ",", "unknown_fields", "\n", "\n", "", "if", "abs_target", "is", "not", "None", "and", "len", "(", "abs_target", ")", ">", "0", ":", "\n", "        ", "target_texts", ".", "append", "(", "abs_target", ")", "\n", "", "if", "sum_target", "is", "not", "None", "and", "len", "(", "sum_target", ")", ">", "0", ":", "\n", "        ", "target_texts", ".", "append", "(", "sum_target", ")", "\n", "\n", "", "if", "abs_preamble", "is", "not", "None", ":", "\n", "        ", "input_text", "=", "abs_preamble", "\n", "", "elif", "sum_preamble", "is", "not", "None", ":", "\n", "        ", "input_text", "=", "sum_preamble", "\n", "", "else", ":", "\n", "        ", "input_text", "=", "''", "\n", "\n", "", "if", "len", "(", "input_text", ".", "strip", "(", ")", ")", "==", "0", ":", "\n", "        ", "return", "None", ",", "set", "(", ")", "\n", "\n", "", "selected_study_references", "=", "map", "(", "select_reference_from_study", ",", "review", ".", "included_studies", ")", "\n", "processed_references", "=", "map", "(", "process_reference", ",", "selected_study_references", ")", "\n", "references", "=", "list", "(", "filter", "(", "lambda", "x", ":", "x", "is", "not", "None", ",", "processed_references", ")", ")", "\n", "\n", "if", "max_refs", "is", "not", "None", "and", "len", "(", "references", ")", ">", "max_refs", ":", "\n", "        ", "logging", ".", "info", "(", "'Truncating review {} references from {} to {}'", ".", "format", "(", "review", ".", "docid", ",", "len", "(", "references", ")", ",", "max_refs", ")", ")", "\n", "references", "=", "references", "[", ":", "max_refs", "]", "\n", "", "target_texts", "=", "clean_targets", "(", "target_texts", ")", "\n", "\n", "return", "TargetSummary", "(", "\n", "preface", "=", "input_text", ".", "strip", "(", ")", ",", "\n", "target_texts", "=", "target_texts", ",", "\n", "review_id", "=", "review", ".", "docid", ",", "\n", "references", "=", "references", ",", "\n", "s2id", "=", "review", ".", "s2id", ",", "\n", "s2hash", "=", "review", ".", "s2hash", ",", "\n", ")", ",", "unknown_fields", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.clean_targets": [[158, 173], ["re.sub", "re.sub", "cleaned_targets.append", "cleaned_targets.append", "t.replace"], "function", ["None"], ["", "def", "clean_targets", "(", "target_texts", ":", "List", "[", "str", "]", ")", "->", "List", "[", "str", "]", ":", "\n", "# remove fancy markers from the target", "\n", "    ", "for", "elem", "in", "EXTRA_TOKENS", ":", "\n", "        ", "cleaned_targets", "=", "[", "]", "\n", "for", "t", "in", "target_texts", ":", "\n", "            ", "cleaned_targets", ".", "append", "(", "t", ".", "replace", "(", "elem", ",", "''", ")", ")", "\n", "", "target_texts", "=", "cleaned_targets", "\n", "# remove standard section markers from the start of the ", "\n", "", "cleaned_targets", "=", "[", "]", "\n", "for", "t", "in", "target_texts", ":", "\n", "        ", "beginning", ",", "end", "=", "t", "[", ":", "50", "]", ",", "t", "[", "50", ":", "]", "\n", "beginning", "=", "re", ".", "sub", "(", "fields_re", ",", "''", ",", "beginning", ")", "\n", "beginning", "=", "re", ".", "sub", "(", "spaces_re", ",", "' '", ",", "beginning", ")", "\n", "cleaned_targets", ".", "append", "(", "beginning", "+", "end", ")", "\n", "", "return", "cleaned_targets", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.tokenize_target_summary": [[174, 223], ["dataclasses.replace", "tokenizer.encode", "tokenizer.encode", "dataclasses.replace", "tokenizer.encode", "len", "tokenizer.encode", "tokenizer.encode", "tokenizer.encode", "target_texts.append", "len", "list", "map", "tokenizer.encode"], "function", ["None"], ["", "def", "tokenize_target_summary", "(", "summary", ":", "TargetSummary", ",", "tokenizer", ",", "max_length", ":", "Optional", "[", "int", "]", ")", "->", "TargetSummary", ":", "\n", "    ", "end_reference", "=", "tokenizer", ".", "encode", "(", "END_REFERENCE", ",", "add_special_tokens", "=", "False", ")", "[", "0", "]", "\n", "def", "tokenize_target_reference", "(", "target_reference", ":", "TargetReference", ")", "->", "TargetReference", ":", "\n", "        ", "title_abstract", "=", "tokenizer", ".", "encode", "(", "\n", "target_reference", ".", "title_abstract", ",", "\n", "add_special_tokens", "=", "False", ",", "\n", "truncation", "=", "max_length", "is", "not", "None", ",", "\n", "max_length", "=", "max_length", "\n", ")", "\n", "if", "title_abstract", "[", "-", "1", "]", "!=", "end_reference", ":", "\n", "            ", "title_abstract", "=", "title_abstract", "+", "[", "end_reference", "]", "\n", "", "return", "replace", "(", "target_reference", ",", "\n", "title_abstract", "=", "title_abstract", ",", "\n", "full_text", "=", "tokenizer", ".", "encode", "(", "\n", "target_reference", ".", "full_text", ",", "\n", "add_special_tokens", "=", "False", ",", "\n", "truncation", "=", "max_length", "is", "not", "None", ",", "max_length", "=", "max_length", "\n", ")", "if", "target_reference", ".", "full_text", "is", "not", "None", "else", "None", ",", "\n", ")", "\n", "\n", "", "end_background", "=", "tokenizer", ".", "encode", "(", "END_BACKGROUND", ",", "add_special_tokens", "=", "False", ")", "[", "0", "]", "\n", "if", "len", "(", "summary", ".", "preface", ")", ">", "0", ":", "\n", "        ", "preface", "=", "tokenizer", ".", "encode", "(", "summary", ".", "preface", ",", "\n", "truncation", "=", "max_length", "is", "not", "None", ",", "\n", "max_length", "=", "max_length", ",", "\n", "add_special_tokens", "=", "False", ")", "\n", "if", "preface", "[", "-", "1", "]", "!=", "end_background", ":", "\n", "            ", "preface", "=", "preface", "+", "[", "end_background", "]", "\n", "", "", "else", ":", "\n", "        ", "preface", "=", "None", "\n", "\n", "", "target_texts", "=", "[", "]", "\n", "eos_token", "=", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ".", "content", ",", "add_special_tokens", "=", "False", ")", "[", "0", "]", "\n", "for", "target_text", "in", "summary", ".", "target_texts", ":", "\n", "        ", "if", "len", "(", "target_text", ")", "==", "0", ":", "\n", "            ", "continue", "\n", "", "target_text", "=", "tokenizer", ".", "encode", "(", "\n", "target_text", ",", "\n", "add_special_tokens", "=", "True", ",", "\n", "truncation", "=", "max_length", "is", "not", "None", ",", "max_length", "=", "max_length", "\n", ")", "\n", "if", "target_text", "[", "-", "1", "]", "!=", "eos_token", ":", "\n", "            ", "target_text", "=", "target_text", "+", "[", "eos_token", "]", "\n", "", "target_texts", ".", "append", "(", "target_text", ")", "\n", "\n", "", "return", "replace", "(", "summary", ",", "\n", "preface", "=", "preface", ",", "\n", "target_texts", "=", "target_texts", ",", "\n", "references", "=", "list", "(", "map", "(", "tokenize_target_reference", ",", "summary", ".", "references", ")", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.valid_review": [[225, 233], ["len", "len"], "function", ["None"], ["", "def", "valid_review", "(", "summary", ":", "TargetSummary", ")", "->", "bool", ":", "\n", "    ", "if", "summary", "is", "None", ":", "\n", "        ", "return", "False", "\n", "", "if", "len", "(", "summary", ".", "references", ")", "==", "0", ":", "\n", "        ", "return", "False", "\n", "", "if", "len", "(", "summary", ".", "target_texts", ")", "==", "0", ":", "\n", "        ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.total_reference_lengths": [[234, 236], ["sum", "len"], "function", ["None"], ["", "def", "total_reference_lengths", "(", "summary", ":", "TargetSummary", ")", "->", "int", ":", "\n", "    ", "return", "sum", "(", "(", "len", "(", "ref", ".", "title_abstract", ")", "for", "ref", "in", "summary", ".", "references", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.total_decoding_lengths": [[237, 241], ["max", "len", "map"], "function", ["None"], ["", "def", "total_decoding_lengths", "(", "summary", ":", "TargetSummary", ")", "->", "int", ":", "\n", "    ", "preface_length", "=", "len", "(", "summary", ".", "preface", ")", "if", "summary", ".", "preface", "is", "not", "None", "else", "0", "\n", "target_lengths", "=", "max", "(", "map", "(", "len", ",", "summary", ".", "target_texts", ")", ")", "\n", "return", "preface_length", "+", "target_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.allenai_ms2.modeling.summarizer_input_prep.main": [[242, 288], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "ms2.utils.get_tokenizer", "ms2.utils.Review.read_reviews", "logging.info", "min", "max", "logging.info", "logging.info", "ms2.utils.get_tokenizer.save_pretrained", "os.path.join", "os.path.exists", "multiprocessing.Pool", "logging.info", "p.imap", "filter", "list", "zip", "set", "list", "logging.info", "p.imap", "list", "logging.info", "list", "list", "sum", "sum", "len", "open", "tqdm.tqdm", "shutil.copyfile", "functools.partial", "itertools.chain.from_iterable", "len", "logging.info", "filter", "functools.partial", "p.map", "p.map", "zip", "of.write", "of.write", "os.path.join", "len", "json.dumps", "len", "len", "dataclasses.asdict"], "function", ["home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.get_tokenizer", "home.repos.pwc.inspect_result.allenai_ms2.ms2.utils.Review.read_reviews"], ["", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Convert Reviews into TargetSummary objects'", ")", "\n", "parser", ".", "add_argument", "(", "'--input'", ",", "required", "=", "True", ",", "help", "=", "'jsonl serialized input reviews'", ")", "\n", "parser", ".", "add_argument", "(", "'--output'", ",", "required", "=", "True", ",", "help", "=", "'file for jsonl serialized output targets'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer_save'", ",", "required", "=", "False", ",", "default", "=", "None", ",", "help", "=", "'Where should we save the tokenizer to?'", ")", "\n", "parser", ".", "add_argument", "(", "'--tokenizer'", ",", "required", "=", "True", ",", "help", "=", "'tokenizer type, e.g. BART'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_length'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "required", "=", "False", ",", "help", "=", "'truncate sequence lengths?'", ")", "\n", "parser", ".", "add_argument", "(", "'--max_refs'", ",", "type", "=", "int", ",", "default", "=", "None", ",", "required", "=", "False", ",", "help", "=", "'truncate number of included refs?'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "# TODO(jayd) assign ids to these elements!", "\n", "tokenizer", "=", "get_tokenizer", "(", "args", ".", "tokenizer", ")", "\n", "if", "args", ".", "tokenizer_save", "is", "not", "None", ":", "\n", "        ", "logging", ".", "info", "(", "f'Saving tokenizer with extended vocab to {args.tokenizer_save}'", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "tokenizer_save", ")", "\n", "# workaround for what seems to be a huggingface bug", "\n", "likely_misnamed_tokenizer_config", "=", "os", ".", "path", ".", "join", "(", "args", ".", "tokenizer_save", ",", "'tokenizer_config.json'", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "likely_misnamed_tokenizer_config", ")", ":", "\n", "            ", "shutil", ".", "copyfile", "(", "likely_misnamed_tokenizer_config", ",", "os", ".", "path", ".", "join", "(", "args", ".", "tokenizer_save", ",", "'config.json'", ")", ")", "\n", "", "", "reviews", "=", "Review", ".", "read_reviews", "(", "args", ".", "input", ")", "\n", "logging", ".", "info", "(", "f'Loaded {len(reviews)}'", ")", "\n", "with", "multiprocessing", ".", "Pool", "(", "processes", "=", "NUM_PROCS", ")", "as", "p", ":", "\n", "        ", "logging", ".", "info", "(", "'Processing reviews'", ")", "\n", "processed", "=", "p", ".", "imap", "(", "functools", ".", "partial", "(", "process_review", ",", "max_refs", "=", "args", ".", "max_refs", ",", "tokenizer", "=", "tokenizer", ")", ",", "reviews", ",", "chunksize", "=", "1", ")", "\n", "processed", "=", "filter", "(", "lambda", "x", ":", "x", "is", "not", "None", ",", "processed", ")", "\n", "processed", "=", "list", "(", "processed", ")", "\n", "target_reviews", ",", "unknown_fields", "=", "zip", "(", "*", "processed", ")", "\n", "all_unknown_fields", "=", "set", "(", "itertools", ".", "chain", ".", "from_iterable", "(", "unknown_fields", ")", ")", "\n", "if", "len", "(", "all_unknown_fields", ")", ">", "0", ":", "\n", "            ", "logging", ".", "info", "(", "f'Unable to process fields {all_unknown_fields}'", ")", "\n", "", "non_empty_reviews", "=", "list", "(", "filter", "(", "valid_review", ",", "target_reviews", ")", ")", "\n", "logging", ".", "info", "(", "'Tensorizing reviews'", ")", "\n", "tensorized_reviews", "=", "p", ".", "imap", "(", "functools", ".", "partial", "(", "tokenize_target_summary", ",", "tokenizer", "=", "tokenizer", ",", "max_length", "=", "args", ".", "max_length", ")", ",", "non_empty_reviews", ",", "chunksize", "=", "1", ")", "\n", "tensorized_reviews", "=", "list", "(", "tensorized_reviews", ")", "\n", "logging", ".", "info", "(", "f'After processing, a total of {len(non_empty_reviews)} reviews are left, with {len(tensorized_reviews)} reviews for input'", ")", "\n", "review_target_lengths", "=", "list", "(", "p", ".", "map", "(", "total_decoding_lengths", ",", "tensorized_reviews", ")", ")", "\n", "review_reference_lengths", "=", "list", "(", "p", ".", "map", "(", "total_reference_lengths", ",", "tensorized_reviews", ")", ")", "\n", "", "total_lengths", "=", "[", "sum", "(", "x", ")", "for", "x", "in", "zip", "(", "review_reference_lengths", ",", "review_target_lengths", ")", "]", "\n", "min_length", "=", "min", "(", "total_lengths", ")", "\n", "max_length", "=", "max", "(", "total_lengths", ")", "\n", "avg_length", "=", "sum", "(", "total_lengths", ")", "/", "len", "(", "total_lengths", ")", "\n", "logging", ".", "info", "(", "f'Input/Output lengths are a minimum of {min_length} wordpieces long, maximum of {max_length} wordpieces, and average of {avg_length} wordpieces.'", ")", "\n", "with", "open", "(", "args", ".", "output", ",", "'w'", ")", "as", "of", ":", "\n", "        ", "for", "review", "in", "tqdm", ".", "tqdm", "(", "tensorized_reviews", ")", ":", "\n", "            ", "of", ".", "write", "(", "json", ".", "dumps", "(", "asdict", "(", "review", ")", ")", ")", "\n", "of", ".", "write", "(", "'\\n'", ")", "\n", "\n"]]}