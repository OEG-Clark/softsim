{"home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.get_dataset_instance": [[50, 59], ["isinstance", "task_adaptation.registry.Registry.lookup", "Registry.lookup.", "isinstance", "ValueError", "type"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup"], ["def", "get_dataset_instance", "(", "data_params", ")", ":", "\n", "  ", "if", "isinstance", "(", "data_params", "[", "\"dataset\"", "]", ",", "str", ")", ":", "\n", "    ", "data_cls", "=", "Registry", ".", "lookup", "(", "data_params", "[", "\"dataset\"", "]", ")", "\n", "return", "data_cls", "(", "data_dir", "=", "data_params", "[", "\"data_dir\"", "]", ")", "\n", "", "elif", "isinstance", "(", "data_params", "[", "\"dataset\"", "]", ",", "base", ".", "ImageData", ")", ":", "\n", "    ", "return", "data_params", "[", "\"dataset\"", "]", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unknown type for \\\"dataset\\\" field: {}\"", ".", "format", "(", "\n", "type", "(", "data_params", "[", "\"dataset\"", "]", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.preprocess_fn": [[61, 70], ["tensorflow.image.resize", "tensorflow.cast"], "function", ["None"], ["", "", "def", "preprocess_fn", "(", "data", ",", "size", "=", "224", ",", "input_range", "=", "(", "0.0", ",", "1.0", ")", ")", ":", "\n", "  ", "image", "=", "data", "[", "\"image\"", "]", "\n", "image", "=", "tf", ".", "image", ".", "resize", "(", "image", ",", "[", "size", ",", "size", "]", ")", "\n", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "/", "255.0", "\n", "image", "=", "image", "*", "(", "input_range", "[", "1", "]", "-", "input_range", "[", "0", "]", ")", "+", "input_range", "[", "0", "]", "\n", "\n", "data", "[", "\"image\"", "]", "=", "image", "\n", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.build_data_pipeline": [[72, 99], ["data_loader.get_dataset_instance", "functools.partial", "ValueError", "functools.partial.", "functools.partial"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.get_dataset_instance"], ["", "def", "build_data_pipeline", "(", "data_params", ",", "mode", ")", ":", "\n", "  ", "\"\"\"Builds data input pipeline.\"\"\"", "\n", "\n", "if", "mode", "not", "in", "[", "\"train\"", ",", "\"eval\"", "]", ":", "\n", "    ", "raise", "ValueError", "(", "\"The input pipeline supports two modes: `train` or `eval`.\"", "\n", "\"Provided mode is {}\"", ".", "format", "(", "mode", ")", ")", "\n", "\n", "", "data", "=", "get_dataset_instance", "(", "data_params", ")", "\n", "data_fn", "=", "functools", ".", "partial", "(", "\n", "data", ".", "get_tf_data", ",", "\n", "split_name", "=", "(", "data_params", "[", "\"dataset_train_split_name\"", "]", "if", "mode", "==", "\"train\"", "\n", "else", "data_params", "[", "\"dataset_eval_split_name\"", "]", ")", ",", "\n", "preprocess_fn", "=", "functools", ".", "partial", "(", "\n", "preprocess_fn", ",", "\n", "input_range", "=", "data_params", "[", "\"input_range\"", "]", ",", "\n", ")", ",", "\n", "for_eval", "=", "mode", "==", "\"eval\"", ",", "\n", "shuffle_buffer_size", "=", "data_params", "[", "\"shuffle_buffer_size\"", "]", ",", "\n", "prefetch", "=", "data_params", "[", "\"prefetch\"", "]", ",", "\n", "train_examples", "=", "data_params", "[", "\"train_examples\"", "]", ",", "\n", ")", "\n", "\n", "# Estimator's API requires a named parameter \"params\".", "\n", "def", "input_fn", "(", "params", ")", ":", "\n", "    ", "return", "data_fn", "(", "batch_size", "=", "params", "[", "\"batch_size\"", "]", ")", "\n", "\n", "", "return", "input_fn", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model_test.ModelTest.call_model_fn": [[37, 56], ["tensorflow.reset_default_graph", "tensorflow.constant", "tensorflow.constant", "task_adaptation.model_fn", "task_adaptation.model_fn", "d.items", "numpy.random.random", "numpy.random.randint", "task_adaptation.get_optimization_params", "task_adaptation.get_optimization_params", "task_adaptation.get_data_params", "task_adaptation.get_data_params"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model.model_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model.model_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_optimization_params", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_optimization_params", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_data_params", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_data_params"], ["  ", "def", "call_model_fn", "(", "self", ",", "hub_module", ")", ":", "\n", "    ", "params", "=", "{", "\n", "k", ":", "v", "for", "d", "in", "[", "\n", "test_utils", ".", "get_optimization_params", "(", ")", ",", "\n", "test_utils", ".", "get_data_params", "(", ")", ",", "\n", "{", "\n", "\"hub_module\"", ":", "hub_module", ",", "\n", "\"hub_module_signature\"", ":", "None", ",", "\n", "\"num_classes\"", ":", "NUM_CLASSES", "\n", "}", "\n", "]", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", "\n", "}", "\n", "\n", "for", "mode", "in", "[", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ",", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", "]", ":", "\n", "      ", "tf", ".", "reset_default_graph", "(", ")", "\n", "images", "=", "tf", ".", "constant", "(", "\n", "np", ".", "random", ".", "random", "(", "[", "32", ",", "224", ",", "224", ",", "3", "]", ")", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "labels", "=", "tf", ".", "constant", "(", "np", ".", "random", ".", "randint", "(", "0", ",", "1000", ",", "[", "32", "]", ")", ",", "dtype", "=", "tf", ".", "int64", ")", "\n", "model", ".", "model_fn", "(", "{", "\"image\"", ":", "images", ",", "\"label\"", ":", "labels", "}", ",", "mode", ",", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model_test.ModelTest.test_hub_module_fn": [[57, 62], ["os.path.join", "task_adaptation.create_dummy_hub_model", "task_adaptation.create_dummy_hub_model", "model_test.ModelTest.call_model_fn", "model_test.ModelTest.get_temp_dir"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.create_dummy_hub_model", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.create_dummy_hub_model", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model_test.ModelTest.call_model_fn"], ["", "", "def", "test_hub_module_fn", "(", "self", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"module\"", ")", "\n", "test_utils", ".", "create_dummy_hub_model", "(", "path", ",", "NUM_CLASSES", ")", "\n", "\n", "self", ".", "call_model_fn", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model_test.ModelTest.test_saved_model_fn": [[63, 68], ["os.path.join", "task_adaptation.create_dummy_saved_model", "task_adaptation.create_dummy_saved_model", "model_test.ModelTest.call_model_fn", "model_test.ModelTest.get_temp_dir"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.create_dummy_saved_model", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.create_dummy_saved_model", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model_test.ModelTest.call_model_fn"], ["", "def", "test_saved_model_fn", "(", "self", ")", ":", "\n", "    ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"model\"", ")", "\n", "test_utils", ".", "create_dummy_saved_model", "(", "path", ")", "\n", "\n", "self", ".", "call_model_fn", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.trainer.apply_warmup_lr": [[25, 36], ["tensorflow.cond", "tensorflow.cast", "tensorflow.less", "tensorflow.cast"], "function", ["None"], ["def", "apply_warmup_lr", "(", "global_step", ",", "lr", ",", "base_lr", ",", "warmup_steps", ")", ":", "\n", "  ", "\"\"\"Modifies learning rate, such that it linearly grows from 0 to base_lr.\"\"\"", "\n", "\n", "if", "warmup_steps", ">", "0", ":", "\n", "    ", "warmup_lr", "=", "(", "tf", ".", "cast", "(", "global_step", ",", "tf", ".", "float32", ")", "*", "(", "base_lr", "/", "warmup_steps", ")", ")", "\n", "\n", "lr", "=", "tf", ".", "cond", "(", "tf", ".", "less", "(", "tf", ".", "cast", "(", "global_step", ",", "tf", ".", "float32", ")", ",", "warmup_steps", ")", ",", "\n", "lambda", ":", "warmup_lr", ",", "\n", "lambda", ":", "lr", ")", "\n", "\n", "", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.trainer.get_train_op": [[38, 68], ["tensorflow.train.get_or_create_global_step", "tensorflow.train.piecewise_constant", "trainer.apply_warmup_lr", "tensorflow.train.MomentumOptimizer", "tf.contrib.tpu.CrossShardOptimizer.minimize", "tensorflow.get_collection", "tensorflow.assign_add", "tensorflow.group", "tensorflow.contrib.tpu.CrossShardOptimizer", "range", "len"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.trainer.apply_warmup_lr"], ["", "def", "get_train_op", "(", "loss", ",", "\n", "initial_learning_rate", ",", "\n", "momentum", ",", "\n", "lr_decay_factor", ",", "\n", "decay_steps", ",", "\n", "warmup_steps", ",", "\n", "use_tpu", "=", "False", ")", ":", "\n", "  ", "\"\"\"Builds an SGD update operation.\"\"\"", "\n", "\n", "global_step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "\n", "lr", "=", "tf", ".", "train", ".", "piecewise_constant", "(", "\n", "global_step", ",", "\n", "decay_steps", ",", "\n", "[", "initial_learning_rate", "*", "(", "lr_decay_factor", "**", "i", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "decay_steps", ")", "+", "1", ")", "]", ")", "\n", "lr", "=", "apply_warmup_lr", "(", "global_step", ",", "lr", ",", "initial_learning_rate", ",", "warmup_steps", ")", "\n", "\n", "optimizer", "=", "tf", ".", "train", ".", "MomentumOptimizer", "(", "learning_rate", "=", "lr", ",", "\n", "momentum", "=", "momentum", ")", "\n", "if", "use_tpu", ":", "\n", "    ", "optimizer", "=", "tf", ".", "contrib", ".", "tpu", ".", "CrossShardOptimizer", "(", "optimizer", ")", "\n", "\n", "", "train_op", "=", "optimizer", ".", "minimize", "(", "loss", ")", "\n", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "\n", "global_step_inc_op", "=", "tf", ".", "assign_add", "(", "global_step", ",", "1", ")", "\n", "\n", "return", "tf", ".", "group", "(", "[", "train_op", ",", "update_ops", ",", "global_step_inc_op", "]", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.setup_estimator": [[40, 94], ["data_params[].get_num_classes", "tensorflow.contrib.cluster_resolver.TPUClusterResolver", "tensorflow.contrib.tpu.RunConfig", "tensorflow.estimator.RunConfig", "params.pop", "params.pop", "tensorflow.contrib.tpu.TPUEstimator", "tensorflow.estimator.Estimator", "d.items", "tensorflow.contrib.tpu.TPUConfig"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_classes"], ["def", "setup_estimator", "(", "\n", "hub_module", ",", "\n", "hub_module_signature", ",", "\n", "work_dir", ",", "\n", "tpu_name", ",", "\n", "save_checkpoints_steps", ",", "\n", "optimization_params", ",", "\n", "data_params", ")", ":", "\n", "  ", "\"\"\"Produces TPUEstimator object for a given configuration.\"\"\"", "\n", "\n", "# Merge all parameters into single dictionary (for tf.estimator API).", "\n", "num_classes", "=", "data_params", "[", "\"dataset\"", "]", ".", "get_num_classes", "(", ")", "\n", "params", "=", "{", "k", ":", "v", "for", "d", "in", "[", "optimization_params", ",", "data_params", ",", "\n", "{", "\"hub_module\"", ":", "hub_module", ",", "\n", "\"hub_module_signature\"", ":", "hub_module_signature", ",", "\n", "\"num_classes\"", ":", "num_classes", "}", "]", "\n", "for", "k", ",", "v", "in", "d", ".", "items", "(", ")", "}", "\n", "\n", "# Defines the configutation of an adaptation/evaluation loop.", "\n", "\n", "if", "tpu_name", "is", "not", "None", ":", "\n", "    ", "cluster", "=", "tf", ".", "contrib", ".", "cluster_resolver", ".", "TPUClusterResolver", "(", "tpu", "=", "tpu_name", ")", "\n", "config", "=", "tf", ".", "contrib", ".", "tpu", ".", "RunConfig", "(", "\n", "model_dir", "=", "work_dir", ",", "\n", "cluster", "=", "cluster", ",", "\n", "keep_checkpoint_max", "=", "None", ",", "\n", "save_checkpoints_steps", "=", "save_checkpoints_steps", ",", "\n", "tpu_config", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUConfig", "(", "\n", "iterations_per_loop", "=", "TPU_ITERATION_PER_LOOP", ")", ")", "\n", "", "else", ":", "\n", "    ", "config", "=", "tf", ".", "estimator", ".", "RunConfig", "(", "\n", "model_dir", "=", "work_dir", ",", "\n", "keep_checkpoint_max", "=", "None", ",", "\n", "save_checkpoints_steps", "=", "save_checkpoints_steps", ")", "\n", "\n", "", "if", "tpu_name", "is", "not", "None", ":", "\n", "    ", "batch_size", "=", "params", ".", "pop", "(", "\"batch_size\"", ")", "\n", "batch_size_eval", "=", "params", ".", "pop", "(", "\"batch_size_eval\"", ")", "\n", "estimator", "=", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimator", "(", "\n", "model_fn", "=", "model", ".", "model_fn", ",", "\n", "model_dir", "=", "work_dir", ",", "\n", "params", "=", "params", ",", "\n", "config", "=", "config", ",", "\n", "use_tpu", "=", "True", ",", "\n", "train_batch_size", "=", "batch_size", ",", "\n", "eval_batch_size", "=", "batch_size_eval", ")", "\n", "", "else", ":", "\n", "    ", "estimator", "=", "tf", ".", "estimator", ".", "Estimator", "(", "\n", "model_fn", "=", "model", ".", "model_fn", ",", "\n", "model_dir", "=", "work_dir", ",", "\n", "params", "=", "params", ",", "\n", "config", "=", "config", ")", "\n", "\n", "", "return", "estimator", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.run_training_loop": [[96, 116], ["task_adaptation.get_dataset_instance", "loop.setup_estimator", "task_adaptation.build_data_pipeline", "setup_estimator.train"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.get_dataset_instance", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.setup_estimator", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.build_data_pipeline"], ["", "def", "run_training_loop", "(", "hub_module", ",", "\n", "hub_module_signature", ",", "\n", "work_dir", ",", "\n", "tpu_name", ",", "\n", "save_checkpoints_steps", ",", "\n", "optimization_params", ",", "\n", "data_params", ")", ":", "\n", "  ", "\"\"\"Runs training loop.\"\"\"", "\n", "data_params", "[", "\"dataset\"", "]", "=", "data_loader", ".", "get_dataset_instance", "(", "data_params", ")", "\n", "estimator", "=", "setup_estimator", "(", "hub_module", ",", "\n", "hub_module_signature", ",", "\n", "work_dir", ",", "\n", "tpu_name", ",", "\n", "save_checkpoints_steps", ",", "\n", "optimization_params", ",", "\n", "data_params", ")", "\n", "input_fn", "=", "data_loader", ".", "build_data_pipeline", "(", "data_params", ",", "mode", "=", "\"train\"", ")", "\n", "\n", "# TPUs require the max number of steps to be specified explicitly.", "\n", "estimator", ".", "train", "(", "input_fn", ",", "max_steps", "=", "optimization_params", "[", "\"max_steps\"", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.run_evaluation_loop": [[118, 153], ["task_adaptation.get_dataset_instance", "loop.setup_estimator", "task_adaptation.build_data_pipeline", "tensorflow.gfile.Open", "set", "sorted", "os.path.join", "os.path.join", "setup_estimator.evaluate", "f.write", "tensorflow.gfile.ListDirectory", "f.startswith", "int", "f.split", "data_params[].get_num_samples", "x.split"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.get_dataset_instance", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.setup_estimator", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.build_data_pipeline", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_samples"], ["", "def", "run_evaluation_loop", "(", "hub_module", ",", "\n", "hub_module_signature", ",", "\n", "work_dir", ",", "\n", "tpu_name", ",", "\n", "save_checkpoints_steps", ",", "\n", "optimization_params", ",", "\n", "data_params", ")", ":", "\n", "  ", "\"\"\"Runs evaluation loop.\"\"\"", "\n", "data_params", "[", "\"dataset\"", "]", "=", "data_loader", ".", "get_dataset_instance", "(", "data_params", ")", "\n", "estimator", "=", "setup_estimator", "(", "hub_module", ",", "\n", "hub_module_signature", ",", "\n", "work_dir", ",", "\n", "tpu_name", ",", "\n", "save_checkpoints_steps", ",", "\n", "optimization_params", ",", "\n", "data_params", ")", "\n", "input_fn", "=", "data_loader", ".", "build_data_pipeline", "(", "data_params", ",", "mode", "=", "\"eval\"", ")", "\n", "\n", "with", "tf", ".", "gfile", ".", "Open", "(", "os", ".", "path", ".", "join", "(", "work_dir", ",", "\"result_file.txt\"", ")", ",", "\"w\"", ")", "as", "f", ":", "\n", "    ", "all_checkpoints", "=", "set", "(", "[", "\".\"", ".", "join", "(", "f", ".", "split", "(", "\".\"", ")", "[", ":", "-", "1", "]", ")", "\n", "for", "f", "in", "tf", ".", "gfile", ".", "ListDirectory", "(", "work_dir", ")", "\n", "if", "f", ".", "startswith", "(", "\"model.ckpt\"", ")", "]", ")", "\n", "# Sort checkpoints by the global step.", "\n", "all_checkpoints", "=", "sorted", "(", "all_checkpoints", ",", "\n", "key", "=", "lambda", "x", ":", "int", "(", "x", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ")", ")", "\n", "# For efficiency reasons we evluate only the last checkpoint", "\n", "for", "ckpt", "in", "all_checkpoints", "[", "-", "1", ":", "]", ":", "\n", "      ", "ckpt", "=", "os", ".", "path", ".", "join", "(", "work_dir", ",", "ckpt", ")", "\n", "res", "=", "estimator", ".", "evaluate", "(", "input_fn", ",", "\n", "steps", "=", "(", "data_params", "[", "\"dataset\"", "]", ".", "get_num_samples", "(", "\n", "data_params", "[", "\"dataset_eval_split_name\"", "]", ")", "//", "\n", "data_params", "[", "\"batch_size_eval\"", "]", ")", ",", "\n", "checkpoint_path", "=", "ckpt", ")", "\n", "f", ".", "write", "(", "\"Accuracy at step {}: {}\\n\"", ".", "format", "(", "res", "[", "\"global_step\"", "]", ",", "\n", "res", "[", "\"accuracy\"", "]", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.global_registry": [[116, 119], ["None"], "methods", ["None"], ["@", "staticmethod", "\n", "def", "global_registry", "(", ")", ":", "\n", "    ", "return", "Registry", ".", "_GLOBAL_REGISTRY", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.register": [[120, 136], ["ValueError", "Registry.global_registry", "KeyError", "Registry.global_registry"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.global_registry", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.global_registry"], ["", "@", "staticmethod", "\n", "def", "register", "(", "name", ",", "item_type", ")", ":", "\n", "    ", "\"\"\"Creates a function that registers its input.\"\"\"", "\n", "if", "item_type", "not", "in", "[", "\"function\"", ",", "\"class\"", "]", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unknown item type: %s\"", "%", "item_type", ")", "\n", "\n", "", "def", "_register", "(", "item", ")", ":", "\n", "      ", "if", "name", "in", "Registry", ".", "global_registry", "(", ")", ":", "\n", "        ", "raise", "KeyError", "(", "\n", "\"The name {!r} was already registered in with type {!r}\"", ".", "format", "(", "\n", "name", ",", "item_type", ")", ")", "\n", "\n", "", "Registry", ".", "global_registry", "(", ")", "[", "name", "]", "=", "(", "item", ",", "item_type", ")", "\n", "return", "item", "\n", "\n", "", "return", "_register", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup": [[137, 149], ["registry.parse_name", "kwargs.update", "Registry.global_registry", "functools.partial", "registry.partialclass"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.global_registry", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.partialclass"], ["", "@", "staticmethod", "\n", "def", "lookup", "(", "lookup_string", ",", "kwargs_extra", "=", "None", ")", ":", "\n", "    ", "\"\"\"Lookup a name in the registry.\"\"\"", "\n", "\n", "name", ",", "kwargs", "=", "parse_name", "(", "lookup_string", ")", "\n", "if", "kwargs_extra", ":", "\n", "      ", "kwargs", ".", "update", "(", "kwargs_extra", ")", "\n", "", "item", ",", "item_type", "=", "Registry", ".", "global_registry", "(", ")", "[", "name", "]", "\n", "if", "item_type", "==", "\"function\"", ":", "\n", "      ", "return", "functools", ".", "partial", "(", "item", ",", "**", "kwargs", ")", "\n", "", "elif", "item_type", "==", "\"class\"", ":", "\n", "      ", "return", "partialclass", "(", "item", ",", "**", "kwargs", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.partialclass": [[27, 52], ["base_kwargs.copy", "base_kwargs.copy.update", "super().__init__"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["def", "partialclass", "(", "cls", ",", "*", "base_args", ",", "**", "base_kwargs", ")", ":", "\n", "  ", "\"\"\"Builds a subclass with partial application of the given args and keywords.\n\n  Equivalent to functools.partial performance, base_args are preprended to the\n  positional arguments given during object initialization and base_kwargs are\n  updated with the kwargs given later.\n\n  Args:\n    cls: The base class.\n    *base_args: Positional arguments to be applied to the subclass.\n    **base_kwargs: Keyword arguments to be applied to the subclass.\n\n  Returns:\n    A subclass of the input class.\n  \"\"\"", "\n", "\n", "class", "_NewClass", "(", "cls", ")", ":", "\n", "\n", "    ", "def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "      ", "bound_args", "=", "base_args", "+", "args", "\n", "bound_kwargs", "=", "base_kwargs", ".", "copy", "(", ")", "\n", "bound_kwargs", ".", "update", "(", "kwargs", ")", "\n", "super", "(", "_NewClass", ",", "self", ")", ".", "__init__", "(", "*", "bound_args", ",", "**", "bound_kwargs", ")", "\n", "\n", "", "", "return", "_NewClass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name": [[54, 109], ["isinstance", "registry.parse_name._get_func_name"], "function", ["None"], ["", "def", "parse_name", "(", "string_to_parse", ")", ":", "\n", "  ", "\"\"\"Parses input to the registry's lookup function.\n\n  Args:\n    string_to_parse: can be either an arbitrary name or function call\n      (optionally with positional and keyword arguments).\n      e.g. \"multiclass\", \"resnet50_v2(filters_factor=8)\".\n\n  Returns:\n    A tuple of input name and a dctinary with arguments. Examples:\n      \"multiclass\" -> (\"multiclass\", (), {})\n      \"resnet50_v2(9, filters_factor=4)\" ->\n          (\"resnet50_v2\", (9,), {\"filters_factor\": 4})\n  \"\"\"", "\n", "expr", "=", "ast", ".", "parse", "(", "string_to_parse", ",", "mode", "=", "\"eval\"", ")", ".", "body", "# pytype: disable=attribute-error", "\n", "if", "not", "isinstance", "(", "expr", ",", "(", "ast", ".", "Attribute", ",", "ast", ".", "Call", ",", "ast", ".", "Name", ")", ")", ":", "\n", "    ", "raise", "ValueError", "(", "\n", "\"The given string should be a name or a call, but a {} was parsed from \"", "\n", "\"the string {!r}\"", ".", "format", "(", "type", "(", "expr", ")", ",", "string_to_parse", ")", ")", "\n", "\n", "# Notes:", "\n", "# name=\"some_name\" -> type(expr) = ast.Name", "\n", "# name=\"module.some_name\" -> type(expr) = ast.Attribute", "\n", "# name=\"some_name()\" -> type(expr) = ast.Call", "\n", "# name=\"module.some_name()\" -> type(expr) = ast.Call", "\n", "\n", "", "if", "isinstance", "(", "expr", ",", "ast", ".", "Name", ")", ":", "\n", "    ", "return", "string_to_parse", ",", "{", "}", "\n", "", "elif", "isinstance", "(", "expr", ",", "ast", ".", "Attribute", ")", ":", "\n", "    ", "return", "string_to_parse", ",", "{", "}", "\n", "\n", "", "def", "_get_func_name", "(", "expr", ")", ":", "\n", "    ", "if", "isinstance", "(", "expr", ",", "ast", ".", "Attribute", ")", ":", "\n", "      ", "return", "_get_func_name", "(", "expr", ".", "value", ")", "+", "\".\"", "+", "expr", ".", "attr", "\n", "", "elif", "isinstance", "(", "expr", ",", "ast", ".", "Name", ")", ":", "\n", "      ", "return", "expr", ".", "id", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"Type {!r} is not supported in a function name, the string to parse \"", "\n", "\"was {!r}\"", ".", "format", "(", "type", "(", "expr", ")", ",", "string_to_parse", ")", ")", "\n", "\n", "", "", "def", "_get_func_args_and_kwargs", "(", "call", ")", ":", "\n", "    ", "args", "=", "tuple", "(", "[", "ast", ".", "literal_eval", "(", "arg", ")", "for", "arg", "in", "call", ".", "args", "]", ")", "\n", "kwargs", "=", "{", "\n", "kwarg", ".", "arg", ":", "ast", ".", "literal_eval", "(", "kwarg", ".", "value", ")", "for", "kwarg", "in", "call", ".", "keywords", "\n", "}", "\n", "return", "args", ",", "kwargs", "\n", "\n", "", "func_name", "=", "_get_func_name", "(", "expr", ".", "func", ")", "\n", "func_args", ",", "func_kwargs", "=", "_get_func_args_and_kwargs", "(", "expr", ")", "\n", "if", "func_args", ":", "\n", "    ", "raise", "ValueError", "(", "\"Positional arguments are not supported here, but these \"", "\n", "\"were found: {!r}\"", ".", "format", "(", "func_args", ")", ")", "\n", "\n", "", "return", "func_name", ",", "func_kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.trainer_test.ModelTest.test_get_train_op": [[31, 39], ["task_adaptation.get_train_op", "tensorflow.Variable"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.trainer.get_train_op"], ["  ", "def", "test_get_train_op", "(", "self", ")", ":", "\n", "    ", "dummy_net", "=", "tf", ".", "Variable", "(", "0.0", ")", "+", "0.0", "\n", "trainer", ".", "get_train_op", "(", "dummy_net", ",", "\n", "initial_learning_rate", "=", "0.01", ",", "\n", "momentum", "=", "0.9", ",", "\n", "lr_decay_factor", "=", "0.1", ",", "\n", "decay_steps", "=", "(", "1000", ",", "2000", ",", "3000", ")", ",", "\n", "warmup_steps", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.adapt_and_eval.get_data_params_from_flags": [[97, 110], ["float"], "function", ["None"], ["def", "get_data_params_from_flags", "(", "mode", ")", ":", "\n", "  ", "return", "{", "\n", "\"dataset\"", ":", "\"data.\"", "+", "FLAGS", ".", "dataset", ",", "\n", "\"dataset_train_split_name\"", ":", "FLAGS", ".", "dataset_train_split_name", ",", "\n", "\"dataset_eval_split_name\"", ":", "FLAGS", ".", "dataset_eval_split_name", ",", "\n", "\"shuffle_buffer_size\"", ":", "FLAGS", ".", "shuffle_buffer_size", ",", "\n", "\"prefetch\"", ":", "FLAGS", ".", "prefetch", ",", "\n", "\"train_examples\"", ":", "FLAGS", ".", "train_examples", ",", "\n", "\"batch_size\"", ":", "FLAGS", ".", "batch_size", ",", "\n", "\"batch_size_eval\"", ":", "FLAGS", ".", "batch_size_eval", ",", "\n", "\"data_for_eval\"", ":", "mode", "==", "\"adaptation\"", ",", "\n", "\"data_dir\"", ":", "FLAGS", ".", "data_dir", ",", "\n", "\"input_range\"", ":", "[", "float", "(", "v", ")", "for", "v", "in", "FLAGS", ".", "input_range", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.adapt_and_eval.get_optimization_params_from_flags": [[113, 123], ["int", "FLAGS.decay_steps.split"], "function", ["None"], ["", "def", "get_optimization_params_from_flags", "(", ")", ":", "\n", "  ", "return", "{", "\n", "\"finetune_layer\"", ":", "FLAGS", ".", "finetune_layer", ",", "\n", "\"initial_learning_rate\"", ":", "FLAGS", ".", "initial_learning_rate", ",", "\n", "\"momentum\"", ":", "FLAGS", ".", "momentum", ",", "\n", "\"lr_decay_factor\"", ":", "FLAGS", ".", "lr_decay_factor", ",", "\n", "\"decay_steps\"", ":", "[", "int", "(", "x", ")", "for", "x", "in", "FLAGS", ".", "decay_steps", ".", "split", "(", "\",\"", ")", "]", ",", "\n", "\"max_steps\"", ":", "FLAGS", ".", "max_steps", ",", "\n", "\"warmup_steps\"", ":", "FLAGS", ".", "warmup_steps", ",", "\n", "\"tpu_name\"", ":", "FLAGS", ".", "tpu_name", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.adapt_and_eval.main": [[126, 147], ["task_adaptation.run_training_loop", "task_adaptation.run_evaluation_loop", "adapt_and_eval.get_optimization_params_from_flags", "adapt_and_eval.get_data_params_from_flags", "adapt_and_eval.get_optimization_params_from_flags", "adapt_and_eval.get_data_params_from_flags"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.run_training_loop", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.run_evaluation_loop", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.adapt_and_eval.get_optimization_params_from_flags", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.adapt_and_eval.get_data_params_from_flags", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.adapt_and_eval.get_optimization_params_from_flags", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.adapt_and_eval.get_data_params_from_flags"], ["", "def", "main", "(", "argv", ")", ":", "\n", "  ", "del", "argv", "\n", "\n", "if", "FLAGS", ".", "run_adaptation", ":", "\n", "    ", "loop", ".", "run_training_loop", "(", "\n", "hub_module", "=", "FLAGS", ".", "hub_module", ",", "\n", "hub_module_signature", "=", "FLAGS", ".", "hub_module_signature", ",", "\n", "work_dir", "=", "FLAGS", ".", "work_dir", ",", "\n", "tpu_name", "=", "FLAGS", ".", "tpu_name", ",", "\n", "save_checkpoints_steps", "=", "FLAGS", ".", "save_checkpoint_steps", ",", "\n", "optimization_params", "=", "get_optimization_params_from_flags", "(", ")", ",", "\n", "data_params", "=", "get_data_params_from_flags", "(", "\"adaptation\"", ")", ")", "\n", "", "if", "FLAGS", ".", "run_evaluation", ":", "\n", "    ", "loop", ".", "run_evaluation_loop", "(", "\n", "hub_module", "=", "FLAGS", ".", "hub_module", ",", "\n", "hub_module_signature", "=", "FLAGS", ".", "hub_module_signature", ",", "\n", "work_dir", "=", "FLAGS", ".", "work_dir", ",", "\n", "tpu_name", "=", "FLAGS", ".", "tpu_name", ",", "\n", "save_checkpoints_steps", "=", "FLAGS", ".", "save_checkpoint_steps", ",", "\n", "optimization_params", "=", "get_optimization_params_from_flags", "(", ")", ",", "\n", "data_params", "=", "get_data_params_from_flags", "(", "\"evaluation\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.create_dummy_hub_model": [[27, 49], ["tensorflow_hub.create_module_spec", "tensorflow_hub.Module", "tensorflow.placeholder", "tensorflow.reduce_mean", "tensorflow.layers.dense", "tensorflow_hub.add_signature", "tensorflow.Session", "sess.run", "hub.Module.export", "tensorflow.nn.dropout", "tensorflow.global_variables_initializer", "set"], "function", ["None"], ["def", "create_dummy_hub_model", "(", "path", ",", "num_outputs", ")", ":", "\n", "  ", "\"\"\"Creates minimal hub module for testing purposes.\"\"\"", "\n", "\n", "def", "module_fn", "(", "is_training", ")", ":", "\n", "    ", "x", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "float32", ",", "shape", "=", "[", "32", ",", "224", ",", "224", ",", "3", "]", ")", "\n", "h", "=", "tf", ".", "reduce_mean", "(", "x", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "\n", "if", "is_training", ":", "\n", "      ", "h", "=", "tf", ".", "nn", ".", "dropout", "(", "h", ",", "0.5", ")", "\n", "", "y", "=", "tf", ".", "layers", ".", "dense", "(", "h", ",", "num_outputs", ")", "\n", "hub", ".", "add_signature", "(", "inputs", "=", "x", ",", "outputs", "=", "{", "\"pre_logits\"", ":", "h", ",", "\"logits\"", ":", "y", "}", ")", "\n", "\n", "", "spec", "=", "hub", ".", "create_module_spec", "(", "\n", "module_fn", ",", "\n", "tags_and_args", "=", "[", "(", "{", "\"train\"", "}", ",", "{", "\n", "\"is_training\"", ":", "True", "\n", "}", ")", ",", "(", "set", "(", ")", ",", "{", "\n", "\"is_training\"", ":", "False", "\n", "}", ")", "]", ")", "\n", "m", "=", "hub", ".", "Module", "(", "spec", ",", "name", "=", "\"module\"", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "m", ".", "export", "(", "path", ",", "sess", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.create_dummy_saved_model": [[51, 79], ["tensorflow.function", "tensorflow.Session", "ImageModel", "tensorflow.initialize_all_variables", "sess.run", "tensorflow.compat.v2.saved_model.save", "super().__init__", "tensorflow.Variable", "tensorflow.reduce_mean", "tensorflow.TensorSpec", "tensorflow.TensorSpec"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["", "", "def", "create_dummy_saved_model", "(", "path", ")", ":", "\n", "  ", "\"\"\"Creates minimal saved model for testing purposes.\"\"\"", "\n", "\n", "class", "ImageModel", "(", "tf", ".", "train", ".", "Checkpoint", ")", ":", "\n", "    ", "\"\"\"Dummy image model.\"\"\"", "\n", "\n", "def", "__init__", "(", "self", ")", ":", "\n", "      ", "super", "(", "ImageModel", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "v", "=", "tf", ".", "Variable", "(", "1.", ",", "use_resource", "=", "True", ")", "\n", "\n", "", "@", "tf", ".", "function", "(", "input_signature", "=", "[", "\n", "tf", ".", "TensorSpec", "(", "name", "=", "\"input\"", ",", "shape", "=", "[", "32", ",", "224", ",", "224", ",", "3", "]", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "tf", ".", "TensorSpec", "(", "name", "=", "\"training\"", ",", "shape", "=", "None", ",", "dtype", "=", "tf", ".", "bool", ")", ",", "\n", "]", ")", "\n", "def", "__call__", "(", "self", ",", "x", ",", "training", ")", ":", "\n", "      ", "return", "tf", ".", "reduce_mean", "(", "x", ",", "axis", "=", "[", "1", ",", "2", "]", ")", "+", "self", ".", "v", "\n", "\n", "", "", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "    ", "model", "=", "ImageModel", "(", ")", "\n", "\n", "# Explicitly reference save_counter so that is initialized before saving", "\n", "# the model.", "\n", "model", ".", "save_counter", "# pylint: disable=pointless-statement", "\n", "\n", "model", ".", "trainable_variables", "=", "[", "model", ".", "v", "]", "\n", "init", "=", "tf", ".", "initialize_all_variables", "(", ")", "\n", "sess", ".", "run", "(", "init", ")", "\n", "tf", ".", "compat", ".", "v2", ".", "saved_model", ".", "save", "(", "model", ",", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_data_params": [[81, 93], ["None"], "function", ["None"], ["", "", "def", "get_data_params", "(", ")", ":", "\n", "  ", "return", "{", "\n", "\"dataset\"", ":", "\"data.cifar(num_classes=10)\"", ",", "\n", "\"dataset_train_split_name\"", ":", "\"train\"", ",", "\n", "\"dataset_eval_split_name\"", ":", "\"test\"", ",", "\n", "\"shuffle_buffer_size\"", ":", "1000", ",", "\n", "\"prefetch\"", ":", "1000", ",", "\n", "\"train_examples\"", ":", "None", ",", "\n", "\"batch_size\"", ":", "32", ",", "\n", "\"batch_size_eval\"", ":", "8", ",", "\n", "\"data_dir\"", ":", "None", ",", "\n", "\"input_range\"", ":", "[", "-", "1.0", ",", "1.0", "]", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_optimization_params": [[96, 106], ["None"], "function", ["None"], ["", "def", "get_optimization_params", "(", ")", ":", "\n", "  ", "return", "{", "\n", "\"finetune_layer\"", ":", "\"pre_logits\"", ",", "\n", "\"initial_learning_rate\"", ":", "0.01", ",", "\n", "\"momentum\"", ":", "0.9", ",", "\n", "\"lr_decay_factor\"", ":", "0.1", ",", "\n", "\"decay_steps\"", ":", "(", "10", ",", "20", ",", "30", ")", ",", "\n", "\"max_steps\"", ":", "10", ",", "\n", "\"warmup_steps\"", ":", "0", ",", "\n", "\"tpu_name\"", ":", "None", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.model.model_fn": [[30, 104], ["tensorflow_hub.resolve", "tensorflow.io.gfile.exists", "len", "tensorflow.layers.dense", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_mean", "os.path.join", "tensorflow_hub.Module", "tensorflow_hub.load", "tensorflow.get_collection_ref().extend", "hub.load.", "tf.squeeze.get_shape().as_list", "tensorflow.squeeze", "hub.load.", "ValueError", "tensorflow.zeros_initializer", "tensorflow.metrics.accuracy", "tensorflow.contrib.tpu.TPUEstimatorSpec", "tensorflow.estimator.EstimatorSpec", "task_adaptation.get_train_op", "spec_type", "ValueError", "tensorflow.get_collection_ref", "tf.squeeze.get_shape", "tensorflow.argmax"], "function", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.trainer.get_train_op"], ["def", "model_fn", "(", "features", ",", "mode", ",", "params", ")", ":", "\n", "  ", "\"\"\"A function for applying hub module that follows Estimator API.\"\"\"", "\n", "\n", "hub_module", "=", "params", "[", "\"hub_module\"", "]", "\n", "finetune_layer", "=", "params", "[", "\"finetune_layer\"", "]", "\n", "num_classes", "=", "params", "[", "\"num_classes\"", "]", "\n", "initial_learning_rate", "=", "params", "[", "\"initial_learning_rate\"", "]", "\n", "momentum", "=", "params", "[", "\"momentum\"", "]", "\n", "lr_decay_factor", "=", "params", "[", "\"lr_decay_factor\"", "]", "\n", "decay_steps", "=", "params", "[", "\"decay_steps\"", "]", "\n", "warmup_steps", "=", "params", "[", "\"warmup_steps\"", "]", "\n", "\n", "is_training", "=", "(", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ")", "\n", "module_path", "=", "hub", ".", "resolve", "(", "hub_module", ")", "\n", "is_legacy_hub_module", "=", "tf", ".", "io", ".", "gfile", ".", "exists", "(", "\n", "os", ".", "path", ".", "join", "(", "module_path", ",", "\"tfhub_module.pb\"", ")", ")", "\n", "if", "is_legacy_hub_module", ":", "\n", "    ", "module", "=", "hub", ".", "Module", "(", "hub_module", ",", "\n", "trainable", "=", "is_training", ",", "\n", "tags", "=", "{", "\"train\"", "}", "if", "is_training", "else", "None", ")", "\n", "pre_logits", "=", "module", "(", "features", "[", "\"image\"", "]", ",", "\n", "signature", "=", "params", "[", "\"hub_module_signature\"", "]", ",", "\n", "as_dict", "=", "True", ")", "[", "finetune_layer", "]", "\n", "", "else", ":", "\n", "    ", "module", "=", "hub", ".", "load", "(", "hub_module", ")", "\n", "tf", ".", "get_collection_ref", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ")", ".", "extend", "(", "\n", "module", ".", "trainable_variables", ")", "\n", "pre_logits", "=", "module", "(", "features", "[", "\"image\"", "]", ",", "training", "=", "is_training", ")", "\n", "\n", "", "num_dim_pre_logits", "=", "len", "(", "pre_logits", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "\n", "if", "num_dim_pre_logits", "==", "4", ":", "\n", "    ", "pre_logits", "=", "tf", ".", "squeeze", "(", "pre_logits", ",", "[", "1", ",", "2", "]", ")", "\n", "", "elif", "num_dim_pre_logits", "!=", "2", ":", "\n", "    ", "raise", "ValueError", "(", "\"Invalid number of dimensions in the representation \"", "\n", "\"layer: {}, but only 2 or 4 are allowed\"", ".", "format", "(", "\n", "num_dim_pre_logits", ")", ")", "\n", "\n", "", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "pre_logits", ",", "\n", "units", "=", "num_classes", ",", "\n", "kernel_initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "name", "=", "\"linear_head\"", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "logits", "=", "logits", ",", "labels", "=", "features", "[", "\"label\"", "]", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "\n", "def", "accuracy_metric", "(", "logits", ",", "labels", ")", ":", "\n", "    ", "return", "{", "\"accuracy\"", ":", "tf", ".", "metrics", ".", "accuracy", "(", "\n", "labels", "=", "labels", ",", "\n", "predictions", "=", "tf", ".", "argmax", "(", "logits", ",", "axis", "=", "-", "1", ")", ")", "}", "\n", "", "eval_metrics", "=", "(", "accuracy_metric", ",", "[", "logits", ",", "features", "[", "\"label\"", "]", "]", ")", "\n", "\n", "if", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "EVAL", ":", "\n", "    ", "if", "params", "[", "\"tpu_name\"", "]", "is", "not", "None", ":", "\n", "      ", "return", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "loss", "=", "loss", ",", "eval_metrics", "=", "eval_metrics", ")", "\n", "", "else", ":", "\n", "      ", "return", "tf", ".", "estimator", ".", "EstimatorSpec", "(", "\n", "mode", "=", "mode", ",", "loss", "=", "loss", ",", "\n", "eval_metric_ops", "=", "eval_metrics", "[", "0", "]", "(", "*", "eval_metrics", "[", "1", "]", ")", ")", "\n", "", "", "elif", "mode", "==", "tf", ".", "estimator", ".", "ModeKeys", ".", "TRAIN", ":", "\n", "    ", "train_op", "=", "trainer", ".", "get_train_op", "(", "loss", ",", "\n", "initial_learning_rate", ",", "\n", "momentum", ",", "\n", "lr_decay_factor", ",", "\n", "decay_steps", ",", "\n", "warmup_steps", ",", "\n", "use_tpu", "=", "params", "[", "\"tpu_name\"", "]", "is", "not", "None", ")", "\n", "spec_type", "=", "(", "tf", ".", "contrib", ".", "tpu", ".", "TPUEstimatorSpec", "\n", "if", "params", "[", "\"tpu_name\"", "]", "is", "not", "None", "\n", "else", "tf", ".", "estimator", ".", "EstimatorSpec", ")", "\n", "return", "spec_type", "(", "mode", "=", "mode", ",", "loss", "=", "loss", ",", "train_op", "=", "train_op", ")", "\n", "", "else", ":", "\n", "    ", "raise", "ValueError", "(", "\"Unsupported mode %s\"", "%", "mode", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop_test.LoopTest.test_run_training_loop": [[33, 48], ["os.path.join", "task_adaptation.test_utils.create_dummy_hub_model", "tempfile.mkdtemp", "task_adaptation.loop.run_training_loop", "loop_test.LoopTest.assertNotEmpty", "loop_test.LoopTest.get_temp_dir", "task_adaptation.test_utils.get_optimization_params", "task_adaptation.test_utils.get_data_params", "os.listdir", "f.startswith"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.create_dummy_hub_model", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.loop.run_training_loop", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_optimization_params", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_data_params"], ["  ", "def", "test_run_training_loop", "(", "self", ")", ":", "\n", "    ", "module_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "get_temp_dir", "(", ")", ",", "\"module\"", ")", "\n", "test_utils", ".", "create_dummy_hub_model", "(", "module_path", ",", "num_outputs", "=", "10", ")", "\n", "tmp_dir", "=", "tempfile", ".", "mkdtemp", "(", ")", "\n", "loop", ".", "run_training_loop", "(", "\n", "hub_module", "=", "module_path", ",", "\n", "hub_module_signature", "=", "None", ",", "\n", "work_dir", "=", "tmp_dir", ",", "\n", "tpu_name", "=", "None", ",", "\n", "save_checkpoints_steps", "=", "10", ",", "\n", "optimization_params", "=", "test_utils", ".", "get_optimization_params", "(", ")", ",", "\n", "data_params", "=", "test_utils", ".", "get_data_params", "(", ")", ")", "\n", "\n", "self", ".", "assertNotEmpty", "(", "[", "f", "for", "f", "in", "os", ".", "listdir", "(", "tmp_dir", ")", "\n", "if", "f", ".", "startswith", "(", "\"model.ckpt\"", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader_test.DataLoaderTest.test_build_data_pipeline": [[31, 37], ["task_adaptation.data_loader.build_data_pipeline", "task_adaptation.data_loader.build_data_pipeline.make_one_shot_iterator().get_next", "data_loader_test.DataLoaderTest.assertIsInstance", "data_loader_test.DataLoaderTest.assertIsInstance", "task_adaptation.test_utils.get_data_params", "task_adaptation.data_loader.build_data_pipeline.make_one_shot_iterator", "task_adaptation.data_loader.build_data_pipeline."], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.data_loader.build_data_pipeline", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.test_utils.get_data_params"], ["  ", "def", "test_build_data_pipeline", "(", "self", ")", ":", "\n", "    ", "input_fn", "=", "data_loader", ".", "build_data_pipeline", "(", "test_utils", ".", "get_data_params", "(", ")", ",", "\n", "mode", "=", "\"eval\"", ")", "\n", "data", "=", "input_fn", "(", "{", "\"batch_size\"", ":", "32", "}", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "self", ".", "assertIsInstance", "(", "data", "[", "\"image\"", "]", ",", "tf", ".", "Tensor", ")", "\n", "self", ".", "assertIsInstance", "(", "data", "[", "\"label\"", "]", ",", "tf", ".", "Tensor", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry_test.RegistryTest.setUp": [[31, 40], ["super().setUp", "registry_test.RegistryTest.addCleanup", "dict", "mock.patch.object().start", "mock.patch.object"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "RegistryTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "# Mock global registry in each test to keep them isolated and allow for", "\n", "# concurrent tests.", "\n", "self", ".", "addCleanup", "(", "mock", ".", "patch", ".", "stopall", ")", "\n", "self", ".", "global_registry", "=", "dict", "(", ")", "\n", "self", ".", "mocked_method", "=", "mock", ".", "patch", ".", "object", "(", "\n", "registry", ".", "Registry", ",", "\"global_registry\"", ",", "\n", "return_value", "=", "self", ".", "global_registry", ")", ".", "start", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry_test.RegistryTest.test_parse_name": [[41, 68], ["task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "dict", "registry_test.RegistryTest.assertRaises", "task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertRaises", "task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertRaises", "task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertRaises", "task_adaptation.registry.parse_name", "registry_test.RegistryTest.assertRaises", "task_adaptation.registry.parse_name"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.parse_name"], ["", "def", "test_parse_name", "(", "self", ")", ":", "\n", "    ", "name", ",", "kwargs", "=", "registry", ".", "parse_name", "(", "\"f\"", ")", "\n", "self", ".", "assertEqual", "(", "name", ",", "\"f\"", ")", "\n", "self", ".", "assertEqual", "(", "kwargs", ",", "{", "}", ")", "\n", "\n", "name", ",", "kwargs", "=", "registry", ".", "parse_name", "(", "\"f()\"", ")", "\n", "self", ".", "assertEqual", "(", "name", ",", "\"f\"", ")", "\n", "self", ".", "assertEqual", "(", "kwargs", ",", "{", "}", ")", "\n", "\n", "name", ",", "kwargs", "=", "registry", ".", "parse_name", "(", "\"func(a=0,b=1,c='s')\"", ")", "\n", "self", ".", "assertEqual", "(", "name", ",", "\"func\"", ")", "\n", "self", ".", "assertEqual", "(", "kwargs", ",", "{", "\"a\"", ":", "0", ",", "\"b\"", ":", "1", ",", "\"c\"", ":", "\"s\"", "}", ")", "\n", "\n", "name", ",", "kwargs", "=", "registry", ".", "parse_name", "(", "\"foo.bar.func(a=0,b=(1),c='s')\"", ")", "\n", "self", ".", "assertEqual", "(", "name", ",", "\"foo.bar.func\"", ")", "\n", "self", ".", "assertEqual", "(", "kwargs", ",", "dict", "(", "a", "=", "0", ",", "b", "=", "1", ",", "c", "=", "\"s\"", ")", ")", "\n", "\n", "with", "self", ".", "assertRaises", "(", "SyntaxError", ")", ":", "\n", "      ", "registry", ".", "parse_name", "(", "\"func(0\"", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "SyntaxError", ")", ":", "\n", "      ", "registry", ".", "parse_name", "(", "\"func(a=0,,b=0)\"", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "SyntaxError", ")", ":", "\n", "      ", "registry", ".", "parse_name", "(", "\"func(a=0,b==1,c='s')\"", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "      ", "registry", ".", "parse_name", "(", "\"func(a=0,b=undefined_name,c='s')\"", ")", "\n", "", "with", "self", ".", "assertRaises", "(", "ValueError", ")", ":", "\n", "      ", "registry", ".", "parse_name", "(", "\"func(0)\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry_test.RegistryTest.test_register": [[69, 86], ["task_adaptation.registry.Registry.register", "task_adaptation.registry.Registry.register", "registry_test.RegistryTest.assertLen", "registry_test.RegistryTest.assertRaises", "task_adaptation.registry.Registry.register", "task_adaptation.registry.Registry.global_registry"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.register", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.register", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.register", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.global_registry"], ["", "", "def", "test_register", "(", "self", ")", ":", "\n", "# pylint: disable=unused-variable", "\n", "    ", "@", "registry", ".", "Registry", ".", "register", "(", "\"func1\"", ",", "\"function\"", ")", "\n", "def", "func1", "(", ")", ":", "\n", "      ", "pass", "\n", "\n", "", "@", "registry", ".", "Registry", ".", "register", "(", "\"A\"", ",", "\"class\"", ")", "\n", "class", "A", "(", "object", ")", ":", "\n", "      ", "pass", "\n", "\n", "", "with", "self", ".", "assertRaises", "(", "KeyError", ")", ":", "\n", "      ", "@", "registry", ".", "Registry", ".", "register", "(", "\"A\"", ",", "\"class\"", ")", "\n", "class", "A1", "(", "object", ")", ":", "\n", "        ", "pass", "\n", "# pylint: enable=unused-variable", "\n", "\n", "", "", "self", ".", "assertLen", "(", "registry", ".", "Registry", ".", "global_registry", "(", ")", ",", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry_test.RegistryTest.test_lookup_function": [[87, 102], ["task_adaptation.registry.Registry.register", "registry_test.RegistryTest.assertTrue", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "callable", "task_adaptation.registry.Registry.lookup", "task_adaptation.registry.Registry.lookup", "task_adaptation.registry.Registry.lookup", "task_adaptation.registry.Registry.lookup", "task_adaptation.registry.Registry.lookup"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.register", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup"], ["", "def", "test_lookup_function", "(", "self", ")", ":", "\n", "\n", "    ", "@", "registry", ".", "Registry", ".", "register", "(", "\"func1\"", ",", "\"function\"", ")", "\n", "def", "func1", "(", "arg1", ",", "arg2", ",", "arg3", ")", ":", "# pylint: disable=unused-variable", "\n", "      ", "return", "arg1", ",", "arg2", ",", "arg3", "\n", "\n", "", "self", ".", "assertTrue", "(", "callable", "(", "registry", ".", "Registry", ".", "lookup", "(", "\"func1\"", ")", ")", ")", "\n", "self", ".", "assertEqual", "(", "registry", ".", "Registry", ".", "lookup", "(", "\"func1\"", ")", "(", "1", ",", "2", ",", "3", ")", ",", "(", "1", ",", "2", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "registry", ".", "Registry", ".", "lookup", "(", "\"func1(arg3=9)\"", ")", "(", "1", ",", "2", ")", ",", "(", "1", ",", "2", ",", "9", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "registry", ".", "Registry", ".", "lookup", "(", "\"func1(arg2=9,arg1=99)\"", ")", "(", "arg3", "=", "3", ")", ",", "(", "99", ",", "9", ",", "3", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "registry", ".", "Registry", ".", "lookup", "(", "\"func1(arg2=9,arg1=99)\"", ")", "(", "arg1", "=", "1", ",", "arg3", "=", "3", ")", ",", "\n", "(", "1", ",", "9", ",", "3", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry_test.RegistryTest.test_lookup_class": [[103, 120], ["task_adaptation.registry.Registry.register", "registry_test.RegistryTest.assertIsInstance", "registry_test.RegistryTest.assertEqual", "registry_test.RegistryTest.assertEqual", "task_adaptation.registry.Registry.lookup", "task_adaptation.registry.Registry.lookup", "task_adaptation.registry.Registry.lookup"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.register", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup", "home.repos.pwc.inspect_result.google-research_task_adaptation.task_adaptation.registry.Registry.lookup"], ["", "def", "test_lookup_class", "(", "self", ")", ":", "\n", "\n", "    ", "@", "registry", ".", "Registry", ".", "register", "(", "\"A\"", ",", "\"class\"", ")", "\n", "class", "A", "(", "object", ")", ":", "\n", "\n", "      ", "def", "__init__", "(", "self", ",", "arg1", ",", "arg2", "=", "2", ")", ":", "\n", "        ", "self", ".", "arg1", "=", "arg1", "\n", "self", ".", "arg2", "=", "arg2", "\n", "\n", "", "def", "as_tuple", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "arg1", ",", "self", ".", "arg2", ")", "\n", "\n", "", "", "self", ".", "assertIsInstance", "(", "registry", ".", "Registry", ".", "lookup", "(", "\"A(arg1=25)\"", ")", "(", ")", ",", "A", ")", "\n", "self", ".", "assertEqual", "(", "\n", "registry", ".", "Registry", ".", "lookup", "(", "\"A(arg1=25)\"", ")", "(", ")", ".", "as_tuple", "(", ")", ",", "(", "25", ",", "2", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "registry", ".", "Registry", ".", "lookup", "(", "\"A(arg1=8, arg2=9)\"", ")", "(", ")", ".", "as_tuple", "(", ")", ",", "(", "8", ",", "9", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.smallnorb.SmallNORBData.__init__": [[46, 94], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "ValueError", "tensorflow.tile", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["def", "__init__", "(", "self", ",", "predicted_attribute", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"smallnorb:2.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "if", "predicted_attribute", "not", "in", "dataset_builder", ".", "info", ".", "features", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"{} is not a valid attribute to predict.\"", ".", "format", "(", "predicted_attribute", ")", ")", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"test[:{}%]\"", ".", "format", "(", "VAL_SPLIT_PERCENT", ")", ",", "\n", "\"trainval\"", ":", "\"train+test[:{}%]\"", ".", "format", "(", "VAL_SPLIT_PERCENT", ")", ",", "\n", "\"test\"", ":", "\"test[{}%:]\"", ".", "format", "(", "VAL_SPLIT_PERCENT", ")", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"test[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+test[:200]\"", ",", "\n", "}", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "train_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "num_samples_validation", "=", "VAL_SPLIT_PERCENT", "*", "test_count", "//", "100", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "num_samples_validation", ",", "\n", "\"trainval\"", ":", "train_count", "+", "num_samples_validation", ",", "\n", "\"test\"", ":", "test_count", "-", "num_samples_validation", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "def", "preprocess_fn", "(", "tensors", ")", ":", "\n", "# For consistency with other datasets, image needs to have three channels.", "\n", "      ", "image", "=", "tf", ".", "tile", "(", "tensors", "[", "\"image\"", "]", ",", "[", "1", ",", "1", ",", "3", "]", ")", "\n", "return", "dict", "(", "image", "=", "image", ",", "label", "=", "tensors", "[", "predicted_attribute", "]", ")", "\n", "\n", "", "info", "=", "dataset_builder", ".", "info", "\n", "super", "(", "SmallNORBData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# We extract the attribute we want to predict in the preprocessing.", "\n", "base_preprocess_fn", "=", "preprocess_fn", ",", "\n", "num_classes", "=", "info", ".", "features", "[", "predicted_attribute", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cifar.CifarData.__init__": [[43, 92], ["tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "tensorflow_datasets.builder", "tensorflow_datasets.builder", "ValueError", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "10", ",", "data_dir", "=", "None", ",", "train_split_percent", "=", "None", ")", ":", "\n", "\n", "    ", "if", "num_classes", "==", "10", ":", "\n", "      ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"cifar10:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "", "elif", "num_classes", "==", "100", ":", "\n", "      ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"cifar100:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"Number of classes must be 10 or 100, got {}\"", ".", "format", "(", "num_classes", ")", ")", "\n", "\n", "", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "train_split_percent", "=", "train_split_percent", "or", "TRAIN_SPLIT_PERCENT", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "(", "train_split_percent", "*", "trainval_count", ")", "//", "100", ",", "\n", "\"val\"", ":", "trainval_count", "-", "(", "train_split_percent", "*", "trainval_count", ")", "//", "100", ",", "\n", "\"trainval\"", ":", "trainval_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"val\"", ":", "\"train[{}:]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"trainval\"", ":", "\"train\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "}", "\n", "\n", "super", "(", "CifarData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "[", "\"image\"", ",", "\"label\"", ",", "\"id\"", "]", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.clevr.CLEVRData.__init__": [[81, 127], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["def", "__init__", "(", "self", ",", "task", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "    ", "if", "task", "not", "in", "_TASK_DICT", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unknown task: %s\"", "%", "task", ")", "\n", "\n", "", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"clevr:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TRAIN", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TEST", "]", ".", "num_examples", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "(", "TRAIN_SPLIT_PERCENT", "*", "trainval_count", ")", "//", "100", ",", "\n", "\"val\"", ":", "trainval_count", "-", "(", "TRAIN_SPLIT_PERCENT", "*", "trainval_count", ")", "//", "100", ",", "\n", "\"trainval\"", ":", "trainval_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"val\"", ":", "\"train[{}:]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"trainval\"", ":", "\"train\"", ",", "\n", "\"test\"", ":", "\"validation\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "}", "\n", "\n", "task", "=", "_TASK_DICT", "[", "task", "]", "\n", "base_preprocess_fn", "=", "task", "[", "\"preprocess_fn\"", "]", "\n", "\n", "super", "(", "CLEVRData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base_preprocess_fn", ",", "\n", "num_classes", "=", "task", "[", "\"num_classes\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.clevr._count_preprocess_fn": [[32, 35], ["tensorflow.size"], "function", ["None"], ["def", "_count_preprocess_fn", "(", "x", ")", ":", "\n", "  ", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\n", "\"label\"", ":", "tf", ".", "size", "(", "x", "[", "\"objects\"", "]", "[", "\"size\"", "]", ")", "-", "3", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.clevr._count_cylinders_preprocess_fn": [[37, 43], ["tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.equal"], "function", ["None"], ["", "def", "_count_cylinders_preprocess_fn", "(", "x", ")", ":", "\n", "# Class distribution:", "\n", "\n", "  ", "num_cylinders", "=", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "cast", "(", "tf", ".", "equal", "(", "x", "[", "\"objects\"", "]", "[", "\"shape\"", "]", ",", "2", ")", ",", "tf", ".", "int32", ")", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "num_cylinders", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.clevr._closest_object_preprocess_fn": [[45, 54], ["tensorflow.reduce_min", "numpy.array", "tensorflow.reduce_max", "tensorflow.where"], "function", ["None"], ["", "def", "_closest_object_preprocess_fn", "(", "x", ")", ":", "\n", "  ", "dist", "=", "tf", ".", "reduce_min", "(", "x", "[", "\"objects\"", "]", "[", "\"pixel_coords\"", "]", "[", ":", ",", "2", "]", ")", "\n", "# These thresholds are uniformly spaced and result in more or less balanced", "\n", "# distribution of classes, see the resulting histogram:", "\n", "\n", "thrs", "=", "np", ".", "array", "(", "[", "0.0", ",", "8.0", ",", "8.5", ",", "9.0", ",", "9.5", ",", "10.0", ",", "100.0", "]", ")", "\n", "label", "=", "tf", ".", "reduce_max", "(", "tf", ".", "where", "(", "(", "thrs", "-", "dist", ")", "<", "0", ")", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\n", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.eurosat_test.EurosatTest.setUp": [[29, 45], ["super().setUp", "task_adaptation.data.eurosat.EurosatData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "EurosatTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "eurosat", ".", "EurosatData", "(", ")", ",", "\n", "num_classes", "=", "10", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "16200", ",", "\n", "val", "=", "5400", ",", "\n", "trainval", "=", "21600", ",", "\n", "test", "=", "5400", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "'image'", ":", "(", "64", ",", "64", ",", "3", ")", ",", "\n", "'label'", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites.DSpritesData.__init__": [[46, 114], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "ValueError", "ValueError", "float", "tensorflow.cast", "dict", "isinstance", "tensorflow.tile", "tensorflow.math.floordiv", "tensorflow.cast"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["def", "__init__", "(", "self", ",", "predicted_attribute", ",", "num_classes", "=", "None", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"dsprites:2.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "info", "=", "dataset_builder", ".", "info", "\n", "\n", "if", "predicted_attribute", "not", "in", "dataset_builder", ".", "info", ".", "features", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"{} is not a valid attribute to predict.\"", ".", "format", "(", "predicted_attribute", ")", ")", "\n", "\n", "# If num_classes is set, we group together nearby integer values to arrive", "\n", "# at the desired number of classes. This is useful for example for grouping", "\n", "# together different spatial positions.", "\n", "", "num_original_classes", "=", "info", ".", "features", "[", "predicted_attribute", "]", ".", "num_classes", "\n", "if", "num_classes", "is", "None", ":", "\n", "      ", "num_classes", "=", "num_original_classes", "\n", "", "if", "not", "isinstance", "(", "num_classes", ",", "int", ")", "or", "num_classes", "<=", "1", "or", "(", "\n", "num_classes", ">", "num_original_classes", ")", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"The number of classes should be None or in [2, ..., num_classes].\"", ")", "\n", "", "class_division_factor", "=", "float", "(", "num_original_classes", ")", "/", "num_classes", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_total", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "num_samples_train", "=", "TRAIN_SPLIT_PERCENT", "*", "num_total", "//", "100", "\n", "num_samples_val", "=", "VAL_SPLIT_PERCENT", "*", "num_total", "//", "100", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "num_samples_train", ",", "\n", "\"val\"", ":", "num_samples_val", ",", "\n", "\"trainval\"", ":", "num_samples_val", "+", "num_samples_train", ",", "\n", "\"test\"", ":", "num_total", "-", "num_samples_val", "-", "num_samples_train", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"val\"", ":", "\"train[{}:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ",", "\n", "num_samples_splits", "[", "\"trainval\"", "]", ")", ",", "\n", "\"trainval\"", ":", "\"train[:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"trainval\"", "]", ")", ",", "\n", "\"test\"", ":", "\"train[{}:]\"", ".", "format", "(", "num_samples_splits", "[", "\"trainval\"", "]", ")", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"train[{}:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ",", "\n", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "}", "\n", "\n", "def", "preprocess_fn", "(", "tensors", ")", ":", "\n", "# For consistency with other datasets, image needs to have three channels", "\n", "# and be in [0, 255).", "\n", "      ", "images", "=", "tf", ".", "tile", "(", "tensors", "[", "\"image\"", "]", ",", "[", "1", ",", "1", ",", "3", "]", ")", "*", "255", "\n", "label", "=", "tf", ".", "cast", "(", "\n", "tf", ".", "math", ".", "floordiv", "(", "\n", "tf", ".", "cast", "(", "tensors", "[", "predicted_attribute", "]", ",", "tf", ".", "float32", ")", ",", "\n", "class_division_factor", ")", ",", "info", ".", "features", "[", "predicted_attribute", "]", ".", "dtype", ")", "\n", "return", "dict", "(", "image", "=", "images", ",", "label", "=", "label", ")", "\n", "\n", "", "super", "(", "DSpritesData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# We extract the attribute we want to predict in the preprocessing.", "\n", "base_preprocess_fn", "=", "preprocess_fn", ",", "\n", "num_classes", "=", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageDataInterface.default_label_key": [[116, 120], ["None"], "methods", ["None"], ["@", "property", "\n", "@", "abc", ".", "abstractmethod", "\n", "def", "default_label_key", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the default label key of the dataset.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageDataInterface.label_keys": [[121, 125], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abc", ".", "abstractmethod", "\n", "def", "label_keys", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns a tuple with the available label keys of the dataset.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageDataInterface.num_channels": [[126, 130], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abc", ".", "abstractmethod", "\n", "def", "num_channels", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the number of channels of the images in the dataset.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageDataInterface.splits": [[131, 135], ["None"], "methods", ["None"], ["", "@", "property", "\n", "@", "abc", ".", "abstractmethod", "\n", "def", "splits", "(", "self", ")", ":", "\n", "    ", "\"\"\"Returns the splits defined in the dataset.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageDataInterface.get_num_samples": [[136, 139], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_num_samples", "(", "self", ",", "split_name", ")", ":", "\n", "    ", "\"\"\"Returns the number of images in the given split name.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageDataInterface.get_num_classes": [[140, 143], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_num_classes", "(", "self", ",", "label_key", "=", "None", ")", ":", "\n", "    ", "\"\"\"Returns the number of classes of the given label_key.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageDataInterface.get_tf_data": [[144, 200], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "get_tf_data", "(", "self", ",", "\n", "split_name", ",", "\n", "batch_size", ",", "\n", "pairwise_mix_fn", "=", "None", ",", "\n", "preprocess_fn", "=", "None", ",", "\n", "preprocess_before_filter", "=", "None", ",", "\n", "epochs", "=", "None", ",", "\n", "drop_remainder", "=", "True", ",", "\n", "for_eval", "=", "False", ",", "\n", "shuffle_buffer_size", "=", "None", ",", "\n", "prefetch", "=", "1", ",", "\n", "train_examples", "=", "None", ",", "\n", "filtered_num_samples", "=", "None", ",", "\n", "filter_fn", "=", "None", ",", "\n", "batch_preprocess_fn", "=", "None", ",", "\n", "ignore_errors", "=", "False", ",", "\n", "shuffle_files", "=", "False", ")", ":", "\n", "    ", "\"\"\"Provides preprocessed and batched data.\n\n    Args:\n      split_name: name of a data split to provide. Can be \"train\", \"val\",\n          \"trainval\" or \"test\".\n      batch_size: batch size.\n      pairwise_mix_fn: a function for mixing each data with another random one.\n      preprocess_fn: a function for preprocessing input data. It expects a\n          dictionary with a key \"image\" associated with a 3D image tensor.\n      preprocess_before_filter: a function for preprocessing input data,\n          before filter_fn. It is only designed for light preprocessing,\n          i.e. augment with image id. For heavy preprocessing, it's more\n          efficient to do it after filter_fn.\n      epochs: number of full passes through the data. If None, the data is\n          provided indefinitely.\n      drop_remainder: if True, the last incomplete batch of data is dropped.\n          Normally, this parameter should be True, otherwise it leads to\n          the unknown batch dimension, which is not compatible with training\n          or evaluation on TPUs.\n      for_eval: get data for evaluation. Disables shuffling.\n      shuffle_buffer_size: overrides default shuffle buffer size.\n      prefetch: number of batches to prefetch.\n      train_examples: optional number of examples to take for training.\n        If greater than available number of examples, equivalent to None (all).\n        Ignored with for_eval is True.\n      filtered_num_samples: required when filter_fn is set, number of\n        samples after applying filter_fn.\n      filter_fn: filter function for generating training subset.\n      batch_preprocess_fn: optional function for preprocessing a full batch of\n        input data. Analoguous to preprocess_fn with an extra batch-dimension\n        on all tensors.\n      ignore_errors: whether to skip images that encountered an error in\n        decoding *or pre-processing*, the latter is why it is False by default.\n      shuffle_files: whether to shuffle the dataset files or not.\n\n    Returns:\n      A tf.data.Dataset object as a dictionary containing the output tensors.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.__init__": [[211, 266], ["base.ImageData._log_warning_if_direct_inheritance", "isinstance", "tensorflow.logging.warning", "isinstance", "ValueError", "ValueError", "type"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageTfdsData._log_warning_if_direct_inheritance"], ["@", "abc", ".", "abstractmethod", "\n", "def", "__init__", "(", "self", ",", "\n", "num_samples_splits", ",", "\n", "shuffle_buffer_size", ",", "\n", "num_preprocessing_threads", ",", "\n", "num_classes", ",", "\n", "default_label_key", "=", "'label'", ",", "\n", "base_preprocess_fn", "=", "None", ",", "\n", "filter_fn", "=", "None", ",", "\n", "image_decoder", "=", "None", ",", "\n", "num_channels", "=", "3", ")", ":", "\n", "    ", "\"\"\"Initializer for the base ImageData class.\n\n    Args:\n      num_samples_splits: a dictionary, that maps splits (\"train\", \"trainval\",\n          \"val\", and \"test\") to the corresponding number of samples.\n      shuffle_buffer_size: size of a buffer used for shuffling.\n      num_preprocessing_threads: the number of parallel threads for data\n          preprocessing.\n      num_classes: int/dict, number of classes in this dataset for the\n        `default_label_key` tensor, or dictionary with the number of classes in\n        each label tensor.\n      default_label_key: optional, string with the name of the tensor to use\n        as label. Default is \"label\".\n      base_preprocess_fn: optional, base preprocess function to apply in all\n        cases for this dataset.\n      filter_fn: optional, function to filter the examples to use in the\n        dataset. DEPRECATED, soon to be removed.\n      image_decoder: a function to decode image.\n      num_channels: number of channels in the dataset image.\n    \"\"\"", "\n", "self", ".", "_log_warning_if_direct_inheritance", "(", ")", "\n", "self", ".", "_num_samples_splits", "=", "num_samples_splits", "\n", "self", ".", "_shuffle_buffer_size", "=", "shuffle_buffer_size", "\n", "self", ".", "_num_preprocessing_threads", "=", "num_preprocessing_threads", "\n", "self", ".", "_base_preprocess_fn", "=", "base_preprocess_fn", "\n", "self", ".", "_default_label_key", "=", "default_label_key", "\n", "self", ".", "_filter_fn", "=", "filter_fn", "\n", "if", "self", ".", "_filter_fn", ":", "\n", "      ", "tf", ".", "logging", ".", "warning", "(", "'Using deprecated filtering mechanism.'", ")", "\n", "", "self", ".", "_image_decoder", "=", "image_decoder", "\n", "self", ".", "_num_channels", "=", "num_channels", "\n", "\n", "if", "isinstance", "(", "num_classes", ",", "dict", ")", ":", "\n", "      ", "self", ".", "_num_classes", "=", "num_classes", "\n", "if", "default_label_key", "not", "in", "num_classes", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "'No num_classes was specified for the default_label_key %r'", "%", "\n", "default_label_key", ")", "\n", "", "", "elif", "isinstance", "(", "num_classes", ",", "int", ")", ":", "\n", "      ", "self", ".", "_num_classes", "=", "{", "default_label_key", ":", "num_classes", "}", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "'\"num_classes\" must be a int or a dict, but type %r was given'", "%", "\n", "type", "(", "num_classes", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.default_label_key": [[267, 270], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "default_label_key", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_default_label_key", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.label_keys": [[271, 274], ["tuple", "base.ImageData._num_classes.keys"], "methods", ["None"], ["", "@", "property", "\n", "def", "label_keys", "(", "self", ")", ":", "\n", "    ", "return", "tuple", "(", "self", ".", "_num_classes", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.num_channels": [[275, 278], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_channels", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_num_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.splits": [[279, 282], ["tuple", "base.ImageData._num_samples_splits.keys"], "methods", ["None"], ["", "@", "property", "\n", "def", "splits", "(", "self", ")", ":", "\n", "    ", "return", "tuple", "(", "self", ".", "_num_samples_splits", ".", "keys", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_samples": [[283, 285], ["None"], "methods", ["None"], ["", "def", "get_num_samples", "(", "self", ",", "split_name", ")", ":", "\n", "    ", "return", "self", ".", "_num_samples_splits", "[", "split_name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_classes": [[286, 290], ["None"], "methods", ["None"], ["", "def", "get_num_classes", "(", "self", ",", "label_key", "=", "None", ")", ":", "\n", "    ", "if", "label_key", "is", "None", ":", "\n", "      ", "label_key", "=", "self", ".", "_default_label_key", "\n", "", "return", "self", ".", "_num_classes", "[", "label_key", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_version": [[291, 293], ["NotImplementedError"], "methods", ["None"], ["", "def", "get_version", "(", "self", ")", ":", "\n", "    ", "return", "NotImplementedError", "(", "'Version is not supported outside TFDS.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_tf_data": [[294, 385], ["base.ImageData._get_dataset_split", "base.ImageData._cache_data_if_possible", "base.ImageData._preprocess_and_batch_data", "preprocess_before_filter", "ValueError", "tensorflow.logging.warning", "data.take.take.filter", "data.take.take.map", "data.take.take.repeat", "data.take.take.shuffle", "data.take.take.map", "data.take.take.prefetch", "data.take.take.take", "base.ImageData.get_num_samples", "isinstance", "tensorflow.print", "tensorflow.control_dependencies", "tensorflow.identity"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base_test.FakeImageData._get_dataset_split", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData._cache_data_if_possible", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData._preprocess_and_batch_data", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_samples"], ["", "def", "get_tf_data", "(", "self", ",", "\n", "split_name", ",", "\n", "batch_size", ",", "\n", "pairwise_mix_fn", "=", "None", ",", "\n", "preprocess_fn", "=", "None", ",", "\n", "preprocess_before_filter", "=", "None", ",", "\n", "epochs", "=", "None", ",", "\n", "drop_remainder", "=", "True", ",", "\n", "for_eval", "=", "False", ",", "\n", "shuffle_buffer_size", "=", "None", ",", "\n", "prefetch", "=", "1", ",", "\n", "train_examples", "=", "None", ",", "\n", "filtered_num_samples", "=", "None", ",", "\n", "filter_fn", "=", "None", ",", "\n", "batch_preprocess_fn", "=", "None", ",", "\n", "ignore_errors", "=", "False", ",", "\n", "shuffle_files", "=", "False", ")", ":", "\n", "# Obtains tf.data object.", "\n", "# We shuffle later when not for eval, it's important to not shuffle before", "\n", "# a subset of data is retrieved.", "\n", "    ", "data", "=", "self", ".", "_get_dataset_split", "(", "\n", "split_name", "=", "split_name", ",", "\n", "shuffle_files", "=", "shuffle_files", ")", "\n", "\n", "if", "preprocess_before_filter", "is", "not", "None", ":", "\n", "      ", "data", "=", "preprocess_before_filter", "(", "data", ")", "\n", "\n", "\n", "", "if", "self", ".", "_filter_fn", "and", "(", "filter_fn", "is", "None", ")", ":", "\n", "      ", "filter_fn", "=", "self", ".", "_filter_fn", "\n", "\n", "# Dataset filtering priority: (1) filter_fn; (2) train_examples.", "\n", "", "if", "filter_fn", "and", "train_examples", ":", "\n", "      ", "raise", "ValueError", "(", "'You must not set both filter_fn and train_examples.'", ")", "\n", "\n", "", "if", "filter_fn", ":", "\n", "      ", "tf", ".", "logging", ".", "warning", "(", "\n", "'You are filtering the dataset. Notice that this may hurt your '", "\n", "'throughput, since examples still need to be decoded, and may '", "\n", "'make the result of get_num_samples() inacurate. '", "\n", "'train_examples is ignored for filtering, but only used for '", "\n", "'calculating training steps.'", ")", "\n", "data", "=", "data", ".", "filter", "(", "filter_fn", ")", "\n", "num_samples", "=", "filtered_num_samples", "\n", "assert", "num_samples", "is", "not", "None", ",", "(", "\n", "'You must set filtered_num_samples if filter_fn is set.'", ")", "\n", "\n", "", "elif", "not", "for_eval", "and", "train_examples", ":", "\n", "# Deterministic for same dataset version.", "\n", "      ", "data", "=", "data", ".", "take", "(", "train_examples", ")", "\n", "num_samples", "=", "train_examples", "\n", "\n", "", "else", ":", "\n", "      ", "num_samples", "=", "self", ".", "get_num_samples", "(", "split_name", ")", "\n", "\n", "", "data", "=", "self", ".", "_cache_data_if_possible", "(", "\n", "data", ",", "split_name", "=", "split_name", ",", "num_samples", "=", "num_samples", ",", "for_eval", "=", "for_eval", ")", "\n", "\n", "def", "print_filtered_subset", "(", "ex", ")", ":", "\n", "      ", "\"\"\"Print filtered subset for debug purpose.\"\"\"", "\n", "if", "isinstance", "(", "ex", ",", "dict", ")", "and", "'id'", "in", "ex", "and", "'label'", "in", "ex", ":", "\n", "        ", "print_op", "=", "tf", ".", "print", "(", "\n", "'filtered_example:'", ",", "\n", "ex", "[", "'id'", "]", ",", "\n", "ex", "[", "'label'", "]", ",", "\n", "output_stream", "=", "tf", ".", "logging", ".", "error", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "print_op", "]", ")", ":", "\n", "          ", "ex", "[", "'id'", "]", "=", "tf", ".", "identity", "(", "ex", "[", "'id'", "]", ")", "\n", "", "", "return", "ex", "\n", "", "if", "not", "for_eval", "and", "filter_fn", ":", "\n", "      ", "data", "=", "data", ".", "map", "(", "print_filtered_subset", ")", "\n", "\n", "# Repeats data `epochs` time or indefinitely if `epochs` is None.", "\n", "", "if", "epochs", "is", "None", "or", "epochs", ">", "1", ":", "\n", "      ", "data", "=", "data", ".", "repeat", "(", "epochs", ")", "\n", "\n", "", "shuffle_buffer_size", "=", "shuffle_buffer_size", "or", "self", ".", "_shuffle_buffer_size", "\n", "if", "not", "for_eval", "and", "shuffle_buffer_size", ">", "1", ":", "\n", "      ", "data", "=", "data", ".", "shuffle", "(", "shuffle_buffer_size", ")", "\n", "\n", "", "data", "=", "self", ".", "_preprocess_and_batch_data", "(", "data", ",", "batch_size", ",", "drop_remainder", ",", "\n", "pairwise_mix_fn", ",", "preprocess_fn", ",", "\n", "ignore_errors", ")", "\n", "\n", "if", "batch_preprocess_fn", "is", "not", "None", ":", "\n", "      ", "data", "=", "data", ".", "map", "(", "batch_preprocess_fn", ",", "self", ".", "_num_preprocessing_threads", ")", "\n", "\n", "", "if", "prefetch", "!=", "0", ":", "\n", "      ", "data", "=", "data", ".", "prefetch", "(", "prefetch", ")", "\n", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData._get_dataset_split": [[386, 397], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "_get_dataset_split", "(", "self", ",", "split_name", ",", "shuffle_files", "=", "False", ")", ":", "\n", "    ", "\"\"\"Return the Dataset object for the given split name.\n\n    Args:\n      split_name: Name of the dataset split to get.\n      shuffle_files: Whether or not to shuffle files in the dataset.\n\n    Returns:\n      A tf.data.Dataset object containing the data for the given split.\n    \"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData._log_warning_if_direct_inheritance": [[398, 401], ["tensorflow.logging.warning"], "methods", ["None"], ["", "def", "_log_warning_if_direct_inheritance", "(", "self", ")", ":", "\n", "    ", "tf", ".", "logging", ".", "warning", "(", "\n", "'You are directly inheriting from ImageData. Please, consider porting '", "\n", "'your dataset to TFDS (go/tfds) and inheriting from ImageTfdsData '", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData._preprocess_and_batch_data": [[404, 437], ["base.compose_preprocess_fn", "data.apply.apply.map", "data.apply.apply.batch", "tensorflow.data.Dataset.zip().map", "data.apply.apply.map", "tensorflow.logging.info", "data.apply.apply.apply", "tensorflow.data.experimental.ignore_errors", "tensorflow.data.Dataset.zip", "data.apply.apply.skip"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.compose_preprocess_fn"], ["", "def", "_preprocess_and_batch_data", "(", "self", ",", "\n", "data", ",", "\n", "batch_size", ",", "\n", "drop_remainder", "=", "True", ",", "\n", "pairwise_mix_fn", "=", "None", ",", "\n", "preprocess_fn", "=", "None", ",", "\n", "ignore_errors", "=", "False", ")", ":", "\n", "    ", "\"\"\"Preprocesses and batches a given tf.Dataset.\"\"\"", "\n", "# Preprocess with basic preprocess functions (e.g. decoding images, parsing", "\n", "# features etc.).", "\n", "base_preprocess_fn", "=", "compose_preprocess_fn", "(", "self", ".", "_image_decoder", ",", "\n", "self", ".", "_base_preprocess_fn", ")", "\n", "# Note: `map_and_batch` is deprecated, and at least when nothing happens", "\n", "# in-between, automatically gets merged for efficiency. Same below.", "\n", "data", "=", "data", ".", "map", "(", "base_preprocess_fn", ",", "self", ".", "_num_preprocessing_threads", ")", "\n", "\n", "# Mix images pair-wise before other element-wise preprocessing.", "\n", "# Note: The pairing is implemented by shifting `data` by 1, so the last", "\n", "# element of `data` will be dropped.", "\n", "if", "pairwise_mix_fn", "is", "not", "None", ":", "\n", "      ", "data", "=", "tf", ".", "data", ".", "Dataset", ".", "zip", "(", "\n", "(", "data", ",", "data", ".", "skip", "(", "1", ")", ")", ")", ".", "map", "(", "pairwise_mix_fn", ",", "\n", "self", ".", "_num_preprocessing_threads", ")", "\n", "\n", "# Preprocess with customized preprocess functions.", "\n", "", "if", "preprocess_fn", "is", "not", "None", ":", "\n", "      ", "data", "=", "data", ".", "map", "(", "preprocess_fn", ",", "self", ".", "_num_preprocessing_threads", ")", "\n", "\n", "", "if", "ignore_errors", ":", "\n", "      ", "tf", ".", "logging", ".", "info", "(", "'Ignoring any image with errors.'", ")", "\n", "data", "=", "data", ".", "apply", "(", "tf", ".", "data", ".", "experimental", ".", "ignore_errors", "(", ")", ")", "\n", "\n", "", "return", "data", ".", "batch", "(", "batch_size", ",", "drop_remainder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData._cache_data_if_possible": [[438, 445], ["data.cache.cache.cache"], "methods", ["None"], ["", "def", "_cache_data_if_possible", "(", "self", ",", "data", ",", "split_name", ",", "num_samples", ",", "for_eval", ")", ":", "\n", "    ", "del", "split_name", "\n", "\n", "if", "not", "for_eval", "and", "num_samples", "<=", "150000", ":", "\n", "# Cache the whole dataset if it's smaller than 150K examples.", "\n", "      ", "data", "=", "data", ".", "cache", "(", ")", "\n", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageTfdsData.__init__": [[455, 480], ["kwargs.update", "base.ImageData.__init__", "decoder"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["@", "abc", ".", "abstractmethod", "\n", "def", "__init__", "(", "self", ",", "dataset_builder", ",", "tfds_splits", ",", "image_key", "=", "'image'", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Initializer for the base ImageData class.\n\n    Args:\n      dataset_builder: tfds dataset builder object.\n      tfds_splits: a dictionary, that maps splits (\"train\", \"trainval\", \"val\",\n          and \"test\") to the corresponding tfds `Split` objects.\n      image_key: image key.\n      **kwargs: Additional keyword arguments for the ImageData class.\n    \"\"\"", "\n", "self", ".", "_dataset_builder", "=", "dataset_builder", "\n", "self", ".", "_tfds_splits", "=", "tfds_splits", "\n", "self", ".", "_image_key", "=", "image_key", "\n", "\n", "# Overwrite image decoder", "\n", "def", "_image_decoder", "(", "data", ")", ":", "\n", "      ", "decoder", "=", "dataset_builder", ".", "info", ".", "features", "[", "image_key", "]", ".", "decode_example", "\n", "data", "[", "image_key", "]", "=", "decoder", "(", "data", "[", "image_key", "]", ")", "\n", "return", "data", "\n", "", "self", ".", "_image_decoder", "=", "_image_decoder", "\n", "\n", "kwargs", ".", "update", "(", "{", "'image_decoder'", ":", "_image_decoder", "}", ")", "\n", "\n", "super", "(", "ImageTfdsData", ",", "self", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageTfdsData.get_version": [[481, 483], ["base.ImageTfdsData._dataset_builder.version.__str__"], "methods", ["None"], ["", "def", "get_version", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_dataset_builder", ".", "version", ".", "__str__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageTfdsData._get_dataset_split": [[484, 489], ["tensorflow_datasets.decode.SkipDecoding", "base.ImageTfdsData._dataset_builder.as_dataset"], "methods", ["None"], ["", "def", "_get_dataset_split", "(", "self", ",", "split_name", ",", "shuffle_files", ")", ":", "\n", "    ", "dummy_decoder", "=", "tfds", ".", "decode", ".", "SkipDecoding", "(", ")", "\n", "return", "self", ".", "_dataset_builder", ".", "as_dataset", "(", "\n", "split", "=", "self", ".", "_tfds_splits", "[", "split_name", "]", ",", "shuffle_files", "=", "shuffle_files", ",", "\n", "decoders", "=", "{", "self", ".", "_image_key", ":", "dummy_decoder", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageTfdsData._log_warning_if_direct_inheritance": [[490, 492], ["None"], "methods", ["None"], ["", "def", "_log_warning_if_direct_inheritance", "(", "self", ")", ":", "\n", "    ", "pass", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn": [[28, 36], ["None"], "function", ["None"], ["def", "make_get_tensors_fn", "(", "output_tensors", ")", ":", "\n", "  ", "\"\"\"Create a function that outputs a collection of tensors from the dataset.\"\"\"", "\n", "\n", "def", "_get_fn", "(", "data", ")", ":", "\n", "    ", "\"\"\"Get tensors by name.\"\"\"", "\n", "return", "{", "tensor_name", ":", "data", "[", "tensor_name", "]", "for", "tensor_name", "in", "output_tensors", "}", "\n", "\n", "", "return", "_get_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn": [[38, 90], ["output_tensors.items", "isinstance", "tensors_to_cast.append", "tensorflow.cast", "base.make_get_and_cast_tensors_fn._tensors_to_cast"], "function", ["None"], ["", "def", "make_get_and_cast_tensors_fn", "(", "output_tensors", ")", ":", "\n", "  ", "\"\"\"Create a function that gets and casts a set of tensors from the dataset.\n\n  Optionally, you can also rename the tensors.\n\n  Examples:\n    # This simply gets \"image\" and \"label\" tensors without any casting.\n    # Note that this is equivalent to make_get_tensors_fn([\"image\", \"label\"]).\n    make_get_and_cast_tensors_fn({\n      \"image\": None,\n      \"label\": None,\n    })\n\n    # This gets the \"image\" tensor without any type conversion, casts the\n    # \"heatmap\" tensor to tf.float32, and renames the tensor \"class/label\" to\n    # \"label\" and casts it to tf.int64.\n    make_get_and_cast_tensors_fn({\n      \"image\": None,\n      \"heatmap\": tf.float32,\n      \"class/label\": (\"label\", tf.int64),\n    })\n\n  Args:\n    output_tensors: dictionary specifying the set of tensors to get and cast\n      from the dataset.\n\n  Returns:\n    The function performing the operation.\n  \"\"\"", "\n", "\n", "def", "_tensors_to_cast", "(", ")", ":", "\n", "    ", "tensors_to_cast", "=", "[", "]", "# AutoGraph does not support generators.", "\n", "for", "tensor_name", ",", "tensor_dtype", "in", "output_tensors", ".", "items", "(", ")", ":", "\n", "      ", "if", "isinstance", "(", "tensor_dtype", ",", "tuple", ")", "and", "len", "(", "tensor_dtype", ")", "==", "2", ":", "\n", "        ", "tensors_to_cast", ".", "append", "(", "(", "tensor_name", ",", "tensor_dtype", "[", "0", "]", ",", "tensor_dtype", "[", "1", "]", ")", ")", "\n", "", "elif", "tensor_dtype", "is", "None", "or", "isinstance", "(", "tensor_dtype", ",", "tf", ".", "dtypes", ".", "DType", ")", ":", "\n", "        ", "tensors_to_cast", ".", "append", "(", "(", "tensor_name", ",", "tensor_name", ",", "tensor_dtype", ")", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Values of the output_tensors dictionary must be '", "\n", "'None, tf.dtypes.DType or 2-tuples.'", ")", "\n", "", "", "return", "tensors_to_cast", "\n", "\n", "", "def", "_get_and_cast_fn", "(", "data", ")", ":", "\n", "    ", "\"\"\"Get and cast tensors by name, optionally changing the name too.\"\"\"", "\n", "\n", "return", "{", "\n", "new_name", ":", "\n", "data", "[", "name", "]", "if", "new_dtype", "is", "None", "else", "tf", ".", "cast", "(", "data", "[", "name", "]", ",", "new_dtype", ")", "\n", "for", "name", ",", "new_name", ",", "new_dtype", "in", "_tensors_to_cast", "(", ")", "\n", "}", "\n", "\n", "", "return", "_get_and_cast_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.compose_preprocess_fn": [[92, 109], ["fn"], "function", ["None"], ["", "def", "compose_preprocess_fn", "(", "*", "functions", ")", ":", "\n", "  ", "\"\"\"Compose two or more preprocessing functions.\n\n  Args:\n    *functions: Sequence of preprocess functions to compose.\n\n  Returns:\n    The composed function.\n  \"\"\"", "\n", "\n", "def", "_composed_fn", "(", "x", ")", ":", "\n", "    ", "for", "fn", "in", "functions", ":", "\n", "      ", "if", "fn", "is", "not", "None", ":", "# Note: If one function is None, equiv. to identity.", "\n", "        ", "x", "=", "fn", "(", "x", ")", "\n", "", "", "return", "x", "\n", "\n", "", "return", "_composed_fn", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cars_test.CarsDataTest.setUp": [[29, 42], ["super().setUp", "task_adaptation.data.cars.CarsData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "CarsDataTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "cars", ".", "CarsData", "(", ")", ",", "\n", "num_classes", "=", "196", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6515", ",", "\n", "val", "=", "1629", ",", "\n", "trainval", "=", "8144", ",", "\n", "test", "=", "8041", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataCountTest.setUp": [[29, 47], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataCountTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"count_all\"", ")", ",", "\n", "num_classes", "=", "16", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataCountLeftTest.setUp": [[52, 70], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataCountLeftTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"count_left\"", ")", ",", "\n", "num_classes", "=", "16", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataCountFarTest.setUp": [[75, 93], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataCountFarTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"count_far\"", ")", ",", "\n", "num_classes", "=", "16", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataCountNearTest.setUp": [[98, 116], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataCountNearTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"count_near\"", ")", ",", "\n", "num_classes", "=", "16", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataClosestDistanceTest.setUp": [[121, 139], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataClosestDistanceTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"closest_object_distance\"", ")", ",", "\n", "num_classes", "=", "5", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataClosestXLocTest.setUp": [[144, 162], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataClosestXLocTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"closest_object_x_location\"", ")", ",", "\n", "num_classes", "=", "5", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataCountVehiclesTest.setUp": [[167, 185], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataCountVehiclesTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"count_vehicles\"", ")", ",", "\n", "num_classes", "=", "4", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.KittiDataClosestVehicleTest.setUp": [[190, 208], ["super().setUp", "task_adaptation.data.kitti.KittiData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "KittiDataClosestVehicleTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "kitti", ".", "KittiData", "(", "task", "=", "\"closest_vehicle_distance\"", ")", ",", "\n", "num_classes", "=", "4", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "6347", ",", "\n", "val", "=", "423", ",", "\n", "trainval", "=", "6770", ",", "\n", "test", "=", "711", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.TestPreprocessing.test_count_vehicles": [[212, 225], ["tensorflow.Session", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.Session.run", "task_adaptation.data.kitti._count_vehicles_pp", "task_adaptation.data.kitti._count_vehicles_pp", "task_adaptation.data.kitti._count_vehicles_pp", "task_adaptation.data.kitti._count_vehicles_pp", "task_adaptation.data.kitti._count_vehicles_pp"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_vehicles_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_vehicles_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_vehicles_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_vehicles_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_vehicles_pp"], ["  ", "def", "test_count_vehicles", "(", "self", ")", ":", "\n", "    ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "x", "=", "{", "\"image\"", ":", "tf", ".", "constant", "(", "[", "0", "]", ")", "}", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", "]", ")", "}", "\n", "self", ".", "assertEqual", "(", "1", ",", "sess", ".", "run", "(", "kitti", ".", "_count_vehicles_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\"type\"", ":", "tf", ".", "constant", "(", "[", "3", "]", ")", "}", "\n", "self", ".", "assertEqual", "(", "0", ",", "sess", ".", "run", "(", "kitti", ".", "_count_vehicles_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", ",", "1", "]", ")", "}", "\n", "self", ".", "assertEqual", "(", "2", ",", "sess", ".", "run", "(", "kitti", ".", "_count_vehicles_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", ",", "1", ",", "2", "]", ")", "}", "\n", "self", ".", "assertEqual", "(", "3", ",", "sess", ".", "run", "(", "kitti", ".", "_count_vehicles_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", ",", "1", ",", "2", ",", "2", ",", "2", ",", "2", ",", "2", "]", ")", "}", "\n", "self", ".", "assertEqual", "(", "3", ",", "sess", ".", "run", "(", "kitti", ".", "_count_vehicles_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti_test.TestPreprocessing.test_closest_vehicle": [[226, 259], ["tensorflow.Session", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "kitti_test.TestPreprocessing.assertEqual", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session.run", "tensorflow.constant", "tensorflow.constant", "tensorflow.Session.run", "task_adaptation.data.kitti._closest_vehicle_distance_pp", "task_adaptation.data.kitti._closest_vehicle_distance_pp", "task_adaptation.data.kitti._closest_vehicle_distance_pp", "task_adaptation.data.kitti._closest_vehicle_distance_pp", "task_adaptation.data.kitti._closest_vehicle_distance_pp"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_vehicle_distance_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_vehicle_distance_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_vehicle_distance_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_vehicle_distance_pp", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_vehicle_distance_pp"], ["", "def", "test_closest_vehicle", "(", "self", ")", ":", "\n", "    ", "sess", "=", "tf", ".", "Session", "(", ")", "\n", "x", "=", "{", "\"image\"", ":", "tf", ".", "constant", "(", "[", "0", "]", ")", "}", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\n", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", "]", ")", ",", "\n", "\"location\"", ":", "tf", ".", "constant", "(", "[", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", ",", "\n", "}", "\n", "self", ".", "assertEqual", "(", "0", ",", "\n", "sess", ".", "run", "(", "kitti", ".", "_closest_vehicle_distance_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\n", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", "]", ")", ",", "\n", "\"location\"", ":", "tf", ".", "constant", "(", "[", "[", "0.0", ",", "0.0", ",", "10.0", "]", "]", ")", ",", "\n", "}", "\n", "self", ".", "assertEqual", "(", "1", ",", "\n", "sess", ".", "run", "(", "kitti", ".", "_closest_vehicle_distance_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\n", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", "]", ")", ",", "\n", "\"location\"", ":", "tf", ".", "constant", "(", "[", "[", "0.0", ",", "0.0", ",", "30.0", "]", "]", ")", ",", "\n", "}", "\n", "self", ".", "assertEqual", "(", "2", ",", "\n", "sess", ".", "run", "(", "kitti", ".", "_closest_vehicle_distance_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\n", "\"type\"", ":", "tf", ".", "constant", "(", "[", "4", "]", ")", ",", "\n", "\"location\"", ":", "tf", ".", "constant", "(", "[", "[", "0.0", ",", "0.0", ",", "30.0", "]", "]", ")", ",", "\n", "}", "\n", "self", ".", "assertEqual", "(", "3", ",", "\n", "sess", ".", "run", "(", "kitti", ".", "_closest_vehicle_distance_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "x", "[", "\"objects\"", "]", "=", "{", "\n", "\"type\"", ":", "tf", ".", "constant", "(", "[", "0", ",", "1", "]", ")", ",", "\n", "\"location\"", ":", "tf", ".", "constant", "(", "[", "[", "0.0", ",", "0.0", ",", "30.0", "]", ",", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", ")", ",", "\n", "}", "\n", "self", ".", "assertEqual", "(", "0", ",", "\n", "sess", ".", "run", "(", "kitti", ".", "_closest_vehicle_distance_pp", "(", "x", ")", "[", "\"label\"", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cub_test.CUB2011DataTest.setUp": [[30, 44], ["task_adaptation.data.cub.CUB2011Data", "super().setUp", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "self", ".", "dataset", "=", "cub", ".", "CUB2011Data", "(", ")", "\n", "super", "(", "CUB2011DataTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "self", ".", "dataset", ",", "\n", "num_classes", "=", "200", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "5395", ",", "\n", "val", "=", "599", ",", "\n", "trainval", "=", "5994", ",", "\n", "test", "=", "5794", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.resisc45.Resisc45Data.__init__": [[42, 92], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.data.base.ImageTfdsData.__init__", "task_adaptation.data.base.make_get_and_cast_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"resisc45:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "num_examples", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "train_count", "=", "num_examples", "*", "TRAIN_SPLIT_PERCENT", "//", "100", "\n", "val_count", "=", "num_examples", "*", "VALIDATION_SPLIT_PERCENT", "//", "100", "\n", "test_count", "=", "num_examples", "*", "TEST_SPLIT_PERCENT", "//", "100", "\n", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\n", "\"train[:{}]\"", ".", "format", "(", "train_count", ")", ",", "\n", "\"val\"", ":", "\n", "\"train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "val_count", ")", ",", "\n", "\"trainval\"", ":", "\n", "\"train[:{}]\"", ".", "format", "(", "train_count", "+", "val_count", ")", ",", "\n", "\"test\"", ":", "\n", "\"train[{}:]\"", ".", "format", "(", "train_count", "+", "val_count", ")", ",", "\n", "\"train800\"", ":", "\n", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\n", "\"train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "\n", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "200", ")", ",", "\n", "}", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "super", "(", "Resisc45Data", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Rename tensors but keep their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "{", "\n", "\"image\"", ":", "(", "\"image\"", ",", "None", ")", ",", "\n", "\"label\"", ":", "(", "\"label\"", ",", "None", ")", ",", "\n", "}", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.patch_camelyon_test.PatchCamelyonTest.setUp": [[29, 45], ["super().setUp", "task_adaptation.data.patch_camelyon.PatchCamelyonData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "PatchCamelyonTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "patch_camelyon", ".", "PatchCamelyonData", "(", ")", ",", "\n", "num_classes", "=", "2", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "262144", ",", "\n", "val", "=", "32768", ",", "\n", "trainval", "=", "262144", "+", "32768", ",", "\n", "test", "=", "32768", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "96", ",", "96", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dmlab_test.DmlabTest.setUp": [[29, 51], ["super().setUp", "task_adaptation.data.dmlab.DmlabData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "# The test scenarios have been defined in the base class", "\n", "# data_testing_lib.BaseDataTest already, which tests the information", "\n", "# provided in the setup function:", "\n", "# classses, num, dataset_output, tfds_splits keys", "\n", "    ", "super", "(", "DmlabTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dmlab", ".", "DmlabData", "(", ")", ",", "\n", "num_classes", "=", "6", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "65550", ",", "\n", "val", "=", "22628", ",", "\n", "trainval", "=", "88178", ",", "\n", "test", "=", "22735", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "360", ",", "480", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.caltech.Caltech101.__init__": [[50, 87], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "dict", "task_adaptation.ImageTfdsData.__init__", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"caltech101:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "train_count", "=", "(", "_TRAIN_SPLIT_PERCENT", "*", "trainval_count", ")", "//", "100", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "num_samples_splits", "=", "dict", "(", "\n", "train", "=", "train_count", ",", "\n", "val", "=", "trainval_count", "-", "train_count", ",", "\n", "trainval", "=", "trainval_count", ",", "\n", "test", "=", "test_count", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", "train800val200", "=", "1000", ")", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}]\"", ".", "format", "(", "train_count", ")", ",", "\n", "\"val\"", ":", "\"train[{}:]\"", ".", "format", "(", "train_count", ")", ",", "\n", "\"trainval\"", ":", "\"train\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "(", "\n", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "200", ")", ")", ",", "\n", "}", "\n", "\n", "super", "(", "Caltech101", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "3000", ",", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "(", "\"image\"", ",", "\"label\"", ")", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.oxford_flowers102_test.OxfordFlowers102Test.setUp": [[29, 49], ["super().setUp", "task_adaptation.data.oxford_flowers102.OxfordFlowers102Data", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "# The test scenarios have been defined in the base class", "\n", "# data_testing_lib.BaseDataTest already, which tests the information", "\n", "# provided in the setup function:", "\n", "# classses, num, dataset_output, tfds_splits keys", "\n", "    ", "super", "(", "OxfordFlowers102Test", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "oxford_flowers102", ".", "OxfordFlowers102Data", "(", ")", ",", "\n", "num_classes", "=", "102", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "1020", ",", "\n", "val", "=", "1020", ",", "\n", "trainval", "=", "2", "*", "1020", ",", "\n", "test", "=", "6149", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.caltech_test.Caltech101Test.setUp": [[31, 48], ["task_adaptation.data.caltech.Caltech101", "super().setUp", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "self", ".", "dataset", "=", "caltech", ".", "Caltech101", "(", ")", "\n", "super", "(", "Caltech101Test", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "self", ".", "dataset", ",", "\n", "num_classes", "=", "102", ",", "# N.b. Caltech101 has 102 classes (1 for background).", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "2754", ",", "\n", "val", "=", "306", ",", "\n", "trainval", "=", "2754", "+", "306", ",", "# 3060 (30 images / class).", "\n", "test", "=", "6084", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.caltech_test.Caltech101Test.test_all_classes_in_train": [[50, 68], ["caltech_test.Caltech101Test.dataset.get_tf_data", "caltech_test.Caltech101Test.repeat", "tensorflow.data.make_one_shot_iterator().get_next", "collections.defaultdict", "caltech_test.Caltech101Test.assertGreater", "tensorflow.Session", "max", "tensorflow.data.make_one_shot_iterator", "collections.defaultdict.values", "sess.run"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.get_tf_data"], ["", "def", "test_all_classes_in_train", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the train set has at least one element in every class.\"\"\"", "\n", "# Runs over the small validation set, rather than the full train set.", "\n", "# For each class, there should be fewer than 30 items for there to be at", "\n", "# least one in the training set.", "\n", "ds", "=", "self", ".", "dataset", ".", "get_tf_data", "(", "\"val\"", ",", "batch_size", "=", "1", ",", "epochs", "=", "1", ")", "\n", "ds", ".", "repeat", "(", "1", ")", "\n", "next_element", "=", "tf", ".", "data", ".", "make_one_shot_iterator", "(", "ds", ")", ".", "get_next", "(", ")", "\n", "class_count", "=", "collections", ".", "defaultdict", "(", "int", ")", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "      ", "while", "True", ":", "\n", "        ", "try", ":", "\n", "          ", "value", "=", "sess", ".", "run", "(", "next_element", ")", "\n", "class_count", "[", "value", "[", "\"label\"", "]", "[", "0", "]", "]", "+=", "1", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "          ", "break", "\n", "\n", "", "", "", "self", ".", "assertGreater", "(", "30", ",", "max", "(", "class_count", ".", "values", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dtd_test.DTDDataTest.setUp": [[29, 45], ["super().setUp", "task_adaptation.data.dtd.DTDData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "DTDDataTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dtd", ".", "DTDData", "(", ")", ",", "\n", "num_classes", "=", "47", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "1880", ",", "\n", "val", "=", "1880", ",", "\n", "trainval", "=", "1880", "+", "1880", ",", "\n", "test", "=", "1880", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.inaturalist.INaturalistData.__init__": [[33, 75], ["tensorflow_datasets.builder", "int", "task_adaptation.data.base.ImageTfdsData.__init__", "ValueError", "round", "task_adaptation.data.base.make_get_and_cast_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["def", "__init__", "(", "self", ",", "year", "=", "2017", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "supported_years", "=", "[", "2017", "]", "\n", "if", "year", "not", "in", "supported_years", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"Only competitions from years {!r} are supported, but {!r} was given\"", "\n", ".", "format", "(", "supported_years", ",", "year", ")", ")", "\n", "", "dataset_builder", "=", "tfds", ".", "builder", "(", "\n", "\"i_naturalist{}:0.1.0\"", ".", "format", "(", "year", ")", ",", "data_dir", "=", "data_dir", ")", "\n", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}%]\"", ".", "format", "(", "TRAIN_SPLIT_PERCENT", ")", ",", "\n", "\"val\"", ":", "\"train[{}%:]\"", ".", "format", "(", "TRAIN_SPLIT_PERCENT", ")", ",", "\n", "\"trainval\"", ":", "\"train\"", ",", "\n", "\"test\"", ":", "\"validation\"", "\n", "}", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TRAIN", "]", ".", "num_examples", "\n", "train_count", "=", "int", "(", "round", "(", "trainval_count", "*", "TRAIN_SPLIT_PERCENT", "/", "100.0", ")", ")", "\n", "val_count", "=", "trainval_count", "-", "train_count", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "VALIDATION", "]", ".", "num_examples", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "trainval_count", ",", "\n", "\"test\"", ":", "test_count", "\n", "}", "\n", "\n", "super", "(", "INaturalistData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "{", "\n", "\"image\"", ":", "(", "\"image\"", ",", "None", ")", ",", "\n", "\"label\"", ":", "(", "\"label\"", ",", "None", ")", ",", "\n", "}", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ",", "\n", "image_key", "=", "\"image\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites_test.DSpritesTestDefault.setUp": [[31, 49], ["super().setUp", "task_adaptation.data.dsprites.DSpritesData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "DSpritesTestDefault", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dsprites", ".", "DSpritesData", "(", "\"label_shape\"", ")", ",", "\n", "num_classes", "=", "3", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "589824", ",", "\n", "val", "=", "73728", ",", "\n", "trainval", "=", "663552", ",", "\n", "test", "=", "73728", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "64", ",", "64", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_shape\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites_test.DSpritesTestScale.setUp": [[54, 72], ["super().setUp", "task_adaptation.data.dsprites.DSpritesData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "DSpritesTestScale", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dsprites", ".", "DSpritesData", "(", "\"label_scale\"", ")", ",", "\n", "num_classes", "=", "6", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "589824", ",", "\n", "val", "=", "73728", ",", "\n", "trainval", "=", "663552", ",", "\n", "test", "=", "73728", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "64", ",", "64", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_scale\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites_test.DSpritesTestOrientation.setUp": [[77, 95], ["super().setUp", "task_adaptation.data.dsprites.DSpritesData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "DSpritesTestOrientation", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dsprites", ".", "DSpritesData", "(", "\"label_orientation\"", ")", ",", "\n", "num_classes", "=", "40", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "589824", ",", "\n", "val", "=", "73728", ",", "\n", "trainval", "=", "663552", ",", "\n", "test", "=", "73728", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "64", ",", "64", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_orientation\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites_test.DSpritesTestXPosition.setUp": [[100, 118], ["super().setUp", "task_adaptation.data.dsprites.DSpritesData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "DSpritesTestXPosition", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dsprites", ".", "DSpritesData", "(", "\"label_x_position\"", ")", ",", "\n", "num_classes", "=", "32", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "589824", ",", "\n", "val", "=", "73728", ",", "\n", "trainval", "=", "663552", ",", "\n", "test", "=", "73728", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "64", ",", "64", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_x_position\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites_test.DSpritesTestXPositionGrouped.setUp": [[123, 141], ["super().setUp", "task_adaptation.data.dsprites.DSpritesData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "DSpritesTestXPositionGrouped", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dsprites", ".", "DSpritesData", "(", "\"label_x_position\"", ",", "15", ")", ",", "\n", "num_classes", "=", "15", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "589824", ",", "\n", "val", "=", "73728", ",", "\n", "trainval", "=", "663552", ",", "\n", "test", "=", "73728", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "64", ",", "64", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites_test.DSpritesTestYPosition.setUp": [[146, 164], ["super().setUp", "task_adaptation.data.dsprites.DSpritesData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "DSpritesTestYPosition", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "dsprites", ".", "DSpritesData", "(", "\"label_y_position\"", ")", ",", "\n", "num_classes", "=", "32", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "589824", ",", "\n", "val", "=", "73728", ",", "\n", "trainval", "=", "663552", ",", "\n", "test", "=", "73728", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "64", ",", "64", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_y_position\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dsprites_test.DSpritesIncorrectTest.test_incorrect_classes": [[169, 173], ["dsprites_test.DSpritesIncorrectTest.assertRaisesWithLiteralMatch", "task_adaptation.data.dsprites.DSpritesData"], "methods", ["None"], ["def", "test_incorrect_classes", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "assertRaisesWithLiteralMatch", "(", "\n", "ValueError", ",", "\"invalid_attribute is not a valid attribute to predict.\"", ")", ":", "\n", "      ", "dsprites", ".", "DSpritesData", "(", "\"invalid_attribute\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.oxford_iiit_pet.OxfordIIITPetData.__init__": [[43, 84], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ",", "train_split_percent", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"oxford_iiit_pet:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "train_split_percent", "=", "train_split_percent", "or", "TRAIN_SPLIT_PERCENT", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TRAIN", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TEST", "]", ".", "num_examples", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "(", "train_split_percent", "*", "trainval_count", ")", "//", "100", ",", "\n", "\"val\"", ":", "trainval_count", "-", "(", "train_split_percent", "*", "trainval_count", ")", "//", "100", ",", "\n", "\"trainval\"", ":", "trainval_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"val\"", ":", "\"train[{}:]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"trainval\"", ":", "tfds", ".", "Split", ".", "TRAIN", ",", "\n", "\"test\"", ":", "tfds", ".", "Split", ".", "TEST", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "}", "\n", "\n", "super", "(", "OxfordIIITPetData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "[", "\"image\"", ",", "\"label\"", "]", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy_test.RetinopathyTest.setUp": [[31, 47], ["super().setUp", "task_adaptation.data.diabetic_retinopathy.RetinopathyData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "RetinopathyTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "diabetic_retinopathy", ".", "RetinopathyData", "(", ")", ",", "\n", "num_classes", "=", "5", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "35126", ",", "\n", "val", "=", "10906", ",", "\n", "trainval", "=", "35126", "+", "10906", ",", "\n", "test", "=", "42670", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy_test.RetinopathyTest.test_heavy_data_augmentation": [[49, 101], ["tensorflow.random.uniform", "tensorflow.cast", "diabetic_retinopathy_test.RetinopathyTest.assertAllEqual", "diabetic_retinopathy_test.RetinopathyTest.assertAllEqual", "diabetic_retinopathy_test.RetinopathyTest.assertAllEqual", "diabetic_retinopathy_test.RetinopathyTest.assertAllEqual", "diabetic_retinopathy_test.RetinopathyTest.assertAllClose", "diabetic_retinopathy_test.RetinopathyTest.assertAllClose", "diabetic_retinopathy_test.RetinopathyTest.assertAllClose", "diabetic_retinopathy_test.RetinopathyTest.assertAllClose", "diabetic_retinopathy_test.RetinopathyTest.cached_session", "diabetic_retinopathy_test.RetinopathyTest.cached_session", "mock.patch.object", "diabetic_retinopathy_test.RetinopathyTest.data_wrapper._heavy_data_augmentation_fn", "diabetic_retinopathy_test.RetinopathyTest.assertEqual", "sess.run", "mock.patch.object", "diabetic_retinopathy_test.RetinopathyTest.data_wrapper._heavy_data_augmentation_fn", "diabetic_retinopathy_test.RetinopathyTest.assertEqual", "sess.run"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData._heavy_data_augmentation_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData._heavy_data_augmentation_fn"], ["", "def", "test_heavy_data_augmentation", "(", "self", ")", ":", "\n", "    ", "augmentation_parameters", "=", "(", "\n", "0.0", ",", "# Relative up/down scale: 0.0 -> No scaling.", "\n", "3.141592", "/", "4.0", ",", "# Rotation angle.", "\n", "3.141592", "/", "4.0", ",", "# Rotation angle.", "\n", "1.0", ",", "# Horizontal flip? 1.0 -> No flipping.", "\n", "1.0", ",", "# Vertical flip?", "\n", "0.0", ",", "# Relative x-translation.", "\n", "0.0", ")", "# Relative y-translation.", "\n", "default_config", "=", "self", ".", "data_wrapper", ".", "_config", "\n", "try", ":", "\n", "      ", "image", "=", "tf", ".", "random", ".", "uniform", "(", "\n", "shape", "=", "(", "32", ",", "32", ",", "3", ")", ",", "minval", "=", "0", ",", "maxval", "=", "256", ",", "dtype", "=", "tf", ".", "int32", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ")", "\n", "\n", "# Test that rotation preserves the original background color from the", "\n", "# images. For that, we rotate 45 degrees the images and check that the", "\n", "# corners have the expected color.", "\n", "\n", "# Pictures with grey background.", "\n", "self", ".", "data_wrapper", ".", "_config", "=", "\"btgraham-300\"", "\n", "with", "self", ".", "cached_session", "(", ")", "as", "sess", ":", "\n", "        ", "with", "mock", ".", "patch", ".", "object", "(", "\n", "self", ".", "data_wrapper", ",", "\n", "\"_sample_heavy_data_augmentation_parameters\"", ",", "\n", "return_value", "=", "augmentation_parameters", ")", ":", "\n", "          ", "output", "=", "self", ".", "data_wrapper", ".", "_heavy_data_augmentation_fn", "(", "\n", "{", "\"image\"", ":", "image", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", "[", "\"image\"", "]", ".", "dtype", ",", "image", ".", "dtype", ")", "\n", "output", "=", "sess", ".", "run", "(", "output", ")", "\n", "", "", "self", ".", "assertAllEqual", "(", "output", "[", "\"image\"", "]", "[", "0", ",", "0", "]", ",", "(", "127", ",", "127", ",", "127", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "output", "[", "\"image\"", "]", "[", "0", ",", "-", "1", "]", ",", "(", "127", ",", "127", ",", "127", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "output", "[", "\"image\"", "]", "[", "-", "1", ",", "0", "]", ",", "(", "127", ",", "127", ",", "127", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "output", "[", "\"image\"", "]", "[", "-", "1", ",", "-", "1", "]", ",", "(", "127", ",", "127", ",", "127", ")", ")", "\n", "\n", "# Pictures with black background.", "\n", "self", ".", "data_wrapper", ".", "_config", "=", "\"250K\"", "\n", "with", "self", ".", "cached_session", "(", ")", "as", "sess", ":", "\n", "        ", "with", "mock", ".", "patch", ".", "object", "(", "\n", "self", ".", "data_wrapper", ",", "\n", "\"_sample_heavy_data_augmentation_parameters\"", ",", "\n", "return_value", "=", "augmentation_parameters", ")", ":", "\n", "          ", "output", "=", "self", ".", "data_wrapper", ".", "_heavy_data_augmentation_fn", "(", "\n", "{", "\"image\"", ":", "image", "}", ")", "\n", "self", ".", "assertEqual", "(", "output", "[", "\"image\"", "]", ".", "dtype", ",", "image", ".", "dtype", ")", "\n", "output", "=", "sess", ".", "run", "(", "output", ")", "\n", "", "", "self", ".", "assertAllClose", "(", "output", "[", "\"image\"", "]", "[", "0", ",", "0", "]", ",", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "self", ".", "assertAllClose", "(", "output", "[", "\"image\"", "]", "[", "0", ",", "-", "1", "]", ",", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "self", ".", "assertAllClose", "(", "output", "[", "\"image\"", "]", "[", "-", "1", ",", "0", "]", ",", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "self", ".", "assertAllClose", "(", "output", "[", "\"image\"", "]", "[", "-", "1", ",", "-", "1", "]", ",", "(", "0", ",", "0", ",", "0", ")", ")", "\n", "", "finally", ":", "\n", "      ", "self", ".", "data_wrapper", ".", "_config", "=", "default_config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn_test.SvhnTest.setUp": [[29, 49], ["super().setUp", "task_adaptation.data.svhn.SvhnData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "# The test scenarios have been defined in the base class", "\n", "# data_testing_lib.BaseDataTest already, which tests the information", "\n", "# provided in the setup function:", "\n", "# classses, num, dataset_output, tfds_splits keys", "\n", "    ", "super", "(", "SvhnTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "svhn", ".", "SvhnData", "(", ")", ",", "\n", "num_classes", "=", "10", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "65931", ",", "\n", "val", "=", "7326", ",", "\n", "trainval", "=", "73257", ",", "\n", "test", "=", "26032", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "32", ",", "32", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cars.CarsData.__init__": [[35, 64], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"cars196:2.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "}", "\n", "tfds_splits", "[", "\"train\"", "]", "=", "\"train[:{}%]\"", ".", "format", "(", "TRAIN_SPLIT_PERCENT", ")", "\n", "tfds_splits", "[", "\"val\"", "]", "=", "\"train[{}%:]\"", ".", "format", "(", "TRAIN_SPLIT_PERCENT", ")", "\n", "tfds_splits", "[", "\"trainval\"", "]", "=", "\"train\"", "\n", "tfds_splits", "[", "\"test\"", "]", "=", "\"test\"", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "}", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "num_samples_splits", "[", "\"train\"", "]", "=", "(", "TRAIN_SPLIT_PERCENT", "*", "trainval_count", ")", "//", "100", "\n", "num_samples_splits", "[", "\"val\"", "]", "=", "trainval_count", "-", "num_samples_splits", "[", "\"train\"", "]", "\n", "num_samples_splits", "[", "\"trainval\"", "]", "=", "trainval_count", "\n", "num_samples_splits", "[", "\"test\"", "]", "=", "test_count", "\n", "super", "(", "CarsData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "[", "\"image\"", ",", "\"label\"", "]", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cub.CUB2011Data.__init__": [[32, 68], ["tensorflow_datasets.builder", "int", "task_adaptation.data.base.ImageTfdsData.__init__", "round", "task_adaptation.data.base.make_get_and_cast_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"caltech_birds2011:0.1.1\"", ",", "data_dir", "=", "data_dir", ")", "\n", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}%]\"", ".", "format", "(", "TRAIN_SPLIT_PERCENT", ")", ",", "\n", "\"val\"", ":", "\"train[{}%:]\"", ".", "format", "(", "TRAIN_SPLIT_PERCENT", ")", ",", "\n", "\"trainval\"", ":", "\"train\"", ",", "\n", "\"test\"", ":", "\"test\"", "\n", "}", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "train_count", "=", "int", "(", "round", "(", "trainval_count", "*", "TRAIN_SPLIT_PERCENT", "/", "100.0", ")", ")", "\n", "val_count", "=", "trainval_count", "-", "train_count", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "trainval_count", ",", "\n", "\"test\"", ":", "test_count", "\n", "}", "\n", "\n", "super", "(", "CUB2011Data", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "{", "\n", "\"image\"", ":", "(", "\"image\"", ",", "None", ")", ",", "\n", "\"label\"", ":", "(", "\"label\"", ",", "None", ")", ",", "\n", "}", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ",", "\n", "image_key", "=", "\"image\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dtd.DTDData.__init__": [[36, 75], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"dtd:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"validation\"", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "train_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "val_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"validation\"", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "super", "(", "DTDData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "[", "\"image\"", ",", "\"label\"", "]", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397.Sun397Data.__init__": [[34, 73], ["task_adaptation.ImageTfdsData.__init__", "tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "ValueError", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "config", "=", "\"tfds\"", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "    ", "if", "config", "==", "\"tfds\"", ":", "\n", "      ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"sun397/tfds:4.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"validation\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "# Creates a dict with example counts.", "\n", "num_samples_splits", "=", "{", "\n", "\"test\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", ",", "\n", "\"train\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", ",", "\n", "\"val\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"validation\"", "]", ".", "num_examples", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "num_samples_splits", "[", "\"trainval\"", "]", "=", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", "+", "num_samples_splits", "[", "\"val\"", "]", ")", "\n", "", "else", ":", "\n", "\n", "      ", "raise", "ValueError", "(", "\"No supported config %r for Sun397Data.\"", "%", "config", ")", "\n", "\n", "", "super", "(", "Sun397Data", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "[", "\"image\"", ",", "\"label\"", "]", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.dmlab.DmlabData.__init__": [[40, 82], ["tensorflow_datasets.builder", "task_adaptation.data.base.ImageTfdsData.__init__", "task_adaptation.data.base.make_get_and_cast_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"dmlab:2.0.1\"", ",", "data_dir", "=", "data_dir", ")", "\n", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"validation\"", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "train_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "val_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"validation\"", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "super", "(", "DmlabData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "{", "\n", "\"image\"", ":", "(", "\"image\"", ",", "None", ")", ",", "\n", "\"label\"", ":", "(", "\"label\"", ",", "None", ")", ",", "\n", "}", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ",", "\n", "image_key", "=", "\"image\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.inaturalist_test.INaturalistTest.setUp": [[30, 43], ["super().setUp", "task_adaptation.data.inaturalist.INaturalistData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["  ", "def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "INaturalistTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "inaturalist", ".", "INaturalistData", "(", ")", ",", "\n", "num_classes", "=", "5089", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "521266", ",", "\n", "val", "=", "57918", ",", "\n", "trainval", "=", "579184", ",", "\n", "test", "=", "95986", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.setUp": [[53, 68], ["super().setUp", "isinstance", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["@", "abc", ".", "abstractmethod", "\n", "def", "setUp", "(", "self", ",", "data_wrapper", ",", "num_classes", ",", "expected_num_samples", ",", "\n", "required_tensors_shapes", ",", "default_label_key", "=", "\"label\"", ")", ":", "\n", "    ", "super", "(", "BaseDataTest", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "data_wrapper", "=", "data_wrapper", "\n", "# Expected dataset statistics.", "\n", "self", ".", "expected_num_samples", "=", "expected_num_samples", "\n", "self", ".", "required_tensors_shapes", "=", "required_tensors_shapes", "\n", "self", ".", "default_label_key", "=", "default_label_key", "\n", "if", "isinstance", "(", "num_classes", ",", "int", ")", ":", "\n", "      ", "self", ".", "expected_num_classes", "=", "{", "default_label_key", ":", "num_classes", "}", "\n", "", "elif", "isinstance", "(", "num_classes", ",", "dict", ")", ":", "\n", "      ", "self", ".", "expected_num_classes", "=", "num_classes", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"`num_classes` must be either int or dict\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.expected_splits": [[69, 72], ["None"], "methods", ["None"], ["", "", "@", "property", "\n", "def", "expected_splits", "(", "self", ")", ":", "\n", "    ", "return", "(", "\"train\"", ",", "\"val\"", ",", "\"trainval\"", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.test_base_class": [[73, 77], ["data_testing_lib.BaseDataTest.assertIsInstance"], "methods", ["None"], ["", "def", "test_base_class", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the dataset wrapper inherits from base.ImageData.\"\"\"", "\n", "self", ".", "assertIsInstance", "(", "self", ".", "data_wrapper", ",", "base", ".", "ImageData", ",", "\n", "\"Dataset class must inherit from `base.ImageData`.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.test_split_dict_keys": [[78, 83], ["set", "set", "data_testing_lib.BaseDataTest.assertSetEqual", "data_testing_lib.BaseDataTest.expected_num_samples.keys", "data_testing_lib.BaseDataTest.data_wrapper._num_samples_splits.keys"], "methods", ["None"], ["", "def", "test_split_dict_keys", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the \"num_samples\" splits contain the correct keys.\"\"\"", "\n", "expected_keys", "=", "set", "(", "self", ".", "expected_num_samples", ".", "keys", "(", ")", ")", "\n", "actual_keys", "=", "set", "(", "self", ".", "data_wrapper", ".", "_num_samples_splits", ".", "keys", "(", ")", ")", "# pylint: disable=protected-access", "\n", "self", ".", "assertSetEqual", "(", "expected_keys", ",", "actual_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.test_num_samples": [[84, 90], ["data_testing_lib.BaseDataTest.expected_num_samples.items", "data_testing_lib.BaseDataTest.assertEqual", "data_testing_lib.BaseDataTest.data_wrapper.get_num_samples"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_samples"], ["", "def", "test_num_samples", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the number of samples for each split is correct.\"\"\"", "\n", "for", "split", ",", "expected", "in", "self", ".", "expected_num_samples", ".", "items", "(", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "\n", "expected", ",", "self", ".", "data_wrapper", ".", "get_num_samples", "(", "split", ")", ",", "\n", "msg", "=", "\"Number of examples does not match for split \\\"%s\\\"\"", "%", "split", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.test_dataset_output": [[91, 107], ["data_testing_lib.BaseDataTest.data_wrapper.get_tf_data", "tensorflow.data.get_output_shapes", "data_testing_lib.BaseDataTest.assertIsInstance", "data_testing_lib.BaseDataTest.required_tensors_shapes.items", "data_testing_lib.BaseDataTest.assertIn", "tf_data_output_shapes[].as_list", "data_testing_lib.BaseDataTest.assertEqual", "tensorflow.data.get_output_shapes.keys", "list"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.get_tf_data"], ["", "", "def", "test_dataset_output", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the final tf.Dataset object has expected output shapes.\"\"\"", "\n", "batch_size", "=", "2", "\n", "for", "split", "in", "self", ".", "expected_splits", ":", "\n", "      ", "tf_data", "=", "self", ".", "data_wrapper", ".", "get_tf_data", "(", "split", ",", "batch_size", ")", "\n", "tf_data_output_shapes", "=", "tf", ".", "data", ".", "get_output_shapes", "(", "tf_data", ")", "\n", "self", ".", "assertIsInstance", "(", "tf_data_output_shapes", ",", "dict", ")", "\n", "for", "tensor_name", ",", "expected_shape", "in", "self", ".", "required_tensors_shapes", ".", "items", "(", ")", ":", "\n", "        ", "self", ".", "assertIn", "(", "tensor_name", ",", "tf_data_output_shapes", ".", "keys", "(", ")", ")", "\n", "expected_shape", "=", "[", "batch_size", "]", "+", "list", "(", "expected_shape", ")", "\n", "actual_shape", "=", "tf_data_output_shapes", "[", "tensor_name", "]", ".", "as_list", "(", ")", "\n", "self", ".", "assertEqual", "(", "\n", "actual_shape", ",", "\n", "expected_shape", ",", "\n", "msg", "=", "(", "\"Tensor {!r} for split {!r} does not match the expected \"", "\n", "\"value\"", ".", "format", "(", "tensor_name", ",", "split", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.test_label_keys": [[108, 115], ["data_testing_lib.BaseDataTest.assertEqual", "data_testing_lib.BaseDataTest.assertIn", "data_testing_lib.BaseDataTest.assertDictEqual"], "methods", ["None"], ["", "", "", "def", "test_label_keys", "(", "self", ")", ":", "\n", "    ", "self", ".", "assertEqual", "(", "\n", "self", ".", "default_label_key", ",", "self", ".", "data_wrapper", ".", "default_label_key", ")", "\n", "self", ".", "assertIn", "(", "self", ".", "default_label_key", ",", "self", ".", "data_wrapper", ".", "label_keys", ")", "\n", "# pylint: disable=protected-access", "\n", "self", ".", "assertDictEqual", "(", "\n", "self", ".", "expected_num_classes", ",", "self", ".", "data_wrapper", ".", "_num_classes", ")", "\n", "# pylint: enable=protected-access", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.test_get_num_classes": [[117, 129], ["data_testing_lib.BaseDataTest.assertEqual", "data_testing_lib.BaseDataTest.expected_num_classes.items", "data_testing_lib.BaseDataTest.data_wrapper.get_num_classes", "data_testing_lib.BaseDataTest.assertEqual", "data_testing_lib.BaseDataTest.data_wrapper.get_num_classes"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_classes", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.ImageData.get_num_classes"], ["", "def", "test_get_num_classes", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests the expected number of classes.\"\"\"", "\n", "# Check get_num_classes default output.", "\n", "self", ".", "assertEqual", "(", "\n", "self", ".", "expected_num_classes", "[", "self", ".", "data_wrapper", ".", "default_label_key", "]", ",", "\n", "self", ".", "data_wrapper", ".", "get_num_classes", "(", ")", ")", "\n", "\n", "# Check get_num_classes output with particular label keys.", "\n", "for", "label_key", ",", "num_classes", "in", "self", ".", "expected_num_classes", ".", "items", "(", ")", ":", "\n", "      ", "self", ".", "assertEqual", "(", "\n", "num_classes", ",", "self", ".", "data_wrapper", ".", "get_num_classes", "(", "label_key", ")", ",", "\n", "msg", "=", "\"Number of classes does not match for label \\\"%s\\\"\"", "%", "label_key", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.iterate_dataset": [[130, 140], ["tensorflow.compat.v1.data.make_initializable_iterator", "tensorflow.compat.v1.data.make_initializable_iterator.get_next", "session.run", "session.run"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "iterate_dataset", "(", "cls", ",", "dataset", ",", "session", ")", ":", "\n", "    ", "dataset_iter", "=", "tf", ".", "compat", ".", "v1", ".", "data", ".", "make_initializable_iterator", "(", "dataset", ")", "\n", "get_next", "=", "dataset_iter", ".", "get_next", "(", ")", "\n", "try", ":", "\n", "      ", "session", ".", "run", "(", "dataset_iter", ".", "initializer", ")", "\n", "while", "True", ":", "\n", "        ", "yield", "session", ".", "run", "(", "get_next", ")", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "      ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseTfdsDataTest.setUp": [[152, 181], ["data_testing_lib.BaseDataTest.setUp", "isinstance", "isinstance", "ValueError", "ValueError", "isinstance", "ValueError", "isinstance"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["@", "abc", ".", "abstractmethod", "\n", "def", "setUp", "(", "self", ",", "data_wrapper", ",", "num_classes", ",", "default_label_key", "=", "\"label\"", ",", "\n", "tfds_label_key_map", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "super", "(", "BaseTfdsDataTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "data_wrapper", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", "default_label_key", "=", "default_label_key", ",", "\n", "**", "kwargs", ")", "\n", "# Set the tfds_label_key_map attribute.", "\n", "if", "isinstance", "(", "num_classes", ",", "int", ")", ":", "\n", "      ", "if", "tfds_label_key_map", "is", "None", ":", "\n", "        ", "self", ".", "tfds_label_key_map", "=", "{", "default_label_key", ":", "default_label_key", "}", "\n", "", "elif", "tfds_label_key_map", ":", "\n", "        ", "if", "not", "isinstance", "(", "tfds_label_key_map", ",", "(", "str", ",", "list", ",", "tuple", ")", ")", ":", "\n", "          ", "raise", "ValueError", "(", "\n", "\"If `num_classes` is an int, `tfds_label_key_map` must be None, \"", "\n", "\"a string, or a tuple of strings.\"", ")", "\n", "", "self", ".", "tfds_label_key_map", "=", "{", "default_label_key", ":", "tfds_label_key_map", "}", "\n", "", "else", ":", "\n", "        ", "self", ".", "tfds_label_key_map", "=", "{", "}", "\n", "", "", "elif", "isinstance", "(", "num_classes", ",", "dict", ")", ":", "\n", "      ", "if", "not", "(", "tfds_label_key_map", "is", "None", "or", "\n", "isinstance", "(", "tfds_label_key_map", ",", "dict", ")", ")", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"If `num_classes` is a dict, `tfds_label_key_map` must be None or \"", "\n", "\"a dict.\"", ")", "\n", "", "self", ".", "tfds_label_key_map", "=", "tfds_label_key_map", "or", "{", "}", "\n", "", "else", ":", "\n", "      ", "raise", "ValueError", "(", "\"`num_classes` must be either int or dict\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseTfdsDataTest.test_base_class": [[182, 186], ["data_testing_lib.BaseTfdsDataTest.assertIsInstance"], "methods", ["None"], ["", "", "def", "test_base_class", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests that the dataset wrapper inherits from base.ImageData.\"\"\"", "\n", "self", ".", "assertIsInstance", "(", "self", ".", "data_wrapper", ",", "base", ".", "ImageTfdsData", ",", "\n", "\"Dataset class must inherit from `base.ImageData`.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseTfdsDataTest.test_split_dict_keys": [[187, 193], ["data_testing_lib.BaseDataTest.test_split_dict_keys", "set", "set", "data_testing_lib.BaseTfdsDataTest.assertSetEqual", "data_testing_lib.BaseTfdsDataTest.expected_num_samples.keys", "data_testing_lib.BaseTfdsDataTest.data_wrapper._tfds_splits.keys"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseTfdsDataTest.test_split_dict_keys"], ["", "def", "test_split_dict_keys", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests the \"tfds\" and \"num_samples\" splits contain the correct keys.\"\"\"", "\n", "super", "(", "BaseTfdsDataTest", ",", "self", ")", ".", "test_split_dict_keys", "(", ")", "\n", "expected_keys", "=", "set", "(", "self", ".", "expected_num_samples", ".", "keys", "(", ")", ")", "\n", "actual_keys", "=", "set", "(", "self", ".", "data_wrapper", ".", "_tfds_splits", ".", "keys", "(", ")", ")", "# pylint: disable=protected-access", "\n", "self", ".", "assertSetEqual", "(", "expected_keys", ",", "actual_keys", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseTfdsDataTest.test_get_num_classes": [[194, 220], ["data_testing_lib.BaseDataTest.test_get_num_classes", "data_testing_lib.BaseTfdsDataTest.tfds_label_key_map.items", "data_testing_lib.BaseTfdsDataTest.assertEqual", "isinstance", "data_testing_lib.BaseTfdsDataTest.test_get_num_classes._get_from_dict_recursive"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseTfdsDataTest.test_get_num_classes"], ["", "def", "test_get_num_classes", "(", "self", ")", ":", "\n", "    ", "\"\"\"Tests the expected number of classes.\"\"\"", "\n", "super", "(", "BaseTfdsDataTest", ",", "self", ")", ".", "test_get_num_classes", "(", ")", "\n", "\n", "# Check get_num_classes output against TFDS.", "\n", "def", "_get_from_dict_recursive", "(", "key", ",", "features", ")", ":", "\n", "      ", "\"\"\"Returns an entry from a dict, recursively.\"\"\"", "\n", "# Examples:", "\n", "# _get_from_dict_recursive(\"key\", features) -> features[\"key\"]", "\n", "# _get_from_dict_recursive([\"key1\", \"key2\"], features) ->", "\n", "#   features[\"key1\"][\"key2\"]", "\n", "if", "isinstance", "(", "key", ",", "(", "list", ",", "tuple", ")", ")", "and", "len", "(", "key", ")", ">", "1", ":", "\n", "        ", "return", "_get_from_dict_recursive", "(", "key", "[", "1", ":", "]", ",", "features", "[", "key", "[", "0", "]", "]", ")", "\n", "", "elif", "isinstance", "(", "key", ",", "(", "list", ",", "tuple", ")", ")", ":", "\n", "        ", "return", "features", "[", "key", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "        ", "return", "features", "[", "key", "]", "\n", "\n", "", "", "for", "label_key", ",", "tfds_label_key", "in", "self", ".", "tfds_label_key_map", ".", "items", "(", ")", ":", "\n", "# pylint: disable=protected-access", "\n", "      ", "tfds_num_classes", "=", "_get_from_dict_recursive", "(", "\n", "tfds_label_key", ",", "\n", "self", ".", "data_wrapper", ".", "_dataset_builder", ".", "info", ".", "features", ")", ".", "num_classes", "\n", "# pylint: enable=protected-access", "\n", "self", ".", "assertEqual", "(", "\n", "self", ".", "data_wrapper", ".", "get_num_classes", "(", "label_key", ")", ",", "tfds_num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseVTABDataTest.expected_splits": [[224, 228], ["None"], "methods", ["None"], ["  ", "@", "property", "\n", "def", "expected_splits", "(", "self", ")", ":", "\n", "    ", "return", "(", "\"train\"", ",", "\"val\"", ",", "\"trainval\"", ",", "\"test\"", ",", "\"train800\"", ",", "\"val200\"", ",", "\n", "\"train800val200\"", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti.KittiData.__init__": [[167, 210], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "ValueError"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["def", "__init__", "(", "self", ",", "task", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "    ", "if", "task", "not", "in", "_TASK_DICT", ":", "\n", "      ", "raise", "ValueError", "(", "\"Unknown task: %s\"", "%", "task", ")", "\n", "\n", "", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"kitti:3.1.0\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"validation\"", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "train_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TRAIN", "]", ".", "num_examples", "\n", "val_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "VALIDATION", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TEST", "]", ".", "num_examples", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "task", "=", "_TASK_DICT", "[", "task", "]", "\n", "base_preprocess_fn", "=", "task", "[", "\"preprocess_fn\"", "]", "\n", "super", "(", "KittiData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "base_preprocess_fn", "=", "base_preprocess_fn", ",", "\n", "num_classes", "=", "task", "[", "\"num_classes\"", "]", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_all_pp": [[29, 35], ["tensorflow.math.minimum", "tensorflow.size"], "function", ["None"], ["def", "_count_all_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Count all objects.\"\"\"", "\n", "# Count distribution (thresholded at 15):", "\n", "\n", "label", "=", "tf", ".", "math", ".", "minimum", "(", "tf", ".", "size", "(", "x", "[", "\"objects\"", "]", "[", "\"type\"", "]", ")", "-", "1", ",", "8", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_vehicles_pp": [[37, 45], ["tensorflow.where", "tensorflow.math.minimum", "tensorflow.size"], "function", ["None"], ["", "def", "_count_vehicles_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Counting vehicles.\"\"\"", "\n", "# Label distribution:", "\n", "\n", "vehicles", "=", "tf", ".", "where", "(", "x", "[", "\"objects\"", "]", "[", "\"type\"", "]", "<", "3", ")", "# Car, Van, Truck.", "\n", "# Cap at 3.", "\n", "label", "=", "tf", ".", "math", ".", "minimum", "(", "tf", ".", "size", "(", "vehicles", ")", ",", "3", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_left_pp": [[47, 55], ["tensorflow.where", "tensorflow.math.minimum", "tensorflow.size"], "function", ["None"], ["", "def", "_count_left_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Count objects on the left hand side of the camera.\"\"\"", "\n", "# Count distribution (thresholded at 15):", "\n", "\n", "# Location feature contains (x, y, z) in meters w.r.t. the camera.", "\n", "objects_on_left", "=", "tf", ".", "where", "(", "x", "[", "\"objects\"", "]", "[", "\"location\"", "]", "[", ":", ",", "0", "]", "<", "0", ")", "\n", "label", "=", "tf", ".", "math", ".", "minimum", "(", "tf", ".", "size", "(", "objects_on_left", ")", ",", "8", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_far_pp": [[57, 66], ["tensorflow.where", "tensorflow.math.minimum", "tensorflow.size"], "function", ["None"], ["", "def", "_count_far_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Counts objects far from the camera.\"\"\"", "\n", "# Threshold removes ~half of the objects.", "\n", "# Count distribution (thresholded at 15):", "\n", "\n", "# Location feature contains (x, y, z) in meters w.r.t. the camera.", "\n", "distant_objects", "=", "tf", ".", "where", "(", "x", "[", "\"objects\"", "]", "[", "\"location\"", "]", "[", ":", ",", "2", "]", ">=", "25", ")", "\n", "label", "=", "tf", ".", "math", ".", "minimum", "(", "tf", ".", "size", "(", "distant_objects", ")", ",", "8", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._count_near_pp": [[68, 77], ["tensorflow.where", "tensorflow.math.minimum", "tensorflow.size"], "function", ["None"], ["", "def", "_count_near_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Counts objects close to the camera.\"\"\"", "\n", "# Threshold removes ~half of the objects.", "\n", "# Count distribution:", "\n", "\n", "# Location feature contains (x, y, z) in meters w.r.t. the camera.", "\n", "close_objects", "=", "tf", ".", "where", "(", "x", "[", "\"objects\"", "]", "[", "\"location\"", "]", "[", ":", ",", "2", "]", "<", "25", ")", "\n", "label", "=", "tf", ".", "math", ".", "minimum", "(", "tf", ".", "size", "(", "close_objects", ")", ",", "8", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_object_distance_pp": [[79, 88], ["tensorflow.reduce_min", "numpy.array", "tensorflow.reduce_max", "tensorflow.where"], "function", ["None"], ["", "def", "_closest_object_distance_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Predict the distance to the closest object.\"\"\"", "\n", "# Label distribution:", "\n", "\n", "# Location feature contains (x, y, z) in meters w.r.t. the camera.", "\n", "dist", "=", "tf", ".", "reduce_min", "(", "x", "[", "\"objects\"", "]", "[", "\"location\"", "]", "[", ":", ",", "2", "]", ")", "\n", "thrs", "=", "np", ".", "array", "(", "[", "-", "100", ",", "5.6", ",", "8.4", ",", "13.4", ",", "23.4", "]", ")", "\n", "label", "=", "tf", ".", "reduce_max", "(", "tf", ".", "where", "(", "(", "thrs", "-", "dist", ")", "<", "0", ")", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_vehicle_distance_pp": [[90, 104], ["tensorflow.where", "tensorflow.gather", "tensorflow.concat", "tensorflow.reduce_min", "numpy.array", "tensorflow.reduce_max", "tensorflow.where", "tensorflow.constant"], "function", ["None"], ["", "def", "_closest_vehicle_distance_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Predict the distance to the closest vehicle.\"\"\"", "\n", "# Label distribution:", "\n", "\n", "# Location feature contains (x, y, z) in meters w.r.t. the camera.", "\n", "vehicles", "=", "tf", ".", "where", "(", "x", "[", "\"objects\"", "]", "[", "\"type\"", "]", "<", "3", ")", "# Car, Van, Truck.", "\n", "vehicle_z", "=", "tf", ".", "gather", "(", "params", "=", "x", "[", "\"objects\"", "]", "[", "\"location\"", "]", "[", ":", ",", "2", "]", ",", "indices", "=", "vehicles", ")", "\n", "vehicle_z", "=", "tf", ".", "concat", "(", "[", "vehicle_z", ",", "tf", ".", "constant", "(", "[", "[", "1000.0", "]", "]", ")", "]", ",", "axis", "=", "0", ")", "\n", "dist", "=", "tf", ".", "reduce_min", "(", "vehicle_z", ")", "\n", "# Results in a uniform distribution over three distances, plus one class for", "\n", "# \"no vehicle\".", "\n", "thrs", "=", "np", ".", "array", "(", "[", "-", "100.0", ",", "8.0", ",", "20.0", ",", "999.0", "]", ")", "\n", "label", "=", "tf", ".", "reduce_max", "(", "tf", ".", "where", "(", "(", "thrs", "-", "dist", ")", "<", "0", ")", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.kitti._closest_object_x_location_pp": [[106, 116], ["tensorflow.math.argmin", "numpy.array", "tensorflow.reduce_max", "tensorflow.where"], "function", ["None"], ["", "def", "_closest_object_x_location_pp", "(", "x", ")", ":", "\n", "  ", "\"\"\"Predict the absolute x position of the closest object.\"\"\"", "\n", "# Label distribution:", "\n", "\n", "# Location feature contains (x, y, z) in meters w.r.t. the camera.", "\n", "idx", "=", "tf", ".", "math", ".", "argmin", "(", "x", "[", "\"objects\"", "]", "[", "\"location\"", "]", "[", ":", ",", "2", "]", ")", "\n", "xloc", "=", "x", "[", "\"objects\"", "]", "[", "\"location\"", "]", "[", "idx", ",", "0", "]", "\n", "thrs", "=", "np", ".", "array", "(", "[", "-", "100", ",", "-", "6.4", ",", "-", "3.5", ",", "0.0", ",", "3.3", ",", "23.9", "]", ")", "\n", "label", "=", "tf", ".", "reduce_max", "(", "tf", ".", "where", "(", "(", "thrs", "-", "xloc", ")", "<", "0", ")", ")", "\n", "return", "{", "\"image\"", ":", "x", "[", "\"image\"", "]", ",", "\"label\"", ":", "label", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.eurosat.EurosatData.__init__": [[41, 97], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.data.base.ImageTfdsData.__init__", "task_adaptation.data.base.make_get_and_cast_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["def", "__init__", "(", "self", ",", "subset", "=", "\"rgb\"", ",", "data_key", "=", "\"image\"", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "dataset_name", "=", "\"eurosat/{}:2.*.*\"", ".", "format", "(", "subset", ")", "\n", "dataset_builder", "=", "tfds", ".", "builder", "(", "dataset_name", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "num_examples", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TRAIN", "]", ".", "num_examples", "\n", "train_count", "=", "num_examples", "*", "TRAIN_SPLIT_PERCENT", "//", "100", "\n", "val_count", "=", "num_examples", "*", "VALIDATION_SPLIT_PERCENT", "//", "100", "\n", "test_count", "=", "num_examples", "*", "TEST_SPLIT_PERCENT", "//", "100", "\n", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\n", "\"train[:{}]\"", ".", "format", "(", "train_count", ")", ",", "\n", "\"val\"", ":", "\n", "\"train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "val_count", ")", ",", "\n", "\"trainval\"", ":", "\n", "\"train[:{}]\"", ".", "format", "(", "train_count", "+", "val_count", ")", ",", "\n", "\"test\"", ":", "\n", "\"train[{}:]\"", ".", "format", "(", "train_count", "+", "val_count", ")", ",", "\n", "\"train800\"", ":", "\n", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\n", "\"train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "\n", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "train_count", ",", "train_count", "+", "200", ")", ",", "\n", "}", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "num_channels", "=", "3", "\n", "if", "data_key", "==", "\"sentinel2\"", ":", "\n", "      ", "num_channels", "=", "13", "\n", "\n", "", "super", "(", "EurosatData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "100", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "{", "\n", "data_key", ":", "(", "\"image\"", ",", "None", ")", ",", "\n", "\"label\"", ":", "(", "\"label\"", ",", "None", ")", ",", "\n", "}", ")", ",", "\n", "image_key", "=", "data_key", ",", "\n", "num_channels", "=", "num_channels", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cifar_test.Cifar10Test.setUp": [[29, 45], ["super().setUp", "task_adaptation.data.cifar.CifarData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "Cifar10Test", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "cifar", ".", "CifarData", "(", "num_classes", "=", "10", ")", ",", "\n", "num_classes", "=", "10", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "45000", ",", "\n", "val", "=", "5000", ",", "\n", "trainval", "=", "50000", ",", "\n", "test", "=", "10000", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "32", ",", "32", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cifar_test.Cifar100Test.setUp": [[51, 67], ["super().setUp", "task_adaptation.data.cifar.CifarData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "Cifar100Test", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "cifar", ".", "CifarData", "(", "num_classes", "=", "100", ")", ",", "\n", "num_classes", "=", "100", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "45000", ",", "\n", "val", "=", "5000", ",", "\n", "trainval", "=", "50000", ",", "\n", "test", "=", "10000", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "32", ",", "32", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.cifar_test.CifarIncorrectTest.test_incorrect_classes": [[73, 77], ["cifar_test.CifarIncorrectTest.assertRaisesWithLiteralMatch", "task_adaptation.data.cifar.CifarData"], "methods", ["None"], ["def", "test_incorrect_classes", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "assertRaisesWithLiteralMatch", "(", "\n", "ValueError", ",", "\"Number of classes must be 10 or 100, got 99\"", ")", ":", "\n", "      ", "cifar", ".", "CifarData", "(", "num_classes", "=", "99", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.resisc45_test.Resisc45DataTest.setUp": [[29, 45], ["super().setUp", "task_adaptation.data.resisc45.Resisc45Data", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "Resisc45DataTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "resisc45", ".", "Resisc45Data", "(", ")", ",", "\n", "num_classes", "=", "45", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "18900", ",", "\n", "val", "=", "6300", ",", "\n", "trainval", "=", "25200", ",", "\n", "test", "=", "6300", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "256", ",", "256", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.patch_camelyon.PatchCamelyonData.__init__": [[30, 65], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"patch_camelyon:2.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"validation\"", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "# Creates a dict with example counts.", "\n", "num_samples_splits", "=", "{", "\n", "\"test\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", ",", "\n", "\"train\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", ",", "\n", "\"val\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"validation\"", "]", ".", "num_examples", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "num_samples_splits", "[", "\"trainval\"", "]", "=", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", "+", "num_samples_splits", "[", "\"val\"", "]", ")", "\n", "super", "(", "PatchCamelyonData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "[", "\"image\"", ",", "\"label\"", "]", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.food101.Food101Data.__init__": [[34, 64], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ",", "train_split_percent", "=", "None", ")", ":", "\n", "    ", "train_split_percent", "=", "train_split_percent", "or", "TRAIN_SPLIT_PERCENT", "\n", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"food101:2.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{}%]\"", ".", "format", "(", "train_split_percent", ")", ",", "\n", "\"val\"", ":", "\"train[{}:]\"", ".", "format", "(", "train_split_percent", ")", ",", "\n", "\"trainval\"", ":", "\"train\"", ",", "\n", "\"test\"", ":", "\"validation\"", ",", "\n", "}", "\n", "# Creates a dict with example counts for each split.", "\n", "num_train_examples_full", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "num_train_examples", "=", "(", "\n", "(", "num_train_examples_full", "*", "train_split_percent", ")", "//", "100", ")", "\n", "num_valid_examples", "=", "num_train_examples_full", "-", "num_train_examples", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "num_train_examples", ",", "\n", "\"val\"", ":", "num_valid_examples", ",", "\n", "\"trainval\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", ",", "\n", "\"test\"", ":", "dataset_builder", ".", "info", ".", "splits", "[", "\"validation\"", "]", ".", "num_examples", ",", "\n", "}", "\n", "\n", "super", "(", "Food101Data", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "100", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "image_key", "=", "\"image\"", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.food101_test.Food101Test.setUp": [[29, 42], ["super().setUp", "task_adaptation.data.food101.Food101Data", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "Food101Test", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "food101", ".", "Food101Data", "(", ")", ",", "\n", "num_classes", "=", "101", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "68175", ",", "\n", "val", "=", "7575", ",", "\n", "trainval", "=", "75750", ",", "\n", "test", "=", "25250", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "'image'", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "'label'", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.oxford_flowers102.OxfordFlowers102Data.__init__": [[35, 99], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.data.base.ImageTfdsData.__init__", "task_adaptation.data.base.make_get_and_cast_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ",", "train_split_percent", "=", "None", ")", ":", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"oxford_flowers102:2.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "train_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TRAIN", "]", ".", "num_examples", "\n", "val_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "VALIDATION", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TEST", "]", ".", "num_examples", "\n", "\n", "if", "train_split_percent", ":", "\n", "      ", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train[:{s}%]+validation[:{s}%]\"", ".", "format", "(", "\n", "s", "=", "train_split_percent", ")", ",", "\n", "\"val\"", ":", "\"train[-{s}%:]+validation[-{s}%:]\"", ".", "format", "(", "\n", "s", "=", "train_split_percent", ")", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "(", "(", "(", "train_count", "+", "val_count", ")", "//", "100", ")", "\n", "*", "train_split_percent", ")", ",", "\n", "\"val\"", ":", "(", "(", "(", "train_count", "+", "val_count", ")", "//", "100", ")", "*", "\n", "(", "100", "-", "train_split_percent", ")", ")", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "", "else", ":", "\n", "      ", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"validation\"", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "", "super", "(", "OxfordFlowers102Data", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Rename tensors but keep their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "{", "\n", "\"image\"", ":", "(", "\"image\"", ",", "None", ")", ",", "\n", "\"label\"", ":", "(", "\"label\"", ",", "None", ")", ",", "\n", "}", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", "\n", ".", "num_classes", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.__init__": [[42, 94], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.ImageTfdsData.__init__", "task_adaptation.make_get_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["def", "__init__", "(", "self", ",", "config", "=", "\"btgraham-300\"", ",", "heavy_train_augmentation", "=", "False", ",", "\n", "data_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"Initializer for Diabetic Retinopathy dataset.\n\n    Args:\n      config: Name of the TFDS config to use for this dataset.\n      heavy_train_augmentation: If True, use heavy data augmentation on the\n        training data. Recommended to achieve SOTA.\n      data_dir: directory for downloading and storing the data.\n    \"\"\"", "\n", "config_and_version", "=", "config", "+", "\":3.*.*\"", "\n", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"diabetic_retinopathy_detection/{}\"", ".", "format", "(", "\n", "config_and_version", ")", ",", "data_dir", "=", "data_dir", ")", "\n", "self", ".", "_config", "=", "config", "\n", "self", ".", "_heavy_train_augmentation", "=", "heavy_train_augmentation", "\n", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\"train\"", ",", "\n", "\"val\"", ":", "\"validation\"", ",", "\n", "\"trainval\"", ":", "\"train+validation\"", ",", "\n", "\"test\"", ":", "\"test\"", ",", "\n", "\"train800\"", ":", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\"validation[:200]\"", ",", "\n", "\"train800val200\"", ":", "\"train[:800]+validation[:200]\"", ",", "\n", "}", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "train_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"train\"", "]", ".", "num_examples", "\n", "val_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"validation\"", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "\"test\"", "]", ".", "num_examples", "\n", "num_samples_splits", "=", "{", "\n", "\"train\"", ":", "train_count", ",", "\n", "\"val\"", ":", "val_count", ",", "\n", "\"trainval\"", ":", "train_count", "+", "val_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "super", "(", "RetinopathyData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Export only image and label tensors with their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_tensors_fn", "(", "[", "\"image\"", ",", "\"label\"", "]", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.config": [[95, 98], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "config", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_config", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.heavy_train_augmentation": [[99, 102], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "heavy_train_augmentation", "(", "self", ")", ":", "\n", "    ", "return", "self", ".", "_heavy_train_augmentation", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.get_tf_data": [[103, 119], ["super().get_tf_data", "task_adaptation.compose_preprocess_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.get_tf_data", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.compose_preprocess_fn"], ["", "def", "get_tf_data", "(", "self", ",", "\n", "split_name", ",", "\n", "batch_size", ",", "\n", "preprocess_fn", "=", "None", ",", "\n", "for_eval", "=", "False", ",", "\n", "**", "kwargs", ")", ":", "\n", "    ", "if", "self", ".", "_heavy_train_augmentation", "and", "not", "for_eval", ":", "\n", "      ", "preprocess_fn", "=", "base", ".", "compose_preprocess_fn", "(", "\n", "self", ".", "_heavy_train_augmentation", ",", "preprocess_fn", ")", "\n", "\n", "", "return", "super", "(", "RetinopathyData", ",", "self", ")", ".", "get_tf_data", "(", "\n", "split_name", "=", "split_name", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "preprocess_fn", "=", "preprocess_fn", ",", "\n", "for_eval", "=", "for_eval", ",", "\n", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData._sample_heavy_data_augmentation_parameters": [[120, 134], ["tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.uniform", "tensorflow.random.shuffle", "tensorflow.random.shuffle"], "methods", ["None"], ["", "def", "_sample_heavy_data_augmentation_parameters", "(", "self", ")", ":", "\n", "# Scale image +/- 10%.", "\n", "    ", "s", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "(", ")", ",", "minval", "=", "-", "0.1", ",", "maxval", "=", "0.1", ")", "\n", "# Rotate image [0, 2pi).", "\n", "a", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "(", ")", ",", "minval", "=", "0.0", ",", "maxval", "=", "2.0", "*", "3.1415926535", ")", "\n", "# Vertically shear image +/- 20%.", "\n", "b", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "(", ")", ",", "minval", "=", "-", "0.2", ",", "maxval", "=", "0.2", ")", "+", "a", "\n", "# Horizontal and vertial flipping.", "\n", "hf", "=", "tf", ".", "random", ".", "shuffle", "(", "[", "-", "1.0", ",", "1.0", "]", ")", "[", "0", "]", "\n", "vf", "=", "tf", ".", "random", ".", "shuffle", "(", "[", "-", "1.0", ",", "1.0", "]", ")", "[", "0", "]", "\n", "# Relative x,y translation.", "\n", "dx", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "(", ")", ",", "minval", "=", "-", "0.1", ",", "maxval", "=", "0.1", ")", "\n", "dy", "=", "tf", ".", "random", ".", "uniform", "(", "shape", "=", "(", ")", ",", "minval", "=", "-", "0.1", ",", "maxval", "=", "0.1", ")", "\n", "return", "s", ",", "a", ",", "b", ",", "hf", ",", "vf", ",", "dx", ",", "dy", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData._heavy_data_augmentation_fn": [[135, 196], ["tensorflow.shape", "tensorflow.cast", "tensorflow.cast", "diabetic_retinopathy.RetinopathyData._sample_heavy_data_augmentation_parameters", "tensorflow.convert_to_tensor", "tensorflow_addons.transform_ops.matrices_to_flat_transforms", "tensorflow_addons.transform", "len", "ValueError", "tensorflow.cos", "tensorflow.sin", "tensorflow.sin", "tensorflow.cos", "tensorflow.linalg.inv", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast.get_shape().as_list", "len", "tensorflow.cast.get_shape", "tensorflow.cast.get_shape().as_list", "tensorflow.cast.get_shape"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData._sample_heavy_data_augmentation_parameters"], ["", "def", "_heavy_data_augmentation_fn", "(", "self", ",", "example", ")", ":", "\n", "    ", "\"\"\"Perform heavy augmentation on a given input data example.\n\n    This is the same data augmentation as the one done by Ben Graham, the winner\n    of the 2015 Kaggle competition. See:\n    https://github.com/btgraham/SparseConvNet/blob/a6bdb0c938b3556c1e6c23d5a014db9f404502b9/kaggleDiabetes1.cpp#L12\n\n    Args:\n      example: A dictionary containing an \"image\" key with the image to\n        augment.\n\n    Returns:\n      The input dictionary with the key \"image\" containing the augmented image.\n    \"\"\"", "\n", "image", "=", "example", "[", "\"image\"", "]", "\n", "image_shape", "=", "tf", ".", "shape", "(", "image", ")", "\n", "if", "len", "(", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", "not", "in", "[", "2", ",", "3", "]", ":", "\n", "      ", "raise", "ValueError", "(", "\n", "\"Input image must be a rank-2 or rank-3 tensor, but rank-{} \"", "\n", "\"was given\"", ".", "format", "(", "len", "(", "image", ".", "get_shape", "(", ")", ".", "as_list", "(", ")", ")", ")", ")", "\n", "", "height", "=", "tf", ".", "cast", "(", "image_shape", "[", "0", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "width", "=", "tf", ".", "cast", "(", "image_shape", "[", "1", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "# Sample data augmentation parameters.", "\n", "s", ",", "a", ",", "b", ",", "hf", ",", "vf", ",", "dx", ",", "dy", "=", "self", ".", "_sample_heavy_data_augmentation_parameters", "(", ")", "\n", "# Rotation + scale.", "\n", "c00", "=", "(", "1", "+", "s", ")", "*", "tf", ".", "cos", "(", "a", ")", "\n", "c01", "=", "(", "1", "+", "s", ")", "*", "tf", ".", "sin", "(", "a", ")", "\n", "c10", "=", "(", "s", "-", "1", ")", "*", "tf", ".", "sin", "(", "b", ")", "\n", "c11", "=", "(", "1", "-", "s", ")", "*", "tf", ".", "cos", "(", "b", ")", "\n", "# Horizontal and vertial flipping.", "\n", "c00", "=", "c00", "*", "hf", "\n", "c01", "=", "c01", "*", "hf", "\n", "c10", "=", "c10", "*", "vf", "\n", "c11", "=", "c11", "*", "vf", "\n", "# Convert x,y translation to absolute values.", "\n", "dx", "=", "width", "*", "dx", "\n", "dy", "=", "height", "*", "dy", "\n", "# Convert affine matrix to TF's transform. Matrix is applied w.r.t. the", "\n", "# center of the image.", "\n", "cy", "=", "height", "/", "2.0", "\n", "cx", "=", "width", "/", "2.0", "\n", "affine_matrix", "=", "[", "[", "c00", ",", "c01", ",", "(", "1.0", "-", "c00", ")", "*", "cx", "-", "c01", "*", "cy", "+", "dx", "]", ",", "\n", "[", "c10", ",", "c11", ",", "(", "1.0", "-", "c11", ")", "*", "cy", "-", "c10", "*", "cx", "+", "dy", "]", ",", "\n", "[", "0.0", ",", "0.0", ",", "1.0", "]", "]", "\n", "affine_matrix", "=", "tf", ".", "convert_to_tensor", "(", "affine_matrix", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "transform", "=", "tfa_image", ".", "transform_ops", ".", "matrices_to_flat_transforms", "(", "\n", "tf", ".", "linalg", ".", "inv", "(", "affine_matrix", ")", ")", "\n", "if", "self", ".", "_config", "in", "self", ".", "_CONFIGS_WITH_GREY_BACKGROUND", ":", "\n", "# Since background is grey in these configs, put in pixels in [-1, 1]", "\n", "# range to avoid artifacts from the affine transformation.", "\n", "      ", "image", "=", "tf", ".", "cast", "(", "image", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "image", "=", "(", "image", "/", "127.5", ")", "-", "1.0", "\n", "# Apply the affine transformation.", "\n", "", "image", "=", "tfa_image", ".", "transform", "(", "images", "=", "image", ",", "transforms", "=", "transform", ")", "\n", "if", "self", ".", "_config", "in", "self", ".", "_CONFIGS_WITH_GREY_BACKGROUND", ":", "\n", "# Put pixels back to [0, 255] range and cast to uint8, since this is what", "\n", "# our preprocessing pipeline usually expects.", "\n", "      ", "image", "=", "(", "1.0", "+", "image", ")", "*", "127.5", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "dtype", "=", "tf", ".", "uint8", ")", "\n", "", "example", "[", "\"image\"", "]", "=", "image", "\n", "return", "example", "\n", "", "", ""]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base_test.FakeImageData.__init__": [[31, 37], ["task_adaptation.data.base.ImageData.__init__"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "    ", "super", "(", "FakeImageData", ",", "self", ")", ".", "__init__", "(", "\n", "num_samples_splits", "=", "{", "'fake'", ":", "FakeImageData", ".", "EXAMPLE_NUM", "}", ",", "\n", "shuffle_buffer_size", "=", "1", ",", "# no shuffle", "\n", "num_preprocessing_threads", "=", "1", ",", "\n", "num_classes", "=", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base_test.FakeImageData._get_dataset_split": [[38, 44], ["tensorflow.data.Dataset.range().map", "tensorflow.data.Dataset.range"], "methods", ["None"], ["", "def", "_get_dataset_split", "(", "self", ",", "split_name", ",", "shuffle_files", "=", "False", ")", ":", "\n", "\n", "    ", "def", "fake_data", "(", "index", ")", ":", "\n", "      ", "return", "{", "'image'", ":", "index", ",", "'label'", ":", "index", "}", "\n", "\n", "", "return", "tf", ".", "data", ".", "Dataset", ".", "range", "(", "FakeImageData", ".", "EXAMPLE_NUM", ")", ".", "map", "(", "fake_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base_test.BaseTest.test_make_get_tensors_fn": [[48, 65], ["task_adaptation.data.base.make_get_tensors_fn", "base_test.BaseTest.assertTrue", "base_test.BaseTest.assertEqual", "task_adaptation.data.base.make_get_tensors_fn", "base_test.BaseTest.assertTrue", "task_adaptation.data.base.make_get_tensors_fn", "base_test.BaseTest.assertTrue", "base_test.BaseTest.assertEqual", "callable", "task_adaptation.data.base.make_get_tensors_fn.", "callable", "base_test.BaseTest.assertRaises", "task_adaptation.data.base.make_get_tensors_fn.", "callable", "task_adaptation.data.base.make_get_tensors_fn."], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_tensors_fn"], ["  ", "def", "test_make_get_tensors_fn", "(", "self", ")", ":", "\n", "    ", "input_dict", "=", "{", "'tens1'", ":", "1", ",", "'tens2'", ":", "2", ",", "'tens3'", ":", "3", "}", "\n", "# Normal case.", "\n", "fn", "=", "base", ".", "make_get_tensors_fn", "(", "output_tensors", "=", "[", "'tens1'", ",", "'tens2'", "]", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "self", ".", "assertEqual", "(", "fn", "(", "input_dict", ")", ",", "{", "'tens1'", ":", "1", ",", "'tens2'", ":", "2", "}", ")", "\n", "\n", "# One output tensor is not specified in the input dict.", "\n", "fn", "=", "base", ".", "make_get_tensors_fn", "(", "output_tensors", "=", "[", "'tens1'", ",", "'tens2'", ",", "'tens4'", "]", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "with", "self", ".", "assertRaises", "(", "KeyError", ")", ":", "\n", "      ", "fn", "(", "input_dict", ")", "\n", "\n", "# Empty output.", "\n", "", "fn", "=", "base", ".", "make_get_tensors_fn", "(", "output_tensors", "=", "(", ")", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "self", ".", "assertEqual", "(", "fn", "(", "input_dict", ")", ",", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base_test.BaseTest.test_make_get_and_cast_tensors_fn": [[66, 116], ["task_adaptation.data.base.make_get_and_cast_tensors_fn", "base_test.BaseTest.assertTrue", "base_test.BaseTest.assertEqual", "task_adaptation.data.base.make_get_and_cast_tensors_fn", "base_test.BaseTest.assertTrue", "task_adaptation.data.base.make_get_and_cast_tensors_fn.", "base_test.BaseTest.assertSetEqual", "base_test.BaseTest.assertEqual", "base_test.BaseTest.assertEqual", "task_adaptation.data.base.make_get_and_cast_tensors_fn", "base_test.BaseTest.assertTrue", "task_adaptation.data.base.make_get_and_cast_tensors_fn.", "base_test.BaseTest.assertSetEqual", "base_test.BaseTest.assertEqual", "base_test.BaseTest.assertEqual", "base_test.BaseTest.assertEqual", "task_adaptation.data.base.make_get_and_cast_tensors_fn", "base_test.BaseTest.assertTrue", "tensorflow.constant", "tensorflow.constant", "tensorflow.constant", "callable", "task_adaptation.data.base.make_get_and_cast_tensors_fn.", "callable", "set", "callable", "set", "callable", "base_test.BaseTest.assertRaises", "task_adaptation.data.base.make_get_and_cast_tensors_fn.", "base.make_get_and_cast_tensors_fn.keys", "base.make_get_and_cast_tensors_fn.keys"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["", "def", "test_make_get_and_cast_tensors_fn", "(", "self", ")", ":", "\n", "    ", "input_dict", "=", "{", "\n", "'t1'", ":", "tf", ".", "constant", "(", "value", "=", "0", ",", "dtype", "=", "tf", ".", "int32", ")", ",", "\n", "'t2'", ":", "tf", ".", "constant", "(", "value", "=", "-", "1.0", ",", "dtype", "=", "tf", ".", "float32", ")", ",", "\n", "'t3'", ":", "tf", ".", "constant", "(", "value", "=", "1.0", ",", "dtype", "=", "tf", ".", "float64", ")", ",", "\n", "}", "\n", "# Equivalent to get_tensors_fn.", "\n", "fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "output_tensors", "=", "{", "\n", "'t1'", ":", "None", ",", "\n", "'t2'", ":", "None", ",", "\n", "}", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "self", ".", "assertEqual", "(", "\n", "fn", "(", "input_dict", ")", ",", "{", "\n", "'t1'", ":", "input_dict", "[", "'t1'", "]", ",", "\n", "'t2'", ":", "input_dict", "[", "'t2'", "]", "\n", "}", ")", "\n", "\n", "# Cast to different type.", "\n", "fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "output_tensors", "=", "{", "\n", "'t1'", ":", "tf", ".", "float64", ",", "\n", "'t2'", ":", "tf", ".", "float64", ",", "\n", "}", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "output_dict", "=", "fn", "(", "input_dict", ")", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "output_dict", ".", "keys", "(", ")", ")", ",", "{", "'t1'", ",", "'t2'", "}", ")", "\n", "self", ".", "assertEqual", "(", "output_dict", "[", "'t1'", "]", ".", "dtype", ",", "tf", ".", "float64", ")", "\n", "self", ".", "assertEqual", "(", "output_dict", "[", "'t2'", "]", ".", "dtype", ",", "tf", ".", "float64", ")", "\n", "\n", "# General case.", "\n", "fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "output_tensors", "=", "{", "\n", "'t1'", ":", "(", "'t1_new_name'", ",", "tf", ".", "float64", ")", ",", "\n", "'t2'", ":", "tf", ".", "float64", ",", "\n", "'t3'", ":", "None", ",", "\n", "}", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "output_dict", "=", "fn", "(", "input_dict", ")", "\n", "self", ".", "assertSetEqual", "(", "set", "(", "output_dict", ".", "keys", "(", ")", ")", ",", "{", "'t1_new_name'", ",", "'t2'", ",", "'t3'", "}", ")", "\n", "self", ".", "assertEqual", "(", "output_dict", "[", "'t1_new_name'", "]", ".", "dtype", ",", "tf", ".", "float64", ")", "\n", "self", ".", "assertEqual", "(", "output_dict", "[", "'t2'", "]", ".", "dtype", ",", "tf", ".", "float64", ")", "\n", "self", ".", "assertEqual", "(", "output_dict", "[", "'t3'", "]", ".", "dtype", ",", "input_dict", "[", "'t3'", "]", ".", "dtype", ")", "\n", "\n", "# Output key does not exist.", "\n", "fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "output_tensors", "=", "{", "\n", "'t1'", ":", "None", ",", "\n", "'t25'", ":", "(", "'t2'", ",", "tf", ".", "float32", ")", ",", "\n", "}", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "with", "self", ".", "assertRaises", "(", "KeyError", ")", ":", "\n", "      ", "fn", "(", "input_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base_test.BaseTest.test_compose_preprocess_fn": [[117, 137], ["task_adaptation.data.base.compose_preprocess_fn", "base_test.BaseTest.assertTrue", "base_test.BaseTest.assertEqual", "task_adaptation.data.base.compose_preprocess_fn", "base_test.BaseTest.assertTrue", "base_test.BaseTest.assertEqual", "task_adaptation.data.base.compose_preprocess_fn", "base_test.BaseTest.assertTrue", "base_test.BaseTest.assertEqual", "task_adaptation.data.base.compose_preprocess_fn", "base_test.BaseTest.assertTrue", "base_test.BaseTest.assertEqual", "callable", "task_adaptation.data.base.compose_preprocess_fn.", "callable", "task_adaptation.data.base.compose_preprocess_fn.", "callable", "task_adaptation.data.base.compose_preprocess_fn.", "callable", "task_adaptation.data.base.compose_preprocess_fn."], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.compose_preprocess_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.compose_preprocess_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.compose_preprocess_fn", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.compose_preprocess_fn"], ["", "", "def", "test_compose_preprocess_fn", "(", "self", ")", ":", "\n", "# If no functions are given to compose, returns identity function.", "\n", "    ", "fn", "=", "base", ".", "compose_preprocess_fn", "(", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "self", ".", "assertEqual", "(", "fn", "(", "25", ")", ",", "25", ")", "\n", "\n", "# If a single function is given, compose simply returns it.", "\n", "fn", "=", "base", ".", "compose_preprocess_fn", "(", "lambda", "x", ":", "2", "*", "x", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "self", ".", "assertEqual", "(", "fn", "(", "25", ")", ",", "50", ")", "\n", "\n", "# None should be ignored, so this is like the identity function.", "\n", "fn", "=", "base", ".", "compose_preprocess_fn", "(", "None", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "self", ".", "assertEqual", "(", "fn", "(", "25", ")", ",", "25", ")", "\n", "\n", "# None should be ignored, result_fn(x) = 2 * x + 1", "\n", "fn", "=", "base", ".", "compose_preprocess_fn", "(", "lambda", "x", ":", "2", "*", "x", ",", "None", ",", "lambda", "x", ":", "x", "+", "1", ")", "\n", "self", ".", "assertTrue", "(", "callable", "(", "fn", ")", ")", "\n", "self", ".", "assertEqual", "(", "fn", "(", "25", ")", ",", "51", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base_test.BaseTest.test_pairwise_mix": [[138, 174], ["base_test.FakeImageData", "FakeImageData.get_tf_data", "base_test.BaseTest.session", "list", "base_test.BaseTest.assertAllEqual", "tensorflow.math.maximum", "task_adaptation.data.data_testing_lib.BaseDataTest.iterate_dataset", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray", "numpy.asarray"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.diabetic_retinopathy.RetinopathyData.get_tf_data", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.data_testing_lib.BaseDataTest.iterate_dataset"], ["", "def", "test_pairwise_mix", "(", "self", ")", ":", "\n", "\n", "    ", "def", "fake_pairwise_mix", "(", "data1", ",", "data2", ")", ":", "\n", "      ", "return", "{", "\n", "'image'", ":", "data1", "[", "'image'", "]", "+", "data2", "[", "'image'", "]", ",", "\n", "'label'", ":", "tf", ".", "math", ".", "maximum", "(", "data1", "[", "'label'", "]", ",", "data2", "[", "'label'", "]", ")", ",", "\n", "}", "\n", "\n", "", "data", "=", "FakeImageData", "(", ")", "\n", "dataset", "=", "data", ".", "get_tf_data", "(", "\n", "split_name", "=", "'fake'", ",", "\n", "batch_size", "=", "1", ",", "\n", "pairwise_mix_fn", "=", "fake_pairwise_mix", ",", "\n", "epochs", "=", "1", ")", "\n", "\n", "with", "self", ".", "session", "(", ")", "as", "sess", ":", "\n", "      ", "actual", "=", "list", "(", "\n", "data_testing_lib", ".", "BaseDataTest", ".", "iterate_dataset", "(", "dataset", ",", "sess", ")", ")", "\n", "self", ".", "assertAllEqual", "(", "[", "\n", "{", "\n", "'image'", ":", "np", ".", "asarray", "(", "[", "1", "]", ")", ",", "\n", "'label'", ":", "np", ".", "asarray", "(", "[", "1", "]", ")", "\n", "}", ",", "\n", "{", "\n", "'image'", ":", "np", ".", "asarray", "(", "[", "3", "]", ")", ",", "\n", "'label'", ":", "np", ".", "asarray", "(", "[", "2", "]", ")", "\n", "}", ",", "\n", "{", "\n", "'image'", ":", "np", ".", "asarray", "(", "[", "5", "]", ")", ",", "\n", "'label'", ":", "np", ".", "asarray", "(", "[", "3", "]", ")", "\n", "}", ",", "\n", "{", "\n", "'image'", ":", "np", ".", "asarray", "(", "[", "7", "]", ")", ",", "\n", "'label'", ":", "np", ".", "asarray", "(", "[", "4", "]", ")", "\n", "}", ",", "\n", "]", ",", "actual", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.clevr_test.CLEVRDataCountAllTest.setUp": [[29, 47], ["super().setUp", "task_adaptation.data.clevr.CLEVRData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "CLEVRDataCountAllTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "clevr", ".", "CLEVRData", "(", "task", "=", "\"count_all\"", ")", ",", "\n", "num_classes", "=", "8", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "63000", ",", "\n", "val", "=", "7000", ",", "\n", "trainval", "=", "70000", ",", "\n", "test", "=", "15000", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.clevr_test.CLEVRDataCountCylindersTest.setUp": [[52, 70], ["super().setUp", "task_adaptation.data.clevr.CLEVRData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "CLEVRDataCountCylindersTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "clevr", ".", "CLEVRData", "(", "task", "=", "\"count_cylinders\"", ")", ",", "\n", "num_classes", "=", "11", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "63000", ",", "\n", "val", "=", "7000", ",", "\n", "trainval", "=", "70000", ",", "\n", "test", "=", "15000", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.clevr_test.CLEVRDataClosestTest.setUp": [[75, 93], ["super().setUp", "task_adaptation.data.clevr.CLEVRData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "CLEVRDataClosestTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "clevr", ".", "CLEVRData", "(", "task", "=", "\"closest_object_distance\"", ")", ",", "\n", "num_classes", "=", "6", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "63000", ",", "\n", "val", "=", "7000", ",", "\n", "trainval", "=", "70000", ",", "\n", "test", "=", "15000", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "{", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.oxford_iiit_pet_test.OxfordIIITPetDataTest.setUp": [[29, 45], ["super().setUp", "task_adaptation.data.oxford_iiit_pet.OxfordIIITPetData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "OxfordIIITPetDataTest", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "oxford_iiit_pet", ".", "OxfordIIITPetData", "(", ")", ",", "\n", "num_classes", "=", "37", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "2944", ",", "\n", "val", "=", "736", ",", "\n", "trainval", "=", "3680", ",", "\n", "test", "=", "3669", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.smallnorb_test.SmallNORBTestDefault.setUp": [[31, 49], ["super().setUp", "task_adaptation.data.smallnorb.SmallNORBData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "SmallNORBTestDefault", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "smallnorb", ".", "SmallNORBData", "(", "\"label_category\"", ")", ",", "\n", "num_classes", "=", "5", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "24300", ",", "\n", "val", "=", "12150", ",", "\n", "trainval", "=", "36450", ",", "\n", "test", "=", "12150", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "96", ",", "96", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_category\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.smallnorb_test.SmallNORBTestElevation.setUp": [[54, 72], ["super().setUp", "task_adaptation.data.smallnorb.SmallNORBData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "SmallNORBTestElevation", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "smallnorb", ".", "SmallNORBData", "(", "\"label_elevation\"", ")", ",", "\n", "num_classes", "=", "9", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "24300", ",", "\n", "val", "=", "12150", ",", "\n", "trainval", "=", "36450", ",", "\n", "test", "=", "12150", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "96", ",", "96", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_elevation\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.smallnorb_test.SmallNORBTestAzimuth.setUp": [[77, 95], ["super().setUp", "task_adaptation.data.smallnorb.SmallNORBData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "SmallNORBTestAzimuth", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "smallnorb", ".", "SmallNORBData", "(", "\"label_azimuth\"", ")", ",", "\n", "num_classes", "=", "18", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "24300", ",", "\n", "val", "=", "12150", ",", "\n", "trainval", "=", "36450", ",", "\n", "test", "=", "12150", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "96", ",", "96", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_azimuth\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.smallnorb_test.SmallNORBTestLighting.setUp": [[100, 118], ["super().setUp", "task_adaptation.data.smallnorb.SmallNORBData", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "SmallNORBTestLighting", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "smallnorb", ".", "SmallNORBData", "(", "\"label_lighting\"", ")", ",", "\n", "num_classes", "=", "6", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "24300", ",", "\n", "val", "=", "12150", ",", "\n", "trainval", "=", "36450", ",", "\n", "test", "=", "12150", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "96", ",", "96", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ",", "\n", "tfds_label_key_map", "=", "\"label_lighting\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.smallnorb_test.SmallNORBIncorrectTest.test_incorrect_classes": [[123, 127], ["smallnorb_test.SmallNORBIncorrectTest.assertRaisesWithLiteralMatch", "task_adaptation.data.smallnorb.SmallNORBData"], "methods", ["None"], ["def", "test_incorrect_classes", "(", "self", ")", ":", "\n", "    ", "with", "self", ".", "assertRaisesWithLiteralMatch", "(", "\n", "ValueError", ",", "\"invalid_attribute is not a valid attribute to predict.\"", ")", ":", "\n", "      ", "smallnorb", ".", "SmallNORBData", "(", "\"invalid_attribute\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp": [[29, 45], ["super().setUp", "task_adaptation.data.sun397.Sun397Data", "dict"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.sun397_test.Sun397Test.setUp"], ["def", "setUp", "(", "self", ")", ":", "\n", "    ", "super", "(", "Sun397Test", ",", "self", ")", ".", "setUp", "(", "\n", "data_wrapper", "=", "sun397", ".", "Sun397Data", "(", "config", "=", "\"tfds\"", ")", ",", "\n", "num_classes", "=", "397", ",", "\n", "expected_num_samples", "=", "dict", "(", "\n", "train", "=", "76128", ",", "\n", "val", "=", "10875", ",", "\n", "trainval", "=", "10875", "+", "76128", ",", "\n", "test", "=", "21750", ",", "\n", "train800val200", "=", "1000", ",", "\n", "train800", "=", "800", ",", "\n", "val200", "=", "200", ",", "\n", ")", ",", "\n", "required_tensors_shapes", "=", "{", "\n", "\"image\"", ":", "(", "None", ",", "None", ",", "3", ")", ",", "\n", "\"label\"", ":", "(", ")", ",", "\n", "}", ")", "\n"]], "home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__": [[47, 102], ["tensorflow_datasets.builder", "tensorflow_datasets.builder.download_and_prepare", "task_adaptation.data.base.ImageTfdsData.__init__", "task_adaptation.data.base.make_get_and_cast_tensors_fn"], "methods", ["home.repos.pwc.inspect_result.google-research_task_adaptation.data.svhn.SvhnData.__init__", "home.repos.pwc.inspect_result.google-research_task_adaptation.data.base.make_get_and_cast_tensors_fn"], ["def", "__init__", "(", "self", ",", "data_dir", "=", "None", ")", ":", "\n", "    ", "dataset_builder", "=", "tfds", ".", "builder", "(", "\"svhn_cropped:3.*.*\"", ",", "data_dir", "=", "data_dir", ")", "\n", "dataset_builder", ".", "download_and_prepare", "(", ")", "\n", "\n", "# Example counts are retrieved from the tensorflow dataset info.", "\n", "trainval_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TRAIN", "]", ".", "num_examples", "\n", "test_count", "=", "dataset_builder", ".", "info", ".", "splits", "[", "tfds", ".", "Split", ".", "TEST", "]", ".", "num_examples", "\n", "\n", "# Creates a dict with example counts for each split.", "\n", "num_samples_splits", "=", "{", "\n", "# Calculates the train/val split example count based on percent.", "\n", "\"train\"", ":", "TRAIN_SPLIT_PERCENT", "*", "trainval_count", "//", "100", ",", "\n", "\"val\"", ":", "trainval_count", "-", "TRAIN_SPLIT_PERCENT", "*", "trainval_count", "//", "100", ",", "\n", "\"trainval\"", ":", "trainval_count", ",", "\n", "\"test\"", ":", "test_count", ",", "\n", "\"train800\"", ":", "800", ",", "\n", "\"val200\"", ":", "200", ",", "\n", "\"train800val200\"", ":", "1000", ",", "\n", "}", "\n", "\n", "# Defines dataset specific train/val/trainval/test splits.", "\n", "# The validation set is split out of the original training set, and the", "\n", "# remaining examples are used as the \"train\" split. The \"trainval\" split", "\n", "# corresponds to the original training set.", "\n", "tfds_splits", "=", "{", "\n", "\"train\"", ":", "\n", "\"train[:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"val\"", ":", "\n", "\"train[{}:]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ")", ",", "\n", "\"trainval\"", ":", "\n", "\"train\"", ",", "\n", "\"test\"", ":", "\n", "\"test\"", ",", "\n", "\"train800\"", ":", "\n", "\"train[:800]\"", ",", "\n", "\"val200\"", ":", "\n", "\"train[{}:{}]\"", ".", "format", "(", "num_samples_splits", "[", "\"train\"", "]", ",", "\n", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "\"train800val200\"", ":", "\n", "\"train[:800]+train[{}:{}]\"", ".", "format", "(", "\n", "num_samples_splits", "[", "\"train\"", "]", ",", "num_samples_splits", "[", "\"train\"", "]", "+", "200", ")", ",", "\n", "}", "\n", "\n", "super", "(", "SvhnData", ",", "self", ")", ".", "__init__", "(", "\n", "dataset_builder", "=", "dataset_builder", ",", "\n", "tfds_splits", "=", "tfds_splits", ",", "\n", "num_samples_splits", "=", "num_samples_splits", ",", "\n", "num_preprocessing_threads", "=", "400", ",", "\n", "shuffle_buffer_size", "=", "10000", ",", "\n", "# Note: Rename tensors but keep their original types.", "\n", "base_preprocess_fn", "=", "base", ".", "make_get_and_cast_tensors_fn", "(", "{", "\n", "\"image\"", ":", "(", "\"image\"", ",", "None", ")", ",", "\n", "\"label\"", ":", "(", "\"label\"", ",", "None", ")", ",", "\n", "}", ")", ",", "\n", "num_classes", "=", "dataset_builder", ".", "info", ".", "features", "[", "\"label\"", "]", "\n", ".", "num_classes", ")", "\n"]]}