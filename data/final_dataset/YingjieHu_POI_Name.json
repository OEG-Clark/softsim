{"home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.distribution_divergence.softmax": [[8, 26], ["len", "numpy.exp", "numpy.sum", "numpy.exp", "numpy.sum", "numpy.max", "numpy.max"], "function", ["None"], ["def", "softmax", "(", "x", ")", ":", "\n", "    ", "orig_shape", "=", "x", ".", "shape", "\n", "\n", "if", "len", "(", "x", ".", "shape", ")", ">", "1", ":", "\n", "# Matrix", "\n", "### YOUR CODE HERE", "\n", "        ", "x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ",", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "x", "/=", "np", ".", "sum", "(", "x", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "### END YOUR CODE", "\n", "", "else", ":", "\n", "# Vector", "\n", "### YOUR CODE HERE", "\n", "        ", "x", "=", "np", ".", "exp", "(", "x", "-", "np", ".", "max", "(", "x", ")", ")", "\n", "x", "/=", "np", ".", "sum", "(", "x", ")", "\n", "### END YOUR CODE", "\n", "\n", "", "assert", "x", ".", "shape", "==", "orig_shape", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.distribution_divergence.normalize": [[28, 46], ["len", "numpy.sum", "numpy.sum"], "function", ["None"], ["", "def", "normalize", "(", "x", ")", ":", "\n", "    ", "orig_shape", "=", "x", ".", "shape", "\n", "\n", "if", "len", "(", "x", ".", "shape", ")", ">", "1", ":", "\n", "# Matrix", "\n", "### YOUR CODE HERE", "\n", "#x = np.exp(x - np.max(x, 1, keepdims= True))", "\n", "        ", "x", "/=", "np", ".", "sum", "(", "x", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "### END YOUR CODE", "\n", "", "else", ":", "\n", "# Vector", "\n", "### YOUR CODE HERE", "\n", "#x = np.exp(x - np.max(x))", "\n", "        ", "x", "/=", "np", ".", "sum", "(", "x", ")", "\n", "### END YOUR CODE", "\n", "\n", "", "assert", "x", ".", "shape", "==", "orig_shape", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.distribution_divergence.JSD": [[51, 56], ["numpy.linalg.norm", "numpy.linalg.norm", "scipy.stats.entropy", "scipy.stats.entropy"], "function", ["None"], ["def", "JSD", "(", "P", ",", "Q", ")", ":", "\n", "    ", "_P", "=", "P", "/", "norm", "(", "P", ",", "ord", "=", "1", ")", "\n", "_Q", "=", "Q", "/", "norm", "(", "Q", ",", "ord", "=", "1", ")", "\n", "_M", "=", "0.5", "*", "(", "_P", "+", "_Q", ")", "\n", "return", "0.5", "*", "(", "entropy", "(", "_P", ",", "_M", ")", "+", "entropy", "(", "_Q", ",", "_M", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.distribution_divergence.calculate_divergence": [[58, 90], ["numpy.empty", "distribution_divergence.normalize", "range", "print", "open", "range", "line.split", "distribution_divergence.JSD", "range", "metro_list.append", "range", "category_list.append", "splitted[].strip"], "function", ["home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.distribution_divergence.normalize", "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.distribution_divergence.JSD"], ["", "def", "calculate_divergence", "(", ")", ":", "\n", "\n", "    ", "data", "=", "np", ".", "empty", "(", "[", "7", ",", "10", "]", ")", "\n", "\n", "category_list", "=", "[", "]", "\n", "metro_list", "=", "[", "]", "\n", "\n", "i", "=", "-", "1", "\n", "with", "open", "(", "'../word_metro_cate_usage_refined.csv'", ",", "'r'", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "splitted", "=", "line", ".", "split", "(", "','", ")", "\n", "if", "i", "==", "-", "1", ":", "\n", "                ", "for", "j", "in", "range", "(", "1", ",", "11", ")", ":", "\n", "                    ", "category_list", ".", "append", "(", "splitted", "[", "j", "]", ".", "strip", "(", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "metro_list", ".", "append", "(", "splitted", "[", "0", "]", ")", "\n", "#print(splitted[0])", "\n", "for", "j", "in", "range", "(", "1", ",", "11", ")", ":", "\n", "                    ", "data", "[", "i", ",", "j", "-", "1", "]", "=", "splitted", "[", "j", "]", "\n", "\n", "", "", "i", "+=", "1", "\n", "\n", "#data = softmax(data)   ", "\n", "", "", "data", "=", "normalize", "(", "data", ")", "\n", "\n", "\n", "sum", "=", "0.0", "\n", "for", "i", "in", "range", "(", "6", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", "+", "1", ",", "7", ")", ":", "\n", "            ", "sum", "+=", "JSD", "(", "data", "[", "i", "]", ",", "data", "[", "j", "]", ")", "\n", "\n", "", "", "print", "(", "sum", "/", "21.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.geocoder.geocoding_cities": [[6, 27], ["geopy.geocoders.GeoNames", "codecs.open", "codecs.open.close", "codecs.open", "line.strip", "line.strip.split", "geopy.geocoders.GeoNames.geocode", "splitted[].upper", "print", "codecs.open.write", "print", "codecs.open.write", "splitted[].title", "str", "str", "str", "str"], "function", ["None"], ["def", "geocoding_cities", "(", ")", ":", "\n", "    ", "geolocator", "=", "GeoNames", "(", "username", "=", "'demo'", ")", "\n", "# output file", "\n", "fw", "=", "codecs", ".", "open", "(", "'../city_coords_AllCategories.csv'", ",", "'w'", ",", "'utf-8'", ")", "\n", "#read from the city list", "\n", "with", "codecs", ".", "open", "(", "'../city_poi_by_type/AllCategory/city_list.csv'", ",", "'r'", ",", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "this_city_name", "=", "line", ".", "strip", "(", ")", "\n", "splitted", "=", "this_city_name", ".", "split", "(", "\",\"", ")", "\n", "this_city_name_new", "=", "splitted", "[", "0", "]", ".", "title", "(", ")", "+", "\", \"", "+", "splitted", "[", "1", "]", ".", "upper", "(", ")", "\n", "location", "=", "geolocator", ".", "geocode", "(", "this_city_name_new", ")", "\n", "if", "location", "!=", "None", ":", "\n", "#print(location.raw)", "\n", "#location = json.dumps(location.raw, encoding='utf-8')", "\n", "                ", "print", "(", "this_city_name", "+", "\": \"", "+", "str", "(", "location", ".", "latitude", ")", "+", "\", \"", "+", "str", "(", "location", ".", "longitude", ")", ")", "\n", "fw", ".", "write", "(", "this_city_name", "+", "\"|\"", "+", "str", "(", "location", ".", "latitude", ")", "+", "\"|\"", "+", "str", "(", "location", ".", "longitude", ")", "+", "\"\\n\"", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "this_city_name", "+", "' not geocoded'", ")", "\n", "fw", ".", "write", "(", "this_city_name", "+", "\"||\\n\"", ")", "\n", "\n", "", "", "", "fw", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.metro_local_word.grey_color_func": [[11, 13], ["None"], "function", ["None"], ["def", "grey_color_func", "(", "word", ",", "font_size", ",", "position", ",", "orientation", ",", "random_state", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "    ", "return", "\"rgb(0, 0, 128)\"", "#% random.randint(60, 100)", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.metro_local_word.visualize_local_words_by_metro": [[16, 123], ["textmining.TermDocumentMatrix", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "os.listdir", "list", "dict", "range", "textmining.TermDocumentMatrix.rows", "scipy.sign", "numpy.array", "numpy.sum", "numpy.log", "numpy.array", "dict", "range", "codecs.open", "fname.replace", "city_name.replace.replace", "codecs.open.close", "textmining.TermDocumentMatrix.add_doc", "list.append", "len", "dict", "numpy.flip", "dict", "wordcloud.WordCloud().generate_from_frequencies", "matplotlib.figure", "matplotlib.imshow", "matplotlib.axis", "matplotlib.show", "os.path.join", "city_name.replace.split", "line.strip.replace", "line.strip.strip", "metro_poi_dict[].has_key", "metro_dict[].strip().replace", "matrix_rows.append", "sorted", "numpy.log2", "WordCloud().generate_from_frequencies.recolor", "list", "range", "str", "wordcloud.WordCloud", "metro_dict[].strip", "len"], "function", ["None"], ["", "def", "visualize_local_words_by_metro", "(", "poi_data_dir", ")", ":", "\n", "    ", "tdm", "=", "textmining", ".", "TermDocumentMatrix", "(", ")", "# this is from the text mining package", "\n", "\n", "# a dict used to store the POI names in a metro", "\n", "metro_dict", "=", "dict", "(", ")", "\n", "metro_dict", "[", "'az'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'il'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'nc'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'nv'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'oh'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'pa'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'wi'", "]", "=", "\"\"", "\n", "\n", "# a dict used to filter out repeating POI names", "\n", "metro_poi_dict", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'az'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'il'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'nc'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'nv'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'oh'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'pa'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'wi'", "]", "=", "dict", "(", ")", "\n", "\n", "\n", "for", "fname", "in", "os", ".", "listdir", "(", "poi_data_dir", ")", ":", "\n", "        ", "if", "fname", "==", "'city_list.csv'", ":", "\n", "            ", "continue", "\n", "\n", "", "fr", "=", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "poi_data_dir", ",", "fname", ")", ",", "'r'", ",", "'utf-8'", ")", "\n", "\n", "city_name", "=", "fname", ".", "replace", "(", "'.txt'", ",", "''", ")", "\n", "city_name", "=", "city_name", ".", "replace", "(", "' '", ",", "'|'", ")", "\n", "#print(city_name)", "\n", "metro_name", "=", "city_name", ".", "split", "(", "','", ")", "[", "1", "]", "\n", "if", "metro_name", "==", "'sc'", ":", "# There is one city in SC, but it is very close to NC", "\n", "            ", "metro_name", "=", "'nc'", "\n", "\n", "#POI_doc = \"\"", "\n", "\n", "", "for", "line", "in", "fr", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "city_name", ",", "''", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "metro_poi_dict", "[", "metro_name", "]", ".", "has_key", "(", "line", ")", ":", "\n", "#print(line)", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "metro_dict", "[", "metro_name", "]", "+=", "\" \"", "+", "line", "\n", "metro_poi_dict", "[", "metro_name", "]", "[", "line", "]", "=", "0", "\n", "#POI_doc += \" \" + line", "\n", "\n", "", "", "fr", ".", "close", "(", ")", "\n", "#POI_doc = POI_doc.strip()", "\n", "\n", "", "metro_name_list", "=", "list", "(", ")", "\n", "\n", "for", "metro", "in", "metro_dict", ":", "\n", "        ", "tdm", ".", "add_doc", "(", "metro_dict", "[", "metro", "]", ".", "strip", "(", ")", ".", "replace", "(", "u'\\ufeff'", ",", "''", ")", ")", "\n", "metro_name_list", ".", "append", "(", "metro", ")", "\n", "\n", "", "vocab_list", "=", "[", "]", "# a list for storing the vocabulary", "\n", "matrix_rows", "=", "[", "]", "# matrix for storing the count values", "\n", "is_first", "=", "True", "\n", "\n", "metro_vector_dict", "=", "dict", "(", ")", "# this is a dictionary; given a city name, we can know it index in the matrix ", "\n", "for", "i", "in", "range", "(", "len", "(", "metro_name_list", ")", ")", ":", "\n", "        ", "metro_vector_dict", "[", "metro_name_list", "[", "i", "]", "]", "=", "i", "\n", "\n", "# put the vocabulary and count values into variables", "\n", "", "for", "row", "in", "tdm", ".", "rows", "(", "cutoff", "=", "1", ")", ":", "\n", "        ", "if", "is_first", ":", "\n", "            ", "vocab_list", "=", "row", "\n", "is_first", "=", "False", "\n", "", "else", ":", "\n", "            ", "matrix_rows", ".", "append", "(", "list", "(", "row", ")", ")", "\n", "\n", "# calculate tf-idf", "\n", "", "", "binary_matrix", "=", "scipy", ".", "sign", "(", "matrix_rows", ")", "\n", "np_array", "=", "np", ".", "array", "(", "binary_matrix", ")", "\n", "term_count_vect", "=", "np", ".", "sum", "(", "np_array", ",", "0", ")", "# sum the binary matrix along columns", "\n", "term_percentage_vect", "=", "np", ".", "log", "(", "(", "7.0", "/", "term_count_vect", ")", ")", "\n", "\n", "np_matrix_row", "=", "np", ".", "array", "(", "matrix_rows", ")", "\n", "tfidf", "=", "np_matrix_row", "*", "term_percentage_vect", "#np.log(np_matrix_row) *", "\n", "\n", "metro_local_dict", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "7", ")", ":", "\n", "        ", "metro_local_dict", "[", "metro_name_list", "[", "i", "]", "]", "=", "dict", "(", ")", "\n", "\n", "a", "=", "tfidf", "[", "i", "]", "\n", "top_index", "=", "sorted", "(", "range", "(", "len", "(", "a", ")", ")", ",", "key", "=", "lambda", "i", ":", "a", "[", "i", "]", ")", "[", "-", "100", ":", "]", "\n", "top_index", "=", "np", ".", "flip", "(", "top_index", ",", "0", ")", "\n", "\n", "top_words", "=", "''", "\n", "word_frequencies", "=", "dict", "(", ")", "\n", "for", "index", "in", "top_index", ":", "\n", "            ", "top_words", "+=", "' '", "+", "vocab_list", "[", "index", "]", "+", "\":\"", "+", "str", "(", "a", "[", "index", "]", ")", "\n", "word_frequencies", "[", "vocab_list", "[", "index", "]", "]", "=", "np", ".", "log2", "(", "a", "[", "index", "]", ")", "\n", "metro_local_dict", "[", "metro_name_list", "[", "i", "]", "]", "[", "vocab_list", "[", "index", "]", "]", "=", "0", "\n", "\n", "#print(metro_name_list[i]+\": \"+top_words.strip())", "\n", "\n", "", "wordcloud", "=", "WordCloud", "(", "width", "=", "350", ",", "height", "=", "300", ",", "margin", "=", "8", ",", "prefer_horizontal", "=", "1", ",", "background_color", "=", "'white'", ",", "max_font_size", "=", "50", ")", ".", "generate_from_frequencies", "(", "word_frequencies", ",", "max_font_size", "=", "None", ")", "\n", "\n", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "imshow", "(", "wordcloud", ".", "recolor", "(", "color_func", "=", "grey_color_func", ")", ",", "interpolation", "=", "'bilinear'", ")", "\n", "plt", ".", "axis", "(", "\"off\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.metro_local_word.find_local_words_by_metro": [[129, 233], ["textmining.TermDocumentMatrix", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "dict", "os.listdir", "list", "dict", "range", "textmining.TermDocumentMatrix.rows", "scipy.sign", "numpy.array", "numpy.sum", "numpy.log", "numpy.array", "dict", "range", "codecs.open", "fname.replace", "city_name.replace.replace", "codecs.open.close", "textmining.TermDocumentMatrix.add_doc", "list.append", "len", "dict", "numpy.flip", "dict", "os.path.join", "city_name.replace.split", "line.strip.replace", "line.strip.strip", "metro_poi_dict[].has_key", "metro_dict[].strip().replace", "matrix_rows.append", "sorted", "numpy.log2", "list", "range", "str", "metro_dict[].strip", "len"], "function", ["None"], ["", "", "def", "find_local_words_by_metro", "(", "poi_data_dir", ")", ":", "\n", "    ", "tdm", "=", "textmining", ".", "TermDocumentMatrix", "(", ")", "# this is from the text mining package", "\n", "\n", "# a dict used to store the POI names in a metro", "\n", "metro_dict", "=", "dict", "(", ")", "\n", "metro_dict", "[", "'az'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'il'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'nc'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'nv'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'oh'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'pa'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'wi'", "]", "=", "\"\"", "\n", "\n", "# a dict used to filter out repeating POI names", "\n", "metro_poi_dict", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'az'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'il'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'nc'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'nv'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'oh'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'pa'", "]", "=", "dict", "(", ")", "\n", "metro_poi_dict", "[", "'wi'", "]", "=", "dict", "(", ")", "\n", "\n", "\n", "for", "fname", "in", "os", ".", "listdir", "(", "poi_data_dir", ")", ":", "\n", "        ", "if", "fname", "==", "'city_list.csv'", ":", "\n", "            ", "continue", "\n", "\n", "", "fr", "=", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "poi_data_dir", ",", "fname", ")", ",", "'r'", ",", "'utf-8'", ")", "\n", "\n", "city_name", "=", "fname", ".", "replace", "(", "'.txt'", ",", "''", ")", "\n", "city_name", "=", "city_name", ".", "replace", "(", "' '", ",", "'|'", ")", "\n", "#print(city_name)", "\n", "metro_name", "=", "city_name", ".", "split", "(", "','", ")", "[", "1", "]", "\n", "if", "metro_name", "==", "'sc'", ":", "\n", "            ", "metro_name", "=", "'nc'", "\n", "\n", "#POI_doc = \"\"", "\n", "\n", "", "for", "line", "in", "fr", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "city_name", ",", "''", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "if", "metro_poi_dict", "[", "metro_name", "]", ".", "has_key", "(", "line", ")", ":", "\n", "#print(line)", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "metro_dict", "[", "metro_name", "]", "+=", "\" \"", "+", "line", "\n", "metro_poi_dict", "[", "metro_name", "]", "[", "line", "]", "=", "0", "\n", "#POI_doc += \" \" + line", "\n", "\n", "", "", "fr", ".", "close", "(", ")", "\n", "#POI_doc = POI_doc.strip()", "\n", "\n", "", "metro_name_list", "=", "list", "(", ")", "\n", "\n", "for", "metro", "in", "metro_dict", ":", "\n", "        ", "tdm", ".", "add_doc", "(", "metro_dict", "[", "metro", "]", ".", "strip", "(", ")", ".", "replace", "(", "u'\\ufeff'", ",", "''", ")", ")", "\n", "metro_name_list", ".", "append", "(", "metro", ")", "\n", "\n", "", "vocab_list", "=", "[", "]", "# a list for storing the vocabulary", "\n", "matrix_rows", "=", "[", "]", "# matrix for storing the count values", "\n", "is_first", "=", "True", "\n", "\n", "metro_vector_dict", "=", "dict", "(", ")", "# this is a dictionary; given a city name, we can know it index in the matrix ", "\n", "for", "i", "in", "range", "(", "len", "(", "metro_name_list", ")", ")", ":", "\n", "        ", "metro_vector_dict", "[", "metro_name_list", "[", "i", "]", "]", "=", "i", "\n", "\n", "\n", "# put the vocabulary and count values into variables", "\n", "", "for", "row", "in", "tdm", ".", "rows", "(", "cutoff", "=", "1", ")", ":", "\n", "        ", "if", "is_first", ":", "\n", "            ", "vocab_list", "=", "row", "\n", "is_first", "=", "False", "\n", "", "else", ":", "\n", "            ", "matrix_rows", ".", "append", "(", "list", "(", "row", ")", ")", "\n", "\n", "\n", "# calculate tf-idf", "\n", "", "", "binary_matrix", "=", "scipy", ".", "sign", "(", "matrix_rows", ")", "\n", "np_array", "=", "np", ".", "array", "(", "binary_matrix", ")", "\n", "term_count_vect", "=", "np", ".", "sum", "(", "np_array", ",", "0", ")", "# sum the binary matrix along columns", "\n", "term_percentage_vect", "=", "np", ".", "log", "(", "(", "7.0", "/", "term_count_vect", ")", ")", "\n", "\n", "np_matrix_row", "=", "np", ".", "array", "(", "matrix_rows", ")", "\n", "tfidf", "=", "np_matrix_row", "*", "term_percentage_vect", "#np.log(np_matrix_row) *", "\n", "\n", "metro_local_dict", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "7", ")", ":", "\n", "        ", "metro_local_dict", "[", "metro_name_list", "[", "i", "]", "]", "=", "dict", "(", ")", "\n", "\n", "a", "=", "tfidf", "[", "i", "]", "\n", "top_index", "=", "sorted", "(", "range", "(", "len", "(", "a", ")", ")", ",", "key", "=", "lambda", "i", ":", "a", "[", "i", "]", ")", "[", "-", "100", ":", "]", "\n", "top_index", "=", "np", ".", "flip", "(", "top_index", ",", "0", ")", "\n", "\n", "top_words", "=", "''", "\n", "word_frequencies", "=", "dict", "(", ")", "\n", "for", "index", "in", "top_index", ":", "\n", "            ", "top_words", "+=", "' '", "+", "vocab_list", "[", "index", "]", "+", "\":\"", "+", "str", "(", "a", "[", "index", "]", ")", "\n", "word_frequencies", "[", "vocab_list", "[", "index", "]", "]", "=", "np", ".", "log2", "(", "a", "[", "index", "]", ")", "\n", "metro_local_dict", "[", "metro_name_list", "[", "i", "]", "]", "[", "vocab_list", "[", "index", "]", "]", "=", "0", "\n", "\n", "#print(metro_name_list[i]+\": \"+top_words.strip())", "\n", "\n", "", "", "return", "metro_local_dict", "\n", "#         wordcloud = WordCloud(width=350, height=300, margin=8, prefer_horizontal=1, background_color='white',max_font_size=50).generate_from_frequencies(word_frequencies, max_font_size=None)", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.metro_local_word.check_metro_local_word_usage": [[245, 287], ["dict", "dict", "os.listdir", "codecs.open", "fname.replace", "city_name.replace.replace", "codecs.open.close", "print", "os.path.join", "city_name.replace.split", "line.strip.replace().replace", "line.strip.strip", "line.strip.split", "word.strip.strip", "metro_local_dict[].has_key", "str", "line.strip.replace"], "function", ["None"], ["", "def", "check_metro_local_word_usage", "(", "poi_data_dir", ",", "metro_local_dict", ")", ":", "\n", "    ", "metro_poi_total_count_dict", "=", "dict", "(", ")", "\n", "metro_poi_local_count_dict", "=", "dict", "(", ")", "\n", "\n", "# init", "\n", "for", "metro", "in", "metro_local_dict", ":", "\n", "        ", "metro_poi_total_count_dict", "[", "metro", "]", "=", "0", "\n", "metro_poi_local_count_dict", "[", "metro", "]", "=", "0", "\n", "\n", "# go through files in the folder   ", "\n", "", "for", "fname", "in", "os", ".", "listdir", "(", "poi_data_dir", ")", ":", "\n", "        ", "if", "fname", "==", "'city_list.csv'", ":", "\n", "            ", "continue", "\n", "\n", "", "fr", "=", "codecs", ".", "open", "(", "os", ".", "path", ".", "join", "(", "poi_data_dir", ",", "fname", ")", ",", "'r'", ",", "'utf-8'", ")", "\n", "\n", "city_name", "=", "fname", ".", "replace", "(", "'.txt'", ",", "''", ")", "\n", "city_name", "=", "city_name", ".", "replace", "(", "' '", ",", "'|'", ")", "\n", "#print(city_name)", "\n", "metro_name", "=", "city_name", ".", "split", "(", "','", ")", "[", "1", "]", "\n", "if", "metro_name", "==", "'sc'", ":", "\n", "            ", "metro_name", "=", "'nc'", "\n", "\n", "#POI_doc = \"\"", "\n", "\n", "", "for", "line", "in", "fr", ":", "\n", "            ", "metro_poi_total_count_dict", "[", "metro_name", "]", "+=", "1", "\n", "\n", "line", "=", "line", ".", "replace", "(", "city_name", ",", "''", ")", ".", "replace", "(", "u'\\ufeff'", ",", "''", ")", "\n", "line", "=", "line", ".", "strip", "(", ")", "\n", "splitted_words", "=", "line", ".", "split", "(", "' '", ")", "\n", "for", "word", "in", "splitted_words", ":", "\n", "                ", "word", "=", "word", ".", "strip", "(", ")", "\n", "if", "metro_local_dict", "[", "metro_name", "]", ".", "has_key", "(", "word", ")", ":", "\n", "                    ", "metro_poi_local_count_dict", "[", "metro_name", "]", "+=", "1", "\n", "break", "\n", "\n", "", "", "", "fr", ".", "close", "(", ")", "\n", "\n", "\n", "", "for", "metro_name", "in", "metro_poi_total_count_dict", ":", "\n", "        ", "print", "(", "metro_name", "+", "\": \"", "+", "str", "(", "metro_poi_local_count_dict", "[", "metro_name", "]", "*", "1.0", "/", "metro_poi_total_count_dict", "[", "metro_name", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.similarity_matrix.plot_similarity_matrix": [[20, 30], ["matplotlib.subplots", "matplotlib.cm.get_cmap", "ax.matshow", "matplotlib.title", "matplotlib.xticks", "matplotlib.yticks", "fig.colorbar", "matplotlib.show", "range", "range"], "function", ["None"], ["def", "plot_similarity_matrix", "(", "matrix_data", ",", "labels", ",", "plot_title", ")", ":", "\n", "    ", "fig", ",", "ax", "=", "plt", ".", "subplots", "(", "figsize", "=", "(", "20", ",", "20", ")", ")", "\n", "cmap", "=", "cm", ".", "get_cmap", "(", "'RdYlGn'", ")", "#'RdYlGn_r'", "\n", "cax", "=", "ax", ".", "matshow", "(", "matrix_data", ",", "interpolation", "=", "'nearest'", ",", "cmap", "=", "cmap", ")", "#, vmin=0.65, vmax=1.0)", "\n", "#ax.grid(True)", "\n", "plt", ".", "title", "(", "plot_title", ")", "\n", "plt", ".", "xticks", "(", "range", "(", "7", ")", ",", "labels", ",", "rotation", "=", "90", ")", ";", "\n", "plt", ".", "yticks", "(", "range", "(", "7", ")", ",", "labels", ")", ";", "\n", "fig", ".", "colorbar", "(", "cax", ",", "ticks", "=", "[", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", ",", "0.5", ",", "0.6", ",", "0.7", ",", ".75", ",", ".8", ",", ".85", ",", ".90", ",", ".95", ",", "1", "]", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.similarity_matrix.word2vec_similarity_metro": [[36, 52], ["gensim.models.word2vec.Word2Vec.load", "len", "numpy.zeros", "range", "similarity_matrix.plot_similarity_matrix", "range", "Word2Vec.load.similarity"], "function", ["home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.similarity_matrix.plot_similarity_matrix"], ["", "def", "word2vec_similarity_metro", "(", ")", ":", "\n", "# use word2vec to fill in the matrix values", "\n", "    ", "model", "=", "Word2Vec", ".", "load", "(", "'../models/model_300_AllCategory_metro.bin'", ")", "\n", "\n", "labels", "=", "[", "'nv'", ",", "'az'", ",", "'wi'", ",", "'il'", ",", "'oh'", ",", "'nc'", ",", "'pa'", "]", "\n", "labels_vec", "=", "[", "'nvstate'", ",", "'azstate'", ",", "'wistate'", ",", "'ilstate'", ",", "'ohstate'", ",", "'ncstate'", ",", "'pastate'", "]", "\n", "\n", "dim", "=", "len", "(", "labels", ")", "\n", "\n", "matrix_data", "=", "np", ".", "zeros", "(", "(", "dim", ",", "dim", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "dim", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "dim", ")", ":", "\n", "            ", "matrix_data", "[", "i", ",", "j", "]", "=", "model", ".", "similarity", "(", "labels_vec", "[", "i", "]", ",", "labels_vec", "[", "j", "]", ")", "\n", "\n", "", "", "plot_similarity_matrix", "(", "matrix_data", "=", "matrix_data", ",", "labels", "=", "labels", ",", "plot_title", "=", "'POI Name Similarity (word2vec)'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.similarity_matrix.geo_distance_similarity_metro": [[57, 135], ["dict", "dict", "list", "dict", "list", "list", "range", "len", "numpy.zeros", "range", "similarity_matrix.plot_similarity_matrix", "codecs.open", "codecs.open", "list.append", "[].split", "this_metro_coord.split.append", "range", "line.replace().strip().replace.strip().split", "splitted[].replace().strip().replace", "line.replace().strip().replace.replace().strip().replace", "list.append", "this_metro_coord.split", "float", "float", "str", "coords[].split", "coords[].split", "str", "float", "float", "float", "float", "geopy.distance.vincenty", "line.replace().strip().replace.strip", "splitted[].replace().strip", "line.replace().strip().replace.replace().strip", "line.replace().strip().replace.split", "splitted[].replace", "line.replace().strip().replace.replace", "len"], "function", ["home.repos.pwc.inspect_result.YingjieHu_POI_Name.src.similarity_matrix.plot_similarity_matrix"], ["", "def", "geo_distance_similarity_metro", "(", ")", ":", "\n", "\n", "    ", "city_coord_dict", "=", "dict", "(", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "'../city_coords_AllCategories.csv'", ",", "'r'", ",", "'utf-8'", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "splitted", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"|\"", ")", "\n", "city_name", "=", "splitted", "[", "0", "]", ".", "replace", "(", "\" \"", ",", "\"|\"", ")", ".", "strip", "(", ")", ".", "replace", "(", "u'\\ufeff'", ",", "''", ")", "\n", "city_coord_dict", "[", "city_name", "]", "=", "splitted", "[", "1", "]", "+", "\"|\"", "+", "splitted", "[", "2", "]", "\n", "\n", "\n", "", "", "metro_dict", "=", "dict", "(", ")", "\n", "metro_dict", "[", "'azstate'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'ilstate'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'ncstate'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'nvstate'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'ohstate'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'pastate'", "]", "=", "\"\"", "\n", "metro_dict", "[", "'wistate'", "]", "=", "\"\"", "\n", "\n", "\n", "city_list", "=", "list", "(", ")", "\n", "with", "codecs", ".", "open", "(", "\"../city_poi_by_type/AllCategory/city_list.csv\"", ",", "\"r\"", ",", "\"utf-8-sig\"", ")", "as", "fr", ":", "\n", "        ", "for", "line", "in", "fr", ":", "\n", "            ", "line", "=", "line", ".", "replace", "(", "\" \"", ",", "\"|\"", ")", ".", "strip", "(", ")", ".", "replace", "(", "u'\\ufeff'", ",", "''", ")", "\n", "city_list", ".", "append", "(", "line", ")", "\n", "metro_name", "=", "line", ".", "split", "(", "','", ")", "[", "1", "]", "+", "'state'", "\n", "if", "metro_name", "==", "'scstate'", ":", "# note: there is one city in South Carolina in the data, which is very close to ther other NC cities. Thus, we consider it as NC.", "\n", "                ", "metro_name", "=", "'ncstate'", "\n", "", "metro_dict", "[", "metro_name", "]", "+=", "city_coord_dict", "[", "line", "]", "+", "','", "\n", "\n", "\n", "", "", "metro_coord_dict", "=", "dict", "(", ")", "\n", "metro_list", "=", "list", "(", ")", "\n", "for", "metro_name", "in", "metro_dict", ":", "\n", "        ", "metro_list", ".", "append", "(", "metro_name", ")", "\n", "metro_coord_array", "=", "metro_dict", "[", "metro_name", "]", "[", "0", ":", "(", "len", "(", "metro_dict", "[", "metro_name", "]", ")", "-", "1", ")", "]", ".", "split", "(", "','", ")", "\n", "lat", "=", "0.0", "\n", "lng", "=", "0.0", "\n", "count", "=", "0.0", "\n", "for", "this_metro_coord", "in", "metro_coord_array", ":", "\n", "            ", "count", "+=", "1.0", "\n", "coords", "=", "this_metro_coord", ".", "split", "(", "\"|\"", ")", "\n", "lat", "+=", "float", "(", "coords", "[", "0", "]", ")", "\n", "lng", "+=", "float", "(", "coords", "[", "1", "]", ")", "\n", "\n", "", "metro_coord_dict", "[", "metro_name", "]", "=", "str", "(", "lat", "/", "count", ")", "+", "','", "+", "str", "(", "lng", "/", "count", ")", "\n", "\n", "\n", "", "labels", "=", "[", "'nv'", ",", "'az'", ",", "'wi'", ",", "'il'", ",", "'oh'", ",", "'nc'", ",", "'pa'", "]", "\n", "coords", "=", "list", "(", ")", "\n", "for", "i", "in", "range", "(", "7", ")", ":", "\n", "        ", "coords", ".", "append", "(", "metro_coord_dict", "[", "labels", "[", "i", "]", "+", "'state'", "]", ")", "\n", "#     with codecs.open(\"../final_city_name_coords_US_only.csv\",\"r\",\"utf-8-sig\") as fr:", "\n", "#             for line in fr:", "\n", "#                 splitted = line.split(',')", "\n", "#                 city_name = (splitted[0]+','+splitted[1]).replace(\" \",\"|\").strip().replace(u'\\ufeff', '')", "\n", "#                 city_name = city_name.decode(\"utf-8-sig\").encode(\"utf-8\")", "\n", "#                 labels.append(city_name)", "\n", "#                 coords.append((splitted[2]+','+splitted[3]).strip())", "\n", "\n", "", "dim", "=", "len", "(", "labels", ")", "\n", "\n", "matrix_data", "=", "np", ".", "zeros", "(", "(", "dim", ",", "dim", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "dim", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "dim", ")", ":", "\n", "            ", "first_splitted", "=", "coords", "[", "i", "]", ".", "split", "(", "\",\"", ")", "\n", "first_coord", "=", "(", "float", "(", "first_splitted", "[", "0", "]", ")", ",", "float", "(", "first_splitted", "[", "1", "]", ")", ")", "\n", "\n", "second_splitted", "=", "coords", "[", "j", "]", ".", "split", "(", "\",\"", ")", "\n", "second_coord", "=", "(", "float", "(", "second_splitted", "[", "0", "]", ")", ",", "float", "(", "second_splitted", "[", "1", "]", ")", ")", "\n", "\n", "distance", "=", "vincenty", "(", "first_coord", ",", "second_coord", ")", ".", "miles", "\n", "\n", "matrix_data", "[", "i", ",", "j", "]", "=", "distance", "/", "1931.44912074", "#math.log(10+distance) / math.log(10+1931.44912074)", "\n", "\n", "", "", "plot_similarity_matrix", "(", "matrix_data", "=", "matrix_data", ",", "labels", "=", "labels", ",", "plot_title", "=", "'Distance Between Geographic Regions'", ")", "\n", "\n"]]}