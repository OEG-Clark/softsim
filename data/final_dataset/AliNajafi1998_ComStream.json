{"home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_seconds": [[4, 13], ["time.split", "float", "float", "float"], "function", ["None"], ["def", "get_seconds", "(", "time", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    calculates the seconds of a time\n    :param time: the time as str 'hh:mm:ss'\n    :return: returns time as seconds\n    \"\"\"", "\n", "s", "=", "time", ".", "split", "(", "':'", ")", "\n", "seconds", "=", "float", "(", "s", "[", "2", "]", ")", "+", "float", "(", "s", "[", "1", "]", ")", "*", "60", "+", "float", "(", "s", "[", "0", "]", ")", "*", "3600", "\n", "return", "seconds", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_distance_cosine": [[15, 17], ["numpy.dot", "numpy.linalg.norm", "numpy.linalg.norm"], "function", ["None"], ["", "def", "get_distance_cosine", "(", "vec_1", ",", "vec_2", ")", ":", "\n", "    ", "return", "(", "1", "-", "(", "np", ".", "dot", "(", "vec_1", ",", "vec_2", ".", "T", ")", ")", "/", "(", "np", ".", "linalg", ".", "norm", "(", "vec_1", ")", "*", "np", ".", "linalg", ".", "norm", "(", "vec_2", ")", ")", ")", "/", "2.0", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_distance_euclidean": [[19, 21], ["numpy.sqrt", "numpy.sum"], "function", ["None"], ["", "def", "get_distance_euclidean", "(", "vec_1", ",", "vec_2", ")", ":", "\n", "    ", "return", "np", ".", "sqrt", "(", "np", ".", "sum", "(", "(", "vec_1", "-", "vec_2", ")", "**", "2", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.__init__": [[23, 71], ["pandas.to_datetime", "re.compile", "DataManager.DataManager.DataManager", "dict", "Exception", "pandas.Timedelta", "len", "len", "re.compile.findall", "re.compile.findall"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "save_output_interval", ":", "str", ",", "\n", "init_no_agents", ":", "int", ",", "\n", "communication_interval", ":", "str", ",", "\n", "sliding_window_interval", ":", "str", ",", "\n", "assign_radius", ":", "float", ",", "\n", "init_dp_per_agent", ":", "int", ",", "\n", "outlier_threshold", ":", "float", ",", "\n", "dp_count", ":", "int", ",", "\n", "no_topics", ":", "int", ",", "\n", "no_keywords", ":", "int", ",", "\n", "agent_fading_rate", ":", "float", ",", "\n", "delete_agent_weight_threshold", ":", "float", ",", "\n", "data_file_path", ":", "str", ",", "\n", "embedding_file_path", ":", "str", ",", "\n", "generic_distance", ",", "\n", "data_start_date", "=", "pd", ".", "to_datetime", "(", "'2020-03-29T00:00:00Z'", ")", ",", "\n", "is_parallel", "=", "True", ",", "\n", "verbose", "=", "0", "\n", ")", ":", "\n", "        ", "pattern", "=", "re", ".", "compile", "(", "r'^[0-9]+:[0-9]{2}:[0-9]{2}$'", ")", "\n", "are_invalid_steps", "=", "len", "(", "pattern", ".", "findall", "(", "communication_interval", ")", ")", "!=", "1", "or", "len", "(", "\n", "pattern", ".", "findall", "(", "sliding_window_interval", ")", ")", "!=", "1", "\n", "\n", "if", "are_invalid_steps", ":", "\n", "            ", "raise", "Exception", "(", "f'Invalid inputs fot steps'", ")", "\n", "", "self", ".", "save_output_interval", "=", "save_output_interval", "\n", "self", ".", "agents", "=", "{", "}", "\n", "self", ".", "assign_radius", "=", "assign_radius", "\n", "self", ".", "agent_fading_rate", "=", "agent_fading_rate", "\n", "self", ".", "delete_agent_weight_threshold", "=", "delete_agent_weight_threshold", "\n", "self", ".", "communication_interval", "=", "communication_interval", "\n", "self", ".", "init_dp_per_agent", "=", "init_dp_per_agent", "\n", "self", ".", "init_no_agents", "=", "init_no_agents", "\n", "self", ".", "outlier_threshold", "=", "outlier_threshold", "\n", "self", ".", "no_keywords", "=", "no_keywords", "\n", "self", ".", "no_topics", "=", "no_topics", "\n", "self", ".", "sliding_window_interval", "=", "sliding_window_interval", "\n", "self", ".", "data_agent", "=", "DataManager", "(", "data_file_path", "=", "data_file_path", ",", "data_embedding_path", "=", "embedding_file_path", ",", "\n", "count", "=", "dp_count", ")", "\n", "self", ".", "generic_distance_function", "=", "generic_distance", "\n", "self", ".", "dp_id_to_agent_id", "=", "dict", "(", ")", "\n", "self", ".", "first_communication_residual", "=", "None", "\n", "self", ".", "first_save_output_residual", "=", "None", "\n", "self", ".", "is_parallel", "=", "is_parallel", "\n", "self", ".", "verbose", "=", "verbose", "\n", "Coordinator", ".", "current_date", "=", "data_start_date", "\n", "Coordinator", ".", "prev_date", "=", "Coordinator", ".", "current_date", "+", "pd", ".", "Timedelta", "(", "days", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.create_agent": [[72, 80], ["Agent.Agent.Agent"], "methods", ["None"], ["", "def", "create_agent", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        creates the agent and returns it's id\n        :return: (int) returns the created agent's id\n        \"\"\"", "\n", "agent", "=", "Agent", "(", "self", ",", "generic_distance_function", "=", "self", ".", "generic_distance_function", ")", "\n", "self", ".", "agents", "[", "agent", ".", "agent_id", "]", "=", "agent", "\n", "return", "agent", ".", "agent_id", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.remove_agent": [[81, 90], ["Coordinator.Coordinator.agents[].remove_data_point"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.remove_data_point"], ["", "def", "remove_agent", "(", "self", ",", "agent_id", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        removes the agent with all it's dps\n        :param agent_id: the id of the agent\n        :return: None\n        \"\"\"", "\n", "for", "dp_id", "in", "self", ".", "agents", "[", "agent_id", "]", ".", "dp_ids", ":", "\n", "            ", "self", ".", "agents", "[", "agent_id", "]", ".", "remove_data_point", "(", "dp_id", ")", "\n", "", "del", "self", ".", "agents", "[", "agent_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.get_outliers": [[91, 104], ["agent.generic_distance_function", "agent.remove_data_point", "outliers_id.append"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.remove_data_point"], ["", "def", "get_outliers", "(", "self", ",", "agent", ")", "->", "[", "]", ":", "\n", "        ", "\"\"\"\n        getting outliers of agent\n        :return: list of ids of outliers\n        \"\"\"", "\n", "outliers_id", "=", "[", "]", "\n", "for", "dp_id", "in", "agent", ".", "dp_ids", ":", "\n", "            ", "dp", "=", "agent", ".", "coordinator", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", "\n", "distance", "=", "agent", ".", "generic_distance_function", "(", "dp", ".", "embedding_vec", ",", "agent", ".", "centroid", ")", "\n", "if", "distance", ">", "agent", ".", "outlier_threshold", ":", "\n", "                ", "agent", ".", "remove_data_point", "(", "dp_id", ",", "outlier", "=", "True", ")", "\n", "outliers_id", ".", "append", "(", "dp_id", ")", "\n", "", "", "return", "outliers_id", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.handle_outliers": [[105, 149], ["list", "Coordinator.Coordinator.agents.values", "Coordinator.Coordinator.remove_agent", "float", "Coordinator.Coordinator.agents.items", "concurrent.futures.ProcessPoolExecutor", "sum", "sum.extend", "len", "agents_to_remove.append", "agent.get_distance", "outliers_to_join.append", "print", "Coordinator.Coordinator.create_agent", "Coordinator.Coordinator.agents[].add_data_point", "Coordinator.Coordinator.agents[].add_data_point", "list", "Coordinator.Coordinator.agents[].get_outliers", "executor.map", "multiprocessing.cpu_count"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.remove_agent", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.get_distance", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.create_agent", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.add_data_point", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.add_data_point", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.get_outliers"], ["", "def", "handle_outliers", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        looks at all the dps and if their distance from their assigned agent is more than outlier_threshold, then\n        if there is another agent which is within the dps radius reassigns it, else creates a new agent for the dp\n        :return: None\n        \"\"\"", "\n", "outliers_id", "=", "None", "\n", "agents", "=", "list", "(", "self", ".", "agents", ".", "values", "(", ")", ")", "\n", "if", "self", ".", "is_parallel", ":", "\n", "            ", "with", "concurrent", ".", "futures", ".", "ProcessPoolExecutor", "(", "max_workers", "=", "multiprocessing", ".", "cpu_count", "(", ")", "-", "1", ")", "as", "executor", ":", "\n", "                ", "outliers_id", "=", "sum", "(", "list", "(", "executor", ".", "map", "(", "self", ".", "get_outliers", ",", "agents", ")", ")", ",", "[", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "outliers_id", "=", "[", "]", "\n", "for", "agent_id", "in", "self", ".", "agents", ":", "\n", "                ", "outliers_id", ".", "extend", "(", "self", ".", "agents", "[", "agent_id", "]", ".", "get_outliers", "(", ")", ")", "\n", "\n", "", "", "agents_to_remove", "=", "[", "]", "\n", "for", "agent_id", "in", "self", ".", "agents", ":", "\n", "            ", "if", "len", "(", "self", ".", "agents", "[", "agent_id", "]", ".", "dp_ids", ")", "<", "1", ":", "\n", "                ", "agents_to_remove", ".", "append", "(", "agent_id", ")", "\n", "", "", "for", "aid", "in", "agents_to_remove", ":", "\n", "            ", "self", ".", "remove_agent", "(", "aid", ")", "\n", "\n", "", "outliers_to_join", "=", "[", "]", "\n", "for", "outlier_id", "in", "outliers_id", ":", "\n", "            ", "min_distance", "=", "float", "(", "'infinity'", ")", "\n", "similar_agent_id", "=", "-", "1", "\n", "for", "agent_id", ",", "agent", "in", "self", ".", "agents", ".", "items", "(", ")", ":", "\n", "                ", "distance", "=", "agent", ".", "get_distance", "(", "self", ".", "data_agent", ".", "data_points", "[", "outlier_id", "]", ".", "embedding_vec", ")", "\n", "if", "distance", "<=", "min_distance", ":", "\n", "                    ", "min_distance", "=", "distance", "\n", "similar_agent_id", "=", "agent_id", "\n", "", "", "if", "similar_agent_id", "!=", "-", "1", ":", "\n", "                ", "outliers_to_join", ".", "append", "(", "(", "outlier_id", ",", "min_distance", ",", "similar_agent_id", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Sth went wrong!'", ")", "\n", "\n", "", "", "for", "dp_id", ",", "distance", ",", "agent_id", "in", "outliers_to_join", ":", "\n", "# print(distance)", "\n", "            ", "if", "distance", ">", "self", ".", "assign_radius", ":", "\n", "                ", "new_agent_id", "=", "self", ".", "create_agent", "(", ")", "\n", "self", ".", "agents", "[", "new_agent_id", "]", ".", "add_data_point", "(", "self", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "agents", "[", "agent_id", "]", ".", "add_data_point", "(", "self", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.parallel_outlier_getting": [[150, 160], ["multiprocessing.Process", "my_processes.append", "multiprocessing.Process.start", "multiprocessing.Process.join"], "methods", ["None"], ["", "", "", "def", "parallel_outlier_getting", "(", "self", ",", "agent_ids", ",", "index", ",", "outliers_id", ",", "stop", ")", ":", "\n", "        ", "my_processes", "=", "[", "]", "\n", "for", "agent_id", "in", "agent_ids", "[", "index", ":", "stop", "]", ":", "\n", "            ", "p", "=", "multiprocessing", ".", "Process", "(", "\n", "target", "=", "self", ".", "agents", "[", "agent_id", "]", ".", "get_outliers", ",", "args", "=", "(", "outliers_id", ",", ")", ")", "\n", "my_processes", ".", "append", "(", "p", ")", "\n", "p", ".", "daemon", "=", "True", "\n", "p", ".", "start", "(", ")", "\n", "", "for", "p", "in", "my_processes", ":", "\n", "            ", "p", ".", "join", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.init_agents": [[161, 188], ["range", "range", "Coordinator.Coordinator.create_agent", "Coordinator.Coordinator.data_agent.get_next_dp", "Coordinator.Coordinator.agents[].add_data_point", "print", "Coordinator.Coordinator.agents.keys", "random.sample", "list", "time.mktime", "Utils.get_seconds", "time.mktime", "Utils.get_seconds", "len", "Coordinator.current_date.timetuple", "Coordinator.current_date.timetuple"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.create_agent", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_next_dp", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.add_data_point", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_seconds", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_seconds"], ["", "", "def", "init_agents", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        filling the initial agents with initial dps at the start of the train\n        :return: None\n        \"\"\"", "\n", "for", "i", "in", "range", "(", "self", ".", "init_no_agents", ")", ":", "\n", "            ", "self", ".", "create_agent", "(", ")", "\n", "", "flag", "=", "True", "\n", "agents_dict", "=", "{", "id_", ":", "self", ".", "init_dp_per_agent", "for", "id_", "in", "self", ".", "agents", ".", "keys", "(", ")", "}", "\n", "for", "i", "in", "range", "(", "self", ".", "init_no_agents", "*", "self", ".", "init_dp_per_agent", ")", ":", "\n", "            ", "random_agent_id", "=", "random", ".", "sample", "(", "list", "(", "agents_dict", ")", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "dp", "=", "self", ".", "data_agent", ".", "get_next_dp", "(", ")", "\n", "if", "flag", ":", "\n", "                ", "self", ".", "first_communication_residual", "=", "time", ".", "mktime", "(", "Coordinator", ".", "current_date", ".", "timetuple", "(", ")", ")", "%", "get_seconds", "(", "\n", "self", ".", "communication_interval", ")", "-", "0", "\n", "self", ".", "first_save_output_residual", "=", "time", ".", "mktime", "(", "Coordinator", ".", "current_date", ".", "timetuple", "(", ")", ")", "%", "get_seconds", "(", "\n", "self", ".", "save_output_interval", ")", "-", "0", "\n", "flag", "=", "False", "\n", "", "Coordinator", ".", "current_date", "=", "dp", ".", "created_at", "\n", "Coordinator", ".", "prev_date", "=", "dp", ".", "created_at", "\n", "self", ".", "agents", "[", "random_agent_id", "]", ".", "add_data_point", "(", "dp", ")", "\n", "agents_dict", "[", "random_agent_id", "]", "-=", "1", "\n", "if", "agents_dict", "[", "random_agent_id", "]", "==", "0", ":", "\n", "                ", "del", "agents_dict", "[", "random_agent_id", "]", "\n", "", "", "del", "agents_dict", "\n", "if", "self", ".", "verbose", "==", "1", ":", "\n", "            ", "print", "(", "f'Init_agents done : Number of agents : {len(self.agents)}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.stream": [[189, 207], ["float", "Coordinator.Coordinator.agents.items", "agent.get_distance", "Coordinator.Coordinator.create_agent", "Coordinator.Coordinator.agents[].add_data_point", "Coordinator.Coordinator.agents[].add_data_point"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.get_distance", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.create_agent", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.add_data_point", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.add_data_point"], ["", "", "def", "stream", "(", "self", ",", "dp", ")", ":", "\n", "        ", "\"\"\"\n        gets the dp, puts it in the closest agent if the agent is within the radius, else makes a new agent for it\n        :param dp: the object of the dp\n        :return: None\n        \"\"\"", "\n", "min_distance", "=", "float", "(", "'infinity'", ")", "\n", "similar_agent_id", "=", "-", "1", "\n", "for", "agent_id", ",", "agent", "in", "self", ".", "agents", ".", "items", "(", ")", ":", "\n", "            ", "distance", "=", "agent", ".", "get_distance", "(", "self", ".", "data_agent", ".", "data_points", "[", "dp", ".", "dp_id", "]", ".", "embedding_vec", ")", "\n", "if", "distance", "<=", "min_distance", ":", "\n", "                ", "min_distance", "=", "distance", "\n", "similar_agent_id", "=", "agent_id", "\n", "", "", "if", "min_distance", ">", "self", ".", "assign_radius", ":", "\n", "            ", "new_agent_id", "=", "self", ".", "create_agent", "(", ")", "\n", "self", ".", "agents", "[", "new_agent_id", "]", ".", "add_data_point", "(", "self", ".", "data_agent", ".", "data_points", "[", "dp", ".", "dp_id", "]", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "agents", "[", "similar_agent_id", "]", ".", "add_data_point", "(", "self", ".", "data_agent", ".", "data_points", "[", "dp", ".", "dp_id", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.fade_agents_weight": [[208, 216], ["list", "Coordinator.Coordinator.agents.keys", "agent.fade_agent_weight"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.fade_agent_weight"], ["", "", "def", "fade_agents_weight", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        for each agent calls the function that will fade that agent's weight\n        :return: None\n        \"\"\"", "\n", "for", "agent_id", "in", "list", "(", "self", ".", "agents", ".", "keys", "(", ")", ")", ":", "\n", "            ", "agent", "=", "self", ".", "agents", "[", "agent_id", "]", "\n", "agent", ".", "fade_agent_weight", "(", "self", ".", "agent_fading_rate", ",", "self", ".", "delete_agent_weight_threshold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.handle_old_dps": [[217, 224], ["Coordinator.Coordinator.agents.items", "agent.handle_old_dps"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.handle_old_dps"], ["", "", "def", "handle_old_dps", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        for each agent, calls the function that handles the old dps\n        :return: None\n        \"\"\"", "\n", "for", "agent_id", ",", "agent", "in", "self", ".", "agents", ".", "items", "(", ")", ":", "\n", "            ", "agent", ".", "handle_old_dps", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.train": [[225, 261], ["Coordinator.Coordinator.init_agents", "Coordinator.Coordinator.handle_outliers", "Coordinator.Coordinator.data_agent.has_next_dp", "Coordinator.Coordinator.handle_old_dps", "Coordinator.Coordinator.handle_outliers", "Coordinator.Coordinator.save_model_and_files", "Coordinator.Coordinator.data_agent.get_next_dp", "print", "pandas.Timedelta", "Coordinator.Coordinator.communicate", "Coordinator.Coordinator.save", "Coordinator.Coordinator.stream", "len"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.init_agents", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.handle_outliers", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.has_next_dp", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.handle_old_dps", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.handle_outliers", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.save_model_and_files", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_next_dp", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.communicate", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.save", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.stream"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        the main training function that handles everything\n        :return: None\n        \"\"\"", "\n", "self", ".", "init_agents", "(", ")", "\n", "self", ".", "handle_outliers", "(", ")", "\n", "Coordinator", ".", "dp_counter", "=", "self", ".", "init_no_agents", "*", "self", ".", "init_dp_per_agent", "\n", "while", "self", ".", "data_agent", ".", "has_next_dp", "(", ")", ":", "\n", "            ", "dp", "=", "self", ".", "data_agent", ".", "get_next_dp", "(", ")", "\n", "if", "self", ".", "verbose", "!=", "0", ":", "\n", "                ", "if", "(", "Coordinator", ".", "dp_counter", "+", "1", ")", "%", "1000", "==", "0", ":", "\n", "                    ", "message", "=", "f'{Fore.CYAN}{Coordinator.current_date} : data point count = {Coordinator.dp_counter + 1}'", "\n", "message", "+=", "f' number of agents : {len(self.agents)}'", "\n", "print", "(", "message", ")", "\n", "", "", "Coordinator", ".", "dp_counter", "+=", "1", "\n", "flag", "=", "True", "\n", "while", "flag", ":", "\n", "\n", "                ", "if", "dp", ".", "created_at", "!=", "Coordinator", ".", "prev_date", ":", "\n", "                    ", "Coordinator", ".", "current_date", "+=", "pd", ".", "Timedelta", "(", "seconds", "=", "1", ")", "\n", "\n", "# communication every interval", "\n", "self", ".", "communicate", "(", ")", "\n", "\n", "# save output every interval", "\n", "self", ".", "save", "(", ")", "\n", "\n", "", "if", "dp", ".", "created_at", "<=", "Coordinator", ".", "current_date", ":", "\n", "                    ", "self", ".", "stream", "(", "dp", ")", "\n", "Coordinator", ".", "prev_date", "=", "dp", ".", "created_at", "\n", "flag", "=", "False", "\n", "\n", "", "", "", "self", ".", "handle_old_dps", "(", ")", "\n", "self", ".", "handle_outliers", "(", ")", "\n", "self", ".", "save_model_and_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.communicate": [[262, 276], ["Utils.get_seconds", "abs", "Coordinator.Coordinator.handle_old_dps", "Coordinator.Coordinator.handle_outliers", "Coordinator.Coordinator.fade_agents_weight", "time.mktime", "print", "Coordinator.current_date.timetuple", "len"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_seconds", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.handle_old_dps", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.handle_outliers", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.fade_agents_weight"], ["", "def", "communicate", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        checks if now is the right time to communicate, if so then handles outliers and old dps and fades agent weights\n        :return: None\n        \"\"\"", "\n", "communication_residual", "=", "(", "time", ".", "mktime", "(", "\n", "Coordinator", ".", "current_date", ".", "timetuple", "(", ")", ")", "-", "self", ".", "first_communication_residual", ")", "%", "get_seconds", "(", "\n", "self", ".", "communication_interval", ")", "\n", "if", "abs", "(", "communication_residual", ")", "<=", "1e-7", ":", "\n", "            ", "self", ".", "handle_old_dps", "(", ")", "\n", "self", ".", "handle_outliers", "(", ")", "\n", "self", ".", "fade_agents_weight", "(", ")", "\n", "if", "self", ".", "verbose", "!=", "0", ":", "\n", "                ", "print", "(", "f'{Fore.BLUE}{self.current_date} : Communicating -> Number of agents : {len(self.agents)}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.save": [[277, 289], ["Utils.get_seconds", "abs", "Coordinator.Coordinator.handle_old_dps", "Coordinator.Coordinator.handle_outliers", "Coordinator.Coordinator.save_model_and_files", "time.mktime", "Coordinator.current_date.timetuple"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_seconds", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.handle_old_dps", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.handle_outliers", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.save_model_and_files"], ["", "", "", "def", "save", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        check if now is the right time to save everything considering save_output_interval and call the function after\n        :return: None\n        \"\"\"", "\n", "save_output_residual", "=", "(", "time", ".", "mktime", "(", "\n", "Coordinator", ".", "current_date", ".", "timetuple", "(", ")", ")", "-", "self", ".", "first_save_output_residual", ")", "%", "get_seconds", "(", "\n", "self", ".", "save_output_interval", ")", "\n", "if", "abs", "(", "save_output_residual", ")", "<=", "1e-7", ":", "\n", "            ", "self", ".", "handle_old_dps", "(", ")", "\n", "self", ".", "handle_outliers", "(", ")", "\n", "self", ".", "save_model_and_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.save_model_and_files": [[290, 313], ["Coordinator.Coordinator.write_output_to_files", "Coordinator.Coordinator.write_topics_to_files", "Coordinator.Coordinator.write_tweet_ids_to_files", "os.path.join", "os.path.join", "os.path.join", "print", "os.getcwd", "os.getcwd", "os.getcwd", "str", "str", "str", "len", "[].replace", "[].replace", "[].replace", "str", "str", "str"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.write_output_to_files", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.write_topics_to_files", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.write_tweet_ids_to_files"], ["", "", "def", "save_model_and_files", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        save the model, agent dps texts, agent dps ids, agent top topics\n        :return: None\n        \"\"\"", "\n", "# self.save_model(", "\n", "#     os.path.join(os.getcwd(), 'outputs/multi_agent',", "\n", "#                  'X' + str(Coordinator.current_date).replace(':', '_') + '--' + str(", "\n", "#                      Coordinator.dp_counter), 'model'))", "\n", "self", ".", "write_output_to_files", "(", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "'outputs/multi_agent'", ",", "\n", "'saved|'", "+", "str", "(", "Coordinator", ".", "current_date", ")", "[", ":", "-", "6", "]", ".", "replace", "(", "' '", ",", "'|'", ")", "+", "'|'", "+", "str", "(", "\n", "Coordinator", ".", "dp_counter", ")", ",", "'clusters'", ")", ")", "\n", "self", ".", "write_topics_to_files", "(", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "'outputs/multi_agent'", ",", "\n", "'saved|'", "+", "str", "(", "Coordinator", ".", "current_date", ")", "[", ":", "-", "6", "]", ".", "replace", "(", "' '", ",", "'|'", ")", "+", "'|'", "+", "str", "(", "\n", "Coordinator", ".", "dp_counter", ")", ",", "'topics'", ")", ")", "\n", "self", ".", "write_tweet_ids_to_files", "(", "\n", "os", ".", "path", ".", "join", "(", "os", ".", "getcwd", "(", ")", ",", "'outputs/multi_agent'", ",", "\n", "'saved|'", "+", "str", "(", "Coordinator", ".", "current_date", ")", "[", ":", "-", "6", "]", ".", "replace", "(", "' '", ",", "'|'", ")", "+", "'|'", "+", "str", "(", "\n", "Coordinator", ".", "dp_counter", ")", ",", "'clusters_tweet_ids'", ")", ")", "\n", "if", "self", ".", "verbose", "==", "1", ":", "\n", "            ", "print", "(", "f'{Fore.YELLOW}{self.current_date} : Save Model and Outputs -> Number of agents : {len(self.agents)}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.save_model": [[314, 324], ["os.path.exists", "os.makedirs", "open", "pickle.dump", "os.path.join"], "methods", ["None"], ["", "", "def", "save_model", "(", "self", ",", "parent_dir", ")", ":", "\n", "        ", "\"\"\"\n        save the whole model at given directory\n        :param parent_dir: the parent dir to store the model at\n        :return: None\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "parent_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "parent_dir", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "'model.pkl'", ")", ",", "'wb'", ")", "as", "file", ":", "\n", "            ", "pickle", ".", "dump", "(", "self", ",", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.load_model": [[325, 334], ["open", "pickle.load"], "methods", ["None"], ["", "", "@", "classmethod", "\n", "def", "load_model", "(", "cls", ",", "file_dir", ")", ":", "\n", "        ", "\"\"\"\n        load a saved model\n        :param file_dir: the exact directory of the model you want to load\n        :return: None\n        \"\"\"", "\n", "with", "open", "(", "file_dir", ",", "'rb'", ")", "as", "file", ":", "\n", "            ", "return", "pickle", ".", "load", "(", "file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.write_topics_to_files": [[335, 349], ["Coordinator.Coordinator.get_topics_of_agents", "os.path.exists", "os.makedirs", "open", "file.write", "os.path.join", "topics_keywords_text.strip"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.get_topics_of_agents"], ["", "", "def", "write_topics_to_files", "(", "self", ",", "parent_dir", ")", ":", "\n", "        ", "\"\"\"\n        write the max_topic_n topics to the file in parent_dir\n        :param parent_dir: the directory of the parent where you want to write the topics at\n        :return: None\n        \"\"\"", "\n", "topics_keywords", "=", "self", ".", "get_topics_of_agents", "(", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "parent_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "parent_dir", ")", "\n", "", "topics_keywords_text", "=", "''", "\n", "for", "keywords", "in", "topics_keywords", ":", "\n", "            ", "topics_keywords_text", "+=", "' '", ".", "join", "(", "keywords", ")", "+", "'\\n'", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "f\"top_topics_keywords.txt\"", ")", ",", "'w'", ",", "encoding", "=", "'utf8'", ")", "as", "file", ":", "\n", "            ", "file", ".", "write", "(", "topics_keywords_text", ".", "strip", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.write_output_to_files": [[350, 363], ["Coordinator.Coordinator.agents.items", "os.path.exists", "os.makedirs", "open", "os.path.join", "file.write"], "methods", ["None"], ["", "", "def", "write_output_to_files", "(", "self", ",", "parent_dir", ")", ":", "\n", "        ", "\"\"\"\n        for each agent a separate text file is generated which the text of dps of that agent are added to them\n        :param parent_dir: the parent directory where you want the output to be at\n        :return: None\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "parent_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "parent_dir", ")", "\n", "", "for", "agent_id", ",", "agent", "in", "self", ".", "agents", ".", "items", "(", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "f\"{agent_id}.txt\"", ")", ",", "'w'", ",", "encoding", "=", "'utf8'", ")", "as", "file", ":", "\n", "                ", "for", "dp_id", "in", "agent", ".", "dp_ids", ":", "\n", "                    ", "tweet", "=", "self", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", ".", "tweet", "\n", "file", ".", "write", "(", "f'{tweet}\\n\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.write_tweet_ids_to_files": [[364, 377], ["Coordinator.Coordinator.agents.items", "os.path.exists", "os.makedirs", "open", "os.path.join", "file.write", "str"], "methods", ["None"], ["", "", "", "", "def", "write_tweet_ids_to_files", "(", "self", ",", "parent_dir", ")", ":", "\n", "        ", "\"\"\"\n        for each agent a separate text file is generated which the id of dps of that agent are added to them\n        :param parent_dir: the parent directory where you want the output to be at\n        :return: None\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "parent_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "parent_dir", ")", "\n", "", "for", "agent_id", ",", "agent", "in", "self", ".", "agents", ".", "items", "(", ")", ":", "\n", "            ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "parent_dir", ",", "f\"{agent_id}.txt\"", ")", ",", "'w'", ",", "encoding", "=", "'utf8'", ")", "as", "file", ":", "\n", "                ", "for", "dp_id", "in", "agent", ".", "dp_ids", ":", "\n", "                    ", "tweet_id", "=", "self", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", ".", "status_id", "\n", "file", ".", "write", "(", "str", "(", "tweet_id", ")", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.get_topics_of_agents": [[378, 419], ["Coordinator.Coordinator.agents.items", "sklearn.feature_extraction.text.TfidfVectorizer", "sklearn.feature_extraction.text.TfidfVectorizer.fit", "sklearn.feature_extraction.text.TfidfVectorizer.get_feature_names", "agent_ids_size.sort", "agent_ids_size.append", "sklearn.feature_extraction.text.TfidfVectorizer.transform", "scipy.sparse.coo_matrix", "zip", "list", "topics_keywords.append", "full_corpus.append", "min", "agent_corpus.append", "sorted", "len", "len", "agent_word2score.get", "min", "len"], "methods", ["None"], ["", "", "", "", "def", "get_topics_of_agents", "(", "self", ")", ":", "\n", "        ", "topics_keywords", "=", "[", "]", "\n", "full_corpus", "=", "[", "]", "\n", "agent_ids_size", "=", "[", "]", "# (agent_id, size)", "\n", "for", "agent_id", ",", "agent_object", "in", "self", ".", "agents", ".", "items", "(", ")", ":", "\n", "            ", "agent_ids_size", ".", "append", "(", "(", "agent_id", ",", "len", "(", "agent_object", ".", "dp_ids", ")", ")", ")", "\n", "for", "dp_id", "in", "agent_object", ".", "dp_ids", ":", "\n", "                ", "dp_object", "=", "self", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", "\n", "full_corpus", ".", "append", "(", "dp_object", ".", "tweet", ")", "\n", "", "", "vectorizer", "=", "TfidfVectorizer", "(", ")", "\n", "# vectorized_corpus.shape (index of corpus, score of each word", "\n", "# (all the words evens words that don't exist in this sentence))", "\n", "vectorizer", ".", "fit", "(", "full_corpus", ")", "\n", "vocab", "=", "vectorizer", ".", "get_feature_names", "(", ")", "# ind -> word", "\n", "\n", "# get the biggest agents:", "\n", "agent_ids_size", ".", "sort", "(", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ",", "reverse", "=", "True", ")", "\n", "candidate_agent_ids_size", "=", "agent_ids_size", "[", ":", "min", "(", "self", ".", "no_topics", ",", "len", "(", "agent_ids_size", ")", ")", "]", "\n", "\n", "# get scores for each word in every agent", "\n", "for", "agent_id", ",", "agent_size", "in", "candidate_agent_ids_size", ":", "\n", "            ", "agent_corpus", "=", "[", "]", "\n", "agent_object", "=", "self", ".", "agents", "[", "agent_id", "]", "\n", "for", "dp_id", "in", "agent_object", ".", "dp_ids", ":", "\n", "                ", "dp_object", "=", "self", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", "\n", "agent_corpus", ".", "append", "(", "dp_object", ".", "tweet", ")", "\n", "", "vectorized_agent_corpus", "=", "vectorizer", ".", "transform", "(", "agent_corpus", ")", "\n", "\n", "cx", "=", "scipy", ".", "sparse", ".", "coo_matrix", "(", "vectorized_agent_corpus", ")", "\n", "agent_word2score", "=", "{", "}", "\n", "for", "i", ",", "j", ",", "v", "in", "zip", "(", "cx", ".", "row", ",", "cx", ".", "col", ",", "cx", ".", "data", ")", ":", "\n", "                ", "agent_word2score", "[", "vocab", "[", "j", "]", "]", "=", "agent_word2score", ".", "get", "(", "vocab", "[", "j", "]", ",", "0.0", ")", "+", "v", "\n", "\n", "# sort and choose the top no_keywords", "\n", "", "sorted_keys", "=", "list", "(", "sorted", "(", "agent_word2score", ",", "key", "=", "agent_word2score", ".", "get", ",", "reverse", "=", "True", ")", ")", "# get the sorted keys", "\n", "sorted_keys", "=", "sorted_keys", "[", ":", "min", "(", "self", ".", "no_keywords", ",", "len", "(", "sorted_keys", ")", ")", "]", "# get best keywords", "\n", "topics_keywords", ".", "append", "(", "sorted_keys", ")", "\n", "\n", "", "del", "vocab", "\n", "del", "vectorizer", "\n", "return", "topics_keywords", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.__init__": [[13, 33], ["DataManager.DataManager.load_data"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.load_data"], ["def", "__init__", "(", "self", ",", "data_file_path", ",", "data_embedding_path", ",", "count", ":", "int", ",", "epsilon", "=", "1e-7", ")", ":", "\n", "        ", "\"\"\"\n        the object that handles data loading and processing\n        :param data_file_path: the path where our data is at\n        :param count: the amount of the data we want to process\n        :param epsilon: Float\n        :return: None\n        \"\"\"", "\n", "self", ".", "data_file_path", "=", "data_file_path", "\n", "self", ".", "epsilon", "=", "epsilon", "\n", "self", ".", "raw_data", "=", "None", "\n", "self", ".", "embedding_vectors", "=", "None", "\n", "self", ".", "token_to_id", "=", "{", "}", "\n", "self", ".", "id_to_token", "=", "{", "}", "\n", "self", ".", "global_freq", "=", "{", "}", "\n", "self", ".", "count", "=", "count", "\n", "self", ".", "data_points", "=", "{", "}", "\n", "self", ".", "max_data", "=", "0", "\n", "\n", "self", ".", "load_data", "(", "data_file_path", ",", "data_embedding_path", ",", "count", "=", "count", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.load_data": [[34, 47], ["pandas.read_pickle().reset_index().head", "len", "numpy.load", "len", "len", "ValueError", "pandas.read_pickle().reset_index", "pandas.read_pickle"], "methods", ["None"], ["", "def", "load_data", "(", "self", ",", "file_path", ":", "str", ",", "data_embedding_path", ":", "str", ",", "count", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        read the df of our dps\n        :param file_path: the dir where our input data is at\n        :param data_embedding_path : the dir where our input data's embedding at\n        :param count: how many of the data we want\n        :return: None\n        \"\"\"", "\n", "self", ".", "raw_data", "=", "pd", ".", "read_pickle", "(", "file_path", ")", ".", "reset_index", "(", ")", ".", "head", "(", "count", ")", "\n", "self", ".", "embedding_vectors", "=", "np", ".", "load", "(", "data_embedding_path", ")", "[", ":", "count", "]", "\n", "if", "len", "(", "self", ".", "raw_data", ")", "!=", "len", "(", "self", ".", "embedding_vectors", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"the data and their embeddings don't have the same length.\"", ")", "\n", "", "self", ".", "max_data", "=", "len", "(", "self", ".", "raw_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_dp": [[48, 56], ["DataManager.DataManager.get_twitter_dp"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_twitter_dp"], ["", "def", "get_dp", "(", "self", ",", "dp", ":", "pd", ".", "DataFrame", ",", "embedding_vec", ")", ":", "\n", "        ", "\"\"\"\n        call the function to turn the df to our dp object\n        :param dp: one dp with format data frame\n        :param embedding_vec : representation of datapoint\n        :return: object dp\n        \"\"\"", "\n", "return", "self", ".", "get_twitter_dp", "(", "dp", ",", "embedding_vec", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_twitter_dp": [[57, 80], ["DataManager.DataManager.get_freq_dict", "datetime.datetime.datetime.now", "pandas.to_datetime", "DataPoint.TwitterDataPoint"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_freq_dict"], ["", "def", "get_twitter_dp", "(", "self", ",", "dp", ":", "pd", ".", "DataFrame", ",", "embedding_vec", ")", "->", "TwitterDataPoint", ":", "\n", "        ", "\"\"\"\n        turns one twitter data point's data-frame to our recognizable object dp\n        :param dp: one twitter dp with format data frame\n        :param embedding_vec : representation of datapoint\n        :return: object twitter dp\n        \"\"\"", "\n", "tweet", "=", "dp", "[", "'text'", "]", ".", "values", "[", "0", "]", "\n", "\n", "# Extracting Data", "\n", "freq_dict", "=", "self", ".", "get_freq_dict", "(", "tweet", ")", "\n", "\n", "time_stamp", "=", "datetime", ".", "now", "(", ")", "\n", "status_id", "=", "dp", "[", "'status_id'", "]", ".", "values", "[", "0", "]", "\n", "created_at", "=", "pd", ".", "to_datetime", "(", "dp", "[", "'created_at'", "]", ".", "values", "[", "0", "]", ")", "\n", "\n", "return", "TwitterDataPoint", "(", "\n", "tweet", "=", "tweet", ",", "\n", "freq", "=", "freq_dict", ",", "time_stamp", "=", "time_stamp", ",", "\n", "status_id", "=", "status_id", ",", "\n", "created_at", "=", "created_at", ",", "\n", "index_in_df", "=", "DataManager", ".", "current_dp_index", "-", "1", ",", "\n", "embedding_vec", "=", "embedding_vec", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_freq_dict": [[82, 102], ["tweet.split"], "methods", ["None"], ["", "def", "get_freq_dict", "(", "self", ",", "tweet", ":", "str", ")", "->", "dict", ":", "\n", "        ", "\"\"\"\n        turns the tweet text in to its token ids with their frequencies\n        :param tweet: the text of the tweet\n        :return: a dict of {token_id:frequency}\n        \"\"\"", "\n", "tweet_tokens", "=", "tweet", ".", "split", "(", ")", "\n", "\n", "freq_dict", "=", "{", "}", "\n", "for", "token", "in", "tweet_tokens", ":", "\n", "            ", "if", "token", "in", "self", ".", "token_to_id", ":", "\n", "                ", "if", "self", ".", "token_to_id", "[", "token", "]", "in", "freq_dict", ":", "\n", "                    ", "freq_dict", "[", "self", ".", "token_to_id", "[", "token", "]", "]", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "freq_dict", "[", "self", ".", "token_to_id", "[", "token", "]", "]", "=", "1", "\n", "", "", "else", ":", "\n", "                ", "self", ".", "token_to_id", "[", "token", "]", "=", "DataManager", ".", "token_id", "\n", "self", ".", "id_to_token", "[", "DataManager", ".", "token_id", "]", "=", "token", "\n", "DataManager", ".", "token_id", "+=", "1", "\n", "", "", "return", "freq_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_next_dp": [[103, 113], ["DataManager.DataManager.get_dp"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.get_dp"], ["", "def", "get_next_dp", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        call the func to read the next dp\n        :return: the object of the dp\n        \"\"\"", "\n", "DataManager", ".", "current_dp_index", "+=", "1", "\n", "dp", "=", "self", ".", "get_dp", "(", "self", ".", "raw_data", ".", "iloc", "[", "[", "DataManager", ".", "current_dp_index", "-", "1", "]", "]", ",", "\n", "self", ".", "embedding_vectors", "[", "DataManager", ".", "current_dp_index", "-", "1", "]", ")", "\n", "self", ".", "data_points", "[", "dp", ".", "dp_id", "]", "=", "dp", "\n", "return", "dp", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataManager.DataManager.has_next_dp": [[114, 122], ["None"], "methods", ["None"], ["", "def", "has_next_dp", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        check if we are not exceeding our maximum dps to process threshold\n        :return: Boolean\n        \"\"\"", "\n", "if", "self", ".", "max_data", "<=", "DataManager", ".", "current_dp_index", "+", "1", ":", "\n", "            ", "return", "False", "\n", "", "return", "not", "(", "DataManager", ".", "current_dp_index", ">=", "self", ".", "count", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataPoint.DataPoint.__init__": [[4, 24], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "tweet", ":", "str", ",", "\n", "freq", ":", "dict", ",", "\n", "time_stamp", ",", "\n", "created_at", ",", "\n", "index_in_df", ")", ":", "\n", "        ", "\"\"\"\n            the object that keeps the details of the dp\n            :param tweet: tweet's full text\n            :param freq: a dict of {token_id, frequency}\n            :param time_stamp: the time the dp has come to system\n            :param created_at: the time the dp was created at\n            :param index_in_df: the index of the dp in the df\n            :return: None\n        \"\"\"", "\n", "self", ".", "tweet", "=", "tweet", "\n", "self", ".", "freq", "=", "freq", "\n", "self", ".", "created_at", "=", "created_at", "\n", "self", ".", "time_stamp", "=", "time_stamp", "\n", "self", ".", "index_in_df", "=", "index_in_df", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.DataPoint.TwitterDataPoint.__init__": [[27, 45], ["DataPoint.DataPoint.__init__"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.__init__"], ["    ", "def", "__init__", "(", "self", ",", "tweet", ":", "str", ",", "freq", ":", "dict", ",", "time_stamp", ",", "status_id", ",", "created_at", ",", "index_in_df", ",", "embedding_vec", ")", ":", "\n", "        ", "\"\"\"\n        the child object of DataPoint\n        :param tweet: tweet's full text\n        :param freq: a dict of {token_id, frequency}\n        :param time_stamp: the time the dp has come to system\n        :param status_id: the id of the tweet\n        :param created_at: the time the dp was created at\n        :param index_in_df: the index of the dp in the df\n        :param embedding_vec: representation of twitter\n        :return: None\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "tweet", ",", "freq", ",", "time_stamp", ",", "created_at", ",", "index_in_df", ")", "\n", "self", ".", "dp_id", "=", "DataPoint", ".", "dp_id", "\n", "DataPoint", ".", "dp_id", "+=", "1", "\n", "\n", "self", ".", "embedding_vec", "=", "embedding_vec", "\n", "self", ".", "status_id", "=", "status_id", "\n", "", "", ""]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.__init__": [[11, 20], ["numpy.zeros"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "coordinator", ",", "generic_distance_function", ":", "Callable", ")", ":", "\n", "        ", "self", ".", "agent_id", "=", "Agent", ".", "agent_id", "\n", "self", ".", "outlier_threshold", "=", "coordinator", ".", "outlier_threshold", "\n", "Agent", ".", "agent_id", "+=", "1", "\n", "self", ".", "centroid", "=", "np", ".", "zeros", "(", "768", ")", "\n", "self", ".", "weight", "=", "0", "\n", "self", ".", "dp_ids", "=", "[", "]", "\n", "self", ".", "coordinator", "=", "coordinator", "\n", "self", ".", "generic_distance_function", "=", "generic_distance_function", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.add_data_point": [[21, 31], ["Agent.Agent.dp_ids.append"], "methods", ["None"], ["", "def", "add_data_point", "(", "self", ",", "dp", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        adding dp to the agent\n        :param dp: dp we want to add to the agent\n        :return: None\n        \"\"\"", "\n", "self", ".", "weight", "+=", "1", "\n", "self", ".", "centroid", "=", "(", "self", ".", "centroid", "+", "dp", ".", "embedding_vec", ")", "/", "2", "\n", "self", ".", "dp_ids", ".", "append", "(", "dp", ".", "dp_id", ")", "\n", "self", ".", "coordinator", ".", "dp_id_to_agent_id", "[", "dp", ".", "dp_id", "]", "=", "self", ".", "agent_id", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.remove_data_point": [[32, 52], ["Agent.Agent.dp_ids.remove", "len", "print", "len"], "methods", ["None"], ["", "def", "remove_data_point", "(", "self", ",", "dp_id", ":", "int", ",", "outlier", "=", "False", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        removing data point from agent\n        :param dp_id: dp id\n        :param outlier : Boolean\n        :return: None\n        \"\"\"", "\n", "try", ":", "\n", "            ", "self", ".", "centroid", "=", "(", "self", ".", "centroid", "*", "len", "(", "self", ".", "dp_ids", ")", "-", "self", ".", "coordinator", ".", "data_agent", ".", "data_points", "[", "\n", "dp_id", "]", ".", "embedding_vec", ")", "/", "len", "(", "\n", "self", ".", "dp_ids", ")", "\n", "self", ".", "dp_ids", ".", "remove", "(", "dp_id", ")", "\n", "if", "self", ".", "weight", "<=", "0", ":", "\n", "                ", "self", ".", "weight", "=", "0", "\n", "", "if", "not", "outlier", ":", "\n", "                ", "del", "self", ".", "coordinator", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", "\n", "", "del", "self", ".", "coordinator", ".", "dp_id_to_agent_id", "[", "dp_id", "]", "\n", "\n", "", "except", "ValueError", ":", "\n", "            ", "print", "(", "f'There is no such data point in Agent : {dp_id}'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.get_outliers": [[53, 66], ["Agent.Agent.generic_distance_function", "Agent.Agent.remove_data_point", "outliers_id.append"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.remove_data_point"], ["", "", "def", "get_outliers", "(", "self", ")", "->", "[", "]", ":", "\n", "        ", "\"\"\"\n        getting outliers of agent\n        :return: list of ids of outliers\n        \"\"\"", "\n", "outliers_id", "=", "[", "]", "\n", "for", "dp_id", "in", "self", ".", "dp_ids", ":", "\n", "            ", "dp", "=", "self", ".", "coordinator", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", "\n", "distance", "=", "self", ".", "generic_distance_function", "(", "dp", ".", "embedding_vec", ",", "self", ".", "centroid", ")", "\n", "if", "distance", ">", "self", ".", "outlier_threshold", ":", "\n", "                ", "self", ".", "remove_data_point", "(", "dp_id", ",", "outlier", "=", "True", ")", "\n", "outliers_id", ".", "append", "(", "dp_id", ")", "\n", "", "", "return", "outliers_id", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.get_distance": [[67, 74], ["Agent.Agent.generic_distance_function"], "methods", ["None"], ["", "def", "get_distance", "(", "self", ",", "embedding", ":", "np", ".", "array", ")", ":", "\n", "        ", "\"\"\"\n        calls the function that finds the distance\n        :param embedding: embedding vector of datapoint\n        :return: (float) returns the distance of the dp and this agent\n        \"\"\"", "\n", "return", "self", ".", "generic_distance_function", "(", "embedding", ",", "self", ".", "centroid", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.handle_old_dps": [[75, 85], ["abs", "Utils.get_seconds", "Agent.Agent.remove_data_point"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Utils.get_seconds", "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.remove_data_point"], ["", "def", "handle_old_dps", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        deletes the dps that are older than sliding_window_interval time interval\n        :return: None\n        \"\"\"", "\n", "for", "dp_id", "in", "self", ".", "dp_ids", ":", "\n", "            ", "dp", "=", "self", ".", "coordinator", ".", "data_agent", ".", "data_points", "[", "dp_id", "]", "\n", "if", "abs", "(", "(", "dp", ".", "created_at", "-", "self", ".", "coordinator", ".", "current_date", ")", ".", "total_seconds", "(", ")", ")", ">", "get_seconds", "(", "\n", "self", ".", "coordinator", ".", "sliding_window_interval", ")", ":", "\n", "                ", "self", ".", "remove_data_point", "(", "dp_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Agent.Agent.fade_agent_weight": [[86, 103], ["abs", "Exception", "Agent.Agent.coordinator.remove_agent"], "methods", ["home.repos.pwc.inspect_result.AliNajafi1998_ComStream.labse.Coordinator.Coordinator.remove_agent"], ["", "", "", "def", "fade_agent_weight", "(", "self", ",", "fade_rate", ":", "float", ",", "delete_faded_threshold", ":", "float", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        fade an agent's weight\n        :param fade_rate: the amount to be faded\n        :param delete_faded_threshold: delete the agent if it's weight gets less than this threshold\n        :return: None\n        \"\"\"", "\n", "if", "abs", "(", "fade_rate", ")", "<", "1e-9", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "fade_rate", ">", "1", "or", "fade_rate", "<", "0", "or", "delete_faded_threshold", ">", "1", "or", "delete_faded_threshold", "<", "0", ":", "\n", "                ", "message", "=", "f'Invalid Fade Rate or delete_agent_weight_threshold : {fade_rate, delete_faded_threshold}'", "\n", "raise", "Exception", "(", "message", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "weight", "=", "self", ".", "weight", "*", "(", "1", "-", "fade_rate", ")", "\n", "if", "self", ".", "weight", "<", "delete_faded_threshold", ":", "\n", "                    ", "self", ".", "coordinator", ".", "remove_agent", "(", "self", ".", "agent_id", ")", "\n", "", "", "", "", "", ""]]}