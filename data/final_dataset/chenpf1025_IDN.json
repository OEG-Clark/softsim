{"home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train": [[11, 28], ["model.train", "len", "print", "optimizer.zero_grad", "model", "torch.nll_loss", "F.nll_loss.backward", "optimizer.step", "model.argmax", "output.argmax.eq().sum().item", "data.to", "target.to", "data.size", "F.nll_loss.item", "len", "output.argmax.eq().sum", "len", "output.argmax.eq", "target.view_as"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train"], ["def", "train", "(", "args", ",", "model", ",", "device", ",", "loader", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "loader", ":", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "=", "F", ".", "nll_loss", "(", "output", ",", "target", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "+=", "data", ".", "size", "(", "0", ")", "*", "loss", ".", "item", "(", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "train_loss", "/=", "len", "(", "loader", ".", "dataset", ")", "\n", "print", "(", "'Epoch: {}/{}\\nTraining loss: {:.4f}, Training accuracy: {}/{} ({:.2f}%)'", ".", "format", "(", "\n", "epoch", ",", "args", ".", "epochs", ",", "train_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train_soft": [[30, 47], ["model.train", "len", "print", "optimizer.zero_grad", "model", "loss.nll_loss_soft", "loss.nll_loss_soft.backward", "optimizer.step", "model.argmax", "output.argmax.eq().sum().item", "data.to", "target_soft.to", "target.to", "data.size", "loss.nll_loss_soft.item", "len", "output.argmax.eq().sum", "len", "output.argmax.eq", "target.view_as"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.loss.nll_loss_soft"], ["", "def", "train_soft", "(", "args", ",", "model", ",", "device", ",", "loader", ",", "optimizer", ",", "epoch", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "for", "data", ",", "target_soft", ",", "target", "in", "loader", ":", "\n", "        ", "data", ",", "target_soft", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target_soft", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "=", "nll_loss_soft", "(", "output", ",", "target_soft", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "+=", "data", ".", "size", "(", "0", ")", "*", "loss", ".", "item", "(", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "train_loss", "/=", "len", "(", "loader", ".", "dataset", ")", "\n", "print", "(", "'Epoch: {}/{}\\nTraining loss: {:.4f}, Training accuracy: {}/{} ({:.2f}%)'", ".", "format", "(", "\n", "epoch", ",", "args", ".", "epochs", ",", "train_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train_dac": [[49, 66], ["model.train", "len", "print", "optimizer.zero_grad", "model", "criterion", "criterion.backward", "optimizer.step", "model.argmax", "output.argmax.eq().sum().item", "data.to", "target.to", "data.size", "criterion.item", "len", "output.argmax.eq().sum", "len", "output.argmax.eq", "target.view_as"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train"], ["", "def", "train_dac", "(", "args", ",", "model", ",", "device", ",", "loader", ",", "optimizer", ",", "epoch", ",", "criterion", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "loader", ":", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "=", "criterion", "(", "output", ",", "target", ",", "epoch", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "+=", "data", ".", "size", "(", "0", ")", "*", "loss", ".", "item", "(", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# If the maximum is the last entry, then it means abstained", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "train_loss", "/=", "len", "(", "loader", ".", "dataset", ")", "\n", "print", "(", "'Epoch: {}/{}\\nTraining loss: {:.4f}, Training accuracy: {}/{} ({:.2f}%)'", ".", "format", "(", "\n", "epoch", ",", "args", ".", "epochs", ",", "train_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train_forward": [[68, 85], ["model.train", "len", "print", "optimizer.zero_grad", "model", "loss.forward_loss", "loss.forward_loss.backward", "optimizer.step", "model.argmax", "output.argmax.eq().sum().item", "data.to", "target.to", "data.size", "loss.forward_loss.item", "len", "output.argmax.eq().sum", "len", "output.argmax.eq", "target.view_as"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.loss.forward_loss"], ["", "def", "train_forward", "(", "args", ",", "model", ",", "device", ",", "loader", ",", "optimizer", ",", "epoch", ",", "T", ")", ":", "\n", "    ", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "correct", "=", "0", "\n", "for", "data", ",", "target", "in", "loader", ":", "\n", "        ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "=", "forward_loss", "(", "output", ",", "target", ",", "T", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "train_loss", "+=", "data", ".", "size", "(", "0", ")", "*", "loss", ".", "item", "(", ")", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "train_loss", "/=", "len", "(", "loader", ".", "dataset", ")", "\n", "print", "(", "'Epoch: {}/{}\\nTraining loss: {:.4f}, Training accuracy: {}/{} ({:.2f}%)'", ".", "format", "(", "\n", "epoch", ",", "args", ".", "epochs", ",", "train_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train_ct": [[87, 118], ["print", "model1.train", "model2.train", "round", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "optimizer1.zero_grad", "loss1[].mean().backward", "optimizer1.step", "optimizer2.zero_grad", "loss2[].mean().backward", "optimizer2.step", "data.to", "target.to", "model1", "model2", "torch.nll_loss", "torch.nll_loss", "loss1.detach", "loss2.detach", "output1.argmax", "output2.argmax", "len", "len", "len", "len", "data.size", "loss1[].mean", "loss2[].mean", "loss1.sum().item", "loss2.sum().item", "pred1.eq().sum().item", "pred2.eq().sum().item", "len", "len", "loss1.sum", "loss2.sum", "pred1.eq().sum", "pred2.eq().sum", "pred1.eq", "pred2.eq", "target.view_as", "target.view_as"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train"], ["", "def", "train_ct", "(", "args", ",", "model1", ",", "model2", ",", "device", ",", "loader", ",", "optimizer1", ",", "optimizer2", ",", "epoch", ",", "p_keep", ")", ":", "\n", "    ", "model1", ".", "train", "(", ")", ",", "model2", ".", "train", "(", ")", "\n", "train_loss1", ",", "train_loss2", "=", "0", ",", "0", "\n", "correct1", ",", "correct2", "=", "0", ",", "0", "\n", "for", "data", ",", "target", "in", "loader", ":", "\n", "        ", "n_keep", "=", "round", "(", "p_keep", "*", "data", ".", "size", "(", "0", ")", ")", "\n", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output1", ",", "output2", "=", "model1", "(", "data", ")", ",", "model2", "(", "data", ")", "\n", "loss1", ",", "loss2", "=", "F", ".", "nll_loss", "(", "output1", ",", "target", ",", "reduction", "=", "'none'", ")", ",", "F", ".", "nll_loss", "(", "output2", ",", "target", ",", "reduction", "=", "'none'", ")", "\n", "\n", "# selecting #n_keep small loss instances", "\n", "_", ",", "index1", "=", "torch", ".", "sort", "(", "loss1", ".", "detach", "(", ")", ")", "\n", "_", ",", "index2", "=", "torch", ".", "sort", "(", "loss2", ".", "detach", "(", ")", ")", "\n", "index1", ",", "index2", "=", "index1", "[", ":", "n_keep", "]", ",", "index2", "[", ":", "n_keep", "]", "\n", "\n", "# taking a optimization step", "\n", "optimizer1", ".", "zero_grad", "(", ")", "\n", "loss1", "[", "index2", "]", ".", "mean", "(", ")", ".", "backward", "(", ")", "\n", "optimizer1", ".", "step", "(", ")", "\n", "optimizer2", ".", "zero_grad", "(", ")", "\n", "loss2", "[", "index1", "]", ".", "mean", "(", ")", ".", "backward", "(", ")", "\n", "optimizer2", ".", "step", "(", ")", "\n", "\n", "train_loss1", ",", "train_loss2", "=", "train_loss1", "+", "loss1", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "train_loss2", "+", "loss2", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "pred1", ",", "pred2", "=", "output1", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ",", "output2", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct1", ",", "correct2", "=", "correct1", "+", "pred1", ".", "eq", "(", "target", ".", "view_as", "(", "pred1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "correct2", "+", "pred2", ".", "eq", "(", "target", ".", "view_as", "(", "pred2", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "train_loss1", ",", "train_loss2", "=", "train_loss1", "/", "len", "(", "loader", ".", "dataset", ")", ",", "train_loss2", "/", "len", "(", "loader", ".", "dataset", ")", "\n", "print", "(", "'Epoch: {}/{}\\nModel1 Training. Training loss: {:.4f}, Training accuracy: {}/{} ({:.2f}%)\\nModel2 Training. Training loss: {:.4f}, Training accuracy: {}/{} ({:.2f}%)'", ".", "format", "(", "\n", "epoch", ",", "args", ".", "epochs", ",", "\n", "train_loss1", ",", "correct1", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct1", "/", "len", "(", "loader", ".", "dataset", ")", ",", "\n", "train_loss2", ",", "correct2", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct2", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test": [[120, 143], ["model.eval", "len", "torch.no_grad", "torch.no_grad", "print", "print", "model", "torch.nll_loss().item", "model.argmax", "output.argmax.eq().sum().item", "data.to", "target.to", "model.topk", "output.argmax.eq().sum().item", "len", "len", "len", "torch.nll_loss", "output.argmax.eq().sum", "len", "len", "len", "output.argmax.eq().sum", "output.argmax.eq", "target.view_as", "output.argmax.eq", "target.view"], "function", ["None"], ["", "def", "test", "(", "args", ",", "model", ",", "device", ",", "loader", ",", "top5", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "correct_k", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "test_loss", "+=", "F", ".", "nll_loss", "(", "output", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "top5", ":", "\n", "                ", "_", ",", "pred", "=", "output", ".", "topk", "(", "5", ",", "1", ",", "True", ",", "True", ")", "\n", "correct_k", "+=", "pred", ".", "eq", "(", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "", "test_loss", "/=", "len", "(", "loader", ".", "dataset", ")", "\n", "if", "top5", ":", "\n", "        ", "print", "(", "'Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%), Top5 Testing accuracy: {}/{} [{:.2f}%]\\n'", ".", "format", "(", "\n", "test_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ",", "correct_k", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct_k", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%)\\n'", ".", "format", "(", "\n", "test_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.val_test": [[145, 180], ["model.eval", "print", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.save", "torch.save", "model", "torch.nll_loss().item", "model.argmax", "output.argmax.eq().sum().item", "len", "len", "model", "torch.nll_loss().item", "model.argmax", "output.argmax.eq().sum().item", "len", "len", "model.state_dict", "data.to", "target.to", "data.to", "target.to", "torch.nll_loss", "output.argmax.eq().sum", "torch.nll_loss", "output.argmax.eq().sum", "output.argmax.eq", "output.argmax.eq", "target.view_as", "target.view_as"], "function", ["None"], ["", "", "def", "val_test", "(", "args", ",", "model", ",", "device", ",", "val_loader", ",", "test_loader", ",", "best_val_acc", ",", "save_path", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "\n", "# val", "\n", "loss", "=", "0", "\n", "correct", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "val_loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "+=", "F", ".", "nll_loss", "(", "output", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "val_loss", ",", "val_acc", "=", "loss", "/", "len", "(", "val_loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "val_loader", ".", "dataset", ")", "\n", "\n", "# test", "\n", "loss", "=", "0", "\n", "correct", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "test_loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "loss", "+=", "F", ".", "nll_loss", "(", "output", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "test_loss", ",", "test_acc", "=", "loss", "/", "len", "(", "test_loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "test_loader", ".", "dataset", ")", "\n", "\n", "if", "val_acc", ">", "best_val_acc", ":", "\n", "        ", "best_val_acc", "=", "val_acc", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "save_path", ")", "\n", "\n", "", "print", "(", "'Val loss: {:.4f}, Testing loss: {:.4f}, Val accuracy: {:.2f}%, Best Val accuracy: {:.2f}%, Testing accuracy: {:.2f}%\\n'", ".", "format", "(", "\n", "val_loss", ",", "test_loss", ",", "val_acc", ",", "best_val_acc", ",", "test_acc", ")", ")", "\n", "\n", "return", "best_val_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test_dac": [[183, 205], ["model.eval", "len", "torch.no_grad", "torch.no_grad", "print", "print", "model", "criterion().item", "model.argmax", "output.argmax.eq().sum().item", "data.to", "target.to", "model.topk", "output.argmax.eq().sum().item", "len", "len", "len", "criterion", "output.argmax.eq().sum", "len", "len", "len", "output.argmax.eq().sum", "output.argmax.eq", "target.view_as", "output.argmax.eq", "target.view"], "function", ["None"], ["", "def", "test_dac", "(", "args", ",", "model", ",", "device", ",", "loader", ",", "epoch", ",", "criterion", ",", "top5", "=", "False", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "correct_k", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "data", ")", "\n", "test_loss", "+=", "criterion", "(", "output", ",", "target", ",", "epoch", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "pred", "=", "output", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# If the maximum is the last entry, then it means abstained", "\n", "correct", "+=", "pred", ".", "eq", "(", "target", ".", "view_as", "(", "pred", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "top5", ":", "\n", "                ", "_", ",", "pred", "=", "output", ".", "topk", "(", "5", ",", "1", ",", "True", ",", "True", ")", "\n", "correct_k", "+=", "pred", ".", "eq", "(", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "", "", "test_loss", "/=", "len", "(", "loader", ".", "dataset", ")", "\n", "if", "top5", ":", "\n", "        ", "print", "(", "'Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%), Top5 Testing accuracy: {}/{} [{:.2f}%]\\n'", ".", "format", "(", "\n", "test_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ",", "correct_k", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct_k", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%)\\n'", ".", "format", "(", "\n", "test_loss", ",", "correct", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test_ct": [[206, 233], ["model1.eval", "model2.eval", "torch.no_grad", "torch.no_grad", "print", "print", "len", "len", "data.to", "target.to", "model1", "model2", "output1.argmax", "output2.argmax", "output1.topk", "pred1.eq().sum().item", "output2.topk", "pred2.eq().sum().item", "len", "len", "len", "len", "len", "len", "torch.nll_loss().item", "torch.nll_loss().item", "pred1.eq().sum().item", "pred2.eq().sum().item", "len", "len", "len", "len", "len", "len", "pred1.eq().sum", "pred2.eq().sum", "torch.nll_loss", "torch.nll_loss", "pred1.eq().sum", "pred2.eq().sum", "pred1.eq", "pred2.eq", "pred1.eq", "pred2.eq", "target.view", "target.view", "target.view_as", "target.view_as"], "function", ["None"], ["", "", "def", "test_ct", "(", "args", ",", "model1", ",", "model2", ",", "device", ",", "loader", ",", "top5", "=", "False", ")", ":", "\n", "    ", "model1", ".", "eval", "(", ")", ",", "model2", ".", "eval", "(", ")", "\n", "test_loss1", ",", "test_loss2", "=", "0", ",", "0", "\n", "correct1", ",", "correct2", "=", "0", ",", "0", "\n", "correct1_k", ",", "correct2_k", "=", "0", ",", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "target", "in", "loader", ":", "\n", "            ", "data", ",", "target", "=", "data", ".", "to", "(", "device", ")", ",", "target", ".", "to", "(", "device", ")", "\n", "output1", ",", "output2", "=", "model1", "(", "data", ")", ",", "model2", "(", "data", ")", "\n", "test_loss1", ",", "test_loss2", "=", "test_loss1", "+", "F", ".", "nll_loss", "(", "output1", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "item", "(", ")", ",", "test_loss2", "+", "F", ".", "nll_loss", "(", "output2", ",", "target", ",", "reduction", "=", "'sum'", ")", ".", "item", "(", ")", "# sum up batch loss", "\n", "pred1", ",", "pred2", "=", "output1", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ",", "output2", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# get the index of the max log-probability", "\n", "correct1", ",", "correct2", "=", "correct1", "+", "pred1", ".", "eq", "(", "target", ".", "view_as", "(", "pred1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", ",", "correct2", "+", "pred2", ".", "eq", "(", "target", ".", "view_as", "(", "pred2", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "if", "top5", ":", "\n", "                ", "_", ",", "pred1", "=", "output1", ".", "topk", "(", "5", ",", "1", ",", "True", ",", "True", ")", "\n", "correct1_k", "+=", "pred1", ".", "eq", "(", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "_", ",", "pred2", "=", "output2", ".", "topk", "(", "5", ",", "1", ",", "True", ",", "True", ")", "\n", "correct2_k", "+=", "pred2", ".", "eq", "(", "target", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "", "", "test_loss1", ",", "test_loss2", "=", "test_loss1", "/", "len", "(", "loader", ".", "dataset", ")", ",", "test_loss2", "/", "len", "(", "loader", ".", "dataset", ")", "\n", "if", "top5", ":", "\n", "        ", "print", "(", "'Model1 Testing. Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%), Top5 Testing accuracy: {}/{} [{:.2f}%]\\nModel2 Testing. Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%), Top5 Testing accuracy: {}/{} [{:.2f}%]\\n'", ".", "format", "(", "\n", "test_loss1", ",", "correct1", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct1", "/", "len", "(", "loader", ".", "dataset", ")", ",", "correct1_k", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct1_k", "/", "len", "(", "loader", ".", "dataset", ")", ",", "\n", "test_loss2", ",", "correct2", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct2", "/", "len", "(", "loader", ".", "dataset", ")", ",", "correct2_k", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct2_k", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "'Model1 Testing. Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%)\\nModel2 Testing. Testing loss: {:.4f}, Testing accuracy: {}/{} ({:.2f}%)\\n'", ".", "format", "(", "\n", "test_loss1", ",", "correct1", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct1", "/", "len", "(", "loader", ".", "dataset", ")", ",", "\n", "test_loss2", ",", "correct2", ",", "len", "(", "loader", ".", "dataset", ")", ",", "100.", "*", "correct2", "/", "len", "(", "loader", ".", "dataset", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.compute_CSR": [[235, 284], ["model.train", "torch.autograd.Variable().to", "x.to.to", "model().argmax", "range", "len", "torch.autograd.Variable().to", "torch.max.retain_grad", "model", "model.zero_grad", "cost.backward", "numpy.random.normal", "torch.max.grad.sign_", "torch.max", "torch.max", "model().argmax.view().eq().view", "pred_on_x.view().eq().view.sum().item", "torch.autograd.Variable", "model", "torch.nll_loss", "print", "torch.max.grad.data.fill_", "torch.min", "torch.min", "torch.autograd.Variable", "model().argmax.view().eq", "pred_on_x.view().eq().view.sum", "model().argmax.size", "model().argmax", "torch.max.cpu", "model().argmax.view", "model"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train"], ["", "", "def", "compute_CSR", "(", "args", ",", "model", ",", "device", ",", "loader", ",", "alpha", "=", "0.25", "/", "255", ",", "beta", "=", "0.2", "/", "255", ",", "r", "=", "0.3", "/", "255", ",", "max_iter", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Refference: Langevin Adversarial Sample Search (LASS) algorithm in the paper 'A Closer Look at Memorization in Deep Networks' <https://arxiv.org/abs/1706.05394>.\n    \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "\n", "count_cs", "=", "0", "\n", "for", "x", ",", "_", "in", "loader", ":", "\n", "\n", "        ", "x_hat", "=", "Variable", "(", "x", ".", "data", ",", "requires_grad", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "x", "=", "x", ".", "to", "(", "device", ")", "\n", "pred_on_x", "=", "model", "(", "x", ")", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "\n", "for", "i", "in", "range", "(", "max_iter", ")", ":", "\n", "# compute gradient on x_hat", "\n", "            ", "x_hat", "=", "Variable", "(", "x_hat", ".", "cpu", "(", ")", ".", "data", ",", "requires_grad", "=", "True", ")", ".", "to", "(", "device", ")", "\n", "x_hat", ".", "retain_grad", "(", ")", "\n", "output_on_x_hat", "=", "model", "(", "x_hat", ")", "\n", "cost", "=", "-", "F", ".", "nll_loss", "(", "output_on_x_hat", ",", "pred_on_x", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "if", "x_hat", ".", "grad", "is", "not", "None", ":", "\n", "                ", "print", "(", "'fill 0 to grad'", ")", "\n", "x_hat", ".", "grad", ".", "data", ".", "fill_", "(", "0", ")", "\n", "", "cost", ".", "backward", "(", ")", "\n", "\n", "# take a step", "\n", "noise", "=", "np", ".", "random", ".", "normal", "(", ")", "\n", "x_hat", ".", "grad", ".", "sign_", "(", ")", "\n", "x_hat", "=", "x_hat", "-", "(", "alpha", "*", "x_hat", ".", "grad", "+", "beta", "*", "noise", ")", "\n", "\n", "# projec back to the box", "\n", "x_hat", "=", "torch", ".", "max", "(", "torch", ".", "min", "(", "x_hat", ",", "x", "+", "r", ")", ",", "x", "-", "r", ")", "\n", "\n", "# check is adversial", "\n", "index_not_adv", "=", "pred_on_x", ".", "view", "(", "-", "1", ",", "1", ")", ".", "eq", "(", "model", "(", "x_hat", ")", ".", "argmax", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", ".", "view", "(", "-", "1", ")", "\n", "num_not_adv", "=", "index_not_adv", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "# record number of adversial samples", "\n", "count_cs", "=", "count_cs", "+", "(", "pred_on_x", ".", "size", "(", "0", ")", "-", "num_not_adv", ")", "\n", "# print('count_cs: {}, num_not_adv: {}'.format(count_cs, num_not_adv))", "\n", "if", "num_not_adv", ">", "0", ":", "\n", "                ", "x_hat", "=", "x_hat", "[", "index_not_adv", "]", "#.unsqueeze(1)", "\n", "x", "=", "x", "[", "index_not_adv", "]", "#.unsqueeze(1)", "\n", "pred_on_x", "=", "pred_on_x", "[", "index_not_adv", "]", "#.view(-1)", "\n", "", "else", ":", "\n", "                ", "break", "\n", "\n", "", "", "", "return", "count_cs", "/", "len", "(", "loader", ".", "dataset", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.mnist_gen_dependent.main": [[14, 78], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.cuda.is_available", "torch.cuda.is_available", "numpy.load", "print", "networks.cnn_mnist.MNIST_CNN().to", "torch.SGD", "numpy.zeros", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "numpy.save", "print", "numpy.array", "range", "np.array.copy", "os.path.join", "pandas.DataFrame.from_dict().to_csv", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "MNIST_CNN().to.parameters", "ops.train", "ops.test", "utils.get_softmax_out", "len", "softmax_out_avg[].copy", "label_noisy_cand.append", "label_noisy_prob.append", "numpy.argsort", "numpy.array", "str", "networks.cnn_mnist.MNIST_CNN", "len", "numpy.argmax", "numpy.max", "pandas.DataFrame.from_dict", "int", "str", "len"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.utils.get_softmax_out"], ["def", "main", "(", ")", ":", "\n", "# Settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch MNIST'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'input batch size for training (default: 64)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "20", ",", "help", "=", "'number of epochs to train (default: 20)'", ")", "# On clean data, 20 is sufficiently large to achiece 100% training accuracy.", "\n", "parser", ".", "add_argument", "(", "'--gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'index of gpu to use (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'learning rate (default: 0.01)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'SGD momentum (default: 0.5)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'random seed (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_rate'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Noise rate (default: 0.0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--load'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'Load existing averaged softmax'", ")", "\n", "parser", ".", "add_argument", "(", "'--gen'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'Generate noisy labels'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "args", ".", "gpu_id", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "# Datasets", "\n", "root", "=", "'./data'", "\n", "kwargs", "=", "{", "'num_workers'", ":", "4", ",", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "]", ")", "#0.1307, 0.3081 are the mean and std of mnist", "\n", "train_dataset", "=", "datasets", ".", "MNIST", "(", "root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "MNIST", "(", "root", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "if", "args", ".", "load", ":", "\n", "        ", "softmax_out_avg", "=", "np", ".", "load", "(", "'data/MNIST/label_noisy/softmax_out_avg.npy'", ")", "\n", "print", "(", "'softmax_out_avg loaded, shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "", "else", ":", "\n", "# Building model", "\n", "        ", "model", "=", "MNIST_CNN", "(", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "momentum", "=", "args", ".", "momentum", ")", "\n", "\n", "# Training", "\n", "softmax_out_avg", "=", "np", ".", "zeros", "(", "[", "len", "(", "train_dataset", ")", ",", "10", "]", ")", "\n", "softmax_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "softmax_out_avg", "+=", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", "\n", "\n", "", "softmax_out_avg", "/=", "args", ".", "epochs", "\n", "np", ".", "save", "(", "'data/MNIST/label_noisy/softmax_out_avg.npy'", ",", "softmax_out_avg", ")", "\n", "\n", "", "if", "args", ".", "gen", ":", "\n", "        ", "print", "(", "'Generating noisy labels according to softmax_out_avg...'", ")", "\n", "label", "=", "np", ".", "array", "(", "train_dataset", ".", "targets", ")", "\n", "label_noisy_cand", ",", "label_noisy_prob", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "label", ")", ")", ":", "\n", "            ", "pred", "=", "softmax_out_avg", "[", "i", ",", ":", "]", ".", "copy", "(", ")", "\n", "pred", "[", "label", "[", "i", "]", "]", "=", "-", "1", "\n", "label_noisy_cand", ".", "append", "(", "np", ".", "argmax", "(", "pred", ")", ")", "\n", "label_noisy_prob", ".", "append", "(", "np", ".", "max", "(", "pred", ")", ")", "\n", "\n", "", "label_noisy", "=", "label", ".", "copy", "(", ")", "\n", "index", "=", "np", ".", "argsort", "(", "label_noisy_prob", ")", "[", "-", "int", "(", "args", ".", "noise_rate", "*", "len", "(", "label", ")", ")", ":", "]", "\n", "label_noisy", "[", "index", "]", "=", "np", ".", "array", "(", "label_noisy_cand", ")", "[", "index", "]", "\n", "\n", "save_pth", "=", "os", ".", "path", ".", "join", "(", "'./data/MNIST/label_noisy'", ",", "'dependent'", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'.csv'", ")", "\n", "pd", ".", "DataFrame", ".", "from_dict", "(", "{", "'label'", ":", "label", ",", "'label_noisy'", ":", "label_noisy", "}", ")", ".", "to_csv", "(", "save_pth", ",", "index", "=", "False", ")", "\n", "print", "(", "'Noisy label data saved to '", ",", "save_pth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.train_mnist.main": [[14, 103], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torchvision.transforms.Compose", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torchvision.datasets.MNIST", "torch.Tensor", "torch.Tensor", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.path.join", "torch.cuda.is_available", "torch.cuda.is_available", "[].values.astype", "os.path.isdir", "os.makedirs", "networks.cnn_mnist.MNIST_CNN().to", "torch.SGD", "numpy.zeros", "range", "numpy.load", "print", "dataset.MNIST_soft", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "networks.cnn_mnist.MNIST_CNN().to", "torch.SGD", "numpy.zeros", "range", "torch.cuda.is_available", "torch.cuda.is_available", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "str", "MNIST_CNN().to.parameters", "ops.train", "ops.test", "utils.get_softmax_out", "os.path.join", "numpy.save", "print", "os.path.join", "os.path.join", "MNIST_CNN().to.parameters", "ops.train_soft", "ops.test", "utils.get_softmax_out", "os.path.join", "numpy.save", "print", "str", "networks.cnn_mnist.MNIST_CNN", "len", "torch.Tensor", "torch.Tensor", "networks.cnn_mnist.MNIST_CNN", "len", "np.zeros.copy", "pandas.read_csv", "str", "str", "str", "str", "os.path.join", "str", "str", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.utils.get_softmax_out", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train_soft", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.utils.get_softmax_out"], ["def", "main", "(", ")", ":", "\n", "# Settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch MNIST'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "64", ",", "help", "=", "'input batch size for training (default: 64)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "help", "=", "'number of epochs to train (default: 50)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'index of gpu to use (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.01", ",", "help", "=", "'learning rate (default: 0.01)'", ")", "\n", "parser", ".", "add_argument", "(", "'--momentum'", ",", "type", "=", "float", ",", "default", "=", "0.5", ",", "help", "=", "'SGD momentum (default: 0.5)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'random seed (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_pattern'", ",", "type", "=", "str", ",", "default", "=", "'dependent'", ",", "help", "=", "'Noise pattern (default: dependent)'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_rate'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Noise rate (default: 0.0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'For saving softmax_out_avg'", ")", "\n", "parser", ".", "add_argument", "(", "'--SEAL'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Phase of self-evolution'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "args", ".", "gpu_id", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "# Datasets", "\n", "root", "=", "'./data'", "\n", "kwargs", "=", "{", "'num_workers'", ":", "4", ",", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "transform", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "transforms", ".", "Normalize", "(", "(", "0.1307", ",", ")", ",", "(", "0.3081", ",", ")", ")", "]", ")", "#0.1307, 0.3081 are the mean and std of mnist", "\n", "train_dataset", "=", "datasets", ".", "MNIST", "(", "root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform", ")", "\n", "train_dataset_noisy", "=", "datasets", ".", "MNIST", "(", "root", ",", "train", "=", "True", ",", "transform", "=", "transform", ")", "\n", "test_dataset", "=", "datasets", ".", "MNIST", "(", "root", ",", "train", "=", "False", ",", "transform", "=", "transform", ")", "\n", "\n", "targets_noisy", "=", "torch", ".", "Tensor", "(", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "'./data/MNIST/label_noisy'", ",", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'.csv'", ")", ")", "[", "'label_noisy'", "]", ".", "values", ".", "astype", "(", "int", ")", ")", "\n", "train_dataset_noisy", ".", "targets", "=", "targets_noisy", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_noisy", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "softmax_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_noisy", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "# results", "\n", "results_root", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "'mnist_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "results_root", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "results_root", ")", "\n", "\n", "", "\"\"\" Get softmax_out_avg - normal training on noisy labels \"\"\"", "\n", "if", "args", ".", "SEAL", "==", "0", ":", "\n", "# Building model", "\n", "        ", "model", "=", "MNIST_CNN", "(", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "momentum", "=", "args", ".", "momentum", ")", "\n", "\n", "# Training", "\n", "softmax_out_avg", "=", "np", ".", "zeros", "(", "[", "len", "(", "train_dataset_noisy", ")", ",", "10", "]", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "softmax_out_avg", "+=", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", "\n", "\n", "", "softmax_out_avg", "/=", "args", ".", "epochs", "\n", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_normal.npy'", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out_avg", ")", "\n", "print", "(", "'new softmax_out_avg saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "", "", "\"\"\" Self Evolution - training on softmax_out_avg \"\"\"", "\n", "if", "args", ".", "SEAL", ">=", "1", ":", "\n", "# Loading softmax_out_avg of last phase", "\n", "        ", "if", "args", ".", "SEAL", "==", "1", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_normal.npy'", ")", "\n", "", "else", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_SEAL'", "+", "str", "(", "args", ".", "SEAL", "-", "1", ")", "+", "'.npy'", ")", "\n", "", "softmax_out_avg", "=", "np", ".", "load", "(", "softmax_root", ")", "\n", "print", "(", "'softmax_out_avg loaded from'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "# Dataset with soft targets", "\n", "train_dataset_soft", "=", "MNIST_soft", "(", "root", ",", "targets_soft", "=", "torch", ".", "Tensor", "(", "softmax_out_avg", ".", "copy", "(", ")", ")", ",", "train", "=", "True", ",", "transform", "=", "transform", ")", "\n", "train_dataset_soft", ".", "targets", "=", "targets_noisy", "\n", "train_loader_soft", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_soft", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "# Building model", "\n", "model", "=", "MNIST_CNN", "(", ")", ".", "to", "(", "device", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "args", ".", "lr", ",", "momentum", "=", "args", ".", "momentum", ")", "\n", "\n", "# Training ", "\n", "softmax_out_avg", "=", "np", ".", "zeros", "(", "[", "len", "(", "train_dataset_noisy", ")", ",", "10", "]", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "train_soft", "(", "args", ",", "model", ",", "device", ",", "train_loader_soft", ",", "optimizer", ",", "epoch", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "softmax_out_avg", "+=", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", "\n", "\n", "", "softmax_out_avg", "/=", "args", ".", "epochs", "\n", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_SEAL'", "+", "str", "(", "args", ".", "SEAL", ")", "+", "'.npy'", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out_avg", ")", "\n", "print", "(", "'new softmax_out_avg saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.cifar10_gen_dependent.main": [[14, 94], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.cuda.is_available", "torch.cuda.is_available", "numpy.load", "print", "networks.wideresnet.Wide_ResNet().to", "numpy.zeros", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "range", "numpy.save", "print", "numpy.array", "range", "np.array.copy", "os.path.join", "pandas.DataFrame.from_dict().to_csv", "print", "torch.cuda.is_available", "torch.cuda.is_available", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "math.pow", "torch.SGD", "ops.train", "ops.test", "utils.get_softmax_out", "len", "softmax_out_avg[].copy", "label_noisy_cand.append", "label_noisy_prob.append", "numpy.argsort", "numpy.array", "str", "networks.wideresnet.Wide_ResNet", "len", "Wide_ResNet().to.parameters", "numpy.argmax", "numpy.max", "pandas.DataFrame.from_dict", "cifar10_gen_dependent.main.learning_rate"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.utils.get_softmax_out"], ["def", "main", "(", ")", ":", "\n", "# Settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch cifar10'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size for training (default: 128)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "help", "=", "'number of epochs to train (default: 150)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'index of gpu to use (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'init learning rate (default: 0.1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dp'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'dropout rate (default: 0.3)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'random seed (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_rate'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Noise rate (default: 0.0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--load'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'Load existing averaged softmax'", ")", "\n", "parser", ".", "add_argument", "(", "'--gen'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'Generate noisy labels'", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "args", ".", "gpu_id", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "# Datasets", "\n", "root", "=", "'./data/CIFAR10'", "\n", "kwargs", "=", "{", "'num_workers'", ":", "4", ",", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", "]", ")", "\n", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", "]", ")", "\n", "\n", "train_dataset", "=", "datasets", ".", "CIFAR10", "(", "root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform_train", ")", "\n", "test_dataset", "=", "datasets", ".", "CIFAR10", "(", "root", ",", "train", "=", "False", ",", "transform", "=", "transform_test", ")", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "def", "learning_rate", "(", "lr_init", ",", "epoch", ")", ":", "\n", "        ", "optim_factor", "=", "0", "\n", "if", "(", "epoch", ">", "120", ")", ":", "\n", "            ", "optim_factor", "=", "2", "\n", "", "elif", "(", "epoch", ">", "60", ")", ":", "\n", "            ", "optim_factor", "=", "1", "\n", "", "return", "lr_init", "*", "math", ".", "pow", "(", "0.2", ",", "optim_factor", ")", "\n", "\n", "", "if", "args", ".", "load", ":", "\n", "        ", "softmax_out_avg", "=", "np", ".", "load", "(", "'data/CIFAR10/label_noisy/softmax_out_avg.npy'", ")", "\n", "print", "(", "'softmax_out_avg loaded, shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "", "else", ":", "\n", "# Building model", "\n", "        ", "model", "=", "Wide_ResNet", "(", "depth", "=", "28", ",", "widen_factor", "=", "10", ",", "dropout_rate", "=", "args", ".", "dp", ",", "num_classes", "=", "10", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Training", "\n", "softmax_out_avg", "=", "np", ".", "zeros", "(", "[", "len", "(", "train_dataset", ")", ",", "10", "]", ")", "\n", "softmax_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", "(", "args", ".", "lr", ",", "epoch", ")", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "softmax_out_avg", "+=", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", "\n", "\n", "", "softmax_out_avg", "/=", "args", ".", "epochs", "\n", "np", ".", "save", "(", "'data/CIFAR10/label_noisy/softmax_out_avg.npy'", ",", "softmax_out_avg", ")", "\n", "\n", "", "if", "args", ".", "gen", ":", "\n", "        ", "print", "(", "'Generating noisy labels according to softmax_out_avg...'", ")", "\n", "label", "=", "np", ".", "array", "(", "train_dataset", ".", "targets", ")", "\n", "label_noisy_cand", ",", "label_noisy_prob", "=", "[", "]", ",", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "label", ")", ")", ":", "\n", "            ", "pred", "=", "softmax_out_avg", "[", "i", ",", ":", "]", ".", "copy", "(", ")", "\n", "pred", "[", "label", "[", "i", "]", "]", "=", "-", "1", "\n", "label_noisy_cand", ".", "append", "(", "np", ".", "argmax", "(", "pred", ")", ")", "\n", "label_noisy_prob", ".", "append", "(", "np", ".", "max", "(", "pred", ")", ")", "\n", "\n", "", "label_noisy", "=", "label", ".", "copy", "(", ")", "\n", "index", "=", "np", ".", "argsort", "(", "label_noisy_prob", ")", "[", "-", "int", "(", "args", ".", "noise_rate", "*", "len", "(", "label", ")", ")", ":", "]", "\n", "label_noisy", "[", "index", "]", "=", "np", ".", "array", "(", "label_noisy_cand", ")", "[", "index", "]", "\n", "\n", "save_pth", "=", "os", ".", "path", ".", "join", "(", "'./data/CIFAR10/label_noisy'", ",", "'dependent'", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'.csv'", ")", "\n", "pd", ".", "DataFrame", ".", "from_dict", "(", "{", "'label'", ":", "label", ",", "'label_noisy'", ":", "label_noisy", "}", ")", ".", "to_csv", "(", "save_pth", ",", "index", "=", "False", ")", "\n", "print", "(", "'Noisy label data saved to '", ",", "save_pth", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.train_labels": [[44, 48], ["warnings.warn"], "methods", ["None"], ["@", "property", "\n", "def", "train_labels", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"train_labels has been renamed targets\"", ")", "\n", "return", "self", ".", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.test_labels": [[49, 53], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_labels", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"test_labels has been renamed targets\"", ")", "\n", "return", "self", ".", "targets", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.train_data": [[54, 58], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "train_data", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"train_data has been renamed data\"", ")", "\n", "return", "self", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.test_data": [[59, 63], ["warnings.warn"], "methods", ["None"], ["", "@", "property", "\n", "def", "test_data", "(", "self", ")", ":", "\n", "        ", "warnings", ".", "warn", "(", "\"test_data has been renamed data\"", ")", "\n", "return", "self", ".", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.__init__": [[64, 82], ["torchvision.datasets.vision.VisionDataset.__init__", "torch.load", "dataset.MNIST_soft.download", "dataset.MNIST_soft._check_exists", "RuntimeError", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft.download", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft._check_exists"], ["", "def", "__init__", "(", "self", ",", "root", ",", "targets_soft", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "download", "=", "False", ")", ":", "\n", "        ", "super", "(", "MNIST_soft", ",", "self", ")", ".", "__init__", "(", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", ")", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "targets_soft", "=", "targets_soft", "\n", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "data_file", "=", "self", ".", "training_file", "\n", "", "else", ":", "\n", "            ", "data_file", "=", "self", ".", "test_file", "\n", "", "self", ".", "data", ",", "self", ".", "targets", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "processed_folder", ",", "data_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.__getitem__": [[83, 103], ["PIL.Image.fromarray", "int", "dataset.MNIST_soft.numpy", "dataset.MNIST_soft.transform", "dataset.MNIST_soft.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target_soft", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets_soft", "[", "index", "]", ",", "int", "(", "self", ".", "targets", "[", "index", "]", ")", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ".", "numpy", "(", ")", ",", "mode", "=", "'L'", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target_soft", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.__len__": [[104, 106], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.raw_folder": [[107, 110], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "raw_folder", "(", "self", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'MNIST'", ",", "'raw'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.processed_folder": [[111, 114], ["os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "processed_folder", "(", "self", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "'MNIST'", ",", "'processed'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.class_to_idx": [[115, 118], ["enumerate"], "methods", ["None"], ["", "@", "property", "\n", "def", "class_to_idx", "(", "self", ")", ":", "\n", "        ", "return", "{", "_class", ":", "i", "for", "i", ",", "_class", "in", "enumerate", "(", "self", ".", "classes", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft._check_exists": [[119, 124], ["os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_check_exists", "(", "self", ")", ":", "\n", "        ", "return", "(", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "processed_folder", ",", "\n", "self", ".", "training_file", ")", ")", "and", "\n", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "processed_folder", ",", "\n", "self", ".", "test_file", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.download": [[125, 156], ["dataset.MNIST_soft._check_exists", "torchvision.datasets.utils.makedir_exist_ok", "torchvision.datasets.utils.makedir_exist_ok", "print", "print", "torchvision.datasets.utils.download_and_extract_archive", "read_image_file", "read_label_file", "read_image_file", "read_label_file", "open", "torch.save", "open", "torch.save", "url.rpartition", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft._check_exists"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "\"\"\"Download the MNIST data if it doesn't exist in processed_folder already.\"\"\"", "\n", "\n", "if", "self", ".", "_check_exists", "(", ")", ":", "\n", "            ", "return", "\n", "\n", "", "makedir_exist_ok", "(", "self", ".", "raw_folder", ")", "\n", "makedir_exist_ok", "(", "self", ".", "processed_folder", ")", "\n", "\n", "# download files", "\n", "for", "url", ",", "md5", "in", "self", ".", "resources", ":", "\n", "            ", "filename", "=", "url", ".", "rpartition", "(", "'/'", ")", "[", "2", "]", "\n", "download_and_extract_archive", "(", "url", ",", "download_root", "=", "self", ".", "raw_folder", ",", "filename", "=", "filename", ",", "md5", "=", "md5", ")", "\n", "\n", "# process and save as torch files", "\n", "", "print", "(", "'Processing...'", ")", "\n", "\n", "training_set", "=", "(", "\n", "read_image_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "raw_folder", ",", "'train-images-idx3-ubyte'", ")", ")", ",", "\n", "read_label_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "raw_folder", ",", "'train-labels-idx1-ubyte'", ")", ")", "\n", ")", "\n", "test_set", "=", "(", "\n", "read_image_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "raw_folder", ",", "'t10k-images-idx3-ubyte'", ")", ")", ",", "\n", "read_label_file", "(", "os", ".", "path", ".", "join", "(", "self", ".", "raw_folder", ",", "'t10k-labels-idx1-ubyte'", ")", ")", "\n", ")", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "processed_folder", ",", "self", ".", "training_file", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "training_set", ",", "f", ")", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "processed_folder", ",", "self", ".", "test_file", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "torch", ".", "save", "(", "test_set", ",", "f", ")", "\n", "\n", "", "print", "(", "'Done!'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.MNIST_soft.extra_repr": [[157, 159], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"Split: {}\"", ".", "format", "(", "\"Train\"", "if", "self", ".", "train", "is", "True", "else", "\"Test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft.__init__": [[192, 233], ["torchvision.datasets.vision.VisionDataset.__init__", "numpy.vstack().reshape", "dataset.CIFAR10_soft.data.transpose", "dataset.CIFAR10_soft._load_meta", "dataset.CIFAR10_soft.download", "dataset.CIFAR10_soft._check_integrity", "RuntimeError", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "dataset.CIFAR10_soft.data.append", "numpy.vstack", "pickle.load", "pickle.load", "dataset.CIFAR10_soft.targets.extend", "dataset.CIFAR10_soft.targets.extend"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft._load_meta", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft.download", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft._check_integrity"], ["def", "__init__", "(", "self", ",", "root", ",", "targets_soft", ",", "train", "=", "True", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "\n", "download", "=", "False", ")", ":", "\n", "\n", "        ", "super", "(", "CIFAR10_soft", ",", "self", ")", ".", "__init__", "(", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", ")", "\n", "\n", "self", ".", "train", "=", "train", "# training set or test set", "\n", "self", ".", "targets_soft", "=", "targets_soft", "\n", "\n", "if", "download", ":", "\n", "            ", "self", ".", "download", "(", ")", "\n", "\n", "", "if", "not", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found or corrupted.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "\n", "", "if", "self", ".", "train", ":", "\n", "            ", "downloaded_list", "=", "self", ".", "train_list", "\n", "", "else", ":", "\n", "            ", "downloaded_list", "=", "self", ".", "test_list", "\n", "\n", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n", "# now load the picked numpy arrays", "\n", "for", "file_name", ",", "checksum", "in", "downloaded_list", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "file_name", ")", "\n", "with", "open", "(", "file_path", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                    ", "entry", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "else", ":", "\n", "                    ", "entry", "=", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "data", ".", "append", "(", "entry", "[", "'data'", "]", ")", "\n", "if", "'labels'", "in", "entry", ":", "\n", "                    ", "self", ".", "targets", ".", "extend", "(", "entry", "[", "'labels'", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "targets", ".", "extend", "(", "entry", "[", "'fine_labels'", "]", ")", "\n", "\n", "", "", "", "self", ".", "data", "=", "np", ".", "vstack", "(", "self", ".", "data", ")", ".", "reshape", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "self", ".", "data", "=", "self", ".", "data", ".", "transpose", "(", "(", "0", ",", "2", ",", "3", ",", "1", ")", ")", "# convert to HWC", "\n", "\n", "self", ".", "_load_meta", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft._load_meta": [[234, 246], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "torchvision.datasets.utils.check_integrity", "RuntimeError", "open", "pickle.load", "pickle.load", "enumerate"], "methods", ["None"], ["", "def", "_load_meta", "(", "self", ")", ":", "\n", "        ", "path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root", ",", "self", ".", "base_folder", ",", "self", ".", "meta", "[", "'filename'", "]", ")", "\n", "if", "not", "check_integrity", "(", "path", ",", "self", ".", "meta", "[", "'md5'", "]", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset metadata file not found or corrupted.'", "+", "\n", "' You can use download=True to download it'", ")", "\n", "", "with", "open", "(", "path", ",", "'rb'", ")", "as", "infile", ":", "\n", "            ", "if", "sys", ".", "version_info", "[", "0", "]", "==", "2", ":", "\n", "                ", "data", "=", "pickle", ".", "load", "(", "infile", ")", "\n", "", "else", ":", "\n", "                ", "data", "=", "pickle", ".", "load", "(", "infile", ",", "encoding", "=", "'latin1'", ")", "\n", "", "self", ".", "classes", "=", "data", "[", "self", ".", "meta", "[", "'key'", "]", "]", "\n", "", "self", ".", "class_to_idx", "=", "{", "_class", ":", "i", "for", "i", ",", "_class", "in", "enumerate", "(", "self", ".", "classes", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft.__getitem__": [[247, 267], ["PIL.Image.fromarray", "dataset.CIFAR10_soft.transform", "dataset.CIFAR10_soft.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target) where target is index of the target class.\n        \"\"\"", "\n", "img", ",", "target_soft", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets_soft", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target_soft", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft.__len__": [[268, 270], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft._check_integrity": [[271, 279], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "torchvision.datasets.utils.check_integrity"], "methods", ["None"], ["", "def", "_check_integrity", "(", "self", ")", ":", "\n", "        ", "root", "=", "self", ".", "root", "\n", "for", "fentry", "in", "(", "self", ".", "train_list", "+", "self", ".", "test_list", ")", ":", "\n", "            ", "filename", ",", "md5", "=", "fentry", "[", "0", "]", ",", "fentry", "[", "1", "]", "\n", "fpath", "=", "os", ".", "path", ".", "join", "(", "root", ",", "self", ".", "base_folder", ",", "filename", ")", "\n", "if", "not", "check_integrity", "(", "fpath", ",", "md5", ")", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft.download": [[280, 285], ["dataset.CIFAR10_soft._check_integrity", "torchvision.datasets.utils.download_and_extract_archive", "print"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft._check_integrity"], ["", "def", "download", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_check_integrity", "(", ")", ":", "\n", "            ", "print", "(", "'Files already downloaded and verified'", ")", "\n", "return", "\n", "", "download_and_extract_archive", "(", "self", ".", "url", ",", "self", ".", "root", ",", "filename", "=", "self", ".", "filename", ",", "md5", "=", "self", ".", "tgz_md5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.CIFAR10_soft.extra_repr": [[286, 288], ["None"], "methods", ["None"], ["", "def", "extra_repr", "(", "self", ")", ":", "\n", "        ", "return", "\"Split: {}\"", ".", "format", "(", "\"Train\"", "if", "self", ".", "train", "is", "True", "else", "\"Test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M.__init__": [[292, 308], ["torchvision.datasets.vision.VisionDataset.__init__", "dataset.Clothing1M.flist_reader", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M_soft.flist_reader"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "mode", "=", "'train'", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", "Clothing1M", ",", "self", ")", ".", "__init__", "(", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", ")", "\n", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "flist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations/noisy_train.txt\"", ")", "\n", "", "if", "mode", "==", "'val'", ":", "\n", "            ", "flist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations/clean_val.txt\"", ")", "\n", "", "if", "mode", "==", "'test'", ":", "\n", "            ", "flist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations/clean_test.txt\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "flist", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found or not extracted.'", "+", "\n", "' You can contact the author of Clothing1M for the download link. <Xiao, Tong, et al. (2015). Learning from massive noisy labeled data for image classification>'", ")", "\n", "\n", "", "self", ".", "imlist", "=", "self", ".", "flist_reader", "(", "flist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M.__getitem__": [[310, 321], ["PIL.Image.open().convert", "dataset.Clothing1M.transform", "dataset.Clothing1M.target_transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "impath", ",", "target", "=", "self", ".", "imlist", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "impath", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M.__len__": [[322, 324], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imlist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M.flist_reader": [[325, 334], ["open", "rf.readlines", "line.split", "imlist.append", "int"], "methods", ["None"], ["", "def", "flist_reader", "(", "self", ",", "flist", ")", ":", "\n", "        ", "imlist", "=", "[", "]", "\n", "with", "open", "(", "flist", ",", "'r'", ")", "as", "rf", ":", "\n", "            ", "for", "line", "in", "rf", ".", "readlines", "(", ")", ":", "\n", "                ", "row", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "impath", "=", "self", ".", "root", "+", "'/'", "+", "row", "[", "0", "]", "\n", "imlabel", "=", "row", "[", "1", "]", "\n", "imlist", ".", "append", "(", "(", "impath", ",", "int", "(", "imlabel", ")", ")", ")", "\n", "", "", "return", "imlist", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M_soft.__init__": [[337, 354], ["torchvision.datasets.vision.VisionDataset.__init__", "dataset.Clothing1M_soft.flist_reader", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.exists", "os.path.exists", "os.path.exists", "os.path.exists", "RuntimeError"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M_soft.flist_reader"], ["    ", "def", "__init__", "(", "self", ",", "root", ",", "targets_soft", ",", "mode", "=", "'train'", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", "Clothing1M_soft", ",", "self", ")", ".", "__init__", "(", "root", ",", "transform", "=", "transform", ",", "target_transform", "=", "target_transform", ")", "\n", "\n", "if", "mode", "==", "'train'", ":", "\n", "            ", "flist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations/noisy_train.txt\"", ")", "\n", "", "if", "mode", "==", "'val'", ":", "\n", "            ", "flist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations/clean_val.txt\"", ")", "\n", "", "if", "mode", "==", "'test'", ":", "\n", "            ", "flist", "=", "os", ".", "path", ".", "join", "(", "root", ",", "\"annotations/clean_test.txt\"", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "flist", ")", ":", "\n", "            ", "raise", "RuntimeError", "(", "'Dataset not found or not extracted.'", "+", "\n", "' You can contact the author of Clothing1M for the download link. <Xiao, Tong, et al. (2015). Learning from massive noisy labeled data for image classification>'", ")", "\n", "\n", "", "self", ".", "imlist", "=", "self", ".", "flist_reader", "(", "flist", ")", "\n", "self", ".", "targets_soft", "=", "targets_soft", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M_soft.__getitem__": [[356, 368], ["PIL.Image.open().convert", "dataset.Clothing1M_soft.transform", "dataset.Clothing1M_soft.target_transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "impath", ",", "target", "=", "self", ".", "imlist", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "impath", ")", ".", "convert", "(", "\"RGB\"", ")", "\n", "target_soft", "=", "self", ".", "targets_soft", "[", "index", "]", "\n", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "\n", "", "return", "img", ",", "target_soft", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M_soft.__len__": [[369, 371], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "imlist", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.dataset.Clothing1M_soft.flist_reader": [[372, 381], ["open", "rf.readlines", "line.split", "imlist.append", "int"], "methods", ["None"], ["", "def", "flist_reader", "(", "self", ",", "flist", ")", ":", "\n", "        ", "imlist", "=", "[", "]", "\n", "with", "open", "(", "flist", ",", "'r'", ")", "as", "rf", ":", "\n", "            ", "for", "line", "in", "rf", ".", "readlines", "(", ")", ":", "\n", "                ", "row", "=", "line", ".", "split", "(", "\" \"", ")", "\n", "impath", "=", "self", ".", "root", "+", "'/'", "+", "row", "[", "0", "]", "\n", "imlabel", "=", "row", "[", "1", "]", "\n", "imlist", ".", "append", "(", "(", "impath", ",", "int", "(", "imlabel", ")", ")", ")", "\n", "", "", "return", "imlist", "", "", "", ""]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.loss.dac_loss.__init__": [[24, 42], ["print", "torch.nn.modules.loss._Loss.__init__"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__"], ["\t", "def", "__init__", "(", "self", ",", "model", ",", "learn_epochs", ",", "total_epochs", ",", "use_cuda", "=", "False", ",", "cuda_device", "=", "None", ",", "\n", "alpha_final", "=", "1.0", ",", "alpha_init_factor", "=", "64.", ")", ":", "\n", "\t\t", "print", "(", "\"using dac loss function\\n\"", ")", "\n", "super", "(", "dac_loss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "learn_epochs", "=", "learn_epochs", "\n", "self", ".", "total_epochs", "=", "total_epochs", "\n", "self", ".", "alpha_final", "=", "alpha_final", "\n", "self", ".", "alpha_init_factor", "=", "alpha_init_factor", "\n", "self", ".", "use_cuda", "=", "use_cuda", "\n", "self", ".", "cuda_device", "=", "cuda_device", "\n", "self", ".", "alpha_var", "=", "None", "\n", "self", ".", "alpha_thresh_ewma", "=", "None", "#exponentially weighted moving average for alpha_thresh", "\n", "self", ".", "alpha_thresh", "=", "None", "#instantaneous alpha_thresh", "\n", "self", ".", "ewma_mu", "=", "0.05", "#mu parameter for EWMA; ", "\n", "self", ".", "curr_alpha_factor", "=", "None", "#for alpha initiliazation", "\n", "self", ".", "alpha_inc", "=", "None", "#linear increase factor of alpha during abstention phase", "\n", "self", ".", "alpha_set_epoch", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.loss.dac_loss.__call__": [[44, 107], ["torch.cross_entropy", "torch.cross_entropy", "torch.cross_entropy.mean", "torch.cross_entropy", "torch.cross_entropy", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.cross_entropy", "torch.cross_entropy", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.autograd.Variable", "torch.autograd.Variable", "torch.log_softmax", "torch.log_softmax", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.cross_entropy.mean", "torch.log_softmax", "torch.log_softmax", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "print", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.autograd.Variable", "torch.autograd.Variable", "torch.log", "torch.log", "torch.log", "torch.log", "torch.autograd.Variable", "torch.autograd.Variable", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "input_batch", ",", "target_batch", ",", "epoch", ")", ":", "\n", "\t\t", "if", "epoch", "<=", "self", ".", "learn_epochs", "or", "not", "self", ".", "model", ".", "training", ":", "\n", "#pdb.set_trace()", "\n", "\t\t\t", "loss", "=", "F", ".", "cross_entropy", "(", "input_batch", ",", "target_batch", ",", "reduction", "=", "'none'", ")", "\n", "#return loss.mean()", "\n", "if", "self", ".", "model", ".", "training", ":", "\n", "\t\t\t\t", "h_c", "=", "F", ".", "cross_entropy", "(", "input_batch", "[", ":", ",", "0", ":", "-", "1", "]", ",", "target_batch", ",", "reduction", "=", "'none'", ")", "\n", "p_out", "=", "torch", ".", "exp", "(", "F", ".", "log_softmax", "(", "input_batch", ",", "dim", "=", "1", ")", ")", "\n", "p_out_abstain", "=", "p_out", "[", ":", ",", "-", "1", "]", "\n", "#pdb.set_trace()", "\n", "\n", "#update instantaneous alpha_thresh", "\n", "self", ".", "alpha_thresh", "=", "Variable", "(", "(", "(", "1.", "-", "p_out_abstain", ")", "*", "h_c", ")", ".", "mean", "(", ")", ".", "data", ")", "\n", "#update alpha_thresh_ewma ", "\n", "if", "self", ".", "alpha_thresh_ewma", "is", "None", ":", "\n", "\t\t\t\t\t", "self", ".", "alpha_thresh_ewma", "=", "self", ".", "alpha_thresh", "#Variable(((1. - p_out_abstain)*h_c).mean().data)", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "self", ".", "alpha_thresh_ewma", "=", "Variable", "(", "self", ".", "ewma_mu", "*", "self", ".", "alpha_thresh", ".", "data", "+", "(", "1.", "-", "self", ".", "ewma_mu", ")", "*", "self", ".", "alpha_thresh_ewma", ".", "data", ")", "\n", "", "", "return", "loss", ".", "mean", "(", ")", "\n", "\n", "", "else", ":", "\n", "#calculate cross entropy only over true classes", "\n", "\t\t\t", "h_c", "=", "F", ".", "cross_entropy", "(", "input_batch", "[", ":", ",", "0", ":", "-", "1", "]", ",", "target_batch", ",", "reduce", "=", "False", ")", "\n", "p_out", "=", "torch", ".", "exp", "(", "F", ".", "log_softmax", "(", "input_batch", ",", "dim", "=", "1", ")", ")", "\n", "#probabilities of abstention  class", "\n", "p_out_abstain", "=", "p_out", "[", ":", ",", "-", "1", "]", "\n", "\n", "if", "self", ".", "use_cuda", ":", "\n", "\t\t\t\t", "p_out_abstain", "=", "torch", ".", "min", "(", "p_out_abstain", ",", "\n", "Variable", "(", "torch", ".", "Tensor", "(", "[", "1.", "-", "epsilon", "]", ")", ")", ".", "cuda", "(", "self", ".", "cuda_device", ")", ")", "\n", "", "else", ":", "\n", "\t\t\t\t", "p_out_abstain", "=", "torch", ".", "min", "(", "p_out_abstain", ",", "\n", "Variable", "(", "torch", ".", "Tensor", "(", "[", "1.", "-", "epsilon", "]", ")", ")", ")", "\n", "\n", "#update instantaneous alpha_thresh", "\n", "", "self", ".", "alpha_thresh", "=", "Variable", "(", "(", "(", "1.", "-", "p_out_abstain", ")", "*", "h_c", ")", ".", "mean", "(", ")", ".", "data", ")", "\n", "\n", "try", ":", "\n", "#update alpha_thresh_ewma", "\n", "\t\t\t\t", "if", "self", ".", "alpha_thresh_ewma", "is", "None", ":", "\n", "\t\t\t\t\t", "self", ".", "alpha_thresh_ewma", "=", "self", ".", "alpha_thresh", "\n", "", "else", ":", "\n", "\t\t\t\t\t", "self", ".", "alpha_thresh_ewma", "=", "Variable", "(", "self", ".", "ewma_mu", "*", "self", ".", "alpha_thresh", ".", "data", "+", "(", "1.", "-", "self", ".", "ewma_mu", ")", "*", "self", ".", "alpha_thresh_ewma", ".", "data", ")", "\n", "\n", "\n", "", "if", "self", ".", "alpha_var", "is", "None", ":", "\n", "\t\t\t\t\t", "self", ".", "alpha_var", "=", "Variable", "(", "self", ".", "alpha_thresh_ewma", ".", "data", "/", "self", ".", "alpha_init_factor", ")", "\n", "self", ".", "alpha_inc", "=", "(", "self", ".", "alpha_final", "-", "self", ".", "alpha_var", ".", "data", ")", "/", "(", "self", ".", "total_epochs", "-", "epoch", ")", "\n", "self", ".", "alpha_set_epoch", "=", "epoch", "\n", "\n", "", "else", ":", "\n", "# we only update alpha every epoch", "\n", "\t\t\t\t\t", "if", "epoch", ">", "self", ".", "alpha_set_epoch", ":", "\n", "\t\t\t\t\t\t", "self", ".", "alpha_var", "=", "Variable", "(", "self", ".", "alpha_var", ".", "data", "+", "self", ".", "alpha_inc", ")", "\n", "self", ".", "alpha_set_epoch", "=", "epoch", "\n", "\n", "", "", "loss", "=", "(", "1.", "-", "p_out_abstain", ")", "*", "h_c", "-", "self", ".", "alpha_var", "*", "torch", ".", "log", "(", "1.", "-", "p_out_abstain", ")", "\n", "return", "loss", ".", "mean", "(", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "\t\t\t\t", "print", "(", "e", ")", "", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.loss.nll_loss_soft": [[9, 11], ["torch.mean", "torch.mean", "torch.sum", "torch.sum"], "function", ["None"], ["def", "nll_loss_soft", "(", "input", ",", "target", ")", ":", "\n", "    ", "return", "-", "torch", ".", "mean", "(", "torch", ".", "sum", "(", "target", "*", "input", ",", "dim", "=", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.loss.forward_loss": [[12, 16], ["torch.log", "torch.log", "torch.matmul", "torch.matmul", "torch.mean", "torch.mean", "torch.exp", "torch.exp", "range", "torch.log.size"], "function", ["None"], ["", "def", "forward_loss", "(", "input", ",", "target", ",", "T", ")", ":", "\n", "\t", "input", "=", "torch", ".", "log", "(", "torch", ".", "matmul", "(", "torch", ".", "exp", "(", "input", ")", ",", "T", ")", ")", "\n", "out", "=", "input", "[", "range", "(", "input", ".", "size", "(", "0", ")", ")", ",", "target", "]", "\n", "return", "-", "torch", ".", "mean", "(", "out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.train_clothing.main": [[15, 150], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "dataset.Clothing1M", "dataset.Clothing1M", "dataset.Clothing1M", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.path.join", "torch.cuda.is_available", "torch.cuda.is_available", "networks.resnet.resnet50", "os.path.isdir", "os.makedirs", "networks.resnet.resnet50().to", "networks.resnet.resnet50.load_state_dict", "ops.test", "train_clothing.main.load_pretrain"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.resnet50", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test"], ["def", "main", "(", ")", ":", "\n", "# Settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch Clothing1M'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'input batch size for training (default: 256)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'input batch size for testing (default: 256)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'number of epochs to train (default: 120)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'index of gpu to use (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'init learning rate (default: 0.1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'random seed (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'For saving softmax_out_avg'", ")", "\n", "parser", ".", "add_argument", "(", "'--SEAL'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Phase of self-evolution'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "args", ".", "gpu_id", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "# Datasets", "\n", "root", "=", "'./data/Clothing1M'", "\n", "num_classes", "=", "14", "\n", "kwargs", "=", "{", "'num_workers'", ":", "32", ",", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "256", ",", "256", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "224", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "224", ",", "224", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "\n", "train_dataset", "=", "Clothing1M", "(", "root", ",", "mode", "=", "'train'", ",", "transform", "=", "transform_train", ")", "\n", "val_dataset", "=", "Clothing1M", "(", "root", ",", "mode", "=", "'val'", ",", "transform", "=", "transform_test", ")", "\n", "test_dataset", "=", "Clothing1M", "(", "root", ",", "mode", "=", "'test'", ",", "transform", "=", "transform_test", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "softmax_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "\n", "def", "learning_rate", "(", "lr_init", ",", "epoch", ")", ":", "\n", "        ", "optim_factor", "=", "0", "\n", "if", "(", "epoch", ">", "5", ")", ":", "\n", "            ", "optim_factor", "=", "1", "\n", "", "return", "lr_init", "*", "math", ".", "pow", "(", "0.1", ",", "optim_factor", ")", "\n", "\n", "", "def", "load_pretrain", "(", "num_classes", ",", "device", ")", ":", "\n", "        ", "model_pre", "=", "resnet50", "(", "num_classes", "=", "1000", ",", "pretrained", "=", "True", ")", "# imagenet pretrained, numclasses=1000", "\n", "if", "num_classes", "==", "1000", ":", "\n", "            ", "return", "model_pre", ".", "to", "(", "device", ")", "\n", "\n", "", "else", ":", "\n", "            ", "model", "=", "resnet50", "(", "num_classes", "=", "num_classes", ",", "pretrained", "=", "False", ")", "\n", "params_pre", "=", "model_pre", ".", "state_dict", "(", ")", ".", "copy", "(", ")", "\n", "params", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "i", "in", "params_pre", ":", "\n", "                ", "if", "not", "i", ".", "startswith", "(", "'fc'", ")", ":", "\n", "                    ", "params", "[", "i", "]", "=", "params_pre", "[", "i", "]", "\n", "", "", "model", ".", "load_state_dict", "(", "params", ")", "\n", "return", "model", ".", "to", "(", "device", ")", "\n", "\n", "# results", "\n", "", "", "results_root", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "'clothing'", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "results_root", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "results_root", ")", "\n", "\n", "", "\"\"\" Test model \"\"\"", "\n", "if", "args", ".", "SEAL", "==", "-", "1", ":", "\n", "        ", "model", "=", "resnet50", "(", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed0_clothing_normal.pt'", ")", ")", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "\n", "\n", "", "\"\"\" Get softmax_out_avg - normal training on noisy labels \"\"\"", "\n", "if", "args", ".", "SEAL", "==", "0", ":", "\n", "# Building model", "\n", "        ", "model", "=", "load_pretrain", "(", "num_classes", ",", "device", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", "\n", "\n", "# Training", "\n", "best_val_acc", "=", "0", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_clothing_normal.pt'", ")", "\n", "softmax_out", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", "(", "args", ".", "lr", ",", "epoch", ")", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "1e-3", ")", "\n", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", "\n", "best_val_acc", "=", "val_test", "(", "args", ",", "model", ",", "device", ",", "val_loader", ",", "test_loader", ",", "best_val_acc", ",", "save_path", ")", "\n", "softmax_out", ".", "append", "(", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", ")", "\n", "\n", "", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_normal.npy'", ")", "\n", "softmax_out", "=", "np", ".", "concatenate", "(", "softmax_out", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out", ")", "\n", "print", "(", "'new softmax_out saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out", ".", "shape", ")", "\n", "\n", "\n", "", "", "\"\"\" Self Evolution - training on softmax_out_avg \"\"\"", "\n", "if", "args", ".", "SEAL", ">=", "1", ":", "\n", "        ", "if", "args", ".", "SEAL", "==", "1", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_normal.npy'", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_clothing_normal.pt'", ")", "\n", "", "else", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_SEAL'", "+", "str", "(", "args", ".", "SEAL", "-", "1", ")", "+", "'.npy'", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_clothing_SEAL'", "+", "str", "(", "args", ".", "SEAL", "-", "1", ")", "+", "'.pt'", ")", "\n", "\n", "", "save_path", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_clothing_SEAL'", "+", "str", "(", "args", ".", "SEAL", ")", "+", "'.pt'", ")", "\n", "\n", "# Loading softmax_out_avg of last phase", "\n", "softmax_out_avg", "=", "np", ".", "load", "(", "softmax_root", ")", ".", "reshape", "(", "[", "-", "1", ",", "len", "(", "train_dataset", ")", ",", "num_classes", "]", ")", "\n", "softmax_out_avg", "=", "softmax_out_avg", ".", "mean", "(", "axis", "=", "0", ")", "\n", "print", "(", "'softmax_out_avg loaded from'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "# Dataset with soft targets", "\n", "train_dataset_soft", "=", "Clothing1M_soft", "(", "root", ",", "targets_soft", "=", "torch", ".", "Tensor", "(", "softmax_out_avg", ".", "copy", "(", ")", ")", ",", "mode", "=", "'train'", ",", "transform", "=", "transform_train", ")", "\n", "train_loader_soft", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_soft", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "# Building model", "\n", "model", "=", "load_pretrain", "(", "num_classes", ",", "device", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "print", "(", "'Initialize the model using {}.'", ".", "format", "(", "model_path", ")", ")", "\n", "\n", "# Training", "\n", "best_val_acc", "=", "0", "\n", "softmax_out", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", "(", "args", ".", "lr", ",", "epoch", ")", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "1e-3", ")", "\n", "train_soft", "(", "args", ",", "model", ",", "device", ",", "train_loader_soft", ",", "optimizer", ",", "epoch", ")", "\n", "best_val_acc", "=", "val_test", "(", "args", ",", "model", ",", "device", ",", "val_loader", ",", "test_loader", ",", "best_val_acc", ",", "save_path", ")", "\n", "softmax_out", ".", "append", "(", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", ")", "\n", "\n", "", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_SEAL'", "+", "str", "(", "args", ".", "SEAL", ")", "+", "'.npy'", ")", "\n", "softmax_out", "=", "np", ".", "concatenate", "(", "softmax_out", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out", ")", "\n", "print", "(", "'new softmax_out saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.train_clothing_dmi.main": [[15, 159], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "dataset.Clothing1M", "dataset.Clothing1M", "dataset.Clothing1M", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.path.join", "torch.cuda.is_available", "torch.cuda.is_available", "networks.resnet.resnet50", "os.path.isdir", "os.makedirs", "networks.resnet.resnet50().to", "networks.resnet.resnet50.load_state_dict", "ops.test", "print", "os.path.join", "numpy.load().reshape", "softmax_out_avg[].mean", "print", "dataset.Clothing1M_soft", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "train_clothing_dmi.main.load_pretrain"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.resnet50", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test"], ["def", "main", "(", ")", ":", "\n", "# Settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch Clothing1M'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'input batch size for training (default: 256)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "256", ",", "help", "=", "'input batch size for testing (default: 256)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "10", ",", "help", "=", "'number of epochs to train (default: 120)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'index of gpu to use (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.001", ",", "help", "=", "'init learning rate (default: 0.1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'random seed (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'For saving softmax_out_avg'", ")", "\n", "parser", ".", "add_argument", "(", "'--SEAL'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Phase of self-evolution'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "args", ".", "gpu_id", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "# Datasets", "\n", "root", "=", "'./data/Clothing1M'", "\n", "num_classes", "=", "14", "\n", "kwargs", "=", "{", "'num_workers'", ":", "32", ",", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "256", ",", "256", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "224", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "Resize", "(", "(", "224", ",", "224", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "]", ")", "\n", "\n", "train_dataset", "=", "Clothing1M", "(", "root", ",", "mode", "=", "'train'", ",", "transform", "=", "transform_train", ")", "\n", "val_dataset", "=", "Clothing1M", "(", "root", ",", "mode", "=", "'val'", ",", "transform", "=", "transform_test", ")", "\n", "test_dataset", "=", "Clothing1M", "(", "root", ",", "mode", "=", "'test'", ",", "transform", "=", "transform_test", ")", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "softmax_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "val_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "val_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "\n", "def", "learning_rate", "(", "lr_init", ",", "epoch", ")", ":", "\n", "        ", "optim_factor", "=", "0", "\n", "if", "(", "epoch", ">", "5", ")", ":", "\n", "            ", "optim_factor", "=", "1", "\n", "", "return", "lr_init", "*", "math", ".", "pow", "(", "0.1", ",", "optim_factor", ")", "\n", "\n", "", "def", "load_pretrain", "(", "num_classes", ",", "device", ")", ":", "\n", "        ", "model_pre", "=", "resnet50", "(", "num_classes", "=", "1000", ",", "pretrained", "=", "True", ")", "# imagenet pretrained, numclasses=1000", "\n", "if", "num_classes", "==", "1000", ":", "\n", "            ", "return", "model_pre", ".", "to", "(", "device", ")", "\n", "\n", "", "else", ":", "\n", "            ", "model", "=", "resnet50", "(", "num_classes", "=", "num_classes", ",", "pretrained", "=", "False", ")", "\n", "params_pre", "=", "model_pre", ".", "state_dict", "(", ")", ".", "copy", "(", ")", "\n", "params", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "i", "in", "params_pre", ":", "\n", "                ", "if", "not", "i", ".", "startswith", "(", "'fc'", ")", ":", "\n", "                    ", "params", "[", "i", "]", "=", "params_pre", "[", "i", "]", "\n", "", "", "model", ".", "load_state_dict", "(", "params", ")", "\n", "return", "model", ".", "to", "(", "device", ")", "\n", "\n", "# results", "\n", "", "", "results_root", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "'clothing'", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "results_root", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "results_root", ")", "\n", "\n", "", "\"\"\" Test model \"\"\"", "\n", "if", "args", ".", "SEAL", "==", "-", "1", ":", "\n", "        ", "model", "=", "resnet50", "(", ")", ".", "to", "(", "device", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed0_clothing_normal.pt'", ")", ")", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "\n", "\n", "", "\"\"\" Get softmax_out_avg - normal training on noisy labels \"\"\"", "\n", "if", "args", ".", "SEAL", "==", "0", ":", "\n", "        ", "print", "(", "'The DMI model is trained using the official pytorch implemention of L_DMI <https://github.com/Newbeeer/L_DMI>.\\n'", ")", "\n", "\n", "\n", "", "\"\"\" Self Evolution - training on softmax_out_avg from DMI model \"\"\"", "\n", "if", "args", ".", "SEAL", "==", "1", ":", "\n", "# Loading softmax_out_avg of last phase", "\n", "        ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'softmax_out_dmi.npy'", ")", "\n", "softmax_out_avg", "=", "np", ".", "load", "(", "softmax_root", ")", ".", "reshape", "(", "[", "-", "1", ",", "len", "(", "train_dataset", ")", ",", "num_classes", "]", ")", "\n", "softmax_out_avg", "=", "softmax_out_avg", "[", ":", "5", "]", ".", "mean", "(", "axis", "=", "0", ")", "# We found that the DMI model may not converged in the last 5 epochs.", "\n", "print", "(", "'softmax_out_avg loaded from'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "# Dataset with soft targets", "\n", "train_dataset_soft", "=", "Clothing1M_soft", "(", "root", ",", "targets_soft", "=", "torch", ".", "Tensor", "(", "softmax_out_avg", ".", "copy", "(", ")", ")", ",", "mode", "=", "'train'", ",", "transform", "=", "transform_train", ")", "\n", "train_loader_soft", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_soft", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "# Building model", "\n", "model", "=", "load_pretrain", "(", "num_classes", ",", "device", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "results_root", ",", "'clothing_dmi.pt'", ")", ")", ")", "\n", "print", "(", "'Initialize the model using DMI model.'", ")", "\n", "\n", "# Training", "\n", "best_val_acc", "=", "0", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_clothing_dmi_SEAL1.pt'", ")", "\n", "softmax_out", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", "(", "args", ".", "lr", ",", "epoch", ")", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "1e-3", ")", "\n", "train_soft", "(", "args", ",", "model", ",", "device", ",", "train_loader_soft", ",", "optimizer", ",", "epoch", ")", "\n", "best_val_acc", "=", "val_test", "(", "args", ",", "model", ",", "device", ",", "val_loader", ",", "test_loader", ",", "best_val_acc", ",", "save_path", ")", "\n", "softmax_out", ".", "append", "(", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", ")", "\n", "\n", "", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_dmi_SEAL1.npy'", ")", "\n", "softmax_out", "=", "np", ".", "concatenate", "(", "softmax_out", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out", ")", "\n", "print", "(", "'new softmax_out saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out", ".", "shape", ")", "\n", "\n", "", "", "if", "args", ".", "SEAL", ">=", "2", ":", "\n", "# Loading softmax_out_avg of last phase", "\n", "        ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_dmi_SEAL'", "+", "str", "(", "args", ".", "SEAL", "-", "1", ")", "+", "'.npy'", ")", "\n", "softmax_out_avg", "=", "np", ".", "load", "(", "softmax_root", ")", ".", "reshape", "(", "[", "-", "1", ",", "len", "(", "train_dataset", ")", ",", "num_classes", "]", ")", "\n", "softmax_out_avg", "=", "softmax_out_avg", ".", "mean", "(", "axis", "=", "0", ")", "\n", "print", "(", "'softmax_out_avg loaded from'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "# Dataset with soft targets", "\n", "train_dataset_soft", "=", "Clothing1M_soft", "(", "root", ",", "targets_soft", "=", "torch", ".", "Tensor", "(", "softmax_out_avg", ".", "copy", "(", ")", ")", ",", "mode", "=", "'train'", ",", "transform", "=", "transform_train", ")", "\n", "train_loader_soft", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_soft", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "# Building model", "\n", "model", "=", "load_pretrain", "(", "num_classes", ",", "device", ")", "\n", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ",", "device_ids", "=", "[", "0", ",", "1", ",", "2", ",", "3", "]", ")", "\n", "model_path", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_clothing_dmi_SEAL'", "+", "str", "(", "args", ".", "SEAL", "-", "1", ")", "+", "'.pt'", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "model_path", ")", ")", "\n", "print", "(", "'Initialize the model using {}.'", ".", "format", "(", "model_path", ")", ")", "\n", "\n", "# Training", "\n", "best_val_acc", "=", "0", "\n", "save_path", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_clothing_dmi_SEAL'", "+", "str", "(", "args", ".", "SEAL", ")", "+", "'.pt'", ")", "\n", "softmax_out", "=", "[", "]", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", "(", "args", ".", "lr", ",", "epoch", ")", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "1e-3", ")", "\n", "train_soft", "(", "args", ",", "model", ",", "device", ",", "train_loader_soft", ",", "optimizer", ",", "epoch", ")", "\n", "best_val_acc", "=", "val_test", "(", "args", ",", "model", ",", "device", ",", "val_loader", ",", "test_loader", ",", "best_val_acc", ",", "save_path", ")", "\n", "softmax_out", ".", "append", "(", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", ")", "\n", "\n", "", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_dmi_SEAL'", "+", "str", "(", "args", ".", "SEAL", ")", "+", "'.npy'", ")", "\n", "softmax_out", "=", "np", ".", "concatenate", "(", "softmax_out", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out", ")", "\n", "print", "(", "'new softmax_out saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.utils.get_softmax_out": [[6, 16], ["torch.cat().cpu().numpy", "torch.cat().cpu().numpy", "torch.no_grad", "torch.no_grad", "data.to.to", "torch.cat().cpu", "torch.cat().cpu", "softmax_out.append", "softmax_out.append", "torch.softmax", "torch.exp", "torch.exp", "torch.cat", "torch.cat", "model", "model"], "function", ["None"], ["def", "get_softmax_out", "(", "model", ",", "loader", ",", "device", ",", "is_dac", "=", "False", ")", ":", "\n", "    ", "softmax_out", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "data", ",", "_", "in", "loader", ":", "\n", "            ", "data", "=", "data", ".", "to", "(", "device", ")", "\n", "if", "is_dac", ":", "\n", "                ", "softmax_out", ".", "append", "(", "F", ".", "softmax", "(", "model", "(", "data", ")", "[", ":", ",", ":", "-", "1", "]", ",", "dim", "=", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "softmax_out", ".", "append", "(", "torch", ".", "exp", "(", "model", "(", "data", ")", ")", ")", "\n", "", "", "", "return", "torch", ".", "cat", "(", "softmax_out", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.chenpf1025_IDN.None.train_cifar10.main": [[15, 121], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.manual_seed", "torch.manual_seed", "torch.device", "torch.device", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "list", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "os.path.join", "torch.cuda.is_available", "torch.cuda.is_available", "[].values.astype", "os.path.isdir", "os.makedirs", "networks.wideresnet.Wide_ResNet().to", "numpy.zeros", "range", "numpy.load", "print", "dataset.CIFAR10_soft", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "networks.wideresnet.Wide_ResNet().to", "numpy.zeros", "range", "torch.cuda.is_available", "torch.cuda.is_available", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "math.pow", "str", "torch.SGD", "ops.train", "ops.test", "utils.get_softmax_out", "os.path.join", "numpy.save", "print", "os.path.join", "os.path.join", "torch.SGD", "ops.train_soft", "ops.test", "utils.get_softmax_out", "os.path.join", "numpy.save", "print", "str", "networks.wideresnet.Wide_ResNet", "len", "Wide_ResNet().to.parameters", "torch.Tensor", "torch.Tensor", "networks.wideresnet.Wide_ResNet", "len", "Wide_ResNet().to.parameters", "train_cifar10.main.learning_rate"], "function", ["home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.utils.get_softmax_out", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.train_soft", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.ops.test", "home.repos.pwc.inspect_result.chenpf1025_IDN.None.utils.get_softmax_out"], ["def", "main", "(", ")", ":", "\n", "# Settings", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'PyTorch cifar10'", ")", "\n", "parser", ".", "add_argument", "(", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "'input batch size for training (default: 128)'", ")", "\n", "parser", ".", "add_argument", "(", "'--test_batch_size'", ",", "type", "=", "int", ",", "default", "=", "1000", ",", "help", "=", "'input batch size for testing (default: 1000)'", ")", "\n", "parser", ".", "add_argument", "(", "'--epochs'", ",", "type", "=", "int", ",", "default", "=", "150", ",", "help", "=", "'number of epochs to train (default: 150)'", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'index of gpu to use (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--lr'", ",", "type", "=", "float", ",", "default", "=", "0.1", ",", "help", "=", "'init learning rate (default: 0.1)'", ")", "\n", "parser", ".", "add_argument", "(", "'--dp'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'dropout rate (default: 0.0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'random seed (default: 0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_pattern'", ",", "type", "=", "str", ",", "default", "=", "'dependent'", ",", "help", "=", "'Noise pattern (default: dependent)'", ")", "\n", "parser", ".", "add_argument", "(", "'--noise_rate'", ",", "type", "=", "float", ",", "default", "=", "0.0", ",", "help", "=", "'Noise rate (default: 0.0)'", ")", "\n", "parser", ".", "add_argument", "(", "'--save'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "help", "=", "'For saving softmax_out_avg'", ")", "\n", "parser", ".", "add_argument", "(", "'--SEAL'", ",", "type", "=", "int", ",", "default", "=", "0", ",", "help", "=", "'Phase of self-evolution'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:'", "+", "str", "(", "args", ".", "gpu_id", ")", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "'cpu'", ")", "\n", "\n", "# Datasets", "\n", "root", "=", "'./data/CIFAR10'", "\n", "num_classes", "=", "10", "\n", "kwargs", "=", "{", "'num_workers'", ":", "4", ",", "'pin_memory'", ":", "True", "}", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "{", "}", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "RandomCrop", "(", "32", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", "]", ")", "\n", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.4914", ",", "0.4822", ",", "0.4465", ")", ",", "(", "0.2023", ",", "0.1994", ",", "0.2010", ")", ")", "]", ")", "\n", "\n", "train_dataset", "=", "datasets", ".", "CIFAR10", "(", "root", ",", "train", "=", "True", ",", "download", "=", "True", ",", "transform", "=", "transform_train", ")", "\n", "train_dataset_noisy", "=", "datasets", ".", "CIFAR10", "(", "root", ",", "train", "=", "True", ",", "transform", "=", "transform_train", ")", "\n", "test_dataset", "=", "datasets", ".", "CIFAR10", "(", "root", ",", "train", "=", "False", ",", "transform", "=", "transform_test", ")", "\n", "\n", "targets_noisy", "=", "list", "(", "pd", ".", "read_csv", "(", "os", ".", "path", ".", "join", "(", "'./data/CIFAR10/label_noisy'", ",", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'.csv'", ")", ")", "[", "'label_noisy'", "]", ".", "values", ".", "astype", "(", "int", ")", ")", "\n", "train_dataset_noisy", ".", "targets", "=", "targets_noisy", "\n", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_noisy", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "softmax_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_noisy", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "test_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_dataset", ",", "batch_size", "=", "args", ".", "test_batch_size", ",", "shuffle", "=", "False", ",", "**", "kwargs", ")", "\n", "\n", "\n", "def", "learning_rate", "(", "lr_init", ",", "epoch", ")", ":", "\n", "        ", "optim_factor", "=", "0", "\n", "if", "(", "epoch", ">", "120", ")", ":", "\n", "            ", "optim_factor", "=", "2", "\n", "", "elif", "(", "epoch", ">", "60", ")", ":", "\n", "            ", "optim_factor", "=", "1", "\n", "", "return", "lr_init", "*", "math", ".", "pow", "(", "0.2", ",", "optim_factor", ")", "\n", "\n", "# results", "\n", "", "results_root", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "'cifar10_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "results_root", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "results_root", ")", "\n", "\n", "", "\"\"\" Get softmax_out_avg - normal training on noisy labels \"\"\"", "\n", "if", "args", ".", "SEAL", "==", "0", ":", "\n", "# Building model", "\n", "        ", "model", "=", "Wide_ResNet", "(", "depth", "=", "28", ",", "widen_factor", "=", "10", ",", "dropout_rate", "=", "args", ".", "dp", ",", "num_classes", "=", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Training", "\n", "softmax_out_avg", "=", "np", ".", "zeros", "(", "[", "len", "(", "train_dataset_noisy", ")", ",", "num_classes", "]", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", "(", "args", ".", "lr", ",", "epoch", ")", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "train", "(", "args", ",", "model", ",", "device", ",", "train_loader", ",", "optimizer", ",", "epoch", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "softmax_out_avg", "+=", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", "\n", "\n", "", "softmax_out_avg", "/=", "args", ".", "epochs", "\n", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_normal.npy'", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out_avg", ")", "\n", "print", "(", "'new softmax_out_avg saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "", "", "\"\"\" Self Evolution - training on softmax_out_avg \"\"\"", "\n", "if", "args", ".", "SEAL", ">=", "1", ":", "\n", "# Loading softmax_out_avg of last phase", "\n", "        ", "if", "args", ".", "SEAL", "==", "1", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_normal.npy'", ")", "\n", "", "else", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_SEAL'", "+", "str", "(", "args", ".", "SEAL", "-", "1", ")", "+", "'.npy'", ")", "\n", "", "softmax_out_avg", "=", "np", ".", "load", "(", "softmax_root", ")", "\n", "print", "(", "'softmax_out_avg loaded from'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n", "# Dataset with soft targets", "\n", "train_dataset_soft", "=", "CIFAR10_soft", "(", "root", ",", "targets_soft", "=", "torch", ".", "Tensor", "(", "softmax_out_avg", ".", "copy", "(", ")", ")", ",", "train", "=", "True", ",", "transform", "=", "transform_train", ")", "\n", "train_dataset_soft", ".", "targets", "=", "targets_noisy", "\n", "train_loader_soft", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "train_dataset_soft", ",", "batch_size", "=", "args", ".", "batch_size", ",", "shuffle", "=", "True", ",", "**", "kwargs", ")", "\n", "\n", "# Building model", "\n", "model", "=", "Wide_ResNet", "(", "depth", "=", "28", ",", "widen_factor", "=", "10", ",", "dropout_rate", "=", "args", ".", "dp", ",", "num_classes", "=", "num_classes", ")", ".", "to", "(", "device", ")", "\n", "\n", "# Training ", "\n", "softmax_out_avg", "=", "np", ".", "zeros", "(", "[", "len", "(", "train_dataset_noisy", ")", ",", "num_classes", "]", ")", "\n", "for", "epoch", "in", "range", "(", "1", ",", "args", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "learning_rate", "(", "args", ".", "lr", ",", "epoch", ")", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "5e-4", ")", "\n", "train_soft", "(", "args", ",", "model", ",", "device", ",", "train_loader_soft", ",", "optimizer", ",", "epoch", ")", "\n", "test", "(", "args", ",", "model", ",", "device", ",", "test_loader", ")", "\n", "softmax_out_avg", "+=", "get_softmax_out", "(", "model", ",", "softmax_loader", ",", "device", ")", "\n", "\n", "", "softmax_out_avg", "/=", "args", ".", "epochs", "\n", "if", "args", ".", "save", ":", "\n", "            ", "softmax_root", "=", "os", ".", "path", ".", "join", "(", "results_root", ",", "'seed'", "+", "str", "(", "args", ".", "seed", ")", "+", "'_softmax_out_avg_'", "+", "args", ".", "noise_pattern", "+", "str", "(", "args", ".", "noise_rate", ")", "+", "'_SEAL'", "+", "str", "(", "args", ".", "SEAL", ")", "+", "'.npy'", ")", "\n", "np", ".", "save", "(", "softmax_root", ",", "softmax_out_avg", ")", "\n", "print", "(", "'new softmax_out_avg saved to'", ",", "softmax_root", ",", "', shape: '", ",", "softmax_out_avg", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.cnn_mnist.MNIST_CNN.__init__": [[7, 14], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", "=", "10", ",", "use_log_softmax", "=", "True", ")", ":", "\n", "        ", "super", "(", "MNIST_CNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "20", ",", "5", ",", "1", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "20", ",", "50", ",", "5", ",", "1", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "4", "*", "4", "*", "50", ",", "500", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "500", ",", "num_classes", ")", "\n", "self", ".", "use_log_softmax", "=", "use_log_softmax", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.cnn_mnist.MNIST_CNN.forward": [[15, 27], ["torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.relu", "torch.relu", "torch.relu", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "cnn_mnist.MNIST_CNN.view", "torch.relu", "torch.relu", "torch.relu", "cnn_mnist.MNIST_CNN.fc2", "cnn_mnist.MNIST_CNN.conv1", "cnn_mnist.MNIST_CNN.conv2", "cnn_mnist.MNIST_CNN.fc1", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "2", ",", "2", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "2", ",", "2", ")", "\n", "x", "=", "x", ".", "view", "(", "-", "1", ",", "4", "*", "4", "*", "50", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "fc1", "(", "x", ")", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "if", "self", ".", "use_log_softmax", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.wide_basic.__init__": [[22, 34], ["torch.Module.__init__", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "dropout_rate", ",", "stride", "=", "1", ")", ":", "\n", "        ", "super", "(", "wide_basic", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "in_planes", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout_rate", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "planes", ":", "\n", "            ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "True", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.wide_basic.forward": [[36, 42], ["wideresnet.wide_basic.dropout", "wideresnet.wide_basic.conv2", "wideresnet.wide_basic.shortcut", "wideresnet.wide_basic.conv1", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "wideresnet.wide_basic.bn2", "wideresnet.wide_basic.bn1"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "dropout", "(", "self", ".", "conv1", "(", "F", ".", "relu", "(", "self", ".", "bn1", "(", "x", ")", ")", ")", ")", "\n", "out", "=", "self", ".", "conv2", "(", "F", ".", "relu", "(", "self", ".", "bn2", "(", "out", ")", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.Wide_ResNet.__init__": [[44, 62], ["torch.Module.__init__", "print", "wideresnet.conv3x3", "wideresnet.Wide_ResNet._wide_layer", "wideresnet.Wide_ResNet._wide_layer", "wideresnet.Wide_ResNet._wide_layer", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.conv3x3", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.Wide_ResNet._wide_layer", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.Wide_ResNet._wide_layer", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.Wide_ResNet._wide_layer"], ["    ", "def", "__init__", "(", "self", ",", "depth", ",", "widen_factor", ",", "dropout_rate", ",", "num_classes", ",", "use_log_softmax", "=", "True", ")", ":", "\n", "        ", "super", "(", "Wide_ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_planes", "=", "16", "\n", "self", ".", "use_log_softmax", "=", "use_log_softmax", "\n", "\n", "assert", "(", "(", "depth", "-", "4", ")", "%", "6", "==", "0", ")", ",", "'Wide-resnet depth should be 6n+4'", "\n", "n", "=", "(", "depth", "-", "4", ")", "//", "6", "\n", "k", "=", "widen_factor", "\n", "\n", "print", "(", "'| Wide-Resnet %dx%d'", "%", "(", "depth", ",", "k", ")", ")", "\n", "nStages", "=", "[", "16", ",", "16", "*", "k", ",", "32", "*", "k", ",", "64", "*", "k", "]", "\n", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "3", ",", "nStages", "[", "0", "]", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_wide_layer", "(", "wide_basic", ",", "nStages", "[", "1", "]", ",", "n", ",", "dropout_rate", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_wide_layer", "(", "wide_basic", ",", "nStages", "[", "2", "]", ",", "n", ",", "dropout_rate", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_wide_layer", "(", "wide_basic", ",", "nStages", "[", "3", "]", ",", "n", ",", "dropout_rate", ",", "stride", "=", "2", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "nStages", "[", "3", "]", ",", "momentum", "=", "0.9", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "nStages", "[", "3", "]", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.Wide_ResNet._wide_layer": [[63, 72], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "def", "_wide_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "dropout_rate", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "\n", "for", "stride", "in", "strides", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "dropout_rate", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.Wide_ResNet.forward": [[73, 87], ["wideresnet.Wide_ResNet.conv1", "wideresnet.Wide_ResNet.layer1", "wideresnet.Wide_ResNet.layer2", "wideresnet.Wide_ResNet.layer3", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "wideresnet.Wide_ResNet.view", "wideresnet.Wide_ResNet.linear", "wideresnet.Wide_ResNet.bn1", "wideresnet.Wide_ResNet.size", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "out", ")", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "8", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "\n", "if", "self", ".", "use_log_softmax", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "out", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "out", "", "", "", "", ""]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.conv3x3": [[9, 11], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.wideresnet.conv_init": [[12, 20], ["classname.find", "torch.xavier_uniform", "torch.constant", "classname.find", "torch.constant", "torch.constant", "numpy.sqrt"], "function", ["None"], ["", "def", "conv_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", ":", "\n", "        ", "init", ".", "xavier_uniform", "(", "m", ".", "weight", ",", "gain", "=", "np", ".", "sqrt", "(", "2", ")", ")", "\n", "init", ".", "constant", "(", "m", ".", "bias", ",", "0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "init", ".", "constant", "(", "m", ".", "weight", ",", "1", ")", "\n", "init", ".", "constant", "(", "m", ".", "bias", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.BasicBlock.__init__": [[28, 37], ["torch.Module.__init__", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "resnet.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.conv3x3", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.conv3x3"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "conv3x3", "(", "inplanes", ",", "planes", ",", "stride", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "conv2", "=", "conv3x3", "(", "planes", ",", "planes", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.BasicBlock.forward": [[38, 55], ["resnet.BasicBlock.conv1", "resnet.BasicBlock.bn1", "resnet.BasicBlock.relu", "resnet.BasicBlock.conv2", "resnet.BasicBlock.bn2", "resnet.BasicBlock.relu", "resnet.BasicBlock.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.Bottleneck.__init__": [[60, 72], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__"], ["def", "__init__", "(", "self", ",", "inplanes", ",", "planes", ",", "stride", "=", "1", ",", "downsample", "=", "None", ")", ":", "\n", "        ", "super", "(", "Bottleneck", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "inplanes", ",", "planes", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", "*", "4", ",", "kernel_size", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm2d", "(", "planes", "*", "4", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "downsample", "=", "downsample", "\n", "self", ".", "stride", "=", "stride", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.Bottleneck.forward": [[73, 94], ["resnet.Bottleneck.conv1", "resnet.Bottleneck.bn1", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv2", "resnet.Bottleneck.bn2", "resnet.Bottleneck.relu", "resnet.Bottleneck.conv3", "resnet.Bottleneck.bn3", "resnet.Bottleneck.relu", "resnet.Bottleneck.downsample"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "\n", "out", "=", "self", ".", "conv1", "(", "x", ")", "\n", "out", "=", "self", ".", "bn1", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv2", "(", "out", ")", "\n", "out", "=", "self", ".", "bn2", "(", "out", ")", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "out", "=", "self", ".", "conv3", "(", "out", ")", "\n", "out", "=", "self", ".", "bn3", "(", "out", ")", "\n", "\n", "if", "self", ".", "downsample", "is", "not", "None", ":", "\n", "            ", "residual", "=", "self", ".", "downsample", "(", "x", ")", "\n", "\n", "", "out", "+=", "residual", "\n", "out", "=", "self", ".", "relu", "(", "out", ")", "\n", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__": [[98, 123], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.AvgPool2d", "torch.AvgPool2d", "torch.AvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "resnet.ResNet.modules", "isinstance", "m.weight.data.normal_", "isinstance", "math.sqrt", "m.weight.data.fill_", "m.bias.data.zero_"], "methods", ["home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.__init__", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "layers", ",", "num_classes", "=", "14", ",", "use_log_softmax", "=", "True", ")", ":", "\n", "        ", "self", ".", "block", "=", "block", "\n", "self", ".", "inplanes", "=", "64", "\n", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "64", ",", "kernel_size", "=", "7", ",", "stride", "=", "2", ",", "padding", "=", "3", ",", "\n", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", "self", ".", "relu", "=", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "3", ",", "stride", "=", "2", ",", "padding", "=", "1", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "layers", "[", "0", "]", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "128", ",", "layers", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "256", ",", "layers", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer4", "=", "self", ".", "_make_layer", "(", "block", ",", "512", ",", "layers", "[", "3", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool", "=", "nn", ".", "AvgPool2d", "(", "7", ",", "stride", "=", "1", ")", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "512", "*", "block", ".", "expansion", ",", "num_classes", ")", "\n", "\n", "self", ".", "use_log_softmax", "=", "use_log_softmax", "\n", "\n", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "                ", "n", "=", "m", ".", "kernel_size", "[", "0", "]", "*", "m", ".", "kernel_size", "[", "1", "]", "*", "m", ".", "out_channels", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "math", ".", "sqrt", "(", "2.", "/", "n", ")", ")", "\n", "", "elif", "isinstance", "(", "m", ",", "nn", ".", "BatchNorm2d", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet._make_layer": [[124, 140], ["layers.append", "range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "block", "layers.append", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "block"], "methods", ["None"], ["", "", "", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "blocks", ",", "stride", "=", "1", ")", ":", "\n", "        ", "downsample", "=", "None", "\n", "if", "stride", "!=", "1", "or", "self", ".", "inplanes", "!=", "planes", "*", "block", ".", "expansion", ":", "\n", "            ", "downsample", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "self", ".", "inplanes", ",", "planes", "*", "block", ".", "expansion", ",", "\n", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "planes", "*", "block", ".", "expansion", ")", ",", "\n", ")", "\n", "\n", "", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ",", "stride", ",", "downsample", ")", ")", "\n", "self", ".", "inplanes", "=", "planes", "*", "block", ".", "expansion", "\n", "for", "i", "in", "range", "(", "1", ",", "blocks", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "inplanes", ",", "planes", ")", ")", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.ResNet.forward": [[141, 160], ["resnet.ResNet.conv1", "resnet.ResNet.bn1", "resnet.ResNet.relu", "resnet.ResNet.maxpool", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "resnet.ResNet.layer4", "resnet.ResNet.avgpool", "resnet.ResNet.view", "resnet.ResNet.fc", "resnet.ResNet.size", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "self", ".", "bn1", "(", "x", ")", "\n", "x", "=", "self", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "layer1", "(", "x", ")", "\n", "x", "=", "self", ".", "layer2", "(", "x", ")", "\n", "x", "=", "self", ".", "layer3", "(", "x", ")", "\n", "x", "=", "self", ".", "layer4", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "x", "=", "self", ".", "fc", "(", "x", ")", "\n", "\n", "if", "self", ".", "use_log_softmax", ":", "\n", "            ", "return", "F", ".", "log_softmax", "(", "x", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.conv3x3": [[19, 23], ["torch.Conv2d"], "function", ["None"], ["def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "stride", "=", "1", ")", ":", "\n", "    ", "\"\"\"3x3 convolution with padding\"\"\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "\n", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.resnet18": [[162, 171], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "", "", "def", "resnet18", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-18 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet18'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.resnet34": [[174, 183], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet34", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-34 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet34'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.resnet50": [[186, 195], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet50", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-50 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet50'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.resnet101": [[198, 207], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet101", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-101 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "23", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet101'", "]", ")", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.chenpf1025_IDN.networks.resnet.resnet152": [[210, 219], ["resnet.ResNet", "ResNet.load_state_dict", "torch.load_url"], "function", ["None"], ["", "def", "resnet152", "(", "pretrained", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Constructs a ResNet-152 model.\n    Args:\n        pretrained (bool): If True, returns a model pre-trained on ImageNet\n    \"\"\"", "\n", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "8", ",", "36", ",", "3", "]", ",", "**", "kwargs", ")", "\n", "if", "pretrained", ":", "\n", "        ", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "model_urls", "[", "'resnet152'", "]", ")", ")", "\n", "", "return", "model", "", "", ""]]}