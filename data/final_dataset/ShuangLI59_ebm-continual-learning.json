{"home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.param_values.set_default_values": [[2, 76], ["print"], "function", ["None"], ["def", "set_default_values", "(", "args", ",", "also_hyper_params", "=", "True", ")", ":", "\n", "# -set default-values for certain arguments based on chosen scenario & experiment", "\n", "    ", "if", "args", ".", "tasks", "is", "None", ":", "\n", "        ", "if", "args", ".", "experiment", "==", "'splitMNIST'", ":", "\n", "            ", "args", ".", "num_classes", "=", "10", "\n", "", "if", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "            ", "args", ".", "num_classes", "=", "10", "\n", "", "elif", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "            ", "args", ".", "num_classes", "=", "100", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "            ", "args", ".", "num_classes", "=", "10", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "            ", "args", ".", "num_classes", "=", "100", "\n", "\n", "", "", "if", "args", ".", "iters", "is", "None", ":", "\n", "        ", "if", "args", ".", "experiment", "==", "'splitMNIST'", ":", "\n", "            ", "args", ".", "iters", "=", "2000", "\n", "", "elif", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "            ", "args", ".", "iters", "=", "2000", "\n", "", "elif", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "            ", "args", ".", "iters", "=", "5000", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "            ", "args", ".", "iters", "=", "5000", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "            ", "args", ".", "iters", "=", "5000", "\n", "", "elif", "args", ".", "experiment", "==", "'block2d'", ":", "\n", "            ", "args", ".", "iters", "=", "5000", "\n", "\n", "", "", "if", "args", ".", "lr", "is", "None", ":", "\n", "        ", "if", "args", ".", "ebm", ":", "\n", "            ", "if", "args", ".", "experiment", "==", "'splitMNIST'", ":", "\n", "                ", "args", ".", "lr", "=", "0.0001", "\n", "", "if", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "                ", "args", ".", "lr", "=", "0.0001", "\n", "", "elif", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "                ", "args", ".", "lr", "=", "0.00001", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "                ", "args", ".", "lr", "=", "0.00001", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "                ", "args", ".", "lr", "=", "0.00001", "\n", "", "elif", "args", ".", "experiment", "==", "'block2d'", ":", "\n", "                ", "args", ".", "lr", "=", "0.00001", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "experiment", "==", "'splitMNIST'", ":", "\n", "                ", "args", ".", "lr", "=", "0.001", "\n", "", "if", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "                ", "args", ".", "lr", "=", "0.001", "\n", "", "elif", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "                ", "args", ".", "lr", "=", "0.0001", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "                ", "args", ".", "lr", "=", "0.0001", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "                ", "args", ".", "lr", "=", "0.0001", "\n", "", "elif", "args", ".", "experiment", "==", "'block2d'", ":", "\n", "                ", "args", ".", "lr", "=", "0.0001", "\n", "\n", "\n", "", "", "", "if", "args", ".", "fc_units", "is", "None", ":", "\n", "        ", "if", "args", ".", "experiment", "==", "'splitMNIST'", ":", "\n", "            ", "args", ".", "fc_units", "=", "400", "\n", "", "if", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "            ", "args", ".", "fc_units", "=", "400", "\n", "", "elif", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "            ", "args", ".", "fc_units", "=", "1000", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "            ", "args", ".", "fc_units", "=", "1000", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "            ", "args", ".", "fc_units", "=", "1000", "\n", "", "elif", "args", ".", "experiment", "==", "'block2d'", ":", "\n", "            ", "args", ".", "fc_units", "=", "400", "\n", "\n", "\n", "", "", "print", "(", "args", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.main.run": [[103, 330], ["torch.device", "random.seed", "numpy.random.seed", "torch.manual_seed", "data_loader.data_loader_online.get_multitask_experiment", "len", "isinstance", "isinstance", "param_stamp.get_param_stamp", "evaluate.initiate_precision_dict", "callbacks._eval_cb", "callbacks._eval_cb", "print", "time.time", "print", "print", "range", "print", "open", "open.write", "range", "open.write", "open.close", "utils.save_object", "utils.save_object", "pidfile.exclusive_dirfn", "os.path.isdir", "os.mkdir", "os.mkdir", "torch.cuda.is_available", "torch.cuda.manual_seed", "torch.cuda.manual_seed_all", "network.ebm.EBM().to", "network.classifier.Classifier().to", "utils.init_params", "utils.init_params", "utils.init_params.convE.parameters", "torch.load", "print", "print", "print", "print", "utils.init_params.fcE.state_dict", "model.fcE.state_dict.update", "utils.init_params.fcE.load_state_dict", "utils.init_params.fcE.model.parameters", "torch.optim.Adam", "callbacks._solver_loss_cb", "train.train_cl", "train.train_cl_noboundary", "time.time", "print", "sum", "os.path.exists", "os.makedirs", "open.write", "open.write", "visual_plt.open_pdf", "visual_plt.plot_lines", "figure_list.append", "visual_plt.plot_lines", "figure_list.append", "visual_plt.open_pdf.close", "pidfile.exclusive_dirfn.done", "os.path.join", "os.path.isdir", "filter", "torch.optim.SGD", "ValueError", "evaluate.validate_ebm", "evaluate.validate", "os.path.join", "os.path.join", "visual_plt.open_pdf.savefig", "network.ebm.EBM", "network.classifier.Classifier", "checkpoint_state.items", "utils.init_params.parameters", "range", "range", "range"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_multitask_experiment", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.param_stamp.get_param_stamp", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.initiate_precision_dict", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.callbacks._eval_cb", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.callbacks._eval_cb", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.save_object", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.save_object", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.init_params", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.init_params", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.callbacks._solver_loss_cb", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.train.train_cl", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.train.train_cl_noboundary", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.open_pdf", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.plot_lines", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.plot_lines", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.validate_ebm", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.validate"], ["def", "run", "(", "args", ")", ":", "\n", "\n", "    ", "if", "not", "args", ".", "single_test", ":", "\n", "        ", "import", "pidfile", "\n", "resfile", "=", "pidfile", ".", "exclusive_dirfn", "(", "os", ".", "path", ".", "join", "(", "args", ".", "r_dir", ",", "args", ".", "save_dir", ")", ")", "\n", "\n", "\n", "", "if", "args", ".", "log_per_task", ":", "\n", "        ", "args", ".", "prec_log", "=", "args", ".", "iters", "\n", "args", ".", "loss_log", "=", "args", ".", "iters", "\n", "\n", "# -create plots- and results-directories if needed", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "r_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "r_dir", ")", "\n", "", "if", "args", ".", "pdf", "and", "not", "os", ".", "path", ".", "isdir", "(", "args", ".", "p_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "args", ".", "p_dir", ")", "\n", "\n", "# set cuda", "\n", "", "cuda", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "args", ".", "cuda", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "cuda", "else", "\"cpu\"", ")", "\n", "\n", "# set random seeds", "\n", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "cuda", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n", "", "scenario", "=", "args", ".", "scenario", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "# DATA", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "(", "train_datasets", ",", "test_datasets", ")", ",", "config", "=", "get_multitask_experiment", "(", "args", ",", "\n", "name", "=", "args", ".", "experiment", ",", "scenario", "=", "scenario", ",", "tasks", "=", "args", ".", "tasks", ",", "data_dir", "=", "args", ".", "d_dir", ",", "\n", "verbose", "=", "True", ",", "exception", "=", "True", "if", "args", ".", "seed", "==", "0", "else", "False", ",", "\n", ")", "\n", "args", ".", "tasks", "=", "len", "(", "config", "[", "'labels_per_task'", "]", ")", "\n", "args", ".", "labels_per_task", "=", "config", "[", "'labels_per_task'", "]", "\n", "if", "not", "args", ".", "task_boundary", ":", "\n", "        ", "args", ".", "iterations_per_virtual_epc", "=", "config", "[", "'iterations_per_virtual_epc'", "]", "\n", "args", ".", "task_dict", "=", "config", "[", "'task_dict'", "]", "\n", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "# MODEL", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "", "if", "args", ".", "ebm", ":", "\n", "        ", "model", "=", "EBM", "(", "args", ",", "image_size", "=", "config", "[", "'size'", "]", ",", "image_channels", "=", "config", "[", "'channels'", "]", ",", "classes", "=", "config", "[", "'num_classes'", "]", ",", "fc_units", "=", "args", ".", "fc_units", ")", ".", "to", "(", "device", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "Classifier", "(", "args", ",", "image_size", "=", "config", "[", "'size'", "]", ",", "image_channels", "=", "config", "[", "'channels'", "]", ",", "classes", "=", "config", "[", "'num_classes'", "]", ",", "fc_units", "=", "args", ".", "fc_units", ")", ".", "to", "(", "device", ")", "\n", "\n", "", "if", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "        ", "model", "=", "utils", ".", "init_params", "(", "model", ",", "args", ")", "\n", "for", "param", "in", "model", ".", "convE", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "", "if", "args", ".", "pretrain", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "pretrain", ")", "\n", "best_acc", "=", "checkpoint", "[", "'best_acc'", "]", "\n", "checkpoint_state", "=", "checkpoint", "[", "'state_dict'", "]", "\n", "\n", "print", "(", "'-----------------------------------------------------------------------------'", ")", "\n", "print", "(", "'load pretrained model %s'", "%", "args", ".", "pretrain", ")", "\n", "print", "(", "'best_acc'", ",", "best_acc", ")", "\n", "print", "(", "'-----------------------------------------------------------------------------'", ")", "\n", "\n", "\n", "model_dict", "=", "model", ".", "fcE", ".", "state_dict", "(", ")", "\n", "checkpoint_state", "=", "{", "k", "[", "7", ":", "]", ":", "v", "for", "k", ",", "v", "in", "checkpoint_state", ".", "items", "(", ")", "if", "k", "[", "7", ":", "]", "in", "model_dict", "}", "## remove module.", "\n", "del", "checkpoint_state", "[", "'classifier.weight'", "]", "\n", "del", "checkpoint_state", "[", "'classifier.bias'", "]", "\n", "if", "'y_ebm.weight'", "in", "checkpoint_state", ":", "\n", "            ", "del", "checkpoint_state", "[", "'y_ebm.weight'", "]", "\n", "", "model_dict", ".", "update", "(", "checkpoint_state", ")", "\n", "model", ".", "fcE", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n", "for", "param", "in", "model", ".", "fcE", ".", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "\n", "\n", "", "", "model", ".", "optim_list", "=", "[", "{", "'params'", ":", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "'lr'", ":", "args", ".", "lr", "}", "]", "\n", "model", ".", "optim_type", "=", "args", ".", "optimizer", "\n", "\n", "if", "model", ".", "optim_type", "in", "(", "\"adam\"", ",", "\"adam_reset\"", ")", ":", "\n", "        ", "model", ".", "optimizer", "=", "optim", ".", "Adam", "(", "model", ".", "optim_list", ",", "betas", "=", "(", "0.9", ",", "0.999", ")", ")", "\n", "", "elif", "model", ".", "optim_type", "==", "\"sgd\"", ":", "\n", "        ", "model", ".", "optimizer", "=", "optim", ".", "SGD", "(", "model", ".", "optim_list", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Unrecognized optimizer, '{}' is not currently a valid option\"", ".", "format", "(", "args", ".", "optimizer", ")", ")", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "# CL-STRATEGY: ALLOCATION", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "\n", "# Elastic Weight Consolidation (EWC)", "\n", "", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", ":", "\n", "        ", "model", ".", "ewc_lambda", "=", "args", ".", "ewc_lambda", "if", "args", ".", "ewc", "else", "0", "\n", "if", "args", ".", "ewc", ":", "\n", "            ", "model", ".", "fisher_n", "=", "args", ".", "fisher_n", "\n", "model", ".", "gamma", "=", "args", ".", "gamma", "\n", "model", ".", "online", "=", "args", ".", "online", "\n", "model", ".", "emp_FI", "=", "args", ".", "emp_fi", "\n", "\n", "# Synpatic Intelligence (SI)", "\n", "", "", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", ":", "\n", "        ", "model", ".", "si_c", "=", "args", ".", "si_c", "if", "args", ".", "si", "else", "0", "\n", "if", "args", ".", "si", ":", "\n", "            ", "model", ".", "epsilon", "=", "args", ".", "epsilon", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "# Get parameter-stamp (and print on screen)", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "", "", "param_stamp", "=", "get_param_stamp", "(", "args", ",", "model", ".", "name", ",", "verbose", "=", "True", ")", "\n", "param_stamp", "=", "param_stamp", "+", "'--'", "+", "args", ".", "model_name", "\n", "\n", "\n", "# -define [precision_dict] to keep track of performance during training for storing and for later plotting in pdf", "\n", "precision_dict", "=", "evaluate", ".", "initiate_precision_dict", "(", "args", ".", "tasks", ")", "\n", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------#", "\n", "\n", "#---------------------#", "\n", "#----- CALLBACKS -----#", "\n", "#---------------------#", "\n", "solver_loss_cbs", "=", "[", "cb", ".", "_solver_loss_cb", "(", "log", "=", "args", ".", "loss_log", ",", "model", "=", "model", ",", "tasks", "=", "args", ".", "tasks", ",", "iters_per_task", "=", "args", ".", "iters", ")", "]", "\n", "\n", "eval_cb", "=", "cb", ".", "_eval_cb", "(", "\n", "log", "=", "args", ".", "prec_log", ",", "test_datasets", "=", "test_datasets", ",", "visdom", "=", "args", ".", "visdom", ",", "precision_dict", "=", "None", ",", "iters_per_task", "=", "args", ".", "iters", ",", "\n", "test_size", "=", "args", ".", "prec_n", ",", "labels_per_task", "=", "config", "[", "'labels_per_task'", "]", ",", "scenario", "=", "scenario", ")", "\n", "eval_cb_full", "=", "cb", ".", "_eval_cb", "(", "\n", "log", "=", "args", ".", "iters", ",", "test_datasets", "=", "test_datasets", ",", "precision_dict", "=", "precision_dict", ",", "\n", "iters_per_task", "=", "args", ".", "iters", ",", "labels_per_task", "=", "config", "[", "'labels_per_task'", "]", ",", "scenario", "=", "scenario", ")", "\n", "eval_cbs", "=", "[", "eval_cb", ",", "eval_cb_full", "]", "\n", "\n", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "# TRAINING", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "print", "(", "\"--> Training:\"", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "args", ".", "task_boundary", ":", "\n", "        ", "train_cl", "(", "\n", "args", ",", "model", ",", "train_datasets", ",", "scenario", "=", "scenario", ",", "labels_per_task", "=", "config", "[", "'labels_per_task'", "]", ",", "\n", "iters", "=", "args", ".", "iters", ",", "batch_size", "=", "args", ".", "batch", ",", "\n", "eval_cbs", "=", "eval_cbs", ",", "loss_cbs", "=", "solver_loss_cbs", ")", "\n", "", "else", ":", "\n", "        ", "train_cl_noboundary", "(", "\n", "args", ",", "model", ",", "train_datasets", ",", "scenario", "=", "scenario", ",", "labels_per_task", "=", "config", "[", "'labels_per_task'", "]", ",", "\n", "iters", "=", "args", ".", "iters", ",", "batch_size", "=", "args", ".", "batch", ",", "\n", "eval_cbs", "=", "eval_cbs", ",", "loss_cbs", "=", "solver_loss_cbs", ")", "\n", "\n", "", "training_time", "=", "time", ".", "time", "(", ")", "-", "start", "\n", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "# EVALUATION", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "print", "(", "\"\\n\\n--> Evaluation ({}-incremental learning scenario):\"", ".", "format", "(", "args", ".", "scenario", ")", ")", "\n", "if", "args", ".", "ebm", ":", "\n", "        ", "precs", "=", "[", "evaluate", ".", "validate_ebm", "(", "\n", "args", ",", "model", ",", "test_datasets", "[", "i", "]", ",", "verbose", "=", "False", ",", "test_size", "=", "None", ",", "task", "=", "i", "+", "1", ",", "with_exemplars", "=", "False", ",", "\n", "current_task", "=", "args", ".", "tasks", ")", "for", "i", "in", "range", "(", "args", ".", "tasks", ")", "]", "\n", "", "else", ":", "\n", "        ", "precs", "=", "[", "evaluate", ".", "validate", "(", "\n", "args", ",", "model", ",", "test_datasets", "[", "i", "]", ",", "verbose", "=", "False", ",", "test_size", "=", "None", ",", "task", "=", "i", "+", "1", ",", "with_exemplars", "=", "False", ",", "\n", "current_task", "=", "args", ".", "tasks", ")", "for", "i", "in", "range", "(", "args", ".", "tasks", ")", "]", "\n", "\n", "", "print", "(", "\"\\n Precision on test-set (softmax classification):\"", ")", "\n", "for", "i", "in", "range", "(", "args", ".", "tasks", ")", ":", "\n", "        ", "print", "(", "\" - Task {}: {:.4f}\"", ".", "format", "(", "i", "+", "1", ",", "precs", "[", "i", "]", ")", ")", "\n", "", "average_precs", "=", "sum", "(", "precs", ")", "/", "args", ".", "tasks", "\n", "print", "(", "'average precision over all {} tasks: {:.4f}'", ".", "format", "(", "args", ".", "tasks", ",", "average_precs", ")", ")", "\n", "\n", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "# OUTPUT", "\n", "#-------------------------------------------------------------------------------------------------", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "args", ".", "r_dir", ",", "args", ".", "save_dir", ")", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "args", ".", "r_dir", ",", "args", ".", "save_dir", ")", ")", "\n", "\n", "", "output_file", "=", "open", "(", "\"{}/{}/{}.txt\"", ".", "format", "(", "args", ".", "r_dir", ",", "args", ".", "save_dir", ",", "param_stamp", ")", ",", "'w'", ")", "\n", "output_file", ".", "write", "(", "\"Training time {} \\n\"", ".", "format", "(", "training_time", ")", ")", "\n", "for", "i", "in", "range", "(", "args", ".", "tasks", ")", ":", "\n", "        ", "output_file", ".", "write", "(", "\" - Task {}: {:.4f}\"", ".", "format", "(", "i", "+", "1", ",", "precs", "[", "i", "]", ")", ")", "\n", "output_file", ".", "write", "(", "\"\\n\"", ")", "\n", "", "output_file", ".", "write", "(", "' - Average {}\\n'", ".", "format", "(", "average_precs", ")", ")", "\n", "output_file", ".", "close", "(", ")", "\n", "file_name", "=", "\"{}/{}/{}\"", ".", "format", "(", "args", ".", "r_dir", ",", "args", ".", "save_dir", ",", "param_stamp", ")", "\n", "utils", ".", "save_object", "(", "precision_dict", ",", "file_name", ")", "\n", "\n", "\n", "if", "args", ".", "pdf", ":", "\n", "        ", "pp", "=", "visual_plt", ".", "open_pdf", "(", "\"{}/{}/{}.pdf\"", ".", "format", "(", "args", ".", "r_dir", ",", "args", ".", "save_dir", ",", "param_stamp", ")", ")", "\n", "# -show metrics reflecting progression during training", "\n", "figure_list", "=", "[", "]", "#-> create list to store all figures to be plotted", "\n", "# -generate all figures (and store them in [figure_list])", "\n", "figure", "=", "visual_plt", ".", "plot_lines", "(", "\n", "precision_dict", "[", "\"all_tasks\"", "]", ",", "x_axes", "=", "precision_dict", "[", "\"x_task\"", "]", ",", "\n", "line_names", "=", "[", "'task {}'", ".", "format", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "args", ".", "tasks", ")", "]", "\n", ")", "\n", "figure_list", ".", "append", "(", "figure", ")", "\n", "figure", "=", "visual_plt", ".", "plot_lines", "(", "\n", "[", "precision_dict", "[", "\"average\"", "]", "]", ",", "x_axes", "=", "precision_dict", "[", "\"x_task\"", "]", ",", "\n", "line_names", "=", "[", "'average all tasks so far'", "]", "\n", ")", "\n", "figure_list", ".", "append", "(", "figure", ")", "\n", "# -add figures to pdf (and close this pdf).", "\n", "for", "figure", "in", "figure_list", ":", "\n", "            ", "pp", ".", "savefig", "(", "figure", ")", "\n", "\n", "", "pp", ".", "close", "(", ")", "\n", "\n", "", "if", "not", "args", ".", "single_test", ":", "\n", "        ", "resfile", ".", "done", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.validate": [[19, 87], ["model.eval", "utils.get_data_loader", "range", "numpy.array", "time.time", "time.time", "print", "model.train", "hasattr", "len", "print", "model.reset_XdGmask", "model.apply_XdGmask", "model._is_on_cuda", "data.to", "labels.to", "torch.no_grad", "model", "torch.tensor().long().cuda", "torch.max", "model._device", "model._device", "torch.tensor().long", "torch.tensor", "seen_classes_list.index"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.get_data_loader", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._is_on_cuda", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device"], ["def", "validate", "(", "args", ",", "model", ",", "dataset", ",", "batch_size", "=", "128", ",", "test_size", "=", "1024", ",", "verbose", "=", "True", ",", "\n", "with_exemplars", "=", "False", ",", "no_task_mask", "=", "False", ",", "task", "=", "None", ",", "current_task", "=", "None", ")", ":", "\n", "    ", "'''Evaluate precision (= accuracy or proportion correct) of a classifier ([model]) on [dataset].\n\n    [allowed_classes]   None or <list> containing all \"active classes\" between which should be chosen\n                            (these \"active classes\" are assumed to be contiguous)'''", "\n", "\n", "# Set model to eval()-mode", "\n", "mode", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Apply task-specifc \"gating-mask\" for each hidden fully connected layer (or remove it!)", "\n", "if", "hasattr", "(", "model", ",", "\"mask_dict\"", ")", "and", "model", ".", "mask_dict", "is", "not", "None", ":", "\n", "        ", "if", "no_task_mask", ":", "\n", "            ", "model", ".", "reset_XdGmask", "(", ")", "\n", "", "else", ":", "\n", "            ", "model", ".", "apply_XdGmask", "(", "task", "=", "task", ")", "\n", "\n", "# Loop over batches in [dataset]", "\n", "", "", "data_loader", "=", "utils", ".", "get_data_loader", "(", "dataset", ",", "batch_size", ",", "cuda", "=", "model", ".", "_is_on_cuda", "(", ")", ")", "\n", "total_tested", "=", "total_correct", "=", "0", "\n", "\n", "labels_per_task", "=", "args", ".", "labels_per_task", "\n", "seen_classes_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "current_task", ")", ":", "\n", "        ", "seen_classes_list", "+=", "labels_per_task", "[", "i", "]", "\n", "", "seen_classes", "=", "np", ".", "array", "(", "seen_classes_list", ")", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "for", "data", ",", "labels", "in", "data_loader", ":", "\n", "# -break on [test_size] (if \"None\", full dataset is used)", "\n", "        ", "if", "test_size", ":", "\n", "            ", "if", "total_tested", ">=", "test_size", ":", "\n", "                ", "break", "\n", "\n", "\n", "# -evaluate model (if requested, only on [allowed_classes])", "\n", "", "", "data", ",", "labels", "=", "data", ".", "to", "(", "model", ".", "_device", "(", ")", ")", ",", "labels", ".", "to", "(", "model", ".", "_device", "(", ")", ")", "\n", "batch_size", "=", "data", ".", "shape", "[", "0", "]", "\n", "for", "tem", "in", "labels", ":", "assert", "tem", "in", "seen_classes_list", "## y shoud be in current classes", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Run model", "\n", "            ", "y_hat", "=", "model", "(", "data", ")", "\n", "\n", "\n", "y_hat", "=", "y_hat", "[", ":", ",", "seen_classes", "]", "\n", "\n", "## accuracy", "\n", "label_tem", "=", "torch", ".", "tensor", "(", "[", "seen_classes_list", ".", "index", "(", "tem", ")", "for", "tem", "in", "labels", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "_", ",", "precision", "=", "torch", ".", "max", "(", "y_hat", ",", "1", ")", "\n", "\n", "predicted", "=", "(", "precision", "==", "label_tem", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "total_correct", "+=", "predicted", "\n", "total_tested", "+=", "len", "(", "data", ")", "\n", "\n", "", "toc", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'time: '", ",", "toc", "-", "tic", ")", "\n", "precision", "=", "total_correct", "/", "total_tested", "\n", "\n", "# Set model back to its initial mode, print result on screen (if requested) and return it", "\n", "model", ".", "train", "(", "mode", "=", "mode", ")", "\n", "verbose", "=", "True", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'=> {}: Task {} precision: {:.3f}'", ".", "format", "(", "args", ".", "save_dir", ",", "task", ",", "precision", ")", ")", "\n", "\n", "", "return", "precision", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.validate_ebm": [[91, 170], ["model.eval", "utils.get_data_loader", "range", "numpy.array", "time.time", "time.time", "print", "model.train", "len", "print", "model._is_on_cuda", "data.to", "labels.to", "torch.LongTensor().cuda", "range", "model", "torch.max", "torch.tensor().long().cuda", "torch.tensor().view().expand", "joint_targets.cuda().long.cuda().long", "model._device", "model._device", "list", "torch.tensor().cuda", "len", "torch.no_grad", "torch.min", "torch.tensor().long().cuda", "torch.LongTensor", "torch.tensor().long", "torch.tensor().view", "joint_targets.cuda().long.cuda", "model", "model", "len", "torch.tensor", "torch.tensor().long", "torch.tensor", "torch.tensor", "torch.tensor", "seen_classes_list.index", "torch.ones", "seen_classes_list.index"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.get_data_loader", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._is_on_cuda", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device"], ["", "def", "validate_ebm", "(", "args", ",", "model", ",", "dataset", ",", "batch_size", "=", "128", ",", "test_size", "=", "1024", ",", "verbose", "=", "True", ",", "\n", "with_exemplars", "=", "False", ",", "no_task_mask", "=", "False", ",", "task", "=", "None", ",", "current_task", "=", "None", ")", ":", "\n", "\n", "# Set model to eval()-mode", "\n", "    ", "mode", "=", "model", ".", "training", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Loop over batches in [dataset]", "\n", "data_loader", "=", "utils", ".", "get_data_loader", "(", "dataset", ",", "batch_size", ",", "cuda", "=", "model", ".", "_is_on_cuda", "(", ")", ")", "\n", "total_tested", "=", "total_correct", "=", "0", "\n", "\n", "labels_per_task", "=", "args", ".", "labels_per_task", "\n", "seen_classes_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "current_task", ")", ":", "\n", "        ", "seen_classes_list", "+=", "labels_per_task", "[", "i", "]", "\n", "", "seen_classes", "=", "np", ".", "array", "(", "seen_classes_list", ")", "\n", "\n", "tic", "=", "time", ".", "time", "(", ")", "\n", "for", "data", ",", "labels", "in", "data_loader", ":", "\n", "# -break on [test_size] (if \"None\", full dataset is used)", "\n", "        ", "if", "test_size", ":", "\n", "            ", "if", "total_tested", ">=", "test_size", ":", "\n", "                ", "break", "\n", "\n", "\n", "", "", "data", ",", "labels", "=", "data", ".", "to", "(", "model", ".", "_device", "(", ")", ")", ",", "labels", ".", "to", "(", "model", ".", "_device", "(", ")", ")", "\n", "batch_size", "=", "data", ".", "shape", "[", "0", "]", "\n", "for", "tem", "in", "labels", ":", "assert", "tem", "in", "list", "(", "seen_classes_list", ")", "## y shoud be in current classes", "\n", "\n", "if", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "            ", "ys_to_test", "=", "torch", ".", "LongTensor", "(", "batch_size", ",", "len", "(", "seen_classes_list", ")", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "ys_to_test", "[", "i", "]", "=", "torch", ".", "tensor", "(", "seen_classes_list", ")", ".", "cuda", "(", ")", "\n", "", "energy", "=", "model", "(", "data", ",", "ys_to_test", ")", "\n", "\n", "# accuracy", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "energy", ",", "1", ")", "## cifar100 model predict negative energy", "\n", "label_tem", "=", "torch", ".", "tensor", "(", "[", "seen_classes_list", ".", "index", "(", "tem", ")", "for", "tem", "in", "labels", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "predicted", "=", "(", "predicted", "==", "label_tem", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "", "else", ":", "\n", "## get negatives+positive labels", "\n", "            ", "joint_targets", "=", "torch", ".", "tensor", "(", "seen_classes", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "len", "(", "seen_classes", ")", ")", "\n", "joint_targets", "=", "joint_targets", ".", "cuda", "(", ")", ".", "long", "(", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# Run model", "\n", "# print(task, current_task)", "\n", "                ", "if", "args", ".", "task_info_input", ":", "\n", "                    ", "task_id", "=", "(", "torch", ".", "ones", "(", "[", "batch_size", "]", ")", "*", "(", "task", "-", "1", ")", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "energy", "=", "model", "(", "data", ",", "joint_targets", ",", "task_id", ")", "\n", "", "else", ":", "\n", "                    ", "energy", "=", "model", "(", "data", ",", "joint_targets", ")", "\n", "\n", "\n", "# accuracy", "\n", "", "_", ",", "predicted", "=", "torch", ".", "min", "(", "energy", ",", "1", ")", "\n", "label_tem", "=", "torch", ".", "tensor", "(", "[", "seen_classes_list", ".", "index", "(", "tem", ")", "for", "tem", "in", "labels", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "predicted", "=", "(", "predicted", "==", "label_tem", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n", "\n", "\n", "\n", "", "", "total_correct", "+=", "predicted", "\n", "total_tested", "+=", "len", "(", "data", ")", "\n", "\n", "", "toc", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "'ebm time: '", ",", "toc", "-", "tic", ")", "\n", "precision", "=", "total_correct", "/", "total_tested", "\n", "\n", "\n", "# Set model back to its initial mode, print result on screen (if requested) and return it", "\n", "model", ".", "train", "(", "mode", "=", "mode", ")", "\n", "verbose", "=", "True", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'=> {}: Task {} precision: {:.3f}'", ".", "format", "(", "args", ".", "save_dir", ",", "task", ",", "precision", ")", ")", "\n", "\n", "", "return", "precision", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.precision": [[173, 214], ["len", "range", "sum", "print", "enumerate", "precision_dict[].append", "precision_dict[].append", "precision_dict[].append", "precs.append", "range", "[].append", "precs.append", "precs.append", "evaluate.validate_ebm", "evaluate.validate", "range"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.validate_ebm", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.validate"], ["", "def", "precision", "(", "args", ",", "model", ",", "datasets", ",", "current_task", ",", "iteration", ",", "labels_per_task", "=", "None", ",", "scenario", "=", "\"class\"", ",", "\n", "precision_dict", "=", "None", ",", "test_size", "=", "None", ",", "visdom", "=", "None", ",", "verbose", "=", "False", ",", "summary_graph", "=", "True", ",", "\n", "with_exemplars", "=", "False", ",", "no_task_mask", "=", "False", ")", ":", "\n", "    ", "'''Evaluate precision of a classifier (=[model]) on all tasks so far (= up to [current_task]) using [datasets].\n\n    [precision_dict]    None or <dict> of all measures to keep track of, to which results will be appended to\n    [scenario]          <str> how to decide which classes to include during evaluating precision\n    [visdom]            None or <dict> with name of \"graph\" and \"env\" (if None, no visdom-plots are made)'''", "\n", "\n", "# Evaluate accuracy of model predictions for all tasks so far (reporting \"0\" for future tasks)", "\n", "\n", "n_tasks", "=", "len", "(", "datasets", ")", "\n", "precs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_tasks", ")", ":", "\n", "        ", "if", "i", "+", "1", "<=", "current_task", ":", "\n", "            ", "if", "args", ".", "ebm", ":", "\n", "                ", "precs", ".", "append", "(", "validate_ebm", "(", "args", ",", "model", ",", "datasets", "[", "i", "]", ",", "test_size", "=", "test_size", ",", "verbose", "=", "verbose", ",", "\n", "with_exemplars", "=", "with_exemplars", ",", "\n", "no_task_mask", "=", "no_task_mask", ",", "task", "=", "i", "+", "1", ",", "current_task", "=", "current_task", ")", ")", "\n", "", "else", ":", "\n", "                ", "precs", ".", "append", "(", "validate", "(", "args", ",", "model", ",", "datasets", "[", "i", "]", ",", "test_size", "=", "test_size", ",", "verbose", "=", "verbose", ",", "\n", "with_exemplars", "=", "with_exemplars", ",", "\n", "no_task_mask", "=", "no_task_mask", ",", "task", "=", "i", "+", "1", ",", "current_task", "=", "current_task", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "precs", ".", "append", "(", "0", ")", "\n", "\n", "", "", "average_precs", "=", "sum", "(", "[", "precs", "[", "task_id", "]", "for", "task_id", "in", "range", "(", "current_task", ")", "]", ")", "/", "current_task", "\n", "\n", "# Print results on screen", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "' => ave precision: {:.3f}'", ".", "format", "(", "average_precs", ")", ")", "\n", "\n", "# Append results to [progress]-dictionary and return", "\n", "", "names", "=", "[", "'task {}'", ".", "format", "(", "i", "+", "1", ")", "for", "i", "in", "range", "(", "n_tasks", ")", "]", "\n", "if", "precision_dict", "is", "not", "None", ":", "\n", "        ", "for", "task_id", ",", "_", "in", "enumerate", "(", "names", ")", ":", "\n", "            ", "precision_dict", "[", "\"all_tasks\"", "]", "[", "task_id", "]", ".", "append", "(", "precs", "[", "task_id", "]", ")", "\n", "", "precision_dict", "[", "\"average\"", "]", ".", "append", "(", "average_precs", ")", "\n", "precision_dict", "[", "\"x_iteration\"", "]", ".", "append", "(", "iteration", ")", "\n", "precision_dict", "[", "\"x_task\"", "]", ".", "append", "(", "current_task", ")", "\n", "", "return", "precision_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.initiate_precision_dict": [[217, 225], ["range"], "function", ["None"], ["", "def", "initiate_precision_dict", "(", "n_tasks", ")", ":", "\n", "    ", "'''Initiate <dict> with all precision-measures to keep track of.'''", "\n", "precision", "=", "{", "}", "\n", "precision", "[", "\"all_tasks\"", "]", "=", "[", "[", "]", "for", "_", "in", "range", "(", "n_tasks", ")", "]", "\n", "precision", "[", "\"average\"", "]", "=", "[", "]", "\n", "precision", "[", "\"x_iteration\"", "]", "=", "[", "]", "\n", "precision", "[", "\"x_task\"", "]", "=", "[", "]", "\n", "return", "precision", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.train.train_cl": [[16, 175], ["list", "list", "model.train", "model._is_on_cuda", "model._device", "enumerate", "isinstance", "model.named_parameters", "tqdm.tqdm", "range", "tqdm.tqdm.close", "isinstance", "model.named_parameters", "iter", "torch.stack().view", "torch.stack().view", "range", "next", "isinstance", "model.estimate_fisher", "isinstance", "model.update_omega", "n.replace.replace", "model.register_buffer", "utils.get_data_loader", "torch.stack().view", "list", "random.shuffle", "pre_data_img_list.append", "pre_data_lab_list.append", "torch.stack().view", "iter", "len", "x.to", "y.to", "list", "random.shuffle", "x_.to.to", "y_.to.to", "model.train_a_batch", "p.data.clone", "n.replace.replace", "p.data.clone().zero_", "p.data.clone", "next", "torch.stack().view.append", "torch.stack().view.append", "torch.stack().view", "torch.stack", "range", "int", "list", "random.shuffle", "pre_data_img_list.append", "pre_data_lab_list.append", "torch.stack().view", "torch.stack", "utils.get_data_loader", "range", "isinstance", "model.named_parameters", "torch.stack", "torch.stack().view", "len", "range", "torch.stack", "torch.stack().view", "len", "loss_cb", "eval_cb", "p.data.clone", "torch.stack", "len", "torch.stack", "n.replace.replace", "p.detach().clone", "torch.stack", "torch.stack", "W[].add_", "p.detach", "p.detach"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._is_on_cuda", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.estimate_fisher", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.update_omega", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.get_data_loader", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier.Classifier.train_a_batch", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.get_data_loader"], ["def", "train_cl", "(", "args", ",", "model", ",", "train_datasets", ",", "scenario", "=", "\"class\"", ",", "labels_per_task", "=", "None", ",", "iters", "=", "2000", ",", "batch_size", "=", "32", ",", "\n", "loss_cbs", "=", "list", "(", ")", ",", "eval_cbs", "=", "list", "(", ")", ")", ":", "\n", "\n", "    ", "model", ".", "train", "(", ")", "\n", "cuda", "=", "model", ".", "_is_on_cuda", "(", ")", "\n", "device", "=", "model", ".", "_device", "(", ")", "\n", "\n", "\n", "# Register starting param-values (needed for \"intelligent synapses\").", "\n", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "        ", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "model", ".", "register_buffer", "(", "'{}_SI_prev_task'", ".", "format", "(", "n", ")", ",", "p", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "", "", "", "REAL_IMG_REPLAY", "=", "None", "\n", "pre_data_img_list", "=", "[", "]", "\n", "pre_data_lab_list", "=", "[", "]", "\n", "\n", "\n", "for", "task", ",", "train_dataset", "in", "enumerate", "(", "train_datasets", ",", "1", ")", ":", "\n", "\n", "# Prepare <dicts> to store running importance estimates and param-values before update (\"Synaptic Intelligence\")", "\n", "        ", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "            ", "W", "=", "{", "}", "\n", "p_old", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "requires_grad", ":", "\n", "                    ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "W", "[", "n", "]", "=", "p", ".", "data", ".", "clone", "(", ")", ".", "zero_", "(", ")", "\n", "p_old", "[", "n", "]", "=", "p", ".", "data", ".", "clone", "(", ")", "\n", "\n", "\n", "", "", "", "if", "REAL_IMG_REPLAY", ":", "\n", "            ", "i", "=", "task", "-", "2", "\n", "previous_dataset", "=", "train_datasets", "[", "i", "]", "\n", "previous_data_loader", "=", "iter", "(", "utils", ".", "get_data_loader", "(", "previous_dataset", ",", "batch_size", ",", "cuda", "=", "cuda", ",", "drop_last", "=", "True", ")", ")", "\n", "\n", "tem_img", "=", "[", "]", "\n", "tem_lab", "=", "[", "]", "\n", "while", "(", "1", ")", ":", "\n", "                ", "try", ":", "\n", "                    ", "previous_x", ",", "previous_y", "=", "next", "(", "previous_data_loader", ")", "\n", "tem_img", ".", "append", "(", "previous_x", ")", "\n", "tem_lab", ".", "append", "(", "previous_y", ")", "\n", "", "except", ":", "\n", "# print(storage.imgs_step)", "\n", "                    ", "break", "\n", "\n", "\n", "", "", "if", "args", ".", "experiment", "==", "'cifar10'", "or", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "                ", "tem_img", "=", "torch", ".", "stack", "(", "tem_img", ")", ".", "view", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "", "elif", "args", ".", "experiment", "==", "'splitMNIST'", ":", "\n", "                ", "tem_img", "=", "torch", ".", "stack", "(", "tem_img", ")", ".", "view", "(", "-", "1", ",", "1", ",", "28", ",", "28", ")", "\n", "", "elif", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "                ", "tem_img", "=", "torch", ".", "stack", "(", "tem_img", ")", ".", "view", "(", "-", "1", ",", "1", ",", "32", ",", "32", ")", "\n", "", "tem_lab", "=", "torch", ".", "stack", "(", "tem_lab", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "\n", "\n", "# classes_per_task = len(args.labels_per_task[0])", "\n", "# pre_data_img_list.append(tem_img[pre_data_i_index[:args.budget*classes_per_task]])", "\n", "# pre_data_lab_list.append(tem_lab[pre_data_i_index[:args.budget*classes_per_task]])", "\n", "\n", "replay_way", "=", "'v2'", "\n", "\n", "\n", "if", "replay_way", "==", "'v1'", ":", "\n", "                ", "pre_data_i_index", "=", "list", "(", "range", "(", "len", "(", "tem_img", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "pre_data_i_index", ")", "\n", "pre_data_img_list", ".", "append", "(", "tem_img", "[", "pre_data_i_index", "[", ":", "args", ".", "budget", "]", "]", ")", "\n", "pre_data_lab_list", ".", "append", "(", "tem_lab", "[", "pre_data_i_index", "[", ":", "args", ".", "budget", "]", "]", ")", "\n", "\n", "", "elif", "replay_way", "==", "'v2'", ":", "\n", "                ", "num_sample_each_task", "=", "int", "(", "args", ".", "budget", "/", "(", "task", "-", "1", ")", ")", "\n", "if", "task", ">", "2", ":", "\n", "                    ", "pre_data_img_list", "=", "[", "tem", "[", ":", "num_sample_each_task", "]", "for", "tem", "in", "pre_data_img_list", "]", "\n", "pre_data_lab_list", "=", "[", "tem", "[", ":", "num_sample_each_task", "]", "for", "tem", "in", "pre_data_lab_list", "]", "\n", "\n", "", "pre_data_i_index", "=", "list", "(", "range", "(", "len", "(", "tem_img", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "pre_data_i_index", ")", "\n", "pre_data_img_list", ".", "append", "(", "tem_img", "[", "pre_data_i_index", "[", ":", "num_sample_each_task", "]", "]", ")", "\n", "pre_data_lab_list", ".", "append", "(", "tem_lab", "[", "pre_data_i_index", "[", ":", "num_sample_each_task", "]", "]", ")", "\n", "\n", "\n", "", "if", "args", ".", "experiment", "==", "'cifar10'", "or", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "                ", "pre_data_img", "=", "torch", ".", "stack", "(", "pre_data_img_list", ")", ".", "view", "(", "-", "1", ",", "3", ",", "32", ",", "32", ")", "\n", "", "elif", "args", ".", "experiment", "==", "'splitMNIST'", ":", "\n", "                ", "pre_data_img", "=", "torch", ".", "stack", "(", "pre_data_img_list", ")", ".", "view", "(", "-", "1", ",", "1", ",", "28", ",", "28", ")", "\n", "", "elif", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "                ", "pre_data_img", "=", "torch", ".", "stack", "(", "pre_data_img_list", ")", ".", "view", "(", "-", "1", ",", "1", ",", "32", ",", "32", ")", "\n", "", "pre_data_lab", "=", "torch", ".", "stack", "(", "pre_data_lab_list", ")", ".", "view", "(", "-", "1", ")", "\n", "\n", "# print(pre_data_img.shape)", "\n", "# print(pre_data_lab.shape)", "\n", "# print(pre_data_lab.max(), pre_data_lab.min())", "\n", "\n", "\n", "", "progress", "=", "tqdm", ".", "tqdm", "(", "range", "(", "1", ",", "iters", "+", "1", ")", ")", "\n", "iters_left", "=", "1", "\n", "\n", "for", "batch_index", "in", "range", "(", "1", ",", "iters", "+", "1", ")", ":", "\n", "            ", "iters_left", "-=", "1", "\n", "if", "iters_left", "==", "0", ":", "\n", "                ", "data_loader", "=", "iter", "(", "utils", ".", "get_data_loader", "(", "train_dataset", ",", "batch_size", ",", "cuda", "=", "cuda", ",", "drop_last", "=", "True", ")", ")", "\n", "iters_left", "=", "len", "(", "data_loader", ")", "\n", "\n", "", "x", ",", "y", "=", "next", "(", "data_loader", ")", "\n", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "\n", "\n", "x_", ",", "y_", "=", "None", ",", "None", "\n", "if", "REAL_IMG_REPLAY", ":", "\n", "                ", "index", "=", "list", "(", "range", "(", "len", "(", "pre_data_img", ")", ")", ")", "\n", "random", ".", "shuffle", "(", "index", ")", "\n", "index", "=", "index", "[", ":", "batch_size", "]", "\n", "# index = index[:batch_size*(task-1)]", "\n", "x_", "=", "pre_data_img", "[", "index", "]", "\n", "y_", "=", "pre_data_lab", "[", "index", "]", "\n", "x_", "=", "x_", ".", "to", "(", "device", ")", "\n", "y_", "=", "y_", ".", "to", "(", "device", ")", "\n", "\n", "\n", "", "if", "batch_index", "<=", "iters", ":", "\n", "                ", "loss_dict", "=", "model", ".", "train_a_batch", "(", "args", ",", "x", ",", "y", ",", "x_", ",", "y_", ",", "task", "=", "task", ")", "\n", "\n", "\n", "# Update running parameter importance estimates in W", "\n", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "                    ", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                        ", "if", "p", ".", "requires_grad", ":", "\n", "                            ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                                ", "W", "[", "n", "]", ".", "add_", "(", "-", "p", ".", "grad", "*", "(", "p", ".", "detach", "(", ")", "-", "p_old", "[", "n", "]", ")", ")", "\n", "", "p_old", "[", "n", "]", "=", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "", "", "", "for", "loss_cb", "in", "loss_cbs", ":", "\n", "                    ", "if", "loss_cb", "is", "not", "None", ":", "\n", "                        ", "loss_cb", "(", "progress", ",", "batch_index", ",", "loss_dict", ",", "task", "=", "task", ")", "\n", "", "", "for", "eval_cb", "in", "eval_cbs", ":", "\n", "                    ", "if", "eval_cb", "is", "not", "None", ":", "\n", "                        ", "eval_cb", "(", "args", ",", "model", ",", "batch_index", ",", "task", "=", "task", ")", "\n", "\n", "", "", "", "", "progress", ".", "close", "(", ")", "\n", "\n", "\n", "## EWC and SI is only for softmax-based classifier", "\n", "# EWC: estimate Fisher Information matrix (FIM) and update term for quadratic penalty    ", "\n", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "ewc_lambda", ">", "0", ")", ":", "\n", "# -estimate FI-matrix", "\n", "            ", "model", ".", "estimate_fisher", "(", "args", ",", "train_dataset", ",", "task", ")", "\n", "\n", "# SI: calculate and update the normalized path integral", "\n", "", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "            ", "model", ".", "update_omega", "(", "W", ",", "model", ".", "epsilon", ")", "\n", "\n", "\n", "", "if", "args", ".", "replay_mode", "==", "'real_img_replay'", ":", "\n", "            ", "REAL_IMG_REPLAY", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.train.train_cl_noboundary": [[178, 252], ["list", "list", "model.train", "model._is_on_cuda", "model._device", "range", "isinstance", "model.named_parameters", "tqdm.tqdm", "enumerate", "tqdm.tqdm.close", "range", "model.train_a_batch", "n.replace.replace", "model.register_buffer", "isinstance", "model.named_parameters", "x.to", "y.to", "isinstance", "model.named_parameters", "isinstance", "model.estimate_fisher", "isinstance", "model.update_omega", "p.data.clone", "loss_cb", "int", "eval_cb", "n.replace.replace", "p.data.clone().zero_", "p.data.clone", "n.replace.replace", "p.detach().clone", "y.max", "W[].add_", "p.data.clone", "p.detach", "p.detach"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._is_on_cuda", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier.Classifier.train_a_batch", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.estimate_fisher", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.update_omega"], ["", "", "", "def", "train_cl_noboundary", "(", "args", ",", "model", ",", "train_datasets", ",", "scenario", "=", "\"class\"", ",", "labels_per_task", "=", "None", ",", "iters", "=", "2000", ",", "batch_size", "=", "32", ",", "loss_cbs", "=", "list", "(", ")", ",", "eval_cbs", "=", "list", "(", ")", ")", ":", "\n", "\n", "    ", "model", ".", "train", "(", ")", "\n", "cuda", "=", "model", ".", "_is_on_cuda", "(", ")", "\n", "device", "=", "model", ".", "_device", "(", ")", "\n", "\n", "\n", "# Register starting param-values (needed for \"intelligent synapses\").", "\n", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "        ", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "model", ".", "register_buffer", "(", "'{}_SI_prev_task'", ".", "format", "(", "n", ")", ",", "p", ".", "data", ".", "clone", "(", ")", ")", "\n", "\n", "\n", "", "", "", "for", "epoch", "in", "range", "(", "args", ".", "epc_per_virtual_task", "*", "args", ".", "tasks", ")", ":", "\n", "\n", "## training", "\n", "        ", "progress", "=", "tqdm", ".", "tqdm", "(", "range", "(", "1", ",", "args", ".", "iterations_per_virtual_epc", "+", "1", ")", ")", "\n", "\n", "for", "batch_index", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "train_datasets", ")", ":", "\n", "\n", "# Prepare <dicts> to store running importance estimates and param-values before update (\"Synaptic Intelligence\")", "\n", "            ", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "                ", "W", "=", "{", "}", "\n", "p_old", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "p", ".", "requires_grad", ":", "\n", "                        ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "W", "[", "n", "]", "=", "p", ".", "data", ".", "clone", "(", ")", ".", "zero_", "(", ")", "\n", "p_old", "[", "n", "]", "=", "p", ".", "data", ".", "clone", "(", ")", "\n", "\n", "\n", "", "", "", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "x_", ",", "y_", "=", "None", ",", "None", "\n", "loss_dict", "=", "model", ".", "train_a_batch", "(", "args", ",", "x", ",", "y", ",", "x_", ",", "y_", ")", "\n", "\n", "\n", "\n", "# Update running parameter importance estimates in W", "\n", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "                ", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "p", ".", "requires_grad", ":", "\n", "                        ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                            ", "W", "[", "n", "]", ".", "add_", "(", "-", "p", ".", "grad", "*", "(", "p", ".", "detach", "(", ")", "-", "p_old", "[", "n", "]", ")", ")", "\n", "", "p_old", "[", "n", "]", "=", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "\n", "\n", "", "", "", "for", "loss_cb", "in", "loss_cbs", ":", "\n", "                ", "if", "loss_cb", "is", "not", "None", ":", "\n", "                    ", "loss_cb", "(", "progress", ",", "batch_index", ",", "loss_dict", ",", "epoch", ")", "\n", "\n", "\n", "# EWC: estimate Fisher Information matrix (FIM) and update term for quadratic penalty", "\n", "", "", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "ewc_lambda", ">", "0", ")", ":", "\n", "# -estimate FI-matrix", "\n", "                ", "model", ".", "estimate_fisher", "(", "args", ",", "x", ",", "y", ")", "\n", "\n", "# SI: calculate and update the normalized path integral", "\n", "", "if", "isinstance", "(", "model", ",", "ContinualLearner", ")", "and", "(", "model", ".", "si_c", ">", "0", ")", ":", "\n", "                ", "model", ".", "update_omega", "(", "W", ",", "model", ".", "epsilon", ")", "\n", "\n", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n", "\n", "## testing", "\n", "if", "epoch", "%", "args", ".", "epc_per_virtual_task", "==", "0", ":", "\n", "            ", "task", "=", "args", ".", "task_dict", "[", "int", "(", "y", ".", "max", "(", ")", ")", "]", "\n", "\n", "for", "eval_cb", "in", "eval_cbs", ":", "\n", "                ", "if", "eval_cb", "is", "not", "None", ":", "\n", "                    ", "eval_cb", "(", "args", ",", "model", ",", "batch_index", ",", "task", "=", "task", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.param_stamp.get_param_stamp": [[2, 34], ["print", "hasattr", "print", "print", "print", "hasattr"], "function", ["None"], ["def", "get_param_stamp", "(", "args", ",", "model_name", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "'''Based on the input-arguments, produce a \"parameter-stamp\".'''", "\n", "\n", "# -for task", "\n", "multi_n_stamp", "=", "\"{n}-{set}\"", ".", "format", "(", "n", "=", "args", ".", "tasks", ",", "set", "=", "args", ".", "scenario", ")", "if", "hasattr", "(", "args", ",", "\"tasks\"", ")", "else", "\"\"", "\n", "task_stamp", "=", "\"{exp}{multi_n}\"", ".", "format", "(", "exp", "=", "args", ".", "experiment", ",", "multi_n", "=", "multi_n_stamp", ")", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\"\\n\"", "+", "\" --> task:          \"", "+", "task_stamp", ")", "\n", "\n", "# -for model", "\n", "", "model_stamp", "=", "model_name", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\" --> model:         \"", "+", "model_stamp", ")", "\n", "\n", "# -for hyper-parameters", "\n", "", "hyper_stamp", "=", "\"{i_e}{num}-lr{lr}{lrg}-b{bsz}-{optim}\"", ".", "format", "(", "\n", "i_e", "=", "\"e\"", "if", "args", ".", "iters", "is", "None", "else", "\"i\"", ",", "num", "=", "args", ".", "epochs", "if", "args", ".", "iters", "is", "None", "else", "args", ".", "iters", ",", "lr", "=", "args", ".", "lr", ",", "\n", "lrg", "=", "(", "\"\"", "if", "args", ".", "lr", "==", "args", ".", "lr_gen", "else", "\"-lrG{}\"", ".", "format", "(", "args", ".", "lr_gen", ")", ")", "if", "hasattr", "(", "args", ",", "\"lr_gen\"", ")", "else", "\"\"", ",", "\n", "bsz", "=", "args", ".", "batch", ",", "optim", "=", "args", ".", "optimizer", ",", "\n", ")", "\n", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "\" --> hyper-params:  \"", "+", "hyper_stamp", ")", "\n", "\n", "\n", "# --> combine", "\n", "", "param_stamp", "=", "\"{}--{}--{}{}\"", ".", "format", "(", "\n", "task_stamp", ",", "model_stamp", ",", "hyper_stamp", ",", "\"-s{}\"", ".", "format", "(", "args", ".", "seed", ")", "if", "not", "args", ".", "seed", "==", "0", "else", "\"\"", ")", "\n", "\n", "## Print param-stamp on screen and return", "\n", "print", "(", "param_stamp", ")", "\n", "return", "param_stamp", "", "", ""]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.open_pdf": [[12, 14], ["matplotlib.backends.backend_pdf.PdfPages"], "function", ["None"], ["def", "open_pdf", "(", "full_path", ")", ":", "\n", "    ", "return", "PdfPages", "(", "full_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.plot_images_from_tensor": [[16, 27], ["torchvision.utils.make_grid", "matplotlib.imshow", "numpy.transpose", "matplotlib.title", "pdf.savefig", "torchvision.utils.make_grid.numpy"], "function", ["None"], ["", "def", "plot_images_from_tensor", "(", "image_tensor", ",", "pdf", "=", "None", ",", "nrow", "=", "8", ",", "title", "=", "None", ")", ":", "\n", "    ", "'''Plot images in [image_tensor] as a grid with [nrow] into [pdf].\n\n    [image_tensor]      <tensor> [batch_size]x[channels]x[width]x[height]'''", "\n", "\n", "image_grid", "=", "make_grid", "(", "image_tensor", ",", "nrow", "=", "nrow", ",", "pad_value", "=", "1", ")", "# pad_value=0 would give black borders", "\n", "plt", ".", "imshow", "(", "np", ".", "transpose", "(", "image_grid", ".", "numpy", "(", ")", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", "\n", "if", "title", ":", "\n", "        ", "plt", ".", "title", "(", "title", ")", "\n", "", "if", "pdf", "is", "not", "None", ":", "\n", "        ", "pdf", ".", "savefig", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.plot_scatter_groups": [[29, 70], ["matplotlib.subplots", "enumerate", "len", "axarr.scatter", "axarr.scatter", "axarr.set_ylim", "axarr.set_xlim", "axarr.set_xlabel", "axarr.set_ylabel", "axarr.set_title", "f.suptitle", "axarr.legend", "str", "range", "numpy.mean", "numpy.mean"], "function", ["None"], ["", "", "def", "plot_scatter_groups", "(", "x", ",", "y", ",", "colors", "=", "None", ",", "ylabel", "=", "None", ",", "xlabel", "=", "None", ",", "title", "=", "None", ",", "top_title", "=", "None", ",", "names", "=", "None", ",", "\n", "xlim", "=", "None", ",", "ylim", "=", "None", ",", "markers", "=", "None", ",", "figsize", "=", "None", ")", ":", "\n", "    ", "'''Generate a figure containing a scatter-plot.'''", "\n", "\n", "# if needed, generate default group-names", "\n", "if", "names", "==", "None", ":", "\n", "        ", "n_groups", "=", "len", "(", "y", ")", "\n", "names", "=", "[", "\"group \"", "+", "str", "(", "id", ")", "for", "id", "in", "range", "(", "n_groups", ")", "]", "\n", "\n", "# make plot", "\n", "", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "(", "12", ",", "7", ")", "if", "figsize", "is", "None", "else", "figsize", ")", "\n", "for", "i", ",", "name", "in", "enumerate", "(", "names", ")", ":", "\n", "# plot individual points", "\n", "        ", "axarr", ".", "scatter", "(", "x", "=", "x", "[", "i", "]", ",", "y", "=", "y", "[", "i", "]", ",", "color", "=", "None", "if", "(", "colors", "is", "None", ")", "else", "colors", "[", "i", "]", ",", "\n", "marker", "=", "\"o\"", "if", "markers", "is", "None", "else", "markers", "[", "i", "]", ",", "s", "=", "40", ",", "alpha", "=", "0.5", ")", "\n", "# plot group means", "\n", "axarr", ".", "scatter", "(", "x", "=", "np", ".", "mean", "(", "x", "[", "i", "]", ")", ",", "y", "=", "np", ".", "mean", "(", "y", "[", "i", "]", ")", ",", "color", "=", "None", "if", "(", "colors", "is", "None", ")", "else", "colors", "[", "i", "]", ",", "label", "=", "name", ",", "\n", "marker", "=", "\"*\"", "if", "markers", "is", "None", "else", "markers", "[", "i", "]", ",", "s", "=", "160", ")", "\n", "\n", "# finish layout", "\n", "# -set y/x-axis", "\n", "", "if", "ylim", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_ylim", "(", "ylim", ")", "\n", "", "if", "xlim", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_xlim", "(", "xlim", ")", "\n", "# -add axis-labels", "\n", "", "if", "xlabel", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_xlabel", "(", "xlabel", ")", "\n", "", "if", "ylabel", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# -add title(s)", "\n", "", "if", "title", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_title", "(", "title", ")", "\n", "", "if", "top_title", "is", "not", "None", ":", "\n", "        ", "f", ".", "suptitle", "(", "top_title", ")", "\n", "# -add legend", "\n", "", "if", "names", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "legend", "(", ")", "\n", "\n", "# return the figure", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.plot_bar": [[72, 101], ["len", "matplotlib.subplots", "axarr.bar", "axarr.set_xticks", "range", "axarr.set_xticklabels", "axarr.legend", "axarr.set_ylabel", "axarr.set_title", "f.suptitle", "axarr.set_ylim", "range"], "function", ["None"], ["", "def", "plot_bar", "(", "numbers", ",", "names", "=", "None", ",", "colors", "=", "None", ",", "ylabel", "=", "None", ",", "title", "=", "None", ",", "top_title", "=", "None", ",", "ylim", "=", "None", ",", "figsize", "=", "None", ",", "\n", "yerr", "=", "None", ")", ":", "\n", "    ", "'''Generate a figure containing a bar-graph.'''", "\n", "\n", "# number of bars", "\n", "n_bars", "=", "len", "(", "numbers", ")", "\n", "\n", "# make plot", "\n", "size", "=", "(", "12", ",", "7", ")", "if", "figsize", "is", "None", "else", "figsize", "\n", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "size", ")", "\n", "axarr", ".", "bar", "(", "x", "=", "range", "(", "n_bars", ")", ",", "height", "=", "numbers", ",", "color", "=", "colors", ",", "yerr", "=", "yerr", ")", "\n", "\n", "# finish layout", "\n", "axarr", ".", "set_xticks", "(", "range", "(", "n_bars", ")", ")", "\n", "if", "names", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_xticklabels", "(", "names", ",", "rotation", "=", "-", "20", ")", "\n", "axarr", ".", "legend", "(", ")", "\n", "", "if", "ylabel", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_ylabel", "(", "ylabel", ")", "\n", "", "if", "title", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_title", "(", "title", ")", "\n", "", "if", "top_title", "is", "not", "None", ":", "\n", "        ", "f", ".", "suptitle", "(", "top_title", ")", "\n", "# -set y-axis", "\n", "", "if", "ylim", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_ylim", "(", "ylim", ")", "\n", "\n", "# return the figure", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.plot_lines": [[103, 207], ["matplotlib.subplots", "enumerate", "len", "list", "len", "enumerate", "axarr.plot", "axarr.axhline", "enumerate", "axarr.set_ylim", "axarr.set_xlabel", "axarr.set_ylabel", "axarr.set_title", "f.suptitle", "axarr.legend", "axarr.set_xscale", "range", "axarr.axhline", "str", "range", "axarr.fill_between", "axarr.plot", "axarr.plot", "axarr.fill_between", "axarr.axhline", "axarr.axhline", "list", "list", "list", "list", "axarr.fill_between", "axarr.axhline", "axarr.axhline", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "plot_lines", "(", "list_with_lines", ",", "x_axes", "=", "None", ",", "line_names", "=", "None", ",", "colors", "=", "None", ",", "title", "=", "None", ",", "\n", "title_top", "=", "None", ",", "xlabel", "=", "None", ",", "ylabel", "=", "None", ",", "ylim", "=", "None", ",", "figsize", "=", "None", ",", "list_with_errors", "=", "None", ",", "errors", "=", "\"shaded\"", ",", "\n", "x_log", "=", "False", ",", "with_dots", "=", "False", ",", "h_line", "=", "None", ",", "h_label", "=", "None", ",", "h_error", "=", "None", ",", "\n", "h_lines", "=", "None", ",", "h_colors", "=", "None", ",", "h_labels", "=", "None", ",", "h_errors", "=", "None", ")", ":", "\n", "    ", "'''Generates a figure containing multiple lines in one plot.\n\n    :param list_with_lines: <list> of all lines to plot (with each line being a <list> as well)\n    :param x_axes:          <list> containing the values for the x-axis\n    :param line_names:      <list> containing the names of each line\n    :param colors:          <list> containing the colors of each line\n    :param title:           <str> title of plot\n    :param title_top:       <str> text to appear on top of the title\n    :return: f:             <figure>\n    '''", "\n", "\n", "# if needed, generate default x-axis", "\n", "if", "x_axes", "==", "None", ":", "\n", "        ", "n_obs", "=", "len", "(", "list_with_lines", "[", "0", "]", ")", "\n", "x_axes", "=", "list", "(", "range", "(", "n_obs", ")", ")", "\n", "\n", "# if needed, generate default line-names", "\n", "", "if", "line_names", "==", "None", ":", "\n", "        ", "n_lines", "=", "len", "(", "list_with_lines", ")", "\n", "line_names", "=", "[", "\"line \"", "+", "str", "(", "line_id", ")", "for", "line_id", "in", "range", "(", "n_lines", ")", "]", "\n", "\n", "# make plot", "\n", "", "size", "=", "(", "12", ",", "7", ")", "if", "figsize", "is", "None", "else", "figsize", "\n", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "1", ",", "figsize", "=", "size", ")", "\n", "\n", "# add error-lines / shaded areas", "\n", "if", "list_with_errors", "is", "not", "None", ":", "\n", "        ", "for", "task_id", ",", "name", "in", "enumerate", "(", "line_names", ")", ":", "\n", "            ", "if", "errors", "==", "\"shaded\"", ":", "\n", "                ", "axarr", ".", "fill_between", "(", "x_axes", ",", "list", "(", "np", ".", "array", "(", "list_with_lines", "[", "task_id", "]", ")", "+", "np", ".", "array", "(", "list_with_errors", "[", "task_id", "]", ")", ")", ",", "\n", "list", "(", "np", ".", "array", "(", "list_with_lines", "[", "task_id", "]", ")", "-", "np", ".", "array", "(", "list_with_errors", "[", "task_id", "]", ")", ")", ",", "\n", "color", "=", "None", "if", "(", "colors", "is", "None", ")", "else", "colors", "[", "task_id", "]", ",", "alpha", "=", "0.25", ")", "\n", "", "else", ":", "\n", "                ", "axarr", ".", "plot", "(", "x_axes", ",", "list", "(", "np", ".", "array", "(", "list_with_lines", "[", "task_id", "]", ")", "+", "np", ".", "array", "(", "list_with_errors", "[", "task_id", "]", ")", ")", ",", "label", "=", "None", ",", "\n", "color", "=", "None", "if", "(", "colors", "is", "None", ")", "else", "colors", "[", "task_id", "]", ",", "linewidth", "=", "1", ",", "linestyle", "=", "'dashed'", ")", "\n", "axarr", ".", "plot", "(", "x_axes", ",", "list", "(", "np", ".", "array", "(", "list_with_lines", "[", "task_id", "]", ")", "-", "np", ".", "array", "(", "list_with_errors", "[", "task_id", "]", ")", ")", ",", "label", "=", "None", ",", "\n", "color", "=", "None", "if", "(", "colors", "is", "None", ")", "else", "colors", "[", "task_id", "]", ",", "linewidth", "=", "1", ",", "linestyle", "=", "'dashed'", ")", "\n", "\n", "# mean lines", "\n", "", "", "", "for", "task_id", ",", "name", "in", "enumerate", "(", "line_names", ")", ":", "\n", "        ", "axarr", ".", "plot", "(", "x_axes", ",", "list_with_lines", "[", "task_id", "]", ",", "label", "=", "name", ",", "\n", "color", "=", "None", "if", "(", "colors", "is", "None", ")", "else", "colors", "[", "task_id", "]", ",", "\n", "linewidth", "=", "2", ",", "marker", "=", "'o'", "if", "with_dots", "else", "None", ")", "\n", "\n", "# add horizontal line", "\n", "", "if", "h_line", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "axhline", "(", "y", "=", "h_line", ",", "label", "=", "h_label", ",", "color", "=", "\"grey\"", ")", "\n", "if", "h_error", "is", "not", "None", ":", "\n", "            ", "if", "errors", "==", "\"shaded\"", ":", "\n", "                ", "axarr", ".", "fill_between", "(", "[", "x_axes", "[", "0", "]", ",", "x_axes", "[", "-", "1", "]", "]", ",", "\n", "[", "h_line", "+", "h_error", ",", "h_line", "+", "h_error", "]", ",", "[", "h_line", "-", "h_error", ",", "h_line", "-", "h_error", "]", ",", "\n", "color", "=", "\"grey\"", ",", "alpha", "=", "0.25", ")", "\n", "", "else", ":", "\n", "                ", "axarr", ".", "axhline", "(", "y", "=", "h_line", "+", "h_error", ",", "label", "=", "None", ",", "color", "=", "\"grey\"", ",", "linewidth", "=", "1", ",", "linestyle", "=", "'dashed'", ")", "\n", "axarr", ".", "axhline", "(", "y", "=", "h_line", "-", "h_error", ",", "label", "=", "None", ",", "color", "=", "\"grey\"", ",", "linewidth", "=", "1", ",", "linestyle", "=", "'dashed'", ")", "\n", "\n", "# add horizontal lines", "\n", "", "", "", "if", "h_lines", "is", "not", "None", ":", "\n", "        ", "h_colors", "=", "colors", "if", "h_colors", "is", "None", "else", "h_colors", "\n", "for", "task_id", ",", "new_h_line", "in", "enumerate", "(", "h_lines", ")", ":", "\n", "            ", "axarr", ".", "axhline", "(", "y", "=", "new_h_line", ",", "label", "=", "None", "if", "h_labels", "is", "None", "else", "h_labels", "[", "task_id", "]", ",", "\n", "color", "=", "None", "if", "(", "h_colors", "is", "None", ")", "else", "h_colors", "[", "task_id", "]", ")", "\n", "if", "h_errors", "is", "not", "None", ":", "\n", "                ", "if", "errors", "==", "\"shaded\"", ":", "\n", "                    ", "axarr", ".", "fill_between", "(", "[", "x_axes", "[", "0", "]", ",", "x_axes", "[", "-", "1", "]", "]", ",", "\n", "[", "new_h_line", "+", "h_errors", "[", "task_id", "]", ",", "new_h_line", "+", "h_errors", "[", "task_id", "]", "]", ",", "\n", "[", "new_h_line", "-", "h_errors", "[", "task_id", "]", ",", "new_h_line", "-", "h_errors", "[", "task_id", "]", "]", ",", "\n", "color", "=", "None", "if", "(", "h_colors", "is", "None", ")", "else", "h_colors", "[", "task_id", "]", ",", "alpha", "=", "0.25", ")", "\n", "", "else", ":", "\n", "                    ", "axarr", ".", "axhline", "(", "y", "=", "new_h_line", "+", "h_errors", "[", "task_id", "]", ",", "label", "=", "None", ",", "\n", "color", "=", "None", "if", "(", "h_colors", "is", "None", ")", "else", "h_colors", "[", "task_id", "]", ",", "linewidth", "=", "1", ",", "\n", "linestyle", "=", "'dashed'", ")", "\n", "axarr", ".", "axhline", "(", "y", "=", "new_h_line", "-", "h_errors", "[", "task_id", "]", ",", "label", "=", "None", ",", "\n", "color", "=", "None", "if", "(", "h_colors", "is", "None", ")", "else", "h_colors", "[", "task_id", "]", ",", "linewidth", "=", "1", ",", "\n", "linestyle", "=", "'dashed'", ")", "\n", "\n", "# finish layout", "\n", "# -set y-axis", "\n", "", "", "", "", "if", "ylim", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_ylim", "(", "ylim", ")", "\n", "# -add axis-labels", "\n", "", "if", "xlabel", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_xlabel", "(", "xlabel", ")", "\n", "", "if", "ylabel", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_ylabel", "(", "ylabel", ")", "\n", "# -add title(s)", "\n", "", "if", "title", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "set_title", "(", "title", ")", "\n", "", "if", "title_top", "is", "not", "None", ":", "\n", "        ", "f", ".", "suptitle", "(", "title_top", ")", "\n", "# -add legend", "\n", "", "if", "line_names", "is", "not", "None", ":", "\n", "        ", "axarr", ".", "legend", "(", ")", "\n", "\n", "# -set x-axis to log-scale", "\n", "", "if", "x_log", ":", "\n", "        ", "axarr", ".", "set_xscale", "(", "'log'", ")", "\n", "\n", "# return the figure", "\n", "", "return", "f", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.visual_plt.plot_bars": [[209, 257], ["len", "range", "matplotlib.subplots", "range", "n_bars.append", "numpy.max", "axarr[].bar", "axarr[].set_xticks", "f.suptitle", "len", "numpy.max", "axarr[].set_ylim", "axarr[].set_ylim", "range", "axarr[].set_xticklabels", "axarr[].legend", "axarr[].set_ylabel", "axarr[].set_title", "range", "type", "type"], "function", ["None"], ["", "def", "plot_bars", "(", "number_list", ",", "names", "=", "None", ",", "colors", "=", "None", ",", "ylabel", "=", "None", ",", "title_list", "=", "None", ",", "top_title", "=", "None", ",", "ylim", "=", "None", ",", "\n", "figsize", "=", "None", ",", "yerr", "=", "None", ")", ":", "\n", "    ", "'''Generate a figure containing multiple bar-graphs.\n\n    [number_list]   <list> with <lists> of numbers to plot in each sub-graph\n    [names]         <list> (with <lists>) of names for axis\n    [colors]        <list> (with <lists>) of colors'''", "\n", "\n", "# number of plots", "\n", "n_plots", "=", "len", "(", "number_list", ")", "\n", "\n", "# number of bars per plot", "\n", "n_bars", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "n_plots", ")", ":", "\n", "        ", "n_bars", ".", "append", "(", "len", "(", "number_list", "[", "i", "]", ")", ")", "\n", "\n", "# decide on scale y-axis", "\n", "", "y_max", "=", "np", ".", "max", "(", "number_list", ")", "+", "0.07", "*", "np", ".", "max", "(", "number_list", ")", "\n", "\n", "# make figure", "\n", "size", "=", "(", "16", ",", "7", ")", "if", "figsize", "is", "None", "else", "figsize", "\n", "f", ",", "axarr", "=", "plt", ".", "subplots", "(", "1", ",", "n_plots", ",", "figsize", "=", "size", ")", "\n", "\n", "# make all plots", "\n", "for", "i", "in", "range", "(", "n_plots", ")", ":", "\n", "        ", "axarr", "[", "i", "]", ".", "bar", "(", "x", "=", "range", "(", "n_bars", "[", "i", "]", ")", ",", "height", "=", "number_list", "[", "i", "]", ",", "color", "=", "colors", "[", "i", "]", "if", "type", "(", "colors", "[", "0", "]", ")", "==", "list", "else", "colors", ",", "\n", "yerr", "=", "yerr", "[", "i", "]", "if", "yerr", "is", "not", "None", "else", "None", ")", "\n", "\n", "# finish layout for this plot", "\n", "if", "ylim", "is", "None", ":", "\n", "            ", "axarr", "[", "i", "]", ".", "set_ylim", "(", "0", ",", "y_max", ")", "\n", "", "else", ":", "\n", "            ", "axarr", "[", "i", "]", ".", "set_ylim", "(", "ylim", ")", "\n", "", "axarr", "[", "i", "]", ".", "set_xticks", "(", "range", "(", "n_bars", "[", "i", "]", ")", ")", "\n", "if", "names", "is", "not", "None", ":", "\n", "            ", "axarr", "[", "i", "]", ".", "set_xticklabels", "(", "names", "[", "i", "]", "if", "type", "(", "names", "[", "0", "]", ")", "==", "list", "else", "names", ",", "rotation", "=", "-", "20", ")", "\n", "axarr", "[", "i", "]", ".", "legend", "(", ")", "\n", "", "if", "i", "==", "0", "and", "ylabel", "is", "not", "None", ":", "\n", "            ", "axarr", "[", "i", "]", ".", "set_ylabel", "(", "ylabel", ")", "\n", "", "if", "title_list", "is", "not", "None", ":", "\n", "            ", "axarr", "[", "i", "]", ".", "set_title", "(", "title_list", "[", "i", "]", ")", "\n", "\n", "# finish global layout", "\n", "", "", "if", "top_title", "is", "not", "None", ":", "\n", "        ", "f", ".", "suptitle", "(", "top_title", ")", "\n", "\n", "# return the figure", "\n", "", "return", "f", "", "", ""]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.__init__": [[16, 34], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "# XdG:", "\n", "self", ".", "mask_dict", "=", "None", "# -> <dict> with task-specific masks for each hidden fully-connected layer", "\n", "self", ".", "excit_buffer_list", "=", "[", "]", "# -> <list> with excit-buffers for all hidden fully-connected layers", "\n", "\n", "# -SI:", "\n", "self", ".", "si_c", "=", "0", "#-> hyperparam: how strong to weigh SI-loss (\"regularisation strength\")", "\n", "self", ".", "epsilon", "=", "0.1", "#-> dampening parameter: bounds 'omega' when squared parameter-change goes to 0", "\n", "\n", "# -EWC:", "\n", "self", ".", "ewc_lambda", "=", "0", "#-> hyperparam: how strong to weigh EWC-loss (\"regularisation strength\")", "\n", "self", ".", "gamma", "=", "1.", "#-> hyperparam (online EWC): decay-term for old tasks' contribution to quadratic term", "\n", "self", ".", "online", "=", "True", "#-> \"online\" (=single quadratic term) or \"offline\" (=quadratic term per task) EWC", "\n", "self", ".", "fisher_n", "=", "None", "#-> sample size for estimating FI-matrix (if \"None\", full pass over dataset)", "\n", "self", ".", "emp_FI", "=", "False", "#-> if True, use provided labels to calculate FI (\"empirical FI\"); else predicted labels", "\n", "self", ".", "EWC_task_count", "=", "0", "#-> keeps track of number of quadratic loss terms (for \"offline EWC\")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device": [[35, 37], ["next", "continual_learner.ContinualLearner.parameters"], "methods", ["None"], ["", "def", "_device", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._is_on_cuda": [[38, 40], ["next", "continual_learner.ContinualLearner.parameters"], "methods", ["None"], ["", "def", "_is_on_cuda", "(", "self", ")", ":", "\n", "        ", "return", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "is_cuda", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.forward": [[41, 44], ["None"], "methods", ["None"], ["", "@", "abc", ".", "abstractmethod", "\n", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.estimate_fisher": [[48, 133], ["continual_learner.ContinualLearner.named_parameters", "continual_learner.ContinualLearner.eval", "utils.get_data_loader", "enumerate", "continual_learner.ContinualLearner.named_parameters", "continual_learner.ContinualLearner.train", "len", "x.to.to.to", "continual_learner.ContinualLearner.named_parameters", "n.replace.replace.replace", "p.detach().clone().zero_", "continual_learner.ContinualLearner._is_on_cuda", "continual_learner.ContinualLearner._device", "continual_learner.ContinualLearner.", "continual_learner.ContinualLearner.zero_grad", "torch.nn.functional.nll_loss.backward", "est_fisher_info.items", "n.replace.replace.replace", "continual_learner.ContinualLearner.register_buffer", "continual_learner.ContinualLearner.register_buffer", "range", "torch.tensor().long().cuda", "torch.nn.functional.nll_loss", "torch.nn.functional.nll_loss", "n.replace.replace.replace", "p.detach().clone", "getattr", "p.detach().clone", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.tensor().long", "p.grad.detach", "p.detach", "p.detach", "torch.tensor", "seen_classes_list.index"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.get_data_loader", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._is_on_cuda", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device"], ["", "def", "estimate_fisher", "(", "self", ",", "args", ",", "dataset", ",", "task", ",", "allowed_classes", "=", "None", ",", "collate_fn", "=", "None", ")", ":", "\n", "        ", "'''After completing training on a task, estimate diagonal of Fisher Information matrix.\n\n        [dataset]:          <DataSet> to be used to estimate FI-matrix\n        [allowed_classes]:  <list> with class-indeces of 'allowed' or 'active' classes'''", "\n", "\n", "# Prepare <dict> to store estimated Fisher Information matrix", "\n", "est_fisher_info", "=", "{", "}", "\n", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "est_fisher_info", "[", "n", "]", "=", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "zero_", "(", ")", "\n", "\n", "# Set model to evaluation mode", "\n", "", "", "mode", "=", "self", ".", "training", "\n", "self", ".", "eval", "(", ")", "\n", "\n", "# Create data-loader to give batches of size 1", "\n", "# data_loader = utils.get_data_loader(dataset, batch_size=1, cuda=self._is_on_cuda(), collate_fn=collate_fn)", "\n", "data_loader", "=", "utils", ".", "get_data_loader", "(", "dataset", ",", "batch_size", "=", "args", ".", "batch", ",", "cuda", "=", "self", ".", "_is_on_cuda", "(", ")", ",", "collate_fn", "=", "collate_fn", ")", "\n", "\n", "# Estimate the FI-matrix for [self.fisher_n] batches of size 1", "\n", "count", "=", "0", "\n", "for", "index", ",", "(", "x", ",", "y", ")", "in", "enumerate", "(", "data_loader", ")", ":", "\n", "            ", "count", "+=", "len", "(", "x", ")", "\n", "# break from for-loop if max number of samples has been reached", "\n", "if", "self", ".", "fisher_n", "is", "not", "None", ":", "\n", "                ", "if", "index", ">=", "self", ".", "fisher_n", ":", "\n", "                    ", "break", "\n", "# run forward pass of model", "\n", "", "", "x", "=", "x", ".", "to", "(", "self", ".", "_device", "(", ")", ")", "\n", "\n", "\n", "if", "not", "args", ".", "ebm", ":", "\n", "                ", "y_hat", "=", "self", "(", "x", ")", "\n", "\n", "over_seen_classes", "=", "True", "\n", "if", "over_seen_classes", ":", "\n", "                    ", "seen_classes_list", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "task", ")", ":", "\n", "                        ", "seen_classes_list", "+=", "self", ".", "labels_per_task", "[", "i", "]", "\n", "\n", "", "y_hat", "=", "y_hat", "[", ":", ",", "seen_classes_list", "]", "\n", "\n", "## compute loss", "\n", "y_tem", "=", "torch", ".", "tensor", "(", "[", "seen_classes_list", ".", "index", "(", "tem", ")", "for", "tem", "in", "y", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "negloglikelihood", "=", "F", ".", "nll_loss", "(", "F", ".", "log_softmax", "(", "y_hat", ",", "dim", "=", "1", ")", ",", "y_tem", ")", "\n", "", "else", ":", "\n", "                    ", "negloglikelihood", "=", "F", ".", "nll_loss", "(", "F", ".", "log_softmax", "(", "y_hat", ",", "dim", "=", "1", ")", ",", "y", ")", "\n", "\n", "# Calculate gradient of negative loglikelihood", "\n", "", "self", ".", "zero_grad", "(", ")", "\n", "negloglikelihood", ".", "backward", "(", ")", "\n", "\n", "\n", "# Square gradients and keep running sum", "\n", "", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "requires_grad", ":", "\n", "                    ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "if", "p", ".", "grad", "is", "not", "None", ":", "\n", "                        ", "est_fisher_info", "[", "n", "]", "+=", "p", ".", "grad", ".", "detach", "(", ")", "**", "2", "\n", "\n", "# Normalize by sample size used for estimation", "\n", "", "", "", "", "est_fisher_info", "=", "{", "n", ":", "p", "/", "index", "for", "n", ",", "p", "in", "est_fisher_info", ".", "items", "(", ")", "}", "\n", "# est_fisher_info = {n: p/count for n, p in est_fisher_info.items()}", "\n", "\n", "# Store new values in the network", "\n", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "# -mode (=MAP parameter estimate)", "\n", "self", ".", "register_buffer", "(", "'{}_EWC_prev_task{}'", ".", "format", "(", "n", ",", "\"\"", "if", "self", ".", "online", "else", "self", ".", "EWC_task_count", "+", "1", ")", ",", "\n", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", ")", "\n", "# -precision (approximated by diagonal Fisher Information matrix)", "\n", "if", "self", ".", "online", "and", "self", ".", "EWC_task_count", "==", "1", ":", "\n", "                    ", "existing_values", "=", "getattr", "(", "self", ",", "'{}_EWC_estimated_fisher'", ".", "format", "(", "n", ")", ")", "\n", "est_fisher_info", "[", "n", "]", "+=", "self", ".", "gamma", "*", "existing_values", "\n", "", "self", ".", "register_buffer", "(", "'{}_EWC_estimated_fisher{}'", ".", "format", "(", "n", ",", "\"\"", "if", "self", ".", "online", "else", "self", ".", "EWC_task_count", "+", "1", ")", ",", "\n", "est_fisher_info", "[", "n", "]", ")", "\n", "\n", "# If \"offline EWC\", increase task-count (for \"online EWC\", set it to 1 to indicate EWC-loss can be calculated)", "\n", "", "", "self", ".", "EWC_task_count", "=", "1", "if", "self", ".", "online", "else", "self", ".", "EWC_task_count", "+", "1", "\n", "\n", "# Set model back to its initial mode", "\n", "self", ".", "train", "(", "mode", "=", "mode", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.ewc_loss": [[135, 156], ["range", "torch.tensor", "continual_learner.ContinualLearner.named_parameters", "sum", "continual_learner.ContinualLearner._device", "n.replace.replace.replace", "getattr", "getattr", "losses.append"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device"], ["", "def", "ewc_loss", "(", "self", ")", ":", "\n", "        ", "'''Calculate EWC-loss.'''", "\n", "if", "self", ".", "EWC_task_count", ">", "0", ":", "\n", "            ", "losses", "=", "[", "]", "\n", "# If \"offline EWC\", loop over all previous tasks (if \"online EWC\", [EWC_task_count]=1 so only 1 iteration)", "\n", "for", "task", "in", "range", "(", "1", ",", "self", ".", "EWC_task_count", "+", "1", ")", ":", "\n", "                ", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "                    ", "if", "p", ".", "requires_grad", ":", "\n", "# Retrieve stored mode (MAP estimate) and precision (Fisher Information matrix)", "\n", "                        ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "mean", "=", "getattr", "(", "self", ",", "'{}_EWC_prev_task{}'", ".", "format", "(", "n", ",", "\"\"", "if", "self", ".", "online", "else", "task", ")", ")", "\n", "fisher", "=", "getattr", "(", "self", ",", "'{}_EWC_estimated_fisher{}'", ".", "format", "(", "n", ",", "\"\"", "if", "self", ".", "online", "else", "task", ")", ")", "\n", "# If \"online EWC\", apply decay-term to the running sum of the Fisher Information matrices", "\n", "fisher", "=", "self", ".", "gamma", "*", "fisher", "if", "self", ".", "online", "else", "fisher", "\n", "# Calculate EWC-loss", "\n", "losses", ".", "append", "(", "(", "fisher", "*", "(", "p", "-", "mean", ")", "**", "2", ")", ".", "sum", "(", ")", ")", "\n", "# Sum EWC-loss from all parameters (and from all tasks, if \"offline EWC\")", "\n", "", "", "", "return", "(", "1.", "/", "2", ")", "*", "sum", "(", "losses", ")", "\n", "", "else", ":", "\n", "# EWC-loss is 0 if there are no stored mode and precision yet", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.", ",", "device", "=", "self", ".", "_device", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.update_omega": [[160, 185], ["continual_learner.ContinualLearner.named_parameters", "n.replace.replace.replace", "getattr", "p.detach().clone", "continual_learner.ContinualLearner.register_buffer", "continual_learner.ContinualLearner.register_buffer", "getattr", "p.detach", "p.detach().clone().zero_", "p.detach().clone", "p.detach"], "methods", ["None"], ["", "", "def", "update_omega", "(", "self", ",", "W", ",", "epsilon", ")", ":", "\n", "        ", "'''After completing training on a task, update the per-parameter regularization strength.\n\n        [W]         <dict> estimated parameter-specific contribution to changes in total loss of completed task\n        [epsilon]   <float> dampening parameter (to bound [omega] when [p_change] goes to 0)'''", "\n", "\n", "# Loop over all parameters", "\n", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "\n", "# Find/calculate new values for quadratic penalty on parameters", "\n", "p_prev", "=", "getattr", "(", "self", ",", "'{}_SI_prev_task'", ".", "format", "(", "n", ")", ")", "\n", "p_current", "=", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "p_change", "=", "p_current", "-", "p_prev", "\n", "omega_add", "=", "W", "[", "n", "]", "/", "(", "p_change", "**", "2", "+", "epsilon", ")", "\n", "try", ":", "\n", "                    ", "omega", "=", "getattr", "(", "self", ",", "'{}_SI_omega'", ".", "format", "(", "n", ")", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "omega", "=", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "zero_", "(", ")", "\n", "", "omega_new", "=", "omega", "+", "omega_add", "\n", "\n", "# Store these new values in the model", "\n", "self", ".", "register_buffer", "(", "'{}_SI_prev_task'", ".", "format", "(", "n", ")", ",", "p_current", ")", "\n", "self", ".", "register_buffer", "(", "'{}_SI_omega'", ".", "format", "(", "n", ")", ",", "omega_new", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.surrogate_loss": [[187, 203], ["continual_learner.ContinualLearner.named_parameters", "sum", "torch.tensor", "n.replace.replace.replace", "getattr", "getattr", "losses.append", "continual_learner.ContinualLearner._device"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device"], ["", "", "", "def", "surrogate_loss", "(", "self", ")", ":", "\n", "        ", "'''Calculate SI's surrogate loss.'''", "\n", "try", ":", "\n", "            ", "losses", "=", "[", "]", "\n", "for", "n", ",", "p", "in", "self", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "p", ".", "requires_grad", ":", "\n", "# Retrieve previous parameter values and their normalized path integral (i.e., omega)", "\n", "                    ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "prev_values", "=", "getattr", "(", "self", ",", "'{}_SI_prev_task'", ".", "format", "(", "n", ")", ")", "\n", "omega", "=", "getattr", "(", "self", ",", "'{}_SI_omega'", ".", "format", "(", "n", ")", ")", "\n", "# Calculate SI's surrogate loss, sum over all parameters", "\n", "losses", ".", "append", "(", "(", "omega", "*", "(", "p", "-", "prev_values", ")", "**", "2", ")", ".", "sum", "(", ")", ")", "\n", "", "", "return", "sum", "(", "losses", ")", "\n", "", "except", "AttributeError", ":", "\n", "# SI-loss is 0 if there is no stored omega yet", "\n", "            ", "return", "torch", ".", "tensor", "(", "0.", ",", "device", "=", "self", ".", "_device", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.callbacks._eval_cb": [[5, 25], ["evaluate.precision"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.evaluate.precision"], ["def", "_eval_cb", "(", "log", ",", "test_datasets", ",", "visdom", "=", "None", ",", "precision_dict", "=", "None", ",", "iters_per_task", "=", "None", ",", "\n", "test_size", "=", "None", ",", "labels_per_task", "=", "None", ",", "scenario", "=", "\"class\"", ",", "summary_graph", "=", "True", ",", "with_exemplars", "=", "False", ")", ":", "\n", "    ", "'''Initiates function for evaluating performance of classifier (in terms of precision).\n\n    [test_datasets]     <list> of <Datasets>; also if only 1 task, it should be presented as a list!\n    [scenario]          <str> how to decide which classes to include during evaluating precision'''", "\n", "\n", "def", "eval_cb", "(", "args", ",", "classifier", ",", "batch", ",", "task", "=", "1", ")", ":", "\n", "        ", "'''Callback-function, to evaluate performance of classifier.'''", "\n", "\n", "iteration", "=", "batch", "if", "task", "==", "1", "else", "(", "task", "-", "1", ")", "*", "iters_per_task", "+", "batch", "\n", "\n", "# evaluate the solver on multiple tasks (and log to visdom)", "\n", "if", "iteration", "%", "log", "==", "0", ":", "\n", "            ", "evaluate", ".", "precision", "(", "args", ",", "classifier", ",", "test_datasets", ",", "task", ",", "iteration", ",", "\n", "labels_per_task", "=", "labels_per_task", ",", "scenario", "=", "scenario", ",", "precision_dict", "=", "precision_dict", ",", "\n", "test_size", "=", "test_size", ",", "visdom", "=", "visdom", ",", "summary_graph", "=", "summary_graph", ",", "\n", "with_exemplars", "=", "with_exemplars", ")", "\n", "\n", "", "", "return", "eval_cb", "if", "(", "(", "visdom", "is", "not", "None", ")", "or", "(", "precision_dict", "is", "not", "None", ")", ")", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.callbacks._solver_loss_cb": [[28, 47], ["bar.set_description", "bar.update"], "function", ["None"], ["", "def", "_solver_loss_cb", "(", "log", ",", "model", "=", "None", ",", "tasks", "=", "None", ",", "iters_per_task", "=", "None", ",", "progress_bar", "=", "True", ")", ":", "\n", "    ", "'''Initiates function for keeping track of, and reporting on, the progress of the solver's training.'''", "\n", "\n", "def", "cb", "(", "bar", ",", "iter", ",", "loss_dict", ",", "task", "=", "1", ")", ":", "\n", "        ", "'''Callback-function, to call on every iteration to keep track of training progress.'''", "\n", "\n", "iteration", "=", "iter", "if", "task", "==", "1", "else", "(", "task", "-", "1", ")", "*", "iters_per_task", "+", "iter", "\n", "\n", "# progress-bar", "\n", "if", "progress_bar", "and", "bar", "is", "not", "None", ":", "\n", "            ", "task_stm", "=", "\"\"", "if", "(", "tasks", "is", "None", ")", "else", "\" Task: {}/{} |\"", ".", "format", "(", "task", ",", "tasks", ")", "\n", "\n", "bar", ".", "set_description", "(", "\n", "'  <SOLVER>   |{t_stm} training loss: {loss:.3} | training precision: {prec:.3} |'", "\n", ".", "format", "(", "t_stm", "=", "task_stm", ",", "loss", "=", "loss_dict", "[", "'loss_total'", "]", ",", "prec", "=", "loss_dict", "[", "'precision'", "]", ")", "\n", ")", "\n", "bar", ".", "update", "(", "1", ")", "\n", "\n", "", "", "return", "cb", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.Identity.forward": [[225, 227], ["None"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.Identity.__repr__": [[228, 231], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.Reshape.__init__": [[235, 238], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "image_channels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "image_channels", "=", "image_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.Reshape.forward": [[239, 243], ["x.size", "int", "x.view", "numpy.sqrt", "x.nelement"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "# first dimenstion should be batch-dimension.", "\n", "image_size", "=", "int", "(", "np", ".", "sqrt", "(", "x", ".", "nelement", "(", ")", "/", "(", "batch_size", "*", "self", ".", "image_channels", ")", ")", ")", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "self", ".", "image_channels", ",", "image_size", ",", "image_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.Reshape.__repr__": [[244, 247], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "'(channels = {})'", ".", "format", "(", "self", ".", "image_channels", ")", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.ToImage.__init__": [[255, 261], ["torch.nn.Module.__init__", "utils.Reshape", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "image_channels", "=", "1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# reshape to 4D-tensor", "\n", "self", ".", "reshape", "=", "Reshape", "(", "image_channels", "=", "image_channels", ")", "\n", "# put through sigmoid-nonlinearity", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.ToImage.forward": [[262, 266], ["utils.ToImage.reshape", "utils.ToImage.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "reshape", "(", "x", ")", "\n", "x", "=", "self", ".", "sigmoid", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.ToImage.image_size": [[267, 271], ["numpy.sqrt"], "methods", ["None"], ["", "def", "image_size", "(", "self", ",", "in_units", ")", ":", "\n", "        ", "'''Given the number of units fed in, return the size of the target image.'''", "\n", "image_size", "=", "np", ".", "sqrt", "(", "in_units", "/", "self", ".", "image_channels", ")", "\n", "return", "image_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.Flatten.forward": [[275, 278], ["x.size", "x.view"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "# first dimenstion should be batch-dimension.", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.Flatten.__repr__": [[279, 282], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.loss_fn_kd": [[20, 48], ["torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "scores.size", "KD_loss_unnorm.mean.sum", "KD_loss_unnorm.mean.mean", "target_scores.size", "scores.size", "torch.zeros", "zeros_to_add.to.to", "torch.cat", "target_scores.size", "torch.cat.detach"], "function", ["None"], ["def", "loss_fn_kd", "(", "scores", ",", "target_scores", ",", "T", "=", "2.", ")", ":", "\n", "    ", "\"\"\"Compute knowledge-distillation (KD) loss given [scores] and [target_scores].\n\n    Both [scores] and [target_scores] should be tensors, although [target_scores] should be repackaged.\n    'Hyperparameter': temperature\"\"\"", "\n", "\n", "device", "=", "scores", ".", "device", "\n", "\n", "log_scores_norm", "=", "F", ".", "log_softmax", "(", "scores", "/", "T", ",", "dim", "=", "1", ")", "\n", "targets_norm", "=", "F", ".", "softmax", "(", "target_scores", "/", "T", ",", "dim", "=", "1", ")", "\n", "\n", "# if [scores] and [target_scores] do not have equal size, append 0's to [targets_norm]", "\n", "n", "=", "scores", ".", "size", "(", "1", ")", "\n", "if", "n", ">", "target_scores", ".", "size", "(", "1", ")", ":", "\n", "        ", "n_batch", "=", "scores", ".", "size", "(", "0", ")", "\n", "zeros_to_add", "=", "torch", ".", "zeros", "(", "n_batch", ",", "n", "-", "target_scores", ".", "size", "(", "1", ")", ")", "\n", "zeros_to_add", "=", "zeros_to_add", ".", "to", "(", "device", ")", "\n", "targets_norm", "=", "torch", ".", "cat", "(", "[", "targets_norm", ".", "detach", "(", ")", ",", "zeros_to_add", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Calculate distillation loss (see e.g., Li and Hoiem, 2017)", "\n", "", "KD_loss_unnorm", "=", "-", "(", "targets_norm", "*", "log_scores_norm", ")", "\n", "KD_loss_unnorm", "=", "KD_loss_unnorm", ".", "sum", "(", "dim", "=", "1", ")", "#--> sum over classes", "\n", "KD_loss_unnorm", "=", "KD_loss_unnorm", ".", "mean", "(", ")", "#--> average over batch", "\n", "\n", "# normalize", "\n", "KD_loss", "=", "KD_loss_unnorm", "*", "T", "**", "2", "\n", "\n", "return", "KD_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.loss_fn_kd_binary": [[50, 78], ["torch.sigmoid", "torch.sigmoid", "scores.size", "KD_loss_unnorm.mean.sum", "KD_loss_unnorm.mean.mean", "target_scores.size", "scores.size", "torch.zeros", "zeros_to_add.to.to", "torch.cat", "target_scores.size", "torch.log", "torch.log"], "function", ["None"], ["", "def", "loss_fn_kd_binary", "(", "scores", ",", "target_scores", ",", "T", "=", "2.", ")", ":", "\n", "    ", "\"\"\"Compute binary knowledge-distillation (KD) loss given [scores] and [target_scores].\n\n    Both [scores] and [target_scores] should be tensors, although [target_scores] should be repackaged.\n    'Hyperparameter': temperature\"\"\"", "\n", "\n", "device", "=", "scores", ".", "device", "\n", "\n", "scores_norm", "=", "torch", ".", "sigmoid", "(", "scores", "/", "T", ")", "\n", "targets_norm", "=", "torch", ".", "sigmoid", "(", "target_scores", "/", "T", ")", "\n", "\n", "# if [scores] and [target_scores] do not have equal size, append 0's to [targets_norm]", "\n", "n", "=", "scores", ".", "size", "(", "1", ")", "\n", "if", "n", ">", "target_scores", ".", "size", "(", "1", ")", ":", "\n", "        ", "n_batch", "=", "scores", ".", "size", "(", "0", ")", "\n", "zeros_to_add", "=", "torch", ".", "zeros", "(", "n_batch", ",", "n", "-", "target_scores", ".", "size", "(", "1", ")", ")", "\n", "zeros_to_add", "=", "zeros_to_add", ".", "to", "(", "device", ")", "\n", "targets_norm", "=", "torch", ".", "cat", "(", "[", "targets_norm", ",", "zeros_to_add", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Calculate distillation loss", "\n", "", "KD_loss_unnorm", "=", "-", "(", "targets_norm", "*", "torch", ".", "log", "(", "scores_norm", ")", "+", "(", "1", "-", "targets_norm", ")", "*", "torch", ".", "log", "(", "1", "-", "scores_norm", ")", ")", "\n", "KD_loss_unnorm", "=", "KD_loss_unnorm", ".", "sum", "(", "dim", "=", "1", ")", "#--> sum over classes", "\n", "KD_loss_unnorm", "=", "KD_loss_unnorm", ".", "mean", "(", ")", "#--> average over batch", "\n", "\n", "# normalize", "\n", "KD_loss", "=", "KD_loss_unnorm", "*", "T", "**", "2", "\n", "\n", "return", "KD_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.get_data_loader": [[87, 102], ["torch.utils.data.DataLoader", "copy.deepcopy", "torchvision.transforms.Compose"], "function", ["None"], ["", "def", "get_data_loader", "(", "dataset", ",", "batch_size", ",", "cuda", "=", "False", ",", "collate_fn", "=", "None", ",", "drop_last", "=", "False", ",", "augment", "=", "False", ",", "shuffle", "=", "True", ")", ":", "\n", "    ", "'''Return <DataLoader>-object for the provided <DataSet>-object [dataset].'''", "\n", "\n", "# If requested, make copy of original dataset to add augmenting transform (without altering original dataset)", "\n", "if", "augment", ":", "\n", "        ", "dataset_", "=", "copy", ".", "deepcopy", "(", "dataset", ")", "\n", "dataset_", ".", "transform", "=", "transforms", ".", "Compose", "(", "[", "dataset", ".", "transform", ",", "*", "data", ".", "AVAILABLE_TRANSFORMS", "[", "'augment'", "]", "]", ")", "\n", "", "else", ":", "\n", "        ", "dataset_", "=", "dataset", "\n", "\n", "# Create and return the <DataLoader>-object", "\n", "", "return", "DataLoader", "(", "\n", "dataset_", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "shuffle", ",", "\n", "collate_fn", "=", "(", "collate_fn", "or", "default_collate", ")", ",", "drop_last", "=", "drop_last", ",", "\n", "**", "(", "{", "'num_workers'", ":", "0", ",", "'pin_memory'", ":", "True", "}", "if", "cuda", "else", "{", "}", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.label_squeezing_collate_fn": [[105, 108], ["torch.utils.data.dataloader.default_collate", "y.long().squeeze", "y.long"], "function", ["None"], ["", "def", "label_squeezing_collate_fn", "(", "batch", ")", ":", "\n", "    ", "x", ",", "y", "=", "default_collate", "(", "batch", ")", "\n", "return", "x", ",", "y", ".", "long", "(", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.to_one_hot": [[110, 116], ["numpy.zeros", "torch.from_numpy", "len", "range", "len"], "function", ["None"], ["", "def", "to_one_hot", "(", "y", ",", "classes", ")", ":", "\n", "    ", "'''Convert a nd-array with integers [y] to a 2D \"one-hot\" tensor.'''", "\n", "c", "=", "np", ".", "zeros", "(", "shape", "=", "[", "len", "(", "y", ")", ",", "classes", "]", ",", "dtype", "=", "'float32'", ")", "\n", "c", "[", "range", "(", "len", "(", "y", ")", ")", ",", "y", "]", "=", "1.", "\n", "c", "=", "torch", ".", "from_numpy", "(", "c", ")", "\n", "return", "c", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.save_object": [[124, 127], ["open", "pickle.dump"], "function", ["None"], ["", "def", "save_object", "(", "object", ",", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", "+", "'.pkl'", ",", "'wb'", ")", "as", "f", ":", "\n", "        ", "pickle", ".", "dump", "(", "object", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.load_object": [[128, 131], ["open", "pickle.load"], "function", ["None"], ["", "", "def", "load_object", "(", "path", ")", ":", "\n", "    ", "with", "open", "(", "path", "+", "'.pkl'", ",", "'rb'", ")", "as", "f", ":", "\n", "        ", "return", "pickle", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.count_parameters": [[140, 160], ["model.parameters", "param.size", "print", "print", "print", "round", "round", "round"], "function", ["None"], ["", "", "def", "count_parameters", "(", "model", ",", "verbose", "=", "True", ")", ":", "\n", "    ", "'''Count number of parameters, print to screen.'''", "\n", "total_params", "=", "learnable_params", "=", "fixed_params", "=", "0", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "        ", "n_params", "=", "index_dims", "=", "0", "\n", "for", "dim", "in", "param", ".", "size", "(", ")", ":", "\n", "            ", "n_params", "=", "dim", "if", "index_dims", "==", "0", "else", "n_params", "*", "dim", "\n", "index_dims", "+=", "1", "\n", "", "total_params", "+=", "n_params", "\n", "if", "param", ".", "requires_grad", ":", "\n", "            ", "learnable_params", "+=", "n_params", "\n", "", "else", ":", "\n", "            ", "fixed_params", "+=", "n_params", "\n", "", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"--> this network has {} parameters (~{} million)\"", "\n", ".", "format", "(", "total_params", ",", "round", "(", "total_params", "/", "1000000", ",", "1", ")", ")", ")", "\n", "print", "(", "\"      of which: - learnable: {} (~{} million)\"", ".", "format", "(", "learnable_params", ",", "\n", "round", "(", "learnable_params", "/", "1000000", ",", "1", ")", ")", ")", "\n", "print", "(", "\"                - fixed: {} (~{} million)\"", ".", "format", "(", "fixed_params", ",", "round", "(", "fixed_params", "/", "1000000", ",", "1", ")", ")", ")", "\n", "", "return", "total_params", ",", "learnable_params", ",", "fixed_params", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.print_model_info": [[162, 170], ["print", "print", "print", "print", "utils.count_parameters", "print"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.count_parameters"], ["", "def", "print_model_info", "(", "model", ",", "title", "=", "\"MODEL\"", ")", ":", "\n", "    ", "'''Print information on [model] onto the screen.'''", "\n", "print", "(", "\"Model-name: \\\"\"", "+", "model", ".", "name", "+", "\"\\\"\"", ")", "\n", "print", "(", "40", "*", "\"-\"", "+", "title", "+", "40", "*", "\"-\"", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "90", "*", "\"-\"", ")", "\n", "_", "=", "count_parameters", "(", "model", ")", "\n", "print", "(", "90", "*", "\"-\"", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.weight_reset": [[181, 185], ["isinstance", "isinstance", "isinstance", "m.reset_parameters"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.LinearExcitability.reset_parameters"], ["def", "weight_reset", "(", "m", ")", ":", "\n", "    ", "'''Reinitializes parameters of [m] according to default initialization scheme.'''", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m", ",", "em", ".", "LinearExcitability", ")", ":", "\n", "        ", "m", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.load_checkpoint": [[186, 209], ["os.path.join", "torch.load", "model.load_state_dict", "model.named_parameters", "print", "print", "print", "n.replace.replace", "p.detach().clone", "p.detach().clone().zero_", "model.register_buffer", "model.register_buffer", "p.detach", "p.detach().clone", "p.detach"], "function", ["None"], ["", "", "def", "load_checkpoint", "(", "model", ",", "model_dir", ",", "verbose", "=", "True", ",", "name", "=", "None", ",", "add_si_buffers", "=", "False", ")", ":", "\n", "    ", "'''Load saved state (in form of dictionary) at [model_dir] (if name is None, use \"model.name\") to [model].'''", "\n", "# -path from where to load checkpoint", "\n", "name", "=", "model", ".", "name", "if", "name", "is", "None", "else", "name", "\n", "path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "name", ")", "\n", "# -if required, add buffers to [model] to make sure its 'state_dict' matches the 'state_dict' of model to be loaded", "\n", "if", "add_si_buffers", ":", "\n", "        ", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "p", ".", "requires_grad", ":", "\n", "                ", "n", "=", "n", ".", "replace", "(", "'.'", ",", "'__'", ")", "\n", "p_current", "=", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", "\n", "omega", "=", "p", ".", "detach", "(", ")", ".", "clone", "(", ")", ".", "zero_", "(", ")", "\n", "model", ".", "register_buffer", "(", "'{}_SI_prev_task'", ".", "format", "(", "n", ")", ",", "p_current", ")", "\n", "model", ".", "register_buffer", "(", "'{}_SI_omega'", ".", "format", "(", "n", ")", ",", "omega", ")", "\n", "\n", "# load parameters (i.e., [model] will now have the state of the loaded model)", "\n", "", "", "", "checkpoint", "=", "torch", ".", "load", "(", "path", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'state'", "]", ")", "\n", "# notify that we succesfully loaded the checkpoint", "\n", "if", "verbose", ":", "\n", "        ", "print", "(", "'-----------------------------------------------------------------------------------'", ")", "\n", "print", "(", "' --> loaded checkpoint of {name} from {path}'", ".", "format", "(", "name", "=", "name", ",", "path", "=", "model_dir", ")", ")", "\n", "print", "(", "'-----------------------------------------------------------------------------------'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.init_params": [[210, 215], ["model.apply", "utils.load_checkpoint"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.utils.load_checkpoint"], ["", "", "def", "init_params", "(", "model", ",", "args", ")", ":", "\n", "# - reinitialize all parameters according to default initialization", "\n", "    ", "model", ".", "apply", "(", "weight_reset", ")", "\n", "load_checkpoint", "(", "model", ".", "convE", ",", "model_dir", "=", "'pretrained_model'", ",", "name", "=", "'C3-5x16-bn-s100N'", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.conv_layers.ConvLayers.__init__": [[21, 93], ["torch.nn.Module.__init__", "range", "setattr", "torch.nn.AdaptiveAvgPool2d", "network.utils.modules.Identity", "len", "network.conv_layer", "network.res_layer", "type"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "conv_type", "=", "\"standard\"", ",", "block_type", "=", "\"basic\"", ",", "num_blocks", "=", "2", ",", "\n", "image_channels", "=", "3", ",", "depth", "=", "5", ",", "start_channels", "=", "16", ",", "reducing_layers", "=", "None", ",", "batch_norm", "=", "True", ",", "nl", "=", "\"relu\"", ",", "\n", "output", "=", "\"normal\"", ",", "global_pooling", "=", "False", ",", "gated", "=", "False", ")", ":", "\n", "        ", "'''Initialize stacked convolutional layers (either \"standard\" or \"res-net\" ones--1st layer is always standard).\n\n        [conv_type]         <str> type of conv-layers to be used: [standard|resnet]\n        [block_type]        <str> block-type to be used: [basic|bottleneck] (only relevant if [type]=resNet)\n        [num_blocks]        <int> or <list> (with len=[depth]-1) of # blocks in each layer\n        [image_channels]    <int> # channels of input image to encode\n        [depth]             <int> # layers\n        [start_channels]    <int> # channels in 1st layer, doubled in every \"rl\" (=reducing layer)\n        [reducing_layers]   <int> # layers in which image-size is halved & # channels doubled (default=[depth]-1)\n                                      (\"rl\"'s are the last conv-layers; in 1st layer # channels cannot double)\n        [batch_norm]        <bool> whether to use batch-norm after each convolution-operation\n        [nl]                <str> non-linearity to be used: [relu|leakyrelu]\n        [output]            <str>  if - \"normal\", final layer is same as all others\n                                      - \"none\", final layer has no batchnorm or non-linearity\n        [global_pooling]    <bool> whether to include global average pooling layer at very end\n        [gated]             <bool> whether conv-layers should be gated (not implemented for ResNet-layers)'''", "\n", "\n", "# Process type and number of blocks", "\n", "conv_type", "=", "\"standard\"", "if", "depth", "<", "2", "else", "conv_type", "\n", "if", "conv_type", "==", "\"resNet\"", ":", "\n", "            ", "num_blocks", "=", "[", "num_blocks", "]", "*", "(", "depth", "-", "1", ")", "if", "type", "(", "num_blocks", ")", "==", "int", "else", "num_blocks", "\n", "assert", "len", "(", "num_blocks", ")", "==", "(", "depth", "-", "1", ")", "\n", "block", "=", "conv_layers", ".", "Bottleneck", "if", "block_type", "==", "\"bottleneck\"", "else", "conv_layers", ".", "BasicBlock", "\n", "\n", "# Prepare label", "\n", "", "type_label", "=", "\"C\"", "if", "conv_type", "==", "\"standard\"", "else", "\"R{}\"", ".", "format", "(", "\"b\"", "if", "block_type", "==", "\"bottleneck\"", "else", "\"\"", ")", "\n", "channel_label", "=", "\"{}-{}x{}\"", ".", "format", "(", "image_channels", ",", "depth", ",", "start_channels", ")", "\n", "block_label", "=", "\"-{}\"", ".", "format", "(", "num_blocks", ")", "if", "conv_type", "==", "\"resNet\"", "else", "\"\"", "\n", "nd_label", "=", "\"{bn}{nl}{gp}{gate}{out}\"", ".", "format", "(", "bn", "=", "\"b\"", "if", "batch_norm", "else", "\"\"", ",", "nl", "=", "\"l\"", "if", "nl", "==", "\"leakyrelu\"", "else", "\"\"", ",", "\n", "gp", "=", "\"p\"", "if", "global_pooling", "else", "\"\"", ",", "gate", "=", "\"g\"", "if", "gated", "else", "\"\"", ",", "\n", "out", "=", "\"n\"", "if", "output", "==", "\"none\"", "else", "\"\"", ")", "\n", "nd_label", "=", "\"\"", "if", "nd_label", "==", "\"\"", "else", "\"-{}\"", ".", "format", "(", "nd_label", ")", "\n", "\n", "# Set configurations", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "depth", "=", "depth", "\n", "self", ".", "rl", "=", "depth", "-", "1", "if", "(", "reducing_layers", "is", "None", ")", "else", "(", "reducing_layers", "if", "(", "depth", "+", "1", ")", ">", "reducing_layers", "else", "depth", ")", "\n", "rl_label", "=", "\"\"", "if", "self", ".", "rl", "==", "(", "self", ".", "depth", "-", "1", ")", "else", "\"-rl{}\"", ".", "format", "(", "self", ".", "rl", ")", "\n", "self", ".", "label", "=", "\"{}{}{}{}{}\"", ".", "format", "(", "type_label", ",", "channel_label", ",", "block_label", ",", "rl_label", ",", "nd_label", ")", "\n", "self", ".", "block_expansion", "=", "block", ".", "expansion", "if", "conv_type", "==", "\"resNet\"", "else", "1", "\n", "# -> constant by which # of output channels of each block is multiplied (if >1, it creates \"bottleneck\"-effect)", "\n", "double_factor", "=", "self", ".", "rl", "if", "self", ".", "rl", "<", "depth", "else", "depth", "-", "1", "# -> how often # start-channels is doubled", "\n", "self", ".", "out_channels", "=", "(", "start_channels", "*", "2", "**", "double_factor", ")", "*", "self", ".", "block_expansion", "if", "depth", ">", "0", "else", "image_channels", "\n", "# -> number channels in last layer (as seen from image)", "\n", "self", ".", "start_channels", "=", "start_channels", "# -> number channels in 1st layer (doubled in every \"reducing layer\")", "\n", "self", ".", "global_pooling", "=", "global_pooling", "# -> whether or not average global pooling layer should be added at end", "\n", "\n", "# Conv-layers", "\n", "output_channels", "=", "start_channels", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "depth", "+", "1", ")", ":", "\n", "# should this layer down-sample? --> last [self.rl] layers should be down-sample layers", "\n", "            ", "reducing", "=", "True", "if", "(", "layer_id", ">", "(", "depth", "-", "self", ".", "rl", ")", ")", "else", "False", "\n", "# calculate number of this layer's input and output channels", "\n", "input_channels", "=", "image_channels", "if", "layer_id", "==", "1", "else", "output_channels", "*", "self", ".", "block_expansion", "\n", "output_channels", "=", "output_channels", "*", "2", "if", "(", "reducing", "and", "not", "layer_id", "==", "1", ")", "else", "output_channels", "\n", "# define and set the convolutional-layer", "\n", "if", "conv_type", "==", "\"standard\"", "or", "layer_id", "==", "1", ":", "\n", "                ", "conv_layer", "=", "conv_layers", ".", "conv_layer", "(", "input_channels", ",", "output_channels", ",", "stride", "=", "2", "if", "reducing", "else", "1", ",", "\n", "drop", "=", "0", ",", "nl", "=", "\"no\"", "if", "output", "==", "\"none\"", "and", "layer_id", "==", "depth", "else", "nl", ",", "\n", "batch_norm", "=", "False", "if", "output", "==", "\"none\"", "and", "layer_id", "==", "depth", "else", "batch_norm", ",", "\n", "gated", "=", "False", "if", "output", "==", "\"none\"", "and", "layer_id", "==", "depth", "else", "gated", ")", "\n", "", "else", ":", "\n", "                ", "conv_layer", "=", "conv_layers", ".", "res_layer", "(", "input_channels", ",", "output_channels", ",", "block", "=", "block", ",", "\n", "num_blocks", "=", "num_blocks", "[", "layer_id", "-", "2", "]", ",", "stride", "=", "2", "if", "reducing", "else", "1", ",", "\n", "drop", "=", "0", ",", "batch_norm", "=", "batch_norm", ",", "nl", "=", "nl", ",", "\n", "no_fnl", "=", "True", "if", "output", "==", "\"none\"", "and", "layer_id", "==", "depth", "else", "False", ")", "\n", "", "setattr", "(", "self", ",", "'convLayer{}'", ".", "format", "(", "layer_id", ")", ",", "conv_layer", ")", "\n", "# Perform pooling (if requested)", "\n", "", "self", ".", "pooling", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "if", "global_pooling", "else", "modules", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.conv_layers.ConvLayers.forward": [[94, 110], ["range", "network.ConvLayers.pooling", "getattr", "pre_act_list.append", "hidden_act_list.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "skip_first", "=", "0", ",", "skip_last", "=", "0", ",", "return_lists", "=", "False", ")", ":", "\n", "# Initiate <list> for keeping track of intermediate hidden (pre-)activations", "\n", "        ", "if", "return_lists", ":", "\n", "            ", "hidden_act_list", "=", "[", "]", "\n", "pre_act_list", "=", "[", "]", "\n", "# Sequentially pass [x] through all conv-layers", "\n", "", "for", "layer_id", "in", "range", "(", "skip_first", "+", "1", ",", "self", ".", "depth", "+", "1", "-", "skip_last", ")", ":", "\n", "            ", "(", "x", ",", "pre_act", ")", "=", "getattr", "(", "self", ",", "'convLayer{}'", ".", "format", "(", "layer_id", ")", ")", "(", "x", ",", "return_pa", "=", "True", ")", "\n", "if", "return_lists", ":", "\n", "                ", "pre_act_list", ".", "append", "(", "pre_act", ")", "#-> for each layer, store pre-activations", "\n", "if", "layer_id", "<", "(", "self", ".", "depth", "-", "skip_last", ")", ":", "\n", "                    ", "hidden_act_list", ".", "append", "(", "x", ")", "#-> for all but last layer, store hidden activations", "\n", "# Global average pooling (if requested)", "\n", "", "", "", "x", "=", "self", ".", "pooling", "(", "x", ")", "\n", "# Return final [x], if requested along with [hidden_act_list] and [pre_act_list]", "\n", "return", "(", "x", ",", "hidden_act_list", ",", "pre_act_list", ")", "if", "return_lists", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.conv_layers.ConvLayers.out_size": [[111, 115], ["int", "numpy.ceil"], "methods", ["None"], ["", "def", "out_size", "(", "self", ",", "image_size", ",", "ignore_gp", "=", "False", ")", ":", "\n", "        ", "'''Given [image_size] of input, return the size of the \"final\" image that is outputted.'''", "\n", "out_size", "=", "int", "(", "np", ".", "ceil", "(", "image_size", "/", "2", "**", "(", "self", ".", "rl", ")", ")", ")", "if", "self", ".", "depth", ">", "0", "else", "image_size", "\n", "return", "1", "if", "(", "self", ".", "global_pooling", "and", "not", "ignore_gp", ")", "else", "out_size", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.conv_layers.ConvLayers.out_units": [[116, 119], ["network.ConvLayers.out_size"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_size"], ["", "def", "out_units", "(", "self", ",", "image_size", ",", "ignore_gp", "=", "False", ")", ":", "\n", "        ", "'''Given [image_size] of input, return the total number of units in the output.'''", "\n", "return", "self", ".", "out_channels", "*", "self", ".", "out_size", "(", "image_size", ",", "ignore_gp", "=", "ignore_gp", ")", "**", "2", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.conv_layers.ConvLayers.layer_info": [[120, 138], ["range", "layer_list.append", "int", "int", "numpy.ceil", "numpy.ceil"], "methods", ["None"], ["", "def", "layer_info", "(", "self", ",", "image_size", ")", ":", "\n", "        ", "'''Return list with shape of all hidden layers.'''", "\n", "layer_list", "=", "[", "]", "\n", "reduce_number", "=", "0", "# keep track how often image-size has been halved", "\n", "double_number", "=", "0", "# keep track how often channel number has been doubled", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "depth", ")", ":", "\n", "            ", "reducing", "=", "True", "if", "(", "layer_id", ">", "(", "self", ".", "depth", "-", "self", ".", "rl", ")", ")", "else", "False", "\n", "if", "reducing", ":", "\n", "                ", "reduce_number", "+=", "1", "\n", "", "if", "reducing", "and", "layer_id", ">", "1", ":", "\n", "                ", "double_number", "+=", "1", "\n", "", "pooling", "=", "True", "if", "self", ".", "global_pooling", "and", "layer_id", "==", "(", "self", ".", "depth", "-", "1", ")", "else", "False", "\n", "expansion", "=", "1", "if", "layer_id", "==", "1", "else", "self", ".", "block_expansion", "\n", "# add shape of this layer to list", "\n", "layer_list", ".", "append", "(", "[", "(", "self", ".", "start_channels", "*", "2", "**", "double_number", ")", "*", "expansion", ",", "\n", "1", "if", "pooling", "else", "int", "(", "np", ".", "ceil", "(", "image_size", "/", "2", "**", "reduce_number", ")", ")", ",", "\n", "1", "if", "pooling", "else", "int", "(", "np", ".", "ceil", "(", "image_size", "/", "2", "**", "reduce_number", ")", ")", "]", ")", "\n", "", "return", "layer_list", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.conv_layers.ConvLayers.list_init_layers": [[139, 145], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "depth", "+", "1", ")", ":", "\n", "            ", "list", "+=", "getattr", "(", "self", ",", "'convLayer{}'", ".", "format", "(", "layer_id", ")", ")", ".", "list_init_layers", "(", ")", "\n", "", "return", "list", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.conv_layers.ConvLayers.name": [[146, 149], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_MLP.__init__": [[10, 20], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "num_classes", ",", "input_size", "=", "1000", ",", "hid_size", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "hid_size", "=", "hid_size", "\n", "\n", "self", ".", "x_fc1", "=", "nn", ".", "Linear", "(", "input_size", ",", "hid_size", ")", "\n", "self", ".", "x_fc2", "=", "nn", ".", "Linear", "(", "hid_size", ",", "hid_size", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "hid_size", ",", "self", ".", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_MLP.forward": [[22, 30], ["classifier_layers.CLS_MLP.x_fc1", "torch.nn.functional.relu", "classifier_layers.CLS_MLP.x_fc2", "torch.nn.functional.relu", "classifier_layers.CLS_MLP.classifier"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "x_fc1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "x_fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_CONV.__init__": [[34, 64], ["torch.nn.Module.__init__", "torch.nn.Sequential", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.MaxPool2d", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.Conv2d", "torch.nn.ReLU", "torch.nn.MaxPool2d"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "num_classes", ",", "input_size", "=", "1000", ",", "hid_size", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "# nn.BatchNorm2d(32),", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "\n", "# nn.BatchNorm2d(32),", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "# nn.Dropout(p=0.25),", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", ",", "\n", "# nn.BatchNorm2d(64),", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", ",", "\n", "# nn.BatchNorm2d(64),", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", ",", "\n", "# nn.Dropout(p=0.25),", "\n", ")", "\n", "\n", "\n", "# self.hid_size = 512", "\n", "self", ".", "hid_size", "=", "1024", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "2304", ",", "self", ".", "hid_size", ")", "\n", "# self.dropout1 = nn.Dropout(p=0.5)", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "self", ".", "hid_size", ",", "self", ".", "hid_size", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "hid_size", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_CONV.forward": [[67, 79], ["classifier_layers.CLS_CONV.model", "classifier_layers.CLS_CONV.view", "classifier_layers.CLS_CONV.fc1", "torch.nn.functional.relu", "classifier_layers.CLS_CONV.fc2", "torch.nn.functional.relu", "classifier_layers.CLS_CONV.classifier", "classifier_layers.CLS_CONV.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "fc2", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_net_cifar100.__init__": [[92, 160], ["torch.nn.Module.__init__", "range", "len", "network.fc.layers.fc_layer", "setattr", "network.utils.modules.Identity", "int", "int", "numpy.linspace", "numpy.repeat", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "input_size", "=", "1000", ",", "output_size", "=", "10", ",", "layers", "=", "2", ",", "hid_size", "=", "1000", ",", "hid_smooth", "=", "None", ",", "size_per_layer", "=", "None", ",", "\n", "drop", "=", "0", ",", "batch_norm", "=", "True", ",", "nl", "=", "\"relu\"", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "gated", "=", "False", ",", "\n", "output", "=", "'normal'", ")", ":", "\n", "        ", "'''sizes: 0th=[input], 1st=[hid_size], ..., 1st-to-last=[hid_smooth], last=[output].\n        [input_size]       # of inputs\n        [output_size]      # of units in final layer\n        [layers]           # of layers\n        [hid_size]         # of units in each hidden layer\n        [hid_smooth]       if None, all hidden layers have [hid_size] units, else # of units linearly in-/decreases s.t.\n                             final hidden layer has [hid_smooth] units (if only 1 hidden layer, it has [hid_size] units)\n        [size_per_layer]   None or <list> with for each layer number of units (1st element = number of inputs)\n                                --> overwrites [input_size], [output_size], [layers], [hid_size] and [hid_smooth]\n        [drop]             % of each layer's inputs that is randomly set to zero during training\n        [batch_norm]       <bool>; if True, batch-normalization is applied to each layer\n        [nl]               <str>; type of non-linearity to be used (options: \"relu\", \"leakyrelu\", \"none\")\n        [gated]            <bool>; if True, each linear layer has an additional learnable gate\n                                    (whereby the gate is controlled by the same input as that goes through the gate)\n        [output]           <str>; if - \"normal\", final layer is same as all others\n                                     - \"none\", final layer has no non-linearity\n                                     - \"sigmoid\", final layer has sigmoid non-linearity'''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output", "=", "output", "\n", "\n", "# get sizes of all layers", "\n", "if", "size_per_layer", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n", "if", "layers", ">", "1", ":", "\n", "                ", "if", "(", "hid_smooth", "is", "not", "None", ")", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "hid_size", ",", "hid_smooth", ",", "num", "=", "layers", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "repeat", "(", "hid_size", ",", "layers", "-", "1", ")", "]", "\n", "", "", "size_per_layer", "=", "[", "input_size", "]", "+", "hidden_sizes", "+", "[", "output_size", "]", "if", "layers", ">", "0", "else", "[", "input_size", "]", "\n", "", "self", ".", "layers", "=", "len", "(", "size_per_layer", ")", "-", "1", "\n", "\n", "# set label for this module", "\n", "# -determine \"non-default options\"-label", "\n", "nd_label", "=", "\"{drop}{bias}{exc}{bn}{nl}{gate}\"", ".", "format", "(", "\n", "drop", "=", "\"\"", "if", "drop", "==", "0", "else", "\"d{}\"", ".", "format", "(", "drop", ")", ",", "\n", "bias", "=", "\"\"", "if", "bias", "else", "\"n\"", ",", "exc", "=", "\"e\"", "if", "excitability", "else", "\"\"", ",", "bn", "=", "\"b\"", "if", "batch_norm", "else", "\"\"", ",", "\n", "nl", "=", "\"l\"", "if", "nl", "==", "\"leakyrelu\"", "else", "\"\"", ",", "gate", "=", "\"g\"", "if", "gated", "else", "\"\"", ",", "\n", ")", "\n", "nd_label", "=", "\"{}{}\"", ".", "format", "(", "\"\"", "if", "nd_label", "==", "\"\"", "else", "\"-{}\"", ".", "format", "(", "nd_label", ")", ",", "\n", "\"\"", "if", "output", "==", "\"normal\"", "else", "\"-{}\"", ".", "format", "(", "output", ")", ")", "\n", "# -set label", "\n", "size_statement", "=", "\"\"", "\n", "for", "i", "in", "size_per_layer", ":", "\n", "            ", "size_statement", "+=", "\"{}{}\"", ".", "format", "(", "\"-\"", "if", "size_statement", "==", "\"\"", "else", "\"x\"", ",", "i", ")", "\n", "", "self", ".", "label", "=", "\"F{}{}\"", ".", "format", "(", "size_statement", ",", "nd_label", ")", "if", "self", ".", "layers", ">", "0", "else", "\"\"", "\n", "\n", "# set layers", "\n", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "# number of units of this layer's input and output", "\n", "            ", "in_size", "=", "size_per_layer", "[", "lay_id", "-", "1", "]", "\n", "out_size", "=", "size_per_layer", "[", "lay_id", "]", "\n", "# define and set the fully connected layer", "\n", "layer", "=", "fc_layer", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "gated", "=", "gated", ",", "\n", "nl", "=", "(", "\"none\"", "if", "output", "==", "\"none\"", "else", "nn", ".", "Sigmoid", "(", ")", ")", "if", "(", "\n", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", "\n", ")", "else", "nl", ",", "drop", "=", "drop", "if", "lay_id", ">", "1", "else", "0.", ",", "\n", ")", "\n", "setattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ",", "layer", ")", "\n", "\n", "# if no layers, add \"identity\"-module to indicate in this module's representation nothing happens", "\n", "", "if", "self", ".", "layers", "<", "1", ":", "\n", "            ", "self", ".", "noLayers", "=", "modules", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_net_cifar100.forward": [[161, 175], ["range", "getattr", "pre_act_list.append", "hidden_act_list.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "skip_first", "=", "0", ",", "skip_last", "=", "0", ",", "return_lists", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# Initiate <list> for keeping track of intermediate hidden-(pre)activations", "\n", "        ", "if", "return_lists", ":", "\n", "            ", "hidden_act_list", "=", "[", "]", "\n", "pre_act_list", "=", "[", "]", "\n", "# Sequentially pass [x] through all fc-layers", "\n", "", "for", "lay_id", "in", "range", "(", "skip_first", "+", "1", ",", "self", ".", "layers", "+", "1", "-", "skip_last", ")", ":", "\n", "            ", "(", "x", ",", "pre_act", ")", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ",", "return_pa", "=", "True", ")", "\n", "if", "return_lists", ":", "\n", "                ", "pre_act_list", ".", "append", "(", "pre_act", ")", "#-> for each layer, store pre-activations", "\n", "if", "lay_id", "<", "(", "self", ".", "layers", "-", "skip_last", ")", ":", "\n", "                    ", "hidden_act_list", ".", "append", "(", "x", ")", "#-> for all but last layer, store hidden activations", "\n", "# Return final [x], if requested along with [hidden_act_list] and [pre_act_list]", "\n", "", "", "", "return", "(", "x", ",", "hidden_act_list", ",", "pre_act_list", ")", "if", "return_lists", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_net_cifar100.name": [[177, 180], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier_layers.CLS_net_cifar100.list_init_layers": [[181, 187], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "list", "+=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "layer_id", ")", ")", ".", "list_init_layers", "(", ")", "\n", "", "return", "list", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_MLP.__init__": [[12, 24], ["torch.nn.Module.__init__", "torch.nn.Embedding", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "num_classes", ",", "input_size", "=", "1000", ",", "hid_size", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "hid_size", "=", "hid_size", "\n", "\n", "self", ".", "y_ebm", "=", "nn", ".", "Embedding", "(", "self", ".", "num_classes", ",", "hid_size", ")", "\n", "\n", "self", ".", "x_fc1", "=", "nn", ".", "Linear", "(", "input_size", ",", "hid_size", ")", "\n", "self", ".", "x_fc2", "=", "nn", ".", "Linear", "(", "hid_size", ",", "hid_size", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "hid_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_MLP.forward": [[26, 49], ["ebm_layers.EBM_MLP.y_ebm", "ebm_layers.EBM_MLP.x_fc1", "x[].expand_as", "torch.nn.functional.normalize", "torch.nn.functional.relu", "ebm_layers.EBM_MLP.classifier", "torch.nn.functional.relu.view", "ebm_layers.EBM_MLP.x_fc2", "torch.nn.functional.relu"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "bs", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "y", "=", "self", ".", "y_ebm", "(", "y", ")", "\n", "\n", "x", "=", "self", ".", "x_fc1", "(", "x", ")", "\n", "x", "=", "x", "[", ":", ",", "None", ",", ":", "]", ".", "expand_as", "(", "y", ")", "\n", "\n", "y", "=", "F", ".", "normalize", "(", "y", ",", "p", "=", "2", ",", "dim", "=", "-", "1", ")", "\n", "z", "=", "x", "*", "y", "\n", "x", "=", "x", "+", "z", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "\n", "if", "not", "self", ".", "args", ".", "task_boundary", ":", "\n", "            ", "x", "=", "self", ".", "x_fc2", "(", "x", ")", "\n", "z", "=", "x", "*", "y", "\n", "x", "=", "x", "+", "z", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "\n", "", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "bs", ",", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_CONV.__init__": [[55, 79], ["torch.nn.Module.__init__", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.Conv2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.MaxPool2d", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Embedding"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "num_classes", ",", "input_size", "=", "1000", ",", "hid_size", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "32", ",", "kernel_size", "=", "3", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "1", ",", "bias", "=", "True", ")", "\n", "self", ".", "conv4", "=", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "kernel_size", "=", "3", ",", "padding", "=", "0", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "maxpool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", "\n", "self", ".", "maxpool2", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", "\n", "\n", "self", ".", "avgpool", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", "\n", "self", ".", "avgpool2", "=", "nn", ".", "MaxPool2d", "(", "2", ",", "stride", "=", "2", ")", "\n", "\n", "\n", "self", ".", "hid_size", "=", "1024", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "2304", ",", "self", ".", "hid_size", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "self", ".", "hid_size", ",", "self", ".", "hid_size", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "hid_size", ",", "1", ")", "\n", "\n", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "y_ebm", "=", "nn", ".", "Embedding", "(", "self", ".", "num_classes", ",", "self", ".", "hid_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_CONV.forward": [[81, 108], ["ebm_layers.EBM_CONV.conv1", "torch.nn.functional.relu", "ebm_layers.EBM_CONV.conv2", "torch.nn.functional.relu", "ebm_layers.EBM_CONV.maxpool", "ebm_layers.EBM_CONV.conv3", "torch.nn.functional.relu", "ebm_layers.EBM_CONV.conv4", "torch.nn.functional.relu", "ebm_layers.EBM_CONV.maxpool2", "x.view.view.view", "ebm_layers.EBM_CONV.y_ebm", "ebm_layers.EBM_CONV.fc1", "x[].expand_as", "ebm_layers.EBM_CONV.classifier", "x.view.view.view", "x.view.view.size", "torch.nn.functional.softmax"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "bs", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv2", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool", "(", "x", ")", "\n", "x", "=", "self", ".", "conv3", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "conv4", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool2", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "\n", "y", "=", "self", ".", "y_ebm", "(", "y", ")", "\n", "y", "=", "F", ".", "softmax", "(", "y", ",", "dim", "=", "-", "1", ")", "*", "y", ".", "shape", "[", "-", "1", "]", "\n", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "x", "[", ":", ",", "None", ",", ":", "]", ".", "expand_as", "(", "y", ")", "\n", "x", "=", "x", "*", "y", "\n", "\n", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "x", "=", "x", ".", "view", "(", "bs", ",", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_net_cifar100.__init__": [[121, 216], ["torch.nn.Module.__init__", "range", "len", "setattr", "utils.Identity", "torch.nn.Embedding", "network.fc.layers.fc_layer_fixed_gates", "network.fc.layers.fc_layer", "int", "int", "numpy.linspace", "numpy.repeat", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "10", ",", "input_size", "=", "1000", ",", "output_size", "=", "10", ",", "layers", "=", "2", ",", "hid_size", "=", "1000", ",", "hid_smooth", "=", "None", ",", "\n", "size_per_layer", "=", "None", ",", "\n", "drop", "=", "0", ",", "batch_norm", "=", "True", ",", "nl", "=", "\"relu\"", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "output", "=", "'normal'", ",", "\n", "fixed_mask", "=", "True", ",", "mask_prob", "=", "0.8", ",", "only_first", "=", "False", ",", "with_skip", "=", "False", ")", ":", "\n", "        ", "'''sizes: 0th=[input], 1st=[hid_size], ..., 1st-to-last=[hid_smooth], last=[output].\n        [num_classes]      # of classes\n        [input_size]       # of inputs\n        [output_size]      # of output units\n        [layers]           # of layers\n        [hid_size]         # of units in each hidden layer\n        [hid_smooth]       if None, all hidden layers have [hid_size] units, else # of units linearly in-/decreases s.t.\n                             final hidden layer has [hid_smooth] units (if only 1 hidden layer, it has [hid_size] units)\n        [size_per_layer]   None or <list> with for each layer number of units (1st element = number of inputs)\n                                --> overwrites [input_size], [output_size], [layers], [hid_size] and [hid_smooth]\n        [drop]             % of each layer's inputs that is randomly set to zero during training\n        [batch_norm]       <bool>; if True, batch-normalization is applied to each layer\n        [nl]               <str>; type of non-linearity to be used (options: \"relu\", \"leakyrelu\", \"none\")\n        [output]           <str>; if - \"normal\", final layer is same as all others\n                                     - \"none\", final layer has no non-linearity\n                                     - \"sigmoid\", final layer has sigmoid non-linearity\n        EBM-related parameters\n        [fixed_mask]       <bool>; whether to use fixed masks instead of learnable gates\n        [mask_prop]        <float>; probability of each node being gated for particular class (if using `fixed_mask`)\n        [only_first]       <bool>; whether learnable gate is only used for first layer (only if not using `fixed_mask`)\n                              NOTE: if set to ``False``, all layers must have same number of units!\n        [with_skip]        <bool>; whehter there should be a skip-connection around the learnable gate\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output", "=", "output", "\n", "self", ".", "fixed_mask", "=", "fixed_mask", "\n", "self", ".", "only_first", "=", "only_first", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "with_skip", "=", "with_skip", "\n", "\n", "# get sizes of all layers", "\n", "if", "size_per_layer", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n", "if", "layers", ">", "1", ":", "\n", "                ", "if", "(", "hid_smooth", "is", "not", "None", ")", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "hid_size", ",", "hid_smooth", ",", "num", "=", "layers", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "repeat", "(", "hid_size", ",", "layers", "-", "1", ")", "]", "\n", "\n", "", "", "size_per_layer", "=", "[", "input_size", "]", "+", "hidden_sizes", "+", "[", "output_size", "]", "\n", "", "self", ".", "layers", "=", "len", "(", "size_per_layer", ")", "-", "1", "\n", "self", ".", "output_size", "=", "size_per_layer", "[", "-", "1", "]", "\n", "\n", "# set label for this module", "\n", "# -determine \"non-default options\"-label", "\n", "nd_label", "=", "\"{drop}{bias}{exc}{bn}{nl}\"", ".", "format", "(", "\n", "drop", "=", "\"\"", "if", "drop", "==", "0", "else", "\"d{}\"", ".", "format", "(", "drop", ")", ",", "\n", "bias", "=", "\"\"", "if", "bias", "else", "\"n\"", ",", "exc", "=", "\"e\"", "if", "excitability", "else", "\"\"", ",", "bn", "=", "\"b\"", "if", "batch_norm", "else", "\"\"", ",", "\n", "nl", "=", "\"l\"", "if", "nl", "==", "\"leakyrelu\"", "else", "\"\"", ",", "\n", ")", "\n", "nd_label", "=", "\"{}{}\"", ".", "format", "(", "\"\"", "if", "nd_label", "==", "\"\"", "else", "\"-{}\"", ".", "format", "(", "nd_label", ")", ",", "\n", "\"\"", "if", "output", "==", "\"normal\"", "else", "\"-{}\"", ".", "format", "(", "output", ")", ")", "\n", "# -set label", "\n", "size_statement", "=", "\"\"", "\n", "for", "i", "in", "size_per_layer", ":", "\n", "            ", "size_statement", "+=", "\"{}{}\"", ".", "format", "(", "\"-\"", "if", "size_statement", "==", "\"\"", "else", "\"x\"", ",", "i", ")", "\n", "", "self", ".", "label", "=", "\"EBM{}{}{}{}\"", ".", "format", "(", "\n", "\"fm{}\"", ".", "format", "(", "mask_prob", ")", "if", "fixed_mask", "else", "(", "\"sk\"", "if", "with_skip", "else", "\"\"", ")", ",", "\n", "\"-of\"", "if", "only_first", "else", "\"\"", ",", "size_statement", ",", "nd_label", "\n", ")", "if", "self", ".", "layers", ">", "0", "else", "\"\"", "\n", "\n", "# set layers", "\n", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "# number of units of this layer's input and output", "\n", "            ", "in_size", "=", "size_per_layer", "[", "lay_id", "-", "1", "]", "\n", "out_size", "=", "size_per_layer", "[", "lay_id", "]", "\n", "\n", "# embedding of y", "\n", "if", "not", "fixed_mask", ":", "\n", "                ", "self", ".", "goal_ebm", "=", "nn", ".", "Embedding", "(", "self", ".", "num_classes", ",", "size_per_layer", "[", "1", "]", ")", "\n", "\n", "# define and set the fully connected layer", "\n", "", "if", "fixed_mask", "and", "(", "lay_id", "==", "1", "or", "not", "self", ".", "only_first", ")", ":", "\n", "                ", "layer", "=", "fc_layer_fixed_gates", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "drop", "=", "drop", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "\n", "nl", "=", "nn", ".", "Sigmoid", "(", ")", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "nl", ",", "\n", "gate_size", "=", "num_classes", ",", "gating_prop", "=", "mask_prob", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer", "=", "fc_layer", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "drop", "=", "drop", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "\n", "nl", "=", "nn", ".", "Sigmoid", "(", ")", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "nl", ",", "\n", ")", "\n", "", "setattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ",", "layer", ")", "\n", "\n", "# if no layers, add \"identity\"-module to indicate in this module's representation nothing happens", "\n", "", "if", "self", ".", "layers", "<", "1", ":", "\n", "            ", "self", ".", "noLayers", "=", "utils", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_net_cifar100.forward": [[219, 262], ["x[].expand", "range", "torch.zeros().to", "torch.zeros().to.scatter_", "ebm_layers.EBM_net_cifar100.goal_ebm", "torch.nn.functional.softmax", "torch.zeros", "next", "torch.nn.functional.softmax.view", "getattr", "getattr", "ebm_layers.EBM_net_cifar100.parameters", "torch.nn.functional.relu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''Returns energies for each batch-sample in [x] according to each class in corresponding batch-entry of [y].\n\n        Args:\n            x (tensor: [batch]x[input_units])\n            y (tensor: [batch]x[classes_to_test])\n\n        Returns:\n            features_per_class (tensor: [batch]x[classes_to_test]x[output_units])\n        '''", "\n", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "# Reshape `x` to [batch]x[classes_to_test]x[input_units]", "\n", "#-> create multiple copies of [x], one for each class to compute energy for", "\n", "classes_to_test", "=", "y", ".", "shape", "[", "1", "]", "\n", "x", "=", "x", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "[", "batch_size", ",", "classes_to_test", ",", "x", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "\n", "# Deal with `y`", "\n", "if", "self", ".", "fixed_mask", ":", "\n", "# -reshape `y` to one-hot-tensor of shape [batch]x[classes_to_test]x[classes]", "\n", "            ", "y_one_hot", "=", "torch", ".", "zeros", "(", "batch_size", ",", "classes_to_test", ",", "self", ".", "num_classes", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "y_one_hot", ".", "scatter_", "(", "dim", "=", "2", ",", "index", "=", "y", ".", "view", "(", "batch_size", ",", "classes_to_test", ",", "1", ")", ",", "value", "=", "1.", ")", "\n", "", "else", ":", "\n", "# -embed `y` and put through softmax for the learnable gate", "\n", "            ", "y", "=", "self", ".", "goal_ebm", "(", "y", ")", "# -> shape: [batch]x[classes_to_test]x[units]", "\n", "y", "=", "F", ".", "softmax", "(", "y", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Sequentially pass [x] through all fc-layers", "\n", "", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "if", "self", ".", "fixed_mask", ":", "\n", "                ", "x", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ",", "gate_input", "=", "y_one_hot", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ")", "\n", "# -apply the learnable gate, if applicable", "\n", "if", "lay_id", "==", "1", "or", "(", "not", "self", ".", "only_first", ")", ":", "\n", "                    ", "if", "self", ".", "with_skip", ":", "\n", "                        ", "x", "=", "x", "*", "y", "*", "y", ".", "shape", "[", "-", "1", "]", "+", "x", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "", "else", ":", "\n", "                        ", "x", "=", "x", "*", "y", "*", "y", ".", "shape", "[", "-", "1", "]", "\n", "\n", "", "", "", "", "return", "x", "#-> shape: [batch]x[classes_to_test]x[output_units]", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_net_cifar100.name": [[264, 267], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm_layers.EBM_net_cifar100.list_init_layers": [[268, 274], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "list", "+=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "layer_id", ")", ")", ".", "list_init_layers", "(", ")", "\n", "", "return", "list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm.EBM.__init__": [[14, 61], ["continual_learner.ContinualLearner.__init__", "list", "utils.Flatten", "range", "network.ebm_layers.EBM_MLP", "network.ebm_layers.EBM_CONV", "network.conv_layers.ConvLayers", "ebm.EBM.convE.out_units", "ebm.EBM.convE.out_size", "network.ebm_layers.EBM_net_cifar100", "torch.Linear", "torch.Linear", "int", "numpy.linspace"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_units", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_size"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "image_size", ",", "image_channels", ",", "classes", ",", "fc_units", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "label", "=", "\"EBM\"", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_classes", "=", "classes", "\n", "self", ".", "class_entries", "=", "list", "(", "range", "(", "self", ".", "num_classes", ")", ")", "\n", "self", ".", "labels_per_task", "=", "args", ".", "labels_per_task", "\n", "\n", "# flatten image to 2D-tensor", "\n", "self", ".", "flatten", "=", "utils", ".", "Flatten", "(", ")", "\n", "\n", "\n", "# fully connected hidden layers", "\n", "if", "args", ".", "experiment", "==", "'splitMNIST'", "or", "args", ".", "experiment", "==", "'permMNIST'", ":", "\n", "            ", "self", ".", "fcE", "=", "EBM_MLP", "(", "args", ",", "num_classes", "=", "self", ".", "num_classes", ",", "input_size", "=", "image_channels", "*", "image_size", "**", "2", ",", "hid_size", "=", "fc_units", ")", "\n", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "            ", "self", ".", "fcE", "=", "EBM_CONV", "(", "args", ",", "num_classes", "=", "self", ".", "num_classes", ",", "input_size", "=", "image_channels", "*", "image_size", "**", "2", ",", "hid_size", "=", "fc_units", ")", "\n", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "# self.fcE = EBM_CONV(args, num_classes=self.num_classes, input_size=image_channels*image_size**2, hid_size=fc_units)", "\n", "\n", "            ", "self", ".", "convE", "=", "ConvLayers", "(", "\n", "conv_type", "=", "'standard'", ",", "block_type", "=", "\"basic\"", ",", "num_blocks", "=", "2", ",", "image_channels", "=", "3", ",", "\n", "depth", "=", "5", ",", "start_channels", "=", "16", ",", "reducing_layers", "=", "4", ",", "batch_norm", "=", "True", ",", "nl", "=", "'relu'", ",", "\n", "global_pooling", "=", "False", ",", "gated", "=", "False", ",", "output", "=", "\"none\"", ",", "\n", ")", "\n", "#------------------------------calculate input/output-sizes--------------------------------#", "\n", "fc_units", "=", "2000", "\n", "h_dim", "=", "2000", "\n", "fc_layers", "=", "3", "\n", "self", ".", "conv_out_units", "=", "self", ".", "convE", ".", "out_units", "(", "image_size", ")", "\n", "self", ".", "conv_out_size", "=", "self", ".", "convE", ".", "out_size", "(", "image_size", ")", "\n", "self", ".", "conv_out_channels", "=", "self", ".", "convE", ".", "out_channels", "\n", "if", "fc_layers", "<", "2", ":", "\n", "                ", "self", ".", "fc_layer_sizes", "=", "[", "self", ".", "conv_out_units", "]", "#--> this results in self.fcE = modules.Identity()", "\n", "", "elif", "fc_layers", "==", "2", ":", "\n", "                ", "self", ".", "fc_layer_sizes", "=", "[", "self", ".", "conv_out_units", ",", "h_dim", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "fc_layer_sizes", "=", "[", "self", ".", "conv_out_units", "]", "+", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "fc_units", ",", "h_dim", ",", "num", "=", "fc_layers", "-", "1", ")", "]", "\n", "", "self", ".", "units_before_classifier", "=", "h_dim", "if", "fc_layers", ">", "1", "else", "self", ".", "conv_out_units", "\n", "#------------------------------------------------------------------------------------------#", "\n", "self", ".", "fcE", "=", "EBM_net_cifar100", "(", "num_classes", "=", "100", ",", "size_per_layer", "=", "self", ".", "fc_layer_sizes", ",", "drop", "=", "0", ",", "batch_norm", "=", "False", ",", "\n", "nl", "=", "'relu'", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "True", ",", "\n", "fixed_mask", "=", "True", ",", "mask_prob", "=", "0.85", ",", "only_first", "=", "False", ",", "with_skip", "=", "False", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "self", ".", "units_before_classifier", ",", "1", ",", "bias", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm.EBM.forward": [[63, 83], ["ebm.EBM.fcE", "ebm.EBM.fcE", "ebm.EBM.fcE", "ebm.EBM.flatten", "ebm.EBM.flatten", "ebm.EBM.flatten", "ebm.EBM.fcE", "ebm.EBM.classifier", "final_features.view.view.view", "ebm.EBM.convE"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "task_id", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "experiment", "==", "'splitMNIST'", "or", "self", ".", "args", ".", "experiment", "==", "'permMNIST'", "or", "self", ".", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "            ", "if", "self", ".", "args", ".", "task_info_input", ":", "\n", "                ", "final_features", "=", "self", ".", "fcE", "(", "self", ".", "flatten", "(", "x", ")", ",", "y", ",", "task_id", ")", "\n", "", "else", ":", "\n", "                ", "final_features", "=", "self", ".", "fcE", "(", "self", ".", "flatten", "(", "x", ")", ",", "y", ")", "\n", "\n", "", "", "elif", "self", ".", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "            ", "final_features", "=", "self", ".", "fcE", "(", "x", ",", "y", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "# final_features = self.fcE(x, y)", "\n", "\n", "            ", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "hidden_rep", "=", "self", ".", "flatten", "(", "self", ".", "convE", "(", "x", ")", ")", "\n", "features", "=", "self", ".", "fcE", "(", "hidden_rep", ",", "y", ")", "\n", "final_features", "=", "self", ".", "classifier", "(", "features", ")", "\n", "final_features", "=", "final_features", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n", "", "return", "final_features", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm.EBM.name": [[85, 88], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'EBM'", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm.EBM.forward_cifar100": [[90, 175], ["list", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "y.expand.expand.cpu().numpy", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "ebm.EBM.", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "ebm.EBM._device", "len", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "list", "ebm.EBM._device", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "ebm.EBM.", "predL.mean.mean.mean", "y.expand.expand.expand", "y.expand.expand.view", "y_neg_energies.gather", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "predL.mean.mean.mean", "y.expand.expand.cpu", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "RuntimeError", "ebm.EBM._device", "range", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "ebm.EBM._device", "len", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "numpy.unique", "random.choice", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "type", "len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "predL[].mean", "predL[].mean", "y.expand.expand.size", "y_neg_energies.max", "y_neg_energies.max"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner._device"], ["", "def", "forward_cifar100", "(", "self", ",", "args", ",", "x", ",", "y", ",", "x_", ",", "y_", ",", "task", ")", ":", "\n", "        ", "single_neg", "=", "True", "\n", "self", ".", "neg_energy", "=", "True", "\n", "self", ".", "only_classes_in_current_task", "=", "True", "\n", "\n", "batch_size_ori", ",", "c", ",", "w", ",", "h", "=", "x", ".", "shape", "\n", "\n", "\n", "\n", "if", "x_", "is", "not", "None", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "x_", "]", ",", "dim", "=", "0", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "y_", "]", ",", "dim", "=", "0", ")", "\n", "\n", "", "y_list", "=", "list", "(", "y", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "y_list_to_sample_from", "=", "y_list", "\n", "batch_size", ",", "c", ",", "w", ",", "h", "=", "x", ".", "shape", "\n", "\n", "# print(x.shape, y.shape)", "\n", "# print(np.max(y_list_to_sample_from), np.min(y_list_to_sample_from))", "\n", "\n", "if", "single_neg", ":", "\n", "            ", "ys_to_test", "=", "torch", ".", "LongTensor", "(", "batch_size", ",", "2", ")", ".", "to", "(", "self", ".", "_device", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "y_list", ")", ")", ":", "\n", "                ", "if", "len", "(", "np", ".", "unique", "(", "y_list_to_sample_from", ")", ")", "==", "1", ":", "\n", "# the below would break down if all entries in the batch have the same label!!!", "\n", "                    ", "raise", "RuntimeError", "(", "'All samples in this batch have the same label!!'", ")", "\n", "", "else", ":", "\n", "                    ", "while", "True", ":", "\n", "                        ", "neg_sample", "=", "random", ".", "choice", "(", "y_list_to_sample_from", ")", "\n", "if", "not", "neg_sample", "==", "y_list", "[", "i", "]", ":", "\n", "                            ", "break", "\n", "", "", "", "ys_to_test", "[", "i", "]", "=", "torch", ".", "tensor", "(", "[", "y_list", "[", "i", "]", ",", "neg_sample", "]", ")", ".", "to", "(", "self", ".", "_device", "(", ")", ")", "\n", "", "", "else", ":", "\n", "# -select all labels to use as negative samples (NOTE: one of them should be the positive sample!)", "\n", "            ", "if", "active_classes", "is", "not", "None", ":", "\n", "                ", "class_entries", "=", "active_classes", "[", "-", "1", "]", "if", "type", "(", "active_classes", "[", "0", "]", ")", "==", "list", "else", "active_classes", "\n", "if", "self", ".", "only_classes_in_current_task", ":", "\n", "                    ", "class_entries", "=", "class_entries", "[", "-", "self", ".", "classes_per_task", ":", "]", "\n", "", "", "else", ":", "\n", "                ", "class_entries", "=", "list", "(", "range", "(", "self", ".", "classes", ")", ")", "\n", "# -convert them to proper shape", "\n", "", "ys_to_test", "=", "torch", ".", "LongTensor", "(", "batch_size", ",", "len", "(", "class_entries", ")", ")", ".", "to", "(", "self", ".", "_device", "(", ")", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                ", "ys_to_test", "[", "i", "]", "=", "torch", ".", "tensor", "(", "class_entries", ")", ".", "to", "(", "self", ".", "_device", "(", ")", ")", "\n", "\n", "\n", "\n", "", "", "y_neg_energies", "=", "self", "(", "x", ",", "y", "=", "ys_to_test", ")", "if", "self", ".", "neg_energy", "else", "-", "1", "*", "self", "(", "x", ",", "y", "=", "ys_to_test", ")", "\n", "\n", "\n", "# Calculate multiclass prediction loss", "\n", "if", "single_neg", ":", "\n", "            ", "ne_pos_sample", "=", "y_neg_energies", "[", ":", ",", "0", "]", "\n", "ne_neg_samples", "=", "torch", ".", "logsumexp", "(", "y_neg_energies", ",", "dim", "=", "1", ",", "keepdim", "=", "False", ")", "\n", "predL", "=", "-", "ne_pos_sample", "+", "ne_neg_samples", "\n", "\n", "if", "y_", "is", "not", "None", ":", "\n", "                ", "predL", "=", "1", "/", "task", "*", "predL", "[", ":", "batch_size_ori", "]", ".", "mean", "(", ")", "+", "(", "1", "-", "1", "/", "task", ")", "*", "predL", "[", "batch_size_ori", ":", "]", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                ", "predL", "=", "predL", ".", "mean", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "y", "is", "not", "None", "and", "len", "(", "y", ".", "size", "(", ")", ")", "==", "0", ":", "\n", "                ", "y", "=", "y", ".", "expand", "(", "1", ")", "# --> hack to make it work if batch-size is 1", "\n", "", "if", "y", "is", "not", "None", ":", "\n", "                ", "if", "self", ".", "only_classes_in_current_task", ":", "\n", "                    ", "y", "=", "y", "-", "class_entries", "[", "0", "]", "\n", "# predL = F.cross_entropy(input=y_neg_energies, target=y, reduction='none') #-> summing over classes implicit", "\n", "# predL = lf.weighted_average(predL, weights=None, dim=0)                   #-> average over batch", "\n", "# NOTE: above two lines are similar to below 5 lines!", "\n", "", "tem_y", "=", "y", ".", "view", "(", "y", ".", "shape", "[", "0", "]", ",", "1", ")", "\n", "ne_pos_sample", "=", "y_neg_energies", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "tem_y", ")", "\n", "ne_neg_samples", "=", "torch", ".", "logsumexp", "(", "y_neg_energies", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "predL", "=", "-", "ne_pos_sample", "+", "ne_neg_samples", "\n", "predL", "=", "predL", ".", "mean", "(", ")", "\n", "\n", "# Weigh losses", "\n", "", "", "loss_cur", "=", "None", "if", "y", "is", "None", "else", "predL", "\n", "\n", "# Calculate training-precision", "\n", "if", "single_neg", ":", "\n", "            ", "precision", "=", "None", "if", "y", "is", "None", "else", "(", "y_neg_energies", ".", "max", "(", "1", ")", "[", "1", "]", "==", "0", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "", "else", ":", "\n", "            ", "precision", "=", "None", "if", "y", "is", "None", "else", "(", "y", "==", "y_neg_energies", ".", "max", "(", "1", ")", "[", "1", "]", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "\n", "", "return", "loss_cur", ",", "precision", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm.EBM.train_a_batch": [[179, 288], ["ebm.EBM.train", "ebm.EBM.optimizer.zero_grad", "ebm.EBM.surrogate_loss", "ebm.EBM.ewc_loss", "loss_total.backward", "ebm.EBM.optimizer.step", "ebm.EBM.forward_cifar100", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "torch.logsumexp", "predL.mean.mean.mean", "ebm.EBM.gather.pow().mean", "loss_total.item", "ebm.EBM.item", "ebm.EBM.item", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "joint_targets.cuda().long.cuda().long.cuda().long", "ebm.EBM.", "ebm.EBM.", "energy[].view", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "y_tem.view.view.view", "ebm.EBM.gather", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "torch.min", "loss_cur.item", "list", "numpy.stack", "cur_classes.reshape.reshape.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "range", "torch.tensor().view().expand", "torch.tensor().view().expand", "torch.tensor().view().expand", "torch.tensor().view().expand", "joint_targets.cuda().long.cuda().long.cuda().long", "ebm.EBM.gather.pow", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.unique", "torch.cat.unique", "joint_targets.cuda().long.cuda().long.cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "len", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "random.choice", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "torch.tensor().view", "joint_targets.cuda().long.cuda().long.cuda", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "y_tem.view.view.view", "numpy.array", "cur_classes.reshape.reshape.index", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.surrogate_loss", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.ewc_loss", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.ebm.EBM.forward_cifar100"], ["", "def", "train_a_batch", "(", "self", ",", "args", ",", "x", ",", "y", ",", "x_", ",", "y_", ",", "task", "=", "1", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# print(y.min(), y.max(), task)", "\n", "\n", "if", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "            ", "loss_cur", ",", "precision", "=", "self", ".", "forward_cifar100", "(", "args", ",", "x", ",", "y", ",", "x_", ",", "y_", ",", "task", ")", "\n", "", "else", ":", "\n", "            ", "if", "x_", "is", "None", ":", "\n", "                ", "if", "args", ".", "task_boundary", ":", "\n", "                    ", "cur_classes", "=", "self", ".", "labels_per_task", "[", "task", "-", "1", "]", "\n", "", "else", ":", "\n", "                    ", "cur_classes", "=", "list", "(", "y", ".", "unique", "(", ")", ")", "\n", "\n", "", "for", "tem", "in", "y", ":", "assert", "tem", "in", "cur_classes", "## y shoud be in current classes", "\n", "", "else", ":", "\n", "\n", "                ", "if", "args", ".", "task_boundary", ":", "\n", "                    ", "cur_classes", "=", "np", ".", "stack", "(", "self", ".", "labels_per_task", "[", ":", "task", "]", ")", "\n", "cur_classes", "=", "cur_classes", ".", "reshape", "(", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "x_", "]", ",", "dim", "=", "0", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "y_", "]", ",", "dim", "=", "0", ")", "\n", "\n", "\n", "", "", "batch_size", ",", "c", ",", "w", ",", "h", "=", "x", ".", "shape", "\n", "\n", "\n", "single_neg", "=", "True", "\n", "if", "self", ".", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "                ", "joint_targets", "=", "torch", ".", "cat", "(", "[", "y", "[", ":", ",", "None", "]", ",", "(", "torch", ".", "ones", "(", "[", "batch_size", ",", "1", "]", ")", "*", "99", ")", ".", "cuda", "(", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "joint_targets", "=", "joint_targets", ".", "cuda", "(", ")", ".", "long", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "single_neg", ":", "\n", "                    ", "joint_targets", "=", "torch", ".", "LongTensor", "(", "batch_size", ",", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                        ", "while", "True", ":", "\n", "                            ", "neg_sample", "=", "random", ".", "choice", "(", "cur_classes", ")", "\n", "if", "not", "neg_sample", "==", "y", "[", "i", "]", ":", "\n", "                                ", "break", "\n", "", "", "joint_targets", "[", "i", "]", "=", "torch", ".", "tensor", "(", "[", "y", "[", "i", "]", ",", "neg_sample", "]", ")", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "                    ", "joint_targets", "=", "torch", ".", "tensor", "(", "np", ".", "array", "(", "cur_classes", ")", ")", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand", "(", "batch_size", ",", "len", "(", "cur_classes", ")", ")", "\n", "joint_targets", "=", "joint_targets", ".", "cuda", "(", ")", ".", "long", "(", ")", "\n", "\n", "\n", "\n", "\n", "", "", "if", "self", ".", "args", ".", "task_info_input", ":", "\n", "                ", "task_id", "=", "(", "torch", ".", "ones", "(", "[", "batch_size", "]", ")", "*", "(", "task", "-", "1", ")", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "energy", "=", "self", "(", "x", ",", "joint_targets", ",", "task_id", ")", "# [128, 4]", "\n", "", "else", ":", "\n", "                ", "energy", "=", "self", "(", "x", ",", "joint_targets", ")", "# [128, 4]", "\n", "\n", "\n", "\n", "\n", "## compute loss", "\n", "", "if", "single_neg", ":", "\n", "                ", "energy_pos", "=", "energy", "[", ":", ",", "0", "]", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "", "else", ":", "\n", "                ", "y_tem", "=", "torch", ".", "tensor", "(", "[", "cur_classes", ".", "index", "(", "tem", ")", "for", "tem", "in", "y", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "y_tem", "=", "y_tem", ".", "view", "(", "batch_size", ",", "1", ")", "\n", "energy_pos", "=", "energy", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "y_tem", ")", "\n", "\n", "\n", "", "partition_estimate", "=", "-", "1", "*", "energy", "\n", "partition_estimate", "=", "torch", ".", "logsumexp", "(", "partition_estimate", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "predL", "=", "energy_pos", "+", "partition_estimate", "\n", "predL", "=", "predL", ".", "mean", "(", ")", "\n", "\n", "L2_loss", "=", "energy_pos", ".", "pow", "(", "2", ")", ".", "mean", "(", ")", "\n", "loss_cur", "=", "predL", "\n", "\n", "## compuate accuracy", "\n", "if", "single_neg", ":", "\n", "                ", "_", ",", "precision", "=", "torch", ".", "min", "(", "energy", ",", "1", ")", "\n", "precision", "=", "1.", "*", "(", "precision", "==", "torch", ".", "zeros", "(", "batch_size", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", ")", ".", "sum", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "_", ",", "precision", "=", "torch", ".", "min", "(", "energy", ",", "1", ")", "\n", "precision", "=", "1.", "*", "(", "precision", "==", "y_tem", ".", "view", "(", "-", "1", ")", ")", ".", "sum", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "\n", "\n", "## other losses", "\n", "", "", "loss_total", "=", "loss_cur", "\n", "\n", "# Add SI-loss (Zenke et al., 2017)", "\n", "surrogate_loss", "=", "self", ".", "surrogate_loss", "(", ")", "\n", "if", "self", ".", "si_c", ">", "0", ":", "\n", "            ", "loss_total", "+=", "self", ".", "si_c", "*", "surrogate_loss", "\n", "\n", "# Add EWC-loss", "\n", "", "ewc_loss", "=", "self", ".", "ewc_loss", "(", ")", "\n", "if", "self", ".", "ewc_lambda", ">", "0", ":", "\n", "            ", "loss_total", "+=", "self", ".", "ewc_lambda", "*", "ewc_loss", "\n", "\n", "\n", "", "loss_total", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "\n", "# Return the dictionary with different training-loss split in categories", "\n", "return", "{", "\n", "'loss_total'", ":", "loss_total", ".", "item", "(", ")", ",", "\n", "'loss_current'", ":", "loss_cur", ".", "item", "(", ")", "if", "x", "is", "not", "None", "else", "0", ",", "\n", "'ewc'", ":", "ewc_loss", ".", "item", "(", ")", ",", "\n", "'si_loss'", ":", "surrogate_loss", ".", "item", "(", ")", ",", "\n", "'precision'", ":", "precision", "if", "precision", "is", "not", "None", "else", "0.", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier.Classifier.__init__": [[14, 57], ["continual_learner.ContinualLearner.__init__", "list", "utils.Flatten", "range", "network.classifier_layers.CLS_MLP", "network.classifier_layers.CLS_CONV", "network.conv_layers.ConvLayers", "classifier.Classifier.convE.out_units", "classifier.Classifier.convE.out_size", "network.classifier_layers.CLS_net_cifar100", "network.fc.layers.fc_layer", "int", "numpy.linspace"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_units", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_size"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "image_size", ",", "image_channels", ",", "classes", ",", "fc_units", "=", "1000", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "label", "=", "\"Classifier\"", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "num_classes", "=", "classes", "\n", "self", ".", "class_entries", "=", "list", "(", "range", "(", "self", ".", "num_classes", ")", ")", "\n", "self", ".", "labels_per_task", "=", "args", ".", "labels_per_task", "\n", "\n", "# flatten image to 2D-tensor", "\n", "self", ".", "flatten", "=", "utils", ".", "Flatten", "(", ")", "\n", "\n", "# fully connected hidden layers", "\n", "if", "args", ".", "experiment", "==", "'splitMNIST'", "or", "args", ".", "experiment", "==", "'permMNIST'", "or", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "            ", "self", ".", "fcE", "=", "CLS_MLP", "(", "args", ",", "num_classes", "=", "self", ".", "num_classes", ",", "input_size", "=", "image_channels", "*", "image_size", "**", "2", ",", "hid_size", "=", "fc_units", ")", "\n", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "            ", "self", ".", "fcE", "=", "CLS_CONV", "(", "args", ",", "num_classes", "=", "self", ".", "num_classes", ",", "input_size", "=", "image_channels", "*", "image_size", "**", "2", ",", "hid_size", "=", "fc_units", ")", "\n", "\n", "", "elif", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "            ", "self", ".", "convE", "=", "ConvLayers", "(", "\n", "conv_type", "=", "'standard'", ",", "block_type", "=", "\"basic\"", ",", "num_blocks", "=", "2", ",", "image_channels", "=", "image_channels", ",", "\n", "depth", "=", "5", ",", "start_channels", "=", "16", ",", "reducing_layers", "=", "4", ",", "batch_norm", "=", "True", ",", "nl", "=", "'relu'", ",", "\n", "global_pooling", "=", "False", ",", "gated", "=", "False", ",", "output", "=", "\"none\"", ",", "\n", ")", "\n", "#------------------------------calculate input/output-sizes--------------------------------#", "\n", "fc_units", "=", "2000", "\n", "h_dim", "=", "2000", "\n", "fc_layers", "=", "3", "\n", "self", ".", "conv_out_units", "=", "self", ".", "convE", ".", "out_units", "(", "image_size", ")", "\n", "self", ".", "conv_out_size", "=", "self", ".", "convE", ".", "out_size", "(", "image_size", ")", "\n", "self", ".", "conv_out_channels", "=", "self", ".", "convE", ".", "out_channels", "\n", "if", "fc_layers", "<", "2", ":", "\n", "                ", "self", ".", "fc_layer_sizes", "=", "[", "self", ".", "conv_out_units", "]", "#--> this results in self.fcE = modules.Identity()", "\n", "", "elif", "fc_layers", "==", "2", ":", "\n", "                ", "self", ".", "fc_layer_sizes", "=", "[", "self", ".", "conv_out_units", ",", "h_dim", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "fc_layer_sizes", "=", "[", "self", ".", "conv_out_units", "]", "+", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "fc_units", ",", "h_dim", ",", "num", "=", "fc_layers", "-", "1", ")", "]", "\n", "", "self", ".", "units_before_classifier", "=", "h_dim", "if", "fc_layers", ">", "1", "else", "self", ".", "conv_out_units", "\n", "#------------------------------------------------------------------------------------------#", "\n", "self", ".", "fcE", "=", "CLS_net_cifar100", "(", "size_per_layer", "=", "self", ".", "fc_layer_sizes", ",", "drop", "=", "0", ",", "batch_norm", "=", "False", ",", "nl", "=", "'relu'", ",", "bias", "=", "True", ",", "\n", "excitability", "=", "False", ",", "excit_buffer", "=", "True", ",", "gated", "=", "False", ")", "\n", "self", ".", "classifier", "=", "fc_layer", "(", "self", ".", "units_before_classifier", ",", "classes", ",", "excit_buffer", "=", "True", ",", "nl", "=", "'none'", ",", "drop", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier.Classifier.forward": [[59, 72], ["classifier.Classifier.fcE", "classifier.Classifier.flatten", "classifier.Classifier.fcE", "classifier.Classifier.convE", "classifier.Classifier.fcE", "classifier.Classifier.classifier", "classifier.Classifier.flatten"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "self", ".", "args", ".", "experiment", "==", "'splitMNIST'", "or", "self", ".", "args", ".", "experiment", "==", "'permMNIST'", "or", "self", ".", "args", ".", "experiment", "==", "'splitMNISToneclass'", ":", "\n", "            ", "final_features", "=", "self", ".", "fcE", "(", "self", ".", "flatten", "(", "x", ")", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "experiment", "==", "'cifar10'", ":", "\n", "            ", "final_features", "=", "self", ".", "fcE", "(", "x", ")", "\n", "\n", "", "elif", "self", ".", "args", ".", "experiment", "==", "'cifar100'", ":", "\n", "            ", "hidden_rep", "=", "self", ".", "convE", "(", "x", ")", "\n", "final_features", "=", "self", ".", "fcE", "(", "self", ".", "flatten", "(", "hidden_rep", ")", ")", "\n", "final_features", "=", "self", ".", "classifier", "(", "final_features", ")", "\n", "\n", "", "return", "final_features", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier.Classifier.name": [[74, 77], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "'Classifier'", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.network.classifier.Classifier.train_a_batch": [[78, 197], ["classifier.Classifier.train", "classifier.Classifier.optimizer.zero_grad", "classifier.Classifier.surrogate_loss", "classifier.Classifier.ewc_loss", "loss_total.backward", "classifier.Classifier.optimizer.step", "classifier.Classifier.", "loss_total.item", "classifier.Classifier.item", "classifier.Classifier.item", "list", "numpy.stack", "cur_classes.reshape.reshape.reshape", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "range", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.max", "torch.max", "torch.max", "torch.max", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.max", "torch.max", "torch.max", "torch.max", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "torch.LongTensor().cuda", "range", "classifier.Classifier.", "classifier.Classifier.gather", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.max", "torch.max", "torch.max", "torch.max", "classifier.Classifier.", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.tensor().long().cuda", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.max", "torch.max", "torch.max", "torch.max", "loss_cur.item", "torch.cat.unique", "torch.cat.unique", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.nn.functional.cross_entropy", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.tensor().cuda", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "random.choice", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "torch.tensor().long", "int", "predL[].mean", "predL[].mean", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.cat.max", "torch.cat.max", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "seen_classes_list.index", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "cur_classes.reshape.reshape.index", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.zeros().long().cuda", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros().long", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.surrogate_loss", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.None.continual_learner.ContinualLearner.ewc_loss"], ["", "def", "train_a_batch", "(", "self", ",", "args", ",", "x", ",", "y", ",", "x_", ",", "y_", ",", "task", "=", "1", ")", ":", "\n", "        ", "self", ".", "train", "(", ")", "\n", "self", ".", "optimizer", ".", "zero_grad", "(", ")", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "\n", "if", "x_", "is", "None", ":", "\n", "            ", "if", "args", ".", "task_boundary", ":", "\n", "                ", "cur_classes", "=", "self", ".", "labels_per_task", "[", "task", "-", "1", "]", "\n", "", "else", ":", "\n", "                ", "cur_classes", "=", "list", "(", "y", ".", "unique", "(", ")", ")", "\n", "", "for", "tem", "in", "y", ":", "assert", "tem", "in", "cur_classes", "## y shoud be in current classes", "\n", "", "else", ":", "\n", "            ", "if", "args", ".", "task_boundary", ":", "\n", "                ", "cur_classes", "=", "np", ".", "stack", "(", "self", ".", "labels_per_task", "[", ":", "task", "]", ")", "\n", "cur_classes", "=", "cur_classes", ".", "reshape", "(", "-", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "[", "x", ",", "x_", "]", ",", "dim", "=", "0", ")", "\n", "y", "=", "torch", ".", "cat", "(", "[", "y", ",", "y_", "]", ",", "dim", "=", "0", ")", "\n", "\n", "\n", "", "", "if", "args", ".", "cls_standard", ":", "\n", "            ", "y_hat", "=", "self", "(", "x", ")", "\n", "\n", "over_seen_classes", "=", "True", "\n", "if", "over_seen_classes", ":", "\n", "                ", "seen_classes_list", "=", "[", "]", "\n", "\n", "if", "not", "args", ".", "task_boundary", ":", "\n", "                    ", "task", "=", "args", ".", "task_dict", "[", "int", "(", "y", ".", "max", "(", ")", ")", "]", "\n", "\n", "", "for", "i", "in", "range", "(", "task", ")", ":", "\n", "                    ", "seen_classes_list", "+=", "self", ".", "labels_per_task", "[", "i", "]", "\n", "\n", "", "y_hat", "=", "y_hat", "[", ":", ",", "seen_classes_list", "]", "\n", "\n", "\n", "## compute loss", "\n", "y_tem", "=", "torch", ".", "tensor", "(", "[", "seen_classes_list", ".", "index", "(", "tem", ")", "for", "tem", "in", "y", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "if", "y_", "is", "not", "None", ":", "\n", "                    ", "predL", "=", "F", ".", "cross_entropy", "(", "input", "=", "y_hat", ",", "target", "=", "y_tem", ",", "reduction", "=", "'none'", ")", "\n", "predL", "=", "1", "/", "task", "*", "predL", "[", ":", "batch_size", "]", ".", "mean", "(", ")", "+", "(", "1", "-", "1", "/", "task", ")", "*", "predL", "[", "batch_size", ":", "]", ".", "mean", "(", ")", "\n", "", "else", ":", "\n", "                    ", "predL", "=", "F", ".", "cross_entropy", "(", "input", "=", "y_hat", ",", "target", "=", "y_tem", ",", "reduction", "=", "'mean'", ")", "\n", "", "loss_cur", "=", "predL", "\n", "\n", "## compuate accuracy", "\n", "_", ",", "precision", "=", "torch", ".", "max", "(", "y_hat", ",", "1", ")", "\n", "precision", "=", "1.", "*", "(", "precision", "==", "y_tem", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "\n", "", "else", ":", "\n", "## compute loss over all classes", "\n", "                ", "predL", "=", "F", ".", "cross_entropy", "(", "input", "=", "y_hat", ",", "target", "=", "y", ",", "reduction", "=", "'mean'", ")", "\n", "loss_cur", "=", "predL", "\n", "\n", "## compuate accuracy", "\n", "_", ",", "precision", "=", "torch", ".", "max", "(", "y_hat", ",", "1", ")", "\n", "precision", "=", "1.", "*", "(", "precision", "==", "y", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "\n", "", "", "else", ":", "\n", "# single_neg = args.single_neg", "\n", "            ", "single_neg", "=", "True", "\n", "if", "single_neg", ":", "\n", "                ", "joint_targets", "=", "torch", ".", "LongTensor", "(", "batch_size", ",", "2", ")", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "batch_size", ")", ":", "\n", "                    ", "while", "True", ":", "\n", "                        ", "neg_sample", "=", "random", ".", "choice", "(", "cur_classes", ")", "\n", "if", "not", "neg_sample", "==", "y", "[", "i", "]", ":", "\n", "                            ", "break", "\n", "", "", "joint_targets", "[", "i", "]", "=", "torch", ".", "tensor", "(", "[", "y", "[", "i", "]", ",", "neg_sample", "]", ")", ".", "cuda", "(", ")", "\n", "\n", "", "y_hat", "=", "self", "(", "x", ")", "\n", "y_hat", "=", "y_hat", ".", "gather", "(", "dim", "=", "1", ",", "index", "=", "joint_targets", ")", "\n", "\n", "## compute loss", "\n", "predL", "=", "F", ".", "cross_entropy", "(", "input", "=", "y_hat", ",", "target", "=", "torch", ".", "zeros", "(", "batch_size", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", ",", "reduction", "=", "'mean'", ")", "\n", "loss_cur", "=", "predL", "\n", "\n", "## compuate accuracy", "\n", "_", ",", "precision", "=", "torch", ".", "max", "(", "y_hat", ",", "1", ")", "\n", "precision", "=", "1.", "*", "(", "precision", "==", "torch", ".", "zeros", "(", "batch_size", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "\n", "", "else", ":", "\n", "                ", "y_hat", "=", "self", "(", "x", ")", "\n", "y_hat", "=", "y_hat", "[", ":", ",", "cur_classes", "]", "\n", "\n", "## compute loss", "\n", "y_tem", "=", "torch", ".", "tensor", "(", "[", "cur_classes", ".", "index", "(", "tem", ")", "for", "tem", "in", "y", "]", ")", ".", "long", "(", ")", ".", "cuda", "(", ")", "\n", "predL", "=", "F", ".", "cross_entropy", "(", "input", "=", "y_hat", ",", "target", "=", "y_tem", ",", "reduction", "=", "'mean'", ")", "\n", "loss_cur", "=", "predL", "\n", "\n", "## compuate accuracy", "\n", "_", ",", "precision", "=", "torch", ".", "max", "(", "y_hat", ",", "1", ")", "\n", "precision", "=", "1.", "*", "(", "precision", "==", "y_tem", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "x", ".", "size", "(", "0", ")", "\n", "\n", "## other losses", "\n", "", "", "loss_total", "=", "loss_cur", "\n", "\n", "# Add SI-loss (Zenke et al., 2017)", "\n", "surrogate_loss", "=", "self", ".", "surrogate_loss", "(", ")", "\n", "if", "self", ".", "si_c", ">", "0", ":", "\n", "            ", "loss_total", "+=", "self", ".", "si_c", "*", "surrogate_loss", "\n", "\n", "# Add EWC-loss", "\n", "", "ewc_loss", "=", "self", ".", "ewc_loss", "(", ")", "\n", "if", "self", ".", "ewc_lambda", ">", "0", ":", "\n", "            ", "loss_total", "+=", "self", ".", "ewc_lambda", "*", "ewc_loss", "\n", "\n", "\n", "", "loss_total", ".", "backward", "(", ")", "\n", "self", ".", "optimizer", ".", "step", "(", ")", "\n", "\n", "# Return the dictionary with different training-loss split in categories", "\n", "return", "{", "\n", "'loss_total'", ":", "loss_total", ".", "item", "(", ")", ",", "\n", "'loss_current'", ":", "loss_cur", ".", "item", "(", ")", "if", "x", "is", "not", "None", "else", "0", ",", "\n", "'ewc'", ":", "ewc_loss", ".", "item", "(", ")", ",", "\n", "'si_loss'", ":", "surrogate_loss", ".", "item", "(", ")", ",", "\n", "'precision'", ":", "precision", "if", "precision", "is", "not", "None", "else", "0.", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP.__init__": [[14, 82], ["torch.nn.Module.__init__", "range", "len", "models.fc.layers.fc_layer", "setattr", "models.utils.modules.Identity", "int", "int", "numpy.linspace", "numpy.repeat", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "input_size", "=", "1000", ",", "output_size", "=", "10", ",", "layers", "=", "2", ",", "hid_size", "=", "1000", ",", "hid_smooth", "=", "None", ",", "size_per_layer", "=", "None", ",", "\n", "drop", "=", "0", ",", "batch_norm", "=", "True", ",", "nl", "=", "\"relu\"", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "gated", "=", "False", ",", "\n", "output", "=", "'normal'", ")", ":", "\n", "        ", "'''sizes: 0th=[input], 1st=[hid_size], ..., 1st-to-last=[hid_smooth], last=[output].\n        [input_size]       # of inputs\n        [output_size]      # of units in final layer\n        [layers]           # of layers\n        [hid_size]         # of units in each hidden layer\n        [hid_smooth]       if None, all hidden layers have [hid_size] units, else # of units linearly in-/decreases s.t.\n                             final hidden layer has [hid_smooth] units (if only 1 hidden layer, it has [hid_size] units)\n        [size_per_layer]   None or <list> with for each layer number of units (1st element = number of inputs)\n                                --> overwrites [input_size], [output_size], [layers], [hid_size] and [hid_smooth]\n        [drop]             % of each layer's inputs that is randomly set to zero during training\n        [batch_norm]       <bool>; if True, batch-normalization is applied to each layer\n        [nl]               <str>; type of non-linearity to be used (options: \"relu\", \"leakyrelu\", \"none\")\n        [gated]            <bool>; if True, each linear layer has an additional learnable gate\n                                    (whereby the gate is controlled by the same input as that goes through the gate)\n        [output]           <str>; if - \"normal\", final layer is same as all others\n                                     - \"none\", final layer has no non-linearity\n                                     - \"sigmoid\", final layer has sigmoid non-linearity'''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output", "=", "output", "\n", "\n", "# get sizes of all layers", "\n", "if", "size_per_layer", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n", "if", "layers", ">", "1", ":", "\n", "                ", "if", "(", "hid_smooth", "is", "not", "None", ")", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "hid_size", ",", "hid_smooth", ",", "num", "=", "layers", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "repeat", "(", "hid_size", ",", "layers", "-", "1", ")", "]", "\n", "", "", "size_per_layer", "=", "[", "input_size", "]", "+", "hidden_sizes", "+", "[", "output_size", "]", "if", "layers", ">", "0", "else", "[", "input_size", "]", "\n", "", "self", ".", "layers", "=", "len", "(", "size_per_layer", ")", "-", "1", "\n", "\n", "# set label for this module", "\n", "# -determine \"non-default options\"-label", "\n", "nd_label", "=", "\"{drop}{bias}{exc}{bn}{nl}{gate}\"", ".", "format", "(", "\n", "drop", "=", "\"\"", "if", "drop", "==", "0", "else", "\"d{}\"", ".", "format", "(", "drop", ")", ",", "\n", "bias", "=", "\"\"", "if", "bias", "else", "\"n\"", ",", "exc", "=", "\"e\"", "if", "excitability", "else", "\"\"", ",", "bn", "=", "\"b\"", "if", "batch_norm", "else", "\"\"", ",", "\n", "nl", "=", "\"l\"", "if", "nl", "==", "\"leakyrelu\"", "else", "\"\"", ",", "gate", "=", "\"g\"", "if", "gated", "else", "\"\"", ",", "\n", ")", "\n", "nd_label", "=", "\"{}{}\"", ".", "format", "(", "\"\"", "if", "nd_label", "==", "\"\"", "else", "\"-{}\"", ".", "format", "(", "nd_label", ")", ",", "\n", "\"\"", "if", "output", "==", "\"normal\"", "else", "\"-{}\"", ".", "format", "(", "output", ")", ")", "\n", "# -set label", "\n", "size_statement", "=", "\"\"", "\n", "for", "i", "in", "size_per_layer", ":", "\n", "            ", "size_statement", "+=", "\"{}{}\"", ".", "format", "(", "\"-\"", "if", "size_statement", "==", "\"\"", "else", "\"x\"", ",", "i", ")", "\n", "", "self", ".", "label", "=", "\"F{}{}\"", ".", "format", "(", "size_statement", ",", "nd_label", ")", "if", "self", ".", "layers", ">", "0", "else", "\"\"", "\n", "\n", "# set layers", "\n", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "# number of units of this layer's input and output", "\n", "            ", "in_size", "=", "size_per_layer", "[", "lay_id", "-", "1", "]", "\n", "out_size", "=", "size_per_layer", "[", "lay_id", "]", "\n", "# define and set the fully connected layer", "\n", "layer", "=", "fc_layer", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "gated", "=", "gated", ",", "\n", "nl", "=", "(", "\"none\"", "if", "output", "==", "\"none\"", "else", "nn", ".", "Sigmoid", "(", ")", ")", "if", "(", "\n", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", "\n", ")", "else", "nl", ",", "drop", "=", "drop", "if", "lay_id", ">", "1", "else", "0.", ",", "\n", ")", "\n", "setattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ",", "layer", ")", "\n", "\n", "# if no layers, add \"identity\"-module to indicate in this module's representation nothing happens", "\n", "", "if", "self", ".", "layers", "<", "1", ":", "\n", "            ", "self", ".", "noLayers", "=", "modules", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP.forward": [[83, 97], ["range", "getattr", "pre_act_list.append", "hidden_act_list.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "skip_first", "=", "0", ",", "skip_last", "=", "0", ",", "return_lists", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# Initiate <list> for keeping track of intermediate hidden-(pre)activations", "\n", "        ", "if", "return_lists", ":", "\n", "            ", "hidden_act_list", "=", "[", "]", "\n", "pre_act_list", "=", "[", "]", "\n", "# Sequentially pass [x] through all fc-layers", "\n", "", "for", "lay_id", "in", "range", "(", "skip_first", "+", "1", ",", "self", ".", "layers", "+", "1", "-", "skip_last", ")", ":", "\n", "            ", "(", "x", ",", "pre_act", ")", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ",", "return_pa", "=", "True", ")", "\n", "if", "return_lists", ":", "\n", "                ", "pre_act_list", ".", "append", "(", "pre_act", ")", "#-> for each layer, store pre-activations", "\n", "if", "lay_id", "<", "(", "self", ".", "layers", "-", "skip_last", ")", ":", "\n", "                    ", "hidden_act_list", ".", "append", "(", "x", ")", "#-> for all but last layer, store hidden activations", "\n", "# Return final [x], if requested along with [hidden_act_list] and [pre_act_list]", "\n", "", "", "", "return", "(", "x", ",", "hidden_act_list", ",", "pre_act_list", ")", "if", "return_lists", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP.name": [[99, 102], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP.list_init_layers": [[103, 109], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "list", "+=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "layer_id", ")", ")", ".", "list_init_layers", "(", ")", "\n", "", "return", "list", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP_gates.__init__": [[122, 202], ["torch.nn.Module.__init__", "range", "len", "setattr", "models.utils.modules.Identity", "models.fc.layers.fc_layer", "models.fc.layers.fc_layer_fixed_gates", "int", "int", "numpy.linspace", "numpy.repeat", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "input_size", "=", "1000", ",", "output_size", "=", "10", ",", "layers", "=", "2", ",", "hid_size", "=", "1000", ",", "hid_smooth", "=", "None", ",", "size_per_layer", "=", "None", ",", "\n", "drop", "=", "0", ",", "batch_norm", "=", "True", ",", "nl", "=", "\"relu\"", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "gate_size", "=", "0", ",", "\n", "gating_prop", "=", "0.", ",", "final_gate", "=", "False", ",", "output", "=", "'normal'", ",", "device", "=", "'cuda'", ")", ":", "\n", "        ", "'''sizes: 0th=[input], 1st=[hid_size], ..., 1st-to-last=[hid_smooth], last=[output].\n        [input_size]       # of inputs\n        [output_size]      # of units in final layer\n        [layers]           # of layers\n        [hid_size]         # of units in each hidden layer\n        [hid_smooth]       if None, all hidden layers have [hid_size] units, else # of units linearly in-/decreases s.t.\n                             final hidden layer has [hid_smooth] units (if only 1 hidden layer, it has [hid_size] units)\n        [size_per_layer]   None or <list> with for each layer number of units (1st element = number of inputs)\n                                --> overwrites [input_size], [output_size], [layers], [hid_size] and [hid_smooth]\n        [drop]             % of each layer's inputs that is randomly set to zero during training\n        [batch_norm]       <bool>; if True, batch-normalization is applied to each layer\n        [nl]               <str>; type of non-linearity to be used (options: \"relu\", \"leakyrelu\", \"none\")\n        [gate_size]        <int>; if>0, each linear layer has gate controlled by separate inputs of size [gate_size]\n        [gating_prop]      <float>; probability for each unit to be gated\n        [final_gate]       <bool>; whether final layer is allowed to have a gate\n        [output]           <str>; if - \"normal\", final layer is same as all others\n                                     - \"none\", final layer has no non-linearity\n                                     - \"sigmoid\", final layer has sigmoid non-linearity'''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output", "=", "output", "\n", "\n", "# get sizes of all layers", "\n", "if", "size_per_layer", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n", "if", "layers", ">", "1", ":", "\n", "                ", "if", "(", "hid_smooth", "is", "not", "None", ")", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "hid_size", ",", "hid_smooth", ",", "num", "=", "layers", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "repeat", "(", "hid_size", ",", "layers", "-", "1", ")", "]", "\n", "", "", "size_per_layer", "=", "[", "input_size", "]", "+", "hidden_sizes", "+", "[", "output_size", "]", "if", "layers", ">", "0", "else", "[", "input_size", "]", "\n", "", "self", ".", "layers", "=", "len", "(", "size_per_layer", ")", "-", "1", "\n", "\n", "# set label for this module", "\n", "# -determine \"non-default options\"-label", "\n", "nd_label", "=", "\"{drop}{bias}{exc}{bn}{nl}{gate}\"", ".", "format", "(", "\n", "drop", "=", "\"\"", "if", "drop", "==", "0", "else", "\"d{}\"", ".", "format", "(", "drop", ")", ",", "\n", "bias", "=", "\"\"", "if", "bias", "else", "\"n\"", ",", "exc", "=", "\"e\"", "if", "excitability", "else", "\"\"", ",", "bn", "=", "\"b\"", "if", "batch_norm", "else", "\"\"", ",", "\n", "nl", "=", "\"l\"", "if", "nl", "==", "\"leakyrelu\"", "else", "\"\"", ",", "\n", "gate", "=", "\"g{}m{}\"", ".", "format", "(", "gate_size", ",", "gating_prop", ")", "if", "(", "gate_size", ">", "0", "and", "gating_prop", ">", "0.", ")", "else", "\"\"", ",", "\n", ")", "\n", "nd_label", "=", "\"{}{}\"", ".", "format", "(", "\"\"", "if", "nd_label", "==", "\"\"", "else", "\"-{}\"", ".", "format", "(", "nd_label", ")", ",", "\n", "\"\"", "if", "output", "==", "\"normal\"", "else", "\"-{}\"", ".", "format", "(", "output", ")", ")", "\n", "# -set label", "\n", "size_statement", "=", "\"\"", "\n", "for", "i", "in", "size_per_layer", ":", "\n", "            ", "size_statement", "+=", "\"{}{}\"", ".", "format", "(", "\"-\"", "if", "size_statement", "==", "\"\"", "else", "\"x\"", ",", "i", ")", "\n", "", "self", ".", "label", "=", "\"F{}{}\"", ".", "format", "(", "size_statement", ",", "nd_label", ")", "if", "self", ".", "layers", ">", "0", "else", "\"\"", "\n", "\n", "# set layers", "\n", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "# number of units of this layer's input and output", "\n", "            ", "in_size", "=", "size_per_layer", "[", "lay_id", "-", "1", "]", "\n", "out_size", "=", "size_per_layer", "[", "lay_id", "]", "\n", "# define and set the fully connected layer", "\n", "if", "(", "not", "gate_size", ">", "0.", ")", "or", "(", "not", "gating_prop", ">", "0.", ")", "or", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "final_gate", ")", ":", "\n", "                ", "layer", "=", "fc_layer", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "\n", "nl", "=", "(", "\"none\"", "if", "output", "==", "\"none\"", "else", "nn", ".", "Sigmoid", "(", ")", ")", "if", "(", "\n", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", "\n", ")", "else", "nl", ",", "drop", "=", "drop", "if", "lay_id", ">", "1", "else", "0.", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer", "=", "fc_layer_fixed_gates", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "\n", "gate_size", "=", "gate_size", ",", "gating_prop", "=", "gating_prop", ",", "device", "=", "device", ",", "\n", "nl", "=", "(", "\"none\"", "if", "output", "==", "\"none\"", "else", "nn", ".", "Sigmoid", "(", ")", ")", "if", "(", "\n", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", "\n", ")", "else", "nl", ",", "drop", "=", "drop", "if", "lay_id", ">", "1", "else", "0.", ",", "\n", ")", "\n", "", "setattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ",", "layer", ")", "\n", "\n", "# if no layers, add \"identity\"-module to indicate in this module's representation nothing happens", "\n", "", "if", "self", ".", "layers", "<", "1", ":", "\n", "            ", "self", ".", "noLayers", "=", "modules", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP_gates.forward": [[203, 217], ["range", "getattr", "pre_act_list.append", "hidden_act_list.append"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "gate_input", "=", "None", ",", "skip_first", "=", "0", ",", "skip_last", "=", "0", ",", "return_lists", "=", "False", ")", ":", "\n", "# Initiate <list> for keeping track of intermediate hidden-(pre)activations", "\n", "        ", "if", "return_lists", ":", "\n", "            ", "hidden_act_list", "=", "[", "]", "\n", "pre_act_list", "=", "[", "]", "\n", "# Sequentially pass [x] through all fc-layers", "\n", "", "for", "lay_id", "in", "range", "(", "skip_first", "+", "1", ",", "self", ".", "layers", "+", "1", "-", "skip_last", ")", ":", "\n", "            ", "(", "x", ",", "pre_act", ")", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ",", "gate_input", "=", "gate_input", ",", "return_pa", "=", "True", ")", "\n", "if", "return_lists", ":", "\n", "                ", "pre_act_list", ".", "append", "(", "pre_act", ")", "#-> for each layer, store pre-activations", "\n", "if", "lay_id", "<", "(", "self", ".", "layers", "-", "skip_last", ")", ":", "\n", "                    ", "hidden_act_list", ".", "append", "(", "x", ")", "#-> for all but last layer, store hidden activations", "\n", "# Return final [x], if requested along with [hidden_act_list] and [pre_act_list]", "\n", "", "", "", "return", "(", "x", ",", "hidden_act_list", ",", "pre_act_list", ")", "if", "return_lists", "else", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP_gates.name": [[219, 222], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.nets.MLP_gates.list_init_layers": [[223, 229], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "list", "+=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "layer_id", ")", ")", ".", "list_init_layers", "(", ")", "\n", "", "return", "list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer.__init__": [[14, 30], ["torch.nn.ReLU", "torch.nn.Module.__init__", "network.fc.excitability_modules.LinearExcitability", "isinstance", "torch.nn.Dropout", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.ReLU", "torch.nn.LeakyReLU", "network.utils.modules.Identity"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "nl", "=", "nn", ".", "ReLU", "(", ")", ",", "\n", "drop", "=", "0.", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "batch_norm", "=", "False", ",", "gated", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "drop", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "", "self", ".", "linear", "=", "em", ".", "LinearExcitability", "(", "in_size", ",", "out_size", ",", "bias", "=", "False", "if", "batch_norm", "else", "bias", ",", "\n", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "out_size", ")", "\n", "", "if", "gated", ":", "\n", "            ", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "", "if", "isinstance", "(", "nl", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "self", ".", "nl", "=", "nl", "\n", "", "elif", "not", "nl", "==", "\"none\"", ":", "\n", "            ", "self", ".", "nl", "=", "nn", ".", "ReLU", "(", ")", "if", "nl", "==", "\"relu\"", "else", "(", "nn", ".", "LeakyReLU", "(", ")", "if", "nl", "==", "\"leakyrelu\"", "else", "modules", ".", "Identity", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer.forward": [[31, 38], ["hasattr", "layers.fc_layer.dropout", "hasattr", "layers.fc_layer.bn", "layers.fc_layer.linear", "hasattr", "layers.fc_layer.sigmoid", "hasattr", "hasattr", "layers.fc_layer.nl", "layers.fc_layer.linear", "layers.fc_layer.gate"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "return_pa", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "input", "=", "self", ".", "dropout", "(", "x", ")", "if", "hasattr", "(", "self", ",", "'dropout'", ")", "else", "x", "\n", "pre_activ", "=", "self", ".", "bn", "(", "self", ".", "linear", "(", "input", ")", ")", "if", "hasattr", "(", "self", ",", "'bn'", ")", "else", "self", ".", "linear", "(", "input", ")", "\n", "gate", "=", "self", ".", "sigmoid", "(", "self", ".", "gate", "(", "x", ")", ")", "if", "hasattr", "(", "self", ",", "'gate'", ")", "else", "None", "\n", "gated_pre_activ", "=", "gate", "*", "pre_activ", "if", "hasattr", "(", "self", ",", "'gate'", ")", "else", "pre_activ", "\n", "output", "=", "self", ".", "nl", "(", "gated_pre_activ", ")", "if", "hasattr", "(", "self", ",", "'nl'", ")", "else", "gated_pre_activ", "\n", "return", "(", "output", ",", "gated_pre_activ", ")", "if", "return_pa", "else", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer.list_init_layers": [[39, 42], ["hasattr"], "methods", ["None"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "return", "[", "self", ".", "linear", ",", "self", ".", "gate", "]", "if", "hasattr", "(", "self", ",", "'gate'", ")", "else", "[", "self", ".", "linear", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer_split.__init__": [[51, 59], ["torch.nn.Sigmoid", "torch.nn.Hardtanh", "torch.nn.Module.__init__", "layers.fc_layer", "layers.fc_layer"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "nl_mean", "=", "nn", ".", "Sigmoid", "(", ")", ",", "nl_logvar", "=", "nn", ".", "Hardtanh", "(", "min_val", "=", "-", "4.5", ",", "max_val", "=", "0.", ")", ",", "\n", "drop", "=", "0.", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "batch_norm", "=", "False", ",", "gated", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "mean", "=", "fc_layer", "(", "in_size", ",", "out_size", ",", "drop", "=", "drop", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "\n", "excit_buffer", "=", "excit_buffer", ",", "batch_norm", "=", "batch_norm", ",", "gated", "=", "gated", ",", "nl", "=", "nl_mean", ")", "\n", "self", ".", "logvar", "=", "fc_layer", "(", "in_size", ",", "out_size", ",", "drop", "=", "drop", ",", "bias", "=", "False", ",", "excitability", "=", "excitability", ",", "\n", "excit_buffer", "=", "excit_buffer", ",", "batch_norm", "=", "batch_norm", ",", "gated", "=", "gated", ",", "nl", "=", "nl_logvar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer_split.forward": [[60, 62], ["layers.fc_layer_split.mean", "layers.fc_layer_split.logvar"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "(", "self", ".", "mean", "(", "x", ")", ",", "self", ".", "logvar", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer_split.list_init_layers": [[63, 69], ["layers.fc_layer_split.mean.list_init_layers", "layers.fc_layer_split.logvar.list_init_layers"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "list", "+=", "self", ".", "mean", ".", "list_init_layers", "(", ")", "\n", "list", "+=", "self", ".", "logvar", ".", "list_init_layers", "(", ")", "\n", "return", "list", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer_fixed_gates.__init__": [[78, 97], ["torch.nn.ReLU", "torch.nn.Module.__init__", "network.fc.excitability_modules.LinearExcitability", "isinstance", "torch.nn.Dropout", "torch.nn.BatchNorm1d", "torch.tensor", "numpy.random.choice", "torch.nn.ReLU", "torch.nn.LeakyReLU", "network.utils.modules.Identity"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "nl", "=", "nn", ".", "ReLU", "(", ")", ",", "\n", "drop", "=", "0.", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "batch_norm", "=", "False", ",", "\n", "gate_size", "=", "0", ",", "gating_prop", "=", "0.8", ",", "device", "=", "'cuda'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "drop", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "", "self", ".", "linear", "=", "em", ".", "LinearExcitability", "(", "in_size", ",", "out_size", ",", "bias", "=", "False", "if", "batch_norm", "else", "bias", ",", "\n", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "out_size", ")", "\n", "", "if", "gate_size", ">", "0", ":", "\n", "            ", "self", ".", "gate_mask", "=", "torch", ".", "tensor", "(", "\n", "np", ".", "random", ".", "choice", "(", "[", "0.", ",", "1.", "]", ",", "size", "=", "(", "gate_size", ",", "out_size", ")", ",", "p", "=", "[", "gating_prop", ",", "1.", "-", "gating_prop", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", "\n", ")", "\n", "", "if", "isinstance", "(", "nl", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "self", ".", "nl", "=", "nl", "\n", "", "elif", "not", "nl", "==", "\"none\"", ":", "\n", "            ", "self", ".", "nl", "=", "nn", ".", "ReLU", "(", ")", "if", "nl", "==", "\"relu\"", "else", "(", "nn", ".", "LeakyReLU", "(", ")", "if", "nl", "==", "\"leakyrelu\"", "else", "modules", ".", "Identity", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer_fixed_gates.forward": [[98, 105], ["hasattr", "layers.fc_layer_fixed_gates.dropout", "hasattr", "layers.fc_layer_fixed_gates.bn", "layers.fc_layer_fixed_gates.linear", "hasattr", "torch.matmul", "hasattr", "hasattr", "layers.fc_layer_fixed_gates.nl", "layers.fc_layer_fixed_gates.linear"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "gate_input", "=", "None", ",", "return_pa", "=", "False", ")", ":", "\n", "        ", "input", "=", "self", ".", "dropout", "(", "x", ")", "if", "hasattr", "(", "self", ",", "'dropout'", ")", "else", "x", "\n", "pre_activ", "=", "self", ".", "bn", "(", "self", ".", "linear", "(", "input", ")", ")", "if", "hasattr", "(", "self", ",", "'bn'", ")", "else", "self", ".", "linear", "(", "input", ")", "\n", "gate", "=", "torch", ".", "matmul", "(", "gate_input", ",", "self", ".", "gate_mask", ")", "if", "hasattr", "(", "self", ",", "'gate_mask'", ")", "else", "None", "\n", "gated_pre_activ", "=", "gate", "*", "pre_activ", "if", "hasattr", "(", "self", ",", "'gate_mask'", ")", "else", "pre_activ", "\n", "output", "=", "self", ".", "nl", "(", "gated_pre_activ", ")", "if", "hasattr", "(", "self", ",", "'nl'", ")", "else", "gated_pre_activ", "\n", "return", "(", "output", ",", "gated_pre_activ", ")", "if", "return_pa", "else", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.layers.fc_layer_fixed_gates.list_init_layers": [[106, 109], ["hasattr"], "methods", ["None"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "return", "[", "self", ".", "linear", ",", "self", ".", "gate", "]", "if", "hasattr", "(", "self", ",", "'gate'", ")", "else", "[", "self", ".", "linear", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.ebm_nets---.EBM_net.__init__": [[15, 110], ["torch.nn.Module.__init__", "range", "len", "setattr", "utils.Identity", "torch.nn.Embedding", "models.fc.layers.fc_layer_fixed_gates", "models.fc.layers.fc_layer", "int", "int", "numpy.linspace", "numpy.repeat", "torch.nn.Sigmoid", "torch.nn.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "num_classes", "=", "10", ",", "input_size", "=", "1000", ",", "output_size", "=", "10", ",", "layers", "=", "2", ",", "hid_size", "=", "1000", ",", "hid_smooth", "=", "None", ",", "\n", "size_per_layer", "=", "None", ",", "\n", "drop", "=", "0", ",", "batch_norm", "=", "True", ",", "nl", "=", "\"relu\"", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "output", "=", "'normal'", ",", "\n", "fixed_mask", "=", "True", ",", "mask_prob", "=", "0.8", ",", "only_first", "=", "False", ",", "with_skip", "=", "False", ")", ":", "\n", "        ", "'''sizes: 0th=[input], 1st=[hid_size], ..., 1st-to-last=[hid_smooth], last=[output].\n        [num_classes]      # of classes\n        [input_size]       # of inputs\n        [output_size]      # of output units\n        [layers]           # of layers\n        [hid_size]         # of units in each hidden layer\n        [hid_smooth]       if None, all hidden layers have [hid_size] units, else # of units linearly in-/decreases s.t.\n                             final hidden layer has [hid_smooth] units (if only 1 hidden layer, it has [hid_size] units)\n        [size_per_layer]   None or <list> with for each layer number of units (1st element = number of inputs)\n                                --> overwrites [input_size], [output_size], [layers], [hid_size] and [hid_smooth]\n        [drop]             % of each layer's inputs that is randomly set to zero during training\n        [batch_norm]       <bool>; if True, batch-normalization is applied to each layer\n        [nl]               <str>; type of non-linearity to be used (options: \"relu\", \"leakyrelu\", \"none\")\n        [output]           <str>; if - \"normal\", final layer is same as all others\n                                     - \"none\", final layer has no non-linearity\n                                     - \"sigmoid\", final layer has sigmoid non-linearity\n        EBM-related parameters\n        [fixed_mask]       <bool>; whether to use fixed masks instead of learnable gates\n        [mask_prop]        <float>; probability of each node being gated for particular class (if using `fixed_mask`)\n        [only_first]       <bool>; whether learnable gate is only used for first layer (only if not using `fixed_mask`)\n                              NOTE: if set to ``False``, all layers must have same number of units!\n        [with_skip]        <bool>; whehter there should be a skip-connection around the learnable gate\n        '''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output", "=", "output", "\n", "self", ".", "fixed_mask", "=", "fixed_mask", "\n", "self", ".", "only_first", "=", "only_first", "\n", "self", ".", "num_classes", "=", "num_classes", "\n", "self", ".", "with_skip", "=", "with_skip", "\n", "\n", "# get sizes of all layers", "\n", "if", "size_per_layer", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n", "if", "layers", ">", "1", ":", "\n", "                ", "if", "(", "hid_smooth", "is", "not", "None", ")", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "hid_size", ",", "hid_smooth", ",", "num", "=", "layers", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "repeat", "(", "hid_size", ",", "layers", "-", "1", ")", "]", "\n", "\n", "", "", "size_per_layer", "=", "[", "input_size", "]", "+", "hidden_sizes", "+", "[", "output_size", "]", "\n", "", "self", ".", "layers", "=", "len", "(", "size_per_layer", ")", "-", "1", "\n", "self", ".", "output_size", "=", "size_per_layer", "[", "-", "1", "]", "\n", "\n", "# set label for this module", "\n", "# -determine \"non-default options\"-label", "\n", "nd_label", "=", "\"{drop}{bias}{exc}{bn}{nl}\"", ".", "format", "(", "\n", "drop", "=", "\"\"", "if", "drop", "==", "0", "else", "\"d{}\"", ".", "format", "(", "drop", ")", ",", "\n", "bias", "=", "\"\"", "if", "bias", "else", "\"n\"", ",", "exc", "=", "\"e\"", "if", "excitability", "else", "\"\"", ",", "bn", "=", "\"b\"", "if", "batch_norm", "else", "\"\"", ",", "\n", "nl", "=", "\"l\"", "if", "nl", "==", "\"leakyrelu\"", "else", "\"\"", ",", "\n", ")", "\n", "nd_label", "=", "\"{}{}\"", ".", "format", "(", "\"\"", "if", "nd_label", "==", "\"\"", "else", "\"-{}\"", ".", "format", "(", "nd_label", ")", ",", "\n", "\"\"", "if", "output", "==", "\"normal\"", "else", "\"-{}\"", ".", "format", "(", "output", ")", ")", "\n", "# -set label", "\n", "size_statement", "=", "\"\"", "\n", "for", "i", "in", "size_per_layer", ":", "\n", "            ", "size_statement", "+=", "\"{}{}\"", ".", "format", "(", "\"-\"", "if", "size_statement", "==", "\"\"", "else", "\"x\"", ",", "i", ")", "\n", "", "self", ".", "label", "=", "\"EBM{}{}{}{}\"", ".", "format", "(", "\n", "\"fm{}\"", ".", "format", "(", "mask_prob", ")", "if", "fixed_mask", "else", "(", "\"sk\"", "if", "with_skip", "else", "\"\"", ")", ",", "\n", "\"-of\"", "if", "only_first", "else", "\"\"", ",", "size_statement", ",", "nd_label", "\n", ")", "if", "self", ".", "layers", ">", "0", "else", "\"\"", "\n", "\n", "# set layers", "\n", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "# number of units of this layer's input and output", "\n", "            ", "in_size", "=", "size_per_layer", "[", "lay_id", "-", "1", "]", "\n", "out_size", "=", "size_per_layer", "[", "lay_id", "]", "\n", "\n", "# embedding of y", "\n", "if", "not", "fixed_mask", ":", "\n", "                ", "self", ".", "goal_ebm", "=", "nn", ".", "Embedding", "(", "self", ".", "num_classes", ",", "size_per_layer", "[", "1", "]", ")", "\n", "\n", "# define and set the fully connected layer", "\n", "", "if", "fixed_mask", "and", "(", "lay_id", "==", "1", "or", "not", "self", ".", "only_first", ")", ":", "\n", "                ", "layer", "=", "fc_layer_fixed_gates", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "drop", "=", "drop", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "\n", "nl", "=", "nn", ".", "Sigmoid", "(", ")", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "nl", ",", "\n", "gate_size", "=", "num_classes", ",", "gating_prop", "=", "mask_prob", ",", "\n", ")", "\n", "", "else", ":", "\n", "                ", "layer", "=", "fc_layer", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "drop", "=", "drop", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "\n", "nl", "=", "nn", ".", "Sigmoid", "(", ")", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "nl", ",", "\n", ")", "\n", "", "setattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ",", "layer", ")", "\n", "\n", "# if no layers, add \"identity\"-module to indicate in this module's representation nothing happens", "\n", "", "if", "self", ".", "layers", "<", "1", ":", "\n", "            ", "self", ".", "noLayers", "=", "utils", ".", "Identity", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.ebm_nets---.EBM_net.forward": [[113, 156], ["x[].expand", "range", "torch.zeros().to", "torch.zeros().to.scatter_", "ebm_nets---.EBM_net.goal_ebm", "torch.nn.functional.softmax", "torch.zeros", "next", "torch.nn.functional.softmax.view", "getattr", "getattr", "ebm_nets---.EBM_net.parameters", "torch.nn.functional.relu"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "y", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''Returns energies for each batch-sample in [x] according to each class in corresponding batch-entry of [y].\n\n        Args:\n            x (tensor: [batch]x[input_units])\n            y (tensor: [batch]x[classes_to_test])\n\n        Returns:\n            features_per_class (tensor: [batch]x[classes_to_test]x[output_units])\n        '''", "\n", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "# Reshape `x` to [batch]x[classes_to_test]x[input_units]", "\n", "#-> create multiple copies of [x], one for each class to compute energy for", "\n", "classes_to_test", "=", "y", ".", "shape", "[", "1", "]", "\n", "x", "=", "x", "[", ":", ",", "None", ",", ":", "]", ".", "expand", "(", "[", "batch_size", ",", "classes_to_test", ",", "x", ".", "shape", "[", "-", "1", "]", "]", ")", "\n", "\n", "# Deal with `y`", "\n", "if", "self", ".", "fixed_mask", ":", "\n", "# -reshape `y` to one-hot-tensor of shape [batch]x[classes_to_test]x[classes]", "\n", "            ", "y_one_hot", "=", "torch", ".", "zeros", "(", "batch_size", ",", "classes_to_test", ",", "self", ".", "num_classes", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "y_one_hot", ".", "scatter_", "(", "dim", "=", "2", ",", "index", "=", "y", ".", "view", "(", "batch_size", ",", "classes_to_test", ",", "1", ")", ",", "value", "=", "1.", ")", "\n", "", "else", ":", "\n", "# -embed `y` and put through softmax for the learnable gate", "\n", "            ", "y", "=", "self", ".", "goal_ebm", "(", "y", ")", "# -> shape: [batch]x[classes_to_test]x[units]", "\n", "y", "=", "F", ".", "softmax", "(", "y", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Sequentially pass [x] through all fc-layers", "\n", "", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "if", "self", ".", "fixed_mask", ":", "\n", "                ", "x", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ",", "gate_input", "=", "y_one_hot", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ")", "\n", "# -apply the learnable gate, if applicable", "\n", "if", "lay_id", "==", "1", "or", "(", "not", "self", ".", "only_first", ")", ":", "\n", "                    ", "if", "self", ".", "with_skip", ":", "\n", "                        ", "x", "=", "x", "*", "y", "*", "y", ".", "shape", "[", "-", "1", "]", "+", "x", "\n", "x", "=", "F", ".", "relu", "(", "x", ")", "\n", "", "else", ":", "\n", "                        ", "x", "=", "x", "*", "y", "*", "y", ".", "shape", "[", "-", "1", "]", "\n", "\n", "", "", "", "", "return", "x", "#-> shape: [batch]x[classes_to_test]x[output_units]", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.ebm_nets---.EBM_net.name": [[158, 161], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.ebm_nets---.EBM_net.list_init_layers": [[162, 168], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], ["", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "list", "+=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "layer_id", ")", ")", ".", "list_init_layers", "(", ")", "\n", "", "return", "list", "\n", "", "", ""]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.LinearExcitability.__init__": [[55, 74], ["torch.nn.Module.__init__", "torch.nn.parameter.Parameter", "excitability_modules.LinearExcitability.reset_parameters", "torch.Tensor", "torch.nn.parameter.Parameter", "excitability_modules.LinearExcitability.register_parameter", "torch.nn.parameter.Parameter", "excitability_modules.LinearExcitability.register_parameter", "torch.Tensor().uniform_", "excitability_modules.LinearExcitability.register_buffer", "excitability_modules.LinearExcitability.register_buffer", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.LinearExcitability.reset_parameters"], ["def", "__init__", "(", "self", ",", "in_features", ",", "out_features", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ")", ":", "\n", "        ", "super", "(", "LinearExcitability", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_features", "=", "in_features", "\n", "self", ".", "out_features", "=", "out_features", "\n", "self", ".", "weight", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ",", "in_features", ")", ")", "\n", "if", "excitability", ":", "\n", "            ", "self", ".", "excitability", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'excitability'", ",", "None", ")", "\n", "", "if", "bias", ":", "\n", "            ", "self", ".", "bias", "=", "Parameter", "(", "torch", ".", "Tensor", "(", "out_features", ")", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_parameter", "(", "'bias'", ",", "None", ")", "\n", "", "if", "excit_buffer", ":", "\n", "            ", "buffer", "=", "torch", ".", "Tensor", "(", "out_features", ")", ".", "uniform_", "(", "1", ",", "1", ")", "\n", "self", ".", "register_buffer", "(", "\"excit_buffer\"", ",", "buffer", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "register_buffer", "(", "\"excit_buffer\"", ",", "None", ")", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.LinearExcitability.reset_parameters": [[75, 83], ["excitability_modules.LinearExcitability.weight.data.uniform_", "math.sqrt", "excitability_modules.LinearExcitability.excitability.data.uniform_", "excitability_modules.LinearExcitability.bias.data.uniform_", "excitability_modules.LinearExcitability.weight.size"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "'''Modifies the parameters \"in-place\" to reset them at appropriate initialization values'''", "\n", "stdv", "=", "1.", "/", "math", ".", "sqrt", "(", "self", ".", "weight", ".", "size", "(", "1", ")", ")", "\n", "self", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "if", "self", ".", "excitability", "is", "not", "None", ":", "\n", "            ", "self", ".", "excitability", ".", "data", ".", "uniform_", "(", "1", ",", "1", ")", "\n", "", "if", "self", ".", "bias", "is", "not", "None", ":", "\n", "            ", "self", ".", "bias", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.LinearExcitability.forward": [[84, 95], ["excitability_modules.linearExcitability"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.linearExcitability"], ["", "", "def", "forward", "(", "self", ",", "input", ")", ":", "\n", "        ", "'''Running this model's forward step requires/returns:\n        INPUT: -[input]: [batch_size]x[...]x[in_features]\n        OUTPUT: -[output]: [batch_size]x[...]x[hidden_features]'''", "\n", "if", "self", ".", "excit_buffer", "is", "None", ":", "\n", "            ", "excitability", "=", "self", ".", "excitability", "\n", "", "elif", "self", ".", "excitability", "is", "None", ":", "\n", "            ", "excitability", "=", "self", ".", "excit_buffer", "\n", "", "else", ":", "\n", "            ", "excitability", "=", "self", ".", "excitability", "*", "self", ".", "excit_buffer", "\n", "", "return", "linearExcitability", "(", "input", ",", "self", ".", "weight", ",", "excitability", ",", "self", ".", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.LinearExcitability.__repr__": [[96, 100], ["str", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__class__", ".", "__name__", "+", "'('", "+", "'in_features='", "+", "str", "(", "self", ".", "in_features", ")", "+", "', out_features='", "+", "str", "(", "self", ".", "out_features", ")", "+", "')'", "", "", "", ""]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.fc.excitability_modules.linearExcitability": [[7, 26], ["input.matmul", "input.matmul", "weight.t", "weight.t"], "function", ["None"], ["def", "linearExcitability", "(", "input", ",", "weight", ",", "excitability", "=", "None", ",", "bias", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Applies a linear transformation to the incoming data: :math:`y = c(xA^T) + b`.\n\n    Shape:\n        - input:        :math:`(N, *, in\\_features)`\n        - weight:       :math:`(out\\_features, in\\_features)`\n        - excitability: :math:`(out\\_features)`\n        - bias:         :math:`(out\\_features)`\n        - output:       :math:`(N, *, out\\_features)`\n    (NOTE: `*` means any number of additional dimensions)\n    \"\"\"", "\n", "if", "excitability", "is", "not", "None", ":", "\n", "        ", "output", "=", "input", ".", "matmul", "(", "weight", ".", "t", "(", ")", ")", "*", "excitability", "\n", "", "else", ":", "\n", "        ", "output", "=", "input", ".", "matmul", "(", "weight", ".", "t", "(", ")", ")", "\n", "", "if", "bias", "is", "not", "None", ":", "\n", "        ", "output", "+=", "bias", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Identity.forward": [[13, 15], ["None"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Identity.__repr__": [[16, 19], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Shape.__init__": [[23, 27], ["torch.nn.Module.__init__", "len"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "shape", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "shape", "=", "shape", "\n", "self", ".", "dim", "=", "len", "(", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Shape.forward": [[28, 30], ["x.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "x", ".", "view", "(", "*", "self", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Shape.__repr__": [[31, 34], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "'(shape = {})'", ".", "format", "(", "self", ".", "shape", ")", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Reshape.__init__": [[38, 41], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "image_channels", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "image_channels", "=", "image_channels", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Reshape.forward": [[42, 51], ["type", "x[].size", "int", "x.size", "int", "x.view", "numpy.sqrt", "x_item.view", "numpy.sqrt", "x[].nelement", "x.nelement"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "if", "type", "(", "x", ")", "==", "tuple", ":", "\n", "            ", "batch_size", "=", "x", "[", "0", "]", ".", "size", "(", "0", ")", "# first dimenstion should be batch-dimension.", "\n", "image_size", "=", "int", "(", "np", ".", "sqrt", "(", "x", "[", "0", "]", ".", "nelement", "(", ")", "/", "(", "batch_size", "*", "self", ".", "image_channels", ")", ")", ")", "\n", "return", "(", "x_item", ".", "view", "(", "batch_size", ",", "self", ".", "image_channels", ",", "image_size", ",", "image_size", ")", "for", "x_item", "in", "x", ")", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "# first dimenstion should be batch-dimension.", "\n", "image_size", "=", "int", "(", "np", ".", "sqrt", "(", "x", ".", "nelement", "(", ")", "/", "(", "batch_size", "*", "self", ".", "image_channels", ")", ")", ")", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "self", ".", "image_channels", ",", "image_size", ",", "image_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Reshape.__repr__": [[52, 55], ["None"], "methods", ["None"], ["", "", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "'(channels = {})'", ".", "format", "(", "self", ".", "image_channels", ")", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Flatten.forward": [[59, 62], ["x.size", "x.view"], "methods", ["None"], ["def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "batch_size", "=", "x", ".", "size", "(", "0", ")", "# first dimenstion should be batch-dimension.", "\n", "return", "x", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.modules.Flatten.__repr__": [[63, 66], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "tmpstr", "=", "self", ".", "__class__", ".", "__name__", "+", "'()'", "\n", "return", "tmpstr", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.loss_fn_kd": [[12, 42], ["torch.nn.functional.log_softmax", "torch.nn.functional.softmax", "scores.size", "weighted_average.sum", "loss_functions.weighted_average", "target_scores.size", "scores.size", "torch.zeros", "zeros_to_add.to.to", "torch.cat", "target_scores.size"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.weighted_average"], ["def", "loss_fn_kd", "(", "scores", ",", "target_scores", ",", "T", "=", "2.", ",", "weights", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute knowledge-distillation (KD) loss given [scores] and [target_scores].\n\n    Both [scores] and [target_scores] should be <2D-tensors>, although [target_scores] should be repackaged.\n    'Hyperparameter': temperature\"\"\"", "\n", "\n", "device", "=", "scores", ".", "device", "\n", "\n", "log_scores_norm", "=", "F", ".", "log_softmax", "(", "scores", "/", "T", ",", "dim", "=", "1", ")", "\n", "targets_norm", "=", "F", ".", "softmax", "(", "target_scores", "/", "T", ",", "dim", "=", "1", ")", "\n", "\n", "# If [scores] and [target_scores] do not have equal size, append 0's to [targets_norm]", "\n", "n", "=", "scores", ".", "size", "(", "1", ")", "\n", "if", "n", ">", "target_scores", ".", "size", "(", "1", ")", ":", "\n", "        ", "n_batch", "=", "scores", ".", "size", "(", "0", ")", "\n", "zeros_to_add", "=", "torch", ".", "zeros", "(", "n_batch", ",", "n", "-", "target_scores", ".", "size", "(", "1", ")", ")", "\n", "zeros_to_add", "=", "zeros_to_add", ".", "to", "(", "device", ")", "\n", "targets_norm", "=", "torch", ".", "cat", "(", "[", "targets_norm", ",", "zeros_to_add", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Calculate distillation loss (see e.g., Li and Hoiem, 2017)", "\n", "", "KD_loss_unnorm", "=", "-", "targets_norm", "*", "log_scores_norm", "\n", "\n", "# Sum over the prob-scores of all classes (1) and then average over all elements in the batch (2)", "\n", "KD_loss_unnorm", "=", "KD_loss_unnorm", ".", "sum", "(", "dim", "=", "1", ")", "#-> sum over classes", "\n", "KD_loss_unnorm", "=", "weighted_average", "(", "KD_loss_unnorm", ",", "weights", "=", "weights", ",", "dim", "=", "0", ")", "#-> average over batch", "\n", "\n", "# Normalize", "\n", "KD_loss", "=", "KD_loss_unnorm", "*", "T", "**", "2", "\n", "\n", "return", "KD_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.loss_fn_kd_binary": [[45, 75], ["torch.sigmoid", "torch.sigmoid", "scores.size", "weighted_average.sum", "loss_functions.weighted_average", "target_scores.size", "scores.size", "torch.zeros", "zeros_to_add.to.to", "torch.cat", "target_scores.size", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.weighted_average"], ["", "def", "loss_fn_kd_binary", "(", "scores", ",", "target_scores", ",", "T", "=", "2.", ",", "weights", "=", "None", ")", ":", "\n", "    ", "\"\"\"Compute binary knowledge-distillation (KD) loss given [scores] and [target_scores].\n\n    Both [scores] and [target_scores] should be tensors, although [target_scores] should be repackaged.\n    'Hyperparameter': temperature\"\"\"", "\n", "\n", "device", "=", "scores", ".", "device", "\n", "\n", "scores_norm", "=", "torch", ".", "sigmoid", "(", "scores", "/", "T", ")", "\n", "targets_norm", "=", "torch", ".", "sigmoid", "(", "target_scores", "/", "T", ")", "\n", "\n", "# If [scores] and [target_scores] do not have equal size, append 0's to [targets_norm]", "\n", "n", "=", "scores", ".", "size", "(", "1", ")", "\n", "if", "n", ">", "target_scores", ".", "size", "(", "1", ")", ":", "\n", "        ", "n_batch", "=", "scores", ".", "size", "(", "0", ")", "\n", "zeros_to_add", "=", "torch", ".", "zeros", "(", "n_batch", ",", "n", "-", "target_scores", ".", "size", "(", "1", ")", ")", "\n", "zeros_to_add", "=", "zeros_to_add", ".", "to", "(", "device", ")", "\n", "targets_norm", "=", "torch", ".", "cat", "(", "[", "targets_norm", ",", "zeros_to_add", "]", ",", "dim", "=", "1", ")", "\n", "\n", "# Calculate distillation loss (see e.g., Li and Hoiem, 2017)", "\n", "", "KD_loss_unnorm", "=", "-", "(", "targets_norm", "*", "torch", ".", "log", "(", "scores_norm", ")", "+", "(", "1", "-", "targets_norm", ")", "*", "torch", ".", "log", "(", "1", "-", "scores_norm", ")", ")", "\n", "\n", "# Sum over the prob-scores of all classes (1) and then average over all elements in the batch (2)", "\n", "KD_loss_unnorm", "=", "KD_loss_unnorm", ".", "sum", "(", "dim", "=", "1", ")", "#-> sum over classes", "\n", "KD_loss_unnorm", "=", "weighted_average", "(", "KD_loss_unnorm", ",", "weights", "=", "weights", ",", "dim", "=", "0", ")", "#-> average over batch", "\n", "\n", "# Normalize", "\n", "KD_loss", "=", "KD_loss_unnorm", "*", "T", "**", "2", "\n", "\n", "return", "KD_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.weighted_average": [[83, 95], ["torch.mean", "torch.tensor().to", "torch.mean", "tensor.size", "len", "len", "torch.tensor", "tensor.size"], "function", ["None"], ["", "def", "weighted_average", "(", "tensor", ",", "weights", "=", "None", ",", "dim", "=", "0", ")", ":", "\n", "    ", "'''Computes weighted average of [tensor] over dimension [dim].'''", "\n", "if", "weights", "is", "None", ":", "\n", "        ", "mean", "=", "torch", ".", "mean", "(", "tensor", ",", "dim", "=", "dim", ")", "\n", "", "else", ":", "\n", "        ", "batch_size", "=", "tensor", ".", "size", "(", "dim", ")", "if", "len", "(", "tensor", ".", "size", "(", ")", ")", ">", "0", "else", "1", "\n", "assert", "len", "(", "weights", ")", "==", "batch_size", "\n", "#sum_weights = sum(weights)", "\n", "#norm_weights = torch.Tensor([weight/sum_weights for weight in weights]).to(tensor.device)", "\n", "norm_weights", "=", "torch", ".", "tensor", "(", "[", "weight", "for", "weight", "in", "weights", "]", ")", ".", "to", "(", "tensor", ".", "device", ")", "\n", "mean", "=", "torch", ".", "mean", "(", "norm_weights", "*", "tensor", ",", "dim", "=", "dim", ")", "\n", "", "return", "mean", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.to_one_hot": [[96, 105], ["numpy.zeros", "torch.from_numpy", "type", "y.cpu.cpu", "torch.from_numpy.to", "len", "range", "len"], "function", ["None"], ["", "def", "to_one_hot", "(", "y", ",", "classes", ",", "device", "=", "None", ")", ":", "\n", "    ", "'''Convert <nd-array> or <tensor> with integers [y] to a 2D \"one-hot\" <tensor>.'''", "\n", "if", "type", "(", "y", ")", "==", "torch", ".", "Tensor", ":", "\n", "        ", "device", "=", "y", ".", "device", "\n", "y", "=", "y", ".", "cpu", "(", ")", "\n", "", "c", "=", "np", ".", "zeros", "(", "shape", "=", "[", "len", "(", "y", ")", ",", "classes", "]", ",", "dtype", "=", "'float32'", ")", "\n", "c", "[", "range", "(", "len", "(", "y", ")", ")", ",", "y", "]", "=", "1.", "\n", "c", "=", "torch", ".", "from_numpy", "(", "c", ")", "\n", "return", "c", "if", "device", "is", "None", "else", "c", ".", "to", "(", "device", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.log_Normal_standard": [[113, 125], ["torch.pow", "log_normal.view.view", "log_normal.view.size", "torch.mean", "torch.mean", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "log_Normal_standard", "(", "x", ",", "mean", "=", "0", ",", "average", "=", "False", ",", "dim", "=", "None", ")", ":", "\n", "    ", "'''Calculate log-likelihood of sample [x] under Gaussian distribution(s) with mu=[mean], diag_var=I.\n    NOTES: [dim]=-1    summing / averaging over all but the first dimension\n           [dim]=None  summing / averaging is done over all dimensions'''", "\n", "log_normal", "=", "-", "0.5", "*", "torch", ".", "pow", "(", "x", "-", "mean", ",", "2", ")", "\n", "if", "dim", "is", "not", "None", "and", "dim", "==", "-", "1", ":", "\n", "        ", "log_normal", "=", "log_normal", ".", "view", "(", "log_normal", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "dim", "=", "1", "\n", "", "if", "average", ":", "\n", "        ", "return", "torch", ".", "mean", "(", "log_normal", ",", "dim", ")", "if", "dim", "is", "not", "None", "else", "torch", ".", "mean", "(", "log_normal", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "sum", "(", "log_normal", ",", "dim", ")", "if", "dim", "is", "not", "None", "else", "torch", ".", "sum", "(", "log_normal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.log_Normal_diag": [[126, 138], ["log_normal.view.view", "log_normal.view.size", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.pow", "torch.exp"], "function", ["None"], ["", "", "def", "log_Normal_diag", "(", "x", ",", "mean", ",", "log_var", ",", "average", "=", "False", ",", "dim", "=", "None", ")", ":", "\n", "    ", "'''Calculate log-likelihood of sample [x] under Gaussian distribution(s) with mu=[mean], diag_var=exp[log_var].\n    NOTES: [dim]=-1    summing / averaging over all but the first dimension\n           [dim]=None  summing / averaging is done over all dimensions'''", "\n", "log_normal", "=", "-", "0.5", "*", "(", "log_var", "+", "torch", ".", "pow", "(", "x", "-", "mean", ",", "2", ")", "/", "torch", ".", "exp", "(", "log_var", ")", ")", "\n", "if", "dim", "is", "not", "None", "and", "dim", "==", "-", "1", ":", "\n", "        ", "log_normal", "=", "log_normal", ".", "view", "(", "log_normal", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "dim", "=", "1", "\n", "", "if", "average", ":", "\n", "        ", "return", "torch", ".", "mean", "(", "log_normal", ",", "dim", ")", "if", "dim", "is", "not", "None", "else", "torch", ".", "mean", "(", "log_normal", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "sum", "(", "log_normal", ",", "dim", ")", "if", "dim", "is", "not", "None", "else", "torch", ".", "sum", "(", "log_normal", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.utils.loss_functions.log_Bernoulli": [[139, 152], ["torch.clamp", "log_bernoulli.view.view", "torch.log", "torch.log", "log_bernoulli.view.size", "torch.mean", "torch.mean", "torch.sum", "torch.sum"], "function", ["None"], ["", "", "def", "log_Bernoulli", "(", "x", ",", "mean", ",", "average", "=", "False", ",", "dim", "=", "None", ")", ":", "\n", "    ", "'''Calculate log-likelihood of sample [x] under Bernoulli distribution(s) with mu=[mean].\n    NOTES: [dim]=-1    summing / averaging over all but the first dimension\n           [dim]=None  summing / averaging is done over all dimensions'''", "\n", "probs", "=", "torch", ".", "clamp", "(", "mean", ",", "min", "=", "1e-5", ",", "max", "=", "1.", "-", "1e-5", ")", "\n", "log_bernoulli", "=", "x", "*", "torch", ".", "log", "(", "probs", ")", "+", "(", "1.", "-", "x", ")", "*", "torch", ".", "log", "(", "1.", "-", "probs", ")", "\n", "if", "dim", "is", "not", "None", "and", "dim", "==", "-", "1", ":", "\n", "        ", "log_bernoulli", "=", "log_bernoulli", ".", "view", "(", "log_bernoulli", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "dim", "=", "1", "\n", "", "if", "average", ":", "\n", "        ", "return", "torch", ".", "mean", "(", "log_bernoulli", ",", "dim", ")", "if", "dim", "is", "not", "None", "else", "torch", ".", "mean", "(", "log_bernoulli", ")", "\n", "", "else", ":", "\n", "        ", "return", "torch", ".", "sum", "(", "log_bernoulli", ",", "dim", ")", "if", "dim", "is", "not", "None", "else", "torch", ".", "sum", "(", "log_bernoulli", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.__init__": [[16, 88], ["torch.nn.Module.__init__", "range", "setattr", "torch.nn.AdaptiveAvgPool2d", "models.utils.modules.Identity", "len", "models.conv_layer", "models.res_layer", "type"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["output", "=", "'normal'", ")", ":", "\n", "        ", "'''sizes: 0th=[input], 1st=[hid_size], ..., 1st-to-last=[hid_smooth], last=[output].\n        [input_size]       # of inputs\n        [output_size]      # of units in final layer\n        [layers]           # of layers\n        [hid_size]         # of units in each hidden layer\n        [hid_smooth]       if None, all hidden layers have [hid_size] units, else # of units linearly in-/decreases s.t.\n                             final hidden layer has [hid_smooth] units (if only 1 hidden layer, it has [hid_size] units)\n        [size_per_layer]   None or <list> with for each layer number of units (1st element = number of inputs)\n                                --> overwrites [input_size], [output_size], [layers], [hid_size] and [hid_smooth]\n        [drop]             % of each layer's inputs that is randomly set to zero during training\n        [batch_norm]       <bool>; if True, batch-normalization is applied to each layer\n        [nl]               <str>; type of non-linearity to be used (options: \"relu\", \"leakyrelu\", \"none\")\n        [gated]            <bool>; if True, each linear layer has an additional learnable gate\n                                    (whereby the gate is controlled by the same input as that goes through the gate)\n        [output]           <str>; if - \"normal\", final layer is same as all others\n                                     - \"none\", final layer has no non-linearity\n                                     - \"sigmoid\", final layer has sigmoid non-linearity'''", "\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output", "=", "output", "\n", "\n", "# get sizes of all layers", "\n", "if", "size_per_layer", "is", "None", ":", "\n", "            ", "hidden_sizes", "=", "[", "]", "\n", "if", "layers", ">", "1", ":", "\n", "                ", "if", "(", "hid_smooth", "is", "not", "None", ")", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "linspace", "(", "hid_size", ",", "hid_smooth", ",", "num", "=", "layers", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                    ", "hidden_sizes", "=", "[", "int", "(", "x", ")", "for", "x", "in", "np", ".", "repeat", "(", "hid_size", ",", "layers", "-", "1", ")", "]", "\n", "", "", "size_per_layer", "=", "[", "input_size", "]", "+", "hidden_sizes", "+", "[", "output_size", "]", "if", "layers", ">", "0", "else", "[", "input_size", "]", "\n", "", "self", ".", "layers", "=", "len", "(", "size_per_layer", ")", "-", "1", "\n", "\n", "# set label for this module", "\n", "# -determine \"non-default options\"-label", "\n", "nd_label", "=", "\"{drop}{bias}{exc}{bn}{nl}{gate}\"", ".", "format", "(", "\n", "drop", "=", "\"\"", "if", "drop", "==", "0", "else", "\"d{}\"", ".", "format", "(", "drop", ")", ",", "\n", "bias", "=", "\"\"", "if", "bias", "else", "\"n\"", ",", "exc", "=", "\"e\"", "if", "excitability", "else", "\"\"", ",", "bn", "=", "\"b\"", "if", "batch_norm", "else", "\"\"", ",", "\n", "nl", "=", "\"l\"", "if", "nl", "==", "\"leakyrelu\"", "else", "\"\"", ",", "gate", "=", "\"g\"", "if", "gated", "else", "\"\"", ",", "\n", ")", "\n", "nd_label", "=", "\"{}{}\"", ".", "format", "(", "\"\"", "if", "nd_label", "==", "\"\"", "else", "\"-{}\"", ".", "format", "(", "nd_label", ")", ",", "\n", "\"\"", "if", "output", "==", "\"normal\"", "else", "\"-{}\"", ".", "format", "(", "output", ")", ")", "\n", "# -set label", "\n", "size_statement", "=", "\"\"", "\n", "for", "i", "in", "size_per_layer", ":", "\n", "            ", "size_statement", "+=", "\"{}{}\"", ".", "format", "(", "\"-\"", "if", "size_statement", "==", "\"\"", "else", "\"x\"", ",", "i", ")", "\n", "", "self", ".", "label", "=", "\"F{}{}\"", ".", "format", "(", "size_statement", ",", "nd_label", ")", "if", "self", ".", "layers", ">", "0", "else", "\"\"", "\n", "\n", "# set layers", "\n", "for", "lay_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "# number of units of this layer's input and output", "\n", "            ", "in_size", "=", "size_per_layer", "[", "lay_id", "-", "1", "]", "\n", "out_size", "=", "size_per_layer", "[", "lay_id", "]", "\n", "# define and set the fully connected layer", "\n", "layer", "=", "fc_layer", "(", "\n", "in_size", ",", "out_size", ",", "bias", "=", "bias", ",", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ",", "\n", "batch_norm", "=", "False", "if", "(", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", ")", "else", "batch_norm", ",", "gated", "=", "gated", ",", "\n", "nl", "=", "(", "\"none\"", "if", "output", "==", "\"none\"", "else", "nn", ".", "Sigmoid", "(", ")", ")", "if", "(", "\n", "lay_id", "==", "self", ".", "layers", "and", "not", "output", "==", "\"normal\"", "\n", ")", "else", "nl", ",", "drop", "=", "drop", "if", "lay_id", ">", "1", "else", "0.", ",", "\n", ")", "\n", "setattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ",", "layer", ")", "\n", "\n", "# if no layers, add \"identity\"-module to indicate in this module's representation nothing happens", "\n", "", "if", "self", ".", "layers", "<", "1", ":", "\n", "            ", "self", ".", "noLayers", "=", "modules", ".", "Identity", "(", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ",", "skip_first", "=", "0", ",", "skip_last", "=", "0", ",", "return_lists", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "# Initiate <list> for keeping track of intermediate hidden-(pre)activations", "\n", "        ", "if", "return_lists", ":", "\n", "            ", "hidden_act_list", "=", "[", "]", "\n", "pre_act_list", "=", "[", "]", "\n", "# Sequentially pass [x] through all fc-layers", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.forward": [[89, 105], ["range", "nets.ConvLayers.pooling", "getattr", "pre_act_list.append", "hidden_act_list.append"], "methods", ["None"], ["", "for", "lay_id", "in", "range", "(", "skip_first", "+", "1", ",", "self", ".", "layers", "+", "1", "-", "skip_last", ")", ":", "\n", "            ", "(", "x", ",", "pre_act", ")", "=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "lay_id", ")", ")", "(", "x", ",", "return_pa", "=", "True", ")", "\n", "if", "return_lists", ":", "\n", "                ", "pre_act_list", ".", "append", "(", "pre_act", ")", "#-> for each layer, store pre-activations", "\n", "if", "lay_id", "<", "(", "self", ".", "layers", "-", "skip_last", ")", ":", "\n", "                    ", "hidden_act_list", ".", "append", "(", "x", ")", "#-> for all but last layer, store hidden activations", "\n", "# Return final [x], if requested along with [hidden_act_list] and [pre_act_list]", "\n", "", "", "", "return", "(", "x", ",", "hidden_act_list", ",", "pre_act_list", ")", "if", "return_lists", "else", "x", "\n", "\n", "\n", "", "@", "property", "\n", "def", "name", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "label", "\n", "\n", "", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_size": [[106, 110], ["int", "numpy.ceil"], "methods", ["None"], ["for", "layer_id", "in", "range", "(", "1", ",", "self", ".", "layers", "+", "1", ")", ":", "\n", "            ", "list", "+=", "getattr", "(", "self", ",", "'fcLayer{}'", ".", "format", "(", "layer_id", ")", ")", ".", "list_init_layers", "(", ")", "\n", "", "return", "list", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_units": [[111, 114], ["nets.ConvLayers.out_size"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.out_size"], ["\n", "\n", "\n", "", "", "class", "MLP_gates", "(", "nn", ".", "Module", ")", ":", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.layer_info": [[115, 133], ["range", "layer_list.append", "int", "int", "numpy.ceil", "numpy.ceil"], "methods", ["None"], ["    ", "'''Module for a multi-layer perceptron (MLP). Possible to return (pre)activations of each layer.\n    Also possible to supply a [skip_first]- or [skip_last]-argument to the forward-function to only pass certain layers.\n    With gates controlled by [gate_input] (of size [gate_size]) with a randomly selected masked (prop=[gating_prop]).\n\n    Input:  [batch_size] x ... x [size_per_layer[0]] tensor         &        [batch_size] x [gate_size]\n    Output: (tuple of) [batch_size] x ... x [size_per_layer[-1]] tensor'''", "\n", "\n", "def", "__init__", "(", "self", ",", "input_size", "=", "1000", ",", "output_size", "=", "10", ",", "layers", "=", "2", ",", "hid_size", "=", "1000", ",", "hid_smooth", "=", "None", ",", "size_per_layer", "=", "None", ",", "\n", "drop", "=", "0", ",", "batch_norm", "=", "True", ",", "nl", "=", "\"relu\"", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "gate_size", "=", "0", ",", "\n", "gating_prop", "=", "0.", ",", "final_gate", "=", "False", ",", "output", "=", "'normal'", ",", "device", "=", "'cuda'", ")", ":", "\n", "        "]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.list_init_layers": [[134, 140], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], []], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.nets.ConvLayers.name": [[141, 144], ["None"], "methods", ["None"], ["\n", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.BasicBlock.__init__": [[15, 41], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "network.utils.modules.Identity", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "network.utils.modules.Identity", "torch.BatchNorm2d", "network.utils.modules.Identity", "torch.ReLU", "torch.LeakyReLU", "torch.BatchNorm2d", "network.utils.modules.Identity", "torch.Conv2d", "torch.ReLU", "torch.LeakyReLU", "torch.BatchNorm2d", "network.utils.modules.Identity"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["drop", "=", "0.", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "batch_norm", "=", "False", ",", "gated", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "drop", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "", "self", ".", "linear", "=", "em", ".", "LinearExcitability", "(", "in_size", ",", "out_size", ",", "bias", "=", "False", "if", "batch_norm", "else", "bias", ",", "\n", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "out_size", ")", "\n", "", "if", "gated", ":", "\n", "            ", "self", ".", "gate", "=", "nn", ".", "Linear", "(", "in_size", ",", "out_size", ")", "\n", "self", ".", "sigmoid", "=", "nn", ".", "Sigmoid", "(", ")", "\n", "", "if", "isinstance", "(", "nl", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "self", ".", "nl", "=", "nl", "\n", "", "elif", "not", "nl", "==", "\"none\"", ":", "\n", "            ", "self", ".", "nl", "=", "nn", ".", "ReLU", "(", ")", "if", "nl", "==", "\"relu\"", "else", "(", "nn", ".", "LeakyReLU", "(", ")", "if", "nl", "==", "\"leakyrelu\"", "else", "modules", ".", "Identity", "(", ")", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ",", "return_pa", "=", "False", ",", "**", "kwargs", ")", ":", "\n", "        ", "input", "=", "self", ".", "dropout", "(", "x", ")", "if", "hasattr", "(", "self", ",", "'dropout'", ")", "else", "x", "\n", "pre_activ", "=", "self", ".", "bn", "(", "self", ".", "linear", "(", "input", ")", ")", "if", "hasattr", "(", "self", ",", "'bn'", ")", "else", "self", ".", "linear", "(", "input", ")", "\n", "gate", "=", "self", ".", "sigmoid", "(", "self", ".", "gate", "(", "x", ")", ")", "if", "hasattr", "(", "self", ",", "'gate'", ")", "else", "None", "\n", "gated_pre_activ", "=", "gate", "*", "pre_activ", "if", "hasattr", "(", "self", ",", "'gate'", ")", "else", "pre_activ", "\n", "output", "=", "self", ".", "nl", "(", "gated_pre_activ", ")", "if", "hasattr", "(", "self", ",", "'nl'", ")", "else", "gated_pre_activ", "\n", "return", "(", "output", ",", "gated_pre_activ", ")", "if", "return_pa", "else", "output", "\n", "\n", "", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "return", "[", "self", ".", "linear", ",", "self", ".", "gate", "]", "if", "hasattr", "(", "self", ",", "'gate'", ")", "else", "[", "self", ".", "linear", "]", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.BasicBlock.forward": [[42, 46], ["layers.BasicBlock.block_layer2", "layers.BasicBlock.shortcut", "layers.BasicBlock.nl", "layers.BasicBlock.block_layer1"], "methods", ["None"], ["\n", "\n", "\n", "", "", "class", "fc_layer_split", "(", "nn", ".", "Module", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.BasicBlock.list_init_layers": [[47, 53], ["list.append", "type"], "methods", ["None"], ["\n", "\n", "def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "nl_mean", "=", "nn", ".", "Sigmoid", "(", ")", ",", "nl_logvar", "=", "nn", ".", "Hardtanh", "(", "min_val", "=", "-", "4.5", ",", "max_val", "=", "0.", ")", ",", "\n", "drop", "=", "0.", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "batch_norm", "=", "False", ",", "gated", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.Bottleneck.__init__": [[59, 89], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "network.utils.modules.Identity", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sequential", "network.utils.modules.Identity", "torch.BatchNorm2d", "network.utils.modules.Identity", "torch.ReLU", "torch.LeakyReLU", "torch.BatchNorm2d", "network.utils.modules.Identity", "torch.ReLU", "torch.LeakyReLU", "torch.BatchNorm2d", "network.utils.modules.Identity", "torch.Conv2d", "torch.ReLU", "torch.LeakyReLU", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["\n", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "(", "self", ".", "mean", "(", "x", ")", ",", "self", ".", "logvar", "(", "x", ")", ")", "\n", "\n", "", "def", "list_init_layers", "(", "self", ")", ":", "\n", "        ", "'''Return list of modules whose parameters could be initialized differently (i.e., conv- or fc-layers).'''", "\n", "list", "=", "[", "]", "\n", "list", "+=", "self", ".", "mean", ".", "list_init_layers", "(", ")", "\n", "list", "+=", "self", ".", "logvar", ".", "list_init_layers", "(", ")", "\n", "return", "list", "\n", "\n", "\n", "\n", "", "", "class", "fc_layer_fixed_gates", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "'''Fully connected layer, with possibility of returning \"pre-activations\". Has fixed gates (of specified dimension).\n\n    Input:  [batch_size] x ... x [in_size] tensor         &        [batch_size] x ... x [gate_size] tensor\n    Output: [batch_size] x ... x [out_size] tensor'''", "\n", "\n", "def", "__init__", "(", "self", ",", "in_size", ",", "out_size", ",", "nl", "=", "nn", ".", "ReLU", "(", ")", ",", "\n", "drop", "=", "0.", ",", "bias", "=", "True", ",", "excitability", "=", "False", ",", "excit_buffer", "=", "False", ",", "batch_norm", "=", "False", ",", "\n", "gate_size", "=", "0", ",", "gating_prop", "=", "0.8", ",", "device", "=", "'cuda'", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "drop", ">", "0", ":", "\n", "            ", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "drop", ")", "\n", "", "self", ".", "linear", "=", "em", ".", "LinearExcitability", "(", "in_size", ",", "out_size", ",", "bias", "=", "False", "if", "batch_norm", "else", "bias", ",", "\n", "excitability", "=", "excitability", ",", "excit_buffer", "=", "excit_buffer", ")", "\n", "if", "batch_norm", ":", "\n", "            ", "self", ".", "bn", "=", "nn", ".", "BatchNorm1d", "(", "out_size", ")", "\n", "", "if", "gate_size", ">", "0", ":", "\n", "            ", "self", ".", "gate_mask", "=", "torch", ".", "tensor", "(", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.Bottleneck.forward": [[90, 94], ["layers.Bottleneck.block_layer3", "layers.Bottleneck.shortcut", "layers.Bottleneck.nl", "layers.Bottleneck.block_layer2", "layers.Bottleneck.block_layer1"], "methods", ["None"], ["np", ".", "random", ".", "choice", "(", "[", "0.", ",", "1.", "]", ",", "size", "=", "(", "gate_size", ",", "out_size", ")", ",", "p", "=", "[", "gating_prop", ",", "1.", "-", "gating_prop", "]", ")", ",", "\n", "dtype", "=", "torch", ".", "float", ",", "device", "=", "device", "\n", ")", "\n", "", "if", "isinstance", "(", "nl", ",", "nn", ".", "Module", ")", ":", "\n", "            ", "self", ".", "nl", "=", "nl", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.Bottleneck.list_init_layers": [[95, 101], ["list.append", "type"], "methods", ["None"], ["", "elif", "not", "nl", "==", "\"none\"", ":", "\n", "            ", "self", ".", "nl", "=", "nn", ".", "ReLU", "(", ")", "if", "nl", "==", "\"relu\"", "else", "(", "nn", ".", "LeakyReLU", "(", ")", "if", "nl", "==", "\"leakyrelu\"", "else", "modules", ".", "Identity", "(", ")", ")", "\n", "\n", "", "", "def", "forward", "(", "self", ",", "x", ",", "gate_input", "=", "None", ",", "return_pa", "=", "False", ")", ":", "\n", "        ", "input", "=", "self", ".", "dropout", "(", "x", ")", "if", "hasattr", "(", "self", ",", "'dropout'", ")", "else", "x", "\n", "pre_activ", "=", "self", ".", "bn", "(", "self", ".", "linear", "(", "input", ")", ")", "if", "hasattr", "(", "self", ",", "'bn'", ")", "else", "self", ".", "linear", "(", "input", ")", "\n", "gate", "=", "torch", ".", "matmul", "(", "gate_input", ",", "self", ".", "gate_mask", ")", "if", "hasattr", "(", "self", ",", "'gate_mask'", ")", "else", "None", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.conv_layer.__init__": [[112, 128], ["torch.ReLU", "torch.Module.__init__", "torch.Conv2d", "isinstance", "torch.Dropout2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Sigmoid", "torch.ReLU", "torch.LeakyReLU", "network.utils.modules.Identity"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], []], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.conv_layer.forward": [[129, 136], ["hasattr", "layers.conv_layer.dropout", "hasattr", "layers.conv_layer.bn", "layers.conv_layer.conv", "hasattr", "layers.conv_layer.sigmoid", "hasattr", "hasattr", "layers.conv_layer.nl", "layers.conv_layer.conv", "layers.conv_layer.gate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.conv_layer.list_init_layers": [[137, 140], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.__init__": [[145, 166], ["torch.Module.__init__", "torch.Dropout2d", "range", "block", "setattr", "network.utils.modules.Identity", "torch.ReLU", "torch.LeakyReLU"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], []], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.forward": [[167, 173], ["layers.res_layer.dropout", "range", "layers.res_layer.nl", "getattr"], "methods", ["None"], []], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers": [[174, 180], ["range", "getattr().list_init_layers", "getattr"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.conv.layers.res_layer.list_init_layers"], []], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.SubDataset.__init__": [[30, 59], ["torch.utils.data.Dataset.__init__", "range", "len", "hasattr", "enumerate", "hasattr", "data_utils.SubDataset.sub_indeces.append", "data_utils.SubDataset.dataset.target_transform", "data_utils.SubDataset.dataset.target_transform"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__"], ["def", "__init__", "(", "self", ",", "args", ",", "original_dataset", ",", "sub_labels", ",", "class_per_task", "=", "None", ",", "task_id", "=", "None", ",", "target_transform", "=", "None", ",", "all_labels", "=", "None", ",", "cifar", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dataset", "=", "original_dataset", "\n", "self", ".", "sub_indeces", "=", "[", "]", "\n", "self", ".", "args", "=", "args", "\n", "self", ".", "task_id", "=", "task_id", "\n", "self", ".", "class_per_task", "=", "class_per_task", "\n", "\n", "if", "cifar", ":", "\n", "## load data faster", "\n", "            ", "self", ".", "sub_indeces", "=", "[", "index", "for", "index", ",", "label", "in", "enumerate", "(", "all_labels", ")", "if", "label", "in", "sub_labels", "]", "\n", "", "else", ":", "\n", "            ", "for", "index", "in", "range", "(", "len", "(", "self", ".", "dataset", ")", ")", ":", "\n", "                ", "if", "hasattr", "(", "original_dataset", ",", "\"train_labels\"", ")", ":", "\n", "                    ", "if", "self", ".", "dataset", ".", "target_transform", "is", "None", ":", "\n", "                        ", "label", "=", "self", ".", "dataset", ".", "train_labels", "[", "index", "]", "\n", "", "else", ":", "\n", "                        ", "label", "=", "self", ".", "dataset", ".", "target_transform", "(", "self", ".", "dataset", ".", "train_labels", "[", "index", "]", ")", "\n", "", "", "elif", "hasattr", "(", "self", ".", "dataset", ",", "\"test_labels\"", ")", ":", "\n", "                    ", "if", "self", ".", "dataset", ".", "target_transform", "is", "None", ":", "\n", "                        ", "label", "=", "self", ".", "dataset", ".", "test_labels", "[", "index", "]", "\n", "", "else", ":", "\n", "                        ", "label", "=", "self", ".", "dataset", ".", "target_transform", "(", "self", ".", "dataset", ".", "test_labels", "[", "index", "]", ")", "\n", "", "", "else", ":", "\n", "                    ", "label", "=", "self", ".", "dataset", "[", "index", "]", "[", "1", "]", "\n", "", "if", "label", "in", "sub_labels", ":", "\n", "                    ", "self", ".", "sub_indeces", ".", "append", "(", "index", ")", "\n", "\n", "", "", "", "self", ".", "target_transform", "=", "target_transform", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.SubDataset.__len__": [[63, 65], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sub_indeces", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.SubDataset.__getitem__": [[66, 77], ["data_utils.SubDataset.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "sample", "=", "self", ".", "dataset", "[", "self", ".", "sub_indeces", "[", "index", "]", "]", "\n", "if", "self", ".", "target_transform", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "sample", "[", "1", "]", ")", "\n", "sample", "=", "(", "sample", "[", "0", "]", ",", "target", ")", "\n", "\n", "", "if", "self", ".", "args", ".", "random_task_order", ":", "\n", "            ", "new_label", "=", "(", "sample", "[", "1", "]", "%", "self", ".", "class_per_task", ")", "+", "self", ".", "task_id", "*", "self", ".", "class_per_task", "\n", "return", "(", "sample", "[", "0", "]", ",", "new_label", ")", "\n", "", "else", ":", "\n", "            ", "return", "sample", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.Sampler.__init__": [[112, 119], ["pdb.set_trace"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_source", ",", "tasks_samples_indices", ",", "tasks_probs_over_iterations", ",", "samples_in_batch", ")", ":", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "self", ".", "tasks_samples_indices", "=", "tasks_samples_indices", "\n", "self", ".", "tasks_probs_over_iterations", "=", "tasks_probs_over_iterations", "\n", "self", ".", "samples_in_batch", "=", "samples_in_batch", "\n", "self", ".", "iter_num", "=", "0", "\n", "pdb", ".", "set_trace", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.Sampler.__iter__": [[120, 126], ["torch.distributions.categorical.Categorical().sample", "data_utils.Sampler.generate_iters_indices", "iter", "torch.Size", "torch.distributions.categorical.Categorical"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.generate_iters_indices"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "tsks", "=", "Categorical", "(", "probs", "=", "self", ".", "tasks_probs_over_iterations", "[", "self", ".", "iter_num", "]", ")", ".", "sample", "(", "torch", ".", "Size", "(", "[", "self", ".", "samples_in_batch", "]", ")", ")", "\n", "\n", "self", ".", "generate_iters_indices", "(", "self", ".", "num_of_batches", ")", "\n", "self", ".", "current_iteration", "+=", "self", ".", "num_of_batches", "\n", "return", "iter", "(", "[", "item", "for", "sublist", "in", "self", ".", "iter_indices_per_iteration", "[", "self", ".", "current_iteration", "-", "self", ".", "num_of_batches", ":", "self", ".", "current_iteration", "]", "for", "item", "in", "sublist", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.Sampler.__len__": [[127, 129], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples_in_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__init__": [[143, 173], ["len", "all", "str", "ValueError", "len", "range", "isinstance", "isinstance", "str", "len", "type", "str"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "data_source", ",", "samples_in_batch", "=", "128", ",", "num_of_batches", "=", "69", ",", "tasks_samples_indices", "=", "None", ",", "\n", "tasks_probs_over_iterations", "=", "None", ")", ":", "\n", "\n", "\n", "        ", "self", ".", "data_source", "=", "data_source", "\n", "assert", "tasks_samples_indices", "is", "not", "None", ",", "\"Must provide tasks_samples_indices - a list of tensors,\"", "\"each item in the list corrosponds to a task, each item of the \"", "\"tensor corrosponds to index of sample of this task\"", "\n", "self", ".", "tasks_samples_indices", "=", "tasks_samples_indices", "\n", "self", ".", "num_of_tasks", "=", "len", "(", "self", ".", "tasks_samples_indices", ")", "\n", "assert", "tasks_probs_over_iterations", "is", "not", "None", ",", "\"Must provide tasks_probs_over_iterations - a list of \"", "\"probs per iteration\"", "\n", "assert", "all", "(", "[", "isinstance", "(", "probs", ",", "torch", ".", "Tensor", ")", "and", "len", "(", "probs", ")", "==", "self", ".", "num_of_tasks", "for", "\n", "probs", "in", "tasks_probs_over_iterations", "]", ")", ",", "\"All probs must be tensors of len\"", "+", "str", "(", "self", ".", "num_of_tasks", ")", "+", "\", first tensor type is \"", "+", "str", "(", "type", "(", "tasks_probs_over_iterations", "[", "0", "]", ")", ")", "+", "\", and \"", "\" len is \"", "+", "str", "(", "len", "(", "tasks_probs_over_iterations", "[", "0", "]", ")", ")", "\n", "self", ".", "tasks_probs_over_iterations", "=", "tasks_probs_over_iterations", "\n", "self", ".", "current_iteration", "=", "0", "\n", "\n", "self", ".", "samples_in_batch", "=", "samples_in_batch", "\n", "self", ".", "num_of_batches", "=", "num_of_batches", "\n", "\n", "# Create the samples_distribution_over_time", "\n", "self", ".", "samples_distribution_over_time", "=", "[", "[", "]", "for", "_", "in", "range", "(", "self", ".", "num_of_tasks", ")", "]", "\n", "self", ".", "iter_indices_per_iteration", "=", "[", "]", "\n", "\n", "if", "not", "isinstance", "(", "self", ".", "samples_in_batch", ",", "int", ")", "or", "self", ".", "samples_in_batch", "<=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"num_samples should be a positive integeral \"", "\n", "\"value, but got num_samples={}\"", ".", "format", "(", "self", ".", "samples_in_batch", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.generate_iters_indices": [[174, 193], ["len", "range", "torch.distributions.categorical.Categorical().sample", "torch.zeros", "range", "data_utils.ContinuousMultinomialSampler.iter_indices_per_iteration.append", "torch.Size", "torch.cat.tolist", "torch.distributions.categorical.Categorical", "data_utils.ContinuousMultinomialSampler.samples_distribution_over_time[].append", "numpy.random.permutation", "torch.cat", "data_utils.ContinuousMultinomialSampler.samples_distribution_over_time[].append", "len"], "methods", ["None"], ["", "", "def", "generate_iters_indices", "(", "self", ",", "num_of_iters", ")", ":", "\n", "        ", "from_iter", "=", "len", "(", "self", ".", "iter_indices_per_iteration", ")", "\n", "for", "iter_num", "in", "range", "(", "from_iter", ",", "from_iter", "+", "num_of_iters", ")", ":", "\n", "\n", "# Get random number of samples per task (according to iteration distribution)", "\n", "            ", "tsks", "=", "Categorical", "(", "probs", "=", "self", ".", "tasks_probs_over_iterations", "[", "iter_num", "]", ")", ".", "sample", "(", "torch", ".", "Size", "(", "[", "self", ".", "samples_in_batch", "]", ")", ")", "\n", "# Generate samples indices for iter_num", "\n", "iter_indices", "=", "torch", ".", "zeros", "(", "0", ",", "dtype", "=", "torch", ".", "int32", ")", "\n", "for", "task_idx", "in", "range", "(", "self", ".", "num_of_tasks", ")", ":", "\n", "                ", "if", "self", ".", "tasks_probs_over_iterations", "[", "iter_num", "]", "[", "task_idx", "]", ">", "0", ":", "\n", "                    ", "num_samples_from_task", "=", "(", "tsks", "==", "task_idx", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "samples_distribution_over_time", "[", "task_idx", "]", ".", "append", "(", "num_samples_from_task", ")", "\n", "# Randomize indices for each task (to allow creation of random task batch)", "\n", "tasks_inner_permute", "=", "np", ".", "random", ".", "permutation", "(", "len", "(", "self", ".", "tasks_samples_indices", "[", "task_idx", "]", ")", ")", "\n", "rand_indices_of_task", "=", "tasks_inner_permute", "[", ":", "num_samples_from_task", "]", "\n", "iter_indices", "=", "torch", ".", "cat", "(", "[", "iter_indices", ",", "self", ".", "tasks_samples_indices", "[", "task_idx", "]", "[", "rand_indices_of_task", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "self", ".", "samples_distribution_over_time", "[", "task_idx", "]", ".", "append", "(", "0", ")", "\n", "", "", "self", ".", "iter_indices_per_iteration", ".", "append", "(", "iter_indices", ".", "tolist", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__iter__": [[194, 199], ["data_utils.ContinuousMultinomialSampler.generate_iters_indices", "iter"], "methods", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.generate_iters_indices"], ["", "", "def", "__iter__", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "generate_iters_indices", "(", "self", ".", "num_of_batches", ")", "\n", "self", ".", "current_iteration", "+=", "self", ".", "num_of_batches", "\n", "return", "iter", "(", "[", "item", "for", "sublist", "in", "self", ".", "iter_indices_per_iteration", "[", "self", ".", "current_iteration", "-", "self", ".", "num_of_batches", ":", "self", ".", "current_iteration", "]", "for", "item", "in", "sublist", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils.ContinuousMultinomialSampler.__len__": [[200, 202], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "samples_in_batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._permutate_image_pixels": [[8, 22], ["image.view.size", "image.view.view", "image.view.view"], "function", ["None"], ["def", "_permutate_image_pixels", "(", "image", ",", "permutation", ")", ":", "\n", "    ", "'''Permutate the pixels of an image according to [permutation].\n\n    [image]         3D-tensor containing the image\n    [permutation]   <ndarray> of pixel-indeces in their new order'''", "\n", "\n", "if", "permutation", "is", "None", ":", "\n", "        ", "return", "image", "\n", "", "else", ":", "\n", "        ", "c", ",", "h", ",", "w", "=", "image", ".", "size", "(", ")", "\n", "image", "=", "image", ".", "view", "(", "c", ",", "-", "1", ")", "\n", "image", "=", "image", "[", ":", ",", "permutation", "]", "#--> same permutation for each channel", "\n", "image", "=", "image", ".", "view", "(", "c", ",", "h", ",", "w", ")", "\n", "return", "image", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._get_linear_line": [[80, 84], ["torch.FloatTensor", "torch.FloatTensor", "range", "range"], "function", ["None"], ["", "", "", "def", "_get_linear_line", "(", "start", ",", "end", ",", "direction", "=", "\"up\"", ")", ":", "\n", "    ", "if", "direction", "==", "\"up\"", ":", "\n", "        ", "return", "torch", ".", "FloatTensor", "(", "[", "(", "i", "-", "start", ")", "/", "(", "end", "-", "start", ")", "for", "i", "in", "range", "(", "start", ",", "end", ")", "]", ")", "\n", "", "return", "torch", ".", "FloatTensor", "(", "[", "1", "-", "(", "(", "i", "-", "start", ")", "/", "(", "end", "-", "start", ")", ")", "for", "i", "in", "range", "(", "start", ",", "end", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._create_task_probs": [[85, 108], ["torch.zeros", "probs[].add_", "int", "int", "max", "int", "int", "min", "probs[].add_", "data_utils._get_linear_line", "probs[].add_", "data_utils._get_linear_line", "int", "int"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._get_linear_line", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._get_linear_line"], ["", "def", "_create_task_probs", "(", "iters", ",", "tasks", ",", "task_id", ",", "beta", "=", "3", ")", ":", "\n", "    ", "if", "beta", "<=", "1", ":", "\n", "        ", "peak_start", "=", "int", "(", "(", "task_id", "/", "tasks", ")", "*", "iters", ")", "\n", "peak_end", "=", "int", "(", "(", "(", "task_id", "+", "1", ")", "/", "tasks", ")", "*", "iters", ")", "\n", "start", "=", "peak_start", "\n", "end", "=", "peak_end", "\n", "", "else", ":", "\n", "        ", "start", "=", "max", "(", "int", "(", "(", "(", "beta", "*", "task_id", "-", "1", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", ",", "0", ")", "\n", "peak_start", "=", "int", "(", "(", "(", "beta", "*", "task_id", "+", "1", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", "\n", "peak_end", "=", "int", "(", "(", "(", "beta", "*", "task_id", "+", "(", "beta", "-", "1", ")", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", "\n", "end", "=", "min", "(", "int", "(", "(", "(", "beta", "*", "task_id", "+", "(", "beta", "+", "1", ")", ")", "*", "iters", ")", "/", "(", "beta", "*", "tasks", ")", ")", ",", "iters", ")", "\n", "\n", "", "probs", "=", "torch", ".", "zeros", "(", "iters", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "if", "task_id", "==", "0", ":", "\n", "        ", "probs", "[", "start", ":", "peak_start", "]", ".", "add_", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "probs", "[", "start", ":", "peak_start", "]", "=", "_get_linear_line", "(", "start", ",", "peak_start", ",", "direction", "=", "\"up\"", ")", "\n", "", "probs", "[", "peak_start", ":", "peak_end", "]", ".", "add_", "(", "1", ")", "\n", "if", "task_id", "==", "tasks", "-", "1", ":", "\n", "        ", "probs", "[", "peak_end", ":", "end", "]", ".", "add_", "(", "1", ")", "\n", "", "else", ":", "\n", "        ", "probs", "[", "peak_end", ":", "end", "]", "=", "_get_linear_line", "(", "peak_end", ",", "end", ",", "direction", "=", "\"down\"", ")", "\n", "", "return", "probs", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset": [[14, 64], ["dataset_class", "print", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "dataset_class", "torchvision.transforms.Compose", "dataset_class", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "len", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "torchvision.transforms.Lambda", "data_loader.data_utils._permutate_image_pixels", "data_loader.data_utils._permutate_image_pixels", "data_loader.data_utils._permutate_image_pixels", "data_loader.data_utils._permutate_image_pixels", "data_loader.data_utils._permutate_image_pixels"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._permutate_image_pixels", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._permutate_image_pixels", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._permutate_image_pixels", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._permutate_image_pixels", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._permutate_image_pixels"], ["def", "get_dataset", "(", "name", ",", "type", "=", "'train'", ",", "download", "=", "True", ",", "capacity", "=", "None", ",", "permutation", "=", "None", ",", "dir", "=", "None", ",", "\n", "verbose", "=", "False", ",", "target_transform", "=", "None", ")", ":", "\n", "\n", "    ", "data_name", "=", "'mnist'", "if", "name", "==", "'mnist28'", "else", "name", "\n", "dataset_class", "=", "AVAILABLE_DATASETS", "[", "data_name", "]", "\n", "\n", "# specify image-transformations to be applied", "\n", "if", "name", "==", "'cifar100'", ":", "\n", "        ", "if", "type", "==", "'train'", ":", "\n", "            ", "dataset_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "*", "AVAILABLE_TRANSFORMS", "[", "'cifar100_train'", "]", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "x", ":", "_permutate_image_pixels", "(", "x", ",", "permutation", ")", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "dataset_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "*", "AVAILABLE_TRANSFORMS", "[", "'cifar100_test'", "]", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "x", ":", "_permutate_image_pixels", "(", "x", ",", "permutation", ")", ")", ",", "\n", "]", ")", "\n", "\n", "", "dataset", "=", "dataset_class", "(", "'{dir}/{name}'", ".", "format", "(", "dir", "=", "dir", ",", "name", "=", "data_name", ")", ",", "train", "=", "False", "if", "type", "==", "'test'", "else", "True", ",", "\n", "download", "=", "download", ",", "transform", "=", "dataset_transform", ",", "target_transform", "=", "target_transform", ")", "\n", "", "elif", "name", "==", "'cifar10'", ":", "\n", "        ", "if", "type", "==", "'train'", ":", "\n", "            ", "dataset_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "*", "AVAILABLE_TRANSFORMS", "[", "'cifar10_train'", "]", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "x", ":", "_permutate_image_pixels", "(", "x", ",", "permutation", ")", ")", ",", "\n", "]", ")", "\n", "", "else", ":", "\n", "            ", "dataset_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "*", "AVAILABLE_TRANSFORMS", "[", "'cifar10_test'", "]", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "x", ":", "_permutate_image_pixels", "(", "x", ",", "permutation", ")", ")", ",", "\n", "]", ")", "\n", "\n", "", "dataset", "=", "dataset_class", "(", "'{dir}/{name}'", ".", "format", "(", "dir", "=", "dir", ",", "name", "=", "data_name", ")", ",", "train", "=", "False", "if", "type", "==", "'test'", "else", "True", ",", "\n", "download", "=", "download", ",", "transform", "=", "dataset_transform", ",", "target_transform", "=", "target_transform", ")", "\n", "", "else", ":", "\n", "        ", "dataset_transform", "=", "transforms", ".", "Compose", "(", "[", "\n", "*", "AVAILABLE_TRANSFORMS", "[", "name", "]", ",", "\n", "transforms", ".", "Lambda", "(", "lambda", "x", ":", "_permutate_image_pixels", "(", "x", ",", "permutation", ")", ")", ",", "\n", "]", ")", "\n", "\n", "\n", "dataset", "=", "dataset_class", "(", "'{dir}/{name}'", ".", "format", "(", "dir", "=", "dir", ",", "name", "=", "data_name", ")", ",", "train", "=", "False", "if", "type", "==", "'test'", "else", "True", ",", "\n", "download", "=", "download", ",", "transform", "=", "dataset_transform", ",", "target_transform", "=", "target_transform", ")", "\n", "\n", "\n", "", "if", "verbose", ":", "\n", "        ", "print", "(", "\"  --> {}: '{}'-dataset consisting of {} samples\"", ".", "format", "(", "name", ",", "type", ",", "len", "(", "dataset", ")", ")", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_multitask_experiment": [[68, 262], ["numpy.min", "int", "torch.zeros_like", "torch.cat().view", "range", "torch.utils.data.ConcatDataset", "data_loader.data_utils.ContinuousMultinomialSampler", "torch.utils.data.DataLoader", "enumerate", "len", "data_loader.data_utils._create_task_probs", "torch.zeros_like.add_", "probs.div_", "tasks_probs_over_iterations_lst.append", "tasks_samples_indices.append", "len", "torch.cuda.is_available", "int", "range", "train_datasets.append", "test_datasets.append", "numpy.array", "torchvision.transforms.Lambda", "data_loader_online.get_dataset", "data_loader_online.get_dataset", "enumerate", "len", "len", "range", "torch.cat", "torch.tensor", "numpy.random.permutation", "torchvision.transforms.Lambda", "data_loader_online.get_dataset", "data_loader_online.get_dataset", "list", "print", "copy.deepcopy", "random.shuffle", "train_datasets.append", "test_datasets.append", "numpy.array", "torchvision.transforms.Lambda", "data_loader_online.get_dataset", "data_loader_online.get_dataset", "RuntimeError", "len", "range", "numpy.random.permutation", "range", "range", "int", "int", "range", "torchvision.transforms.Lambda", "data_loader.data_utils.SubDataset", "data_loader.data_utils.SubDataset", "list", "train_datasets.append", "test_datasets.append", "numpy.array", "torchvision.transforms.Lambda", "data_loader_online.get_dataset", "data_loader_online.get_dataset", "range", "len", "range", "int", "int", "range", "range", "range", "torchvision.transforms.Lambda", "data_loader.data_utils.SubDataset", "data_loader.data_utils.SubDataset", "list", "train_datasets.append", "test_datasets.append", "len", "len", "len", "range", "int", "int", "range", "range", "range", "torchvision.transforms.Lambda", "data_loader.data_utils.SubDataset", "data_loader.data_utils.SubDataset", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_utils._create_task_probs", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset", "home.repos.pwc.inspect_result.ShuangLI59_ebm-continual-learning.data_loader.data_loader_online.get_dataset"], ["", "def", "get_multitask_experiment", "(", "args", ",", "name", ",", "scenario", ",", "tasks", ",", "data_dir", "=", "None", ",", "only_config", "=", "False", ",", "verbose", "=", "False", ",", "exception", "=", "False", ")", ":", "\n", "\n", "    ", "if", "name", "==", "'permMNIST'", ":", "\n", "        ", "config", "=", "DATASET_CONFIGS", "[", "'mnist'", "]", "\n", "\n", "labels_per_task", "=", "labels_per_tasks_standard", "[", "'permMNIST'", "]", "[", "args", ".", "seed", "]", "\n", "classes_per_task", "=", "10", "\n", "task_dict", "=", "{", "k", ":", "int", "(", "k", "/", "10", ")", "+", "1", "for", "k", "in", "range", "(", "100", ")", "}", "\n", "\n", "if", "not", "only_config", ":", "\n", "# generate permutations", "\n", "            ", "if", "exception", ":", "\n", "                ", "permutations", "=", "[", "None", "]", "+", "[", "np", ".", "random", ".", "permutation", "(", "config", "[", "'size'", "]", "**", "2", ")", "for", "_", "in", "range", "(", "len", "(", "labels_per_task", ")", "-", "1", ")", "]", "\n", "", "else", ":", "\n", "                ", "permutations", "=", "[", "np", ".", "random", ".", "permutation", "(", "config", "[", "'size'", "]", "**", "2", ")", "for", "_", "in", "range", "(", "len", "(", "labels_per_task", ")", ")", "]", "\n", "# prepare datasets", "\n", "", "train_datasets", "=", "[", "]", "\n", "test_datasets", "=", "[", "]", "\n", "for", "task_id", ",", "p", "in", "enumerate", "(", "permutations", ")", ":", "\n", "                ", "target_transform", "=", "transforms", ".", "Lambda", "(", "\n", "lambda", "y", ",", "x", "=", "task_id", ":", "y", "+", "x", "*", "classes_per_task", "\n", ")", "if", "scenario", "in", "(", "'task'", ",", "'class'", ")", "else", "None", "\n", "train_datasets", ".", "append", "(", "get_dataset", "(", "'mnist'", ",", "type", "=", "\"train\"", ",", "permutation", "=", "p", ",", "dir", "=", "data_dir", ",", "\n", "target_transform", "=", "target_transform", ",", "verbose", "=", "verbose", ")", ")", "\n", "test_datasets", ".", "append", "(", "get_dataset", "(", "'mnist'", ",", "type", "=", "\"test\"", ",", "permutation", "=", "p", ",", "dir", "=", "data_dir", ",", "\n", "target_transform", "=", "target_transform", ",", "verbose", "=", "verbose", ")", ")", "\n", "\n", "\n", "", "", "", "elif", "name", "==", "'splitMNIST'", ":", "\n", "        ", "config", "=", "DATASET_CONFIGS", "[", "'mnist28'", "]", "\n", "\n", "if", "not", "only_config", ":", "\n", "            ", "permutation", "=", "np", ".", "array", "(", "list", "(", "range", "(", "10", ")", ")", ")", "\n", "target_transform", "=", "transforms", ".", "Lambda", "(", "lambda", "y", ",", "x", "=", "permutation", ":", "int", "(", "permutation", "[", "y", "]", ")", ")", "\n", "mnist_train", "=", "get_dataset", "(", "'mnist28'", ",", "type", "=", "\"train\"", ",", "dir", "=", "data_dir", ",", "target_transform", "=", "target_transform", ",", "\n", "verbose", "=", "verbose", ")", "\n", "mnist_test", "=", "get_dataset", "(", "'mnist28'", ",", "type", "=", "\"test\"", ",", "dir", "=", "data_dir", ",", "target_transform", "=", "target_transform", ",", "\n", "verbose", "=", "verbose", ")", "\n", "\n", "## ---------------------------------------------------------------------------------------------------------", "\n", "## generated data splits", "\n", "## ---------------------------------------------------------------------------------------------------------", "\n", "labels_per_task", "=", "labels_per_tasks_standard", "[", "'splitMNIST'", "]", "[", "args", ".", "seed", "]", "\n", "task_dict", "=", "{", "k", ":", "int", "(", "k", "/", "2", ")", "+", "1", "for", "k", "in", "range", "(", "10", ")", "}", "\n", "\n", "# split them up into sub-tasks", "\n", "train_datasets", "=", "[", "]", "\n", "test_datasets", "=", "[", "]", "\n", "\n", "if", "args", ".", "random_task_order", ":", "\n", "                ", "print", "(", "'random task order'", ")", "\n", "labels_per_task", "=", "deepcopy", "(", "labels_per_task", ")", "\n", "random", ".", "shuffle", "(", "labels_per_task", ")", "\n", "\n", "", "for", "task_id", ",", "labels", "in", "enumerate", "(", "labels_per_task", ")", ":", "\n", "                ", "target_transform", "=", "transforms", ".", "Lambda", "(", "\n", "lambda", "y", ",", "x", "=", "labels", "[", "0", "]", ":", "y", "-", "x", "\n", ")", "if", "scenario", "==", "'domain'", "else", "None", "\n", "train_datasets", ".", "append", "(", "SubDataset", "(", "args", ",", "mnist_train", ",", "labels", ",", "class_per_task", "=", "2", ",", "task_id", "=", "task_id", ",", "target_transform", "=", "target_transform", ")", ")", "\n", "test_datasets", ".", "append", "(", "SubDataset", "(", "args", ",", "mnist_test", ",", "labels", ",", "class_per_task", "=", "2", ",", "task_id", "=", "task_id", ",", "target_transform", "=", "target_transform", ")", ")", "\n", "\n", "\n", "", "labels_per_task", "=", "labels_per_tasks_standard", "[", "'splitMNIST'", "]", "[", "args", ".", "seed", "]", "\n", "\n", "\n", "", "", "elif", "name", "==", "'cifar10'", ":", "\n", "        ", "config", "=", "DATASET_CONFIGS", "[", "'cifar10'", "]", "\n", "\n", "if", "not", "only_config", ":", "\n", "# prepare permutation to shuffle label-ids (to create different class batches for each random seed)", "\n", "            ", "permutation", "=", "np", ".", "array", "(", "list", "(", "range", "(", "10", ")", ")", ")", "\n", "target_transform", "=", "transforms", ".", "Lambda", "(", "lambda", "y", ",", "x", "=", "permutation", ":", "int", "(", "permutation", "[", "y", "]", ")", ")", "\n", "# prepare train and test datasets with all classes", "\n", "cifar10_train", "=", "get_dataset", "(", "'cifar10'", ",", "type", "=", "\"train\"", ",", "dir", "=", "data_dir", ",", "target_transform", "=", "target_transform", ",", "\n", "verbose", "=", "verbose", ")", "\n", "cifar10_test", "=", "get_dataset", "(", "'cifar10'", ",", "type", "=", "\"test\"", ",", "dir", "=", "data_dir", ",", "target_transform", "=", "target_transform", ",", "\n", "verbose", "=", "verbose", ")", "\n", "\n", "## ---------------------------------------------------------------------------------------------------------", "\n", "## generated data splits", "\n", "## ---------------------------------------------------------------------------------------------------------", "\n", "labels_per_task", "=", "labels_per_tasks_standard", "[", "'cifar10'", "]", "[", "args", ".", "seed", "]", "\n", "task_dict", "=", "{", "k", ":", "int", "(", "k", "/", "2", ")", "+", "1", "for", "k", "in", "range", "(", "10", ")", "}", "\n", "\n", "# split them up into sub-tasks", "\n", "train_datasets", "=", "[", "]", "\n", "test_datasets", "=", "[", "]", "\n", "\n", "all_train_labels", "=", "[", "cifar10_train", "[", "index", "]", "[", "1", "]", "for", "index", "in", "range", "(", "len", "(", "cifar10_train", ")", ")", "]", "\n", "all_test_labels", "=", "[", "cifar10_test", "[", "index", "]", "[", "1", "]", "for", "index", "in", "range", "(", "len", "(", "cifar10_test", ")", ")", "]", "\n", "\n", "for", "labels", "in", "labels_per_task", ":", "\n", "                ", "target_transform", "=", "transforms", ".", "Lambda", "(", "\n", "lambda", "y", ",", "x", "=", "labels", "[", "0", "]", ":", "y", "-", "x", "\n", ")", "if", "scenario", "==", "'domain'", "else", "None", "\n", "train_datasets", ".", "append", "(", "SubDataset", "(", "args", ",", "cifar10_train", ",", "labels", ",", "target_transform", "=", "target_transform", ",", "all_labels", "=", "all_train_labels", ",", "cifar", "=", "True", ")", ")", "\n", "test_datasets", ".", "append", "(", "SubDataset", "(", "args", ",", "cifar10_test", ",", "labels", ",", "target_transform", "=", "target_transform", ",", "all_labels", "=", "all_test_labels", ",", "cifar", "=", "True", ")", ")", "\n", "\n", "", "", "", "elif", "name", "==", "'cifar100'", ":", "\n", "# configurations", "\n", "        ", "config", "=", "DATASET_CONFIGS", "[", "'cifar100'", "]", "\n", "\n", "if", "not", "only_config", ":", "\n", "# prepare permutation to shuffle label-ids (to create different class batches for each random seed)", "\n", "            ", "permutation", "=", "np", ".", "array", "(", "list", "(", "range", "(", "100", ")", ")", ")", "\n", "target_transform", "=", "transforms", ".", "Lambda", "(", "lambda", "y", ",", "x", "=", "permutation", ":", "int", "(", "permutation", "[", "y", "]", ")", ")", "\n", "# prepare train and test datasets with all classes", "\n", "cifar100_train", "=", "get_dataset", "(", "'cifar100'", ",", "type", "=", "\"train\"", ",", "dir", "=", "data_dir", ",", "target_transform", "=", "target_transform", ",", "\n", "verbose", "=", "verbose", ")", "\n", "cifar100_test", "=", "get_dataset", "(", "'cifar100'", ",", "type", "=", "\"test\"", ",", "dir", "=", "data_dir", ",", "target_transform", "=", "target_transform", ",", "\n", "verbose", "=", "verbose", ")", "\n", "\n", "## ---------------------------------------------------------------------------------------------------------", "\n", "## generated data splits", "\n", "## ---------------------------------------------------------------------------------------------------------", "\n", "labels_per_task", "=", "labels_per_tasks_standard", "[", "'cifar100'", "]", "[", "args", ".", "seed", "]", "\n", "task_dict", "=", "{", "k", ":", "int", "(", "k", "/", "10", ")", "+", "1", "for", "k", "in", "range", "(", "100", ")", "}", "\n", "\n", "# split them up into sub-tasks", "\n", "train_datasets", "=", "[", "]", "\n", "test_datasets", "=", "[", "]", "\n", "\n", "all_train_labels", "=", "[", "cifar100_train", "[", "index", "]", "[", "1", "]", "for", "index", "in", "range", "(", "len", "(", "cifar100_train", ")", ")", "]", "\n", "all_test_labels", "=", "[", "cifar100_test", "[", "index", "]", "[", "1", "]", "for", "index", "in", "range", "(", "len", "(", "cifar100_test", ")", ")", "]", "\n", "\n", "for", "labels", "in", "labels_per_task", ":", "\n", "                ", "target_transform", "=", "transforms", ".", "Lambda", "(", "\n", "lambda", "y", ",", "x", "=", "labels", "[", "0", "]", ":", "y", "-", "x", "\n", ")", "if", "scenario", "==", "'domain'", "else", "None", "\n", "train_datasets", ".", "append", "(", "SubDataset", "(", "args", ",", "cifar100_train", ",", "labels", ",", "target_transform", "=", "target_transform", ",", "all_labels", "=", "all_train_labels", ",", "cifar", "=", "True", ")", ")", "\n", "test_datasets", ".", "append", "(", "SubDataset", "(", "args", ",", "cifar100_test", ",", "labels", ",", "target_transform", "=", "target_transform", ",", "all_labels", "=", "all_test_labels", ",", "cifar", "=", "True", ")", ")", "\n", "\n", "", "", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", "'Given undefined experiment: {}'", ".", "format", "(", "name", ")", ")", "\n", "\n", "\n", "\n", "", "if", "not", "args", ".", "task_boundary", ":", "\n", "\n", "        ", "iterations_per_virtual_epc", "=", "np", ".", "min", "(", "[", "len", "(", "train_dataset", ")", "for", "train_dataset", "in", "train_datasets", "]", ")", "\n", "iterations_per_virtual_epc", "=", "int", "(", "iterations_per_virtual_epc", "/", "args", ".", "batch", ")", "\n", "\n", "total_num_epochs", "=", "args", ".", "epc_per_virtual_task", "*", "len", "(", "labels_per_task", ")", "\n", "total_iters", "=", "total_num_epochs", "*", "iterations_per_virtual_epc", "\n", "\n", "beta", "=", "4", "\n", "# Create probabilities of tasks over iterations", "\n", "tasks_probs_over_iterations", "=", "[", "_create_task_probs", "(", "total_iters", ",", "len", "(", "labels_per_task", ")", ",", "task_id", ",", "beta", "=", "beta", ")", "for", "task_id", "in", "range", "(", "len", "(", "labels_per_task", ")", ")", "]", "\n", "normalize_probs", "=", "torch", ".", "zeros_like", "(", "tasks_probs_over_iterations", "[", "0", "]", ")", "\n", "for", "probs", "in", "tasks_probs_over_iterations", ":", "\n", "            ", "normalize_probs", ".", "add_", "(", "probs", ")", "\n", "", "for", "probs", "in", "tasks_probs_over_iterations", ":", "\n", "            ", "probs", ".", "div_", "(", "normalize_probs", ")", "\n", "", "tasks_probs_over_iterations", "=", "torch", ".", "cat", "(", "tasks_probs_over_iterations", ")", ".", "view", "(", "-", "1", ",", "tasks_probs_over_iterations", "[", "0", "]", ".", "shape", "[", "0", "]", ")", "\n", "tasks_probs_over_iterations_lst", "=", "[", "]", "\n", "for", "col", "in", "range", "(", "tasks_probs_over_iterations", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "tasks_probs_over_iterations_lst", ".", "append", "(", "tasks_probs_over_iterations", "[", ":", ",", "col", "]", ")", "\n", "", "tasks_probs_over_iterations", "=", "tasks_probs_over_iterations_lst", "\n", "\n", "\n", "\n", "tasks_samples_indices", "=", "[", "]", "\n", "total_len", "=", "0", "\n", "for", "train_dataset", "in", "train_datasets", ":", "\n", "            ", "tasks_samples_indices", ".", "append", "(", "torch", ".", "tensor", "(", "range", "(", "total_len", ",", "total_len", "+", "len", "(", "train_dataset", ")", ")", ",", "dtype", "=", "torch", ".", "int32", ")", ")", "\n", "total_len", "+=", "len", "(", "train_dataset", ")", "\n", "\n", "\n", "", "all_datasets", "=", "torch", ".", "utils", ".", "data", ".", "ConcatDataset", "(", "train_datasets", ")", "\n", "train_sampler", "=", "ContinuousMultinomialSampler", "(", "data_source", "=", "all_datasets", ",", "samples_in_batch", "=", "args", ".", "batch", ",", "\n", "tasks_samples_indices", "=", "tasks_samples_indices", ",", "\n", "tasks_probs_over_iterations", "=", "tasks_probs_over_iterations", ",", "\n", "num_of_batches", "=", "iterations_per_virtual_epc", ")", "\n", "\n", "pin_memory", "=", "True", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "else", "False", "\n", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "all_datasets", ",", "batch_size", "=", "args", ".", "batch", ",", "\n", "num_workers", "=", "1", ",", "sampler", "=", "train_sampler", ",", "pin_memory", "=", "pin_memory", ")", "\n", "\n", "\n", "# test_loaders = []", "\n", "# for test_dataset in test_datasets:", "\n", "#     test_loaders.append(torch.utils.data.DataLoader(test_dataset, batch_size=args.batch, num_workers=1, shuffle=False, pin_memory=pin_memory))", "\n", "\n", "\n", "config", "[", "'num_classes'", "]", "=", "args", ".", "num_classes", "\n", "config", "[", "'labels_per_task'", "]", "=", "labels_per_task", "\n", "config", "[", "'iterations_per_virtual_epc'", "]", "=", "iterations_per_virtual_epc", "\n", "config", "[", "'task_dict'", "]", "=", "task_dict", "\n", "return", "(", "(", "train_loader", ",", "test_datasets", ")", ",", "config", ")", "\n", "\n", "", "else", ":", "\n", "        ", "config", "[", "'num_classes'", "]", "=", "args", ".", "num_classes", "\n", "config", "[", "'labels_per_task'", "]", "=", "labels_per_task", "\n", "return", "(", "(", "train_datasets", ",", "test_datasets", ")", ",", "config", ")", "\n", "\n"]]}