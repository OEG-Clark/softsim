{"home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.cal_performence": [[21, 32], ["train_no_sns.cal_loss", "gold.contiguous().view.contiguous().view", "gold.contiguous().view.ne", "pred.eq", "n_correct.masked_select().sum().item.masked_select().sum().item", "pred.max", "gold.contiguous().view.contiguous", "n_correct.masked_select().sum().item.masked_select().sum", "n_correct.masked_select().sum().item.masked_select"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_loss"], ["def", "cal_performence", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Apply label smooth if needed\n    \"\"\"", "\n", "loss", ",", "loss_recon", ",", "loss_kl", "=", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "pred", "=", "pred", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_correct", "=", "pred", ".", "eq", "(", "gold", ")", "\n", "n_correct", "=", "n_correct", ".", "masked_select", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.gaussian_kld": [[33, 38], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "exp", "(", "recog_logvar", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", ",", "1", ")", "\n", "return", "torch", ".", "sum", "(", "kld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.cal_loss": [[48, 58], ["gold.contiguous().view.contiguous().view", "torch.cross_entropy", "train_no_sns.gaussian_kld", "gold.contiguous().view.contiguous"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.gaussian_kld"], ["", "def", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Calculate cross entropy loss, apply label smoothing if needed\n    \"\"\"", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss_recon", "=", "F", ".", "cross_entropy", "(", "pred", ",", "gold", ",", "ignore_index", "=", "Constants", ".", "PAD", ",", "reduction", "=", "'sum'", ")", "\n", "# loss_kl = lambda_kl*-0.5 * torch.sum(1 + log_var - mu.pow(2)-log_var.exp())", "\n", "loss_kl", "=", "lambda_kl", "*", "gaussian_kld", "(", "mu_posterior", ",", "log_var_posterior", ",", "mu_prior", ",", "log_var_prior", ")", "\n", "# loss_sparse = sparse_resularizer(plan_attns)", "\n", "return", "loss_recon", "+", "loss_kl", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.train_epoch": [[59, 108], ["model.train", "tqdm.tqdm", "map", "optimizer.zero_grad", "model", "train_no_sns.cal_performence", "loss.backward", "optimizer.step", "scheduler.step", "loss.item", "loss_kl.item", "loss_recon.item", "len", "gold.ne", "gold.ne.sum().item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", ",", "lambda_kl", ")", ":", "\n", "    ", "'''Epoch operation in training phase'''", "\n", "model", ".", "train", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "\n", "for", "batch", "in", "tqdm", "(", "training_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Training) '", ",", "leave", "=", "False", ")", ":", "\n", "\n", "# prepare data", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "#print('src_seq shape:', src_seq.shape)", "\n", "#print('src_pos shape:', src_pos.shape)", "\n", "#print('tgt_seq shape:', tgt_seq.shape)", "\n", "#print('tgt_pos shape:', tgt_pos.shape)", "\n", "gold", "=", "tgt_seq", "\n", "# forward", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "#print('pred shape', pred.shape)", "\n", "#print('gold shape', gold.shape)", "\n", "\n", "# backward", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "#print(loss)", "\n", "#print(n_correct)", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# update parameters", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.eval_epoch": [[110, 143], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "map", "model", "train_no_sns.cal_performence", "loss.item", "gold.ne", "gold.ne.sum().item", "loss_kl.item", "len", "loss_recon.item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", ":", "\n", "    ", "'''Epoch operation in evaluation phase'''", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "validation_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Validation) '", ",", "leave", "=", "False", ")", ":", "\n", "# prepare data", "\n", "            ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "gold", "=", "tgt_seq", "\n", "\n", "# forward", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", "=", "1", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "\n", "", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.train": [[145, 198], ["utils.cyclical_annealing.frange_cycle_linear", "range", "print", "print", "time.time", "train_no_sns.train_epoch", "print", "time.time", "train_no_sns.eval_epoch", "print", "model.state_dict", "open", "open", "log_tf.write", "log_vf.write", "torch.save", "torch.save", "torch.save", "torch.save", "open", "open", "log_tf.write", "log_vf.write", "math.exp", "math.exp", "max", "torch.save", "torch.save", "torch.save", "torch.save", "print", "train_no_sns.sample_generation", "min", "min", "time.time", "time.time", "math.exp", "math.exp", "min", "min"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_linear", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.eval_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.sample_generation"], ["", "def", "train", "(", "model", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", ":", "\n", "    ", "'''Start training'''", "\n", "log_train_file", "=", "None", "\n", "log_valid_file", "=", "None", "\n", "beta_epochs", "=", "frange_cycle_linear", "(", "start", "=", "0.0", ",", "stop", "=", "1.0", ",", "n_epoch", "=", "opt", ".", "epoch", ")", "\n", "\n", "if", "opt", ".", "log", ":", "\n", "        ", "log_train_file", "=", "opt", ".", "log", "+", "'.train.log'", "\n", "log_valid_file", "=", "opt", ".", "log", "+", "'.valid.log'", "\n", "\n", "print", "(", "'[Info] Training performence will be written to file: {} and {}'", ".", "format", "(", "log_train_file", ",", "log_valid_file", ")", ")", "\n", "with", "open", "(", "log_train_file", ",", "'w'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'w'", ")", "as", "log_vf", ":", "\n", "            ", "log_tf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "log_vf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "", "", "valid_accus", "=", "[", "]", "\n", "for", "epoch_i", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "beta_this_epoch", "=", "beta_epochs", "[", "epoch_i", "]", "\n", "print", "(", "'[ Epoch'", ",", "epoch_i", ",", "' ]'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_accu", ",", "train_loss_recon", ",", "train_loss_kl", "=", "train_epoch", "(", "\n", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", "=", "opt", ".", "label_smoothing", ",", "lambda_kl", "=", "beta_this_epoch", "\n", ")", "\n", "print", "(", "' -(Trianing) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, train_loss_recon: {recon: 8.5f}, train_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", ",", "\n", "recon", "=", "train_loss_recon", ",", "kl", "=", "train_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "valid_loss", ",", "valid_accu", ",", "valid_loss_recon", ",", "valid_loss_kl", "=", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", "\n", "print", "(", "' -(Validation) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, valid_loss_recon: {recon: 8.5f}, valid_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", ",", "\n", "recon", "=", "valid_loss_recon", ",", "kl", "=", "valid_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "valid_accus", "+=", "[", "valid_accu", "]", "\n", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'settings'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch_i", "\n", "}", "\n", "if", "opt", ".", "save_model", ":", "\n", "            ", "if", "opt", ".", "save_mode", "==", "'all'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'_accu_{accu:3.3f}.chkpt'", ".", "format", "(", "accu", "=", "100", "*", "valid_accu", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "", "if", "opt", ".", "save_mode", "==", "'best'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'.chkpt'", "\n", "if", "valid_accu", ">=", "max", "(", "valid_accus", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "' -[Info] The check point file has been updated.'", ")", "\n", "sample_generation", "(", "model", ",", "training_data", ",", "idx2word", ",", "device", ")", "\n", "\n", "", "", "", "if", "log_train_file", "and", "log_valid_file", ":", "\n", "            ", "with", "open", "(", "log_train_file", ",", "'a'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'a'", ")", "as", "log_vf", ":", "\n", "                ", "log_tf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "train_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", "\n", ")", ")", "\n", "log_vf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "valid_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.sample_generation": [[200, 216], ["print", "print", "print", "print", "print", "map", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "model.predict", "show_case.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.to", "equ_nodes[].unsqueeze", "equ_adj_matrixs[].unsqueeze", "equ_node_lens[].unsqueeze", "sns_nodes[].unsqueeze", "sns_adj_matrixs[].unsqueeze", "sns_node_lens[].unsqueeze", "scene[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "", "", "", "def", "sample_generation", "(", "model", ",", "train_loader", ",", "idx2word", ",", "device", ")", ":", "\n", "    ", "for", "batch", "in", "train_loader", ":", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "", "print", "(", "'show case during training'", ")", "\n", "show_case", ",", "show_attn", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "dec_ids", ",", "attn_matrix", "=", "model", ".", "predict", "(", "\n", "input_equ_nodes", "=", "equ_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_equ_matrix", "=", "equ_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "equ_node_lens", "=", "equ_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "input_sns_nodes", "=", "sns_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_sns_matrix", "=", "sns_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "sns_node_lens", "=", "sns_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "scene", "=", "scene", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "device", "=", "device", ",", "max_tgt_len", "=", "50", ")", "\n", "show_case", ".", "append", "(", "''", ".", "join", "(", "idx2word", "[", "x", "]", "for", "x", "in", "dec_ids", ")", ")", "\n", "", "", "print", "(", "'one attention matrix is {}'", ".", "format", "(", "torch", ".", "stack", "(", "attn_matrix", ",", "1", ")", ")", ")", "\n", "print", "(", "show_case", "[", "0", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "1", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "2", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.main": [[217, 293], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "argparse.ArgumentParser.parse_args", "torch.load", "torch.load", "torch.load", "torch.load", "max", "print", "train_no_sns.prepare_dataloaders", "print", "print", "torch.device", "torch.device", "torch.device", "torch.device", "model.model_no_sns.Graph2seq().to", "transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "train_no_sns.train", "Graph2seq().to.parameters", "len", "len", "model.model_no_sns.Graph2seq", "[].items"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.prepare_dataloaders", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "'''Main function'''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "'./processed_data/dual_graph_rev_res.pt'", ")", "\n", "parser", ".", "add_argument", "(", "'-epoch'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "#node dim same as this", "\n", "parser", ".", "add_argument", "(", "'-n_hop'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'-hidden_size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'-z_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'-teacher_forcing'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "500", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-log'", ",", "default", "=", "'./logs/MaKE_res_no_sns'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'./saved_model/MaKE_res_no_sns'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_mode'", ",", "type", "=", "str", ",", "choices", "=", "[", "'all'", ",", "'best'", "]", ",", "default", "=", "'best'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-no_cuda'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-label_smoothing'", ",", "action", "=", "'store_true'", ")", "\n", "torch", ".", "manual_seed", "(", "32", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "not", "opt", ".", "no_cuda", "\n", "# god seed", "\n", "\n", "#====== Loading Dataset =====#", "\n", "data", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "opt", ".", "max_token_seq_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "data", "[", "'train'", "]", "[", "'ref'", "]", ")", "\n", "print", "(", "'max token length is:'", ",", "opt", ".", "max_token_seq_len", ")", "\n", "\n", "training_data", ",", "validation_data", "=", "prepare_dataloaders", "(", "data", ",", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "training_data", ".", "dataset", ".", "src_vocab_size", "\n", "print", "(", "'vocab size is:'", ",", "opt", ".", "vocab_size", ")", "\n", "\n", "#======= Preparing model ====#", "\n", "print", "(", "opt", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:0'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "# device = torch.device('cpu')", "\n", "graph2seq", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "opt", ".", "z_dim", ",", "\n", "output_size", "=", "opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "# optimizer = ScheduledOptim(", "\n", "#     optim.Adam(", "\n", "#         filter(lambda x: x.requires_grad, graph2seq.parameters()),", "\n", "#         betas=(0.9,0.98),eps=1e-09),", "\n", "#     opt.hidden_size, opt.n_warmup_steps", "\n", "# )", "\n", "optimizer", "=", "AdamW", "(", "graph2seq", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "1e-3", ",", "# args.learning_rate - default is 5e-5, our notebook had 2e-5", "\n", "eps", "=", "1e-8", "# args.adam_epsilon  - default is 1e-8.", "\n", ")", "\n", "# Number of training epochs (authors recommend between 2 and 4)", "\n", "epochs", "=", "opt", ".", "epoch", "\n", "\n", "# Total number of training steps is number of batches * number of epochs.", "\n", "total_steps", "=", "len", "(", "training_data", ")", "*", "epochs", "\n", "\n", "# Create the learning rate scheduler.", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "num_warmup_steps", "=", "0", ",", "# Default value in run_glue.py", "\n", "num_training_steps", "=", "total_steps", ")", "\n", "# train(model, tokenizer, train_loader, valid_loader, optimizer, scheduler, device, opt)", "\n", "\n", "idx2word", "=", "{", "value", ":", "item", "for", "item", ",", "value", "in", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ".", "items", "(", ")", "}", "\n", "train", "(", "graph2seq", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_sns.prepare_dataloaders": [[294, 329], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataset_dual.MyDataset", "dataset_dual.MyDataset"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "data", ",", "opt", ")", ":", "\n", "# =====Prepareing DataLoader=====", "\n", "    ", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'train'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'train'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'train'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'train'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'train'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'train'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "True", "\n", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'dev'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'dev'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'dev'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'dev'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'dev'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'dev'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.cal_performence": [[19, 30], ["train_res_seed_16.cal_loss", "gold.contiguous().view.contiguous().view", "gold.contiguous().view.ne", "pred.eq", "n_correct.masked_select().sum().item.masked_select().sum().item", "pred.max", "gold.contiguous().view.contiguous", "n_correct.masked_select().sum().item.masked_select().sum", "n_correct.masked_select().sum().item.masked_select"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_loss"], ["def", "cal_performence", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Apply label smooth if needed\n    \"\"\"", "\n", "loss", ",", "loss_recon", ",", "loss_kl", "=", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "pred", "=", "pred", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_correct", "=", "pred", ".", "eq", "(", "gold", ")", "\n", "n_correct", "=", "n_correct", ".", "masked_select", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.gaussian_kld": [[31, 36], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "exp", "(", "recog_logvar", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", ",", "1", ")", "\n", "return", "torch", ".", "sum", "(", "kld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.cal_loss": [[46, 56], ["gold.contiguous().view.contiguous().view", "torch.cross_entropy", "train_res_seed_16.gaussian_kld", "gold.contiguous().view.contiguous"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.gaussian_kld"], ["", "def", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Calculate cross entropy loss, apply label smoothing if needed\n    \"\"\"", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss_recon", "=", "F", ".", "cross_entropy", "(", "pred", ",", "gold", ",", "ignore_index", "=", "Constants", ".", "PAD", ",", "reduction", "=", "'sum'", ")", "\n", "# loss_kl = lambda_kl*-0.5 * torch.sum(1 + log_var - mu.pow(2)-log_var.exp())", "\n", "loss_kl", "=", "lambda_kl", "*", "gaussian_kld", "(", "mu_posterior", ",", "log_var_posterior", ",", "mu_prior", ",", "log_var_prior", ")", "\n", "# loss_sparse = sparse_resularizer(plan_attns)", "\n", "return", "loss_recon", "+", "loss_kl", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.train_epoch": [[57, 105], ["model.train", "tqdm.tqdm", "map", "optimizer.zero_grad", "model", "train_res_seed_16.cal_performence", "loss.backward", "optimizer.step_and_update_lr", "loss.item", "loss_kl.item", "loss_recon.item", "len", "gold.ne", "gold.ne.sum().item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.step_and_update_lr"], ["", "def", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "device", ",", "smoothing", ",", "lambda_kl", ")", ":", "\n", "    ", "'''Epoch operation in training phase'''", "\n", "model", ".", "train", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "\n", "for", "batch", "in", "tqdm", "(", "training_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Training) '", ",", "leave", "=", "False", ")", ":", "\n", "\n", "# prepare data", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "#print('src_seq shape:', src_seq.shape)", "\n", "#print('src_pos shape:', src_pos.shape)", "\n", "#print('tgt_seq shape:', tgt_seq.shape)", "\n", "#print('tgt_pos shape:', tgt_pos.shape)", "\n", "gold", "=", "tgt_seq", "\n", "# forward", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "#print('pred shape', pred.shape)", "\n", "#print('gold shape', gold.shape)", "\n", "\n", "# backward", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "#print(loss)", "\n", "#print(n_correct)", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# update parameters", "\n", "optimizer", ".", "step_and_update_lr", "(", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.eval_epoch": [[107, 140], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "map", "model", "train_res_seed_16.cal_performence", "loss.item", "gold.ne", "gold.ne.sum().item", "loss_kl.item", "len", "loss_recon.item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", ":", "\n", "    ", "'''Epoch operation in evaluation phase'''", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "validation_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Validation) '", ",", "leave", "=", "False", ")", ":", "\n", "# prepare data", "\n", "            ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "gold", "=", "tgt_seq", "\n", "\n", "# forward", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", "=", "1", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "\n", "", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.train": [[142, 195], ["utils.cyclical_annealing.frange_cycle_linear", "range", "print", "print", "time.time", "train_res_seed_16.train_epoch", "print", "time.time", "train_res_seed_16.eval_epoch", "print", "model.state_dict", "open", "open", "log_tf.write", "log_vf.write", "torch.save", "torch.save", "torch.save", "torch.save", "open", "open", "log_tf.write", "log_vf.write", "math.exp", "math.exp", "max", "torch.save", "torch.save", "torch.save", "torch.save", "print", "train_res_seed_16.sample_generation", "min", "min", "time.time", "time.time", "math.exp", "math.exp", "min", "min"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_linear", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.eval_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.sample_generation"], ["", "def", "train", "(", "model", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "device", ",", "idx2word", ",", "opt", ")", ":", "\n", "    ", "'''Start training'''", "\n", "log_train_file", "=", "None", "\n", "log_valid_file", "=", "None", "\n", "beta_epochs", "=", "frange_cycle_linear", "(", "start", "=", "0.0", ",", "stop", "=", "1.0", ",", "n_epoch", "=", "opt", ".", "epoch", ")", "\n", "\n", "if", "opt", ".", "log", ":", "\n", "        ", "log_train_file", "=", "opt", ".", "log", "+", "'.train.log'", "\n", "log_valid_file", "=", "opt", ".", "log", "+", "'.valid.log'", "\n", "\n", "print", "(", "'[Info] Training performence will be written to file: {} and {}'", ".", "format", "(", "log_train_file", ",", "log_valid_file", ")", ")", "\n", "with", "open", "(", "log_train_file", ",", "'w'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'w'", ")", "as", "log_vf", ":", "\n", "            ", "log_tf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "log_vf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "", "", "valid_accus", "=", "[", "]", "\n", "for", "epoch_i", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "beta_this_epoch", "=", "beta_epochs", "[", "epoch_i", "]", "\n", "print", "(", "'[ Epoch'", ",", "epoch_i", ",", "' ]'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_accu", ",", "train_loss_recon", ",", "train_loss_kl", "=", "train_epoch", "(", "\n", "model", ",", "training_data", ",", "optimizer", ",", "device", ",", "smoothing", "=", "opt", ".", "label_smoothing", ",", "lambda_kl", "=", "beta_this_epoch", "\n", ")", "\n", "print", "(", "' -(Trianing) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, train_loss_recon: {recon: 8.5f}, train_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", ",", "\n", "recon", "=", "train_loss_recon", ",", "kl", "=", "train_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "valid_loss", ",", "valid_accu", ",", "valid_loss_recon", ",", "valid_loss_kl", "=", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", "\n", "print", "(", "' -(Validation) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, valid_loss_recon: {recon: 8.5f}, valid_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", ",", "\n", "recon", "=", "valid_loss_recon", ",", "kl", "=", "valid_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "valid_accus", "+=", "[", "valid_accu", "]", "\n", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'settings'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch_i", "\n", "}", "\n", "if", "opt", ".", "save_model", ":", "\n", "            ", "if", "opt", ".", "save_mode", "==", "'all'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'_accu_{accu:3.3f}.chkpt'", ".", "format", "(", "accu", "=", "100", "*", "valid_accu", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "", "if", "opt", ".", "save_mode", "==", "'best'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'.chkpt'", "\n", "if", "valid_accu", ">=", "max", "(", "valid_accus", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "' -[Info] The check point file has been updated.'", ")", "\n", "sample_generation", "(", "model", ",", "training_data", ",", "idx2word", ",", "device", ")", "\n", "\n", "", "", "", "if", "log_train_file", "and", "log_valid_file", ":", "\n", "            ", "with", "open", "(", "log_train_file", ",", "'a'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'a'", ")", "as", "log_vf", ":", "\n", "                ", "log_tf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "train_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", "\n", ")", ")", "\n", "log_vf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "valid_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.sample_generation": [[197, 213], ["print", "print", "print", "print", "print", "map", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "model.predict", "show_case.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.to", "equ_nodes[].unsqueeze", "equ_adj_matrixs[].unsqueeze", "equ_node_lens[].unsqueeze", "sns_nodes[].unsqueeze", "sns_adj_matrixs[].unsqueeze", "sns_node_lens[].unsqueeze", "scene[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "", "", "", "def", "sample_generation", "(", "model", ",", "train_loader", ",", "idx2word", ",", "device", ")", ":", "\n", "    ", "for", "batch", "in", "train_loader", ":", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "", "print", "(", "'show case during training'", ")", "\n", "show_case", ",", "show_attn", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "dec_ids", ",", "attn_matrix", "=", "model", ".", "predict", "(", "\n", "input_equ_nodes", "=", "equ_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_equ_matrix", "=", "equ_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "equ_node_lens", "=", "equ_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "input_sns_nodes", "=", "sns_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_sns_matrix", "=", "sns_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "sns_node_lens", "=", "sns_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "scene", "=", "scene", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "device", "=", "device", ",", "max_tgt_len", "=", "50", ")", "\n", "show_case", ".", "append", "(", "''", ".", "join", "(", "idx2word", "[", "x", "]", "for", "x", "in", "dec_ids", ")", ")", "\n", "", "", "print", "(", "'one attention matrix is {}'", ".", "format", "(", "torch", ".", "stack", "(", "attn_matrix", ",", "1", ")", ")", ")", "\n", "print", "(", "show_case", "[", "0", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "1", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "2", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.main": [[214, 272], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "argparse.ArgumentParser.parse_args", "torch.load", "torch.load", "torch.load", "torch.load", "max", "train_res_seed_16.prepare_dataloaders", "print", "torch.device", "torch.device", "torch.device", "torch.device", "model.dual_graph_vae_2.Graph2seq().to", "model.dual_graph_vae_2.ScheduledOptim", "train_res_seed_16.train", "torch.Adam", "len", "model.dual_graph_vae_2.Graph2seq", "filter", "[].items", "Graph2seq().to.parameters"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.prepare_dataloaders", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "'''Main function'''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "\"./processed_data/dual_graph_rev_res.pt\"", ")", "\n", "parser", ".", "add_argument", "(", "'-epoch'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "#node dim same as this", "\n", "parser", ".", "add_argument", "(", "'-n_hop'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'-hidden_size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'-z_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'-teacher_forcing'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "500", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-log'", ",", "default", "=", "'./logs/MaKE_res_seed_16_regular'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'./saved_model/MaKE_res_seed_16_regular'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_mode'", ",", "type", "=", "str", ",", "choices", "=", "[", "'all'", ",", "'best'", "]", ",", "default", "=", "'best'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-no_cuda'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-label_smoothing'", ",", "action", "=", "'store_true'", ")", "\n", "torch", ".", "manual_seed", "(", "16", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "not", "opt", ".", "no_cuda", "\n", "# god seed", "\n", "\n", "#====== Loading Dataset =====#", "\n", "data", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "opt", ".", "max_token_seq_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "data", "[", "'train'", "]", "[", "'ref'", "]", ")", "\n", "\n", "training_data", ",", "validation_data", "=", "prepare_dataloaders", "(", "data", ",", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "training_data", ".", "dataset", ".", "src_vocab_size", "\n", "\n", "#======= Preparing model ====#", "\n", "print", "(", "opt", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:0'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "# device = torch.device('cpu')", "\n", "graph2seq", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "opt", ".", "z_dim", ",", "\n", "output_size", "=", "opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "optimizer", "=", "ScheduledOptim", "(", "\n", "optim", ".", "Adam", "(", "\n", "filter", "(", "lambda", "x", ":", "x", ".", "requires_grad", ",", "graph2seq", ".", "parameters", "(", ")", ")", ",", "\n", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-09", ")", ",", "\n", "opt", ".", "hidden_size", ",", "opt", ".", "n_warmup_steps", "\n", ")", "\n", "idx2word", "=", "{", "value", ":", "item", "for", "item", ",", "value", "in", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ".", "items", "(", ")", "}", "\n", "train", "(", "graph2seq", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "device", ",", "idx2word", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res_seed_16.prepare_dataloaders": [[273, 308], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataset_dual.MyDataset", "dataset_dual.MyDataset"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "data", ",", "opt", ")", ":", "\n", "# =====Prepareing DataLoader=====", "\n", "    ", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'train'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'train'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'train'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'train'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'train'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'train'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "20", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "True", "\n", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'dev'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'dev'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'dev'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'dev'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'dev'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'dev'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "20", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.cal_performence": [[21, 32], ["train_with_reg.cal_loss", "gold.contiguous().view.contiguous().view", "gold.contiguous().view.ne", "pred.eq", "n_correct.masked_select().sum().item.masked_select().sum().item", "pred.max", "gold.contiguous().view.contiguous", "n_correct.masked_select().sum().item.masked_select().sum", "n_correct.masked_select().sum().item.masked_select"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_loss"], ["def", "cal_performence", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Apply label smooth if needed\n    \"\"\"", "\n", "loss", ",", "loss_recon", ",", "loss_kl", ",", "loss_sparse", "=", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "pred", "=", "pred", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_correct", "=", "pred", ".", "eq", "(", "gold", ")", "\n", "n_correct", "=", "n_correct", ".", "masked_select", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", ",", "loss_sparse", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.gaussian_kld": [[33, 38], ["torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "exp", "(", "recog_logvar", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", ",", "1", ")", "\n", "return", "torch", ".", "mean", "(", "kld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.sparse_resularizer": [[39, 43], ["attn_matrix.view.view", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.abs", "torch.abs", "torch.abs", "torch.abs", "torch.sum", "torch.sum", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "sparse_resularizer", "(", "attn_matrix", ")", ":", "\n", "    ", "attn_matrix", "=", "attn_matrix", ".", "view", "(", "-", "1", ",", "attn_matrix", ".", "shape", "[", "-", "1", "]", ")", "\n", "L_sparse", "=", "0.5", "*", "torch", ".", "sum", "(", "torch", ".", "abs", "(", "torch", ".", "sum", "(", "attn_matrix", "**", "2", ",", "1", ")", "-", "1", ")", ",", "0", ")", "\n", "return", "L_sparse", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.cal_loss": [[48, 58], ["gold.contiguous().view.contiguous().view", "torch.cross_entropy", "train_with_reg.gaussian_kld", "train_with_reg.sparse_resularizer", "gold.contiguous().view.contiguous"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.gaussian_kld", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.sparse_resularizer"], ["", "def", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Calculate cross entropy loss, apply label smoothing if needed\n    \"\"\"", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss_recon", "=", "F", ".", "cross_entropy", "(", "pred", ",", "gold", ",", "ignore_index", "=", "Constants", ".", "PAD", ",", "reduction", "=", "'sum'", ")", "\n", "# loss_kl = lambda_kl*-0.5 * torch.sum(1 + log_var - mu.pow(2)-log_var.exp())", "\n", "loss_kl", "=", "lambda_kl", "*", "gaussian_kld", "(", "mu_posterior", ",", "log_var_posterior", ",", "mu_prior", ",", "log_var_prior", ")", "\n", "loss_sparse", "=", "0.05", "*", "sparse_resularizer", "(", "plan_attns", ")", "\n", "return", "loss_recon", "+", "loss_kl", "+", "loss_sparse", ",", "loss_recon", ",", "loss_kl", ",", "loss_sparse", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.train_epoch": [[59, 108], ["model.train", "tqdm.tqdm", "map", "optimizer.zero_grad", "model", "train_with_reg.cal_performence", "loss.backward", "optimizer.step", "scheduler.step", "loss.item", "loss_kl.item", "loss_recon.item", "loss_sparse.item", "len", "gold.ne", "gold.ne.sum().item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", ",", "lambda_kl", ")", ":", "\n", "    ", "'''Epoch operation in training phase'''", "\n", "model", ".", "train", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", ",", "total_loss_sparse", "=", "0", ",", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "\n", "for", "batch", "in", "tqdm", "(", "training_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Training) '", ",", "leave", "=", "False", ")", ":", "\n", "\n", "# prepare data", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "#print('src_seq shape:', src_seq.shape)", "\n", "#print('src_pos shape:', src_pos.shape)", "\n", "#print('tgt_seq shape:', tgt_seq.shape)", "\n", "#print('tgt_pos shape:', tgt_pos.shape)", "\n", "gold", "=", "tgt_seq", "\n", "# forward", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "#print('pred shape', pred.shape)", "\n", "#print('gold shape', gold.shape)", "\n", "\n", "# backward", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", ",", "loss_sparse", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "#print(loss)", "\n", "#print(n_correct)", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# update parameters", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "total_loss_sparse", "+=", "loss_sparse", ".", "item", "(", ")", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", ",", "total_loss_sparse", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.eval_epoch": [[110, 143], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "map", "model", "train_with_reg.cal_performence", "loss.item", "gold.ne", "gold.ne.sum().item", "loss_kl.item", "len", "loss_recon.item", "loss_sparse.item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", ":", "\n", "    ", "'''Epoch operation in evaluation phase'''", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", ",", "total_loss_sparse", "=", "0", ",", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "validation_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Validation) '", ",", "leave", "=", "False", ")", ":", "\n", "# prepare data", "\n", "            ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "gold", "=", "tgt_seq", "\n", "\n", "# forward", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", ",", "loss_sparse", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", "=", "1", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "total_loss_sparse", "+=", "loss_sparse", ".", "item", "(", ")", "\n", "\n", "", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", ",", "total_loss_sparse", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.train": [[145, 198], ["utils.cyclical_annealing.frange_cycle_linear", "range", "print", "print", "time.time", "train_with_reg.train_epoch", "print", "time.time", "train_with_reg.eval_epoch", "print", "model.state_dict", "open", "open", "log_tf.write", "log_vf.write", "torch.save", "torch.save", "torch.save", "torch.save", "open", "open", "log_tf.write", "log_vf.write", "math.exp", "math.exp", "max", "torch.save", "torch.save", "torch.save", "torch.save", "print", "train_with_reg.sample_generation", "min", "min", "time.time", "time.time", "math.exp", "math.exp", "min", "min"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_linear", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.eval_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.sample_generation"], ["", "def", "train", "(", "model", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", ":", "\n", "    ", "'''Start training'''", "\n", "log_train_file", "=", "None", "\n", "log_valid_file", "=", "None", "\n", "beta_epochs", "=", "frange_cycle_linear", "(", "start", "=", "0.0", ",", "stop", "=", "1.0", ",", "n_epoch", "=", "opt", ".", "epoch", ")", "\n", "\n", "if", "opt", ".", "log", ":", "\n", "        ", "log_train_file", "=", "opt", ".", "log", "+", "'.train.log'", "\n", "log_valid_file", "=", "opt", ".", "log", "+", "'.valid.log'", "\n", "\n", "print", "(", "'[Info] Training performence will be written to file: {} and {}'", ".", "format", "(", "log_train_file", ",", "log_valid_file", ")", ")", "\n", "with", "open", "(", "log_train_file", ",", "'w'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'w'", ")", "as", "log_vf", ":", "\n", "            ", "log_tf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "log_vf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "", "", "valid_accus", "=", "[", "]", "\n", "for", "epoch_i", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "beta_this_epoch", "=", "beta_epochs", "[", "epoch_i", "]", "\n", "print", "(", "'[ Epoch'", ",", "epoch_i", ",", "' ]'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_accu", ",", "train_loss_recon", ",", "train_loss_kl", ",", "train_loss_sparse", "=", "train_epoch", "(", "\n", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", "=", "opt", ".", "label_smoothing", ",", "lambda_kl", "=", "beta_this_epoch", "\n", ")", "\n", "print", "(", "' -(Trianing) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, train_loss_recon: {recon: 8.5f}, train_loss_kl:{kl: 8.5f}, train_loss_sparse:{sp: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", ",", "\n", "recon", "=", "train_loss_recon", ",", "kl", "=", "train_loss_kl", ",", "sp", "=", "train_loss_sparse", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "valid_loss", ",", "valid_accu", ",", "valid_loss_recon", ",", "valid_loss_kl", ",", "valid_loss_sparse", "=", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", "\n", "print", "(", "' -(Validation) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, valid_loss_recon: {recon: 8.5f}, valid_loss_kl:{kl: 8.5f}, valid_loss_sparse: {sp: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", ",", "\n", "recon", "=", "valid_loss_recon", ",", "kl", "=", "valid_loss_kl", ",", "sp", "=", "valid_loss_sparse", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "valid_accus", "+=", "[", "valid_accu", "]", "\n", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'settings'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch_i", "\n", "}", "\n", "if", "opt", ".", "save_model", ":", "\n", "            ", "if", "opt", ".", "save_mode", "==", "'all'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'_accu_{accu:3.3f}.chkpt'", ".", "format", "(", "accu", "=", "100", "*", "valid_accu", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "", "if", "opt", ".", "save_mode", "==", "'best'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'.chkpt'", "\n", "if", "valid_accu", ">=", "max", "(", "valid_accus", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "' -[Info] The check point file has been updated.'", ")", "\n", "sample_generation", "(", "model", ",", "training_data", ",", "idx2word", ",", "device", ")", "\n", "\n", "", "", "", "if", "log_train_file", "and", "log_valid_file", ":", "\n", "            ", "with", "open", "(", "log_train_file", ",", "'a'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'a'", ")", "as", "log_vf", ":", "\n", "                ", "log_tf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "train_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", "\n", ")", ")", "\n", "log_vf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "valid_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.sample_generation": [[200, 216], ["print", "print", "print", "print", "print", "map", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "model.predict", "show_case.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.to", "equ_nodes[].unsqueeze", "equ_adj_matrixs[].unsqueeze", "equ_node_lens[].unsqueeze", "sns_nodes[].unsqueeze", "sns_adj_matrixs[].unsqueeze", "sns_node_lens[].unsqueeze", "scene[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "", "", "", "def", "sample_generation", "(", "model", ",", "train_loader", ",", "idx2word", ",", "device", ")", ":", "\n", "    ", "for", "batch", "in", "train_loader", ":", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "", "print", "(", "'show case during training'", ")", "\n", "show_case", ",", "show_attn", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "dec_ids", ",", "attn_matrix", "=", "model", ".", "predict", "(", "\n", "input_equ_nodes", "=", "equ_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_equ_matrix", "=", "equ_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "equ_node_lens", "=", "equ_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "input_sns_nodes", "=", "sns_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_sns_matrix", "=", "sns_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "sns_node_lens", "=", "sns_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "scene", "=", "scene", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "device", "=", "device", ",", "max_tgt_len", "=", "50", ")", "\n", "show_case", ".", "append", "(", "''", ".", "join", "(", "idx2word", "[", "x", "]", "for", "x", "in", "dec_ids", ")", ")", "\n", "", "", "print", "(", "'one attention matrix is {}'", ".", "format", "(", "torch", ".", "stack", "(", "attn_matrix", ",", "1", ")", ")", ")", "\n", "print", "(", "show_case", "[", "0", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "1", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "2", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.main": [[217, 289], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "torch.load", "torch.load", "torch.load", "torch.load", "max", "train_with_reg.prepare_dataloaders", "print", "torch.device", "torch.device", "torch.device", "torch.device", "model.dual_graph_vae_2.Graph2seq().to", "transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "train_with_reg.train", "Graph2seq().to.parameters", "len", "len", "model.dual_graph_vae_2.Graph2seq", "[].items"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.prepare_dataloaders", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "'''Main function'''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "'./processed_data/dual_graph_rev_res.pt'", ")", "\n", "parser", ".", "add_argument", "(", "'-epoch'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "256", ")", "#node dim same as this", "\n", "parser", ".", "add_argument", "(", "'-n_hop'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'-hidden_size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'-z_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'-teacher_forcing'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "2000", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-log'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-save_mode'", ",", "type", "=", "str", ",", "choices", "=", "[", "'all'", ",", "'best'", "]", ",", "default", "=", "'best'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-no_cuda'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-label_smoothing'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "not", "opt", ".", "no_cuda", "\n", "\n", "#====== Loading Dataset =====#", "\n", "data", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "opt", ".", "max_token_seq_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "data", "[", "'train'", "]", "[", "'ref'", "]", ")", "\n", "\n", "training_data", ",", "validation_data", "=", "prepare_dataloaders", "(", "data", ",", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "training_data", ".", "dataset", ".", "src_vocab_size", "\n", "\n", "#======= Preparing model ====#", "\n", "print", "(", "opt", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:3'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "# device = torch.device('cpu')", "\n", "graph2seq", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "opt", ".", "z_dim", ",", "\n", "output_size", "=", "opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "\n", "# optimizer = ScheduledOptim(", "\n", "#     optim.Adam(", "\n", "#         filter(lambda x: x.requires_grad, graph2seq.parameters()),", "\n", "#         betas=(0.9,0.98),eps=1e-09),", "\n", "#     opt.hidden_size, opt.n_warmup_steps", "\n", "# )", "\n", "optimizer", "=", "AdamW", "(", "graph2seq", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "1e-3", ",", "# args.learning_rate - default is 5e-5, our notebook had 2e-5", "\n", "eps", "=", "1e-8", "# args.adam_epsilon  - default is 1e-8.", "\n", ")", "\n", "# Number of training epochs (authors recommend between 2 and 4)", "\n", "epochs", "=", "opt", ".", "epoch", "\n", "\n", "# Total number of training steps is number of batches * number of epochs.", "\n", "total_steps", "=", "len", "(", "training_data", ")", "*", "epochs", "\n", "\n", "# Create the learning rate scheduler.", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "num_warmup_steps", "=", "0", ",", "# Default value in run_glue.py", "\n", "num_training_steps", "=", "total_steps", ")", "\n", "# train(model, tokenizer, train_loader, valid_loader, optimizer, scheduler, device, opt)", "\n", "\n", "idx2word", "=", "{", "value", ":", "item", "for", "item", ",", "value", "in", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ".", "items", "(", ")", "}", "\n", "train", "(", "graph2seq", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_with_reg.prepare_dataloaders": [[290, 325], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataset_dual.MyDataset", "dataset_dual.MyDataset"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "data", ",", "opt", ")", ":", "\n", "# =====Prepareing DataLoader=====", "\n", "    ", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'train'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'train'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'train'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'train'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'train'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'train'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "True", "\n", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'dev'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'dev'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'dev'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'dev'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'dev'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'dev'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.cal_performence": [[21, 32], ["train_no_symbolic.cal_loss", "gold.contiguous().view.contiguous().view", "gold.contiguous().view.ne", "pred.eq", "n_correct.masked_select().sum().item.masked_select().sum().item", "pred.max", "gold.contiguous().view.contiguous", "n_correct.masked_select().sum().item.masked_select().sum", "n_correct.masked_select().sum().item.masked_select"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_loss"], ["def", "cal_performence", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Apply label smooth if needed\n    \"\"\"", "\n", "loss", ",", "loss_recon", ",", "loss_kl", "=", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "pred", "=", "pred", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_correct", "=", "pred", ".", "eq", "(", "gold", ")", "\n", "n_correct", "=", "n_correct", ".", "masked_select", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.gaussian_kld": [[33, 38], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "exp", "(", "recog_logvar", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", ",", "1", ")", "\n", "return", "torch", ".", "sum", "(", "kld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.cal_loss": [[48, 58], ["gold.contiguous().view.contiguous().view", "torch.cross_entropy", "train_no_symbolic.gaussian_kld", "gold.contiguous().view.contiguous"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.gaussian_kld"], ["", "def", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Calculate cross entropy loss, apply label smoothing if needed\n    \"\"\"", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss_recon", "=", "F", ".", "cross_entropy", "(", "pred", ",", "gold", ",", "ignore_index", "=", "Constants", ".", "PAD", ",", "reduction", "=", "'sum'", ")", "\n", "# loss_kl = lambda_kl*-0.5 * torch.sum(1 + log_var - mu.pow(2)-log_var.exp())", "\n", "loss_kl", "=", "lambda_kl", "*", "gaussian_kld", "(", "mu_posterior", ",", "log_var_posterior", ",", "mu_prior", ",", "log_var_prior", ")", "\n", "# loss_sparse = sparse_resularizer(plan_attns)", "\n", "return", "loss_recon", "+", "loss_kl", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.train_epoch": [[59, 108], ["model.train", "tqdm.tqdm", "map", "optimizer.zero_grad", "model", "train_no_symbolic.cal_performence", "loss.backward", "optimizer.step", "scheduler.step", "loss.item", "loss_kl.item", "loss_recon.item", "len", "gold.ne", "gold.ne.sum().item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", ",", "lambda_kl", ")", ":", "\n", "    ", "'''Epoch operation in training phase'''", "\n", "model", ".", "train", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "\n", "for", "batch", "in", "tqdm", "(", "training_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Training) '", ",", "leave", "=", "False", ")", ":", "\n", "\n", "# prepare data", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "#print('src_seq shape:', src_seq.shape)", "\n", "#print('src_pos shape:', src_pos.shape)", "\n", "#print('tgt_seq shape:', tgt_seq.shape)", "\n", "#print('tgt_pos shape:', tgt_pos.shape)", "\n", "gold", "=", "tgt_seq", "\n", "# forward", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "#print('pred shape', pred.shape)", "\n", "#print('gold shape', gold.shape)", "\n", "\n", "# backward", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "#print(loss)", "\n", "#print(n_correct)", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# update parameters", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.eval_epoch": [[110, 143], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "map", "model", "train_no_symbolic.cal_performence", "loss.item", "gold.ne", "gold.ne.sum().item", "loss_kl.item", "len", "loss_recon.item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", ":", "\n", "    ", "'''Epoch operation in evaluation phase'''", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "validation_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Validation) '", ",", "leave", "=", "False", ")", ":", "\n", "# prepare data", "\n", "            ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "gold", "=", "tgt_seq", "\n", "\n", "# forward", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", "=", "1", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "\n", "", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.train": [[145, 198], ["utils.cyclical_annealing.frange_cycle_linear", "range", "print", "print", "time.time", "train_no_symbolic.train_epoch", "print", "time.time", "train_no_symbolic.eval_epoch", "print", "model.state_dict", "open", "open", "log_tf.write", "log_vf.write", "torch.save", "torch.save", "torch.save", "torch.save", "open", "open", "log_tf.write", "log_vf.write", "math.exp", "math.exp", "max", "torch.save", "torch.save", "torch.save", "torch.save", "print", "train_no_symbolic.sample_generation", "min", "min", "time.time", "time.time", "math.exp", "math.exp", "min", "min"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_linear", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.eval_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.sample_generation"], ["", "def", "train", "(", "model", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", ":", "\n", "    ", "'''Start training'''", "\n", "log_train_file", "=", "None", "\n", "log_valid_file", "=", "None", "\n", "beta_epochs", "=", "frange_cycle_linear", "(", "start", "=", "0.0", ",", "stop", "=", "1.0", ",", "n_epoch", "=", "opt", ".", "epoch", ")", "\n", "\n", "if", "opt", ".", "log", ":", "\n", "        ", "log_train_file", "=", "opt", ".", "log", "+", "'.train.log'", "\n", "log_valid_file", "=", "opt", ".", "log", "+", "'.valid.log'", "\n", "\n", "print", "(", "'[Info] Training performence will be written to file: {} and {}'", ".", "format", "(", "log_train_file", ",", "log_valid_file", ")", ")", "\n", "with", "open", "(", "log_train_file", ",", "'w'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'w'", ")", "as", "log_vf", ":", "\n", "            ", "log_tf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "log_vf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "", "", "valid_accus", "=", "[", "]", "\n", "for", "epoch_i", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "beta_this_epoch", "=", "beta_epochs", "[", "epoch_i", "]", "\n", "print", "(", "'[ Epoch'", ",", "epoch_i", ",", "' ]'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_accu", ",", "train_loss_recon", ",", "train_loss_kl", "=", "train_epoch", "(", "\n", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", "=", "opt", ".", "label_smoothing", ",", "lambda_kl", "=", "beta_this_epoch", "\n", ")", "\n", "print", "(", "' -(Trianing) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, train_loss_recon: {recon: 8.5f}, train_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", ",", "\n", "recon", "=", "train_loss_recon", ",", "kl", "=", "train_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "valid_loss", ",", "valid_accu", ",", "valid_loss_recon", ",", "valid_loss_kl", "=", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", "\n", "print", "(", "' -(Validation) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, valid_loss_recon: {recon: 8.5f}, valid_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", ",", "\n", "recon", "=", "valid_loss_recon", ",", "kl", "=", "valid_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "valid_accus", "+=", "[", "valid_accu", "]", "\n", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'settings'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch_i", "\n", "}", "\n", "if", "opt", ".", "save_model", ":", "\n", "            ", "if", "opt", ".", "save_mode", "==", "'all'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'_accu_{accu:3.3f}.chkpt'", ".", "format", "(", "accu", "=", "100", "*", "valid_accu", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "", "if", "opt", ".", "save_mode", "==", "'best'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'.chkpt'", "\n", "if", "valid_accu", ">=", "max", "(", "valid_accus", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "' -[Info] The check point file has been updated.'", ")", "\n", "sample_generation", "(", "model", ",", "training_data", ",", "idx2word", ",", "device", ")", "\n", "\n", "", "", "", "if", "log_train_file", "and", "log_valid_file", ":", "\n", "            ", "with", "open", "(", "log_train_file", ",", "'a'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'a'", ")", "as", "log_vf", ":", "\n", "                ", "log_tf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "train_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", "\n", ")", ")", "\n", "log_vf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "valid_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.sample_generation": [[200, 216], ["print", "print", "print", "print", "print", "map", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "model.predict", "show_case.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.to", "equ_nodes[].unsqueeze", "equ_adj_matrixs[].unsqueeze", "equ_node_lens[].unsqueeze", "sns_nodes[].unsqueeze", "sns_adj_matrixs[].unsqueeze", "sns_node_lens[].unsqueeze", "scene[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "", "", "", "def", "sample_generation", "(", "model", ",", "train_loader", ",", "idx2word", ",", "device", ")", ":", "\n", "    ", "for", "batch", "in", "train_loader", ":", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "", "print", "(", "'show case during training'", ")", "\n", "show_case", ",", "show_attn", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "dec_ids", ",", "attn_matrix", "=", "model", ".", "predict", "(", "\n", "input_equ_nodes", "=", "equ_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_equ_matrix", "=", "equ_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "equ_node_lens", "=", "equ_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "input_sns_nodes", "=", "sns_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_sns_matrix", "=", "sns_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "sns_node_lens", "=", "sns_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "scene", "=", "scene", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "device", "=", "device", ",", "max_tgt_len", "=", "50", ")", "\n", "show_case", ".", "append", "(", "''", ".", "join", "(", "idx2word", "[", "x", "]", "for", "x", "in", "dec_ids", ")", ")", "\n", "", "", "print", "(", "'one attention matrix is {}'", ".", "format", "(", "torch", ".", "stack", "(", "attn_matrix", ",", "1", ")", ")", ")", "\n", "print", "(", "show_case", "[", "0", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "1", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "2", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.main": [[217, 293], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "argparse.ArgumentParser.parse_args", "torch.load", "torch.load", "torch.load", "torch.load", "max", "print", "train_no_symbolic.prepare_dataloaders", "print", "print", "torch.device", "torch.device", "torch.device", "torch.device", "model.model_no_symbolic.Graph2seq().to", "transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "train_no_symbolic.train", "Graph2seq().to.parameters", "len", "len", "model.model_no_symbolic.Graph2seq", "[].items"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.prepare_dataloaders", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "'''Main function'''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "'./processed_data/dual_graph_rev_res.pt'", ")", "\n", "parser", ".", "add_argument", "(", "'-epoch'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "#node dim same as this", "\n", "parser", ".", "add_argument", "(", "'-n_hop'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'-hidden_size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'-z_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'-teacher_forcing'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "500", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-log'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "None", ")", "\n", "parser", ".", "add_argument", "(", "'-save_mode'", ",", "type", "=", "str", ",", "choices", "=", "[", "'all'", ",", "'best'", "]", ",", "default", "=", "'best'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-no_cuda'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-label_smoothing'", ",", "action", "=", "'store_true'", ")", "\n", "torch", ".", "manual_seed", "(", "32", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "not", "opt", ".", "no_cuda", "\n", "# god seed", "\n", "\n", "#====== Loading Dataset =====#", "\n", "data", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "opt", ".", "max_token_seq_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "data", "[", "'train'", "]", "[", "'ref'", "]", ")", "\n", "print", "(", "'max token length is:'", ",", "opt", ".", "max_token_seq_len", ")", "\n", "\n", "training_data", ",", "validation_data", "=", "prepare_dataloaders", "(", "data", ",", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "training_data", ".", "dataset", ".", "src_vocab_size", "\n", "print", "(", "'vocab size is:'", ",", "opt", ".", "vocab_size", ")", "\n", "\n", "#======= Preparing model ====#", "\n", "print", "(", "opt", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:4'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "# device = torch.device('cpu')", "\n", "graph2seq", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "opt", ".", "z_dim", ",", "\n", "output_size", "=", "opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "# optimizer = ScheduledOptim(", "\n", "#     optim.Adam(", "\n", "#         filter(lambda x: x.requires_grad, graph2seq.parameters()),", "\n", "#         betas=(0.9,0.98),eps=1e-09),", "\n", "#     opt.hidden_size, opt.n_warmup_steps", "\n", "# )", "\n", "optimizer", "=", "AdamW", "(", "graph2seq", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "1e-3", ",", "# args.learning_rate - default is 5e-5, our notebook had 2e-5", "\n", "eps", "=", "1e-8", "# args.adam_epsilon  - default is 1e-8.", "\n", ")", "\n", "# Number of training epochs (authors recommend between 2 and 4)", "\n", "epochs", "=", "opt", ".", "epoch", "\n", "\n", "# Total number of training steps is number of batches * number of epochs.", "\n", "total_steps", "=", "len", "(", "training_data", ")", "*", "epochs", "\n", "\n", "# Create the learning rate scheduler.", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "num_warmup_steps", "=", "0", ",", "# Default value in run_glue.py", "\n", "num_training_steps", "=", "total_steps", ")", "\n", "# train(model, tokenizer, train_loader, valid_loader, optimizer, scheduler, device, opt)", "\n", "\n", "idx2word", "=", "{", "value", ":", "item", "for", "item", ",", "value", "in", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ".", "items", "(", ")", "}", "\n", "train", "(", "graph2seq", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_symbolic.prepare_dataloaders": [[294, 329], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataset_dual.MyDataset", "dataset_dual.MyDataset"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "data", ",", "opt", ")", ":", "\n", "# =====Prepareing DataLoader=====", "\n", "    ", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'train'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'train'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'train'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'train'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'train'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'train'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "True", "\n", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'dev'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'dev'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'dev'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'dev'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'dev'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'dev'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.Constants.__init__": [[344, 383], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "BOS_WORD", "=", "'<s>'", "\n", "self", ".", "EOS_WORD", "=", "'</s>'", "\n", "self", ".", "PAD_WORD", "=", "'<blank>'", "\n", "self", ".", "UNK_WORD", "=", "'<unk>'", "\n", "self", ".", "eq1_x_index_WORD", "=", "'eq_one_x_index'", "\n", "self", ".", "eq2_x_index_WORD", "=", "'eq_two_x_index'", "\n", "self", ".", "eq1_y_index_WORD", "=", "'eq_one_y_index'", "\n", "self", ".", "eq2_y_index_WORD", "=", "'eq_two_y_index'", "\n", "self", ".", "eq1_right_num1_WORD", "=", "'eq_one_right_num_one'", "\n", "self", ".", "eq2_right_num1_WORD", "=", "'eq_two_right_num_one'", "\n", "self", ".", "eq1_right_num2_WORD", "=", "'eq_one_right_num_two'", "\n", "self", ".", "eq2_right_num2_WORD", "=", "'eq_two_right_num_two'", "\n", "self", ".", "x_entity_WORD", "=", "'x_entity'", "\n", "self", ".", "y_entity_WORD", "=", "'y_entity'", "\n", "self", ".", "head_info_unit_WORD", "=", "'head_info_unit'", "\n", "self", ".", "jiao_info_unit_WORD", "=", "'jiao_info_unit'", "\n", "self", ".", "jiao_info_entity_WORD", "=", "'jiao_info_entity'", "\n", "self", ".", "head_info_entity_WORD", "=", "'head_info_entity'", "\n", "#         self.dummy_equal_WORD = 'dummy_cal'", "\n", "\n", "self", ".", "PAD", "=", "0", "\n", "self", ".", "UNK", "=", "1", "\n", "self", ".", "BOS", "=", "2", "\n", "self", ".", "EOS", "=", "3", "\n", "self", ".", "eq1_x_index", "=", "4", "\n", "self", ".", "eq2_x_index", "=", "5", "\n", "self", ".", "eq1_y_index", "=", "6", "\n", "self", ".", "eq2_y_index", "=", "7", "\n", "self", ".", "eq1_right_num1", "=", "8", "\n", "self", ".", "eq2_right_num1", "=", "9", "\n", "self", ".", "eq1_right_num2", "=", "10", "\n", "self", ".", "eq2_right_num2", "=", "11", "\n", "self", ".", "x_entity", "=", "12", "\n", "self", ".", "y_entity", "=", "13", "\n", "self", ".", "head_info_unit", "=", "14", "\n", "self", ".", "jiao_info_unit", "=", "15", "\n", "self", ".", "jiao_info_entity", "=", "16", "\n", "self", ".", "head_info_entity", "=", "17", "\n", "#         self.dummy_equal = 18", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_scene": [[8, 18], ["scene.replace.replace", "re.split", "edge_0.split", "edge_1[].split"], "function", ["None"], ["def", "process_scene", "(", "scene", ")", ":", "\n", "    ", "scene", "=", "scene", ".", "replace", "(", "' '", ",", "''", ")", "\n", "map_scene", "=", "{", "}", "\n", "edge_0", ",", "edge_1", "=", "re", ".", "split", "(", "r'\\),|\\)\uff0c'", ",", "scene", ")", "\n", "ent0", ",", "ent1", "=", "edge_0", ".", "split", "(", "'('", ")", "\n", "map_scene", "[", "ent0", "]", "=", "ent1", "\n", "\n", "ent2", ",", "ent3", "=", "edge_1", "[", ":", "-", "1", "]", ".", "split", "(", "'('", ")", "\n", "map_scene", "[", "ent2", "]", "=", "ent3", "\n", "return", "map_scene", "\n", "", "def", "process_var", "(", "var", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_var": [[18, 26], ["re.split", "edge_0.split", "ent0.replace", "edge_1[].split", "ent2.replace"], "function", ["None"], ["", "def", "process_var", "(", "var", ")", ":", "\n", "    ", "map_var", "=", "{", "}", "\n", "edge_0", ",", "edge_1", "=", "re", ".", "split", "(", "r'\\),|\\)\uff0c'", ",", "var", ")", "\n", "ent0", ",", "ent1", "=", "edge_0", ".", "split", "(", "'('", ")", "\n", "map_var", "[", "ent1", "]", "=", "ent0", ".", "replace", "(", "' '", ",", "''", ")", "\n", "ent2", ",", "ent3", "=", "edge_1", "[", ":", "-", "1", "]", ".", "split", "(", "'('", ")", "\n", "map_var", "[", "ent3", "]", "=", "ent2", ".", "replace", "(", "' '", ",", "''", ")", "\n", "return", "map_var", "\n", "", "def", "process_mr", "(", "mr", ",", "var", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_mr": [[26, 36], ["mr.split", "preprocess_data.process_var", "one.split"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_var"], ["", "def", "process_mr", "(", "mr", ",", "var", ")", ":", "\n", "    ", "splited_mr", "=", "mr", ".", "split", "(", "','", ")", "\n", "mr_dict", "=", "{", "}", "\n", "for", "one", "in", "splited_mr", ":", "\n", "        ", "ent0", ",", "ent1", "=", "one", ".", "split", "(", "'['", ")", "\n", "mr_dict", "[", "ent0", "]", "=", "ent1", "[", ":", "-", "1", "]", "\n", "", "processed_var", "=", "process_var", "(", "var", ")", "\n", "mr_dict", "[", "'x_ent'", "]", "=", "processed_var", "[", "'x'", "]", "\n", "mr_dict", "[", "'y_ent'", "]", "=", "processed_var", "[", "'y'", "]", "\n", "return", "mr_dict", "\n", "", "def", "fenge_B006", "(", "text", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.fenge_B006": [[36, 39], ["re.split", "x.strip"], "function", ["None"], ["", "def", "fenge_B006", "(", "text", ")", ":", "\n", "    ", "a", "=", "re", ".", "split", "(", "r'(\\+|,|-|\\*|/|=|!=|>=|<=|>|<|\\(|\\)|\\[|\\]|\\\\|\\|\\b\\d+\\w*\\b|[\\u4E00-\\u9FA5]|\\\u2461|\\\u2460|\\\u2462|\\\u2463|\\\u3256|\\:)'", ",", "text", ")", "\n", "return", "[", "x", ".", "strip", "(", ")", "for", "x", "in", "a", "if", "x", "!=", "''", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_equation_mr": [[47, 143], ["preprocess_data.fenge_B006", "preprocess_data.fenge_B006", "preprocess_data.fenge_B006", "preprocess_data.fenge_B006", "len", "one_mr.append", "len", "one_mr.append", "len", "one_mr.append", "len", "one_mr.append", "equation1.find", "one_mr.append", "one_mr.append", "len", "one_mr.append", "one_mr.append", "len", "one_mr.append", "one_mr.append", "one_mr.append", "equation2.find", "one_mr.append", "one_mr.append", "len", "one_mr.append", "one_mr.append", "len", "one_mr.append", "one_mr.append", "one_mr.append", "equation1.find", "one_mr.append", "one_mr.append", "equation2.find", "one_mr.append", "one_mr.append", "splited_left_1[].replace", "splited_left_1[].replace", "splited_left_2[].replace", "splited_left_2[].replace", "splited_left_1[].replace", "splited_left_1[].replace", "splited_left_2[].replace", "splited_left_2[].replace"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.fenge_B006", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.fenge_B006", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.fenge_B006", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.fenge_B006"], ["def", "get_equation_mr", "(", "equation1", ",", "equation2", ")", ":", "\n", "    ", "equ1_left", "=", "equation1", "[", ":", "equation1", ".", "find", "(", "'='", ")", "]", "\n", "equ1_right", "=", "equation1", "[", "equation1", ".", "find", "(", "'='", ")", "+", "1", ":", "]", "\n", "splited_left_1", "=", "fenge_B006", "(", "equ1_left", ")", "\n", "splited_right_1", "=", "fenge_B006", "(", "equ1_right", ")", "\n", "one_mr", "=", "[", "]", "\n", "# \u5148\u5904\u7406\u7b2c\u4e00\u4e2a\u5f0f\u5b50\u7684\u5de6\u534a\u90e8\u5206", "\n", "if", "len", "(", "splited_left_1", ")", "==", "3", ":", "\n", "# \u5904\u7406x\u90e8\u5206", "\n", "        ", "if", "splited_left_1", "[", "0", "]", "==", "'x'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq1_x_index[{}]'", ".", "format", "(", "splited_left_1", "[", "0", "]", ".", "replace", "(", "'x'", ",", "''", ")", ")", ")", "\n", "# \u5904\u7406\u4e2d\u95f4\u7684\u90a3\u4e2a\u8fd0\u7b97\u7b26", "\n", "", "one_mr", ".", "append", "(", "'eq1_left_sym2[{}]'", ".", "format", "(", "splited_left_1", "[", "1", "]", ")", ")", "\n", "# \u5904\u7406y\u90e8\u5206", "\n", "if", "splited_left_1", "[", "2", "]", "==", "'y'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq1_y_index[{}]'", ".", "format", "(", "splited_left_1", "[", "2", "]", ".", "replace", "(", "'y'", ",", "''", ")", ")", ")", "\n", "", "", "elif", "len", "(", "splited_left_1", ")", "==", "4", ":", "\n", "# \u6709\u56db\u4e2a\u90e8\u5206\uff0c\u770b\u8d77\u6765\u90fd\u8981\u505a\u586b\u5145", "\n", "# \u7b2c\u4e00\u4e2a\u90e8\u5206\u7684\u7b26\u53f7", "\n", "        ", "one_mr", ".", "append", "(", "'eq1_left_sym1[{}]'", ".", "format", "(", "splited_left_1", "[", "0", "]", ")", ")", "\n", "if", "splited_left_1", "[", "1", "]", "==", "'x'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq1_x_index[{}]'", ".", "format", "(", "splited_left_1", "[", "1", "]", ".", "replace", "(", "'x'", ",", "''", ")", ")", ")", "\n", "# \u7b2c\u4e8c\u4e2a\u90e8\u5206\u7684\u7b26\u53f7", "\n", "", "one_mr", ".", "append", "(", "'eq1_left_sym2[{}]'", ".", "format", "(", "splited_left_1", "[", "2", "]", ")", ")", "\n", "# \u5904\u7406y\u90e8\u5206", "\n", "if", "splited_left_1", "[", "3", "]", "==", "'y'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq1_y_index[{}]'", ".", "format", "(", "splited_left_1", "[", "3", "]", ".", "replace", "(", "'y'", ",", "''", ")", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "'wrong input equation1, check preprocessing'", "\n", "\n", "# \u5904\u7406\u7b2c\u4e00\u4e2a\u5f0f\u5b50\u7684\u53f3\u534a\u90e8\u5206", "\n", "", "if", "len", "(", "splited_right_1", ")", "==", "1", ":", "\n", "# \u53ea\u6709\u4e00\u4e2a\u5b9e\u6570\uff0c\u5e94\u8be5\u5927\u90e8\u5206\u90fd\u662f\u5982\u6b64", "\n", "        ", "one_mr", ".", "append", "(", "'eq1_right_num1[{}]'", ".", "format", "(", "splited_right_1", "[", "0", "]", ")", ")", "\n", "", "elif", "len", "(", "splited_right_1", ")", "==", "3", ":", "\n", "# \u6709\u5b9e\u6570\u7684\u8ba1\u7b97\u5b58\u5728\uff0c\u597d\u5427\uff0c\u90a3\u5c31\u7b97\u4e00\u7b97\u5427", "\n", "        ", "one_mr", ".", "append", "(", "'eq1_right_num1[{}]'", ".", "format", "(", "splited_right_1", "[", "0", "]", ")", ")", "\n", "one_mr", ".", "append", "(", "'eq1_right_sym[{}]'", ".", "format", "(", "splited_right_1", "[", "1", "]", ")", ")", "\n", "one_mr", ".", "append", "(", "'eq1_right_num2[{}]'", ".", "format", "(", "splited_right_1", "[", "2", "]", ")", ")", "\n", "\n", "\n", "", "equ2_left", "=", "equation2", "[", ":", "equation2", ".", "find", "(", "'='", ")", "]", "\n", "equ2_right", "=", "equation2", "[", "equation2", ".", "find", "(", "'='", ")", "+", "1", ":", "]", "\n", "splited_left_2", "=", "fenge_B006", "(", "equ2_left", ")", "\n", "splited_right_2", "=", "fenge_B006", "(", "equ2_right", ")", "\n", "\n", "# \u5148\u5904\u7406\u7b2c\u4e8c\u4e2a\u5f0f\u5b50\u7684\u5de6\u534a\u90e8\u5206", "\n", "if", "len", "(", "splited_left_2", ")", "==", "3", ":", "\n", "# \u5904\u7406x\u90e8\u5206", "\n", "        ", "if", "splited_left_2", "[", "0", "]", "==", "'x'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq2_x_index[{}]'", ".", "format", "(", "splited_left_2", "[", "0", "]", ".", "replace", "(", "'x'", ",", "''", ")", ")", ")", "\n", "# \u5904\u7406\u4e2d\u95f4\u7684\u90a3\u4e2a\u8fd0\u7b97\u7b26", "\n", "", "one_mr", ".", "append", "(", "'eq2_left_sym2[{}]'", ".", "format", "(", "splited_left_2", "[", "1", "]", ")", ")", "\n", "# \u5904\u7406y\u90e8\u5206", "\n", "if", "splited_left_2", "[", "2", "]", "==", "'y'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq2_y_index[{}]'", ".", "format", "(", "splited_left_2", "[", "2", "]", ".", "replace", "(", "'y'", ",", "''", ")", ")", ")", "\n", "", "", "elif", "len", "(", "splited_left_2", ")", "==", "4", ":", "\n", "# \u6709\u56db\u4e2a\u90e8\u5206\uff0c\u770b\u8d77\u6765\u90fd\u8981\u505a\u586b\u5145", "\n", "# \u7b2c\u4e00\u4e2a\u90e8\u5206\u7684\u7b26\u53f7", "\n", "        ", "one_mr", ".", "append", "(", "'eq2_left_sym1[{}]'", ".", "format", "(", "splited_left_2", "[", "0", "]", ")", ")", "\n", "if", "splited_left_2", "[", "1", "]", "==", "'x'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq2_x_index[{}]'", ".", "format", "(", "splited_left_2", "[", "1", "]", ".", "replace", "(", "'x'", ",", "''", ")", ")", ")", "\n", "# \u7b2c\u4e8c\u4e2a\u90e8\u5206\u7684\u7b26\u53f7", "\n", "", "one_mr", ".", "append", "(", "'eq2_left_sym2[{}]'", ".", "format", "(", "splited_left_2", "[", "2", "]", ")", ")", "\n", "# \u5904\u7406y\u90e8\u5206", "\n", "if", "splited_left_2", "[", "3", "]", "==", "'y'", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "one_mr", ".", "append", "(", "'eq2_y_index[{}]'", ".", "format", "(", "splited_left_2", "[", "3", "]", ".", "replace", "(", "'y'", ",", "''", ")", ")", ")", "\n", "", "", "else", ":", "\n", "        ", "raise", "'wrong input equation2, check preprocessing'", "\n", "\n", "# \u5904\u7406\u7b2c\u4e00\u4e2a\u5f0f\u5b50\u7684\u53f3\u534a\u90e8\u5206", "\n", "", "if", "len", "(", "splited_right_2", ")", "==", "1", ":", "\n", "# \u53ea\u6709\u4e00\u4e2a\u5b9e\u6570\uff0c\u5e94\u8be5\u5927\u90e8\u5206\u90fd\u662f\u5982\u6b64", "\n", "        ", "one_mr", ".", "append", "(", "'eq2_right_num1[{}]'", ".", "format", "(", "splited_right_2", "[", "0", "]", ")", ")", "\n", "", "elif", "len", "(", "splited_right_2", ")", "==", "3", ":", "\n", "# \u6709\u5b9e\u6570\u7684\u8ba1\u7b97\u5b58\u5728\uff0c\u597d\u5427\uff0c\u90a3\u5c31\u7b97\u4e00\u7b97\u5427", "\n", "        ", "one_mr", ".", "append", "(", "'eq2_right_num1[{}]'", ".", "format", "(", "splited_right_2", "[", "0", "]", ")", ")", "\n", "one_mr", ".", "append", "(", "'eq2_right_sym[{}]'", ".", "format", "(", "splited_right_2", "[", "1", "]", ")", ")", "\n", "one_mr", ".", "append", "(", "'eq2_right_num2[{}]'", ".", "format", "(", "splited_right_2", "[", "2", "]", ")", ")", "\n", "", "return", "','", ".", "join", "(", "one_mr", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_biparty": [[167, 198], ["None"], "function", ["None"], ["def", "get_biparty", "(", "head", ",", "rel", ",", "tail", ",", "eqn", "=", "'eq1'", ")", ":", "\n", "    ", "one_dummy", "=", "'dummy_cal'", "\n", "one_edge", ",", "one_node", "=", "[", "]", ",", "[", "one_dummy", "]", "\n", "if", "rel", "==", "'+'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head", ",", "'\u548c\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u548c\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "one_dummy", ")", ",", "\n", "(", "one_dummy", ",", "'\u548c\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u548c\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "head", ")", ",", "\n", "(", "tail", ",", "'\u548c\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u548c\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "tail", ")", "]", "\n", "one_node", "+=", "[", "head", ",", "tail", ",", "'\u548c\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "'\u548c\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", "]", "\n", "", "if", "rel", "==", "'-'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "one_dummy", ")", ",", "\n", "(", "one_dummy", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "head", ")", ",", "\n", "(", "tail", ",", "'\u51cf\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u51cf\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "one_dummy", ")", ",", "\n", "(", "one_dummy", ",", "'\u51cf\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u51cf\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "tail", ")", "\n", "]", "\n", "one_node", "+=", "[", "head", ",", "tail", ",", "'\u51cf\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "'\u51cf\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", "]", "\n", "", "if", "rel", "==", "'*'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "one_dummy", ")", ",", "\n", "(", "one_dummy", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "head", ")", ",", "\n", "(", "tail", ",", "'\u4e58\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u4e58\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "one_dummy", ")", ",", "\n", "(", "one_dummy", ",", "'\u4e58\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u4e58\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "tail", ")", "\n", "]", "\n", "one_node", "+=", "[", "head", ",", "tail", ",", "'\u4e58\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "'\u4e58\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", "]", "\n", "", "if", "rel", "==", "'/'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u9664\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "one_dummy", ")", ",", "\n", "(", "one_dummy", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "head", ")", ",", "\n", "(", "tail", ",", "'\u9664\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u9664\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "one_dummy", ")", ",", "\n", "(", "one_dummy", ",", "'\u9664\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u9664\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "tail", ")", "\n", "]", "\n", "one_node", "+=", "[", "head", ",", "tail", ",", "'\u9664\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", ",", "'\u9664\u6570\u5173\u7cfb_{}_rev'", ".", "format", "(", "eqn", ")", "]", "\n", "\n", "", "return", "one_edge", ",", "one_node", ",", "one_dummy", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.bild_dual_new_graph": [[202, 305], ["re.split", "re.split", "equ_1.replace", "equ_2.replace", "preprocess_data.process_var", "preprocess_data.process_scene", "preprocess_data.get_biparty", "preprocess_data.get_biparty", "preprocess_data.get_triparty", "preprocess_data.get_triparty", "preprocess_data.get_triparty", "preprocess_data.get_triparty", "set", "set", "list", "list", "list", "list", "set", "set"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_var", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_scene", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_biparty", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_biparty", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_triparty", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_triparty", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_triparty", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_triparty"], ["", "def", "bild_dual_new_graph", "(", "equ_1", ",", "equ_2", ",", "scene", ",", "var", ",", "mr_dict", ",", "tou_info", ",", "jiao_info", ")", ":", "\n", "    ", "equ_1", ",", "equ_2", "=", "equ_1", ".", "replace", "(", "' '", ",", "''", ")", ",", "equ_2", ".", "replace", "(", "' '", ",", "''", ")", "\n", "\n", "processed_var", ",", "processed_scene", "=", "process_var", "(", "var", ")", ",", "process_scene", "(", "scene", ")", "\n", "x_ent", ",", "y_ent", "=", "mr_dict", "[", "'x_ent'", "]", ",", "mr_dict", "[", "'y_ent'", "]", "\n", "\n", "# equation graph", "\n", "all_node", ",", "all_edge", "=", "[", "x_ent", ",", "y_ent", "]", ",", "[", "]", "\n", "\n", "# common sense graph", "\n", "all_node_1", ",", "all_edge_1", "=", "[", "x_ent", ",", "y_ent", "]", ",", "[", "]", "\n", "\n", "#\u52a0\u5165\u573a\u666f\u4fe1\u606f", "\n", "for", "tail", "in", "re", ".", "split", "(", "r',|\uff0c'", ",", "processed_scene", "[", "x_ent", "]", ")", ":", "\n", "        ", "all_edge_1", "+=", "[", "(", "x_ent", ",", "'belong_to_x'", ")", ",", "(", "'belong_to_x'", ",", "tail", ")", ",", "(", "tail", ",", "'belong_to_x_rev'", ")", ",", "(", "'belong_to_x_rev'", ",", "x_ent", ")", "]", "\n", "all_node_1", "+=", "[", "tail", ",", "'belong_to_x'", ",", "'belong_to_x_rev'", "]", "\n", "\n", "", "for", "tail", "in", "re", ".", "split", "(", "r',|\uff0c'", ",", "processed_scene", "[", "y_ent", "]", ")", ":", "\n", "        ", "all_edge_1", "+=", "[", "(", "y_ent", ",", "'belong_to_y'", ")", ",", "(", "'belong_to_y'", ",", "tail", ")", ",", "(", "tail", ",", "'belong_to_y_rev'", ")", ",", "(", "'belong_to_y_rev'", ",", "y_ent", ")", "]", "\n", "all_node_1", "+=", "[", "tail", ",", "'belong_to_y'", ",", "'belong_to_y_rev'", "]", "\n", "\n", "# \u5904\u7406\u5934_entity, \u5934_unit, \u811a_entity, \u811a_unit", "\n", "", "if", "tou_info", "[", "'entity'", "]", "!=", "''", ":", "\n", "        ", "all_node_1", "+=", "[", "tou_info", "[", "'entity'", "]", ",", "'\u6709\u5934_ent'", ",", "'\u6709\u5934_ent_rev'", "]", "\n", "all_edge_1", "+=", "[", "(", "x_ent", ",", "'\u6709\u5934_ent'", ")", ",", "(", "'\u6709\u5934_ent'", ",", "tou_info", "[", "'entity'", "]", ")", ",", "(", "tou_info", "[", "'entity'", "]", ",", "'\u6709\u5934_ent_rev'", ")", ",", "(", "'\u6709\u5934_ent_rev'", ",", "x_ent", ")", ",", "\n", "(", "y_ent", ",", "'\u6709\u5934_ent'", ")", ",", "(", "'\u6709\u5934_ent_rev'", ",", "y_ent", ")", "]", "\n", "", "if", "jiao_info", "[", "'entity'", "]", "!=", "''", ":", "\n", "        ", "all_node_1", "+=", "[", "jiao_info", "[", "'entity'", "]", ",", "'\u6709\u811a_ent'", ",", "'\u6709\u811a_ent_rev'", "]", "\n", "all_edge_1", "+=", "[", "(", "x_ent", ",", "'\u6709\u811a_ent'", ")", ",", "(", "'\u6709\u811a_ent'", ",", "jiao_info", "[", "'entity'", "]", ")", ",", "(", "jiao_info", "[", "'entity'", "]", ",", "'\u6709\u811a_ent_rev'", ")", ",", "(", "'\u6709\u811a_ent_rev'", ",", "x_ent", ")", ",", "\n", "(", "y_ent", ",", "'\u6709\u811a_ent'", ")", ",", "(", "'\u6709\u811a_ent_rev'", ",", "y_ent", ")", "]", "\n", "", "if", "tou_info", "[", "'unit'", "]", "!=", "''", ":", "\n", "        ", "all_node_1", "+=", "[", "tou_info", "[", "'unit'", "]", ",", "'\u6709\u5934_unit'", ",", "'\u6709\u5934_unit_rev'", "]", "\n", "all_edge_1", "+=", "[", "(", "x_ent", ",", "'\u6709\u5934_unit'", ")", ",", "(", "'\u6709\u5934_unit'", ",", "tou_info", "[", "'unit'", "]", ")", ",", "(", "tou_info", "[", "'unit'", "]", ",", "'\u6709\u5934_unit_rev'", ")", ",", "(", "'\u6709\u5934_unit_rev'", ",", "x_ent", ")", ",", "\n", "(", "y_ent", ",", "'\u6709\u5934_unit'", ")", ",", "(", "'\u6709\u5934_unit_rev'", ",", "y_ent", ")", "]", "\n", "", "if", "jiao_info", "[", "'unit'", "]", "!=", "''", ":", "\n", "        ", "all_node_1", "+=", "[", "jiao_info", "[", "'unit'", "]", ",", "'\u6709\u811a_unit'", ",", "'\u6709\u811a_unit_rev'", "]", "\n", "all_edge_1", "+=", "[", "(", "x_ent", ",", "'\u6709\u811a_unit'", ")", ",", "(", "'\u6709\u811a_unit'", ",", "jiao_info", "[", "'unit'", "]", ")", ",", "(", "jiao_info", "[", "'unit'", "]", ",", "'\u6709\u811a_unit_rev'", ")", ",", "(", "'\u6709\u811a_unit_rev'", ",", "x_ent", ")", ",", "\n", "(", "y_ent", ",", "'\u6709\u811a_unit'", ")", ",", "(", "'\u6709\u811a_unit_rev'", ",", "y_ent", ")", "]", "\n", "\n", "# \u5904\u7406\u5173\u7cfb1\u5de6\u534a\u90e8\u5206", "\n", "", "tmp_x_eq1", ",", "tmp_y_eq1", ",", "tmp_x_eq2", ",", "tmp_y_eq2", "=", "x_ent", ",", "y_ent", ",", "x_ent", ",", "y_ent", "\n", "tmp_right_eq1", ",", "tmp_right_eq2", "=", "mr_dict", "[", "'eq1_right_num1'", "]", ",", "mr_dict", "[", "'eq2_right_num1'", "]", "\n", "if", "'eq1_x_index'", "in", "mr_dict", ":", "\n", "        ", "all_edge", "+=", "[", "(", "x_ent", ",", "'\u4e58\u5173\u7cfbx'", ")", ",", "(", "'\u4e58\u5173\u7cfbx'", ",", "mr_dict", "[", "'eq1_x_index'", "]", ")", ",", "(", "mr_dict", "[", "'eq1_x_index'", "]", ",", "'\u4e58\u5173\u7cfbx_rev'", ")", ",", "(", "'\u4e58\u5173\u7cfbx_rev'", ",", "x_ent", ")", "]", "\n", "all_node", "+=", "[", "'\u4e58\u5173\u7cfbx'", ",", "mr_dict", "[", "'eq1_x_index'", "]", ",", "'\u4e58\u5173\u7cfbx_rev'", "]", "\n", "tmp_x_eq1", "=", "mr_dict", "[", "'eq1_x_index'", "]", "\n", "\n", "", "if", "'eq1_y_index'", "in", "mr_dict", ":", "\n", "        ", "all_edge", "+=", "[", "(", "y_ent", ",", "'\u4e58\u5173\u7cfby'", ")", ",", "(", "'\u4e58\u5173\u7cfby'", ",", "mr_dict", "[", "'eq1_y_index'", "]", ")", ",", "(", "mr_dict", "[", "'eq1_y_index'", "]", ",", "'\u4e58\u5173\u7cfby_rev'", ")", ",", "(", "'\u4e58\u5173\u7cfby_rev'", ",", "y_ent", ")", "]", "\n", "all_node", "+=", "[", "'\u4e58\u5173\u7cfby'", ",", "mr_dict", "[", "'eq1_y_index'", "]", ",", "'\u4e58\u5173\u7cfby_rev'", "]", "\n", "tmp_y_eq1", "=", "mr_dict", "[", "'eq1_y_index'", "]", "\n", "\n", "# \u5904\u7406\u5173\u7cfb2\u5de6\u534a\u90e8\u5206", "\n", "", "if", "'eq2_x_index'", "in", "mr_dict", ":", "\n", "        ", "all_edge", "+=", "[", "(", "x_ent", ",", "'\u4e58\u5173\u7cfbx'", ")", ",", "(", "'\u4e58\u5173\u7cfbx'", ",", "mr_dict", "[", "'eq2_x_index'", "]", ")", ",", "(", "mr_dict", "[", "'eq2_x_index'", "]", ",", "'\u4e58\u5173\u7cfbx_rev'", ")", ",", "(", "'\u4e58\u5173\u7cfbx_rev'", ",", "x_ent", ")", "]", "\n", "all_node", "+=", "[", "'\u4e58\u5173\u7cfbx'", ",", "mr_dict", "[", "'eq2_x_index'", "]", ",", "'\u4e58\u5173\u7cfbx_rev'", "]", "\n", "tmp_x_eq2", "=", "mr_dict", "[", "'eq2_x_index'", "]", "\n", "\n", "", "if", "'eq2_y_index'", "in", "mr_dict", ":", "\n", "        ", "all_edge", "+=", "[", "(", "y_ent", ",", "'\u4e58\u5173\u7cfby'", ")", ",", "(", "'\u4e58\u5173\u7cfby'", ",", "mr_dict", "[", "'eq2_y_index'", "]", ")", ",", "(", "mr_dict", "[", "'eq2_y_index'", "]", ",", "'\u4e58\u5173\u7cfby_rev'", ")", ",", "(", "'\u4e58\u5173\u7cfby_rev'", ",", "y_ent", ")", "]", "\n", "all_node", "+=", "[", "'\u4e58\u5173\u7cfby'", ",", "mr_dict", "[", "'eq2_y_index'", "]", ",", "'\u4e58\u5173\u7cfby_rev'", "]", "\n", "tmp_y_eq2", "=", "mr_dict", "[", "'eq2_y_index'", "]", "\n", "\n", "# \u5206\u6790\u4e00\u4e0b\u53f3\u8fb9", "\n", "", "if", "'eq1_right_sym'", "in", "mr_dict", ":", "\n", "# \u53f3\u8fb9\u5b58\u5728\u4e00\u5768\u8ba1\u7b97\uff0c\u9700\u8981\u7b97\u7b97", "\n", "        ", "one_tmp_edge1", ",", "one_tmp_node1", ",", "one_tmp_right1", "=", "get_biparty", "(", "mr_dict", "[", "'eq1_right_num1'", "]", ",", "mr_dict", "[", "'eq1_right_sym'", "]", ",", "mr_dict", "[", "'eq1_right_num2'", "]", ",", "'eq1'", ")", "\n", "", "else", ":", "\n", "        ", "one_tmp_edge1", ",", "one_tmp_node1", ",", "one_tmp_right1", "=", "[", "]", ",", "[", "mr_dict", "[", "'eq1_right_num1'", "]", "]", ",", "mr_dict", "[", "'eq1_right_num1'", "]", "\n", "\n", "", "if", "'eq2_right_sym'", "in", "mr_dict", ":", "\n", "        ", "one_tmp_edge2", ",", "one_tmp_node2", ",", "one_tmp_right2", "=", "get_biparty", "(", "mr_dict", "[", "'eq2_right_num1'", "]", ",", "mr_dict", "[", "'eq2_right_sym'", "]", ",", "mr_dict", "[", "'eq2_right_num2'", "]", ",", "'eq2'", ")", "\n", "", "else", ":", "\n", "        ", "one_tmp_edge2", ",", "one_tmp_node2", ",", "one_tmp_right2", "=", "[", "]", ",", "[", "mr_dict", "[", "'eq2_right_num1'", "]", "]", ",", "mr_dict", "[", "'eq2_right_num1'", "]", "\n", "\n", "", "all_edge", "+=", "one_tmp_edge1", "\n", "all_edge", "+=", "one_tmp_edge2", "\n", "all_node", "+=", "one_tmp_node1", "\n", "all_node", "+=", "one_tmp_node2", "\n", "\n", "# \u7ed3\u5408\u5de6\u8fb9\u548c\u53f3\u8fb9", "\n", "if", "'eq1_left_sym1'", "in", "mr_dict", ":", "\n", "# \u8fd9\u4e2a\u65f6\u5019\u53ea\u53ef\u80fd\u662feq1sym1=\u8d1f\u6570\uff0ceq1sym2=\u6b63\u6570", "\n", "        ", "one_tmp_edge_inner_1", ",", "one_tmp_node_inner_1", "=", "get_triparty", "(", "tmp_y_eq1", ",", "tmp_x_eq1", ",", "'-'", ",", "one_tmp_right1", ",", "'eq1'", ")", "\n", "", "else", ":", "\n", "        ", "one_tmp_edge_inner_1", ",", "one_tmp_node_inner_1", "=", "get_triparty", "(", "tmp_x_eq1", ",", "tmp_y_eq1", ",", "mr_dict", "[", "'eq1_left_sym2'", "]", ",", "one_tmp_right1", ",", "'eq1'", ")", "\n", "\n", "", "if", "'eq2_left_sym1'", "in", "mr_dict", ":", "\n", "        ", "one_tmp_edge_inner_2", ",", "one_tmp_node_inner_2", "=", "get_triparty", "(", "tmp_y_eq2", ",", "tmp_x_eq2", ",", "'-'", ",", "one_tmp_right2", ",", "'eq2'", ")", "\n", "", "else", ":", "\n", "        ", "one_tmp_edge_inner_2", ",", "one_tmp_node_inner_2", "=", "get_triparty", "(", "tmp_x_eq2", ",", "tmp_y_eq2", ",", "mr_dict", "[", "'eq2_left_sym2'", "]", ",", "one_tmp_right2", ",", "'eq2'", ")", "\n", "\n", "\n", "", "all_edge", "+=", "one_tmp_edge_inner_1", "\n", "all_edge", "+=", "one_tmp_edge_inner_2", "\n", "all_node", "+=", "one_tmp_node_inner_1", "\n", "all_node", "+=", "one_tmp_node_inner_2", "\n", "\n", "\n", "all_ele", "=", "[", "x", "for", "y", "in", "all_edge", "for", "x", "in", "y", "]", "\n", "assert", "set", "(", "all_ele", ")", "==", "set", "(", "all_node", ")", ",", "'wrong preprocessing code'", "\n", "\n", "return", "list", "(", "all_edge", ")", ",", "list", "(", "set", "(", "all_node", ")", ")", ",", "list", "(", "all_edge_1", ")", ",", "list", "(", "set", "(", "all_node_1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_triparty": [[308, 338], ["None"], "function", ["None"], ["", "def", "get_triparty", "(", "head_left_1", ",", "head_left_2", ",", "rel", ",", "right_one", ",", "eqn", "=", "'eq1'", ")", ":", "\n", "    ", "one_edge", ",", "one_node", "=", "[", "]", ",", "[", "]", "\n", "if", "rel", "==", "'+'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head_left_1", ",", "'\u548c\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u548c\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ")", ",", "\n", "(", "right_one", ",", "'\u548c\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u548c\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_1", ")", ",", "\n", "(", "head_left_2", ",", "'\u548c\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u548c\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_2", ")", ",", "]", "\n", "one_node", "+=", "[", "head_left_1", ",", "head_left_2", ",", "right_one", ",", "'\u548c\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "'\u548c\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", "]", "\n", "", "if", "rel", "==", "'-'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head_left_1", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ")", ",", "\n", "(", "right_one", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_1", ")", ",", "\n", "(", "head_left_2", ",", "'\u51cf\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u51cf\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ")", ",", "\n", "(", "right_one", ",", "'\u51cf\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u51cf\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_2", ")", "\n", "]", "\n", "one_node", "+=", "[", "head_left_1", ",", "head_left_2", ",", "'\u51cf\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ",", "'\u51cf\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u51cf\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", "]", "\n", "", "if", "rel", "==", "'*'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head_left_1", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ")", ",", "\n", "(", "right_one", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_1", ")", ",", "\n", "(", "head_left_2", ",", "'\u4e58\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u4e58\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ")", ",", "\n", "(", "right_one", ",", "'\u4e58\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u4e58\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_2", ")", "\n", "]", "\n", "one_node", "+=", "[", "head_left_1", ",", "head_left_2", ",", "'\u4e58\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ",", "\n", "'\u4e58\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u4e58\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", "]", "\n", "", "if", "rel", "==", "'/'", ":", "\n", "        ", "one_edge", "+=", "[", "(", "head_left_1", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ")", ",", "\n", "(", "right_one", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_1", ")", ",", "\n", "(", "head_left_2", ",", "'\u9664\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u9664\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ")", ",", "\n", "(", "right_one", ",", "'\u9664\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ")", ",", "(", "'\u9664\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "head_left_2", ")", "\n", "]", "\n", "one_node", "+=", "[", "head_left_1", ",", "head_left_2", ",", "'\u9664\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_res'", ".", "format", "(", "eqn", ")", ",", "right_one", ",", "'\u88ab\u9664\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", ",", "'\u9664\u6570\u5173\u7cfb_{}_rev_res'", ".", "format", "(", "eqn", ")", "]", "\n", "", "return", "one_edge", ",", "one_node", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_jitu_mr_type": [[407, 532], ["preprocess_data.process_mr", "mr.split", "enumerate", "preprocess_data.bild_dual_new_graph", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "copy.deepcopy", "eval", "eval", "len", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace", "item.split", "copy.deepcopy", "copy.deepcopy", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace", "scene.replace.replace"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_mr", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.bild_dual_new_graph"], ["def", "process_jitu_mr_type", "(", "mr", ",", "scene", ",", "equ1", ",", "equ2", ",", "var", ",", "tou_info", ",", "jiao_info", ")", ":", "\n", "    ", "mr", ",", "scene", ",", "equ1", ",", "equ2", ",", "var", "=", "copy", ".", "deepcopy", "(", "mr", ")", ",", "copy", ".", "deepcopy", "(", "scene", ")", ",", "copy", ".", "deepcopy", "(", "equ1", ")", ",", "copy", ".", "deepcopy", "(", "equ2", ")", ",", "copy", ".", "deepcopy", "(", "var", ")", "\n", "tou_info", ",", "jiao_info", "=", "eval", "(", "copy", ".", "deepcopy", "(", "tou_info", ")", ")", ",", "eval", "(", "copy", ".", "deepcopy", "(", "jiao_info", ")", ")", "\n", "lex_this", "=", "[", "None", "]", "*", "len", "(", "lex_tar", ")", "\n", "\n", "mr_dict", "=", "process_mr", "(", "mr", ",", "var", ")", "\n", "#     print(mr_dict)", "\n", "ent_x", ",", "ent_y", "=", "mr_dict", "[", "'x_ent'", "]", ",", "mr_dict", "[", "'y_ent'", "]", "\n", "\n", "# \u66ff\u6362\u5b9e\u4f53\u7684\u540d\u79f0\u4f5c\u4e3a\u8f93\u5165", "\n", "if", "ent_y", "==", "(", "'\u8d85\u7ea7'", "+", "ent_x", ")", ":", "\n", "        ", "scene", "=", "scene", ".", "replace", "(", "ent_y", ",", "Constants", ".", "y_entity_WORD", ")", "\n", "mr_dict", "[", "'y_ent'", "]", "=", "Constants", ".", "y_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'y_entity'", "]", "]", "=", "ent_y", "\n", "scene", "=", "scene", ".", "replace", "(", "ent_x", ",", "Constants", ".", "x_entity_WORD", ")", "\n", "mr_dict", "[", "'x_ent'", "]", "=", "Constants", ".", "x_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'x_entity'", "]", "]", "=", "ent_x", "\n", "", "if", "ent_x", "==", "(", "'\u53e6'", "+", "ent_y", ")", ":", "\n", "        ", "scene", "=", "scene", ".", "replace", "(", "ent_x", ",", "Constants", ".", "x_entity_WORD", ")", "\n", "mr_dict", "[", "'x_ent'", "]", "=", "Constants", ".", "x_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'x_entity'", "]", "]", "=", "ent_x", "\n", "scene", "=", "scene", ".", "replace", "(", "ent_y", ",", "Constants", ".", "y_entity_WORD", ")", "\n", "mr_dict", "[", "'y_ent'", "]", "=", "Constants", ".", "y_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'y_entity'", "]", "]", "=", "ent_y", "\n", "", "elif", "ent_y", "==", "(", "'\u53e6'", "+", "ent_x", ")", ":", "\n", "        ", "scene", "=", "scene", ".", "replace", "(", "ent_y", ",", "Constants", ".", "y_entity_WORD", ")", "\n", "mr_dict", "[", "'y_ent'", "]", "=", "Constants", ".", "y_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'y_entity'", "]", "]", "=", "ent_y", "\n", "scene", "=", "scene", ".", "replace", "(", "ent_x", ",", "Constants", ".", "x_entity_WORD", ")", "\n", "mr_dict", "[", "'x_ent'", "]", "=", "Constants", ".", "x_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'x_entity'", "]", "]", "=", "ent_x", "\n", "", "elif", "(", "'\u53e6\u4e00'", "in", "ent_x", ")", "or", "(", "'\u53e6\u5916\u4e00'", "in", "ent_y", ")", ":", "\n", "        ", "scene", "=", "scene", ".", "replace", "(", "ent_y", ",", "Constants", ".", "y_entity_WORD", ")", "\n", "mr_dict", "[", "'y_ent'", "]", "=", "Constants", ".", "y_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'y_entity'", "]", "]", "=", "ent_y", "\n", "scene", "=", "scene", ".", "replace", "(", "ent_x", ",", "Constants", ".", "x_entity_WORD", ")", "\n", "mr_dict", "[", "'x_ent'", "]", "=", "Constants", ".", "x_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'x_entity'", "]", "]", "=", "ent_x", "\n", "", "elif", "(", "'\u53e6\u4e00'", "in", "ent_y", ")", "or", "(", "'\u53e6\u5916\u4e00'", "in", "ent_x", ")", ":", "\n", "        ", "scene", "=", "scene", ".", "replace", "(", "ent_x", ",", "Constants", ".", "x_entity_WORD", ")", "\n", "mr_dict", "[", "'x_ent'", "]", "=", "Constants", ".", "x_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'x_entity'", "]", "]", "=", "ent_x", "\n", "scene", "=", "scene", ".", "replace", "(", "ent_y", ",", "Constants", ".", "y_entity_WORD", ")", "\n", "mr_dict", "[", "'y_ent'", "]", "=", "Constants", ".", "y_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'y_entity'", "]", "]", "=", "ent_y", "\n", "", "else", ":", "\n", "        ", "if", "'dummy'", "not", "in", "ent_x", ":", "\n", "            ", "scene", "=", "scene", ".", "replace", "(", "ent_x", ",", "Constants", ".", "x_entity_WORD", ")", "\n", "mr_dict", "[", "'x_ent'", "]", "=", "Constants", ".", "x_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'x_entity'", "]", "]", "=", "ent_x", "\n", "scene", "=", "scene", ".", "replace", "(", "ent_y", ",", "Constants", ".", "y_entity_WORD", ")", "\n", "mr_dict", "[", "'y_ent'", "]", "=", "Constants", ".", "y_entity_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'y_entity'", "]", "]", "=", "ent_y", "\n", "\n", "", "", "items", "=", "mr", ".", "split", "(", "','", ")", "\n", "for", "idx", ",", "item", "in", "enumerate", "(", "items", ")", ":", "\n", "        ", "key", ",", "raw_val", "=", "item", ".", "split", "(", "'['", ")", "\n", "#         if (key=='x_ent') & ('dummy' not in raw_val):", "\n", "#             scene = scene.replace(ent_x,Constants.x_entity_WORD)", "\n", "#             mr_dict['x_ent'] = Constants.x_entity_WORD", "\n", "#             lex_this[lex_keymap['x_entity']] = ent_x", "\n", "#         elif (key =='y_ent') & ('dummy' not in raw_val):", "\n", "#             scene = scene.replace(ent_y,Constants.y_entity_WORD)", "\n", "#             mr_dict['y_ent'] = Constants.y_entity_WORD", "\n", "#             lex_this[lex_keymap['y_entity']] = ent_y", "\n", "if", "key", "==", "'eq1_x_index'", ":", "\n", "            ", "mr_dict", "[", "'eq1_x_index'", "]", "=", "Constants", ".", "eq1_x_index_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00x\u7cfb\u6570'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "elif", "key", "==", "'eq1_y_index'", ":", "\n", "            ", "mr_dict", "[", "'eq1_y_index'", "]", "=", "Constants", ".", "eq1_y_index_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00y\u7cfb\u6570'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "elif", "key", "==", "'eq1_left_sym2'", ":", "\n", "            ", "pass", "\n", "", "elif", "key", "==", "'eq1_right_num1'", ":", "\n", "            ", "if", "mr_dict", "[", "'eq1_right_num1'", "]", "==", "'0'", ":", "\n", "                ", "mr_dict", "[", "'eq1_right_num1'", "]", "=", "'0'", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00\u53f3\u8fb9\u6570\u5b57\u4e00'", "]", "]", "=", "'0'", "\n", "", "else", ":", "\n", "                ", "mr_dict", "[", "'eq1_right_num1'", "]", "=", "Constants", ".", "eq1_right_num1_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00\u53f3\u8fb9\u6570\u5b57\u4e00'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "", "elif", "key", "==", "'eq1_right_num2'", ":", "\n", "            ", "mr_dict", "[", "'eq1_right_num2'", "]", "=", "Constants", ".", "eq1_right_num2_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00\u53f3\u8fb9\u6570\u5b57\u4e8c'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "elif", "key", "==", "'eq2_x_index'", ":", "\n", "            ", "mr_dict", "[", "'eq2_x_index'", "]", "=", "Constants", ".", "eq2_x_index_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e8cx\u7cfb\u6570'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "elif", "key", "==", "'eq2_y_index'", ":", "\n", "            ", "mr_dict", "[", "'eq2_y_index'", "]", "=", "Constants", ".", "eq2_y_index_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e8cy\u7cfb\u6570'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "elif", "key", "==", "'eq2_left_sym2'", ":", "\n", "            ", "pass", "\n", "", "elif", "key", "==", "'eq2_right_num1'", ":", "\n", "            ", "if", "mr_dict", "[", "'eq2_right_num1'", "]", "==", "'0'", ":", "\n", "                ", "mr_dict", "[", "'eq2_right_num1'", "]", "=", "'0'", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00\u53f3\u8fb9\u6570\u5b57\u4e00'", "]", "]", "=", "'0'", "\n", "", "else", ":", "\n", "                ", "mr_dict", "[", "'eq2_right_num1'", "]", "=", "Constants", ".", "eq2_right_num1_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e8c\u53f3\u8fb9\u6570\u5b57\u4e00'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "", "elif", "key", "==", "'eq2_right_num2'", ":", "\n", "            ", "mr_dict", "[", "'eq2_right_num2'", "]", "=", "Constants", ".", "eq2_right_num2_WORD", "\n", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e8c\u53f3\u8fb9\u6570\u5b57\u4e8c'", "]", "]", "=", "raw_val", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# \u4e00\u4e9b\u7279\u6b8acase\uff0c\u9700\u8981\u505a\u4e00\u4e0b\u5904\u7406\uff0c\u8fd9\u91cc\u9762\u662f\u4e3a\u4e86\u5e94\u5bf9\u9664\u6cd5\u7684\u60c5\u51b5", "\n", "", "", "if", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e8c\u53f3\u8fb9\u6570\u5b57\u4e00'", "]", "]", "==", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00\u53f3\u8fb9\u6570\u5b57\u4e00'", "]", "]", ":", "\n", "        ", "mr_dict", "[", "'eq2_right_num1'", "]", "=", "Constants", ".", "eq1_right_num1_WORD", "\n", "# \u7279\u6b8acase \u5982\u679c\u9e21\u5154\u4e92\u6362", "\n", "", "if", "(", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00x\u7cfb\u6570'", "]", "]", "==", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e8cy\u7cfb\u6570'", "]", "]", ")", "&", "(", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e8cx\u7cfb\u6570'", "]", "]", "==", "lex_this", "[", "lex_keymap", "[", "'\u65b9\u7a0b\u4e00y\u7cfb\u6570'", "]", "]", ")", ":", "\n", "        ", "mr_dict", "[", "'eq2_y_index'", "]", "=", "Constants", ".", "eq1_x_index_WORD", "\n", "mr_dict", "[", "'eq2_x_index'", "]", "=", "Constants", ".", "eq1_y_index_WORD", "\n", "\n", "", "if", "tou_info", "[", "'entity'", "]", "!=", "''", ":", "\n", "        ", "lex_this", "[", "lex_keymap", "[", "'head\u4fe1\u606f_entity'", "]", "]", "=", "tou_info", "[", "'entity'", "]", "\n", "tou_info", "[", "'entity'", "]", "=", "Constants", ".", "head_info_entity_WORD", "\n", "", "if", "tou_info", "[", "'unit'", "]", "!=", "''", ":", "\n", "        ", "lex_this", "[", "lex_keymap", "[", "'head\u4fe1\u606f_unit'", "]", "]", "=", "tou_info", "[", "'unit'", "]", "\n", "tou_info", "[", "'unit'", "]", "=", "Constants", ".", "head_info_unit_WORD", "\n", "", "if", "jiao_info", "[", "'entity'", "]", "!=", "''", ":", "\n", "        ", "lex_this", "[", "lex_keymap", "[", "'\u811a\u4fe1\u606f_entity'", "]", "]", "=", "jiao_info", "[", "'entity'", "]", "\n", "jiao_info", "[", "'entity'", "]", "=", "Constants", ".", "jiao_info_entity_WORD", "\n", "", "if", "jiao_info", "[", "'unit'", "]", "!=", "''", ":", "\n", "        ", "lex_this", "[", "lex_keymap", "[", "'\u811a\u4fe1\u606f_unit'", "]", "]", "=", "jiao_info", "[", "'unit'", "]", "\n", "jiao_info", "[", "'unit'", "]", "=", "Constants", ".", "jiao_info_unit_WORD", "\n", "", "all_edge", ",", "all_node", ",", "all_edge_1", ",", "all_node_1", "=", "bild_dual_new_graph", "(", "equ1", ",", "equ2", ",", "scene", ",", "var", ",", "mr_dict", ",", "tou_info", ",", "jiao_info", ")", "\n", "return", "all_edge", ",", "all_node", ",", "lex_this", ",", "all_edge_1", ",", "all_node_1", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_after_text": [[571, 578], ["zip", "text.replace.replace"], "function", ["None"], ["def", "get_after_text", "(", "text", ",", "lex_list", ")", ":", "\n", "    ", "if", "lex_list", ":", "\n", "        ", "for", "word", ",", "tar", "in", "zip", "(", "lex_list", ",", "lex_tar", ")", ":", "\n", "            ", "if", "word", "is", "not", "None", ":", "\n", "                ", "if", "word", "in", "text", ":", "\n", "                    ", "text", "=", "text", ".", "replace", "(", "word", ",", "tar", ")", "\n", "", "", "", "", "return", "text", "\n", "", "def", "tokenize_word", "(", "text", ",", "sp", ",", "lex_list", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.tokenize_word": [[578, 588], ["sp.EncodeAsPieces", "zip", "words.append", "text.replace.replace"], "function", ["None"], ["", "def", "tokenize_word", "(", "text", ",", "sp", ",", "lex_list", "=", "None", ")", ":", "\n", "    ", "words", "=", "[", "]", "\n", "if", "lex_list", ":", "\n", "        ", "for", "word", ",", "tar", "in", "zip", "(", "lex_list", ",", "lex_tar", ")", ":", "\n", "            ", "if", "word", "is", "not", "None", ":", "\n", "                ", "if", "word", "in", "text", ":", "\n", "                    ", "text", "=", "text", ".", "replace", "(", "word", ",", "tar", ")", "\n", "", "", "", "", "for", "frag", "in", "sp", ".", "EncodeAsPieces", "(", "text", ")", ":", "\n", "        ", "words", ".", "append", "(", "frag", ")", "\n", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.build_vocab_idx": [[641, 680], ["set", "print", "word_count.items", "print", "print", "len", "len", "len"], "function", ["None"], ["def", "build_vocab_idx", "(", "word_insts", ",", "min_word_count", ")", ":", "\n", "    ", "'''Trim vocab by number of occurence'''", "\n", "full_vocab", "=", "set", "(", "w", "for", "sent", "in", "word_insts", "for", "w", "in", "sent", ")", "\n", "print", "(", "'[Info] Original Vocabulary size ='", ",", "len", "(", "full_vocab", ")", ")", "\n", "word2idx", "=", "{", "\n", "Constants", ".", "BOS_WORD", ":", "Constants", ".", "BOS", ",", "\n", "Constants", ".", "EOS_WORD", ":", "Constants", ".", "EOS", ",", "\n", "Constants", ".", "PAD_WORD", ":", "Constants", ".", "PAD", ",", "\n", "Constants", ".", "UNK_WORD", ":", "Constants", ".", "UNK", ",", "\n", "Constants", ".", "eq1_x_index_WORD", ":", "Constants", ".", "eq1_x_index", ",", "\n", "Constants", ".", "eq2_x_index_WORD", ":", "Constants", ".", "eq2_x_index", ",", "\n", "Constants", ".", "eq1_y_index_WORD", ":", "Constants", ".", "eq1_y_index", ",", "\n", "Constants", ".", "eq2_y_index_WORD", ":", "Constants", ".", "eq2_y_index", ",", "\n", "Constants", ".", "eq1_right_num1_WORD", ":", "Constants", ".", "eq1_right_num1", ",", "\n", "Constants", ".", "eq2_right_num1_WORD", ":", "Constants", ".", "eq2_right_num1", ",", "\n", "Constants", ".", "eq1_right_num2_WORD", ":", "Constants", ".", "eq1_right_num2", ",", "\n", "Constants", ".", "eq2_right_num2_WORD", ":", "Constants", ".", "eq1_right_num2", ",", "\n", "Constants", ".", "x_entity_WORD", ":", "Constants", ".", "x_entity", ",", "\n", "Constants", ".", "y_entity_WORD", ":", "Constants", ".", "y_entity", ",", "\n", "Constants", ".", "head_info_unit_WORD", ":", "Constants", ".", "head_info_unit", ",", "\n", "Constants", ".", "jiao_info_unit_WORD", ":", "Constants", ".", "jiao_info_unit", ",", "\n", "Constants", ".", "jiao_info_entity_WORD", ":", "Constants", ".", "jiao_info_entity", ",", "\n", "Constants", ".", "head_info_entity_WORD", ":", "Constants", ".", "head_info_entity", "\n", "}", "\n", "\n", "word_count", "=", "{", "w", ":", "0", "for", "w", "in", "full_vocab", "}", "\n", "for", "sent", "in", "word_insts", ":", "\n", "        ", "for", "word", "in", "sent", ":", "\n", "            ", "word_count", "[", "word", "]", "+=", "1", "\n", "", "", "ignored_word_count", "=", "0", "\n", "for", "word", ",", "count", "in", "word_count", ".", "items", "(", ")", ":", "\n", "        ", "if", "word", "not", "in", "word2idx", ":", "\n", "            ", "if", "count", ">", "min_word_count", ":", "\n", "                ", "word2idx", "[", "word", "]", "=", "len", "(", "word2idx", ")", "\n", "", "else", ":", "\n", "                ", "ignored_word_count", "+=", "1", "\n", "", "", "", "print", "(", "'[Info] Trimmed vocabulary size = {},'", ".", "format", "(", "len", "(", "word2idx", ")", ")", ",", "'each with minimum occurence = {}'", ".", "format", "(", "min_word_count", ")", ")", "\n", "print", "(", "'[Info] Ingored word count = {}'", ".", "format", "(", "ignored_word_count", ")", ")", "\n", "return", "word2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.get_scene": [[682, 690], ["one_scene.replace.replace", "preprocess_data.process_scene", "set", "process_scene.items", "list", "re.split", "set.add"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.preprocess_data.process_scene"], ["", "def", "get_scene", "(", "one_scene", ")", ":", "\n", "    ", "one_scene", "=", "one_scene", ".", "replace", "(", "' '", ",", "''", ")", "\n", "processed", "=", "process_scene", "(", "one_scene", ")", "\n", "all_word", "=", "set", "(", ")", "\n", "for", "key", ",", "value", "in", "processed", ".", "items", "(", ")", ":", "\n", "        ", "for", "one_word", "in", "re", ".", "split", "(", "',|\uff0c'", ",", "value", ")", ":", "\n", "            ", "all_word", ".", "add", "(", "one_word", ")", "\n", "", "", "return", "list", "(", "all_word", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.__init__": [[53, 67], ["src_word2idx.items", "tgt_word2idx.items"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "src_word2idx", ",", "tgt_word2idx", ",", "node_insts", "=", "None", ",", "rel_insts", "=", "None", ",", "node_insts_1", "=", "None", ",", "rel_insts_1", "=", "None", ",", "scene_insts", "=", "None", ",", "tgt_insts", "=", "None", ")", ":", "\n", "        ", "src_idx2word", "=", "{", "idx", ":", "word", "for", "word", ",", "idx", "in", "src_word2idx", ".", "items", "(", ")", "}", "\n", "self", ".", "_src_word2idx", "=", "src_word2idx", "\n", "self", ".", "_src_idx2word", "=", "src_idx2word", "\n", "self", ".", "_node_insts", "=", "node_insts", "# equation info", "\n", "self", ".", "_node_insts_1", "=", "node_insts_1", "# common sense info", "\n", "\n", "tgt_idx2word", "=", "{", "idx", ":", "word", "for", "word", ",", "idx", "in", "tgt_word2idx", ".", "items", "(", ")", "}", "\n", "self", ".", "_tgt_word2idx", "=", "tgt_word2idx", "\n", "self", ".", "_tgt_idx2word", "=", "tgt_idx2word", "\n", "self", ".", "_rel_insts", "=", "rel_insts", "# equation info", "\n", "self", ".", "_rel_insts_1", "=", "rel_insts_1", "# common sense info", "\n", "self", ".", "_tgt_insts", "=", "tgt_insts", "\n", "self", ".", "_scene_insts", "=", "scene_insts", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.n_insts": [[68, 72], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_insts", "(", "self", ")", ":", "\n", "        ", "'''Property for dataset size'''", "\n", "return", "len", "(", "self", ".", "_node_insts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.src_vocab_size": [[73, 77], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "src_vocab_size", "(", "self", ")", ":", "\n", "        ", "'''property for vocab size'''", "\n", "return", "len", "(", "self", ".", "_src_word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.tgt_vocab_size": [[78, 82], ["len"], "methods", ["None"], ["", "@", "property", "\n", "def", "tgt_vocab_size", "(", "self", ")", ":", "\n", "        ", "'''peoperty for vocab size'''", "\n", "return", "len", "(", "self", ".", "_tgt_word2idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.src_word2idx": [[83, 86], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "src_word2idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_src_word2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.tgt_word2idx": [[87, 90], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "tgt_word2idx", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_tgt_word2idx", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.src_idx2word": [[91, 95], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "src_idx2word", "(", "self", ")", ":", "\n", "        ", "'''Property for index dictionary'''", "\n", "return", "self", ".", "_src_idx2word", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.tgt_idx2word": [[96, 99], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "tgt_idx2word", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_tgt_idx2word", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.__len__": [[100, 102], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_insts", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.MyDataset.__getitem__": [[103, 151], ["len", "numpy.zeros", "range", "len", "numpy.zeros", "range", "dataset_dual.MyDataset._src_word2idx.get", "dataset_dual.MyDataset._src_word2idx.get", "dataset_dual.MyDataset._src_word2idx.get", "dataset_dual.MyDataset._src_word2idx.get"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "# return one data pair (node and caption and adjmatrix)", "\n", "        ", "one_caption", "=", "self", ".", "_tgt_insts", "[", "idx", "]", "+", "[", "Constants", ".", "EOS_WORD", "]", "\n", "one_node", "=", "self", ".", "_node_insts", "[", "idx", "]", "\n", "one_rel", "=", "self", ".", "_rel_insts", "[", "idx", "]", "\n", "one_scene", "=", "self", ".", "_scene_insts", "[", "idx", "]", "\n", "other_node", "=", "self", ".", "_node_insts_1", "[", "idx", "]", "\n", "other_rel", "=", "self", ".", "_rel_insts_1", "[", "idx", "]", "\n", "\n", "one_num_caption", "=", "[", "self", ".", "_src_word2idx", ".", "get", "(", "x", ",", "Constants", ".", "UNK", ")", "for", "x", "in", "one_caption", "]", "\n", "one_num_node", "=", "[", "self", ".", "_src_word2idx", ".", "get", "(", "x", ",", "Constants", ".", "UNK", ")", "for", "x", "in", "one_node", "]", "\n", "one_num_scene", "=", "[", "self", ".", "_src_word2idx", ".", "get", "(", "x", ",", "Constants", ".", "UNK", ")", "for", "x", "in", "one_scene", "]", "\n", "other_num_node", "=", "[", "self", ".", "_src_word2idx", ".", "get", "(", "x", ",", "Constants", ".", "UNK", ")", "for", "x", "in", "other_node", "]", "\n", "# build adj matrix", "\n", "# this is graph for equation information", "\n", "i", "=", "0", "\n", "one_inner_dict", "=", "{", "}", "\n", "for", "tok", "in", "one_node", ":", "\n", "            ", "one_inner_dict", "[", "tok", "]", "=", "i", "\n", "i", "+=", "1", "\n", "\n", "", "node_num", "=", "len", "(", "one_inner_dict", ")", "\n", "matrix", "=", "np", ".", "zeros", "(", "(", "node_num", ",", "node_num", ")", ",", "dtype", "=", "int", ")", "\n", "for", "m", "in", "range", "(", "0", ",", "node_num", ")", ":", "\n", "# add diagonal", "\n", "            ", "matrix", "[", "m", "]", "[", "m", "]", "=", "1", "\n", "", "for", "r", "in", "one_rel", ":", "\n", "            ", "head", ",", "tail", "=", "r", "\n", "loc1", ",", "loc2", "=", "one_inner_dict", "[", "head", "]", ",", "one_inner_dict", "[", "tail", "]", "\n", "matrix", "[", "loc1", "]", "[", "loc2", "]", ",", "matrix", "[", "loc2", "]", "[", "loc1", "]", "=", "1", ",", "1", "\n", "\n", "# common sense graph", "\n", "", "ii", "=", "0", "\n", "other_inner_dict", "=", "{", "}", "\n", "for", "tok_other", "in", "other_node", ":", "\n", "            ", "other_inner_dict", "[", "tok_other", "]", "=", "ii", "\n", "ii", "+=", "1", "\n", "\n", "", "other_node_num", "=", "len", "(", "other_inner_dict", ")", "\n", "other_matrix", "=", "np", ".", "zeros", "(", "(", "other_node_num", ",", "other_node_num", ")", ",", "dtype", "=", "int", ")", "\n", "for", "m_other", "in", "range", "(", "0", ",", "other_node_num", ")", ":", "\n", "# add diagonal", "\n", "            ", "other_matrix", "[", "m_other", "]", "[", "m_other", "]", "=", "1", "\n", "", "for", "r_other", "in", "other_rel", ":", "\n", "            ", "head_other", ",", "tail_other", "=", "r_other", "\n", "loc1_other", ",", "loc2_other", "=", "other_inner_dict", "[", "head_other", "]", ",", "other_inner_dict", "[", "tail_other", "]", "\n", "other_matrix", "[", "loc1_other", "]", "[", "loc2_other", "]", ",", "other_matrix", "[", "loc2_other", "]", "[", "loc1_other", "]", "=", "1", ",", "1", "\n", "", "return", "one_num_node", ",", "other_num_node", ",", "one_num_caption", ",", "matrix", ",", "other_matrix", ",", "one_num_scene", "\n", "", "", ""]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.dataset_dual.collate_fn": [[11, 51], ["zip", "max", "numpy.array", "max", "numpy.array", "max", "numpy.array", "max", "numpy.array", "enumerate", "enumerate", "len", "len", "len", "numpy.pad", "equ_matrixs_pad.append", "numpy.pad", "sns_matrixs_pad.append", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "len", "len", "len", "len", "len", "len", "len", "len", "len"], "function", ["None"], ["def", "collate_fn", "(", "insts", ")", ":", "\n", "    ", "'''PAD the instance to the max seq length in batch'''", "\n", "equ_nodes", ",", "com_sns_nodes", ",", "captions", ",", "equ_matrixs", ",", "com_sns_matrixs", ",", "scenes", "=", "zip", "(", "*", "insts", ")", "\n", "len_equ_nodes", "=", "[", "len", "(", "node", ")", "for", "node", "in", "equ_nodes", "]", "\n", "len_sns_nodes", "=", "[", "len", "(", "node", ")", "for", "node", "in", "com_sns_nodes", "]", "\n", "# padding scenes", "\n", "max_scene_len", "=", "max", "(", "len", "(", "scene", ")", "for", "scene", "in", "scenes", ")", "\n", "batch_scenes", "=", "np", ".", "array", "(", "[", "\n", "inst", "+", "[", "Constants", ".", "PAD", "]", "*", "(", "max_scene_len", "-", "len", "(", "inst", ")", ")", "for", "inst", "in", "scenes", "\n", "]", ")", "\n", "# padding equation nodes", "\n", "max_equ_node_len", "=", "max", "(", "len_equ_nodes", ")", "\n", "batch_equ_nodes", "=", "np", ".", "array", "(", "[", "\n", "inst", "+", "[", "Constants", ".", "PAD", "]", "*", "(", "max_equ_node_len", "-", "len", "(", "inst", ")", ")", "for", "inst", "in", "equ_nodes", "\n", "]", ")", "\n", "# padding common sense nodes", "\n", "max_sns_node_len", "=", "max", "(", "len_sns_nodes", ")", "\n", "batch_sns_nodes", "=", "np", ".", "array", "(", "[", "\n", "inst", "+", "[", "Constants", ".", "PAD", "]", "*", "(", "max_sns_node_len", "-", "len", "(", "inst", ")", ")", "for", "inst", "in", "com_sns_nodes", "\n", "]", ")", "\n", "\n", "# padding captions", "\n", "lengths_caption", "=", "[", "len", "(", "cap", ")", "for", "cap", "in", "captions", "]", "\n", "max_caption_len", "=", "max", "(", "lengths_caption", ")", "\n", "batch_captions", "=", "np", ".", "array", "(", "[", "\n", "cap_inst", "+", "[", "Constants", ".", "PAD", "]", "*", "(", "max_caption_len", "-", "len", "(", "cap_inst", ")", ")", "for", "cap_inst", "in", "captions", "\n", "]", ")", "\n", "\n", "# padding equation matrix", "\n", "equ_matrixs_pad", "=", "[", "]", "\n", "for", "j", ",", "node_one", "in", "enumerate", "(", "equ_matrixs", ")", ":", "\n", "        ", "new_matrix", "=", "np", ".", "pad", "(", "equ_matrixs", "[", "j", "]", ",", "(", "(", "0", ",", "max_equ_node_len", "-", "len", "(", "equ_matrixs", "[", "j", "]", ")", ")", ",", "(", "0", ",", "max_equ_node_len", "-", "len", "(", "equ_matrixs", "[", "j", "]", ")", ")", ")", ",", "'constant'", ",", "constant_values", "=", "(", "0", ",", "0", ")", ")", "\n", "equ_matrixs_pad", ".", "append", "(", "new_matrix", ")", "\n", "\n", "# padding common sense matrix", "\n", "", "sns_matrixs_pad", "=", "[", "]", "\n", "for", "j", ",", "node_one", "in", "enumerate", "(", "com_sns_matrixs", ")", ":", "\n", "        ", "new_matrix", "=", "np", ".", "pad", "(", "com_sns_matrixs", "[", "j", "]", ",", "(", "(", "0", ",", "max_sns_node_len", "-", "len", "(", "com_sns_matrixs", "[", "j", "]", ")", ")", ",", "(", "0", ",", "max_sns_node_len", "-", "len", "(", "com_sns_matrixs", "[", "j", "]", ")", ")", ")", ",", "'constant'", ",", "constant_values", "=", "(", "0", ",", "0", ")", ")", "\n", "sns_matrixs_pad", ".", "append", "(", "new_matrix", ")", "\n", "", "return", "torch", ".", "LongTensor", "(", "batch_equ_nodes", ")", ",", "torch", ".", "LongTensor", "(", "batch_sns_nodes", ")", ",", "torch", ".", "FloatTensor", "(", "len_equ_nodes", ")", ",", "torch", ".", "FloatTensor", "(", "len_sns_nodes", ")", ",", "torch", ".", "FloatTensor", "(", "equ_matrixs_pad", ")", ",", "torch", ".", "FloatTensor", "(", "sns_matrixs_pad", ")", ",", "torch", ".", "LongTensor", "(", "batch_captions", ")", ",", "torch", ".", "LongTensor", "(", "batch_scenes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.cal_performence": [[19, 30], ["train_res.cal_loss", "gold.contiguous().view.contiguous().view", "gold.contiguous().view.ne", "pred.eq", "n_correct.masked_select().sum().item.masked_select().sum().item", "pred.max", "gold.contiguous().view.contiguous", "n_correct.masked_select().sum().item.masked_select().sum", "n_correct.masked_select().sum().item.masked_select"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_loss"], ["def", "cal_performence", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Apply label smooth if needed\n    \"\"\"", "\n", "loss", ",", "loss_recon", ",", "loss_kl", "=", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "pred", "=", "pred", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_correct", "=", "pred", ".", "eq", "(", "gold", ")", "\n", "n_correct", "=", "n_correct", ".", "masked_select", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.gaussian_kld": [[31, 36], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "exp", "(", "recog_logvar", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", ",", "1", ")", "\n", "return", "torch", ".", "sum", "(", "kld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.cal_loss": [[46, 56], ["gold.contiguous().view.contiguous().view", "torch.cross_entropy", "train_res.gaussian_kld", "gold.contiguous().view.contiguous"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.gaussian_kld"], ["", "def", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Calculate cross entropy loss, apply label smoothing if needed\n    \"\"\"", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss_recon", "=", "F", ".", "cross_entropy", "(", "pred", ",", "gold", ",", "ignore_index", "=", "Constants", ".", "PAD", ",", "reduction", "=", "'sum'", ")", "\n", "# loss_kl = lambda_kl*-0.5 * torch.sum(1 + log_var - mu.pow(2)-log_var.exp())", "\n", "loss_kl", "=", "lambda_kl", "*", "gaussian_kld", "(", "mu_posterior", ",", "log_var_posterior", ",", "mu_prior", ",", "log_var_prior", ")", "\n", "# loss_sparse = sparse_resularizer(plan_attns)", "\n", "return", "loss_recon", "+", "loss_kl", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.train_epoch": [[57, 105], ["model.train", "tqdm.tqdm", "map", "optimizer.zero_grad", "model", "train_res.cal_performence", "loss.backward", "optimizer.step_and_update_lr", "loss.item", "loss_kl.item", "loss_recon.item", "len", "gold.ne", "gold.ne.sum().item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.step_and_update_lr"], ["", "def", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "device", ",", "smoothing", ",", "lambda_kl", ")", ":", "\n", "    ", "'''Epoch operation in training phase'''", "\n", "model", ".", "train", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "\n", "for", "batch", "in", "tqdm", "(", "training_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Training) '", ",", "leave", "=", "False", ")", ":", "\n", "\n", "# prepare data", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "#print('src_seq shape:', src_seq.shape)", "\n", "#print('src_pos shape:', src_pos.shape)", "\n", "#print('tgt_seq shape:', tgt_seq.shape)", "\n", "#print('tgt_pos shape:', tgt_pos.shape)", "\n", "gold", "=", "tgt_seq", "\n", "# forward", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "#print('pred shape', pred.shape)", "\n", "#print('gold shape', gold.shape)", "\n", "\n", "# backward", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "#print(loss)", "\n", "#print(n_correct)", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# update parameters", "\n", "optimizer", ".", "step_and_update_lr", "(", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.eval_epoch": [[107, 140], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "map", "model", "train_res.cal_performence", "loss.item", "gold.ne", "gold.ne.sum().item", "loss_kl.item", "len", "loss_recon.item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", ":", "\n", "    ", "'''Epoch operation in evaluation phase'''", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "validation_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Validation) '", ",", "leave", "=", "False", ")", ":", "\n", "# prepare data", "\n", "            ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "gold", "=", "tgt_seq", "\n", "\n", "# forward", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", "=", "1", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "\n", "", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.train": [[142, 195], ["utils.cyclical_annealing.frange_cycle_linear", "range", "print", "print", "time.time", "train_res.train_epoch", "print", "time.time", "train_res.eval_epoch", "print", "model.state_dict", "open", "open", "log_tf.write", "log_vf.write", "torch.save", "torch.save", "torch.save", "torch.save", "open", "open", "log_tf.write", "log_vf.write", "math.exp", "math.exp", "max", "torch.save", "torch.save", "torch.save", "torch.save", "print", "train_res.sample_generation", "min", "min", "time.time", "time.time", "math.exp", "math.exp", "min", "min"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_linear", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.eval_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.sample_generation"], ["", "def", "train", "(", "model", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "device", ",", "idx2word", ",", "opt", ")", ":", "\n", "    ", "'''Start training'''", "\n", "log_train_file", "=", "None", "\n", "log_valid_file", "=", "None", "\n", "beta_epochs", "=", "frange_cycle_linear", "(", "start", "=", "0.0", ",", "stop", "=", "1.0", ",", "n_epoch", "=", "opt", ".", "epoch", ")", "\n", "\n", "if", "opt", ".", "log", ":", "\n", "        ", "log_train_file", "=", "opt", ".", "log", "+", "'.train.log'", "\n", "log_valid_file", "=", "opt", ".", "log", "+", "'.valid.log'", "\n", "\n", "print", "(", "'[Info] Training performence will be written to file: {} and {}'", ".", "format", "(", "log_train_file", ",", "log_valid_file", ")", ")", "\n", "with", "open", "(", "log_train_file", ",", "'w'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'w'", ")", "as", "log_vf", ":", "\n", "            ", "log_tf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "log_vf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "", "", "valid_accus", "=", "[", "]", "\n", "for", "epoch_i", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "beta_this_epoch", "=", "beta_epochs", "[", "epoch_i", "]", "\n", "print", "(", "'[ Epoch'", ",", "epoch_i", ",", "' ]'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_accu", ",", "train_loss_recon", ",", "train_loss_kl", "=", "train_epoch", "(", "\n", "model", ",", "training_data", ",", "optimizer", ",", "device", ",", "smoothing", "=", "opt", ".", "label_smoothing", ",", "lambda_kl", "=", "beta_this_epoch", "\n", ")", "\n", "print", "(", "' -(Trianing) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, train_loss_recon: {recon: 8.5f}, train_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", ",", "\n", "recon", "=", "train_loss_recon", ",", "kl", "=", "train_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "valid_loss", ",", "valid_accu", ",", "valid_loss_recon", ",", "valid_loss_kl", "=", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", "\n", "print", "(", "' -(Validation) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, valid_loss_recon: {recon: 8.5f}, valid_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", ",", "\n", "recon", "=", "valid_loss_recon", ",", "kl", "=", "valid_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "valid_accus", "+=", "[", "valid_accu", "]", "\n", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'settings'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch_i", "\n", "}", "\n", "if", "opt", ".", "save_model", ":", "\n", "            ", "if", "opt", ".", "save_mode", "==", "'all'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'_accu_{accu:3.3f}.chkpt'", ".", "format", "(", "accu", "=", "100", "*", "valid_accu", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "", "if", "opt", ".", "save_mode", "==", "'best'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'.chkpt'", "\n", "if", "valid_accu", ">=", "max", "(", "valid_accus", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "' -[Info] The check point file has been updated.'", ")", "\n", "sample_generation", "(", "model", ",", "training_data", ",", "idx2word", ",", "device", ")", "\n", "\n", "", "", "", "if", "log_train_file", "and", "log_valid_file", ":", "\n", "            ", "with", "open", "(", "log_train_file", ",", "'a'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'a'", ")", "as", "log_vf", ":", "\n", "                ", "log_tf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "train_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", "\n", ")", ")", "\n", "log_vf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "valid_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.sample_generation": [[197, 213], ["print", "print", "print", "print", "print", "map", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "model.predict", "show_case.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.to", "equ_nodes[].unsqueeze", "equ_adj_matrixs[].unsqueeze", "equ_node_lens[].unsqueeze", "sns_nodes[].unsqueeze", "sns_adj_matrixs[].unsqueeze", "sns_node_lens[].unsqueeze", "scene[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "", "", "", "def", "sample_generation", "(", "model", ",", "train_loader", ",", "idx2word", ",", "device", ")", ":", "\n", "    ", "for", "batch", "in", "train_loader", ":", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "", "print", "(", "'show case during training'", ")", "\n", "show_case", ",", "show_attn", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "dec_ids", ",", "attn_matrix", "=", "model", ".", "predict", "(", "\n", "input_equ_nodes", "=", "equ_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_equ_matrix", "=", "equ_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "equ_node_lens", "=", "equ_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "input_sns_nodes", "=", "sns_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_sns_matrix", "=", "sns_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "sns_node_lens", "=", "sns_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "scene", "=", "scene", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "device", "=", "device", ",", "max_tgt_len", "=", "50", ")", "\n", "show_case", ".", "append", "(", "''", ".", "join", "(", "idx2word", "[", "x", "]", "for", "x", "in", "dec_ids", ")", ")", "\n", "", "", "print", "(", "'one attention matrix is {}'", ".", "format", "(", "torch", ".", "stack", "(", "attn_matrix", ",", "1", ")", ")", ")", "\n", "print", "(", "show_case", "[", "0", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "1", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "2", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.main": [[214, 272], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "argparse.ArgumentParser.parse_args", "torch.load", "torch.load", "torch.load", "torch.load", "max", "train_res.prepare_dataloaders", "print", "torch.device", "torch.device", "torch.device", "torch.device", "model.dual_graph_vae_2.Graph2seq().to", "model.dual_graph_vae_2.ScheduledOptim", "train_res.train", "torch.Adam", "len", "model.dual_graph_vae_2.Graph2seq", "filter", "[].items", "Graph2seq().to.parameters"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.prepare_dataloaders", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "'''Main function'''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "\"./processed_data/dual_graph_rev_res_little.pt\"", ")", "\n", "parser", ".", "add_argument", "(", "'-epoch'", ",", "type", "=", "int", ",", "default", "=", "200", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "#node dim same as this", "\n", "parser", ".", "add_argument", "(", "'-n_hop'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'-hidden_size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'-z_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'-teacher_forcing'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "500", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-log'", ",", "default", "=", "'./logs/MaKE_res_seed_42_clean_little'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'./saved_model/MaKE_res_seed_42_clean_little'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_mode'", ",", "type", "=", "str", ",", "choices", "=", "[", "'all'", ",", "'best'", "]", ",", "default", "=", "'best'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-no_cuda'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-label_smoothing'", ",", "action", "=", "'store_true'", ")", "\n", "torch", ".", "manual_seed", "(", "42", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "not", "opt", ".", "no_cuda", "\n", "# god seed", "\n", "\n", "#====== Loading Dataset =====#", "\n", "data", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "opt", ".", "max_token_seq_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "data", "[", "'train'", "]", "[", "'ref'", "]", ")", "\n", "\n", "training_data", ",", "validation_data", "=", "prepare_dataloaders", "(", "data", ",", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "training_data", ".", "dataset", ".", "src_vocab_size", "\n", "\n", "#======= Preparing model ====#", "\n", "print", "(", "opt", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:0'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "# device = torch.device('cpu')", "\n", "graph2seq", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "opt", ".", "z_dim", ",", "\n", "output_size", "=", "opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "optimizer", "=", "ScheduledOptim", "(", "\n", "optim", ".", "Adam", "(", "\n", "filter", "(", "lambda", "x", ":", "x", ".", "requires_grad", ",", "graph2seq", ".", "parameters", "(", ")", ")", ",", "\n", "betas", "=", "(", "0.9", ",", "0.98", ")", ",", "eps", "=", "1e-09", ")", ",", "\n", "opt", ".", "hidden_size", ",", "opt", ".", "n_warmup_steps", "\n", ")", "\n", "idx2word", "=", "{", "value", ":", "item", "for", "item", ",", "value", "in", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ".", "items", "(", ")", "}", "\n", "train", "(", "graph2seq", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "device", ",", "idx2word", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_res.prepare_dataloaders": [[273, 308], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataset_dual.MyDataset", "dataset_dual.MyDataset"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "data", ",", "opt", ")", ":", "\n", "# =====Prepareing DataLoader=====", "\n", "    ", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'train'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'train'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'train'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'train'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'train'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'train'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "20", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "True", "\n", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'dev'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'dev'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'dev'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'dev'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'dev'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'dev'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "20", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence": [[21, 32], ["train_no_plan.cal_loss", "gold.contiguous().view.contiguous().view", "gold.contiguous().view.ne", "pred.eq", "n_correct.masked_select().sum().item.masked_select().sum().item", "pred.max", "gold.contiguous().view.contiguous", "n_correct.masked_select().sum().item.masked_select().sum", "n_correct.masked_select().sum().item.masked_select"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_loss"], ["def", "cal_performence", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Apply label smooth if needed\n    \"\"\"", "\n", "loss", ",", "loss_recon", ",", "loss_kl", "=", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "pred", "=", "pred", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_correct", "=", "pred", ".", "eq", "(", "gold", ")", "\n", "n_correct", "=", "n_correct", ".", "masked_select", "(", "non_pad_mask", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "return", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.gaussian_kld": [[33, 38], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "function", ["None"], ["", "def", "gaussian_kld", "(", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ")", ":", "\n", "    ", "kld", "=", "-", "0.5", "*", "torch", ".", "sum", "(", "1", "+", "(", "recog_logvar", "-", "prior_logvar", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "pow", "(", "prior_mu", "-", "recog_mu", ",", "2", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", "\n", "-", "torch", ".", "div", "(", "torch", ".", "exp", "(", "recog_logvar", ")", ",", "torch", ".", "exp", "(", "prior_logvar", ")", ")", ",", "1", ")", "\n", "return", "torch", ".", "sum", "(", "kld", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_loss": [[48, 58], ["gold.contiguous().view.contiguous().view", "torch.cross_entropy", "train_no_plan.gaussian_kld", "gold.contiguous().view.contiguous"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.gaussian_kld"], ["", "def", "cal_loss", "(", "pred", ",", "gold", ",", "mu_prior", ",", "log_var_prior", ",", "mu_posterior", ",", "log_var_posterior", ",", "plan_attns", ",", "lambda_kl", ")", ":", "\n", "    ", "\"\"\"\n    Calculate cross entropy loss, apply label smoothing if needed\n    \"\"\"", "\n", "gold", "=", "gold", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ")", "\n", "loss_recon", "=", "F", ".", "cross_entropy", "(", "pred", ",", "gold", ",", "ignore_index", "=", "Constants", ".", "PAD", ",", "reduction", "=", "'sum'", ")", "\n", "# loss_kl = lambda_kl*-0.5 * torch.sum(1 + log_var - mu.pow(2)-log_var.exp())", "\n", "loss_kl", "=", "lambda_kl", "*", "gaussian_kld", "(", "mu_posterior", ",", "log_var_posterior", ",", "mu_prior", ",", "log_var_prior", ")", "\n", "# loss_sparse = sparse_resularizer(plan_attns)", "\n", "return", "loss_recon", "+", "loss_kl", ",", "loss_recon", ",", "loss_kl", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train_epoch": [[59, 108], ["model.train", "tqdm.tqdm", "map", "optimizer.zero_grad", "model", "train_no_plan.cal_performence", "loss.backward", "optimizer.step", "scheduler.step", "loss.item", "loss_kl.item", "loss_recon.item", "len", "gold.ne", "gold.ne.sum().item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "train_epoch", "(", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", ",", "lambda_kl", ")", ":", "\n", "    ", "'''Epoch operation in training phase'''", "\n", "model", ".", "train", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "\n", "for", "batch", "in", "tqdm", "(", "training_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Training) '", ",", "leave", "=", "False", ")", ":", "\n", "\n", "# prepare data", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "#print('src_seq shape:', src_seq.shape)", "\n", "#print('src_pos shape:', src_pos.shape)", "\n", "#print('tgt_seq shape:', tgt_seq.shape)", "\n", "#print('tgt_pos shape:', tgt_pos.shape)", "\n", "gold", "=", "tgt_seq", "\n", "# forward", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "#print('pred shape', pred.shape)", "\n", "#print('gold shape', gold.shape)", "\n", "\n", "# backward", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", ")", "\n", "#print(loss)", "\n", "#print(n_correct)", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "# update parameters", "\n", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.eval_epoch": [[110, 143], ["model.eval", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "tqdm.tqdm", "map", "model", "train_no_plan.cal_performence", "loss.item", "gold.ne", "gold.ne.sum().item", "loss_kl.item", "len", "loss_recon.item", "x.to", "gold.ne.sum"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.cal_performence"], ["", "def", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", ":", "\n", "    ", "'''Epoch operation in evaluation phase'''", "\n", "model", ".", "eval", "(", ")", "\n", "total_loss", "=", "0", "\n", "n_word_total", "=", "0", "\n", "n_word_correct", "=", "0", "\n", "total_loss_recon", ",", "total_loss_kl", "=", "0", ",", "0", "\n", "total_sen", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "batch", "in", "tqdm", "(", "validation_data", ",", "mininterval", "=", "2", ",", "desc", "=", "' -(Validation) '", ",", "leave", "=", "False", ")", ":", "\n", "# prepare data", "\n", "            ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "gold", "=", "tgt_seq", "\n", "\n", "# forward", "\n", "pred", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "=", "model", "(", "equ_nodes", ",", "equ_adj_matrixs", ",", "equ_node_lens", ",", "sns_nodes", ",", "sns_adj_matrixs", ",", "sns_node_lens", ",", "tgt_seq", ",", "scene", ",", "device", ")", "\n", "loss", ",", "n_correct", ",", "loss_recon", ",", "loss_kl", "=", "cal_performence", "(", "pred", ",", "gold", ",", "prior_mu", ",", "prior_logvar", ",", "recog_mu", ",", "recog_logvar", ",", "plan_attns", ",", "lambda_kl", "=", "1", ")", "\n", "\n", "# note keeping", "\n", "total_loss", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "non_pad_mask", "=", "gold", ".", "ne", "(", "Constants", ".", "PAD", ")", "\n", "n_word", "=", "non_pad_mask", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "n_word_total", "+=", "n_word", "\n", "n_word_correct", "+=", "n_correct", "\n", "total_loss_kl", "+=", "loss_kl", ".", "item", "(", ")", "\n", "total_sen", "+=", "len", "(", "equ_nodes", ")", "\n", "total_loss_recon", "+=", "loss_recon", ".", "item", "(", ")", "\n", "# total_loss_sparse += loss_sparse.item()", "\n", "\n", "", "", "loss_per_word", "=", "total_loss", "/", "n_word_total", "\n", "accuracy", "=", "n_word_correct", "/", "n_word_total", "\n", "return", "loss_per_word", ",", "accuracy", ",", "total_loss_recon", "/", "n_word_total", ",", "total_loss_kl", "/", "total_sen", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train": [[145, 198], ["utils.cyclical_annealing.frange_cycle_linear", "range", "print", "print", "time.time", "train_no_plan.train_epoch", "print", "time.time", "train_no_plan.eval_epoch", "print", "model.state_dict", "open", "open", "log_tf.write", "log_vf.write", "torch.save", "torch.save", "torch.save", "torch.save", "open", "open", "log_tf.write", "log_vf.write", "math.exp", "math.exp", "max", "torch.save", "torch.save", "torch.save", "torch.save", "print", "train_no_plan.sample_generation", "min", "min", "time.time", "time.time", "math.exp", "math.exp", "min", "min"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_linear", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.eval_epoch", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.sample_generation"], ["", "def", "train", "(", "model", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", ":", "\n", "    ", "'''Start training'''", "\n", "log_train_file", "=", "None", "\n", "log_valid_file", "=", "None", "\n", "beta_epochs", "=", "frange_cycle_linear", "(", "start", "=", "0.0", ",", "stop", "=", "1.0", ",", "n_epoch", "=", "opt", ".", "epoch", ")", "\n", "\n", "if", "opt", ".", "log", ":", "\n", "        ", "log_train_file", "=", "opt", ".", "log", "+", "'.train.log'", "\n", "log_valid_file", "=", "opt", ".", "log", "+", "'.valid.log'", "\n", "\n", "print", "(", "'[Info] Training performence will be written to file: {} and {}'", ".", "format", "(", "log_train_file", ",", "log_valid_file", ")", ")", "\n", "with", "open", "(", "log_train_file", ",", "'w'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'w'", ")", "as", "log_vf", ":", "\n", "            ", "log_tf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "log_vf", ".", "write", "(", "'epoch,loss,ppl,accuracy\\n'", ")", "\n", "", "", "valid_accus", "=", "[", "]", "\n", "for", "epoch_i", "in", "range", "(", "opt", ".", "epoch", ")", ":", "\n", "        ", "beta_this_epoch", "=", "beta_epochs", "[", "epoch_i", "]", "\n", "print", "(", "'[ Epoch'", ",", "epoch_i", ",", "' ]'", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "train_loss", ",", "train_accu", ",", "train_loss_recon", ",", "train_loss_kl", "=", "train_epoch", "(", "\n", "model", ",", "training_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "smoothing", "=", "opt", ".", "label_smoothing", ",", "lambda_kl", "=", "beta_this_epoch", "\n", ")", "\n", "print", "(", "' -(Trianing) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, train_loss_recon: {recon: 8.5f}, train_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", ",", "\n", "recon", "=", "train_loss_recon", ",", "kl", "=", "train_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "start", "=", "time", ".", "time", "(", ")", "\n", "valid_loss", ",", "valid_accu", ",", "valid_loss_recon", ",", "valid_loss_kl", "=", "eval_epoch", "(", "model", ",", "validation_data", ",", "device", ")", "\n", "print", "(", "' -(Validation) ppl: {ppl: 8.5f}, accuracy: {accu:3.3f}, valid_loss_recon: {recon: 8.5f}, valid_loss_kl:{kl: 8.5f}, elapse: {elapse:3.3f} min'", ".", "format", "(", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", ",", "\n", "recon", "=", "valid_loss_recon", ",", "kl", "=", "valid_loss_kl", ",", "elapse", "=", "(", "time", ".", "time", "(", ")", "-", "start", ")", "/", "60", ")", ")", "\n", "valid_accus", "+=", "[", "valid_accu", "]", "\n", "model_state_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "checkpoint", "=", "{", "\n", "'model'", ":", "model_state_dict", ",", "\n", "'settings'", ":", "opt", ",", "\n", "'epoch'", ":", "epoch_i", "\n", "}", "\n", "if", "opt", ".", "save_model", ":", "\n", "            ", "if", "opt", ".", "save_mode", "==", "'all'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'_accu_{accu:3.3f}.chkpt'", ".", "format", "(", "accu", "=", "100", "*", "valid_accu", ")", "\n", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "", "if", "opt", ".", "save_mode", "==", "'best'", ":", "\n", "                ", "model_name", "=", "opt", ".", "save_model", "+", "'.chkpt'", "\n", "if", "valid_accu", ">=", "max", "(", "valid_accus", ")", ":", "\n", "                    ", "torch", ".", "save", "(", "checkpoint", ",", "model_name", ")", "\n", "print", "(", "' -[Info] The check point file has been updated.'", ")", "\n", "sample_generation", "(", "model", ",", "training_data", ",", "idx2word", ",", "device", ")", "\n", "\n", "", "", "", "if", "log_train_file", "and", "log_valid_file", ":", "\n", "            ", "with", "open", "(", "log_train_file", ",", "'a'", ")", "as", "log_tf", ",", "open", "(", "log_valid_file", ",", "'a'", ")", "as", "log_vf", ":", "\n", "                ", "log_tf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "train_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "train_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "train_accu", "\n", ")", ")", "\n", "log_vf", ".", "write", "(", "'{epoch}, {loss: 8.5f},{ppl: 8.5f},{accu: 3.3f}\\n'", ".", "format", "(", "\n", "epoch", "=", "epoch_i", ",", "loss", "=", "valid_loss", ",", "ppl", "=", "math", ".", "exp", "(", "min", "(", "valid_loss", ",", "100", ")", ")", ",", "accu", "=", "100", "*", "valid_accu", "\n", ")", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.sample_generation": [[200, 216], ["print", "print", "print", "print", "print", "map", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "range", "model.predict", "show_case.append", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "x.to", "equ_nodes[].unsqueeze", "equ_adj_matrixs[].unsqueeze", "equ_node_lens[].unsqueeze", "sns_nodes[].unsqueeze", "sns_adj_matrixs[].unsqueeze", "sns_node_lens[].unsqueeze", "scene[].unsqueeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "", "", "", "def", "sample_generation", "(", "model", ",", "train_loader", ",", "idx2word", ",", "device", ")", ":", "\n", "    ", "for", "batch", "in", "train_loader", ":", "\n", "        ", "equ_nodes", ",", "sns_nodes", ",", "equ_node_lens", ",", "sns_node_lens", ",", "equ_adj_matrixs", ",", "sns_adj_matrixs", ",", "tgt_seq", ",", "scene", "=", "map", "(", "lambda", "x", ":", "x", ".", "to", "(", "device", ")", ",", "batch", ")", "\n", "", "print", "(", "'show case during training'", ")", "\n", "show_case", ",", "show_attn", "=", "[", "]", ",", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "            ", "dec_ids", ",", "attn_matrix", "=", "model", ".", "predict", "(", "\n", "input_equ_nodes", "=", "equ_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_equ_matrix", "=", "equ_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "equ_node_lens", "=", "equ_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "input_sns_nodes", "=", "sns_nodes", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "adj_sns_matrix", "=", "sns_adj_matrixs", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "sns_node_lens", "=", "sns_node_lens", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "scene", "=", "scene", "[", "i", "]", ".", "unsqueeze", "(", "0", ")", ",", "device", "=", "device", ",", "max_tgt_len", "=", "50", ")", "\n", "show_case", ".", "append", "(", "''", ".", "join", "(", "idx2word", "[", "x", "]", "for", "x", "in", "dec_ids", ")", ")", "\n", "", "", "print", "(", "'one attention matrix is {}'", ".", "format", "(", "torch", ".", "stack", "(", "attn_matrix", ",", "1", ")", ")", ")", "\n", "print", "(", "show_case", "[", "0", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "1", "]", "+", "'\\n'", ")", "\n", "print", "(", "show_case", "[", "2", "]", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.main": [[217, 293], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "argparse.ArgumentParser.parse_args", "torch.load", "torch.load", "torch.load", "torch.load", "max", "print", "train_no_plan.prepare_dataloaders", "print", "print", "torch.device", "torch.device", "torch.device", "torch.device", "model.model_no_plan.Graph2seq().to", "transformers.optimization.AdamW", "transformers.optimization.get_linear_schedule_with_warmup", "train_no_plan.train", "Graph2seq().to.parameters", "len", "len", "model.model_no_plan.Graph2seq", "[].items"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.prepare_dataloaders", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.train"], ["", "def", "main", "(", ")", ":", "\n", "    ", "'''Main function'''", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "'-data'", ",", "default", "=", "'./processed_data/dual_graph_rev_res.pt'", ")", "\n", "parser", ".", "add_argument", "(", "'-epoch'", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "'-batch_size'", ",", "type", "=", "int", ",", "default", "=", "16", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-embedding_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "#node dim same as this", "\n", "parser", ".", "add_argument", "(", "'-n_hop'", ",", "type", "=", "int", ",", "default", "=", "3", ")", "\n", "parser", ".", "add_argument", "(", "'-hidden_size'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'-z_dim'", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "'-teacher_forcing'", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-n_warmup_steps'", ",", "type", "=", "int", ",", "default", "=", "500", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-dropout'", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-log'", ",", "default", "=", "'./logs/MaKE_res_no_plan'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_model'", ",", "default", "=", "'./saved_model/MaKE_res_no_plan'", ")", "\n", "parser", ".", "add_argument", "(", "'-save_mode'", ",", "type", "=", "str", ",", "choices", "=", "[", "'all'", ",", "'best'", "]", ",", "default", "=", "'best'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'-no_cuda'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'-label_smoothing'", ",", "action", "=", "'store_true'", ")", "\n", "torch", ".", "manual_seed", "(", "42", ")", "\n", "opt", "=", "parser", ".", "parse_args", "(", ")", "\n", "opt", ".", "cuda", "=", "not", "opt", ".", "no_cuda", "\n", "# god seed", "\n", "\n", "#====== Loading Dataset =====#", "\n", "data", "=", "torch", ".", "load", "(", "opt", ".", "data", ")", "\n", "opt", ".", "max_token_seq_len", "=", "max", "(", "len", "(", "x", ")", "for", "x", "in", "data", "[", "'train'", "]", "[", "'ref'", "]", ")", "\n", "print", "(", "'max token length is:'", ",", "opt", ".", "max_token_seq_len", ")", "\n", "\n", "training_data", ",", "validation_data", "=", "prepare_dataloaders", "(", "data", ",", "opt", ")", "\n", "opt", ".", "vocab_size", "=", "training_data", ".", "dataset", ".", "src_vocab_size", "\n", "print", "(", "'vocab size is:'", ",", "opt", ".", "vocab_size", ")", "\n", "\n", "#======= Preparing model ====#", "\n", "print", "(", "opt", ")", "\n", "device", "=", "torch", ".", "device", "(", "'cuda:4'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "# device = torch.device('cpu')", "\n", "graph2seq", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "opt", ".", "z_dim", ",", "\n", "output_size", "=", "opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", ")", ".", "to", "(", "device", ")", "\n", "\n", "\n", "# optimizer = ScheduledOptim(", "\n", "#     optim.Adam(", "\n", "#         filter(lambda x: x.requires_grad, graph2seq.parameters()),", "\n", "#         betas=(0.9,0.98),eps=1e-09),", "\n", "#     opt.hidden_size, opt.n_warmup_steps", "\n", "# )", "\n", "optimizer", "=", "AdamW", "(", "graph2seq", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "1e-3", ",", "# args.learning_rate - default is 5e-5, our notebook had 2e-5", "\n", "eps", "=", "1e-8", "# args.adam_epsilon  - default is 1e-8.", "\n", ")", "\n", "# Number of training epochs (authors recommend between 2 and 4)", "\n", "epochs", "=", "opt", ".", "epoch", "\n", "\n", "# Total number of training steps is number of batches * number of epochs.", "\n", "total_steps", "=", "len", "(", "training_data", ")", "*", "epochs", "\n", "\n", "# Create the learning rate scheduler.", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "\n", "num_warmup_steps", "=", "0", ",", "# Default value in run_glue.py", "\n", "num_training_steps", "=", "total_steps", ")", "\n", "# train(model, tokenizer, train_loader, valid_loader, optimizer, scheduler, device, opt)", "\n", "\n", "idx2word", "=", "{", "value", ":", "item", "for", "item", ",", "value", "in", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ".", "items", "(", ")", "}", "\n", "train", "(", "graph2seq", ",", "training_data", ",", "validation_data", ",", "optimizer", ",", "scheduler", ",", "device", ",", "idx2word", ",", "opt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.None.train_no_plan.prepare_dataloaders": [[294, 329], ["torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "dataset_dual.MyDataset", "dataset_dual.MyDataset"], "function", ["None"], ["", "def", "prepare_dataloaders", "(", "data", ",", "opt", ")", ":", "\n", "# =====Prepareing DataLoader=====", "\n", "    ", "train_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'train'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'train'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'train'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'train'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'train'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'train'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "True", "\n", ")", "\n", "valid_loader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "\n", "MyDataset", "(", "\n", "src_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "tgt_word2idx", "=", "data", "[", "'dict'", "]", "[", "'tgt'", "]", ",", "\n", "node_insts", "=", "data", "[", "'dev'", "]", "[", "'node_1'", "]", ",", "# equation info", "\n", "rel_insts", "=", "data", "[", "'dev'", "]", "[", "'edge_1'", "]", ",", "\n", "node_insts_1", "=", "data", "[", "'dev'", "]", "[", "'node_2'", "]", ",", "# common sense info", "\n", "rel_insts_1", "=", "data", "[", "'dev'", "]", "[", "'edge_2'", "]", ",", "\n", "scene_insts", "=", "data", "[", "'dev'", "]", "[", "'scene'", "]", ",", "\n", "tgt_insts", "=", "data", "[", "'dev'", "]", "[", "'ref'", "]", "\n", ")", ",", "\n", "num_workers", "=", "4", ",", "\n", "batch_size", "=", "opt", ".", "batch_size", ",", "\n", "collate_fn", "=", "collate_fn", ",", "\n", "shuffle", "=", "False", ",", "\n", ")", "\n", "return", "train_loader", ",", "valid_loader", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_linear": [[6, 19], ["numpy.ones", "range", "int", "int"], "function", ["None"], ["def", "frange_cycle_linear", "(", "start", ",", "stop", ",", "n_epoch", ",", "n_cycle", "=", "4", ",", "ratio", "=", "0.5", ")", ":", "\n", "    ", "L", "=", "np", ".", "ones", "(", "n_epoch", ")", "\n", "period", "=", "n_epoch", "/", "n_cycle", "\n", "step", "=", "(", "stop", "-", "start", ")", "/", "(", "period", "*", "ratio", ")", "# linear schedule", "\n", "\n", "for", "c", "in", "range", "(", "n_cycle", ")", ":", "\n", "\n", "        ", "v", ",", "i", "=", "start", ",", "0", "\n", "while", "v", "<=", "stop", "and", "(", "int", "(", "i", "+", "c", "*", "period", ")", "<", "n_epoch", ")", ":", "\n", "            ", "L", "[", "int", "(", "i", "+", "c", "*", "period", ")", "]", "=", "v", "\n", "v", "+=", "step", "\n", "i", "+=", "1", "\n", "", "", "return", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_sigmoid": [[21, 36], ["numpy.ones", "range", "int", "numpy.exp"], "function", ["None"], ["", "def", "frange_cycle_sigmoid", "(", "start", ",", "stop", ",", "n_epoch", ",", "n_cycle", "=", "4", ",", "ratio", "=", "0.5", ")", ":", "\n", "    ", "L", "=", "np", ".", "ones", "(", "n_epoch", ")", "\n", "period", "=", "n_epoch", "/", "n_cycle", "\n", "step", "=", "(", "stop", "-", "start", ")", "/", "(", "period", "*", "ratio", ")", "# step is in [0,1]", "\n", "\n", "# transform into [-6, 6] for plots: v*12.-6.", "\n", "\n", "for", "c", "in", "range", "(", "n_cycle", ")", ":", "\n", "\n", "        ", "v", ",", "i", "=", "start", ",", "0", "\n", "while", "v", "<=", "stop", ":", "\n", "            ", "L", "[", "int", "(", "i", "+", "c", "*", "period", ")", "]", "=", "1.0", "/", "(", "1.0", "+", "np", ".", "exp", "(", "-", "(", "v", "*", "12.", "-", "6.", ")", ")", ")", "\n", "v", "+=", "step", "\n", "i", "+=", "1", "\n", "", "", "return", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange_cycle_cosine": [[40, 55], ["numpy.ones", "range", "int", "math.cos"], "function", ["None"], ["", "def", "frange_cycle_cosine", "(", "start", ",", "stop", ",", "n_epoch", ",", "n_cycle", "=", "4", ",", "ratio", "=", "0.5", ")", ":", "\n", "    ", "L", "=", "np", ".", "ones", "(", "n_epoch", ")", "\n", "period", "=", "n_epoch", "/", "n_cycle", "\n", "step", "=", "(", "stop", "-", "start", ")", "/", "(", "period", "*", "ratio", ")", "# step is in [0,1]", "\n", "\n", "# transform into [0, pi] for plots: ", "\n", "\n", "for", "c", "in", "range", "(", "n_cycle", ")", ":", "\n", "\n", "        ", "v", ",", "i", "=", "start", ",", "0", "\n", "while", "v", "<=", "stop", ":", "\n", "            ", "L", "[", "int", "(", "i", "+", "c", "*", "period", ")", "]", "=", "0.5", "-", ".5", "*", "math", ".", "cos", "(", "v", "*", "math", ".", "pi", ")", "\n", "v", "+=", "step", "\n", "i", "+=", "1", "\n", "", "", "return", "L", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.utils.cyclical_annealing.frange": [[56, 64], ["numpy.ones"], "function", ["None"], ["", "def", "frange", "(", "start", ",", "stop", ",", "step", ",", "n_epoch", ")", ":", "\n", "    ", "L", "=", "np", ".", "ones", "(", "n_epoch", ")", "\n", "v", ",", "i", "=", "start", ",", "0", "\n", "while", "v", "<=", "stop", ":", "\n", "        ", "L", "[", "i", "]", "=", "v", "\n", "v", "+=", "step", "\n", "i", "+=", "1", "\n", "", "return", "L", "", "", ""]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.Generator.__init__": [[14, 38], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.model_no_sns.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_wo_sns.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:5'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.Generator.translate_one": [[39, 42], ["gen_wo_sns.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.Generator.translate_with_beam": [[43, 46], ["gen_wo_sns.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.opt.__init__": [[48, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/MaKE_res_no_sns.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.GateNode.__init__": [[121, 128], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.ids2token_2": [[100, 110], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.end2end_beam": [[111, 118], ["generator.translate_with_beam", "gen_wo_sns.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_sns.beam_search_graph_gate_vae": [[130, 203], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_wo_sns.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_wo_sns.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "# cond_embedding = torch.cat([equ_encoder_hidden, sns_encoder_hidden],1)", "\n", "cond_embedding", "=", "equ_encoder_hidden", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ",", "device", "=", "device", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.opt.__init__": [[13, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/levi_2.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.Generator.__init__": [[21, 45], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.dual_graph_vae_2.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_no_levi.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:5'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.Generator.translate_one": [[46, 49], ["gen_no_levi.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.Generator.translate_with_beam": [[50, 53], ["gen_no_levi.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.GateNode.__init__": [[120, 127], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.ids2token_2": [[100, 110], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.end2end_beam": [[111, 118], ["generator.translate_with_beam", "gen_no_levi.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_levi.beam_search_graph_gate_vae": [[128, 200], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "torch.cat", "torch.cat", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_no_levi.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_no_levi.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.Generator.__init__": [[14, 38], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.model_no_symbolic.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_wo_symbolic.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:2'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.Generator.translate_one": [[39, 42], ["gen_wo_symbolic.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.Generator.translate_with_beam": [[43, 46], ["gen_wo_symbolic.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.opt.__init__": [[48, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/no_symbolic.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.GateNode.__init__": [[121, 128], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.ids2token_2": [[100, 110], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.end2end_beam": [[111, 118], ["generator.translate_with_beam", "gen_wo_symbolic.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_wo_symbolic.beam_search_graph_gate_vae": [[130, 203], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_wo_symbolic.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_wo_symbolic.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "# cond_embedding = torch.cat([equ_encoder_hidden, sns_encoder_hidden],1)", "\n", "cond_embedding", "=", "sns_encoder_hidden", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ",", "device", "=", "device", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.opt.__init__": [[13, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/dir_dual_3.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.Generator.__init__": [[21, 45], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.dual_graph_vae_2.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_MaKE.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:2'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.Generator.translate_one": [[46, 49], ["gen_MaKE.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.Generator.translate_with_beam": [[50, 53], ["gen_MaKE.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.GateNode.__init__": [[120, 127], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.ids2token_2": [[100, 110], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.end2end_beam": [[111, 118], ["generator.translate_with_beam", "gen_MaKE.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE.beam_search_graph_gate_vae": [[128, 200], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "torch.cat", "torch.cat", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_MaKE.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_MaKE.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.opt.__init__": [[13, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/schedule_dual_graph_rev_fix_with_reg.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.Generator.__init__": [[21, 45], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.dual_graph_vae_2.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_yes_reg.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:5'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.Generator.translate_one": [[46, 49], ["gen_yes_reg.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.Generator.translate_with_beam": [[50, 53], ["gen_yes_reg.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.GateNode.__init__": [[120, 127], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.ids2token_2": [[100, 110], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.end2end_beam": [[111, 118], ["generator.translate_with_beam", "gen_yes_reg.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_yes_reg.beam_search_graph_gate_vae": [[128, 200], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "torch.cat", "torch.cat", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_yes_reg.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_yes_reg.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.opt.__init__": [[13, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/dual_dir_fix_0.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.Generator.__init__": [[21, 45], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.dual_graph_vae_2.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_MaKE_2.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:2'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.Generator.translate_one": [[46, 49], ["gen_MaKE_2.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.Generator.translate_with_beam": [[50, 53], ["gen_MaKE_2.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.GateNode.__init__": [[120, 127], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.ids2token_2": [[100, 110], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.end2end_beam": [[111, 118], ["generator.translate_with_beam", "gen_MaKE_2.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_2.beam_search_graph_gate_vae": [[128, 200], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "torch.cat", "torch.cat", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_MaKE_2.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_MaKE_2.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.opt.__init__": [[14, 18], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/MaKE_res_seed_16.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.Generator.__init__": [[22, 46], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.dual_graph_vae_2.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_MaKE_res.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:1'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.Generator.translate_one": [[47, 50], ["gen_MaKE_res.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.Generator.translate_with_beam": [[51, 54], ["gen_MaKE_res.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.GateNode.__init__": [[121, 128], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.ids2token_2": [[101, 111], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.end2end_beam": [[112, 119], ["generator.translate_with_beam", "gen_MaKE_res.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_MaKE_res.beam_search_graph_gate_vae": [[129, 201], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "torch.cat", "torch.cat", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_MaKE_res.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_MaKE_res.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.opt.__init__": [[13, 17], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", "=", "'../saved_model/MaKE_res_no_plan.chkpt'", "\n", "self", ".", "cuda", "=", "True", "\n", "self", ".", "batch_size", "=", "1", "\n", "", "", "opt", "=", "opt", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.__init__": [[21, 45], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.load", "torch.load", "torch.load", "torch.load", "model.to.model_no_plan.Graph2seq", "model.to.to.load_state_dict", "print", "model.to.to.to", "gen_no_plan.Generator.model.eval"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "opt", ",", "mmi_opt", "=", "None", ",", "mmi_g", "=", "10", ",", "mmi_lambda", "=", "0.1", ",", "mmi_gamma", "=", "0.1", ")", ":", "\n", "        ", "self", ".", "opt", "=", "opt", "\n", "self", ".", "device", "=", "torch", ".", "device", "(", "'cuda:4'", "if", "opt", ".", "cuda", "else", "'cpu'", ")", "\n", "\n", "checkpoint", "=", "torch", ".", "load", "(", "opt", ".", "model", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "model_opt", "=", "checkpoint", "[", "'settings'", "]", "\n", "self", ".", "model_opt", "=", "model_opt", "\n", "model", "=", "Graph2seq", "(", "\n", "vocab_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "embedding_dim", "=", "model_opt", ".", "embedding_dim", ",", "\n", "hidden_size", "=", "model_opt", ".", "hidden_size", ",", "\n", "z_dim", "=", "model_opt", ".", "z_dim", ",", "\n", "output_size", "=", "model_opt", ".", "vocab_size", ",", "\n", "n_hop", "=", "model_opt", ".", "n_hop", ",", "\n", "teacher_forcing", "=", "model_opt", ".", "teacher_forcing", ",", "\n", "dropout", "=", "0.1", "\n", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "'model'", "]", ")", "\n", "print", "(", "'[Info] Trained model state loaded.'", ")", "\n", "model", "=", "model", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "beam_width", "=", "20", "\n", "self", ".", "output_beam", "=", "5", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_one": [[46, 49], ["gen_no_plan.Generator.model.predict"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict"], ["", "def", "translate_one", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ")", ":", "\n", "        ", "dec_ids", ",", "attn_weights", "=", "self", ".", "model", ".", "predict", "(", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ")", "\n", "return", "dec_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam": [[50, 53], ["gen_no_plan.beam_search_graph_gate_vae"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae"], ["", "def", "translate_with_beam", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", ":", "\n", "        ", "attns", ",", "res", "=", "beam_search_graph_gate_vae", "(", "self", ".", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "self", ".", "device", ",", "self", ".", "model_opt", ".", "max_token_seq_len", "+", "1", ",", "self", ".", "beam_width", ",", "self", ".", "output_beam", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.GateNode.__init__": [[120, 127], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden", ",", "previous_node", ",", "decoder_input", ",", "attn", ",", "log_prob", ",", "length", ")", ":", "\n", "        ", "self", ".", "hidden", "=", "hidden", "\n", "self", ".", "previous_node", "=", "previous_node", "\n", "self", ".", "decoder_input", "=", "decoder_input", "\n", "self", ".", "attn", "=", "attn", "\n", "self", ".", "log_prob", "=", "log_prob", "\n", "self", ".", "length", "=", "length", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2": [[100, 110], ["res.append", "res.append"], "function", ["None"], ["def", "ids2token_2", "(", "ids", ",", "lex", ",", "idx2word", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "#print('before delexicalization is:', ' '.join([idx2word[x] for x in ids]))", "\n", "for", "id_", "in", "ids", ":", "\n", "        ", "if", "id_", "in", "lex_tar_id", ":", "\n", "            ", "if", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", "is", "not", "None", ":", "\n", "                ", "res", ".", "append", "(", "lex", "[", "lex_tar_id_map", "[", "id_", "]", "]", ")", "\n", "", "", "else", ":", "\n", "            ", "res", ".", "append", "(", "idx2word", "[", "id_", "]", ")", "\n", "", "", "return", "''", ".", "join", "(", "res", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.end2end_beam": [[111, 118], ["generator.translate_with_beam", "gen_no_plan.ids2token_2", "all_text.append"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.Generator.translate_with_beam", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.ids2token_2"], ["", "def", "end2end_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "lex", ",", "idx2word", ",", "generator", ")", ":", "\n", "    ", "output", "=", "generator", ".", "translate_with_beam", "(", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ")", "\n", "all_text", "=", "[", "]", "\n", "for", "one_res", "in", "output", ":", "\n", "        ", "one_text", "=", "ids2token_2", "(", "one_res", ",", "lex", ",", "idx2word", ")", "\n", "all_text", ".", "append", "(", "one_text", ")", "\n", "", "return", "all_text", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.test.gen_no_plan.beam_search_graph_gate_vae": [[128, 200], ["model.eval", "torch.no_grad", "torch.no_grad", "model.embedding", "model.encoder_equ", "model.embedding", "model.encoder_sns", "torch.cat", "torch.cat", "model.prior_fc1", "model.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "gen_no_plan.GateNode", "queue.Queue", "queue.Queue.put", "sorted", "model.q_mu_prior", "model.q_logvar_prior", "torch.cat", "torch.cat", "queue.Queue.empty", "range", "sorted", "min", "range", "sorted.append", "res.append", "attns.append", "torch.LongTensor", "torch.LongTensor", "queue.Queue.qsize", "queue.Queue.get", "model.embedding", "model.decoder", "torch.log_softmax", "F.log_softmax.topk", "range", "len", "queue.Queue.put", "one_res.append", "one_attns.append", "end_nodes.append", "F.log_softmax.squeeze", "indices[].unsqueeze", "log_prob[].item", "gen_no_plan.GateNode", "sorted.append", "one_node.decoder_input.item", "one_node.attn.squeeze().cpu().numpy().tolist", "torch.LongTensor().to.item", "hidden.squeeze", "one_node.attn.squeeze().cpu().numpy", "one_node.attn.squeeze().cpu", "one_node.attn.squeeze"], "function", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "", "def", "beam_search_graph_gate_vae", "(", "model", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ",", "beam_width", "=", "3", ",", "output_num", "=", "3", ")", ":", "\n", "    ", "model", ".", "eval", "(", ")", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "model", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "model", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "model", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "model", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "# get condition embedding", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "model", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "model", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "model", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "model", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "decoder_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", ")", ".", "to", "(", "device", ")", "\n", "node", "=", "GateNode", "(", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", ",", "None", ",", "decoder_input", ",", "None", ",", "0", ",", "1", ")", "\n", "q", "=", "Queue", "(", ")", "\n", "q", ".", "put", "(", "node", ")", "\n", "end_nodes", "=", "[", "]", "\n", "while", "not", "q", ".", "empty", "(", ")", ":", "\n", "            ", "candidates", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "q", ".", "qsize", "(", ")", ")", ":", "\n", "                ", "node", "=", "q", ".", "get", "(", ")", "\n", "decoder_input", "=", "node", ".", "decoder_input", "\n", "prev_y", "=", "model", ".", "embedding", "(", "decoder_input", ")", "\n", "hidden", "=", "node", ".", "hidden", "\n", "\n", "if", "decoder_input", ".", "item", "(", ")", "==", "Constants", ".", "EOS", "or", "node", ".", "length", ">=", "max_tgt_len", ":", "\n", "                    ", "end_nodes", ".", "append", "(", "node", ")", "\n", "continue", "\n", "#                 print(\"prev_y shape\",prev_y.shape)", "\n", "#                 print('hidden shape', hidden.shape)", "\n", "#                 print(\"d_dec shape\", d_dec.shape)", "\n", "\n", "", "log_prob", ",", "hidden", ",", "attn", "=", "model", ".", "decoder", "(", "prev_y", ",", "hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "log_prob", "=", "F", ".", "log_softmax", "(", "log_prob", ".", "squeeze", "(", ")", ",", "dim", "=", "-", "1", ")", "\n", "log_prob", ",", "indices", "=", "log_prob", ".", "topk", "(", "beam_width", ")", "\n", "\n", "for", "k", "in", "range", "(", "beam_width", ")", ":", "\n", "                    ", "index", "=", "indices", "[", "k", "]", ".", "unsqueeze", "(", "0", ")", "\n", "log_p", "=", "log_prob", "[", "k", "]", ".", "item", "(", ")", "\n", "child", "=", "GateNode", "(", "hidden", ".", "squeeze", "(", "1", ")", ",", "node", ",", "index", ",", "attn", ",", "node", ".", "log_prob", "+", "log_p", ",", "node", ".", "length", "+", "1", ")", "\n", "candidates", ".", "append", "(", "(", "node", ".", "log_prob", "+", "log_p", ",", "child", ")", ")", "\n", "", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "length", "=", "min", "(", "len", "(", "candidates", ")", ",", "beam_width", ")", "\n", "for", "i", "in", "range", "(", "length", ")", ":", "\n", "                ", "q", ".", "put", "(", "candidates", "[", "i", "]", "[", "1", "]", ")", "\n", "", "", "candidates", "=", "[", "]", "\n", "for", "node", "in", "end_nodes", ":", "\n", "            ", "value", "=", "node", ".", "log_prob", "\n", "candidates", ".", "append", "(", "(", "value", ",", "node", ")", ")", "\n", "", "candidates", "=", "sorted", "(", "candidates", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "node", "=", "[", "x", "[", "1", "]", "for", "x", "in", "candidates", "[", ":", "output_num", "]", "]", "\n", "res", "=", "[", "]", "\n", "attns", "=", "[", "]", "\n", "for", "one_node", "in", "node", ":", "\n", "            ", "one_res", "=", "[", "]", "\n", "one_attns", "=", "[", "]", "\n", "while", "one_node", ".", "previous_node", "!=", "None", ":", "\n", "                ", "one_res", ".", "append", "(", "one_node", ".", "decoder_input", ".", "item", "(", ")", ")", "\n", "one_attns", ".", "append", "(", "one_node", ".", "attn", ".", "squeeze", "(", "0", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "tolist", "(", ")", ")", "\n", "one_node", "=", "one_node", ".", "previous_node", "\n", "", "res", ".", "append", "(", "one_res", "[", ":", ":", "-", "1", "]", ")", "\n", "attns", ".", "append", "(", "attns", "[", ":", ":", "-", "1", "]", ")", "\n", "", "", "return", "attns", ",", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Propogator.__init__": [[8, 22], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_dim", ")", ":", "\n", "        ", "super", "(", "Propogator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Propogator.forward": [[24, 33], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.Propogator.update_gate", "model_no_plan.Propogator.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.Propogator.transform"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "node_representation", ",", "adjmatrixs", ")", ":", "# ICLR 2016 fomulas implementation", "\n", "        ", "a", "=", "torch", ".", "bmm", "(", "adjmatrixs", ",", "node_representation", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "a", ",", "node_representation", ")", ",", "2", ")", "# bs * node_len * hidden", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "(", "a", ",", "r", "*", "node_representation", ")", ",", "2", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "output", "=", "(", "1", "-", "z", ")", "*", "node_representation", "+", "z", "*", "h_hat", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.EncoderGGNN.__init__": [[35, 48], ["torch.Module.__init__", "model_no_plan.Propogator", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model_no_plan.EncoderGGNN._initialization", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.EncoderGGNN._initialization"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "node_dim", ",", "hidden_dim", ",", "n_hop", "=", "5", ")", ":", "\n", "        ", "super", "(", "EncoderGGNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "n_hop", "=", "n_hop", "\n", "self", ".", "propogator", "=", "Propogator", "(", "self", ".", "node_dim", ")", "\n", "self", ".", "out1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "node_dim", "*", "2", ",", "hidden_dim", ")", "\n", ")", "\n", "# self.out2 = nn.Sequential(", "\n", "#     nn.Linear(self.node_dim * 2, self.node_dim),", "\n", "#     nn.Sigmoid()", "\n", "# )", "\n", "self", ".", "_initialization", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.EncoderGGNN._initialization": [[49, 54], ["model_no_plan.EncoderGGNN.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.fill_"], "methods", ["None"], ["", "def", "_initialization", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.EncoderGGNN.forward": [[55, 68], ["lengths.view.view.view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.EncoderGGNN.out1", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model_no_plan.EncoderGGNN.propogator"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "nodes_rep", ",", "adjmatrixs", ",", "lengths", ")", ":", "\n", "        ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# embeddings = self.embed(nodes)", "\n", "node_representation", "=", "nodes_rep", "\n", "init_node_representation", "=", "nodes_rep", "\n", "for", "_", "in", "range", "(", "self", ".", "n_hop", ")", ":", "\n", "            ", "node_representation", "=", "self", ".", "propogator", "(", "node_representation", ",", "adjmatrixs", ")", "\n", "", "gate_inputs", "=", "torch", ".", "cat", "(", "(", "node_representation", ",", "init_node_representation", ")", ",", "2", ")", "\n", "gate_outputs", "=", "self", ".", "out1", "(", "gate_inputs", ")", "\n", "# aggregate all node information as global vector", "\n", "features", "=", "torch", ".", "sum", "(", "gate_outputs", ",", "1", ")", "\n", "features", "=", "features", "/", "lengths", "\n", "return", "gate_outputs", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Constants.__init__": [[70, 96], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "BOS_WORD", "=", "'<s>'", "\n", "self", ".", "EOS_WORD", "=", "'</s>'", "\n", "self", ".", "PAD_WORD", "=", "'<blank>'", "\n", "self", ".", "UNK_WORD", "=", "'<unk>'", "\n", "self", ".", "head_info_num_WORD", "=", "'head_info_num'", "\n", "self", ".", "rabbit_entity_WORD", "=", "'rabbit_entity'", "\n", "self", ".", "rabbit_tou_num_WORD", "=", "'rabbit_tou_num'", "\n", "self", ".", "rabbit_jiao_num_WORD", "=", "'rabbit_jiao_num'", "\n", "self", ".", "jiao_info_num_WORD", "=", "'jiao_info_num'", "\n", "self", ".", "ji_entity_WORD", "=", "'ji_entity'", "\n", "self", ".", "ji_tou_num_WORD", "=", "'ji_tou_num'", "\n", "self", ".", "ji_jiao_num_WORD", "=", "'ji_jiao_num'", "\n", "\n", "self", ".", "PAD", "=", "0", "\n", "self", ".", "UNK", "=", "1", "\n", "self", ".", "BOS", "=", "2", "\n", "self", ".", "EOS", "=", "3", "\n", "self", ".", "head_info_num", "=", "4", "\n", "self", ".", "rabbit_entity", "=", "5", "\n", "self", ".", "rabbit_tou_num", "=", "6", "\n", "self", ".", "rabbit_jiao_num", "=", "7", "\n", "self", ".", "jiao_info_num", "=", "8", "\n", "self", ".", "ji_entity", "=", "9", "\n", "self", ".", "ji_tou_num", "=", "10", "\n", "self", ".", "ji_jiao_num", "=", "11", "\n", "", "", "Constants", "=", "Constants", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.ScheduledOptim.__init__": [[101, 106], ["numpy.power"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "d_model", ",", "n_warmup_steps", ")", ":", "\n", "        ", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "n_warmup_steps", "=", "n_warmup_steps", "\n", "self", ".", "n_current_steps", "=", "0", "\n", "self", ".", "init_lr", "=", "np", ".", "power", "(", "d_model", ",", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.ScheduledOptim.step_and_update_lr": [[107, 111], ["model_no_plan.ScheduledOptim._update_learning_rate", "model_no_plan.ScheduledOptim._optimizer.step"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._update_learning_rate"], ["", "def", "step_and_update_lr", "(", "self", ")", ":", "\n", "        ", "\"step with the inner optimizer\"", "\n", "self", ".", "_update_learning_rate", "(", ")", "\n", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.ScheduledOptim.zero_grad": [[112, 115], ["model_no_plan.ScheduledOptim._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"zero out the gradient by the inner optimizer\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.ScheduledOptim._get_lr_scale": [[116, 120], ["numpy.min", "numpy.power", "numpy.power"], "methods", ["None"], ["", "def", "_get_lr_scale", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "min", "(", "[", "\n", "np", ".", "power", "(", "self", ".", "n_current_steps", ",", "-", "0.5", ")", ",", "\n", "np", ".", "power", "(", "self", ".", "n_warmup_steps", ",", "-", "1.5", ")", "*", "self", ".", "n_current_steps", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.ScheduledOptim._update_learning_rate": [[122, 128], ["model_no_plan.ScheduledOptim._get_lr_scale"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._get_lr_scale"], ["", "def", "_update_learning_rate", "(", "self", ")", ":", "\n", "        ", "'''learning rate scheduleing per step'''", "\n", "self", ".", "n_current_steps", "+=", "1", "\n", "lr", "=", "self", ".", "init_lr", "*", "self", ".", "_get_lr_scale", "(", ")", "\n", "for", "param_group", "in", "self", ".", "_optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.MyGRUCell.__init__": [[138, 161], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "d_size", ",", "batch_first", "=", "True", ")", ":", "\n", "        ", "super", "(", "MyGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "w2h_r", "=", "nn", ".", "Linear", "(", "input_size", ",", "d_size", ")", "\n", "self", ".", "h2h_r", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "d_size", ")", "\n", "self", ".", "dc", "=", "nn", ".", "Linear", "(", "d_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.MyGRUCell.forward": [[163, 181], ["input_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.MyGRUCell.update_gate", "model_no_plan.MyGRUCell.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.MyGRUCell.transform", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "model_no_plan.MyGRUCell.output", "model_no_plan.MyGRUCell.dc", "model_no_plan.MyGRUCell.w2h_r", "model_no_plan.MyGRUCell.h2h_r"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_t", ",", "last_hidden", ",", "last_dt", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Do feedforward for one step\n        input_t: (batch_size, 1, input_size)\n        last_hidden: (bs, hidden_size)\n        last_dt: (bs, d_size)\n        \"\"\"", "\n", "input_t", "=", "input_t", ".", "squeeze", "(", "1", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "last_hidden", ",", "input_t", ")", ",", "-", "1", ")", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "[", "r", "*", "last_hidden", ",", "input_t", "]", ",", "-", "1", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "gate_r", "=", "torch", ".", "sigmoid", "(", "self", ".", "w2h_r", "(", "input_t", ")", "+", "alpha", "*", "self", ".", "h2h_r", "(", "last_hidden", ")", ")", "\n", "dt", "=", "gate_r", "*", "last_dt", "# bs * d_size", "\n", "hidden", "=", "(", "1", "-", "z", ")", "*", "last_hidden", "+", "z", "*", "h_hat", "+", "self", ".", "dc", "(", "dt", ")", "\n", "output", "=", "self", ".", "output", "(", "hidden", ")", "\n", "return", "output", ",", "hidden", ",", "dt", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Attention.__init__": [[183, 189], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "z_dim", ",", "emb_size", "=", "0", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "W1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", "+", "z_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "vt", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Attention.forward": [[189, 208], ["model_no_plan.Attention.W1", "model_no_plan.Attention.W2().unsqueeze", "model_no_plan.Attention.vt().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "u_i.masked_fill.masked_fill.masked_fill", "model_no_plan.Attention.W2", "model_no_plan.Attention.vt", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n", "# print('decoder state dimension,',decoder_state.shape)", "\n", "# print('encoder_outputs dimension,', encoder_outputs.shape)", "\n", "# (bs, seq_len, hidden_size)", "\n", "        ", "encoder_transform", "=", "self", ".", "W1", "(", "encoder_outputs", ")", "\n", "# (bs, 1(unsqueeze), hidden_size)", "\n", "decoder_transform", "=", "self", ".", "W2", "(", "decoder_state", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# # (bs, max_doc_len, 1) => (bs, max_doc_len)", "\n", "u_i", "=", "self", ".", "vt", "(", "torch", ".", "tanh", "(", "encoder_transform", "+", "decoder_transform", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# softmax with only valid inputs, excluding zero padding parts", "\n", "# # log-softmax for a better numerical stability", "\n", "if", "input_node_mask", "is", "not", "None", ":", "\n", "            ", "u_i", "=", "u_i", ".", "masked_fill", "(", "input_node_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# log_score = F.log_softmax(u_i, dim=-1)", "\n", "", "log_score", "=", "F", ".", "softmax", "(", "u_i", ",", "dim", "=", "-", "1", ")", "\n", "# log_score = masked_log_softmax(u_i, input_node_mask, dim=-1)", "\n", "return", "log_score", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.DecoderVAE.__init__": [[210, 224], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.GRU", "model_no_plan.Attention", "model_no_plan.Attention", "model_no_plan.Attention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "DecoderVAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "# self.rnn = nn.GRU(input_size=hidden_size+z_dim,hidden_size=hidden_size+z_dim, batch_first=True)", "\n", "# self.my_rnn_gate = MyGRUCell(input_size = hidden_size+z_dim, hidden_size=hidden_size+z_dim+embedding_dim, d_size=embedding_dim)", "\n", "self", ".", "my_rnn_gate", "=", "nn", ".", "GRU", "(", "input_size", "=", "hidden_size", ",", "hidden_size", "=", "2", "*", "hidden_size", "+", "z_dim", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_size", "\n", "self", ".", "attn_equ", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "attn_sns", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "attn_all", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "plan_w", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", "+", "z_dim", ",", "2", ")", "\n", "# self.plan_w = ScaledDotProductAttention(d_q=2*hidden_size+z_dim, d_k=hidden_size, d_attn=hidden_size,temperature=1)", "\n", "self", ".", "linear_map_context", "=", "nn", ".", "Linear", "(", "embedding_dim", "+", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "linear_map", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", "+", "z_dim", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.DecoderVAE.forward": [[225, 272], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.DecoderVAE.attn_all", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.DecoderVAE.linear_map_context", "model_no_plan.DecoderVAE.my_rnn_gate", "model_no_plan.DecoderVAE.linear_map", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.DecoderVAE.unsqueeze", "model_no_plan.DecoderVAE.unsqueeze", "prev_h_batch.unsqueeze", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.bmm.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_y_batch", ",", "prev_h_batch", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", ":", "\n", "        ", "\"\"\"\n        A foward path step to a Decoder\n        The step operates on one step-slice of the target sequence\n        :param prev_y_batch: embedded previous prediction bs*embedding_dim\n        :param prev_h_batch: current decoder state: bs * hidden_size(dec_dim)\n        :param z_sample: vae sample z: bs * z_dim\n        :param *_encoder_outputs\" bs * n * hidden_size, bs*m*hidden_size\n        equ_global, sns_global leave as future work\n        \"\"\"", "\n", "# calcualte attention from current RNN state and equation encoder outputs", "\n", "# attn_weights_equ = self.attn_equ(prev_h_batch, equ_encoder_outputs, input_equ_node_mask)", "\n", "# # Apply attention weights to encoder outputs to get weighted average", "\n", "# # bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "# context_equation = torch.bmm(attn_weights_equ.unsqueeze(1), equ_encoder_outputs)", "\n", "\n", "# # calculate attention fom current RNN state and common sense outputs", "\n", "# attn_weights_sns = self.attn_sns(prev_h_batch, sns_encoder_outputs, input_sns_node_mask)", "\n", "# # bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "# context_sns = torch.bmm(attn_weights_sns.unsqueeze(1), sns_encoder_outputs)", "\n", "\n", "all_encoder_outputs", "=", "torch", ".", "cat", "(", "(", "equ_encoder_outputs", ",", "sns_encoder_outputs", ")", ",", "1", ")", "\n", "if", "input_sns_node_mask", "is", "not", "None", ":", "\n", "            ", "node_mask", "=", "torch", ".", "cat", "(", "(", "input_equ_node_mask", ",", "input_sns_node_mask", ")", ",", "1", ")", "\n", "# print(\"all encoder outputs shape:\", all_encoder_outputs.shape)", "\n", "# print('node mask shape:', node_mask.shape)", "\n", "", "else", ":", "\n", "            ", "node_mask", "=", "None", "\n", "", "attn_weights_all", "=", "self", ".", "attn_all", "(", "prev_h_batch", ",", "all_encoder_outputs", ",", "node_mask", ")", "\n", "context_all", "=", "torch", ".", "bmm", "(", "attn_weights_all", ".", "unsqueeze", "(", "1", ")", ",", "all_encoder_outputs", ")", "\n", "\n", "# calculate plan attention, extract how many info from equ_encoder_outputs, how many info from sns_encoder_outputs", "\n", "# plan attention is conducted by softmax(ht-1W + b)", "\n", "# plan_attn_weight = F.softmax(self.plan_w(prev_h_batch), dim=-1) # bs * 2\uff0c\u8fd9\u91cc\u662f\u4e0d\u662f\u6539\u4e00\u4e0b\u597d\u4e00\u70b9", "\n", "# # print('plan attention shape is ',plan_attn_weight.shape)", "\n", "# combine_context = torch.cat((context_equation, context_sns), 1)", "\n", "# # print('combine context shape is, ', combine_context.shape)", "\n", "# context = torch.bmm(plan_attn_weight.unsqueeze(1), combine_context) # bs*1*2 x bs*2*hidden_size -> bs*1*hidden_size", "\n", "\n", "# context, plan_attn_weight = self.plan_w(prev_h_batch.unsqueeze(1),combine_context,combine_context)", "\n", "# combine embedded input word and attented context, run through RNN", "\n", "y_ctx", "=", "torch", ".", "cat", "(", "(", "prev_y_batch", ",", "context_all", ".", "squeeze", "(", "1", ")", ")", ",", "1", ")", "# bs*(hidden_size+embedding_dim)", "\n", "rnn_input", "=", "self", ".", "linear_map_context", "(", "y_ctx", ")", "# bs * hidden_size", "\n", "\n", "dec_output", ",", "dec_hidden", "=", "self", ".", "my_rnn_gate", "(", "rnn_input", ".", "unsqueeze", "(", "1", ")", ",", "prev_h_batch", ".", "unsqueeze", "(", "0", ")", ")", "\n", "dec_output", "=", "self", ".", "linear_map", "(", "dec_output", ")", "\n", "return", "dec_output", ",", "dec_hidden", ",", "attn_weights_all", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.ScaledDotProductAttention.__init__": [[274, 283], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_q", ",", "d_k", ",", "d_attn", ",", "temperature", ",", "attn_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "2", ")", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_q", ",", "d_attn", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs", ".", "weight", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_k", ",", "d_attn", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.ScaledDotProductAttention.forward": [[284, 297], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model_no_plan.ScaledDotProductAttention.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "model_no_plan.ScaledDotProductAttention.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model_no_plan.ScaledDotProductAttention.w_qs", "model_no_plan.ScaledDotProductAttention.w_ks", "k.transpose", "attn.masked_fill.masked_fill.masked_fill", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "mask", "=", "None", ")", ":", "\n", "        ", "q", ",", "k", "=", "self", ".", "w_qs", "(", "q", ")", ",", "self", ".", "w_ks", "(", "k", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "attn", "/", "self", ".", "temperature", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", ".", "masked_fill", "(", "mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "safe_attn", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "attn", ")", ",", "torch", ".", "zeros_like", "(", "attn", ")", ",", "attn", ")", "\n", "# attn[attn!=attn] = 0.0", "\n", "safe_attn", "=", "self", ".", "dropout", "(", "safe_attn", ")", "\n", "# print(attn)", "\n", "output", "=", "torch", ".", "bmm", "(", "safe_attn", ",", "v", ")", "\n", "return", "output", ",", "safe_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.WordRNN.__init__": [[299, 318], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model_no_plan.WordRNN.Ws1.data.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model_no_plan.WordRNN.Ws2.data.uniform_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_dim", ",", "dropout", "=", "0.1", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "super", "(", "WordRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "embed_size", "=", "embedding_dim", "\n", "self", ".", "hidden_size", "=", "hidden_dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "if", "pretrained", "is", "None", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", ".", "from_pretrained", "(", "pretrained", ")", "\n", "# self.word_encoder = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)", "\n", "# no bidirectional trytry", "\n", "", "self", ".", "word_encoder", "=", "nn", ".", "GRU", "(", "embedding_dim", ",", "hidden_dim", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "False", ")", "\n", "# self.Ws1 = nn.Parameter(torch.Tensor(1, 2*hidden_dim, 2*hidden_dim))", "\n", "self", ".", "Ws1", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws1", ".", "data", "=", "self", ".", "Ws1", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "# self.Ws2 = nn.Parameter(torch.Tensor(1, 1, 2*hidden_dim))", "\n", "self", ".", "Ws2", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws2", ".", "data", "=", "self", ".", "Ws2", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.WordRNN.forward": [[319, 338], ["len", "len", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "model_no_plan.WordRNN.embedding", "model_no_plan.WordRNN.dropout", "model_no_plan.WordRNN.word_encoder", "model_no_plan.WordRNN.dropout", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view.squeeze().masked_fill", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model_no_plan.WordRNN.Ws2.repeat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "model_no_plan.WordRNN.Ws1.repeat", "torch.softmax().view.squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "one_doc", ")", ":", "\n", "        ", "'''\n        one_doc: [[1,2,3,0],[2,3,4,5],[3,0,0,0]], doc_lens:[3,4,1]\n        '''", "\n", "seq_len", "=", "len", "(", "one_doc", "[", "0", "]", ")", "\n", "max_sent_len", "=", "len", "(", "one_doc", ")", "\n", "tmp_mask", "=", "torch", ".", "eq", "(", "one_doc", ",", "0", ")", "\n", "doc_embedding", "=", "self", ".", "embedding", "(", "one_doc", ")", "\n", "doc_embedding", "=", "self", ".", "dropout", "(", "doc_embedding", ")", "\n", "rnn_out", ",", "_", "=", "self", ".", "word_encoder", "(", "doc_embedding", ")", "\n", "#rnn_out = run_rnn(self.word_encoder,doc_embedding, doc_lens)", "\n", "rnn_out", "=", "self", ".", "dropout", "(", "rnn_out", ")", "\n", "final_T", "=", "torch", ".", "transpose", "(", "rnn_out", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "A", "=", "torch", ".", "tanh", "(", "torch", ".", "bmm", "(", "self", ".", "Ws1", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "final_T", ")", ")", "\n", "A", "=", "torch", ".", "bmm", "(", "self", ".", "Ws2", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "A", ")", "\n", "A", "=", "A", ".", "squeeze", "(", "1", ")", ".", "masked_fill", "(", "tmp_mask", ",", "-", "1e12", ")", "\n", "A", "=", "F", ".", "softmax", "(", "A", ",", "dim", "=", "1", ")", ".", "view", "(", "1", "*", "max_sent_len", ",", "-", "1", ",", "seq_len", ")", "\n", "final", "=", "torch", ".", "bmm", "(", "A", ",", "rnn_out", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Graph2seq.__init__": [[341, 365], ["torch.Module.__init__", "model_no_plan.EncoderGGNN", "model_no_plan.EncoderGGNN", "model_no_plan.WordRNN", "model_no_plan.DecoderVAE", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "n_hop", "=", "5", ",", "teacher_forcing", "=", "0.5", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "Graph2seq", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# the First encoder to encode equation information", "\n", "self", ".", "encoder_equ", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# the second encoder to encode common sense information", "\n", "self", ".", "encoder_sns", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# this is sentence encoder for training VAE posterior", "\n", "self", ".", "out_enc", "=", "WordRNN", "(", "vocab_size", "=", "vocab_size", ",", "embedding_dim", "=", "embedding_dim", ",", "hidden_dim", "=", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "decoder", "=", "DecoderVAE", "(", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "self", ".", "teacher_forcing", "=", "teacher_forcing", "\n", "# sample mu and logvars", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "\n", "self", ".", "q_mu_posterior", "=", "nn", ".", "Linear", "(", "3", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_posterior", "=", "nn", ".", "Linear", "(", "3", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "prior_fc1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "q_mu_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "# set embedding layer with the same parameters", "\n", "self", ".", "out_enc", ".", "embedding", ".", "weight", "=", "self", ".", "embedding", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Graph2seq.sample_z": [[366, 373], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul", "torch.randn_like.mul", "torch.randn_like.mul"], "methods", ["None"], ["", "def", "sample_z", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "\"\"\"\n        Reparameterization trick: z = mu + std*eps; eps ~ N(0,I)\n        \"\"\"", "\n", "std", "=", "torch", ".", "exp", "(", "logvar", "/", "2", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Graph2seq.sample_z_prior": [[374, 377], ["torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "sample_z_prior", "(", "self", ",", "mbsize", ",", "device", ")", ":", "\n", "        ", "z", "=", "torch", ".", "randn", "(", "mbsize", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Graph2seq.forward": [[378, 404], ["model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.encoder_equ", "model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.encoder_sns", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.Graph2seq.out_enc", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.Graph2seq.prior_fc1", "model_no_plan.Graph2seq.sample_z", "input_equ_nodes.eq", "input_sns_nodes.eq", "model_no_plan.Graph2seq.decode_dual", "logits.view.view.view", "model_no_plan.Graph2seq.q_mu_posterior", "model_no_plan.Graph2seq.q_logvar_posterior", "model_no_plan.Graph2seq.q_mu_prior", "model_no_plan.Graph2seq.q_logvar_prior", "logits.view.view.size"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.decode_dual"], ["", "def", "forward", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "input_target", ",", "scene", ",", "device", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# print('node representation dim is,', nodes_resp.shape)", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "output_embedding", "=", "self", ".", "out_enc", "(", "input_target", ")", "\n", "# get posterior mu & logvar", "\n", "recog_input", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "output_embedding", "]", ",", "1", ")", "\n", "recog_mu", ",", "recog_logvar", "=", "self", ".", "q_mu_posterior", "(", "recog_input", ")", ",", "self", ".", "q_logvar_posterior", "(", "recog_input", ")", "\n", "# get prior mu & logvar", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "# sample latent z during training, sample posterior, inference with prior", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "recog_mu", ",", "recog_logvar", ")", "\n", "input_equ_node_mask", "=", "input_equ_nodes", ".", "eq", "(", "0", ")", "\n", "input_sns_node_mask", "=", "input_sns_nodes", ".", "eq", "(", "0", ")", "\n", "\n", "# train with schedule sampling", "\n", "logits", ",", "plan_attns", "=", "self", ".", "decode_dual", "(", "input_target", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "\n", "sns_encoder_outputs", ",", "latent_sample", ",", "self", ".", "teacher_forcing", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "logits", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "2", ")", ")", "\n", "return", "logits", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Graph2seq.decode_dual": [[405, 432], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "random.random", "model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_hidden.squeeze.squeeze.squeeze", "model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_output.squeeze().max", "dec_hidden.squeeze.squeeze.squeeze", "dec_output.squeeze", "dec_output.squeeze", "dec_output.squeeze"], "methods", ["None"], ["", "def", "decode_dual", "(", "self", ",", "dec_input_var", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "teacher_forcing_ratio", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", ":", "\n", "        ", "bs", ",", "seq_len", "=", "dec_input_var", ".", "shape", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "z_sample", "]", ",", "dim", "=", "1", ")", "\n", "dec_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", "*", "bs", ")", ".", "to", "(", "device", ")", "\n", "predicted_logits", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "# use this to record the attention score", "\n", "# d_dec = d_initial", "\n", "for", "di", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "teacher_forcing", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "dec_input", "=", "dec_input_var", "[", ":", ",", "di", "]", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "dec_input", "=", "max_index", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "", "predicted_logits", "=", "torch", ".", "stack", "(", "predicted_logits", ",", "1", ")", "\n", "planning_probs", "=", "torch", ".", "stack", "(", "graph_attntion", ",", "1", ")", "\n", "return", "predicted_logits", ",", "planning_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Graph2seq.predict": [[433, 477], ["model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.encoder_equ", "model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.encoder_sns", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.Graph2seq.prior_fc1", "model_no_plan.Graph2seq.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_plan.Graph2seq.q_mu_prior", "model_no_plan.Graph2seq.q_logvar_prior", "model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.decoder", "graph_attntion.append", "dec_output.squeeze().max", "dec_ids.append", "dec_hidden.squeeze.squeeze.squeeze", "max_index.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "max_index.squeeze().item", "dec_output.squeeze", "max_index.squeeze"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "def", "predict", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "\n", "# get prior mu & logvar", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "dec_ids", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", "\n", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "# print(prev_y.shape)", "\n", "# print(dec_hidden.shape)", "\n", "# print(sns_encoder_outputs.shape)", "\n", "# print(latent_sample.shape)", "\n", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ".", "data", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "#max_index = F.softmax(dec_output, dim=-1).squeeze(1).multinomial(1)", "\n", "dec_ids", ".", "append", "(", "max_index", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "max_index", "\n", "# print(max_index)", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "1", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "max_index", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "graph_attntion", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.Graph2seq.predict_with_sampling": [[478, 544], ["model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.encoder", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "model_no_plan.Graph2seq.embedding", "model_no_plan.Graph2seq.decoder", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "dec_ids.append", "probs.clone.multinomial.squeeze", "dec_hidden.squeeze.squeeze.squeeze", "probs.clone.multinomial.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze.clone", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "probs.clone.multinomial.squeeze().item", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_probs.clone", "sorted_probs.clone.multinomial().view", "sorted_indices.gather", "sorted_probs.clone.gather().log", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "torch.softmax", "torch.softmax", "torch.softmax", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul_", "F.softmax().squeeze.clone.gather", "sorted_probs.clone.div_", "sorted_probs.clone.mul_", "sorted_probs.clone.add_", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "probs.clone.multinomial.squeeze", "decoder_output.div_", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "probs.clone.multinomial.view", "sorted_probs.clone.sum().unsqueeze", "sorted_probs.mul", "sorted_probs.clone.multinomial", "sorted_probs.clone.gather", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul", "F.softmax().squeeze.clone.gather", "F.softmax().squeeze.clone.sum", "probs.clone.multinomial.view", "sorted_probs.clone.sum", "F.softmax().squeeze.clone.sum"], "methods", ["None"], ["", "def", "predict_with_sampling", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "device", ",", "max_tgt_len", ",", "temp", "=", "None", ",", "k", "=", "None", ",", "p", "=", "None", ",", "m", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        some sampling based decoding method:\n        tem: temperature\n        k: top-k sampling method k\n        p: Nucleus sampling method\n        m: mass of original dist to interpolate\n        \"\"\"", "\n", "# embedding look up table", "\n", "nodes_resp", "=", "self", ".", "embedding", "(", "input_nodes", ")", "\n", "encoder_outputs", ",", "encoder_hidden", "=", "self", ".", "encoder", "(", "nodes_resp", ",", "adj_matrix", ",", "node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# decode", "\n", "dec_ids", ",", "attn_weight", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "encoder_hidden", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "decoder_output", ",", "dec_hidden", ",", "dec_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "encoder_outputs", ",", "input_node_mask", "=", "None", ")", "\n", "\n", "probs", "=", "F", ".", "softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "if", "temp", "is", "not", "None", ":", "\n", "                ", "samp_probs", "=", "F", ".", "softmax", "(", "decoder_output", ".", "div_", "(", "temp", ")", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "samp_probs", "=", "probs", ".", "clone", "(", ")", "\n", "", "if", "k", "is", "not", "None", ":", "\n", "                ", "indices_to_remove", "=", "samp_probs", "<", "torch", ".", "topk", "(", "samp_probs", ",", "k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "samp_probs", "[", "indices_to_remove", "]", "=", "0.", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul_", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "elif", "p", "is", "not", "None", ":", "\n", "                ", "sorted_probs", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "samp_probs", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "sorted_probs", ",", "dim", "=", "-", "1", ")", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "p", "\n", "sorted_indices_to_remove", "[", ":", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", ":", ",", "0", "]", "=", "0", "\n", "sorted_samp_probs", "=", "sorted_probs", ".", "clone", "(", ")", "\n", "sorted_samp_probs", "[", "sorted_indices_to_remove", "]", "=", "0", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "sorted_samp_probs", ".", "div_", "(", "sorted_samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "sorted_samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "sorted_samp_probs", ".", "add_", "(", "sorted_probs", ".", "mul", "(", "m", ")", ")", "\n", "", "sorted_next_indices", "=", "sorted_samp_probs", ".", "multinomial", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "next_tokens", "=", "sorted_indices", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", "\n", "next_logprobs", "=", "sorted_samp_probs", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", ".", "log", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "dec_ids", ".", "append", "(", "next_tokens", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "next_tokens", ".", "squeeze", "(", "1", ")", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "next_tokens", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "attn_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_plan.masked_log_softmax": [[129, 136], ["torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "mask.unsqueeze.float", "mask.unsqueeze.dim", "vector.dim", "mask.unsqueeze.unsqueeze"], "function", ["None"], ["", "", "", "def", "masked_log_softmax", "(", "vector", ",", "mask", ",", "dim", ")", ":", "\n", "\t", "if", "mask", "is", "not", "None", ":", "\n", "\t\t", "mask", "=", "mask", ".", "float", "(", ")", "\n", "while", "mask", ".", "dim", "(", ")", "<", "vector", ".", "dim", "(", ")", ":", "\n", "\t\t\t", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "vector", "=", "vector", "+", "(", "mask", "+", "1e-45", ")", ".", "log", "(", ")", "\n", "", "return", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "vector", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Propogator.__init__": [[8, 22], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_dim", ")", ":", "\n", "        ", "super", "(", "Propogator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Propogator.forward": [[24, 33], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.Propogator.update_gate", "model_no_sns.Propogator.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.Propogator.transform"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "node_representation", ",", "adjmatrixs", ")", ":", "# ICLR 2016 fomulas implementation", "\n", "        ", "a", "=", "torch", ".", "bmm", "(", "adjmatrixs", ",", "node_representation", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "a", ",", "node_representation", ")", ",", "2", ")", "# bs * node_len * hidden", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "(", "a", ",", "r", "*", "node_representation", ")", ",", "2", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "output", "=", "(", "1", "-", "z", ")", "*", "node_representation", "+", "z", "*", "h_hat", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.EncoderGGNN.__init__": [[35, 48], ["torch.Module.__init__", "model_no_sns.Propogator", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model_no_sns.EncoderGGNN._initialization", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.EncoderGGNN._initialization"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "node_dim", ",", "hidden_dim", ",", "n_hop", "=", "5", ")", ":", "\n", "        ", "super", "(", "EncoderGGNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "n_hop", "=", "n_hop", "\n", "self", ".", "propogator", "=", "Propogator", "(", "self", ".", "node_dim", ")", "\n", "self", ".", "out1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "node_dim", "*", "2", ",", "hidden_dim", ")", "\n", ")", "\n", "# self.out2 = nn.Sequential(", "\n", "#     nn.Linear(self.node_dim * 2, self.node_dim),", "\n", "#     nn.Sigmoid()", "\n", "# )", "\n", "self", ".", "_initialization", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.EncoderGGNN._initialization": [[49, 54], ["model_no_sns.EncoderGGNN.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.fill_"], "methods", ["None"], ["", "def", "_initialization", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.EncoderGGNN.forward": [[55, 68], ["lengths.view.view.view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.EncoderGGNN.out1", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model_no_sns.EncoderGGNN.propogator"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "nodes_rep", ",", "adjmatrixs", ",", "lengths", ")", ":", "\n", "        ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# embeddings = self.embed(nodes)", "\n", "node_representation", "=", "nodes_rep", "\n", "init_node_representation", "=", "nodes_rep", "\n", "for", "_", "in", "range", "(", "self", ".", "n_hop", ")", ":", "\n", "            ", "node_representation", "=", "self", ".", "propogator", "(", "node_representation", ",", "adjmatrixs", ")", "\n", "", "gate_inputs", "=", "torch", ".", "cat", "(", "(", "node_representation", ",", "init_node_representation", ")", ",", "2", ")", "\n", "gate_outputs", "=", "self", ".", "out1", "(", "gate_inputs", ")", "\n", "# aggregate all node information as global vector", "\n", "features", "=", "torch", ".", "sum", "(", "gate_outputs", ",", "1", ")", "\n", "features", "=", "features", "/", "lengths", "\n", "return", "gate_outputs", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Constants.__init__": [[70, 96], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "BOS_WORD", "=", "'<s>'", "\n", "self", ".", "EOS_WORD", "=", "'</s>'", "\n", "self", ".", "PAD_WORD", "=", "'<blank>'", "\n", "self", ".", "UNK_WORD", "=", "'<unk>'", "\n", "self", ".", "head_info_num_WORD", "=", "'head_info_num'", "\n", "self", ".", "rabbit_entity_WORD", "=", "'rabbit_entity'", "\n", "self", ".", "rabbit_tou_num_WORD", "=", "'rabbit_tou_num'", "\n", "self", ".", "rabbit_jiao_num_WORD", "=", "'rabbit_jiao_num'", "\n", "self", ".", "jiao_info_num_WORD", "=", "'jiao_info_num'", "\n", "self", ".", "ji_entity_WORD", "=", "'ji_entity'", "\n", "self", ".", "ji_tou_num_WORD", "=", "'ji_tou_num'", "\n", "self", ".", "ji_jiao_num_WORD", "=", "'ji_jiao_num'", "\n", "\n", "self", ".", "PAD", "=", "0", "\n", "self", ".", "UNK", "=", "1", "\n", "self", ".", "BOS", "=", "2", "\n", "self", ".", "EOS", "=", "3", "\n", "self", ".", "head_info_num", "=", "4", "\n", "self", ".", "rabbit_entity", "=", "5", "\n", "self", ".", "rabbit_tou_num", "=", "6", "\n", "self", ".", "rabbit_jiao_num", "=", "7", "\n", "self", ".", "jiao_info_num", "=", "8", "\n", "self", ".", "ji_entity", "=", "9", "\n", "self", ".", "ji_tou_num", "=", "10", "\n", "self", ".", "ji_jiao_num", "=", "11", "\n", "", "", "Constants", "=", "Constants", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.ScheduledOptim.__init__": [[101, 106], ["numpy.power"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "d_model", ",", "n_warmup_steps", ")", ":", "\n", "        ", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "n_warmup_steps", "=", "n_warmup_steps", "\n", "self", ".", "n_current_steps", "=", "0", "\n", "self", ".", "init_lr", "=", "np", ".", "power", "(", "d_model", ",", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.ScheduledOptim.step_and_update_lr": [[107, 111], ["model_no_sns.ScheduledOptim._update_learning_rate", "model_no_sns.ScheduledOptim._optimizer.step"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._update_learning_rate"], ["", "def", "step_and_update_lr", "(", "self", ")", ":", "\n", "        ", "\"step with the inner optimizer\"", "\n", "self", ".", "_update_learning_rate", "(", ")", "\n", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.ScheduledOptim.zero_grad": [[112, 115], ["model_no_sns.ScheduledOptim._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"zero out the gradient by the inner optimizer\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.ScheduledOptim._get_lr_scale": [[116, 120], ["numpy.min", "numpy.power", "numpy.power"], "methods", ["None"], ["", "def", "_get_lr_scale", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "min", "(", "[", "\n", "np", ".", "power", "(", "self", ".", "n_current_steps", ",", "-", "0.5", ")", ",", "\n", "np", ".", "power", "(", "self", ".", "n_warmup_steps", ",", "-", "1.5", ")", "*", "self", ".", "n_current_steps", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.ScheduledOptim._update_learning_rate": [[122, 128], ["model_no_sns.ScheduledOptim._get_lr_scale"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._get_lr_scale"], ["", "def", "_update_learning_rate", "(", "self", ")", ":", "\n", "        ", "'''learning rate scheduleing per step'''", "\n", "self", ".", "n_current_steps", "+=", "1", "\n", "lr", "=", "self", ".", "init_lr", "*", "self", ".", "_get_lr_scale", "(", ")", "\n", "for", "param_group", "in", "self", ".", "_optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.MyGRUCell.__init__": [[138, 161], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "d_size", ",", "batch_first", "=", "True", ")", ":", "\n", "        ", "super", "(", "MyGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "w2h_r", "=", "nn", ".", "Linear", "(", "input_size", ",", "d_size", ")", "\n", "self", ".", "h2h_r", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "d_size", ")", "\n", "self", ".", "dc", "=", "nn", ".", "Linear", "(", "d_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.MyGRUCell.forward": [[163, 181], ["input_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.MyGRUCell.update_gate", "model_no_sns.MyGRUCell.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.MyGRUCell.transform", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "model_no_sns.MyGRUCell.output", "model_no_sns.MyGRUCell.dc", "model_no_sns.MyGRUCell.w2h_r", "model_no_sns.MyGRUCell.h2h_r"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_t", ",", "last_hidden", ",", "last_dt", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Do feedforward for one step\n        input_t: (batch_size, 1, input_size)\n        last_hidden: (bs, hidden_size)\n        last_dt: (bs, d_size)\n        \"\"\"", "\n", "input_t", "=", "input_t", ".", "squeeze", "(", "1", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "last_hidden", ",", "input_t", ")", ",", "-", "1", ")", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "[", "r", "*", "last_hidden", ",", "input_t", "]", ",", "-", "1", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "gate_r", "=", "torch", ".", "sigmoid", "(", "self", ".", "w2h_r", "(", "input_t", ")", "+", "alpha", "*", "self", ".", "h2h_r", "(", "last_hidden", ")", ")", "\n", "dt", "=", "gate_r", "*", "last_dt", "# bs * d_size", "\n", "hidden", "=", "(", "1", "-", "z", ")", "*", "last_hidden", "+", "z", "*", "h_hat", "+", "self", ".", "dc", "(", "dt", ")", "\n", "output", "=", "self", ".", "output", "(", "hidden", ")", "\n", "return", "output", ",", "hidden", ",", "dt", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Attention.__init__": [[183, 189], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "z_dim", ",", "emb_size", "=", "0", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "W1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "z_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "vt", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Attention.forward": [[189, 208], ["model_no_sns.Attention.W1", "model_no_sns.Attention.W2().unsqueeze", "model_no_sns.Attention.vt().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "u_i.masked_fill.masked_fill.masked_fill", "model_no_sns.Attention.W2", "model_no_sns.Attention.vt", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n", "# print('decoder state dimension,',decoder_state.shape)", "\n", "# print('encoder_outputs dimension,', encoder_outputs.shape)", "\n", "# (bs, seq_len, hidden_size)", "\n", "        ", "encoder_transform", "=", "self", ".", "W1", "(", "encoder_outputs", ")", "\n", "# (bs, 1(unsqueeze), hidden_size)", "\n", "decoder_transform", "=", "self", ".", "W2", "(", "decoder_state", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# # (bs, max_doc_len, 1) => (bs, max_doc_len)", "\n", "u_i", "=", "self", ".", "vt", "(", "torch", ".", "tanh", "(", "encoder_transform", "+", "decoder_transform", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# softmax with only valid inputs, excluding zero padding parts", "\n", "# # log-softmax for a better numerical stability", "\n", "if", "input_node_mask", "is", "not", "None", ":", "\n", "            ", "u_i", "=", "u_i", ".", "masked_fill", "(", "input_node_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# log_score = F.log_softmax(u_i, dim=-1)", "\n", "", "log_score", "=", "F", ".", "softmax", "(", "u_i", ",", "dim", "=", "-", "1", ")", "\n", "# log_score = masked_log_softmax(u_i, input_node_mask, dim=-1)", "\n", "return", "log_score", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.DecoderVAE.__init__": [[210, 222], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.GRU", "model_no_sns.Attention", "model_no_sns.Attention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "DecoderVAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "# self.rnn = nn.GRU(input_size=hidden_size+z_dim,hidden_size=hidden_size+z_dim, batch_first=True)", "\n", "# self.my_rnn_gate = MyGRUCell(input_size = hidden_size+z_dim, hidden_size=hidden_size+z_dim+embedding_dim, d_size=embedding_dim)", "\n", "self", ".", "my_rnn_gate", "=", "nn", ".", "GRU", "(", "input_size", "=", "hidden_size", ",", "hidden_size", "=", "hidden_size", "+", "z_dim", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_size", "\n", "self", ".", "attn_equ", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "attn_sns", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "plan_w", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", "+", "z_dim", ",", "2", ")", "\n", "self", ".", "linear_map_context", "=", "nn", ".", "Linear", "(", "embedding_dim", "+", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "linear_map", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "z_dim", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.DecoderVAE.forward": [[223, 260], ["model_no_sns.DecoderVAE.attn_equ", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model_no_sns.DecoderVAE.attn_sns", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.DecoderVAE.linear_map_context", "model_no_sns.DecoderVAE.my_rnn_gate", "model_no_sns.DecoderVAE.linear_map", "model_no_sns.DecoderVAE.unsqueeze", "model_no_sns.DecoderVAE.unsqueeze", "torch.FloatTensor().to.unsqueeze", "torch.FloatTensor().to.unsqueeze", "torch.FloatTensor().to.unsqueeze", "model_no_sns.DecoderVAE.unsqueeze", "prev_h_batch.unsqueeze", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.bmm.squeeze", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_y_batch", ",", "prev_h_batch", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        A foward path step to a Decoder\n        The step operates on one step-slice of the target sequence\n        :param prev_y_batch: embedded previous prediction bs*embedding_dim\n        :param prev_h_batch: current decoder state: bs * hidden_size(dec_dim)\n        :param z_sample: vae sample z: bs * z_dim\n        :param *_encoder_outputs\" bs * n * hidden_size, bs*m*hidden_size\n        equ_global, sns_global leave as future work\n        \"\"\"", "\n", "bs", "=", "prev_h_batch", ".", "shape", "[", "0", "]", "\n", "# calcualte attention from current RNN state and equation encoder outputs", "\n", "attn_weights_equ", "=", "self", ".", "attn_equ", "(", "prev_h_batch", ",", "equ_encoder_outputs", ",", "input_equ_node_mask", ")", "\n", "# Apply attention weights to encoder outputs to get weighted average", "\n", "# bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "context_equation", "=", "torch", ".", "bmm", "(", "attn_weights_equ", ".", "unsqueeze", "(", "1", ")", ",", "equ_encoder_outputs", ")", "\n", "\n", "# calculate attention fom current RNN state and common sense outputs", "\n", "attn_weights_sns", "=", "self", ".", "attn_sns", "(", "prev_h_batch", ",", "sns_encoder_outputs", ",", "input_sns_node_mask", ")", "\n", "# bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "context_sns", "=", "torch", ".", "bmm", "(", "attn_weights_sns", ".", "unsqueeze", "(", "1", ")", ",", "sns_encoder_outputs", ")", "\n", "\n", "# calculate plan attention, extract how many info from equ_encoder_outputs, how many info from sns_encoder_outputs", "\n", "# plan attention is conducted by softmax(ht-1W + b)", "\n", "# plan_attn_weight = F.softmax(self.plan_w(prev_h_batch), dim=-1) # bs * 2", "\n", "plan_attn_weight", "=", "torch", ".", "FloatTensor", "(", "[", "[", "1.0", ",", "0.0", "]", "for", "_", "in", "range", "(", "bs", ")", "]", ")", ".", "to", "(", "device", ")", "# do not conside commonsense information", "\n", "# print('plan attention shape is ',plan_attn_weight.shape)", "\n", "combine_context", "=", "torch", ".", "cat", "(", "(", "context_equation", ",", "context_sns", ")", ",", "1", ")", "\n", "# print('combine context shape is, ', combine_context.shape)", "\n", "context", "=", "torch", ".", "bmm", "(", "plan_attn_weight", ".", "unsqueeze", "(", "1", ")", ",", "combine_context", ")", "# bs*1*2 x bs*2*hidden_size -> bs*1*hidden_size", "\n", "# combine embedded input word and attented context, run through RNN", "\n", "y_ctx", "=", "torch", ".", "cat", "(", "(", "prev_y_batch", ",", "context", ".", "squeeze", "(", "1", ")", ")", ",", "1", ")", "# bs*(hidden_size+embedding_dim)", "\n", "rnn_input", "=", "self", ".", "linear_map_context", "(", "y_ctx", ")", "# bs * hidden_size", "\n", "\n", "dec_output", ",", "dec_hidden", "=", "self", ".", "my_rnn_gate", "(", "rnn_input", ".", "unsqueeze", "(", "1", ")", ",", "prev_h_batch", ".", "unsqueeze", "(", "0", ")", ")", "\n", "dec_output", "=", "self", ".", "linear_map", "(", "dec_output", ")", "\n", "return", "dec_output", ",", "dec_hidden", ",", "plan_attn_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.WordRNN.__init__": [[263, 282], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model_no_sns.WordRNN.Ws1.data.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model_no_sns.WordRNN.Ws2.data.uniform_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_dim", ",", "dropout", "=", "0.1", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "super", "(", "WordRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "embed_size", "=", "embedding_dim", "\n", "self", ".", "hidden_size", "=", "hidden_dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "if", "pretrained", "is", "None", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", ".", "from_pretrained", "(", "pretrained", ")", "\n", "# self.word_encoder = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)", "\n", "# no bidirectional trytry", "\n", "", "self", ".", "word_encoder", "=", "nn", ".", "GRU", "(", "embedding_dim", ",", "hidden_dim", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "False", ")", "\n", "# self.Ws1 = nn.Parameter(torch.Tensor(1, 2*hidden_dim, 2*hidden_dim))", "\n", "self", ".", "Ws1", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws1", ".", "data", "=", "self", ".", "Ws1", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "# self.Ws2 = nn.Parameter(torch.Tensor(1, 1, 2*hidden_dim))", "\n", "self", ".", "Ws2", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws2", ".", "data", "=", "self", ".", "Ws2", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.WordRNN.forward": [[283, 302], ["len", "len", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "model_no_sns.WordRNN.embedding", "model_no_sns.WordRNN.dropout", "model_no_sns.WordRNN.word_encoder", "model_no_sns.WordRNN.dropout", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view.squeeze().masked_fill", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model_no_sns.WordRNN.Ws2.repeat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "model_no_sns.WordRNN.Ws1.repeat", "torch.softmax().view.squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "one_doc", ")", ":", "\n", "        ", "'''\n        one_doc: [[1,2,3,0],[2,3,4,5],[3,0,0,0]], doc_lens:[3,4,1]\n        '''", "\n", "seq_len", "=", "len", "(", "one_doc", "[", "0", "]", ")", "\n", "max_sent_len", "=", "len", "(", "one_doc", ")", "\n", "tmp_mask", "=", "torch", ".", "eq", "(", "one_doc", ",", "0", ")", "\n", "doc_embedding", "=", "self", ".", "embedding", "(", "one_doc", ")", "\n", "doc_embedding", "=", "self", ".", "dropout", "(", "doc_embedding", ")", "\n", "rnn_out", ",", "_", "=", "self", ".", "word_encoder", "(", "doc_embedding", ")", "\n", "#rnn_out = run_rnn(self.word_encoder,doc_embedding, doc_lens)", "\n", "rnn_out", "=", "self", ".", "dropout", "(", "rnn_out", ")", "\n", "final_T", "=", "torch", ".", "transpose", "(", "rnn_out", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "A", "=", "torch", ".", "tanh", "(", "torch", ".", "bmm", "(", "self", ".", "Ws1", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "final_T", ")", ")", "\n", "A", "=", "torch", ".", "bmm", "(", "self", ".", "Ws2", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "A", ")", "\n", "A", "=", "A", ".", "squeeze", "(", "1", ")", ".", "masked_fill", "(", "tmp_mask", ",", "-", "1e12", ")", "\n", "A", "=", "F", ".", "softmax", "(", "A", ",", "dim", "=", "1", ")", ".", "view", "(", "1", "*", "max_sent_len", ",", "-", "1", ",", "seq_len", ")", "\n", "final", "=", "torch", ".", "bmm", "(", "A", ",", "rnn_out", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Graph2seq.__init__": [[305, 329], ["torch.Module.__init__", "model_no_sns.EncoderGGNN", "model_no_sns.EncoderGGNN", "model_no_sns.WordRNN", "model_no_sns.DecoderVAE", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "n_hop", "=", "5", ",", "teacher_forcing", "=", "0.5", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "Graph2seq", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# the First encoder to encode equation information", "\n", "self", ".", "encoder_equ", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# the second encoder to encode common sense information", "\n", "self", ".", "encoder_sns", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# this is sentence encoder for training VAE posterior", "\n", "self", ".", "out_enc", "=", "WordRNN", "(", "vocab_size", "=", "vocab_size", ",", "embedding_dim", "=", "embedding_dim", ",", "hidden_dim", "=", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "decoder", "=", "DecoderVAE", "(", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "self", ".", "teacher_forcing", "=", "teacher_forcing", "\n", "# sample mu and logvars", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "\n", "self", ".", "q_mu_posterior", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_posterior", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "prior_fc1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "q_mu_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "# set embedding layer with the same parameters", "\n", "self", ".", "out_enc", ".", "embedding", ".", "weight", "=", "self", ".", "embedding", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Graph2seq.sample_z": [[330, 337], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul", "torch.randn_like.mul", "torch.randn_like.mul"], "methods", ["None"], ["", "def", "sample_z", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "\"\"\"\n        Reparameterization trick: z = mu + std*eps; eps ~ N(0,I)\n        \"\"\"", "\n", "std", "=", "torch", ".", "exp", "(", "logvar", "/", "2", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Graph2seq.sample_z_prior": [[338, 341], ["torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "sample_z_prior", "(", "self", ",", "mbsize", ",", "device", ")", ":", "\n", "        ", "z", "=", "torch", ".", "randn", "(", "mbsize", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Graph2seq.forward": [[342, 369], ["model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.encoder_equ", "model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.encoder_sns", "model_no_sns.Graph2seq.out_enc", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.Graph2seq.prior_fc1", "model_no_sns.Graph2seq.sample_z", "input_equ_nodes.eq", "input_sns_nodes.eq", "model_no_sns.Graph2seq.decode_dual", "logits.view.view.view", "model_no_sns.Graph2seq.q_mu_posterior", "model_no_sns.Graph2seq.q_logvar_posterior", "model_no_sns.Graph2seq.q_mu_prior", "model_no_sns.Graph2seq.q_logvar_prior", "logits.view.view.size"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.decode_dual"], ["", "def", "forward", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "input_target", ",", "scene", ",", "device", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# print('node representation dim is,', nodes_resp.shape)", "\n", "# cond_embedding = torch.cat([equ_encoder_hidden, equ_encoder_hidden],1)", "\n", "cond_embedding", "=", "equ_encoder_hidden", "\n", "output_embedding", "=", "self", ".", "out_enc", "(", "input_target", ")", "\n", "# get posterior mu & logvar", "\n", "recog_input", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "output_embedding", "]", ",", "1", ")", "\n", "recog_mu", ",", "recog_logvar", "=", "self", ".", "q_mu_posterior", "(", "recog_input", ")", ",", "self", ".", "q_logvar_posterior", "(", "recog_input", ")", "\n", "# get prior mu & logvar", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "# sample latent z during training, sample posterior, inference with prior", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "recog_mu", ",", "recog_logvar", ")", "\n", "input_equ_node_mask", "=", "input_equ_nodes", ".", "eq", "(", "0", ")", "\n", "input_sns_node_mask", "=", "input_sns_nodes", ".", "eq", "(", "0", ")", "\n", "\n", "# train with schedule sampling", "\n", "logits", ",", "plan_attns", "=", "self", ".", "decode_dual", "(", "input_target", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "\n", "sns_encoder_outputs", ",", "latent_sample", ",", "self", ".", "teacher_forcing", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "logits", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "2", ")", ")", "\n", "return", "logits", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Graph2seq.decode_dual": [[370, 397], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "random.random", "model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_hidden.squeeze.squeeze.squeeze", "model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_output.squeeze().max", "dec_hidden.squeeze.squeeze.squeeze", "dec_output.squeeze", "dec_output.squeeze", "dec_output.squeeze"], "methods", ["None"], ["", "def", "decode_dual", "(", "self", ",", "dec_input_var", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "teacher_forcing_ratio", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", ":", "\n", "        ", "bs", ",", "seq_len", "=", "dec_input_var", ".", "shape", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "z_sample", "]", ",", "dim", "=", "1", ")", "\n", "dec_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", "*", "bs", ")", ".", "to", "(", "device", ")", "\n", "predicted_logits", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "# use this to record the attention score", "\n", "# d_dec = d_initial", "\n", "for", "di", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "teacher_forcing", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ",", "device", ")", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "dec_input", "=", "dec_input_var", "[", ":", ",", "di", "]", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ",", "device", ")", "\n", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "dec_input", "=", "max_index", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "", "predicted_logits", "=", "torch", ".", "stack", "(", "predicted_logits", ",", "1", ")", "\n", "planning_probs", "=", "torch", ".", "stack", "(", "graph_attntion", ",", "1", ")", "\n", "return", "predicted_logits", ",", "planning_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Graph2seq.predict": [[398, 443], ["model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.encoder_equ", "model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.encoder_sns", "model_no_sns.Graph2seq.prior_fc1", "model_no_sns.Graph2seq.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_sns.Graph2seq.q_mu_prior", "model_no_sns.Graph2seq.q_logvar_prior", "model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.decoder", "graph_attntion.append", "dec_output.squeeze().max", "dec_ids.append", "dec_hidden.squeeze.squeeze.squeeze", "max_index.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "max_index.squeeze().item", "dec_output.squeeze", "max_index.squeeze"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "def", "predict", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "\n", "# get prior mu & logvar", "\n", "# cond_embedding = torch.cat([equ_encoder_hidden, sns_encoder_hidden],1)", "\n", "cond_embedding", "=", "equ_encoder_hidden", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "dec_ids", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", "\n", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "# print(prev_y.shape)", "\n", "# print(dec_hidden.shape)", "\n", "# print(sns_encoder_outputs.shape)", "\n", "# print(latent_sample.shape)", "\n", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ",", "device", "=", "device", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ".", "data", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "#max_index = F.softmax(dec_output, dim=-1).squeeze(1).multinomial(1)", "\n", "dec_ids", ".", "append", "(", "max_index", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "max_index", "\n", "# print(max_index)", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "1", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "max_index", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "graph_attntion", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.Graph2seq.predict_with_sampling": [[444, 510], ["model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.encoder", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "model_no_sns.Graph2seq.embedding", "model_no_sns.Graph2seq.decoder", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "dec_ids.append", "probs.clone.multinomial.squeeze", "dec_hidden.squeeze.squeeze.squeeze", "probs.clone.multinomial.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze.clone", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "probs.clone.multinomial.squeeze().item", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_probs.clone", "sorted_probs.clone.multinomial().view", "sorted_indices.gather", "sorted_probs.clone.gather().log", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "torch.softmax", "torch.softmax", "torch.softmax", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul_", "F.softmax().squeeze.clone.gather", "sorted_probs.clone.div_", "sorted_probs.clone.mul_", "sorted_probs.clone.add_", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "probs.clone.multinomial.squeeze", "decoder_output.div_", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "probs.clone.multinomial.view", "sorted_probs.clone.sum().unsqueeze", "sorted_probs.mul", "sorted_probs.clone.multinomial", "sorted_probs.clone.gather", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul", "F.softmax().squeeze.clone.gather", "F.softmax().squeeze.clone.sum", "probs.clone.multinomial.view", "sorted_probs.clone.sum", "F.softmax().squeeze.clone.sum"], "methods", ["None"], ["", "def", "predict_with_sampling", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "device", ",", "max_tgt_len", ",", "temp", "=", "None", ",", "k", "=", "None", ",", "p", "=", "None", ",", "m", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        some sampling based decoding method:\n        tem: temperature\n        k: top-k sampling method k\n        p: Nucleus sampling method\n        m: mass of original dist to interpolate\n        \"\"\"", "\n", "# embedding look up table", "\n", "nodes_resp", "=", "self", ".", "embedding", "(", "input_nodes", ")", "\n", "encoder_outputs", ",", "encoder_hidden", "=", "self", ".", "encoder", "(", "nodes_resp", ",", "adj_matrix", ",", "node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# decode", "\n", "dec_ids", ",", "attn_weight", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "encoder_hidden", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "decoder_output", ",", "dec_hidden", ",", "dec_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "encoder_outputs", ",", "input_node_mask", "=", "None", ")", "\n", "\n", "probs", "=", "F", ".", "softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "if", "temp", "is", "not", "None", ":", "\n", "                ", "samp_probs", "=", "F", ".", "softmax", "(", "decoder_output", ".", "div_", "(", "temp", ")", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "samp_probs", "=", "probs", ".", "clone", "(", ")", "\n", "", "if", "k", "is", "not", "None", ":", "\n", "                ", "indices_to_remove", "=", "samp_probs", "<", "torch", ".", "topk", "(", "samp_probs", ",", "k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "samp_probs", "[", "indices_to_remove", "]", "=", "0.", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul_", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "elif", "p", "is", "not", "None", ":", "\n", "                ", "sorted_probs", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "samp_probs", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "sorted_probs", ",", "dim", "=", "-", "1", ")", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "p", "\n", "sorted_indices_to_remove", "[", ":", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", ":", ",", "0", "]", "=", "0", "\n", "sorted_samp_probs", "=", "sorted_probs", ".", "clone", "(", ")", "\n", "sorted_samp_probs", "[", "sorted_indices_to_remove", "]", "=", "0", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "sorted_samp_probs", ".", "div_", "(", "sorted_samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "sorted_samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "sorted_samp_probs", ".", "add_", "(", "sorted_probs", ".", "mul", "(", "m", ")", ")", "\n", "", "sorted_next_indices", "=", "sorted_samp_probs", ".", "multinomial", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "next_tokens", "=", "sorted_indices", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", "\n", "next_logprobs", "=", "sorted_samp_probs", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", ".", "log", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "dec_ids", ".", "append", "(", "next_tokens", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "next_tokens", ".", "squeeze", "(", "1", ")", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "next_tokens", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "attn_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_sns.masked_log_softmax": [[129, 136], ["torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "mask.unsqueeze.float", "mask.unsqueeze.dim", "vector.dim", "mask.unsqueeze.unsqueeze"], "function", ["None"], ["", "", "", "def", "masked_log_softmax", "(", "vector", ",", "mask", ",", "dim", ")", ":", "\n", "\t", "if", "mask", "is", "not", "None", ":", "\n", "\t\t", "mask", "=", "mask", ".", "float", "(", ")", "\n", "while", "mask", ".", "dim", "(", ")", "<", "vector", ".", "dim", "(", ")", ":", "\n", "\t\t\t", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "vector", "=", "vector", "+", "(", "mask", "+", "1e-45", ")", ".", "log", "(", ")", "\n", "", "return", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "vector", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Propogator.__init__": [[8, 22], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_dim", ")", ":", "\n", "        ", "super", "(", "Propogator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Propogator.forward": [[24, 33], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.Propogator.update_gate", "dual_graph_vae_2.Propogator.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.Propogator.transform"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "node_representation", ",", "adjmatrixs", ")", ":", "# ICLR 2016 fomulas implementation", "\n", "        ", "a", "=", "torch", ".", "bmm", "(", "adjmatrixs", ",", "node_representation", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "a", ",", "node_representation", ")", ",", "2", ")", "# bs * node_len * hidden", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "(", "a", ",", "r", "*", "node_representation", ")", ",", "2", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "output", "=", "(", "1", "-", "z", ")", "*", "node_representation", "+", "z", "*", "h_hat", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.EncoderGGNN.__init__": [[35, 48], ["torch.Module.__init__", "dual_graph_vae_2.Propogator", "torch.Sequential", "torch.Sequential", "torch.Sequential", "dual_graph_vae_2.EncoderGGNN._initialization", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.EncoderGGNN._initialization"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "node_dim", ",", "hidden_dim", ",", "n_hop", "=", "5", ")", ":", "\n", "        ", "super", "(", "EncoderGGNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "n_hop", "=", "n_hop", "\n", "self", ".", "propogator", "=", "Propogator", "(", "self", ".", "node_dim", ")", "\n", "self", ".", "out1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "node_dim", "*", "2", ",", "hidden_dim", ")", "\n", ")", "\n", "# self.out2 = nn.Sequential(", "\n", "#     nn.Linear(self.node_dim * 2, self.node_dim),", "\n", "#     nn.Sigmoid()", "\n", "# )", "\n", "self", ".", "_initialization", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.EncoderGGNN._initialization": [[49, 54], ["dual_graph_vae_2.EncoderGGNN.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.fill_"], "methods", ["None"], ["", "def", "_initialization", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.EncoderGGNN.forward": [[55, 68], ["lengths.view.view.view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.EncoderGGNN.out1", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "dual_graph_vae_2.EncoderGGNN.propogator"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "nodes_rep", ",", "adjmatrixs", ",", "lengths", ")", ":", "\n", "        ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# embeddings = self.embed(nodes)", "\n", "node_representation", "=", "nodes_rep", "\n", "init_node_representation", "=", "nodes_rep", "\n", "for", "_", "in", "range", "(", "self", ".", "n_hop", ")", ":", "\n", "            ", "node_representation", "=", "self", ".", "propogator", "(", "node_representation", ",", "adjmatrixs", ")", "\n", "", "gate_inputs", "=", "torch", ".", "cat", "(", "(", "node_representation", ",", "init_node_representation", ")", ",", "2", ")", "\n", "gate_outputs", "=", "self", ".", "out1", "(", "gate_inputs", ")", "\n", "# aggregate all node information as global vector", "\n", "features", "=", "torch", ".", "sum", "(", "gate_outputs", ",", "1", ")", "\n", "features", "=", "features", "/", "lengths", "\n", "return", "gate_outputs", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Constants.__init__": [[70, 96], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "BOS_WORD", "=", "'<s>'", "\n", "self", ".", "EOS_WORD", "=", "'</s>'", "\n", "self", ".", "PAD_WORD", "=", "'<blank>'", "\n", "self", ".", "UNK_WORD", "=", "'<unk>'", "\n", "self", ".", "head_info_num_WORD", "=", "'head_info_num'", "\n", "self", ".", "rabbit_entity_WORD", "=", "'rabbit_entity'", "\n", "self", ".", "rabbit_tou_num_WORD", "=", "'rabbit_tou_num'", "\n", "self", ".", "rabbit_jiao_num_WORD", "=", "'rabbit_jiao_num'", "\n", "self", ".", "jiao_info_num_WORD", "=", "'jiao_info_num'", "\n", "self", ".", "ji_entity_WORD", "=", "'ji_entity'", "\n", "self", ".", "ji_tou_num_WORD", "=", "'ji_tou_num'", "\n", "self", ".", "ji_jiao_num_WORD", "=", "'ji_jiao_num'", "\n", "\n", "self", ".", "PAD", "=", "0", "\n", "self", ".", "UNK", "=", "1", "\n", "self", ".", "BOS", "=", "2", "\n", "self", ".", "EOS", "=", "3", "\n", "self", ".", "head_info_num", "=", "4", "\n", "self", ".", "rabbit_entity", "=", "5", "\n", "self", ".", "rabbit_tou_num", "=", "6", "\n", "self", ".", "rabbit_jiao_num", "=", "7", "\n", "self", ".", "jiao_info_num", "=", "8", "\n", "self", ".", "ji_entity", "=", "9", "\n", "self", ".", "ji_tou_num", "=", "10", "\n", "self", ".", "ji_jiao_num", "=", "11", "\n", "", "", "Constants", "=", "Constants", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.ScheduledOptim.__init__": [[101, 106], ["numpy.power"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "d_model", ",", "n_warmup_steps", ")", ":", "\n", "        ", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "n_warmup_steps", "=", "n_warmup_steps", "\n", "self", ".", "n_current_steps", "=", "0", "\n", "self", ".", "init_lr", "=", "np", ".", "power", "(", "d_model", ",", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.ScheduledOptim.step_and_update_lr": [[107, 111], ["dual_graph_vae_2.ScheduledOptim._update_learning_rate", "dual_graph_vae_2.ScheduledOptim._optimizer.step"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._update_learning_rate"], ["", "def", "step_and_update_lr", "(", "self", ")", ":", "\n", "        ", "\"step with the inner optimizer\"", "\n", "self", ".", "_update_learning_rate", "(", ")", "\n", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.ScheduledOptim.zero_grad": [[112, 115], ["dual_graph_vae_2.ScheduledOptim._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"zero out the gradient by the inner optimizer\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.ScheduledOptim._get_lr_scale": [[116, 120], ["numpy.min", "numpy.power", "numpy.power"], "methods", ["None"], ["", "def", "_get_lr_scale", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "min", "(", "[", "\n", "np", ".", "power", "(", "self", ".", "n_current_steps", ",", "-", "0.5", ")", ",", "\n", "np", ".", "power", "(", "self", ".", "n_warmup_steps", ",", "-", "1.5", ")", "*", "self", ".", "n_current_steps", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.ScheduledOptim._update_learning_rate": [[122, 128], ["dual_graph_vae_2.ScheduledOptim._get_lr_scale"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._get_lr_scale"], ["", "def", "_update_learning_rate", "(", "self", ")", ":", "\n", "        ", "'''learning rate scheduleing per step'''", "\n", "self", ".", "n_current_steps", "+=", "1", "\n", "lr", "=", "self", ".", "init_lr", "*", "self", ".", "_get_lr_scale", "(", ")", "\n", "for", "param_group", "in", "self", ".", "_optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.MyGRUCell.__init__": [[138, 161], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "d_size", ",", "batch_first", "=", "True", ")", ":", "\n", "        ", "super", "(", "MyGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "w2h_r", "=", "nn", ".", "Linear", "(", "input_size", ",", "d_size", ")", "\n", "self", ".", "h2h_r", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "d_size", ")", "\n", "self", ".", "dc", "=", "nn", ".", "Linear", "(", "d_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.MyGRUCell.forward": [[163, 181], ["input_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.MyGRUCell.update_gate", "dual_graph_vae_2.MyGRUCell.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.MyGRUCell.transform", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "dual_graph_vae_2.MyGRUCell.output", "dual_graph_vae_2.MyGRUCell.dc", "dual_graph_vae_2.MyGRUCell.w2h_r", "dual_graph_vae_2.MyGRUCell.h2h_r"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_t", ",", "last_hidden", ",", "last_dt", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Do feedforward for one step\n        input_t: (batch_size, 1, input_size)\n        last_hidden: (bs, hidden_size)\n        last_dt: (bs, d_size)\n        \"\"\"", "\n", "input_t", "=", "input_t", ".", "squeeze", "(", "1", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "last_hidden", ",", "input_t", ")", ",", "-", "1", ")", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "[", "r", "*", "last_hidden", ",", "input_t", "]", ",", "-", "1", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "gate_r", "=", "torch", ".", "sigmoid", "(", "self", ".", "w2h_r", "(", "input_t", ")", "+", "alpha", "*", "self", ".", "h2h_r", "(", "last_hidden", ")", ")", "\n", "dt", "=", "gate_r", "*", "last_dt", "# bs * d_size", "\n", "hidden", "=", "(", "1", "-", "z", ")", "*", "last_hidden", "+", "z", "*", "h_hat", "+", "self", ".", "dc", "(", "dt", ")", "\n", "output", "=", "self", ".", "output", "(", "hidden", ")", "\n", "return", "output", ",", "hidden", ",", "dt", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Attention.__init__": [[183, 189], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "z_dim", ",", "emb_size", "=", "0", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "W1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", "+", "z_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "vt", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Attention.forward": [[189, 208], ["dual_graph_vae_2.Attention.W1", "dual_graph_vae_2.Attention.W2().unsqueeze", "dual_graph_vae_2.Attention.vt().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "u_i.masked_fill.masked_fill.masked_fill", "dual_graph_vae_2.Attention.W2", "dual_graph_vae_2.Attention.vt", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n", "# print('decoder state dimension,',decoder_state.shape)", "\n", "# print('encoder_outputs dimension,', encoder_outputs.shape)", "\n", "# (bs, seq_len, hidden_size)", "\n", "        ", "encoder_transform", "=", "self", ".", "W1", "(", "encoder_outputs", ")", "\n", "# (bs, 1(unsqueeze), hidden_size)", "\n", "decoder_transform", "=", "self", ".", "W2", "(", "decoder_state", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# # (bs, max_doc_len, 1) => (bs, max_doc_len)", "\n", "u_i", "=", "self", ".", "vt", "(", "torch", ".", "tanh", "(", "encoder_transform", "+", "decoder_transform", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# softmax with only valid inputs, excluding zero padding parts", "\n", "# # log-softmax for a better numerical stability", "\n", "if", "input_node_mask", "is", "not", "None", ":", "\n", "            ", "u_i", "=", "u_i", ".", "masked_fill", "(", "input_node_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# log_score = F.log_softmax(u_i, dim=-1)", "\n", "", "log_score", "=", "F", ".", "softmax", "(", "u_i", ",", "dim", "=", "-", "1", ")", "\n", "# log_score = masked_log_softmax(u_i, input_node_mask, dim=-1)", "\n", "return", "log_score", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.DecoderVAE.__init__": [[210, 223], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.GRU", "dual_graph_vae_2.Attention", "dual_graph_vae_2.Attention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "DecoderVAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "# self.rnn = nn.GRU(input_size=hidden_size+z_dim,hidden_size=hidden_size+z_dim, batch_first=True)", "\n", "# self.my_rnn_gate = MyGRUCell(input_size = hidden_size+z_dim, hidden_size=hidden_size+z_dim+embedding_dim, d_size=embedding_dim)", "\n", "self", ".", "my_rnn_gate", "=", "nn", ".", "GRU", "(", "input_size", "=", "hidden_size", ",", "hidden_size", "=", "2", "*", "hidden_size", "+", "z_dim", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_size", "\n", "self", ".", "attn_equ", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "attn_sns", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "plan_w", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", "+", "z_dim", ",", "2", ")", "\n", "# self.plan_w = ScaledDotProductAttention(d_q=2*hidden_size+z_dim, d_k=hidden_size, d_attn=hidden_size,temperature=1)", "\n", "self", ".", "linear_map_context", "=", "nn", ".", "Linear", "(", "embedding_dim", "+", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "linear_map", "=", "nn", ".", "Linear", "(", "hidden_size", "*", "2", "+", "z_dim", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.DecoderVAE.forward": [[224, 261], ["dual_graph_vae_2.DecoderVAE.attn_equ", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "dual_graph_vae_2.DecoderVAE.attn_sns", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax", "torch.softmax", "torch.softmax", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.DecoderVAE.linear_map_context", "dual_graph_vae_2.DecoderVAE.my_rnn_gate", "dual_graph_vae_2.DecoderVAE.linear_map", "dual_graph_vae_2.DecoderVAE.unsqueeze", "dual_graph_vae_2.DecoderVAE.unsqueeze", "dual_graph_vae_2.DecoderVAE.plan_w", "torch.softmax.unsqueeze", "dual_graph_vae_2.DecoderVAE.unsqueeze", "prev_h_batch.unsqueeze", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.bmm.squeeze"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_y_batch", ",", "prev_h_batch", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", ":", "\n", "        ", "\"\"\"\n        A foward path step to a Decoder\n        The step operates on one step-slice of the target sequence\n        :param prev_y_batch: embedded previous prediction bs*embedding_dim\n        :param prev_h_batch: current decoder state: bs * hidden_size(dec_dim)\n        :param z_sample: vae sample z: bs * z_dim\n        :param *_encoder_outputs\" bs * n * hidden_size, bs*m*hidden_size\n        equ_global, sns_global leave as future work\n        \"\"\"", "\n", "# calcualte attention from current RNN state and equation encoder outputs", "\n", "attn_weights_equ", "=", "self", ".", "attn_equ", "(", "prev_h_batch", ",", "equ_encoder_outputs", ",", "input_equ_node_mask", ")", "\n", "# Apply attention weights to encoder outputs to get weighted average", "\n", "# bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "context_equation", "=", "torch", ".", "bmm", "(", "attn_weights_equ", ".", "unsqueeze", "(", "1", ")", ",", "equ_encoder_outputs", ")", "\n", "\n", "# calculate attention fom current RNN state and common sense outputs", "\n", "attn_weights_sns", "=", "self", ".", "attn_sns", "(", "prev_h_batch", ",", "sns_encoder_outputs", ",", "input_sns_node_mask", ")", "\n", "# bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "context_sns", "=", "torch", ".", "bmm", "(", "attn_weights_sns", ".", "unsqueeze", "(", "1", ")", ",", "sns_encoder_outputs", ")", "\n", "\n", "# calculate plan attention, extract how many info from equ_encoder_outputs, how many info from sns_encoder_outputs", "\n", "# plan attention is conducted by softmax(ht-1W + b)", "\n", "plan_attn_weight", "=", "F", ".", "softmax", "(", "self", ".", "plan_w", "(", "prev_h_batch", ")", ",", "dim", "=", "-", "1", ")", "# bs * 2\uff0c\u8fd9\u91cc\u662f\u4e0d\u662f\u6539\u4e00\u4e0b\u597d\u4e00\u70b9", "\n", "# print('plan attention shape is ',plan_attn_weight.shape)", "\n", "combine_context", "=", "torch", ".", "cat", "(", "(", "context_equation", ",", "context_sns", ")", ",", "1", ")", "\n", "# print('combine context shape is, ', combine_context.shape)", "\n", "context", "=", "torch", ".", "bmm", "(", "plan_attn_weight", ".", "unsqueeze", "(", "1", ")", ",", "combine_context", ")", "# bs*1*2 x bs*2*hidden_size -> bs*1*hidden_size", "\n", "\n", "# context, plan_attn_weight = self.plan_w(prev_h_batch.unsqueeze(1),combine_context,combine_context)", "\n", "# combine embedded input word and attented context, run through RNN", "\n", "y_ctx", "=", "torch", ".", "cat", "(", "(", "prev_y_batch", ",", "context", ".", "squeeze", "(", "1", ")", ")", ",", "1", ")", "# bs*(hidden_size+embedding_dim)", "\n", "rnn_input", "=", "self", ".", "linear_map_context", "(", "y_ctx", ")", "# bs * hidden_size", "\n", "\n", "dec_output", ",", "dec_hidden", "=", "self", ".", "my_rnn_gate", "(", "rnn_input", ".", "unsqueeze", "(", "1", ")", ",", "prev_h_batch", ".", "unsqueeze", "(", "0", ")", ")", "\n", "dec_output", "=", "self", ".", "linear_map", "(", "dec_output", ")", "\n", "return", "dec_output", ",", "dec_hidden", ",", "plan_attn_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.ScaledDotProductAttention.__init__": [[263, 272], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.Linear", "torch.Linear", "torch.Linear", "torch.init.xavier_normal_", "torch.init.xavier_normal_", "torch.init.xavier_normal_"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "d_q", ",", "d_k", ",", "d_attn", ",", "temperature", ",", "attn_dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "temperature", "=", "temperature", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "attn_dropout", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "2", ")", "\n", "self", ".", "w_qs", "=", "nn", ".", "Linear", "(", "d_q", ",", "d_attn", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_qs", ".", "weight", ")", "\n", "self", ".", "w_ks", "=", "nn", ".", "Linear", "(", "d_k", ",", "d_attn", ")", "\n", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "w_ks", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.ScaledDotProductAttention.forward": [[273, 286], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "dual_graph_vae_2.ScaledDotProductAttention.softmax", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "torch.where", "dual_graph_vae_2.ScaledDotProductAttention.dropout", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "dual_graph_vae_2.ScaledDotProductAttention.w_qs", "dual_graph_vae_2.ScaledDotProductAttention.w_ks", "k.transpose", "attn.masked_fill.masked_fill.masked_fill", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.isnan", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "q", ",", "k", ",", "v", ",", "mask", "=", "None", ")", ":", "\n", "        ", "q", ",", "k", "=", "self", ".", "w_qs", "(", "q", ")", ",", "self", ".", "w_ks", "(", "k", ")", "\n", "attn", "=", "torch", ".", "bmm", "(", "q", ",", "k", ".", "transpose", "(", "1", ",", "2", ")", ")", "\n", "attn", "=", "attn", "/", "self", ".", "temperature", "\n", "if", "mask", "is", "not", "None", ":", "\n", "            ", "attn", "=", "attn", ".", "masked_fill", "(", "mask", ",", "-", "np", ".", "inf", ")", "\n", "", "attn", "=", "self", ".", "softmax", "(", "attn", ")", "\n", "safe_attn", "=", "torch", ".", "where", "(", "torch", ".", "isnan", "(", "attn", ")", ",", "torch", ".", "zeros_like", "(", "attn", ")", ",", "attn", ")", "\n", "# attn[attn!=attn] = 0.0", "\n", "safe_attn", "=", "self", ".", "dropout", "(", "safe_attn", ")", "\n", "# print(attn)", "\n", "output", "=", "torch", ".", "bmm", "(", "safe_attn", ",", "v", ")", "\n", "return", "output", ",", "safe_attn", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.WordRNN.__init__": [[288, 307], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "dual_graph_vae_2.WordRNN.Ws1.data.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "dual_graph_vae_2.WordRNN.Ws2.data.uniform_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_dim", ",", "dropout", "=", "0.1", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "super", "(", "WordRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "embed_size", "=", "embedding_dim", "\n", "self", ".", "hidden_size", "=", "hidden_dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "if", "pretrained", "is", "None", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", ".", "from_pretrained", "(", "pretrained", ")", "\n", "# self.word_encoder = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)", "\n", "# no bidirectional trytry", "\n", "", "self", ".", "word_encoder", "=", "nn", ".", "GRU", "(", "embedding_dim", ",", "hidden_dim", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "False", ")", "\n", "# self.Ws1 = nn.Parameter(torch.Tensor(1, 2*hidden_dim, 2*hidden_dim))", "\n", "self", ".", "Ws1", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws1", ".", "data", "=", "self", ".", "Ws1", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "# self.Ws2 = nn.Parameter(torch.Tensor(1, 1, 2*hidden_dim))", "\n", "self", ".", "Ws2", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws2", ".", "data", "=", "self", ".", "Ws2", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.WordRNN.forward": [[308, 327], ["len", "len", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "dual_graph_vae_2.WordRNN.embedding", "dual_graph_vae_2.WordRNN.dropout", "dual_graph_vae_2.WordRNN.word_encoder", "dual_graph_vae_2.WordRNN.dropout", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view.squeeze().masked_fill", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "dual_graph_vae_2.WordRNN.Ws2.repeat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "dual_graph_vae_2.WordRNN.Ws1.repeat", "torch.softmax().view.squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "one_doc", ")", ":", "\n", "        ", "'''\n        one_doc: [[1,2,3,0],[2,3,4,5],[3,0,0,0]], doc_lens:[3,4,1]\n        '''", "\n", "seq_len", "=", "len", "(", "one_doc", "[", "0", "]", ")", "\n", "max_sent_len", "=", "len", "(", "one_doc", ")", "\n", "tmp_mask", "=", "torch", ".", "eq", "(", "one_doc", ",", "0", ")", "\n", "doc_embedding", "=", "self", ".", "embedding", "(", "one_doc", ")", "\n", "doc_embedding", "=", "self", ".", "dropout", "(", "doc_embedding", ")", "\n", "rnn_out", ",", "_", "=", "self", ".", "word_encoder", "(", "doc_embedding", ")", "\n", "#rnn_out = run_rnn(self.word_encoder,doc_embedding, doc_lens)", "\n", "rnn_out", "=", "self", ".", "dropout", "(", "rnn_out", ")", "\n", "final_T", "=", "torch", ".", "transpose", "(", "rnn_out", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "A", "=", "torch", ".", "tanh", "(", "torch", ".", "bmm", "(", "self", ".", "Ws1", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "final_T", ")", ")", "\n", "A", "=", "torch", ".", "bmm", "(", "self", ".", "Ws2", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "A", ")", "\n", "A", "=", "A", ".", "squeeze", "(", "1", ")", ".", "masked_fill", "(", "tmp_mask", ",", "-", "1e12", ")", "\n", "A", "=", "F", ".", "softmax", "(", "A", ",", "dim", "=", "1", ")", ".", "view", "(", "1", "*", "max_sent_len", ",", "-", "1", ",", "seq_len", ")", "\n", "final", "=", "torch", ".", "bmm", "(", "A", ",", "rnn_out", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Graph2seq.__init__": [[330, 354], ["torch.Module.__init__", "dual_graph_vae_2.EncoderGGNN", "dual_graph_vae_2.EncoderGGNN", "dual_graph_vae_2.WordRNN", "dual_graph_vae_2.DecoderVAE", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "n_hop", "=", "5", ",", "teacher_forcing", "=", "0.5", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "Graph2seq", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# the First encoder to encode equation information", "\n", "self", ".", "encoder_equ", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# the second encoder to encode common sense information", "\n", "self", ".", "encoder_sns", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# this is sentence encoder for training VAE posterior", "\n", "self", ".", "out_enc", "=", "WordRNN", "(", "vocab_size", "=", "vocab_size", ",", "embedding_dim", "=", "embedding_dim", ",", "hidden_dim", "=", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "decoder", "=", "DecoderVAE", "(", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "self", ".", "teacher_forcing", "=", "teacher_forcing", "\n", "# sample mu and logvars", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "\n", "self", ".", "q_mu_posterior", "=", "nn", ".", "Linear", "(", "3", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_posterior", "=", "nn", ".", "Linear", "(", "3", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "prior_fc1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "q_mu_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "# set embedding layer with the same parameters", "\n", "self", ".", "out_enc", ".", "embedding", ".", "weight", "=", "self", ".", "embedding", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Graph2seq.sample_z": [[355, 362], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul", "torch.randn_like.mul", "torch.randn_like.mul"], "methods", ["None"], ["", "def", "sample_z", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "\"\"\"\n        Reparameterization trick: z = mu + std*eps; eps ~ N(0,I)\n        \"\"\"", "\n", "std", "=", "torch", ".", "exp", "(", "logvar", "/", "2", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Graph2seq.sample_z_prior": [[363, 366], ["torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "sample_z_prior", "(", "self", ",", "mbsize", ",", "device", ")", ":", "\n", "        ", "z", "=", "torch", ".", "randn", "(", "mbsize", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Graph2seq.forward": [[367, 393], ["dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.encoder_equ", "dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.encoder_sns", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.Graph2seq.out_enc", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.Graph2seq.prior_fc1", "dual_graph_vae_2.Graph2seq.sample_z", "input_equ_nodes.eq", "input_sns_nodes.eq", "dual_graph_vae_2.Graph2seq.decode_dual", "logits.view.view.view", "dual_graph_vae_2.Graph2seq.q_mu_posterior", "dual_graph_vae_2.Graph2seq.q_logvar_posterior", "dual_graph_vae_2.Graph2seq.q_mu_prior", "dual_graph_vae_2.Graph2seq.q_logvar_prior", "logits.view.view.size"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.decode_dual"], ["", "def", "forward", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "input_target", ",", "scene", ",", "device", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# print('node representation dim is,', nodes_resp.shape)", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "output_embedding", "=", "self", ".", "out_enc", "(", "input_target", ")", "\n", "# get posterior mu & logvar", "\n", "recog_input", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "output_embedding", "]", ",", "1", ")", "\n", "recog_mu", ",", "recog_logvar", "=", "self", ".", "q_mu_posterior", "(", "recog_input", ")", ",", "self", ".", "q_logvar_posterior", "(", "recog_input", ")", "\n", "# get prior mu & logvar", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "# sample latent z during training, sample posterior, inference with prior", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "recog_mu", ",", "recog_logvar", ")", "\n", "input_equ_node_mask", "=", "input_equ_nodes", ".", "eq", "(", "0", ")", "\n", "input_sns_node_mask", "=", "input_sns_nodes", ".", "eq", "(", "0", ")", "\n", "\n", "# train with schedule sampling", "\n", "logits", ",", "plan_attns", "=", "self", ".", "decode_dual", "(", "input_target", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "\n", "sns_encoder_outputs", ",", "latent_sample", ",", "self", ".", "teacher_forcing", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "logits", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "2", ")", ")", "\n", "return", "logits", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Graph2seq.decode_dual": [[394, 421], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "random.random", "dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_hidden.squeeze.squeeze.squeeze", "dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_output.squeeze().max", "dec_hidden.squeeze.squeeze.squeeze", "dec_output.squeeze", "dec_output.squeeze", "dec_output.squeeze"], "methods", ["None"], ["", "def", "decode_dual", "(", "self", ",", "dec_input_var", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "teacher_forcing_ratio", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", ":", "\n", "        ", "bs", ",", "seq_len", "=", "dec_input_var", ".", "shape", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "z_sample", "]", ",", "dim", "=", "1", ")", "\n", "dec_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", "*", "bs", ")", ".", "to", "(", "device", ")", "\n", "predicted_logits", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "# use this to record the attention score", "\n", "# d_dec = d_initial", "\n", "for", "di", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "teacher_forcing", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "dec_input", "=", "dec_input_var", "[", ":", ",", "di", "]", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "dec_input", "=", "max_index", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "", "predicted_logits", "=", "torch", ".", "stack", "(", "predicted_logits", ",", "1", ")", "\n", "planning_probs", "=", "torch", ".", "stack", "(", "graph_attntion", ",", "1", ")", "\n", "return", "predicted_logits", ",", "planning_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Graph2seq.predict": [[422, 466], ["dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.encoder_equ", "dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.encoder_sns", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.Graph2seq.prior_fc1", "dual_graph_vae_2.Graph2seq.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "dual_graph_vae_2.Graph2seq.q_mu_prior", "dual_graph_vae_2.Graph2seq.q_logvar_prior", "dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.decoder", "graph_attntion.append", "dec_output.squeeze().max", "dec_ids.append", "dec_hidden.squeeze.squeeze.squeeze", "max_index.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "max_index.squeeze().item", "dec_output.squeeze", "max_index.squeeze"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "def", "predict", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "\n", "# get prior mu & logvar", "\n", "cond_embedding", "=", "torch", ".", "cat", "(", "[", "equ_encoder_hidden", ",", "sns_encoder_hidden", "]", ",", "1", ")", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "dec_ids", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", "\n", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "# print(prev_y.shape)", "\n", "# print(dec_hidden.shape)", "\n", "# print(sns_encoder_outputs.shape)", "\n", "# print(latent_sample.shape)", "\n", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ".", "data", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "#max_index = F.softmax(dec_output, dim=-1).squeeze(1).multinomial(1)", "\n", "dec_ids", ".", "append", "(", "max_index", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "max_index", "\n", "# print(max_index)", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "1", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "max_index", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "graph_attntion", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.Graph2seq.predict_with_sampling": [[467, 533], ["dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.encoder", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "dual_graph_vae_2.Graph2seq.embedding", "dual_graph_vae_2.Graph2seq.decoder", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "dec_ids.append", "probs.clone.multinomial.squeeze", "dec_hidden.squeeze.squeeze.squeeze", "probs.clone.multinomial.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze.clone", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "probs.clone.multinomial.squeeze().item", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_probs.clone", "sorted_probs.clone.multinomial().view", "sorted_indices.gather", "sorted_probs.clone.gather().log", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "torch.softmax", "torch.softmax", "torch.softmax", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul_", "F.softmax().squeeze.clone.gather", "sorted_probs.clone.div_", "sorted_probs.clone.mul_", "sorted_probs.clone.add_", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "probs.clone.multinomial.squeeze", "decoder_output.div_", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "probs.clone.multinomial.view", "sorted_probs.clone.sum().unsqueeze", "sorted_probs.mul", "sorted_probs.clone.multinomial", "sorted_probs.clone.gather", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul", "F.softmax().squeeze.clone.gather", "F.softmax().squeeze.clone.sum", "probs.clone.multinomial.view", "sorted_probs.clone.sum", "F.softmax().squeeze.clone.sum"], "methods", ["None"], ["", "def", "predict_with_sampling", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "device", ",", "max_tgt_len", ",", "temp", "=", "None", ",", "k", "=", "None", ",", "p", "=", "None", ",", "m", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        some sampling based decoding method:\n        tem: temperature\n        k: top-k sampling method k\n        p: Nucleus sampling method\n        m: mass of original dist to interpolate\n        \"\"\"", "\n", "# embedding look up table", "\n", "nodes_resp", "=", "self", ".", "embedding", "(", "input_nodes", ")", "\n", "encoder_outputs", ",", "encoder_hidden", "=", "self", ".", "encoder", "(", "nodes_resp", ",", "adj_matrix", ",", "node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# decode", "\n", "dec_ids", ",", "attn_weight", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "encoder_hidden", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "decoder_output", ",", "dec_hidden", ",", "dec_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "encoder_outputs", ",", "input_node_mask", "=", "None", ")", "\n", "\n", "probs", "=", "F", ".", "softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "if", "temp", "is", "not", "None", ":", "\n", "                ", "samp_probs", "=", "F", ".", "softmax", "(", "decoder_output", ".", "div_", "(", "temp", ")", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "samp_probs", "=", "probs", ".", "clone", "(", ")", "\n", "", "if", "k", "is", "not", "None", ":", "\n", "                ", "indices_to_remove", "=", "samp_probs", "<", "torch", ".", "topk", "(", "samp_probs", ",", "k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "samp_probs", "[", "indices_to_remove", "]", "=", "0.", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul_", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "elif", "p", "is", "not", "None", ":", "\n", "                ", "sorted_probs", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "samp_probs", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "sorted_probs", ",", "dim", "=", "-", "1", ")", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "p", "\n", "sorted_indices_to_remove", "[", ":", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", ":", ",", "0", "]", "=", "0", "\n", "sorted_samp_probs", "=", "sorted_probs", ".", "clone", "(", ")", "\n", "sorted_samp_probs", "[", "sorted_indices_to_remove", "]", "=", "0", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "sorted_samp_probs", ".", "div_", "(", "sorted_samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "sorted_samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "sorted_samp_probs", ".", "add_", "(", "sorted_probs", ".", "mul", "(", "m", ")", ")", "\n", "", "sorted_next_indices", "=", "sorted_samp_probs", ".", "multinomial", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "next_tokens", "=", "sorted_indices", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", "\n", "next_logprobs", "=", "sorted_samp_probs", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", ".", "log", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "dec_ids", ".", "append", "(", "next_tokens", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "next_tokens", ".", "squeeze", "(", "1", ")", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "next_tokens", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "attn_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.dual_graph_vae_2.masked_log_softmax": [[129, 136], ["torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "mask.unsqueeze.float", "mask.unsqueeze.dim", "vector.dim", "mask.unsqueeze.unsqueeze"], "function", ["None"], ["", "", "", "def", "masked_log_softmax", "(", "vector", ",", "mask", ",", "dim", ")", ":", "\n", "\t", "if", "mask", "is", "not", "None", ":", "\n", "\t\t", "mask", "=", "mask", ".", "float", "(", ")", "\n", "while", "mask", ".", "dim", "(", ")", "<", "vector", ".", "dim", "(", ")", ":", "\n", "\t\t\t", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "vector", "=", "vector", "+", "(", "mask", "+", "1e-45", ")", ".", "log", "(", ")", "\n", "", "return", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "vector", ",", "dim", "=", "dim", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.Constant.Constants.__init__": [[2, 40], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "BOS_WORD", "=", "'<s>'", "\n", "self", ".", "EOS_WORD", "=", "'</s>'", "\n", "self", ".", "PAD_WORD", "=", "'<blank>'", "\n", "self", ".", "UNK_WORD", "=", "'<unk>'", "\n", "self", ".", "eq1_x_index_WORD", "=", "'eq_one_x_index'", "\n", "self", ".", "eq2_x_index_WORD", "=", "'eq_two_x_index'", "\n", "self", ".", "eq1_y_index_WORD", "=", "'eq_one_y_index'", "\n", "self", ".", "eq2_y_index_WORD", "=", "'eq_two_y_index'", "\n", "self", ".", "eq1_right_num1_WORD", "=", "'eq_one_right_num_one'", "\n", "self", ".", "eq2_right_num1_WORD", "=", "'eq_two_right_num_one'", "\n", "self", ".", "eq1_right_num2_WORD", "=", "'eq_one_right_num_two'", "\n", "self", ".", "eq2_right_num2_WORD", "=", "'eq_two_right_num_two'", "\n", "self", ".", "x_entity_WORD", "=", "'x_entity'", "\n", "self", ".", "y_entity_WORD", "=", "'y_entity'", "\n", "self", ".", "head_info_unit_WORD", "=", "'head_info_unit'", "\n", "self", ".", "jiao_info_unit_WORD", "=", "'jiao_info_unit'", "\n", "self", ".", "jiao_info_entity_WORD", "=", "'jiao_info_entity'", "\n", "self", ".", "head_info_entity_WORD", "=", "'head_info_entity'", "\n", "\n", "self", ".", "PAD", "=", "0", "\n", "self", ".", "UNK", "=", "1", "\n", "self", ".", "BOS", "=", "2", "\n", "self", ".", "EOS", "=", "3", "\n", "self", ".", "eq1_x_index", "=", "4", "\n", "self", ".", "eq2_x_index", "=", "5", "\n", "self", ".", "eq1_y_index", "=", "6", "\n", "self", ".", "eq2_y_index", "=", "7", "\n", "self", ".", "eq1_right_num1", "=", "8", "\n", "self", ".", "eq2_right_num1", "=", "9", "\n", "self", ".", "eq1_right_num2", "=", "10", "\n", "self", ".", "eq2_right_num2", "=", "11", "\n", "self", ".", "x_entity", "=", "12", "\n", "self", ".", "y_entity", "=", "13", "\n", "self", ".", "head_info_unit", "=", "14", "\n", "self", ".", "jiao_info_unit", "=", "15", "\n", "self", ".", "jiao_info_entity", "=", "16", "\n", "self", ".", "head_info_entity", "=", "17", "", "", "", ""]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Propogator.__init__": [[8, 22], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "node_dim", ")", ":", "\n", "        ", "super", "(", "Propogator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "node_dim", "*", "2", ",", "node_dim", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Propogator.forward": [[24, 33], ["torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.Propogator.update_gate", "model_no_symbolic.Propogator.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.Propogator.transform"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "node_representation", ",", "adjmatrixs", ")", ":", "# ICLR 2016 fomulas implementation", "\n", "        ", "a", "=", "torch", ".", "bmm", "(", "adjmatrixs", ",", "node_representation", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "a", ",", "node_representation", ")", ",", "2", ")", "# bs * node_len * hidden", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "(", "a", ",", "r", "*", "node_representation", ")", ",", "2", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "output", "=", "(", "1", "-", "z", ")", "*", "node_representation", "+", "z", "*", "h_hat", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.EncoderGGNN.__init__": [[35, 48], ["torch.Module.__init__", "model_no_symbolic.Propogator", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model_no_symbolic.EncoderGGNN._initialization", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.EncoderGGNN._initialization"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "node_dim", ",", "hidden_dim", ",", "n_hop", "=", "5", ")", ":", "\n", "        ", "super", "(", "EncoderGGNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "node_dim", "=", "node_dim", "\n", "self", ".", "n_hop", "=", "n_hop", "\n", "self", ".", "propogator", "=", "Propogator", "(", "self", ".", "node_dim", ")", "\n", "self", ".", "out1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "self", ".", "node_dim", "*", "2", ",", "hidden_dim", ")", "\n", ")", "\n", "# self.out2 = nn.Sequential(", "\n", "#     nn.Linear(self.node_dim * 2, self.node_dim),", "\n", "#     nn.Sigmoid()", "\n", "# )", "\n", "self", ".", "_initialization", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.EncoderGGNN._initialization": [[49, 54], ["model_no_symbolic.EncoderGGNN.modules", "isinstance", "m.weight.data.normal_", "m.bias.data.fill_"], "methods", ["None"], ["", "def", "_initialization", "(", "self", ")", ":", "\n", "        ", "for", "m", "in", "self", ".", "modules", "(", ")", ":", "\n", "            ", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", ":", "\n", "                ", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0.0", ",", "0.02", ")", "\n", "m", ".", "bias", ".", "data", ".", "fill_", "(", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.EncoderGGNN.forward": [[55, 68], ["lengths.view.view.view", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.EncoderGGNN.out1", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "model_no_symbolic.EncoderGGNN.propogator"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "nodes_rep", ",", "adjmatrixs", ",", "lengths", ")", ":", "\n", "        ", "lengths", "=", "lengths", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "# embeddings = self.embed(nodes)", "\n", "node_representation", "=", "nodes_rep", "\n", "init_node_representation", "=", "nodes_rep", "\n", "for", "_", "in", "range", "(", "self", ".", "n_hop", ")", ":", "\n", "            ", "node_representation", "=", "self", ".", "propogator", "(", "node_representation", ",", "adjmatrixs", ")", "\n", "", "gate_inputs", "=", "torch", ".", "cat", "(", "(", "node_representation", ",", "init_node_representation", ")", ",", "2", ")", "\n", "gate_outputs", "=", "self", ".", "out1", "(", "gate_inputs", ")", "\n", "# aggregate all node information as global vector", "\n", "features", "=", "torch", ".", "sum", "(", "gate_outputs", ",", "1", ")", "\n", "features", "=", "features", "/", "lengths", "\n", "return", "gate_outputs", ",", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Constants.__init__": [[70, 96], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "BOS_WORD", "=", "'<s>'", "\n", "self", ".", "EOS_WORD", "=", "'</s>'", "\n", "self", ".", "PAD_WORD", "=", "'<blank>'", "\n", "self", ".", "UNK_WORD", "=", "'<unk>'", "\n", "self", ".", "head_info_num_WORD", "=", "'head_info_num'", "\n", "self", ".", "rabbit_entity_WORD", "=", "'rabbit_entity'", "\n", "self", ".", "rabbit_tou_num_WORD", "=", "'rabbit_tou_num'", "\n", "self", ".", "rabbit_jiao_num_WORD", "=", "'rabbit_jiao_num'", "\n", "self", ".", "jiao_info_num_WORD", "=", "'jiao_info_num'", "\n", "self", ".", "ji_entity_WORD", "=", "'ji_entity'", "\n", "self", ".", "ji_tou_num_WORD", "=", "'ji_tou_num'", "\n", "self", ".", "ji_jiao_num_WORD", "=", "'ji_jiao_num'", "\n", "\n", "self", ".", "PAD", "=", "0", "\n", "self", ".", "UNK", "=", "1", "\n", "self", ".", "BOS", "=", "2", "\n", "self", ".", "EOS", "=", "3", "\n", "self", ".", "head_info_num", "=", "4", "\n", "self", ".", "rabbit_entity", "=", "5", "\n", "self", ".", "rabbit_tou_num", "=", "6", "\n", "self", ".", "rabbit_jiao_num", "=", "7", "\n", "self", ".", "jiao_info_num", "=", "8", "\n", "self", ".", "ji_entity", "=", "9", "\n", "self", ".", "ji_tou_num", "=", "10", "\n", "self", ".", "ji_jiao_num", "=", "11", "\n", "", "", "Constants", "=", "Constants", "(", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.__init__": [[101, 106], ["numpy.power"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "optimizer", ",", "d_model", ",", "n_warmup_steps", ")", ":", "\n", "        ", "self", ".", "_optimizer", "=", "optimizer", "\n", "self", ".", "n_warmup_steps", "=", "n_warmup_steps", "\n", "self", ".", "n_current_steps", "=", "0", "\n", "self", ".", "init_lr", "=", "np", ".", "power", "(", "d_model", ",", "-", "0.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.step_and_update_lr": [[107, 111], ["model_no_symbolic.ScheduledOptim._update_learning_rate", "model_no_symbolic.ScheduledOptim._optimizer.step"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._update_learning_rate"], ["", "def", "step_and_update_lr", "(", "self", ")", ":", "\n", "        ", "\"step with the inner optimizer\"", "\n", "self", ".", "_update_learning_rate", "(", ")", "\n", "self", ".", "_optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad": [[112, 115], ["model_no_symbolic.ScheduledOptim._optimizer.zero_grad"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim.zero_grad"], ["", "def", "zero_grad", "(", "self", ")", ":", "\n", "        ", "\"zero out the gradient by the inner optimizer\"", "\n", "self", ".", "_optimizer", ".", "zero_grad", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._get_lr_scale": [[116, 120], ["numpy.min", "numpy.power", "numpy.power"], "methods", ["None"], ["", "def", "_get_lr_scale", "(", "self", ")", ":", "\n", "        ", "return", "np", ".", "min", "(", "[", "\n", "np", ".", "power", "(", "self", ".", "n_current_steps", ",", "-", "0.5", ")", ",", "\n", "np", ".", "power", "(", "self", ".", "n_warmup_steps", ",", "-", "1.5", ")", "*", "self", ".", "n_current_steps", "\n", "]", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._update_learning_rate": [[122, 128], ["model_no_symbolic.ScheduledOptim._get_lr_scale"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.ScheduledOptim._get_lr_scale"], ["", "def", "_update_learning_rate", "(", "self", ")", ":", "\n", "        ", "'''learning rate scheduleing per step'''", "\n", "self", ".", "n_current_steps", "+=", "1", "\n", "lr", "=", "self", ".", "init_lr", "*", "self", ".", "_get_lr_scale", "(", ")", "\n", "for", "param_group", "in", "self", ".", "_optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.MyGRUCell.__init__": [[138, 161], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "input_size", ",", "hidden_size", ",", "d_size", ",", "batch_first", "=", "True", ")", ":", "\n", "        ", "super", "(", "MyGRUCell", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "batch_first", "=", "batch_first", "\n", "self", ".", "reset_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "update_gate", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n", "self", ".", "transform", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", "+", "input_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "w2h_r", "=", "nn", ".", "Linear", "(", "input_size", ",", "d_size", ")", "\n", "self", ".", "h2h_r", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "d_size", ")", "\n", "self", ".", "dc", "=", "nn", ".", "Linear", "(", "d_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "output", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.MyGRUCell.forward": [[163, 181], ["input_t.squeeze.squeeze.squeeze", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.MyGRUCell.update_gate", "model_no_symbolic.MyGRUCell.reset_gate", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.MyGRUCell.transform", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "model_no_symbolic.MyGRUCell.output", "model_no_symbolic.MyGRUCell.dc", "model_no_symbolic.MyGRUCell.w2h_r", "model_no_symbolic.MyGRUCell.h2h_r"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_t", ",", "last_hidden", ",", "last_dt", ",", "alpha", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"\n        Do feedforward for one step\n        input_t: (batch_size, 1, input_size)\n        last_hidden: (bs, hidden_size)\n        last_dt: (bs, d_size)\n        \"\"\"", "\n", "input_t", "=", "input_t", ".", "squeeze", "(", "1", ")", "\n", "joined_input1", "=", "torch", ".", "cat", "(", "(", "last_hidden", ",", "input_t", ")", ",", "-", "1", ")", "\n", "z", "=", "self", ".", "update_gate", "(", "joined_input1", ")", "\n", "r", "=", "self", ".", "reset_gate", "(", "joined_input1", ")", "\n", "joined_input2", "=", "torch", ".", "cat", "(", "[", "r", "*", "last_hidden", ",", "input_t", "]", ",", "-", "1", ")", "\n", "h_hat", "=", "self", ".", "transform", "(", "joined_input2", ")", "\n", "gate_r", "=", "torch", ".", "sigmoid", "(", "self", ".", "w2h_r", "(", "input_t", ")", "+", "alpha", "*", "self", ".", "h2h_r", "(", "last_hidden", ")", ")", "\n", "dt", "=", "gate_r", "*", "last_dt", "# bs * d_size", "\n", "hidden", "=", "(", "1", "-", "z", ")", "*", "last_hidden", "+", "z", "*", "h_hat", "+", "self", ".", "dc", "(", "dt", ")", "\n", "output", "=", "self", ".", "output", "(", "hidden", ")", "\n", "return", "output", ",", "hidden", ",", "dt", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Attention.__init__": [[183, 189], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "hidden_size", ",", "z_dim", ",", "emb_size", "=", "0", ")", ":", "\n", "        ", "super", "(", "Attention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "W1", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "W2", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "z_dim", ",", "hidden_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "vt", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Attention.forward": [[189, 208], ["model_no_symbolic.Attention.W1", "model_no_symbolic.Attention.W2().unsqueeze", "model_no_symbolic.Attention.vt().squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "u_i.masked_fill.masked_fill.masked_fill", "model_no_symbolic.Attention.W2", "model_no_symbolic.Attention.vt", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "decoder_state", ",", "encoder_outputs", ",", "input_node_mask", ")", ":", "\n", "# print('decoder state dimension,',decoder_state.shape)", "\n", "# print('encoder_outputs dimension,', encoder_outputs.shape)", "\n", "# (bs, seq_len, hidden_size)", "\n", "        ", "encoder_transform", "=", "self", ".", "W1", "(", "encoder_outputs", ")", "\n", "# (bs, 1(unsqueeze), hidden_size)", "\n", "decoder_transform", "=", "self", ".", "W2", "(", "decoder_state", ")", ".", "unsqueeze", "(", "1", ")", "\n", "# # (bs, max_doc_len, 1) => (bs, max_doc_len)", "\n", "u_i", "=", "self", ".", "vt", "(", "torch", ".", "tanh", "(", "encoder_transform", "+", "decoder_transform", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# softmax with only valid inputs, excluding zero padding parts", "\n", "# # log-softmax for a better numerical stability", "\n", "if", "input_node_mask", "is", "not", "None", ":", "\n", "            ", "u_i", "=", "u_i", ".", "masked_fill", "(", "input_node_mask", ",", "-", "np", ".", "inf", ")", "\n", "", "else", ":", "\n", "            ", "pass", "\n", "# log_score = F.log_softmax(u_i, dim=-1)", "\n", "", "log_score", "=", "F", ".", "softmax", "(", "u_i", ",", "dim", "=", "-", "1", ")", "\n", "# log_score = masked_log_softmax(u_i, input_node_mask, dim=-1)", "\n", "return", "log_score", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.DecoderVAE.__init__": [[210, 222], ["torch.Module.__init__", "torch.GRU", "torch.GRU", "torch.GRU", "model_no_symbolic.Attention", "model_no_symbolic.Attention", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "DecoderVAE", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "# self.rnn = nn.GRU(input_size=hidden_size+z_dim,hidden_size=hidden_size+z_dim, batch_first=True)", "\n", "# self.my_rnn_gate = MyGRUCell(input_size = hidden_size+z_dim, hidden_size=hidden_size+z_dim+embedding_dim, d_size=embedding_dim)", "\n", "self", ".", "my_rnn_gate", "=", "nn", ".", "GRU", "(", "input_size", "=", "hidden_size", ",", "hidden_size", "=", "hidden_size", "+", "z_dim", ",", "batch_first", "=", "True", ")", "\n", "self", ".", "hidden_dim", "=", "hidden_size", "\n", "self", ".", "attn_equ", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "attn_sns", "=", "Attention", "(", "hidden_size", ",", "z_dim", ",", "embedding_dim", ")", "\n", "self", ".", "plan_w", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", "+", "z_dim", ",", "2", ")", "\n", "self", ".", "linear_map_context", "=", "nn", ".", "Linear", "(", "embedding_dim", "+", "hidden_size", ",", "hidden_size", ")", "\n", "self", ".", "linear_map", "=", "nn", ".", "Linear", "(", "hidden_size", "+", "z_dim", ",", "output_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.DecoderVAE.forward": [[223, 260], ["model_no_symbolic.DecoderVAE.attn_equ", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model_no_symbolic.DecoderVAE.attn_sns", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.DecoderVAE.linear_map_context", "model_no_symbolic.DecoderVAE.my_rnn_gate", "model_no_symbolic.DecoderVAE.linear_map", "model_no_symbolic.DecoderVAE.unsqueeze", "model_no_symbolic.DecoderVAE.unsqueeze", "torch.FloatTensor().to.unsqueeze", "torch.FloatTensor().to.unsqueeze", "torch.FloatTensor().to.unsqueeze", "model_no_symbolic.DecoderVAE.unsqueeze", "prev_h_batch.unsqueeze", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.bmm.squeeze", "torch.bmm.squeeze", "torch.bmm.squeeze", "range"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "prev_y_batch", ",", "prev_h_batch", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ",", "device", ")", ":", "\n", "        ", "\"\"\"\n        A foward path step to a Decoder\n        The step operates on one step-slice of the target sequence\n        :param prev_y_batch: embedded previous prediction bs*embedding_dim\n        :param prev_h_batch: current decoder state: bs * hidden_size(dec_dim)\n        :param z_sample: vae sample z: bs * z_dim\n        :param *_encoder_outputs\" bs * n * hidden_size, bs*m*hidden_size\n        equ_global, sns_global leave as future work\n        \"\"\"", "\n", "bs", "=", "prev_h_batch", ".", "shape", "[", "0", "]", "\n", "# calcualte attention from current RNN state and equation encoder outputs", "\n", "attn_weights_equ", "=", "self", ".", "attn_equ", "(", "prev_h_batch", ",", "equ_encoder_outputs", ",", "input_equ_node_mask", ")", "\n", "# Apply attention weights to encoder outputs to get weighted average", "\n", "# bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "context_equation", "=", "torch", ".", "bmm", "(", "attn_weights_equ", ".", "unsqueeze", "(", "1", ")", ",", "equ_encoder_outputs", ")", "\n", "\n", "# calculate attention fom current RNN state and common sense outputs", "\n", "attn_weights_sns", "=", "self", ".", "attn_sns", "(", "prev_h_batch", ",", "sns_encoder_outputs", ",", "input_sns_node_mask", ")", "\n", "# bs*1*seq_len x bs*seq_len*hidden_size -> bs*1*hidden_size", "\n", "context_sns", "=", "torch", ".", "bmm", "(", "attn_weights_sns", ".", "unsqueeze", "(", "1", ")", ",", "sns_encoder_outputs", ")", "\n", "\n", "# calculate plan attention, extract how many info from equ_encoder_outputs, how many info from sns_encoder_outputs", "\n", "# plan attention is conducted by softmax(ht-1W + b)", "\n", "# plan_attn_weight = F.softmax(self.plan_w(prev_h_batch), dim=-1) # bs * 2", "\n", "plan_attn_weight", "=", "torch", ".", "FloatTensor", "(", "[", "[", "0.0", ",", "1.0", "]", "for", "_", "in", "range", "(", "bs", ")", "]", ")", ".", "to", "(", "device", ")", "# do not conside equation information", "\n", "# print('plan attention shape is ',plan_attn_weight.shape)", "\n", "combine_context", "=", "torch", ".", "cat", "(", "(", "context_equation", ",", "context_sns", ")", ",", "1", ")", "\n", "# print('combine context shape is, ', combine_context.shape)", "\n", "context", "=", "torch", ".", "bmm", "(", "plan_attn_weight", ".", "unsqueeze", "(", "1", ")", ",", "combine_context", ")", "# bs*1*2 x bs*2*hidden_size -> bs*1*hidden_size", "\n", "# combine embedded input word and attented context, run through RNN", "\n", "y_ctx", "=", "torch", ".", "cat", "(", "(", "prev_y_batch", ",", "context", ".", "squeeze", "(", "1", ")", ")", ",", "1", ")", "# bs*(hidden_size+embedding_dim)", "\n", "rnn_input", "=", "self", ".", "linear_map_context", "(", "y_ctx", ")", "# bs * hidden_size", "\n", "\n", "dec_output", ",", "dec_hidden", "=", "self", ".", "my_rnn_gate", "(", "rnn_input", ".", "unsqueeze", "(", "1", ")", ",", "prev_h_batch", ".", "unsqueeze", "(", "0", ")", ")", "\n", "dec_output", "=", "self", ".", "linear_map", "(", "dec_output", ")", "\n", "return", "dec_output", ",", "dec_hidden", ",", "plan_attn_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.WordRNN.__init__": [[263, 282], ["torch.Module.__init__", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.GRU", "torch.GRU", "torch.GRU", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model_no_symbolic.WordRNN.Ws1.data.uniform_", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model_no_symbolic.WordRNN.Ws2.data.uniform_", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Embedding().from_pretrained", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_dim", ",", "dropout", "=", "0.1", ",", "pretrained", "=", "None", ")", ":", "\n", "        ", "super", "(", "WordRNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "embed_size", "=", "embedding_dim", "\n", "self", ".", "hidden_size", "=", "hidden_dim", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "dropout", ")", "\n", "if", "pretrained", "is", "None", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", ".", "from_pretrained", "(", "pretrained", ")", "\n", "# self.word_encoder = nn.GRU(embedding_dim, hidden_dim, batch_first=True, bidirectional=True)", "\n", "# no bidirectional trytry", "\n", "", "self", ".", "word_encoder", "=", "nn", ".", "GRU", "(", "embedding_dim", ",", "hidden_dim", ",", "batch_first", "=", "True", ",", "bidirectional", "=", "False", ")", "\n", "# self.Ws1 = nn.Parameter(torch.Tensor(1, 2*hidden_dim, 2*hidden_dim))", "\n", "self", ".", "Ws1", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "hidden_dim", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws1", ".", "data", "=", "self", ".", "Ws1", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "# self.Ws2 = nn.Parameter(torch.Tensor(1, 1, 2*hidden_dim))", "\n", "self", ".", "Ws2", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "1", ",", "1", ",", "hidden_dim", ")", ")", "\n", "self", ".", "Ws2", ".", "data", "=", "self", ".", "Ws2", ".", "data", ".", "uniform_", "(", "-", "0.1", ",", "0.1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.WordRNN.forward": [[283, 302], ["len", "len", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "torch.eq", "model_no_symbolic.WordRNN.embedding", "model_no_symbolic.WordRNN.dropout", "model_no_symbolic.WordRNN.word_encoder", "model_no_symbolic.WordRNN.dropout", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.softmax().view.squeeze().masked_fill", "torch.softmax().view", "torch.softmax().view", "torch.softmax().view", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "model_no_symbolic.WordRNN.Ws2.repeat", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "model_no_symbolic.WordRNN.Ws1.repeat", "torch.softmax().view.squeeze", "torch.softmax", "torch.softmax", "torch.softmax", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "one_doc", ")", ":", "\n", "        ", "'''\n        one_doc: [[1,2,3,0],[2,3,4,5],[3,0,0,0]], doc_lens:[3,4,1]\n        '''", "\n", "seq_len", "=", "len", "(", "one_doc", "[", "0", "]", ")", "\n", "max_sent_len", "=", "len", "(", "one_doc", ")", "\n", "tmp_mask", "=", "torch", ".", "eq", "(", "one_doc", ",", "0", ")", "\n", "doc_embedding", "=", "self", ".", "embedding", "(", "one_doc", ")", "\n", "doc_embedding", "=", "self", ".", "dropout", "(", "doc_embedding", ")", "\n", "rnn_out", ",", "_", "=", "self", ".", "word_encoder", "(", "doc_embedding", ")", "\n", "#rnn_out = run_rnn(self.word_encoder,doc_embedding, doc_lens)", "\n", "rnn_out", "=", "self", ".", "dropout", "(", "rnn_out", ")", "\n", "final_T", "=", "torch", ".", "transpose", "(", "rnn_out", ",", "2", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "A", "=", "torch", ".", "tanh", "(", "torch", ".", "bmm", "(", "self", ".", "Ws1", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "final_T", ")", ")", "\n", "A", "=", "torch", ".", "bmm", "(", "self", ".", "Ws2", ".", "repeat", "(", "1", "*", "max_sent_len", ",", "1", ",", "1", ")", ",", "A", ")", "\n", "A", "=", "A", ".", "squeeze", "(", "1", ")", ".", "masked_fill", "(", "tmp_mask", ",", "-", "1e12", ")", "\n", "A", "=", "F", ".", "softmax", "(", "A", ",", "dim", "=", "1", ")", ".", "view", "(", "1", "*", "max_sent_len", ",", "-", "1", ",", "seq_len", ")", "\n", "final", "=", "torch", ".", "bmm", "(", "A", ",", "rnn_out", ")", ".", "squeeze", "(", "1", ")", "\n", "return", "final", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__": [[305, 329], ["torch.Module.__init__", "model_no_symbolic.EncoderGGNN", "model_no_symbolic.EncoderGGNN", "model_no_symbolic.WordRNN", "model_no_symbolic.DecoderVAE", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.__init__"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "n_hop", "=", "5", ",", "teacher_forcing", "=", "0.5", ",", "dropout", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "Graph2seq", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# the First encoder to encode equation information", "\n", "self", ".", "encoder_equ", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# the second encoder to encode common sense information", "\n", "self", ".", "encoder_sns", "=", "EncoderGGNN", "(", "vocab_size", ",", "embedding_dim", ",", "hidden_size", ",", "n_hop", ")", "\n", "# this is sentence encoder for training VAE posterior", "\n", "self", ".", "out_enc", "=", "WordRNN", "(", "vocab_size", "=", "vocab_size", ",", "embedding_dim", "=", "embedding_dim", ",", "hidden_dim", "=", "hidden_size", ",", "dropout", "=", "dropout", ")", "\n", "self", ".", "decoder", "=", "DecoderVAE", "(", "embedding_dim", ",", "hidden_size", ",", "z_dim", ",", "output_size", ",", "dropout", ")", "\n", "self", ".", "embedding", "=", "nn", ".", "Embedding", "(", "vocab_size", ",", "embedding_dim", ")", "\n", "self", ".", "teacher_forcing", "=", "teacher_forcing", "\n", "# sample mu and logvars", "\n", "self", ".", "z_dim", "=", "z_dim", "\n", "\n", "self", ".", "q_mu_posterior", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_posterior", "=", "nn", ".", "Linear", "(", "2", "*", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "prior_fc1", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "hidden_size", ",", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", ")", "\n", "self", ".", "q_mu_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "self", ".", "q_logvar_prior", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "z_dim", ")", "\n", "# set embedding layer with the same parameters", "\n", "self", ".", "out_enc", ".", "embedding", ".", "weight", "=", "self", ".", "embedding", ".", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z": [[330, 337], ["torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul().add_", "torch.randn_like.mul", "torch.randn_like.mul", "torch.randn_like.mul"], "methods", ["None"], ["", "def", "sample_z", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "\"\"\"\n        Reparameterization trick: z = mu + std*eps; eps ~ N(0,I)\n        \"\"\"", "\n", "std", "=", "torch", ".", "exp", "(", "logvar", "/", "2", ")", "\n", "eps", "=", "torch", ".", "randn_like", "(", "std", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z_prior": [[338, 341], ["torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn().to", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "sample_z_prior", "(", "self", ",", "mbsize", ",", "device", ")", ":", "\n", "        ", "z", "=", "torch", ".", "randn", "(", "mbsize", ",", "self", ".", "z_dim", ")", ".", "to", "(", "device", ")", "\n", "return", "z", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.forward": [[342, 369], ["model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.encoder_equ", "model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.encoder_sns", "model_no_symbolic.Graph2seq.out_enc", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.Graph2seq.prior_fc1", "model_no_symbolic.Graph2seq.sample_z", "input_equ_nodes.eq", "input_sns_nodes.eq", "model_no_symbolic.Graph2seq.decode_dual", "logits.view.view.view", "model_no_symbolic.Graph2seq.q_mu_posterior", "model_no_symbolic.Graph2seq.q_logvar_posterior", "model_no_symbolic.Graph2seq.q_mu_prior", "model_no_symbolic.Graph2seq.q_logvar_prior", "logits.view.view.size"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z", "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.decode_dual"], ["", "def", "forward", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "input_target", ",", "scene", ",", "device", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# print('node representation dim is,', nodes_resp.shape)", "\n", "# cond_embedding = torch.cat([equ_encoder_hidden, equ_encoder_hidden],1)", "\n", "cond_embedding", "=", "sns_encoder_hidden", "\n", "output_embedding", "=", "self", ".", "out_enc", "(", "input_target", ")", "\n", "# get posterior mu & logvar", "\n", "recog_input", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "output_embedding", "]", ",", "1", ")", "\n", "recog_mu", ",", "recog_logvar", "=", "self", ".", "q_mu_posterior", "(", "recog_input", ")", ",", "self", ".", "q_logvar_posterior", "(", "recog_input", ")", "\n", "# get prior mu & logvar", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "# sample latent z during training, sample posterior, inference with prior", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "recog_mu", ",", "recog_logvar", ")", "\n", "input_equ_node_mask", "=", "input_equ_nodes", ".", "eq", "(", "0", ")", "\n", "input_sns_node_mask", "=", "input_sns_nodes", ".", "eq", "(", "0", ")", "\n", "\n", "# train with schedule sampling", "\n", "logits", ",", "plan_attns", "=", "self", ".", "decode_dual", "(", "input_target", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "\n", "sns_encoder_outputs", ",", "latent_sample", ",", "self", ".", "teacher_forcing", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", "\n", "logits", "=", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "2", ")", ")", "\n", "return", "logits", ",", "recog_mu", ",", "recog_logvar", ",", "prior_mu", ",", "prior_logvar", ",", "plan_attns", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.decode_dual": [[370, 397], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "range", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "random.random", "model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_hidden.squeeze.squeeze.squeeze", "model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.decoder", "torch.stack.append", "torch.stack.append", "torch.stack.append", "graph_attntion.append", "dec_output.squeeze().max", "dec_hidden.squeeze.squeeze.squeeze", "dec_output.squeeze", "dec_output.squeeze", "dec_output.squeeze"], "methods", ["None"], ["", "def", "decode_dual", "(", "self", ",", "dec_input_var", ",", "cond_embedding", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "teacher_forcing_ratio", ",", "device", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ")", ":", "\n", "        ", "bs", ",", "seq_len", "=", "dec_input_var", ".", "shape", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "z_sample", "]", ",", "dim", "=", "1", ")", "\n", "dec_input", "=", "torch", ".", "LongTensor", "(", "[", "Constants", ".", "BOS", "]", "*", "bs", ")", ".", "to", "(", "device", ")", "\n", "predicted_logits", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "# use this to record the attention score", "\n", "# d_dec = d_initial", "\n", "for", "di", "in", "range", "(", "seq_len", ")", ":", "\n", "            ", "if", "random", ".", "random", "(", ")", "<", "self", ".", "teacher_forcing", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ",", "device", ")", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "dec_input", "=", "dec_input_var", "[", ":", ",", "di", "]", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "else", ":", "\n", "                ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input", ")", "# embedding look up table", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "z_sample", ",", "input_equ_node_mask", ",", "input_sns_node_mask", ",", "device", ")", "\n", "\n", "predicted_logits", ".", "append", "(", "dec_output", ".", "squeeze", "(", "1", ")", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "dec_input", "=", "max_index", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "", "", "predicted_logits", "=", "torch", ".", "stack", "(", "predicted_logits", ",", "1", ")", "\n", "planning_probs", "=", "torch", ".", "stack", "(", "graph_attntion", ",", "1", ")", "\n", "return", "predicted_logits", ",", "planning_probs", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict": [[398, 443], ["model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.encoder_equ", "model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.encoder_sns", "model_no_symbolic.Graph2seq.prior_fc1", "model_no_symbolic.Graph2seq.sample_z", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model_no_symbolic.Graph2seq.q_mu_prior", "model_no_symbolic.Graph2seq.q_logvar_prior", "model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.decoder", "graph_attntion.append", "dec_output.squeeze().max", "dec_ids.append", "dec_hidden.squeeze.squeeze.squeeze", "max_index.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "max_index.squeeze().item", "dec_output.squeeze", "max_index.squeeze"], "methods", ["home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.sample_z"], ["", "def", "predict", "(", "self", ",", "input_equ_nodes", ",", "adj_equ_matrix", ",", "equ_node_lens", ",", "input_sns_nodes", ",", "adj_sns_matrix", ",", "sns_node_lens", ",", "scene", ",", "device", ",", "max_tgt_len", ")", ":", "\n", "# encode equation input", "\n", "        ", "equ_node_resp", "=", "self", ".", "embedding", "(", "input_equ_nodes", ")", "\n", "equ_encoder_outputs", ",", "equ_encoder_hidden", "=", "self", ".", "encoder_equ", "(", "equ_node_resp", ",", "adj_equ_matrix", ",", "equ_node_lens", ")", "# bs*seq*h, bs*h", "\n", "# encode common sense input", "\n", "sns_node_resp", "=", "self", ".", "embedding", "(", "input_sns_nodes", ")", "\n", "sns_encoder_outputs", ",", "sns_encoder_hidden", "=", "self", ".", "encoder_sns", "(", "sns_node_resp", ",", "adj_sns_matrix", ",", "sns_node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# sample z from normal distribution", "\n", "batch_size", "=", "equ_node_resp", ".", "shape", "[", "0", "]", "\n", "\n", "# get prior mu & logvar", "\n", "# cond_embedding = torch.cat([equ_encoder_hidden, sns_encoder_hidden],1)", "\n", "cond_embedding", "=", "sns_encoder_hidden", "\n", "prior_embedding", "=", "self", ".", "prior_fc1", "(", "cond_embedding", ")", "\n", "prior_mu", ",", "prior_logvar", "=", "self", ".", "q_mu_prior", "(", "prior_embedding", ")", ",", "self", ".", "q_logvar_prior", "(", "prior_embedding", ")", "\n", "\n", "# smaple latent z", "\n", "latent_sample", "=", "self", ".", "sample_z", "(", "prior_mu", ",", "prior_logvar", ")", "\n", "\n", "# decode", "\n", "dec_ids", ",", "graph_attntion", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "torch", ".", "cat", "(", "[", "cond_embedding", ",", "latent_sample", "]", ",", "dim", "=", "1", ")", "\n", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "# print(prev_y.shape)", "\n", "# print(dec_hidden.shape)", "\n", "# print(sns_encoder_outputs.shape)", "\n", "# print(latent_sample.shape)", "\n", "\n", "dec_output", ",", "dec_hidden", ",", "plan_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "equ_encoder_outputs", ",", "sns_encoder_outputs", ",", "latent_sample", ",", "input_equ_node_mask", "=", "None", ",", "input_sns_node_mask", "=", "None", ",", "device", "=", "device", ")", "\n", "graph_attntion", ".", "append", "(", "plan_attn", ".", "data", ")", "\n", "max_value", ",", "max_index", "=", "dec_output", ".", "squeeze", "(", "1", ")", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "#max_index = F.softmax(dec_output, dim=-1).squeeze(1).multinomial(1)", "\n", "dec_ids", ".", "append", "(", "max_index", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "max_index", "\n", "# print(max_index)", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "1", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "max_index", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "graph_attntion", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.Graph2seq.predict_with_sampling": [[444, 510], ["model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.encoder", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "model_no_symbolic.Graph2seq.embedding", "model_no_symbolic.Graph2seq.decoder", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "torch.log_softmax().squeeze", "dec_ids.append", "probs.clone.multinomial.squeeze", "dec_hidden.squeeze.squeeze.squeeze", "probs.clone.multinomial.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze", "torch.softmax().squeeze.clone", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "probs.clone.multinomial.squeeze().item", "torch.softmax", "torch.softmax", "torch.softmax", "torch.log_softmax", "torch.log_softmax", "torch.log_softmax", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_probs.clone", "sorted_probs.clone.multinomial().view", "sorted_indices.gather", "sorted_probs.clone.gather().log", "F.softmax().squeeze.clone.multinomial", "F.softmax().squeeze.clone.gather().log", "torch.softmax", "torch.softmax", "torch.softmax", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul_", "F.softmax().squeeze.clone.gather", "sorted_probs.clone.div_", "sorted_probs.clone.mul_", "sorted_probs.clone.add_", "F.softmax().squeeze.clone.div_", "F.softmax().squeeze.clone.mul_", "F.softmax().squeeze.clone.add_", "probs.clone.multinomial.squeeze", "decoder_output.div_", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "torch.topk", "probs.clone.multinomial.view", "sorted_probs.clone.sum().unsqueeze", "sorted_probs.mul", "sorted_probs.clone.multinomial", "sorted_probs.clone.gather", "F.softmax().squeeze.clone.sum().unsqueeze", "torch.softmax().squeeze.mul", "F.softmax().squeeze.clone.gather", "F.softmax().squeeze.clone.sum", "probs.clone.multinomial.view", "sorted_probs.clone.sum", "F.softmax().squeeze.clone.sum"], "methods", ["None"], ["", "def", "predict_with_sampling", "(", "self", ",", "input_nodes", ",", "adj_matrix", ",", "node_lens", ",", "device", ",", "max_tgt_len", ",", "temp", "=", "None", ",", "k", "=", "None", ",", "p", "=", "None", ",", "m", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        some sampling based decoding method:\n        tem: temperature\n        k: top-k sampling method k\n        p: Nucleus sampling method\n        m: mass of original dist to interpolate\n        \"\"\"", "\n", "# embedding look up table", "\n", "nodes_resp", "=", "self", ".", "embedding", "(", "input_nodes", ")", "\n", "encoder_outputs", ",", "encoder_hidden", "=", "self", ".", "encoder", "(", "nodes_resp", ",", "adj_matrix", ",", "node_lens", ")", "# bs*seq*h, bs*h", "\n", "\n", "# decode", "\n", "dec_ids", ",", "attn_weight", "=", "[", "]", ",", "[", "]", "\n", "curr_token", "=", "Constants", ".", "BOS", "\n", "curr_dec_idx", "=", "0", "\n", "dec_input_var", "=", "torch", ".", "LongTensor", "(", "[", "curr_token", "]", ")", ".", "to", "(", "device", ")", "\n", "dec_hidden", "=", "encoder_hidden", "\n", "while", "(", "curr_token", "!=", "Constants", ".", "EOS", "and", "curr_dec_idx", "<=", "max_tgt_len", ")", ":", "\n", "            ", "prev_y", "=", "self", ".", "embedding", "(", "dec_input_var", ")", "\n", "decoder_output", ",", "dec_hidden", ",", "dec_attn", "=", "self", ".", "decoder", "(", "prev_y", ",", "dec_hidden", ",", "encoder_outputs", ",", "input_node_mask", "=", "None", ")", "\n", "\n", "probs", "=", "F", ".", "softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "logprobs", "=", "F", ".", "log_softmax", "(", "decoder_output", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "if", "temp", "is", "not", "None", ":", "\n", "                ", "samp_probs", "=", "F", ".", "softmax", "(", "decoder_output", ".", "div_", "(", "temp", ")", ",", "dim", "=", "-", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "samp_probs", "=", "probs", ".", "clone", "(", ")", "\n", "", "if", "k", "is", "not", "None", ":", "\n", "                ", "indices_to_remove", "=", "samp_probs", "<", "torch", ".", "topk", "(", "samp_probs", ",", "k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "samp_probs", "[", "indices_to_remove", "]", "=", "0.", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul_", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "elif", "p", "is", "not", "None", ":", "\n", "                ", "sorted_probs", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "samp_probs", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "sorted_probs", ",", "dim", "=", "-", "1", ")", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "p", "\n", "sorted_indices_to_remove", "[", ":", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", ":", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", ":", ",", "0", "]", "=", "0", "\n", "sorted_samp_probs", "=", "sorted_probs", ".", "clone", "(", ")", "\n", "sorted_samp_probs", "[", "sorted_indices_to_remove", "]", "=", "0", "\n", "if", "m", "is", "not", "None", ":", "\n", "                    ", "sorted_samp_probs", ".", "div_", "(", "sorted_samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "sorted_samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "sorted_samp_probs", ".", "add_", "(", "sorted_probs", ".", "mul", "(", "m", ")", ")", "\n", "", "sorted_next_indices", "=", "sorted_samp_probs", ".", "multinomial", "(", "1", ")", ".", "view", "(", "-", "1", ",", "1", ")", "\n", "next_tokens", "=", "sorted_indices", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", "\n", "next_logprobs", "=", "sorted_samp_probs", ".", "gather", "(", "1", ",", "sorted_next_indices", ")", ".", "log", "(", ")", "\n", "", "else", ":", "\n", "                ", "if", "m", "is", "not", "None", ":", "\n", "                    ", "samp_probs", ".", "div_", "(", "samp_probs", ".", "sum", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ")", "\n", "samp_probs", ".", "mul_", "(", "1", "-", "m", ")", "\n", "samp_probs", ".", "add_", "(", "probs", ".", "mul", "(", "m", ")", ")", "\n", "", "next_tokens", "=", "samp_probs", ".", "multinomial", "(", "1", ")", "\n", "next_logprobs", "=", "samp_probs", ".", "gather", "(", "1", ",", "next_tokens", ".", "view", "(", "-", "1", ",", "1", ")", ")", ".", "log", "(", ")", "\n", "", "dec_ids", ".", "append", "(", "next_tokens", ".", "squeeze", "(", ")", ".", "item", "(", ")", ")", "\n", "dec_input_var", "=", "next_tokens", ".", "squeeze", "(", "1", ")", "\n", "dec_hidden", "=", "dec_hidden", ".", "squeeze", "(", "0", ")", "\n", "curr_dec_idx", "+=", "1", "\n", "curr_token", "=", "next_tokens", ".", "item", "(", ")", "\n", "", "return", "dec_ids", ",", "attn_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.tal-ai_make_emnlp2021.model.model_no_symbolic.masked_log_softmax": [[129, 136], ["torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "torch.nn.functional.log_softmax", "mask.unsqueeze.float", "mask.unsqueeze.dim", "vector.dim", "mask.unsqueeze.unsqueeze"], "function", ["None"], ["", "", "", "def", "masked_log_softmax", "(", "vector", ",", "mask", ",", "dim", ")", ":", "\n", "\t", "if", "mask", "is", "not", "None", ":", "\n", "\t\t", "mask", "=", "mask", ".", "float", "(", ")", "\n", "while", "mask", ".", "dim", "(", ")", "<", "vector", ".", "dim", "(", ")", ":", "\n", "\t\t\t", "mask", "=", "mask", ".", "unsqueeze", "(", "1", ")", "\n", "", "vector", "=", "vector", "+", "(", "mask", "+", "1e-45", ")", ".", "log", "(", ")", "\n", "", "return", "torch", ".", "nn", ".", "functional", ".", "log_softmax", "(", "vector", ",", "dim", "=", "dim", ")", "\n", "\n"]]}