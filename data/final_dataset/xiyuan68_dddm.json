{"home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.AccuracyGetter.__init__": [[69, 82], ["Exception"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ":", "str", ",", "architecture", ":", "str", ")", ":", "\n", "        ", "if", "dataset", "==", "'mnist'", "and", "architecture", "==", "'cnn'", ":", "\n", "            ", "self", ".", "feature_dim", "=", "1", "\n", "", "elif", "dataset", "==", "'imdb'", "and", "architecture", "==", "'lstm'", ":", "\n", "            ", "self", ".", "feature_dim", "=", "-", "1", "\n", "", "elif", "dataset", "==", "'cifar10'", "and", "architecture", "==", "'resnet'", ":", "\n", "            ", "self", ".", "feature_dim", "=", "1", "\n", "", "elif", "dataset", "==", "'speechcommands'", "and", "architecture", "==", "'deepspeech'", ":", "\n", "            ", "self", ".", "feature_dim", "=", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "Exception", "(", "'Wrong dataset and architecture combination: %s + %s'", "%", "(", "dataset", ",", "architecture", ")", ")", "\n", "", "self", ".", "n_sample", "=", "0", "\n", "self", ".", "n_correct", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.AccuracyGetter.compute_batch": [[83, 90], ["torch.max", "torch.mean"], "methods", ["None"], ["", "def", "compute_batch", "(", "self", ",", "output", ":", "torch", ".", "Tensor", ",", "y", ":", "torch", ".", "Tensor", ")", ":", "\n", "# RNN return sequence instead of single label", "\n", "        ", "if", "output", ".", "ndim", ">", "2", ":", "\n", "            ", "output", "=", "torch", ".", "mean", "(", "output", ",", "dim", "=", "1", ")", "\n", "", "self", ".", "n_sample", "+=", "y", ".", "shape", "[", "0", "]", "\n", "_", ",", "predicted", "=", "torch", ".", "max", "(", "output", ",", "self", ".", "feature_dim", ")", "\n", "self", ".", "n_correct", "+=", "(", "predicted", "==", "y", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.AccuracyGetter.get_accuracy": [[91, 95], ["None"], "methods", ["None"], ["", "def", "get_accuracy", "(", "self", ")", ":", "\n", "        ", "acc", "=", "self", ".", "n_correct", "/", "self", ".", "n_sample", "\n", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.train_epoch": [[97, 146], ["model.train", "traintest.AccuracyGetter", "numpy.mean", "traintest.AccuracyGetter.get_accuracy", "model", "loss_func", "optimizer.zero_grad", "loss_func.backward", "optimizer.step", "np.mean.append", "traintest.AccuracyGetter.compute_batch", "x.to", "y.to", "loss_func.item"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.AccuracyGetter.get_accuracy", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.AccuracyGetter.compute_batch"], ["", "", "def", "train_epoch", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "loader", ":", "torch", ".", "utils", ".", "data", ".", "DataLoader", ",", "\n", "loss_func", ":", "torch", ".", "nn", ".", "modules", ".", "loss", ".", "_Loss", ",", "\n", "optimizer", ":", "torch", ".", "optim", ".", "Optimizer", ",", "\n", "device", ":", "str", ")", ":", "\n", "    ", "\"\"\"\n    Train given model for one epoch.\n\n    Parameters\n    ----------\n    model : torch.nn.Module\n        neural network classifier.\n    loader : torch.utils.data.DataLoader\n        pytorch data loader.\n    loss_func : torch.nn.modules.loss._Loss\n        pytorch loss function.\n    optimizer : torch.optim.Optimizer\n        pytorch optimizer.\n    device : str, optional\n        device on which the model is loaded.\n\n    Returns\n    -------\n    loss_train : float\n        mean loss in this epoch.\n    acc_train : float\n        mean accuracy in this epoch..\n\n    \"\"\"", "\n", "model", ".", "train", "(", ")", "\n", "acc_getter", "=", "AccuracyGetter", "(", "dataset", ",", "architecture", ")", "\n", "loss_train", "=", "[", "]", "\n", "\n", "for", "x", ",", "y", "in", "loader", ":", "\n", "        ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "output", "=", "model", "(", "x", ")", "\n", "loss", "=", "loss_func", "(", "output", ",", "y", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "loss_train", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "acc_getter", ".", "compute_batch", "(", "output", ",", "y", ")", "\n", "\n", "", "loss_train", "=", "np", ".", "mean", "(", "loss_train", ")", "\n", "acc_train", "=", "acc_getter", ".", "get_accuracy", "(", ")", "\n", "\n", "return", "loss_train", ",", "acc_train", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.predict_epoch": [[148, 205], ["model.eval", "traintest.AccuracyGetter", "numpy.mean", "traintest.AccuracyGetter.get_accuracy", "model", "traintest.AccuracyGetter.compute_batch", "numpy.concatenate", "torch.autograd.Variable.to", "torch.autograd.Variable.to", "torch.autograd.Variable", "torch.autograd.Variable", "np.concatenate.append", "loss_func", "loss_all.append", "model.cpu().detach().numpy", "loss_func.item", "model.cpu().detach", "model.cpu"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.AccuracyGetter.get_accuracy", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.AccuracyGetter.compute_batch"], ["", "def", "predict_epoch", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "model", ":", "torch", ".", "nn", ".", "Module", ",", "\n", "loader", ":", "torch", ".", "utils", ".", "data", ".", "DataLoader", ",", "\n", "loss_func", ":", "torch", ".", "nn", ".", "modules", ".", "loss", ".", "_Loss", "=", "None", ",", "\n", "return_output", ":", "bool", "=", "False", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ")", ":", "\n", "    ", "\"\"\"\n    Let given neural network make predicitons.\n\n    Parameters\n    ----------\n    model : torch.nn.Module\n        neural network classifier.\n    loader : torch.utils.data.DataLoader\n        pytorch data loader.\n    loss_func : torch.nn.modules.loss._Loss, optional\n        pytorch loss function. The default is None.\n    return_output : bool, optional\n        whether return model prediction. The default is False.\n    device : str, optional\n        device on which the model is loaded. The default is DEVICE.\n\n        when False, mean loss and accuracy of this epoch will be returned.\n\n    Returns\n    -------\n    TYPE\n        DESCRIPTION.\n\n    \"\"\"", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "acc_getter", "=", "AccuracyGetter", "(", "dataset", ",", "architecture", ")", "\n", "loss_all", "=", "[", "]", "\n", "output_all", "=", "[", "]", "\n", "for", "x", ",", "y", "in", "loader", ":", "\n", "        ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "if", "loss_func", "is", "not", "None", ":", "\n", "            ", "x", "=", "torch", ".", "autograd", ".", "Variable", "(", "x", ")", "\n", "y", "=", "torch", ".", "autograd", ".", "Variable", "(", "y", ")", "\n", "", "output", "=", "model", "(", "x", ")", "\n", "if", "return_output", ":", "\n", "            ", "output_all", ".", "append", "(", "output", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", ")", "\n", "", "if", "loss_func", "is", "not", "None", ":", "\n", "            ", "loss", "=", "loss_func", "(", "output", ",", "y", ")", "\n", "loss_all", ".", "append", "(", "loss", ".", "item", "(", ")", ")", "\n", "", "acc_getter", ".", "compute_batch", "(", "output", ",", "y", ")", "\n", "\n", "", "loss_mean", "=", "np", ".", "mean", "(", "loss_all", ")", "\n", "acc", "=", "acc_getter", ".", "get_accuracy", "(", ")", "\n", "\n", "if", "return_output", ":", "\n", "        ", "output_all", "=", "np", ".", "concatenate", "(", "output_all", ",", "-", "2", ")", "\n", "return", "output_all", "\n", "", "else", ":", "\n", "        ", "return", "loss_mean", ",", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.train_model": [[207, 292], ["print", "utils.update_trainlog", "model.load_model", "torch.nn.CrossEntropyLoss", "torch.optim.Adam", "task.get_loader", "task.get_loader", "utils.get_pt_model", "range", "model.load_model.parameters", "traintest.train_epoch", "traintest.predict_epoch", "print", "utils.update_trainlog", "print", "print", "utils.update_trainlog", "torch.save", "model.load_model.state_dict"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.update_trainlog", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.load_model", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_loader", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_loader", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_pt_model", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.train_epoch", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.predict_epoch", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.update_trainlog", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.update_trainlog"], ["", "", "def", "train_model", "(", "dataset", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "\n", "epochs", ":", "int", "=", "50", ",", "\n", "save", ":", "bool", "=", "True", ",", "\n", "patience", ":", "int", "=", "20", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ",", "\n", "num_workers", ":", "int", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Train a neural network.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout : float, optional\n        dropout rate at training phase. The default is 0.\n    batch_size : int, optional\n        batch size. The default is 64.\n    epochs : int, optional\n        number of maximum training epochs. The default is 50.\n    save : bool, optional\n        whether save model after training. The default is True.\n    patience : int, optional\n        training will be stopped if validation loss stops decreasing in *patience* epochs. \n        The default is 20.\n    device : str, optional\n        device on which the model is loaded. The default is DEVICE.\n    num_workers: int, optional\n        how many subprocesses to use for data. The default is 4.\n\n    Returns\n    -------\n    model : torch.nn.Module\n        well-trained neural network.\n\n    \"\"\"", "\n", "\n", "print", "(", "'Training'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout", ")", "\n", "\n", "update_trainlog", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout", ",", "mode", "=", "'w'", ")", "\n", "model", "=", "load_model", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout", ",", "None", ",", "\n", "device", ",", "return_untrained", "=", "True", ")", "\n", "loss_func", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ")", "\n", "\n", "loader_train", "=", "get_loader", "(", "dataset", ",", "subset", "=", "'train'", ",", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "True", ",", "num_workers", "=", "num_workers", ",", "\n", "phase", "=", "'training'", ")", "\n", "loader_val", "=", "get_loader", "(", "dataset", ",", "subset", "=", "'val'", ",", "batch_size", "=", "batch_size", ",", "\n", "num_workers", "=", "num_workers", ")", "\n", "pt", "=", "get_pt_model", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout", ")", "\n", "\n", "loss_val_min", "=", "0", "\n", "idx_epoch_saved", "=", "0", "\n", "for", "i", "in", "range", "(", "epochs", ")", ":", "\n", "        ", "if", "i", ">", "idx_epoch_saved", "+", "patience", ":", "\n", "            ", "print", "(", "'Early Stopping'", ")", "\n", "break", "\n", "", "loss_train", ",", "acc_train", "=", "train_epoch", "(", "dataset", ",", "architecture", ",", "\n", "model", ",", "loader_train", ",", "loss_func", ",", "\n", "optimizer", ",", "device", ")", "\n", "loss_val", ",", "acc_val", "=", "predict_epoch", "(", "dataset", ",", "architecture", ",", "\n", "model", ",", "loader_val", ",", "loss_func", ",", "\n", "device", "=", "device", ")", "\n", "\n", "line", "=", "'Epoch [{}/{}], Train Loss: {:.4f}, Train Acc: {:.2f}, Val Loss: {:.4f}, Val Acc: {:.2f}'", ".", "format", "(", "i", "+", "1", ",", "epochs", ",", "loss_train", ",", "acc_train", ",", "loss_val", ",", "acc_val", ")", "\n", "print", "(", "line", ")", "\n", "update_trainlog", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout", ",", "line", ")", "\n", "# save current model if it shows lowest val loss in history", "\n", "if", "save", "and", "(", "i", "==", "0", "or", "loss_val", "<", "loss_val_min", ")", ":", "\n", "            ", "line", "=", "'Saving model'", "\n", "print", "(", "line", ")", "\n", "update_trainlog", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout", ",", "line", ")", "\n", "loss_val_min", "=", "loss_val", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "pt", ")", "\n", "idx_epoch_saved", "=", "i", "\n", "\n", "", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.attack_model": [[294, 444], ["print", "model.load_model", "task.get_loader", "print", "print", "utils.get_npz", "numpy.savez_compressed", "traintest.predict_epoch", "torch.cat", "task.iter2array", "task.iter2array", "art.estimators.classification.PyTorchClassifier", "art.attacks.evasion.SquareAttack", "foolbox.attacks.LinfRepeatedAdditiveUniformNoiseAttack.generate", "art.estimators.classification.PyTorchClassifier.predict", "numpy.mean", "foolbox.PyTorchModel", "numpy.concatenate", "torch.nn.CrossEntropyLoss", "foolbox.attacks.PGD", "np.concatenate.append", "list", "numpy.mean", "numpy.argmax", "dict", "Exception", "task.iter2array.to", "task.iter2array.to", "eagerpy.astensors", "foolbox.attacks.LinfRepeatedAdditiveUniformNoiseAttack.", "cleverhans.torch.attacks.carlini_wagner_l2.carlini_wagner_l2", "torch.argmax", "x_adv.cpu.cpu", "x_adv.cpu.numpy", "success.numpy", "foolbox.attacks.SpatialAttack", "model.load_model.", "foolbox.attacks.FGSM", "foolbox.attacks.L2DeepFoolAttack", "foolbox.attacks.SaltAndPepperNoiseAttack", "foolbox.attacks.LinfRepeatedAdditiveUniformNoiseAttack", "Exception"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.load_model", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_loader", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.predict_epoch", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.iter2array", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.iter2array"], ["", "def", "attack_model", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "batch_size", ":", "int", "=", "512", ",", "\n", "save", ":", "bool", "=", "True", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ",", "\n", "num_workers", ":", "int", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Attack neural network if method!='clean'.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    batch_size : int, optional\n        batch size. The default is 512.\n    save : bool, optional\n        whether save generated adversarial samples. The default is True.\n    device : str, optional\n        device on which the model is loaded. The default is DEVICE.\n    num_workers: int, optional\n        how many subprocesses to use for data. The default is 4.\n\n    Returns\n    -------\n    x_attacked : np.ndarray, shape as [n_sample, *input_shape]\n        adversarial samples.\n\n    \"\"\"", "\n", "print", "(", "'Attacking'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ")", "\n", "if", "dataset", "in", "DATASET_TEXT", "+", "DATASET_AUDIO", "and", "method", "!=", "'clean'", ":", "\n", "        ", "print", "(", "'Skipping'", ")", "\n", "return", "0", "\n", "\n", "\n", "", "model", "=", "load_model", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "device", ",", "MULTIGPU", ")", "\n", "x_attacked", "=", "[", "]", "\n", "\n", "phase", "=", "None", "if", "method", "==", "'clean'", "else", "'attacking'", "\n", "loader", "=", "get_loader", "(", "dataset", ",", "subset", "=", "subset", ",", "proportion", "=", "proportion", ",", "\n", "batch_size", "=", "batch_size", ",", "num_workers", "=", "num_workers", ",", "\n", "phase", "=", "phase", ")", "\n", "\n", "\n", "# no attacks, clean evaluation", "\n", "if", "method", "==", "'clean'", ":", "\n", "        ", "acc", "=", "predict_epoch", "(", "dataset", ",", "architecture", ",", "model", ",", "loader", ",", "device", "=", "device", ")", "[", "-", "1", "]", "\n", "\n", "# attack model", "\n", "", "else", ":", "\n", "        ", "if", "method", "==", "'square'", ":", "\n", "            ", "x", "=", "torch", ".", "cat", "(", "[", "x", "for", "x", ",", "y", "in", "loader", "]", ",", "dim", "=", "0", ")", "\n", "x", "=", "iter2array", "(", "x", ")", "\n", "y", "=", "iter2array", "(", "loader", ".", "dataset", ".", "targets", ")", "\n", "\n", "n_class", "=", "10", "\n", "# mnist or cifar10", "\n", "input_shape", "=", "(", "1", ",", "28", ",", "28", ")", "if", "dataset", "==", "'mnist'", "else", "(", "3", ",", "32", ",", "32", ")", "\n", "classifier", "=", "PyTorchClassifier", "(", "model", ",", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", ",", "\n", "input_shape", ",", "n_class", ",", "\n", "clip_values", "=", "(", "0", ",", "1", ")", ")", "\n", "attack", "=", "SquareAttack", "(", "classifier", ",", "eps", "=", "epsilon", ",", "batch_size", "=", "batch_size", ")", "\n", "x_attacked", "=", "attack", ".", "generate", "(", "x", "=", "x", ")", "\n", "pred", "=", "classifier", ".", "predict", "(", "x_attacked", ",", "batch_size", "=", "batch_size", ")", "\n", "acc", "=", "np", ".", "mean", "(", "np", ".", "argmax", "(", "pred", ",", "axis", "=", "-", "1", ")", "==", "y", ")", "\n", "\n", "", "else", ":", "\n", "            ", "if", "dataset", "==", "'mnist'", ":", "\n", "                ", "preprocessing", "=", "None", "\n", "", "elif", "dataset", "==", "'cifar10'", ":", "\n", "                ", "preprocessing", "=", "dict", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ",", "\n", "axis", "=", "-", "3", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Wrong dataset: %s'", "%", "dataset", ")", "\n", "\n", "", "if", "method", "==", "'pgd'", ":", "\n", "                ", "attack", "=", "PGD", "(", ")", "\n", "# here we use the cleverhans C&W L2 implemantation, which is faster and ", "\n", "# has higher success rate", "\n", "", "elif", "method", "==", "'cwl2'", ":", "\n", "                ", "pass", "\n", "", "elif", "method", "==", "'spatial'", ":", "\n", "                ", "attack", "=", "SpatialAttack", "(", ")", "\n", "", "elif", "method", "==", "'fgsm'", ":", "\n", "                ", "attack", "=", "FGSM", "(", ")", "\n", "", "elif", "method", "==", "'deepfool'", ":", "\n", "                ", "attack", "=", "L2DeepFoolAttack", "(", ")", "\n", "", "elif", "method", "==", "'saltpepper'", ":", "\n", "                ", "attack", "=", "SaltAndPepperNoiseAttack", "(", ")", "\n", "", "elif", "method", "==", "'uniform'", ":", "\n", "                ", "attack", "=", "LinfRepeatedAdditiveUniformNoiseAttack", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "Exception", "(", "'Invalid attack method: %s'", "%", "method", ")", "\n", "\n", "\n", "", "fmodel", "=", "PyTorchModel", "(", "model", ",", "bounds", "=", "(", "0", ",", "1", ")", ",", "preprocessing", "=", "preprocessing", ")", "\n", "\n", "\n", "if_attacked", "=", "[", "]", "\n", "for", "x", ",", "y", "in", "loader", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "if", "method", "!=", "'cwl2'", ":", "\n", "                    ", "x", ",", "y", "=", "ep", ".", "astensors", "(", "x", ",", "y", ")", "\n", "_", ",", "x_adv", ",", "success", "=", "attack", "(", "fmodel", ",", "x", ",", "y", ",", "epsilons", "=", "epsilon", ")", "\n", "", "else", ":", "\n", "# TODO: maybe there should be some preprocessing here ", "\n", "# if attacking resnet", "\n", "                    ", "x_adv", "=", "carlini_wagner_l2", "(", "model", ",", "x", ",", "10", ")", "\n", "pred_adv", "=", "torch", ".", "argmax", "(", "model", "(", "x_adv", ")", ",", "axis", "=", "-", "1", ")", "\n", "x_adv", "=", "x_adv", ".", "cpu", "(", ")", "\n", "success", "=", "(", "pred_adv", "!=", "y", ")", ".", "cpu", "(", ")", "\n", "", "x_attacked", ".", "append", "(", "x_adv", ".", "numpy", "(", ")", ")", "\n", "if_attacked", "+=", "list", "(", "success", ".", "numpy", "(", ")", ")", "\n", "\n", "", "x_attacked", "=", "np", ".", "concatenate", "(", "x_attacked", ")", "\n", "acc", "=", "1", "-", "np", ".", "mean", "(", "if_attacked", ")", "\n", "\n", "\n", "", "", "print", "(", "'Acc: %f'", "%", "acc", ")", "\n", "if", "save", ":", "\n", "        ", "npz", "=", "get_npz", "(", "'attack'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "epsilon", ",", "subset", ",", "proportion", ")", "\n", "np", ".", "savez_compressed", "(", "npz", ",", "x", "=", "x_attacked", ",", "acc", "=", "[", "acc", "]", ")", "\n", "\n", "", "return", "x_attacked", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.save_output": [[446, 519], ["print", "task.get_loader", "model.load_model", "range", "numpy.stack", "scipy.special.softmax", "utils.get_npz", "numpy.savez_compressed", "scipy.special.softmax.append", "traintest.predict_epoch"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_loader", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.load_model", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.predict_epoch"], ["", "def", "save_output", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "batch_size", ":", "int", "=", "1024", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ",", "\n", "num_workers", ":", "int", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Save neural network output.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    batch_size : int, optional\n        batch size. The default is 1024.\n    device : str, optional\n        device on which the model is loaded. The default is DEVICE.\n    num_workers: int, optional\n        how many subprocesses to use for data. The default is 4.\n\n    Returns\n    -------\n    output : np.ndarray, shape as [n_sample, n_choice]\n        neural network classifier outputs.\n\n    \"\"\"", "\n", "print", "(", "'Saving Output'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ")", "\n", "\n", "loader", "=", "get_loader", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "batch_size", ",", "num_workers", ")", "\n", "\n", "model", "=", "load_model", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "device", ",", "MULTIGPU", ")", "\n", "\n", "output", "=", "[", "]", "\n", "# print(predict_epoch(dataset, architecture, model, loader, device=device))", "\n", "for", "i", "in", "range", "(", "repeat", ")", ":", "\n", "        ", "output", ".", "append", "(", "predict_epoch", "(", "dataset", ",", "architecture", ",", "model", ",", "loader", ",", "\n", "return_output", "=", "True", ",", "device", "=", "device", ")", ")", "\n", "", "output_raw", "=", "np", ".", "stack", "(", "output", ",", "axis", "=", "0", ")", "\n", "output", "=", "softmax", "(", "output_raw", ",", "axis", "=", "-", "1", ")", "\n", "\n", "npz", "=", "get_npz", "(", "'output'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ")", "\n", "np", ".", "savez_compressed", "(", "npz", ",", "output", "=", "output", ",", "output_raw", "=", "output_raw", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.save_likelihood": [[521, 584], ["print", "zip", "len", "range", "model.get_likelihood", "utils.get_npz", "numpy.savez_compressed", "output_of_category_permethod.append", "output_of_category.append", "task.get_output_of_category", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.get_likelihood", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_output_of_category"], ["", "def", "save_likelihood", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "list", "=", "[", "'clean'", ",", "'pgd'", "]", ",", "\n", "epsilon", ":", "list", "=", "[", "0", ",", "0.3", "]", ",", "\n", "subset", ":", "str", "=", "'train'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "10", ",", "\n", "n_channel", ":", "int", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    Save estimated likelihood of discretized neural network outputs in each class.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : list, optional\n        attack methods. The default is ['clean', 'pgd'].\n    epsilon : list, optional\n        perturbation threshold of attacks. The default is [0, 0.3].\n    subset : str, optional\n        subset of dataset. The default is 'train'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 10.\n    n_channel : int, optional\n        number of channel for likelihood estimation. The default is 3.\n\n    Returns\n    -------\n    likelihood : TYPE\n        DESCRIPTION.\n\n    \"\"\"", "\n", "print", "(", "'Saving Likelihood'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ",", "n_channel", ")", "\n", "output_of_category_permethod", "=", "[", "]", "\n", "for", "m", ",", "e", "in", "zip", "(", "method", ",", "epsilon", ")", ":", "\n", "        ", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "m", ",", "e", ",", "subset", ",", "proportion", ",", "repeat", "]", "\n", "output_of_category_permethod", ".", "append", "(", "get_output_of_category", "(", "*", "args", ")", ")", "\n", "", "output_of_category", "=", "[", "]", "\n", "n_choice", "=", "len", "(", "output_of_category_permethod", "[", "0", "]", ")", "\n", "for", "i", "in", "range", "(", "n_choice", ")", ":", "\n", "        ", "output_of_category", ".", "append", "(", "np", ".", "concatenate", "(", "[", "j", "[", "i", "]", "for", "j", "in", "output_of_category_permethod", "]", ")", ")", "\n", "", "likelihood", "=", "get_likelihood", "(", "output_of_category", ",", "n_channel", ")", "\n", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", "]", "\n", "npz", "=", "get_npz", "(", "*", "(", "[", "'likelihood'", "]", "+", "args", "+", "[", "n_channel", "]", ")", ")", "\n", "np", ".", "savez_compressed", "(", "npz", ",", "likelihood", "=", "likelihood", ")", "\n", "\n", "return", "likelihood", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.save_inference": [[586, 691], ["print", "task.get_trial", "numpy.mean", "print", "utils.get_npz", "numpy.savez_compressed", "task.load_likelihood", "model.bayesian_inference", "model.cumsum_inference", "Exception"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_trial", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_likelihood", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.bayesian_inference", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.cumsum_inference"], ["", "def", "save_inference", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "len_trial", ":", "int", "=", "25", ",", "\n", "n_trial", ":", "int", "=", "10", ",", "\n", "inference", ":", "str", "=", "'bayes'", ",", "\n", "boundary", ":", "float", "=", "0.99", ",", "\n", "n_channel", ":", "int", "=", "3", ",", "\n", "repeat_train", ":", "int", "=", "10", ",", "\n", "likelihood_method", ":", "list", "=", "[", "'clean'", "]", ",", "\n", "likelihood_epsilon", ":", "list", "=", "[", "0", "]", ")", ":", "\n", "    ", "\"\"\"\n    Save cumsum/bayesian inference results.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    len_trial : int, optional\n        length of each trial. The default is 25.\n    n_trial : int, optional\n        number of trials for each sample. The default is 10.\n    inference : str, optional\n        type of inference to perform, choose from ['cumsum' | 'bayes']. \n        The default is 'bayes'.\n    boundary : float, optional\n        decision evidence boundary. The default is 0.99.\n    n_channel : int, optional\n        number of channel for likelihood estimation, only for bayes inference. \n        The default is 3.\n    repeat_train : int, optional\n        number of neural network prediction of each training set sample to \n        estimate likelihood, only for bayes inference.\n        The default is 10.\n    likelihood_method : list, optional\n        strings of attack methods for likelihood estimation, only for bayes inference. \n        The default is ['clean'].\n    likelihood_epsilon : list, optional\n        floats of attack epsilons for likelihood estimation, only for bayes inference. \n        The default is [0].\n        \n\n    Returns\n    -------\n    acc : float\n        mean accuracy.\n    result : tuple\n        (belief_post, response_time, choice).\n\n    \"\"\"", "\n", "# TODO: low acc, posterior belief rises too fast (1-2 step)", "\n", "print", "(", "'Saving'", ",", "inference", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "epsilon", ",", "subset", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "\n", "boundary", ",", ")", "\n", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "epsilon", "]", "\n", "\n", "args_trial", "=", "args", "+", "[", "subset", ",", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", "]", "\n", "trial", ",", "y", "=", "get_trial", "(", "*", "args_trial", ")", "\n", "\n", "args_npz", "=", "args", "+", "[", "subset", ",", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", "]", "\n", "if", "inference", "==", "'bayes'", ":", "\n", "        ", "args_likelihood", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", "]", "\n", "args_likelihood", "+=", "[", "likelihood_method", ",", "likelihood_epsilon", ",", "'train'", ",", "\n", "proportion", ",", "repeat_train", ",", "n_channel", "]", "\n", "likelihood", "=", "load_likelihood", "(", "*", "args_likelihood", ")", "\n", "result", "=", "bayesian_inference", "(", "trial", ",", "boundary", ",", "likelihood", ",", "n_channel", ")", "\n", "args_npz", "+=", "[", "n_channel", ",", "likelihood_method", ",", "likelihood_epsilon", "]", "\n", "", "elif", "inference", "==", "'cumsum'", ":", "\n", "        ", "result", "=", "cumsum_inference", "(", "trial", ",", "boundary", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Invalid inference: %s\"", "%", "inference", ")", "\n", "\n", "", "response_time", ",", "choice", ",", "evidence", "=", "result", "\n", "acc", "=", "np", ".", "mean", "(", "y", "==", "choice", ")", "\n", "print", "(", "'Acc: %f'", "%", "acc", ")", "\n", "npz", "=", "get_npz", "(", "inference", ",", "*", "args_npz", ")", "\n", "np", ".", "savez_compressed", "(", "npz", ",", "acc", "=", "[", "acc", "]", ",", "evidence", "=", "evidence", ",", "\n", "response_time", "=", "response_time", ",", "choice", "=", "choice", ")", "\n", "\n", "return", "acc", ",", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.train_model_multidropout": [[693, 777], ["list", "range", "zip", "subprocess.run", "len", "list", "len", "len", "lines.append", "open", "f.writelines", "traintest.train_model", "range", "len", "len", "str", "len", "str", "zip"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.train_model"], ["", "def", "train_model_multidropout", "(", "dataset", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout", ":", "list", "=", "DROPOUT", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "\n", "epochs", ":", "int", "=", "50", ",", "\n", "save", ":", "bool", "=", "True", ",", "\n", "patience", ":", "int", "=", "20", ",", "\n", "device", ":", "list", "=", "list", "(", "range", "(", "len", "(", "DROPOUT", ")", ")", ")", ",", "\n", "num_workers", ":", "int", "=", "4", ")", ":", "\n", "    ", "\"\"\"\n    Train multiple models with multiple dropout rates \n    (on multiple GPUs simultaneously if available).\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout : list, optional\n        training and testing dropout rates. The default is DROPOUT.\n    batch_size : int, optional\n        batch size. The default is 64.\n    epochs : int, optional\n        number of maximum training epochs. The default is 50.\n    save : bool, optional\n        whether save model after training. The default is True.\n    patience : int, optional\n        training will be stopped if validation loss stops decreasing in *patience* epochs. \n        The default is 20.\n    device : list of ints, optional\n        indexs of GPUs on which the models are loaded.\n        The default is None, same as list(range(len(dropout))).\n    num_workers: int, optional\n        how many subprocesses to use for data loader. The default is 4.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "# train models on multiple GPUs simultaneously", "\n", "if", "MULTIGPU", ":", "\n", "        ", "if", "device", "is", "None", ":", "\n", "            ", "device", "=", "list", "(", "range", "(", "len", "(", "dropout", ")", ")", ")", "\n", "", "error", "=", "'number of GPUs (%d) != number of dropout rates (%d)'", "%", "(", "len", "(", "device", ")", ",", "len", "(", "dropout", ")", ")", "\n", "assert", "len", "(", "device", ")", "==", "len", "(", "dropout", ")", ",", "error", "\n", "device", "=", "[", "'cuda:'", "+", "str", "(", "i", ")", "for", "i", "in", "device", "]", "\n", "# TODO: only training progress of last model can be output", "\n", "# it's ideal to show progress of all training", "\n", "# create a bash script to run multiple train_single_model.py simultaneously", "\n", "# the script be like:", "\n", "# #!/bin/bash", "\n", "# python train_single_model.py ... dropout 0 ... --device cuda:0 &", "\n", "# python train_single_model.py ... dropout 0.2 ... --device cuda:1 &", "\n", "# python train_single_model.py ... dropout 0.4 ... --device cuda:2", "\n", "lines", "=", "[", "'#!/bin/bash\\n'", "]", "\n", "for", "dr", ",", "de", "in", "zip", "(", "dropout", ",", "device", ")", ":", "\n", "            ", "l", "=", "'python train_single_model.py '", "\n", "arg_str", "=", "[", "'dataset'", ",", "'architecture'", ",", "'index'", ",", "'dropout'", ",", "'batch_size'", ",", "\n", "'epochs'", ",", "'save'", ",", "'patience'", ",", "'device'", ",", "'num_workers'", "]", "\n", "arg_str", "=", "[", "'--'", "+", "i", "+", "' '", "for", "i", "in", "arg_str", "]", "\n", "arg_arg", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dr", ",", "batch_size", ",", "epochs", ",", "\n", "save", ",", "patience", ",", "de", ",", "num_workers", "]", "\n", "l", "+=", "' '", ".", "join", "(", "[", "s", "+", "str", "(", "a", ")", "for", "s", ",", "a", "in", "zip", "(", "arg_str", ",", "arg_arg", ")", "]", ")", "+", "' &\\n'", "\n", "lines", ".", "append", "(", "l", ")", "\n", "# print training progress of last model in terminal", "\n", "", "lines", "[", "-", "1", "]", "=", "l", "[", ":", "-", "3", "]", "\n", "script", "=", "'train_multiple_model.sh'", "\n", "with", "open", "(", "script", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "writelines", "(", "lines", ")", "\n", "# run the bash script", "\n", "", "subprocess", ".", "run", "(", "[", "'bash'", ",", "script", "]", ")", "\n", "pass", "\n", "\n", "# train models on single GPU", "\n", "", "else", ":", "\n", "        ", "device", "=", "'cuda'", "\n", "for", "i", "in", "dropout", ":", "\n", "            ", "train_model", "(", "dataset", ",", "architecture", ",", "index", ",", "i", ",", "batch_size", ",", "epochs", ",", "\n", "save", ",", "patience", ",", "device", ",", "num_workers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.get_dropout_pair": [[779, 801], ["dropout_pair.append"], "function", ["None"], ["", "", "", "def", "get_dropout_pair", "(", "dropout_train", ":", "list", "=", "DROPOUT", ",", "dropout_test", ":", "list", "=", "DROPOUT", ")", ":", "\n", "    ", "\"\"\"\n    Return cartesian product of given training and testing dropout rates.\n\n    Parameters\n    ----------\n    dropout_train : list, optional\n        training dropout rates. The default is DROPOUT.\n    dropout_test : list, optional\n        testing dropout rates. The default is DROPOUT.\n\n    Returns\n    -------\n    dropout_pair : list\n        training and testing dropout rate pairs.\n\n    \"\"\"", "\n", "dropout_pair", "=", "[", "]", "\n", "for", "i", "in", "dropout_train", ":", "\n", "        ", "for", "j", "in", "dropout_test", ":", "\n", "            ", "dropout_pair", ".", "append", "(", "(", "i", ",", "j", ")", ")", "\n", "", "", "return", "dropout_pair", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.pipeline": [[803, 932], ["isinstance", "isinstance", "isinstance", "joblib.Parallel", "joblib.Parallel", "zip", "args_cumsum.append", "args_likelihood.append", "args_bayes.append", "joblib.Parallel", "traintest.attack_model", "traintest.save_output", "joblib.delayed", "joblib.delayed", "joblib.delayed"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.attack_model", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.save_output"], ["", "def", "pipeline", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_pair", ":", "Union", "[", "list", ",", "tuple", "]", "=", "(", "0", ",", "0", ")", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "Union", "[", "float", ",", "int", ",", "list", "]", "=", "0", ",", "\n", "proportion_train", ":", "float", "=", "PROPORTION", ",", "\n", "repeat_train", ":", "int", "=", "10", ",", "\n", "proportion_test", ":", "float", "=", "PROPORTION", ",", "\n", "repeat_test", ":", "int", "=", "100", ",", "\n", "len_trial", ":", "int", "=", "25", ",", "\n", "n_trial", ":", "int", "=", "10", ",", "\n", "boundary_cumsum", ":", "float", "=", "5", ",", "\n", "boundary_bayes", ":", "float", "=", "0.99", ",", "\n", "n_channel", ":", "int", "=", "3", ",", "\n", "batch_size", ":", "int", "=", "512", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ",", "\n", "num_workers", ":", "int", "=", "4", ",", "\n", "likelihood_method", ":", "list", "=", "[", "'clean'", "]", ",", "\n", "likelihood_epsilon", ":", "list", "=", "[", "0", "]", ",", "\n", "likelihood_estimate", ":", "bool", "=", "True", ")", ":", "\n", "    ", "\"\"\"\n    Convenient function to attack neural networks, estimate likelihood and \n    perform cumsum and bayesian inference.\n    \n    Cumsum inference, likelihood estimation and bayesian inference will be \n    processed in a CPU parallel fashion if multiple dropout rate pairs and/or\n    multiple epsilon values are given.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_pair : Union[list, tuple], optional\n        training and testing dropout rate pair(s). \n        single dropout rate pair should be in the form as (d_train, d_test).\n        multiple dropout rate pairs should be in the form as \n        [(d_train_0, d_test_0), (d_train_1, d_test_1), (d_train_2, d_test_2), ...],\n        which could be returned by get_dropout_pair().\n        The default is (0, 0).\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : Union[float, int, list], optional\n        perturbation threshold(s) of attacks. The default is 0.\n    proportion_train : float, optional\n        proportion of training set. The default is 1.\n    repeat_train : int, optional\n        prediction repeat of training set. The default is 10.\n    proportion_test : float, optional\n        proportion of test set. The default is 1.\n    repeat_test : int, optional\n        prediction repeat of test set. The default is 100.\n    len_trial : int, optional\n        length of each trial. The default is 25.\n    n_trial : int, optional\n        number of trials for each sample. The default is 10.\n    boundary_cumsum : float, optional\n        neural network prediction decision boundary. The default is 5.\n    boundary_bayes : float, optional\n        posterior belief decision boundary. The default is 0.99.\n    n_channel : int, optional\n        number of channel for likelihood estimation. The default is 3.\n    batch_size : int, optional\n        batch size. The default is 512.\n    device : str, optional\n        device on which the model is loaded. The default is DEVICE.\n    num_workers: int, optional\n        how many subprocesses to use for data. The default is 4.\n    likelihood_method : list, optional\n        strings of attack methods for likelihood estimation, only for bayes inference. \n        The default is ['clean'].\n    likelihood_epsilon : list, optional\n        floats of attack epsilons for likelihood estimation, only for bayes inference. \n        The default is [0].\n    likelihood_estimate : bool, optional\n        whether estimate likelihood. The default is True.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "\n", "if", "likelihood_method", "==", "[", "'clean'", "]", "and", "method", "!=", "'clean'", ":", "\n", "        ", "spr", "=", "[", "[", "'test'", "]", ",", "\n", "[", "proportion_test", "]", ",", "\n", "[", "repeat_test", "]", "]", "\n", "", "else", ":", "\n", "        ", "spr", "=", "[", "[", "'train'", ",", "'test'", "]", ",", "\n", "[", "proportion_train", ",", "proportion_test", "]", ",", "\n", "[", "repeat_train", ",", "repeat_test", "]", "]", "\n", "\n", "", "args_likelihood", "=", "[", "]", "\n", "args_cumsum", "=", "[", "]", "\n", "args_bayes", "=", "[", "]", "\n", "\n", "if", "isinstance", "(", "epsilon", ",", "float", ")", "or", "isinstance", "(", "epsilon", ",", "int", ")", ":", "\n", "        ", "epsilon", "=", "[", "epsilon", "]", "\n", "", "if", "isinstance", "(", "dropout_pair", ",", "tuple", ")", ":", "\n", "        ", "dropout_pair", "=", "[", "dropout_pair", "]", "\n", "\n", "", "for", "i", ",", "j", "in", "dropout_pair", ":", "\n", "        ", "for", "e", "in", "epsilon", ":", "\n", "            ", "for", "s", ",", "p", ",", "r", "in", "zip", "(", "*", "spr", ")", ":", "\n", "                ", "attack_model", "(", "dataset", ",", "architecture", ",", "index", ",", "i", ",", "j", ",", "method", ",", "e", ",", "\n", "s", ",", "p", ",", "batch_size", ",", "True", ",", "device", ",", "num_workers", ")", "\n", "save_output", "(", "dataset", ",", "architecture", ",", "index", ",", "i", ",", "j", ",", "method", ",", "e", ",", "\n", "s", ",", "p", ",", "r", ",", "batch_size", ",", "device", ",", "num_workers", ")", "\n", "\n", "", "args_cumsum", ".", "append", "(", "[", "dataset", ",", "architecture", ",", "index", ",", "i", ",", "j", ",", "method", ",", "\n", "e", ",", "'test'", ",", "proportion_test", ",", "repeat_test", ",", "\n", "len_trial", ",", "n_trial", ",", "'cumsum'", ",", "boundary_cumsum", "]", ")", "\n", "args_likelihood", ".", "append", "(", "[", "dataset", ",", "architecture", ",", "index", ",", "i", ",", "\n", "j", ",", "likelihood_method", ",", "likelihood_epsilon", ",", "\n", "'train'", ",", "proportion_train", ",", "repeat_train", ",", "\n", "n_channel", "]", ")", "\n", "args_bayes", ".", "append", "(", "[", "dataset", ",", "architecture", ",", "index", ",", "i", ",", "j", ",", "method", ",", "\n", "e", ",", "'test'", ",", "proportion_test", ",", "repeat_test", ",", "\n", "len_trial", ",", "n_trial", ",", "'bayes'", ",", "boundary_bayes", ",", "\n", "n_channel", ",", "repeat_train", ",", "likelihood_method", ",", "\n", "likelihood_epsilon", "]", ")", "\n", "", "", "Parallel", "(", "-", "1", ")", "(", "delayed", "(", "save_inference", ")", "(", "*", "i", ")", "for", "i", "in", "args_cumsum", ")", "\n", "if", "likelihood_estimate", ":", "\n", "        ", "Parallel", "(", "-", "1", ")", "(", "delayed", "(", "save_likelihood", ")", "(", "*", "i", ")", "for", "i", "in", "args_likelihood", ")", "\n", "", "Parallel", "(", "-", "1", ")", "(", "delayed", "(", "save_inference", ")", "(", "*", "i", ")", "for", "i", "in", "args_bayes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.TextModelWrapper.__init__": [[223, 227], ["torch.device", "task.TextToTensor"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "model", ":", "torch", ".", "nn", ".", "Module", ",", "device", ":", "str", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "device", ")", "\n", "self", ".", "model", "=", "model", "\n", "self", ".", "transform", "=", "TextToTensor", "(", ")", "\n", "", "def", "__call__", "(", "self", ",", "text_input_list", ":", "list", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.TextModelWrapper.__call__": [[227, 232], ["torch.stack", "x.to.to.to", "nlp.TextModelWrapper.model().cpu().detach().numpy", "nlp.TextModelWrapper.transform", "nlp.TextModelWrapper.model().cpu().detach", "nlp.TextModelWrapper.model().cpu", "nlp.TextModelWrapper.model"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "text_input_list", ":", "list", ")", ":", "\n", "        ", "x", "=", "torch", ".", "stack", "(", "[", "self", ".", "transform", "(", "i", ")", "for", "i", "in", "text_input_list", "]", ",", "dim", "=", "0", ")", "\n", "x", "=", "x", ".", "to", "(", "self", ".", "device", ")", "\n", "y", "=", "self", ".", "model", "(", "x", ")", ".", "cpu", "(", ")", ".", "detach", "(", ")", ".", "numpy", "(", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_txt_textattacklog": [[26, 67], ["utils.get_dir", "str"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir"], ["def", "get_txt_textattacklog", "(", "dataset", ":", "str", "=", "'imdb'", ",", "\n", "architecture", ":", "str", "=", "'lstm'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'textbugger'", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ")", ":", "\n", "    ", "\"\"\"\n    Return `.txt` file path that saves TextAttack results.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'imdb'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'lstm'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'textbugger'.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is 1.\n\n    Returns\n    -------\n    txt : str\n        `.txt` file path.\n\n    \"\"\"", "\n", "d", "=", "get_dir", "(", "dataset", ",", "'others'", ")", "\n", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "subset", ",", "proportion", "]", "\n", "txt", "=", "d", "+", "'_'", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "args", "]", ")", "+", "'.txt'", "\n", "return", "txt", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_accuracy_fromstring": [[69, 87], ["float", "string.split"], "function", ["None"], ["", "def", "get_accuracy_fromstring", "(", "string", ":", "str", "=", "''", ")", ":", "\n", "    ", "\"\"\"\n    Return float of accuracy in given string.\n\n    Parameters\n    ----------\n    string : string, optional\n        string in format like 'Original accuracy: 88.24%'. The default is ''.\n\n    Returns\n    -------\n    number : float\n        accuracy in given string.\n\n    \"\"\"", "\n", "number", "=", "string", ".", "split", "(", "' '", ")", "[", "-", "1", "]", "[", ":", "-", "2", "]", "\n", "number", "=", "float", "(", "number", ")", "/", "100", "\n", "return", "number", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_truncated_string": [[89, 95], ["tokenizer", "len"], "function", ["None"], ["", "def", "get_truncated_string", "(", "string", ":", "str", ",", "tokenizer", ":", "None", ",", "max_len", ":", "int", ")", ":", "\n", "    ", "tokens", "=", "tokenizer", "(", "string", ")", "\n", "if", "len", "(", "tokens", ")", ">", "max_len", ":", "\n", "        ", "tokens", "=", "tokens", "[", ":", "max_len", "]", "\n", "", "string", "=", "' '", ".", "join", "(", "tokens", "[", ":", "max_len", "]", ")", "\n", "return", "string", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_dataset_textattack": [[97, 126], ["task.get_dataset", "torchtext.data.utils.get_tokenizer", "textattack.datasets.Dataset", "nlp.get_truncated_string", "str", "zip"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_dataset", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_truncated_string"], ["", "def", "get_dataset_textattack", "(", "dataset", ":", "str", "=", "'imdb'", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ",", "\n", "tokenizer", ":", "str", "=", "'basic_english'", ",", "\n", "max_len", ":", "int", "=", "400", ")", ":", "\n", "    ", "\"\"\"\n    Instantiate and return a textattack.datasets.Dataset for textattack.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'imdb'.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n\n    Returns\n    -------\n    dataset_textattack : textattack.datasets.Dataset\n        dataset for textattack.\n\n    \"\"\"", "\n", "dataset_torch", "=", "get_dataset", "(", "dataset", ",", "subset", ",", "proportion", ",", "transform", "=", "False", ")", "\n", "tokenizer", "=", "get_tokenizer", "(", "tokenizer", ")", "\n", "data", "=", "[", "get_truncated_string", "(", "i", ",", "tokenizer", ",", "max_len", ")", "for", "i", "in", "dataset_torch", ".", "data", "]", "\n", "xy_pair", "=", "[", "(", "str", "(", "x", ")", ",", "y", ")", "for", "x", ",", "y", "in", "zip", "(", "data", ",", "dataset_torch", ".", "targets", ")", "]", "\n", "dataset_textattack", "=", "Dataset", "(", "xy_pair", ")", "\n", "return", "dataset_textattack", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_str_adversarial": [[128, 209], ["enumerate", "string.replace.replace", "string.replace.replace", "unattacked_string.index", "unattacked_string.append", "attacked_string.append", "nlp.get_str_adversarial.remove_bracket"], "function", ["None"], ["", "def", "get_str_adversarial", "(", "lines", ":", "list", ",", "lines_clean", ":", "list", ")", ":", "\n", "    ", "\"\"\"\n    Return clean text, adversarial text and bool array of adversarial samples\n    in log files.\n\n    lines in log txts are typically like this:\n\n        \n    -------------- Result 1 ---------------------------------------------\n    [[0 (100%)]] --> [[[FAILED]]]\n    \n    from livesey solntze wpd sgi com \n    ---------------- Result 2 ---------------------------------------------\n    [[0 (100%)]] --> [[9 (51%)]]\n    \n    rom nosubdomain nodomain brian cash [[subject]] re [[free]] \n    \n    from nosubdomain nodomain brian cash [[matter]] re [[innocent]]\n    ------------------- Result 3 ---------------------------------------------\n    [[0 (100%)]] --> [[9 (50%)]]\n    \n    .\n    .\n    .\n\n\n    Parameters\n    ----------\n    lines : list\n        strings in log files.\n    lines_clean : list\n        strings from torchtext.\n\n\n    Returns\n    -------\n    clean_string : list\n        clean strings.\n    attacked_string : list\n        adversarial text.\n    adversarial : list\n        whether adversarial sample is generated.\n\n    \"\"\"", "\n", "\n", "def", "remove_bracket", "(", "string", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        remove '[[]]' around attacked words because torchtext tokenizer\n        will keep them and make the '[[word]]' vectorized as zero vectors\n\n        Parameters\n        ----------\n        string : str\n            DESCRIPTION.\n\n        Returns\n        -------\n        string : TYPE\n            DESCRIPTION.\n\n        \"\"\"", "\n", "string", "=", "string", ".", "replace", "(", "'[['", ",", "''", ")", "\n", "string", "=", "string", ".", "replace", "(", "']]'", ",", "''", ")", "\n", "return", "string", "\n", "\n", "", "unattacked_string", "=", "[", "]", "\n", "attacked_string", "=", "[", "]", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "if", "'Result'", "not", "in", "i", ":", "\n", "            ", "continue", "\n", "", "else", ":", "\n", "            ", "unattacked_string", ".", "append", "(", "remove_bracket", "(", "lines", "[", "idx", "+", "3", "]", ")", ")", "\n", "idx_attacked", "=", "idx", "+", "3", "if", "'FAILED'", "in", "lines", "[", "idx", "+", "1", "]", "else", "idx", "+", "5", "\n", "attacked_string", ".", "append", "(", "remove_bracket", "(", "lines", "[", "idx_attacked", "]", ")", ")", "\n", "\n", "# the order of unattacked strings in log file could be in different from", "\n", "# ones loaded from torchtext", "\n", "", "", "idx_correct", "=", "[", "unattacked_string", ".", "index", "(", "i", ")", "for", "i", "in", "lines_clean", "]", "\n", "attacked_string", "=", "[", "attacked_string", "[", "i", "]", "for", "i", "in", "idx_correct", "]", "\n", "\n", "return", "attacked_string", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.attack_model_textattack": [[234, 311], ["print", "model.load_model", "nlp.TextModelWrapper", "eval().build", "nlp.get_dataset_textattack", "textattack.AttackArgs", "textattack.Attacker", "textattack.Attacker.attack_dataset", "nlp.get_txt_textattacklog", "nlp.get_accuracy_fromstring", "nlp.get_str_adversarial", "utils.get_npz_attack", "numpy.savez_compressed", "eval", "open", "f.readlines"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.load_model", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_dataset_textattack", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_txt_textattacklog", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_accuracy_fromstring", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.nlp.get_str_adversarial", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_attack"], ["", "", "def", "attack_model_textattack", "(", "dataset", ":", "str", "=", "'imdb'", ",", "\n", "architecture", ":", "str", "=", "'lstm'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'textbugger'", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ",", "\n", "batch_size", ":", "int", "=", "1", ",", "\n", "save", ":", "bool", "=", "True", ",", "\n", "device", ":", "str", "=", "'cuda'", ",", "\n", "multigpu", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Attack text classifier with TextAtack.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'imdb'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'lstm'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'textbugger'.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is 1.\n    batch_size : int, optional\n        number of parallel attacks. The default is 2.\n    save : bool, optional\n        whether save the result. The default is True.\n    device : str, optional\n        device of torch model. The default is 'cuda'.\n    multigpu : bool, optional\n        whether perform Data Parallelism on multiplt GPUs. The default is False.\n\n    Returns\n    -------\n    x_attacked : numpy.ndarray\n        adversarial(if attack successfuly)/clean strings.\n    acc : float\n        accuracy after attacks.\n\n    \"\"\"", "\n", "epsilon", "=", "0", "\n", "print", "(", "'Attacking'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ")", "\n", "model", "=", "load_model", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "device", ",", "multigpu", ")", "\n", "wrapper", "=", "TextModelWrapper", "(", "model", ",", "device", ")", "\n", "attack", "=", "eval", "(", "method", ")", ".", "build", "(", "wrapper", ")", "\n", "dataset_ta", "=", "get_dataset_textattack", "(", "dataset", ",", "subset", ",", "proportion", ")", "\n", "txt", "=", "get_txt_textattacklog", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "subset", ",", "proportion", ")", "if", "save", "else", "None", "\n", "attack_args", "=", "AttackArgs", "(", "num_examples", "=", "-", "1", ",", "disable_stdout", "=", "True", ",", "\n", "log_to_txt", "=", "txt", ",", "parallel", "=", "batch_size", ">", "1", ",", "\n", "num_workers_per_device", "=", "batch_size", ")", "\n", "attacker", "=", "Attacker", "(", "attack", ",", "dataset_ta", ",", "attack_args", ")", "\n", "attacker", ".", "attack_dataset", "(", ")", "\n", "\n", "if", "save", ":", "\n", "        ", "with", "open", "(", "txt", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "lines", "=", "[", "i", "[", ":", "-", "1", "]", "for", "i", "in", "lines", "]", "\n", "acc", "=", "get_accuracy_fromstring", "(", "lines", "[", "-", "5", "]", ")", "\n", "lines_clean", "=", "[", "i", "[", "0", "]", "for", "i", "in", "dataset_ta", ".", "_dataset", "]", "\n", "x_attacked", "=", "get_str_adversarial", "(", "lines", ",", "lines_clean", ")", "\n", "npz", "=", "get_npz_attack", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "epsilon", ",", "subset", ",", "proportion", ")", "\n", "np", ".", "savez_compressed", "(", "npz", ",", "x", "=", "x_attacked", ",", "acc", "=", "[", "acc", "]", ")", "\n", "return", "x_attacked", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.analysis.plot_heatmap": [[24, 164], ["len", "len", "numpy.zeros", "enumerate", "zip", "numpy.zeros", "numpy.max", "matplotlib.pyplot.subplots", "matplotlib.pyplot.setp", "utils.get_svgpng_heatmap", "range", "enumerate", "joblib.Parallel", "axes[].set_ylabel", "axes[].set_xlabel", "mpl_toolkits.axes_grid1.make_axes_locatable", "mpl_toolkits.axes_grid1.make_axes_locatable.append_axes", "matplotlib.pyplot.colorbar", "plt.figure.suptitle", "plt.figure.show", "enumerate", "range", "range", "matplotlib.pyplot.figure", "matplotlib.pyplot.axis", "matplotlib.pyplot.imshow", "matplotlib.pyplot.savefig", "matplotlib.pyplot.savefig", "axes[].imshow", "numpy.unravel_index", "axes[].set_title", "zip", "idx_ijk.append", "args.append", "joblib.delayed", "numpy.argmax", "matplotlib.colors.Normalize"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_svgpng_heatmap"], ["def", "plot_heatmap", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout", ":", "list", "=", "DROPOUT", ",", "\n", "method", ":", "list", "=", "METHOD_MNIST", ",", "\n", "epsilon", ":", "list", "=", "EPSILON_MNIST", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "len_trial", ":", "int", "=", "25", ",", "\n", "n_trial", ":", "int", "=", "10", ",", "\n", "boundary", ":", "float", "=", "0.99", ",", "\n", "n_channel", ":", "int", "=", "3", ",", "\n", "likelihood_method", ":", "list", "=", "[", "'clean'", "]", ",", "\n", "likelihood_epsilon", ":", "list", "=", "[", "0", "]", ",", "\n", "mode", ":", "str", "=", "'attack'", ",", "\n", "save_single_heatmap", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Plot accuracy heatmap of all dropout rates and attacks combinations.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout : list, optional\n        training and testing dropout rates. The default is DROPOUT.\n    method : list, optional\n        attack methods. The default is METHOD.\n    epsilon : list, optional\n        epsilons of each attack. The default is EPSILON.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    len_trial : int, optional\n        length of each trial. The default is 25.\n    n_trial : int, optional\n        number of trials for each sample. The default is 10.\n    boundary : float, optional\n        posterior belief decision boundary. The default is 0.99.\n    n_channel : int, optional\n        number of channel for likelihood estimation. The default is 3.\n    likelihood_method : list, optional\n        strings of attack methods for likelihood estimation, only for bayes inference. \n        The default is ['clean'].\n    likelihood_epsilon : list, optional\n        floats of attack epsilons for likelihood estimation, only for bayes inference. \n        The default is [0].\n    mode : str, optional\n        name of defense method, should be chosen from [attack|cumsum|bayes]. \n        when assign 'attack', it means model defense solely by dropout.\n        The default is 'attack'.\n    save_single_heatmap : bool, optional\n        whether save each heatmap into single .svg and .png files.\n        The default is False.\n\n    Returns\n    -------\n    acc : TYPE\n        DESCRIPTION.\n    table : TYPE\n        DESCRIPTION.\n\n    \"\"\"", "\n", "subset", "=", "'test'", "\n", "n_dropout", "=", "len", "(", "dropout", ")", "\n", "n_subplot", "=", "len", "(", "method", ")", "\n", "acc", "=", "np", ".", "zeros", "(", "[", "n_dropout", ",", "n_dropout", ",", "n_subplot", "]", ")", "\n", "\n", "idx_ijk", "=", "[", "]", "\n", "args", "=", "[", "]", "\n", "for", "idx_i", ",", "i", "in", "enumerate", "(", "dropout", ")", ":", "\n", "        ", "for", "idx_j", ",", "j", "in", "enumerate", "(", "dropout", ")", ":", "\n", "            ", "for", "idx_k", ",", "(", "m", ",", "e", ")", "in", "enumerate", "(", "zip", "(", "method", ",", "epsilon", ")", ")", ":", "\n", "                ", "idx_ijk", ".", "append", "(", "(", "idx_i", ",", "idx_j", ",", "idx_k", ")", ")", "\n", "# args for loading acc before bayes", "\n", "arg", "=", "[", "mode", ",", "dataset", ",", "architecture", ",", "index", ",", "i", ",", "j", ",", "m", ",", "e", ",", "subset", ",", "proportion", "]", "\n", "if", "mode", "==", "'bayes'", ":", "\n", "                    ", "arg", "+=", "[", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", ",", "n_channel", ",", "\n", "likelihood_method", ",", "likelihood_epsilon", "]", "\n", "", "elif", "mode", "==", "'cumsum'", ":", "\n", "                    ", "arg", "+=", "[", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", "]", "\n", "\n", "", "args", ".", "append", "(", "arg", ")", "\n", "", "", "", "result", "=", "Parallel", "(", "-", "1", ")", "(", "delayed", "(", "load_acc", ")", "(", "*", "i", ")", "for", "i", "in", "args", ")", "\n", "\n", "for", "(", "idx_i", ",", "idx_j", ",", "idx_k", ")", ",", "r", "in", "zip", "(", "idx_ijk", ",", "result", ")", ":", "\n", "        ", "acc", "[", "idx_i", ",", "idx_j", ",", "idx_k", "]", "=", "r", "\n", "\n", "# 4 is for acc(0, 0), max(acc), max(acc).train_level, max(acc).test_level", "\n", "", "table", "=", "np", ".", "zeros", "(", "[", "4", ",", "n_subplot", "]", ")", "\n", "table", "[", "0", "]", "=", "acc", "[", "0", ",", "0", ",", ":", "]", "\n", "table", "[", "1", "]", "=", "np", ".", "max", "(", "acc", ",", "axis", "=", "(", "0", ",", "1", ")", ")", "\n", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "1", ",", "n_subplot", ",", "figsize", "=", "(", "n_subplot", "*", "3", ",", "3", ")", ",", "sharey", "=", "True", ")", "\n", "xticklabels", "=", "[", "'%.1f'", "%", "i", "for", "i", "in", "dropout", "]", "\n", "yticklabels", "=", "[", "'%.1f'", "%", "i", "for", "i", "in", "dropout", "]", "\n", "plt", ".", "setp", "(", "axes", ",", "xticks", "=", "range", "(", "n_dropout", ")", ",", "xticklabels", "=", "xticklabels", ",", "\n", "yticks", "=", "range", "(", "n_dropout", ")", ",", "yticklabels", "=", "yticklabels", ")", "\n", "subtitle", "=", "[", "METHOD_TITLE", "[", "i", "]", "for", "i", "in", "method", "]", "\n", "svg_heatmap", ",", "png_heatmap", "=", "get_svgpng_heatmap", "(", "dataset", ",", "architecture", ",", "index", ",", "\n", "method", ",", "subset", ",", "mode", ",", "\n", "likelihood_method", ")", "\n", "\n", "for", "i", "in", "range", "(", "n_subplot", ")", ":", "\n", "        ", "a", "=", "acc", "[", ":", ",", ":", ",", "i", "]", "\n", "\n", "if", "save_single_heatmap", ":", "\n", "            ", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "axis", "(", "'off'", ")", "\n", "im", "=", "plt", ".", "imshow", "(", "a", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ")", "\n", "plt", ".", "savefig", "(", "svg_heatmap", "[", "i", "]", ",", "bbox_inches", "=", "'tight'", ",", "pad_inches", "=", "0", ")", "\n", "plt", ".", "savefig", "(", "png_heatmap", "[", "i", "]", ",", "dpi", "=", "300", ",", "bbox_inches", "=", "'tight'", ",", "pad_inches", "=", "0", ")", "\n", "\n", "", "else", ":", "\n", "            ", "im", "=", "axes", "[", "i", "]", ".", "imshow", "(", "a", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ",", "norm", "=", "Normalize", "(", "0", ",", "1", ")", ")", "\n", "idx", "=", "np", ".", "unravel_index", "(", "np", ".", "argmax", "(", "a", ")", ",", "a", ".", "shape", ")", "\n", "table", "[", "2", ",", "i", "]", "=", "dropout", "[", "idx", "[", "0", "]", "]", "\n", "table", "[", "3", ",", "i", "]", "=", "dropout", "[", "idx", "[", "1", "]", "]", "\n", "t", "=", "' (%.1f, %.1f: %.4f)'", "%", "(", "table", "[", "2", ",", "i", "]", ",", "table", "[", "3", ",", "i", "]", ",", "table", "[", "1", ",", "i", "]", ")", "\n", "axes", "[", "i", "]", ".", "set_title", "(", "subtitle", "[", "i", "]", "+", "t", ")", "\n", "\n", "", "", "if", "not", "save_single_heatmap", ":", "\n", "        ", "axes", "[", "0", "]", ".", "set_ylabel", "(", "'Training Dropout Rate'", ")", "\n", "axes", "[", "n_subplot", "//", "2", "]", ".", "set_xlabel", "(", "'Testing Dropout Rate'", ")", "\n", "# color bar for heatmap", "\n", "divider", "=", "make_axes_locatable", "(", "axes", "[", "-", "1", "]", ")", "\n", "cax", "=", "divider", ".", "append_axes", "(", "\"right\"", ",", "size", "=", "\"5%\"", ",", "pad", "=", "0.05", ")", "\n", "plt", ".", "colorbar", "(", "im", ",", "cax", "=", "cax", ")", "\n", "title", "=", "mode", "if", "mode", "!=", "'attack'", "else", "'dropout'", "\n", "fig", ".", "suptitle", "(", "title", ")", "\n", "fig", ".", "show", "(", ")", "\n", "\n", "", "return", "acc", ",", "table", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.analysis.plot_output_histogram": [[166, 227], ["task.get_output_of_category", "len", "matplotlib.pyplot.subplots", "fig.suptitle", "range", "fig.show", "utils.get_dir", "matplotlib.pyplot.savefig", "range", "str", "[].hist", "[].set_title"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_output_of_category", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir"], ["", "def", "plot_output_histogram", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "bins", ":", "int", "=", "20", ")", ":", "\n", "    ", "\"\"\"\n    Plot histogram of outputs of each channel in each class.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    bins : int, optional\n        number of bins of histogram. The default is 20.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "\n", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", "]", "\n", "output_of_category", "=", "get_output_of_category", "(", "*", "args", ")", "\n", "n_choice", "=", "len", "(", "output_of_category", ")", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "n_choice", ",", "n_choice", ",", "True", ",", "True", ",", "\n", "figsize", "=", "(", "n_choice", "*", "3", ",", "n_choice", "*", "3", ")", ")", "\n", "title", "=", "[", "dataset", ",", "architecture", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "epsilon", "]", "\n", "title", "=", "' '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "title", "]", ")", "\n", "fig", ".", "suptitle", "(", "title", ",", "fontsize", "=", "80", ")", "\n", "for", "i", "in", "range", "(", "n_choice", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "n_choice", ")", ":", "\n", "            ", "axes", "[", "i", "]", "[", "j", "]", ".", "hist", "(", "output_of_category", "[", "i", "]", "[", ":", ",", "j", "]", ",", "bins", ")", "\n", "axes", "[", "i", "]", "[", "j", "]", ".", "set_title", "(", "'image %d - output %d'", "%", "(", "i", ",", "j", ")", ")", "\n", "\n", "", "", "fig", ".", "show", "(", ")", "\n", "d", "=", "get_dir", "(", "dataset", ",", "'figure'", ")", "\n", "plt", ".", "savefig", "(", "d", "+", "title", "+", "'.output_histogram.svg'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.analysis.plot_rt_histogram": [[229, 292], ["task.load_bayes", "matplotlib.pyplot.figure", "matplotlib.pyplot.hist", "matplotlib.pyplot.title", "str"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_bayes"], ["", "def", "plot_rt_histogram", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "len_trial", ":", "int", "=", "25", ",", "\n", "n_trial", ":", "int", "=", "10", ",", "\n", "boundary", ":", "float", "=", "0.99", ",", "\n", "n_channel", ":", "int", "=", "3", ",", ")", ":", "\n", "    ", "\"\"\"\n    Plot histogram of response time of bayesian inference.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    len_trial : int, optional\n        length of each trial. The default is 25.\n    n_trial : int, optional\n        number of trials for each sample. The default is 10.\n    boundary : float, optional\n        posterior belief decision boundary. The default is 0.99.\n    n_channel : int, optional\n        number of channel for likelihood estimation. The default is 3.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "\n", "response_time", "=", "load_bayes", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "\n", "boundary", ",", "n_channel", ")", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "hist", "(", "response_time", ")", "\n", "title", "=", "[", "dataset", ",", "architecture", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "epsilon", "]", "\n", "title", "=", "' '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "title", "]", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "show", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.analysis.plot_epsilon_accrt": [[294, 407], ["matplotlib.pyplot.figure", "plt.figure.add_subplot", "fig.add_subplot.set_xlabel", "fig.add_subplot.set_ylabel", "fig.add_subplot.set_ylim", "fig.add_subplot.twinx", "y_left.twinx.set_ylabel", "y_left.twinx.set_ylim", "len", "numpy.zeros", "numpy.zeros", "enumerate", "range", "fig.add_subplot.plot", "y_left.twinx.plot", "fig.add_subplot.legend", "matplotlib.pyplot.title", "matplotlib.pyplot.show", "enumerate", "task.load_acc", "numpy.mean", "fig.add_subplot.plot", "task.load_acc", "inference.capitalize", "load_func", "inference.capitalize", "str"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_acc", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_acc"], ["", "def", "plot_epsilon_accrt", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'pgd'", ",", "\n", "epsilon", ":", "list", "=", "EPSILON_MNIST_FIGURE", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "len_trial", ":", "int", "=", "25", ",", "\n", "n_trial", ":", "int", "=", "10", ",", "\n", "inference", ":", "str", "=", "'bayes'", ",", "\n", "boundary", ":", "float", "=", "0.99", ",", "\n", "n_channel", ":", "int", "=", "3", ",", "\n", "likelihood_method", ":", "list", "=", "[", "'clean'", "]", ",", "\n", "likelihood_epsilon", ":", "list", "=", "[", "0", "]", ")", ":", "\n", "    ", "\"\"\"\n    Plot relationship of epsilon-accuracy and epsilon-response_time.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'pgd'.\n    epsilon : list, optional\n        perturbation thresholds of attack. The default is EPSILON_FIGURE.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    len_trial : int, optional\n        length of each trial. The default is 25.\n    n_trial : int, optional\n        number of trials for each sample. The default is 10.\n    boundary : float, optional\n        posterior belief decision boundary. The default is 0.99.\n    n_channel : int, optional\n        number of channel for likelihood estimation. The default is 3.\n    likelihood_method : list, optional\n        strings of attack methods for likelihood estimation, only for bayes inference. \n        The default is ['clean'].\n    likelihood_epsilon : list, optional\n        floats of attack epsilons for likelihood estimation, only for bayes inference. \n        The default is [0].\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "y_left", "=", "fig", ".", "add_subplot", "(", "111", ")", "\n", "y_left", ".", "set_xlabel", "(", "'\u03f5'", ")", "\n", "y_left", ".", "set_ylabel", "(", "\"Accuracy\"", ")", "\n", "y_left", ".", "set_ylim", "(", "0", ",", "1", ")", "\n", "\n", "y_right", "=", "y_left", ".", "twinx", "(", ")", "\n", "y_right", ".", "set_ylabel", "(", "\"Response Time\"", ")", "\n", "y_right", ".", "set_ylim", "(", "0", ",", "25", ")", "\n", "\n", "n_epsilon", "=", "len", "(", "epsilon", ")", "\n", "# dropout_00, dropout_optimal, bayes", "\n", "n_accuracy", "=", "3", "\n", "# bayesian", "\n", "accuracy", "=", "np", ".", "zeros", "(", "[", "n_epsilon", ",", "n_accuracy", "]", ")", "\n", "response_time", "=", "np", ".", "zeros", "(", "[", "n_epsilon", "]", ")", "\n", "for", "i", ",", "eps", "in", "enumerate", "(", "epsilon", ")", ":", "\n", "# load acc of dropout_00 and dropout_optimal", "\n", "        ", "for", "j", ",", "(", "dtrain", ",", "dtest", ")", "in", "enumerate", "(", "[", "(", "0", ",", "0", ")", ",", "(", "dropout_train", ",", "dropout_test", ")", "]", ")", ":", "\n", "            ", "args", "=", "[", "'attack'", ",", "dataset", ",", "architecture", ",", "index", ",", "dtrain", ",", "dtest", ",", "method", ",", "\n", "eps", ",", "subset", ",", "proportion", "]", "\n", "accuracy", "[", "i", ",", "j", "]", "=", "load_acc", "(", "*", "args", ")", "\n", "\n", "# load acc and rt of inference", "\n", "", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "\n", "eps", ",", "subset", ",", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", "]", "\n", "if", "inference", "==", "'cumsum'", ":", "\n", "            ", "load_func", "=", "load_cumsum", "\n", "", "if", "inference", "==", "'bayes'", ":", "\n", "            ", "load_func", "=", "load_bayes", "\n", "# TODO: specify likelihood epsilon for each attack epsilon", "\n", "if", "likelihood_epsilon", "is", "None", ":", "\n", "                ", "likelihood_epsilon_current", "=", "[", "0", ",", "eps", "]", "\n", "", "else", ":", "\n", "                ", "likelihood_epsilon_current", "=", "likelihood_epsilon", "\n", "", "args", "+=", "[", "n_channel", ",", "likelihood_method", ",", "likelihood_epsilon_current", "]", "\n", "", "accuracy", "[", "i", ",", "2", "]", "=", "load_acc", "(", "*", "(", "[", "inference", "]", "+", "args", ")", ")", "\n", "response_time", "[", "i", "]", "=", "np", ".", "mean", "(", "load_func", "(", "*", "args", ")", "[", "0", "]", ")", "\n", "\n", "", "label_accuracy", "=", "[", "'Naive Acc'", ",", "'Dropout Acc'", ",", "inference", ".", "capitalize", "(", ")", "+", "' Acc'", "]", "\n", "color", "=", "[", "'red'", ",", "'orange'", ",", "'green'", "]", "\n", "for", "i", "in", "range", "(", "n_accuracy", ")", ":", "\n", "        ", "y_left", ".", "plot", "(", "epsilon", ",", "accuracy", "[", ":", ",", "i", "]", ",", "label", "=", "label_accuracy", "[", "i", "]", ",", "color", "=", "color", "[", "i", "]", ")", "\n", "# fake line to insert the legend", "\n", "", "y_left", ".", "plot", "(", "[", "]", ",", "[", "]", ",", "label", "=", "inference", ".", "capitalize", "(", ")", "+", "' RT'", ",", "ls", "=", "'--'", ",", "color", "=", "color", "[", "-", "1", "]", ")", "\n", "y_right", ".", "plot", "(", "epsilon", ",", "response_time", ",", "ls", "=", "'--'", ",", "color", "=", "color", "[", "-", "1", "]", ")", "\n", "y_left", ".", "legend", "(", ")", "\n", "title", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", "]", "\n", "title", "=", "'\u03f5-Acc/RT '", "+", "' '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "title", "]", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.analysis.plot_epsilon_accpersample": [[410, 490], ["matplotlib.pyplot.figure", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "numpy.stack", "enumerate", "matplotlib.pyplot.title", "matplotlib.pyplot.show", "task.load_output", "task.get_y", "range", "numpy.concatenate", "np.stack.append", "numpy.argmax", "numpy.mean", "np.concatenate.append", "matplotlib.pyplot.plot", "numpy.max", "str"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_output", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_y"], ["", "def", "plot_epsilon_accpersample", "(", "dataset", ":", "str", "=", "'cifar10'", ",", "\n", "architecture", ":", "str", "=", "'resnet'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0.8", ",", "\n", "dropout_test", ":", "float", "=", "0.8", ",", "\n", "method", ":", "str", "=", "'pgd'", ",", "\n", "epsilon", ":", "list", "=", "EPSILON_CIFAR10_FIGURE", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", ")", ":", "\n", "    ", "\"\"\"\n    Plot relationship of epsilon-accuracy of each sample\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'pgd'.\n    epsilon : list, optional\n        perturbation thresholds of attack. The default is EPSILON_FIGURE.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is PROPORTION.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    len_trial : int, optional\n        length of each trial. The default is 25.\n    n_trial : int, optional\n        number of trials for each sample. The default is 10.\n    boundary : float, optional\n        posterior belief decision boundary. The default is 0.99.\n    n_channel : int, optional\n        number of channel for likelihood estimation. The default is 3.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "fig", "=", "plt", ".", "figure", "(", ")", "\n", "plt", ".", "xlabel", "(", "'\u03f5'", ")", "\n", "plt", ".", "ylabel", "(", "\"Accuracy\"", ")", "\n", "\n", "acc", "=", "[", "]", "\n", "for", "eps", "in", "epsilon", ":", "\n", "        ", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "eps", ",", "subset", ",", "proportion", ",", "repeat", "]", "\n", "output", "=", "load_output", "(", "*", "args", ")", "\n", "y", "=", "get_y", "(", "dataset", ",", "subset", ",", "proportion", ")", "\n", "acc_epsilon", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "np", ".", "max", "(", "y", ")", "+", "1", ")", ":", "\n", "            ", "idx", "=", "y", "==", "i", "\n", "# [repeat, n_sample]", "\n", "output_of_category", "=", "np", ".", "argmax", "(", "output", "[", ":", ",", "idx", "]", ",", "axis", "=", "-", "1", ")", "\n", "# [n_sample]", "\n", "acc_sample", "=", "np", ".", "mean", "(", "output_of_category", "==", "i", ",", "axis", "=", "0", ")", "\n", "acc_epsilon", ".", "append", "(", "acc_sample", ")", "\n", "", "acc_epsilon", "=", "np", ".", "concatenate", "(", "acc_epsilon", ")", "\n", "acc", ".", "append", "(", "acc_epsilon", ")", "\n", "# [n_sample_all, n_eps]", "\n", "", "acc", "=", "np", ".", "stack", "(", "acc", ",", "axis", "=", "-", "1", ")", "\n", "idx_interval", "=", "acc", ".", "shape", "[", "0", "]", "*", "0.05", "\n", "for", "idx", ",", "i", "in", "enumerate", "(", "acc", ")", ":", "\n", "        ", "if", "idx", "//", "idx_interval", "==", "0", ":", "\n", "            ", "plt", ".", "plot", "(", "epsilon", ",", "i", ")", "\n", "\n", "", "", "title", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", "]", "\n", "title", "=", "'\u03f5-Acc '", "+", "' '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "title", "]", ")", "\n", "plt", ".", "title", "(", "title", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.analysis.plot_failbayes_histogram": [[493, 550], ["len", "matplotlib.pyplot.subplots", "fig.suptitle", "task.get_y", "numpy.stack", "numpy.mean", "numpy.logical_and", "enumerate", "fig.show", "utils.get_dir", "matplotlib.pyplot.savefig", "task.load_bayes", "numpy.split", "numpy.argwhere().reshape", "zip", "task.load_output", "range", "str", "[].hist", "numpy.argwhere"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_y", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_bayes", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_output"], ["", "def", "plot_failbayes_histogram", "(", "dataset", ":", "str", "=", "'cifar10'", ",", "\n", "architecture", ":", "str", "=", "'resnet'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "[", "0", ",", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", "]", ",", "\n", "dropout_test", ":", "float", "=", "[", "0", ",", "0.2", ",", "0.4", ",", "0.6", ",", "0.8", "]", ",", "\n", "method", ":", "str", "=", "'pgd'", ",", "\n", "epsilon", ":", "float", "=", "0.031", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "PROPORTION", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "len_trial", ":", "int", "=", "25", ",", "\n", "n_trial", ":", "int", "=", "10", ",", "\n", "inference", ":", "str", "=", "'bayes'", ",", "\n", "boundary", ":", "float", "=", "0.99", ",", "\n", "n_channel", ":", "int", "=", "3", ",", "\n", "likelihood_method", ":", "list", "=", "[", "'clean'", ",", "'pgd'", "]", ",", "\n", "likelihood_epsilon", ":", "list", "=", "None", ",", "\n", "idx_sample", ":", "int", "=", "0", ")", ":", "\n", "    ", "true_label", "=", "0", "\n", "n_dropout", "=", "len", "(", "dropout_train", ")", "\n", "fig", ",", "axes", "=", "plt", ".", "subplots", "(", "n_dropout", ",", "10", ",", "True", ",", "True", ",", "\n", "figsize", "=", "(", "10", "*", "3", ",", "n_dropout", "*", "3", ")", ")", "\n", "title", "=", "[", "dataset", ",", "architecture", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "epsilon", "]", "\n", "title", "=", "' '", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "title", "]", ")", "\n", "fig", ".", "suptitle", "(", "title", ",", "fontsize", "=", "40", ")", "\n", "\n", "y", "=", "get_y", "(", "dataset", ",", "subset", ",", "proportion", ")", "\n", "# only plot one misclassified `true_label` images", "\n", "idx_truelabel", "=", "y", "==", "true_label", "\n", "\n", "if", "likelihood_epsilon", "is", "None", ":", "\n", "        ", "likelihood_epsilon_current", "=", "[", "0", ",", "epsilon", "]", "\n", "", "else", ":", "\n", "        ", "likelihood_epsilon_current", "=", "likelihood_epsilon", "\n", "", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "0.8", ",", "0.8", ",", "method", ",", "epsilon", ",", "subset", ",", "\n", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", ",", "n_channel", ",", "\n", "likelihood_method", ",", "likelihood_epsilon_current", "]", "\n", "choice", "=", "load_bayes", "(", "*", "args", ")", "[", "1", "]", "\n", "choice", "=", "np", ".", "stack", "(", "np", ".", "split", "(", "choice", ",", "choice", ".", "shape", "[", "0", "]", "//", "n_trial", ")", ")", "\n", "acc", "=", "np", ".", "mean", "(", "choice", "==", "y", "[", ":", ",", "np", ".", "newaxis", "]", ",", "axis", "=", "-", "1", ")", "\n", "idx_fail", "=", "acc", "<", "0.1", "\n", "\n", "idx", "=", "np", ".", "logical_and", "(", "idx_truelabel", ",", "idx_fail", ")", "\n", "idx", "=", "np", ".", "argwhere", "(", "idx", ")", ".", "reshape", "(", "[", "-", "1", "]", ")", "[", "idx_sample", "]", "\n", "\n", "for", "i", ",", "(", "dtrain", ",", "dtest", ")", "in", "enumerate", "(", "zip", "(", "dropout_train", ",", "dropout_test", ")", ")", ":", "\n", "        ", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dtrain", ",", "dtest", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", "]", "\n", "output", "=", "load_output", "(", "*", "args", ")", "\n", "\n", "output", "=", "output", "[", ":", ",", "idx", "]", "\n", "for", "j", "in", "range", "(", "10", ")", ":", "\n", "            ", "axes", "[", "i", "]", "[", "j", "]", ".", "hist", "(", "output", "[", ":", ",", "j", "]", ",", "bins", "=", "20", ")", "\n", "\n", "", "", "fig", ".", "show", "(", ")", "\n", "d", "=", "get_dir", "(", "dataset", ",", "'figure'", ")", "\n", "plt", ".", "savefig", "(", "d", "+", "'output_histogram.failbayes.image%d.%d.svg'", "%", "(", "true_label", ",", "idx_sample", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.audio.SpeechRecognizer.__init__": [[30, 53], ["model.load_model", "torch.nn.CrossEntropyLoss", "torch.optim.Adam", "eval", "eval", "art.estimators.classification.PyTorchClassifier.__init__", "audio.SpeechRecognizer.model_original.parameters", "dataset.upper", "dataset.upper", "len"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.load_model", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "\n", "dataset", "=", "'speechcommands'", ",", "\n", "architecture", ":", "str", "=", "'deepspeech'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ")", ":", "\n", "        ", "self", ".", "device_original", "=", "device", "\n", "self", ".", "model_original", "=", "load_model", "(", "dataset", ",", "architecture", ",", "index", ",", "\n", "dropout_train", ",", "dropout_test", ",", "device", ")", "\n", "self", ".", "loss_original", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "self", ".", "optimizer_original", "=", "torch", ".", "optim", ".", "Adam", "(", "self", ".", "model_original", ".", "parameters", "(", ")", ")", "\n", "self", ".", "label_list", ":", "list", "=", "eval", "(", "dataset", ".", "upper", "(", ")", "+", "'_LABEL'", ")", "\n", "self", ".", "sampling_rate", ":", "int", "=", "eval", "(", "dataset", ".", "upper", "(", ")", "+", "'_SAMPLINGRATE'", ")", "\n", "self", ".", "sample_rate", "=", "self", ".", "sampling_rate", "\n", "\n", "PyTorchClassifier", ".", "__init__", "(", "self", ",", "\n", "self", ".", "model_original", ",", "\n", "input_shape", "=", "(", "self", ".", "sampling_rate", ",", ")", ",", "\n", "nb_classes", "=", "len", "(", "self", ".", "label_list", ")", ",", "\n", "loss", "=", "self", ".", "loss_original", ",", "\n", "optimizer", "=", "self", ".", "optimizer_original", ",", "\n", "clip_values", "=", "(", "-", "1", ",", "1", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.audio.SpeechRecognizer.compute_loss_and_decoded_output": [[55, 71], ["masked_adv_input.type.type.type", "audio.SpeechRecognizer.model_original", "torch.Tensor().type().to", "audio.SpeechRecognizer.loss_original", "torch.argmax", "numpy.array", "audio.SpeechRecognizer.label_list.index", "torch.Tensor().type", "torch.Tensor"], "methods", ["None"], ["", "def", "compute_loss_and_decoded_output", "(", "self", ",", "\n", "masked_adv_input", ":", "torch", ".", "Tensor", ",", "\n", "original_output", ":", "np", ".", "ndarray", ",", "\n", "**", "kwargs", ")", "->", "tuple", "[", "torch", ".", "Tensor", ",", "np", ".", "ndarray", "]", ":", "\n", "# masked_adv_input.dtype == float64", "\n", "        ", "masked_adv_input", "=", "masked_adv_input", ".", "type", "(", "torch", ".", "float32", ")", "\n", "output", "=", "self", ".", "model_original", "(", "masked_adv_input", ")", "\n", "# str --> int", "\n", "original_output", "=", "[", "self", ".", "label_list", ".", "index", "(", "i", ")", "for", "i", "in", "original_output", "]", "\n", "original_output", "=", "torch", ".", "Tensor", "(", "original_output", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "self", ".", "device_original", ")", "\n", "loss", "=", "self", ".", "loss_original", "(", "output", ",", "original_output", ")", "\n", "\n", "output_argmax", "=", "torch", ".", "argmax", "(", "output", ",", "dim", "=", "-", "1", ")", "\n", "label", "=", "np", ".", "array", "(", "[", "self", ".", "label_list", "[", "i", "]", "for", "i", "in", "output_argmax", "]", ")", "\n", "\n", "return", "loss", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.audio.SpeechRecognizer.to_training_mode": [[73, 78], ["audio.SpeechRecognizer.model.train"], "methods", ["None"], ["", "def", "to_training_mode", "(", "self", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Put the estimator in the training mode.\n        \"\"\"", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.audio.SpeechRecognizer.sample_rate": [[80, 87], ["None"], "methods", ["None"], ["", "def", "sample_rate", "(", "self", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Get the sampling rate.\n\n        :return: The audio sampling rate.\n        \"\"\"", "\n", "return", "self", ".", "sampling_rate", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.audio.attack_model_artasr": [[89, 138], ["print", "audio.SpeechRecognizer", "task.get_dataset", "task.get_dataset.data.numpy", "numpy.array", "numpy.random.randint", "numpy.array", "art.attacks.evasion.ImperceptibleASRPyTorch.generate", "art.attacks.evasion.ImperceptibleASRPyTorch", "Exception", "numpy.max", "utils.get_npz", "numpy.savez_compressed", "task.get_loader", "print", "numpy.savez_compressed", "numpy.max", "traintest.predict_epoch"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_dataset", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_loader", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.traintest.predict_epoch"], ["", "", "def", "attack_model_artasr", "(", "dataset", ":", "str", "=", "'speechcommands'", ",", "\n", "architecture", ":", "str", "=", "'deepspeech'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'imperceptible'", ",", "\n", "epsilon", ":", "float", "=", "0.05", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "0.1", ",", "\n", "batch_size", ":", "int", "=", "256", ",", "\n", "save", ":", "bool", "=", "True", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ",", "\n", "num_workers", ":", "int", "=", "4", ")", ":", "\n", "    ", "print", "(", "'Attacking'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ")", "\n", "\n", "recognizer", "=", "SpeechRecognizer", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "device", ")", "\n", "\n", "if", "method", "==", "'imperceptible'", ":", "\n", "        ", "attacker", "=", "ImperceptibleASRPyTorch", "(", "recognizer", ",", "epsilon", ",", "max_iter_1", "=", "30", ",", "\n", "max_iter_2", "=", "100", ",", "batch_size", "=", "batch_size", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Invalid Attack Method: %s'", "%", "method", ")", "\n", "\n", "", "dataset_torch", "=", "get_dataset", "(", "dataset", ",", "subset", ",", "proportion", ")", "\n", "x", "=", "dataset_torch", ".", "data", ".", "numpy", "(", ")", "\n", "y", "=", "np", ".", "array", "(", "dataset_torch", ".", "targets", ")", "\n", "# random target label for each audio clip", "\n", "y_target", "=", "np", ".", "random", ".", "randint", "(", "1", ",", "np", ".", "max", "(", "y", ")", ",", "y", ".", "shape", "[", "0", "]", ")", "\n", "y_target", "=", "(", "y_target", "+", "y", ")", "%", "(", "np", ".", "max", "(", "y", ")", "+", "1", ")", "\n", "label_target", "=", "np", ".", "array", "(", "[", "recognizer", ".", "label_list", "[", "i", "]", "for", "i", "in", "y_target", "]", ")", "\n", "\n", "x_attacked", "=", "attacker", ".", "generate", "(", "x", ",", "label_target", ")", "\n", "\n", "if", "save", ":", "\n", "        ", "npz", "=", "get_npz", "(", "'attack'", ",", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "epsilon", ",", "subset", ",", "proportion", ")", "\n", "np", ".", "savez_compressed", "(", "npz", ",", "x", "=", "x_attacked", ",", "acc", "=", "[", "None", "]", ")", "\n", "\n", "loader", "=", "get_loader", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "\n", "dropout_test", ",", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "\n", "batch_size", ")", "\n", "acc", "=", "predict_epoch", "(", "dataset", ",", "architecture", ",", "recognizer", ".", "model", ",", "loader", ",", "\n", "device", "=", "device", ")", "[", "-", "1", "]", "\n", "print", "(", "'Acc: %f'", "%", "acc", ")", "\n", "np", ".", "savez_compressed", "(", "npz", ",", "x", "=", "x_attacked", ",", "acc", "=", "[", "acc", "]", ")", "\n", "\n", "", "return", "x_attacked", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.LambdaLayer.__init__": [[48, 51], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "lambd", ")", ":", "\n", "        ", "super", "(", "LambdaLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lambd", "=", "lambd", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.LambdaLayer.forward": [[52, 54], ["resnet.LambdaLayer.lambd"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "lambd", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.BasicBlock.__init__": [[59, 78], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "resnet.LambdaLayer", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.pad", "torch.pad", "torch.pad", "torch.pad", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__"], ["def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ",", "stride", "=", "1", ",", "option", "=", "'A'", ")", ":", "\n", "        ", "super", "(", "BasicBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "stride", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm2d", "(", "planes", ")", "\n", "\n", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", ")", "\n", "if", "stride", "!=", "1", "or", "in_planes", "!=", "planes", ":", "\n", "            ", "if", "option", "==", "'A'", ":", "\n", "                ", "\"\"\"\n                For CIFAR10 ResNet paper uses option A.\n                \"\"\"", "\n", "self", ".", "shortcut", "=", "LambdaLayer", "(", "lambda", "x", ":", "\n", "F", ".", "pad", "(", "x", "[", ":", ",", ":", ",", ":", ":", "2", ",", ":", ":", "2", "]", ",", "(", "0", ",", "0", ",", "0", ",", "0", ",", "planes", "//", "4", ",", "planes", "//", "4", ")", ",", "\"constant\"", ",", "0", ")", ")", "\n", "", "elif", "option", "==", "'B'", ":", "\n", "                ", "self", ".", "shortcut", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_planes", ",", "self", ".", "expansion", "*", "planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "stride", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "self", ".", "expansion", "*", "planes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.BasicBlock.forward": [[80, 86], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "resnet.BasicBlock.bn2", "resnet.BasicBlock.shortcut", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "resnet.BasicBlock.bn1", "resnet.BasicBlock.conv2", "resnet.BasicBlock.conv1"], "methods", ["None"], ["", "", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", "\n", "out", "+=", "self", ".", "shortcut", "(", "x", ")", "\n", "out", "=", "F", ".", "relu", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.ResNet.__init__": [[89, 101], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "resnet.ResNet._make_layer", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "resnet.ResNet.apply"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.ResNet._make_layer", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.ResNet._make_layer"], ["    ", "def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "num_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", "ResNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "in_planes", "=", "16", "\n", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "3", ",", "16", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm2d", "(", "16", ")", "\n", "self", ".", "layer1", "=", "self", ".", "_make_layer", "(", "block", ",", "16", ",", "num_blocks", "[", "0", "]", ",", "stride", "=", "1", ")", "\n", "self", ".", "layer2", "=", "self", ".", "_make_layer", "(", "block", ",", "32", ",", "num_blocks", "[", "1", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "layer3", "=", "self", ".", "_make_layer", "(", "block", ",", "64", ",", "num_blocks", "[", "2", "]", ",", "stride", "=", "2", ")", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "64", ",", "num_classes", ")", "\n", "\n", "self", ".", "apply", "(", "_weights_init", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.ResNet._make_layer": [[102, 110], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "planes", ",", "num_blocks", ",", "stride", ")", ":", "\n", "        ", "strides", "=", "[", "stride", "]", "+", "[", "1", "]", "*", "(", "num_blocks", "-", "1", ")", "\n", "layers", "=", "[", "]", "\n", "for", "stride", "in", "strides", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "self", ".", "in_planes", ",", "planes", ",", "stride", ")", ")", "\n", "self", ".", "in_planes", "=", "planes", "*", "block", ".", "expansion", "\n", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.ResNet.forward": [[111, 120], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "resnet.ResNet.layer1", "resnet.ResNet.layer2", "resnet.ResNet.layer3", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "resnet.ResNet.view", "resnet.ResNet.linear", "resnet.ResNet.bn1", "resnet.ResNet.size", "resnet.ResNet.conv1", "resnet.ResNet.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "F", ".", "avg_pool2d", "(", "out", ",", "out", ".", "size", "(", ")", "[", "3", "]", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet._weights_init": [[41, 46], ["isinstance", "isinstance", "torch.kaiming_normal_"], "function", ["None"], ["def", "_weights_init", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "#print(classname)", "\n", "if", "isinstance", "(", "m", ",", "nn", ".", "Linear", ")", "or", "isinstance", "(", "m", ",", "nn", ".", "Conv2d", ")", ":", "\n", "        ", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.resnet20": [[122, 124], ["resnet.ResNet"], "function", ["None"], ["", "", "def", "resnet20", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "3", ",", "3", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.resnet32": [[126, 128], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet32", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "5", ",", "5", ",", "5", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.resnet44": [[130, 132], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet44", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "7", ",", "7", ",", "7", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.resnet56": [[134, 136], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet56", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "9", ",", "9", ",", "9", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.resnet110": [[138, 140], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet110", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "18", ",", "18", ",", "18", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.resnet1202": [[142, 144], ["resnet.ResNet"], "function", ["None"], ["", "def", "resnet1202", "(", ")", ":", "\n", "    ", "return", "ResNet", "(", "BasicBlock", ",", "[", "200", ",", "200", ",", "200", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.test": [[146, 154], ["filter", "print", "print", "net.parameters", "np.prod", "len", "list", "x.data.numpy", "filter", "net.parameters", "len", "p.data.size"], "function", ["None"], ["", "def", "test", "(", "net", ")", ":", "\n", "    ", "import", "numpy", "as", "np", "\n", "total_params", "=", "0", "\n", "\n", "for", "x", "in", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "net", ".", "parameters", "(", ")", ")", ":", "\n", "        ", "total_params", "+=", "np", ".", "prod", "(", "x", ".", "data", ".", "numpy", "(", ")", ".", "shape", ")", "\n", "", "print", "(", "\"Total number of params\"", ",", "total_params", ")", "\n", "print", "(", "\"Total layers\"", ",", "len", "(", "list", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", "and", "len", "(", "p", ".", "data", ".", "size", "(", ")", ")", ">", "1", ",", "net", ".", "parameters", "(", ")", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.MNISTCNN.__init__": [[39, 58], ["torch.Module.__init__", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__"], ["def", "__init__", "(", "self", ",", "dropout", ":", "float", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        A simple CNN for MNIST classificaiton.\n\n        Parameters\n        ----------\n        dropout : float, optional\n            dropout rate at training phase. The default is 0.\n\n        \"\"\"", "\n", "super", "(", "MNISTCNN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "input_shape", "=", "(", "1", ",", "28", ",", "28", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv2d", "(", "1", ",", "32", ",", "5", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "True", ")", "\n", "self", ".", "maxpool1", "=", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "0", ")", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "5", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "True", ")", "\n", "self", ".", "maxpool2", "=", "nn", ".", "MaxPool2d", "(", "(", "2", ",", "2", ")", ",", "stride", "=", "(", "2", ",", "2", ")", ",", "padding", "=", "0", ")", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "7", "*", "7", "*", "64", ",", "1024", ",", "bias", "=", "True", ")", "\n", "self", ".", "fc2", "=", "nn", ".", "Linear", "(", "1024", ",", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.MNISTCNN.forward": [[59, 74], ["torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.relu", "torch.relu", "torch.relu", "torch.Dropout.", "model.MNISTCNN.maxpool1", "torch.Dropout.", "torch.relu", "torch.relu", "torch.relu", "torch.Dropout.", "model.MNISTCNN.maxpool2", "nn.Dropout.reshape", "torch.Dropout.", "model.MNISTCNN.fc1", "torch.Dropout.", "model.MNISTCNN.fc2", "model.MNISTCNN.conv1", "model.MNISTCNN.conv2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv1", "(", "x", ")", ")", "\n", "x", "=", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool1", "(", "x", ")", "\n", "x", "=", "dropout", "(", "x", ")", "\n", "x", "=", "F", ".", "relu", "(", "self", ".", "conv2", "(", "x", ")", ")", "\n", "x", "=", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "maxpool2", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "[", "x", ".", "shape", "[", "0", "]", ",", "-", "1", "]", ")", "\n", "x", "=", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "dropout", "(", "x", ")", "\n", "output", "=", "self", ".", "fc2", "(", "x", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.LSTM.__init__": [[96, 111], ["torch.Module.__init__", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "torch.Parameter", "model.LSTM.init_weights", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.LSTM.init_weights"], ["def", "__init__", "(", "self", ",", "\n", "input_size", ":", "int", "=", "300", ",", "\n", "hidden_size", ":", "int", "=", "512", ",", "\n", "dropout", ":", "float", "=", "0", ")", ":", "\n", "        ", "super", "(", "LSTM", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_size", "=", "input_size", "\n", "self", ".", "hidden_size", "=", "hidden_size", "\n", "self", ".", "dropout", "=", "dropout", "\n", "\n", "self", ".", "W", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "input_size", ",", "hidden_size", "*", "4", ")", ")", "\n", "self", ".", "U", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", ",", "hidden_size", "*", "4", ")", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "hidden_size", "*", "4", ")", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.LSTM.init_weights": [[112, 116], ["model.LSTM.parameters", "math.sqrt", "weight.data.uniform_"], "methods", ["None"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "stdv", "=", "1.0", "/", "math", ".", "sqrt", "(", "self", ".", "hidden_size", ")", "\n", "for", "weight", "in", "self", ".", "parameters", "(", ")", ":", "\n", "            ", "weight", ".", "data", ".", "uniform_", "(", "-", "stdv", ",", "stdv", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.LSTM.forward": [[117, 148], ["torch.Dropout", "torch.Dropout", "torch.Dropout", "x.size", "range", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "sequence.transpose().contiguous.transpose().contiguous.transpose().contiguous", "torch.Dropout.", "sequence.transpose().contiguous.transpose().contiguous.append", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.zeros().to", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "h_t.unsqueeze", "sequence.transpose().contiguous.transpose().contiguous.transpose", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "init_states", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "\"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"", "\n", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", "\n", "batch_size", ",", "len_seq", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "sequence", "=", "[", "]", "\n", "if", "init_states", "is", "None", ":", "\n", "            ", "h_t", ",", "c_t", "=", "(", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "x", ".", "device", ")", ",", "\n", "torch", ".", "zeros", "(", "batch_size", ",", "self", ".", "hidden_size", ")", ".", "to", "(", "x", ".", "device", ")", ")", "\n", "", "else", ":", "\n", "            ", "h_t", ",", "c_t", "=", "init_states", "\n", "\n", "", "for", "t", "in", "range", "(", "len_seq", ")", ":", "\n", "            ", "x_t", "=", "x", "[", ":", ",", "t", ",", ":", "]", "\n", "# batch the computations into a single matrix multiplication", "\n", "gates", "=", "x_t", "@", "self", ".", "W", "+", "h_t", "@", "self", ".", "U", "+", "self", ".", "bias", "\n", "gates", "=", "dropout", "(", "gates", ")", "\n", "i_t", ",", "f_t", ",", "g_t", ",", "o_t", "=", "(", "\n", "torch", ".", "sigmoid", "(", "gates", "[", ":", ",", ":", "self", ".", "hidden_size", "]", ")", ",", "# input", "\n", "torch", ".", "sigmoid", "(", "gates", "[", ":", ",", "self", ".", "hidden_size", ":", "self", ".", "hidden_size", "*", "2", "]", ")", ",", "# forget", "\n", "torch", ".", "tanh", "(", "gates", "[", ":", ",", "self", ".", "hidden_size", "*", "2", ":", "self", ".", "hidden_size", "*", "3", "]", ")", ",", "\n", "torch", ".", "sigmoid", "(", "gates", "[", ":", ",", "self", ".", "hidden_size", "*", "3", ":", "]", ")", ",", "# output", "\n", ")", "\n", "c_t", "=", "f_t", "*", "c_t", "+", "i_t", "*", "g_t", "\n", "h_t", "=", "o_t", "*", "torch", ".", "tanh", "(", "c_t", ")", "\n", "sequence", ".", "append", "(", "h_t", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "", "sequence", "=", "torch", ".", "cat", "(", "sequence", ",", "dim", "=", "0", ")", "\n", "# reshape from shape (sequence, batch, hidden_size | proj_size) to ", "\n", "# (batch, sequence, hidden_size | proj_size)", "\n", "sequence", "=", "sequence", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "return", "sequence", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.IMDBLSTM.__init__": [[152, 159], ["model.LSTM", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "\n", "input_size", ":", "int", "=", "300", ",", "\n", "hidden_size", ":", "int", "=", "512", ",", "\n", "proj_size", ":", "int", "=", "2", ",", "\n", "dropout", ":", "float", "=", "0", ")", ":", "\n", "        ", "self", ".", "lstm", "=", "LSTM", "(", "input_size", ",", "hidden_size", ",", "dropout", ")", "\n", "self", ".", "project_layer", "=", "nn", ".", "Linear", "(", "hidden_size", ",", "proj_size", ")", "\n", "", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "init_states", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.IMDBLSTM.forward": [[159, 166], ["x.size", "model.IMDBLSTM.lstm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.IMDBLSTM.project_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "init_states", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "batch_size", ",", "len_seq", ",", "_", "=", "x", ".", "size", "(", ")", "\n", "sequence", "=", "self", ".", "lstm", "(", "x", ")", "\n", "output", "=", "torch", ".", "mean", "(", "sequence", ",", "dim", "=", "1", ")", "\n", "output", "=", "self", ".", "project_layer", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.CIFAR10RESNET.__init__": [[185, 198], ["torch.Module.__init__", "int", "resnet.resnet20", "list", "model.CIFAR10RESNET.resnet.load_state_dict", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "state_dict.keys", "state_dict.pop"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.resnet.resnet20"], ["def", "__init__", "(", "self", ",", "dropout", ":", "float", "=", "0", ",", "pretrained_th", ":", "str", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", "CIFAR10RESNET", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "downsample_size", "=", "int", "(", "32", "*", "(", "1", "-", "dropout", ")", "**", "0.5", ")", "\n", "self", ".", "resnet", "=", "resnet20", "(", ")", "\n", "if", "pretrained_th", "is", "not", "None", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "pretrained_th", ")", "[", "'state_dict'", "]", "\n", "for", "i", "in", "list", "(", "state_dict", ".", "keys", "(", ")", ")", ":", "\n", "# \"module.conv1.weight\" --> \"conv1.weight\"", "\n", "                ", "state_dict", "[", "i", "[", "7", ":", "]", "]", "=", "state_dict", "[", "i", "]", "\n", "state_dict", ".", "pop", "(", "i", ")", "\n", "", "self", ".", "resnet", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.CIFAR10RESNET.get_random_index": [[200, 204], ["torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.sort"], "methods", ["None"], ["", "", "def", "get_random_index", "(", "self", ")", ":", "\n", "        ", "idx", "=", "torch", ".", "randperm", "(", "32", ")", "[", ":", "self", ".", "downsample_size", "]", "\n", "idx", "=", "torch", ".", "sort", "(", "idx", ")", "[", "0", "]", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.CIFAR10RESNET.downsample": [[206, 229], ["model.CIFAR10RESNET.get_random_index", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "model.CIFAR10RESNET.get_random_index", "torch.stack.append", "torch.stack.append", "torch.stack.append"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.CIFAR10RESNET.get_random_index", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.CIFAR10RESNET.get_random_index"], ["", "def", "downsample", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "\"\"\"\n        Randomly downsample image.\n\n        Parameters\n        ----------\n        x : torch.Tensor\n            cifar-10 image.\n\n        Returns\n        -------\n        x_downsampled : torch.Tensor\n            downsampled image.\n\n        \"\"\"", "\n", "x_downsampled", "=", "[", "]", "\n", "idx_row", "=", "self", ".", "get_random_index", "(", ")", "\n", "for", "i", "in", "idx_row", ":", "\n", "            ", "idx_column", "=", "self", ".", "get_random_index", "(", ")", "\n", "x_downsampled", ".", "append", "(", "x", "[", ":", ",", ":", ",", "i", ",", "idx_column", "]", ")", "\n", "", "x_downsampled", "=", "torch", ".", "stack", "(", "x_downsampled", ",", "2", ")", "\n", "\n", "return", "x_downsampled", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.CIFAR10RESNET.forward": [[230, 234], ["model.CIFAR10RESNET.downsample", "model.CIFAR10RESNET.resnet"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.CIFAR10RESNET.downsample"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "self", ".", "downsample", "(", "x", ")", "\n", "y", "=", "self", ".", "resnet", "(", "x", ")", "\n", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.SPEECHCOMMANDSDEEPSPEECH.__init__": [[237, 250], ["torch.Module.__init__", "torchaudio.transforms.MelSpectrogram", "torch.Conv1d", "torch.Conv1d", "torch.Conv1d", "model.LSTM", "model.LSTM", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "dropout", ":", "float", "=", "0", ",", "return_sequence", ":", "bool", "=", "False", ")", ":", "\n", "        ", "super", "(", "SPEECHCOMMANDSDEEPSPEECH", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "self", ".", "spectrogram", "=", "MelSpectrogram", "(", ")", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv1d", "(", "128", ",", "128", ",", "3", ",", "1", ")", "\n", "# self.conv2 = nn.Conv1d(128, 128, 3, 1)", "\n", "# self.conv3 = nn.Conv2d(32, 32, (21, 11), (2,1))", "\n", "self", ".", "lstm1", "=", "LSTM", "(", "128", ",", "128", ",", "dropout", ")", "\n", "self", ".", "lstm2", "=", "LSTM", "(", "128", ",", "128", ",", "dropout", ")", "\n", "# self.lstm3 = LSTM(128, 128, dropout)", "\n", "# self.lstm4 = LSTM(128, 128, dropout)", "\n", "self", ".", "fc1", "=", "nn", ".", "Linear", "(", "128", ",", "128", ")", "\n", "self", ".", "project_layer", "=", "nn", ".", "Linear", "(", "128", ",", "35", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.SPEECHCOMMANDSDEEPSPEECH.forward": [[252, 275], ["torch.Dropout", "torch.Dropout", "torch.Dropout", "model.SPEECHCOMMANDSDEEPSPEECH.spectrogram", "model.SPEECHCOMMANDSDEEPSPEECH.conv1", "torch.Dropout.", "torch.permute", "torch.permute", "torch.permute", "torch.permute", "torch.permute", "torch.permute", "torch.permute", "torch.permute", "torch.permute", "model.SPEECHCOMMANDSDEEPSPEECH.lstm1", "model.SPEECHCOMMANDSDEEPSPEECH.lstm2", "model.SPEECHCOMMANDSDEEPSPEECH.fc1", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "model.SPEECHCOMMANDSDEEPSPEECH.project_layer"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ":", "torch", ".", "Tensor", ",", "init_states", ":", "torch", ".", "Tensor", "=", "None", ")", ":", "\n", "        ", "\"\"\"Assumes x is of shape (batch, sequence, feature)\"\"\"", "\n", "dropout", "=", "nn", ".", "Dropout", "(", "self", ".", "dropout", ")", "\n", "batch_size", "=", "x", ".", "shape", "[", "0", "]", "\n", "\n", "# [batch_size, 128, 81]", "\n", "x", "=", "self", ".", "spectrogram", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "conv1", "(", "x", ")", "\n", "x", "=", "dropout", "(", "x", ")", "\n", "\n", "x", "=", "torch", ".", "permute", "(", "x", ",", "[", "0", ",", "2", ",", "1", "]", ")", "\n", "\n", "x", "=", "self", ".", "lstm1", "(", "x", ")", "\n", "x", "=", "self", ".", "lstm2", "(", "x", ")", "\n", "\n", "x", "=", "self", ".", "fc1", "(", "x", ")", "\n", "x", "=", "torch", ".", "mean", "(", "x", ",", "dim", "=", "1", ")", "\n", "output", "=", "self", ".", "project_layer", "(", "x", ")", "\n", "\n", "return", "output", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.load_model": [[277, 345], ["utils.get_pt_model", "SPEECHCOMMANDSDEEPSPEECH.load_state_dict", "SPEECHCOMMANDSDEEPSPEECH.to", "SPEECHCOMMANDSDEEPSPEECH.eval", "model.MNISTCNN", "SPEECHCOMMANDSDEEPSPEECH.to", "torch.load", "torch.load", "torch.load", "torch.DataParallel", "model.IMDBLSTM", "model.CIFAR10RESNET", "model.SPEECHCOMMANDSDEEPSPEECH", "Exception"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_pt_model"], ["", "", "def", "load_model", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "device", ":", "torch", ".", "device", "=", "DEVICE", ",", "\n", "multigpu", ":", "bool", "=", "False", ",", "\n", "return_untrained", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Load a well-trained model and change its dropout rate.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    device : str, optional\n        device on which the model is loaded. The default is 'cuda'.\n    multigpu : bool, optional\n        whether perform Data Parallelism on multiplt GPUs. The default is True.\n    return_sequence : bool, optional\n        whether RNN returns predictions of each token. The default is False.\n\n    Returns\n    -------\n    model : torch.nn.Module\n        pytorch neural network classifier.    \n    \"\"\"", "\n", "if", "return_untrained", ":", "\n", "        ", "dropout_test", "=", "dropout_train", "\n", "if", "dataset", "==", "'cifar10'", "and", "architecture", "==", "'resnet'", ":", "\n", "# https://github.com/akamaster/pytorch_resnet_cifar10/raw/master/pretrained_models/resnet20-12fca82f.th", "\n", "            ", "th", "=", "'data/cifar10/others/resnet20-12fca82f.th'", "\n", "", "else", ":", "\n", "            ", "th", "=", "None", "\n", "\n", "# define model", "\n", "", "", "if", "dataset", "==", "'mnist'", "and", "architecture", "==", "'cnn'", ":", "\n", "        ", "model", "=", "MNISTCNN", "(", "dropout_test", ")", "\n", "", "elif", "dataset", "==", "'imdb'", "and", "architecture", "==", "'lstm'", ":", "\n", "        ", "model", "=", "IMDBLSTM", "(", "dropout", "=", "dropout_test", ")", "\n", "", "elif", "dataset", "==", "'cifar10'", "and", "architecture", "==", "'resnet'", ":", "\n", "        ", "model", "=", "CIFAR10RESNET", "(", "dropout_test", ",", "th", ")", "\n", "", "elif", "dataset", "==", "'speechcommands'", "and", "architecture", "==", "'deepspeech'", ":", "\n", "        ", "model", "=", "SPEECHCOMMANDSDEEPSPEECH", "(", "dropout_test", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "'Wrong dataset and architecture combination: %s + %s'", "%", "(", "dataset", ",", "architecture", ")", ")", "\n", "\n", "", "if", "return_untrained", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "return", "model", "\n", "\n", "# load pre-trained weights", "\n", "", "pt", "=", "get_pt_model", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ")", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "pt", ")", ")", "\n", "model", "=", "model", ".", "to", "(", "device", ")", "\n", "model", ".", "eval", "(", ")", "\n", "# perform Data Parallelism", "\n", "if", "device", "==", "'cuda'", "and", "multigpu", ":", "\n", "        ", "model", "=", "nn", ".", "DataParallel", "(", "model", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.get_combination_all": [[347, 368], ["list", "numpy.array", "itertools.permutations", "range"], "function", ["None"], ["", "def", "get_combination_all", "(", "n_choice", ":", "int", ",", "n_channel", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Return all possible discretized neural network outputs.\n\n    Parameters\n    ----------\n    n_choice : int\n        number of labels.\n    n_channel : int\n        number of channel for likelihood estimation.\n\n    Returns\n    -------\n    combination_all : np.ndarray, shape as [n_combination, n_channel]\n        all possible discretized neural network outputs.\n\n    \"\"\"", "\n", "# up to 256 labels when using uint8", "\n", "combination_all", "=", "list", "(", "permutations", "(", "range", "(", "n_choice", ")", ",", "n_channel", ")", ")", "\n", "combination_all", "=", "np", ".", "array", "(", "combination_all", ",", "dtype", "=", "'uint8'", ")", "\n", "return", "combination_all", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.output2index": [[370, 410], ["model.get_combination_all", "numpy.flip", "numpy.stack", "numpy.argmax", "numpy.sum", "numpy.argsort"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.get_combination_all"], ["", "def", "output2index", "(", "output", ":", "np", ".", "ndarray", ",", "n_channel", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Discretize the neural network output by sorting the first *n_channel* max output \n    channels and return the index of this discretized output in all possible combination.\n    \n    For example:\n        for a 10-label classification task and n_channel=3,\n\n        for an output of `[0, 0.7, 0, 0, 0.1, 0, 0.2, 0, 0, 0]`, the first 3 maximum\n        channels are `[1, 6, 4]`\n    \n        all possible combinations of 3 channels are `[0, 1, 2]`, `[0, 1, 3]`, `[0, 1, 4]`, ...\n        \n        `[1, 6, 4]` is the *155th* of all possible combinations\n        \n        hence `[0, 0.7, 0, 0, 0.1, 0, 0.2, 0, 0, 0]` will be converted as 155\n    \n\n    Parameters\n    ----------\n    output : np.ndarray, shape as [n_sample, n_choice]\n        neural network classifier outputs.\n    n_channel : int\n        number of channel for likelihood estimation.\n\n    Returns\n    -------\n    idx : TYPE\n        DESCRIPTION.\n\n    \"\"\"", "\n", "# [n_combination_possible, n_channel]", "\n", "combination_all", "=", "get_combination_all", "(", "output", ".", "shape", "[", "-", "1", "]", ",", "n_channel", ")", "\n", "combination", "=", "np", ".", "flip", "(", "np", ".", "argsort", "(", "output", ",", "axis", "=", "-", "1", ")", "[", "...", ",", "-", "n_channel", ":", "]", ",", "axis", "=", "-", "1", ")", "\n", "n_sample", ",", "n_channel", "=", "combination", ".", "shape", "\n", "# [n_sample, n_combination, n_channel]", "\n", "combination_repeat", "=", "np", ".", "stack", "(", "[", "combination_all", "]", "*", "n_sample", ",", "axis", "=", "0", ")", "\n", "idx", "=", "combination_repeat", "==", "combination", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "idx", "=", "np", ".", "argmax", "(", "np", ".", "sum", "(", "idx", ",", "axis", "=", "-", "1", ")", ",", "axis", "=", "-", "1", ")", "\n", "return", "idx", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.get_likelihood": [[412, 447], ["model.get_combination_all", "len", "numpy.zeros", "enumerate", "model.output2index", "numpy.unique", "numpy.delete", "min", "numpy.sum", "numpy.arange"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.get_combination_all", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.output2index"], ["", "def", "get_likelihood", "(", "output_of_category", ":", "list", ",", "n_channel", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Estimate the likelihood of discretized neural network outputs in each class.\n\n    Parameters\n    ----------\n    output_of_category : list, shape as [n_choice] [n_output, n_choice]\n        list of arrays of neural network output of each category.\n    n_channel : int\n        number of channel for likelihood estimation.\n\n    Returns\n    -------\n    likelihood : np.ndarray, shape as [n_combination_possible, n_choice]\n        likelihood of discretized neural network outputs in each class.\n\n    \"\"\"", "\n", "n_choice", "=", "output_of_category", "[", "0", "]", ".", "shape", "[", "-", "1", "]", "\n", "combination_all", "=", "get_combination_all", "(", "n_choice", ",", "n_channel", ")", "\n", "n_combination", "=", "len", "(", "combination_all", ")", "\n", "\n", "likelihood", "=", "np", ".", "zeros", "(", "[", "n_combination", ",", "n_choice", "]", ")", "\n", "for", "choice", ",", "i", "in", "enumerate", "(", "output_of_category", ")", ":", "\n", "        ", "n_sample", ",", "n_choice", "=", "i", ".", "shape", "\n", "index", "=", "output2index", "(", "i", ",", "n_channel", ")", "\n", "# counting combination of outputs of all choices", "\n", "combination_i", ",", "count_i", "=", "np", ".", "unique", "(", "index", ",", "False", ",", "False", ",", "True", ")", "\n", "likelihood_i", "=", "count_i", "/", "np", ".", "sum", "(", "n_sample", ")", "\n", "likelihood", "[", "combination_i", ",", "choice", "]", "=", "likelihood_i", "\n", "# assign unshown combination with minimum likelihood", "\n", "idx_unshown", "=", "np", ".", "delete", "(", "np", ".", "arange", "(", "n_combination", ")", ",", "index", ")", "\n", "likelihood", "[", "idx_unshown", ",", "choice", "]", "=", "min", "(", "likelihood_i", ")", "\n", "\n", "\n", "", "return", "likelihood", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.threshold_decision_process": [[448, 481], ["numpy.max", "numpy.argmax", "numpy.logical_not", "numpy.argmax", "numpy.sum", "numpy.max"], "function", ["None"], ["", "def", "threshold_decision_process", "(", "evidence", ":", "np", ".", "ndarray", ",", "boundary", ":", "float", ")", ":", "\n", "    ", "\"\"\"\n    Make dicision when accumulated evience reaches threshold/bounday. \n    For bayesian inference, the evidence will be posterior beliefs.\n\n    Parameters\n    ----------\n    evidence : np.ndarray\n        DESCRIPTION.\n    boundary : float\n        DESCRIPTION.\n\n    Returns\n    -------\n    response_time : np.ndarray\n        number of timesteps needed to make the decision.\n    choice : np.ndarray\n        final decisions.\n\n    \"\"\"", "\n", "# decision-making based on posteror belief", "\n", "# [n_trial, n_timestep]", "\n", "evidence_max", "=", "np", ".", "max", "(", "evidence", ",", "axis", "=", "-", "1", ")", "\n", "channel_max", "=", "np", ".", "argmax", "(", "evidence", ",", "axis", "=", "-", "1", ")", "\n", "hit_boundary", "=", "evidence_max", ">=", "boundary", "\n", "# force decision based on last evidence if never hit boundary", "\n", "never_hit", "=", "np", ".", "logical_not", "(", "np", ".", "sum", "(", "hit_boundary", ",", "-", "1", ")", ")", "\n", "hit_boundary", "[", "never_hit", ",", "-", "1", "]", "=", "True", "\n", "# [n_trial]", "\n", "response_time", "=", "np", ".", "argmax", "(", "hit_boundary", ",", "axis", "=", "-", "1", ")", "\n", "choice", "=", "np", ".", "max", "(", "(", "channel_max", "+", "1", ")", "*", "hit_boundary", ",", "axis", "=", "-", "1", ")", "-", "1", "\n", "\n", "return", "response_time", ",", "choice", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.cumsum_inference": [[483, 506], ["numpy.cumsum", "model.threshold_decision_process"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.threshold_decision_process"], ["", "def", "cumsum_inference", "(", "trial", ":", "np", ".", "ndarray", ",", "boundary", ":", "float", ")", ":", "\n", "    ", "\"\"\"\n    Perform cumsum inference with neural network predictions as observations.\n\n    Parameters\n    ----------\n    trial : np.ndarray, shape as [n_sample*n_trial, len_trial, n_channel]\n        trials of neural network predicitons.\n    boundary : float\n        decision made when any accumulated prediction surpass this boundary.\n\n    Returns\n    -------\n    response_time : np.ndarray, shape as [n_sample*n_trial]\n        number of timesteps needed to make the decision.\n    choice : np.ndarray, shape as [n_sample*n_trial]\n        final decisions made by bayesian inference.\n    evidence : np.ndarray, shape as [n_sample*n_trial, len_trial, n_choice]\n        all accumulated predictions through the process of cumsum inference.\n    \"\"\"", "\n", "evidence", "=", "np", ".", "cumsum", "(", "trial", ",", "axis", "=", "1", ",", ")", "\n", "response_time", ",", "choice", "=", "threshold_decision_process", "(", "evidence", ",", "boundary", ")", "\n", "return", "response_time", ",", "choice", ",", "evidence", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.bayesian_inference": [[508, 552], ["numpy.stack", "numpy.full", "range", "model.threshold_decision_process", "model.output2index", "range", "numpy.sum"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.threshold_decision_process", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.model.output2index"], ["", "def", "bayesian_inference", "(", "trial", ":", "np", ".", "ndarray", ",", "\n", "boundary", ":", "float", ",", "\n", "likelihood", ":", "np", ".", "ndarray", ",", "\n", "n_channel", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Perform bayesian inference with neural network predictions as observations.\n\n    Parameters\n    ----------\n    trial : np.ndarray, shape as [n_sample*n_trial, len_trial, n_channel]\n        trials of neural network predicitons.\n    boundary : float\n        decision made when any posterior belief surpass this boundary.\n    likelihood : np.ndarray, shape as [n_combination_possible, n_choice]\n        likelihood of discretized neural network outputs in each class.\n    n_channel : int\n        number of channel for likelihood estimation.\n\n    Returns\n    -------\n    response_time : np.ndarray, shape as [n_sample*n_trial]\n        number of timesteps needed to make the decision.\n    choice : np.ndarray, shape as [n_sample*n_trial]\n        final decisions made by bayesian inference.\n    belief_post : np.ndarray, shape as [n_sample*n_trial, len_trial, n_choice]\n        all posterior beliefs through the process of bayesian inference.\n    \"\"\"", "\n", "\n", "n_trial", ",", "len_trial", ",", "n_choice", "=", "trial", ".", "shape", "\n", "idx_combination", "=", "[", "output2index", "(", "trial", "[", ":", ",", "i", "]", ",", "n_channel", ")", "for", "i", "in", "range", "(", "len_trial", ")", "]", "\n", "idx_combination", "=", "np", ".", "stack", "(", "idx_combination", ",", "axis", "=", "1", ")", "\n", "\n", "belief_post", "=", "np", ".", "full", "(", "[", "n_trial", ",", "len_trial", ",", "n_choice", "]", ",", "1", "/", "n_choice", ")", "\n", "for", "t", "in", "range", "(", "1", ",", "len_trial", ")", ":", "\n", "# likelihood.shape = [n_choice, n_combination]", "\n", "# p(x_t|A_i) for all i(labels), shape as [n_trial, n_choice]", "\n", "        ", "prob_xt", "=", "likelihood", "[", "idx_combination", "[", ":", ",", "t", "]", "]", "\n", "# p(x_t|A_i)*p(A_i|X_1:t-1)", "\n", "prob_product", "=", "prob_xt", "*", "belief_post", "[", ":", ",", "t", "-", "1", "]", "\n", "belief_post", "[", ":", ",", "t", "]", "=", "prob_product", "/", "np", ".", "sum", "(", "prob_product", ",", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n", "", "response_time", ",", "choice", "=", "threshold_decision_process", "(", "belief_post", ",", "boundary", ")", "\n", "\n", "return", "response_time", ",", "choice", ",", "belief_post", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.TextToTensor.__init__": [[69, 78], ["torchtext.data.utils.get_tokenizer", "torchtext.vocab.GloVe"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "tokenizer", ":", "str", "=", "'basic_english'", ",", "\n", "glove_name", ":", "str", "=", "'6B'", ",", "\n", "glove_dim", ":", "int", "=", "300", ",", "\n", "max_len", ":", "int", "=", "400", ")", ":", "\n", "\n", "        ", "self", ".", "tokenizer", "=", "get_tokenizer", "(", "tokenizer", ")", "\n", "self", ".", "vocab", "=", "GloVe", "(", "name", "=", "glove_name", ",", "dim", "=", "glove_dim", ")", "\n", "self", ".", "max_len", "=", "max_len", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.TextToTensor.__call__": [[79, 85], ["task.TextToTensor.tokenizer", "len", "task.TextToTensor.vocab.get_vecs_by_tokens"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "text", ")", ":", "\n", "        ", "x", "=", "self", ".", "tokenizer", "(", "text", ")", "\n", "len_x", "=", "len", "(", "x", ")", "\n", "x", "=", "x", "[", ":", "self", ".", "max_len", "]", "if", "len_x", ">=", "self", ".", "max_len", "else", "x", "+", "[", "''", "]", "*", "(", "self", ".", "max_len", "-", "len_x", ")", "\n", "x", "=", "self", ".", "vocab", ".", "get_vecs_by_tokens", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__init__": [[106, 130], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "\n", "x", ":", "np", ".", "ndarray", ",", "\n", "y", ":", "np", ".", "ndarray", ",", "\n", "transform_x", ":", "None", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Instantiate a pytorch dataset with given x and y.\n\n        Parameters\n        ----------\n        x : np.ndarray, shape as [n_sample, *input_shape]\n            inputs for model.\n        y : np.ndarray, shape as [n_sample]\n            true labels in indexs.\n        transform : None, optional\n            transformation of x. The default is ToTensor().\n\n        Returns\n        -------\n        None.\n\n        \"\"\"", "\n", "self", ".", "data", "=", "x", "\n", "self", ".", "targets", "=", "y", "\n", "self", ".", "transform_x", "=", "transform_x", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__len__": [[131, 133], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__getitem__": [[134, 141], ["task.CustomDataset.transform_x"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ":", "int", ")", ":", "\n", "        ", "x", "=", "self", ".", "data", "[", "idx", "]", "\n", "if", "self", ".", "transform_x", "is", "not", "None", ":", "\n", "            ", "x", "=", "self", ".", "transform_x", "(", "x", ")", "\n", "", "y", "=", "self", ".", "targets", "[", "idx", "]", "\n", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_n_sample_dataset": [[143, 165], ["None"], "function", ["None"], ["", "", "def", "get_n_sample_dataset", "(", "dataset", ":", "str", ",", "torch_dataset", ":", "torch", ".", "utils", ".", "data", ".", "Dataset", ")", ":", "\n", "    ", "\"\"\"\n    Return number of samples in given dataset.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    torch_dataset : torch.utils.data.Dataset\n        torch dataset.\n\n    Returns\n    -------\n    n_sample : int\n        number of samples.\n\n    \"\"\"", "\n", "if", "dataset", "in", "DATASET_VISION", ":", "\n", "        ", "n_sample", "=", "torch_dataset", ".", "data", ".", "shape", "[", "0", "]", "\n", "", "elif", "dataset", "in", "DATASET_TEXT", ":", "\n", "        ", "n_sample", "=", "torch_dataset", ".", "num_lines", "\n", "", "return", "n_sample", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_dataset": [[167, 297], ["torch.Generator().manual_seed", "task.CustomDataset", "torchaudio.datasets.speechcommands.SPEECHCOMMANDS", "int", "torch.utils.data.random_split", "range", "torch.stack", "task.CustomDataset", "task.get_n_sample_dataset", "int", "torch.utils.data.random_split", "torch.Generator", "subset_return.__getitem__", "torch.stack.append", "y.append", "torchvision.datasets.MNIST", "int", "int", "task.get_n_sample_dataset", "torch.utils.data.random_split", "enumerate", "torchaudio.datasets.speechcommands.SPEECHCOMMANDS.__len__", "torch.cat", "SPEECHCOMMANDS_LABEL.index", "torchvision.transforms.ToTensor", "torchvision.datasets.CIFAR10", "int", "int", "torchvision.datasets.MNIST", "int", "subset_return.dataset.data.numpy", "subset_return.dataset.targets.numpy", "torchvision.transforms.ToTensor", "task.TextToTensor", "torchaudio.datasets.speechcommands.SPEECHCOMMANDS.__len__", "torchvision.transforms.ToTensor", "torchtext.datasets.IMDB", "torchvision.transforms.ToTensor", "torchvision.datasets.CIFAR10", "int", "numpy.array", "torchvision.transforms.Normalize", "torch.stack.append", "y.append", "torch.zeros", "torchvision.transforms.ToTensor", "torchtext.datasets.IMDB", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.ToPILImage", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToTensor", "torchvision.transforms.ToPILImage", "torchvision.transforms.ToTensor"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_n_sample_dataset", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__getitem__", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_n_sample_dataset", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__len__", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.CustomDataset.__len__"], ["", "def", "get_dataset", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ",", "\n", "validation_split", ":", "float", "=", "0.2", ",", "\n", "transform", ":", "bool", "=", "True", ",", "\n", "phase", ":", "str", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return pytorch dataset.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    subset : str, optional\n        subset of datset, should be one of [train|val|test]. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is 1.\n    validation_split : float, optional\n        split of original training set to be the validation set. The default is 0.2.\n    transform : bool, optional\n        whether apply transformation to inputs before feeding to model. \n        The default is True.\n    phase : str, optional\n        ['training' | 'attacking' | None], for cifar10+renset only. \n        The default is None.\n\n    Returns\n    -------\n    dataset_return : CustomDataset\n        pytorch dataset.\n\n    \"\"\"", "\n", "dataset_directory", "=", "DATASET_DIRECTORY", "[", "dataset", "]", "\n", "generator", "=", "torch", ".", "Generator", "(", ")", ".", "manual_seed", "(", "0", ")", "\n", "\n", "if", "dataset", "==", "'speechcommands'", ":", "\n", "        ", "subset_dict", "=", "{", "'train'", ":", "'training'", ",", "'val'", ":", "'validation'", ",", "'test'", ":", "'testing'", "}", "\n", "ds", "=", "SPEECHCOMMANDS", "(", "dataset_directory", ",", "subset", "=", "subset_dict", "[", "subset", "]", ")", "\n", "n_sample", "=", "int", "(", "ds", ".", "__len__", "(", ")", "*", "proportion", ")", "\n", "subset_return", ",", "_", "=", "random_split", "(", "ds", ",", "[", "n_sample", ",", "ds", ".", "__len__", "(", ")", "-", "n_sample", "]", ",", "\n", "generator", "=", "generator", ")", "\n", "\n", "x", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "length", "=", "16000", "\n", "for", "i", "in", "range", "(", "n_sample", ")", ":", "\n", "# waveform, sample_rate, label, speaker_id, utterance_number", "\n", "            ", "item", "=", "subset_return", ".", "__getitem__", "(", "i", ")", "\n", "x_i", "=", "item", "[", "0", "]", "\n", "# pad waveform if shorter than one second", "\n", "x_len", "=", "x_i", ".", "shape", "[", "-", "1", "]", "\n", "if", "x_len", "<", "length", ":", "\n", "                ", "x_i", "=", "torch", ".", "cat", "(", "[", "x_i", ",", "torch", ".", "zeros", "(", "[", "1", ",", "length", "-", "x_len", "]", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "# cut waveform if longer than one second", "\n", "", "elif", "x_len", ">", "length", ":", "\n", "                ", "x_i", "=", "x_i", "[", ":", ",", ":", "length", "]", "\n", "\n", "", "x", ".", "append", "(", "x_i", "[", "0", "]", ")", "\n", "y", ".", "append", "(", "SPEECHCOMMANDS_LABEL", ".", "index", "(", "item", "[", "2", "]", ")", ")", "\n", "\n", "", "x", "=", "torch", ".", "stack", "(", "x", ")", "\n", "dataset_return", "=", "CustomDataset", "(", "x", ",", "y", ")", "\n", "return", "dataset_return", "\n", "\n", "\n", "", "if", "subset", "in", "[", "'train'", ",", "'val'", "]", ":", "\n", "        ", "if", "dataset", "==", "'mnist'", ":", "\n", "            ", "train_data", "=", "MNIST", "(", "dataset_directory", ",", "True", ",", "ToTensor", "(", ")", ",", "download", "=", "True", ")", "\n", "", "elif", "dataset", "==", "'cifar10'", ":", "\n", "            ", "train_data", "=", "CIFAR10", "(", "dataset_directory", ",", "True", ",", "ToTensor", "(", ")", ",", "download", "=", "True", ")", "\n", "", "elif", "dataset", "==", "'imdb'", ":", "\n", "            ", "train_data", "=", "IMDB", "(", "root", "=", "dataset_directory", ",", "split", "=", "'train'", ")", "\n", "# split full training set into real training set and validation set", "\n", "", "n_fulltrain", "=", "get_n_sample_dataset", "(", "dataset", ",", "train_data", ")", "\n", "n_val", "=", "int", "(", "n_fulltrain", "*", "validation_split", ")", "\n", "n_train", "=", "n_fulltrain", "-", "n_val", "\n", "lengths", "=", "[", "int", "(", "n_train", "*", "proportion", ")", ",", "n_train", "-", "int", "(", "n_train", "*", "proportion", ")", ",", "\n", "int", "(", "n_val", "*", "proportion", ")", ",", "n_val", "-", "int", "(", "n_val", "*", "proportion", ")", "]", "\n", "train_subset", ",", "_", ",", "val_subset", ",", "_", "=", "random_split", "(", "train_data", ",", "lengths", ",", "\n", "generator", "=", "generator", ")", "\n", "subset_return", "=", "train_subset", "if", "subset", "==", "'train'", "else", "val_subset", "\n", "", "elif", "subset", "==", "'test'", ":", "\n", "        ", "if", "dataset", "==", "'mnist'", ":", "\n", "            ", "test_data", "=", "MNIST", "(", "dataset_directory", ",", "False", ",", "ToTensor", "(", ")", ",", "download", "=", "True", ")", "\n", "", "elif", "dataset", "==", "'cifar10'", ":", "\n", "            ", "test_data", "=", "CIFAR10", "(", "dataset_directory", ",", "False", ",", "ToTensor", "(", ")", ",", "download", "=", "True", ")", "\n", "", "elif", "dataset", "==", "'imdb'", ":", "\n", "            ", "test_data", "=", "IMDB", "(", "root", "=", "dataset_directory", ",", "split", "=", "'test'", ")", "\n", "", "n_test", "=", "get_n_sample_dataset", "(", "dataset", ",", "test_data", ")", "\n", "lengths", "=", "[", "int", "(", "n_test", "*", "proportion", ")", ",", "n_test", "-", "int", "(", "n_test", "*", "proportion", ")", "]", "\n", "subset_return", ",", "_", "=", "random_split", "(", "test_data", ",", "lengths", ",", "generator", ")", "\n", "\n", "", "if", "dataset", "in", "DATASET_VISION", ":", "\n", "        ", "if", "dataset", "==", "'mnist'", ":", "\n", "            ", "x", "=", "subset_return", ".", "dataset", ".", "data", ".", "numpy", "(", ")", "[", "subset_return", ".", "indices", "]", "\n", "y", "=", "subset_return", ".", "dataset", ".", "targets", ".", "numpy", "(", ")", "[", "subset_return", ".", "indices", "]", "\n", "transform_x", "=", "ToTensor", "(", ")", "if", "transform", "else", "None", "\n", "", "elif", "dataset", "==", "'cifar10'", ":", "\n", "            ", "x", "=", "subset_return", ".", "dataset", ".", "data", "[", "subset_return", ".", "indices", "]", "\n", "y", "=", "np", ".", "array", "(", "subset_return", ".", "dataset", ".", "targets", ")", "[", "subset_return", ".", "indices", "]", "\n", "# these transform only suits resnet", "\n", "if", "transform", ":", "\n", "                ", "normalize", "=", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "if", "phase", "==", "'training'", ":", "\n", "                    ", "transform_x", "=", "Compose", "(", "[", "ToPILImage", "(", ")", ",", "\n", "RandomHorizontalFlip", "(", ")", ",", "\n", "ToTensor", "(", ")", ",", "\n", "normalize", "]", ")", "\n", "", "elif", "phase", "==", "'attacking'", ":", "\n", "                    ", "transform_x", "=", "Compose", "(", "[", "ToPILImage", "(", ")", ",", "ToTensor", "(", ")", "]", ")", "\n", "", "else", ":", "\n", "                    ", "transform_x", "=", "Compose", "(", "[", "ToPILImage", "(", ")", ",", "ToTensor", "(", ")", ",", "normalize", "]", ")", "\n", "", "", "else", ":", "\n", "                ", "transform_x", "=", "None", "\n", "\n", "\n", "", "", "", "elif", "dataset", "in", "DATASET_TEXT", ":", "\n", "        ", "idx_subset", "=", "subset_return", ".", "indices", "\n", "x", ",", "y", "=", "[", "]", ",", "[", "]", "\n", "for", "idx", ",", "(", "iy", ",", "ix", ")", "in", "enumerate", "(", "subset_return", ".", "dataset", ")", ":", "\n", "            ", "if", "idx", "in", "idx_subset", ":", "\n", "                ", "x", ".", "append", "(", "ix", ")", "\n", "iy", "=", "0", "if", "iy", "==", "'neg'", "else", "1", "\n", "y", ".", "append", "(", "iy", ")", "\n", "", "", "transform_x", "=", "TextToTensor", "(", ")", "if", "transform", "else", "None", "\n", "\n", "", "dataset_return", "=", "CustomDataset", "(", "x", ",", "y", ",", "transform_x", ")", "\n", "\n", "return", "dataset_return", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_loader": [[299, 379], ["task.get_dataset", "torch.utils.data.DataLoader", "task.load_attack", "task.CustomDataset", "task.TextToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Compose", "torch.tensor"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_dataset", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_attack"], ["", "def", "get_loader", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ",", "\n", "batch_size", ":", "int", "=", "64", ",", "\n", "num_workers", ":", "int", "=", "4", ",", "\n", "shuffle", ":", "bool", "=", "False", ",", "\n", "phase", ":", "str", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return pytorch data loader.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is 1.\n    batch_size : int, optional\n        batch size. The default is 64.\n    num_workers: int, optional\n        how many subprocesses to use for data. The default is 4.\n    shuffle : bool, optional\n        whether return data in random order. The default is False.\n    phase : str, optional\n        ['training' | 'attacking' | None], for cifar10+renset only. \n        The default is None.\n        \n\n    Returns\n    -------\n    loader : torch.utils.data.DataLoader\n        pytorch data loader.\n\n    \"\"\"", "\n", "\n", "d", "=", "get_dataset", "(", "dataset", ",", "subset", ",", "proportion", ",", "phase", "=", "phase", ")", "\n", "# load adversarial samples", "\n", "if", "method", "!=", "'clean'", ":", "\n", "        ", "if", "dataset", "in", "DATASET_TEXT", ":", "\n", "            ", "transform", "=", "TextToTensor", "(", ")", "\n", "", "elif", "dataset", "==", "'cifar10'", ":", "\n", "            ", "normalize", "=", "Normalize", "(", "mean", "=", "[", "0.485", ",", "0.456", ",", "0.406", "]", ",", "\n", "std", "=", "[", "0.229", ",", "0.224", ",", "0.225", "]", ")", "\n", "transform", "=", "Compose", "(", "[", "lambda", "x", ":", "torch", ".", "tensor", "(", "x", ")", ",", "normalize", "]", ")", "\n", "", "else", ":", "\n", "            ", "transform", "=", "None", "\n", "", "x", "=", "load_attack", "(", "dataset", ",", "\n", "architecture", ",", "\n", "index", ",", "\n", "dropout_train", ",", "\n", "dropout_test", ",", "\n", "method", ",", "\n", "epsilon", ",", "\n", "subset", ",", "\n", "proportion", ")", "\n", "y", "=", "d", ".", "targets", "\n", "d", "=", "CustomDataset", "(", "x", ",", "y", ",", "transform", ")", "\n", "\n", "", "loader", "=", "DataLoader", "(", "d", ",", "batch_size", ",", "shuffle", ",", "num_workers", "=", "num_workers", ")", "\n", "\n", "return", "loader", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.iter2array": [[381, 411], ["isinstance", "isinstance", "np.array.numpy", "isinstance", "numpy.array", "Exception", "str", "type"], "function", ["None"], ["", "def", "iter2array", "(", "x", ")", ":", "\n", "    ", "\"\"\"\n    Convert list or torch.Tensor into numpy.ndarray\n\n    Parameters\n    ----------\n    x : iterable type \n        list, torch.Tensor or numpy.ndarray.\n\n    Raises\n    ------\n    Exception\n        x belongs to other types.\n\n    Returns\n    -------\n    x : np.ndarray\n        converted x.\n\n    \"\"\"", "\n", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", ":", "\n", "        ", "pass", "\n", "", "elif", "isinstance", "(", "x", ",", "torch", ".", "Tensor", ")", ":", "\n", "        ", "x", "=", "x", ".", "numpy", "(", ")", "\n", "", "elif", "isinstance", "(", "x", ",", "list", ")", ":", "\n", "        ", "x", "=", "np", ".", "array", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "raise", "Exception", "(", "\"Invalid type: %s\"", "%", "str", "(", "type", "(", "x", ")", ")", ")", "\n", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_y": [[413, 445], ["task.get_dataset", "task.iter2array", "numpy.eye", "numpy.max"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_dataset", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.iter2array"], ["", "def", "get_y", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ",", "\n", "onehot", ":", "bool", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Return pytorch tensors of inputs and labels of dataset.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is 1.\n    onehot : bool, optional\n        whether encode labels in the onehot manner. The default is False.\n\n    Returns\n    -------\n    y : np.ndarray\n        labels.\n\n    \"\"\"", "\n", "dataset_torch", "=", "get_dataset", "(", "dataset", ",", "subset", ",", "proportion", ")", "\n", "\n", "y", "=", "dataset_torch", ".", "targets", "\n", "y", "=", "iter2array", "(", "y", ")", "\n", "if", "onehot", ":", "\n", "        ", "y", "=", "np", ".", "eye", "(", "np", ".", "max", "(", "y", ")", "+", "1", ")", "[", "y", "]", "\n", "\n", "", "return", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_attack": [[447, 491], ["utils.get_npz_attack", "numpy.load"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_attack"], ["", "def", "load_attack", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ")", ":", "\n", "    ", "\"\"\"\n    Return saved adversarial samples.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n\n    Returns\n    -------\n    x : np.ndarray, shape as [n_sample, *input_shape]\n        adversarial samples.\n\n    \"\"\"", "\n", "npz", "=", "get_npz_attack", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ")", "\n", "with", "np", ".", "load", "(", "npz", ",", "allow_pickle", "=", "True", ")", "as", "data", ":", "\n", "        ", "x", "=", "data", "[", "'x'", "]", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_output": [[493, 541], ["utils.get_npz_output", "numpy.load"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_output"], ["", "def", "load_output", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Return saved outputs of neural networks.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n\n    Returns\n    -------\n    output : np.ndarray, shape [repeat, n_sample, n_choice]\n        outputs of neural networks.\n\n    \"\"\"", "\n", "npz", "=", "get_npz_output", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ")", "\n", "with", "np", ".", "load", "(", "npz", ",", "allow_pickle", "=", "True", ")", "as", "data", ":", "\n", "        ", "output", "=", "data", "[", "'output'", "]", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_trial": [[543, 610], ["task.load_output", "numpy.random.choice", "numpy.concatenate", "numpy.repeat", "numpy.moveaxis", "task.get_y"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_output", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_y"], ["", "def", "get_trial", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ",", "\n", "repeat", ":", "int", "=", "100", ",", "\n", "len_trial", ":", "int", "=", "25", ",", "\n", "n_trial", ":", "int", "=", "10", ")", ":", "\n", "    ", "\"\"\"\n    Return trials of neural networks prediction for bayesian inference.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is 1.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100.\n    len_trial : int, optional\n        length of each trial. The default is 25.\n    n_trial : int, optional\n        number of trials for each sample. The default is 10.\n\n    Returns\n    -------\n    trial : np.ndarray, shape as [n_sample*n_trial, len_trial, n_choice]\n        trials for decision process.\n    y : np.ndarray, shape as [n_sample*n_trial]\n        true labels of each trial.\n\n    \"\"\"", "\n", "\n", "output", "=", "load_output", "(", "dataset", ",", "\n", "architecture", ",", "\n", "index", ",", "\n", "dropout_train", ",", "\n", "dropout_test", ",", "\n", "method", ",", "\n", "epsilon", ",", "\n", "subset", ",", "\n", "proportion", ",", "\n", "repeat", ")", "\n", "n_repeat", ",", "n_sample", ",", "n_choice", "=", "output", ".", "shape", "\n", "idx_timestep", "=", "np", ".", "random", ".", "choice", "(", "n_repeat", ",", "[", "n_trial", ",", "len_trial", "]", ")", "\n", "trial", "=", "np", ".", "concatenate", "(", "np", ".", "moveaxis", "(", "output", "[", "idx_timestep", "]", ",", "-", "2", ",", "0", ")", ")", "\n", "y", "=", "np", ".", "repeat", "(", "get_y", "(", "dataset", ",", "subset", ",", "proportion", ")", ",", "n_trial", ")", "\n", "\n", "return", "trial", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_output_of_category": [[612, 670], ["task.load_output", "task.get_y", "range", "output_of_category.append", "numpy.max", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_output", "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.get_y"], ["", "def", "get_output_of_category", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout_train", ":", "float", "=", "0", ",", "\n", "dropout_test", ":", "float", "=", "0", ",", "\n", "method", ":", "str", "=", "'clean'", ",", "\n", "epsilon", ":", "float", "=", "0", ",", "\n", "subset", ":", "str", "=", "'test'", ",", "\n", "proportion", ":", "float", "=", "1", ",", "\n", "repeat", ":", "int", "=", "100", ")", ":", "\n", "    ", "\"\"\"\n    Return neural network outputs of each category for likelihood acquisition.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout_train : float, optional\n        dropout rate at training phase. The default is 0.\n    dropout_test : float, optional\n        dropout rate at test phase. The default is 0.\n    method : str, optional\n        adversarial attack method. The default is 'clean'.\n    epsilon : float, optional\n        perturbation threshold of attacks. The default is 0.\n    subset : str, optional\n        subset of dataset. The default is 'test'.\n    proportion : float, optional\n        proportion of subset data. The default is 1.\n    repeat : int, optional\n        number of neural network prediction of each sample. The default is 100\n\n    Returns\n    -------\n    output_of_category : list of np.ndarray, shape as [n_choice][repeat*n_sample, n_choice]\n        neural network outputs of each category.\n\n    \"\"\"", "\n", "output", "=", "load_output", "(", "dataset", ",", "\n", "architecture", ",", "\n", "index", ",", "\n", "dropout_train", ",", "\n", "dropout_test", ",", "\n", "method", ",", "\n", "epsilon", ",", "\n", "subset", ",", "\n", "proportion", ",", "\n", "repeat", ")", "\n", "y", "=", "get_y", "(", "dataset", ",", "subset", ",", "proportion", ")", "\n", "output_of_category", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "np", ".", "max", "(", "y", ")", "+", "1", ")", ":", "\n", "        ", "idx", "=", "y", "==", "i", "\n", "output_of_category", ".", "append", "(", "np", ".", "concatenate", "(", "output", "[", ":", ",", "idx", "]", ")", ")", "\n", "", "return", "output_of_category", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_likelihood": [[672, 725], ["utils.get_npz_likelihood", "numpy.load"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_likelihood"], ["", "def", "load_likelihood", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ",", "\n", "n_channel", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Return saved likelihood.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n    n_channel : int\n        number of channel in outputs to used for likelihood estimation.\n\n    Returns\n    -------\n    combination : np.ndarray, shape as [n_combination, n_channel]\n        all possible combinations of discretized outputs.\n    likelihood : np.ndarray, shape as [n_combination, n_choice]\n        likelihood of each discretized output when input belongs to certain true label.\n\n    \"\"\"", "\n", "npz", "=", "get_npz_likelihood", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "\n", "method", ",", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ",", "n_channel", ")", "\n", "with", "np", ".", "load", "(", "npz", ",", "allow_pickle", "=", "True", ")", "as", "data", ":", "\n", "        ", "likelihood", "=", "data", "[", "'likelihood'", "]", "\n", "\n", "", "return", "likelihood", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_bayes": [[727, 801], ["utils.get_npz_bayes", "numpy.load"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_bayes"], ["", "def", "load_bayes", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ",", "\n", "len_trial", ":", "int", ",", "\n", "n_trial", ":", "int", ",", "\n", "boundary", ":", "float", ",", "\n", "n_channel", ":", "int", ",", "\n", "likelihood_method", ":", "list", ",", "\n", "likelihood_epsilon", ":", "list", ")", ":", "\n", "    ", "\"\"\"\n    Return saved bayesian inference results.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n    len_trial : int\n        length of each trial.\n    n_trial : int\n        number of trials for each sample.\n    boundary : float\n        posterior belief decision boundary.\n    n_channel : int\n        number of channel for likelihood estimation.\n    likelihood_method: list\n        strings of attack methods for likelihood estimation.\n    likelihood_epsilon: list\n        floats of attack epsilons for likelihood estimation.\n\n    Returns\n    -------\n    response_time : np.ndarray, shape as [n_sample*n_trial]\n        number of timesteps needed to make the decision.\n    choice : np.ndarray, shape as [n_sample*n_trial]\n        final decisions made by bayesian inference.\n    evidence : np.ndarray, shape as [n_sample*n_trial, len_trial, n_choice]\n        all posterior probabilities through the process of bayesian inference.\n\n    \"\"\"", "\n", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "\n", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", ",", "\n", "n_channel", ",", "likelihood_method", ",", "likelihood_epsilon", "]", "\n", "npz", "=", "get_npz_bayes", "(", "*", "args", ")", "\n", "with", "np", ".", "load", "(", "npz", ",", "allow_pickle", "=", "True", ")", "as", "data", ":", "\n", "        ", "evidence", "=", "data", "[", "'evidence'", "]", "\n", "response_time", "=", "data", "[", "'response_time'", "]", "\n", "choice", "=", "data", "[", "'choice'", "]", "\n", "\n", "", "return", "response_time", ",", "choice", ",", "evidence", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_cumsum": [[803, 867], ["utils.get_npz_cumsum", "numpy.load"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_cumsum"], ["", "def", "load_cumsum", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ",", "\n", "len_trial", ":", "int", ",", "\n", "n_trial", ":", "int", ",", "\n", "boundary", ":", "float", ",", ")", ":", "\n", "    ", "\"\"\"\n    Return saved Cumsum inference results.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n    len_trial : int\n        length of each trial.\n    n_trial : int\n        number of trials for each sample.\n    boundary : float\n        posterior belief decision boundary.\n\n    Returns\n    -------\n    response_time : np.ndarray, shape as [n_sample*n_trial]\n        number of timesteps needed to make the decision.\n    choice : np.ndarray, shape as [n_sample*n_trial]\n        final decisions made by cumsum inference.\n    evidence : np.ndarray, shape as [n_sample*n_trial, len_trial, n_choice]\n        all summed prediciton through the process of cumsum inference.\n\n    \"\"\"", "\n", "args", "=", "[", "dataset", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "\n", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", "]", "\n", "npz", "=", "get_npz_cumsum", "(", "*", "args", ")", "\n", "with", "np", ".", "load", "(", "npz", ",", "allow_pickle", "=", "True", ")", "as", "data", ":", "\n", "        ", "evidence", "=", "data", "[", "'evidence'", "]", "\n", "response_time", "=", "data", "[", "'response_time'", "]", "\n", "choice", "=", "data", "[", "'choice'", "]", "\n", "\n", "", "return", "response_time", ",", "choice", ",", "evidence", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.task.load_acc": [[870, 891], ["utils.get_npz", "numpy.load"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz"], ["", "def", "load_acc", "(", "mode", ":", "str", ",", "*", "args", ":", "list", ")", ":", "\n", "    ", "\"\"\"\n    Return accuracy of given saved results.\n\n    Parameters\n    ----------\n    mode : str\n        type of data, one of [ attack | bayes ].\n    *args : list\n        other arguments of desired `.npz` file, depend on `utils.get_npz_mode()`.\n\n    Returns\n    -------\n    acc : float\n        accuracy of given saved results.\n\n    \"\"\"", "\n", "npz", "=", "get_npz", "(", "mode", ",", "*", "args", ")", "\n", "with", "np", ".", "load", "(", "npz", ",", "allow_pickle", "=", "True", ")", "as", "data", ":", "\n", "        ", "acc", "=", "data", "[", "'acc'", "]", "[", "0", "]", "\n", "", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir": [[16, 35], ["None"], "function", ["None"], ["def", "get_dir", "(", "dataset", ":", "str", "=", "'mnist'", ",", "subdir", ":", "str", "=", "'model'", ")", ":", "\n", "    ", "\"\"\"\n    Return path of subdir in ./data/.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    subdir : str, optional\n        name of sub-directory. The default is 'model'.\n\n    Returns\n    -------\n    path : str\n        path of subdir in ./data/.\n\n    \"\"\"", "\n", "path", "=", "'/'", ".", "join", "(", "[", "'data'", ",", "dataset", ",", "subdir", ",", "''", "]", ")", "\n", "return", "path", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.mkdir_databackup": [[37, 51], ["os.listdir", "os.mkdir", "os.mkdir"], "function", ["None"], ["", "def", "mkdir_databackup", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create empty directories of ./data/ and ./backup/ if not existing.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "path", "=", "listdir", "(", ")", "\n", "if", "'data'", "not", "in", "path", ":", "\n", "        ", "mkdir", "(", "'data'", ")", "\n", "", "if", "'backup'", "not", "in", "path", ":", "\n", "        ", "mkdir", "(", "'backup'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.mkdir_dataset": [[53, 76], ["os.listdir", "print", "os.mkdir", "os.mkdir", "utils.get_dir"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir"], ["", "", "def", "mkdir_dataset", "(", "dataset", ":", "str", "=", "'mnist'", ")", ":", "\n", "    ", "\"\"\"\n    Create empty directories in ./data/ for data storage.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "path", "=", "listdir", "(", "'data'", ")", "\n", "if", "dataset", "not", "in", "path", ":", "\n", "        ", "print", "(", "'Creating Directories for'", ",", "dataset", ")", "\n", "dir_dataset", "=", "'data/'", "+", "dataset", "\n", "mkdir", "(", "dir_dataset", ")", "\n", "subdir", "=", "[", "'model'", ",", "'figure'", ",", "'attack'", ",", "'output'", ",", "'likelihood'", ",", "'bayes'", ",", "\n", "'others'", ",", "'cumsum'", "]", "\n", "for", "i", "in", "subdir", ":", "\n", "            ", "mkdir", "(", "get_dir", "(", "dataset", ",", "i", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_pt_model": [[78, 105], ["utils.get_dir", "str", "str"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir"], ["", "", "", "def", "get_pt_model", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout", ":", "float", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Return path of pytorch model `.pt` file.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout : float, optional\n        dropout rate at training phase. The default is 0.\n\n    Returns\n    -------\n    pt : str\n        path of pytorch model `.pt` file.\n\n    \"\"\"", "\n", "d", "=", "get_dir", "(", "dataset", ",", "'model'", ")", "\n", "pt", "=", "d", "+", "'_'", ".", "join", "(", "[", "architecture", ",", "str", "(", "index", ")", ",", "str", "(", "dropout", ")", "]", ")", "+", "'.pt'", "\n", "return", "pt", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_txt_trainlog": [[107, 134], ["utils.get_dir", "str", "str"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir"], ["", "def", "get_txt_trainlog", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout", ":", "float", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Return path of model training log `.txt` file.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout : float, optional\n        dropout rate at training phase. The default is 0.\n\n    Returns\n    -------\n    txt : str\n        path of model training log `.txt` file.\n\n    \"\"\"", "\n", "d", "=", "get_dir", "(", "dataset", ",", "'model'", ")", "\n", "txt", "=", "d", "+", "'_'", ".", "join", "(", "[", "architecture", ",", "str", "(", "index", ")", ",", "str", "(", "dropout", ")", "]", ")", "+", "'.txt'", "\n", "return", "txt", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.update_trainlog": [[136, 168], ["utils.get_txt_trainlog", "open", "f.write"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_txt_trainlog"], ["", "def", "update_trainlog", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "architecture", ":", "str", "=", "'cnn'", ",", "\n", "index", ":", "int", "=", "0", ",", "\n", "dropout", ":", "float", "=", "0", ",", "\n", "line", ":", "str", "=", "''", ",", "\n", "mode", ":", "str", "=", "'a'", ")", ":", "\n", "    ", "\"\"\"\n    Write meassage in training log.\n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    architecture : str, optional\n        architecture of the neural network. The default is 'cnn'.\n    index : int, optional\n        index of data to return. The default is 0.\n    dropout : float, optional\n        dropout rate at training phase. The default is 0.\n    line : str, optional\n        training message to be looged. The default is ''.\n    mode : str, optional\n        mode of opening file. The default is 'a'.\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "txt", "=", "get_txt_trainlog", "(", "dataset", ",", "architecture", ",", "index", ",", "dropout", ")", "\n", "with", "open", "(", "txt", ",", "mode", ")", "as", "f", ":", "\n", "        ", "f", ".", "write", "(", "line", "+", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.args2npz": [[170, 193], ["utils.get_dir", "str"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir"], ["", "", "def", "args2npz", "(", "dataset", ":", "str", ",", "subdir", ":", "str", ",", "args", ":", "list", ")", ":", "\n", "    ", "\"\"\"\n    Return path of `.npz` file\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    subdir : str\n        name of sub-directory.\n    args : list\n        other arguments of desired `.npz` file.\n\n    Returns\n    -------\n    npz : str\n        path of `.npz` file.\n\n    \"\"\"", "\n", "d", "=", "get_dir", "(", "dataset", ",", "subdir", ")", "\n", "npz", "=", "'_'", ".", "join", "(", "[", "str", "(", "i", ")", "for", "i", "in", "args", "]", ")", "\n", "npz", "=", "d", "+", "npz", "+", "'.npz'", "\n", "return", "npz", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_attack": [[195, 238], ["utils.args2npz"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.args2npz"], ["", "def", "get_npz_attack", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ")", ":", "\n", "    ", "\"\"\"\n    Return path of `.npz` file that contains adversarial samples.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n\n    Returns\n    -------\n    npz : str\n        path of `.npz` file.\n\n    \"\"\"", "\n", "args", "=", "[", "'attack'", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "epsilon", ",", "\n", "subset", ",", "proportion", "]", "\n", "npz", "=", "args2npz", "(", "dataset", ",", "'attack'", ",", "args", ")", "\n", "return", "npz", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_output": [[240, 286], ["utils.args2npz"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.args2npz"], ["", "def", "get_npz_output", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Return path of `.npz` file that contains outputs of neural networks.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n\n    Returns\n    -------\n    npz : str\n        path of `.npz` file.\n\n    \"\"\"", "\n", "args", "=", "[", "'output'", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "epsilon", ",", "\n", "subset", ",", "proportion", ",", "repeat", "]", "\n", "npz", "=", "args2npz", "(", "dataset", ",", "'output'", ",", "args", ")", "\n", "return", "npz", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_likelihood": [[288, 337], ["utils.args2npz"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.args2npz"], ["", "def", "get_npz_likelihood", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ",", "\n", "n_channel", ":", "int", ")", ":", "\n", "    ", "\"\"\"\n    Return path of `.npz` file that contains estimated likelihood.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n    n_channel : int\n        number of channel in outputs to used for likelihood estimation.\n\n    Returns\n    -------\n    npz : str\n        path of `.npz` file.\n\n    \"\"\"", "\n", "args", "=", "[", "'likelihood'", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "\n", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ",", "n_channel", "]", "\n", "npz", "=", "args2npz", "(", "dataset", ",", "'likelihood'", ",", "args", ")", "\n", "return", "npz", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_bayes": [[339, 400], ["utils.args2npz"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.args2npz"], ["", "def", "get_npz_bayes", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ",", "\n", "len_trial", ":", "int", ",", "\n", "n_trial", ":", "int", ",", "\n", "boundary", ":", "float", ",", "\n", "n_channel", ":", "int", ",", "\n", "likelihood_method", ":", "list", ",", "\n", "likelihood_epsilon", ":", "list", ")", ":", "\n", "    ", "\"\"\"\n    Return path of `.npz` file that contains bayesian inference results.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n    len_trial : int\n        length of each trial.\n    n_trial : int\n        number of trials for each sample.\n    boundary : float\n        posterior belief decision boundary.\n    n_channel : int\n        number of channel for likelihood estimation.\n\n    Returns\n    -------\n    npz : str\n        path of `.npz` file.\n\n    \"\"\"", "\n", "args", "=", "[", "'bayes'", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "\n", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", ",", "\n", "n_channel", ",", "likelihood_method", ",", "likelihood_epsilon", "]", "\n", "npz", "=", "args2npz", "(", "dataset", ",", "'bayes'", ",", "args", ")", "\n", "return", "npz", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz_cumsum": [[402, 458], ["utils.args2npz"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.args2npz"], ["", "def", "get_npz_cumsum", "(", "dataset", ":", "str", ",", "\n", "architecture", ":", "str", ",", "\n", "index", ":", "int", ",", "\n", "dropout_train", ":", "float", ",", "\n", "dropout_test", ":", "float", ",", "\n", "method", ":", "str", ",", "\n", "epsilon", ":", "float", ",", "\n", "subset", ":", "str", ",", "\n", "proportion", ":", "float", ",", "\n", "repeat", ":", "int", ",", "\n", "len_trial", ":", "int", ",", "\n", "n_trial", ":", "int", ",", "\n", "boundary", ":", "float", ")", ":", "\n", "    ", "\"\"\"\n    Return path of `.npz` file that contains bayesian inference results.\n\n    Parameters\n    ----------\n    dataset : str\n        name of dataset.\n    architecture : str\n        architecture of the neural network.\n    index : int\n        index of data to return.\n    dropout_train : float\n        dropout rate at training phase.\n    dropout_test : float\n        dropout rate at test phase.\n    method : str\n        adversarial attack method.\n    epsilon : float\n        perturbation threshold of attacks.\n    subset : str\n        subset of dataset.\n    proportion : float\n        proportion of subset data.\n    repeat : int\n        number of neural network prediction of each sample.\n    len_trial : int\n        length of each trial.\n    n_trial : int\n        number of trials for each sample.\n    boundary : float\n        posterior belief decision boundary.\n\n\n    Returns\n    -------\n    npz : str\n        path of `.npz` file.\n\n    \"\"\"", "\n", "args", "=", "[", "'cumsum'", ",", "architecture", ",", "index", ",", "dropout_train", ",", "dropout_test", ",", "method", ",", "\n", "epsilon", ",", "subset", ",", "proportion", ",", "repeat", ",", "len_trial", ",", "n_trial", ",", "boundary", "]", "\n", "npz", "=", "args2npz", "(", "dataset", ",", "'cumsum'", ",", "args", ")", "\n", "return", "npz", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_npz": [[460, 480], ["eval"], "function", ["None"], ["", "def", "get_npz", "(", "mode", ":", "str", ",", "*", "args", ":", "list", ")", ":", "\n", "    ", "\"\"\"\n    Convenient function to return path of `.npz` file.\n\n    Parameters\n    ----------\n    mode : str\n        type of `.npz` path to return, one of [ attack | output | likelihood | bayes ].\n    *args : list\n        other arguments of desired `.npz` file, depend on `get_npz_mode()`.\n\n    Returns\n    -------\n    npz : str\n        path of `.npz` file.\n\n    \"\"\"", "\n", "string_func", "=", "'_'", ".", "join", "(", "[", "'get_npz'", ",", "mode", "]", ")", "\n", "npz", "=", "eval", "(", "string_func", ")", "(", "*", "args", ")", "\n", "return", "npz", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.backup_script": [[482, 496], ["os.mkdir", "print", "str", "shutil.copyfile", "os.listdir", "datetime.datetime.now"], "function", ["None"], ["", "def", "backup_script", "(", ")", ":", "\n", "    ", "\"\"\"\n    Copy all .py files to a time-tagged directory in backup/ .\n\n    Returns\n    -------\n    None.\n\n    \"\"\"", "\n", "script", "=", "[", "i", "for", "i", "in", "listdir", "(", ")", "if", "'.py'", "in", "i", "]", "\n", "backup_dir", "=", "'backup/'", "+", "str", "(", "datetime", ".", "now", "(", ")", ")", "\n", "mkdir", "(", "backup_dir", ")", "\n", "[", "copyfile", "(", "i", ",", "'/'", ".", "join", "(", "[", "backup_dir", ",", "i", "]", ")", ")", "for", "i", "in", "script", "]", "\n", "print", "(", "'all scripts back-upped at'", ",", "backup_dir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_svgpng_heatmap": [[498, 535], ["utils.get_dir", "str", "utils.get_svgpng_heatmap.get_svgpng"], "function", ["home.repos.pwc.inspect_result.xiyuan68_dddm.None.utils.get_dir"], ["", "def", "get_svgpng_heatmap", "(", "dataset", ":", "str", "=", "'mnist'", ",", "\n", "method", ":", "list", "=", "[", "'clean'", "]", ",", "\n", "mode", ":", "str", "=", "'attack'", ",", "\n", "likelihood_method", ":", "list", "=", "[", "'clean'", "]", ")", ":", "\n", "    ", "\"\"\"\n    \n\n    Parameters\n    ----------\n    dataset : str, optional\n        name of dataset. The default is 'mnist'.\n    method : list, optional\n        attack methods. The default is ['clean'].\n    mode : str, optional\n        name of defense method, should be chosen from [attack|cumsum|bayes]. \n        when assign 'attack', it means model defense solely by dropout.\n        The default is 'attack'.\n    likelihood_method : list, optional\n        strings of attack methods for likelihood estimation, only for bayes inference. \n        The default is ['clean'].\n\n    Returns\n    -------\n    svg_heatmap: list\n        .svg paths for each heatmpa.\n    png_heatmap: list\n        .png paths for each heatmpa.\n\n    \"\"\"", "\n", "dir_figure", "=", "get_dir", "(", "dataset", ",", "'figure'", ")", "\n", "mode", "=", "'dropout'", "if", "mode", "==", "'attack'", "else", "mode", "\n", "likelihood_method", "=", "'none'", "if", "mode", "!=", "'bayes'", "else", "str", "(", "likelihood_method", ")", "\n", "def", "get_svgpng", "(", "m", ",", "suffix", "=", "'svg'", ")", ":", "\n", "        ", "return", "'.'", ".", "join", "(", "[", "'heatmap'", ",", "mode", ",", "m", ",", "likelihood_method", ",", "suffix", "]", ")", "\n", "", "svg_heatmap", "=", "[", "dir_figure", "+", "get_svgpng", "(", "i", ",", "'svg'", ")", "for", "i", "in", "method", "]", "\n", "png_heatmap", "=", "[", "dir_figure", "+", "get_svgpng", "(", "i", ",", "'png'", ")", "for", "i", "in", "method", "]", "\n", "return", "svg_heatmap", ",", "png_heatmap", "\n", "\n"]]}