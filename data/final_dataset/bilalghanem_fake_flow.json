{"home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.read_data.prepare_input": [[12, 30], ["pandas.read_csv", "data.utils.split", "features.building_features.manual_features().transform", "features.building_features.segmentation_text().transform", "content[].map", "features.building_features.manual_features", "features.building_features.segmentation_text", "features.building_features.clean_regex"], "function", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.transform", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.transform", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.manual_features", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.clean_regex"], ["def", "prepare_input", "(", "dataset", "=", "'MultiSourceFake'", ",", "segments_number", "=", "10", ",", "n_jobs", "=", "-", "1", ",", "emo_rep", "=", "'frequency'", ",", "return_features", "=", "True", ",", "\n", "text_segments", "=", "False", ",", "clean_text", "=", "True", ")", ":", "\n", "\n", "    ", "content", "=", "pd", ".", "read_csv", "(", "'./data/{}/sample.csv'", ".", "format", "(", "dataset", ")", ")", "\n", "content_features", "=", "[", "]", "\n", "\"\"\"Extract features, segment text, clean it.\"\"\"", "\n", "if", "return_features", ":", "\n", "        ", "content_features", "=", "manual_features", "(", "n_jobs", "=", "n_jobs", ",", "path", "=", "'./features'", ",", "model_name", "=", "dataset", ",", "\n", "segments_number", "=", "segments_number", ",", "emo_rep", "=", "emo_rep", ")", ".", "transform", "(", "content", "[", "'content'", "]", ")", "\n", "\n", "", "\"\"\"In segmentation we already clean the text to keep the DOTS (.) only.\"\"\"", "\n", "if", "text_segments", ":", "\n", "        ", "content", "[", "'content'", "]", "=", "segmentation_text", "(", "segments_number", "=", "segments_number", ")", ".", "transform", "(", "content", "[", "'content'", "]", ")", "\n", "", "elif", "clean_text", ":", "\n", "        ", "content", "[", "'content'", "]", "=", "content", "[", "'content'", "]", ".", "map", "(", "lambda", "text", ":", "clean_regex", "(", "text", ",", "keep_dot", "=", "True", ")", ")", "\n", "\n", "", "train", ",", "dev", ",", "test", "=", "split", "(", "content", ",", "content_features", ",", "return_features", ")", "\n", "return", "train", ",", "dev", ",", "test", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.__init__": [[50, 85], ["sklearn.preprocessing.LabelEncoder", "fake_flow.fake_flow.labelencoder.fit", "keras.preprocessing.text.Tokenizer", "int", "model_name.split"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.fit", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split"], ["    ", "def", "__init__", "(", "self", ",", "model_name", ",", "SHUFFLE", "=", "False", ")", ":", "\n", "# Settings", "\n", "        ", "self", ".", "scoring", "=", "'f1'", "\n", "self", ".", "verbose", "=", "1", "\n", "self", ".", "SHUFFLE", "=", "SHUFFLE", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "search", "=", "False", "\n", "self", ".", "summary_table", "=", "{", "}", "\n", "self", ".", "labelencoder", "=", "LabelEncoder", "(", ")", "\n", "self", ".", "labelencoder", ".", "fit", "(", "[", "'a'", "]", ")", "\n", "\n", "self", ".", "parameters", "=", "{", "'rnn_size'", ":", "8", ",", "\n", "'activation_rnn'", ":", "'tanh'", ",", "\n", "\n", "'num_filters'", ":", "16", ",", "\n", "'filter_sizes'", ":", "(", "2", ",", "3", ",", "4", ")", ",", "\n", "'pool_size'", ":", "3", ",", "\n", "'activation_cnn'", ":", "'relu'", ",", "\n", "\n", "'dense_1'", ":", "8", ",", "\n", "'activation_attention'", ":", "'softmax'", ",", "\n", "'dense_2'", ":", "8", ",", "\n", "'dense_3'", ":", "8", ",", "\n", "'dropout'", ":", "0.3910", ",", "\n", "'optimizer'", ":", "'adam'", ",", "\n", "\n", "'max_senten_len'", ":", "500", ",", "\n", "'max_senten_num'", ":", "int", "(", "model_name", ".", "split", "(", "'_'", ")", "[", "1", "]", ")", ",", "\n", "'vocab'", ":", "1000000", ",", "\n", "'embedding_path'", ":", "'./GoogleNews-vectors-negative300.bin'", ",", "\n", "'embeddingSize'", ":", "300", ",", "\n", "'max_epoch'", ":", "50", ",", "\n", "'batch_size'", ":", "16", ",", "\n", "}", "\n", "self", ".", "tokenizer", "=", "Tokenizer", "(", "num_words", "=", "self", ".", "parameters", "[", "'vocab'", "]", ",", "oov_token", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.shuffle_along_axis": [[86, 94], ["sklearn.utils.shuffle", "numpy.array", "numpy.array", "range", "item.split", "a[].tolist"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split"], ["", "def", "shuffle_along_axis", "(", "self", ",", "a", ")", ":", "\n", "        ", "idx", "=", "[", "item", "for", "item", "in", "range", "(", "a", "[", "'features'", "]", ".", "shape", "[", "1", "]", ")", "]", "\n", "idx", "=", "shuffle", "(", "idx", ",", "random_state", "=", "0", ")", "\n", "a", "[", "'features'", "]", "=", "a", "[", "'features'", "]", "[", ":", ",", "idx", ",", ":", "]", "\n", "a", "[", "'text'", "]", "=", "np", ".", "array", "(", "[", "item", ".", "split", "(", "'.'", ")", "for", "item", "in", "a", "[", "'text'", "]", "]", ")", "\n", "a", "[", "'text'", "]", "=", "a", "[", "'text'", "]", "[", ":", ",", "idx", "]", "\n", "a", "[", "'text'", "]", "=", "np", ".", "array", "(", "[", "' . '", ".", "join", "(", "item", ")", "for", "item", "in", "a", "[", "'text'", "]", ".", "tolist", "(", ")", "]", ")", "\n", "return", "a", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.prepare_input": [[95, 115], ["fake_flow.fake_flow.train[].tolist", "fake_flow.fake_flow.dev[].tolist", "fake_flow.fake_flow.test[].tolist", "fake_flow.fake_flow.tokenizer.fit_on_texts", "fake_flow.fake_flow.preprocessing", "fake_flow.fake_flow.preprocessing", "fake_flow.fake_flow.preprocessing", "fake_flow.fake_flow.prep_embed", "fake_flow.fake_flow.shuffle_along_axis", "fake_flow.fake_flow.shuffle_along_axis", "fake_flow.fake_flow.shuffle_along_axis", "len"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.preprocessing", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.preprocessing", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.preprocessing", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.prep_embed", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.shuffle_along_axis", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.shuffle_along_axis", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.shuffle_along_axis"], ["", "def", "prepare_input", "(", "self", ",", "train", ",", "dev", ",", "test", ")", ":", "\n", "        ", "if", "self", ".", "SHUFFLE", "==", "True", ":", "\n", "            ", "train", "=", "self", ".", "shuffle_along_axis", "(", "train", ")", "\n", "dev", "=", "self", ".", "shuffle_along_axis", "(", "dev", ")", "\n", "test", "=", "self", ".", "shuffle_along_axis", "(", "test", ")", "\n", "self", ".", "model_name", "+=", "'_shuffled'", "\n", "\n", "", "self", ".", "train", ",", "self", ".", "dev", ",", "self", ".", "test", "=", "train", ",", "dev", ",", "test", "\n", "self", ".", "train", "[", "'text'", "]", "=", "self", ".", "train", "[", "'text'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "dev", "[", "'text'", "]", "=", "self", ".", "dev", "[", "'text'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "test", "[", "'text'", "]", "=", "self", ".", "test", "[", "'text'", "]", ".", "tolist", "(", ")", "\n", "\n", "self", ".", "tokenizer", ".", "fit_on_texts", "(", "self", ".", "train", "[", "'text'", "]", "+", "self", ".", "dev", "[", "'text'", "]", "+", "self", ".", "test", "[", "'text'", "]", ")", "\n", "self", ".", "parameters", "[", "'vocab'", "]", "=", "len", "(", "self", ".", "tokenizer", ".", "word_counts", ")", "+", "1", "\n", "\n", "self", ".", "train", "[", "'text'", "]", ",", "self", ".", "train", "[", "'label'", "]", "=", "self", ".", "preprocessing", "(", "train", "[", "'text'", "]", ",", "train", "[", "'label'", "]", ")", "\n", "self", ".", "dev", "[", "'text'", "]", ",", "self", ".", "dev", "[", "'label'", "]", "=", "self", ".", "preprocessing", "(", "dev", "[", "'text'", "]", ",", "dev", "[", "'label'", "]", ")", "\n", "self", ".", "test", "[", "'text'", "]", ",", "self", ".", "test", "[", "'label'", "]", "=", "self", ".", "preprocessing", "(", "test", "[", "'text'", "]", ",", "test", "[", "'label'", "]", ")", "\n", "\n", "self", ".", "prep_embed", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.preprocessing": [[116, 146], ["tqdm.tqdm.tqdm", "numpy.zeros", "tqdm.tqdm.tqdm", "fake_flow.fake_flow.preparing_labels", "range", "nltk.tokenize.sent_tokenize", "max", "paras.append", "enumerate", "enumerate", "len", "len", "print", "len", "len", "len", "len", "sent.split", "keras.preprocessing.text.text_to_word_sequence", "enumerate"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.preparing_labels", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split"], ["", "def", "preprocessing", "(", "self", ",", "text", ",", "label", ")", ":", "\n", "        ", "\"\"\"Preprocessing of the text to make it more resonant for training\n        \"\"\"", "\n", "paras", "=", "[", "]", "\n", "max_sent_num", "=", "0", "\n", "max_sent_len", "=", "0", "\n", "for", "idx", "in", "tqdm", "(", "range", "(", "len", "(", "text", ")", ")", ",", "desc", "=", "'Tokenizing text'", ")", ":", "\n", "            ", "sentences", "=", "tokenize", ".", "sent_tokenize", "(", "text", "[", "idx", "]", ")", "\n", "if", "len", "(", "sentences", ")", ">", "45", ":", "\n", "                ", "print", "(", ")", "\n", "", "if", "len", "(", "sentences", ")", ">", "max_sent_num", ":", "\n", "                ", "max_sent_num", "=", "len", "(", "sentences", ")", "\n", "", "tmp", "=", "[", "len", "(", "sent", ".", "split", "(", ")", ")", "for", "sent", "in", "sentences", "]", "\n", "sent_len", "=", "max", "(", "tmp", ")", "\n", "if", "sent_len", ">", "max_sent_len", ":", "\n", "                ", "max_sent_len", "=", "sent_len", "\n", "", "paras", ".", "append", "(", "sentences", ")", "\n", "\n", "", "data", "=", "np", ".", "zeros", "(", "(", "len", "(", "text", ")", ",", "self", ".", "parameters", "[", "'max_senten_num'", "]", ",", "self", ".", "parameters", "[", "'max_senten_len'", "]", ")", ",", "dtype", "=", "'int32'", ")", "\n", "for", "i", ",", "sentences", "in", "tqdm", "(", "enumerate", "(", "paras", ")", ",", "desc", "=", "'Preparing input matrix'", ")", ":", "\n", "            ", "for", "j", ",", "sent", "in", "enumerate", "(", "sentences", ")", ":", "\n", "                ", "if", "j", "<", "self", ".", "parameters", "[", "'max_senten_num'", "]", ":", "\n", "                    ", "wordTokens", "=", "text_to_word_sequence", "(", "sent", ")", "\n", "k", "=", "0", "\n", "for", "_", ",", "word", "in", "enumerate", "(", "wordTokens", ")", ":", "\n", "                        ", "if", "k", "<", "self", ".", "parameters", "[", "'max_senten_len'", "]", "and", "word", "in", "self", ".", "tokenizer", ".", "word_index", "and", "self", ".", "tokenizer", ".", "word_index", "[", "word", "]", "<", "self", ".", "parameters", "[", "'vocab'", "]", ":", "\n", "                            ", "data", "[", "i", ",", "j", ",", "k", "]", "=", "self", ".", "tokenizer", ".", "word_index", "[", "word", "]", "\n", "k", "=", "k", "+", "1", "\n", "", "", "", "", "", "labels", "=", "self", ".", "preparing_labels", "(", "label", ")", "\n", "return", "data", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.preparing_labels": [[147, 157], ["numpy.array", "fake_flow.fake_flow.astype", "keras.utils.to_categorical", "fake_flow.fake_flow.labelencoder.transform", "len", "len", "fake_flow.fake_flow.labelencoder.fit", "fake_flow.fake_flow.labelencoder.classes_.tolist", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.transform", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.fit"], ["", "def", "preparing_labels", "(", "self", ",", "y", ")", ":", "\n", "        ", "y", "=", "np", ".", "array", "(", "y", ")", "\n", "y", "=", "y", ".", "astype", "(", "str", ")", "\n", "if", "y", ".", "dtype", ".", "type", "==", "np", ".", "array", "(", "[", "'a'", "]", ")", ".", "dtype", ".", "type", ":", "\n", "            ", "if", "len", "(", "self", ".", "labelencoder", ".", "classes_", ")", "<", "2", ":", "\n", "                ", "self", ".", "labelencoder", ".", "fit", "(", "y", ")", "\n", "self", ".", "Labels", "=", "self", ".", "labelencoder", ".", "classes_", ".", "tolist", "(", ")", "\n", "", "y", "=", "self", ".", "labelencoder", ".", "transform", "(", "y", ")", "\n", "", "labels", "=", "to_categorical", "(", "y", ",", "len", "(", "self", ".", "Labels", ")", ")", "\n", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.prep_embed": [[158, 177], ["os.path.exists", "os.path.join", "numpy.load", "gensim.models.KeyedVectors.load_word2vec_format", "numpy.zeros", "tqdm.tqdm.tqdm", "numpy.save", "fake_flow.fake_flow.model_name.split", "os.path.join", "fake_flow.fake_flow.tokenizer.word_index.items", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split"], ["", "def", "prep_embed", "(", "self", ")", ":", "\n", "        ", "path", "=", "'./processed_files'", "\n", "filename", "=", "'{}.npy'", ".", "format", "(", "self", ".", "model_name", ".", "split", "(", "'_'", ")", "[", "0", "]", ")", "\n", "file", "=", "exists", "(", "join", "(", "path", ",", "filename", ")", ")", "\n", "if", "file", ":", "\n", "            ", "embedding_matrix", "=", "np", ".", "load", "(", "join", "(", "path", ",", "filename", ")", ")", "\n", "", "else", ":", "\n", "            ", "embeddings_index", "=", "gensim", ".", "models", ".", "KeyedVectors", ".", "load_word2vec_format", "(", "self", ".", "parameters", "[", "'embedding_path'", "]", ",", "binary", "=", "True", ")", "\n", "embedding_matrix", "=", "np", ".", "zeros", "(", "(", "self", ".", "parameters", "[", "'vocab'", "]", ",", "self", ".", "parameters", "[", "'embeddingSize'", "]", ")", ")", "\n", "\n", "for", "word", ",", "i", "in", "tqdm", "(", "self", ".", "tokenizer", ".", "word_index", ".", "items", "(", ")", ")", ":", "\n", "                ", "if", "i", ">=", "self", ".", "parameters", "[", "'vocab'", "]", ":", "\n", "                    ", "continue", "\n", "", "if", "word", "in", "embeddings_index", ":", "# .vocab", "\n", "                    ", "embedding_matrix", "[", "i", "]", "=", "embeddings_index", "[", "word", "]", "\n", "", "", "embeddings_index", "=", "{", "}", "\n", "np", ".", "save", "(", "join", "(", "path", ",", "filename", ")", ",", "embedding_matrix", ")", "\n", "\n", "", "self", ".", "embedding_matrix", "=", "embedding_matrix", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.Network": [[178, 224], ["keras.layers.Embedding", "keras.layers.Input", "keras.models.Model", "keras.layers.Input", "keras.layers.Embedding.", "keras.models.Model", "keras.layers.Input", "keras.layers.concatenate", "keras.layers.dot", "keras.models.Model", "keras.layers.Bidirectional", "keras.models.Model.summary", "conv_blocks.append", "keras.models.Model.summary", "keras.layers.TimeDistributed", "keras.layers.Dense", "keras.layers.Dense", "fake_flow.fake_flow.SeqSelfAttention", "keras.layers.Lambda", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.models.Model.summary", "keras.layers.GRU", "keras.layers.Convolution1D", "keras.layers.MaxPooling1D", "keras.layers.Flatten", "len", "keras.layers.Concatenate", "len", "keras.backend.mean"], "methods", ["None"], ["", "def", "Network", "(", "self", ")", ":", "\n", "        ", "Embed", "=", "Embedding", "(", "input_dim", "=", "self", ".", "parameters", "[", "'vocab'", "]", ",", "\n", "output_dim", "=", "self", ".", "parameters", "[", "'embeddingSize'", "]", ",", "\n", "input_length", "=", "self", ".", "parameters", "[", "'max_senten_len'", "]", ",", "\n", "trainable", "=", "True", ",", "\n", "weights", "=", "[", "self", ".", "embedding_matrix", "]", ",", "\n", "name", "=", "'Embed_Layer'", ")", "\n", "\n", "# Features:", "\n", "inp_features", "=", "Input", "(", "shape", "=", "(", "self", ".", "train", "[", "'features'", "]", ".", "shape", "[", "1", "]", ",", "self", ".", "train", "[", "'features'", "]", ".", "shape", "[", "2", "]", ")", ",", "name", "=", "'features_input'", ")", "\n", "flow_features", "=", "Bidirectional", "(", "GRU", "(", "self", ".", "parameters", "[", "'rnn_size'", "]", ",", "activation", "=", "self", ".", "parameters", "[", "'activation_rnn'", "]", ",", "return_sequences", "=", "True", ",", "name", "=", "'rnn'", ")", ")", "(", "inp_features", ")", "\n", "features", "=", "Model", "(", "inp_features", ",", "flow_features", ")", "\n", "if", "self", ".", "verbose", "==", "1", ":", "\n", "            ", "features", ".", "summary", "(", ")", "\n", "\n", "# WordEmbd", "\n", "", "word_input", "=", "Input", "(", "shape", "=", "(", "self", ".", "parameters", "[", "'max_senten_len'", "]", ",", ")", ",", "dtype", "=", "'float32'", ")", "\n", "z", "=", "Embed", "(", "word_input", ")", "\n", "conv_blocks", "=", "[", "]", "\n", "for", "sz", "in", "self", ".", "parameters", "[", "'filter_sizes'", "]", ":", "\n", "            ", "conv", "=", "Convolution1D", "(", "filters", "=", "self", ".", "parameters", "[", "'num_filters'", "]", ",", "kernel_size", "=", "sz", ",", "padding", "=", "\"valid\"", ",", "activation", "=", "self", ".", "parameters", "[", "'activation_cnn'", "]", ",", "strides", "=", "1", ")", "(", "z", ")", "\n", "conv", "=", "MaxPooling1D", "(", "pool_size", "=", "self", ".", "parameters", "[", "'pool_size'", "]", ")", "(", "conv", ")", "\n", "conv", "=", "Flatten", "(", ")", "(", "conv", ")", "\n", "conv_blocks", ".", "append", "(", "conv", ")", "\n", "", "z", "=", "Concatenate", "(", ")", "(", "conv_blocks", ")", "if", "len", "(", "conv_blocks", ")", ">", "1", "else", "conv_blocks", "[", "0", "]", "\n", "wordEncoder", "=", "Model", "(", "word_input", ",", "z", ")", "\n", "if", "self", ".", "verbose", "==", "1", ":", "\n", "            ", "wordEncoder", ".", "summary", "(", ")", "\n", "\n", "# Sentences Concated", "\n", "", "sent_input", "=", "Input", "(", "shape", "=", "(", "self", ".", "train", "[", "'text'", "]", ".", "shape", "[", "1", "]", ",", "self", ".", "parameters", "[", "'max_senten_len'", "]", ")", ",", "dtype", "=", "'float32'", ",", "name", "=", "'input_2'", ")", "\n", "y", "=", "TimeDistributed", "(", "wordEncoder", ",", "name", "=", "'input_sent2'", ")", "(", "sent_input", ")", "\n", "y", "=", "Dense", "(", "self", ".", "parameters", "[", "'dense_1'", "]", ",", "name", "=", "'dense_1'", ")", "(", "y", ")", "\n", "y", "=", "concatenate", "(", "[", "inp_features", ",", "y", "]", ",", "axis", "=", "2", ")", "\n", "y", "=", "Dense", "(", "self", ".", "parameters", "[", "'dense_2'", "]", ",", "name", "=", "'dense_2'", ")", "(", "y", ")", "\n", "y", "=", "SeqSelfAttention", "(", "attention_activation", "=", "self", ".", "parameters", "[", "'activation_attention'", "]", ",", "return_attention", "=", "False", ",", "name", "=", "'Self-Attention'", ")", "(", "y", ")", "\n", "\n", "y", "=", "keras", ".", "layers", ".", "dot", "(", "[", "flow_features", ",", "y", "]", ",", "axes", "=", "[", "1", ",", "1", "]", ")", "\n", "y", "=", "keras", ".", "layers", ".", "Lambda", "(", "lambda", "x", ":", "K", ".", "mean", "(", "x", ",", "axis", "=", "1", ")", ")", "(", "y", ")", "\n", "y", "=", "Dense", "(", "self", ".", "parameters", "[", "'dense_3'", "]", ",", "name", "=", "'dense_3'", ")", "(", "y", ")", "\n", "y", "=", "Dropout", "(", "self", ".", "parameters", "[", "'dropout'", "]", ")", "(", "y", ")", "\n", "y", "=", "Dense", "(", "len", "(", "self", ".", "Labels", ")", ",", "activation", "=", "'softmax'", ",", "name", "=", "'final_softmax'", ")", "(", "y", ")", "\n", "model", "=", "Model", "(", "[", "inp_features", ",", "sent_input", "]", ",", "y", ")", "\n", "if", "self", ".", "verbose", "==", "1", ":", "\n", "            ", "model", ".", "summary", "(", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.evaluate_on_test": [[225, 230], ["fake_flow.fake_flow.model.predict", "numpy.argmax", "numpy.argmax", "print", "sklearn.metrics.classification_report"], "methods", ["None"], ["", "def", "evaluate_on_test", "(", "self", ")", ":", "\n", "        ", "Y_test_pred", "=", "self", ".", "model", ".", "predict", "(", "[", "self", ".", "test", "[", "'features'", "]", ",", "self", ".", "test", "[", "'text'", "]", "]", ",", "batch_size", "=", "self", ".", "parameters", "[", "'batch_size'", "]", ",", "verbose", "=", "0", ")", "\n", "Y_test_pred", "=", "np", ".", "argmax", "(", "Y_test_pred", ",", "axis", "=", "1", ")", "\n", "Y_test", "=", "np", ".", "argmax", "(", "self", ".", "test", "[", "'label'", "]", ",", "axis", "=", "1", ")", "\n", "print", "(", "classification_report", "(", "Y_test", ",", "Y_test_pred", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.run_model": [[231, 266], ["tensorflow.compat.v1.InteractiveSession", "fake_flow.fake_flow.Network", "fake_flow.fake_flow.model.compile", "keras.callbacks.EarlyStopping", "keras.callbacks.ReduceLROnPlateau", "callback.append", "fake_flow.fake_flow.model.fit", "fake_flow.fake_flow.evaluate_on_test", "str().__contains__", "keras.callbacks.ModelCheckpoint", "os.path.exists", "print", "exit", "print", "fake_flow.fake_flow.evaluate_on_test", "fake_flow.fake_flow.model.load_weights", "print", "print", "exit", "str", "file.rfind"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.Network", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.fit", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.evaluate_on_test", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.evaluate_on_test"], ["", "def", "run_model", "(", "self", ",", "type_", "=", "'train'", ")", ":", "\n", "        ", "file", "=", "'./processed_files/saved_models/{}_{}.check'", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "model_name", ")", "\n", "# 1, Compile the model", "\n", "self", ".", "session", "=", "InteractiveSession", "(", "config", "=", "config", ")", "\n", "self", ".", "model", "=", "self", ".", "Network", "(", ")", "\n", "self", ".", "model", ".", "compile", "(", "optimizer", "=", "self", ".", "parameters", "[", "'optimizer'", "]", ",", "loss", "=", "'categorical_crossentropy'", ",", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "# 2, Prep", "\n", "callback", "=", "[", "EarlyStopping", "(", "min_delta", "=", "0.0001", ",", "patience", "=", "4", ",", "verbose", "=", "2", ",", "restore_best_weights", "=", "True", ")", ",", "\n", "ReduceLROnPlateau", "(", "factor", "=", "0.03", ",", "patience", "=", "3", ",", "verbose", "=", "2", ",", "min_lr", "=", "0.00001", ")", "]", "\n", "if", "not", "self", ".", "search", ":", "\n", "            ", "callback", ".", "append", "(", "ModelCheckpoint", "(", "file", ",", "save_best_only", "=", "True", ",", "save_weights_only", "=", "False", ")", ")", "\n", "\n", "# 3, Train", "\n", "", "if", "type_", "==", "'train'", ":", "\n", "            ", "self", ".", "model", ".", "fit", "(", "x", "=", "[", "self", ".", "train", "[", "'features'", "]", ",", "self", ".", "train", "[", "'text'", "]", "]", ",", "y", "=", "self", ".", "train", "[", "'label'", "]", ",", "batch_size", "=", "self", ".", "parameters", "[", "'batch_size'", "]", ",", "epochs", "=", "self", ".", "parameters", "[", "'max_epoch'", "]", ",", "verbose", "=", "self", ".", "verbose", ",", "\n", "validation_data", "=", "(", "[", "self", ".", "dev", "[", "'features'", "]", ",", "self", ".", "dev", "[", "'text'", "]", "]", ",", "self", ".", "dev", "[", "'label'", "]", ")", ",", "callbacks", "=", "callback", ")", "\n", "", "elif", "type_", "==", "'test'", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "file", ")", ":", "\n", "                ", "self", ".", "model", ".", "load_weights", "(", "file", ",", "by_name", "=", "True", ")", "\n", "print", "(", "'--------Load Weights Successful!--------'", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'Model doesn\\'t exist: {}'", ".", "format", "(", "file", "[", "file", ".", "rfind", "(", "'/'", ")", ":", "]", ")", ")", "\n", "exit", "(", "1", ")", "\n", "", "", "else", ":", "\n", "            ", "print", "(", "'Mode not defined!'", ")", "\n", "exit", "(", "1", ")", "\n", "\n", "# 4, Evaluate", "\n", "", "if", "not", "self", ".", "search", ":", "\n", "            ", "self", ".", "evaluate_on_test", "(", ")", "\n", "if", "str", "(", "self", ".", "model_name", ")", ".", "__contains__", "(", "'truthShades'", ")", ":", "\n", "                ", "print", "(", "'In-domain test:'", ")", "\n", "self", ".", "test", "=", "self", ".", "test_in", "\n", "self", ".", "evaluate_on_test", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.run_hyperopt_search": [[267, 293], ["hyperopt.Trials", "hyperopt.fmin", "print", "print", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.choice", "hyperopt.hp.uniform", "hyperopt.hp.choice"], "methods", ["None"], ["", "", "", "def", "run_hyperopt_search", "(", "self", ",", "n_evals", ")", ":", "\n", "        ", "self", ".", "verbose", "=", "0", "\n", "self", ".", "search", "=", "True", "\n", "# self.pbar = tqdm(total=n_evals)", "\n", "# self.pbar.set_description('Hyperopt evals')", "\n", "search_space", "=", "{", "'rnn_size'", ":", "hp", ".", "choice", "(", "'lstmSize'", ",", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ")", ",", "\n", "'activation_rnn'", ":", "hp", ".", "choice", "(", "'activation_rnn'", ",", "[", "'selu'", ",", "'relu'", ",", "'tanh'", ",", "'elu'", "]", ")", ",", "\n", "\n", "'num_filters'", ":", "hp", ".", "choice", "(", "'num_filters'", ",", "[", "4", ",", "8", ",", "16", ",", "32", ",", "64", "]", ")", ",", "\n", "'filter_sizes'", ":", "hp", ".", "choice", "(", "'filter_sizes'", ",", "[", "(", "2", ",", "3", ",", "4", ")", ",", "(", "3", ",", "4", ",", "5", ")", ",", "(", "4", ",", "5", ",", "6", ")", ",", "(", "3", ",", "5", ")", ",", "(", "2", ",", "4", ")", ",", "(", "4", ",", ")", ",", "(", "5", ",", ")", ",", "(", "3", ",", "5", ",", "7", ")", ",", "(", "3", ",", "6", ")", "]", ")", ",", "\n", "'activation_cnn'", ":", "hp", ".", "choice", "(", "'activation_cnn'", ",", "[", "'selu'", ",", "'relu'", ",", "'tanh'", ",", "'elu'", "]", ")", ",", "\n", "'pool_size'", ":", "hp", ".", "choice", "(", "'pool_size'", ",", "[", "2", ",", "3", "]", ")", ",", "\n", "\n", "'dense_1'", ":", "hp", ".", "choice", "(", "'dense_1'", ",", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ")", ",", "\n", "'activation_attention'", ":", "hp", ".", "choice", "(", "'activation_attention'", ",", "[", "'sigmoid'", ",", "'softmax'", "]", ")", ",", "\n", "'dense_2'", ":", "hp", ".", "choice", "(", "'dense_2'", ",", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ")", ",", "\n", "'dense_3'", ":", "hp", ".", "choice", "(", "'dense_3'", ",", "[", "8", ",", "16", ",", "32", ",", "64", ",", "128", "]", ")", ",", "\n", "'dropout'", ":", "hp", ".", "uniform", "(", "'dropout'", ",", "0.1", ",", "0.6", ")", ",", "\n", "'optimizer'", ":", "hp", ".", "choice", "(", "'optimizer'", ",", "[", "'adam'", ",", "'adadelta'", ",", "'rmsprop'", ",", "'sgd'", "]", ")", ",", "\n", "}", "\n", "trials", "=", "Trials", "(", ")", "\n", "best", "=", "fmin", "(", "self", ".", "objective_function", ",", "space", "=", "search_space", ",", "algo", "=", "tpe", ".", "suggest", ",", "max_evals", "=", "n_evals", ",", "trials", "=", "trials", ")", "\n", "# self.pbar.close()", "\n", "bp", "=", "trials", ".", "best_trial", "[", "'result'", "]", "[", "'Params'", "]", "\n", "print", "(", "'\\n\\n'", ",", "best", ")", "\n", "print", "(", "bp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.objective_function": [[294, 324], ["fake_flow.fake_flow.Kstratified", "params.update", "print", "pandas.DataFrame.sort_values", "pandas.DataFrame.to_csv", "str", "len", "fake_flow.fake_flow.summary_table.update", "fake_flow.fake_flow.summary_table.items", "pandas.DataFrame", "params.items", "pandas.DataFrame", "values.append", "type"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.Kstratified"], ["", "def", "objective_function", "(", "self", ",", "params", ")", ":", "\n", "        ", "mean_score", "=", "self", ".", "Kstratified", "(", "params", ")", "\n", "params", ".", "update", "(", "{", "'score'", ":", "mean_score", "}", ")", "\n", "params", "=", "{", "key", ":", "str", "(", "val", ")", "for", "key", ",", "val", "in", "params", ".", "items", "(", ")", "}", "\n", "print", "(", "params", ")", "\n", "\n", "if", "len", "(", "self", ".", "summary_table", ")", "<", "1", ":", "\n", "            ", "self", ".", "summary_table", ".", "update", "(", "params", ")", "\n", "", "else", ":", "\n", "            ", "for", "key", ",", "value", "in", "self", ".", "summary_table", ".", "items", "(", ")", ":", "\n", "                ", "if", "key", "in", "params", ":", "\n", "                    ", "values", "=", "self", ".", "summary_table", "[", "key", "]", "\n", "if", "not", "type", "(", "values", ")", "is", "list", ":", "\n", "                        ", "values", "=", "[", "values", "]", "\n", "", "values", ".", "append", "(", "params", "[", "key", "]", ")", "\n", "self", ".", "summary_table", "[", "key", "]", "=", "values", "\n", "\n", "", "", "", "try", ":", "\n", "            ", "df_summary_table", "=", "pd", ".", "DataFrame", "(", "self", ".", "summary_table", ",", "index", "=", "[", "0", "]", ")", "\n", "", "except", ":", "\n", "            ", "df_summary_table", "=", "pd", ".", "DataFrame", "(", "self", ".", "summary_table", ")", "\n", "", "df_summary_table", ".", "sort_values", "(", "'score'", ",", "inplace", "=", "True", ",", "ascending", "=", "False", ")", "\n", "df_summary_table", ".", "to_csv", "(", "'./processed_files/saved_models/results_{}_{}.csv'", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "model_name", ")", ",", "header", "=", "True", ",", "index", "=", "False", ")", "\n", "\n", "output", "=", "{", "'loss'", ":", "1", "-", "mean_score", ",", "\n", "'Params'", ":", "params", ",", "\n", "'status'", ":", "STATUS_OK", ",", "\n", "}", "\n", "# self.pbar.update(1)", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.Kstratified": [[325, 353], ["print", "fake_flow.fake_flow.run_model", "fake_flow.fake_flow.model.predict", "numpy.argmax", "numpy.argmax", "fake_flow.fake_flow.scoring.lower", "f1_score", "fake_flow.fake_flow.scoring.lower", "accuracy_score"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.None.fake_flow.fake_flow.run_model"], ["", "def", "Kstratified", "(", "self", ",", "params", ")", ":", "\n", "\n", "        ", "self", ".", "parameters", "[", "'rnn_size'", "]", "=", "params", "[", "'rnn_size'", "]", "\n", "self", ".", "parameters", "[", "'activation_rnn'", "]", "=", "params", "[", "'activation_rnn'", "]", "\n", "\n", "self", ".", "parameters", "[", "'num_filters'", "]", "=", "params", "[", "'num_filters'", "]", "\n", "self", ".", "parameters", "[", "'filter_sizes'", "]", "=", "params", "[", "'filter_sizes'", "]", "\n", "self", ".", "parameters", "[", "'pool_size'", "]", "=", "params", "[", "'pool_size'", "]", "\n", "self", ".", "parameters", "[", "'activation_cnn'", "]", "=", "params", "[", "'activation_cnn'", "]", "\n", "\n", "self", ".", "parameters", "[", "'dense_1'", "]", "=", "params", "[", "'dense_1'", "]", "\n", "self", ".", "parameters", "[", "'activation_attention'", "]", "=", "params", "[", "'activation_attention'", "]", "\n", "self", ".", "parameters", "[", "'dense_2'", "]", "=", "params", "[", "'dense_2'", "]", "\n", "self", ".", "parameters", "[", "'dense_3'", "]", "=", "params", "[", "'dense_3'", "]", "\n", "self", ".", "parameters", "[", "'dropout'", "]", "=", "params", "[", "'dropout'", "]", "\n", "self", ".", "parameters", "[", "'optimizer'", "]", "=", "params", "[", "'optimizer'", "]", "\n", "\n", "print", "(", "'Current: {}'", ".", "format", "(", "params", ")", ")", "\n", "self", ".", "run_model", "(", ")", "\n", "Y_dev_pred", "=", "self", ".", "model", ".", "predict", "(", "[", "self", ".", "dev", "[", "'features'", "]", ",", "self", ".", "dev", "[", "'text'", "]", "]", ",", "batch_size", "=", "self", ".", "parameters", "[", "'batch_size'", "]", ",", "verbose", "=", "0", ")", "\n", "Y_dev_pred", "=", "np", ".", "argmax", "(", "Y_dev_pred", ",", "axis", "=", "1", ")", "\n", "self", ".", "Y_dev", "=", "np", ".", "argmax", "(", "self", ".", "dev", "[", "'label'", "]", ",", "axis", "=", "1", ")", "\n", "# self.session.close()", "\n", "\n", "if", "self", ".", "scoring", ".", "lower", "(", ")", "==", "'f1'", ":", "\n", "            ", "return", "f1_score", "(", "self", ".", "Y_dev", ",", "Y_dev_pred", ",", "average", "=", "'macro'", ")", "\n", "", "elif", "self", ".", "scoring", ".", "lower", "(", ")", "==", "'acc'", ":", "\n", "            ", "return", "accuracy_score", "(", "self", ".", "Y_dev", ",", "Y_dev_pred", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.append_split_3D.__init__": [[55, 60], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "segments_number", "=", "20", ",", "max_len", "=", "50", ",", "mode", "=", "'append'", ")", ":", "\n", "        ", "self", ".", "segments_number", "=", "segments_number", "\n", "self", ".", "max_len", "=", "max_len", "\n", "self", ".", "mode", "=", "mode", "\n", "self", ".", "appending_value", "=", "-", "5.123", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.append_split_3D.fit": [[61, 63], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.append_split_3D.transform": [[64, 80], ["numpy.full", "numpy.concatenate", "range", "numpy.concatenate", "print", "exit", "tmp.append", "item[].reshape"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "if", "self", ".", "mode", "==", "'append'", ":", "\n", "            ", "self", ".", "max_len", "=", "self", ".", "max_len", "-", "data", ".", "shape", "[", "2", "]", "\n", "appending", "=", "np", ".", "full", "(", "(", "data", ".", "shape", "[", "0", "]", ",", "data", ".", "shape", "[", "1", "]", ",", "self", ".", "max_len", ")", ",", "self", ".", "appending_value", ")", "\n", "new", "=", "np", ".", "concatenate", "(", "[", "data", ",", "appending", "]", ",", "axis", "=", "2", ")", "\n", "return", "new", "\n", "", "elif", "self", ".", "mode", "==", "'split'", ":", "\n", "            ", "tmp", "=", "[", "]", "\n", "for", "item", "in", "range", "(", "0", ",", "data", ".", "shape", "[", "1", "]", ",", "self", ".", "segments_number", ")", ":", "\n", "                ", "tmp", ".", "append", "(", "data", "[", ":", ",", "item", ":", "(", "item", "+", "self", ".", "segments_number", ")", ",", ":", "]", ")", "\n", "", "tmp", "=", "[", "item", "[", "item", "!=", "self", ".", "appending_value", "]", ".", "reshape", "(", "data", ".", "shape", "[", "0", "]", ",", "self", ".", "segments_number", ",", "-", "1", ")", "for", "item", "in", "tmp", "]", "\n", "new", "=", "np", ".", "concatenate", "(", "tmp", ",", "axis", "=", "2", ")", "\n", "return", "new", "\n", "", "else", ":", "\n", "            ", "print", "(", "'Error: Mode value is not defined'", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.segmentation.__init__": [[83, 86], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_jobs", "=", "1", ",", "segments_number", "=", "20", ")", ":", "\n", "        ", "self", ".", "n_jobs", "=", "n_jobs", "\n", "self", ".", "segments_number", "=", "segments_number", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.segmentation.fit": [[87, 89], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.segmentation.transform": [[90, 98], ["numpy.array", "numpy.array_split", "numpy.array.append", "numpy.sum"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "out", "=", "[", "]", "\n", "for", "sentence", "in", "data", ":", "\n", "            ", "tmp", "=", "np", ".", "array_split", "(", "sentence", ",", "self", ".", "segments_number", ")", "\n", "tmp", "=", "[", "np", ".", "sum", "(", "item", ",", "axis", "=", "0", ")", "/", "sentence", ".", "shape", "[", "0", "]", "for", "item", "in", "tmp", "]", "\n", "out", ".", "append", "(", "tmp", ")", "\n", "", "out", "=", "np", ".", "array", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.segmentation_text.__init__": [[101, 104], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "n_jobs", "=", "1", ",", "segments_number", "=", "20", ")", ":", "\n", "        ", "self", ".", "n_jobs", "=", "n_jobs", "\n", "self", ".", "segments_number", "=", "segments_number", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.segmentation_text.fit": [[105, 107], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.segmentation_text.transform": [[108, 122], ["isinstance", "joblib.Parallel", "numpy.array", "out.append", "numpy.array_split", "joblib.delayed", "tqdm.tqdm.tqdm", "numpy.array", "print", "item.tolist"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "data", "=", "Parallel", "(", "n_jobs", "=", "1", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "clean_regex", ")", "(", "sentence", ",", "keep_dot", "=", "False", ",", "split_text", "=", "True", ")", "for", "sentence", "in", "tqdm", "(", "data", ",", "desc", "=", "'Text Segmentation'", ")", ")", "\n", "if", "isinstance", "(", "data", ",", "list", ")", ":", "\n", "            ", "data", "=", "np", ".", "array", "(", "[", "np", ".", "array", "(", "sent", ")", "for", "sent", "in", "data", "]", ")", "\n", "", "out", "=", "[", "]", "\n", "for", "sentence", "in", "data", ":", "\n", "            ", "try", ":", "\n", "                ", "tmp", "=", "np", ".", "array_split", "(", "sentence", ",", "self", ".", "segments_number", ")", "\n", "tmp", "=", "' . '", ".", "join", "(", "[", "' '", ".", "join", "(", "item", ".", "tolist", "(", ")", ")", "for", "item", "in", "tmp", "]", ")", "\n", "", "except", ":", "\n", "                ", "print", "(", ")", "\n", "", "out", ".", "append", "(", "tmp", ")", "\n", "", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.emotional_features.__init__": [[126, 131], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ",", "n_jobs", "=", "1", ",", "model_name", "=", "''", ",", "representation", "=", "'frequency'", ")", ":", "\n", "        ", "self", ".", "path", "=", "path", "\n", "self", ".", "n_jobs", "=", "n_jobs", "\n", "self", ".", "model_name", "=", "model_name", "\n", "self", ".", "representation", "=", "representation", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.emotional_features.fit": [[132, 134], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.emotional_features.error_representation": [[135, 138], ["print", "exit"], "methods", ["None"], ["", "def", "error_representation", "(", "self", ")", ":", "\n", "        ", "print", "(", "'\\n\\nError: check the value of the variable \"representation\".'", ")", "\n", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.emotional_features.transform": [[139, 158], ["os.path.exists", "numpy.load().tolist", "np.load().tolist.emotional.loading_emotional_lexicons.emotional_lexicons", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.set_description", "numpy.save", "joblib.Parallel", "joblib.Parallel", "numpy.array", "numpy.load", "os.path.join", "joblib.delayed", "tqdm.tqdm.tqdm", "joblib.delayed", "building_features.emotional_features.error_representation"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.emotional_features.error_representation"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "file_name", "=", "'./processed_files/features/emotional_features_{}_{}.npy'", ".", "format", "(", "self", ".", "model_name", ",", "self", ".", "representation", ")", "\n", "if", "exists", "(", "file_name", ")", ":", "\n", "            ", "features", "=", "np", ".", "load", "(", "file_name", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "clean_regex", ")", "(", "sentence", ",", "False", ",", "True", ")", "for", "sentence", "in", "tqdm", "(", "data", ",", "desc", "=", "'Cleaning text'", ")", ")", "\n", "\n", "emo", "=", "emotional_lexicons", "(", "path", "=", "join", "(", "self", ".", "path", ",", "'emotional'", ")", ")", "\n", "loop", "=", "tqdm", "(", "data", ")", "\n", "loop", ".", "set_description", "(", "'Building emotional_features ({})'", ".", "format", "(", "self", ".", "representation", ")", ")", "\n", "\n", "features", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "emo", ".", "frequency", "if", "self", ".", "representation", "==", "'frequency'", "else", "emo", ".", "intensity", "if", "self", ".", "representation", "==", "'intensity'", "else", "self", ".", "error_representation", "(", ")", ")", "\n", "(", "sentence", ")", "for", "sentence", "in", "loop", ")", "\n", "\n", "features", "=", "[", "np", ".", "array", "(", "item", ")", "for", "item", "in", "features", "]", "\n", "np", ".", "save", "(", "file_name", ",", "features", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.sentiment_features.__init__": [[161, 165], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ",", "n_jobs", "=", "1", ",", "model_name", "=", "''", ")", ":", "\n", "        ", "self", ".", "path", "=", "path", "\n", "self", ".", "n_jobs", "=", "n_jobs", "\n", "self", ".", "model_name", "=", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.sentiment_features.fit": [[166, 168], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.sentiment_features.transform": [[169, 185], ["os.path.exists", "numpy.load().tolist", "np.load().tolist.sentiment.loading_sentiment_lexicons.sentiment_lexicons", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.set_description", "numpy.save", "joblib.Parallel", "joblib.Parallel", "numpy.array", "numpy.load", "os.path.join", "joblib.delayed", "tqdm.tqdm.tqdm", "joblib.delayed"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "file_name", "=", "'./processed_files/features/sentiment_features_{}.npy'", ".", "format", "(", "self", ".", "model_name", ")", "\n", "if", "exists", "(", "file_name", ")", ":", "\n", "            ", "features", "=", "np", ".", "load", "(", "file_name", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "clean_regex", ")", "(", "sentence", ",", "False", ",", "True", ")", "for", "sentence", "in", "tqdm", "(", "data", ",", "desc", "=", "'Cleaning text'", ")", ")", "\n", "\n", "senti", "=", "sentiment_lexicons", "(", "path", "=", "join", "(", "self", ".", "path", ",", "'sentiment'", ")", ")", "\n", "loop", "=", "tqdm", "(", "data", ")", "\n", "loop", ".", "set_description", "(", "'Building sentiment_features'", ")", "\n", "\n", "features", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "senti", ".", "score", ")", "(", "sentence", ")", "for", "sentence", "in", "loop", ")", "\n", "features", "=", "[", "np", ".", "array", "(", "item", ")", "for", "item", "in", "features", "]", "\n", "np", ".", "save", "(", "file_name", ",", "features", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.morality_features.__init__": [[188, 192], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ",", "n_jobs", "=", "1", ",", "model_name", "=", "''", ")", ":", "\n", "        ", "self", ".", "path", "=", "path", "\n", "self", ".", "n_jobs", "=", "n_jobs", "\n", "self", ".", "model_name", "=", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.morality_features.fit": [[193, 195], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.morality_features.transform": [[196, 212], ["os.path.exists", "numpy.load().tolist", "np.load().tolist.morality.morality.MORALITY_class", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.set_description", "numpy.save", "joblib.Parallel", "joblib.Parallel", "numpy.array", "numpy.load", "os.path.join", "joblib.delayed", "tqdm.tqdm.tqdm", "joblib.delayed"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "file_name", "=", "'./processed_files/features/morality_features_{}.npy'", ".", "format", "(", "self", ".", "model_name", ")", "\n", "if", "exists", "(", "file_name", ")", ":", "\n", "            ", "features", "=", "np", ".", "load", "(", "file_name", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "clean_regex", ")", "(", "sentence", ",", "False", ",", "True", ")", "for", "sentence", "in", "tqdm", "(", "data", ",", "desc", "=", "'Cleaning text'", ")", ")", "\n", "\n", "lex", "=", "MORALITY_class", "(", "path", "=", "join", "(", "self", ".", "path", ",", "'morality'", ")", ")", "\n", "loop", "=", "tqdm", "(", "data", ")", "\n", "loop", ".", "set_description", "(", "'Building Morality_features'", ")", "\n", "\n", "features", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "lex", ".", "score", ")", "(", "sentence", ")", "for", "sentence", "in", "loop", ")", "\n", "features", "=", "[", "np", ".", "array", "(", "item", ")", "for", "item", "in", "features", "]", "\n", "np", ".", "save", "(", "file_name", ",", "features", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.imageability_features.__init__": [[215, 219], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ",", "n_jobs", "=", "1", ",", "model_name", "=", "''", ")", ":", "\n", "        ", "self", ".", "path", "=", "path", "\n", "self", ".", "n_jobs", "=", "n_jobs", "\n", "self", ".", "model_name", "=", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.imageability_features.fit": [[220, 222], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.imageability_features.transform": [[223, 239], ["os.path.exists", "numpy.load().tolist", "np.load().tolist.imageability.imageability.imageability_class", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.set_description", "numpy.save", "joblib.Parallel", "joblib.Parallel", "numpy.array", "numpy.load", "os.path.join", "joblib.delayed", "tqdm.tqdm.tqdm", "joblib.delayed"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "file_name", "=", "'./processed_files/features/imageability_features_{}.npy'", ".", "format", "(", "self", ".", "model_name", ")", "\n", "if", "exists", "(", "file_name", ")", ":", "\n", "            ", "features", "=", "np", ".", "load", "(", "file_name", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "clean_regex", ")", "(", "sentence", ",", "False", ",", "True", ")", "for", "sentence", "in", "tqdm", "(", "data", ",", "desc", "=", "'Cleaning text'", ")", ")", "\n", "\n", "lex", "=", "imageability_class", "(", "path", "=", "join", "(", "self", ".", "path", ",", "'imageability'", ")", ")", "\n", "loop", "=", "tqdm", "(", "data", ")", "\n", "loop", ".", "set_description", "(", "'Building Imageability_features'", ")", "\n", "\n", "features", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "lex", ".", "score", ")", "(", "sentence", ")", "for", "sentence", "in", "loop", ")", "\n", "features", "=", "[", "np", ".", "array", "(", "item", ")", "for", "item", "in", "features", "]", "\n", "np", ".", "save", "(", "file_name", ",", "features", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.__init__": [[242, 246], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ",", "n_jobs", "=", "1", ",", "model_name", "=", "''", ")", ":", "\n", "        ", "self", ".", "path", "=", "path", "\n", "self", ".", "n_jobs", "=", "n_jobs", "\n", "self", ".", "model_name", "=", "model_name", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.fit": [[247, 249], ["None"], "methods", ["None"], ["", "def", "fit", "(", "self", ",", "X", ",", "y", "=", "None", ")", ":", "\n", "        ", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.hyperbolic_features.transform": [[250, 266], ["os.path.exists", "numpy.load().tolist", "np.load().tolist.hyperbolic.hyperbolic.hyperbolic_class", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.set_description", "numpy.save", "joblib.Parallel", "joblib.Parallel", "numpy.array", "numpy.load", "os.path.join", "joblib.delayed", "tqdm.tqdm.tqdm", "joblib.delayed"], "methods", ["None"], ["", "def", "transform", "(", "self", ",", "data", ")", ":", "\n", "        ", "file_name", "=", "'./processed_files/features/hyperbolic_features_{}.npy'", ".", "format", "(", "self", ".", "model_name", ")", "\n", "if", "exists", "(", "file_name", ")", ":", "\n", "            ", "features", "=", "np", ".", "load", "(", "file_name", ")", ".", "tolist", "(", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "clean_regex", ")", "(", "sentence", ",", "False", ",", "True", ")", "for", "sentence", "in", "tqdm", "(", "data", ",", "desc", "=", "'Cleaning text'", ")", ")", "\n", "\n", "lex", "=", "hyperbolic_class", "(", "path", "=", "join", "(", "self", ".", "path", ",", "'hyperbolic'", ")", ")", "\n", "loop", "=", "tqdm", "(", "data", ")", "\n", "loop", ".", "set_description", "(", "'Building Hyperbolic_features'", ")", "\n", "\n", "features", "=", "Parallel", "(", "n_jobs", "=", "self", ".", "n_jobs", ",", "backend", "=", "\"multiprocessing\"", ",", "prefer", "=", "\"processes\"", ")", "(", "delayed", "(", "lex", ".", "score", ")", "(", "sentence", ")", "for", "sentence", "in", "loop", ")", "\n", "features", "=", "[", "np", ".", "array", "(", "item", ")", "for", "item", "in", "features", "]", "\n", "np", ".", "save", "(", "file_name", ",", "features", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.clean_regex": [[25, 53], ["re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "text.lower.split", "text.lower.lower", "str().strip", "str().strip", "text.lower.split", "text.lower.split", "str", "str", "sent.strip", "sent.strip"], "function", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split"], ["def", "clean_regex", "(", "text", ",", "keep_dot", "=", "False", ",", "split_text", "=", "False", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "text", "=", "re", ".", "sub", "(", "r'((http|https)://([\\w_-]+(?:(?:\\.[\\w_-]+)+))([\\w.,@?^=;%&:/~+#-]*[\\w@?^=%&;:/~+#-])?)'", ",", "' '", ",", "\n", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^ ]+\\.com'", ",", "' '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'(\\d{1,},)?\\d{1,}(\\.\\d{1,})?'", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\u2019'", ",", "'\\''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'[^A-Za-z\\'. ]'", ",", "' '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\.'", ",", "'. '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\s{2,}'", ",", "' '", ",", "text", ")", "\n", "\n", "text", "=", "re", ".", "sub", "(", "r'(\\.\\s)+'", ",", "'.'", ",", "str", "(", "text", ")", ".", "strip", "(", ")", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'\\.{2,}'", ",", "'.'", ",", "str", "(", "text", ")", ".", "strip", "(", ")", ")", "\n", "text", "=", "re", ".", "sub", "(", "r'(?<!\\w)([A-Z])\\.'", ",", "r'\\1'", ",", "text", ")", "\n", "\n", "text", "=", "re", ".", "sub", "(", "r'\\'(?!\\w{1,2}\\s)'", ",", "' '", ",", "text", ")", "\n", "\n", "text", "=", "text", ".", "split", "(", "'.'", ")", "\n", "if", "keep_dot", ":", "\n", "            ", "text", "=", "' '", ".", "join", "(", "[", "sent", ".", "strip", "(", ")", "+", "' . '", "for", "sent", "in", "text", "]", ")", "\n", "", "else", ":", "\n", "            ", "text", "=", "' '", ".", "join", "(", "[", "sent", ".", "strip", "(", ")", "for", "sent", "in", "text", "]", ")", "\n", "\n", "", "text", "=", "text", ".", "lower", "(", ")", "\n", "return", "text", ".", "split", "(", ")", "if", "split_text", "else", "text", "\n", "", "except", ":", "\n", "        ", "text", "=", "'empty text'", "\n", "return", "text", ".", "split", "(", ")", "if", "split_text", "else", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.features.building_features.manual_features": [[268, 300], ["sklearn.pipeline.Pipeline", "sklearn.pipeline.FeatureUnion", "building_features.append_split_3D", "sklearn.pipeline.Pipeline", "sklearn.pipeline.Pipeline", "sklearn.pipeline.Pipeline", "sklearn.pipeline.Pipeline", "sklearn.pipeline.Pipeline", "building_features.emotional_features", "building_features.segmentation", "building_features.append_split_3D", "building_features.sentiment_features", "building_features.segmentation", "building_features.append_split_3D", "building_features.morality_features", "building_features.segmentation", "building_features.append_split_3D", "building_features.imageability_features", "building_features.segmentation", "building_features.append_split_3D", "building_features.hyperbolic_features", "building_features.segmentation", "building_features.append_split_3D"], "function", ["None"], ["", "", "def", "manual_features", "(", "path", "=", "''", ",", "n_jobs", "=", "1", ",", "model_name", "=", "''", ",", "segments_number", "=", "20", ",", "emo_rep", "=", "'frequency'", ")", ":", "\n", "    ", "manual_feats", "=", "Pipeline", "(", "[", "\n", "(", "'FeatureUnion'", ",", "FeatureUnion", "(", "[", "\n", "(", "'1'", ",", "Pipeline", "(", "[", "\n", "(", "'emotional_features'", ",", "emotional_features", "(", "path", "=", "path", ",", "n_jobs", "=", "n_jobs", ",", "model_name", "=", "model_name", ",", "representation", "=", "emo_rep", ")", ")", ",", "\n", "(", "'segmentation'", ",", "segmentation", "(", "n_jobs", "=", "n_jobs", ",", "segments_number", "=", "segments_number", ")", ")", ",", "\n", "(", "'append'", ",", "append_split_3D", "(", "segments_number", "=", "segments_number", ",", "max_len", "=", "50", ",", "mode", "=", "'append'", ")", ")", ",", "\n", "]", ")", ")", ",", "\n", "(", "'2'", ",", "Pipeline", "(", "[", "\n", "(", "'sentiment_features'", ",", "sentiment_features", "(", "path", "=", "path", ",", "n_jobs", "=", "n_jobs", ",", "model_name", "=", "model_name", ")", ")", ",", "\n", "(", "'segmentation'", ",", "segmentation", "(", "n_jobs", "=", "n_jobs", ",", "segments_number", "=", "segments_number", ")", ")", ",", "\n", "(", "'append'", ",", "append_split_3D", "(", "segments_number", "=", "segments_number", ",", "max_len", "=", "50", ",", "mode", "=", "'append'", ")", ")", ",", "\n", "]", ")", ")", ",", "\n", "(", "'3'", ",", "Pipeline", "(", "[", "\n", "(", "'morality_features'", ",", "morality_features", "(", "path", "=", "path", ",", "n_jobs", "=", "n_jobs", ",", "model_name", "=", "model_name", ")", ")", ",", "\n", "(", "'segmentation'", ",", "segmentation", "(", "n_jobs", "=", "n_jobs", ",", "segments_number", "=", "segments_number", ")", ")", ",", "\n", "(", "'append'", ",", "append_split_3D", "(", "segments_number", "=", "segments_number", ",", "max_len", "=", "50", ",", "mode", "=", "'append'", ")", ")", ",", "\n", "]", ")", ")", ",", "\n", "(", "'4'", ",", "Pipeline", "(", "[", "\n", "(", "'imageability_features'", ",", "imageability_features", "(", "path", "=", "path", ",", "n_jobs", "=", "n_jobs", ",", "model_name", "=", "model_name", ")", ")", ",", "\n", "(", "'segmentation'", ",", "segmentation", "(", "n_jobs", "=", "n_jobs", ",", "segments_number", "=", "segments_number", ")", ")", ",", "\n", "(", "'append'", ",", "append_split_3D", "(", "segments_number", "=", "segments_number", ",", "max_len", "=", "50", ",", "mode", "=", "'append'", ")", ")", ",", "\n", "]", ")", ")", ",", "\n", "(", "'5'", ",", "Pipeline", "(", "[", "\n", "(", "'hyperbolic_features'", ",", "hyperbolic_features", "(", "path", "=", "path", ",", "n_jobs", "=", "n_jobs", ",", "model_name", "=", "model_name", ")", ")", ",", "\n", "(", "'segmentation'", ",", "segmentation", "(", "n_jobs", "=", "n_jobs", ",", "segments_number", "=", "segments_number", ")", ")", ",", "\n", "(", "'append'", ",", "append_split_3D", "(", "segments_number", "=", "segments_number", ",", "max_len", "=", "50", ",", "mode", "=", "'append'", ")", ")", ",", "\n", "]", ")", ")", ",", "\n", "]", ",", "n_jobs", "=", "1", ")", ")", ",", "\n", "(", "'split'", ",", "append_split_3D", "(", "segments_number", "=", "segments_number", ",", "max_len", "=", "50", ",", "mode", "=", "'split'", ")", ")", "\n", "]", ")", "\n", "return", "manual_feats", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.morality.morality_readDict.readDict": [[10, 50], ["collections.OrderedDict", "enumerate", "wordList.items", "open", "enumerate", "open", "dictionaryFile.readlines", "re.sub", "re.split", "list", "len", "sys.exit", "re.sub.rstrip", "finalDict.append", "catLocation.append", "print", "re.split", "re.split", "re.sub.rstrip"], "function", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split", "home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split"], ["def", "readDict", "(", "dictionaryPath", ")", ":", "\n", "    ", "catList", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "catLocation", "=", "[", "]", "\n", "wordList", "=", "{", "}", "\n", "finalDict", "=", "[", "]", "\n", "\n", "# Check to make sure the dictionary is properly formatted", "\n", "with", "open", "(", "dictionaryPath", ",", "\"r\"", ")", "as", "dictionaryFile", ":", "\n", "        ", "for", "idx", ",", "item", "in", "enumerate", "(", "dictionaryFile", ")", ":", "\n", "            ", "if", "\"%\"", "in", "item", ":", "\n", "                ", "catLocation", ".", "append", "(", "idx", ")", "\n", "", "", "if", "len", "(", "catLocation", ")", ">", "2", ":", "\n", "# There are apparently more than two category sections; throw error and die", "\n", "            ", "sys", ".", "exit", "(", "\"Invalid dictionary format. Check the number/locations of the category delimiters (%).\"", ")", "\n", "\n", "# Read dictionary as lines", "\n", "", "", "with", "open", "(", "dictionaryPath", ",", "\"r\"", ")", "as", "dictionaryFile", ":", "\n", "        ", "lines", "=", "dictionaryFile", ".", "readlines", "(", ")", "\n", "\n", "# Within the category section of the dictionary file, grab the numbers associated with each category", "\n", "", "for", "line", "in", "lines", "[", "catLocation", "[", "0", "]", "+", "1", ":", "catLocation", "[", "1", "]", "]", ":", "\n", "        ", "try", ":", "\n", "            ", "catList", "[", "re", ".", "split", "(", "r'\\s{20}'", ",", "line", ")", "[", "0", "]", "]", "=", "[", "re", ".", "split", "(", "r'\\s{20}'", ",", "line", ".", "rstrip", "(", ")", ")", "[", "1", "]", "]", "\n", "", "except", "Exception", "as", "ex", ":", "\n", "            ", "print", "(", "ex", ")", "\n", "\n", "# Now move on to the words", "\n", "", "", "for", "idx", ",", "line", "in", "enumerate", "(", "lines", "[", "catLocation", "[", "1", "]", "+", "1", ":", "]", ")", ":", "\n", "# Get each line (row), and split it by tabs (\\t)", "\n", "        ", "line", "=", "re", ".", "sub", "(", "'(?<=[a-zA-Z*])\\s+(?=\\d{2})'", ",", "' '", ",", "line", ".", "rstrip", "(", ")", ")", "\n", "workingRow", "=", "re", ".", "split", "(", "' '", ",", "line", ")", "\n", "wordList", "[", "workingRow", "[", "0", "]", "]", "=", "list", "(", "workingRow", "[", "1", ":", "]", ")", "\n", "\n", "# Merge the category list and the word list", "\n", "\n", "", "for", "key", ",", "values", "in", "wordList", ".", "items", "(", ")", ":", "\n", "        ", "for", "catnum", "in", "values", ":", "\n", "            ", "workingValue", "=", "catList", "[", "catnum", "]", "[", "0", "]", "\n", "finalDict", ".", "append", "(", "[", "key", ",", "workingValue", "]", ")", "\n", "", "", "return", "finalDict", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.morality.morality.MORALITY_class.__init__": [[8, 28], ["features.morality.morality_readDict.readDict", "pandas.DataFrame", "morality.MORALITY_class.mor[].map", "pandas.pivot_table().reset_index().reindex", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "[].tolist", "os.path.join", "re.sub", "pandas.pivot_table().reset_index", "pandas.pivot_table"], "methods", ["home.repos.pwc.inspect_result.bilalghanem_fake_flow.morality.morality_readDict.readDict"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ")", ":", "\n", "# Morality", "\n", "        ", "self", ".", "mor", "=", "readDict", "(", "join", "(", "path", ",", "'moral foundations dictionary-edited.dic'", ")", ")", "\n", "self", ".", "mor", "=", "pd", ".", "DataFrame", "(", "self", ".", "mor", ",", "columns", "=", "[", "'word'", ",", "'category'", "]", ")", "\n", "self", ".", "mor", "[", "'word'", "]", "=", "self", ".", "mor", "[", "'word'", "]", ".", "map", "(", "lambda", "x", ":", "re", ".", "sub", "(", "r'[*]'", ",", "''", ",", "x", ")", ")", "\n", "self", ".", "mor", "[", "'value'", "]", "=", "1", "\n", "self", ".", "mor", "=", "pd", ".", "pivot_table", "(", "self", ".", "mor", ",", "index", "=", "'word'", ",", "columns", "=", "[", "'category'", "]", ",", "\n", "values", "=", "'value'", ",", "fill_value", "=", "0", ")", ".", "reset_index", "(", ")", ".", "reindex", "(", "[", "'word'", ",", "'HarmVirtue'", ",", "'HarmVice'", ",", "'FairnessVirtue'", ",", "'FairnessVice'", ",", "'IngroupVirtue'", ",", "'IngroupVice'", ",", "'AuthorityVirtue'", ",", "'AuthorityVice'", ",", "'PurityVirtue'", ",", "'PurityVice'", ",", "'MoralityGeneral'", "]", ",", "axis", "=", "1", ")", "\n", "\n", "self", ".", "HarmVirtue", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'HarmVirtue'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "HarmVice", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'HarmVice'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "FairnessVirtue", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'FairnessVirtue'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "FairnessVice", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'FairnessVice'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "IngroupVirtue", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'IngroupVirtue'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "IngroupVice", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'IngroupVice'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "AuthorityVirtue", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'AuthorityVirtue'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "AuthorityVice", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'AuthorityVice'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "PurityVirtue", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'PurityVirtue'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "PurityVice", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'PurityVice'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "MoralityGeneral", "=", "self", ".", "mor", "[", "self", ".", "mor", "[", "'MoralityGeneral'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.morality.morality.MORALITY_class.score": [[29, 49], ["results.append", "len", "results.append"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "words", "=", "sentence", "\n", "results", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "HarmVirtue", "=", "1", "if", "word", "in", "self", ".", "HarmVirtue", "else", "0", "\n", "HarmVice", "=", "1", "if", "word", "in", "self", ".", "HarmVice", "else", "0", "\n", "FairnessVirtue", "=", "1", "if", "word", "in", "self", ".", "FairnessVirtue", "else", "0", "\n", "FairnessVice", "=", "1", "if", "word", "in", "self", ".", "FairnessVice", "else", "0", "\n", "IngroupVirtue", "=", "1", "if", "word", "in", "self", ".", "IngroupVirtue", "else", "0", "\n", "IngroupVice", "=", "1", "if", "word", "in", "self", ".", "IngroupVice", "else", "0", "\n", "AuthorityVirtue", "=", "1", "if", "word", "in", "self", ".", "AuthorityVirtue", "else", "0", "\n", "AuthorityVice", "=", "1", "if", "word", "in", "self", ".", "AuthorityVice", "else", "0", "\n", "PurityVirtue", "=", "1", "if", "word", "in", "self", ".", "PurityVirtue", "else", "0", "\n", "PurityVice", "=", "1", "if", "word", "in", "self", ".", "PurityVice", "else", "0", "\n", "MoralityGeneral", "=", "1", "if", "word", "in", "self", ".", "MoralityGeneral", "else", "0", "\n", "results", ".", "append", "(", "[", "HarmVirtue", ",", "HarmVice", ",", "FairnessVirtue", ",", "FairnessVice", ",", "IngroupVirtue", ",", "IngroupVice", ",", "\n", "AuthorityVirtue", ",", "AuthorityVice", ",", "PurityVirtue", ",", "PurityVice", ",", "MoralityGeneral", "]", ")", "\n", "", "if", "len", "(", "results", ")", "==", "0", ":", "\n", "            ", "results", ".", "append", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.sentiment.loading_sentiment_lexicons.sentiment_lexicons.__init__": [[6, 11], ["pandas.read_csv", "loading_sentiment_lexicons.sentiment_lexicons.nrc.pivot().reset_index", "[].tolist", "[].tolist", "os.path.join", "loading_sentiment_lexicons.sentiment_lexicons.nrc.pivot"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ")", ":", "\n", "        ", "self", ".", "nrc", "=", "pd", ".", "read_csv", "(", "join", "(", "path", ",", "'nrc.txt'", ")", ",", "sep", "=", "'\\t'", ",", "names", "=", "[", "\"word\"", ",", "\"emotion\"", ",", "\"association\"", "]", ")", "\n", "self", ".", "nrc", "=", "self", ".", "nrc", ".", "pivot", "(", "index", "=", "'word'", ",", "columns", "=", "'emotion'", ",", "values", "=", "'association'", ")", ".", "reset_index", "(", ")", "\n", "self", ".", "positive", "=", "self", ".", "nrc", "[", "self", ".", "nrc", "[", "'positive'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "negative", "=", "self", ".", "nrc", "[", "self", ".", "nrc", "[", "'negative'", "]", "==", "1", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.sentiment.loading_sentiment_lexicons.sentiment_lexicons.score": [[12, 27], ["words.append", "len", "words.append"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "words", "=", "[", "]", "\n", "for", "word", "in", "sentence", ":", "\n", "            ", "try", ":", "\n", "                ", "pos", "=", "1", "if", "word", "in", "self", ".", "positive", "else", "0", "\n", "neg", "=", "1", "if", "word", "in", "self", ".", "negative", "else", "0", "\n", "result", "=", "[", "pos", ",", "neg", "]", "\n", "", "except", ":", "\n", "                ", "result", "=", "[", "0", ",", "0", "]", "\n", "pass", "\n", "", "words", ".", "append", "(", "result", ")", "\n", "\n", "", "if", "len", "(", "words", ")", "==", "0", ":", "\n", "            ", "words", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.hyperbolic.hyperbolic.hyperbolic_class.__init__": [[6, 9], ["pandas.read_csv", "hyperbolic.hyperbolic_class.reader[].tolist", "os.path.join"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ")", ":", "\n", "        ", "self", ".", "reader", "=", "pd", ".", "read_csv", "(", "join", "(", "path", ",", "'hyperbolic'", ")", ",", "sep", "=", "'\\n'", ",", "names", "=", "[", "\"word\"", "]", ")", "\n", "self", ".", "hyper", "=", "self", ".", "reader", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.hyperbolic.hyperbolic.hyperbolic_class.score": [[10, 20], ["results.append", "len", "results.append"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "words", "=", "sentence", "\n", "results", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "hyper", "=", "1", "if", "word", "in", "self", ".", "hyper", "else", "0", "\n", "results", ".", "append", "(", "[", "hyper", "]", ")", "\n", "\n", "", "if", "len", "(", "results", ")", "==", "0", ":", "\n", "            ", "results", ".", "append", "(", "[", "0", "]", ")", "\n", "", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.imageability.imageability.imageability_class.__init__": [[7, 16], ["pandas.read_csv", "imageability.imageability_class.reader[].tolist", "pandas.DataFrame", "pandas.DataFrame.rename", "pandas.concat", "[].tolist", "[].tolist", "os.path.join", "ast.literal_eval"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", "=", "''", ")", ":", "\n", "        ", "self", ".", "reader", "=", "pd", ".", "read_csv", "(", "join", "(", "path", ",", "'imageability.predictions'", ")", ",", "sep", "=", "'\\t'", ",", "names", "=", "[", "\"word\"", ",", "\"class\"", ",", "\"association\"", "]", ")", "\n", "association", "=", "self", ".", "reader", "[", "'association'", "]", ".", "tolist", "(", ")", "\n", "association", "=", "pd", ".", "DataFrame", "(", "[", "ast", ".", "literal_eval", "(", "item", ")", "for", "item", "in", "association", "]", ")", "\n", "association", ".", "rename", "(", "columns", "=", "{", "'A'", ":", "'imageability_prob'", ",", "'C'", ":", "'abstraction_prob'", "}", ",", "inplace", "=", "True", ")", "\n", "del", "self", ".", "reader", "[", "'association'", "]", "\n", "self", ".", "reader", "=", "pd", ".", "concat", "(", "[", "self", ".", "reader", ",", "association", "]", ",", "axis", "=", "1", ")", "\n", "self", ".", "img", "=", "self", ".", "reader", "[", "(", "self", ".", "reader", "[", "'imageability_prob'", "]", ">", "0.9", ")", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "self", ".", "abs", "=", "self", ".", "reader", "[", "(", "self", ".", "reader", "[", "'abstraction_prob'", "]", ">", "0.8", ")", "]", "[", "'word'", "]", ".", "tolist", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.imageability.imageability.imageability_class.score": [[17, 27], ["results.append", "len", "results.append"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "words", "=", "sentence", "\n", "results", "=", "[", "]", "\n", "for", "word", "in", "words", ":", "\n", "            ", "img", "=", "1", "if", "word", "in", "self", ".", "img", "else", "0", "\n", "abs", "=", "1", "if", "word", "in", "self", ".", "abs", "else", "0", "\n", "results", ".", "append", "(", "[", "img", ",", "abs", "]", ")", "\n", "", "if", "len", "(", "results", ")", "==", "0", ":", "\n", "            ", "results", ".", "append", "(", "[", "0", ",", "0", "]", ")", "\n", "", "return", "results", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.emotional.loading_emotional_lexicons.emotional_lexicons.__init__": [[9, 22], ["pandas.read_csv", "loading_emotional_lexicons.emotional_lexicons.nrc.pivot().reset_index", "pandas.read_csv", "loading_emotional_lexicons.emotional_lexicons.nrc_intensity.pivot().reset_index", "loading_emotional_lexicons.emotional_lexicons.nrc_intensity.fillna", "os.path.join", "os.path.join", "loading_emotional_lexicons.emotional_lexicons.nrc.pivot", "loading_emotional_lexicons.emotional_lexicons.nrc_intensity.pivot"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "path", ")", ":", "\n", "        ", "self", ".", "lexicons_path", "=", "path", "\n", "\n", "# NRC, plutchik", "\n", "self", ".", "nrc", "=", "pd", ".", "read_csv", "(", "join", "(", "self", ".", "lexicons_path", ",", "'nrc.txt'", ")", ",", "sep", "=", "'\\t'", ",", "names", "=", "[", "\"word\"", ",", "\"emotion\"", ",", "\"association\"", "]", ")", "\n", "self", ".", "nrc", "=", "self", ".", "nrc", ".", "pivot", "(", "index", "=", "'word'", ",", "columns", "=", "'emotion'", ",", "values", "=", "'association'", ")", ".", "reset_index", "(", ")", "\n", "del", "self", ".", "nrc", "[", "'positive'", "]", "\n", "del", "self", ".", "nrc", "[", "'negative'", "]", "\n", "\n", "# NRC (intensity), plutchik", "\n", "self", ".", "nrc_intensity", "=", "pd", ".", "read_csv", "(", "join", "(", "self", ".", "lexicons_path", ",", "'NRC-AffectIntensity-Lexicon.txt'", ")", ",", "sep", "=", "'\\t'", ",", "names", "=", "[", "\"word\"", ",", "\"score\"", ",", "\"emotion\"", "]", ",", "skiprows", "=", "1", ")", "\n", "self", ".", "nrc_intensity", "=", "self", ".", "nrc_intensity", ".", "pivot", "(", "index", "=", "'word'", ",", "columns", "=", "'emotion'", ",", "values", "=", "'score'", ")", ".", "reset_index", "(", ")", "\n", "self", ".", "nrc_intensity", ".", "fillna", "(", "value", "=", "0", ",", "inplace", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.emotional.loading_emotional_lexicons.emotional_lexicons.frequency": [[25, 38], ["words.append", "len", "words.append", "loading_emotional_lexicons.emotional_lexicons.nrc[].values.tolist", "str"], "methods", ["None"], ["", "def", "frequency", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "words", "=", "[", "]", "\n", "for", "word", "in", "sentence", ":", "\n", "            ", "try", ":", "\n", "                ", "result", "=", "self", ".", "nrc", "[", "self", ".", "nrc", ".", "word", "==", "str", "(", "word", ")", "]", ".", "values", ".", "tolist", "(", ")", "[", "0", "]", "[", "1", ":", "]", "\n", "", "except", ":", "\n", "                ", "result", "=", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "pass", "\n", "", "words", ".", "append", "(", "result", ")", "\n", "\n", "", "if", "len", "(", "words", ")", "==", "0", ":", "\n", "            ", "words", ".", "append", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "return", "words", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.emotional.loading_emotional_lexicons.emotional_lexicons.intensity": [[39, 51], ["words.append", "len", "words.append", "loading_emotional_lexicons.emotional_lexicons.nrc_intensity[].values.tolist", "str"], "methods", ["None"], ["", "def", "intensity", "(", "self", ",", "sentence", ")", ":", "\n", "        ", "words", "=", "[", "]", "\n", "for", "word", "in", "sentence", ":", "\n", "            ", "try", ":", "\n", "                ", "result", "=", "self", ".", "nrc_intensity", "[", "self", ".", "nrc_intensity", ".", "word", "==", "str", "(", "word", ")", "]", ".", "values", ".", "tolist", "(", ")", "[", "0", "]", "[", "1", ":", "]", "\n", "", "except", ":", "\n", "                ", "result", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "pass", "\n", "", "words", ".", "append", "(", "result", ")", "\n", "", "if", "len", "(", "words", ")", "==", "0", ":", "\n", "            ", "words", ".", "append", "(", "[", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "return", "words", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bilalghanem_fake_flow.data.utils.split": [[7, 39], ["sklearn.utils.shuffle", "train.rename.reset_index().reset_index", "train.rename.rename", "sklearn.utils.shuffle", "test.rename.reset_index().reset_index", "test.rename.rename", "numpy.random.rand", "train.rename.reset_index", "test.rename.reset_index", "len"], "function", ["None"], ["def", "split", "(", "data", ",", "data_features", ",", "return_features", ",", "dev_ratio", "=", "0.3", ")", ":", "\n", "    ", "train", "=", "data", "[", "data", ".", "type", "==", "'training'", "]", "\n", "train_features", "=", "data_features", "[", "train", ".", "index", ",", ":", ",", ":", "]", "if", "return_features", "else", "[", "]", "\n", "train", "=", "shuffle", "(", "train", ")", "\n", "train", "=", "train", ".", "reset_index", "(", "drop", "=", "True", ")", ".", "reset_index", "(", ")", "\n", "del", "train", "[", "'id'", "]", "\n", "train", "=", "train", ".", "rename", "(", "columns", "=", "{", "'index'", ":", "'id'", "}", ")", "\n", "\n", "test", "=", "data", "[", "data", ".", "type", "==", "'test'", "]", "\n", "test_features", "=", "data_features", "[", "test", ".", "index", ",", ":", ",", ":", "]", "if", "return_features", "else", "[", "]", "\n", "test", "=", "shuffle", "(", "test", ")", "\n", "test", "=", "test", ".", "reset_index", "(", "drop", "=", "True", ")", ".", "reset_index", "(", ")", "\n", "del", "test", "[", "'id'", "]", "\n", "test", "=", "test", ".", "rename", "(", "columns", "=", "{", "'index'", ":", "'id'", "}", ")", "\n", "\n", "self_train", "=", "{", "}", "\n", "self_dev", "=", "{", "}", "\n", "self_test", "=", "{", "}", "\n", "\n", "msk_dev", "=", "np", ".", "random", ".", "rand", "(", "len", "(", "train", ")", ")", "<", "dev_ratio", "\n", "self_dev", "[", "'text'", "]", "=", "train", "[", "'content'", "]", "[", "msk_dev", "]", "\n", "self_dev", "[", "'features'", "]", "=", "train_features", "[", "msk_dev", ",", ":", ",", ":", "]", "if", "return_features", "else", "[", "]", "\n", "self_dev", "[", "'label'", "]", "=", "train", "[", "'label'", "]", "[", "msk_dev", "]", "\n", "train", "=", "train", "[", "~", "msk_dev", "]", "\n", "self_train", "[", "'text'", "]", "=", "train", "[", "'content'", "]", "\n", "self_train", "[", "'features'", "]", "=", "train_features", "[", "~", "msk_dev", ",", ":", ",", ":", "]", "if", "return_features", "else", "[", "]", "\n", "self_train", "[", "'label'", "]", "=", "train", "[", "'label'", "]", "\n", "\n", "self_test", "[", "'text'", "]", "=", "test", "[", "'content'", "]", "\n", "self_test", "[", "'features'", "]", "=", "test_features", "if", "return_features", "else", "[", "]", "\n", "self_test", "[", "'label'", "]", "=", "test", "[", "'label'", "]", "\n", "return", "self_train", ",", "self_dev", ",", "self_test", "\n", "", ""]]}