{"home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.cross_validate_all": [[37, 73], ["print", "sklearn.dummy.DummyClassifier", "sklearn.dummy.DummyClassifier", "sklearn.dummy.DummyClassifier", "sklearn.model_selection.KFold", "sklearn.model_selection.cross_validate", "sklearn.model_selection.cross_validate", "sklearn.model_selection.cross_validate", "sklearn.model_selection.cross_validate", "numpy.around", "numpy.around", "numpy.around", "numpy.around", "numpy.around", "numpy.around", "dum_uniform_scores[].mean", "dum_stratified_scores[].mean", "dum_freq_scores[].mean", "numpy.around", "numpy.around", "numpy.around", "scores[].mean", "scores[].std", "scores[].mean", "scores[].std", "scores[].mean", "scores[].std"], "function", ["None"], ["def", "cross_validate_all", "(", "model", ",", "data", ",", "labels", ")", ":", "\n", "    ", "\"\"\"Pass the data and model to the cross validation function\"\"\"", "\n", "\n", "print", "(", "\"Running Cross Validation\"", ")", "\n", "model", "=", "model", "\n", "dum_unifrom", "=", "DummyClassifier", "(", "strategy", "=", "'uniform'", ")", "#uniform most_frequent stratified", "\n", "dum_stratified", "=", "DummyClassifier", "(", "strategy", "=", "'stratified'", ")", "\n", "dum_freq", "=", "DummyClassifier", "(", "strategy", "=", "'most_frequent'", ")", "\n", "\n", "scoring", "=", "[", "'accuracy'", ",", "'f1_micro'", ",", "'f1_macro'", "]", "\n", "\n", "cv", "=", "KFold", "(", "n_splits", "=", "5", ",", "shuffle", "=", "True", ",", "random_state", "=", "42", ")", "\n", "scores", "=", "cross_validate", "(", "model", ",", "data", ",", "labels", ",", "scoring", "=", "scoring", ",", "cv", "=", "cv", ",", "return_train_score", "=", "False", ",", "n_jobs", "=", "-", "1", ")", "\n", "dum_uniform_scores", "=", "cross_validate", "(", "dum_unifrom", ",", "data", ",", "labels", ",", "scoring", "=", "scoring", ",", "cv", "=", "cv", ",", "return_train_score", "=", "False", ",", "n_jobs", "=", "-", "1", ")", "\n", "dum_stratified_scores", "=", "cross_validate", "(", "dum_stratified", ",", "data", ",", "labels", ",", "scoring", "=", "scoring", ",", "cv", "=", "cv", ",", "return_train_score", "=", "False", ",", "n_jobs", "=", "-", "1", ")", "\n", "dum_freq_scores", "=", "cross_validate", "(", "dum_freq", ",", "data", ",", "labels", ",", "scoring", "=", "scoring", ",", "cv", "=", "cv", ",", "return_train_score", "=", "False", ",", "n_jobs", "=", "-", "1", ")", "\n", "\n", "acc_mean", "=", "np", ".", "around", "(", "scores", "[", "'test_accuracy'", "]", ".", "mean", "(", ")", ",", "decimals", "=", "3", ")", "\n", "acc_std", "=", "np", ".", "around", "(", "scores", "[", "'test_accuracy'", "]", ".", "std", "(", ")", ",", "decimals", "=", "3", ")", "\n", "\n", "micro_mean", "=", "np", ".", "around", "(", "scores", "[", "'test_f1_micro'", "]", ".", "mean", "(", ")", ",", "decimals", "=", "3", ")", "\n", "micro_std", "=", "np", ".", "around", "(", "scores", "[", "'test_f1_micro'", "]", ".", "std", "(", ")", ",", "decimals", "=", "3", ")", "\n", "\n", "macro_mean", "=", "np", ".", "around", "(", "scores", "[", "'test_f1_macro'", "]", ".", "mean", "(", ")", ",", "decimals", "=", "3", ")", "\n", "macro_std", "=", "np", ".", "around", "(", "scores", "[", "'test_f1_macro'", "]", ".", "std", "(", ")", ",", "decimals", "=", "3", ")", "\n", "\n", "# calculate the lift over random score", "\n", "dum_mean", "=", "dum_uniform_scores", "[", "'test_f1_micro'", "]", ".", "mean", "(", ")", "\n", "strat_mean", "=", "dum_stratified_scores", "[", "'test_f1_micro'", "]", ".", "mean", "(", ")", "\n", "freq_mean", "=", "dum_freq_scores", "[", "'test_f1_micro'", "]", ".", "mean", "(", ")", "\n", "\n", "dum_lift_mean", "=", "np", ".", "around", "(", "(", "(", "acc_mean", "-", "dum_mean", ")", "/", "dum_mean", ")", "*", "100", ",", "decimals", "=", "2", ")", "\n", "strat_lift_mean", "=", "np", ".", "around", "(", "(", "(", "acc_mean", "-", "strat_mean", ")", "/", "strat_mean", ")", "*", "100", ",", "decimals", "=", "2", ")", "\n", "freq_lift_mean", "=", "np", ".", "around", "(", "(", "(", "acc_mean", "-", "freq_mean", ")", "/", "freq_mean", ")", "*", "100", ",", "decimals", "=", "2", ")", "\n", "\n", "return", "acc_mean", ",", "acc_std", ",", "micro_mean", ",", "micro_std", ",", "macro_mean", ",", "macro_std", ",", "dum_lift_mean", ",", "strat_lift_mean", ",", "freq_lift_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.run_linear_reg": [[80, 114], ["sklearn.model_selection.train_test_split", "sklearn.neural_network.MLPRegressor", "sklearn.neural_network.MLPRegressor.fit", "nn_model.fit.predict", "print", "print", "print", "print", "matplotlib.scatter", "matplotlib.xticks", "matplotlib.yticks", "matplotlib.show", "sklearn.metrics.mean_squared_error", "sklearn.metrics.r2_score"], "function", ["None"], ["", "def", "run_linear_reg", "(", "X", ",", "Y", ",", "test_ratio", "=", "0.3", ")", ":", "\n", "\n", "#http://scikit-learn.org/stable/auto_examples/plot_cv_predict.html#sphx-glr-auto-examples-plot-cv-predict-py", "\n", "# http://scikit-learn.org/stable/modules/generated/sklearn.neural_network.MLPRegressor.html#sklearn.neural_network.MLPRegressor", "\n", "\n", "#Y = preprocessing.scale(Y, axis=0)", "\n", "\n", "    ", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", "=", "sk_ms", ".", "train_test_split", "(", "X", ",", "Y", ",", "train_size", "=", "test_ratio", ")", "\n", "\n", "# Create the logreg with balanced class weights ", "\n", "nn_model", "=", "MLPRegressor", "(", ")", "\n", "#Fit the model", "\n", "fit_nn", "=", "nn_model", ".", "fit", "(", "X_train", ",", "Y_train", ")", "\n", "\n", "# Predict on the test set", "\n", "pred", "=", "fit_nn", ".", "predict", "(", "X_test", ")", "\n", "\n", "print", "(", "pred", ")", "\n", "\n", "print", "(", "nn_model", ".", "loss_curve_", ")", "\n", "\n", "print", "(", "mean_squared_error", "(", "Y_test", ",", "pred", ")", ")", "\n", "print", "(", "r2_score", "(", "Y_test", ",", "pred", ")", ")", "\n", "\n", "\n", "# Plot outputs", "\n", "plt", ".", "scatter", "(", "Y_test", ",", "pred", ",", "color", "=", "'black'", ")", "\n", "\n", "plt", ".", "xticks", "(", "(", ")", ")", "\n", "plt", ".", "yticks", "(", "(", ")", ")", "\n", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.balanced_log_reg": [[115, 139], ["sklearn.model_selection.train_test_split", "sklearn.linear_model.LogisticRegression", "sklearn.linear_model.LogisticRegression.fit", "logreg.fit.score", "logreg.fit.predict", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "eval.dummy_classification", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.dummy_classification"], ["", "def", "balanced_log_reg", "(", "X", ",", "Y", ",", "test_ratio", "=", "0.2", ",", "class_weight", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run the logreg model\"\"\"", "\n", "\n", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", "=", "sk_ms", ".", "train_test_split", "(", "X", ",", "Y", ",", "test_size", "=", "test_ratio", ")", "\n", "\n", "# Create the logreg with balanced class weights ", "\n", "logreg", "=", "lr", "(", "class_weight", "=", "class_weight", ")", "\n", "#Fit the model", "\n", "fit_logreg", "=", "logreg", ".", "fit", "(", "X_train", ",", "Y_train", ")", "\n", "# Get the model acccuracy", "\n", "score", "=", "fit_logreg", ".", "score", "(", "X_test", ",", "Y_test", ")", "\n", "# Predict on the test set", "\n", "pred", "=", "fit_logreg", ".", "predict", "(", "X_test", ")", "\n", "\n", "micro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'micro'", ")", "\n", "macro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "a", ",", "mic", ",", "mac", "=", "dummy_classification", "(", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", ",", "'most_frequent'", ")", "\n", "\n", "print", "(", "a", ")", "\n", "print", "(", "mic", ")", "\n", "print", "(", "mac", ")", "\n", "\n", "return", "score", ",", "micro", ",", "macro", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.balanced_SVM": [[141, 168], ["sklearn.model_selection.train_test_split", "print", "sklearn.svm.SVC", "sklearn.svm.SVC.fit", "svm_model.fit.score", "svm_model.fit.predict", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score", "eval.dummy_classification", "print", "print", "print", "numpy.unique"], "function", ["home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.dummy_classification"], ["", "def", "balanced_SVM", "(", "X", ",", "Y", ",", "test_ratio", "=", "0.2", ",", "class_weight", "=", "None", ")", ":", "\n", "    ", "\"\"\"Run the SVM model with cbf kernel\"\"\"", "\n", "\n", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", "=", "sk_ms", ".", "train_test_split", "(", "X", ",", "Y", ",", "test_size", "=", "test_ratio", ")", "\n", "\n", "# USE THIS! to calculate the random guess level and level for just predicting the majority class", "\n", "print", "(", "np", ".", "unique", "(", "Y_test", ",", "return_counts", "=", "True", ")", ")", "\n", "\n", "# Create the logreg with balanced class weights ", "\n", "svm_model", "=", "SVC", "(", "class_weight", "=", "class_weight", ")", "\n", "#Fit the model", "\n", "fit_svm", "=", "svm_model", ".", "fit", "(", "X_train", ",", "Y_train", ")", "\n", "# Get the model acccuracy", "\n", "score", "=", "fit_svm", ".", "score", "(", "X_test", ",", "Y_test", ")", "\n", "# Predict on the test set", "\n", "pred", "=", "fit_svm", ".", "predict", "(", "X_test", ")", "\n", "\n", "micro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'micro'", ")", "\n", "macro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "a", ",", "mic", ",", "mac", "=", "dummy_classification", "(", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", ",", "'most_frequent'", ")", "\n", "\n", "print", "(", "a", ")", "\n", "print", "(", "mic", ")", "\n", "print", "(", "mac", ")", "\n", "\n", "return", "score", ",", "micro", ",", "macro", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.balanced_NN": [[169, 187], ["sklearn.model_selection.train_test_split", "sklearn.neural_network.MLPClassifier", "sklearn.neural_network.MLPClassifier.fit", "nn_model.fit.score", "nn_model.fit.predict", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score"], "function", ["None"], ["", "def", "balanced_NN", "(", "X", ",", "Y", ",", "train_ratio", "=", "0.9", ")", ":", "\n", "    ", "\"\"\"Run the NN model\"\"\"", "\n", "\n", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", "=", "sk_ms", ".", "train_test_split", "(", "X", ",", "Y", ",", "train_size", "=", "train_ratio", ")", "\n", "\n", "# Create the logreg with balanced class weights ", "\n", "nn_model", "=", "MLPClassifier", "(", "hidden_layer_sizes", "=", "(", "500", ",", ")", ")", "\n", "#Fit the model", "\n", "fit_nn", "=", "nn_model", ".", "fit", "(", "X_train", ",", "Y_train", ")", "\n", "# Get the model acccuracy", "\n", "score", "=", "fit_nn", ".", "score", "(", "X_test", ",", "Y_test", ")", "\n", "# Predict on the test set", "\n", "pred", "=", "fit_nn", ".", "predict", "(", "X_test", ")", "\n", "\n", "micro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'micro'", ")", "\n", "macro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "return", "score", ",", "micro", ",", "macro", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.dummy_classification": [[188, 199], ["sklearn.dummy.DummyClassifier", "sklearn.dummy.DummyClassifier.fit", "dum.fit.score", "dum.fit.predict", "sklearn.metrics.f1_score", "sklearn.metrics.f1_score"], "function", ["None"], ["", "def", "dummy_classification", "(", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", ",", "mode", ")", ":", "\n", "\n", "    ", "dum", "=", "DummyClassifier", "(", "strategy", "=", "mode", ")", "\n", "fit_dum", "=", "dum", ".", "fit", "(", "X_train", ",", "Y_train", ")", "\n", "score", "=", "fit_dum", ".", "score", "(", "X_test", ",", "Y_test", ")", "\n", "pred", "=", "fit_dum", ".", "predict", "(", "X_test", ")", "\n", "\n", "micro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'micro'", ")", "\n", "macro", "=", "f1_score", "(", "Y_test", ",", "pred", ",", "average", "=", "'macro'", ")", "\n", "\n", "return", "score", ",", "micro", ",", "macro", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.bins_values_and_create_class_labels": [[201, 223], ["numpy.histogram", "print", "print", "print", "range", "len", "class_array.append"], "function", ["None"], ["", "def", "bins_values_and_create_class_labels", "(", "labels", ",", "num_bins", ")", ":", "\n", "    ", "\"\"\"Bin the labels based on a histogram\"\"\"", "\n", "\n", "n", ",", "bins", "=", "np", ".", "histogram", "(", "labels", ",", "bins", "=", "num_bins", ")", "\n", "class_array", "=", "[", "]", "\n", "\n", "print", "(", "\"Bin edges and counts\"", ")", "\n", "print", "(", "bins", ")", "\n", "print", "(", "n", ")", "\n", "\n", "# https://docs.scipy.org/doc/numpy/reference/generated/numpy.digitize.html", "\n", "\n", "# Loop through labels and bin based on histogram", "\n", "for", "val", "in", "labels", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "bins", ")", "-", "1", ")", ":", "\n", "            ", "if", "val", ">=", "bins", "[", "i", "]", "and", "val", "<=", "bins", "[", "i", "+", "1", "]", ":", "\n", "                ", "class_array", ".", "append", "(", "i", ")", "\n", "break", "\n", "\n", "", "", "", "labels", "=", "class_array", "\n", "\n", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.load_and_preprocess_data": [[224, 276], ["networkx.read_gpickle", "print", "print", "numpy.absolute", "nx.get_node_attributes.astype", "networkx.get_node_attributes", "print", "numpy.asarray", "numpy.where", "numpy.where", "print", "numpy.log", "networkx.get_node_attributes", "print", "list", "networkx.get_node_attributes", "print", "nx.get_node_attributes.values", "networkx.get_node_attributes", "print", "networkx.get_node_attributes", "print", "networkx.get_node_attributes", "print", "networkx.get_node_attributes", "print", "ValueError"], "function", ["None"], ["", "def", "load_and_preprocess_data", "(", "filename", ",", "feature", ",", "num_bins", ",", "norm", "=", "True", ")", ":", "\n", "    ", "\"\"\"Load and process the label data -- including the binning process for the features\"\"\"", "\n", "\n", "total_graph", "=", "nx", ".", "read_gpickle", "(", "filename", ")", "\n", "print", "(", "\"Graph Loaded\"", ")", "\n", "\n", "# extract graph features/labels", "\n", "if", "feature", "==", "1", ":", "\n", "        ", "labels", "=", "nx", ".", "get_node_attributes", "(", "total_graph", ",", "\"DEG\"", ")", "\n", "print", "(", "'Degree ======================================'", ")", "\n", "", "elif", "feature", "==", "2", ":", "\n", "        ", "labels", "=", "nx", ".", "get_node_attributes", "(", "total_graph", ",", "\"TR\"", ")", "\n", "print", "(", "'Triangle Count ======================================'", ")", "\n", "", "elif", "feature", "==", "3", ":", "\n", "        ", "labels", "=", "nx", ".", "get_node_attributes", "(", "total_graph", ",", "\"PR\"", ")", "\n", "print", "(", "'Page Rank ======================================'", ")", "\n", "", "elif", "feature", "==", "4", ":", "\n", "        ", "labels", "=", "nx", ".", "get_node_attributes", "(", "total_graph", ",", "\"DC\"", ")", "\n", "print", "(", "'Degree Centrality ======================================'", ")", "\n", "", "elif", "feature", "==", "5", ":", "\n", "        ", "labels", "=", "nx", ".", "get_node_attributes", "(", "total_graph", ",", "\"CLU\"", ")", "\n", "print", "(", "'Clustering Coefficient ======================================'", ")", "\n", "", "elif", "feature", "==", "6", ":", "\n", "        ", "labels", "=", "nx", ".", "get_node_attributes", "(", "total_graph", ",", "'EC'", ")", "\n", "print", "(", "'Eigen Vector Centrality ======================================'", ")", "\n", "", "elif", "feature", "==", "7", ":", "\n", "        ", "labels", "=", "nx", ".", "get_node_attributes", "(", "total_graph", ",", "'BC'", ")", "\n", "print", "(", "'Betweenness Centrality ======================================'", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid Feature Selection'", ")", "\n", "\n", "", "print", "(", "\"Labels Loaded\"", ")", "\n", "labels", "=", "np", ".", "absolute", "(", "np", ".", "asarray", "(", "list", "(", "labels", ".", "values", "(", ")", ")", ")", ")", "\n", "\n", "# Get the zero elements if any", "\n", "zero_elements", "=", "np", ".", "where", "(", "labels", "==", "0", ")", "[", "0", "]", "\n", "non_zeros", "=", "np", ".", "where", "(", "labels", "!=", "0", ")", "[", "0", "]", "\n", "\n", "# Take the log of the none zero elements", "\n", "if", "norm", ":", "\n", "        ", "print", "(", "\"Using Log Norm on Vertex Features\"", ")", "\n", "labels", "[", "non_zeros", "]", "=", "np", ".", "log", "(", "labels", "[", "non_zeros", "]", ")", "\n", "\n", "# Bin the non-zero labels", "\n", "# labels[non_zeros] = bins_values_and_create_class_labels(labels[non_zeros], num_bins)", "\n", "# # Add one to increase the class number of the none zero elements", "\n", "# labels = labels+1", "\n", "# # Create the zero labels as class zero (although should be zero anyway)", "\n", "# labels[zero_elements] = 0", "\n", "# print(\"Label Binning Completed\")", "\n", "\n", "", "return", "labels", ".", "astype", "(", "float", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.createErrorMatrix": [[277, 324], ["dataset_location.endswith", "eval.load_and_preprocess_data", "sklearn.model_selection.train_test_split", "sklearn.neural_network.MLPClassifier", "sklearn.neural_network.MLPClassifier.fit", "nn_model.fit.predict", "print", "numpy.unique", "confusion_matrix", "numpy.set_printoptions", "cnf_matrix.round.round", "matplotlib.rcParams.update", "matplotlib.rcParams.update", "matplotlib.figure", "gen_plots.plot_error_matrix", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.show", "print", "numpy.loadtxt", "ValueError", "numpy.unique", "cnf_matrix.round.astype", "cnf_matrix.round.sum", "dataset_location.split"], "function", ["home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.load_and_preprocess_data"], ["", "def", "createErrorMatrix", "(", ")", ":", "\n", "    ", "\"\"\"Create an error matrix for the multiclass model \"\"\"", "\n", "\n", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "import", "matplotlib", "\n", "from", "sklearn", ".", "metrics", "import", "confusion_matrix", "\n", "import", "itertools", "\n", "\n", "#dataset_location = '../data/embeddings/facebook_combined-node2vec-hom.emb'", "\n", "dataset_location", "=", "'../data/embeddings/soc-sign-bitcoinotc-autoenc.emb'", "\n", "labels_location", "=", "'../data/features/soc-sign-bitcoinotc.ini.gz'", "\n", "feature", "=", "2", "\n", "\n", "# Load the dataset in the required format", "\n", "if", "dataset_location", ".", "endswith", "(", "'.emb'", ")", ":", "\n", "        ", "print", "(", "\"Loading .emb file  -  \"", "+", "dataset_location", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "data", "=", "np", ".", "loadtxt", "(", "dataset_location", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid file format'", ")", "\n", "\n", "", "labels", "=", "load_and_preprocess_data", "(", "labels_location", ",", "feature", ",", "6", ",", "norm", "=", "True", ")", "\n", "X_train", ",", "X_test", ",", "Y_train", ",", "Y_test", "=", "sk_ms", ".", "train_test_split", "(", "data", ",", "labels", ",", "train_size", "=", "0.6", ")", "\n", "\n", "# Create the NN with balanced class weights ", "\n", "nn_model", "=", "MLPClassifier", "(", "hidden_layer_sizes", "=", "(", "500", ",", ")", ")", "\n", "#Fit the model", "\n", "fit_nn", "=", "nn_model", ".", "fit", "(", "X_train", ",", "Y_train", ")", "\n", "y_pred", "=", "fit_nn", ".", "predict", "(", "X_test", ")", "\n", "\n", "print", "(", "np", ".", "unique", "(", "Y_test", ")", ")", "\n", "class_names", "=", "np", ".", "unique", "(", "Y_test", ")", "\n", "\n", "# Compute confusion matrix", "\n", "cnf_matrix", "=", "confusion_matrix", "(", "Y_test", ",", "y_pred", ",", "labels", "=", "class_names", ")", "\n", "np", ".", "set_printoptions", "(", "precision", "=", "2", ")", "\n", "\n", "# Normalise", "\n", "cnf_matrix", "=", "cnf_matrix", ".", "astype", "(", "'float'", ")", "/", "cnf_matrix", ".", "sum", "(", "axis", "=", "1", ")", "[", ":", ",", "np", ".", "newaxis", "]", "\n", "cnf_matrix", "=", "cnf_matrix", ".", "round", "(", "4", ")", "\n", "matplotlib", ".", "rcParams", ".", "update", "(", "{", "'font.size'", ":", "16", "}", ")", "\n", "\n", "# Plot normalized confusion matrix", "\n", "plt", ".", "figure", "(", ")", "\n", "ut", ".", "plot_error_matrix", "(", "cnf_matrix", ",", "classes", "=", "class_names", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "'EM-facebook_combined-node2vec-hom.pdf'", ",", "format", "=", "'PDF'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.generate_classification_alg_choice_results": [[325, 363], ["dataset_location.endswith", "print", "numpy.loadtxt", "ValueError", "eval.load_and_preprocess_data", "sklearn.svm.SVC", "sklearn.svm.SVC", "sklearn.linear_model.LogisticRegression", "sklearn.neural_network.MLPClassifier", "sklearn.neural_network.MLPClassifier", "eval.cross_validate_all", "print", "print", "print", "print", "print", "print", "print", "dataset_location.split"], "function", ["home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.load_and_preprocess_data", "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.cross_validate_all"], ["", "def", "generate_classification_alg_choice_results", "(", "bins", "=", "5", ",", "norm", "=", "True", ",", "balance", "=", "None", ")", ":", "\n", "\n", "    ", "dataset_location", "=", "'../data/embeddings/facebook_combined-autoenc.emb'", "\n", "labels_location", "=", "'../data/features/facebook_combined.ini.gz'", "\n", "\n", "# Load the dataset in the required format", "\n", "if", "dataset_location", ".", "endswith", "(", "'.emb'", ")", ":", "\n", "        ", "print", "(", "\"Loading .emb file  -  \"", "+", "dataset_location", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "data", "=", "np", ".", "loadtxt", "(", "dataset_location", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid file format'", ")", "\n", "\n", "", "test_feats", "=", "[", "1", ",", "2", ",", "6", "]", "\n", "\n", "# loop through all the features", "\n", "for", "i", "in", "test_feats", ":", "\n", "\n", "# Load the labels", "\n", "        ", "labels", "=", "load_and_preprocess_data", "(", "labels_location", ",", "i", ",", "bins", ",", "norm", "=", "norm", ")", "\n", "\n", "svm_lin", "=", "SVC", "(", "kernel", "=", "'linear'", ",", "class_weight", "=", "balance", ")", "\n", "svm", "=", "SVC", "(", "class_weight", "=", "balance", ")", "\n", "logr", "=", "lr", "(", "class_weight", "=", "balance", ")", "\n", "nn", "=", "MLPClassifier", "(", ")", "\n", "complex_nn", "=", "MLPClassifier", "(", "hidden_layer_sizes", "=", "(", "1000", ",", "500", ")", ")", "\n", "models", "=", "[", "logr", ",", "svm_lin", ",", "svm", ",", "nn", ",", "complex_nn", "]", "\n", "\n", "for", "model", "in", "models", ":", "\n", "            ", "acc_mean", ",", "acc_std", ",", "micro_mean", ",", "micro_std", ",", "macro_mean", ",", "macro_std", ",", "dum_lift_mean", ",", "strat_lift_mean", ",", "freq_lift_mean", "=", "cross_validate_all", "(", "model", ",", "data", ",", "labels", ")", "\n", "print", "(", "model", ")", "\n", "print", "(", "'Micro'", ",", "micro_mean", ",", "'+'", ",", "micro_std", ")", "\n", "print", "(", "'Macro'", ",", "macro_mean", ",", "'+'", ",", "macro_std", ")", "\n", "print", "(", "'Uniform Lift'", ",", "dum_lift_mean", ")", "\n", "print", "(", "'Stratified Lift'", ",", "strat_lift_mean", ")", "\n", "print", "(", "'Freq Lift'", ",", "freq_lift_mean", ")", "\n", "print", "(", "'---------------------------------------------------------------'", ")", "\n", "\n", "", "", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.run_multi_class": [[364, 424], ["dataset_location.endswith", "eval.load_and_preprocess_data", "print", "numpy.loadtxt", "ValueError", "print", "range", "mean_score.append", "mean_micro.append", "mean_macro.append", "std_score.append", "std_micro.append", "std_macro.append", "eval.balanced_log_reg", "average_score.append", "average_micro.append", "average_macro.append", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.std", "numpy.std", "numpy.std", "dataset_location.split"], "function", ["home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.load_and_preprocess_data", "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.eval.balanced_log_reg"], ["", "def", "run_multi_class", "(", "dataset_location", ",", "labels_location", ",", "feature", "=", "1", ")", ":", "\n", "    ", "\"\"\"Load the data and labels and run the logreg classification\"\"\"", "\n", "\n", "# Load the dataset in the required format", "\n", "if", "dataset_location", ".", "endswith", "(", "'.emb'", ")", ":", "\n", "        ", "print", "(", "\"Loading .emb file  -  \"", "+", "dataset_location", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", "\n", "data", "=", "np", ".", "loadtxt", "(", "dataset_location", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid file format'", ")", "\n", "\n", "# Load datasets", "\n", "", "labels", "=", "load_and_preprocess_data", "(", "labels_location", ",", "feature", ",", "5", ")", "\n", "\n", "labelling_faction", "=", "[", "0.1", ",", "0.2", ",", "0.3", ",", "0.4", ",", "0.5", ",", "0.6", ",", "0.7", ",", "0.8", ",", "0.9", "]", "\n", "\n", "# Loop through all the labelling fractions", "\n", "mean_score", "=", "[", "]", "\n", "mean_micro", "=", "[", "]", "\n", "mean_macro", "=", "[", "]", "\n", "std_score", "=", "[", "]", "\n", "std_micro", "=", "[", "]", "\n", "std_macro", "=", "[", "]", "\n", "results", "=", "{", "}", "\n", "for", "frac", "in", "labelling_faction", ":", "\n", "        ", "print", "(", "frac", ")", "\n", "\n", "average_score", "=", "[", "]", "\n", "average_macro", "=", "[", "]", "\n", "average_micro", "=", "[", "]", "\n", "# Run the logreg for 10 repeats", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "\n", "# create a new model with the required split", "\n", "            ", "score", ",", "micro", ",", "macro", "=", "balanced_log_reg", "(", "data", ",", "labels", ",", "frac", ")", "\n", "average_score", ".", "append", "(", "score", ")", "\n", "average_micro", ".", "append", "(", "micro", ")", "\n", "average_macro", ".", "append", "(", "macro", ")", "\n", "\n", "#print(np.mean(average_score))", "\n", "#print(np.mean(average_micro))", "\n", "#print(np.mean(average_macro))", "\n", "#print(np.std(average_score))", "\n", "#print(np.std(average_micro))", "\n", "#print(np.std(average_macro))", "\n", "", "mean_score", ".", "append", "(", "np", ".", "mean", "(", "average_score", ")", ")", "\n", "mean_micro", ".", "append", "(", "np", ".", "mean", "(", "average_micro", ")", ")", "\n", "mean_macro", ".", "append", "(", "np", ".", "mean", "(", "average_macro", ")", ")", "\n", "std_score", ".", "append", "(", "np", ".", "std", "(", "average_score", ")", ")", "\n", "std_micro", ".", "append", "(", "np", ".", "std", "(", "average_micro", ")", ")", "\n", "std_macro", ".", "append", "(", "np", ".", "std", "(", "average_macro", ")", ")", "\n", "\n", "", "results", "[", "'avg_score'", "]", "=", "mean_score", "\n", "results", "[", "'avg_micro'", "]", "=", "mean_micro", "\n", "results", "[", "'avg_macro'", "]", "=", "mean_macro", "\n", "results", "[", "'std_score'", "]", "=", "std_score", "\n", "results", "[", "'std_micro'", "]", "=", "std_micro", "\n", "results", "[", "'std_macro'", "]", "=", "std_macro", "\n", "#print (results)", "\n", "\n", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.read_graph": [[11, 24], ["networkx.convert_node_labels_to_integers", "nx.read_edgelist.to_undirected", "networkx.read_edgelist", "networkx.read_edgelist", "networkx.DiGraph"], "function", ["None"], ["def", "read_graph", "(", "dataset_location", ",", "weighted", "=", "False", ",", "directed", "=", "False", ")", ":", "\n", "    ", "\"\"\"Reads the input network in networkx \"\"\"", "\n", "\n", "if", "weighted", ":", "\n", "        ", "G", "=", "nx", ".", "read_edgelist", "(", "dataset_location", ",", "nodetype", "=", "int", ",", "data", "=", "(", "(", "'weight'", ",", "float", ")", ",", ")", ",", "create_using", "=", "nx", ".", "DiGraph", "(", ")", ")", "\n", "", "else", ":", "\n", "        ", "G", "=", "nx", ".", "read_edgelist", "(", "dataset_location", ",", "nodetype", "=", "int", ",", "data", "=", "False", ")", "\n", "\n", "# Provide sequential node labelling", "\n", "", "G", "=", "nx", ".", "convert_node_labels_to_integers", "(", "G", ")", "\n", "G", "=", "G", ".", "to_undirected", "(", ")", "\n", "\n", "return", "G", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.generate_random_graphs": [[25, 40], ["print", "networkx.erdos_renyi_graph", "networkx.barabasi_albert_graph", "ValueError"], "function", ["None"], ["", "def", "generate_random_graphs", "(", "num_nodes", ",", "num_edges", ",", "gen_meth", ")", ":", "\n", "    ", "\"\"\"Generate random graphs: 1 for ER, 2 for BA\"\"\"", "\n", "\n", "if", "gen_meth", "==", "1", ":", "\n", "        ", "temp_graph", "=", "nx", ".", "erdos_renyi_graph", "(", "num_nodes", ",", "0.3", ")", "\n", "\n", "", "elif", "gen_meth", "==", "2", ":", "\n", "        ", "temp_graph", "=", "nx", ".", "barabasi_albert_graph", "(", "num_nodes", ",", "num_edges", ")", "\n", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "'Invalid model selection'", ")", "\n", "\n", "", "print", "(", "\"Graph Generation Complete\"", ")", "\n", "\n", "return", "temp_graph", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.generate_deg_seq_graph": [[41, 64], ["range", "random.shuffle", "networkx.configuration_model", "temp1.append", "temp2.append", "temp3.append", "temp4.append", "temp5.append", "temp6.append", "temp7.append", "temp8.append", "temp9.append", "temp10.append", "range", "networkx.Graph"], "function", ["None"], ["", "def", "generate_deg_seq_graph", "(", ")", ":", "\n", "    ", "\"\"\"Generate a graph with a set degree sequence\"\"\"", "\n", "\n", "temp1", ",", "temp2", ",", "temp3", ",", "temp4", ",", "temp5", ",", "temp6", ",", "temp7", ",", "temp8", ",", "temp9", ",", "temp10", "=", "(", "[", "]", "for", "i", "in", "range", "(", "10", ")", ")", "\n", "\n", "for", "i", "in", "range", "(", "5000", ")", ":", "\n", "        ", "temp1", ".", "append", "(", "1", ")", "\n", "temp2", ".", "append", "(", "5", ")", "\n", "temp3", ".", "append", "(", "10", ")", "\n", "temp4", ".", "append", "(", "15", ")", "\n", "temp5", ".", "append", "(", "20", ")", "\n", "temp6", ".", "append", "(", "25", ")", "\n", "temp7", ".", "append", "(", "30", ")", "\n", "temp8", ".", "append", "(", "35", ")", "\n", "temp9", ".", "append", "(", "40", ")", "\n", "temp10", ".", "append", "(", "45", ")", "\n", "\n", "", "temp", "=", "temp1", "+", "temp2", "+", "temp3", "+", "temp4", "+", "temp5", "+", "temp6", "+", "temp7", "+", "temp8", "+", "temp9", "+", "temp10", "\n", "random", ".", "shuffle", "(", "temp", ")", "\n", "\n", "G", "=", "nx", ".", "configuration_model", "(", "temp", ",", "create_using", "=", "nx", ".", "Graph", "(", ")", ")", "\n", "\n", "return", "G", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.extract_graph_features": [[65, 89], ["dict", "networkx.degree_centrality", "networkx.clustering", "networkx.triangles", "networkx.pagerank_scipy", "networkx.eigenvector_centrality_numpy", "networkx.betweenness_centrality", "networkx.set_node_attributes", "networkx.set_node_attributes", "networkx.set_node_attributes", "networkx.set_node_attributes", "networkx.set_node_attributes", "networkx.set_node_attributes", "networkx.set_node_attributes", "print", "networkx.degree"], "function", ["None"], ["", "def", "extract_graph_features", "(", "graph", ")", ":", "\n", "    ", "\"\"\"Extract features and save in graph object\"\"\"", "\n", "\n", "# Extract features for each vertex", "\n", "deg", "=", "dict", "(", "nx", ".", "degree", "(", "graph", ")", ")", "\n", "deg_cent", "=", "nx", ".", "degree_centrality", "(", "graph", ")", "\n", "clu", "=", "nx", ".", "clustering", "(", "graph", ")", "\n", "tr", "=", "nx", ".", "triangles", "(", "graph", ")", "\n", "pr", "=", "nx", ".", "pagerank_scipy", "(", "graph", ",", "alpha", "=", "0.75", ")", "\n", "eig", "=", "nx", ".", "eigenvector_centrality_numpy", "(", "graph", ")", "\n", "bet", "=", "nx", ".", "betweenness_centrality", "(", "graph", ",", "k", "=", "100", ")", "\n", "\n", "# Save features back into the graph object", "\n", "nx", ".", "set_node_attributes", "(", "graph", ",", "deg", ",", "'DEG'", ")", "\n", "nx", ".", "set_node_attributes", "(", "graph", ",", "deg_cent", ",", "'DC'", ")", "\n", "nx", ".", "set_node_attributes", "(", "graph", ",", "clu", ",", "'CLU'", ")", "\n", "nx", ".", "set_node_attributes", "(", "graph", ",", "tr", ",", "'TR'", ")", "\n", "nx", ".", "set_node_attributes", "(", "graph", ",", "pr", ",", "'PR'", ")", "\n", "nx", ".", "set_node_attributes", "(", "graph", ",", "eig", ",", "'EC'", ")", "\n", "nx", ".", "set_node_attributes", "(", "graph", ",", "bet", ",", "'BC'", ")", "\n", "\n", "print", "(", "'Feature Extraction Complete'", ")", "\n", "\n", "return", "graph", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.save_graph": [[90, 97], ["networkx.write_gpickle"], "function", ["None"], ["", "def", "save_graph", "(", "graph", ",", "save_path", ")", ":", "\n", "    ", "\"\"\"Save a graph to disk\"\"\"", "\n", "# Using Pickle for now, h5py seems not to accept python objects", "\n", "\n", "nx", ".", "write_gpickle", "(", "graph", ",", "save_path", ")", "\n", "\n", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.clean_dataset": [[98, 113], ["list", "os.walk", "get_features.read_graph", "networkx.write_edgelist", "list.append", "[].lower", "[].lower", "[].lower", "os.path.splitext", "os.path.splitext", "os.path.splitext"], "function", ["home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.read_graph"], ["", "def", "clean_dataset", "(", "indir", ")", ":", "\n", "    ", "\"\"\"Generate clean datasets where all vertices have sequential ordering\"\"\"", "\n", "\n", "fileList", "=", "list", "(", ")", "\n", "\n", "# Loop through all the files in the input dir and add to list", "\n", "for", "root", ",", "dirs", ",", "files", "in", "walk", "(", "indir", ")", ":", "\n", "        ", "for", "f", "in", "files", ":", "\n", "            ", "if", "splitext", "(", "f", ")", "[", "1", "]", ".", "lower", "(", ")", "==", "\".txt\"", "and", "\"auto\"", "not", "in", "splitext", "(", "f", ")", "[", "0", "]", ".", "lower", "(", ")", "and", "\"10\"", "not", "in", "splitext", "(", "f", ")", "[", "0", "]", ".", "lower", "(", ")", ":", "\n", "                ", "fileList", ".", "append", "(", "root", "+", "f", ")", "\n", "\n", "# Loop through and load the graphs and save the cleaned graph's back to disk", "\n", "", "", "", "for", "f", "in", "fileList", ":", "\n", "        ", "clean_graph", "=", "read_graph", "(", "f", ")", "\n", "nx", ".", "write_edgelist", "(", "clean_graph", ",", "f", ",", "data", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.main": [[114, 119], ["get_features.read_graph", "get_features.extract_graph_features", "get_features.save_graph"], "function", ["home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.read_graph", "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.extract_graph_features", "home.repos.pwc.inspect_result.sbonner0_unsupervised-graph-embedding.src.get_features.save_graph"], ["", "", "def", "main", "(", "infile", ",", "outfile", ")", ":", "\n", "\n", "    ", "graph", "=", "read_graph", "(", "infile", ")", "\n", "feat_graph", "=", "extract_graph_features", "(", "graph", ")", "\n", "save_graph", "(", "feat_graph", ",", "outfile", ")", "\n", "\n"]]}