{"home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.MultiWozDB.queryResultVenues": [[53, 106], ["turn.items", "[].items", "demo.MultiWozDB.dbs[].execute().fetchall", "print", "print", "dict.fromkeys", "zip", "results_dic.append", "val.replace", "utils.multiwoz.nlp.normalize_for_sql", "val.replace", "utils.multiwoz.nlp.normalize_for_sql", "demo.MultiWozDB.dbs[].execute"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_for_sql", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_for_sql"], ["", "def", "queryResultVenues", "(", "self", ",", "domain", ",", "turn", ",", "real_belief", "=", "False", ")", ":", "\n", "# query the db", "\n", "\n", "        ", "sql_query", "=", "\"select {} from {}\"", ".", "format", "(", "','", ".", "join", "(", "self", ".", "database_keys", "[", "domain", "]", ")", ",", "domain", ")", "\n", "#     sql_query = \"select * from {}\".format(domain)", "\n", "\n", "if", "real_belief", "==", "True", ":", "\n", "            ", "items", "=", "turn", ".", "items", "(", ")", "\n", "", "else", ":", "\n", "            ", "items", "=", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", "\n", "\n", "", "flag", "=", "True", "\n", "for", "key", ",", "val", "in", "items", ":", "\n", "            ", "if", "val", "==", "\"\"", "or", "val", "==", "\"dontcare\"", "or", "val", "==", "'not mentioned'", "or", "val", "==", "\"don't care\"", "or", "val", "==", "\"dont care\"", "or", "val", "==", "\"do n't care\"", ":", "\n", "                ", "pass", "\n", "", "if", "'book'", "in", "key", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize_for_sql", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                    ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize_for_sql", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "", "", "", "", "try", ":", "# \"select * from attraction  where name = 'queens college'\"", "\n", "            ", "results", "=", "self", ".", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", "\n", "print", "(", "sql_query", ")", "\n", "results_dic", "=", "[", "]", "\n", "for", "a", "in", "results", ":", "\n", "                ", "a_dic", "=", "dict", ".", "fromkeys", "(", "self", ".", "database_keys", "[", "domain", "]", ")", "\n", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "database_keys", "[", "domain", "]", ",", "a", ")", ":", "\n", "                    ", "a_dic", "[", "k", "]", "=", "v", "\n", "", "results_dic", ".", "append", "(", "a_dic", ")", "\n", "", "print", "(", "results_dic", ")", "\n", "return", "results_dic", "\n", "\n", "", "except", ":", "\n", "            ", "return", "[", "]", "# TODO test it", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.MultiWozDB.queryResultVenues_new": [[107, 190], ["turn.items", "[].items", "list", "ipdb.set_trace", "demo.MultiWozDB.dbs[].execute().fetchall", "turn.items", "dict.fromkeys", "zip", "results_dic.append", "val.replace", "utils.multiwoz.nlp.normalize_for_sql", "val.replace", "utils.multiwoz.nlp.normalize_for_sql", "demo.MultiWozDB.dbs[].execute"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_for_sql", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_for_sql"], ["", "", "def", "queryResultVenues_new", "(", "self", ",", "domain", ",", "turn", ",", "real_belief", "=", "False", ")", ":", "\n", "# query the db", "\n", "# sql_query = \"select * from {}\".format(domain)", "\n", "        ", "sql_query", "=", "\"select {} from {}\"", ".", "format", "(", "','", ".", "join", "(", "self", ".", "database_keys", "[", "domain", "]", ")", ",", "domain", ")", "\n", "\n", "if", "real_belief", "==", "True", ":", "\n", "            ", "items", "=", "turn", ".", "items", "(", ")", "\n", "", "else", ":", "\n", "            ", "items", "=", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", "\n", "\n", "", "flag", "=", "True", "\n", "for", "key", ",", "val", "in", "items", ":", "\n", "            ", "if", "key", "==", "'leaveat'", ":", "\n", "                ", "key", "=", "'leaveAt'", "\n", "", "if", "key", "==", "'arriveby'", ":", "\n", "                ", "key", "=", "'arriveBy'", "\n", "\n", "", "if", "val", "==", "\"\"", "or", "val", "==", "\"dontcare\"", "or", "val", "==", "'not mentioned'", "or", "val", "==", "\"don't care\"", "or", "val", "==", "\"dont care\"", "or", "val", "==", "\"do n't care\"", ":", "\n", "                ", "pass", "\n", "", "if", "'book'", "in", "key", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize_for_sql", "(", "val2", ")", "\n", "\n", "# val2 = val2.replace('marys', r\"mary's\")", "\n", "# val2 = val2.replace('restaurant 17', 'restaurant one seven')", "\n", "# val2 = val2.replace('christ college', r\"christ's college\")", "\n", "# val2 = val2.replace('city centre north bed and breakfast', 'city centre north b and b')", "\n", "\n", "if", "key", "==", "'name'", "and", "val2", "in", "[", "'the cow pizza kitchen and bar'", ",", "\n", "'cow pizza kitchen and bar'", ",", "\n", "'wankworth house'", "]", ":", "\n", "                        ", "continue", "\n", "\n", "\n", "", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                    ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize_for_sql", "(", "val2", ")", "\n", "\n", "# val2 = val2.replace('marys', r\"mary's\")", "\n", "# val2 = val2.replace('restaurant 17', 'restaurant one seven')", "\n", "# val2 = val2.replace('christ college', r\"christ's college\")", "\n", "# val2 = val2.replace('city centre north bed and breakfast', 'city centre north b and b')", "\n", "\n", "if", "key", "==", "'name'", "and", "val2", "in", "[", "'the cow pizza kitchen and bar'", ",", "\n", "'cow pizza kitchen and bar'", ",", "\n", "'wankworth house'", "]", ":", "\n", "                        ", "continue", "\n", "\n", "\n", "", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "", "", "", "", "if", "(", "'name'", ",", "'restaurant one seven'", ")", "in", "list", "(", "turn", ".", "items", "(", ")", ")", ":", "\n", "            ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "try", ":", "# \"select * from attraction  where name = 'queens college'\"", "\n", "# return self.dbs[domain].execute(sql_query).fetchall()", "\n", "            ", "results", "=", "self", ".", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", "\n", "# print(sql_query)", "\n", "results_dic", "=", "[", "]", "\n", "for", "a", "in", "results", ":", "\n", "                ", "a_dic", "=", "dict", ".", "fromkeys", "(", "self", ".", "database_keys", "[", "domain", "]", ")", "\n", "for", "k", ",", "v", "in", "zip", "(", "self", ".", "database_keys", "[", "domain", "]", ",", "a", ")", ":", "\n", "                    ", "a_dic", "[", "k", "]", "=", "v", "\n", "", "results_dic", ".", "append", "(", "a_dic", ")", "\n", "# print(results_dic)", "\n", "", "return", "results_dic", "\n", "", "except", ":", "\n", "            ", "return", "[", "]", "# TODO test it", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_belief_new": [[192, 214], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tmp.replace.split", "bs.strip.strip", "[].split", "new_belief.append", "sent.strip().split", "sent.strip"], "function", ["None"], ["", "", "", "def", "get_belief_new", "(", "sent", ")", ":", "\n", "    ", "if", "'<|belief|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "strip", "(", "' '", ")", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|action|>'", ")", "[", "0", "]", "\n", "# elif 'belief.' in sent:", "\n", "#     tmp = sent.strip(' ').split('<belief>')[-1].split('<action>')[0]", "\n", "# elif 'belief' not in sent:", "\n", "#     return []", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "# else:", "\n", "#     raise TypeError('unknown belief separator')", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "# assert tmp.endswith('<endofbelief>')", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofbelief|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "belief", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_belief", "=", "[", "]", "\n", "for", "bs", "in", "belief", ":", "\n", "        ", "bs", "=", "bs", ".", "strip", "(", "' .,'", ")", "\n", "if", "bs", "not", "in", "new_belief", ":", "\n", "            ", "new_belief", ".", "append", "(", "bs", ")", "\n", "", "", "return", "new_belief", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_belief_new_openaigpt": [[216, 238], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tmp.replace.split", "bs.strip.strip", "[].split", "new_belief.append", "sent.strip().split", "sent.strip"], "function", ["None"], ["", "def", "get_belief_new_openaigpt", "(", "sent", ")", ":", "\n", "    ", "if", "'< | belief | >'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "strip", "(", "' '", ")", ".", "split", "(", "'< | belief | >'", ")", "[", "-", "1", "]", ".", "split", "(", "'< | action | >'", ")", "[", "0", "]", "\n", "# elif 'belief.' in sent:", "\n", "#     tmp = sent.strip(' ').split('<belief>')[-1].split('<action>')[0]", "\n", "# elif 'belief' not in sent:", "\n", "#     return []", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "# else:", "\n", "#     raise TypeError('unknown belief separator')", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "# assert tmp.endswith('<endofbelief>')", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endofbelief | >'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "belief", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_belief", "=", "[", "]", "\n", "for", "bs", "in", "belief", ":", "\n", "        ", "bs", "=", "bs", ".", "strip", "(", "' .,'", ")", "\n", "if", "bs", "not", "in", "new_belief", ":", "\n", "            ", "new_belief", ".", "append", "(", "bs", ")", "\n", "", "", "return", "new_belief", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_belief_new_dbsearch": [[240, 262], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tmp.replace.split", "bs.strip.strip", "[].split", "new_belief.append", "sent.strip().split", "sent.strip"], "function", ["None"], ["", "def", "get_belief_new_dbsearch", "(", "sent", ")", ":", "\n", "    ", "if", "'<|belief|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "strip", "(", "' '", ")", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofbelief|>'", ")", "[", "0", "]", "\n", "# elif 'belief.' in sent:", "\n", "#     tmp = sent.strip(' ').split('<belief>')[-1].split('<action>')[0]", "\n", "# elif 'belief' not in sent:", "\n", "#     return []", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "# else:", "\n", "#     raise TypeError('unknown belief separator')", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "# assert tmp.endswith('<endofbelief>')", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofbelief|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "belief", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_belief", "=", "[", "]", "\n", "for", "bs", "in", "belief", ":", "\n", "        ", "bs", "=", "bs", ".", "strip", "(", "' .,'", ")", "\n", "if", "bs", "not", "in", "new_belief", ":", "\n", "            ", "new_belief", ".", "append", "(", "bs", ")", "\n", "", "", "return", "new_belief", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_action_new_openaigpt": [[264, 287], ["[].strip.strip", "[].strip.replace", "[].strip.replace", "[].strip.replace", "[].strip.split", "[].strip", "act.replace.strip", "[].strip", "act.replace.replace", "new_action.append", "[].split", "[].split", "[].split", "sent.split", "sent.split"], "function", ["None"], ["", "def", "get_action_new_openaigpt", "(", "sent", ")", ":", "\n", "    ", "if", "'< | belief | >'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'< | belief | >'", ")", "[", "-", "1", "]", ".", "split", "(", "'< | response | >'", ")", "[", "0", "]", ".", "split", "(", "'< | action | >'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "elif", "'< | action | >'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'< | response | >'", ")", "[", "0", "]", ".", "split", "(", "'< | action | >'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "# if not tmp.endswith('<endofaction>'):", "\n", "#     ipdb.set_trace()", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endofaction | >'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endofbelief | >'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "action", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_action", "=", "[", "]", "\n", "for", "act", "in", "action", ":", "\n", "        ", "if", "act", "==", "''", ":", "\n", "            ", "continue", "\n", "", "act", "=", "act", ".", "strip", "(", "' .,'", ")", "\n", "if", "act", "not", "in", "new_action", ":", "\n", "            ", "act", "=", "act", ".", "replace", "(", "'i d'", ",", "'id'", ")", "\n", "new_action", ".", "append", "(", "act", ")", "\n", "", "", "return", "new_action", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_action_new": [[289, 312], ["[].strip.strip", "[].strip.replace", "[].strip.replace", "[].strip.split", "act.strip.strip", "[].strip", "new_action.append", "[].strip", "[].split", "[].split", "[].split", "sent.split", "sent.split"], "function", ["None"], ["", "def", "get_action_new", "(", "sent", ")", ":", "\n", "    ", "if", "'<|action|>'", "not", "in", "sent", ":", "\n", "        ", "return", "[", "]", "\n", "", "elif", "'<|belief|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|response|>'", ")", "[", "0", "]", ".", "split", "(", "'<|action|>'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "elif", "'<|action|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'<|response|>'", ")", "[", "0", "]", ".", "split", "(", "'<|action|>'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "# if not tmp.endswith('<endofaction>'):", "\n", "#     ipdb.set_trace()", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofaction|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "action", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_action", "=", "[", "]", "\n", "for", "act", "in", "action", ":", "\n", "        ", "if", "act", "==", "''", ":", "\n", "            ", "continue", "\n", "", "act", "=", "act", ".", "strip", "(", "' .,'", ")", "\n", "if", "act", "not", "in", "new_action", ":", "\n", "            ", "new_action", ".", "append", "(", "act", ")", "\n", "", "", "return", "new_action", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_response_new": [[314, 341], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tokenizer.encode", "tokenizer.decode().strip", "new_tokens.append", "[].split", "tokenizer.encode", "tokenizer.decode", "[].split", "sent.split"], "function", ["None"], ["", "def", "get_response_new", "(", "sent", ")", ":", "\n", "    ", "if", "'<|response|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|action|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|response|>'", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "return", "''", "\n", "# if '<belief>' in sent:", "\n", "#     tmp = sent.split('<belief>')[-1].split('<action>')[-1].split('<response>')[-1]", "\n", "# elif '<action>' in sent:", "\n", "#     tmp = sent.split('<action>')[-1].split('<response>')[-1]", "\n", "# elif '<response>' in sent:", "\n", "#     tmp = sent.split('<response>')[-1]", "\n", "# else:", "\n", "#     tmp = sent", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "# assert tmp.endswith('<endofresponse>')", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofresponse|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "tokens", "=", "tokenizer", ".", "encode", "(", "tmp", ")", "\n", "new_tokens", "=", "[", "]", "\n", "for", "tok", "in", "tokens", ":", "\n", "# if tok in break_tokens:", "\n", "        ", "if", "tok", "in", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ")", ":", "\n", "            ", "continue", "\n", "", "new_tokens", ".", "append", "(", "tok", ")", "\n", "# ipdb.set_trace()", "\n", "", "response", "=", "tokenizer", ".", "decode", "(", "new_tokens", ")", ".", "strip", "(", "' ,.'", ")", "\n", "return", "response", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.convert_belief": [[343, 363], ["bs.split", "bs.split", "print", "print", "bs.split", "bs.split", "bs.split"], "function", ["None"], ["", "def", "convert_belief", "(", "belief", ")", ":", "\n", "    ", "dic", "=", "{", "}", "\n", "for", "bs", "in", "belief", ":", "\n", "        ", "if", "bs", "in", "[", "' '", ",", "''", "]", ":", "\n", "            ", "continue", "\n", "", "domain", "=", "bs", ".", "split", "(", "' '", ")", "[", "0", "]", "\n", "slot", "=", "bs", ".", "split", "(", "' '", ")", "[", "1", "]", "\n", "if", "slot", "==", "'book'", ":", "\n", "            ", "slot", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", "' '", ")", "[", "1", ":", "3", "]", ")", "\n", "value", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", "' '", ")", "[", "3", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "value", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", "' '", ")", "[", "2", ":", "]", ")", "\n", "", "if", "domain", "not", "in", "dic", ":", "\n", "            ", "dic", "[", "domain", "]", "=", "{", "}", "\n", "", "try", ":", "\n", "            ", "dic", "[", "domain", "]", "[", "slot", "]", "=", "value", "\n", "", "except", ":", "\n", "            ", "print", "(", "domain", ")", "\n", "print", "(", "slot", ")", "\n", "", "", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_db_text": [[365, 414], ["len", "multiwoz_db.queryResultVenues_new", "db_text_tmp.append", "db_text_tmp.append"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.MultiWozDB.queryResultVenues_new"], ["", "def", "get_db_text", "(", "belief_domain", ",", "dom", ",", "only_match", "=", "False", ")", ":", "\n", "    ", "db_text_tmp", "=", "[", "]", "\n", "# for dom in belief_domain:", "\n", "if", "dom", "not", "in", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", ":", "\n", "        ", "db_text_tmp", "=", "''", "\n", "", "domain_match", "=", "len", "(", "multiwoz_db", ".", "queryResultVenues_new", "(", "dom", ",", "belief_domain", "[", "dom", "]", ",", "real_belief", "=", "True", ")", ")", "\n", "\n", "if", "dom", "!=", "'train'", ":", "\n", "        ", "if", "domain_match", ">=", "5", ":", "\n", "            ", "domain_match_text", "=", "'>=5'", "\n", "", "else", ":", "\n", "            ", "domain_match_text", "=", "'={}'", ".", "format", "(", "domain_match", ")", "\n", "\n", "", "", "elif", "dom", "==", "'train'", ":", "\n", "        ", "if", "domain_match", "==", "0", ":", "\n", "            ", "domain_match_text", "=", "'=0'", "\n", "", "elif", "domain_match", "==", "2", ":", "\n", "            ", "domain_match_text", "=", "'<3'", "\n", "", "elif", "domain_match", "==", "5", ":", "\n", "            ", "domain_match_text", "=", "'<6'", "\n", "", "elif", "domain_match", "==", "10", ":", "\n", "            ", "domain_match_text", "=", "'<11'", "\n", "", "elif", "domain_match", "==", "40", ":", "\n", "            ", "domain_match_text", "=", "'<41'", "\n", "", "else", ":", "\n", "            ", "domain_match_text", "=", "'>40'", "\n", "\n", "# if 'fail_book' in goal[dom]:", "\n", "#     for item in goal[dom]['fail_book'].items():", "\n", "#         if item in belief_book_domain[dom].items():", "\n", "#             domain_book_text = 'not available'", "\n", "#             break", "\n", "#         else:", "\n", "#             domain_book_text = 'available'", "\n", "# else:", "\n", "#     domain_book_text = 'available'", "\n", "", "", "if", "domain_match", "==", "0", ":", "\n", "        ", "domain_book_text", "=", "'not available'", "\n", "", "else", ":", "\n", "        ", "domain_book_text", "=", "'available'", "\n", "\n", "\n", "# if USE_DB_BOOK_DYNAMIC:", "\n", "", "if", "only_match", ":", "\n", "        ", "db_text_tmp", ".", "append", "(", "'{} match{}'", ".", "format", "(", "dom", ",", "domain_match_text", ")", ")", "\n", "", "else", ":", "\n", "        ", "db_text_tmp", ".", "append", "(", "'{} match{} booking={}'", ".", "format", "(", "dom", ",", "domain_match_text", ",", "domain_book_text", ")", ")", "\n", "\n", "", "return", "db_text_tmp", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.lexicalize_train": [[416, 504], ["len", "len", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "str", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "random.randint", "lex_response.replace.replace", "random.sample", "lex_response.replace.replace", "str"], "function", ["None"], ["", "def", "lexicalize_train", "(", "delex_response", ",", "db_results", ",", "turn_beliefs", ",", "turn_domain", ")", ":", "\n", "    ", "if", "len", "(", "db_results", ")", ">", "0", ":", "\n", "        ", "sample", "=", "random", ".", "sample", "(", "db_results", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "value_count", "=", "len", "(", "db_results", ")", "\n", "", "else", ":", "\n", "# domain = list(beliefs.keys())[0]", "\n", "        ", "sample", "=", "turn_beliefs", "[", "turn_domain", "]", "\n", "value_count", "=", "0", "\n", "\n", "# print(sample)", "\n", "", "lex_response", "=", "delex_response", "\n", "\n", "if", "'from [value_place] to [value_place]'", "in", "delex_response", ":", "\n", "        ", "departure", "=", "sample", "[", "'departure'", "]", "\n", "destination", "=", "sample", "[", "'destination'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'from [value_place] to [value_place]'", ",", "'from {} to {}'", ".", "format", "(", "departure", ",", "destination", ")", ")", "\n", "", "if", "'from [value_place] on [value_day]'", "in", "delex_response", ":", "\n", "        ", "departure", "=", "sample", "[", "'departure'", "]", "\n", "day", "=", "sample", "[", "'day'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'from [value_place] on [value_day]'", ",", "'from {} on {}'", ".", "format", "(", "departure", ",", "day", ")", ")", "\n", "\n", "", "if", "'from [value_place]'", "in", "delex_response", ":", "\n", "        ", "departure", "=", "sample", "[", "'departure'", "]", "\n", "# destination = sample['destination']", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'from [value_place]'", ",", "'from {}'", ".", "format", "(", "departure", ")", ")", "\n", "\n", "", "if", "'leaving [value_place] at [value_day]'", "in", "delex_response", ":", "\n", "        ", "departure", "=", "sample", "[", "'departure'", "]", "\n", "day", "=", "sample", "[", "'day'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'leaving [value_place] at [value_day]'", ",", "'leaving {} at {}'", ".", "format", "(", "departure", ",", "day", ")", ")", "\n", "\n", "", "if", "'leaving [value_place] at [value_time]'", "in", "delex_response", ":", "\n", "        ", "leaveat", "=", "sample", "[", "'leaveAt'", "]", "\n", "departure", "=", "sample", "[", "'departure'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'leaving [value_place] at [value_time]'", ",", "'leaving {} at {}'", ".", "format", "(", "departure", ",", "leaveat", ")", ")", "\n", "", "if", "'leaves [value_place] at [value_time]'", "in", "delex_response", ":", "\n", "        ", "leaveat", "=", "sample", "[", "'leaveAt'", "]", "\n", "departure", "=", "sample", "[", "'departure'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'leaves [value_place] at [value_time]'", ",", "'leaves {} at {}'", ".", "format", "(", "departure", ",", "leaveat", ")", ")", "\n", "", "if", "'leaves at [value_time]'", "in", "delex_response", ":", "\n", "        ", "if", "'leaveAt'", "in", "sample", ":", "\n", "            ", "leaveat", "=", "sample", "[", "'leaveAt'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'leaves at [value_time]'", ",", "'leaves at {}'", ".", "format", "(", "leaveat", ")", ")", "\n", "", "", "if", "'other at [value_time]'", "in", "delex_response", ":", "\n", "        ", "leaveat", "=", "sample", "[", "'leaveAt'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'other at [value_time]'", ",", "'other at {}'", ".", "format", "(", "leaveat", ")", ")", "\n", "\n", "", "if", "'arrives in [value_place] at [value_time]'", "in", "delex_response", ":", "\n", "        ", "arriveby", "=", "sample", "[", "'arriveBy'", "]", "\n", "destination", "=", "sample", "[", "'destination'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'arrives in [value_place] at [value_time]'", ",", "'arrives in {} at {}'", ".", "format", "(", "destination", ",", "arriveby", ")", ")", "\n", "", "if", "'arrives at [value_time]'", "in", "delex_response", ":", "\n", "        ", "arriveby", "=", "sample", "[", "'arriveBy'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'arrives at [value_time]'", ",", "'arrives at {}'", ".", "format", "(", "arriveby", ")", ")", "\n", "\n", "", "if", "'[value_count] of these'", "in", "delex_response", ":", "\n", "        ", "value_count", "=", "'one'", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_count] of these'", ",", "value_count", ")", "\n", "", "if", "'[value_count] minutes'", "in", "delex_response", ":", "\n", "        ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_count] minutes'", ",", "sample", "[", "'duration'", "]", ")", "\n", "", "if", "'[value_count]'", "in", "delex_response", ":", "\n", "        ", "value_count", "=", "str", "(", "value_count", ")", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_count]'", ",", "value_count", ")", "\n", "", "if", "'leaving [value_place]'", "in", "delex_response", ":", "\n", "        ", "departure", "=", "sample", "[", "'departure'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'leaving [value_place]'", ",", "'leaving {}'", ".", "format", "(", "departure", ")", ")", "\n", "", "if", "'leaves [value_place]'", "in", "delex_response", ":", "\n", "        ", "departure", "=", "sample", "[", "'departure'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'leaves [value_place]'", ",", "'leaves {}'", ".", "format", "(", "departure", ")", ")", "\n", "", "if", "'arrives in [value_place]'", "in", "delex_response", ":", "\n", "        ", "destination", "=", "sample", "[", "'destination'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'arrives in [value_place]'", ",", "'arrives in {}'", ".", "format", "(", "destination", ")", ")", "\n", "", "if", "'[train_id]'", "in", "delex_response", ":", "\n", "        ", "train_id", "=", "sample", "[", "'trainID'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'[train_id]'", ",", "train_id", ")", "\n", "", "if", "'[value_day]'", "in", "delex_response", ":", "\n", "        ", "train_day", "=", "sample", "[", "'day'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_day]'", ",", "train_day", ")", "\n", "", "if", "'[value_price]'", "in", "delex_response", ":", "\n", "        ", "train_price", "=", "sample", "[", "'price'", "]", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_price]'", ",", "train_price", ")", "\n", "", "if", "'[train_reference]'", "in", "delex_response", ":", "\n", "        ", "random_number", "=", "random", ".", "randint", "(", "10000", ",", "99999", ")", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'[train_reference]'", ",", "str", "(", "random_number", ")", ")", "\n", "\n", "\n", "\n", "", "return", "lex_response", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.lexicalize_hotel": [[506, 546], ["len", "len", "random.sample", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "random.randint", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "lex_response.replace.replace", "ipdb.set_trace", "str", "str"], "function", ["None"], ["", "def", "lexicalize_hotel", "(", "delex_response", ",", "db_results", ",", "turn_beliefs", ",", "turn_domain", ")", ":", "\n", "    ", "if", "len", "(", "db_results", ")", ">", "0", ":", "\n", "        ", "sample", "=", "random", ".", "sample", "(", "db_results", ",", "k", "=", "1", ")", "[", "0", "]", "\n", "value_count", "=", "len", "(", "db_results", ")", "\n", "", "else", ":", "\n", "# ipdb.set_trace()", "\n", "# domain = list(beliefs.keys())[0]", "\n", "        ", "sample", "=", "turn_beliefs", "[", "turn_domain", "]", "\n", "value_count", "=", "0", "\n", "\n", "# print(sample)", "\n", "", "lex_response", "=", "delex_response", "\n", "try", ":", "\n", "        ", "if", "'[hotel_name]'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[hotel_name]'", ",", "sample", "[", "'name'", "]", ")", "\n", "", "if", "'[hotel_address]'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[hotel_address]'", ",", "sample", "[", "'address'", "]", ")", "\n", "", "if", "'[value_area]'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_area]'", ",", "sample", "[", "'area'", "]", ")", "\n", "", "if", "'starting [value_day]'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'starting [value_day]'", ",", "'starting {}'", ".", "format", "(", "beliefs", "[", "'book day'", "]", ")", ")", "\n", "", "if", "'[value_pricerange]'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_pricerange]'", ",", "sample", "[", "'pricerange'", "]", ")", "\n", "", "if", "'[value_count] star'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_count] star'", ",", "'{} star'", ".", "format", "(", "sample", "[", "'stars'", "]", ")", ")", "\n", "", "if", "'[value_count]'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_count]'", ",", "str", "(", "value_count", ")", ")", "\n", "", "if", "'[hotel_reference]'", "in", "delex_response", ":", "\n", "            ", "random_number", "=", "random", ".", "randint", "(", "10000", ",", "99999", ")", "\n", "lex_response", "=", "lex_response", ".", "replace", "(", "'[hotel_reference]'", ",", "str", "(", "random_number", ")", ")", "\n", "", "if", "'starting [value_day]'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'starting [value_day]'", ",", "'starting {}'", ".", "format", "(", "beliefs", "[", "'book day'", "]", ")", ")", "\n", "", "if", "'[value_count] people'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_count] people'", ",", "'{} people'", ".", "format", "(", "beliefs", "[", "'book people'", "]", ")", ")", "\n", "", "if", "'[value_count] nights'", "in", "delex_response", ":", "\n", "            ", "lex_response", "=", "lex_response", ".", "replace", "(", "'[value_count] nights'", ",", "'{} nights'", ".", "format", "(", "beliefs", "[", "'book stay'", "]", ")", ")", "\n", "", "", "except", ":", "\n", "        ", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "return", "lex_response", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_turn_domain_old": [[548, 579], ["print", "print", "print", "print", "b.keys", "ipdb.set_trace", "list", "a.keys", "set", "set"], "function", ["None"], ["", "def", "get_turn_domain_old", "(", "b", ",", "a", ")", ":", "\n", "    ", "tmp", "=", "{", "}", "\n", "turn_domain", "=", "None", "\n", "if", "a", "==", "b", ":", "\n", "        ", "turn_domain", "=", "list", "(", "a", ".", "keys", "(", ")", ")", "[", "0", "]", "\n", "# elif len(b.keys()) > len(a.keys()):", "\n", "#     turn_domain = list(set(b) - set(a))[0]", "\n", "", "else", ":", "\n", "        ", "for", "domain", "in", "b", ".", "keys", "(", ")", ":", "\n", "            ", "if", "domain", "not", "in", "a", ":", "\n", "                ", "turn_domain", "=", "domain", "\n", "tmp", "=", "b", "\n", "break", "\n", "", "tmp", "=", "{", "k", ":", "b", "[", "domain", "]", "[", "k", "]", "for", "k", "in", "set", "(", "b", "[", "domain", "]", ")", "-", "set", "(", "a", "[", "domain", "]", ")", "}", "\n", "if", "tmp", "!=", "{", "}", ":", "\n", "                ", "turn_domain", "=", "domain", "\n", "break", "\n", "", "", "", "if", "not", "turn_domain", ":", "\n", "        ", "ipdb", ".", "set_trace", "(", ")", "\n", "", "print", "(", "'domain change'", ")", "\n", "print", "(", "'chane'", ",", "tmp", ")", "\n", "print", "(", "b", ")", "\n", "print", "(", "a", ")", "\n", "# domain = list(tmp.keys())", "\n", "# if len(domain) > 1:", "\n", "#     raise TypeError()", "\n", "# elif len(domain) == 0:", "\n", "#     domain = list(a.keys())[0]", "\n", "# else:", "\n", "#     domain = domain[0]", "\n", "return", "turn_domain", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.demo.get_turn_domain": [[581, 588], ["beliefs.keys", "q.append"], "function", ["None"], ["", "def", "get_turn_domain", "(", "beliefs", ",", "q", ")", ":", "\n", "    ", "for", "k", "in", "beliefs", ".", "keys", "(", ")", ":", "\n", "        ", "if", "k", "not", "in", "q", ":", "\n", "            ", "q", ".", "append", "(", "k", ")", "\n", "turn_domain", "=", "k", "\n", "return", "turn_domain", "\n", "", "", "return", "q", "[", "-", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.BaseEvaluator.initialize": [[105, 107], ["None"], "methods", ["None"], ["    ", "def", "initialize", "(", "self", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.BaseEvaluator.add_example": [[108, 110], ["None"], "methods", ["None"], ["", "def", "add_example", "(", "self", ",", "ref", ",", "hyp", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.BaseEvaluator.get_report": [[111, 113], ["None"], "methods", ["None"], ["", "def", "get_report", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.BaseEvaluator._get_prec_recall": [[114, 120], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_prec_recall", "(", "tp", ",", "fp", ",", "fn", ")", ":", "\n", "        ", "precision", "=", "tp", "/", "(", "tp", "+", "fp", "+", "10e-20", ")", "\n", "recall", "=", "tp", "/", "(", "tp", "+", "fn", "+", "10e-20", ")", "\n", "f1", "=", "2", "*", "precision", "*", "recall", "/", "(", "precision", "+", "recall", "+", "1e-20", ")", "\n", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.BaseEvaluator._get_tp_fp_fn": [[121, 127], ["len", "max", "max", "len", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_tp_fp_fn", "(", "label_list", ",", "pred_list", ")", ":", "\n", "        ", "tp", "=", "len", "(", "[", "t", "for", "t", "in", "pred_list", "if", "t", "in", "label_list", "]", ")", "\n", "fp", "=", "max", "(", "0", ",", "len", "(", "pred_list", ")", "-", "tp", ")", "\n", "fn", "=", "max", "(", "0", ",", "len", "(", "label_list", ")", "-", "tp", ")", "\n", "return", "tp", ",", "fp", ",", "fn", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.BLEUScorer.score": [[133, 197], ["zip", "math.fsum", "enumerate", "math.exp", "math.exp", "type", "ref.split", "range", "len", "range", "hyp.split", "hyp.split", "collections.Counter", "sum", "dict", "sum", "abs", "float", "float", "math.log", "zip", "nltk.util.ngrams", "collections.Counter.values", "collections.Counter", "dict.values", "len", "float", "float", "nltk.util.ngrams", "max", "len", "len", "max_counts.get", "min", "collections.Counter.items"], "methods", ["None"], ["    ", "def", "score", "(", "self", ",", "hypothesis", ",", "corpus", ",", "n", "=", "1", ")", ":", "\n", "# containers", "\n", "        ", "count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "clip_count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "r", "=", "0", "\n", "c", "=", "0", "\n", "weights", "=", "[", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", "]", "\n", "\n", "# hypothesis = [hypothesis]", "\n", "# corpus = [corpus]", "\n", "# ipdb.set_trace()", "\n", "\n", "# accumulate ngram statistics", "\n", "for", "hyps", ",", "refs", "in", "zip", "(", "hypothesis", ",", "corpus", ")", ":", "\n", "            ", "if", "type", "(", "hyps", "[", "0", "]", ")", "is", "list", ":", "\n", "               ", "hyps", "=", "[", "hyp", ".", "split", "(", ")", "for", "hyp", "in", "hyps", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "               ", "hyps", "=", "[", "hyp", ".", "split", "(", ")", "for", "hyp", "in", "hyps", "]", "\n", "#", "\n", "", "refs", "=", "[", "ref", ".", "split", "(", ")", "for", "ref", "in", "refs", "]", "\n", "# hyps = [hyps]", "\n", "# hyps = hyps", "\n", "# Shawn's evaluation", "\n", "# refs[0] = [u'GO_'] + refs[0] + [u'EOS_']", "\n", "# hyps[0] = [u'GO_'] + hyps[0] + [u'EOS_']", "\n", "# ipdb.set_trace()", "\n", "for", "idx", ",", "hyp", "in", "enumerate", "(", "hyps", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "# accumulate ngram counts", "\n", "                    ", "hypcnts", "=", "Counter", "(", "ngrams", "(", "hyp", ",", "i", "+", "1", ")", ")", "\n", "cnt", "=", "sum", "(", "hypcnts", ".", "values", "(", ")", ")", "\n", "count", "[", "i", "]", "+=", "cnt", "\n", "\n", "# compute clipped counts", "\n", "max_counts", "=", "{", "}", "\n", "for", "ref", "in", "refs", ":", "\n", "                        ", "refcnts", "=", "Counter", "(", "ngrams", "(", "ref", ",", "i", "+", "1", ")", ")", "\n", "for", "ng", "in", "hypcnts", ":", "\n", "                            ", "max_counts", "[", "ng", "]", "=", "max", "(", "max_counts", ".", "get", "(", "ng", ",", "0", ")", ",", "refcnts", "[", "ng", "]", ")", "\n", "", "", "clipcnt", "=", "dict", "(", "(", "ng", ",", "min", "(", "count", ",", "max_counts", "[", "ng", "]", ")", ")", "for", "ng", ",", "count", "in", "hypcnts", ".", "items", "(", ")", ")", "\n", "clip_count", "[", "i", "]", "+=", "sum", "(", "clipcnt", ".", "values", "(", ")", ")", "\n", "\n", "# accumulate r & c", "\n", "", "bestmatch", "=", "[", "1000", ",", "1000", "]", "\n", "for", "ref", "in", "refs", ":", "\n", "                    ", "if", "bestmatch", "[", "0", "]", "==", "0", ":", "break", "\n", "diff", "=", "abs", "(", "len", "(", "ref", ")", "-", "len", "(", "hyp", ")", ")", "\n", "if", "diff", "<", "bestmatch", "[", "0", "]", ":", "\n", "                        ", "bestmatch", "[", "0", "]", "=", "diff", "\n", "bestmatch", "[", "1", "]", "=", "len", "(", "ref", ")", "\n", "", "", "r", "+=", "bestmatch", "[", "1", "]", "\n", "c", "+=", "len", "(", "hyp", ")", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "break", "\n", "# computing bleu score", "\n", "", "", "", "p0", "=", "1e-7", "\n", "bp", "=", "1", "if", "c", ">", "r", "else", "math", ".", "exp", "(", "1", "-", "float", "(", "r", ")", "/", "float", "(", "c", ")", ")", "\n", "p_ns", "=", "[", "float", "(", "clip_count", "[", "i", "]", ")", "/", "float", "(", "count", "[", "i", "]", "+", "p0", ")", "+", "p0", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "s", "=", "math", ".", "fsum", "(", "w", "*", "math", ".", "log", "(", "p_n", ")", "for", "w", ",", "p_n", "in", "zip", "(", "weights", ",", "p_ns", ")", "if", "p_n", ")", "\n", "bleu", "=", "bp", "*", "math", ".", "exp", "(", "s", ")", "\n", "return", "bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozDB.queryResultVenues": [[211, 250], ["turn.items", "[].items", "evaluate_multiwoz.MultiWozDB.dbs[].execute().fetchall", "val.replace", "utils.multiwoz.nlp.normalize", "val.replace", "utils.multiwoz.nlp.normalize", "evaluate_multiwoz.MultiWozDB.dbs[].execute"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize"], ["", "def", "queryResultVenues", "(", "self", ",", "domain", ",", "turn", ",", "real_belief", "=", "False", ")", ":", "\n", "# query the db", "\n", "        ", "sql_query", "=", "\"select * from {}\"", ".", "format", "(", "domain", ")", "\n", "\n", "if", "real_belief", "==", "True", ":", "\n", "            ", "items", "=", "turn", ".", "items", "(", ")", "\n", "", "else", ":", "\n", "            ", "items", "=", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", "\n", "\n", "", "flag", "=", "True", "\n", "for", "key", ",", "val", "in", "items", ":", "\n", "            ", "if", "val", "==", "\"\"", "or", "val", "==", "\"dontcare\"", "or", "val", "==", "'not mentioned'", "or", "val", "==", "\"don't care\"", "or", "val", "==", "\"dont care\"", "or", "val", "==", "\"do n't care\"", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                    ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "", "", "", "", "try", ":", "# \"select * from attraction  where name = 'queens college'\"", "\n", "            ", "return", "self", ".", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", "\n", "", "except", ":", "\n", "            ", "return", "[", "]", "# TODO test it", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator.__init__": [[253, 261], ["utils.multiwoz.delexicalize.prepareSlotValuesIndependent", "json.load", "evaluate_multiwoz.MultiWozDB", "list", "list", "json.load", "open", "open"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.prepareSlotValuesIndependent"], ["    ", "def", "__init__", "(", "self", ",", "data_name", ")", ":", "\n", "        ", "self", ".", "data_name", "=", "data_name", "\n", "self", ".", "slot_dict", "=", "delex", ".", "prepareSlotValuesIndependent", "(", ")", "\n", "self", ".", "delex_dialogues", "=", "json", ".", "load", "(", "open", "(", "'resources/multi-woz-2.1/delex.json'", ",", "'r'", ")", ")", "\n", "self", ".", "db", "=", "MultiWozDB", "(", ")", "\n", "self", ".", "labels", "=", "list", "(", ")", "\n", "self", ".", "hyps", "=", "list", "(", ")", "\n", "self", ".", "venues", "=", "json", ".", "load", "(", "open", "(", "'resources/all_venues.json'", ",", "'r'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator.add_example": [[262, 265], ["evaluate_multiwoz.MultiWozEvaluator.labels.append", "evaluate_multiwoz.MultiWozEvaluator.hyps.append"], "methods", ["None"], ["", "def", "add_example", "(", "self", ",", "ref", ",", "hyp", ")", ":", "\n", "        ", "self", ".", "labels", ".", "append", "(", "ref", ")", "\n", "self", ".", "hyps", ".", "append", "(", "hyp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator._parseGoal": [[266, 298], ["[].append", "[].append", "[].append", "[].append"], "methods", ["None"], ["", "def", "_parseGoal", "(", "self", ",", "goal", ",", "d", ",", "domain", ")", ":", "\n", "        ", "\"\"\"Parses user goal into dictionary format.\"\"\"", "\n", "goal", "[", "domain", "]", "=", "{", "}", "\n", "goal", "[", "domain", "]", "=", "{", "'informable'", ":", "[", "]", ",", "'requestable'", ":", "[", "]", ",", "'booking'", ":", "[", "]", "}", "\n", "if", "'info'", "in", "d", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if d['goal'][domain].has_key('info'):", "\n", "            ", "if", "domain", "==", "'train'", ":", "\n", "# we consider dialogues only where train had to be booked!", "\n", "                ", "if", "'book'", "in", "d", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if d['goal'][domain].has_key('book'):", "\n", "                    ", "goal", "[", "domain", "]", "[", "'requestable'", "]", ".", "append", "(", "'reference'", ")", "\n", "", "if", "'reqt'", "in", "d", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if d['goal'][domain].has_key('reqt'):", "\n", "                    ", "if", "'trainID'", "in", "d", "[", "'goal'", "]", "[", "domain", "]", "[", "'reqt'", "]", ":", "\n", "                        ", "goal", "[", "domain", "]", "[", "'requestable'", "]", ".", "append", "(", "'id'", ")", "\n", "", "", "", "else", ":", "\n", "                ", "if", "'reqt'", "in", "d", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if d['goal'][domain].has_key('reqt'):", "\n", "                    ", "for", "s", "in", "d", "[", "'goal'", "]", "[", "domain", "]", "[", "'reqt'", "]", ":", "# addtional requests:", "\n", "                        ", "if", "s", "in", "[", "'phone'", ",", "'address'", ",", "'postcode'", ",", "'reference'", ",", "'id'", "]", ":", "\n", "# ones that can be easily delexicalized", "\n", "                            ", "goal", "[", "domain", "]", "[", "'requestable'", "]", ".", "append", "(", "s", ")", "\n", "", "", "", "if", "'book'", "in", "d", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if d['goal'][domain].has_key('book'):", "\n", "                    ", "goal", "[", "domain", "]", "[", "'requestable'", "]", ".", "append", "(", "\"reference\"", ")", "\n", "\n", "", "", "goal", "[", "domain", "]", "[", "\"informable\"", "]", "=", "d", "[", "'goal'", "]", "[", "domain", "]", "[", "'info'", "]", "\n", "if", "'book'", "in", "d", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if d['goal'][domain].has_key('book'):", "\n", "                ", "goal", "[", "domain", "]", "[", "\"booking\"", "]", "=", "d", "[", "'goal'", "]", "[", "domain", "]", "[", "'book'", "]", "\n", "\n", "", "", "return", "goal", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator._evaluateGeneratedDialogue": [[299, 488], ["goal.keys", "enumerate", "goal.keys", "goal.keys", "domains_in_goal.append", "zip", "goal.keys", "enumerate", "evaluate_multiwoz.MultiWozEvaluator.db.queryResultVenues", "float", "len", "len", "set", "goal.keys", "goal.keys", "len", "len", "float", "len", "len", "type", "evaluate_multiwoz.remove_model_mismatch_and_db_data", "evaluate_multiwoz.MultiWozEvaluator.db.queryResultVenues", "provided_requestables[].append", "len", "len", "provided_requestables[].append", "provided_requestables[].append", "provided_requestables[].append", "provided_requestables[].append"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResultVenues", "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.remove_model_mismatch_and_db_data", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResultVenues"], ["", "def", "_evaluateGeneratedDialogue", "(", "self", ",", "dialname", ",", "dial", ",", "goal", ",", "realDialogue", ",", "real_requestables", ",", "soft_acc", "=", "False", ")", ":", "\n", "        ", "\"\"\"Evaluates the dialogue created by the model.\n        First we load the user goal of the dialogue, then for each turn\n        generated by the system we look for key-words.\n        For the Inform rate we look whether the entity was proposed.\n        For the Success rate we look for requestables slots\"\"\"", "\n", "# for computing corpus success", "\n", "requestables", "=", "[", "'phone'", ",", "'address'", ",", "'postcode'", ",", "'reference'", ",", "'id'", "]", "\n", "\n", "# CHECK IF MATCH HAPPENED", "\n", "provided_requestables", "=", "{", "}", "\n", "venue_offered", "=", "{", "}", "\n", "domains_in_goal", "=", "[", "]", "\n", "\n", "for", "domain", "in", "goal", ".", "keys", "(", ")", ":", "\n", "            ", "venue_offered", "[", "domain", "]", "=", "[", "]", "\n", "provided_requestables", "[", "domain", "]", "=", "[", "]", "\n", "domains_in_goal", ".", "append", "(", "domain", ")", "\n", "\n", "", "m_targetutt", "=", "[", "turn", "[", "'text'", "]", "for", "idx", ",", "turn", "in", "enumerate", "(", "realDialogue", "[", "'log'", "]", ")", "if", "idx", "%", "2", "==", "1", "]", "\n", "\n", "# pred_beliefs = dial['aggregated_belief']", "\n", "pred_beliefs", "=", "dial", "[", "'beliefs'", "]", "\n", "target_beliefs", "=", "dial", "[", "'target_beliefs'", "]", "\n", "pred_responses", "=", "dial", "[", "'responses'", "]", "\n", "\n", "for", "t", ",", "(", "sent_gpt", ",", "sent_t", ")", "in", "enumerate", "(", "zip", "(", "pred_responses", ",", "m_targetutt", ")", ")", ":", "\n", "            ", "for", "domain", "in", "goal", ".", "keys", "(", ")", ":", "\n", "\n", "                ", "if", "'['", "+", "domain", "+", "'_name]'", "in", "sent_gpt", "or", "'_id'", "in", "sent_gpt", ":", "\n", "                    ", "if", "domain", "in", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", ":", "\n", "# HERE YOU CAN PUT YOUR BELIEF STATE ESTIMATION", "\n", "\n", "                        ", "if", "domain", "not", "in", "pred_beliefs", ":", "\n", "                            ", "venues", "=", "[", "]", "\n", "", "else", ":", "\n", "                            ", "pred_beliefs", "=", "remove_model_mismatch_and_db_data", "(", "dialname", ",", "target_beliefs", ",", "pred_beliefs", "[", "t", "]", ",", "domain", ",", "t", ")", "\n", "venues", "=", "self", ".", "db", ".", "queryResultVenues", "(", "domain", ",", "pred_beliefs", "[", "t", "]", "[", "domain", "]", ",", "real_belief", "=", "True", ")", "\n", "\n", "# if venue has changed", "\n", "", "if", "len", "(", "venue_offered", "[", "domain", "]", ")", "==", "0", "and", "venues", ":", "\n", "                            ", "venue_offered", "[", "domain", "]", "=", "venues", "\n", "", "else", ":", "\n", "                            ", "flag", "=", "False", "\n", "for", "ven", "in", "venues", ":", "\n", "                                ", "if", "venue_offered", "[", "domain", "]", "[", "0", "]", "==", "ven", ":", "\n", "                                    ", "flag", "=", "True", "\n", "break", "\n", "", "", "if", "not", "flag", "and", "venues", ":", "# sometimes there are no results so sample won't work", "\n", "                                ", "venue_offered", "[", "domain", "]", "=", "venues", "\n", "", "", "", "else", ":", "# not limited so we can provide one", "\n", "                        ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "# ATTENTION: assumption here - we didn't provide phone or address twice! etc", "\n", "", "", "for", "requestable", "in", "requestables", ":", "\n", "                    ", "if", "requestable", "==", "'reference'", ":", "\n", "# if domain + '_reference' in sent_t:", "\n", "#     if 'restaurant_reference' in sent_t:", "\n", "                        ", "if", "domain", "+", "'_reference'", "in", "sent_gpt", ":", "\n", "                            ", "if", "'restaurant_reference'", "in", "sent_gpt", ":", "\n", "                                ", "if", "realDialogue", "[", "'log'", "]", "[", "t", "*", "2", "]", "[", "'db_pointer'", "]", "[", "\n", "-", "5", "]", "==", "1", ":", "# if pointer was allowing for that?", "\n", "                                    ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "\n", "# elif 'hotel_reference' in sent_t:", "\n", "", "", "elif", "'hotel_reference'", "in", "sent_gpt", ":", "\n", "                                ", "if", "realDialogue", "[", "'log'", "]", "[", "t", "*", "2", "]", "[", "'db_pointer'", "]", "[", "\n", "-", "3", "]", "==", "1", ":", "# if pointer was allowing for that?", "\n", "                                    ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "\n", "# elif 'train_reference' in sent_t:", "\n", "", "", "elif", "'train_reference'", "in", "sent_gpt", ":", "\n", "                                ", "if", "realDialogue", "[", "'log'", "]", "[", "t", "*", "2", "]", "[", "'db_pointer'", "]", "[", "\n", "-", "1", "]", "==", "1", ":", "# if pointer was allowing for that?", "\n", "                                    ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "\n", "", "", "else", ":", "\n", "                                ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "", "", "", "else", ":", "\n", "# if domain + '_' + requestable + ']' in sent_t:", "\n", "                        ", "if", "domain", "+", "'_'", "+", "requestable", "+", "']'", "in", "sent_gpt", ":", "\n", "                            ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "requestable", ")", "\n", "\n", "# print('venues', venue_offered)", "\n", "# print('request', provided_requestables)", "\n", "\n", "# if name was given in the task", "\n", "", "", "", "", "", "for", "domain", "in", "goal", ".", "keys", "(", ")", ":", "\n", "# if name was provided for the user, the match is being done automatically", "\n", "# if realDialogue['goal'][domain].has_key('info'):", "\n", "            ", "if", "'info'", "in", "realDialogue", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if realDialogue['goal'][domain]['info'].has_key('name'):", "\n", "                ", "if", "'name'", "in", "realDialogue", "[", "'goal'", "]", "[", "domain", "]", "[", "'info'", "]", ":", "\n", "                    ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "# special domains - entity does not need to be provided", "\n", "", "", "if", "domain", "in", "[", "'taxi'", ",", "'police'", ",", "'hospital'", "]", ":", "\n", "                ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "# the original method", "\n", "# if domain == 'train':", "\n", "#     if not venue_offered[domain]:", "\n", "#         # if realDialogue['goal'][domain].has_key('reqt') and 'id' not in realDialogue['goal'][domain]['reqt']:", "\n", "#         if 'reqt' in realDialogue['goal'][domain] and 'id' not in realDialogue['goal'][domain]['reqt']:", "\n", "#             venue_offered[domain] = '[' + domain + '_name]'", "\n", "\n", "# Wrong one in HDSA", "\n", "# if domain == 'train':", "\n", "#     if not venue_offered[domain]:", "\n", "#         if goal[domain]['requestable'] and 'id' not in goal[domain]['requestable']:", "\n", "#             venue_offered[domain] = '[' + domain + '_name]'", "\n", "\n", "# if id was not requested but train was found we dont want to override it to check if we booked the right train", "\n", "", "if", "domain", "==", "'train'", "and", "(", "not", "venue_offered", "[", "domain", "]", "and", "'id'", "not", "in", "goal", "[", "'train'", "]", "[", "'requestable'", "]", ")", ":", "\n", "                ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "", "", "\"\"\"\n        Given all inform and requestable slots\n        we go through each domain from the user goal\n        and check whether right entity was provided and\n        all requestable slots were given to the user.\n        The dialogue is successful if that's the case for all domains.\n        \"\"\"", "\n", "# HARD EVAL", "\n", "stats", "=", "{", "'restaurant'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'hotel'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'attraction'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'train'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "'taxi'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "'hospital'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'police'", ":", "[", "0", ",", "0", ",", "0", "]", "}", "\n", "\n", "match", "=", "0", "\n", "success", "=", "0", "\n", "# MATCH", "\n", "for", "domain", "in", "goal", ".", "keys", "(", ")", ":", "\n", "            ", "match_stat", "=", "0", "\n", "if", "domain", "in", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", ":", "\n", "                ", "goal_venues", "=", "self", ".", "db", ".", "queryResultVenues", "(", "domain", ",", "goal", "[", "domain", "]", "[", "'informable'", "]", ",", "real_belief", "=", "True", ")", "\n", "\n", "if", "type", "(", "venue_offered", "[", "domain", "]", ")", "is", "str", "and", "'_name'", "in", "venue_offered", "[", "domain", "]", ":", "\n", "                    ", "match", "+=", "1", "\n", "match_stat", "=", "1", "\n", "", "elif", "len", "(", "venue_offered", "[", "domain", "]", ")", ">", "0", "and", "venue_offered", "[", "domain", "]", "[", "0", "]", "in", "goal_venues", ":", "\n", "                    ", "match", "+=", "1", "\n", "match_stat", "=", "1", "\n", "", "", "else", ":", "\n", "                ", "if", "domain", "+", "'_name]'", "in", "venue_offered", "[", "domain", "]", ":", "\n", "                    ", "match", "+=", "1", "\n", "match_stat", "=", "1", "\n", "\n", "", "", "stats", "[", "domain", "]", "[", "0", "]", "=", "match_stat", "\n", "stats", "[", "domain", "]", "[", "2", "]", "=", "1", "\n", "\n", "", "if", "soft_acc", ":", "\n", "            ", "match", "=", "float", "(", "match", ")", "/", "len", "(", "goal", ".", "keys", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "if", "match", "==", "len", "(", "goal", ".", "keys", "(", ")", ")", ":", "\n", "                ", "match", "=", "1.0", "\n", "", "else", ":", "\n", "                ", "match", "=", "0.0", "\n", "\n", "# SUCCESS", "\n", "", "", "if", "match", "==", "1.0", ":", "\n", "            ", "for", "domain", "in", "domains_in_goal", ":", "\n", "                ", "success_stat", "=", "0", "\n", "domain_success", "=", "0", "\n", "if", "len", "(", "real_requestables", "[", "domain", "]", ")", "==", "0", ":", "\n", "                    ", "success", "+=", "1", "\n", "success_stat", "=", "1", "\n", "stats", "[", "domain", "]", "[", "1", "]", "=", "success_stat", "\n", "continue", "\n", "# if values in sentences are super set of requestables", "\n", "", "for", "request", "in", "set", "(", "provided_requestables", "[", "domain", "]", ")", ":", "\n", "                    ", "if", "request", "in", "real_requestables", "[", "domain", "]", ":", "\n", "                        ", "domain_success", "+=", "1", "\n", "\n", "", "", "if", "domain_success", ">=", "len", "(", "real_requestables", "[", "domain", "]", ")", ":", "\n", "                    ", "success", "+=", "1", "\n", "success_stat", "=", "1", "\n", "\n", "", "stats", "[", "domain", "]", "[", "1", "]", "=", "success_stat", "\n", "\n", "# final eval", "\n", "", "if", "soft_acc", ":", "\n", "                ", "success", "=", "float", "(", "success", ")", "/", "len", "(", "real_requestables", ")", "\n", "", "else", ":", "\n", "                ", "if", "success", ">=", "len", "(", "real_requestables", ")", ":", "\n", "                    ", "success", "=", "1", "\n", "", "else", ":", "\n", "                    ", "success", "=", "0", "\n", "\n", "", "", "", "return", "success", ",", "match", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator._evaluateRealDialogue": [[490, 641], ["evaluate_multiwoz.MultiWozEvaluator.keys", "range", "evaluate_multiwoz.MultiWozEvaluator.keys", "len", "len", "evaluate_multiwoz.MultiWozEvaluator._parseGoal", "domains_in_goal.append", "enumerate", "evaluate_multiwoz.MultiWozEvaluator.db.queryResultVenues", "evaluate_multiwoz.MultiWozEvaluator.keys", "set", "len", "len", "len", "evaluate_multiwoz.MultiWozEvaluator.db.queryResultVenues", "type", "random.sample", "provided_requestables[].append", "len", "len", "random.sample", "provided_requestables[].append", "provided_requestables[].append", "provided_requestables[].append", "provided_requestables[].append"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator._parseGoal", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResultVenues", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResultVenues"], ["", "def", "_evaluateRealDialogue", "(", "self", ",", "dialog", ",", "filename", ")", ":", "\n", "        ", "\"\"\"Evaluation of the real dialogue.\n        First we loads the user goal and then go through the dialogue history.\n        Similar to evaluateGeneratedDialogue above.\"\"\"", "\n", "domains", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", ",", "'taxi'", ",", "'hospital'", ",", "'police'", "]", "\n", "requestables", "=", "[", "'phone'", ",", "'address'", ",", "'postcode'", ",", "'reference'", ",", "'id'", "]", "\n", "\n", "# get the list of domains in the goal", "\n", "domains_in_goal", "=", "[", "]", "\n", "goal", "=", "{", "}", "\n", "for", "domain", "in", "domains", ":", "\n", "            ", "if", "dialog", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "                ", "goal", "=", "self", ".", "_parseGoal", "(", "goal", ",", "dialog", ",", "domain", ")", "\n", "domains_in_goal", ".", "append", "(", "domain", ")", "\n", "\n", "# compute corpus success", "\n", "", "", "real_requestables", "=", "{", "}", "\n", "provided_requestables", "=", "{", "}", "\n", "venue_offered", "=", "{", "}", "\n", "for", "domain", "in", "goal", ".", "keys", "(", ")", ":", "\n", "            ", "provided_requestables", "[", "domain", "]", "=", "[", "]", "\n", "venue_offered", "[", "domain", "]", "=", "[", "]", "\n", "real_requestables", "[", "domain", "]", "=", "goal", "[", "domain", "]", "[", "'requestable'", "]", "\n", "\n", "# iterate each turn", "\n", "", "m_targetutt", "=", "[", "turn", "[", "'text'", "]", "for", "idx", ",", "turn", "in", "enumerate", "(", "dialog", "[", "'log'", "]", ")", "if", "idx", "%", "2", "==", "1", "]", "\n", "for", "t", "in", "range", "(", "len", "(", "m_targetutt", ")", ")", ":", "\n", "            ", "for", "domain", "in", "domains_in_goal", ":", "\n", "                ", "sent_t", "=", "m_targetutt", "[", "t", "]", "\n", "# for computing match - where there are limited entities", "\n", "if", "domain", "+", "'_name'", "in", "sent_t", "or", "'_id'", "in", "sent_t", ":", "\n", "                    ", "if", "domain", "in", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", ":", "\n", "# HERE YOU CAN PUT YOUR BELIEF STATE ESTIMATION", "\n", "                        ", "venues", "=", "self", ".", "db", ".", "queryResultVenues", "(", "domain", ",", "dialog", "[", "'log'", "]", "[", "t", "*", "2", "+", "1", "]", ")", "\n", "\n", "# if venue has changed", "\n", "if", "len", "(", "venue_offered", "[", "domain", "]", ")", "==", "0", "and", "venues", ":", "\n", "                            ", "venue_offered", "[", "domain", "]", "=", "random", ".", "sample", "(", "venues", ",", "1", ")", "\n", "", "else", ":", "\n", "                            ", "flag", "=", "False", "\n", "for", "ven", "in", "venues", ":", "\n", "                                ", "if", "venue_offered", "[", "domain", "]", "[", "0", "]", "==", "ven", ":", "\n", "                                    ", "flag", "=", "True", "\n", "break", "\n", "", "", "if", "not", "flag", "and", "venues", ":", "# sometimes there are no results so sample won't work", "\n", "# print venues", "\n", "                                ", "venue_offered", "[", "domain", "]", "=", "random", ".", "sample", "(", "venues", ",", "1", ")", "\n", "", "", "", "else", ":", "# not limited so we can provide one", "\n", "                        ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "", "", "for", "requestable", "in", "requestables", ":", "\n", "# check if reference could be issued", "\n", "                    ", "if", "requestable", "==", "'reference'", ":", "\n", "                        ", "if", "domain", "+", "'_reference'", "in", "sent_t", ":", "\n", "                            ", "if", "'restaurant_reference'", "in", "sent_t", ":", "\n", "                                ", "if", "dialog", "[", "'log'", "]", "[", "t", "*", "2", "]", "[", "'db_pointer'", "]", "[", "-", "5", "]", "==", "1", ":", "# if pointer was allowing for that?", "\n", "                                    ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "\n", "", "", "elif", "'hotel_reference'", "in", "sent_t", ":", "\n", "                                ", "if", "dialog", "[", "'log'", "]", "[", "t", "*", "2", "]", "[", "'db_pointer'", "]", "[", "-", "3", "]", "==", "1", ":", "# if pointer was allowing for that?", "\n", "                                    ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "\n", "# return goal, 0, match, real_requestables", "\n", "", "", "elif", "'train_reference'", "in", "sent_t", ":", "\n", "                                ", "if", "dialog", "[", "'log'", "]", "[", "t", "*", "2", "]", "[", "'db_pointer'", "]", "[", "-", "1", "]", "==", "1", ":", "# if pointer was allowing for that?", "\n", "                                    ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "\n", "", "", "else", ":", "\n", "                                ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "'reference'", ")", "\n", "", "", "", "else", ":", "\n", "                        ", "if", "domain", "+", "'_'", "+", "requestable", "in", "sent_t", ":", "\n", "                            ", "provided_requestables", "[", "domain", "]", ".", "append", "(", "requestable", ")", "\n", "\n", "# offer was made?", "\n", "", "", "", "", "", "for", "domain", "in", "domains_in_goal", ":", "\n", "# if name was provided for the user, the match is being done automatically", "\n", "# if dialog['goal'][domain].has_key('info'):", "\n", "            ", "if", "'info'", "in", "dialog", "[", "'goal'", "]", "[", "domain", "]", ":", "\n", "# if dialog['goal'][domain]['info'].has_key('name'):", "\n", "                ", "if", "'name'", "in", "dialog", "[", "'goal'", "]", "[", "domain", "]", "[", "'info'", "]", ":", "\n", "                    ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "# special domains - entity does not need to be provided", "\n", "", "", "if", "domain", "in", "[", "'taxi'", ",", "'police'", ",", "'hospital'", "]", ":", "\n", "                ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "# if id was not requested but train was found we dont want to override it to check if we booked the right train", "\n", "", "if", "domain", "==", "'train'", "and", "(", "not", "venue_offered", "[", "domain", "]", "and", "'id'", "not", "in", "goal", "[", "'train'", "]", "[", "'requestable'", "]", ")", ":", "\n", "                ", "venue_offered", "[", "domain", "]", "=", "'['", "+", "domain", "+", "'_name]'", "\n", "\n", "# HARD (0-1) EVAL", "\n", "", "", "stats", "=", "{", "'restaurant'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'hotel'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'attraction'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'train'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "'taxi'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "'hospital'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'police'", ":", "[", "0", ",", "0", ",", "0", "]", "}", "\n", "\n", "match", ",", "success", "=", "0", ",", "0", "\n", "# MATCH", "\n", "for", "domain", "in", "goal", ".", "keys", "(", ")", ":", "\n", "            ", "match_stat", "=", "0", "\n", "if", "domain", "in", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", ":", "\n", "                ", "goal_venues", "=", "self", ".", "db", ".", "queryResultVenues", "(", "domain", ",", "dialog", "[", "'goal'", "]", "[", "domain", "]", "[", "'info'", "]", ",", "real_belief", "=", "True", ")", "\n", "# print(goal_venues)", "\n", "if", "type", "(", "venue_offered", "[", "domain", "]", ")", "is", "str", "and", "'_name'", "in", "venue_offered", "[", "domain", "]", ":", "\n", "                    ", "match", "+=", "1", "\n", "match_stat", "=", "1", "\n", "", "elif", "len", "(", "venue_offered", "[", "domain", "]", ")", ">", "0", "and", "venue_offered", "[", "domain", "]", "[", "0", "]", "in", "goal_venues", ":", "\n", "                    ", "match", "+=", "1", "\n", "match_stat", "=", "1", "\n", "\n", "", "", "else", ":", "\n", "                ", "if", "domain", "+", "'_name'", "in", "venue_offered", "[", "domain", "]", ":", "\n", "                    ", "match", "+=", "1", "\n", "match_stat", "=", "1", "\n", "\n", "", "", "stats", "[", "domain", "]", "[", "0", "]", "=", "match_stat", "\n", "stats", "[", "domain", "]", "[", "2", "]", "=", "1", "\n", "\n", "", "if", "match", "==", "len", "(", "goal", ".", "keys", "(", ")", ")", ":", "\n", "            ", "match", "=", "1", "\n", "", "else", ":", "\n", "            ", "match", "=", "0", "\n", "\n", "# SUCCESS", "\n", "", "if", "match", ":", "\n", "            ", "for", "domain", "in", "domains_in_goal", ":", "\n", "                ", "domain_success", "=", "0", "\n", "success_stat", "=", "0", "\n", "if", "len", "(", "real_requestables", "[", "domain", "]", ")", "==", "0", ":", "\n", "# check that", "\n", "                    ", "success", "+=", "1", "\n", "success_stat", "=", "1", "\n", "stats", "[", "domain", "]", "[", "1", "]", "=", "success_stat", "\n", "continue", "\n", "# if values in sentences are super set of requestables", "\n", "", "for", "request", "in", "set", "(", "provided_requestables", "[", "domain", "]", ")", ":", "\n", "                    ", "if", "request", "in", "real_requestables", "[", "domain", "]", ":", "\n", "                        ", "domain_success", "+=", "1", "\n", "\n", "", "", "if", "domain_success", ">=", "len", "(", "real_requestables", "[", "domain", "]", ")", ":", "\n", "                    ", "success", "+=", "1", "\n", "success_stat", "=", "1", "\n", "\n", "", "stats", "[", "domain", "]", "[", "1", "]", "=", "success_stat", "\n", "\n", "# final eval", "\n", "", "if", "success", ">=", "len", "(", "real_requestables", ")", ":", "\n", "                ", "success", "=", "1", "\n", "", "else", ":", "\n", "                ", "success", "=", "0", "\n", "\n", "", "", "return", "goal", ",", "success", ",", "match", ",", "real_requestables", ",", "stats", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator._parse_entities": [[642, 648], ["entities.append"], "methods", ["None"], ["", "def", "_parse_entities", "(", "self", ",", "tokens", ")", ":", "\n", "        ", "entities", "=", "[", "]", "\n", "for", "t", "in", "tokens", ":", "\n", "            ", "if", "'['", "in", "t", "and", "']'", "in", "t", ":", "\n", "                ", "entities", ".", "append", "(", "t", ")", "\n", "", "", "return", "entities", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator.evaluateModel_gpt2": [[649, 731], ["enumerate", "print", "dialogues.items", "evaluate_multiwoz.MultiWozEvaluator._evaluateRealDialogue", "evaluate_multiwoz.MultiWozEvaluator._evaluateGeneratedDialogue", "gen_stats.keys", "evaluate_multiwoz.BLEUScorer", "all", "utils.multiwoz.nlp.BLEUScorer.score", "gen_stats.keys", "enumerate", "print", "float", "float", "corpus_turns.append", "model_turns.append", "len", "len", "corpus.extend", "model_corpus.extend", "model_corpus_len.append", "model_corpus_len.append", "float", "float"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator._evaluateRealDialogue", "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.MultiWozEvaluator._evaluateGeneratedDialogue", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.BLEUScorer.score"], ["", "def", "evaluateModel_gpt2", "(", "self", ",", "dialogues", ",", "real_dialogues", "=", "False", ",", "mode", "=", "'valid'", ")", ":", "\n", "        ", "\"\"\"Gathers statistics for the whole sets.\"\"\"", "\n", "delex_dialogues", "=", "self", ".", "delex_dialogues", "\n", "successes", ",", "matches", "=", "0", ",", "0", "\n", "total", "=", "0", "\n", "\n", "gen_stats", "=", "{", "'restaurant'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'hotel'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'attraction'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'train'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "'taxi'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "'hospital'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'police'", ":", "[", "0", ",", "0", ",", "0", "]", "}", "\n", "sng_gen_stats", "=", "{", "'restaurant'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'hotel'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'attraction'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'train'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "\n", "'taxi'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'hospital'", ":", "[", "0", ",", "0", ",", "0", "]", ",", "'police'", ":", "[", "0", ",", "0", ",", "0", "]", "}", "\n", "\n", "\n", "for", "idx", ",", "(", "filename", ",", "dial", ")", "in", "enumerate", "(", "dialogues", ".", "items", "(", ")", ")", ":", "\n", "            ", "data", "=", "delex_dialogues", "[", "filename", "]", "\n", "\n", "goal", ",", "success", ",", "match", ",", "requestables", ",", "_", "=", "self", ".", "_evaluateRealDialogue", "(", "data", ",", "filename", ")", "\n", "\n", "success", ",", "match", ",", "stats", "=", "self", ".", "_evaluateGeneratedDialogue", "(", "filename", ",", "dial", ",", "goal", ",", "\n", "data", ",", "requestables", ",", "\n", "soft_acc", "=", "mode", "==", "'soft'", ")", "\n", "\n", "successes", "+=", "success", "\n", "matches", "+=", "match", "\n", "total", "+=", "1", "\n", "\n", "for", "domain", "in", "gen_stats", ".", "keys", "(", ")", ":", "\n", "                ", "gen_stats", "[", "domain", "]", "[", "0", "]", "+=", "stats", "[", "domain", "]", "[", "0", "]", "\n", "gen_stats", "[", "domain", "]", "[", "1", "]", "+=", "stats", "[", "domain", "]", "[", "1", "]", "\n", "gen_stats", "[", "domain", "]", "[", "2", "]", "+=", "stats", "[", "domain", "]", "[", "2", "]", "\n", "\n", "", "if", "'SNG'", "in", "filename", ":", "\n", "                ", "for", "domain", "in", "gen_stats", ".", "keys", "(", ")", ":", "\n", "                    ", "sng_gen_stats", "[", "domain", "]", "[", "0", "]", "+=", "stats", "[", "domain", "]", "[", "0", "]", "\n", "sng_gen_stats", "[", "domain", "]", "[", "1", "]", "+=", "stats", "[", "domain", "]", "[", "1", "]", "\n", "sng_gen_stats", "[", "domain", "]", "[", "2", "]", "+=", "stats", "[", "domain", "]", "[", "2", "]", "\n", "\n", "", "", "", "if", "real_dialogues", ":", "\n", "# BLUE SCORE", "\n", "            ", "corpus", "=", "[", "]", "\n", "model_corpus", "=", "[", "]", "\n", "bscorer", "=", "BLEUScorer", "(", ")", "\n", "\n", "for", "dialogue", "in", "dialogues", ":", "\n", "                ", "data", "=", "real_dialogues", "[", "dialogue", "]", "\n", "model_turns", ",", "corpus_turns", "=", "[", "]", ",", "[", "]", "\n", "# for idx, turn in enumerate(data['sys']):", "\n", "for", "idx", ",", "turn", "in", "enumerate", "(", "data", ")", ":", "\n", "                    ", "corpus_turns", ".", "append", "(", "[", "turn", "]", ")", "\n", "", "for", "turn", "in", "dialogues", "[", "dialogue", "]", "[", "'responses'", "]", ":", "\n", "                    ", "model_turns", ".", "append", "(", "[", "turn", "]", ")", "\n", "\n", "# ipdb.set_trace()", "\n", "", "if", "len", "(", "model_turns", ")", "==", "len", "(", "corpus_turns", ")", ":", "\n", "                    ", "corpus", ".", "extend", "(", "corpus_turns", ")", "\n", "model_corpus", ".", "extend", "(", "model_turns", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "(", "'Wrong amount of turns'", ")", "\n", "\n", "", "", "model_corpus_len", "=", "[", "]", "\n", "for", "turn", "in", "model_corpus", ":", "\n", "                ", "if", "turn", "[", "0", "]", "==", "''", ":", "\n", "                    ", "model_corpus_len", ".", "append", "(", "True", ")", "\n", "", "else", ":", "\n", "                    ", "model_corpus_len", ".", "append", "(", "False", ")", "\n", "", "", "if", "all", "(", "model_corpus_len", ")", ":", "\n", "                ", "print", "(", "'no model response'", ")", "\n", "model_corpus", "=", "corpus", "\n", "# ipdb.set_trace()", "\n", "", "blue_score", "=", "bscorer", ".", "score", "(", "model_corpus", ",", "corpus", ")", "\n", "", "else", ":", "\n", "            ", "blue_score", "=", "0.", "\n", "\n", "", "report", "=", "\"\"", "\n", "report", "+=", "'{} Corpus Matches : {:2.2f}%'", ".", "format", "(", "mode", ",", "(", "matches", "/", "float", "(", "total", ")", "*", "100", ")", ")", "+", "\"\\n\"", "\n", "report", "+=", "'{} Corpus Success : {:2.2f}%'", ".", "format", "(", "mode", ",", "(", "successes", "/", "float", "(", "total", ")", "*", "100", ")", ")", "+", "\"\\n\"", "\n", "report", "+=", "'{} Corpus BLEU : {:2.4f}%'", ".", "format", "(", "mode", ",", "blue_score", ")", "+", "\"\\n\"", "\n", "report", "+=", "'Total number of dialogues: %s '", "%", "total", "\n", "\n", "print", "(", "report", ")", "\n", "\n", "return", "report", ",", "successes", "/", "float", "(", "total", ")", ",", "matches", "/", "float", "(", "total", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.remove_model_mismatch_and_db_data": [[17, 102], ["None"], "function", ["None"], ["def", "remove_model_mismatch_and_db_data", "(", "dial_name", ",", "target_beliefs", ",", "pred_beliefs", ",", "domain", ",", "t", ")", ":", "\n", "    ", "if", "domain", "==", "'hotel'", ":", "\n", "        ", "if", "domain", "in", "target_beliefs", "[", "t", "]", ":", "\n", "            ", "if", "'type'", "in", "pred_beliefs", "[", "domain", "]", "and", "'type'", "in", "target_beliefs", "[", "t", "]", "[", "domain", "]", ":", "\n", "                ", "if", "pred_beliefs", "[", "domain", "]", "[", "'type'", "]", "!=", "target_beliefs", "[", "t", "]", "[", "domain", "]", "[", "'type'", "]", ":", "\n", "                    ", "pred_beliefs", "[", "domain", "]", "[", "'type'", "]", "=", "target_beliefs", "[", "t", "]", "[", "domain", "]", "[", "'type'", "]", "\n", "", "", "elif", "'type'", "in", "pred_beliefs", "[", "domain", "]", "and", "'type'", "not", "in", "target_beliefs", "[", "t", "]", "[", "domain", "]", ":", "\n", "                ", "del", "pred_beliefs", "[", "domain", "]", "[", "'type'", "]", "\n", "\n", "", "", "", "if", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'pizza hut fenditton'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "=", "'pizza hut fen ditton'", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "==", "'riverside brasserie'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'food'", "]", "=", "\"modern european\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'charlie chan'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'area'", "]", "=", "\"centre\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "==", "'saint johns chop house'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'pricerange'", "]", "=", "\"moderate\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "==", "'pizza hut fen ditton'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'pricerange'", "]", "=", "\"moderate\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'cote'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'pricerange'", "]", "=", "\"expensive\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "==", "'cambridge lodge restaurant'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'food'", "]", "=", "\"european\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "==", "'cafe jello gallery'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'food'", "]", "=", "\"peking restaurant\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'nandos'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'food'", "]", "=", "\"portuguese\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "==", "'yippee noodle bar'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'pricerange'", "]", "=", "\"moderate\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'copper kettle'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'food'", "]", "=", "\"british\"", "\n", "\n", "", "if", "domain", "==", "'restaurant'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "in", "[", "'nirala'", ",", "'the nirala'", "]", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'food'", "]", "=", "\"indian\"", "\n", "\n", "", "if", "domain", "==", "'attraction'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'vue cinema'", ":", "\n", "        ", "if", "'type'", "in", "pred_beliefs", "[", "domain", "]", ":", "\n", "            ", "del", "pred_beliefs", "[", "domain", "]", "[", "'type'", "]", "\n", "\n", "", "", "if", "domain", "==", "'attraction'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'funky fun house'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'area'", "]", "=", "'dontcare'", "\n", "\n", "", "if", "domain", "==", "'attraction'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'little seoul'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "=", "'downing college'", "# correct name in turn_belief_pred", "\n", "\n", "", "if", "domain", "==", "'attraction'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'byard art'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'type'", "]", "=", "'museum'", "# correct name in turn_belief_pred", "\n", "\n", "", "if", "domain", "==", "'attraction'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'trinity college'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'type'", "]", "=", "'college'", "# correct name in turn_belief_pred", "\n", "\n", "", "if", "domain", "==", "'attraction'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "\n", "'name'", "]", "==", "'cambridge university botanic gardens'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'area'", "]", "=", "'centre'", "# correct name in turn_belief_pred", "\n", "\n", "", "if", "domain", "==", "'hotel'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'lovell lodge'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'parking'", "]", "=", "'yes'", "# correct name in turn_belief_pred", "\n", "\n", "", "if", "domain", "==", "'hotel'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'whale of a time'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'type'", "]", "=", "'entertainment'", "# correct name in turn_belief_pred", "\n", "\n", "", "if", "domain", "==", "'hotel'", "and", "'name'", "in", "pred_beliefs", "[", "domain", "]", "and", "pred_beliefs", "[", "domain", "]", "[", "'name'", "]", "==", "'a and b guest house'", ":", "\n", "        ", "pred_beliefs", "[", "domain", "]", "[", "'parking'", "]", "=", "'yes'", "# correct name in turn_belief_pred", "\n", "\n", "", "if", "dial_name", "==", "'MUL0116.json'", "and", "domain", "==", "'hotel'", "and", "'area'", "in", "pred_beliefs", "[", "domain", "]", ":", "\n", "        ", "del", "pred_beliefs", "[", "domain", "]", "[", "'area'", "]", "\n", "\n", "", "return", "pred_beliefs", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.postprocess_gpt2": [[733, 828], ["generated_raw_data.items", "belief_dict.append", "target_beliefs_dict.append", "len", "bs.split", "print", "bs.split", "len", "bs.split", "print", "bs.split", "bs.split", "bs.split", "bs.split", "print", "bs.split", "bs.split", "bs.split", "bs.split", "len", "len", "aggregated_belief_dict[].keys", "[].keys"], "function", ["None"], ["", "", "def", "postprocess_gpt2", "(", "generated_raw_data", ")", ":", "\n", "    ", "generated_proc_data", "=", "{", "}", "\n", "for", "key", ",", "value", "in", "generated_raw_data", ".", "items", "(", ")", ":", "\n", "        ", "target_beliefs", "=", "value", "[", "'target_turn_belief'", "]", "\n", "target_beliefs_dict", "=", "[", "]", "\n", "beliefs", "=", "value", "[", "'generated_turn_belief'", "]", "\n", "belief_dict", "=", "[", "]", "\n", "\n", "for", "turn_bs", "in", "beliefs", ":", "\n", "            ", "bs_dict", "=", "{", "}", "\n", "for", "bs", "in", "turn_bs", ":", "\n", "                ", "if", "len", "(", "bs", ".", "split", "(", ")", ")", "<", "3", ":", "\n", "                    ", "continue", "\n", "", "if", "bs", "in", "[", "''", ",", "' '", "]", ":", "\n", "                    ", "continue", "\n", "", "domain", "=", "bs", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "domain", "not", "in", "[", "'train'", ",", "'taxi'", ",", "'hotel'", ",", "'hospital'", ",", "'attraction'", ",", "'restaurant'", "]", ":", "\n", "                    ", "print", "(", "key", ",", "domain", ")", "\n", "continue", "\n", "", "if", "'book'", "in", "bs", ":", "\n", "                    ", "continue", "\n", "", "slot", "=", "bs", ".", "split", "(", ")", "[", "1", "]", "\n", "val", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", ")", "[", "2", ":", "]", ")", "\n", "if", "val", "==", "'none'", ":", "\n", "                    ", "continue", "\n", "", "if", "domain", "not", "in", "bs_dict", ":", "\n", "                    ", "bs_dict", "[", "domain", "]", "=", "{", "}", "\n", "", "bs_dict", "[", "domain", "]", "[", "slot", "]", "=", "val", "\n", "", "belief_dict", ".", "append", "(", "bs_dict", ")", "\n", "\n", "", "aggregated_belief_dict", "=", "{", "}", "\n", "for", "bs", "in", "value", "[", "'generated_belief'", "]", ":", "\n", "            ", "if", "len", "(", "bs", ".", "split", "(", ")", ")", "<", "3", ":", "\n", "# print('skipping {}'.format(bs))", "\n", "                ", "continue", "\n", "", "domain", "=", "bs", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "domain", "not", "in", "[", "'train'", ",", "'taxi'", ",", "'hotel'", ",", "'hospital'", ",", "'attraction'", ",", "'restaurant'", "]", ":", "\n", "                ", "print", "(", "domain", ")", "\n", "continue", "\n", "", "if", "'book'", "in", "bs", ":", "\n", "                ", "continue", "\n", "", "slot", "=", "bs", ".", "split", "(", ")", "[", "1", "]", "\n", "val", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", ")", "[", "2", ":", "]", ")", "\n", "if", "val", "==", "'none'", ":", "\n", "                ", "continue", "\n", "", "if", "domain", "not", "in", "aggregated_belief_dict", ":", "\n", "                ", "aggregated_belief_dict", "[", "domain", "]", "=", "{", "}", "\n", "", "aggregated_belief_dict", "[", "domain", "]", "[", "slot", "]", "=", "val", "\n", "\n", "", "for", "turn_bs", "in", "target_beliefs", ":", "\n", "            ", "bs_dict", "=", "{", "}", "\n", "for", "bs", "in", "turn_bs", ":", "\n", "                ", "if", "bs", "in", "[", "''", ",", "' '", "]", ":", "\n", "                    ", "continue", "\n", "", "domain", "=", "bs", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "domain", "not", "in", "[", "'train'", ",", "'taxi'", ",", "'hotel'", ",", "'hospital'", ",", "'attraction'", ",", "'restaurant'", "]", ":", "\n", "                    ", "print", "(", "domain", ")", "\n", "continue", "\n", "", "if", "'book'", "in", "bs", ":", "\n", "                    ", "continue", "\n", "", "slot", "=", "bs", ".", "split", "(", ")", "[", "1", "]", "\n", "val", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", ")", "[", "2", ":", "]", ")", "\n", "if", "val", "==", "'none'", ":", "\n", "                    ", "continue", "\n", "", "if", "domain", "not", "in", "bs_dict", ":", "\n", "                    ", "bs_dict", "[", "domain", "]", "=", "{", "}", "\n", "", "bs_dict", "[", "domain", "]", "[", "slot", "]", "=", "val", "\n", "", "target_beliefs_dict", ".", "append", "(", "bs_dict", ")", "\n", "\n", "", "if", "aggregated_belief_dict", "!=", "belief_dict", "[", "-", "1", "]", ":", "\n", "            ", "for", "domain", "in", "aggregated_belief_dict", ":", "\n", "                ", "if", "domain", "==", "'attraction'", "and", "domain", "in", "belief_dict", "[", "-", "1", "]", "and", "len", "(", "\n", "aggregated_belief_dict", "[", "domain", "]", ".", "keys", "(", ")", ")", "<", "len", "(", "belief_dict", "[", "-", "1", "]", "[", "domain", "]", ".", "keys", "(", ")", ")", ":", "\n", "                    ", "aggregated_belief_dict", "[", "domain", "]", "=", "belief_dict", "[", "-", "1", "]", "[", "domain", "]", "\n", "", "elif", "domain", "==", "'restaurant'", "and", "domain", "in", "aggregated_belief_dict", "and", "'name'", "in", "aggregated_belief_dict", "[", "\n", "domain", "]", "and", "aggregated_belief_dict", "[", "domain", "]", "[", "'name'", "]", "==", "'lovell lodge'", "and", "domain", "in", "belief_dict", "[", "\n", "-", "1", "]", "and", "'name'", "in", "belief_dict", "[", "-", "1", "]", "[", "domain", "]", "and", "belief_dict", "[", "-", "1", "]", "[", "domain", "]", "[", "'name'", "]", "==", "'restaurant 17'", ":", "\n", "# ipdb.set_trace()", "\n", "                    ", "aggregated_belief_dict", "[", "domain", "]", "=", "belief_dict", "[", "-", "1", "]", "[", "domain", "]", "\n", "", "elif", "domain", "==", "'restaurant'", "and", "'name'", "in", "aggregated_belief_dict", "[", "domain", "]", "and", "aggregated_belief_dict", "[", "domain", "]", "[", "'name'", "]", "==", "'curry garden'", "and", "'area'", "in", "aggregated_belief_dict", "[", "\n", "domain", "]", "and", "aggregated_belief_dict", "[", "domain", "]", "[", "'area'", "]", "==", "'east'", "and", "domain", "in", "belief_dict", ":", "\n", "                    ", "aggregated_belief_dict", "[", "domain", "]", "=", "belief_dict", "[", "-", "1", "]", "[", "domain", "]", "\n", "\n", "\n", "", "", "", "generated_proc_data", "[", "key", "]", "=", "{", "\n", "'name'", ":", "key", ",", "\n", "'responses'", ":", "value", "[", "'generated_response'", "]", ",", "\n", "'beliefs'", ":", "belief_dict", ",", "\n", "'aggregated_belief'", ":", "aggregated_belief_dict", ",", "\n", "'target_beliefs'", ":", "target_beliefs_dict", ",", "\n", "'generated_action'", ":", "value", "[", "'generated_action'", "]", ",", "\n", "'target_action'", ":", "value", "[", "'target_action'", "]", ",", "\n", "}", "\n", "", "return", "generated_proc_data", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.get_model_tokenizer": [[60, 106], ["model_class.to", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "min", "model_class.from_pretrained", "logger.info", "model_class", "tokenizer_class.from_pretrained.add_special_tokens", "tokenizer_class.from_pretrained.add_special_tokens", "config_class.from_pretrained", "config_class", "tokenizer_class.from_pretrained", "ValueError", "bool"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained"], ["def", "get_model_tokenizer", "(", "args", ")", ":", "\n", "    ", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "if", "args", ".", "config_name", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "config", "=", "config_class", "(", ")", "\n", "\n", "", "if", "args", ".", "tokenizer_name", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "elif", "args", ".", "model_name_or_path", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "cache_dir", "=", "args", ".", "cache_dir", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"You are instantiating a new {} tokenizer. This is not supported, but you can do it from another script, save it,\"", "\n", "\"and load it from here, using --tokenizer_name\"", ".", "format", "(", "tokenizer_class", ".", "__name__", ")", "\n", ")", "\n", "\n", "", "if", "args", ".", "block_size", "<=", "0", ":", "\n", "        ", "args", ".", "block_size", "=", "tokenizer", ".", "max_len", "\n", "# Our input block size will be the max possible for the model", "\n", "", "else", ":", "\n", "        ", "args", ".", "block_size", "=", "min", "(", "args", ".", "block_size", ",", "tokenizer", ".", "max_len", ")", "\n", "\n", "", "if", "args", ".", "model_name_or_path", ":", "\n", "        ", "model", "=", "model_class", ".", "from_pretrained", "(", "\n", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Training new model from scratch\"", ")", "\n", "model", "=", "model_class", "(", "config", "=", "config", ")", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "if", "args", ".", "model_name_or_path", "==", "'openai-gpt'", ":", "\n", "        ", "tokenizer", ".", "add_special_tokens", "(", "{", "'bos_token'", ":", "'<|endoftext|>'", "}", ")", "\n", "tokenizer", ".", "add_special_tokens", "(", "{", "'eos_token'", ":", "'<|endoftext|>'", "}", ")", "\n", "", "elif", "args", ".", "model_name_or_path", "==", "'gpt2'", ":", "\n", "        ", "pass", "\n", "\n", "", "return", "model", ",", "tokenizer", ",", "model_class", ",", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.get_training_info": [[108, 129], ["os.path.exists", "int", "logger.info", "logger.info", "logger.info", "logger.info", "[].split", "logger.info", "len", "len", "args.model_name_or_path.split"], "function", ["None"], ["", "def", "get_training_info", "(", "dataloader", ",", "args", ")", ":", "\n", "    ", "global_step", "=", "0", "\n", "epochs_trained", "=", "0", "\n", "steps_trained_in_current_epoch", "=", "0", "\n", "\n", "# Check if continuing training from a checkpoint", "\n", "if", "args", ".", "model_name_or_path", "and", "os", ".", "path", ".", "exists", "(", "args", ".", "model_name_or_path", ")", ":", "\n", "        ", "try", ":", "\n", "# set global_step to gobal_step of last saved checkpoint from model path", "\n", "            ", "checkpoint_suffix", "=", "args", ".", "model_name_or_path", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", ".", "split", "(", "\"/\"", ")", "[", "0", "]", "\n", "global_step", "=", "int", "(", "checkpoint_suffix", ")", "\n", "epochs_trained", "=", "global_step", "//", "(", "len", "(", "dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "steps_trained_in_current_epoch", "=", "global_step", "%", "(", "len", "(", "dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "\n", "\n", "logger", ".", "info", "(", "\"  Continuing training from checkpoint, will skip to saved global_step\"", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from epoch %d\"", ",", "epochs_trained", ")", "\n", "logger", ".", "info", "(", "\"  Continuing training from global step %d\"", ",", "global_step", ")", "\n", "logger", ".", "info", "(", "\"  Will skip the first %d steps in the first epoch\"", ",", "steps_trained_in_current_epoch", ")", "\n", "", "except", "ValueError", ":", "\n", "            ", "logger", ".", "info", "(", "\"  Starting fine-tuning.\"", ")", "\n", "", "", "return", "global_step", ",", "epochs_trained", ",", "steps_trained_in_current_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.train_epoch": [[132, 197], ["tqdm.tqdm", "enumerate", "inputs.to.to", "labels.to.to", "model.train", "model", "loss.mean.item", "loss.mean.mean", "loss.mean.backward", "optimizer.step", "scheduler.step", "model.zero_grad", "tqdm.tqdm.close", "ImportError", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "tb_writer.add_scalar", "tb_writer.add_scalar", "amp.master_params", "model.parameters", "main.evaluate", "evaluate.items", "utils.model.save_checkpoint", "tb_writer.add_scalar", "scheduler.get_lr"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.main.train", "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.evaluate", "home.repos.pwc.inspect_result.salesforce_simpletod.utils.model.save_checkpoint"], ["", "def", "train_epoch", "(", "model", ",", "tokenizer", ",", "optimizer", ",", "scheduler", ",", "train_dataloader", ",", "tr_loss", ",", "logging_loss", ",", "global_step", ",", "steps_trained_in_current_epoch", ",", "tb_writer", ",", "args", ")", ":", "\n", "    ", "\"\"\"train one epoch\"\"\"", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "\n", "", "", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "\n", "# Skip past any already trained steps if resuming training", "\n", "        ", "if", "steps_trained_in_current_epoch", ">", "0", ":", "\n", "            ", "steps_trained_in_current_epoch", "-=", "1", "\n", "continue", "\n", "\n", "", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "model", ".", "train", "(", ")", "\n", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "            ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "            ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "            ", "if", "args", ".", "fp16", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "# Log metrics", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                ", "if", "(", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ")", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                    ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "# save checkpoint", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "evaluate_during_training", ":", "\n", "                    ", "save_checkpoint", "(", "model", ",", "optimizer", ",", "scheduler", ",", "tokenizer", ",", "args", ")", "\n", "\n", "", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "return", "model", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "tr_loss", ",", "logging_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.train": [[199, 272], ["data.dataset.language_model.get_dataloader", "utils.language_model.get_optimizer_scheduler", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "main.get_training_info", "model_to_resize.resize_token_embeddings", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "SummaryWriter", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "hasattr", "len", "int", "main.train_epoch", "SummaryWriter.close", "torch.distributed.get_world_size", "len", "tqdm.trange.close", "len", "ImportError", "args.output_dir.split", "len"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.get_dataloader", "home.repos.pwc.inspect_result.salesforce_simpletod.utils.language_model.get_optimizer_scheduler", "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.get_training_info", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.resize_token_embeddings", "home.repos.pwc.inspect_result.salesforce_simpletod.None.evaluate_multiwoz.BaseEvaluator.initialize", "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.train_epoch"], ["", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", "'./runs/{}'", ".", "format", "(", "args", ".", "output_dir", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ")", ")", "\n", "\n", "# Prepare dataloader", "\n", "", "train_dataloader", ",", "args", "=", "get_dataloader", "(", "train_dataset", ",", "tokenizer", ",", "args", ")", "\n", "\n", "# total iteration and batch size", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "", "total_batch_size", "=", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "optimizer", ",", "scheduler", "=", "get_optimizer_scheduler", "(", "args", ",", "model", ",", "t_total", ")", "\n", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "output_device", "=", "args", ".", "local_rank", ",", "find_unused_parameters", "=", "True", "\n", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = {}\"", ".", "format", "(", "len", "(", "train_dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = {}\"", ".", "format", "(", "args", ".", "num_train_epochs", ")", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = {}\"", ".", "format", "(", "args", ".", "per_gpu_train_batch_size", ")", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = {}\"", ".", "format", "(", "total_batch_size", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = {}\"", ".", "format", "(", "args", ".", "gradient_accumulation_steps", ")", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = {}\"", ".", "format", "(", "t_total", ")", ")", "\n", "\n", "global_step", ",", "epochs_trained", ",", "steps_trained_in_current_epoch", "=", "get_training_info", "(", "train_dataloader", ",", "args", ")", "\n", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "\n", "model_to_resize", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_resize", ".", "resize_token_embeddings", "(", "len", "(", "tokenizer", ")", ")", "\n", "\n", "model", ".", "zero_grad", "(", ")", "\n", "\n", "train_iterator", "=", "trange", "(", "\n", "epochs_trained", ",", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "\n", ")", "\n", "\n", "for", "_", "in", "train_iterator", ":", "\n", "\n", "        ", "model", ",", "optimizer", ",", "scheduler", ",", "global_step", ",", "tr_loss", ",", "logging_loss", "=", "train_epoch", "(", "model", ",", "tokenizer", ",", "optimizer", ",", "scheduler", ",", "train_dataloader", ",", "tr_loss", ",", "logging_loss", ",", "global_step", ",", "\n", "steps_trained_in_current_epoch", ",", "tb_writer", ",", "args", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.evaluate": [[274, 322], ["data.dataset.language_model.load_and_cache_examples", "data.dataset.language_model.get_dataloader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "torch.exp", "os.path.join", "os.makedirs", "torch.nn.DataParallel", "inputs.to.to", "labels.to.to", "torch.tensor", "open", "logger.info", "sorted", "len", "torch.no_grad", "torch.nn.DataParallel.", "lm_loss.mean().item", "result.keys", "logger.info", "writer.write", "str", "lm_loss.mean", "str"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.load_and_cache_examples", "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.get_dataloader"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_output_dir", "=", "args", ".", "output_dir", "\n", "\n", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "True", ")", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "os", ".", "makedirs", "(", "eval_output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Prepare dataloader", "\n", "", "eval_dataloader", ",", "args", "=", "get_dataloader", "(", "eval_dataset", ",", "tokenizer", ",", "args", ",", "split", "=", "'eval'", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = {}\"", ".", "format", "(", "len", "(", "eval_dataset", ")", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = {}\"", ".", "format", "(", "args", ".", "eval_batch_size", ")", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "inputs", ",", "labels", "=", "(", "batch", ",", "batch", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "args", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "outputs", "=", "model", "(", "inputs", ",", "labels", "=", "labels", ")", "\n", "lm_loss", "=", "outputs", "[", "0", "]", "\n", "eval_loss", "+=", "lm_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "\n", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "perplexity", "=", "torch", ".", "exp", "(", "torch", ".", "tensor", "(", "eval_loss", ")", ")", "\n", "\n", "result", "=", "{", "\"perplexity\"", ":", "perplexity", "}", "\n", "\n", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "        ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.main": [[324, 412], ["utils.gpt2_args_parser.ArgsParser().parse", "logging.basicConfig", "logger.warning", "main.get_model_tokenizer", "logger.info", "ValueError", "utils.model._sorted_checkpoints", "torch.device", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.distributed.barrier", "torch.distributed.barrier", "data.dataset.language_model.load_and_cache_examples", "main.train", "logger.info", "logger.info", "utils.gpt2_args_parser.ArgsParser", "len", "ValueError", "torch.cuda.device_count", "torch.distributed.barrier", "torch.distributed.barrier", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "main.evaluate", "dict", "results.update", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.utils.gpt2_args_parser.ArgsParser.parse", "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.get_model_tokenizer", "home.repos.pwc.inspect_result.salesforce_simpletod.utils.model._sorted_checkpoints", "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.load_and_cache_examples", "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.train", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained", "home.repos.pwc.inspect_result.salesforce_simpletod.None.main.evaluate"], ["", "def", "main", "(", ")", ":", "\n", "\n", "    ", "args", "=", "ArgsParser", "(", ")", ".", "parse", "(", ")", "\n", "\n", "if", "args", ".", "eval_data_file", "is", "None", "and", "args", ".", "do_eval", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"--eval_data_file should be specified when do_eval is true\"", "\n", ")", "\n", "", "if", "args", ".", "should_continue", ":", "\n", "        ", "sorted_checkpoints", "=", "_sorted_checkpoints", "(", "args", ")", "\n", "if", "len", "(", "sorted_checkpoints", ")", "==", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\"--should_continue is true, but no checkpoint found in --output_dir\"", ")", "\n", "", "else", ":", "\n", "            ", "args", ".", "model_name_or_path", "=", "sorted_checkpoints", "[", "-", "1", "]", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "0", "if", "args", ".", "no_cuda", "else", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# initialize distributed training", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "\n", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ",", "\n", ")", "\n", "logger", ".", "warning", "(", "\n", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "\n", "device", ",", "\n", "args", ".", "n_gpu", ",", "\n", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "\n", "args", ".", "fp16", ",", "\n", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# if not the first process, do not load pretrained model & vocab", "\n", "\n", "", "model", ",", "tokenizer", ",", "model_class", ",", "args", "=", "get_model_tokenizer", "(", "args", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# finish barrier, when first process has loaded pretrained model & vocab", "\n", "\n", "", "logger", ".", "info", "(", "\"Training/evaluation parameters {}\"", ".", "format", "(", "args", ")", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# only first process will preprocess data/caching", "\n", "\n", "", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "evaluate", "=", "False", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "            ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# end of barrier", "\n", "\n", "", "global_step", ",", "train_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = {}, average loss = {}\"", ".", "format", "(", "global_step", ",", "train_loss", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "\n", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", "\n", ")", "\n", "logging", ".", "getLogger", "(", "\"models.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: {}\"", ".", "format", "(", "checkpoints", ")", ")", "\n", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "\"/\"", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "\"checkpoint\"", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "\"_{}\"", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.is_ascii": [[33, 35], ["all", "ord"], "function", ["None"], ["def", "is_ascii", "(", "s", ")", ":", "\n", "    ", "return", "all", "(", "ord", "(", "c", ")", "<", "128", "for", "c", "in", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.fixDelex": [[37, 64], ["turn.items", "isinstance", "isinstance", "str", "filename.strip", "[].replace", "[].replace", "[].replace", "[].replace", "[].replace", "[].replace"], "function", ["None"], ["", "def", "fixDelex", "(", "filename", ",", "data", ",", "data2", ",", "idx", ",", "idx_acts", ")", ":", "\n", "    ", "\"\"\"Given system dialogue acts fix automatic delexicalization.\"\"\"", "\n", "try", ":", "\n", "        ", "turn", "=", "data2", "[", "filename", ".", "strip", "(", "'.json'", ")", "]", "[", "str", "(", "idx_acts", ")", "]", "\n", "", "except", ":", "\n", "        ", "return", "data", "\n", "\n", "# if not isinstance(turn, str) and not isinstance(turn, unicode):", "\n", "", "if", "not", "isinstance", "(", "turn", ",", "bytes", ")", "and", "not", "isinstance", "(", "turn", ",", "str", ")", ":", "\n", "        ", "for", "k", ",", "act", "in", "turn", ".", "items", "(", ")", ":", "\n", "            ", "if", "'Attraction'", "in", "k", ":", "\n", "                ", "if", "'restaurant_'", "in", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ":", "\n", "                    ", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ".", "replace", "(", "\"restaurant\"", ",", "\"attraction\"", ")", "\n", "", "if", "'hotel_'", "in", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ":", "\n", "                    ", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ".", "replace", "(", "\"hotel\"", ",", "\"attraction\"", ")", "\n", "", "", "if", "'Hotel'", "in", "k", ":", "\n", "                ", "if", "'attraction_'", "in", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ":", "\n", "                    ", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ".", "replace", "(", "\"attraction\"", ",", "\"hotel\"", ")", "\n", "", "if", "'restaurant_'", "in", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ":", "\n", "                    ", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ".", "replace", "(", "\"restaurant\"", ",", "\"hotel\"", ")", "\n", "", "", "if", "'Restaurant'", "in", "k", ":", "\n", "                ", "if", "'attraction_'", "in", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ":", "\n", "                    ", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ".", "replace", "(", "\"attraction\"", ",", "\"restaurant\"", ")", "\n", "", "if", "'hotel_'", "in", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ":", "\n", "                    ", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "data", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", ".", "replace", "(", "\"hotel\"", ",", "\"restaurant\"", ")", "\n", "\n", "", "", "", "", "return", "data", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.delexicaliseReferenceNumber": [[66, 89], ["utils.multiwoz.nlp.normalize", "utils.multiwoz.nlp.normalize", "utils.multiwoz.nlp.normalize"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize"], ["", "def", "delexicaliseReferenceNumber", "(", "sent", ",", "turn", ")", ":", "\n", "    ", "\"\"\"Based on the belief state, we can find reference number that\n    during data gathering was created randomly.\"\"\"", "\n", "domains", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", ",", "'taxi'", ",", "'hospital'", "]", "# , 'police']", "\n", "if", "turn", "[", "'metadata'", "]", ":", "\n", "        ", "for", "domain", "in", "domains", ":", "\n", "            ", "if", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", ":", "\n", "                ", "for", "slot", "in", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", ":", "\n", "                    ", "if", "slot", "==", "'reference'", ":", "\n", "                        ", "val", "=", "'['", "+", "domain", "+", "'_'", "+", "slot", "+", "']'", "\n", "", "else", ":", "\n", "                        ", "val", "=", "'['", "+", "domain", "+", "'_'", "+", "slot", "+", "']'", "\n", "", "key", "=", "normalize", "(", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", "[", "slot", "]", ")", "\n", "sent", "=", "(", "' '", "+", "sent", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "\n", "# try reference with hashtag", "\n", "key", "=", "normalize", "(", "\"#\"", "+", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", "[", "slot", "]", ")", "\n", "sent", "=", "(", "' '", "+", "sent", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "\n", "# try reference with ref#", "\n", "key", "=", "normalize", "(", "\"ref#\"", "+", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", "[", "slot", "]", ")", "\n", "sent", "=", "(", "' '", "+", "sent", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "", "", "", "", "return", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.delexicaliseReferenceNumber_mine": [[91, 114], ["utils.multiwoz.nlp.normalize_mine", "utils.multiwoz.nlp.normalize_mine", "utils.multiwoz.nlp.normalize_mine"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_mine", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_mine", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_mine"], ["", "def", "delexicaliseReferenceNumber_mine", "(", "sent", ",", "turn", ")", ":", "\n", "    ", "\"\"\"Based on the belief state, we can find reference number that\n    during data gathering was created randomly.\"\"\"", "\n", "domains", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", ",", "'taxi'", ",", "'hospital'", "]", "# , 'police']", "\n", "if", "turn", "[", "'metadata'", "]", ":", "\n", "        ", "for", "domain", "in", "domains", ":", "\n", "            ", "if", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", ":", "\n", "                ", "for", "slot", "in", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", ":", "\n", "                    ", "if", "slot", "==", "'reference'", ":", "\n", "                        ", "val", "=", "'['", "+", "domain", "+", "'_'", "+", "slot", "+", "']'", "\n", "", "else", ":", "\n", "                        ", "val", "=", "'['", "+", "domain", "+", "'_'", "+", "slot", "+", "']'", "\n", "", "key", "=", "normalize_mine", "(", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", "[", "slot", "]", ")", "\n", "sent", "=", "(", "' '", "+", "sent", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "\n", "# try reference with hashtag", "\n", "key", "=", "normalize_mine", "(", "\"#\"", "+", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", "[", "slot", "]", ")", "\n", "sent", "=", "(", "' '", "+", "sent", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "\n", "# try reference with ref#", "\n", "key", "=", "normalize_mine", "(", "\"ref#\"", "+", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", "[", "0", "]", "[", "slot", "]", ")", "\n", "sent", "=", "(", "' '", "+", "sent", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "", "", "", "", "return", "sent", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addBookingPointer": [[116, 154], ["numpy.array", "numpy.array", "numpy.array", "numpy.append", "numpy.append", "numpy.append", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "addBookingPointer", "(", "task", ",", "turn", ",", "pointer_vector", ")", ":", "\n", "    ", "\"\"\"Add information about availability of the booking option.\"\"\"", "\n", "# Booking pointer", "\n", "rest_vec", "=", "np", ".", "array", "(", "[", "1", ",", "0", "]", ")", "\n", "if", "task", "[", "'goal'", "]", "[", "'restaurant'", "]", ":", "\n", "# if turn['metadata']['restaurant'].has_key(\"book\"):", "\n", "# if turn['metadata']['restaurant']['book'].has_key(\"booked\"):", "\n", "        ", "if", "\"book\"", "in", "turn", "[", "'metadata'", "]", "[", "'restaurant'", "]", ":", "\n", "            ", "if", "\"booked\"", "in", "turn", "[", "'metadata'", "]", "[", "'restaurant'", "]", "[", "'book'", "]", ":", "\n", "                ", "if", "turn", "[", "'metadata'", "]", "[", "'restaurant'", "]", "[", "'book'", "]", "[", "\"booked\"", "]", ":", "\n", "                    ", "if", "\"reference\"", "in", "turn", "[", "'metadata'", "]", "[", "'restaurant'", "]", "[", "'book'", "]", "[", "\"booked\"", "]", "[", "0", "]", ":", "\n", "                        ", "rest_vec", "=", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", "\n", "\n", "", "", "", "", "", "hotel_vec", "=", "np", ".", "array", "(", "[", "1", ",", "0", "]", ")", "\n", "if", "task", "[", "'goal'", "]", "[", "'hotel'", "]", ":", "\n", "# if turn['metadata']['hotel'].has_key(\"book\"):", "\n", "#     if turn['metadata']['hotel']['book'].has_key(\"booked\"):", "\n", "        ", "if", "\"book\"", "in", "turn", "[", "'metadata'", "]", "[", "'hotel'", "]", ":", "\n", "            ", "if", "\"booked\"", "in", "turn", "[", "'metadata'", "]", "[", "'hotel'", "]", "[", "'book'", "]", ":", "\n", "                ", "if", "turn", "[", "'metadata'", "]", "[", "'hotel'", "]", "[", "'book'", "]", "[", "\"booked\"", "]", ":", "\n", "                    ", "if", "\"reference\"", "in", "turn", "[", "'metadata'", "]", "[", "'hotel'", "]", "[", "'book'", "]", "[", "\"booked\"", "]", "[", "0", "]", ":", "\n", "                        ", "hotel_vec", "=", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", "\n", "\n", "", "", "", "", "", "train_vec", "=", "np", ".", "array", "(", "[", "1", ",", "0", "]", ")", "\n", "if", "task", "[", "'goal'", "]", "[", "'train'", "]", ":", "\n", "# if turn['metadata']['train'].has_key(\"book\"):", "\n", "#     if turn['metadata']['train']['book'].has_key(\"booked\"):", "\n", "        ", "if", "\"book\"", "in", "turn", "[", "'metadata'", "]", "[", "'train'", "]", ":", "\n", "            ", "if", "\"booked\"", "in", "turn", "[", "'metadata'", "]", "[", "'train'", "]", "[", "'book'", "]", ":", "\n", "                ", "if", "turn", "[", "'metadata'", "]", "[", "'train'", "]", "[", "'book'", "]", "[", "\"booked\"", "]", ":", "\n", "                    ", "if", "\"reference\"", "in", "turn", "[", "'metadata'", "]", "[", "'train'", "]", "[", "'book'", "]", "[", "\"booked\"", "]", "[", "0", "]", ":", "\n", "                        ", "train_vec", "=", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", "\n", "\n", "", "", "", "", "", "pointer_vector", "=", "np", ".", "append", "(", "pointer_vector", ",", "rest_vec", ")", "\n", "pointer_vector", "=", "np", ".", "append", "(", "pointer_vector", ",", "hotel_vec", ")", "\n", "pointer_vector", "=", "np", ".", "append", "(", "pointer_vector", ",", "train_vec", ")", "\n", "\n", "return", "pointer_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addDBPointer": [[156, 165], ["numpy.zeros", "utils.multiwoz.dbPointer.queryResult", "utils.multiwoz.dbPointer.oneHotVector", "len"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResult", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.oneHotVector"], ["", "def", "addDBPointer", "(", "turn", ")", ":", "\n", "    ", "\"\"\"Create database pointer for all related domains.\"\"\"", "\n", "domains", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", "\n", "pointer_vector", "=", "np", ".", "zeros", "(", "6", "*", "len", "(", "domains", ")", ")", "\n", "for", "domain", "in", "domains", ":", "\n", "        ", "num_entities", "=", "dbPointer", ".", "queryResult", "(", "domain", ",", "turn", ")", "\n", "pointer_vector", "=", "dbPointer", ".", "oneHotVector", "(", "num_entities", ",", "domain", ",", "pointer_vector", ")", "\n", "\n", "", "return", "pointer_vector", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_summary_bstate": [[167, 216], ["sorted", "len", "[].keys", "[].keys", "booking.append", "[].keys", "booking.append", "booking.append", "booking.append", "booking.append", "booking.append"], "function", ["None"], ["", "def", "get_summary_bstate", "(", "bstate", ")", ":", "\n", "    ", "\"\"\"Based on the mturk annotations we form multi-domain belief state\"\"\"", "\n", "domains", "=", "[", "u'taxi'", ",", "u'restaurant'", ",", "u'hospital'", ",", "u'hotel'", ",", "u'attraction'", ",", "u'train'", ",", "u'police'", "]", "\n", "summary_bstate", "=", "[", "]", "\n", "for", "domain", "in", "domains", ":", "\n", "        ", "domain_active", "=", "False", "\n", "\n", "booking", "=", "[", "]", "\n", "# print(domain,len(bstate[domain]['book'].keys()))", "\n", "for", "slot", "in", "sorted", "(", "bstate", "[", "domain", "]", "[", "'book'", "]", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "slot", "==", "'booked'", ":", "\n", "                ", "if", "bstate", "[", "domain", "]", "[", "'book'", "]", "[", "'booked'", "]", ":", "\n", "                    ", "booking", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                    ", "booking", ".", "append", "(", "0", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "bstate", "[", "domain", "]", "[", "'book'", "]", "[", "slot", "]", "!=", "\"\"", ":", "\n", "                    ", "booking", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                    ", "booking", ".", "append", "(", "0", ")", "\n", "", "", "", "if", "domain", "==", "'train'", ":", "\n", "            ", "if", "'people'", "not", "in", "bstate", "[", "domain", "]", "[", "'book'", "]", ".", "keys", "(", ")", ":", "\n", "                ", "booking", ".", "append", "(", "0", ")", "\n", "", "if", "'ticket'", "not", "in", "bstate", "[", "domain", "]", "[", "'book'", "]", ".", "keys", "(", ")", ":", "\n", "                ", "booking", ".", "append", "(", "0", ")", "\n", "", "", "summary_bstate", "+=", "booking", "\n", "\n", "for", "slot", "in", "bstate", "[", "domain", "]", "[", "'semi'", "]", ":", "\n", "            ", "slot_enc", "=", "[", "0", ",", "0", ",", "0", "]", "# not mentioned, dontcare, filled", "\n", "if", "bstate", "[", "domain", "]", "[", "'semi'", "]", "[", "slot", "]", "==", "'not mentioned'", ":", "\n", "                ", "slot_enc", "[", "0", "]", "=", "1", "\n", "", "elif", "bstate", "[", "domain", "]", "[", "'semi'", "]", "[", "slot", "]", "==", "'dont care'", "or", "bstate", "[", "domain", "]", "[", "'semi'", "]", "[", "slot", "]", "==", "'dontcare'", "or", "bstate", "[", "domain", "]", "[", "'semi'", "]", "[", "slot", "]", "==", "\"don't care\"", ":", "\n", "                ", "slot_enc", "[", "1", "]", "=", "1", "\n", "", "elif", "bstate", "[", "domain", "]", "[", "'semi'", "]", "[", "slot", "]", ":", "\n", "                ", "slot_enc", "[", "2", "]", "=", "1", "\n", "", "if", "slot_enc", "!=", "[", "0", ",", "0", ",", "0", "]", ":", "\n", "                ", "domain_active", "=", "True", "\n", "", "summary_bstate", "+=", "slot_enc", "\n", "\n", "# quasi domain-tracker", "\n", "", "if", "domain_active", ":", "\n", "            ", "summary_bstate", "+=", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "summary_bstate", "+=", "[", "0", "]", "\n", "\n", "# print(len(summary_bstate))", "\n", "", "", "assert", "len", "(", "summary_bstate", ")", "==", "94", "\n", "return", "summary_bstate", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_belief_state": [[218, 233], ["[].items", "[].items", "raw_bstate.append", "raw_bstate.append", "utils.multiwoz.nlp.normalize_beliefstate", "utils.multiwoz.nlp.normalize_beliefstate"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_beliefstate", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_beliefstate"], ["", "def", "get_belief_state", "(", "bstate", ")", ":", "\n", "    ", "domains", "=", "[", "u'taxi'", ",", "u'restaurant'", ",", "u'hospital'", ",", "u'hotel'", ",", "u'attraction'", ",", "u'train'", ",", "u'police'", "]", "\n", "raw_bstate", "=", "[", "]", "\n", "for", "domain", "in", "domains", ":", "\n", "        ", "for", "slot", ",", "value", "in", "bstate", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "value", ":", "\n", "                ", "raw_bstate", ".", "append", "(", "(", "domain", ",", "slot", ",", "normalize_beliefstate", "(", "value", ")", ")", ")", "\n", "", "", "for", "slot", ",", "value", "in", "bstate", "[", "domain", "]", "[", "'book'", "]", ".", "items", "(", ")", ":", "\n", "            ", "if", "slot", "==", "'booked'", ":", "\n", "                ", "continue", "\n", "", "if", "value", ":", "\n", "                ", "new_slot", "=", "'{} {}'", ".", "format", "(", "'book'", ",", "slot", ")", "\n", "raw_bstate", ".", "append", "(", "(", "domain", ",", "new_slot", ",", "normalize_beliefstate", "(", "value", ")", ")", ")", "\n", "# ipdb.set_trace()", "\n", "", "", "", "return", "raw_bstate", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.analyze_dialogue": [[235, 274], ["range", "print", "len", "len", "len", "print", "usr_turns.append", "preprocess_multiwoz.get_summary_bstate", "sys_turns.append", "[].split", "print", "preprocess_multiwoz.is_ascii", "print", "preprocess_multiwoz.is_ascii", "print"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_summary_bstate", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.is_ascii", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.is_ascii"], ["", "def", "analyze_dialogue", "(", "dialogue", ",", "maxlen", ")", ":", "\n", "    ", "\"\"\"Cleaning procedure for all kinds of errors in text and annotation.\"\"\"", "\n", "d", "=", "dialogue", "\n", "# do all the necessary postprocessing", "\n", "if", "len", "(", "d", "[", "'log'", "]", ")", "%", "2", "!=", "0", ":", "\n", "# print path", "\n", "        ", "print", "(", "'odd # of turns'", ")", "\n", "return", "None", "# odd number of turns, wrong dialogue", "\n", "", "d_pp", "=", "{", "}", "\n", "d_pp", "[", "'goal'", "]", "=", "d", "[", "'goal'", "]", "# for now we just copy the goal", "\n", "usr_turns", "=", "[", "]", "\n", "sys_turns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "d", "[", "'log'", "]", ")", ")", ":", "\n", "        ", "if", "len", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", ".", "split", "(", ")", ")", ">", "maxlen", ":", "\n", "            ", "print", "(", "'too long'", ")", "\n", "return", "None", "# too long sentence, wrong dialogue", "\n", "", "if", "i", "%", "2", "==", "0", ":", "# usr turn", "\n", "            ", "if", "'db_pointer'", "not", "in", "d", "[", "'log'", "]", "[", "i", "]", ":", "\n", "                ", "print", "(", "'no db'", ")", "\n", "return", "None", "# no db_pointer, probably 2 usr turns in a row, wrong dialogue", "\n", "", "text", "=", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", "\n", "if", "not", "is_ascii", "(", "text", ")", ":", "\n", "                ", "print", "(", "'not ascii'", ")", "\n", "return", "None", "\n", "# d['log'][i]['tkn_text'] = self.tokenize_sentence(text, usr=True)", "\n", "", "usr_turns", ".", "append", "(", "d", "[", "'log'", "]", "[", "i", "]", ")", "\n", "", "else", ":", "# sys turn", "\n", "            ", "text", "=", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", "\n", "if", "not", "is_ascii", "(", "text", ")", ":", "\n", "                ", "print", "(", "'not ascii'", ")", "\n", "return", "None", "\n", "# d['log'][i]['tkn_text'] = self.tokenize_sentence(text, usr=False)", "\n", "", "belief_summary", "=", "get_summary_bstate", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'metadata'", "]", ")", "\n", "d", "[", "'log'", "]", "[", "i", "]", "[", "'belief_summary'", "]", "=", "belief_summary", "\n", "sys_turns", ".", "append", "(", "d", "[", "'log'", "]", "[", "i", "]", ")", "\n", "", "", "d_pp", "[", "'usr_log'", "]", "=", "usr_turns", "\n", "d_pp", "[", "'sys_log'", "]", "=", "sys_turns", "\n", "\n", "return", "d_pp", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.analyze_dialogue_raw_beliefstate": [[276, 318], ["range", "print", "len", "len", "len", "print", "usr_turns.append", "preprocess_multiwoz.get_summary_bstate", "preprocess_multiwoz.get_belief_state", "sys_turns.append", "[].split", "print", "preprocess_multiwoz.is_ascii", "print", "preprocess_multiwoz.is_ascii", "print"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_summary_bstate", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_belief_state", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.is_ascii", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.is_ascii"], ["", "def", "analyze_dialogue_raw_beliefstate", "(", "dialogue", ",", "maxlen", ")", ":", "\n", "    ", "\"\"\"Cleaning procedure for all kinds of errors in text and annotation.\"\"\"", "\n", "d", "=", "dialogue", "\n", "# do all the necessary postprocessing", "\n", "if", "len", "(", "d", "[", "'log'", "]", ")", "%", "2", "!=", "0", ":", "\n", "# print path", "\n", "        ", "print", "(", "'odd # of turns'", ")", "\n", "return", "None", "# odd number of turns, wrong dialogue", "\n", "", "d_pp", "=", "{", "}", "\n", "d_pp", "[", "'goal'", "]", "=", "d", "[", "'goal'", "]", "# for now we just copy the goal", "\n", "usr_turns", "=", "[", "]", "\n", "sys_turns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "d", "[", "'log'", "]", ")", ")", ":", "\n", "        ", "if", "len", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", ".", "split", "(", ")", ")", ">", "maxlen", ":", "\n", "            ", "print", "(", "'too long'", ")", "\n", "return", "None", "# too long sentence, wrong dialogue", "\n", "", "if", "i", "%", "2", "==", "0", ":", "# usr turn", "\n", "            ", "if", "'db_pointer'", "not", "in", "d", "[", "'log'", "]", "[", "i", "]", ":", "\n", "                ", "print", "(", "'no db'", ")", "\n", "return", "None", "# no db_pointer, probably 2 usr turns in a row, wrong dialogue", "\n", "", "text", "=", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", "\n", "if", "not", "is_ascii", "(", "text", ")", ":", "\n", "                ", "print", "(", "'not ascii'", ")", "\n", "return", "None", "\n", "# d['log'][i]['tkn_text'] = self.tokenize_sentence(text, usr=True)", "\n", "", "usr_turns", ".", "append", "(", "d", "[", "'log'", "]", "[", "i", "]", ")", "\n", "", "else", ":", "# sys turn", "\n", "            ", "text", "=", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", "\n", "if", "not", "is_ascii", "(", "text", ")", ":", "\n", "                ", "print", "(", "'not ascii'", ")", "\n", "return", "None", "\n", "# d['log'][i]['tkn_text'] = self.tokenize_sentence(text, usr=False)", "\n", "", "belief_summary", "=", "get_summary_bstate", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'metadata'", "]", ")", "\n", "d", "[", "'log'", "]", "[", "i", "]", "[", "'belief_summary'", "]", "=", "belief_summary", "\n", "# get raw belief state", "\n", "belief_state", "=", "get_belief_state", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'metadata'", "]", ")", "\n", "d", "[", "'log'", "]", "[", "i", "]", "[", "'belief_state'", "]", "=", "belief_state", "\n", "sys_turns", ".", "append", "(", "d", "[", "'log'", "]", "[", "i", "]", ")", "\n", "", "", "d_pp", "[", "'usr_log'", "]", "=", "usr_turns", "\n", "d_pp", "[", "'sys_log'", "]", "=", "sys_turns", "\n", "\n", "return", "d_pp", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.analyze_dialogue_raw_beliefstate_v2": [[320, 362], ["range", "print", "len", "len", "len", "print", "usr_turns.append", "preprocess_multiwoz.get_summary_bstate", "preprocess_multiwoz.get_belief_state", "sys_turns.append", "[].split", "print", "preprocess_multiwoz.is_ascii", "print", "preprocess_multiwoz.is_ascii", "print"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_summary_bstate", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_belief_state", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.is_ascii", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.is_ascii"], ["", "def", "analyze_dialogue_raw_beliefstate_v2", "(", "dialogue", ",", "maxlen", ")", ":", "\n", "    ", "\"\"\"Cleaning procedure for all kinds of errors in text and annotation.\"\"\"", "\n", "d", "=", "dialogue", "\n", "# do all the necessary postprocessing", "\n", "if", "len", "(", "d", "[", "'log'", "]", ")", "%", "2", "!=", "0", ":", "\n", "# print path", "\n", "        ", "print", "(", "'odd # of turns'", ")", "\n", "return", "None", "# odd number of turns, wrong dialogue", "\n", "", "d_pp", "=", "{", "}", "\n", "d_pp", "[", "'goal'", "]", "=", "d", "[", "'goal'", "]", "# for now we just copy the goal", "\n", "usr_turns", "=", "[", "]", "\n", "sys_turns", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "d", "[", "'log'", "]", ")", ")", ":", "\n", "        ", "if", "len", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", ".", "split", "(", ")", ")", ">", "maxlen", ":", "\n", "            ", "print", "(", "'too long'", ")", "\n", "return", "None", "# too long sentence, wrong dialogue", "\n", "", "if", "i", "%", "2", "==", "0", ":", "# usr turn", "\n", "            ", "if", "'db_pointer'", "not", "in", "d", "[", "'log'", "]", "[", "i", "]", ":", "\n", "                ", "print", "(", "'no db'", ")", "\n", "return", "None", "# no db_pointer, probably 2 usr turns in a row, wrong dialogue", "\n", "", "text", "=", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", "\n", "if", "not", "is_ascii", "(", "text", ")", ":", "\n", "                ", "print", "(", "'not ascii'", ")", "\n", "return", "None", "\n", "# d['log'][i]['tkn_text'] = self.tokenize_sentence(text, usr=True)", "\n", "", "usr_turns", ".", "append", "(", "d", "[", "'log'", "]", "[", "i", "]", ")", "\n", "", "else", ":", "# sys turn", "\n", "            ", "text", "=", "d", "[", "'log'", "]", "[", "i", "]", "[", "'text'", "]", "\n", "if", "not", "is_ascii", "(", "text", ")", ":", "\n", "                ", "print", "(", "'not ascii'", ")", "\n", "return", "None", "\n", "# d['log'][i]['tkn_text'] = self.tokenize_sentence(text, usr=False)", "\n", "", "belief_summary", "=", "get_summary_bstate", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'metadata'", "]", ")", "\n", "d", "[", "'log'", "]", "[", "i", "]", "[", "'belief_summary'", "]", "=", "belief_summary", "\n", "# get raw belief state", "\n", "belief_state", "=", "get_belief_state", "(", "d", "[", "'log'", "]", "[", "i", "]", "[", "'metadata'", "]", ")", "\n", "d", "[", "'log'", "]", "[", "i", "]", "[", "'belief_state'", "]", "=", "belief_state", "\n", "sys_turns", ".", "append", "(", "d", "[", "'log'", "]", "[", "i", "]", ")", "\n", "", "", "d_pp", "[", "'usr_log'", "]", "=", "usr_turns", "\n", "d_pp", "[", "'sys_log'", "]", "=", "sys_turns", "\n", "\n", "return", "d_pp", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_dial": [[364, 379], ["preprocess_multiwoz.analyze_dialogue_raw_beliefstate", "zip", "dial.append"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.analyze_dialogue_raw_beliefstate"], ["", "def", "get_dial", "(", "dialogue", ")", ":", "\n", "    ", "\"\"\"Extract a dialogue from the file\"\"\"", "\n", "dial", "=", "[", "]", "\n", "# d_orig = analyze_dialogue(dialogue, MAX_LENGTH)  # max turn len is 50 words", "\n", "d_orig", "=", "analyze_dialogue_raw_beliefstate", "(", "dialogue", ",", "MAX_LENGTH", ")", "# max turn len is 50 words", "\n", "if", "d_orig", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "usr", "=", "[", "t", "[", "'text'", "]", "for", "t", "in", "d_orig", "[", "'usr_log'", "]", "]", "\n", "db", "=", "[", "t", "[", "'db_pointer'", "]", "for", "t", "in", "d_orig", "[", "'usr_log'", "]", "]", "\n", "bs", "=", "[", "t", "[", "'belief_summary'", "]", "for", "t", "in", "d_orig", "[", "'sys_log'", "]", "]", "\n", "sys", "=", "[", "t", "[", "'text'", "]", "for", "t", "in", "d_orig", "[", "'sys_log'", "]", "]", "\n", "for", "u", ",", "d", ",", "s", ",", "b", "in", "zip", "(", "usr", ",", "db", ",", "sys", ",", "bs", ")", ":", "\n", "        ", "dial", ".", "append", "(", "(", "u", ",", "s", ",", "d", ",", "b", ")", ")", "\n", "\n", "", "return", "dial", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_dial_raw_bstate": [[381, 396], ["preprocess_multiwoz.analyze_dialogue_raw_beliefstate", "zip", "dial.append"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.analyze_dialogue_raw_beliefstate"], ["", "def", "get_dial_raw_bstate", "(", "dialogue", ")", ":", "\n", "    ", "\"\"\"Extract a dialogue from the file\"\"\"", "\n", "dial", "=", "[", "]", "\n", "d_orig", "=", "analyze_dialogue_raw_beliefstate", "(", "dialogue", ",", "MAX_LENGTH", ")", "# max turn len is 50 words", "\n", "if", "d_orig", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "usr", "=", "[", "t", "[", "'text'", "]", "for", "t", "in", "d_orig", "[", "'usr_log'", "]", "]", "\n", "db", "=", "[", "t", "[", "'db_pointer'", "]", "for", "t", "in", "d_orig", "[", "'usr_log'", "]", "]", "\n", "bs", "=", "[", "t", "[", "'belief_summary'", "]", "for", "t", "in", "d_orig", "[", "'sys_log'", "]", "]", "\n", "belief_state", "=", "[", "t", "[", "'belief_state'", "]", "for", "t", "in", "d_orig", "[", "'sys_log'", "]", "]", "\n", "sys", "=", "[", "t", "[", "'text'", "]", "for", "t", "in", "d_orig", "[", "'sys_log'", "]", "]", "\n", "for", "u", ",", "d", ",", "s", ",", "b", ",", "bstate", "in", "zip", "(", "usr", ",", "db", ",", "sys", ",", "bs", ",", "belief_state", ")", ":", "\n", "        ", "dial", ".", "append", "(", "(", "u", ",", "s", ",", "d", ",", "b", ",", "bstate", ")", ")", "\n", "\n", "", "return", "dial", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createDict": [[398, 432], ["numpy.argsort", "collections.OrderedDict", "enumerate", "enumerate", "collections.OrderedDict.copy", "collections.OrderedDict.items", "word_freqs.keys", "word_freqs.values"], "function", ["None"], ["", "def", "createDict", "(", "word_freqs", ")", ":", "\n", "    ", "words", "=", "[", "k", "for", "k", "in", "word_freqs", ".", "keys", "(", ")", "]", "\n", "freqs", "=", "[", "v", "for", "v", "in", "word_freqs", ".", "values", "(", ")", "]", "\n", "\n", "sorted_idx", "=", "np", ".", "argsort", "(", "freqs", ")", "\n", "sorted_words", "=", "[", "words", "[", "ii", "]", "for", "ii", "in", "sorted_idx", "[", ":", ":", "-", "1", "]", "]", "\n", "\n", "# Extra vocabulary symbols", "\n", "_GO", "=", "'_GO'", "\n", "EOS", "=", "'_EOS'", "\n", "UNK", "=", "'_UNK'", "\n", "PAD", "=", "'_PAD'", "\n", "SEP0", "=", "'_SEP0'", "\n", "SEP1", "=", "'_SEP1'", "\n", "SEP2", "=", "'_SEP2'", "\n", "SEP3", "=", "'_SEP3'", "\n", "SEP4", "=", "'_SEP4'", "\n", "SEP5", "=", "'_SEP5'", "\n", "SEP6", "=", "'_SEP6'", "\n", "SEP7", "=", "'_SEP7'", "\n", "extra_tokens", "=", "[", "_GO", ",", "EOS", ",", "UNK", ",", "PAD", ",", "SEP0", ",", "SEP1", ",", "SEP2", ",", "SEP3", ",", "SEP4", ",", "SEP5", ",", "SEP6", ",", "SEP7", "]", "\n", "# extra_tokens = [_GO, EOS, UNK, PAD]", "\n", "\n", "worddict", "=", "OrderedDict", "(", ")", "\n", "for", "ii", ",", "ww", "in", "enumerate", "(", "extra_tokens", ")", ":", "\n", "        ", "worddict", "[", "ww", "]", "=", "ii", "\n", "", "for", "ii", ",", "ww", "in", "enumerate", "(", "sorted_words", ")", ":", "\n", "        ", "worddict", "[", "ww", "]", "=", "ii", "#+ len(extra_tokens)", "\n", "\n", "", "new_worddict", "=", "worddict", ".", "copy", "(", ")", "\n", "for", "key", ",", "idx", "in", "worddict", ".", "items", "(", ")", ":", "\n", "        ", "if", "idx", ">=", "DICT_SIZE", ":", "\n", "            ", "del", "new_worddict", "[", "key", "]", "\n", "", "", "return", "new_worddict", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.moveFiles": [[434, 440], ["shutil.copy", "shutil.copy", "shutil.copy", "shutil.copy", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "moveFiles", "(", "src_path", ",", "dst_path", ")", ":", "\n", "    ", "shutil", ".", "copy", "(", "os", ".", "path", ".", "join", "(", "src_path", ",", "'data.json'", ")", ",", "dst_path", ")", "\n", "shutil", ".", "copy", "(", "os", ".", "path", ".", "join", "(", "src_path", ",", "'valListFile.json'", ")", ",", "dst_path", ")", "\n", "shutil", ".", "copy", "(", "os", ".", "path", ".", "join", "(", "src_path", ",", "'testListFile.json'", ")", ",", "dst_path", ")", "\n", "shutil", ".", "copy", "(", "os", ".", "path", ".", "join", "(", "src_path", ",", "'dialogue_acts.json'", ")", ",", "dst_path", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createDelexData": [[442, 504], ["preprocess_multiwoz.loadDataMultiWoz", "utils.multiwoz.delexicalize.prepareSlotValuesIndependent", "open", "json.load", "open", "json.load", "tqdm.tqdm", "os.path.join", "os.path.join", "enumerate", "open", "json.dump", "utils.multiwoz.nlp.normalize", "re.sub.split", "utils.multiwoz.delexicalize.delexicalise", "preprocess_multiwoz.delexicaliseReferenceNumber", "re.compile", "re.sub", "preprocess_multiwoz.fixDelex", "os.path.join", "preprocess_multiwoz.addDBPointer", "preprocess_multiwoz.addBookingPointer", "addBookingPointer.tolist"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.loadDataMultiWoz", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.prepareSlotValuesIndependent", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.delexicalise", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.delexicaliseReferenceNumber", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.fixDelex", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addDBPointer", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addBookingPointer"], ["", "def", "createDelexData", "(", ")", ":", "\n", "    ", "\"\"\"Main function of the script - loads delexical dictionary,\n    goes through each dialogue and does:\n    1) data normalization\n    2) delexicalization\n    3) addition of database pointer\n    4) saves the delexicalized data\n    \"\"\"", "\n", "# download the data", "\n", "loadDataMultiWoz", "(", ")", "\n", "\n", "# create dictionary of delexicalied values that then we will search against, order matters here!", "\n", "dic", "=", "delexicalize", ".", "prepareSlotValuesIndependent", "(", ")", "\n", "delex_data", "=", "{", "}", "\n", "\n", "fin1", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/data.json'", ")", ")", "\n", "data", "=", "json", ".", "load", "(", "fin1", ")", "\n", "\n", "fin2", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/dialogue_acts.json'", ")", ")", "\n", "data2", "=", "json", ".", "load", "(", "fin2", ")", "\n", "\n", "for", "dialogue_name", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "dialogue", "=", "data", "[", "dialogue_name", "]", "\n", "# print dialogue_name", "\n", "\n", "idx_acts", "=", "1", "\n", "for", "idx", ",", "turn", "in", "enumerate", "(", "dialogue", "[", "'log'", "]", ")", ":", "\n", "# normalization, split and delexicalization of the sentence", "\n", "            ", "sent", "=", "normalize", "(", "turn", "[", "'text'", "]", ")", "\n", "\n", "words", "=", "sent", ".", "split", "(", ")", "\n", "sent", "=", "delexicalize", ".", "delexicalise", "(", "' '", ".", "join", "(", "words", ")", ",", "dic", ")", "\n", "\n", "# parsing reference number GIVEN belief state", "\n", "sent", "=", "delexicaliseReferenceNumber", "(", "sent", ",", "turn", ")", "\n", "\n", "# changes to numbers only here", "\n", "digitpat", "=", "re", ".", "compile", "(", "'\\d+'", ")", "\n", "sent", "=", "re", ".", "sub", "(", "digitpat", ",", "'[value_count]'", ",", "sent", ")", "\n", "\n", "# delexicalized sentence added to the dialogue", "\n", "dialogue", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "sent", "\n", "\n", "if", "idx", "%", "2", "==", "1", ":", "# if it's a system turn", "\n", "# add database pointer", "\n", "                ", "pointer_vector", "=", "addDBPointer", "(", "turn", ")", "\n", "# add booking pointer", "\n", "pointer_vector", "=", "addBookingPointer", "(", "dialogue", ",", "turn", ",", "pointer_vector", ")", "\n", "\n", "# print pointer_vector", "\n", "dialogue", "[", "'log'", "]", "[", "idx", "-", "1", "]", "[", "'db_pointer'", "]", "=", "pointer_vector", ".", "tolist", "(", ")", "\n", "\n", "# FIXING delexicalization:", "\n", "", "dialogue", "=", "fixDelex", "(", "dialogue_name", ",", "dialogue", ",", "data2", ",", "idx", ",", "idx_acts", ")", "\n", "idx_acts", "+=", "1", "\n", "\n", "", "delex_data", "[", "dialogue_name", "]", "=", "dialogue", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/delex.json'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "delex_data", ",", "outfile", ")", "\n", "\n", "", "return", "delex_data", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.loadDataMultiWoz": [[506, 522], ["os.path.join", "os.path.join", "os.path.join", "os.makedirs", "os.path.exists", "print", "urllib.request.urlopen", "zipfile.ZipFile", "zipfile.ZipFile.extractall", "zipfile.ZipFile.close", "preprocess_multiwoz.moveFiles", "io.BytesIO", "urllib.request.urlopen.read"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.moveFiles"], ["", "def", "loadDataMultiWoz", "(", ")", ":", "\n", "    ", "data_url", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz-2.1/data.json'", ")", "\n", "dataset_url", "=", "\"https://www.repository.cam.ac.uk/bitstream/handle/1810/294507/MULTIWOZ2.1.zip?sequence=1&isAllowed=y\"", "\n", "download_path", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz'", ")", "\n", "extract_path", "=", "os", ".", "path", ".", "join", "(", "download_path", ",", "'MULTIWOZ2.1'", ")", "\n", "os", ".", "makedirs", "(", "download_path", ",", "exist_ok", "=", "True", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "data_url", ")", ":", "\n", "        ", "print", "(", "\"Downloading and unzipping the MultiWOZ dataset\"", ")", "\n", "resp", "=", "urllib", ".", "request", ".", "urlopen", "(", "dataset_url", ")", "\n", "zip_ref", "=", "ZipFile", "(", "BytesIO", "(", "resp", ".", "read", "(", ")", ")", ")", "\n", "zip_ref", ".", "extractall", "(", "download_path", ")", "\n", "zip_ref", ".", "close", "(", ")", "\n", "\n", "moveFiles", "(", "src_path", "=", "extract_path", ",", "dst_path", "=", "download_path", ")", "\n", "return", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createDelexData_mine": [[524, 588], ["preprocess_multiwoz.loadDataMultiWoz", "utils.multiwoz.delexicalize.prepareSlotValuesIndependent_mine", "open", "json.load", "open", "json.load", "tqdm.tqdm", "os.path.join", "os.path.join", "enumerate", "open", "json.dump", "utils.multiwoz.nlp.normalize_mine", "preprocess_multiwoz.delexicaliseReferenceNumber_mine", "re.compile", "preprocess_multiwoz.fixDelex", "os.path.join", "delexicalize.delexicalise.split", "utils.multiwoz.delexicalize.delexicalise", "preprocess_multiwoz.addDBPointer", "preprocess_multiwoz.addBookingPointer", "addBookingPointer.tolist"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.loadDataMultiWoz", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.prepareSlotValuesIndependent_mine", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_mine", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.delexicaliseReferenceNumber_mine", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.fixDelex", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.delexicalise", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addDBPointer", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addBookingPointer"], ["", "", "def", "createDelexData_mine", "(", ")", ":", "\n", "    ", "\"\"\"Main function of the script - loads delexical dictionary,\n    goes through each dialogue and does:\n    1) data normalization\n    2) delexicalization\n    3) addition of database pointer\n    4) saves the delexicalized data\n    \"\"\"", "\n", "# download the data", "\n", "loadDataMultiWoz", "(", ")", "\n", "\n", "# create dictionary of delexicalied values that then we will search against, order matters here!", "\n", "dic", "=", "delexicalize", ".", "prepareSlotValuesIndependent_mine", "(", ")", "\n", "delex_data", "=", "{", "}", "\n", "\n", "fin1", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/data.json'", ")", ")", "\n", "data", "=", "json", ".", "load", "(", "fin1", ")", "\n", "\n", "fin2", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/dialogue_acts.json'", ")", ")", "\n", "data2", "=", "json", ".", "load", "(", "fin2", ")", "\n", "\n", "for", "dialogue_name", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "dialogue", "=", "data", "[", "dialogue_name", "]", "\n", "# print dialogue_name", "\n", "\n", "idx_acts", "=", "1", "\n", "for", "idx", ",", "turn", "in", "enumerate", "(", "dialogue", "[", "'log'", "]", ")", ":", "\n", "# normalization, split and delexicalization of the sentence", "\n", "            ", "sent", "=", "normalize_mine", "(", "turn", "[", "'text'", "]", ")", "\n", "\n", "# only delexicalize system response", "\n", "if", "idx", "%", "2", "==", "1", ":", "\n", "                ", "words", "=", "sent", ".", "split", "(", ")", "\n", "sent", "=", "delexicalize", ".", "delexicalise", "(", "' '", ".", "join", "(", "words", ")", ",", "dic", ")", "\n", "\n", "# parsing reference number GIVEN belief state", "\n", "", "sent", "=", "delexicaliseReferenceNumber_mine", "(", "sent", ",", "turn", ")", "\n", "\n", "# changes to numbers only here", "\n", "digitpat", "=", "re", ".", "compile", "(", "'\\d+'", ")", "\n", "# sent = re.sub(digitpat, '[value_count]', sent)", "\n", "\n", "# delexicalized sentence added to the dialogue", "\n", "dialogue", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "sent", "\n", "\n", "if", "idx", "%", "2", "==", "1", ":", "# if it's a system turn", "\n", "# add database pointer", "\n", "                ", "pointer_vector", "=", "addDBPointer", "(", "turn", ")", "\n", "# add booking pointer", "\n", "pointer_vector", "=", "addBookingPointer", "(", "dialogue", ",", "turn", ",", "pointer_vector", ")", "\n", "\n", "# print pointer_vector", "\n", "dialogue", "[", "'log'", "]", "[", "idx", "-", "1", "]", "[", "'db_pointer'", "]", "=", "pointer_vector", ".", "tolist", "(", ")", "\n", "\n", "# FIXING delexicalization:", "\n", "", "dialogue", "=", "fixDelex", "(", "dialogue_name", ",", "dialogue", ",", "data2", ",", "idx", ",", "idx_acts", ")", "\n", "idx_acts", "+=", "1", "\n", "\n", "", "delex_data", "[", "dialogue_name", "]", "=", "dialogue", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/delex_mine.json'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "delex_data", ",", "outfile", ")", "\n", "\n", "", "return", "delex_data", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createLexicalData": [[590, 653], ["preprocess_multiwoz.loadDataMultiWoz", "open", "json.load", "open", "json.load", "tqdm.tqdm", "os.path.join", "os.path.join", "enumerate", "open", "json.dump", "utils.multiwoz.nlp.normalize_lexical", "os.path.join", "preprocess_multiwoz.addDBPointer", "preprocess_multiwoz.addBookingPointer", "addBookingPointer.tolist"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.loadDataMultiWoz", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_lexical", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addDBPointer", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.addBookingPointer"], ["", "def", "createLexicalData", "(", ")", ":", "\n", "    ", "\"\"\"Main function of the script - loads delexical dictionary,\n    goes through each dialogue and does:\n    1) data normalization\n    2) delexicalization\n    3) addition of database pointer\n    4) saves the delexicalized data\n    \"\"\"", "\n", "# download the data", "\n", "loadDataMultiWoz", "(", ")", "\n", "\n", "# create dictionary of delexicalied values that then we will search against, order matters here!", "\n", "# dic = delexicalize.prepareSlotValuesIndependent()", "\n", "delex_data", "=", "{", "}", "\n", "\n", "fin1", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/data.json'", ")", ")", "\n", "data", "=", "json", ".", "load", "(", "fin1", ")", "\n", "\n", "fin2", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/dialogue_acts.json'", ")", ")", "\n", "data2", "=", "json", ".", "load", "(", "fin2", ")", "\n", "\n", "for", "dialogue_name", "in", "tqdm", "(", "data", ")", ":", "\n", "        ", "dialogue", "=", "data", "[", "dialogue_name", "]", "\n", "# print dialogue_name", "\n", "\n", "idx_acts", "=", "1", "\n", "for", "idx", ",", "turn", "in", "enumerate", "(", "dialogue", "[", "'log'", "]", ")", ":", "\n", "# normalization, split and delexicalization of the sentence", "\n", "            ", "sent", "=", "normalize_lexical", "(", "turn", "[", "'text'", "]", ")", "\n", "\n", "# words = sent.split()", "\n", "# sent = delexicalize.delexicalise(' '.join(words), dic)", "\n", "\n", "# parsing reference number GIVEN belief state", "\n", "# sent = delexicaliseReferenceNumber(sent, turn)", "\n", "\n", "# changes to numbers only here", "\n", "# digitpat = re.compile('\\d+')", "\n", "# sent = re.sub(digitpat, '[value_count]', sent)", "\n", "\n", "# delexicalized sentence added to the dialogue", "\n", "dialogue", "[", "'log'", "]", "[", "idx", "]", "[", "'text'", "]", "=", "sent", "\n", "\n", "if", "idx", "%", "2", "==", "1", ":", "# if it's a system turn", "\n", "# add database pointer", "\n", "                ", "pointer_vector", "=", "addDBPointer", "(", "turn", ")", "\n", "# add booking pointer", "\n", "pointer_vector", "=", "addBookingPointer", "(", "dialogue", ",", "turn", ",", "pointer_vector", ")", "\n", "\n", "# print pointer_vector", "\n", "dialogue", "[", "'log'", "]", "[", "idx", "-", "1", "]", "[", "'db_pointer'", "]", "=", "pointer_vector", ".", "tolist", "(", ")", "\n", "\n", "# FIXING delexicalization:", "\n", "# dialogue = fixDelex(dialogue_name, dialogue, data2, idx, idx_acts)", "\n", "", "idx_acts", "+=", "1", "\n", "\n", "# ipdb.set_trace()", "\n", "", "delex_data", "[", "dialogue_name", "]", "=", "dialogue", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/lex.json'", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "json", ".", "dump", "(", "delex_data", ",", "outfile", ")", "\n", "\n", "", "return", "delex_data", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_action": [[655, 688], ["str", "isinstance", "turn_action.items", "w.lower", "dial_name.split", "k.split", "slot.lower().strip().split", "value.lower().strip().split", "concat.append", "dial_name.split", "[].append", "slot.lower().strip", "value.lower().strip", "slot.lower", "value.lower"], "function", ["None"], ["", "def", "get_action", "(", "actions", ",", "dial_name", ",", "turn_id", ")", ":", "\n", "    ", "turn_id", "=", "str", "(", "turn_id", ")", "\n", "if", "turn_id", "in", "actions", "[", "dial_name", ".", "split", "(", "'.'", ")", "[", "0", "]", "]", ":", "\n", "        ", "turn_action", "=", "actions", "[", "dial_name", ".", "split", "(", "'.'", ")", "[", "0", "]", "]", "[", "turn_id", "]", "\n", "if", "isinstance", "(", "turn_action", ",", "str", ")", ":", "\n", "            ", "return", "turn_action", ",", "[", "]", "\n", "", "acts", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "turn_action", ".", "items", "(", ")", ":", "\n", "            ", "domain", ",", "act", "=", "[", "w", ".", "lower", "(", ")", "for", "w", "in", "k", ".", "split", "(", "'-'", ")", "]", "\n", "for", "(", "slot", ",", "value", ")", "in", "v", ":", "\n", "                ", "slot", "=", "' '", ".", "join", "(", "slot", ".", "lower", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", ")", "\n", "value", "=", "' '", ".", "join", "(", "value", ".", "lower", "(", ")", ".", "strip", "(", ")", ".", "split", "(", "'\\t'", ")", ")", "\n", "# concat.extend(['_SEP1', v1, '_SEP2', v2])", "\n", "if", "domain", "in", "acts", "and", "act", "in", "acts", "[", "domain", "]", "and", "slot", "in", "acts", "[", "domain", "]", "[", "act", "]", ":", "# already domain-act is considered, skip", "\n", "                    ", "continue", "\n", "", "if", "domain", "not", "in", "acts", ":", "\n", "                    ", "acts", "[", "domain", "]", "=", "{", "}", "\n", "acts", "[", "domain", "]", "[", "act", "]", "=", "{", "}", "\n", "acts", "[", "domain", "]", "[", "act", "]", "=", "[", "(", "slot", ",", "value", ")", "]", "\n", "", "elif", "act", "not", "in", "acts", "[", "domain", "]", ":", "\n", "                    ", "acts", "[", "domain", "]", "[", "act", "]", "=", "{", "}", "\n", "acts", "[", "domain", "]", "[", "act", "]", "=", "[", "(", "slot", ",", "value", ")", "]", "\n", "", "else", ":", "\n", "                    ", "acts", "[", "domain", "]", "[", "act", "]", ".", "append", "(", "(", "slot", ",", "value", ")", ")", "\n", "\n", "", "", "", "concat", "=", "[", "]", "\n", "for", "domain", "in", "acts", ":", "\n", "            ", "for", "act", "in", "acts", "[", "domain", "]", ":", "\n", "                ", "for", "slot", ",", "value", "in", "acts", "[", "domain", "]", "[", "act", "]", ":", "\n", "                    ", "concat", ".", "append", "(", "(", "domain", ",", "act", ",", "slot", ")", ")", "\n", "", "", "", "return", "turn_action", ",", "concat", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", ",", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.divideData": [[690, 831], ["open", "open.close", "open", "open.close", "open", "json.load", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "collections.OrderedDict", "tqdm.tqdm", "os.path.join", "testListFile.append", "os.path.join", "valListFile.append", "os.path.join", "open", "preprocess_multiwoz.get_dial_raw_bstate", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "json.dump", "open", "json.dump", "open", "json.dump", "enumerate", "dialogue[].append", "dialogue[].append", "dialogue[].append", "dialogue[].append", "dialogue[].append", "preprocess_multiwoz.get_action", "dialogue[].append", "dialogue[].append", "line.strip().split", "line.strip().split", "open.write", "act_words.extend", "belief_words.extend", "belief_words.extend", "line.strip", "line.strip", "utils.multiwoz.nlp.normalize_beliefstate().strip().split", "utils.multiwoz.nlp.normalize_beliefstate().strip", "utils.multiwoz.nlp.normalize_beliefstate"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.get_dial_raw_bstate", "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_action", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_beliefstate"], ["", "", "def", "divideData", "(", "data", ",", "lexicalize", "=", "False", ")", ":", "\n", "    ", "\"\"\"Given test and validation sets, divide\n    the data for three different sets\"\"\"", "\n", "# ipdb.set_trace()", "\n", "testListFile", "=", "[", "]", "\n", "fin", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/testListFile.json'", ")", ")", "\n", "for", "line", "in", "fin", ":", "\n", "        ", "testListFile", ".", "append", "(", "line", "[", ":", "-", "1", "]", ")", "\n", "", "fin", ".", "close", "(", ")", "\n", "\n", "valListFile", "=", "[", "]", "\n", "fin", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/valListFile.json'", ")", ")", "\n", "for", "line", "in", "fin", ":", "\n", "        ", "valListFile", ".", "append", "(", "line", "[", ":", "-", "1", "]", ")", "\n", "", "fin", ".", "close", "(", ")", "\n", "\n", "trainListFile", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/trainListFile'", ")", ",", "'w'", ")", "\n", "\n", "actions", "=", "json", ".", "load", "(", "open", "(", "'resources/multi-woz/dialogue_acts.json'", ",", "'r'", ")", ")", "\n", "test_dials", "=", "{", "}", "\n", "val_dials", "=", "{", "}", "\n", "train_dials", "=", "{", "}", "\n", "\n", "# dictionaries", "\n", "word_freqs_usr", "=", "OrderedDict", "(", ")", "\n", "word_freqs_sys", "=", "OrderedDict", "(", ")", "\n", "word_freqs_history", "=", "OrderedDict", "(", ")", "\n", "word_freqs_action", "=", "OrderedDict", "(", ")", "\n", "word_freqs_belief", "=", "OrderedDict", "(", ")", "\n", "\n", "for", "dialogue_name", "in", "tqdm", "(", "data", ")", ":", "\n", "\n", "        ", "dial", "=", "get_dial_raw_bstate", "(", "data", "[", "dialogue_name", "]", ")", "\n", "\n", "if", "dial", ":", "\n", "            ", "dialogue", "=", "{", "}", "\n", "dialogue", "[", "'usr'", "]", "=", "[", "]", "\n", "dialogue", "[", "'sys'", "]", "=", "[", "]", "\n", "dialogue", "[", "'db'", "]", "=", "[", "]", "\n", "dialogue", "[", "'bs'", "]", "=", "[", "]", "\n", "dialogue", "[", "'bstate'", "]", "=", "[", "]", "\n", "dialogue", "[", "'sys_act_raw'", "]", "=", "[", "]", "\n", "dialogue", "[", "'sys_act'", "]", "=", "[", "]", "\n", "for", "turn_id", ",", "turn", "in", "enumerate", "(", "dial", ")", ":", "\n", "                ", "dialogue", "[", "'usr'", "]", ".", "append", "(", "turn", "[", "0", "]", ")", "\n", "dialogue", "[", "'sys'", "]", ".", "append", "(", "turn", "[", "1", "]", ")", "\n", "dialogue", "[", "'db'", "]", ".", "append", "(", "turn", "[", "2", "]", ")", "\n", "dialogue", "[", "'bs'", "]", ".", "append", "(", "turn", "[", "3", "]", ")", "\n", "dialogue", "[", "'bstate'", "]", ".", "append", "(", "turn", "[", "4", "]", ")", "\n", "\n", "turn_act_raw", ",", "turn_act", "=", "get_action", "(", "actions", ",", "dialogue_name", ",", "turn_id", "+", "1", ")", "\n", "# ipdb.set_trace()", "\n", "dialogue", "[", "'sys_act_raw'", "]", ".", "append", "(", "turn_act_raw", ")", "\n", "dialogue", "[", "'sys_act'", "]", ".", "append", "(", "turn_act", ")", "\n", "\n", "", "if", "dialogue_name", "in", "testListFile", ":", "\n", "                ", "test_dials", "[", "dialogue_name", "]", "=", "dialogue", "\n", "", "elif", "dialogue_name", "in", "valListFile", ":", "\n", "                ", "val_dials", "[", "dialogue_name", "]", "=", "dialogue", "\n", "", "else", ":", "\n", "                ", "trainListFile", ".", "write", "(", "dialogue_name", "+", "'\\n'", ")", "\n", "train_dials", "[", "dialogue_name", "]", "=", "dialogue", "\n", "\n", "", "for", "turn", "in", "dial", ":", "\n", "                ", "line", "=", "turn", "[", "0", "]", "\n", "words_in", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "for", "w", "in", "words_in", ":", "\n", "                    ", "if", "w", "not", "in", "word_freqs_usr", ":", "\n", "                        ", "word_freqs_usr", "[", "w", "]", "=", "0", "\n", "", "word_freqs_usr", "[", "w", "]", "+=", "1", "\n", "\n", "# dialogue history vocab", "\n", "", "for", "w", "in", "words_in", ":", "\n", "                    ", "if", "w", "not", "in", "word_freqs_history", ":", "\n", "                        ", "word_freqs_history", "[", "w", "]", "=", "0", "\n", "", "word_freqs_history", "[", "w", "]", "+=", "1", "\n", "\n", "", "line", "=", "turn", "[", "1", "]", "\n", "words_in", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "\n", "for", "w", "in", "words_in", ":", "\n", "                    ", "if", "w", "not", "in", "word_freqs_sys", ":", "\n", "                        ", "word_freqs_sys", "[", "w", "]", "=", "0", "\n", "", "word_freqs_sys", "[", "w", "]", "+=", "1", "\n", "\n", "# dialogue history vocab", "\n", "", "for", "w", "in", "words_in", ":", "\n", "                    ", "if", "w", "not", "in", "word_freqs_history", ":", "\n", "                        ", "word_freqs_history", "[", "w", "]", "=", "0", "\n", "", "word_freqs_history", "[", "w", "]", "+=", "1", "\n", "\n", "", "", "act_words", "=", "[", "]", "\n", "for", "dial_act", "in", "dialogue", "[", "'sys_act'", "]", ":", "\n", "                ", "for", "domain", ",", "act", ",", "slot", "in", "dial_act", ":", "\n", "                    ", "act_words", ".", "extend", "(", "[", "domain", ",", "act", ",", "slot", "]", ")", "\n", "", "", "for", "w", "in", "act_words", ":", "\n", "                ", "if", "w", "not", "in", "word_freqs_sys", ":", "\n", "                    ", "word_freqs_sys", "[", "w", "]", "=", "0", "\n", "", "word_freqs_sys", "[", "w", "]", "+=", "1", "\n", "if", "w", "not", "in", "word_freqs_history", ":", "\n", "                    ", "word_freqs_history", "[", "w", "]", "=", "0", "\n", "", "word_freqs_history", "[", "w", "]", "+=", "1", "\n", "if", "w", "not", "in", "word_freqs_action", ":", "\n", "                    ", "word_freqs_action", "[", "w", "]", "=", "0", "\n", "", "word_freqs_action", "[", "w", "]", "+=", "1", "\n", "\n", "", "belief_words", "=", "[", "]", "\n", "for", "dial_bstate", "in", "dialogue", "[", "'bstate'", "]", ":", "\n", "                ", "for", "domain", ",", "slot", ",", "value", "in", "dial_bstate", ":", "\n", "                    ", "belief_words", ".", "extend", "(", "[", "domain", ",", "slot", "]", ")", "\n", "belief_words", ".", "extend", "(", "normalize_beliefstate", "(", "value", ")", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", ")", "\n", "", "", "for", "w", "in", "belief_words", ":", "\n", "                ", "if", "w", "not", "in", "word_freqs_sys", ":", "\n", "                    ", "word_freqs_sys", "[", "w", "]", "=", "0", "\n", "", "word_freqs_sys", "[", "w", "]", "+=", "1", "\n", "if", "w", "not", "in", "word_freqs_history", ":", "\n", "                    ", "word_freqs_history", "[", "w", "]", "=", "0", "\n", "", "word_freqs_history", "[", "w", "]", "+=", "1", "\n", "if", "w", "not", "in", "word_freqs_belief", ":", "\n", "                    ", "word_freqs_belief", "[", "w", "]", "=", "0", "\n", "", "word_freqs_belief", "[", "w", "]", "+=", "1", "\n", "\n", "# save all dialogues", "\n", "", "", "", "if", "lexicalize", ":", "\n", "        ", "val_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'val_dials_lexicalized.json'", ")", "\n", "test_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'test_dials_lexicalized.json'", ")", "\n", "train_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'train_dials_lexicalized.json'", ")", "\n", "", "else", ":", "\n", "        ", "val_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'val_dials.json'", ")", "\n", "test_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'test_dials.json'", ")", "\n", "train_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'train_dials.json'", ")", "\n", "\n", "", "with", "open", "(", "val_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "val_dials", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "with", "open", "(", "test_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "test_dials", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "with", "open", "(", "train_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "train_dials", ",", "f", ",", "indent", "=", "4", ")", "\n", "\n", "", "return", "word_freqs_usr", ",", "word_freqs_sys", ",", "word_freqs_history", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.buildDictionaries": [[833, 879], ["preprocess_multiwoz.createDict", "dicts.append", "preprocess_multiwoz.createDict", "dicts.append", "preprocess_multiwoz.createDict", "dicts.append", "dictionary.items", "idx2words.append", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "open", "json.dump", "open", "json.dump", "open", "json.dump", "open", "json.dump", "open", "json.dump", "open", "json.dump"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createDict", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createDict", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createDict"], ["", "def", "buildDictionaries", "(", "word_freqs_usr", ",", "word_freqs_sys", ",", "word_freqs_histoy", ",", "lexicalize", "=", "False", ")", ":", "\n", "    ", "\"\"\"Build dictionaries for both user and system sides.\n    You can specify the size of the dictionary through DICT_SIZE variable.\"\"\"", "\n", "dicts", "=", "[", "]", "\n", "worddict_usr", "=", "createDict", "(", "word_freqs_usr", ")", "\n", "dicts", ".", "append", "(", "worddict_usr", ")", "\n", "worddict_sys", "=", "createDict", "(", "word_freqs_sys", ")", "\n", "dicts", ".", "append", "(", "worddict_sys", ")", "\n", "worddict_history", "=", "createDict", "(", "word_freqs_histoy", ")", "\n", "dicts", ".", "append", "(", "worddict_history", ")", "\n", "\n", "# reverse dictionaries", "\n", "idx2words", "=", "[", "]", "\n", "for", "dictionary", "in", "dicts", ":", "\n", "        ", "dic", "=", "{", "}", "\n", "for", "k", ",", "v", "in", "dictionary", ".", "items", "(", ")", ":", "\n", "            ", "dic", "[", "v", "]", "=", "k", "\n", "", "idx2words", ".", "append", "(", "dic", ")", "\n", "\n", "", "if", "lexicalize", ":", "\n", "        ", "input_index2word_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'input_lang.index2word_lexicalized.json'", ")", "\n", "input_word2index_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'input_lang.word2index_lexicalized.json'", ")", "\n", "output_index2word_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'output_lang.index2word_lexicalized.json'", ")", "\n", "output_word2index_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'output_lang.word2index_lexicalized.json'", ")", "\n", "history_index2word_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'history_lang.index2word_lexicalized.json'", ")", "\n", "history_word2index_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'history_lang.word2index_lexicalized.json'", ")", "\n", "", "else", ":", "\n", "        ", "input_index2word_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'input_lang.index2word.json'", ")", "\n", "input_word2index_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'input_lang.word2index.json'", ")", "\n", "output_index2word_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'output_lang.index2word.json'", ")", "\n", "output_word2index_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'output_lang.word2index.json'", ")", "\n", "history_index2word_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'history_lang.index2word.json'", ")", "\n", "history_word2index_filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'history_lang.word2index.json'", ")", "\n", "\n", "", "with", "open", "(", "input_index2word_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "idx2words", "[", "0", "]", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "with", "open", "(", "input_word2index_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "dicts", "[", "0", "]", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "with", "open", "(", "output_index2word_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "idx2words", "[", "1", "]", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "with", "open", "(", "output_word2index_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "dicts", "[", "1", "]", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "with", "open", "(", "history_index2word_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "idx2words", "[", "2", "]", ",", "f", ",", "indent", "=", "2", ")", "\n", "", "with", "open", "(", "history_word2index_filename", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "dicts", "[", "2", "]", ",", "f", ",", "indent", "=", "2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.main": [[881, 904], ["print", "preprocess_multiwoz.divideData", "print", "preprocess_multiwoz.buildDictionaries", "print", "os.path.isfile", "preprocess_multiwoz.createDelexData", "json.load", "print", "TypeError", "os.path.join", "open", "os.path.isfile", "preprocess_multiwoz.createLexicalData", "json.load", "str", "str", "os.path.join", "os.path.join", "open", "os.path.join"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.divideData", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.buildDictionaries", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createDelexData", "home.repos.pwc.inspect_result.salesforce_simpletod.None.preprocess_multiwoz.createLexicalData"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "sys", ".", "argv", "[", "1", "]", "==", "'delex'", ":", "\n", "        ", "print", "(", "'MultiWoz Create delexicalized dialogues. Get yourself a coffee, this might take a while.'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/delex.json'", ")", ")", ":", "\n", "            ", "data", "=", "createDelexData", "(", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/delex.json'", ")", ")", ")", "\n", "", "", "elif", "sys", ".", "argv", "[", "1", "]", "==", "'lexical'", ":", "\n", "        ", "print", "(", "'MultiWoz Create lexicalized dialogues. Get yourself a coffee, this might take a while.'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/lex.json'", ")", ")", ":", "\n", "            ", "data", "=", "createLexicalData", "(", ")", "\n", "", "else", ":", "\n", "            ", "data", "=", "json", ".", "load", "(", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'multi-woz/lex.json'", ")", ")", ")", "\n", "\n", "", "", "else", ":", "\n", "        ", "raise", "TypeError", "(", "'unknown preprocessing'", ")", "\n", "", "print", "(", "'Divide dialogues for separate bits - usr, sys, db, bs'", ")", "\n", "word_freqs_usr", ",", "word_freqs_sys", ",", "word_freqs_history", "=", "divideData", "(", "data", ",", "\n", "lexicalize", "=", "(", "str", "(", "sys", ".", "argv", "[", "1", "]", ")", "==", "'lexical'", ")", ")", "\n", "\n", "print", "(", "'Building dictionaries'", ")", "\n", "buildDictionaries", "(", "word_freqs_usr", ",", "word_freqs_sys", ",", "word_freqs_history", ",", "\n", "lexicalize", "=", "(", "str", "(", "sys", ".", "argv", "[", "1", "]", ")", "==", "'lexical'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.dst.ignore_none": [[74, 95], ["clean_target_belief.append", "clean_pred_belief.append", "pred.replace"], "function", ["None"], ["def", "ignore_none", "(", "pred_belief", ",", "target_belief", ")", ":", "\n", "    ", "for", "pred", "in", "pred_belief", ":", "\n", "        ", "if", "'catherine s'", "in", "pred", ":", "\n", "            ", "pred", ".", "replace", "(", "'catherine s'", ",", "'catherines'", ")", "\n", "\n", "", "", "clean_target_belief", "=", "[", "]", "\n", "clean_pred_belief", "=", "[", "]", "\n", "for", "bs", "in", "target_belief", ":", "\n", "        ", "if", "'not mentioned'", "in", "bs", ":", "\n", "            ", "continue", "\n", "", "clean_target_belief", ".", "append", "(", "bs", ")", "\n", "\n", "", "for", "bs", "in", "pred_belief", ":", "\n", "        ", "if", "'not mentioned'", "in", "bs", ":", "\n", "            ", "continue", "\n", "", "clean_pred_belief", ".", "append", "(", "bs", ")", "\n", "\n", "", "target_belief", "=", "clean_target_belief", "\n", "pred_belief", "=", "clean_pred_belief", "\n", "\n", "return", "pred_belief", ",", "target_belief", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.dst.fix_mismatch_jason": [[97, 135], ["None"], "function", ["None"], ["", "def", "fix_mismatch_jason", "(", "slot", ",", "value", ")", ":", "\n", "# miss match slot and value", "\n", "    ", "if", "slot", "==", "\"type\"", "and", "value", "in", "[", "\"nigh\"", ",", "\"moderate -ly priced\"", ",", "\"bed and breakfast\"", ",", "\n", "\"centre\"", ",", "\"venetian\"", ",", "\"intern\"", ",", "\"a cheap -er hotel\"", "]", "or", "slot", "==", "\"internet\"", "and", "value", "==", "\"4\"", "or", "slot", "==", "\"pricerange\"", "and", "value", "==", "\"2\"", "or", "slot", "==", "\"type\"", "and", "value", "in", "[", "\"gastropub\"", ",", "\"la raza\"", ",", "\"galleria\"", ",", "\"gallery\"", ",", "\n", "\"science\"", ",", "\"m\"", "]", "or", "\"area\"", "in", "slot", "and", "value", "in", "[", "\"moderate\"", "]", "or", "\"day\"", "in", "slot", "and", "value", "==", "\"t\"", ":", "\n", "        ", "value", "=", "\"none\"", "\n", "", "elif", "slot", "==", "\"type\"", "and", "value", "in", "[", "\"hotel with free parking and free wifi\"", ",", "\"4\"", ",", "\n", "\"3 star hotel\"", "]", ":", "\n", "        ", "value", "=", "\"hotel\"", "\n", "", "elif", "slot", "==", "\"star\"", "and", "value", "==", "\"3 star hotel\"", ":", "\n", "        ", "value", "=", "\"3\"", "\n", "", "elif", "\"area\"", "in", "slot", ":", "\n", "        ", "if", "value", "==", "\"no\"", ":", "\n", "            ", "value", "=", "\"north\"", "\n", "", "elif", "value", "==", "\"we\"", ":", "\n", "            ", "value", "=", "\"west\"", "\n", "", "elif", "value", "==", "\"cent\"", ":", "\n", "            ", "value", "=", "\"centre\"", "\n", "", "", "elif", "\"day\"", "in", "slot", ":", "\n", "        ", "if", "value", "==", "\"we\"", ":", "\n", "            ", "value", "=", "\"wednesday\"", "\n", "", "elif", "value", "==", "\"no\"", ":", "\n", "            ", "value", "=", "\"none\"", "\n", "", "", "elif", "\"price\"", "in", "slot", "and", "value", "==", "\"ch\"", ":", "\n", "        ", "value", "=", "\"cheap\"", "\n", "", "elif", "\"internet\"", "in", "slot", "and", "value", "==", "\"free\"", ":", "\n", "        ", "value", "=", "\"yes\"", "\n", "\n", "# some out-of-define classification slot values", "\n", "", "if", "slot", "==", "\"area\"", "and", "value", "in", "[", "\"stansted airport\"", ",", "\"cambridge\"", ",", "\"silver street\"", "]", "or", "slot", "==", "\"area\"", "and", "value", "in", "[", "\"norwich\"", ",", "\"ely\"", ",", "\"museum\"", ",", "\"same area as hotel\"", "]", ":", "\n", "        ", "value", "=", "\"none\"", "\n", "", "return", "slot", ",", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.dst.default_cleaning": [[137, 176], ["dst.fix_mismatch_jason", "pred_belief_jason.append", "dst.fix_mismatch_jason", "target_belief_jason.append", "pred.split", "tgt.split", "pred.split", "tgt.split", "pred.split", "pred.split", "pred.split", "tgt.split", "tgt.split", "tgt.split"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.utils.dst.fix_mismatch_jason", "home.repos.pwc.inspect_result.salesforce_simpletod.utils.dst.fix_mismatch_jason"], ["", "def", "default_cleaning", "(", "pred_belief", ",", "target_belief", ")", ":", "\n", "    ", "pred_belief_jason", "=", "[", "]", "\n", "target_belief_jason", "=", "[", "]", "\n", "for", "pred", "in", "pred_belief", ":", "\n", "        ", "if", "pred", "in", "[", "''", ",", "' '", "]", ":", "\n", "            ", "continue", "\n", "", "domain", "=", "pred", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "'book'", "in", "pred", ":", "\n", "            ", "slot", "=", "' '", ".", "join", "(", "pred", ".", "split", "(", ")", "[", "1", ":", "3", "]", ")", "\n", "val", "=", "' '", ".", "join", "(", "pred", ".", "split", "(", ")", "[", "3", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "slot", "=", "pred", ".", "split", "(", ")", "[", "1", "]", "\n", "val", "=", "' '", ".", "join", "(", "pred", ".", "split", "(", ")", "[", "2", ":", "]", ")", "\n", "\n", "", "if", "slot", "in", "GENERAL_TYPO", ":", "\n", "            ", "val", "=", "GENERAL_TYPO", "[", "slot", "]", "\n", "\n", "", "slot", ",", "val", "=", "fix_mismatch_jason", "(", "slot", ",", "val", ")", "\n", "\n", "pred_belief_jason", ".", "append", "(", "'{} {} {}'", ".", "format", "(", "domain", ",", "slot", ",", "val", ")", ")", "\n", "\n", "", "for", "tgt", "in", "target_belief", ":", "\n", "        ", "domain", "=", "tgt", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "'book'", "in", "tgt", ":", "\n", "            ", "slot", "=", "' '", ".", "join", "(", "tgt", ".", "split", "(", ")", "[", "1", ":", "3", "]", ")", "\n", "val", "=", "' '", ".", "join", "(", "tgt", ".", "split", "(", ")", "[", "3", ":", "]", ")", "\n", "", "else", ":", "\n", "            ", "slot", "=", "tgt", ".", "split", "(", ")", "[", "1", "]", "\n", "val", "=", "' '", ".", "join", "(", "tgt", ".", "split", "(", ")", "[", "2", ":", "]", ")", "\n", "\n", "", "if", "slot", "in", "GENERAL_TYPO", ":", "\n", "            ", "val", "=", "GENERAL_TYPO", "[", "slot", "]", "\n", "", "slot", ",", "val", "=", "fix_mismatch_jason", "(", "slot", ",", "val", ")", "\n", "target_belief_jason", ".", "append", "(", "'{} {} {}'", ".", "format", "(", "domain", ",", "slot", ",", "val", ")", ")", "\n", "\n", "", "turn_pred", "=", "pred_belief_jason", "\n", "turn_target", "=", "target_belief_jason", "\n", "\n", "return", "turn_pred", ",", "turn_target", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.args_parser.ArgsParser.__init__": [[11, 76], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "default", "=", "'./resources'", ")", "\n", "parser", ".", "add_argument", "(", "'--log_dir'", ",", "default", "=", "'./logs'", ")", "\n", "parser", ".", "add_argument", "(", "'--dataset'", ",", "default", "=", "'multiwoz'", ")", "\n", "parser", ".", "add_argument", "(", "'--save_dir'", ",", "default", "=", "'./checkpoints'", ")", "\n", "\n", "# generation args for SimpleTOD", "\n", "parser", ".", "add_argument", "(", "'--checkpoint'", ",", "default", "=", "None", ",", "type", "=", "str", ",", "\n", "help", "=", "'model checkpoint for generation'", ")", "\n", "parser", ".", "add_argument", "(", "'--experiment_name'", ",", "default", "=", "None", ",", "help", "=", "'experiment name'", ")", "\n", "parser", ".", "add_argument", "(", "'--split_set'", ",", "default", "=", "'test'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_db_search'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'use db search in prompt, should be used with oracle belief'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_dynamic_db'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'compute db search dynamically using generated belief'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_oracle_belief'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'generate with oracle belief in simpleTOD'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_oracle_action'", ",", "action", "=", "'store_true'", ",", "default", "=", "False", ",", "\n", "help", "=", "'generate with oracle action in simpleTOD'", ")", "\n", "parser", ".", "add_argument", "(", "'--decoding'", ",", "default", "=", "'greedy'", ",", "\n", "help", "=", "'decoding method for simpletod'", ")", "\n", "\n", "# dataset args", "\n", "parser", ".", "add_argument", "(", "'--name'", ",", "default", "=", "'multiwoz'", ")", "\n", "parser", ".", "add_argument", "(", "'-b'", ",", "'--batch_size'", ",", "type", "=", "int", ",", "default", "=", "2048", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--seq_len'", ",", "type", "=", "int", ",", "default", "=", "512", ")", "\n", "parser", ".", "add_argument", "(", "'--history_length'", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "'number of turns for context history'", ")", "\n", "parser", ".", "add_argument", "(", "'--no_history'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use current turn only'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--mode'", ",", "type", "=", "str", ",", "default", "=", "'train'", ",", "\n", "choices", "=", "[", "'train'", ",", "'evaluate'", ",", "'generate'", "]", ",", "help", "=", "'mode'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--lexical'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use lexical data'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_knowledge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use knowledge'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_knowledge_for_decoding'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use knowledge in decoder attention'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_all_knowledge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use knowledge'", ")", "\n", "parser", ".", "add_argument", "(", "'--knowledge_len'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "'knowledge length x seq_len'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_action'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use action'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_belief'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use belief'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_action_only'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use action as target only'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_belief_only'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use belief as target only'", ")", "\n", "parser", ".", "add_argument", "(", "'--positive_knowledge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use only positive knowledge'", ")", "\n", "parser", ".", "add_argument", "(", "'--context_knowledge'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "'use context knowledge'", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--knowledge_matching'", ",", "type", "=", "str", ",", "default", "=", "'entity'", ",", "\n", "help", "=", "'criterium to find positive knowledge'", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cached\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"do not use cached data\"", ")", "\n", "self", ".", "parser", "=", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.args_parser.ArgsParser.parse": [[77, 81], ["args_parser.ArgsParser.parser.parse_args"], "methods", ["None"], ["", "def", "parse", "(", "self", ")", ":", "\n", "        ", "args", "=", "self", ".", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_belief": [[3, 18], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tmp.replace.split", "bs.strip.strip", "[].split", "new_belief.append", "sent.strip().split", "sent.strip"], "function", ["None"], ["def", "get_belief", "(", "sent", ")", ":", "\n", "    ", "if", "'<|belief|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "strip", "(", "' '", ")", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|action|>'", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofbelief|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "belief", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_belief", "=", "[", "]", "\n", "for", "bs", "in", "belief", ":", "\n", "        ", "bs", "=", "bs", ".", "strip", "(", "' .,'", ")", "\n", "if", "bs", "not", "in", "new_belief", ":", "\n", "            ", "new_belief", ".", "append", "(", "bs", ")", "\n", "", "", "return", "new_belief", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_belief_dbsearch": [[20, 35], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tmp.replace.split", "bs.strip.strip", "[].split", "new_belief.append", "sent.strip().split", "sent.strip"], "function", ["None"], ["", "def", "get_belief_dbsearch", "(", "sent", ")", ":", "\n", "    ", "if", "'<|belief|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "strip", "(", "' '", ")", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|endofbelief|>'", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofbelief|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "belief", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_belief", "=", "[", "]", "\n", "for", "bs", "in", "belief", ":", "\n", "        ", "bs", "=", "bs", ".", "strip", "(", "' .,'", ")", "\n", "if", "bs", "not", "in", "new_belief", ":", "\n", "            ", "new_belief", ".", "append", "(", "bs", ")", "\n", "", "", "return", "new_belief", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_belief_openaigpt": [[37, 52], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tmp.replace.split", "bs.strip.strip", "[].split", "new_belief.append", "sent.strip().split", "sent.strip"], "function", ["None"], ["", "def", "get_belief_openaigpt", "(", "sent", ")", ":", "\n", "    ", "if", "'< | belief | >'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "strip", "(", "' '", ")", ".", "split", "(", "'< | belief | >'", ")", "[", "-", "1", "]", ".", "split", "(", "'< | action | >'", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endofbelief | >'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endoftext | >'", ",", "''", ")", "\n", "belief", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_belief", "=", "[", "]", "\n", "for", "bs", "in", "belief", ":", "\n", "        ", "bs", "=", "bs", ".", "strip", "(", "' .,'", ")", "\n", "if", "bs", "not", "in", "new_belief", ":", "\n", "            ", "new_belief", ".", "append", "(", "bs", ")", "\n", "", "", "return", "new_belief", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_response": [[54, 70], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tokenizer.encode", "tokenizer.decode().strip", "new_tokens.append", "[].split", "tokenizer.encode", "tokenizer.decode", "[].split", "sent.split"], "function", ["None"], ["", "def", "get_response", "(", "sent", ",", "tokenizer", ")", ":", "\n", "    ", "if", "'<|response|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|action|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|response|>'", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "return", "''", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofresponse|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "tokens", "=", "tokenizer", ".", "encode", "(", "tmp", ")", "\n", "new_tokens", "=", "[", "]", "\n", "for", "tok", "in", "tokens", ":", "\n", "        ", "if", "tok", "in", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ")", ":", "\n", "            ", "continue", "\n", "", "new_tokens", ".", "append", "(", "tok", ")", "\n", "", "response", "=", "tokenizer", ".", "decode", "(", "new_tokens", ")", ".", "strip", "(", "' ,.'", ")", "\n", "return", "response", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_response_openaigpt": [[72, 92], ["tmp.replace.strip", "tmp.replace.replace", "tmp.replace.replace", "tokenizer.encode", "tokenizer.decode().strip", "response.replace.replace", "response.replace.replace", "response.replace.replace", "response.replace.replace", "new_tokens.append", "[].split", "tokenizer.encode", "tokenizer.decode", "[].split", "sent.split"], "function", ["None"], ["", "def", "get_response_openaigpt", "(", "sent", ",", "tokenizer", ")", ":", "\n", "    ", "if", "'< | response | >'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'< | belief | >'", ")", "[", "-", "1", "]", ".", "split", "(", "'< | action | >'", ")", "[", "-", "1", "]", ".", "split", "(", "'< | response | >'", ")", "[", "-", "1", "]", "\n", "", "else", ":", "\n", "        ", "return", "''", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endofresponse | >'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endoftext | >'", ",", "''", ")", "\n", "tokens", "=", "tokenizer", ".", "encode", "(", "tmp", ")", "\n", "new_tokens", "=", "[", "]", "\n", "for", "tok", "in", "tokens", ":", "\n", "        ", "if", "tok", "in", "tokenizer", ".", "encode", "(", "tokenizer", ".", "_eos_token", ")", ":", "\n", "            ", "continue", "\n", "", "new_tokens", ".", "append", "(", "tok", ")", "\n", "", "response", "=", "tokenizer", ".", "decode", "(", "new_tokens", ")", ".", "strip", "(", "' ,.'", ")", "\n", "response", "=", "response", ".", "replace", "(", "'[ '", ",", "'['", ")", "\n", "response", "=", "response", ".", "replace", "(", "' ]'", ",", "']'", ")", "\n", "response", "=", "response", ".", "replace", "(", "' _ '", ",", "'_'", ")", "\n", "response", "=", "response", ".", "replace", "(", "'i d'", ",", "'id'", ")", "\n", "return", "response", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_action": [[94, 115], ["[].strip.strip", "[].strip.replace", "[].strip.replace", "[].strip.split", "act.strip.strip", "[].strip", "new_action.append", "[].strip", "[].split", "[].split", "[].split", "sent.split", "sent.split"], "function", ["None"], ["", "def", "get_action", "(", "sent", ")", ":", "\n", "    ", "if", "'<|action|>'", "not", "in", "sent", ":", "\n", "        ", "return", "[", "]", "\n", "", "elif", "'<|belief|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'<|belief|>'", ")", "[", "-", "1", "]", ".", "split", "(", "'<|response|>'", ")", "[", "0", "]", ".", "split", "(", "'<|action|>'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "elif", "'<|action|>'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'<|response|>'", ")", "[", "0", "]", ".", "split", "(", "'<|action|>'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endofaction|>'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'<|endoftext|>'", ",", "''", ")", "\n", "action", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_action", "=", "[", "]", "\n", "for", "act", "in", "action", ":", "\n", "        ", "if", "act", "==", "''", ":", "\n", "            ", "continue", "\n", "", "act", "=", "act", ".", "strip", "(", "' .,'", ")", "\n", "if", "act", "not", "in", "new_action", ":", "\n", "            ", "new_action", ".", "append", "(", "act", ")", "\n", "", "", "return", "new_action", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_action_openaigpt": [[117, 137], ["[].strip.strip", "[].strip.replace", "[].strip.replace", "[].strip.split", "[].strip", "act.replace.strip", "[].strip", "act.replace.replace", "new_action.append", "[].split", "[].split", "[].split", "sent.split", "sent.split"], "function", ["None"], ["", "def", "get_action_openaigpt", "(", "sent", ")", ":", "\n", "    ", "if", "'< | belief | >'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'< | belief | >'", ")", "[", "-", "1", "]", ".", "split", "(", "'< | response | >'", ")", "[", "0", "]", ".", "split", "(", "'< | action | >'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "elif", "'< | action | >'", "in", "sent", ":", "\n", "        ", "tmp", "=", "sent", ".", "split", "(", "'< | response | >'", ")", "[", "0", "]", ".", "split", "(", "'< | action | >'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "", "else", ":", "\n", "        ", "return", "[", "]", "\n", "", "tmp", "=", "tmp", ".", "strip", "(", "' .,'", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endofaction | >'", ",", "''", ")", "\n", "tmp", "=", "tmp", ".", "replace", "(", "'< | endoftext | >'", ",", "''", ")", "\n", "action", "=", "tmp", ".", "split", "(", "','", ")", "\n", "new_action", "=", "[", "]", "\n", "for", "act", "in", "action", ":", "\n", "        ", "if", "act", "==", "''", ":", "\n", "            ", "continue", "\n", "", "act", "=", "act", ".", "strip", "(", "' .,'", ")", "\n", "if", "act", "not", "in", "new_action", ":", "\n", "            ", "act", "=", "act", ".", "replace", "(", "'i d'", ",", "'id'", ")", "\n", "new_action", ".", "append", "(", "act", ")", "\n", "", "", "return", "new_action", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_db_dynamically": [[139, 202], ["simpletod.get_belief_dbsearch", "len", "db_text_tmp.append", "bs.split", "multiwoz_db.queryResultVenues", "[].items", "bs.split", "bs.split", "bs.split", "bs.split", "belief_book_domain[].items"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.utils.simpletod.get_belief_dbsearch", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResultVenues"], ["", "def", "get_db_dynamically", "(", "predicted_text", ",", "goal", ",", "multiwoz_db", ")", ":", "\n", "    ", "gen_belief", "=", "get_belief_dbsearch", "(", "predicted_text", ")", "\n", "belief_domain", "=", "{", "}", "\n", "belief_book_domain", "=", "{", "}", "\n", "for", "bs", "in", "gen_belief", ":", "\n", "        ", "if", "bs", "in", "[", "''", ",", "' '", "]", ":", "\n", "            ", "continue", "\n", "", "bs_domain", "=", "bs", ".", "split", "(", ")", "[", "0", "]", "\n", "if", "'book'", "in", "bs", ":", "\n", "            ", "bs_slot", "=", "bs", ".", "split", "(", ")", "[", "2", "]", "\n", "bs_val", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", ")", "[", "3", ":", "]", ")", "\n", "if", "bs_domain", "not", "in", "belief_book_domain", ":", "\n", "                ", "belief_book_domain", "[", "bs_domain", "]", "=", "{", "}", "\n", "", "belief_book_domain", "[", "bs_domain", "]", "[", "bs_slot", "]", "=", "bs_val", "\n", "", "else", ":", "\n", "            ", "bs_slot", "=", "bs", ".", "split", "(", ")", "[", "1", "]", "\n", "bs_val", "=", "' '", ".", "join", "(", "bs", ".", "split", "(", ")", "[", "2", ":", "]", ")", "\n", "if", "bs_domain", "not", "in", "belief_domain", ":", "\n", "                ", "belief_domain", "[", "bs_domain", "]", "=", "{", "}", "\n", "belief_book_domain", "[", "bs_domain", "]", "=", "{", "}", "\n", "", "belief_domain", "[", "bs_domain", "]", "[", "bs_slot", "]", "=", "bs_val", "\n", "\n", "", "", "db_text_tmp", "=", "[", "]", "\n", "for", "dom", "in", "belief_domain", ":", "\n", "        ", "if", "dom", "not", "in", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", ":", "\n", "            ", "continue", "\n", "", "domain_match", "=", "len", "(", "multiwoz_db", ".", "queryResultVenues", "(", "dom", ",", "belief_domain", "[", "dom", "]", ",", "real_belief", "=", "True", ")", ")", "\n", "\n", "if", "dom", "!=", "'train'", ":", "\n", "            ", "if", "domain_match", ">=", "5", ":", "\n", "                ", "domain_match_text", "=", "'>=5'", "\n", "", "else", ":", "\n", "                ", "domain_match_text", "=", "'={}'", ".", "format", "(", "domain_match", ")", "\n", "\n", "", "", "elif", "dom", "==", "'train'", ":", "\n", "            ", "if", "domain_match", "==", "0", ":", "\n", "                ", "domain_match_text", "=", "'=0'", "\n", "", "elif", "domain_match", "==", "2", ":", "\n", "                ", "domain_match_text", "=", "'<3'", "\n", "", "elif", "domain_match", "==", "5", ":", "\n", "                ", "domain_match_text", "=", "'<6'", "\n", "", "elif", "domain_match", "==", "10", ":", "\n", "                ", "domain_match_text", "=", "'<11'", "\n", "", "elif", "domain_match", "==", "40", ":", "\n", "                ", "domain_match_text", "=", "'<41'", "\n", "", "else", ":", "\n", "                ", "domain_match_text", "=", "'>40'", "\n", "", "", "if", "'fail_book'", "in", "goal", "[", "dom", "]", ":", "\n", "            ", "for", "item", "in", "goal", "[", "dom", "]", "[", "'fail_book'", "]", ".", "items", "(", ")", ":", "\n", "                ", "if", "item", "in", "belief_book_domain", "[", "dom", "]", ".", "items", "(", ")", ":", "\n", "                    ", "domain_book_text", "=", "'not available'", "\n", "break", "\n", "", "else", ":", "\n", "                    ", "domain_book_text", "=", "'available'", "\n", "", "", "", "else", ":", "\n", "            ", "if", "domain_match", "==", "0", ":", "\n", "                ", "domain_book_text", "=", "'not available'", "\n", "", "else", ":", "\n", "                ", "domain_book_text", "=", "'available'", "\n", "\n", "", "", "db_text_tmp", ".", "append", "(", "'{} match{} booking={}'", ".", "format", "(", "dom", ",", "domain_match_text", ",", "domain_book_text", ")", ")", "\n", "", "db_text", "=", "' <|dbsearch|> {} <|endofdbsearch|>'", ".", "format", "(", "' , '", ".", "join", "(", "db_text_tmp", ")", ")", "\n", "return", "db_text", "\n", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.model.set_seed": [[13, 19], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.model._sorted_checkpoints": [[21, 37], ["glob.glob", "sorted", "os.path.join", "ordering_and_checkpoint_path.append", "re.match", "re.match.groups", "ordering_and_checkpoint_path.append", "os.path.getmtime", "int", "re.match.groups"], "function", ["None"], ["", "", "def", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", ":", "\n", "    ", "ordering_and_checkpoint_path", "=", "[", "]", "\n", "\n", "glob_checkpoints", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-*\"", ".", "format", "(", "checkpoint_prefix", ")", ")", ")", "\n", "\n", "for", "path", "in", "glob_checkpoints", ":", "\n", "        ", "if", "use_mtime", ":", "\n", "            ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "os", ".", "path", ".", "getmtime", "(", "path", ")", ",", "path", ")", ")", "\n", "", "else", ":", "\n", "            ", "regex_match", "=", "re", ".", "match", "(", "\".*{}-([0-9]+)\"", ".", "format", "(", "checkpoint_prefix", ")", ",", "path", ")", "\n", "if", "regex_match", "and", "regex_match", ".", "groups", "(", ")", ":", "\n", "                ", "ordering_and_checkpoint_path", ".", "append", "(", "(", "int", "(", "regex_match", ".", "groups", "(", ")", "[", "0", "]", ")", ",", "path", ")", ")", "\n", "\n", "", "", "", "checkpoints_sorted", "=", "sorted", "(", "ordering_and_checkpoint_path", ")", "\n", "checkpoints_sorted", "=", "[", "checkpoint", "[", "1", "]", "for", "checkpoint", "in", "checkpoints_sorted", "]", "\n", "return", "checkpoints_sorted", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.model._rotate_checkpoints": [[39, 55], ["model._sorted_checkpoints", "max", "len", "logger.info", "shutil.rmtree", "len"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.utils.model._sorted_checkpoints"], ["", "def", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", "=", "\"checkpoint\"", ",", "use_mtime", "=", "False", ")", ":", "\n", "    ", "if", "not", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "", "if", "args", ".", "save_total_limit", "<=", "0", ":", "\n", "        ", "return", "\n", "\n", "# Check if we should delete older checkpoint(s)", "\n", "", "checkpoints_sorted", "=", "_sorted_checkpoints", "(", "args", ",", "checkpoint_prefix", ",", "use_mtime", ")", "\n", "if", "len", "(", "checkpoints_sorted", ")", "<=", "args", ".", "save_total_limit", ":", "\n", "        ", "return", "\n", "\n", "", "number_of_checkpoints_to_delete", "=", "max", "(", "0", ",", "len", "(", "checkpoints_sorted", ")", "-", "args", ".", "save_total_limit", ")", "\n", "checkpoints_to_be_deleted", "=", "checkpoints_sorted", "[", ":", "number_of_checkpoints_to_delete", "]", "\n", "for", "checkpoint", "in", "checkpoints_to_be_deleted", ":", "\n", "        ", "logger", ".", "info", "(", "\"Deleting older checkpoint [{}] due to args.save_total_limit\"", ".", "format", "(", "checkpoint", ")", ")", "\n", "shutil", ".", "rmtree", "(", "checkpoint", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.model.save_checkpoint": [[57, 74], ["os.path.join", "os.makedirs", "model_to_save.save_pretrained", "tokenizer.save_pretrained", "torch.save", "logger.info", "model._rotate_checkpoints", "torch.save", "torch.save", "logger.info", "hasattr", "os.path.join", "optimizer.state_dict", "os.path.join", "scheduler.state_dict", "os.path.join"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.save_pretrained", "home.repos.pwc.inspect_result.salesforce_simpletod.utils.model._rotate_checkpoints"], ["", "", "def", "save_checkpoint", "(", "model", ",", "optimizer", ",", "scheduler", ",", "tokenizer", ",", "args", ")", ":", "\n", "    ", "checkpoint_prefix", "=", "\"checkpoint\"", "\n", "# Save model checkpoint", "\n", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"{}-{}\"", ".", "format", "(", "checkpoint_prefix", ",", "global_step", ")", ")", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "model_to_save", "=", "(", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", ")", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "output_dir", ")", "\n", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "_rotate_checkpoints", "(", "args", ",", "checkpoint_prefix", ")", "\n", "\n", "torch", ".", "save", "(", "optimizer", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"optimizer.pt\"", ")", ")", "\n", "torch", ".", "save", "(", "scheduler", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"scheduler.pt\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving optimizer and scheduler states to %s\"", ",", "output_dir", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.gpt2_args_parser.ArgsParser.__init__": [[8, 150], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "# Required parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--train_data_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The input training data file (a text file).\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--output_dir\"", ",", "\n", "type", "=", "str", ",", "\n", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_type\"", ",", "type", "=", "str", ",", "required", "=", "True", ",", "help", "=", "\"The model architecture to be trained or fine-tuned.\"", ",", "\n", ")", "\n", "\n", "# Other parameters", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_data_file\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"An optional input evaluation data file to evaluate the perplexity on (a text file).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shuffle_context\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"permute user/system text in dialogue context\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shuffle_belief_action\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"permute belief/action in dialogue\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--shuffle_belief\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"permute belief/action in dialogue\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--should_continue\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to continue from latest checkpoint in output_dir\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--model_name_or_path\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The model checkpoint for weights initialization. Leave None if you want to train a model from scratch.\"", ",", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--config_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained config name or path if not the same as model_name_or_path. If both are None, initialize a new config.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--tokenizer_name\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional pretrained tokenizer name or path if not the same as model_name_or_path. If both are None, initialize a new tokenizer.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--cache_dir\"", ",", "\n", "default", "=", "None", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"Optional directory to store the pre-trained models downloaded from s3 (instead of the default one)\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--block_size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"Optional input sequence length after tokenization.\"", "\n", "\"The training dataset will be truncated in block of this size for training.\"", "\n", "\"Default to the model max input length for single sentence inputs (take into account special tokens).\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--evaluate_during_training\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Run evaluation during training at each logging step.\"", "\n", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "4", ",", "type", "=", "int", ",", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--gradient_accumulation_steps\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "help", "=", "\"Weight decay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--num_train_epochs\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "help", "=", "\"Total number of training epochs to perform.\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--max_steps\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--logging_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--save_steps\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--save_total_limit\"", ",", "\n", "type", "=", "int", ",", "\n", "default", "=", "None", ",", "\n", "help", "=", "\"Limit the total amount of checkpoints, delete the older checkpoints in the output_dir, does not delete by default\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--eval_all_checkpoints\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name_or_path ending and ending with step number\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "# parser.add_argument(", "\n", "#     \"--overwrite_output_dir\", action=\"store_true\", help=\"Overwrite the content of the output directory\"", "\n", "# )", "\n", "parser", ".", "add_argument", "(", "\n", "\"--overwrite_cache\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Overwrite the cached training and evaluation sets\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "42", ",", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--fp16_opt_level\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"O1\"", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "self", ".", "parser", "=", "parser", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.gpt2_args_parser.ArgsParser.parse": [[151, 154], ["gpt2_args_parser.ArgsParser.parser.parse_args"], "methods", ["None"], ["", "def", "parse", "(", "self", ")", ":", "\n", "        ", "args", "=", "self", ".", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.language_model.get_optimizer_scheduler": [[12, 37], ["transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "os.path.isfile", "os.path.isfile", "transformers.AdamW.load_state_dict", "transformers.get_linear_schedule_with_warmup.load_state_dict", "os.path.join", "os.path.join", "torch.load", "torch.load", "os.path.join", "os.path.join", "model.named_parameters", "model.named_parameters", "any", "any"], "function", ["None"], ["def", "get_optimizer_scheduler", "(", "args", ",", "model", ",", "t_total", ")", ":", "\n", "    ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n", "\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n", "args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n", ")", ":", "\n", "# Load in optimizer and scheduler states", "\n", "        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "return", "optimizer", ",", "scheduler", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.__init__.get_logger": [[13, 17], ["logging.getLogger", "logging.getLogger.setLevel"], "function", ["None"], ["def", "get_logger", "(", "name", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "return", "logger", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.__init__.get_writer": [[19, 22], ["tensorboardX.SummaryWriter"], "function", ["None"], ["", "def", "get_writer", "(", "name", ")", ":", "\n", "    ", "writer", "=", "SummaryWriter", "(", "name", ")", "\n", "return", "writer", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.__init__.prepare_logger_writer": [[24, 35], ["__init__.get_logger", "__init__.get_writer", "os.path.join"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.utils.__init__.get_logger", "home.repos.pwc.inspect_result.salesforce_simpletod.utils.__init__.get_writer"], ["", "def", "prepare_logger_writer", "(", "args", ")", ":", "\n", "# if args.resume or args.mode in ['evaluate', 'generate']:", "\n", "#     chekpoint_name = os.path.join(args.experiment_dir, '{}_best.chkpt'.format(args.model_type))", "\n", "#     chekpoint_params = torch.load(chekpoint_name)", "\n", "#     config = chekpoint_params['config']", "\n", "#     args.name = config.name", "\n", "#     args.log_dir = config.log_dir", "\n", "#     args.exp_name = config.exp_name", "\n", "    ", "args", ".", "logger", "=", "get_logger", "(", "args", ".", "name", ")", "\n", "args", ".", "writer", "=", "get_writer", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "args", ".", "exp_name", ")", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.utils.__init__.get_config": [[37, 41], ["copy.copy"], "function", ["None"], ["", "def", "get_config", "(", "args", ")", ":", "\n", "    ", "config", "=", "copy", ".", "copy", "(", "args", ")", "\n", "config", ".", "writer", "=", "None", "\n", "return", "config", "\n", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.prepareSlotValuesIndependent": [[25, 132], ["open", "simplejson.load", "open.close", "dic.extend", "dic.extend", "dic.extend", "os.path.join", "ent.items", "dic.append", "open", "simplejson.load", "open.close", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "os.path.join", "ent.items", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "nlp.normalize", "dic.append", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "nlp.normalize", "val.replace.replace", "dic.append", "nlp.normalize", "dic.append", "nlp.normalize", "nlp.normalize", "val.replace.replace", "dic.append", "dic.append", "nlp.normalize", "nlp.normalize", "nlp.normalize", "dic_area.append", "nlp.normalize", "nlp.normalize", "dic_food.append", "nlp.normalize", "dic_price.append", "nlp.normalize", "nlp.normalize"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize"], ["def", "prepareSlotValuesIndependent", "(", ")", ":", "\n", "    ", "domains", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", ",", "'taxi'", ",", "'hospital'", ",", "'police'", "]", "\n", "requestables", "=", "[", "'phone'", ",", "'address'", ",", "'postcode'", ",", "'reference'", ",", "'id'", "]", "\n", "dic", "=", "[", "]", "\n", "dic_area", "=", "[", "]", "\n", "dic_food", "=", "[", "]", "\n", "dic_price", "=", "[", "]", "\n", "\n", "# read databases", "\n", "for", "domain", "in", "domains", ":", "\n", "        ", "try", ":", "\n", "# fin = file(os.path.join(PATH, 'db/' + domain + '_db.json'))", "\n", "            ", "fin", "=", "open", "(", "os", ".", "path", ".", "join", "(", "PATH", ",", "domain", "+", "'_db.json'", ")", ",", "'r'", ")", "\n", "db_json", "=", "json", ".", "load", "(", "fin", ")", "\n", "fin", ".", "close", "(", ")", "\n", "\n", "for", "ent", "in", "db_json", ":", "\n", "                ", "for", "key", ",", "val", "in", "ent", ".", "items", "(", ")", ":", "\n", "                    ", "if", "val", "==", "'?'", "or", "val", "==", "'free'", ":", "\n", "                        ", "pass", "\n", "", "elif", "key", "==", "'address'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "if", "\"road\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"road\"", ",", "\"rd\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"rd\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"rd\"", ",", "\"road\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"st\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"st\"", ",", "\"street\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"street\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"street\"", ",", "\"st\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "", "elif", "key", "==", "'name'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "if", "\"b & b\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"b & b\"", ",", "\"bed and breakfast\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"bed and breakfast\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"bed and breakfast\"", ",", "\"b & b\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"hotel\"", "in", "val", "and", "'gonville'", "not", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"hotel\"", ",", "\"\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"restaurant\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"restaurant\"", ",", "\"\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "", "elif", "key", "==", "'postcode'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'phone'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "val", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'trainID'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'id'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'department'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'department'", "+", "']'", ")", ")", "\n", "\n", "# NORMAL DELEX", "\n", "", "elif", "key", "==", "'area'", ":", "\n", "                        ", "dic_area", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'area'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'food'", ":", "\n", "                        ", "dic_food", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'food'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'pricerange'", ":", "\n", "                        ", "dic_price", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'pricerange'", "+", "']'", ")", ")", "\n", "", "else", ":", "\n", "                        ", "pass", "\n", "# TODO car type?", "\n", "", "", "", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "domain", "==", "'hospital'", ":", "\n", "            ", "dic", ".", "append", "(", "(", "normalize", "(", "'Hills Rd'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'Hills Road'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'CB20QQ'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'01223245151'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'1223245151'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'0122324515'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'Addenbrookes Hospital'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "\n", "", "elif", "domain", "==", "'police'", ":", "\n", "            ", "dic", ".", "append", "(", "(", "normalize", "(", "'Parkside'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'CB11JG'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'01223358966'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'1223358966'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize", "(", "'Parkside Police Station'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "\n", "# add at the end places from trains", "\n", "# fin = open(os.path.join(PATH, 'db/' + 'train' + '_db.json'))", "\n", "", "", "fin", "=", "open", "(", "os", ".", "path", ".", "join", "(", "PATH", ",", "'train'", "+", "'_db.json'", ")", ")", "\n", "db_json", "=", "json", ".", "load", "(", "fin", ")", "\n", "fin", ".", "close", "(", ")", "\n", "\n", "for", "ent", "in", "db_json", ":", "\n", "        ", "for", "key", ",", "val", "in", "ent", ".", "items", "(", ")", ":", "\n", "            ", "if", "key", "==", "'departure'", "or", "key", "==", "'destination'", ":", "\n", "                ", "dic", ".", "append", "(", "(", "normalize", "(", "val", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'place'", "+", "']'", ")", ")", "\n", "\n", "# add specific values:", "\n", "", "", "", "for", "key", "in", "[", "'monday'", ",", "'tuesday'", ",", "'wednesday'", ",", "'thursday'", ",", "'friday'", ",", "'saturday'", ",", "'sunday'", "]", ":", "\n", "        ", "dic", ".", "append", "(", "(", "normalize", "(", "key", ")", ",", "'['", "+", "'value'", "+", "'_'", "+", "'day'", "+", "']'", ")", ")", "\n", "\n", "# more general values add at the end", "\n", "", "dic", ".", "extend", "(", "dic_area", ")", "\n", "dic", ".", "extend", "(", "dic_food", ")", "\n", "dic", ".", "extend", "(", "dic_price", ")", "\n", "\n", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.prepareSlotValuesIndependent_mine": [[134, 242], ["dic.extend", "dic.extend", "dic.extend", "open", "simplejson.load", "open.close", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "os.path.join", "ent.items", "dic.append", "dic.append", "dic.append", "dic.append", "dic.append", "normalize_func", "normalize_func", "normalize_func", "normalize_func", "normalize_func", "normalize_func", "normalize_func", "dic.append", "val.replace.replace", "dic.append", "dic.append", "normalize_func", "val.replace.replace", "dic.append", "val.replace.replace", "dic.append", "dic.append", "normalize_func", "val.replace.replace", "dic.append", "normalize_func", "val.replace.replace", "dic.append", "dic.append", "normalize_func", "val.replace.replace", "dic.append", "normalize_func", "val.replace.replace", "dic.append", "normalize_func", "dic.append", "normalize_func", "normalize_func", "val.replace.replace", "dic.append", "dic.append", "normalize_func", "normalize_func", "normalize_func", "normalize_func", "normalize_func"], "function", ["None"], ["", "def", "prepareSlotValuesIndependent_mine", "(", ")", ":", "\n", "    ", "'''just delex entity names, not price, food or area'''", "\n", "domains", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", ",", "'taxi'", ",", "'hospital'", ",", "'police'", "]", "\n", "requestables", "=", "[", "'phone'", ",", "'address'", ",", "'postcode'", ",", "'reference'", ",", "'id'", "]", "\n", "dic", "=", "[", "]", "\n", "dic_area", "=", "[", "]", "\n", "dic_food", "=", "[", "]", "\n", "dic_price", "=", "[", "]", "\n", "\n", "normalize_func", "=", "normalize_mine", "\n", "# read databases", "\n", "for", "domain", "in", "domains", ":", "\n", "        ", "try", ":", "\n", "# fin = file(os.path.join(PATH, 'db/' + domain + '_db.json'))", "\n", "            ", "fin", "=", "open", "(", "os", ".", "path", ".", "join", "(", "PATH", ",", "domain", "+", "'_db.json'", ")", ",", "'r'", ")", "\n", "db_json", "=", "json", ".", "load", "(", "fin", ")", "\n", "fin", ".", "close", "(", ")", "\n", "\n", "for", "ent", "in", "db_json", ":", "\n", "                ", "for", "key", ",", "val", "in", "ent", ".", "items", "(", ")", ":", "\n", "                    ", "if", "val", "==", "'?'", "or", "val", "==", "'free'", ":", "\n", "                        ", "pass", "\n", "", "elif", "key", "==", "'address'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "if", "\"road\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"road\"", ",", "\"rd\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"rd\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"rd\"", ",", "\"road\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"st\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"st\"", ",", "\"street\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "elif", "\"street\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"street\"", ",", "\"st\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "", "", "elif", "key", "==", "'name'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "if", "\"b & b\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"b & b\"", ",", "\"bed and breakfast\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"bed and breakfast\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"bed and breakfast\"", ",", "\"b & b\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"hotel\"", "in", "val", "and", "'gonville'", "not", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"hotel\"", ",", "\"\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "elif", "\"restaurant\"", "in", "val", ":", "\n", "                            ", "val", "=", "val", ".", "replace", "(", "\"restaurant\"", ",", "\"\"", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "", "", "elif", "key", "==", "'postcode'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'phone'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "val", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'trainID'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'id'", "+", "']'", ")", ")", "\n", "", "elif", "key", "==", "'department'", ":", "\n", "                        ", "dic", ".", "append", "(", "(", "normalize_func", "(", "val", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'department'", "+", "']'", ")", ")", "\n", "\n", "# NORMAL DELEX", "\n", "# elif key == 'area':", "\n", "#     dic_area.append((normalize(val), '[' + 'value' + '_' + 'area' + ']'))", "\n", "# elif key == 'food':", "\n", "#     dic_food.append((normalize(val), '[' + 'value' + '_' + 'food' + ']'))", "\n", "# elif key == 'pricerange':", "\n", "#     dic_price.append((normalize(val), '[' + 'value' + '_' + 'pricerange' + ']'))", "\n", "# else:", "\n", "#     pass", "\n", "# TODO car type?", "\n", "", "", "", "", "except", ":", "\n", "            ", "pass", "\n", "\n", "", "if", "domain", "==", "'hospital'", ":", "\n", "            ", "dic", ".", "append", "(", "(", "normalize_func", "(", "'Hills Rd'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "'Hills Road'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "'CB20QQ'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'01223245151'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'1223245151'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'0122324515'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "'Addenbrookes Hospital'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "\n", "", "elif", "domain", "==", "'police'", ":", "\n", "            ", "dic", ".", "append", "(", "(", "normalize_func", "(", "'Parkside'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'address'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "'CB11JG'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'postcode'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'01223358966'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "'1223358966'", ",", "'['", "+", "domain", "+", "'_'", "+", "'phone'", "+", "']'", ")", ")", "\n", "dic", ".", "append", "(", "(", "normalize_func", "(", "'Parkside Police Station'", ")", ",", "'['", "+", "domain", "+", "'_'", "+", "'name'", "+", "']'", ")", ")", "\n", "\n", "# add at the end places from trains", "\n", "# fin = open(os.path.join(PATH, 'db/' + 'train' + '_db.json'))", "\n", "# db_json = json.load(fin)", "\n", "# fin.close()", "\n", "#", "\n", "# for ent in db_json:", "\n", "#     for key, val in ent.items():", "\n", "#         if key == 'departure' or key == 'destination':", "\n", "#             dic.append((normalize(val), '[' + 'value' + '_' + 'place' + ']'))", "\n", "#", "\n", "# # add specific values:", "\n", "# for key in ['monday', 'tuesday', 'wednesday', 'thursday', 'friday', 'saturday', 'sunday']:", "\n", "#     dic.append((normalize(key), '[' + 'value' + '_' + 'day' + ']'))", "\n", "\n", "# more general values add at the end", "\n", "", "", "dic", ".", "extend", "(", "dic_area", ")", "\n", "dic", ".", "extend", "(", "dic_food", ")", "\n", "dic", ".", "extend", "(", "dic_price", ")", "\n", "\n", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.delexicalise": [[244, 250], ["None"], "function", ["None"], ["", "def", "delexicalise", "(", "utt", ",", "dictionary", ")", ":", "\n", "    ", "for", "key", ",", "val", "in", "dictionary", ":", "\n", "        ", "utt", "=", "(", "' '", "+", "utt", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "utt", "=", "utt", "[", "1", ":", "-", "1", "]", "# why this?", "\n", "\n", "", "return", "utt", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.delexicalize.delexicaliseDomain": [[252, 263], ["None"], "function", ["None"], ["", "def", "delexicaliseDomain", "(", "utt", ",", "dictionary", ",", "domain", ")", ":", "\n", "    ", "for", "key", ",", "val", "in", "dictionary", ":", "\n", "        ", "if", "key", "==", "domain", "or", "key", "==", "'value'", ":", "\n", "            ", "utt", "=", "(", "' '", "+", "utt", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "utt", "=", "utt", "[", "1", ":", "-", "1", "]", "# why this?", "\n", "\n", "# go through rest of domain in case we are missing something out?", "\n", "", "", "for", "key", ",", "val", "in", "dictionary", ":", "\n", "        ", "utt", "=", "(", "' '", "+", "utt", "+", "' '", ")", ".", "replace", "(", "' '", "+", "key", "+", "' '", ",", "' '", "+", "val", "+", "' '", ")", "\n", "utt", "=", "utt", "[", "1", ":", "-", "1", "]", "# why this?", "\n", "", "return", "utt", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.BLEUScorer.__init__": [[495, 497], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.BLEUScorer.score": [[498, 557], ["zip", "math.fsum", "enumerate", "math.exp", "math.exp", "type", "ref.split", "range", "len", "range", "hyp.split", "hyp.split", "collections.Counter", "sum", "dict", "sum", "abs", "float", "float", "math.log", "zip", "nltk.util.ngrams", "collections.Counter.values", "collections.Counter", "dict.values", "len", "float", "float", "nltk.util.ngrams", "max", "len", "len", "max_counts.get", "min", "collections.Counter.items"], "methods", ["None"], ["", "def", "score", "(", "self", ",", "hypothesis", ",", "corpus", ",", "n", "=", "1", ")", ":", "\n", "# containers", "\n", "        ", "count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "clip_count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "r", "=", "0", "\n", "c", "=", "0", "\n", "weights", "=", "[", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", "]", "\n", "\n", "# accumulate ngram statistics", "\n", "for", "hyps", ",", "refs", "in", "zip", "(", "hypothesis", ",", "corpus", ")", ":", "\n", "            ", "if", "type", "(", "hyps", "[", "0", "]", ")", "is", "list", ":", "\n", "                ", "hyps", "=", "[", "hyp", ".", "split", "(", ")", "for", "hyp", "in", "hyps", "[", "0", "]", "]", "\n", "", "else", ":", "\n", "                ", "hyps", "=", "[", "hyp", ".", "split", "(", ")", "for", "hyp", "in", "hyps", "]", "\n", "\n", "", "refs", "=", "[", "ref", ".", "split", "(", ")", "for", "ref", "in", "refs", "]", "\n", "\n", "# Shawn's evaluation", "\n", "refs", "[", "0", "]", "=", "[", "u'GO_'", "]", "+", "refs", "[", "0", "]", "+", "[", "u'EOS_'", "]", "\n", "hyps", "[", "0", "]", "=", "[", "u'GO_'", "]", "+", "hyps", "[", "0", "]", "+", "[", "u'EOS_'", "]", "\n", "\n", "for", "idx", ",", "hyp", "in", "enumerate", "(", "hyps", ")", ":", "\n", "                ", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "# accumulate ngram counts", "\n", "                    ", "hypcnts", "=", "Counter", "(", "ngrams", "(", "hyp", ",", "i", "+", "1", ")", ")", "\n", "cnt", "=", "sum", "(", "hypcnts", ".", "values", "(", ")", ")", "\n", "count", "[", "i", "]", "+=", "cnt", "\n", "\n", "# compute clipped counts", "\n", "max_counts", "=", "{", "}", "\n", "for", "ref", "in", "refs", ":", "\n", "                        ", "refcnts", "=", "Counter", "(", "ngrams", "(", "ref", ",", "i", "+", "1", ")", ")", "\n", "for", "ng", "in", "hypcnts", ":", "\n", "                            ", "max_counts", "[", "ng", "]", "=", "max", "(", "max_counts", ".", "get", "(", "ng", ",", "0", ")", ",", "refcnts", "[", "ng", "]", ")", "\n", "", "", "clipcnt", "=", "dict", "(", "(", "ng", ",", "min", "(", "count", ",", "max_counts", "[", "ng", "]", ")", ")", "for", "ng", ",", "count", "in", "hypcnts", ".", "items", "(", ")", ")", "\n", "clip_count", "[", "i", "]", "+=", "sum", "(", "clipcnt", ".", "values", "(", ")", ")", "\n", "\n", "# accumulate r & c", "\n", "", "bestmatch", "=", "[", "1000", ",", "1000", "]", "\n", "for", "ref", "in", "refs", ":", "\n", "                    ", "if", "bestmatch", "[", "0", "]", "==", "0", ":", "break", "\n", "diff", "=", "abs", "(", "len", "(", "ref", ")", "-", "len", "(", "hyp", ")", ")", "\n", "if", "diff", "<", "bestmatch", "[", "0", "]", ":", "\n", "                        ", "bestmatch", "[", "0", "]", "=", "diff", "\n", "bestmatch", "[", "1", "]", "=", "len", "(", "ref", ")", "\n", "", "", "r", "+=", "bestmatch", "[", "1", "]", "\n", "c", "+=", "len", "(", "hyp", ")", "\n", "if", "n", "==", "1", ":", "\n", "                    ", "break", "\n", "# computing bleu score", "\n", "", "", "", "p0", "=", "1e-7", "\n", "bp", "=", "1", "if", "c", ">", "r", "else", "math", ".", "exp", "(", "1", "-", "float", "(", "r", ")", "/", "float", "(", "c", ")", ")", "\n", "p_ns", "=", "[", "float", "(", "clip_count", "[", "i", "]", ")", "/", "float", "(", "count", "[", "i", "]", "+", "p0", ")", "+", "p0", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "s", "=", "math", ".", "fsum", "(", "w", "*", "math", ".", "log", "(", "p_n", ")", "for", "w", ",", "p_n", "in", "zip", "(", "weights", ",", "p_ns", ")", "if", "p_n", ")", "\n", "bleu", "=", "bp", "*", "math", ".", "exp", "(", "s", ")", "\n", "return", "bleu", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.GentScorer.__init__": [[560, 562], ["nlp.BLEUScorer"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "detectfile", ")", ":", "\n", "        ", "self", ".", "bleuscorer", "=", "BLEUScorer", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.GentScorer.scoreBLEU": [[563, 565], ["nlp.GentScorer.bleuscorer.score"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.BLEUScorer.score"], ["", "def", "scoreBLEU", "(", "self", ",", "parallel_corpus", ")", ":", "\n", "        ", "return", "self", ".", "bleuscorer", ".", "score", "(", "parallel_corpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace": [[19, 36], ["text.find", "re.match", "re.match", "len", "len", "len", "len"], "function", ["None"], ["", "def", "insertSpace", "(", "token", ",", "text", ")", ":", "\n", "    ", "sidx", "=", "0", "\n", "while", "True", ":", "\n", "        ", "sidx", "=", "text", ".", "find", "(", "token", ",", "sidx", ")", "\n", "if", "sidx", "==", "-", "1", ":", "\n", "            ", "break", "\n", "", "if", "sidx", "+", "1", "<", "len", "(", "text", ")", "and", "re", ".", "match", "(", "'[0-9]'", ",", "text", "[", "sidx", "-", "1", "]", ")", "and", "re", ".", "match", "(", "'[0-9]'", ",", "text", "[", "sidx", "+", "1", "]", ")", ":", "\n", "            ", "sidx", "+=", "1", "\n", "continue", "\n", "", "if", "text", "[", "sidx", "-", "1", "]", "!=", "' '", ":", "\n", "            ", "text", "=", "text", "[", ":", "sidx", "]", "+", "' '", "+", "text", "[", "sidx", ":", "]", "\n", "sidx", "+=", "1", "\n", "", "if", "sidx", "+", "len", "(", "token", ")", "<", "len", "(", "text", ")", "and", "text", "[", "sidx", "+", "len", "(", "token", ")", "]", "!=", "' '", ":", "\n", "            ", "text", "=", "text", "[", ":", "sidx", "+", "1", "]", "+", "' '", "+", "text", "[", "sidx", "+", "1", ":", "]", "\n", "", "sidx", "+=", "1", "\n", "", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize": [[38, 120], ["text.replace.lower", "re.sub", "re.sub", "re.sub", "re.findall", "re.findall", "re.sub", "re.sub", "re.sub", "text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "re.sub", "nlp.insertSpace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "text.replace.split", "nlp.insertSpace", "len", "text.replace.find", "text.replace.replace", "text.replace.find", "text.replace.replace", "re.match", "re.match", "text.replace.find", "len", "len", "re.sub"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace"], ["", "def", "normalize", "(", "text", ")", ":", "\n", "# lower case every word", "\n", "    ", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "# replace white spaces in front and end", "\n", "text", "=", "re", ".", "sub", "(", "r'^\\s*|\\s*$'", ",", "''", ",", "text", ")", "\n", "\n", "# hotel domain pfb30", "\n", "text", "=", "re", ".", "sub", "(", "r\"b&b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"b and b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "\n", "# normalize phone number", "\n", "ms", "=", "re", ".", "findall", "(", "'\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4,5})'", ",", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", "[", "0", "]", ",", "sidx", ")", "\n", "if", "text", "[", "sidx", "-", "1", "]", "==", "'('", ":", "\n", "                ", "sidx", "-=", "1", "\n", "", "eidx", "=", "text", ".", "find", "(", "m", "[", "-", "1", "]", ",", "sidx", ")", "+", "len", "(", "m", "[", "-", "1", "]", ")", "\n", "text", "=", "text", ".", "replace", "(", "text", "[", "sidx", ":", "eidx", "]", ",", "''", ".", "join", "(", "m", ")", ")", "\n", "\n", "# normalize postcode", "\n", "", "", "ms", "=", "re", ".", "findall", "(", "'([a-z]{1}[\\. ]?[a-z]{1}[\\. ]?\\d{1,2}[, ]+\\d{1}[\\. ]?[a-z]{1}[\\. ]?[a-z]{1}|[a-z]{2}\\d{2}[a-z]{2})'", ",", "\n", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", ",", "sidx", ")", "\n", "eidx", "=", "sidx", "+", "len", "(", "m", ")", "\n", "text", "=", "text", "[", ":", "sidx", "]", "+", "re", ".", "sub", "(", "'[,\\. ]'", ",", "''", ",", "m", ")", "+", "text", "[", "eidx", ":", "]", "\n", "\n", "# weird unicode bug", "\n", "", "", "text", "=", "re", ".", "sub", "(", "u\"(\\u2018|\\u2019)\"", ",", "\"'\"", ",", "text", ")", "\n", "\n", "# replace time and and price", "\n", "text", "=", "re", ".", "sub", "(", "timepat", ",", "' [value_time] '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "pricepat", ",", "' [value_price] '", ",", "text", ")", "\n", "# text = re.sub(pricepat2, '[value_price]', text)", "\n", "\n", "# replace st.", "\n", "text", "=", "text", ".", "replace", "(", "';'", ",", "','", ")", "\n", "text", "=", "re", ".", "sub", "(", "'$\\/'", ",", "''", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' and '", ")", "\n", "\n", "# replace other special characters", "\n", "text", "=", "text", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "text", "=", "re", ".", "sub", "(", "'[\\\":\\<>@\\(\\)]'", ",", "''", ",", "text", ")", "\n", "\n", "# insert white space before and after tokens:", "\n", "for", "token", "in", "[", "'?'", ",", "'.'", ",", "','", ",", "'!'", "]", ":", "\n", "        ", "text", "=", "insertSpace", "(", "token", ",", "text", ")", "\n", "\n", "# insert white space for 's", "\n", "", "text", "=", "insertSpace", "(", "'\\'s'", ",", "text", ")", "\n", "\n", "# replace it's, does't, you'd ... etc", "\n", "text", "=", "re", ".", "sub", "(", "'^\\''", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'$'", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'\\s'", ",", "' '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\s\\''", ",", "' '", ",", "text", ")", "\n", "for", "fromx", ",", "tox", "in", "replacements", ":", "\n", "        ", "text", "=", "' '", "+", "text", "+", "' '", "\n", "text", "=", "text", ".", "replace", "(", "fromx", ",", "tox", ")", "[", "1", ":", "-", "1", "]", "\n", "\n", "# remove multiple spaces", "\n", "", "text", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "text", ")", "\n", "\n", "# concatenate numbers", "\n", "tmp", "=", "text", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "i", "=", "1", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "        ", "if", "re", ".", "match", "(", "u'^\\d+$'", ",", "tokens", "[", "i", "]", ")", "and", "re", ".", "match", "(", "u'\\d+$'", ",", "tokens", "[", "i", "-", "1", "]", ")", ":", "\n", "            ", "tokens", "[", "i", "-", "1", "]", "+=", "tokens", "[", "i", "]", "\n", "del", "tokens", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "", "", "text", "=", "' '", ".", "join", "(", "tokens", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_for_sql": [[122, 235], ["text.replace.lower", "re.sub", "re.findall", "re.findall", "re.sub", "text.replace.replace", "re.sub", "text.replace.replace", "re.sub", "nlp.insertSpace", "re.sub", "text.replace.split", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "text.replace.replace", "nlp.insertSpace", "len", "text.replace.find", "text.replace.replace", "text.replace.find", "re.match", "re.match", "text.replace.find", "len", "len", "re.sub"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace"], ["", "def", "normalize_for_sql", "(", "text", ")", ":", "\n", "# lower case every word", "\n", "    ", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "# replace white spaces in front and end", "\n", "text", "=", "re", ".", "sub", "(", "r'^\\s*|\\s*$'", ",", "''", ",", "text", ")", "\n", "\n", "# normalize phone number", "\n", "ms", "=", "re", ".", "findall", "(", "'\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4,5})'", ",", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", "[", "0", "]", ",", "sidx", ")", "\n", "if", "text", "[", "sidx", "-", "1", "]", "==", "'('", ":", "\n", "                ", "sidx", "-=", "1", "\n", "", "eidx", "=", "text", ".", "find", "(", "m", "[", "-", "1", "]", ",", "sidx", ")", "+", "len", "(", "m", "[", "-", "1", "]", ")", "\n", "text", "=", "text", ".", "replace", "(", "text", "[", "sidx", ":", "eidx", "]", ",", "''", ".", "join", "(", "m", ")", ")", "\n", "\n", "# normalize postcode", "\n", "", "", "ms", "=", "re", ".", "findall", "(", "'([a-z]{1}[\\. ]?[a-z]{1}[\\. ]?\\d{1,2}[, ]+\\d{1}[\\. ]?[a-z]{1}[\\. ]?[a-z]{1}|[a-z]{2}\\d{2}[a-z]{2})'", ",", "\n", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", ",", "sidx", ")", "\n", "eidx", "=", "sidx", "+", "len", "(", "m", ")", "\n", "text", "=", "text", "[", ":", "sidx", "]", "+", "re", ".", "sub", "(", "'[,\\. ]'", ",", "''", ",", "m", ")", "+", "text", "[", "eidx", ":", "]", "\n", "\n", "# weird unicode bug", "\n", "", "", "text", "=", "re", ".", "sub", "(", "u\"(\\u2018|\\u2019)\"", ",", "\"'\"", ",", "text", ")", "\n", "\n", "# replace time and and price", "\n", "# text = re.sub(timepat, ' [value_time] ', text)", "\n", "# text = re.sub(pricepat, ' [value_price] ', text)", "\n", "# text = re.sub(pricepat2, '[value_price]', text)", "\n", "\n", "# replace st.", "\n", "text", "=", "text", ".", "replace", "(", "';'", ",", "','", ")", "\n", "text", "=", "re", ".", "sub", "(", "'$\\/'", ",", "''", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' and '", ")", "\n", "\n", "# replace other special characters", "\n", "text", "=", "re", ".", "sub", "(", "'[\\\":\\<>@\\(\\)]'", ",", "''", ",", "text", ")", "\n", "\n", "# insert white space before and after tokens:", "\n", "for", "token", "in", "[", "'?'", ",", "'.'", ",", "','", ",", "'!'", "]", ":", "\n", "        ", "text", "=", "insertSpace", "(", "token", ",", "text", ")", "\n", "\n", "# insert white space for 's", "\n", "", "text", "=", "insertSpace", "(", "'\\'s'", ",", "text", ")", "\n", "\n", "# replace it's, does't, you'd ... etc", "\n", "# text = re.sub('^\\'', '', text)", "\n", "# text = re.sub('\\'$', '', text)", "\n", "# text = re.sub('\\'\\s', ' ', text)", "\n", "# text = re.sub('\\s\\'', ' ', text)", "\n", "# for fromx, tox in replacements:", "\n", "#     text = ' ' + text + ' '", "\n", "#     text = text.replace(fromx, tox)[1:-1]", "\n", "\n", "# remove multiple spaces", "\n", "text", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "text", ")", "\n", "\n", "# concatenate numbers", "\n", "tmp", "=", "text", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "i", "=", "1", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "        ", "if", "re", ".", "match", "(", "u'^\\d+$'", ",", "tokens", "[", "i", "]", ")", "and", "re", ".", "match", "(", "u'\\d+$'", ",", "tokens", "[", "i", "-", "1", "]", ")", ":", "\n", "            ", "tokens", "[", "i", "-", "1", "]", "+=", "tokens", "[", "i", "]", "\n", "del", "tokens", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "", "", "text", "=", "' '", ".", "join", "(", "tokens", ")", "\n", "\n", "text", "=", "text", ".", "replace", "(", "'marys'", ",", "r\"mary''s\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'restaurant 17'", ",", "'restaurant one seven'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'christ college'", ",", "r\"christ''s college\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'city centre north bed and breakfast'", ",", "'city centre north b and b'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'cambridge belfry'", ",", "'the cambridge belfry'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'cow pizza kitchen and bar'", ",", "'the cow pizza kitchen and bar'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"peoples portraits exhibition at girton college\"", ",", "r\"people''s portraits exhibition at girton college\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'golden curry'", ",", "'the golden curry'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"shiraz\"", ",", "\"shiraz restaurant\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"queens college\"", ",", "r\"queens'' college\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'alpha milton guest house'", ",", "'alpha-milton guest house'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'cherry hinton village centre'", ",", "'the cherry hinton village centre'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'multiple sports'", ",", "'mutliple sports'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'cambridge chop house'", ",", "'the cambridge chop house'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"cambridge punter\"", ",", "\"the cambridge punter\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"rosas bed and breakfast\"", ",", "r\"rosa''s bed and breakfast\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'el shaddia guesthouse'", ",", "\"el shaddai\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'swimming pool'", ",", "'swimmingpool'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'night club'", ",", "'nightclub'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"nirala\"", ",", "\"the nirala\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"kings college\"", ",", "r\"king''s college\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'copper kettle'", ",", "'the copper kettle'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'cherry hinton village centre'", ",", "'the cherry hinton village centre'", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"kettles yard\"", ",", "r\"kettle''s yard\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"good luck\"", ",", "\"the good luck chinese food takeaway\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"lensfield hotel\"", ",", "\"the lensfield hotel\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"restaurant 2 two\"", ",", "\"restaurant two two\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"churchills college\"", ",", "\"churchill college\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"fitzwilliam museum\"", ",", "\"the fitzwilliam museum\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'cafe uno'", ",", "'caffe uno'", ")", "\n", "text", "=", "text", ".", "replace", "(", "'sheeps green and lammas land park fen causeway'", ",", "\"sheep's green and lammas land park fen causeway\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"cambridge contemporary art museum\"", ",", "\"cambridge contemporary art\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'graffton hotel restaurant'", ",", "\"grafton hotel restaurant\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "\"saint catharine s college\"", ",", "r\"saint catharine''s college\"", ")", "\n", "text", "=", "text", ".", "replace", "(", "'meze bar'", ",", "'meze bar restaurant'", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_mine": [[236, 319], ["text.replace.lower", "re.sub", "re.sub", "re.sub", "re.findall", "re.findall", "re.sub", "text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "re.sub", "nlp.insertSpace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "text.replace.split", "nlp.insertSpace", "len", "text.replace.find", "text.replace.replace", "text.replace.find", "text.replace.replace", "re.match", "re.match", "text.replace.find", "len", "len", "re.sub"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace"], ["", "def", "normalize_mine", "(", "text", ")", ":", "\n", "# lower case every word", "\n", "    ", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "# replace white spaces in front and end", "\n", "text", "=", "re", ".", "sub", "(", "r'^\\s*|\\s*$'", ",", "''", ",", "text", ")", "\n", "\n", "# hotel domain pfb30", "\n", "text", "=", "re", ".", "sub", "(", "r\"b&b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"b and b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "\n", "# normalize phone number", "\n", "ms", "=", "re", ".", "findall", "(", "'\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4,5})'", ",", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", "[", "0", "]", ",", "sidx", ")", "\n", "if", "text", "[", "sidx", "-", "1", "]", "==", "'('", ":", "\n", "                ", "sidx", "-=", "1", "\n", "", "eidx", "=", "text", ".", "find", "(", "m", "[", "-", "1", "]", ",", "sidx", ")", "+", "len", "(", "m", "[", "-", "1", "]", ")", "\n", "text", "=", "text", ".", "replace", "(", "text", "[", "sidx", ":", "eidx", "]", ",", "''", ".", "join", "(", "m", ")", ")", "\n", "\n", "# normalize postcode", "\n", "", "", "ms", "=", "re", ".", "findall", "(", "'([a-z]{1}[\\. ]?[a-z]{1}[\\. ]?\\d{1,2}[, ]+\\d{1}[\\. ]?[a-z]{1}[\\. ]?[a-z]{1}|[a-z]{2}\\d{2}[a-z]{2})'", ",", "\n", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", ",", "sidx", ")", "\n", "eidx", "=", "sidx", "+", "len", "(", "m", ")", "\n", "text", "=", "text", "[", ":", "sidx", "]", "+", "re", ".", "sub", "(", "'[,\\. ]'", ",", "''", ",", "m", ")", "+", "text", "[", "eidx", ":", "]", "\n", "\n", "# weird unicode bug", "\n", "", "", "text", "=", "re", ".", "sub", "(", "u\"(\\u2018|\\u2019)\"", ",", "\"'\"", ",", "text", ")", "\n", "\n", "# replace time and and price", "\n", "# text = re.sub(timepat, ' [value_time] ', text)", "\n", "# text = re.sub(pricepat, ' [value_price] ', text)", "\n", "#text = re.sub(pricepat2, '[value_price]', text)", "\n", "\n", "# replace st.", "\n", "text", "=", "text", ".", "replace", "(", "';'", ",", "','", ")", "\n", "text", "=", "re", ".", "sub", "(", "'$\\/'", ",", "''", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' and '", ")", "\n", "\n", "# replace other special characters", "\n", "text", "=", "text", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "# text = re.sub('[\\\":\\<>@\\(\\)]', '', text)", "\n", "text", "=", "re", ".", "sub", "(", "'[\\\"\\<>@\\(\\)]'", ",", "''", ",", "text", ")", "\n", "\n", "# insert white space before and after tokens:", "\n", "for", "token", "in", "[", "'?'", ",", "'.'", ",", "','", ",", "'!'", "]", ":", "\n", "        ", "text", "=", "insertSpace", "(", "token", ",", "text", ")", "\n", "\n", "# insert white space for 's", "\n", "", "text", "=", "insertSpace", "(", "'\\'s'", ",", "text", ")", "\n", "\n", "# replace it's, does't, you'd ... etc", "\n", "text", "=", "re", ".", "sub", "(", "'^\\''", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'$'", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'\\s'", ",", "' '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\s\\''", ",", "' '", ",", "text", ")", "\n", "for", "fromx", ",", "tox", "in", "replacements", ":", "\n", "        ", "text", "=", "' '", "+", "text", "+", "' '", "\n", "text", "=", "text", ".", "replace", "(", "fromx", ",", "tox", ")", "[", "1", ":", "-", "1", "]", "\n", "\n", "# remove multiple spaces", "\n", "", "text", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "text", ")", "\n", "\n", "# concatenate numbers", "\n", "tmp", "=", "text", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "i", "=", "1", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "        ", "if", "re", ".", "match", "(", "u'^\\d+$'", ",", "tokens", "[", "i", "]", ")", "and", "re", ".", "match", "(", "u'\\d+$'", ",", "tokens", "[", "i", "-", "1", "]", ")", ":", "\n", "            ", "tokens", "[", "i", "-", "1", "]", "+=", "tokens", "[", "i", "]", "\n", "del", "tokens", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "", "", "text", "=", "' '", ".", "join", "(", "tokens", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_lexical": [[321, 404], ["text.replace.lower", "re.sub", "re.sub", "re.sub", "re.findall", "re.findall", "re.sub", "text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "re.sub", "nlp.insertSpace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "text.replace.split", "nlp.insertSpace", "len", "text.replace.find", "text.replace.replace", "text.replace.find", "text.replace.replace", "re.match", "re.match", "text.replace.find", "len", "len", "re.sub"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace"], ["", "def", "normalize_lexical", "(", "text", ")", ":", "\n", "# lower case every word", "\n", "    ", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "# replace white spaces in front and end", "\n", "text", "=", "re", ".", "sub", "(", "r'^\\s*|\\s*$'", ",", "''", ",", "text", ")", "\n", "\n", "# hotel domain pfb30", "\n", "text", "=", "re", ".", "sub", "(", "r\"b&b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"b and b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "\n", "# normalize phone number", "\n", "ms", "=", "re", ".", "findall", "(", "'\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4,5})'", ",", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", "[", "0", "]", ",", "sidx", ")", "\n", "if", "text", "[", "sidx", "-", "1", "]", "==", "'('", ":", "\n", "                ", "sidx", "-=", "1", "\n", "", "eidx", "=", "text", ".", "find", "(", "m", "[", "-", "1", "]", ",", "sidx", ")", "+", "len", "(", "m", "[", "-", "1", "]", ")", "\n", "text", "=", "text", ".", "replace", "(", "text", "[", "sidx", ":", "eidx", "]", ",", "''", ".", "join", "(", "m", ")", ")", "\n", "\n", "# normalize postcode", "\n", "", "", "ms", "=", "re", ".", "findall", "(", "'([a-z]{1}[\\. ]?[a-z]{1}[\\. ]?\\d{1,2}[, ]+\\d{1}[\\. ]?[a-z]{1}[\\. ]?[a-z]{1}|[a-z]{2}\\d{2}[a-z]{2})'", ",", "\n", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", ",", "sidx", ")", "\n", "eidx", "=", "sidx", "+", "len", "(", "m", ")", "\n", "text", "=", "text", "[", ":", "sidx", "]", "+", "re", ".", "sub", "(", "'[,\\. ]'", ",", "''", ",", "m", ")", "+", "text", "[", "eidx", ":", "]", "\n", "\n", "# weird unicode bug", "\n", "", "", "text", "=", "re", ".", "sub", "(", "u\"(\\u2018|\\u2019)\"", ",", "\"'\"", ",", "text", ")", "\n", "\n", "# # replace time and and price", "\n", "# text = re.sub(timepat, ' [value_time] ', text)", "\n", "# text = re.sub(pricepat, ' [value_price] ', text)", "\n", "# #text = re.sub(pricepat2, '[value_price]', text)", "\n", "\n", "# replace st.", "\n", "text", "=", "text", ".", "replace", "(", "';'", ",", "','", ")", "\n", "text", "=", "re", ".", "sub", "(", "'$\\/'", ",", "''", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' and '", ")", "\n", "\n", "# replace other special characters", "\n", "text", "=", "text", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "# text = re.sub('[\\\":\\<>@\\(\\)]', '', text)", "\n", "text", "=", "re", ".", "sub", "(", "'[\\\"\\<>@\\(\\)]'", ",", "''", ",", "text", ")", "\n", "\n", "# insert white space before and after tokens:", "\n", "for", "token", "in", "[", "'?'", ",", "'.'", ",", "','", ",", "'!'", "]", ":", "\n", "        ", "text", "=", "insertSpace", "(", "token", ",", "text", ")", "\n", "\n", "# insert white space for 's", "\n", "", "text", "=", "insertSpace", "(", "'\\'s'", ",", "text", ")", "\n", "\n", "# replace it's, does't, you'd ... etc", "\n", "text", "=", "re", ".", "sub", "(", "'^\\''", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'$'", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'\\s'", ",", "' '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\s\\''", ",", "' '", ",", "text", ")", "\n", "for", "fromx", ",", "tox", "in", "replacements", ":", "\n", "        ", "text", "=", "' '", "+", "text", "+", "' '", "\n", "text", "=", "text", ".", "replace", "(", "fromx", ",", "tox", ")", "[", "1", ":", "-", "1", "]", "\n", "\n", "# remove multiple spaces", "\n", "", "text", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "text", ")", "\n", "\n", "# concatenate numbers", "\n", "tmp", "=", "text", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "i", "=", "1", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "        ", "if", "re", ".", "match", "(", "u'^\\d+$'", ",", "tokens", "[", "i", "]", ")", "and", "re", ".", "match", "(", "u'\\d+$'", ",", "tokens", "[", "i", "-", "1", "]", ")", ":", "\n", "            ", "tokens", "[", "i", "-", "1", "]", "+=", "tokens", "[", "i", "]", "\n", "del", "tokens", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "", "", "text", "=", "' '", ".", "join", "(", "tokens", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize_beliefstate": [[406, 489], ["text.replace.lower", "re.sub", "re.sub", "re.sub", "re.findall", "re.findall", "re.sub", "text.replace.replace", "re.sub", "text.replace.replace", "text.replace.replace", "re.sub", "nlp.insertSpace", "re.sub", "re.sub", "re.sub", "re.sub", "re.sub", "text.replace.split", "nlp.insertSpace", "len", "text.replace.find", "text.replace.replace", "text.replace.find", "text.replace.replace", "re.match", "re.match", "text.replace.find", "len", "len", "re.sub"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.insertSpace"], ["", "def", "normalize_beliefstate", "(", "text", ")", ":", "\n", "# lower case every word", "\n", "    ", "text", "=", "text", ".", "lower", "(", ")", "\n", "\n", "# replace white spaces in front and end", "\n", "text", "=", "re", ".", "sub", "(", "r'^\\s*|\\s*$'", ",", "''", ",", "text", ")", "\n", "\n", "# hotel domain pfb30", "\n", "text", "=", "re", ".", "sub", "(", "r\"b&b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "r\"b and b\"", ",", "\"bed and breakfast\"", ",", "text", ")", "\n", "\n", "# normalize phone number", "\n", "ms", "=", "re", ".", "findall", "(", "'\\(?(\\d{3})\\)?[-.\\s]?(\\d{3})[-.\\s]?(\\d{4,5})'", ",", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", "[", "0", "]", ",", "sidx", ")", "\n", "if", "text", "[", "sidx", "-", "1", "]", "==", "'('", ":", "\n", "                ", "sidx", "-=", "1", "\n", "", "eidx", "=", "text", ".", "find", "(", "m", "[", "-", "1", "]", ",", "sidx", ")", "+", "len", "(", "m", "[", "-", "1", "]", ")", "\n", "text", "=", "text", ".", "replace", "(", "text", "[", "sidx", ":", "eidx", "]", ",", "''", ".", "join", "(", "m", ")", ")", "\n", "\n", "# normalize postcode", "\n", "", "", "ms", "=", "re", ".", "findall", "(", "'([a-z]{1}[\\. ]?[a-z]{1}[\\. ]?\\d{1,2}[, ]+\\d{1}[\\. ]?[a-z]{1}[\\. ]?[a-z]{1}|[a-z]{2}\\d{2}[a-z]{2})'", ",", "\n", "text", ")", "\n", "if", "ms", ":", "\n", "        ", "sidx", "=", "0", "\n", "for", "m", "in", "ms", ":", "\n", "            ", "sidx", "=", "text", ".", "find", "(", "m", ",", "sidx", ")", "\n", "eidx", "=", "sidx", "+", "len", "(", "m", ")", "\n", "text", "=", "text", "[", ":", "sidx", "]", "+", "re", ".", "sub", "(", "'[,\\. ]'", ",", "''", ",", "m", ")", "+", "text", "[", "eidx", ":", "]", "\n", "\n", "# weird unicode bug", "\n", "", "", "text", "=", "re", ".", "sub", "(", "u\"(\\u2018|\\u2019)\"", ",", "\"'\"", ",", "text", ")", "\n", "\n", "# # replace time and and price", "\n", "# text = re.sub(timepat, ' [value_time] ', text)", "\n", "# text = re.sub(pricepat, ' [value_price] ', text)", "\n", "# #text = re.sub(pricepat2, '[value_price]', text)", "\n", "\n", "# replace st.", "\n", "text", "=", "text", ".", "replace", "(", "';'", ",", "','", ")", "\n", "text", "=", "re", ".", "sub", "(", "'$\\/'", ",", "''", ",", "text", ")", "\n", "text", "=", "text", ".", "replace", "(", "'/'", ",", "' and '", ")", "\n", "\n", "# replace other special characters", "\n", "text", "=", "text", ".", "replace", "(", "'-'", ",", "' '", ")", "\n", "# text = re.sub('[\\\":\\<>@\\(\\)]', '', text)", "\n", "text", "=", "re", ".", "sub", "(", "'[\\\"\\<>@\\(\\)]'", ",", "''", ",", "text", ")", "\n", "\n", "# insert white space before and after tokens:", "\n", "for", "token", "in", "[", "'?'", ",", "'.'", ",", "','", ",", "'!'", "]", ":", "\n", "        ", "text", "=", "insertSpace", "(", "token", ",", "text", ")", "\n", "\n", "# insert white space for 's", "\n", "", "text", "=", "insertSpace", "(", "'\\'s'", ",", "text", ")", "\n", "\n", "# replace it's, does't, you'd ... etc", "\n", "text", "=", "re", ".", "sub", "(", "'^\\''", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'$'", ",", "''", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\'\\s'", ",", "' '", ",", "text", ")", "\n", "text", "=", "re", ".", "sub", "(", "'\\s\\''", ",", "' '", ",", "text", ")", "\n", "for", "fromx", ",", "tox", "in", "replacements", ":", "\n", "        ", "text", "=", "' '", "+", "text", "+", "' '", "\n", "text", "=", "text", ".", "replace", "(", "fromx", ",", "tox", ")", "[", "1", ":", "-", "1", "]", "\n", "\n", "# remove multiple spaces", "\n", "", "text", "=", "re", ".", "sub", "(", "' +'", ",", "' '", ",", "text", ")", "\n", "\n", "# concatenate numbers", "\n", "tmp", "=", "text", "\n", "tokens", "=", "text", ".", "split", "(", ")", "\n", "i", "=", "1", "\n", "while", "i", "<", "len", "(", "tokens", ")", ":", "\n", "        ", "if", "re", ".", "match", "(", "u'^\\d+$'", ",", "tokens", "[", "i", "]", ")", "and", "re", ".", "match", "(", "u'\\d+$'", ",", "tokens", "[", "i", "-", "1", "]", ")", ":", "\n", "            ", "tokens", "[", "i", "-", "1", "]", "+=", "tokens", "[", "i", "]", "\n", "del", "tokens", "[", "i", "]", "\n", "", "else", ":", "\n", "            ", "i", "+=", "1", "\n", "", "", "text", "=", "' '", ".", "join", "(", "tokens", ")", "\n", "\n", "return", "text", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.sentence_bleu_4": [[567, 608], ["range", "len", "math.exp", "math.fsum", "collections.Counter", "sum", "dict", "sum", "abs", "math.exp", "nltk.util.ngrams", "collections.Counter.values", "collections.Counter", "dict.values", "len", "abs", "range", "nltk.util.ngrams", "max", "len", "len", "float", "float", "math.log", "zip", "max_counts.get", "min", "collections.Counter.items", "float", "float"], "function", ["None"], ["", "", "def", "sentence_bleu_4", "(", "hyp", ",", "refs", ",", "weights", "=", "[", "0.25", ",", "0.25", ",", "0.25", ",", "0.25", "]", ")", ":", "\n", "# input : single sentence, multiple references", "\n", "    ", "count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "clip_count", "=", "[", "0", ",", "0", ",", "0", ",", "0", "]", "\n", "r", "=", "0", "\n", "c", "=", "0", "\n", "\n", "for", "i", "in", "range", "(", "4", ")", ":", "\n", "        ", "hypcnts", "=", "Counter", "(", "ngrams", "(", "hyp", ",", "i", "+", "1", ")", ")", "\n", "cnt", "=", "sum", "(", "hypcnts", ".", "values", "(", ")", ")", "\n", "count", "[", "i", "]", "+=", "cnt", "\n", "\n", "# compute clipped counts", "\n", "max_counts", "=", "{", "}", "\n", "for", "ref", "in", "refs", ":", "\n", "            ", "refcnts", "=", "Counter", "(", "ngrams", "(", "ref", ",", "i", "+", "1", ")", ")", "\n", "for", "ng", "in", "hypcnts", ":", "\n", "                ", "max_counts", "[", "ng", "]", "=", "max", "(", "max_counts", ".", "get", "(", "ng", ",", "0", ")", ",", "refcnts", "[", "ng", "]", ")", "\n", "", "", "clipcnt", "=", "dict", "(", "(", "ng", ",", "min", "(", "count", ",", "max_counts", "[", "ng", "]", ")", ")", "for", "ng", ",", "count", "in", "hypcnts", ".", "items", "(", ")", ")", "\n", "clip_count", "[", "i", "]", "+=", "sum", "(", "clipcnt", ".", "values", "(", ")", ")", "\n", "\n", "", "bestmatch", "=", "[", "1000", ",", "1000", "]", "\n", "for", "ref", "in", "refs", ":", "\n", "        ", "if", "bestmatch", "[", "0", "]", "==", "0", ":", "\n", "            ", "break", "\n", "", "diff", "=", "abs", "(", "len", "(", "ref", ")", "-", "len", "(", "hyp", ")", ")", "\n", "if", "diff", "<", "bestmatch", "[", "0", "]", ":", "\n", "            ", "bestmatch", "[", "0", "]", "=", "diff", "\n", "bestmatch", "[", "1", "]", "=", "len", "(", "ref", ")", "\n", "", "", "r", "=", "bestmatch", "[", "1", "]", "\n", "c", "=", "len", "(", "hyp", ")", "\n", "\n", "p0", "=", "1e-7", "\n", "bp", "=", "math", ".", "exp", "(", "-", "abs", "(", "1.0", "-", "float", "(", "r", ")", "/", "float", "(", "c", "+", "p0", ")", ")", ")", "\n", "\n", "p_ns", "=", "[", "float", "(", "clip_count", "[", "i", "]", ")", "/", "float", "(", "count", "[", "i", "]", "+", "p0", ")", "+", "p0", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "s", "=", "math", ".", "fsum", "(", "w", "*", "math", ".", "log", "(", "p_n", ")", "for", "w", ",", "p_n", "in", "zip", "(", "weights", ",", "p_ns", ")", "if", "p_n", ")", "\n", "bleu_hyp", "=", "bp", "*", "math", ".", "exp", "(", "s", ")", "\n", "\n", "return", "bleu_hyp", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.convert_dbpointer_to_text": [[20, 97], ["range", "numpy.all", "numpy.all", "numpy.all", "numpy.all", "text.append", "text.append", "numpy.all", "text.append", "text.append", "numpy.array", "numpy.all", "numpy.all", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.array", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "ValueError", "numpy.array", "ValueError", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "convert_dbpointer_to_text", "(", "vect", ",", "goal", ",", "belief", ")", ":", "\n", "    ", "domain_in_pointer", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", "\n", "restaurant_book_vec", "=", "vect", "[", "24", ":", "26", "]", "\n", "hotel_book_vec", "=", "vect", "[", "26", ":", "28", "]", "\n", "train_book_vec", "=", "vect", "[", "28", ":", "]", "\n", "text", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "4", ")", ":", "\n", "        ", "domain", "=", "domains", "[", "idx", "]", "\n", "if", "domain", "not", "in", "goal", ":", "\n", "            ", "continue", "\n", "", "Flag", "=", "False", "\n", "for", "bs", "in", "belief", ":", "\n", "            ", "if", "bs", "[", "0", "]", "==", "domain", ":", "\n", "                ", "Flag", "=", "True", "\n", "", "", "if", "not", "Flag", ":", "# not bstate for domain", "\n", "            ", "continue", "\n", "", "domain_vec", "=", "vect", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "\n", "if", "domain", "!=", "'train'", ":", "\n", "            ", "if", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "0", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "1", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "2", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "3", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "4", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "5", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'invalid domain match'", ")", "\n", "\n", "", "if", "domain_match", ">=", "5", ":", "\n", "                ", "domain_match_text", "=", "'>=5'", "\n", "", "else", ":", "\n", "                ", "domain_match_text", "=", "'={}'", ".", "format", "(", "domain_match", ")", "\n", "", "if", "(", "domain", "==", "'restaurant'", "and", "np", ".", "all", "(", "restaurant_book_vec", "==", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", ")", ")", "or", "(", "domain", "==", "'hotel'", "and", "np", ".", "all", "(", "hotel_book_vec", "==", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", ")", ")", ":", "\n", "                ", "text", ".", "append", "(", "'{} match{} booking=available'", ".", "format", "(", "domain", ",", "domain_match_text", ")", ")", "\n", "", "else", ":", "\n", "                ", "text", ".", "append", "(", "'{} match{} booking=not available'", ".", "format", "(", "domain", ",", "domain_match_text", ")", ")", "\n", "\n", "", "", "else", ":", "# train domain", "\n", "            ", "if", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "0", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "2", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "5", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "10", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "40", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "41", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'invalid domain match'", ")", "\n", "\n", "", "if", "domain_match", "==", "0", ":", "\n", "                ", "domain_match_text", "=", "'=0'", "\n", "", "elif", "domain_match", "==", "2", ":", "\n", "                ", "domain_match_text", "=", "'<3'", "\n", "", "elif", "domain_match", "==", "5", ":", "\n", "                ", "domain_match_text", "=", "'<6'", "\n", "", "elif", "domain_match", "==", "10", ":", "\n", "                ", "domain_match_text", "=", "'<11'", "\n", "", "elif", "domain_match", "==", "40", ":", "\n", "                ", "domain_match_text", "=", "'<41'", "\n", "", "else", ":", "\n", "                ", "domain_match_text", "=", "'>40'", "\n", "\n", "", "if", "np", ".", "all", "(", "train_book_vec", "==", "np", ".", "array", "(", "[", "0", ",", "1", "]", ")", ")", ":", "\n", "                ", "text", ".", "append", "(", "'{} match{} booking=available'", ".", "format", "(", "domain", ",", "domain_match_text", ")", ")", "\n", "", "else", ":", "\n", "                ", "text", ".", "append", "(", "'{} match{} booking=not available'", ".", "format", "(", "domain", ",", "domain_match_text", ")", ")", "\n", "\n", "", "", "", "return", "' , '", ".", "join", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.convert_dbpointer_to_text_nmatch": [[99, 182], ["range", "numpy.all", "text.append", "numpy.all", "text.append", "numpy.all", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "numpy.all", "numpy.array", "ValueError", "numpy.array", "ValueError", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "convert_dbpointer_to_text_nmatch", "(", "vect", ",", "goal", ",", "belief", ")", ":", "\n", "    ", "domain_in_pointer", "=", "[", "'restaurant'", ",", "'hotel'", ",", "'attraction'", ",", "'train'", "]", "\n", "restaurant_book_vec", "=", "vect", "[", "24", ":", "26", "]", "\n", "hotel_book_vec", "=", "vect", "[", "26", ":", "28", "]", "\n", "train_book_vec", "=", "vect", "[", "28", ":", "]", "\n", "text", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "4", ")", ":", "\n", "        ", "domain", "=", "domains", "[", "idx", "]", "\n", "if", "domain", "not", "in", "goal", ":", "\n", "            ", "continue", "\n", "", "Flag", "=", "False", "\n", "for", "bs", "in", "belief", ":", "\n", "            ", "if", "bs", "[", "0", "]", "==", "domain", ":", "\n", "                ", "Flag", "=", "True", "\n", "", "", "if", "not", "Flag", ":", "# not bstate for domain", "\n", "            ", "continue", "\n", "", "domain_vec", "=", "vect", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "\n", "if", "domain", "!=", "'train'", ":", "\n", "            ", "if", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "0", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "1", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "2", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "3", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "4", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "5", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'invalid domain match'", ")", "\n", "\n", "", "if", "domain_match", ">=", "5", ":", "\n", "                ", "domain_match_text", "=", "'>=5'", "\n", "", "else", ":", "\n", "                ", "domain_match_text", "=", "'={}'", ".", "format", "(", "domain_match", ")", "\n", "\n", "", "text", ".", "append", "(", "'{} match{}'", ".", "format", "(", "domain", ",", "domain_match_text", ")", ")", "\n", "\n", "# if (domain == 'restaurant' and np.all(restaurant_book_vec == np.array([0, 1]))) or (domain == 'hotel' and np.all(hotel_book_vec == np.array([0, 1]))):", "\n", "#     # text.append('{} match{} booking=available'.format(domain, domain_match_text))", "\n", "#     text.append('{} match{}'.format(domain, domain_match_text))", "\n", "# else:", "\n", "#     text.append('{} match{} booking=not available'.format(domain, domain_match_text))", "\n", "\n", "", "else", ":", "# train domain", "\n", "            ", "if", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "0", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "2", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "5", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "10", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "40", "\n", "", "elif", "np", ".", "all", "(", "domain_vec", "==", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", ")", ":", "\n", "                ", "domain_match", "=", "41", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", "'invalid domain match'", ")", "\n", "\n", "", "if", "domain_match", "==", "0", ":", "\n", "                ", "domain_match_text", "=", "'=0'", "\n", "", "elif", "domain_match", "==", "2", ":", "\n", "                ", "domain_match_text", "=", "'<3'", "\n", "", "elif", "domain_match", "==", "5", ":", "\n", "                ", "domain_match_text", "=", "'<6'", "\n", "", "elif", "domain_match", "==", "10", ":", "\n", "                ", "domain_match_text", "=", "'<11'", "\n", "", "elif", "domain_match", "==", "40", ":", "\n", "                ", "domain_match_text", "=", "'<41'", "\n", "", "else", ":", "\n", "                ", "domain_match_text", "=", "'>40'", "\n", "\n", "", "text", ".", "append", "(", "'{} match{}'", ".", "format", "(", "domain", ",", "domain_match_text", ")", ")", "\n", "\n", "# if np.all(train_book_vec == np.array([0, 1])):", "\n", "#     text.append('{} match{} booking=available'.format(domain, domain_match_text))", "\n", "# else:", "\n", "#     text.append('{} match{} booking=not available'.format(domain, domain_match_text))", "\n", "\n", "", "", "return", "' , '", ".", "join", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.oneHotVector": [[184, 217], ["domains.index", "domains.index", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "numpy.array"], "function", ["None"], ["", "def", "oneHotVector", "(", "num", ",", "domain", ",", "vector", ")", ":", "\n", "    ", "\"\"\"Return number of available entities for particular domain.\"\"\"", "\n", "number_of_options", "=", "6", "\n", "if", "domain", "!=", "'train'", ":", "\n", "        ", "idx", "=", "domains", ".", "index", "(", "domain", ")", "\n", "if", "num", "==", "0", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "1", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "2", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "3", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "==", "4", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", "\n", "", "elif", "num", ">=", "5", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", "\n", "", "", "else", ":", "\n", "        ", "idx", "=", "domains", ".", "index", "(", "domain", ")", "\n", "if", "num", "==", "0", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "1", ",", "0", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "2", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "1", ",", "0", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "5", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "1", ",", "0", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "10", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "1", ",", "0", ",", "0", "]", ")", "\n", "", "elif", "num", "<=", "40", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "1", ",", "0", "]", ")", "\n", "", "elif", "num", ">", "40", ":", "\n", "            ", "vector", "[", "idx", "*", "6", ":", "idx", "*", "6", "+", "6", "]", "=", "np", ".", "array", "(", "[", "0", ",", "0", ",", "0", ",", "0", ",", "0", ",", "1", "]", ")", "\n", "\n", "", "", "return", "vector", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResult": [[219, 259], ["[].items", "len", "dbs[].execute().fetchall", "val.replace", "val.replace", "dbs[].execute"], "function", ["None"], ["", "def", "queryResult", "(", "domain", ",", "turn", ")", ":", "\n", "    ", "\"\"\"Returns the list of entities for a given domain\n    based on the annotation of the belief state\"\"\"", "\n", "# query the db", "\n", "sql_query", "=", "\"select * from {}\"", ".", "format", "(", "domain", ")", "\n", "\n", "flag", "=", "True", "\n", "#print turn['metadata'][domain]['semi']", "\n", "for", "key", ",", "val", "in", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", ":", "\n", "        ", "if", "val", "==", "\"\"", "or", "val", "==", "\"dont care\"", "or", "val", "==", "'not mentioned'", "or", "val", "==", "\"don't care\"", "or", "val", "==", "\"dontcare\"", "or", "val", "==", "\"do n't care\"", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "flag", ":", "\n", "                ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "#val2 = normalize(val2)", "\n", "# change query for trains", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "#val2 = normalize(val2)", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "#try:  # \"select * from attraction  where name = 'queens college'\"", "\n", "#print sql_query", "\n", "#print domain", "\n", "", "", "", "", "num_entities", "=", "len", "(", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", ")", "\n", "\n", "return", "num_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.dbPointer.queryResultVenues": [[261, 339], ["turn.items", "dbs[].execute().fetchall", "[].items", "val.replace", "nlp.normalize", "val.replace", "nlp.normalize", "dbs[].execute", "slot[].split", "slot[].split", "dbs[].execute().fetchall", "val.replace", "nlp.normalize", "val.replace", "nlp.normalize", "dbs[].execute"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize", "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.nlp.normalize"], ["", "def", "queryResultVenues", "(", "domain", ",", "turn", ",", "real_belief", "=", "False", ")", ":", "\n", "# query the db", "\n", "    ", "sql_query", "=", "\"select * from {}\"", ".", "format", "(", "domain", ")", "\n", "\n", "if", "real_belief", "==", "True", ":", "\n", "        ", "items", "=", "turn", ".", "items", "(", ")", "\n", "", "elif", "real_belief", "==", "'tracking'", ":", "\n", "        ", "for", "slot", "in", "turn", "[", "domain", "]", ":", "\n", "            ", "key", "=", "slot", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "1", "]", "\n", "val", "=", "slot", "[", "0", "]", ".", "split", "(", "\"-\"", ")", "[", "2", "]", "\n", "if", "key", "==", "\"price range\"", ":", "\n", "                ", "key", "=", "\"pricerange\"", "\n", "", "elif", "key", "==", "\"leave at\"", ":", "\n", "                ", "key", "=", "\"leaveAt\"", "\n", "", "elif", "key", "==", "\"arrive by\"", ":", "\n", "                ", "key", "=", "\"arriveBy\"", "\n", "", "if", "val", "==", "\"do n't care\"", ":", "\n", "                ", "pass", "\n", "", "else", ":", "\n", "                ", "if", "flag", ":", "\n", "                    ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                    ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                        ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "", "", "", "try", ":", "# \"select * from attraction  where name = 'queens college'\"", "\n", "                ", "return", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", "\n", "", "except", ":", "\n", "                ", "return", "[", "]", "# TODO test it", "\n", "", "", "pass", "\n", "", "else", ":", "\n", "        ", "items", "=", "turn", "[", "'metadata'", "]", "[", "domain", "]", "[", "'semi'", "]", ".", "items", "(", ")", "\n", "\n", "", "flag", "=", "True", "\n", "for", "key", ",", "val", "in", "items", ":", "\n", "        ", "if", "val", "==", "\"\"", "or", "val", "==", "\"dontcare\"", "or", "val", "==", "'not mentioned'", "or", "val", "==", "\"don't care\"", "or", "val", "==", "\"dont care\"", "or", "val", "==", "\"do n't care\"", ":", "\n", "            ", "pass", "\n", "", "else", ":", "\n", "            ", "if", "flag", ":", "\n", "                ", "sql_query", "+=", "\" where \"", "\n", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "flag", "=", "False", "\n", "", "else", ":", "\n", "                ", "val2", "=", "val", ".", "replace", "(", "\"'\"", ",", "\"''\"", ")", "\n", "val2", "=", "normalize", "(", "val2", ")", "\n", "if", "key", "==", "'leaveAt'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" > \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "elif", "key", "==", "'arriveBy'", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\" < \"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "", "else", ":", "\n", "                    ", "sql_query", "+=", "r\" and \"", "+", "key", "+", "\"=\"", "+", "r\"'\"", "+", "val2", "+", "r\"'\"", "\n", "\n", "", "", "", "", "try", ":", "# \"select * from attraction  where name = 'queens college'\"", "\n", "        ", "return", "dbs", "[", "domain", "]", ".", "execute", "(", "sql_query", ")", ".", "fetchall", "(", ")", "\n", "", "except", ":", "\n", "        ", "return", "[", "]", "# TODO test it", "\n", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.padSequence": [[21, 35], ["max", "len", "enumerate", "torch.LongTensor", "len", "numpy.ones"], "function", ["None"], ["def", "padSequence", "(", "tensor", ")", ":", "\n", "    ", "pad_token", "=", "PAD_token", "\n", "tensor_lengths", "=", "[", "len", "(", "sentence", ")", "for", "sentence", "in", "tensor", "]", "\n", "longest_sent", "=", "max", "(", "tensor_lengths", ")", "\n", "batch_size", "=", "len", "(", "tensor", ")", "\n", "padded_tensor", "=", "np", ".", "ones", "(", "(", "batch_size", ",", "longest_sent", ")", ")", "*", "pad_token", "\n", "\n", "# copy over the actual sequences", "\n", "for", "i", ",", "x_len", "in", "enumerate", "(", "tensor_lengths", ")", ":", "\n", "        ", "sequence", "=", "tensor", "[", "i", "]", "\n", "padded_tensor", "[", "i", ",", "0", ":", "x_len", "]", "=", "sequence", "[", ":", "x_len", "]", "\n", "\n", "", "padded_tensor", "=", "torch", ".", "LongTensor", "(", "padded_tensor", ")", "\n", "return", "padded_tensor", ",", "tensor_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.loadDialogue": [[37, 52], ["enumerate", "zip", "input_tensor.append", "target_tensor.append", "bs_tensor.append", "db_tensor.append", "torch.LongTensor", "torch.LongTensor", "model.input_word2index", "model.output_word2index", "float", "float", "usr.strip().split", "sys.strip().split", "usr.strip", "sys.strip"], "function", ["None"], ["", "def", "loadDialogue", "(", "model", ",", "val_file", ",", "input_tensor", ",", "target_tensor", ",", "bs_tensor", ",", "db_tensor", ")", ":", "\n", "# Iterate over dialogue", "\n", "    ", "for", "idx", ",", "(", "usr", ",", "sys", ",", "bs", ",", "db", ")", "in", "enumerate", "(", "\n", "zip", "(", "val_file", "[", "'usr'", "]", ",", "val_file", "[", "'sys'", "]", ",", "val_file", "[", "'bs'", "]", ",", "val_file", "[", "'db'", "]", ")", ")", ":", "\n", "        ", "tensor", "=", "[", "model", ".", "input_word2index", "(", "word", ")", "for", "word", "in", "usr", ".", "strip", "(", "' '", ")", ".", "split", "(", "' '", ")", "]", "+", "[", "\n", "EOS_token", "]", "# model.input_word2index(word)", "\n", "input_tensor", ".", "append", "(", "torch", ".", "LongTensor", "(", "tensor", ")", ")", "# .view(-1, 1))", "\n", "\n", "tensor", "=", "[", "model", ".", "output_word2index", "(", "word", ")", "for", "word", "in", "sys", ".", "strip", "(", "' '", ")", ".", "split", "(", "' '", ")", "]", "+", "[", "EOS_token", "]", "\n", "target_tensor", ".", "append", "(", "torch", ".", "LongTensor", "(", "tensor", ")", ")", "# .view(-1, 1)", "\n", "\n", "bs_tensor", ".", "append", "(", "[", "float", "(", "belief", ")", "for", "belief", "in", "bs", "]", ")", "\n", "db_tensor", ".", "append", "(", "[", "float", "(", "pointer", ")", "for", "pointer", "in", "db", "]", ")", "\n", "\n", "", "return", "input_tensor", ",", "target_tensor", ",", "bs_tensor", ",", "db_tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.unicode_to_utf8": [[55, 57], ["dict", "key.encode", "d.items"], "function", ["None"], ["", "def", "unicode_to_utf8", "(", "d", ")", ":", "\n", "    ", "return", "dict", "(", "(", "key", ".", "encode", "(", "\"UTF-8\"", ")", ",", "value", ")", "for", "(", "key", ",", "value", ")", "in", "d", ".", "items", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.load_dict": [[59, 66], ["open", "util.unicode_to_utf8", "json.load", "open", "cPickle.load"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.unicode_to_utf8"], ["", "def", "load_dict", "(", "filename", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "unicode_to_utf8", "(", "json", ".", "load", "(", "f", ")", ")", "\n", "", "", "except", ":", "\n", "        ", "with", "open", "(", "filename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "pkl", ".", "load", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.load_config": [[68, 79], ["open", "json.load", "open", "cPickle.load", "sys.stderr.write", "sys.exit"], "function", ["None"], ["", "", "", "def", "load_config", "(", "basename", ")", ":", "\n", "    ", "try", ":", "\n", "        ", "with", "open", "(", "'%s.json'", "%", "basename", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "return", "json", ".", "load", "(", "f", ")", "\n", "", "", "except", ":", "\n", "        ", "try", ":", "\n", "            ", "with", "open", "(", "'%s.pkl'", "%", "basename", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "return", "pkl", ".", "load", "(", "f", ")", "\n", "", "", "except", ":", "\n", "            ", "sys", ".", "stderr", ".", "write", "(", "'Error: config file {0}.json is missing\\n'", ".", "format", "(", "basename", ")", ")", "\n", "sys", ".", "exit", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.str2bool": [[81, 88], ["v.lower", "v.lower", "argparse.ArgumentTypeError"], "function", ["None"], ["", "", "", "def", "str2bool", "(", "v", ")", ":", "\n", "    ", "if", "v", ".", "lower", "(", ")", "in", "(", "'yes'", ",", "'true'", ",", "'t'", ",", "'y'", ",", "'1'", ")", ":", "\n", "        ", "return", "True", "\n", "", "elif", "v", ".", "lower", "(", ")", "in", "(", "'no'", ",", "'false'", ",", "'f'", ",", "'n'", ",", "'0'", ")", ":", "\n", "        ", "return", "False", "\n", "", "else", ":", "\n", "        ", "raise", "argparse", ".", "ArgumentTypeError", "(", "'Boolean value expected.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.asMinutes": [[90, 94], ["math.floor"], "function", ["None"], ["", "", "def", "asMinutes", "(", "s", ")", ":", "\n", "    ", "m", "=", "math", ".", "floor", "(", "s", "/", "60", ")", "\n", "s", "-=", "m", "*", "60", "\n", "return", "'%dm %ds'", "%", "(", "m", ",", "s", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.timeSince": [[96, 100], ["time.time", "util.asMinutes"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.multiwoz.util.asMinutes"], ["", "def", "timeSince", "(", "since", ",", "percent", ")", ":", "\n", "    ", "now", "=", "time", ".", "time", "(", ")", "\n", "s", "=", "now", "-", "since", "\n", "return", "'%s '", "%", "(", "asMinutes", "(", "s", ")", ")", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2Config.__init__": [[120, 163], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "12", ",", "\n", "n_head", "=", "12", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "bos_token_id", "=", "50256", ",", "\n", "eos_token_id", "=", "50256", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n", "self", ".", "bos_token_id", "=", "bos_token_id", "\n", "self", ".", "eos_token_ids", "=", "[", "eos_token_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2Config.max_position_embeddings": [[164, 167], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2Config.hidden_size": [[168, 171], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2Config.num_attention_heads": [[172, 175], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2Config.num_hidden_layers": [[176, 179], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2SmallConfig.__init__": [[266, 309], ["configuration_utils.PretrainedConfig.__init__"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "\n", "self", ",", "\n", "vocab_size", "=", "50257", ",", "\n", "n_positions", "=", "1024", ",", "\n", "n_ctx", "=", "1024", ",", "\n", "n_embd", "=", "768", ",", "\n", "n_layer", "=", "6", ",", "\n", "n_head", "=", "12", ",", "\n", "resid_pdrop", "=", "0.1", ",", "\n", "embd_pdrop", "=", "0.1", ",", "\n", "attn_pdrop", "=", "0.1", ",", "\n", "layer_norm_epsilon", "=", "1e-5", ",", "\n", "initializer_range", "=", "0.02", ",", "\n", "summary_type", "=", "\"cls_index\"", ",", "\n", "summary_use_proj", "=", "True", ",", "\n", "summary_activation", "=", "None", ",", "\n", "summary_proj_to_labels", "=", "True", ",", "\n", "summary_first_dropout", "=", "0.1", ",", "\n", "bos_token_id", "=", "50256", ",", "\n", "eos_token_id", "=", "50256", ",", "\n", "**", "kwargs", "\n", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "**", "kwargs", ")", "\n", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "n_ctx", "=", "n_ctx", "\n", "self", ".", "n_positions", "=", "n_positions", "\n", "self", ".", "n_embd", "=", "n_embd", "\n", "self", ".", "n_layer", "=", "n_layer", "\n", "self", ".", "n_head", "=", "n_head", "\n", "self", ".", "resid_pdrop", "=", "resid_pdrop", "\n", "self", ".", "embd_pdrop", "=", "embd_pdrop", "\n", "self", ".", "attn_pdrop", "=", "attn_pdrop", "\n", "self", ".", "layer_norm_epsilon", "=", "layer_norm_epsilon", "\n", "self", ".", "initializer_range", "=", "initializer_range", "\n", "self", ".", "summary_type", "=", "summary_type", "\n", "self", ".", "summary_use_proj", "=", "summary_use_proj", "\n", "self", ".", "summary_activation", "=", "summary_activation", "\n", "self", ".", "summary_first_dropout", "=", "summary_first_dropout", "\n", "self", ".", "summary_proj_to_labels", "=", "summary_proj_to_labels", "\n", "\n", "self", ".", "bos_token_id", "=", "bos_token_id", "\n", "self", ".", "eos_token_ids", "=", "[", "eos_token_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2SmallConfig.max_position_embeddings": [[310, 313], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "max_position_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_positions", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2SmallConfig.hidden_size": [[314, 317], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "hidden_size", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_embd", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2SmallConfig.num_attention_heads": [[318, 321], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_attention_heads", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_head", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_gpt2.GPT2SmallConfig.num_hidden_layers": [[322, 325], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "num_hidden_layers", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "n_layer", "", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.__init__": [[100, 117], ["torch.Module.__init__", "modeling_gpt2.Attention.register_buffer", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "set", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril().view", "torch.tril", "torch.tril", "torch.tril", "torch.tril", "torch.ones", "torch.ones", "torch.ones", "torch.ones"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nx", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "n_state", "=", "nx", "# in Attention: n_state=768 (nx=n_embd)", "\n", "# [switch nx => n_state from Block to Attention to keep identical to TF implem]", "\n", "assert", "n_state", "%", "config", ".", "n_head", "==", "0", "\n", "self", ".", "register_buffer", "(", "\"bias\"", ",", "torch", ".", "tril", "(", "torch", ".", "ones", "(", "n_ctx", ",", "n_ctx", ")", ")", ".", "view", "(", "1", ",", "1", ",", "n_ctx", ",", "n_ctx", ")", ")", "\n", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "split_size", "=", "n_state", "\n", "self", ".", "scale", "=", "scale", "\n", "\n", "self", ".", "c_attn", "=", "Conv1D", "(", "n_state", "*", "3", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "attn_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "attn_pdrop", ")", "\n", "self", ".", "resid_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "self", ".", "pruned_heads", "=", "set", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.prune_heads": [[118, 139], ["torch.ones", "torch.ones", "torch.ones", "torch.ones", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous().eq", "[].long", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_utils.prune_conv1d_layer", "modeling_utils.prune_conv1d_layer", "modeling_gpt2.Attention.pruned_heads.union", "len", "set", "len", "sum", "mask.view().contiguous().eq.view().contiguous().eq.view().contiguous", "len", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "mask.view().contiguous().eq.view().contiguous().eq.view", "len"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.prune_conv1d_layer", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "if", "len", "(", "heads", ")", "==", "0", ":", "\n", "            ", "return", "\n", "", "mask", "=", "torch", ".", "ones", "(", "self", ".", "n_head", ",", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "\n", "heads", "=", "set", "(", "heads", ")", "-", "self", ".", "pruned_heads", "# Convert to set and emove already pruned heads", "\n", "for", "head", "in", "heads", ":", "\n", "# Compute how many pruned heads are before the head and move the index accordingly", "\n", "            ", "head", "=", "head", "-", "sum", "(", "1", "if", "h", "<", "head", "else", "0", "for", "h", "in", "self", ".", "pruned_heads", ")", "\n", "mask", "[", "head", "]", "=", "0", "\n", "", "mask", "=", "mask", ".", "view", "(", "-", "1", ")", ".", "contiguous", "(", ")", ".", "eq", "(", "1", ")", "\n", "index", "=", "torch", ".", "arange", "(", "len", "(", "mask", ")", ")", "[", "mask", "]", ".", "long", "(", ")", "\n", "index_attn", "=", "torch", ".", "cat", "(", "[", "index", ",", "index", "+", "self", ".", "split_size", ",", "index", "+", "(", "2", "*", "self", ".", "split_size", ")", "]", ")", "\n", "\n", "# Prune conv1d layers", "\n", "self", ".", "c_attn", "=", "prune_conv1d_layer", "(", "self", ".", "c_attn", ",", "index_attn", ",", "dim", "=", "1", ")", "\n", "self", ".", "c_proj", "=", "prune_conv1d_layer", "(", "self", ".", "c_proj", ",", "index", ",", "dim", "=", "0", ")", "\n", "\n", "# Update hyper params", "\n", "self", ".", "split_size", "=", "(", "self", ".", "split_size", "//", "self", ".", "n_head", ")", "*", "(", "self", ".", "n_head", "-", "len", "(", "heads", ")", ")", "\n", "self", ".", "n_head", "=", "self", ".", "n_head", "-", "len", "(", "heads", ")", "\n", "self", ".", "pruned_heads", "=", "self", ".", "pruned_heads", ".", "union", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention._attn": [[140, 163], ["torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "modeling_gpt2.Attention.attn_dropout", "modeling_gpt2.Attention.size", "modeling_gpt2.Attention.size", "torch.Softmax", "torch.Softmax", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "outputs.append", "math.sqrt", "v.size"], "methods", ["None"], ["", "def", "_attn", "(", "self", ",", "q", ",", "k", ",", "v", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "w", "=", "torch", ".", "matmul", "(", "q", ",", "k", ")", "\n", "if", "self", ".", "scale", ":", "\n", "            ", "w", "=", "w", "/", "math", ".", "sqrt", "(", "v", ".", "size", "(", "-", "1", ")", ")", "\n", "", "nd", ",", "ns", "=", "w", ".", "size", "(", "-", "2", ")", ",", "w", ".", "size", "(", "-", "1", ")", "\n", "b", "=", "self", ".", "bias", "[", ":", ",", ":", ",", "ns", "-", "nd", ":", "ns", ",", ":", "ns", "]", "\n", "w", "=", "w", "*", "b", "-", "1e4", "*", "(", "1", "-", "b", ")", "\n", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "# Apply the attention mask", "\n", "            ", "w", "=", "w", "+", "attention_mask", "\n", "\n", "", "w", "=", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "(", "w", ")", "\n", "w", "=", "self", ".", "attn_dropout", "(", "w", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "w", "=", "w", "*", "head_mask", "\n", "\n", "", "outputs", "=", "[", "torch", ".", "matmul", "(", "w", ",", "v", ")", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", ".", "append", "(", "w", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.merge_heads": [[164, 168], ["x.permute().contiguous.permute().contiguous.permute().contiguous", "x.permute().contiguous.permute().contiguous.view", "x.permute().contiguous.permute().contiguous.permute", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size", "x.permute().contiguous.permute().contiguous.size"], "methods", ["None"], ["", "def", "merge_heads", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", ".", "contiguous", "(", ")", "\n", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "2", "]", "+", "(", "x", ".", "size", "(", "-", "2", ")", "*", "x", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "return", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct merge_states", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.split_heads": [[169, 176], ["x.view.view.view", "x.view.view.permute", "x.view.view.permute", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "split_heads", "(", "self", ",", "x", ",", "k", "=", "False", ")", ":", "\n", "        ", "new_x_shape", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "n_head", ",", "x", ".", "size", "(", "-", "1", ")", "//", "self", ".", "n_head", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "new_x_shape", ")", "# in Tensorflow implem: fct split_states", "\n", "if", "k", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "3", ",", "1", ")", "# (batch, head, head_features, seq_length)", "\n", "", "else", ":", "\n", "            ", "return", "x", ".", "permute", "(", "0", ",", "2", ",", "1", ",", "3", ")", "# (batch, head, seq_length, head_features)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.forward": [[177, 198], ["modeling_gpt2.Attention.c_attn", "modeling_gpt2.Attention.split", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "modeling_gpt2.Attention.split_heads", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "modeling_gpt2.Attention._attn", "modeling_gpt2.Attention.merge_heads", "modeling_gpt2.Attention.c_proj", "modeling_gpt2.Attention.resid_dropout", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "layer_past[].transpose", "torch.cat.transpose", "torch.cat.transpose"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.split_heads", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention._attn", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Attention.merge_heads"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "x", "=", "self", ".", "c_attn", "(", "x", ")", "\n", "query", ",", "key", ",", "value", "=", "x", ".", "split", "(", "self", ".", "split_size", ",", "dim", "=", "2", ")", "\n", "query", "=", "self", ".", "split_heads", "(", "query", ")", "\n", "key", "=", "self", ".", "split_heads", "(", "key", ",", "k", "=", "True", ")", "\n", "value", "=", "self", ".", "split_heads", "(", "value", ")", "\n", "if", "layer_past", "is", "not", "None", ":", "\n", "            ", "past_key", ",", "past_value", "=", "layer_past", "[", "0", "]", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "layer_past", "[", "1", "]", "# transpose back cf below", "\n", "key", "=", "torch", ".", "cat", "(", "(", "past_key", ",", "key", ")", ",", "dim", "=", "-", "1", ")", "\n", "value", "=", "torch", ".", "cat", "(", "(", "past_value", ",", "value", ")", ",", "dim", "=", "-", "2", ")", "\n", "", "present", "=", "torch", ".", "stack", "(", "(", "key", ".", "transpose", "(", "-", "2", ",", "-", "1", ")", ",", "value", ")", ")", "# transpose to have same shapes for stacking", "\n", "\n", "attn_outputs", "=", "self", ".", "_attn", "(", "query", ",", "key", ",", "value", ",", "attention_mask", ",", "head_mask", ")", "\n", "a", "=", "attn_outputs", "[", "0", "]", "\n", "\n", "a", "=", "self", ".", "merge_heads", "(", "a", ")", "\n", "a", "=", "self", ".", "c_proj", "(", "a", ")", "\n", "a", "=", "self", ".", "resid_dropout", "(", "a", ")", "\n", "\n", "outputs", "=", "[", "a", ",", "present", "]", "+", "attn_outputs", "[", "1", ":", "]", "\n", "return", "outputs", "# a, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.MLP.__init__": [[201, 208], ["torch.Module.__init__", "modeling_utils.Conv1D", "modeling_utils.Conv1D", "torch.Dropout", "torch.Dropout"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_state", ",", "config", ")", ":", "# in MLP: n_state=3072 (4 * n_embd)", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "c_fc", "=", "Conv1D", "(", "n_state", ",", "nx", ")", "\n", "self", ".", "c_proj", "=", "Conv1D", "(", "nx", ",", "n_state", ")", "\n", "self", ".", "act", "=", "gelu_new", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "resid_pdrop", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.MLP.forward": [[209, 213], ["modeling_gpt2.MLP.act", "modeling_gpt2.MLP.c_proj", "modeling_gpt2.MLP.dropout", "modeling_gpt2.MLP.c_fc"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "h", "=", "self", ".", "act", "(", "self", ".", "c_fc", "(", "x", ")", ")", "\n", "h2", "=", "self", ".", "c_proj", "(", "h", ")", "\n", "return", "self", ".", "dropout", "(", "h2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Block.__init__": [[216, 223], ["torch.Module.__init__", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.Attention", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.MLP"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "n_ctx", ",", "config", ",", "scale", "=", "False", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "nx", "=", "config", ".", "n_embd", "\n", "self", ".", "ln_1", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "attn", "=", "Attention", "(", "nx", ",", "n_ctx", ",", "config", ",", "scale", ")", "\n", "self", ".", "ln_2", "=", "nn", ".", "LayerNorm", "(", "nx", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "self", ".", "mlp", "=", "MLP", "(", "4", "*", "nx", ",", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.Block.forward": [[224, 236], ["modeling_gpt2.Block.attn", "modeling_gpt2.Block.mlp", "modeling_gpt2.Block.ln_1", "modeling_gpt2.Block.ln_2"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ",", "layer_past", "=", "None", ",", "attention_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "output_attn", "=", "self", ".", "attn", "(", "\n", "self", ".", "ln_1", "(", "x", ")", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "\n", ")", "\n", "a", "=", "output_attn", "[", "0", "]", "# output_attn: a, present, (attentions)", "\n", "\n", "x", "=", "x", "+", "a", "\n", "m", "=", "self", ".", "mlp", "(", "self", ".", "ln_2", "(", "x", ")", ")", "\n", "x", "=", "x", "+", "m", "\n", "\n", "outputs", "=", "[", "x", "]", "+", "output_attn", "[", "1", ":", "]", "\n", "return", "outputs", "# x, present, (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2PreTrainedModel.__init__": [[248, 250], ["modeling_utils.PreTrainedModel.__init__"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "self", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "inputs", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2PreTrainedModel._init_weights": [[251, 263], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_"], "methods", ["None"], ["", "def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ",", "Conv1D", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "Conv1D", ")", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "nn", ".", "LayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2Model.__init__": [[329, 342], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.ModuleList", "torch.ModuleList", "torch.LayerNorm", "torch.LayerNorm", "modeling_gpt2.GPT2Model.init_weights", "modeling_gpt2.Block", "range"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "wte", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "wpe", "=", "nn", ".", "Embedding", "(", "config", ".", "n_positions", ",", "config", ".", "n_embd", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "config", ".", "embd_pdrop", ")", "\n", "self", ".", "h", "=", "nn", ".", "ModuleList", "(", "[", "Block", "(", "config", ".", "n_ctx", ",", "config", ",", "scale", "=", "True", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "ln_f", "=", "nn", ".", "LayerNorm", "(", "config", ".", "n_embd", ",", "eps", "=", "config", ".", "layer_norm_epsilon", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2Model.get_input_embeddings": [[343, 345], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "wte", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2Model.set_input_embeddings": [[346, 348], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "wte", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2Model._prune_heads": [[349, 355], ["heads_to_prune.items", "modeling_gpt2.GPT2Model.h[].attn.prune_heads"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.prune_heads"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the model.\n            heads_to_prune: dict of {layer_num: list of heads to prune in this layer}\n        \"\"\"", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "self", ".", "h", "[", "layer", "]", ".", "attn", ".", "prune_heads", "(", "heads", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2Model.forward": [[356, 510], ["file_utils.add_start_docstrings_to_callable", "modeling_gpt2.GPT2Model.wpe", "modeling_gpt2.GPT2Model.drop", "enumerate", "modeling_gpt2.GPT2Model.ln_f", "hidden_states.view.view.view", "ValueError", "token_type_ids.view.view.view", "position_ids.unsqueeze().view.unsqueeze().view.view", "[].size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze().view", "attention_mask.to.to.view", "attention_mask.to.to.unsqueeze().unsqueeze", "attention_mask.to.to.to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "modeling_gpt2.GPT2Model.wte", "modeling_gpt2.GPT2Model.wte", "zip", "block", "tuple", "input_ids.view.view.size", "input_ids.view.view.view", "len", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "hidden_states.view.view.size", "tuple.append", "ValueError", "position_ids.unsqueeze().view.unsqueeze().view.unsqueeze", "attention_mask.to.to.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "t.view", "modeling_gpt2.GPT2Model.size", "next", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "hidden_states.view.view.view", "modeling_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_gpt2.GPT2Model.parameters", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.add_start_docstrings_to_callable"], ["", "", "@", "add_start_docstrings_to_callable", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n    Return:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.GPT2Config`) and inputs:\n        last_hidden_state (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, hidden_size)`):\n            Sequence of hidden-states at the last layer of the model.\n        past (:obj:`List[torch.FloatTensor]` of length :obj:`config.n_layers` with each tensor of shape :obj:`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`):\n            Contains pre-computed hidden-states (key and values in the attention blocks).\n            Can be used (see `past` input) to speed up sequential decoding. The token ids which have their past given to this model\n            should not be passed as input ids as they have already been computed.\n        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n\n    Examples::\n\n        from transformers import GPT2Tokenizer, GPT2Model\n        import torch\n\n        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n        model = GPT2Model.from_pretrained('gpt2')\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids)\n        last_hidden_states = outputs[0]  # The last hidden-state is the first element of the output tuple\n\n        \"\"\"", "\n", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "", "if", "position_ids", "is", "not", "None", ":", "\n", "            ", "position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "", "if", "past", "is", "None", ":", "\n", "            ", "past_length", "=", "0", "\n", "past", "=", "[", "None", "]", "*", "len", "(", "self", ".", "h", ")", "\n", "", "else", ":", "\n", "            ", "past_length", "=", "past", "[", "0", "]", "[", "0", "]", ".", "size", "(", "-", "2", ")", "\n", "", "if", "position_ids", "is", "None", ":", "\n", "            ", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "position_ids", "=", "torch", ".", "arange", "(", "past_length", ",", "input_shape", "[", "-", "1", "]", "+", "past_length", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "view", "(", "-", "1", ",", "input_shape", "[", "-", "1", "]", ")", "\n", "\n", "# Attention mask.", "\n", "", "if", "attention_mask", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "\n", "attention_mask", "=", "attention_mask", ".", "view", "(", "batch_size", ",", "-", "1", ")", "\n", "# We create a 3D attention mask from a 2D tensor mask.", "\n", "# Sizes are [batch_size, 1, 1, to_seq_length]", "\n", "# So we can broadcast to [batch_size, num_heads, from_seq_length, to_seq_length]", "\n", "# this attention mask is more simple than the triangular masking of causal attention", "\n", "# used in OpenAI GPT, we just need to prepare the broadcast dimension here.", "\n", "attention_mask", "=", "attention_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "\n", "# Since attention_mask is 1.0 for positions we want to attend and 0.0 for", "\n", "# masked positions, this operation will create a tensor which is 0.0 for", "\n", "# positions we want to attend and -10000.0 for masked positions.", "\n", "# Since we are adding it to the raw scores before the softmax, this is", "\n", "# effectively the same as removing these entirely.", "\n", "attention_mask", "=", "attention_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# fp16 compatibility", "\n", "attention_mask", "=", "(", "1.0", "-", "attention_mask", ")", "*", "-", "10000.0", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# head_mask has shape n_layer x batch x n_heads x N x N", "\n", "", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "config", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "(", "\n", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", ")", "# We can specify head_mask for each layer", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "\n", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "config", ".", "n_layer", "\n", "\n", "", "if", "inputs_embeds", "is", "None", ":", "\n", "            ", "inputs_embeds", "=", "self", ".", "wte", "(", "input_ids", ")", "\n", "", "position_embeds", "=", "self", ".", "wpe", "(", "position_ids", ")", "\n", "if", "token_type_ids", "is", "not", "None", ":", "\n", "            ", "token_type_embeds", "=", "self", ".", "wte", "(", "token_type_ids", ")", "\n", "", "else", ":", "\n", "            ", "token_type_embeds", "=", "0", "\n", "", "hidden_states", "=", "inputs_embeds", "+", "position_embeds", "+", "token_type_embeds", "\n", "hidden_states", "=", "self", ".", "drop", "(", "hidden_states", ")", "\n", "\n", "output_shape", "=", "input_shape", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", "\n", "\n", "presents", "=", "(", ")", "\n", "all_attentions", "=", "[", "]", "\n", "all_hidden_states", "=", "(", ")", "\n", "for", "i", ",", "(", "block", ",", "layer_past", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "h", ",", "past", ")", ")", ":", "\n", "            ", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ".", "view", "(", "*", "output_shape", ")", ",", ")", "\n", "\n", "", "outputs", "=", "block", "(", "\n", "hidden_states", ",", "layer_past", "=", "layer_past", ",", "attention_mask", "=", "attention_mask", ",", "head_mask", "=", "head_mask", "[", "i", "]", "\n", ")", "\n", "\n", "hidden_states", ",", "present", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_past", ":", "\n", "                ", "presents", "=", "presents", "+", "(", "present", ",", ")", "\n", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "                ", "all_attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "", "", "hidden_states", "=", "self", ".", "ln_f", "(", "hidden_states", ")", "\n", "\n", "hidden_states", "=", "hidden_states", ".", "view", "(", "*", "output_shape", ")", "\n", "# Add last hidden state", "\n", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "all_hidden_states", "=", "all_hidden_states", "+", "(", "hidden_states", ",", ")", "\n", "\n", "", "outputs", "=", "(", "hidden_states", ",", ")", "\n", "if", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "presents", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "all_hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "# let the number of heads free (-1) so we can extract attention even after head pruning", "\n", "            ", "attention_output_shape", "=", "input_shape", "[", ":", "-", "1", "]", "+", "(", "-", "1", ",", ")", "+", "all_attentions", "[", "0", "]", ".", "shape", "[", "-", "2", ":", "]", "\n", "all_attentions", "=", "tuple", "(", "t", ".", "view", "(", "*", "attention_output_shape", ")", "for", "t", "in", "all_attentions", ")", "\n", "outputs", "=", "outputs", "+", "(", "all_attentions", ",", ")", "\n", "", "return", "outputs", "# last hidden state, (presents), (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2LMHeadModel.__init__": [[518, 524], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_gpt2.GPT2LMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2LMHeadModel.get_output_embeddings": [[525, 527], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2LMHeadModel.prepare_inputs_for_generation": [[528, 534], ["input_ids[].unsqueeze"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "past", ",", "**", "kwargs", ")", ":", "\n", "# only last token for inputs_ids if past is defined in kwargs", "\n", "        ", "if", "past", ":", "\n", "            ", "input_ids", "=", "input_ids", "[", ":", ",", "-", "1", "]", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "", "return", "{", "\"input_ids\"", ":", "input_ids", ",", "\"past\"", ":", "past", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2LMHeadModel.forward": [[535, 614], ["file_utils.add_start_docstrings_to_callable", "modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.add_start_docstrings_to_callable"], ["", "@", "add_start_docstrings_to_callable", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n            Labels for language modeling.\n            Note that the labels **are shifted** inside the model, i.e. you can set ``lm_labels = input_ids``\n            Indices are selected in ``[-100, 0, ..., config.vocab_size]``\n            All labels set to ``-100`` are ignored (masked), the loss is only\n            computed for labels in ``[0, ..., config.vocab_size]``\n\n    Return:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.GPT2Config`) and inputs:\n        loss (:obj:`torch.FloatTensor` of shape `(1,)`, `optional`, returned when ``labels`` is provided)\n            Language modeling loss.\n        prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`):\n            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n        past (:obj:`List[torch.FloatTensor]` of length :obj:`config.n_layers` with each tensor of shape :obj:`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`):\n            Contains pre-computed hidden-states (key and values in the attention blocks).\n            Can be used (see `past` input) to speed up sequential decoding. The token ids which have their past given to this model\n            should not be passed as input ids as they have already been computed.\n        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n\n    Examples::\n\n        import torch\n        from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\n        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n        model = GPT2LMHeadModel.from_pretrained('gpt2')\n\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids, labels=input_ids)\n        loss, logits = outputs[:2]\n\n        \"\"\"", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2LMHeadModel.forward_task_mask": [[615, 699], ["file_utils.add_start_docstrings_to_callable", "modeling_gpt2.GPT2LMHeadModel.transformer", "modeling_gpt2.GPT2LMHeadModel.lm_head", "lm_logits[].contiguous", "labels[].contiguous", "task_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous.view", "task_labels[].contiguous.view", "lm_logits[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.add_start_docstrings_to_callable"], ["", "@", "add_start_docstrings_to_callable", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "def", "forward_task_mask", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "labels", "=", "None", ",", "\n", "task_labels", "=", "None", ",", "\n", "ignore_index", "=", "-", "1", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`):\n            Labels for language modeling.\n            Note that the labels **are shifted** inside the model, i.e. you can set ``lm_labels = input_ids``\n            Indices are selected in ``[-100, 0, ..., config.vocab_size]``\n            All labels set to ``-100`` are ignored (masked), the loss is only\n            computed for labels in ``[0, ..., config.vocab_size]``\n\n    Return:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.GPT2Config`) and inputs:\n        loss (:obj:`torch.FloatTensor` of shape `(1,)`, `optional`, returned when ``labels`` is provided)\n            Language modeling loss.\n        prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, sequence_length, config.vocab_size)`):\n            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n        past (:obj:`List[torch.FloatTensor]` of length :obj:`config.n_layers` with each tensor of shape :obj:`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`):\n            Contains pre-computed hidden-states (key and values in the attention blocks).\n            Can be used (see `past` input) to speed up sequential decoding. The token ids which have their past given to this model\n            should not be passed as input ids as they have already been computed.\n        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n\n    Examples::\n\n        import torch\n        from transformers import GPT2Tokenizer, GPT2LMHeadModel\n\n        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n        model = GPT2LMHeadModel.from_pretrained('gpt2')\n\n        input_ids = torch.tensor(tokenizer.encode(\"Hello, my dog is cute\", add_special_tokens=True)).unsqueeze(0)  # Batch size 1\n        outputs = model(input_ids, labels=input_ids)\n        loss, logits = outputs[:2]\n\n        \"\"\"", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "\n", "# import ipdb", "\n", "# ipdb.set_trace()", "\n", "outputs", "=", "(", "lm_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Shift so that tokens < n predict n", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_task_labels", "=", "task_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "# Flatten the tokens", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignore_index", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_task_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), lm_logits, presents, (all hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2DoubleHeadsModel.__init__": [[710, 718], ["modeling_gpt2.GPT2PreTrainedModel.__init__", "modeling_gpt2.GPT2Model", "torch.Linear", "torch.Linear", "modeling_utils.SequenceSummary", "modeling_gpt2.GPT2DoubleHeadsModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "config", ")", "\n", "config", ".", "num_labels", "=", "1", "\n", "self", ".", "transformer", "=", "GPT2Model", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "nn", ".", "Linear", "(", "config", ".", "n_embd", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "multiple_choice_head", "=", "SequenceSummary", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2DoubleHeadsModel.get_output_embeddings": [[719, 721], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2DoubleHeadsModel.forward": [[722, 829], ["file_utils.add_start_docstrings_to_callable", "modeling_gpt2.GPT2DoubleHeadsModel.transformer", "modeling_gpt2.GPT2DoubleHeadsModel.lm_head", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head().squeeze", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "lm_logits[].contiguous", "lm_labels[].contiguous", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_gpt2.GPT2DoubleHeadsModel.multiple_choice_head", "modeling_gpt2.GPT2DoubleHeadsModel.view", "mc_labels.view", "lm_logits[].contiguous.view", "lm_labels[].contiguous.view", "modeling_gpt2.GPT2DoubleHeadsModel.size", "lm_logits[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.add_start_docstrings_to_callable"], ["", "@", "add_start_docstrings_to_callable", "(", "GPT2_INPUTS_DOCSTRING", ")", "\n", "def", "forward", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "past", "=", "None", ",", "\n", "attention_mask", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "\n", "head_mask", "=", "None", ",", "\n", "inputs_embeds", "=", "None", ",", "\n", "mc_token_ids", "=", "None", ",", "\n", "lm_labels", "=", "None", ",", "\n", "mc_labels", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\"\n        mc_token_ids (:obj:`torch.LongTensor` of shape :obj:`(batch_size, num_choices)`, `optional`, default to index of the last token of the input)\n            Index of the classification token in each input sequence.\n            Selected in the range ``[0, input_ids.size(-1) - 1[``.\n        lm_labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size, sequence_length)`, `optional`, defaults to :obj:`None`)\n            Labels for language modeling.\n            Note that the labels **are shifted** inside the model, i.e. you can set ``lm_labels = input_ids``\n            Indices are selected in ``[-1, 0, ..., config.vocab_size]``\n            All labels set to ``-100`` are ignored (masked), the loss is only\n            computed for labels in ``[0, ..., config.vocab_size]``\n        mc_labels (:obj:`torch.LongTensor` of shape :obj:`(batch_size)`, `optional`, defaults to :obj:`None`)\n            Labels for computing the multiple choice classification loss.\n            Indices should be in ``[0, ..., num_choices]`` where `num_choices` is the size of the second dimension\n            of the input tensors. (see `input_ids` above)\n\n    Return:\n        :obj:`tuple(torch.FloatTensor)` comprising various elements depending on the configuration (:class:`~transformers.GPT2Config`) and inputs:\n        lm_loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when ``lm_labels`` is provided):\n            Language modeling loss.\n        mc_loss (:obj:`torch.FloatTensor` of shape :obj:`(1,)`, `optional`, returned when :obj:`multiple_choice_labels` is provided):\n            Multiple choice classification loss.\n        lm_prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, num_choices, sequence_length, config.vocab_size)`):\n            Prediction scores of the language modeling head (scores for each vocabulary token before SoftMax).\n        mc_prediction_scores (:obj:`torch.FloatTensor` of shape :obj:`(batch_size, num_choices)`):\n            Prediction scores of the multiple choice classification head (scores for each choice before SoftMax).\n        past (:obj:`List[torch.FloatTensor]` of length :obj:`config.n_layers` with each tensor of shape :obj:`(2, batch_size, num_heads, sequence_length, embed_size_per_head)`):\n            Contains pre-computed hidden-states (key and values in the attention blocks).\n            Can be used (see `past` input) to speed up sequential decoding. The token ids which have their past given to this model\n            should not be passed as input ids as they have already been computed.\n        hidden_states (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_hidden_states=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for the output of the embeddings + one for the output of each layer)\n            of shape :obj:`(batch_size, sequence_length, hidden_size)`.\n\n            Hidden-states of the model at the output of each layer plus the initial embedding outputs.\n        attentions (:obj:`tuple(torch.FloatTensor)`, `optional`, returned when ``config.output_attentions=True``):\n            Tuple of :obj:`torch.FloatTensor` (one for each layer) of shape\n            :obj:`(batch_size, num_heads, sequence_length, sequence_length)`.\n\n            Attentions weights after the attention softmax, used to compute the weighted average in the self-attention\n            heads.\n\n    Examples::\n\n        import torch\n        from transformers import GPT2Tokenizer, GPT2DoubleHeadsModel\n\n        tokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n        model = GPT2DoubleHeadsModel.from_pretrained('gpt2')\n\n        # Add a [CLS] to the vocabulary (we should train it also!)\n        tokenizer.add_special_tokens({'cls_token': '[CLS]'})\n        model.resize_token_embeddings(len(tokenizer))  # Update the model embeddings with the new vocabulary size\n        print(tokenizer.cls_token_id, len(tokenizer))  # The newly token the last token of the vocabulary\n\n        choices = [\"Hello, my dog is cute [CLS]\", \"Hello, my cat is cute [CLS]\"]\n        encoded_choices = [tokenizer.encode(s) for s in choices]\n        cls_token_location = [tokens.index(tokenizer.cls_token_id) for tokens in encoded_choices]\n\n        input_ids = torch.tensor(encoded_choices).unsqueeze(0)  # Batch size: 1, number of choices: 2\n        mc_token_ids = torch.tensor([cls_token_location])  # Batch size: 1\n\n        outputs = model(input_ids, mc_token_ids=mc_token_ids)\n        lm_prediction_scores, mc_prediction_scores = outputs[:2]\n\n        \"\"\"", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "\n", "input_ids", ",", "\n", "past", "=", "past", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ",", "\n", ")", "\n", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "lm_logits", "=", "self", ".", "lm_head", "(", "hidden_states", ")", "\n", "mc_logits", "=", "self", ".", "multiple_choice_head", "(", "hidden_states", ",", "mc_token_ids", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "lm_logits", ",", "mc_logits", ")", "+", "transformer_outputs", "[", "1", ":", "]", "\n", "if", "mc_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "mc_logits", ".", "view", "(", "-", "1", ",", "mc_logits", ".", "size", "(", "-", "1", ")", ")", ",", "mc_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "", "if", "lm_labels", "is", "not", "None", ":", "\n", "            ", "shift_logits", "=", "lm_logits", "[", "...", ",", ":", "-", "1", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "shift_labels", "=", "lm_labels", "[", "...", ",", "1", ":", "]", ".", "contiguous", "(", ")", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "shift_logits", ".", "view", "(", "-", "1", ",", "shift_logits", ".", "size", "(", "-", "1", ")", ")", ",", "shift_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (lm loss), (mc loss), lm logits, mc logits, presents, (all hidden_states), (attentions)", "\n", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.load_tf_weights_in_gpt2": [[44, 97], ["os.path.abspath", "logger.info", "tf.train.list_variables", "zip", "logger.info", "tf.train.load_variable", "names.append", "arrays.append", "name.split.split", "logger.info", "torch.from_numpy", "torch.from_numpy", "logger.error", "tf.train.load_variable.squeeze", "re.fullmatch", "re.split", "getattr", "len", "int", "getattr", "getattr", "getattr", "getattr"], "function", ["None"], ["def", "load_tf_weights_in_gpt2", "(", "model", ",", "config", ",", "gpt2_checkpoint_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "re", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "tf_path", "=", "os", ".", "path", ".", "abspath", "(", "gpt2_checkpoint_path", ")", "\n", "logger", ".", "info", "(", "\"Converting TensorFlow checkpoint from {}\"", ".", "format", "(", "tf_path", ")", ")", "\n", "# Load weights from TF model", "\n", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "names", "=", "[", "]", "\n", "arrays", "=", "[", "]", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "names", ".", "append", "(", "name", ")", "\n", "arrays", ".", "append", "(", "array", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "for", "name", ",", "array", "in", "zip", "(", "names", ",", "arrays", ")", ":", "\n", "        ", "name", "=", "name", "[", "6", ":", "]", "# skip \"model/\"", "\n", "name", "=", "name", ".", "split", "(", "\"/\"", ")", "\n", "pointer", "=", "model", "\n", "for", "m_name", "in", "name", ":", "\n", "            ", "if", "re", ".", "fullmatch", "(", "r\"[A-Za-z]+\\d+\"", ",", "m_name", ")", ":", "\n", "                ", "scope_names", "=", "re", ".", "split", "(", "r\"(\\d+)\"", ",", "m_name", ")", "\n", "", "else", ":", "\n", "                ", "scope_names", "=", "[", "m_name", "]", "\n", "", "if", "scope_names", "[", "0", "]", "==", "\"w\"", "or", "scope_names", "[", "0", "]", "==", "\"g\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"b\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "\"bias\"", ")", "\n", "", "elif", "scope_names", "[", "0", "]", "==", "\"wpe\"", "or", "scope_names", "[", "0", "]", "==", "\"wte\"", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "pointer", "=", "getattr", "(", "pointer", ",", "\"weight\"", ")", "\n", "", "else", ":", "\n", "                ", "pointer", "=", "getattr", "(", "pointer", ",", "scope_names", "[", "0", "]", ")", "\n", "", "if", "len", "(", "scope_names", ")", ">=", "2", ":", "\n", "                ", "num", "=", "int", "(", "scope_names", "[", "1", "]", ")", "\n", "pointer", "=", "pointer", "[", "num", "]", "\n", "", "", "try", ":", "\n", "            ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "            ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.is_torch_available": [[103, 105], ["None"], "function", ["None"], ["def", "is_torch_available", "(", ")", ":", "\n", "    ", "return", "_torch_available", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.is_tf_available": [[107, 109], ["None"], "function", ["None"], ["", "def", "is_tf_available", "(", ")", ":", "\n", "    ", "return", "_tf_available", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.add_start_docstrings": [[111, 117], ["None"], "function", ["None"], ["", "def", "add_start_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "\"\"", ".", "join", "(", "docstr", ")", "+", "(", "fn", ".", "__doc__", "if", "fn", ".", "__doc__", "is", "not", "None", "else", "\"\"", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.add_start_docstrings_to_callable": [[119, 135], ["fn.__qualname__.split"], "function", ["None"], ["", "def", "add_start_docstrings_to_callable", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "class_name", "=", "\":class:`~transformers.{}`\"", ".", "format", "(", "fn", ".", "__qualname__", ".", "split", "(", "\".\"", ")", "[", "0", "]", ")", "\n", "intro", "=", "\"   The {} forward method, overrides the :func:`__call__` special method.\"", ".", "format", "(", "class_name", ")", "\n", "note", "=", "r\"\"\"\n\n    .. note::\n        Although the recipe for forward pass needs to be defined within\n        this function, one should call the :class:`Module` instance afterwards\n        instead of this since the former takes care of running the\n        pre and post processing steps while the latter silently ignores them.\n        \"\"\"", "\n", "fn", ".", "__doc__", "=", "intro", "+", "note", "+", "\"\"", ".", "join", "(", "docstr", ")", "+", "(", "fn", ".", "__doc__", "if", "fn", ".", "__doc__", "is", "not", "None", "else", "\"\"", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.add_end_docstrings": [[137, 143], ["None"], "function", ["None"], ["", "def", "add_end_docstrings", "(", "*", "docstr", ")", ":", "\n", "    ", "def", "docstring_decorator", "(", "fn", ")", ":", "\n", "        ", "fn", ".", "__doc__", "=", "fn", ".", "__doc__", "+", "\"\"", ".", "join", "(", "docstr", ")", "\n", "return", "fn", "\n", "\n", "", "return", "docstring_decorator", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.is_remote_url": [[145, 148], ["urllib.parse.urlparse"], "function", ["None"], ["", "def", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "    ", "parsed", "=", "urlparse", "(", "url_or_filename", ")", "\n", "return", "parsed", ".", "scheme", "in", "(", "\"http\"", ",", "\"https\"", ",", "\"s3\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.hf_bucket_url": [[150, 156], ["None"], "function", ["None"], ["", "def", "hf_bucket_url", "(", "identifier", ",", "postfix", "=", "None", ",", "cdn", "=", "False", ")", "->", "str", ":", "\n", "    ", "endpoint", "=", "CLOUDFRONT_DISTRIB_PREFIX", "if", "cdn", "else", "S3_BUCKET_PREFIX", "\n", "if", "postfix", "is", "None", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "\"/\"", ".", "join", "(", "(", "endpoint", ",", "identifier", ",", "postfix", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.url_to_filename": [[158, 180], ["url.encode", "hashlib.sha256", "hashlib.sha256.hexdigest", "url.endswith", "etag.encode", "hashlib.sha256", "hashlib.sha256.hexdigest"], "function", ["None"], ["", "", "def", "url_to_filename", "(", "url", ",", "etag", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Convert `url` into a hashed filename in a repeatable way.\n    If `etag` is specified, append its hash to the url's, delimited\n    by a period.\n    If the url ends with .h5 (Keras HDF5 weights) adds '.h5' to the name\n    so that TF 2.0 can identify it as a HDF5 file\n    (see https://github.com/tensorflow/tensorflow/blob/00fad90125b18b80fe054de1055770cfb8fe4ba3/tensorflow/python/keras/engine/network.py#L1380)\n    \"\"\"", "\n", "url_bytes", "=", "url", ".", "encode", "(", "\"utf-8\"", ")", "\n", "url_hash", "=", "sha256", "(", "url_bytes", ")", "\n", "filename", "=", "url_hash", ".", "hexdigest", "(", ")", "\n", "\n", "if", "etag", ":", "\n", "        ", "etag_bytes", "=", "etag", ".", "encode", "(", "\"utf-8\"", ")", "\n", "etag_hash", "=", "sha256", "(", "etag_bytes", ")", "\n", "filename", "+=", "\".\"", "+", "etag_hash", ".", "hexdigest", "(", ")", "\n", "\n", "", "if", "url", ".", "endswith", "(", "\".h5\"", ")", ":", "\n", "        ", "filename", "+=", "\".h5\"", "\n", "\n", "", "return", "filename", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.filename_to_url": [[182, 206], ["isinstance", "os.path.join", "str", "os.path.exists", "EnvironmentError", "os.path.exists", "EnvironmentError", "open", "json.load"], "function", ["None"], ["", "def", "filename_to_url", "(", "filename", ",", "cache_dir", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    Return the url and etag (which may be ``None``) stored for `filename`.\n    Raise ``EnvironmentError`` if `filename` or its stored metadata do not exist.\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "cache_path", ")", ")", "\n", "\n", "", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "meta_path", ")", ":", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "meta_path", ")", ")", "\n", "\n", "", "with", "open", "(", "meta_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "meta_file", ":", "\n", "        ", "metadata", "=", "json", ".", "load", "(", "meta_file", ")", "\n", "", "url", "=", "metadata", "[", "\"url\"", "]", "\n", "etag", "=", "metadata", "[", "\"etag\"", "]", "\n", "\n", "return", "url", ",", "etag", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.cached_path": [[208, 298], ["isinstance", "isinstance", "file_utils.is_remote_url", "str", "str", "file_utils.get_from_cache", "os.path.exists", "os.path.split", "os.path.join", "output_file.replace", "os.path.isdir", "os.listdir", "filelock.FileLock", "shutil.rmtree", "os.makedirs", "zipfile.is_zipfile", "EnvironmentError", "ValueError", "zipfile.is_zipfile", "tarfile.is_tarfile", "tarfile.is_tarfile", "urllib.parse.urlparse", "zipfile.ZipFile", "zip_file.extractall", "zip_file.close", "tarfile.open", "tarfile.open.extractall", "tarfile.open.close", "EnvironmentError"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.is_remote_url", "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.get_from_cache"], ["", "def", "cached_path", "(", "\n", "url_or_filename", ",", "\n", "cache_dir", "=", "None", ",", "\n", "force_download", "=", "False", ",", "\n", "proxies", "=", "None", ",", "\n", "resume_download", "=", "False", ",", "\n", "user_agent", "=", "None", ",", "\n", "extract_compressed_file", "=", "False", ",", "\n", "force_extract", "=", "False", ",", "\n", "local_files_only", "=", "False", ",", "\n", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Given something that might be a URL (or might be a local path),\n    determine which. If it's a URL, download the file and cache it, and\n    return the path to the cached file. If it's already a local path,\n    make sure the file exists and then return the path.\n    Args:\n        cache_dir: specify a cache directory to save the file to (overwrite the default cache dir).\n        force_download: if True, re-dowload the file even if it's already cached in the cache dir.\n        resume_download: if True, resume the download if incompletly recieved file is found.\n        user_agent: Optional string or dict that will be appended to the user-agent on remote requests.\n        extract_compressed_file: if True and the path point to a zip or tar file, extract the compressed\n            file in a folder along the archive.\n        force_extract: if True when extract_compressed_file is True and the archive was already extracted,\n            re-extract the archive and overide the folder where it was extracted.\n\n    Return:\n        None in case of non-recoverable file (non-existent or inaccessible url + no cache on disk).\n        Local path (string) otherwise\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "url_or_filename", ",", "Path", ")", ":", "\n", "        ", "url_or_filename", "=", "str", "(", "url_or_filename", ")", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "if", "is_remote_url", "(", "url_or_filename", ")", ":", "\n", "# URL, so get it from the cache (downloading if necessary)", "\n", "        ", "output_path", "=", "get_from_cache", "(", "\n", "url_or_filename", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "user_agent", "=", "user_agent", ",", "\n", "local_files_only", "=", "local_files_only", ",", "\n", ")", "\n", "", "elif", "os", ".", "path", ".", "exists", "(", "url_or_filename", ")", ":", "\n", "# File, and it exists.", "\n", "        ", "output_path", "=", "url_or_filename", "\n", "", "elif", "urlparse", "(", "url_or_filename", ")", ".", "scheme", "==", "\"\"", ":", "\n", "# File, but it doesn't exist.", "\n", "        ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "", "else", ":", "\n", "# Something unknown", "\n", "        ", "raise", "ValueError", "(", "\"unable to parse {} as a URL or as a local path\"", ".", "format", "(", "url_or_filename", ")", ")", "\n", "\n", "", "if", "extract_compressed_file", ":", "\n", "        ", "if", "not", "is_zipfile", "(", "output_path", ")", "and", "not", "tarfile", ".", "is_tarfile", "(", "output_path", ")", ":", "\n", "            ", "return", "output_path", "\n", "\n", "# Path where we extract compressed archives", "\n", "# We avoid '.' in dir name and add \"-extracted\" at the end: \"./model.zip\" => \"./model-zip-extracted/\"", "\n", "", "output_dir", ",", "output_file", "=", "os", ".", "path", ".", "split", "(", "output_path", ")", "\n", "output_extract_dir_name", "=", "output_file", ".", "replace", "(", "\".\"", ",", "\"-\"", ")", "+", "\"-extracted\"", "\n", "output_path_extracted", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "output_extract_dir_name", ")", "\n", "\n", "if", "os", ".", "path", ".", "isdir", "(", "output_path_extracted", ")", "and", "os", ".", "listdir", "(", "output_path_extracted", ")", "and", "not", "force_extract", ":", "\n", "            ", "return", "output_path_extracted", "\n", "\n", "# Prevent parallel extractions", "\n", "", "lock_path", "=", "output_path", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "            ", "shutil", ".", "rmtree", "(", "output_path_extracted", ",", "ignore_errors", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "output_path_extracted", ")", "\n", "if", "is_zipfile", "(", "output_path", ")", ":", "\n", "                ", "with", "ZipFile", "(", "output_path", ",", "\"r\"", ")", "as", "zip_file", ":", "\n", "                    ", "zip_file", ".", "extractall", "(", "output_path_extracted", ")", "\n", "zip_file", ".", "close", "(", ")", "\n", "", "", "elif", "tarfile", ".", "is_tarfile", "(", "output_path", ")", ":", "\n", "                ", "tar_file", "=", "tarfile", ".", "open", "(", "output_path", ")", "\n", "tar_file", ".", "extractall", "(", "output_path_extracted", ")", "\n", "tar_file", ".", "close", "(", ")", "\n", "", "else", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"Archive format of {} could not be identified\"", ".", "format", "(", "output_path", ")", ")", "\n", "\n", "", "", "return", "output_path_extracted", "\n", "\n", "", "return", "output_path", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.split_s3_path": [[300, 311], ["urllib.parse.urlparse", "s3_path.startswith", "ValueError"], "function", ["None"], ["", "def", "split_s3_path", "(", "url", ")", ":", "\n", "    ", "\"\"\"Split a full s3 path into the bucket name and path.\"\"\"", "\n", "parsed", "=", "urlparse", "(", "url", ")", "\n", "if", "not", "parsed", ".", "netloc", "or", "not", "parsed", ".", "path", ":", "\n", "        ", "raise", "ValueError", "(", "\"bad s3 path {}\"", ".", "format", "(", "url", ")", ")", "\n", "", "bucket_name", "=", "parsed", ".", "netloc", "\n", "s3_path", "=", "parsed", ".", "path", "\n", "# Remove '/' at beginning of path.", "\n", "if", "s3_path", ".", "startswith", "(", "\"/\"", ")", ":", "\n", "        ", "s3_path", "=", "s3_path", "[", "1", ":", "]", "\n", "", "return", "bucket_name", ",", "s3_path", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.s3_request": [[313, 330], ["functools.wraps", "func", "int", "EnvironmentError"], "function", ["None"], ["", "def", "s3_request", "(", "func", ")", ":", "\n", "    ", "\"\"\"\n    Wrapper function for s3 requests in order to create more helpful error\n    messages.\n    \"\"\"", "\n", "\n", "@", "wraps", "(", "func", ")", "\n", "def", "wrapper", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "return", "func", "(", "url", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "except", "ClientError", "as", "exc", ":", "\n", "            ", "if", "int", "(", "exc", ".", "response", "[", "\"Error\"", "]", "[", "\"Code\"", "]", ")", "==", "404", ":", "\n", "                ", "raise", "EnvironmentError", "(", "\"file {} not found\"", ".", "format", "(", "url", ")", ")", "\n", "", "else", ":", "\n", "                ", "raise", "\n", "\n", "", "", "", "return", "wrapper", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.s3_etag": [[332, 339], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Object", "botocore.config.Config"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_etag", "(", "url", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Check ETag on S3 object.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_object", "=", "s3_resource", ".", "Object", "(", "bucket_name", ",", "s3_path", ")", "\n", "return", "s3_object", ".", "e_tag", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.s3_get": [[341, 347], ["boto3.resource", "file_utils.split_s3_path", "boto3.resource.Bucket().download_fileobj", "botocore.config.Config", "boto3.resource.Bucket"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.split_s3_path"], ["", "@", "s3_request", "\n", "def", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ")", ":", "\n", "    ", "\"\"\"Pull a file directly from S3.\"\"\"", "\n", "s3_resource", "=", "boto3", ".", "resource", "(", "\"s3\"", ",", "config", "=", "Config", "(", "proxies", "=", "proxies", ")", ")", "\n", "bucket_name", ",", "s3_path", "=", "split_s3_path", "(", "url", ")", "\n", "s3_resource", ".", "Bucket", "(", "bucket_name", ")", ".", "download_fileobj", "(", "s3_path", ",", "temp_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.http_get": [[349, 380], ["file_utils.is_torch_available", "file_utils.is_tf_available", "isinstance", "requests.get", "requests.get.headers.get", "tqdm.auto.tqdm", "requests.get.iter_content", "tqdm.auto.tqdm.close", "isinstance", "sys.version.split", "int", "bool", "tqdm.auto.tqdm.update", "temp_file.write", "len", "logger.getEffectiveLevel", "user_agent.items"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.is_torch_available", "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.is_tf_available"], ["", "def", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "None", ",", "resume_size", "=", "0", ",", "user_agent", "=", "None", ")", ":", "\n", "    ", "ua", "=", "\"transformers/{}; python/{}\"", ".", "format", "(", "__version__", ",", "sys", ".", "version", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "if", "is_torch_available", "(", ")", ":", "\n", "        ", "ua", "+=", "\"; torch/{}\"", ".", "format", "(", "torch", ".", "__version__", ")", "\n", "", "if", "is_tf_available", "(", ")", ":", "\n", "        ", "ua", "+=", "\"; tensorflow/{}\"", ".", "format", "(", "tf", ".", "__version__", ")", "\n", "", "if", "isinstance", "(", "user_agent", ",", "dict", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "\"; \"", ".", "join", "(", "\"{}/{}\"", ".", "format", "(", "k", ",", "v", ")", "for", "k", ",", "v", "in", "user_agent", ".", "items", "(", ")", ")", "\n", "", "elif", "isinstance", "(", "user_agent", ",", "str", ")", ":", "\n", "        ", "ua", "+=", "\"; \"", "+", "user_agent", "\n", "", "headers", "=", "{", "\"user-agent\"", ":", "ua", "}", "\n", "if", "resume_size", ">", "0", ":", "\n", "        ", "headers", "[", "\"Range\"", "]", "=", "\"bytes=%d-\"", "%", "(", "resume_size", ",", ")", "\n", "", "response", "=", "requests", ".", "get", "(", "url", ",", "stream", "=", "True", ",", "proxies", "=", "proxies", ",", "headers", "=", "headers", ")", "\n", "if", "response", ".", "status_code", "==", "416", ":", "# Range not satisfiable", "\n", "        ", "return", "\n", "", "content_length", "=", "response", ".", "headers", ".", "get", "(", "\"Content-Length\"", ")", "\n", "total", "=", "resume_size", "+", "int", "(", "content_length", ")", "if", "content_length", "is", "not", "None", "else", "None", "\n", "progress", "=", "tqdm", "(", "\n", "unit", "=", "\"B\"", ",", "\n", "unit_scale", "=", "True", ",", "\n", "total", "=", "total", ",", "\n", "initial", "=", "resume_size", ",", "\n", "desc", "=", "\"Downloading\"", ",", "\n", "disable", "=", "bool", "(", "logger", ".", "getEffectiveLevel", "(", ")", "==", "logging", ".", "NOTSET", ")", ",", "\n", ")", "\n", "for", "chunk", "in", "response", ".", "iter_content", "(", "chunk_size", "=", "1024", ")", ":", "\n", "        ", "if", "chunk", ":", "# filter out keep-alive new chunks", "\n", "            ", "progress", ".", "update", "(", "len", "(", "chunk", ")", ")", "\n", "temp_file", ".", "write", "(", "chunk", ")", "\n", "", "", "progress", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.get_from_cache": [[382, 499], ["isinstance", "os.makedirs", "file_utils.url_to_filename", "os.path.join", "str", "url.startswith", "os.path.exists", "os.path.exists", "filelock.FileLock", "logger.info", "os.rename", "logger.info", "file_utils.s3_etag", "os.path.exists", "functools.partial", "functools.partial.", "logger.info", "url.startswith", "open", "json.dump", "requests.head", "len", "os.path.join", "file_utils.s3_get", "file_utils.http_get", "requests.head.headers.get", "fnmatch.filter", "ValueError", "open", "os.stat", "logger.warn", "os.listdir", "file.endswith", "file.endswith"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.url_to_filename", "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.s3_etag", "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.s3_get", "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.http_get"], ["", "def", "get_from_cache", "(", "\n", "url", ",", "\n", "cache_dir", "=", "None", ",", "\n", "force_download", "=", "False", ",", "\n", "proxies", "=", "None", ",", "\n", "etag_timeout", "=", "10", ",", "\n", "resume_download", "=", "False", ",", "\n", "user_agent", "=", "None", ",", "\n", "local_files_only", "=", "False", ",", "\n", ")", "->", "Optional", "[", "str", "]", ":", "\n", "    ", "\"\"\"\n    Given a URL, look for the corresponding file in the local cache.\n    If it's not there, download it. Then return the path to the cached file.\n\n    Return:\n        None in case of non-recoverable file (non-existent or inaccessible url + no cache on disk).\n        Local path (string) otherwise\n    \"\"\"", "\n", "if", "cache_dir", "is", "None", ":", "\n", "        ", "cache_dir", "=", "TRANSFORMERS_CACHE", "\n", "", "if", "isinstance", "(", "cache_dir", ",", "Path", ")", ":", "\n", "        ", "cache_dir", "=", "str", "(", "cache_dir", ")", "\n", "\n", "", "os", ".", "makedirs", "(", "cache_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "etag", "=", "None", "\n", "if", "not", "local_files_only", ":", "\n", "# Get eTag to add to filename, if it exists.", "\n", "        ", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "            ", "etag", "=", "s3_etag", "(", "url", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "response", "=", "requests", ".", "head", "(", "url", ",", "allow_redirects", "=", "True", ",", "proxies", "=", "proxies", ",", "timeout", "=", "etag_timeout", ")", "\n", "if", "response", ".", "status_code", "==", "200", ":", "\n", "                    ", "etag", "=", "response", ".", "headers", ".", "get", "(", "\"ETag\"", ")", "\n", "", "", "except", "(", "EnvironmentError", ",", "requests", ".", "exceptions", ".", "Timeout", ")", ":", "\n", "# etag is already None", "\n", "                ", "pass", "\n", "\n", "", "", "", "filename", "=", "url_to_filename", "(", "url", ",", "etag", ")", "\n", "\n", "# get cache path to put the file", "\n", "cache_path", "=", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "filename", ")", "\n", "\n", "# etag is None = we don't have a connection, or url doesn't exist, or is otherwise inaccessible.", "\n", "# try to get the last downloaded one", "\n", "if", "etag", "is", "None", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", ":", "\n", "            ", "return", "cache_path", "\n", "", "else", ":", "\n", "            ", "matching_files", "=", "[", "\n", "file", "\n", "for", "file", "in", "fnmatch", ".", "filter", "(", "os", ".", "listdir", "(", "cache_dir", ")", ",", "filename", "+", "\".*\"", ")", "\n", "if", "not", "file", ".", "endswith", "(", "\".json\"", ")", "and", "not", "file", ".", "endswith", "(", "\".lock\"", ")", "\n", "]", "\n", "if", "len", "(", "matching_files", ")", ">", "0", ":", "\n", "                ", "return", "os", ".", "path", ".", "join", "(", "cache_dir", ",", "matching_files", "[", "-", "1", "]", ")", "\n", "", "else", ":", "\n", "# If files cannot be found and local_files_only=True,", "\n", "# the models might've been found if local_files_only=False", "\n", "# Notify the user about that", "\n", "                ", "if", "local_files_only", ":", "\n", "                    ", "raise", "ValueError", "(", "\n", "\"Cannot find the requested files in the cached path and outgoing traffic has been\"", "\n", "\" disabled. To enable model look-ups and downloads online, set 'local_files_only'\"", "\n", "\" to False.\"", "\n", ")", "\n", "", "return", "None", "\n", "\n", "# From now on, etag is not None.", "\n", "", "", "", "if", "os", ".", "path", ".", "exists", "(", "cache_path", ")", "and", "not", "force_download", ":", "\n", "        ", "return", "cache_path", "\n", "\n", "# Prevent parallel downloads of the same file with a lock.", "\n", "", "lock_path", "=", "cache_path", "+", "\".lock\"", "\n", "with", "FileLock", "(", "lock_path", ")", ":", "\n", "\n", "        ", "if", "resume_download", ":", "\n", "            ", "incomplete_path", "=", "cache_path", "+", "\".incomplete\"", "\n", "\n", "@", "contextmanager", "\n", "def", "_resumable_file_manager", "(", ")", ":", "\n", "                ", "with", "open", "(", "incomplete_path", ",", "\"a+b\"", ")", "as", "f", ":", "\n", "                    ", "yield", "f", "\n", "\n", "", "", "temp_file_manager", "=", "_resumable_file_manager", "\n", "if", "os", ".", "path", ".", "exists", "(", "incomplete_path", ")", ":", "\n", "                ", "resume_size", "=", "os", ".", "stat", "(", "incomplete_path", ")", ".", "st_size", "\n", "", "else", ":", "\n", "                ", "resume_size", "=", "0", "\n", "", "", "else", ":", "\n", "            ", "temp_file_manager", "=", "partial", "(", "tempfile", ".", "NamedTemporaryFile", ",", "dir", "=", "cache_dir", ",", "delete", "=", "False", ")", "\n", "resume_size", "=", "0", "\n", "\n", "# Download to temporary file, then copy to cache dir once finished.", "\n", "# Otherwise you get corrupt cache entries if the download gets interrupted.", "\n", "", "with", "temp_file_manager", "(", ")", "as", "temp_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"%s not found in cache or force_download set to True, downloading to %s\"", ",", "url", ",", "temp_file", ".", "name", ")", "\n", "\n", "# GET file object", "\n", "if", "url", ".", "startswith", "(", "\"s3://\"", ")", ":", "\n", "                ", "if", "resume_download", ":", "\n", "                    ", "logger", ".", "warn", "(", "'Warning: resumable downloads are not implemented for \"s3://\" urls'", ")", "\n", "", "s3_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ")", "\n", "", "else", ":", "\n", "                ", "http_get", "(", "url", ",", "temp_file", ",", "proxies", "=", "proxies", ",", "resume_size", "=", "resume_size", ",", "user_agent", "=", "user_agent", ")", "\n", "\n", "", "", "logger", ".", "info", "(", "\"storing %s in cache at %s\"", ",", "url", ",", "cache_path", ")", "\n", "os", ".", "rename", "(", "temp_file", ".", "name", ",", "cache_path", ")", "\n", "\n", "logger", ".", "info", "(", "\"creating metadata file for %s\"", ",", "cache_path", ")", "\n", "meta", "=", "{", "\"url\"", ":", "url", ",", "\"etag\"", ":", "etag", "}", "\n", "meta_path", "=", "cache_path", "+", "\".json\"", "\n", "with", "open", "(", "meta_path", ",", "\"w\"", ")", "as", "meta_file", ":", "\n", "            ", "json", ".", "dump", "(", "meta", ",", "meta_file", ")", "\n", "\n", "", "", "return", "cache_path", "\n", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.ModuleUtilsMixin.num_parameters": [[62, 68], ["sum", "filter", "modeling_utils.ModuleUtilsMixin.parameters", "modeling_utils.ModuleUtilsMixin.parameters", "p.numel"], "methods", ["None"], ["def", "num_parameters", "(", "self", ",", "only_trainable", ":", "bool", "=", "False", ")", "->", "int", ":", "\n", "        ", "\"\"\"\n        Get number of (optionally, trainable) parameters in the module.\n        \"\"\"", "\n", "params", "=", "filter", "(", "lambda", "x", ":", "x", ".", "requires_grad", ",", "self", ".", "parameters", "(", ")", ")", "if", "only_trainable", "else", "self", ".", "parameters", "(", ")", "\n", "return", "sum", "(", "p", ".", "numel", "(", ")", "for", "p", "in", "params", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.dummy_inputs": [[91, 99], ["torch.tensor"], "methods", ["None"], ["@", "property", "\n", "def", "dummy_inputs", "(", "self", ")", ":", "\n", "        ", "\"\"\" Dummy inputs to do a forward pass in the network.\n\n        Returns:\n            torch.Tensor with dummy inputs\n        \"\"\"", "\n", "return", "{", "\"input_ids\"", ":", "torch", ".", "tensor", "(", "DUMMY_INPUTS", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.__init__": [[100, 112], ["super().__init__", "isinstance", "ValueError"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["", "def", "__init__", "(", "self", ",", "config", ",", "*", "inputs", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"Parameter config in `{}(config)` should be an instance of class `PretrainedConfig`. \"", "\n", "\"To create a model from a pretrained model use \"", "\n", "\"`model = {}.from_pretrained(PRETRAINED_MODEL_NAME)`\"", ".", "format", "(", "\n", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "__class__", ".", "__name__", "\n", ")", "\n", ")", "\n", "# Save config in model", "\n", "", "self", ".", "config", "=", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.base_model": [[113, 116], ["getattr"], "methods", ["None"], ["", "@", "property", "\n", "def", "base_model", "(", "self", ")", ":", "\n", "        ", "return", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_input_embeddings": [[117, 130], ["getattr", "getattr.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_input_embeddings"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the model's input embeddings.\n\n        Returns:\n            :obj:`nn.Module`:\n                A torch module mapping vocabulary to hidden states.\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "if", "base_model", "is", "not", "self", ":", "\n", "            ", "return", "base_model", ".", "get_input_embeddings", "(", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.set_input_embeddings": [[131, 144], ["getattr", "getattr.set_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.set_input_embeddings"], ["", "", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "\"\"\"\n        Set model's input embeddings\n\n        Args:\n            value (:obj:`nn.Module`):\n                A module mapping vocabulary to hidden states.\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "\n", "if", "base_model", "is", "not", "self", ":", "\n", "            ", "base_model", ".", "set_input_embeddings", "(", "value", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_output_embeddings": [[145, 154], ["None"], "methods", ["None"], ["", "", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the model's output embeddings.\n\n        Returns:\n            :obj:`nn.Module`:\n                A torch module mapping hidden states to vocabulary.\n        \"\"\"", "\n", "return", "None", "# Overwrite for models with output embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.tie_weights": [[155, 164], ["modeling_utils.PreTrainedModel.get_output_embeddings", "modeling_utils.PreTrainedModel._tie_or_clone_weights", "modeling_utils.PreTrainedModel.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_output_embeddings", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._tie_or_clone_weights", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_input_embeddings"], ["", "def", "tie_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Tie the weights between the input embeddings and the output embeddings.\n        If the `torchscript` flag is set in the configuration, can't handle parameter sharing so we are cloning\n        the weights instead.\n        \"\"\"", "\n", "output_embeddings", "=", "self", ".", "get_output_embeddings", "(", ")", "\n", "if", "output_embeddings", "is", "not", "None", ":", "\n", "            ", "self", ".", "_tie_or_clone_weights", "(", "output_embeddings", ",", "self", ".", "get_input_embeddings", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._tie_or_clone_weights": [[165, 182], ["torch.nn.Parameter", "getattr", "torch.nn.functional.pad", "hasattr", "hasattr", "input_embeddings.weight.clone"], "methods", ["None"], ["", "", "def", "_tie_or_clone_weights", "(", "self", ",", "output_embeddings", ",", "input_embeddings", ")", ":", "\n", "        ", "\"\"\" Tie or clone module weights depending of weither we are using TorchScript or not\n        \"\"\"", "\n", "if", "self", ".", "config", ".", "torchscript", ":", "\n", "            ", "output_embeddings", ".", "weight", "=", "nn", ".", "Parameter", "(", "input_embeddings", ".", "weight", ".", "clone", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "output_embeddings", ".", "weight", "=", "input_embeddings", ".", "weight", "\n", "\n", "", "if", "getattr", "(", "output_embeddings", ",", "\"bias\"", ",", "None", ")", "is", "not", "None", ":", "\n", "            ", "output_embeddings", ".", "bias", ".", "data", "=", "torch", ".", "nn", ".", "functional", ".", "pad", "(", "\n", "output_embeddings", ".", "bias", ".", "data", ",", "\n", "(", "0", ",", "output_embeddings", ".", "weight", ".", "shape", "[", "0", "]", "-", "output_embeddings", ".", "bias", ".", "shape", "[", "0", "]", ")", ",", "\n", "\"constant\"", ",", "\n", "0", ",", "\n", ")", "\n", "", "if", "hasattr", "(", "output_embeddings", ",", "\"out_features\"", ")", "and", "hasattr", "(", "input_embeddings", ",", "\"num_embeddings\"", ")", ":", "\n", "            ", "output_embeddings", ".", "out_features", "=", "input_embeddings", ".", "num_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.resize_token_embeddings": [[183, 209], ["getattr", "getattr._resize_token_embeddings", "modeling_utils.PreTrainedModel.tie_weights"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._resize_token_embeddings", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.tie_weights"], ["", "", "def", "resize_token_embeddings", "(", "self", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Resize input token embeddings matrix of the model if new_num_tokens != config.vocab_size.\n        Take care of tying weights embeddings afterwards if the model class has a `tie_weights()` method.\n\n        Arguments:\n\n            new_num_tokens: (`optional`) int:\n                New number of tokens in the embedding matrix. Increasing the size will add newly initialized vectors at the end. Reducing the size will remove vectors from the end.\n                If not provided or None: does nothing and just returns a pointer to the input tokens ``torch.nn.Embeddings`` Module of the model.\n\n        Return: ``torch.nn.Embeddings``\n            Pointer to the input tokens Embeddings Module of the model\n        \"\"\"", "\n", "base_model", "=", "getattr", "(", "self", ",", "self", ".", "base_model_prefix", ",", "self", ")", "# get the base model if needed", "\n", "model_embeds", "=", "base_model", ".", "_resize_token_embeddings", "(", "new_num_tokens", ")", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "model_embeds", "\n", "\n", "# Update base model and current model config", "\n", "", "self", ".", "config", ".", "vocab_size", "=", "new_num_tokens", "\n", "base_model", ".", "vocab_size", "=", "new_num_tokens", "\n", "\n", "# Tie weights again if needed", "\n", "self", ".", "tie_weights", "(", ")", "\n", "\n", "return", "model_embeds", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._resize_token_embeddings": [[210, 215], ["modeling_utils.PreTrainedModel.get_input_embeddings", "modeling_utils.PreTrainedModel._get_resized_embeddings", "modeling_utils.PreTrainedModel.set_input_embeddings", "modeling_utils.PreTrainedModel.get_input_embeddings"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_input_embeddings", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._get_resized_embeddings", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.set_input_embeddings", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_input_embeddings"], ["", "def", "_resize_token_embeddings", "(", "self", ",", "new_num_tokens", ")", ":", "\n", "        ", "old_embeddings", "=", "self", ".", "get_input_embeddings", "(", ")", "\n", "new_embeddings", "=", "self", ".", "_get_resized_embeddings", "(", "old_embeddings", ",", "new_num_tokens", ")", "\n", "self", ".", "set_input_embeddings", "(", "new_embeddings", ")", "\n", "return", "self", ".", "get_input_embeddings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._get_resized_embeddings": [[216, 249], ["old_embeddings.weight.size", "torch.nn.Embedding", "torch.nn.Embedding.to", "modeling_utils.PreTrainedModel._init_weights", "min"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2PreTrainedModel._init_weights"], ["", "def", "_get_resized_embeddings", "(", "self", ",", "old_embeddings", ",", "new_num_tokens", "=", "None", ")", ":", "\n", "        ", "\"\"\" Build a resized Embedding Module from a provided token Embedding Module.\n            Increasing the size will add newly initialized vectors at the end\n            Reducing the size will remove vectors from the end\n\n        Args:\n            new_num_tokens: (`optional`) int\n                New number of tokens in the embedding matrix.\n                Increasing the size will add newly initialized vectors at the end\n                Reducing the size will remove vectors from the end\n                If not provided or None: return the provided token Embedding Module.\n        Return: ``torch.nn.Embeddings``\n            Pointer to the resized Embedding Module or the old Embedding Module if new_num_tokens is None\n        \"\"\"", "\n", "if", "new_num_tokens", "is", "None", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "", "old_num_tokens", ",", "old_embedding_dim", "=", "old_embeddings", ".", "weight", ".", "size", "(", ")", "\n", "if", "old_num_tokens", "==", "new_num_tokens", ":", "\n", "            ", "return", "old_embeddings", "\n", "\n", "# Build new embeddings", "\n", "", "new_embeddings", "=", "nn", ".", "Embedding", "(", "new_num_tokens", ",", "old_embedding_dim", ")", "\n", "new_embeddings", ".", "to", "(", "old_embeddings", ".", "weight", ".", "device", ")", "\n", "\n", "# initialize all new embeddings (in particular added tokens)", "\n", "self", ".", "_init_weights", "(", "new_embeddings", ")", "\n", "\n", "# Copy token embeddings from the previous weights", "\n", "num_tokens_to_copy", "=", "min", "(", "old_num_tokens", ",", "new_num_tokens", ")", "\n", "new_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "=", "old_embeddings", ".", "weight", ".", "data", "[", ":", "num_tokens_to_copy", ",", ":", "]", "\n", "\n", "return", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.init_weights": [[250, 261], ["modeling_utils.PreTrainedModel.apply", "modeling_utils.PreTrainedModel.tie_weights", "modeling_utils.PreTrainedModel.prune_heads"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.tie_weights", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.prune_heads"], ["", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\" Initialize and prunes weights if needed. \"\"\"", "\n", "# Initialize weights", "\n", "self", ".", "apply", "(", "self", ".", "_init_weights", ")", "\n", "\n", "# Prune heads if needed", "\n", "if", "self", ".", "config", ".", "pruned_heads", ":", "\n", "            ", "self", ".", "prune_heads", "(", "self", ".", "config", ".", "pruned_heads", ")", "\n", "\n", "# Tie weights if needed", "\n", "", "self", ".", "tie_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.prune_heads": [[262, 276], ["heads_to_prune.items", "modeling_utils.PreTrainedModel.base_model._prune_heads", "list", "set", "set", "modeling_utils.PreTrainedModel.config.pruned_heads.get"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_gpt2.GPT2Model._prune_heads"], ["", "def", "prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "\"\"\" Prunes heads of the base model.\n\n            Arguments:\n\n                heads_to_prune: dict with keys being selected layer indices (`int`) and associated values being the list of heads to prune in said layer (list of `int`).\n                E.g. {1: [0, 2], 2: [2, 3]} will prune heads 0 and 2 on layer 1 and heads 2 and 3 on layer 2.\n        \"\"\"", "\n", "# save new sets of pruned heads as union of previously stored pruned heads and newly pruned heads", "\n", "for", "layer", ",", "heads", "in", "heads_to_prune", ".", "items", "(", ")", ":", "\n", "            ", "union_heads", "=", "set", "(", "self", ".", "config", ".", "pruned_heads", ".", "get", "(", "layer", ",", "[", "]", ")", ")", "|", "set", "(", "heads", ")", "\n", "self", ".", "config", ".", "pruned_heads", "[", "layer", "]", "=", "list", "(", "union_heads", ")", "# Unfortunately we have to store it as list for JSON", "\n", "\n", "", "self", ".", "base_model", ".", "_prune_heads", "(", "heads_to_prune", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.save_pretrained": [[277, 298], ["os.path.isdir", "model_to_save.config.save_pretrained", "os.path.join", "torch.save", "logger.info", "hasattr", "model_to_save.state_dict"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.save_pretrained"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\" Save a model and its configuration file to a directory, so that it\n            can be re-loaded using the `:func:`~transformers.PreTrainedModel.from_pretrained`` class method.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "\n", "save_directory", "\n", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# Only save the model itself if we are using distributed training", "\n", "model_to_save", "=", "self", ".", "module", "if", "hasattr", "(", "self", ",", "\"module\"", ")", "else", "self", "\n", "\n", "# Attach architecture to the config", "\n", "model_to_save", ".", "config", ".", "architectures", "=", "[", "model_to_save", ".", "__class__", ".", "__name__", "]", "\n", "\n", "# Save configuration file", "\n", "model_to_save", ".", "config", ".", "save_pretrained", "(", "save_directory", ")", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_model_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "WEIGHTS_NAME", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "output_model_file", ")", "\n", "logger", ".", "info", "(", "\"Model weights saved in {}\"", ".", "format", "(", "output_model_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.from_pretrained": [[299, 583], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "cls", "load_tf2_checkpoint_in_pytorch_model.tie_weights", "load_tf2_checkpoint_in_pytorch_model.eval", "isinstance", "cls.config_class.from_pretrained", "file_utils.cached_path.endswith", "torch.load.keys", "zip", "getattr", "torch.load.copy", "modeling_utils.PreTrainedModel.from_pretrained.load"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.tie_weights", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "*", "model_args", ",", "**", "kwargs", ")", ":", "\n", "        ", "r\"\"\"Instantiate a pretrained pytorch model from a pre-trained model configuration.\n\n        The model is set in evaluation mode by default using ``model.eval()`` (Dropout modules are deactivated)\n        To train the model, you should first set it back in training mode with ``model.train()``\n\n        The warning ``Weights from XXX not initialized from pretrained model`` means that the weights of XXX do not come pre-trained with the rest of the model.\n        It is up to you to train those weights with a downstream fine-tuning task.\n\n        The warning ``Weights from XXX not used in YYY`` means that the layer XXX is not used by YYY, therefore those weights are discarded.\n\n        Parameters:\n            pretrained_model_name_or_path: either:\n              - a string with the `shortcut name` of a pre-trained model to load from cache or download, e.g.: ``bert-base-uncased``.\n              - a string with the `identifier name` of a pre-trained model that was user-uploaded to our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n              - a path to a `directory` containing model weights saved using :func:`~transformers.PreTrainedModel.save_pretrained`, e.g.: ``./my_model_directory/``.\n              - a path or url to a `tensorflow index checkpoint file` (e.g. `./tf_model/model.ckpt.index`). In this case, ``from_tf`` should be set to True and a configuration object should be provided as ``config`` argument. This loading path is slower than converting the TensorFlow checkpoint in a PyTorch model using the provided conversion scripts and loading the PyTorch model afterwards.\n              - None if you are both providing the configuration and state dictionary (resp. with keyword arguments ``config`` and ``state_dict``)\n\n            model_args: (`optional`) Sequence of positional arguments:\n                All remaning positional arguments will be passed to the underlying model's ``__init__`` method\n\n            config: (`optional`) one of:\n                - an instance of a class derived from :class:`~transformers.PretrainedConfig`, or\n                - a string valid as input to :func:`~transformers.PretrainedConfig.from_pretrained()`\n                Configuration for the model to use instead of an automatically loaded configuation. Configuration can be automatically loaded when:\n                    - the model is a model provided by the library (loaded with the ``shortcut-name`` string of a pretrained model), or\n                    - the model was saved using :func:`~transformers.PreTrainedModel.save_pretrained` and is reloaded by suppling the save directory.\n                    - the model is loaded by suppling a local directory as ``pretrained_model_name_or_path`` and a configuration JSON file named `config.json` is found in the directory.\n\n            state_dict: (`optional`) dict:\n                an optional state dictionnary for the model to use instead of a state dictionary loaded from saved weights file.\n                This option can be used if you want to create a model from a pretrained configuration but load your own weights.\n                In this case though, you should check if using :func:`~transformers.PreTrainedModel.save_pretrained` and :func:`~transformers.PreTrainedModel.from_pretrained` is not a simpler option.\n\n            cache_dir: (`optional`) string:\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n\n            force_download: (`optional`) boolean, default False:\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exists.\n\n            resume_download: (`optional`) boolean, default False:\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n\n            proxies: (`optional`) dict, default None:\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.: {'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.\n                The proxies are used on each request.\n\n            output_loading_info: (`optional`) boolean:\n                Set to ``True`` to also return a dictionnary containing missing keys, unexpected keys and error messages.\n\n            kwargs: (`optional`) Remaining dictionary of keyword arguments:\n                Can be used to update the configuration object (after it being loaded) and initiate the model. (e.g. ``output_attention=True``). Behave differently depending on whether a `config` is provided or automatically loaded:\n\n                - If a configuration is provided with ``config``, ``**kwargs`` will be directly passed to the underlying model's ``__init__`` method (we assume all relevant updates to the configuration have already been done)\n                - If a configuration is not provided, ``kwargs`` will be first passed to the configuration class initialization function (:func:`~transformers.PretrainedConfig.from_pretrained`). Each key of ``kwargs`` that corresponds to a configuration attribute will be used to override said attribute with the supplied ``kwargs`` value. Remaining keys that do not correspond to any configuration attribute will be passed to the underlying model's ``__init__`` function.\n\n        Examples::\n\n            # For example purposes. Not runnable.\n            model = BertModel.from_pretrained('bert-base-uncased')    # Download model and configuration from S3 and cache.\n            model = BertModel.from_pretrained('./test/saved_model/')  # E.g. model was saved using `save_pretrained('./test/saved_model/')`\n            model = BertModel.from_pretrained('bert-base-uncased', output_attention=True)  # Update configuration during loading\n            assert model.config.output_attention == True\n            # Loading from a TF checkpoint file instead of a PyTorch model (slower)\n            config = BertConfig.from_json_file('./tf_model/my_tf_model_config.json')\n            model = BertModel.from_pretrained('./tf_model/my_tf_checkpoint.ckpt.index', from_tf=True, config=config)\n\n        \"\"\"", "\n", "config", "=", "kwargs", ".", "pop", "(", "\"config\"", ",", "None", ")", "\n", "state_dict", "=", "kwargs", ".", "pop", "(", "\"state_dict\"", ",", "None", ")", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "from_tf", "=", "kwargs", ".", "pop", "(", "\"from_tf\"", ",", "False", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "output_loading_info", "=", "kwargs", ".", "pop", "(", "\"output_loading_info\"", ",", "False", ")", "\n", "local_files_only", "=", "kwargs", ".", "pop", "(", "\"local_files_only\"", ",", "False", ")", "\n", "\n", "# Load config if we don't provide a configuration", "\n", "if", "not", "isinstance", "(", "config", ",", "PretrainedConfig", ")", ":", "\n", "            ", "config_path", "=", "config", "if", "config", "is", "not", "None", "else", "pretrained_model_name_or_path", "\n", "config", ",", "model_kwargs", "=", "cls", ".", "config_class", ".", "from_pretrained", "(", "\n", "config_path", ",", "\n", "*", "model_args", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "return_unused_kwargs", "=", "True", ",", "\n", "force_download", "=", "force_download", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "local_files_only", "=", "local_files_only", ",", "\n", "**", "kwargs", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "model_kwargs", "=", "kwargs", "\n", "\n", "# Load model", "\n", "", "if", "pretrained_model_name_or_path", "is", "not", "None", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                ", "archive_file", "=", "cls", ".", "pretrained_model_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "if", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", ")", ":", "\n", "# Load from a TF 1.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", ")", "\n", "", "elif", "from_tf", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a TF 2.0 checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "TF2_WEIGHTS_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", ")", ":", "\n", "# Load from a PyTorch checkpoint", "\n", "                    ", "archive_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "WEIGHTS_NAME", ")", "\n", "", "else", ":", "\n", "                    ", "raise", "EnvironmentError", "(", "\n", "\"Error no file named {} found in directory {} or `from_tf` set to False\"", ".", "format", "(", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "+", "\".index\"", "]", ",", "pretrained_model_name_or_path", "\n", ")", "\n", ")", "\n", "", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "                ", "archive_file", "=", "pretrained_model_name_or_path", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", "+", "\".index\"", ")", ":", "\n", "                ", "assert", "(", "\n", "from_tf", "\n", ")", ",", "\"We found a TensorFlow checkpoint at {}, please set from_tf to True to load from this checkpoint\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", "+", "\".index\"", "\n", ")", "\n", "archive_file", "=", "pretrained_model_name_or_path", "+", "\".index\"", "\n", "", "else", ":", "\n", "                ", "archive_file", "=", "hf_bucket_url", "(", "\n", "pretrained_model_name_or_path", ",", "postfix", "=", "(", "TF2_WEIGHTS_NAME", "if", "from_tf", "else", "WEIGHTS_NAME", ")", "\n", ")", "\n", "\n", "# redirect to the cache, if necessary", "\n", "", "try", ":", "\n", "                ", "resolved_archive_file", "=", "cached_path", "(", "\n", "archive_file", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "local_files_only", "=", "local_files_only", ",", "\n", ")", "\n", "", "except", "EnvironmentError", ":", "\n", "                ", "if", "pretrained_model_name_or_path", "in", "cls", ".", "pretrained_model_archive_map", ":", "\n", "                    ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained weights.\"", ".", "format", "(", "archive_file", ")", "\n", "", "else", ":", "\n", "                    ", "msg", "=", "(", "\n", "\"Model name '{}' was not found in model name list ({}). \"", "\n", "\"We assumed '{}' was a path or url to model weight files named one of {} but \"", "\n", "\"couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "\n", "\", \"", ".", "join", "(", "cls", ".", "pretrained_model_archive_map", ".", "keys", "(", ")", ")", ",", "\n", "archive_file", ",", "\n", "[", "WEIGHTS_NAME", ",", "TF2_WEIGHTS_NAME", ",", "TF_WEIGHTS_NAME", "]", ",", "\n", ")", "\n", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_archive_file", "==", "archive_file", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {}\"", ".", "format", "(", "archive_file", ")", ")", "\n", "", "else", ":", "\n", "                ", "logger", ".", "info", "(", "\"loading weights file {} from cache at {}\"", ".", "format", "(", "archive_file", ",", "resolved_archive_file", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "resolved_archive_file", "=", "None", "\n", "\n", "# Instantiate model.", "\n", "", "model", "=", "cls", "(", "config", ",", "*", "model_args", ",", "**", "model_kwargs", ")", "\n", "\n", "if", "state_dict", "is", "None", "and", "not", "from_tf", ":", "\n", "            ", "try", ":", "\n", "                ", "state_dict", "=", "torch", ".", "load", "(", "resolved_archive_file", ",", "map_location", "=", "\"cpu\"", ")", "\n", "", "except", "Exception", ":", "\n", "                ", "raise", "OSError", "(", "\n", "\"Unable to load weights from pytorch checkpoint file. \"", "\n", "\"If you tried to load a PyTorch model from a TF 2.0 checkpoint, please set from_tf=True. \"", "\n", ")", "\n", "\n", "", "", "missing_keys", "=", "[", "]", "\n", "unexpected_keys", "=", "[", "]", "\n", "error_msgs", "=", "[", "]", "\n", "\n", "if", "from_tf", ":", "\n", "            ", "if", "resolved_archive_file", ".", "endswith", "(", "\".index\"", ")", ":", "\n", "# Load from a TensorFlow 1.X checkpoint - provided by original authors", "\n", "                ", "model", "=", "cls", ".", "load_tf_weights", "(", "model", ",", "config", ",", "resolved_archive_file", "[", ":", "-", "6", "]", ")", "# Remove the '.index'", "\n", "", "else", ":", "\n", "# Load from our TensorFlow 2.0 checkpoints", "\n", "                ", "try", ":", "\n", "                    ", "from", "transformers", "import", "load_tf2_checkpoint_in_pytorch_model", "\n", "\n", "model", "=", "load_tf2_checkpoint_in_pytorch_model", "(", "model", ",", "resolved_archive_file", ",", "allow_missing_keys", "=", "True", ")", "\n", "", "except", "ImportError", ":", "\n", "                    ", "logger", ".", "error", "(", "\n", "\"Loading a TensorFlow model in PyTorch, requires both PyTorch and TensorFlow to be installed. Please see \"", "\n", "\"https://pytorch.org/ and https://www.tensorflow.org/install/ for installation instructions.\"", "\n", ")", "\n", "raise", "\n", "", "", "", "else", ":", "\n", "# Convert old format to new format if needed from a PyTorch state_dict", "\n", "            ", "old_keys", "=", "[", "]", "\n", "new_keys", "=", "[", "]", "\n", "for", "key", "in", "state_dict", ".", "keys", "(", ")", ":", "\n", "                ", "new_key", "=", "None", "\n", "if", "\"gamma\"", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "\"gamma\"", ",", "\"weight\"", ")", "\n", "", "if", "\"beta\"", "in", "key", ":", "\n", "                    ", "new_key", "=", "key", ".", "replace", "(", "\"beta\"", ",", "\"bias\"", ")", "\n", "", "if", "new_key", ":", "\n", "                    ", "old_keys", ".", "append", "(", "key", ")", "\n", "new_keys", ".", "append", "(", "new_key", ")", "\n", "", "", "for", "old_key", ",", "new_key", "in", "zip", "(", "old_keys", ",", "new_keys", ")", ":", "\n", "                ", "state_dict", "[", "new_key", "]", "=", "state_dict", ".", "pop", "(", "old_key", ")", "\n", "\n", "# copy state_dict so _load_from_state_dict can modify it", "\n", "", "metadata", "=", "getattr", "(", "state_dict", ",", "\"_metadata\"", ",", "None", ")", "\n", "state_dict", "=", "state_dict", ".", "copy", "(", ")", "\n", "if", "metadata", "is", "not", "None", ":", "\n", "                ", "state_dict", ".", "_metadata", "=", "metadata", "\n", "\n", "# PyTorch's `_load_from_state_dict` does not copy parameters in a module's descendants", "\n", "# so we need to apply the function recursively.", "\n", "", "def", "load", "(", "module", ":", "nn", ".", "Module", ",", "prefix", "=", "\"\"", ")", ":", "\n", "                ", "local_metadata", "=", "{", "}", "if", "metadata", "is", "None", "else", "metadata", ".", "get", "(", "prefix", "[", ":", "-", "1", "]", ",", "{", "}", ")", "\n", "module", ".", "_load_from_state_dict", "(", "\n", "state_dict", ",", "prefix", ",", "local_metadata", ",", "True", ",", "missing_keys", ",", "unexpected_keys", ",", "error_msgs", "\n", ")", "\n", "for", "name", ",", "child", "in", "module", ".", "_modules", ".", "items", "(", ")", ":", "\n", "                    ", "if", "child", "is", "not", "None", ":", "\n", "                        ", "load", "(", "child", ",", "prefix", "+", "name", "+", "\".\"", ")", "\n", "\n", "# Make sure we are able to load base models as well as derived models (with heads)", "\n", "", "", "", "start_prefix", "=", "\"\"", "\n", "model_to_load", "=", "model", "\n", "if", "not", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "any", "(", "\n", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", "\n", ")", ":", "\n", "                ", "start_prefix", "=", "cls", ".", "base_model_prefix", "+", "\".\"", "\n", "", "if", "hasattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "and", "not", "any", "(", "\n", "s", ".", "startswith", "(", "cls", ".", "base_model_prefix", ")", "for", "s", "in", "state_dict", ".", "keys", "(", ")", "\n", ")", ":", "\n", "                ", "model_to_load", "=", "getattr", "(", "model", ",", "cls", ".", "base_model_prefix", ")", "\n", "\n", "", "load", "(", "model_to_load", ",", "prefix", "=", "start_prefix", ")", "\n", "\n", "if", "model", ".", "__class__", ".", "__name__", "!=", "model_to_load", ".", "__class__", ".", "__name__", ":", "\n", "                ", "base_model_state_dict", "=", "model_to_load", ".", "state_dict", "(", ")", ".", "keys", "(", ")", "\n", "head_model_state_dict_without_base_prefix", "=", "[", "\n", "key", ".", "split", "(", "cls", ".", "base_model_prefix", "+", "\".\"", ")", "[", "-", "1", "]", "for", "key", "in", "model", ".", "state_dict", "(", ")", ".", "keys", "(", ")", "\n", "]", "\n", "\n", "missing_keys", ".", "extend", "(", "head_model_state_dict_without_base_prefix", "-", "base_model_state_dict", ")", "\n", "\n", "", "if", "len", "(", "missing_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Weights of {} not initialized from pretrained model: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "missing_keys", "\n", ")", "\n", ")", "\n", "", "if", "len", "(", "unexpected_keys", ")", ">", "0", ":", "\n", "                ", "logger", ".", "info", "(", "\n", "\"Weights from pretrained model not used in {}: {}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "unexpected_keys", "\n", ")", "\n", ")", "\n", "", "if", "len", "(", "error_msgs", ")", ">", "0", ":", "\n", "                ", "raise", "RuntimeError", "(", "\n", "\"Error(s) in loading state_dict for {}:\\n\\t{}\"", ".", "format", "(", "\n", "model", ".", "__class__", ".", "__name__", ",", "\"\\n\\t\"", ".", "join", "(", "error_msgs", ")", "\n", ")", "\n", ")", "\n", "", "", "model", ".", "tie_weights", "(", ")", "# make sure token embedding weights are still tied if needed", "\n", "\n", "# Set model in evaluation mode to desactivate DropOut modules by default", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "if", "output_loading_info", ":", "\n", "            ", "loading_info", "=", "{", "\n", "\"missing_keys\"", ":", "missing_keys", ",", "\n", "\"unexpected_keys\"", ":", "unexpected_keys", ",", "\n", "\"error_msgs\"", ":", "error_msgs", ",", "\n", "}", "\n", "return", "model", ",", "loading_info", "\n", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.prepare_inputs_for_generation": [[584, 586], ["None"], "methods", ["None"], ["", "def", "prepare_inputs_for_generation", "(", "self", ",", "input_ids", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "{", "\"input_ids\"", ":", "input_ids", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._do_output_past": [[587, 596], ["getattr", "getattr", "len"], "methods", ["None"], ["", "def", "_do_output_past", "(", "self", ",", "outputs", ")", ":", "\n", "        ", "\"\"\"During generation, decide whether to pass the `past` variable to the next forward pass.\"\"\"", "\n", "has_output_past", "=", "getattr", "(", "self", ".", "config", ",", "\"output_past\"", ",", "False", ")", "\n", "mem_len", "=", "getattr", "(", "self", ".", "config", ",", "\"mem_len\"", ",", "0", ")", "\n", "if", "len", "(", "outputs", ")", "<=", "1", ":", "\n", "            ", "return", "False", "\n", "", "if", "mem_len", ">", "0", "or", "has_output_past", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.enforce_repetition_penalty_": [[597, 606], ["range", "set", "prev_output_tokens[].tolist"], "methods", ["None"], ["", "def", "enforce_repetition_penalty_", "(", "self", ",", "lprobs", ",", "batch_size", ",", "num_beams", ",", "prev_output_tokens", ",", "repetition_penalty", ")", ":", "\n", "        ", "\"\"\"repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858). \"\"\"", "\n", "for", "i", "in", "range", "(", "batch_size", "*", "num_beams", ")", ":", "\n", "            ", "for", "previous_token", "in", "set", "(", "prev_output_tokens", "[", "i", "]", ".", "tolist", "(", ")", ")", ":", "\n", "# if score < 0 then repetition penalty has to multiplied to reduce the previous token probability", "\n", "                ", "if", "lprobs", "[", "i", ",", "previous_token", "]", "<", "0", ":", "\n", "                    ", "lprobs", "[", "i", ",", "previous_token", "]", "*=", "repetition_penalty", "\n", "", "else", ":", "\n", "                    ", "lprobs", "[", "i", ",", "previous_token", "]", "/=", "repetition_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.generate": [[607, 843], ["torch.no_grad", "isinstance", "isinstance", "modeling_utils.PreTrainedModel.get_output_embeddings", "AttributeError", "isinstance", "isinstance", "isinstance", "isinstance", "torch.full", "logger.warning", "input_ids.contiguous().view.contiguous().view.unsqueeze().expand", "input_ids.contiguous().view.contiguous().view.contiguous().view", "modeling_utils.PreTrainedModel._generate_beam_search", "modeling_utils.PreTrainedModel._generate_no_beam_search", "isinstance", "isinstance", "isinstance", "isinstance", "input_ids.contiguous().view.contiguous().view.dim", "input_ids.contiguous().view.contiguous().view.unsqueeze", "input_ids.contiguous().view.contiguous().view.contiguous", "isinstance", "next", "modeling_utils.PreTrainedModel.parameters"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.get_output_embeddings", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._generate_beam_search", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._generate_no_beam_search"], ["", "", "", "", "@", "torch", ".", "no_grad", "(", ")", "\n", "def", "generate", "(", "\n", "self", ",", "\n", "input_ids", "=", "None", ",", "\n", "max_length", "=", "None", ",", "\n", "do_sample", "=", "True", ",", "\n", "num_beams", "=", "None", ",", "\n", "temperature", "=", "None", ",", "\n", "top_k", "=", "None", ",", "\n", "top_p", "=", "None", ",", "\n", "repetition_penalty", "=", "None", ",", "\n", "bos_token_id", "=", "None", ",", "\n", "pad_token_id", "=", "None", ",", "\n", "eos_token_ids", "=", "None", ",", "\n", "length_penalty", "=", "None", ",", "\n", "num_return_sequences", "=", "None", ",", "\n", ")", ":", "\n", "        ", "r\"\"\" Generates sequences for models with a LM head. The method currently supports greedy or penalized greedy decoding, sampling with top-k or nucleus sampling\n        and beam-search.\n\n        Adapted in part from `Facebook's XLM beam search code`_.\n\n        .. _`Facebook's XLM beam search code`:\n           https://github.com/facebookresearch/XLM/blob/9e6f6814d17be4fe5b15f2e6c43eb2b2d76daeb4/src/model/transformer.py#L529\n\n\n        Parameters:\n\n            input_ids: (`optional`) `torch.LongTensor` of shape `(batch_size, sequence_length)`\n                The sequence used as a prompt for the generation. If `None` the method initializes\n                it as an empty `torch.LongTensor` of shape `(1,)`.\n\n            max_length: (`optional`) int\n                The max length of the sequence to be generated.  Between 1 and infinity. Default to 20.\n\n            do_sample: (`optional`) bool\n                If set to `False` greedy decoding is used. Otherwise sampling is used. Defaults to `True`.\n\n            num_beams: (`optional`) int\n                Number of beams for beam search. Must be between 1 and infinity. 1 means no beam search. Default to 1.\n\n            temperature: (`optional`) float\n                The value used to module the next token probabilities. Must be strictly positive. Default to 1.0.\n\n            top_k: (`optional`) int\n                The number of highest probability vocabulary tokens to keep for top-k-filtering. Between 1 and infinity. Default to 50.\n\n            top_p: (`optional`) float\n                The cumulative probability of parameter highest probability vocabulary tokens to keep for nucleus sampling. Must be between 0 and 1. Default to 1.\n\n            repetition_penalty: (`optional`) float\n                The parameter for repetition penalty. Between 1.0 and infinity. 1.0 means no penalty. Default to 1.0.\n\n            bos_token_id: (`optional`) int\n                Beginning of sentence token if no prompt is provided. Default to 0.\n\n            eos_token_ids: (`optional`) int or list of int\n                End of sequence token or list of tokens to stop the generation. Default to 0.\n            length_penalty: (`optional`) float\n                Exponential penalty to the length. Default to 1.\n\n            num_return_sequences: (`optional`) int\n                The number of independently computed returned sequences for each element in the batch. Default to 1.\n\n        Return:\n\n            output: `torch.LongTensor` of shape `(batch_size * num_return_sequences, sequence_length)`\n                sequence_length is either equal to max_length or shorter if all batches finished early due to the `eos_token_id`\n\n        Examples::\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            outputs = model.generate(max_length=40, do_sample=False)  # do greedy decoding\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('openai-gpt')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('openai-gpt')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, num_beams=5, num_return_sequences=3, temperature=1.5)  # generate 3 independent sequences using beam search decoding (5 beams) with sampling from initial context 'The dog'\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('distilgpt2')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('distilgpt2')    # Download model and configuration from S3 and cache.\n            input_context = 'The dog'\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=40, temperature=0.7, num_return_sequences=3)  # 3 generate sequences using by sampling\n            for i in range(3): #  3 output sequences were generated\n                print('Generated {}: {}'.format(i, tokenizer.decode(outputs[i], skip_special_tokens=True)))\n\n            tokenizer = AutoTokenizer.from_pretrained('ctrl')   # Initialize tokenizer\n            model = AutoModelWithLMHead.from_pretrained('ctrl')    # Download model and configuration from S3 and cache.\n            input_context = 'Legal My neighbor is'  # \"Legal\" is one of the control codes for ctrl\n            input_ids = torch.tensor(tokenizer.encode(input_context)).unsqueeze(0)  # encode input context\n            outputs = model.generate(input_ids=input_ids, max_length=50, temperature=0.7, repetition_penalty=1.2)  # generate sequences\n            print('Generated: {}'.format(tokenizer.decode(outputs[0], skip_special_tokens=True)))\n\n        \"\"\"", "\n", "\n", "# We cannot generate if the model does not have a LM head", "\n", "if", "self", ".", "get_output_embeddings", "(", ")", "is", "None", ":", "\n", "            ", "raise", "AttributeError", "(", "\n", "\"You tried to generate sequences with a model that does not have a LM Head.\"", "\n", "\"Please use another model class (e.g. `OpenAIGPTLMHeadModel`, `XLNetLMHeadModel`, `GPT2LMHeadModel`, `CTRLLMHeadModel`, `T5WithLMHeadModel`, `TransfoXLLMHeadModel`)\"", "\n", ")", "\n", "\n", "", "max_length", "=", "max_length", "if", "max_length", "is", "not", "None", "else", "self", ".", "config", ".", "max_length", "\n", "do_sample", "=", "do_sample", "if", "do_sample", "is", "not", "None", "else", "self", ".", "config", ".", "do_sample", "\n", "num_beams", "=", "num_beams", "if", "num_beams", "is", "not", "None", "else", "self", ".", "config", ".", "num_beams", "\n", "temperature", "=", "temperature", "if", "temperature", "is", "not", "None", "else", "self", ".", "config", ".", "temperature", "\n", "top_k", "=", "top_k", "if", "top_k", "is", "not", "None", "else", "self", ".", "config", ".", "top_k", "\n", "top_p", "=", "top_p", "if", "top_p", "is", "not", "None", "else", "self", ".", "config", ".", "top_p", "\n", "repetition_penalty", "=", "repetition_penalty", "if", "repetition_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "repetition_penalty", "\n", "bos_token_id", "=", "bos_token_id", "if", "bos_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "bos_token_id", "\n", "pad_token_id", "=", "pad_token_id", "if", "pad_token_id", "is", "not", "None", "else", "self", ".", "config", ".", "pad_token_id", "\n", "eos_token_ids", "=", "eos_token_ids", "if", "eos_token_ids", "is", "not", "None", "else", "self", ".", "config", ".", "eos_token_ids", "\n", "length_penalty", "=", "length_penalty", "if", "length_penalty", "is", "not", "None", "else", "self", ".", "config", ".", "length_penalty", "\n", "num_return_sequences", "=", "(", "\n", "num_return_sequences", "if", "num_return_sequences", "is", "not", "None", "else", "self", ".", "config", ".", "num_return_sequences", "\n", ")", "\n", "\n", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "batch_size", "=", "input_ids", ".", "shape", "[", "0", "]", "# overriden by the input batch_size", "\n", "", "else", ":", "\n", "            ", "batch_size", "=", "1", "\n", "", "if", "isinstance", "(", "eos_token_ids", ",", "int", ")", ":", "\n", "            ", "eos_token_ids", "=", "[", "eos_token_ids", "]", "\n", "\n", "", "assert", "isinstance", "(", "max_length", ",", "int", ")", "and", "max_length", ">", "0", ",", "\"`max_length` should be a strictly positive integer.\"", "\n", "assert", "isinstance", "(", "do_sample", ",", "bool", ")", ",", "\"`do_sample` should be a boolean.\"", "\n", "assert", "isinstance", "(", "num_beams", ",", "int", ")", "and", "num_beams", ">", "0", ",", "\"`num_beams` should be a strictly positive integer.\"", "\n", "assert", "temperature", ">", "0", ",", "\"`temperature` should be strictly positive.\"", "\n", "assert", "isinstance", "(", "top_k", ",", "int", ")", "and", "top_k", ">=", "0", ",", "\"`top_k` should be a positive integer.\"", "\n", "assert", "0", "<=", "top_p", "<=", "1", ",", "\"`top_p` should be between 0 and 1.\"", "\n", "assert", "repetition_penalty", ">=", "1.0", ",", "\"`repetition_penalty` should be >= 1.\"", "\n", "assert", "input_ids", "is", "not", "None", "or", "(", "\n", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", "\n", ")", ",", "\"If input_ids is not defined, `bos_token_id` should be a positive integer.\"", "\n", "assert", "pad_token_id", "is", "None", "or", "(", "\n", "isinstance", "(", "pad_token_id", ",", "int", ")", "and", "(", "pad_token_id", ">=", "0", ")", "\n", ")", ",", "\"`pad_token_id` should be a positive integer.\"", "\n", "assert", "(", "eos_token_ids", "is", "None", ")", "or", "(", "\n", "isinstance", "(", "eos_token_ids", ",", "(", "list", ",", "tuple", ")", ")", "and", "(", "(", "isinstance", "(", "e", ",", "int", ")", "and", "e", ">=", "0", ")", "for", "e", "in", "eos_token_ids", ")", "\n", ")", ",", "\"`eos_token_ids` should be a positive integer or a list/tuple of positive integers.\"", "\n", "assert", "length_penalty", ">", "0", ",", "\"`length_penalty` should be strictly positive.\"", "\n", "assert", "(", "\n", "isinstance", "(", "num_return_sequences", ",", "int", ")", "and", "num_return_sequences", ">", "0", "\n", ")", ",", "\"`num_return_sequences` should be a strictly positive integer.\"", "\n", "\n", "if", "input_ids", "is", "None", ":", "\n", "            ", "assert", "isinstance", "(", "bos_token_id", ",", "int", ")", "and", "bos_token_id", ">=", "0", ",", "(", "\n", "\"you should either supply a context to complete as `input_ids` input \"", "\n", "\"or a `bos_token_id` (integer >= 0) as a first token to start the generation.\"", "\n", ")", "\n", "input_ids", "=", "torch", ".", "full", "(", "\n", "(", "batch_size", ",", "1", ")", ",", "bos_token_id", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", ")", "\n", "", "else", ":", "\n", "            ", "assert", "input_ids", ".", "dim", "(", ")", "==", "2", ",", "\"Input prompt should be of shape (batch_size, sequence length).\"", "\n", "\n", "# not allow to duplicate outputs when greedy decoding", "\n", "", "if", "do_sample", "is", "False", ":", "\n", "            ", "if", "num_beams", "==", "1", ":", "\n", "# no_beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_return_sequences", "==", "1", "\n", ")", ",", "\"Greedy decoding will always produce the same output for num_beams == 1 and num_return_sequences > 1. Please set num_return_sequences = 1\"", "\n", "\n", "", "else", ":", "\n", "# beam_search greedy generation conditions", "\n", "                ", "assert", "(", "\n", "num_beams", ">=", "num_return_sequences", "\n", ")", ",", "\"Greedy beam search decoding cannot return more sequences than it has beams. Please set num_beams >= num_return_sequences\"", "\n", "\n", "", "", "if", "pad_token_id", "is", "None", "and", "eos_token_ids", "is", "not", "None", ":", "\n", "            ", "logger", ".", "warning", "(", "\n", "\"Setting `pad_token_id` to {} (first `eos_token_id`) to generate sequence\"", ".", "format", "(", "eos_token_ids", "[", "0", "]", ")", "\n", ")", "\n", "pad_token_id", "=", "eos_token_ids", "[", "0", "]", "\n", "\n", "# current position and vocab size", "\n", "", "cur_len", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "vocab_size", "=", "self", ".", "config", ".", "vocab_size", "\n", "\n", "# set effective batch size and effective batch multiplier according to do_sample", "\n", "if", "do_sample", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "*", "num_return_sequences", "\n", "effective_batch_mult", "=", "num_return_sequences", "\n", "", "else", ":", "\n", "            ", "effective_batch_size", "=", "batch_size", "\n", "effective_batch_mult", "=", "1", "\n", "\n", "# Expand input ids if num_beams > 1 or num_return_sequences > 1", "\n", "", "if", "num_return_sequences", ">", "1", "or", "num_beams", ">", "1", ":", "\n", "            ", "input_ids_len", "=", "input_ids", ".", "shape", "[", "-", "1", "]", "\n", "input_ids", "=", "input_ids", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "batch_size", ",", "effective_batch_mult", "*", "num_beams", ",", "input_ids_len", ")", "\n", "input_ids", "=", "input_ids", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "effective_batch_size", "*", "num_beams", ",", "input_ids_len", "\n", ")", "# shape: (batch_size * num_return_sequences * num_beams, cur_len)", "\n", "\n", "", "if", "num_beams", ">", "1", ":", "\n", "            ", "output", "=", "self", ".", "_generate_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", "num_return_sequences", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", "\n", "", "else", ":", "\n", "            ", "output", "=", "self", ".", "_generate_no_beam_search", "(", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "effective_batch_size", ",", "\n", ")", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._generate_no_beam_search": [[844, 928], ["torch.cat.new().fill_", "torch.cat.new().fill_", "enumerate", "modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "modeling_utils.PreTrainedModel.", "modeling_utils.PreTrainedModel._do_output_past", "torch.cat", "torch.cat.new().fill_.min().item", "torch.cat.new().fill_.max().item", "torch.cat.new().fill_", "torch.cat.new", "torch.cat.new", "modeling_utils.PreTrainedModel.enforce_repetition_penalty_", "modeling_utils.top_k_top_p_filtering", "torch.multinomial().squeeze", "torch.argmax", "torch.cat.new().fill_.max", "tokens_to_add.unsqueeze", "torch.cat.new().fill_.mul().bool", "torch.cat.new().fill_.masked_fill_", "torch.cat.new().fill_.mul_", "torch.cat.new().fill_.min", "torch.cat.new().fill_.max", "torch.cat.new", "torch.multinomial", "torch.cat.new().fill_.max().item", "torch.nn.functional.softmax", "torch.cat.new().fill_.mul", "eos_in_sents.long", "torch.cat.new().fill_.max"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._do_output_past", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.enforce_repetition_penalty_", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.top_k_top_p_filtering"], ["", "def", "_generate_no_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example without beam search (num_beams == 1).\n            All returned sequence are generated independantly.\n        \"\"\"", "\n", "# length of generated sentences / unfinished sentences", "\n", "unfinished_sents", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "batch_size", ")", ".", "fill_", "(", "max_length", ")", "\n", "\n", "past", "=", "None", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", "=", "past", ")", "\n", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty from CTRL paper (https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "self", ".", "enforce_repetition_penalty_", "(", "next_token_logits", ",", "batch_size", ",", "1", ",", "input_ids", ",", "repetition_penalty", ")", "\n", "\n", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "# Top-p/top-k filtering", "\n", "", "next_token_logits", "=", "top_k_top_p_filtering", "(", "next_token_logits", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ")", "\n", "# Sample", "\n", "next_token", "=", "torch", ".", "multinomial", "(", "F", ".", "softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "1", ")", ".", "squeeze", "(", "1", ")", "\n", "", "else", ":", "\n", "# Greedy decoding", "\n", "                ", "next_token", "=", "torch", ".", "argmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# update generations and finished sentences", "\n", "", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "# pad finished sentences if eos_token_ids exist", "\n", "                ", "tokens_to_add", "=", "next_token", "*", "unfinished_sents", "+", "(", "pad_token_id", ")", "*", "(", "1", "-", "unfinished_sents", ")", "\n", "", "else", ":", "\n", "                ", "tokens_to_add", "=", "next_token", "\n", "\n", "", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "tokens_to_add", ".", "unsqueeze", "(", "-", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "if", "eos_token_ids", "is", "not", "None", ":", "\n", "                ", "for", "eos_token_id", "in", "eos_token_ids", ":", "\n", "                    ", "eos_in_sents", "=", "tokens_to_add", "==", "eos_token_id", "\n", "# if sentence is unfinished and the token to add is eos, sent_lengths is filled with current length", "\n", "is_sents_unfinished_and_token_to_add_is_eos", "=", "unfinished_sents", ".", "mul", "(", "eos_in_sents", ".", "long", "(", ")", ")", ".", "bool", "(", ")", "\n", "sent_lengths", ".", "masked_fill_", "(", "is_sents_unfinished_and_token_to_add_is_eos", ",", "cur_len", "+", "1", ")", "\n", "# unfinished_sents is set to zero if eos in sentence", "\n", "unfinished_sents", ".", "mul_", "(", "(", "~", "eos_in_sents", ")", ".", "long", "(", ")", ")", "\n", "\n", "# stop when there is a </s> in each sentence, or if we exceed the maximul length", "\n", "", "", "if", "unfinished_sents", ".", "max", "(", ")", "==", "0", ":", "\n", "                ", "break", "\n", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# if there are different sentences lengths in the batch, some batches have to be padded", "\n", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined if batches have different lengths\"", "\n", "# finished sents are filled with pad_token", "\n", "decoded", "=", "input_ids", ".", "new", "(", "batch_size", ",", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "", "else", ":", "\n", "            ", "decoded", "=", "input_ids", "\n", "\n", "", "for", "hypo_idx", ",", "hypo", "in", "enumerate", "(", "input_ids", ")", ":", "\n", "            ", "decoded", "[", "hypo_idx", ",", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "=", "hypo", "[", ":", "sent_lengths", "[", "hypo_idx", "]", "]", "\n", "\n", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._generate_beam_search": [[929, 1154], ["torch.zeros", "beam_scores.new.new.view", "range", "torch.cat.new", "enumerate", "modeling_utils.BeamHypotheses", "modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "modeling_utils.PreTrainedModel.", "modeling_utils.PreTrainedModel._do_output_past", "range", "beam_scores.new.new.new", "torch.cat.new", "torch.cat.new", "torch.cat", "all", "range", "sorted", "range", "torch.cat.new.min().item", "torch.cat.new.max().item", "min", "torch.cat.new().fill_", "enumerate", "torch.stack().type().to", "range", "range", "modeling_utils.PreTrainedModel.enforce_repetition_penalty_", "torch.nn.functional.log_softmax", "modeling_utils.top_k_top_p_filtering", "_scores.contiguous().view.contiguous().view.contiguous().view", "torch.multinomial", "torch.gather", "torch.sort", "torch.gather", "torch.nn.functional.log_softmax", "next_scores.view.view.view", "torch.topk", "next_scores.view.view.size", "torch.gather.size", "zip", "next_batch_beam.extend", "len", "modeling_utils.PreTrainedModel._reorder_cache", "all", "torch.all", "beam_scores[].item", "generated_hyps[].add", "len", "best.append", "beam_scores[].expand_as", "torch.nn.functional.softmax", "torch.nn.functional.log_softmax.size", "beam_scores[].expand_as", "generated_hyps[].is_done", "next_batch_beam.extend", "len", "len", "torch.cat.new.unsqueeze", "sorted.pop", "torch.cat.new.min", "torch.cat.new.max", "torch.cat.new.max().item", "torch.cat.new", "len", "torch.stack().type", "next", "_scores.contiguous().view.contiguous().view.contiguous", "next_scores[].max().item", "len", "generated_hyps[].add", "next_sent_beam.append", "len", "beam_scores.new.new.view", "modeling_utils.PreTrainedModel.parameters", "token_id.item", "input_ids[].clone", "score.item", "beam_scores.new.new.view", "torch.cat.new.max", "torch.stack", "next_scores[].max"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.prepare_inputs_for_generation", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._do_output_past", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel.enforce_repetition_penalty_", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.top_k_top_p_filtering", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._reorder_cache", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.BeamHypotheses.add", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.BeamHypotheses.is_done", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.BeamHypotheses.add"], ["", "def", "_generate_beam_search", "(", "\n", "self", ",", "\n", "input_ids", ",", "\n", "cur_len", ",", "\n", "max_length", ",", "\n", "do_sample", ",", "\n", "temperature", ",", "\n", "top_k", ",", "\n", "top_p", ",", "\n", "repetition_penalty", ",", "\n", "pad_token_id", ",", "\n", "eos_token_ids", ",", "\n", "batch_size", ",", "\n", "num_return_sequences", ",", "\n", "length_penalty", ",", "\n", "num_beams", ",", "\n", "vocab_size", ",", "\n", ")", ":", "\n", "        ", "\"\"\" Generate sequences for each example with beam search.\n        \"\"\"", "\n", "\n", "# generated hypotheses", "\n", "generated_hyps", "=", "[", "\n", "BeamHypotheses", "(", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", "=", "False", ")", "for", "_", "in", "range", "(", "batch_size", ")", "\n", "]", "\n", "\n", "# scores for each sentence in the beam", "\n", "beam_scores", "=", "torch", ".", "zeros", "(", "(", "batch_size", ",", "num_beams", ")", ",", "dtype", "=", "torch", ".", "float", ",", "device", "=", "input_ids", ".", "device", ")", "\n", "# Greedy decoding it is made sure that only tokens of the first beam are considered to avoid sampling the exact same tokens three times", "\n", "if", "do_sample", "is", "False", ":", "\n", "            ", "beam_scores", "[", ":", ",", "1", ":", "]", "=", "-", "1e9", "\n", "", "beam_scores", "=", "beam_scores", ".", "view", "(", "-", "1", ")", "# shape (batch_size * num_beams,)", "\n", "\n", "# cache compute states", "\n", "past", "=", "None", "\n", "\n", "# done sentences", "\n", "done", "=", "[", "False", "for", "_", "in", "range", "(", "batch_size", ")", "]", "\n", "\n", "while", "cur_len", "<", "max_length", ":", "\n", "            ", "model_inputs", "=", "self", ".", "prepare_inputs_for_generation", "(", "input_ids", ",", "past", "=", "past", ")", "\n", "outputs", "=", "self", "(", "**", "model_inputs", ")", "# (batch_size * num_beams, cur_len, vocab_size)", "\n", "next_token_logits", "=", "outputs", "[", "0", "]", "[", ":", ",", "-", "1", ",", ":", "]", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# if model has past, then set the past variable to speed up decoding", "\n", "if", "self", ".", "_do_output_past", "(", "outputs", ")", ":", "\n", "                ", "past", "=", "outputs", "[", "1", "]", "\n", "\n", "# repetition penalty (from CTRL paper https://arxiv.org/abs/1909.05858)", "\n", "", "if", "repetition_penalty", "!=", "1.0", ":", "\n", "                ", "self", ".", "enforce_repetition_penalty_", "(", "\n", "next_token_logits", ",", "batch_size", ",", "num_beams", ",", "input_ids", ",", "repetition_penalty", "\n", ")", "\n", "\n", "", "if", "do_sample", ":", "\n", "# Temperature (higher temperature => more likely to sample low probability tokens)", "\n", "                ", "if", "temperature", "!=", "1.0", ":", "\n", "                    ", "next_token_logits", "=", "next_token_logits", "/", "temperature", "\n", "\n", "", "scores", "=", "F", ".", "log_softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# Top-p/top-k filtering", "\n", "_scores", "=", "top_k_top_p_filtering", "(", "\n", "_scores", ",", "top_k", "=", "top_k", ",", "top_p", "=", "top_p", ",", "min_tokens_to_keep", "=", "2", "\n", ")", "# (batch_size * num_beams, vocab_size)", "\n", "\n", "# re-organize to group the beam together to sample from all beam_idxs", "\n", "_scores", "=", "_scores", ".", "contiguous", "(", ")", ".", "view", "(", "\n", "batch_size", ",", "num_beams", "*", "vocab_size", "\n", ")", "# (batch_size, num_beams * vocab_size)", "\n", "\n", "# Sample 2 next tokens for each beam (so we have some spare tokens and match output of greedy beam search)", "\n", "next_tokens", "=", "torch", ".", "multinomial", "(", "\n", "F", ".", "softmax", "(", "_scores", ",", "dim", "=", "-", "1", ")", ",", "num_samples", "=", "2", "*", "num_beams", "\n", ")", "# (batch_size, num_beams * 2)", "\n", "\n", "# Compute next scores", "\n", "next_scores", "=", "torch", ".", "gather", "(", "_scores", ",", "-", "1", ",", "next_tokens", ")", "# (batch_size, num_beams * 2)", "\n", "\n", "# sort the sampled vector to make sure that the first num_beams samples are the best", "\n", "next_scores", ",", "next_scores_indices", "=", "torch", ".", "sort", "(", "next_scores", ",", "descending", "=", "True", ",", "dim", "=", "1", ")", "\n", "next_tokens", "=", "torch", ".", "gather", "(", "next_tokens", ",", "-", "1", ",", "next_scores_indices", ")", "# (batch_size, num_beams * 2)", "\n", "", "else", ":", "\n", "# do greedy beam search", "\n", "                ", "scores", "=", "F", ".", "log_softmax", "(", "next_token_logits", ",", "dim", "=", "-", "1", ")", "# (batch_size * num_beams, vocab_size)", "\n", "assert", "scores", ".", "size", "(", ")", "==", "(", "batch_size", "*", "num_beams", ",", "vocab_size", ")", "\n", "# Add the log prob of the new beams to the log prob of the beginning of the sequence (sum of logs == log of the product)", "\n", "next_scores", "=", "scores", "+", "beam_scores", "[", ":", ",", "None", "]", ".", "expand_as", "(", "scores", ")", "# (batch_size * num_beams, vocab_size)", "\n", "# re-organize to group the beam together (we are keeping top hypothesis accross beams)", "\n", "next_scores", "=", "next_scores", ".", "view", "(", "\n", "batch_size", ",", "num_beams", "*", "vocab_size", "\n", ")", "# (batch_size, num_beams * vocab_size)", "\n", "\n", "next_scores", ",", "next_tokens", "=", "torch", ".", "topk", "(", "next_scores", ",", "2", "*", "num_beams", ",", "dim", "=", "1", ",", "largest", "=", "True", ",", "sorted", "=", "True", ")", "\n", "\n", "", "assert", "next_scores", ".", "size", "(", ")", "==", "next_tokens", ".", "size", "(", ")", "==", "(", "batch_size", ",", "2", "*", "num_beams", ")", "\n", "\n", "# next batch beam content", "\n", "# list of (batch_size * num_beams) tuple(next hypothesis score, next word, current position in the batch)", "\n", "next_batch_beam", "=", "[", "]", "\n", "\n", "# for each sentence", "\n", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "\n", "# if we are done with this sentence", "\n", "                ", "done", "[", "batch_idx", "]", "=", "done", "[", "batch_idx", "]", "or", "generated_hyps", "[", "batch_idx", "]", ".", "is_done", "(", "\n", "next_scores", "[", "batch_idx", "]", ".", "max", "(", ")", ".", "item", "(", ")", "\n", ")", "\n", "if", "done", "[", "batch_idx", "]", ":", "\n", "                    ", "assert", "(", "\n", "len", "(", "generated_hyps", "[", "batch_idx", "]", ")", ">=", "num_beams", "\n", ")", ",", "\"Batch can only be done if at least {} beams have been generated\"", ".", "format", "(", "num_beams", ")", "\n", "assert", "(", "\n", "eos_token_ids", "is", "not", "None", "and", "pad_token_id", "is", "not", "None", "\n", ")", ",", "\"generated beams >= num_beams -> eos_token_id and pad_token have to be defined\"", "\n", "next_batch_beam", ".", "extend", "(", "[", "(", "0", ",", "pad_token_id", ",", "0", ")", "]", "*", "num_beams", ")", "# pad the batch", "\n", "continue", "\n", "\n", "# next sentence beam content", "\n", "", "next_sent_beam", "=", "[", "]", "\n", "\n", "# next tokens for this sentence", "\n", "for", "idx", ",", "score", "in", "zip", "(", "next_tokens", "[", "batch_idx", "]", ",", "next_scores", "[", "batch_idx", "]", ")", ":", "\n", "\n", "# get beam and word IDs", "\n", "                    ", "beam_id", "=", "idx", "//", "vocab_size", "\n", "token_id", "=", "idx", "%", "vocab_size", "\n", "\n", "effective_beam_id", "=", "batch_idx", "*", "num_beams", "+", "beam_id", "\n", "# add to generated hypotheses if end of sentence", "\n", "if", "eos_token_ids", "is", "not", "None", "and", "token_id", ".", "item", "(", ")", "in", "eos_token_ids", ":", "\n", "                        ", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "\n", "input_ids", "[", "effective_beam_id", "]", ".", "clone", "(", ")", ",", "score", ".", "item", "(", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "# add next predicted word if it is not eos_token", "\n", "                        ", "next_sent_beam", ".", "append", "(", "(", "score", ",", "token_id", ",", "effective_beam_id", ")", ")", "\n", "\n", "# the beam for next step is full", "\n", "", "if", "len", "(", "next_sent_beam", ")", "==", "num_beams", ":", "\n", "                        ", "break", "\n", "\n", "# update next beam content", "\n", "", "", "assert", "len", "(", "next_sent_beam", ")", "==", "num_beams", ",", "\"Beam should always be full\"", "\n", "next_batch_beam", ".", "extend", "(", "next_sent_beam", ")", "\n", "assert", "len", "(", "next_batch_beam", ")", "==", "num_beams", "*", "(", "batch_idx", "+", "1", ")", "\n", "\n", "# sanity check / prepare next batch", "\n", "", "assert", "len", "(", "next_batch_beam", ")", "==", "batch_size", "*", "num_beams", "\n", "beam_scores", "=", "beam_scores", ".", "new", "(", "[", "x", "[", "0", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_tokens", "=", "input_ids", ".", "new", "(", "[", "x", "[", "1", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "beam_idx", "=", "input_ids", ".", "new", "(", "[", "x", "[", "2", "]", "for", "x", "in", "next_batch_beam", "]", ")", "\n", "\n", "# re-order batch", "\n", "input_ids", "=", "input_ids", "[", "beam_idx", ",", ":", "]", "\n", "input_ids", "=", "torch", ".", "cat", "(", "[", "input_ids", ",", "beam_tokens", ".", "unsqueeze", "(", "1", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# re-order internal states", "\n", "if", "past", ":", "\n", "                ", "past", "=", "self", ".", "_reorder_cache", "(", "past", ",", "beam_idx", ")", "\n", "\n", "# stop when we are done with each sentence", "\n", "", "if", "all", "(", "done", ")", ":", "\n", "                ", "break", "\n", "\n", "# update current length", "\n", "", "cur_len", "=", "cur_len", "+", "1", "\n", "\n", "# finalize all open beam hypotheses and end to generated hypotheses", "\n", "", "for", "batch_idx", "in", "range", "(", "batch_size", ")", ":", "\n", "            ", "if", "done", "[", "batch_idx", "]", ":", "\n", "                ", "continue", "\n", "\n", "# test that beam scores match previously calculated scores if not eos and batch_idx not done", "\n", "", "if", "eos_token_ids", "is", "not", "None", "and", "all", "(", "\n", "(", "token_id", "%", "vocab_size", ")", ".", "item", "(", ")", "not", "in", "eos_token_ids", "for", "token_id", "in", "next_tokens", "[", "batch_idx", "]", "\n", ")", ":", "\n", "                ", "assert", "torch", ".", "all", "(", "\n", "next_scores", "[", "batch_idx", ",", ":", "num_beams", "]", "==", "beam_scores", ".", "view", "(", "batch_size", ",", "num_beams", ")", "[", "batch_idx", "]", "\n", ")", ",", "\"If batch_idx is not done, final next scores: {} have to equal to accumulated beam_scores: {}\"", ".", "format", "(", "\n", "next_scores", "[", ":", ",", ":", "num_beams", "]", "[", "batch_idx", "]", ",", "beam_scores", ".", "view", "(", "batch_size", ",", "num_beams", ")", "[", "batch_idx", "]", "\n", ")", "\n", "\n", "# need to add best num_beams hypotheses to generated hyps", "\n", "", "for", "beam_id", "in", "range", "(", "num_beams", ")", ":", "\n", "                ", "effective_beam_id", "=", "batch_idx", "*", "num_beams", "+", "beam_id", "\n", "final_score", "=", "beam_scores", "[", "effective_beam_id", "]", ".", "item", "(", ")", "\n", "final_tokens", "=", "input_ids", "[", "effective_beam_id", "]", "\n", "generated_hyps", "[", "batch_idx", "]", ".", "add", "(", "final_tokens", ",", "final_score", ")", "\n", "\n", "# depending on whether greedy generation is wanted or not define different output_batch_size and output_num_return_sequences_per_batch", "\n", "", "", "output_batch_size", "=", "batch_size", "if", "do_sample", "else", "batch_size", "*", "num_return_sequences", "\n", "output_num_return_sequences_per_batch", "=", "1", "if", "do_sample", "else", "num_return_sequences", "\n", "\n", "# select the best hypotheses", "\n", "sent_lengths", "=", "input_ids", ".", "new", "(", "output_batch_size", ")", "\n", "best", "=", "[", "]", "\n", "\n", "# retrieve best hypotheses", "\n", "for", "i", ",", "hypotheses", "in", "enumerate", "(", "generated_hyps", ")", ":", "\n", "            ", "sorted_hyps", "=", "sorted", "(", "hypotheses", ".", "beams", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ")", "\n", "for", "j", "in", "range", "(", "output_num_return_sequences_per_batch", ")", ":", "\n", "                ", "effective_batch_idx", "=", "output_num_return_sequences_per_batch", "*", "i", "+", "j", "\n", "best_hyp", "=", "sorted_hyps", ".", "pop", "(", ")", "[", "1", "]", "\n", "sent_lengths", "[", "effective_batch_idx", "]", "=", "len", "(", "best_hyp", ")", "\n", "best", ".", "append", "(", "best_hyp", ")", "\n", "\n", "# shorter batches are filled with pad_token", "\n", "", "", "if", "sent_lengths", ".", "min", "(", ")", ".", "item", "(", ")", "!=", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", ":", "\n", "            ", "assert", "pad_token_id", "is", "not", "None", ",", "\"`Pad_token_id` has to be defined\"", "\n", "sent_max_len", "=", "min", "(", "sent_lengths", ".", "max", "(", ")", ".", "item", "(", ")", "+", "1", ",", "max_length", ")", "\n", "decoded", "=", "input_ids", ".", "new", "(", "output_batch_size", ",", "sent_max_len", ")", ".", "fill_", "(", "pad_token_id", ")", "\n", "\n", "# fill with hypothesis and eos_token_id if necessary", "\n", "for", "i", ",", "hypo", "in", "enumerate", "(", "best", ")", ":", "\n", "                ", "decoded", "[", "i", ",", ":", "sent_lengths", "[", "i", "]", "]", "=", "hypo", "\n", "if", "sent_lengths", "[", "i", "]", "<", "max_length", ":", "\n", "                    ", "decoded", "[", "i", ",", "sent_lengths", "[", "i", "]", "]", "=", "eos_token_ids", "[", "0", "]", "\n", "", "", "", "else", ":", "\n", "# none of the hypotheses have an eos_token", "\n", "            ", "assert", "(", "len", "(", "hypo", ")", "==", "max_length", "for", "hypo", "in", "best", ")", "\n", "decoded", "=", "torch", ".", "stack", "(", "best", ")", ".", "type", "(", "torch", ".", "long", ")", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", ")", "\n", "\n", "", "return", "decoded", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PreTrainedModel._reorder_cache": [[1155, 1168], ["tuple", "torch.cat", "reordered_past.append", "layer_past[].unsqueeze().clone().detach", "layer_past[].unsqueeze().clone", "layer_past[].unsqueeze"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_reorder_cache", "(", "past", ",", "beam_idx", ")", ":", "\n", "        ", "reordered_past", "=", "[", "]", "\n", "for", "layer_past", "in", "past", ":", "\n", "# get the correct batch idx from layer past batch dim", "\n", "# batch dim of `past` and `mems` is at 2nd position", "\n", "            ", "reordered_layer_past", "=", "[", "layer_past", "[", ":", ",", "i", "]", ".", "unsqueeze", "(", "1", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "for", "i", "in", "beam_idx", "]", "\n", "reordered_layer_past", "=", "torch", ".", "cat", "(", "reordered_layer_past", ",", "dim", "=", "1", ")", "\n", "# check that shape matches", "\n", "assert", "reordered_layer_past", ".", "shape", "==", "layer_past", ".", "shape", "\n", "reordered_past", ".", "append", "(", "reordered_layer_past", ")", "\n", "", "past", "=", "tuple", "(", "reordered_past", ")", "\n", "return", "past", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.BeamHypotheses.__init__": [[1206, 1216], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_beams", ",", "max_length", ",", "length_penalty", ",", "early_stopping", ")", ":", "\n", "        ", "\"\"\"\n        Initialize n-best list of hypotheses.\n        \"\"\"", "\n", "self", ".", "max_length", "=", "max_length", "-", "1", "# ignoring bos_token", "\n", "self", ".", "length_penalty", "=", "length_penalty", "\n", "self", ".", "early_stopping", "=", "early_stopping", "\n", "self", ".", "num_beams", "=", "num_beams", "\n", "self", ".", "beams", "=", "[", "]", "\n", "self", ".", "worst_score", "=", "1e9", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.BeamHypotheses.__len__": [[1217, 1222], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Number of hypotheses in the list.\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "beams", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.BeamHypotheses.add": [[1223, 1236], ["modeling_utils.BeamHypotheses.beams.append", "len", "len", "len", "sorted", "min", "enumerate"], "methods", ["None"], ["", "def", "add", "(", "self", ",", "hyp", ",", "sum_logprobs", ")", ":", "\n", "        ", "\"\"\"\n        Add a new hypothesis to the list.\n        \"\"\"", "\n", "score", "=", "sum_logprobs", "/", "len", "(", "hyp", ")", "**", "self", ".", "length_penalty", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "num_beams", "or", "score", ">", "self", ".", "worst_score", ":", "\n", "            ", "self", ".", "beams", ".", "append", "(", "(", "score", ",", "hyp", ")", ")", "\n", "if", "len", "(", "self", ")", ">", "self", ".", "num_beams", ":", "\n", "                ", "sorted_scores", "=", "sorted", "(", "[", "(", "s", ",", "idx", ")", "for", "idx", ",", "(", "s", ",", "_", ")", "in", "enumerate", "(", "self", ".", "beams", ")", "]", ")", "\n", "del", "self", ".", "beams", "[", "sorted_scores", "[", "0", "]", "[", "1", "]", "]", "\n", "self", ".", "worst_score", "=", "sorted_scores", "[", "1", "]", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "self", ".", "worst_score", "=", "min", "(", "score", ",", "self", ".", "worst_score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.BeamHypotheses.is_done": [[1237, 1253], ["len"], "methods", ["None"], ["", "", "", "def", "is_done", "(", "self", ",", "best_sum_logprobs", ",", "cur_len", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        If there are enough hypotheses and that none of the hypotheses being generated\n        can become better than the worst one in the heap, then we are done with this sentence.\n        \"\"\"", "\n", "\n", "if", "len", "(", "self", ")", "<", "self", ".", "num_beams", ":", "\n", "            ", "return", "False", "\n", "", "elif", "self", ".", "early_stopping", ":", "\n", "            ", "return", "True", "\n", "", "else", ":", "\n", "            ", "if", "cur_len", "is", "None", ":", "\n", "                ", "cur_len", "=", "self", ".", "max_length", "\n", "", "cur_score", "=", "best_sum_logprobs", "/", "cur_len", "**", "self", ".", "length_penalty", "\n", "ret", "=", "self", ".", "worst_score", ">=", "cur_score", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.Conv1D.__init__": [[1256, 1266], ["torch.nn.Module.__init__", "torch.empty", "torch.nn.init.normal_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "nf", ",", "nx", ")", ":", "\n", "        ", "\"\"\" Conv1D layer as defined by Radford et al. for OpenAI GPT (and also used in GPT-2)\n            Basically works like a Linear layer but the weights are transposed\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "nf", "=", "nf", "\n", "w", "=", "torch", ".", "empty", "(", "nx", ",", "nf", ")", "\n", "nn", ".", "init", ".", "normal_", "(", "w", ",", "std", "=", "0.02", ")", "\n", "self", ".", "weight", "=", "nn", ".", "Parameter", "(", "w", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "nf", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.Conv1D.forward": [[1267, 1272], ["torch.addmm", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "size_out", "=", "x", ".", "size", "(", ")", "[", ":", "-", "1", "]", "+", "(", "self", ".", "nf", ",", ")", "\n", "x", "=", "torch", ".", "addmm", "(", "self", ".", "bias", ",", "x", ".", "view", "(", "-", "1", ",", "x", ".", "size", "(", "-", "1", ")", ")", ",", "self", ".", "weight", ")", "\n", "x", "=", "x", ".", "view", "(", "*", "size_out", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PoolerStartLogits.__init__": [[1277, 1280], ["torch.nn.Module.__init__", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PoolerStartLogits.forward": [[1281, 1296], ["modeling_utils.PoolerStartLogits.dense().squeeze", "modeling_utils.PoolerStartLogits.dense", "next", "modeling_utils.PoolerStartLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape `(batch_size, seq_len)`\n                invalid position mask such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "x", "=", "self", ".", "dense", "(", "hidden_states", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PoolerEndLogits.__init__": [[1302, 1308], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.LayerNorm", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "LayerNorm", "=", "nn", ".", "LayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PoolerEndLogits.forward": [[1309, 1343], ["modeling_utils.PoolerEndLogits.dense_0", "modeling_utils.PoolerEndLogits.activation", "modeling_utils.PoolerEndLogits.LayerNorm", "modeling_utils.PoolerEndLogits.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather", "start_states.expand.expand.expand", "torch.cat", "modeling_utils.PoolerEndLogits.dense_1", "next", "modeling_utils.PoolerEndLogits.parameters"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "p_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\" Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to hidden_states\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span:\n            **p_mask**: (`optional`) ``torch.FloatTensor`` of shape ``(batch_size, seq_len)``\n                Mask of invalid position such as query and special symbols (PAD, SEP, CLS)\n                1.0 means token should be masked.\n        \"\"\"", "\n", "assert", "(", "\n", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", "\n", ")", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "slen", ",", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "2", ":", "]", "\n", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "start_states", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ")", "# shape (bsz, slen, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "hidden_states", ",", "start_states", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "LayerNorm", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "if", "p_mask", "is", "not", "None", ":", "\n", "            ", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "65500", "*", "p_mask", "\n", "", "else", ":", "\n", "                ", "x", "=", "x", "*", "(", "1", "-", "p_mask", ")", "-", "1e30", "*", "p_mask", "\n", "\n", "", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PoolerAnswerClass.__init__": [[1348, 1353], ["torch.nn.Module.__init__", "torch.nn.Linear", "torch.nn.Tanh", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense_0", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "dense_1", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.PoolerAnswerClass.forward": [[1354, 1390], ["modeling_utils.PoolerAnswerClass.dense_0", "modeling_utils.PoolerAnswerClass.activation", "modeling_utils.PoolerAnswerClass.dense_1().squeeze", "start_positions[].expand", "hidden_states.gather().squeeze", "cls_index[].expand", "hidden_states.gather().squeeze", "torch.cat", "modeling_utils.PoolerAnswerClass.dense_1", "hidden_states.gather", "hidden_states.gather"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "start_states", "=", "None", ",", "start_positions", "=", "None", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            One of ``start_states``, ``start_positions`` should be not None.\n            If both are set, ``start_positions`` overrides ``start_states``.\n\n            **start_states**: ``torch.LongTensor`` of shape identical to ``hidden_states``.\n                hidden states of the first tokens for the labeled span.\n            **start_positions**: ``torch.LongTensor`` of shape ``(batch_size,)``\n                position of the first token for the labeled span.\n            **cls_index**: torch.LongTensor of shape ``(batch_size,)``\n                position of the CLS token. If None, take the last token.\n\n            note(Original repo):\n                no dependency on end_feature so that we can obtain one single `cls_logits`\n                for each sample\n        \"\"\"", "\n", "hsz", "=", "hidden_states", ".", "shape", "[", "-", "1", "]", "\n", "assert", "(", "\n", "start_states", "is", "not", "None", "or", "start_positions", "is", "not", "None", "\n", ")", ",", "\"One of start_states, start_positions should be not None\"", "\n", "if", "start_positions", "is", "not", "None", ":", "\n", "            ", "start_positions", "=", "start_positions", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "start_states", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "start_positions", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "\n", "", "if", "cls_index", "is", "not", "None", ":", "\n", "            ", "cls_index", "=", "cls_index", "[", ":", ",", "None", ",", "None", "]", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, 1, hsz)", "\n", "cls_token_state", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, hsz)", "\n", "", "else", ":", "\n", "            ", "cls_token_state", "=", "hidden_states", "[", ":", ",", "-", "1", ",", ":", "]", "# shape (bsz, hsz)", "\n", "\n", "", "x", "=", "self", ".", "dense_0", "(", "torch", ".", "cat", "(", "[", "start_states", ",", "cls_token_state", "]", ",", "dim", "=", "-", "1", ")", ")", "\n", "x", "=", "self", ".", "activation", "(", "x", ")", "\n", "x", "=", "self", ".", "dense_1", "(", "x", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.SQuADHead.__init__": [[1433, 1441], ["torch.nn.Module.__init__", "modeling_utils.PoolerStartLogits", "modeling_utils.PoolerEndLogits", "modeling_utils.PoolerAnswerClass"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.SQuADHead.forward": [[1442, 1507], ["modeling_utils.SQuADHead.start_logits", "modeling_utils.SQuADHead.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_utils.SQuADHead.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_utils.SQuADHead.answer_class", "modeling_utils.SQuADHead.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "\n", "self", ",", "hidden_states", ",", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "cls_index", "=", "None", ",", "is_impossible", "=", "None", ",", "p_mask", "=", "None", "\n", ")", ":", "\n", "        ", "outputs", "=", "(", ")", "\n", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "\n", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", "\n", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "\n", "start_states", "\n", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "\n", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", "\n", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.SequenceSummary.__init__": [[1525, 1555], ["torch.nn.Module.__init__", "getattr", "Identity", "getattr", "Identity", "Identity", "hasattr", "torch.nn.Linear", "transformers.activations.get_activation", "Identity", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__"], ["def", "__init__", "(", "self", ",", "config", ":", "PretrainedConfig", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "getattr", "(", "config", ",", "\"summary_type\"", ",", "\"last\"", ")", "\n", "if", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_use_proj\"", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "\"summary_proj_to_labels\"", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "\n", "", "activation_string", "=", "getattr", "(", "config", ",", "\"summary_activation\"", ",", "None", ")", "\n", "self", ".", "activation", "=", "(", "\n", "get_activation", "(", "activation_string", ")", "if", "activation_string", "else", "Identity", "(", ")", "\n", ")", "# type: typing.Callable", "\n", "\n", "self", ".", "first_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_first_dropout\"", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "\"summary_last_dropout\"", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.SequenceSummary.forward": [[1556, 1586], ["modeling_utils.SequenceSummary.first_dropout", "modeling_utils.SequenceSummary.summary", "modeling_utils.SequenceSummary.activation", "modeling_utils.SequenceSummary.last_dropout", "hidden_states.mean", "hidden_states.gather().squeeze", "torch.full_like", "cls_index.expand.expand.unsqueeze().unsqueeze", "cls_index.expand.expand.expand", "hidden_states.gather", "cls_index.expand.expand.unsqueeze", "hidden_states.size", "cls_index.expand.expand.dim"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "hidden_states", ",", "cls_index", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, ..., seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "\"last\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"first\"", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "\"mean\"", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "\"cls_index\"", ":", "\n", "            ", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "cls_index", "=", "cls_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cls_index", "=", "cls_index", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "cls_index", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "\"attn\"", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.top_k_top_p_filtering": [[1170, 1203], ["float", "min", "torch.sort", "torch.cumsum", "sorted_indices_to_remove[].clone", "sorted_indices_to_remove.scatter", "max", "logits.size", "torch.nn.functional.softmax", "torch.topk"], "function", ["None"], ["", "", "def", "top_k_top_p_filtering", "(", "logits", ",", "top_k", "=", "0", ",", "top_p", "=", "1.0", ",", "filter_value", "=", "-", "float", "(", "\"Inf\"", ")", ",", "min_tokens_to_keep", "=", "1", ")", ":", "\n", "    ", "\"\"\" Filter a distribution of logits using top-k and/or nucleus (top-p) filtering\n        Args:\n            logits: logits distribution shape (batch size, vocabulary size)\n            if top_k > 0: keep only top k tokens with highest probability (top-k filtering).\n            if top_p < 1.0: keep the top tokens with cumulative probability >= top_p (nucleus filtering).\n                Nucleus filtering is described in Holtzman et al. (http://arxiv.org/abs/1904.09751)\n            Make sure we keep at least min_tokens_to_keep per batch example in the output\n        From: https://gist.github.com/thomwolf/1a5a29f6962089e871b94cbd09daf317\n    \"\"\"", "\n", "if", "top_k", ">", "0", ":", "\n", "        ", "top_k", "=", "min", "(", "max", "(", "top_k", ",", "min_tokens_to_keep", ")", ",", "logits", ".", "size", "(", "-", "1", ")", ")", "# Safety check", "\n", "# Remove all tokens with a probability less than the last token of the top-k", "\n", "indices_to_remove", "=", "logits", "<", "torch", ".", "topk", "(", "logits", ",", "top_k", ")", "[", "0", "]", "[", "...", ",", "-", "1", ",", "None", "]", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "\n", "", "if", "top_p", "<", "1.0", ":", "\n", "        ", "sorted_logits", ",", "sorted_indices", "=", "torch", ".", "sort", "(", "logits", ",", "descending", "=", "True", ")", "\n", "cumulative_probs", "=", "torch", ".", "cumsum", "(", "F", ".", "softmax", "(", "sorted_logits", ",", "dim", "=", "-", "1", ")", ",", "dim", "=", "-", "1", ")", "\n", "\n", "# Remove tokens with cumulative probability above the threshold (token with 0 are kept)", "\n", "sorted_indices_to_remove", "=", "cumulative_probs", ">", "top_p", "\n", "if", "min_tokens_to_keep", ">", "1", ":", "\n", "# Keep at least min_tokens_to_keep (set to min_tokens_to_keep-1 because we add the first one below)", "\n", "            ", "sorted_indices_to_remove", "[", "...", ",", ":", "min_tokens_to_keep", "]", "=", "0", "\n", "# Shift the indices to the right to keep also the first token above the threshold", "\n", "", "sorted_indices_to_remove", "[", "...", ",", "1", ":", "]", "=", "sorted_indices_to_remove", "[", "...", ",", ":", "-", "1", "]", ".", "clone", "(", ")", "\n", "sorted_indices_to_remove", "[", "...", ",", "0", "]", "=", "0", "\n", "\n", "# scatter sorted tensors to original indexing", "\n", "indices_to_remove", "=", "sorted_indices_to_remove", ".", "scatter", "(", "1", ",", "sorted_indices", ",", "sorted_indices_to_remove", ")", "\n", "logits", "[", "indices_to_remove", "]", "=", "filter_value", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.create_position_ids_from_input_ids": [[1588, 1600], ["input_ids.ne().int", "torch.cumsum().type_as", "incremental_indicies.long", "input_ids.ne", "torch.cumsum"], "function", ["None"], ["", "", "def", "create_position_ids_from_input_ids", "(", "input_ids", ",", "padding_idx", ")", ":", "\n", "    ", "\"\"\" Replace non-padding symbols with their position numbers. Position numbers begin at\n    padding_idx+1. Padding symbols are ignored. This is modified from fairseq's\n    `utils.make_positions`.\n\n    :param torch.Tensor x:\n    :return torch.Tensor:\n    \"\"\"", "\n", "# The series of casts and type-conversions here are carefully balanced to both work with ONNX export and XLA.", "\n", "mask", "=", "input_ids", ".", "ne", "(", "padding_idx", ")", ".", "int", "(", ")", "\n", "incremental_indicies", "=", "torch", ".", "cumsum", "(", "mask", ",", "dim", "=", "1", ")", ".", "type_as", "(", "mask", ")", "*", "mask", "\n", "return", "incremental_indicies", ".", "long", "(", ")", "+", "padding_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.prune_linear_layer": [[1602, 1625], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "torch.nn.Linear().to", "nn.Linear().to.weight.copy_", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "nn.Linear().to.bias.copy_", "layer.weight.index_select().clone", "layer.bias.clone().detach", "layer.bias[].clone().detach", "torch.nn.Linear", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select", "layer.bias.clone", "layer.bias[].clone"], "function", ["None"], ["", "def", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", ")", ":", "\n", "    ", "\"\"\" Prune a linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "if", "dim", "==", "1", ":", "\n", "            ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "            ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "nn", ".", "Linear", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ",", "bias", "=", "layer", ".", "bias", "is", "not", "None", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "if", "layer", ".", "bias", "is", "not", "None", ":", "\n", "        ", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.prune_conv1d_layer": [[1627, 1649], ["index.to.to", "layer.weight.index_select().clone().detach", "list", "len", "Conv1D().to", "Conv1D().to.weight.copy_", "Conv1D().to.bias.copy_", "layer.bias.clone().detach", "layer.bias[].clone().detach", "layer.weight.size", "layer.weight.index_select().clone().detach.contiguous", "layer.bias[].clone().detach.contiguous", "layer.weight.index_select().clone", "modeling_utils.Conv1D", "layer.bias.clone", "layer.bias[].clone", "layer.weight.index_select"], "function", ["None"], ["", "def", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D layer (a model parameters) to keep only entries in index.\n        A Conv1D work as a Linear layer (see e.g. BERT) but the weights are transposed.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "index", "=", "index", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "W", "=", "layer", ".", "weight", ".", "index_select", "(", "dim", ",", "index", ")", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "if", "dim", "==", "0", ":", "\n", "        ", "b", "=", "layer", ".", "bias", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "b", "=", "layer", ".", "bias", "[", "index", "]", ".", "clone", "(", ")", ".", "detach", "(", ")", "\n", "", "new_size", "=", "list", "(", "layer", ".", "weight", ".", "size", "(", ")", ")", "\n", "new_size", "[", "dim", "]", "=", "len", "(", "index", ")", "\n", "new_layer", "=", "Conv1D", "(", "new_size", "[", "1", "]", ",", "new_size", "[", "0", "]", ")", ".", "to", "(", "layer", ".", "weight", ".", "device", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "weight", ".", "copy_", "(", "W", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "weight", ".", "requires_grad", "=", "True", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "False", "\n", "new_layer", ".", "bias", ".", "copy_", "(", "b", ".", "contiguous", "(", ")", ")", "\n", "new_layer", ".", "bias", ".", "requires_grad", "=", "True", "\n", "return", "new_layer", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.prune_layer": [[1651, 1662], ["isinstance", "modeling_utils.prune_linear_layer", "isinstance", "modeling_utils.prune_conv1d_layer", "ValueError"], "function", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.prune_linear_layer", "home.repos.pwc.inspect_result.salesforce_simpletod.models.modeling_utils.prune_conv1d_layer"], ["", "def", "prune_layer", "(", "layer", ",", "index", ",", "dim", "=", "None", ")", ":", "\n", "    ", "\"\"\" Prune a Conv1D or nn.Linear layer (a model parameters) to keep only entries in index.\n        Return the pruned layer as a new layer with requires_grad=True.\n        Used to remove heads.\n    \"\"\"", "\n", "if", "isinstance", "(", "layer", ",", "nn", ".", "Linear", ")", ":", "\n", "        ", "return", "prune_linear_layer", "(", "layer", ",", "index", ",", "dim", "=", "0", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "elif", "isinstance", "(", "layer", ",", "Conv1D", ")", ":", "\n", "        ", "return", "prune_conv1d_layer", "(", "layer", ",", "index", ",", "dim", "=", "1", "if", "dim", "is", "None", "else", "dim", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Can't prune layer of class {}\"", ".", "format", "(", "layer", ".", "__class__", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.__init__": [[58, 101], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "dict", "kwargs.pop", "dict", "kwargs.items", "dict", "zip", "setattr", "range", "int", "configuration_utils.PretrainedConfig.id2label.items", "configuration_utils.PretrainedConfig.id2label.values", "configuration_utils.PretrainedConfig.id2label.keys", "int", "configuration_utils.PretrainedConfig.label2id.items", "logger.error"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "# Attributes with defaults", "\n", "        ", "self", ".", "output_attentions", "=", "kwargs", ".", "pop", "(", "\"output_attentions\"", ",", "False", ")", "\n", "self", ".", "output_hidden_states", "=", "kwargs", ".", "pop", "(", "\"output_hidden_states\"", ",", "False", ")", "\n", "self", ".", "output_past", "=", "kwargs", ".", "pop", "(", "\"output_past\"", ",", "True", ")", "# Not used by all models", "\n", "self", ".", "torchscript", "=", "kwargs", ".", "pop", "(", "\"torchscript\"", ",", "False", ")", "# Only used by PyTorch models", "\n", "self", ".", "use_bfloat16", "=", "kwargs", ".", "pop", "(", "\"use_bfloat16\"", ",", "False", ")", "\n", "self", ".", "pruned_heads", "=", "kwargs", ".", "pop", "(", "\"pruned_heads\"", ",", "{", "}", ")", "\n", "\n", "# Is decoder is used in encoder-decoder models to differentiate encoder from decoder", "\n", "self", ".", "is_decoder", "=", "kwargs", ".", "pop", "(", "\"is_decoder\"", ",", "False", ")", "\n", "\n", "# Parameters for sequence generation", "\n", "self", ".", "max_length", "=", "kwargs", ".", "pop", "(", "\"max_length\"", ",", "20", ")", "\n", "self", ".", "do_sample", "=", "kwargs", ".", "pop", "(", "\"do_sample\"", ",", "False", ")", "\n", "self", ".", "early_stopping", "=", "kwargs", ".", "pop", "(", "\"early_stopping\"", ",", "False", ")", "\n", "self", ".", "num_beams", "=", "kwargs", ".", "pop", "(", "\"num_beams\"", ",", "1", ")", "\n", "self", ".", "temperature", "=", "kwargs", ".", "pop", "(", "\"temperature\"", ",", "1.0", ")", "\n", "self", ".", "top_k", "=", "kwargs", ".", "pop", "(", "\"top_k\"", ",", "50", ")", "\n", "self", ".", "top_p", "=", "kwargs", ".", "pop", "(", "\"top_p\"", ",", "1.0", ")", "\n", "self", ".", "repetition_penalty", "=", "kwargs", ".", "pop", "(", "\"repetition_penalty\"", ",", "1.0", ")", "\n", "self", ".", "bos_token_id", "=", "kwargs", ".", "pop", "(", "\"bos_token_id\"", ",", "None", ")", "\n", "self", ".", "pad_token_id", "=", "kwargs", ".", "pop", "(", "\"pad_token_id\"", ",", "None", ")", "\n", "self", ".", "eos_token_ids", "=", "kwargs", ".", "pop", "(", "\"eos_token_ids\"", ",", "None", ")", "\n", "self", ".", "length_penalty", "=", "kwargs", ".", "pop", "(", "\"length_penalty\"", ",", "1.0", ")", "\n", "self", ".", "num_return_sequences", "=", "kwargs", ".", "pop", "(", "\"num_return_sequences\"", ",", "1", ")", "\n", "\n", "# Fine-tuning task arguments", "\n", "self", ".", "architectures", "=", "kwargs", ".", "pop", "(", "\"architectures\"", ",", "None", ")", "\n", "self", ".", "finetuning_task", "=", "kwargs", ".", "pop", "(", "\"finetuning_task\"", ",", "None", ")", "\n", "self", ".", "num_labels", "=", "kwargs", ".", "pop", "(", "\"num_labels\"", ",", "2", ")", "\n", "self", ".", "id2label", "=", "kwargs", ".", "pop", "(", "\"id2label\"", ",", "{", "i", ":", "\"LABEL_{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_labels", ")", "}", ")", "\n", "self", ".", "id2label", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "self", ".", "id2label", ".", "items", "(", ")", ")", "\n", "self", ".", "label2id", "=", "kwargs", ".", "pop", "(", "\"label2id\"", ",", "dict", "(", "zip", "(", "self", ".", "id2label", ".", "values", "(", ")", ",", "self", ".", "id2label", ".", "keys", "(", ")", ")", ")", ")", "\n", "self", ".", "label2id", "=", "dict", "(", "(", "key", ",", "int", "(", "value", ")", ")", "for", "key", ",", "value", "in", "self", ".", "label2id", ".", "items", "(", ")", ")", "\n", "\n", "# Additional attributes without default values", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "setattr", "(", "self", ",", "key", ",", "value", ")", "\n", "", "except", "AttributeError", "as", "err", ":", "\n", "                ", "logger", ".", "error", "(", "\"Can't set {} with value {} for {}\"", ".", "format", "(", "key", ",", "value", ",", "self", ")", ")", "\n", "raise", "err", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.num_labels": [[106, 113], ["dict", "dict", "dict", "zip", "range", "configuration_utils.PretrainedConfig.id2label.values", "configuration_utils.PretrainedConfig.id2label.keys", "int", "configuration_utils.PretrainedConfig.id2label.items", "int", "configuration_utils.PretrainedConfig.label2id.items"], "methods", ["None"], ["", "@", "num_labels", ".", "setter", "\n", "def", "num_labels", "(", "self", ",", "num_labels", ")", ":", "\n", "        ", "self", ".", "_num_labels", "=", "num_labels", "\n", "self", ".", "id2label", "=", "{", "i", ":", "\"LABEL_{}\"", ".", "format", "(", "i", ")", "for", "i", "in", "range", "(", "self", ".", "num_labels", ")", "}", "\n", "self", ".", "id2label", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "self", ".", "id2label", ".", "items", "(", ")", ")", "\n", "self", ".", "label2id", "=", "dict", "(", "zip", "(", "self", ".", "id2label", ".", "values", "(", ")", ",", "self", ".", "id2label", ".", "keys", "(", ")", ")", ")", "\n", "self", ".", "label2id", "=", "dict", "(", "(", "key", ",", "int", "(", "value", ")", ")", "for", "key", ",", "value", "in", "self", ".", "label2id", ".", "items", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.save_pretrained": [[114, 132], ["os.path.isdir", "os.path.join", "configuration_utils.PretrainedConfig.to_json_file", "logger.info"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.to_json_file"], ["", "def", "save_pretrained", "(", "self", ",", "save_directory", ")", ":", "\n", "        ", "\"\"\"\n        Save a configuration object to the directory `save_directory`, so that it\n        can be re-loaded using the :func:`~transformers.PretrainedConfig.from_pretrained` class method.\n\n        Args:\n            save_directory (:obj:`string`):\n                Directory where the configuration JSON file will be saved.\n        \"\"\"", "\n", "assert", "os", ".", "path", ".", "isdir", "(", "\n", "save_directory", "\n", ")", ",", "\"Saving path should be a directory where the model and configuration can be saved\"", "\n", "\n", "# If we save using the predefined names, we can load using `from_pretrained`", "\n", "output_config_file", "=", "os", ".", "path", ".", "join", "(", "save_directory", ",", "CONFIG_NAME", ")", "\n", "\n", "self", ".", "to_json_file", "(", "output_config_file", ")", "\n", "logger", ".", "info", "(", "\"Configuration saved in {}\"", ".", "format", "(", "output_config_file", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_pretrained": [[133, 191], ["cls.get_config_dict", "cls.from_dict"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.get_config_dict", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_dict"], ["", "@", "classmethod", "\n", "def", "from_pretrained", "(", "cls", ",", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "->", "\"PretrainedConfig\"", ":", "\n", "        ", "r\"\"\"\n\n        Instantiate a :class:`~transformers.PretrainedConfig` (or a derived class) from a pre-trained model configuration.\n\n        Args:\n            pretrained_model_name_or_path (:obj:`string`):\n                either:\n                  - a string with the `shortcut name` of a pre-trained model configuration to load from cache or\n                    download, e.g.: ``bert-base-uncased``.\n                  - a string with the `identifier name` of a pre-trained model configuration that was user-uploaded to\n                    our S3, e.g.: ``dbmdz/bert-base-german-cased``.\n                  - a path to a `directory` containing a configuration file saved using the\n                    :func:`~transformers.PretrainedConfig.save_pretrained` method, e.g.: ``./my_model_directory/``.\n                  - a path or url to a saved configuration JSON `file`, e.g.:\n                    ``./my_model_directory/configuration.json``.\n            cache_dir (:obj:`string`, `optional`):\n                Path to a directory in which a downloaded pre-trained model\n                configuration should be cached if the standard cache should not be used.\n            kwargs (:obj:`Dict[str, any]`, `optional`):\n                The values in kwargs of any keys which are configuration attributes will be used to override the loaded\n                values. Behavior concerning key/value pairs whose keys are *not* configuration attributes is\n                controlled by the `return_unused_kwargs` keyword parameter.\n            force_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n                Force to (re-)download the model weights and configuration files and override the cached versions if they exist.\n            resume_download (:obj:`bool`, `optional`, defaults to :obj:`False`):\n                Do not delete incompletely recieved file. Attempt to resume the download if such a file exists.\n            proxies (:obj:`Dict`, `optional`):\n                A dictionary of proxy servers to use by protocol or endpoint, e.g.:\n                :obj:`{'http': 'foo.bar:3128', 'http://hostname': 'foo.bar:4012'}.`\n                The proxies are used on each request.\n            return_unused_kwargs: (`optional`) bool:\n                If False, then this function returns just the final configuration object.\n                If True, then this functions returns a :obj:`Tuple(config, unused_kwargs)` where `unused_kwargs` is a\n                dictionary consisting of the key/value pairs whose keys are not configuration attributes: ie the part\n                of kwargs which has not been used to update `config` and is otherwise ignored.\n\n        Returns:\n            :class:`PretrainedConfig`: An instance of a configuration object\n\n        Examples::\n\n            # We can't instantiate directly the base class `PretrainedConfig` so let's show the examples on a\n            # derived class: BertConfig\n            config = BertConfig.from_pretrained('bert-base-uncased')    # Download configuration from S3 and cache.\n            config = BertConfig.from_pretrained('./test/saved_model/')  # E.g. config (or model) was saved using `save_pretrained('./test/saved_model/')`\n            config = BertConfig.from_pretrained('./test/saved_model/my_configuration.json')\n            config = BertConfig.from_pretrained('bert-base-uncased', output_attention=True, foo=False)\n            assert config.output_attention == True\n            config, unused_kwargs = BertConfig.from_pretrained('bert-base-uncased', output_attention=True,\n                                                               foo=False, return_unused_kwargs=True)\n            assert config.output_attention == True\n            assert unused_kwargs == {'foo': False}\n\n        \"\"\"", "\n", "config_dict", ",", "kwargs", "=", "cls", ".", "get_config_dict", "(", "pretrained_model_name_or_path", ",", "**", "kwargs", ")", "\n", "return", "cls", ".", "from_dict", "(", "config_dict", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.get_config_dict": [[192, 272], ["kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "kwargs.pop", "os.path.isdir", "file_utils.cached_path", "cls._dict_from_json_file", "logger.info", "logger.info", "os.path.join", "EnvironmentError", "EnvironmentError", "os.path.isfile", "file_utils.is_remote_url", "file_utils.hf_bucket_url"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.cached_path", "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig._dict_from_json_file", "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.is_remote_url", "home.repos.pwc.inspect_result.salesforce_simpletod.models.file_utils.hf_bucket_url"], ["", "@", "classmethod", "\n", "def", "get_config_dict", "(", "\n", "cls", ",", "pretrained_model_name_or_path", ":", "str", ",", "pretrained_config_archive_map", ":", "Optional", "[", "Dict", "]", "=", "None", ",", "**", "kwargs", "\n", ")", "->", "Tuple", "[", "Dict", ",", "Dict", "]", ":", "\n", "        ", "\"\"\"\n        From a `pretrained_model_name_or_path`, resolve to a dictionary of parameters, to be used\n        for instantiating a Config using `from_dict`.\n\n        Parameters:\n            pretrained_model_name_or_path (:obj:`string`):\n                The identifier of the pre-trained checkpoint from which we want the dictionary of parameters.\n            pretrained_config_archive_map: (:obj:`Dict[str, str]`, `optional`) Dict:\n                A map of `shortcut names` to `url`. By default, will use the current class attribute.\n\n        Returns:\n            :obj:`Tuple[Dict, Dict]`: The dictionary that will be used to instantiate the configuration object.\n\n        \"\"\"", "\n", "cache_dir", "=", "kwargs", ".", "pop", "(", "\"cache_dir\"", ",", "None", ")", "\n", "force_download", "=", "kwargs", ".", "pop", "(", "\"force_download\"", ",", "False", ")", "\n", "resume_download", "=", "kwargs", ".", "pop", "(", "\"resume_download\"", ",", "False", ")", "\n", "proxies", "=", "kwargs", ".", "pop", "(", "\"proxies\"", ",", "None", ")", "\n", "local_files_only", "=", "kwargs", ".", "pop", "(", "\"local_files_only\"", ",", "False", ")", "\n", "\n", "if", "pretrained_config_archive_map", "is", "None", ":", "\n", "            ", "pretrained_config_archive_map", "=", "cls", ".", "pretrained_config_archive_map", "\n", "\n", "", "if", "pretrained_model_name_or_path", "in", "pretrained_config_archive_map", ":", "\n", "            ", "config_file", "=", "pretrained_config_archive_map", "[", "pretrained_model_name_or_path", "]", "\n", "", "elif", "os", ".", "path", ".", "isdir", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "os", ".", "path", ".", "join", "(", "pretrained_model_name_or_path", ",", "CONFIG_NAME", ")", "\n", "", "elif", "os", ".", "path", ".", "isfile", "(", "pretrained_model_name_or_path", ")", "or", "is_remote_url", "(", "pretrained_model_name_or_path", ")", ":", "\n", "            ", "config_file", "=", "pretrained_model_name_or_path", "\n", "", "else", ":", "\n", "            ", "config_file", "=", "hf_bucket_url", "(", "pretrained_model_name_or_path", ",", "postfix", "=", "CONFIG_NAME", ")", "\n", "\n", "", "try", ":", "\n", "# Load from URL or cache if already cached", "\n", "            ", "resolved_config_file", "=", "cached_path", "(", "\n", "config_file", ",", "\n", "cache_dir", "=", "cache_dir", ",", "\n", "force_download", "=", "force_download", ",", "\n", "proxies", "=", "proxies", ",", "\n", "resume_download", "=", "resume_download", ",", "\n", "local_files_only", "=", "local_files_only", ",", "\n", ")", "\n", "# Load config dict", "\n", "if", "resolved_config_file", "is", "None", ":", "\n", "                ", "raise", "EnvironmentError", "\n", "", "config_dict", "=", "cls", ".", "_dict_from_json_file", "(", "resolved_config_file", ")", "\n", "\n", "", "except", "EnvironmentError", ":", "\n", "            ", "if", "pretrained_model_name_or_path", "in", "pretrained_config_archive_map", ":", "\n", "                ", "msg", "=", "\"Couldn't reach server at '{}' to download pretrained model configuration file.\"", ".", "format", "(", "\n", "config_file", "\n", ")", "\n", "", "else", ":", "\n", "                ", "msg", "=", "(", "\n", "\"Model name '{}' was not found in model name list. \"", "\n", "\"We assumed '{}' was a path, a model identifier, or url to a configuration file named {} or \"", "\n", "\"a directory containing such a file but couldn't find any such file at this path or url.\"", ".", "format", "(", "\n", "pretrained_model_name_or_path", ",", "config_file", ",", "CONFIG_NAME", ",", "\n", ")", "\n", ")", "\n", "", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "except", "json", ".", "JSONDecodeError", ":", "\n", "            ", "msg", "=", "(", "\n", "\"Couldn't reach server at '{}' to download configuration file or \"", "\n", "\"configuration file is not a valid JSON file. \"", "\n", "\"Please check network or file content here: {}.\"", ".", "format", "(", "config_file", ",", "resolved_config_file", ")", "\n", ")", "\n", "raise", "EnvironmentError", "(", "msg", ")", "\n", "\n", "", "if", "resolved_config_file", "==", "config_file", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {}\"", ".", "format", "(", "config_file", ")", ")", "\n", "", "else", ":", "\n", "            ", "logger", ".", "info", "(", "\"loading configuration file {} from cache at {}\"", ".", "format", "(", "config_file", ",", "resolved_config_file", ")", ")", "\n", "\n", "", "return", "config_dict", ",", "kwargs", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_dict": [[273, 310], ["kwargs.pop", "cls", "hasattr", "kwargs.items", "logger.info", "dict", "hasattr", "kwargs.pop", "str", "setattr", "to_remove.append", "int", "cls.pruned_heads.items"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "from_dict", "(", "cls", ",", "config_dict", ":", "Dict", ",", "**", "kwargs", ")", "->", "\"PretrainedConfig\"", ":", "\n", "        ", "\"\"\"\n        Constructs a `Config` from a Python dictionary of parameters.\n\n        Args:\n            config_dict (:obj:`Dict[str, any]`):\n                Dictionary that will be used to instantiate the configuration object. Such a dictionary can be retrieved\n                from a pre-trained checkpoint by leveraging the :func:`~transformers.PretrainedConfig.get_config_dict`\n                method.\n            kwargs (:obj:`Dict[str, any]`):\n                Additional parameters from which to initialize the configuration object.\n\n        Returns:\n            :class:`PretrainedConfig`: An instance of a configuration object\n        \"\"\"", "\n", "return_unused_kwargs", "=", "kwargs", ".", "pop", "(", "\"return_unused_kwargs\"", ",", "False", ")", "\n", "\n", "config", "=", "cls", "(", "**", "config_dict", ")", "\n", "\n", "if", "hasattr", "(", "config", ",", "\"pruned_heads\"", ")", ":", "\n", "            ", "config", ".", "pruned_heads", "=", "dict", "(", "(", "int", "(", "key", ")", ",", "value", ")", "for", "key", ",", "value", "in", "config", ".", "pruned_heads", ".", "items", "(", ")", ")", "\n", "\n", "# Update config with kwargs if needed", "\n", "", "to_remove", "=", "[", "]", "\n", "for", "key", ",", "value", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "key", ")", ":", "\n", "                ", "setattr", "(", "config", ",", "key", ",", "value", ")", "\n", "to_remove", ".", "append", "(", "key", ")", "\n", "", "", "for", "key", "in", "to_remove", ":", "\n", "            ", "kwargs", ".", "pop", "(", "key", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Model config %s\"", ",", "str", "(", "config", ")", ")", "\n", "if", "return_unused_kwargs", ":", "\n", "            ", "return", "config", ",", "kwargs", "\n", "", "else", ":", "\n", "            ", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.from_json_file": [[311, 326], ["cls._dict_from_json_file", "cls"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig._dict_from_json_file"], ["", "", "@", "classmethod", "\n", "def", "from_json_file", "(", "cls", ",", "json_file", ":", "str", ")", "->", "\"PretrainedConfig\"", ":", "\n", "        ", "\"\"\"\n        Constructs a `Config` from the path to a json file of parameters.\n\n        Args:\n            json_file (:obj:`string`):\n                Path to the JSON file containing the parameters.\n\n        Returns:\n            :class:`PretrainedConfig`: An instance of a configuration object\n\n        \"\"\"", "\n", "config_dict", "=", "cls", ".", "_dict_from_json_file", "(", "json_file", ")", "\n", "return", "cls", "(", "**", "config_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig._dict_from_json_file": [[327, 332], ["json.loads", "open", "reader.read"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "_dict_from_json_file", "(", "cls", ",", "json_file", ":", "str", ")", ":", "\n", "        ", "with", "open", "(", "json_file", ",", "\"r\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "reader", ":", "\n", "            ", "text", "=", "reader", ".", "read", "(", ")", "\n", "", "return", "json", ".", "loads", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.__eq__": [[333, 335], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "self", ".", "__dict__", "==", "other", ".", "__dict__", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.__repr__": [[336, 338], ["configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.to_json_string"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"{} {}\"", ".", "format", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "to_json_string", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.to_dict": [[339, 350], ["copy.deepcopy", "hasattr"], "methods", ["None"], ["", "def", "to_dict", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Serializes this instance to a Python dictionary.\n\n        Returns:\n            :obj:`Dict[str, any]`: Dictionary of all the attributes that make up this configuration instance,\n        \"\"\"", "\n", "output", "=", "copy", ".", "deepcopy", "(", "self", ".", "__dict__", ")", "\n", "if", "hasattr", "(", "self", ".", "__class__", ",", "\"model_type\"", ")", ":", "\n", "            ", "output", "[", "\"model_type\"", "]", "=", "self", ".", "__class__", ".", "model_type", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.to_json_string": [[351, 359], ["json.dumps", "configuration_utils.PretrainedConfig.to_dict"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.to_dict"], ["", "def", "to_json_string", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Serializes this instance to a JSON string.\n\n        Returns:\n            :obj:`string`: String containing all the attributes that make up this configuration instance in JSON format.\n        \"\"\"", "\n", "return", "json", ".", "dumps", "(", "self", ".", "to_dict", "(", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.to_json_file": [[360, 370], ["open", "writer.write", "configuration_utils.PretrainedConfig.to_json_string"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.models.configuration_utils.PretrainedConfig.to_json_string"], ["", "def", "to_json_file", "(", "self", ",", "json_file_path", ")", ":", "\n", "        ", "\"\"\"\n        Save this instance to a json file.\n\n        Args:\n            json_file_path (:obj:`string`):\n                Path to the JSON file in which this configuration instance's parameters will be saved.\n        \"\"\"", "\n", "with", "open", "(", "json_file_path", ",", "\"w\"", ",", "encoding", "=", "\"utf-8\"", ")", "as", "writer", ":", "\n", "            ", "writer", ".", "write", "(", "self", ".", "to_json_string", "(", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset.__init__": [[13, 24], ["os.path.isfile", "logger.info", "open", "tokenizer.batch_encode_plus", "f.read().splitlines", "f.read", "len", "line.isspace"], "methods", ["None"], ["    ", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\n", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", ",", "\n", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", ",", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "\n", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset.__len__": [[25, 27], ["len"], "methods", ["None"], ["\n", "# Check if saved optimizer or scheduler states exist", "\n", "if", "(", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset.__getitem__": [[28, 30], ["torch.tensor"], "methods", ["None"], ["args", ".", "model_name_or_path", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", "\n", "and", "os", ".", "path", ".", "isfile", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_context.__init__": [[33, 46], ["os.path.isfile", "logger.info", "open", "tokenizer.batch_encode_plus", "language_model.LineByLineTextDataset_shuffle_context.shuffle_context", "f.read().splitlines", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_context.shuffle_context"], ["        ", "optimizer", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"optimizer.pt\"", ")", ")", ")", "\n", "scheduler", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "args", ".", "model_name_or_path", ",", "\"scheduler.pt\"", ")", ")", ")", "\n", "\n", "", "return", "optimizer", ",", "scheduler", "\n", "\n", "\n", "# def mask_tokens(inputs: torch.Tensor, tokenizer: PreTrainedTokenizer, args) -> Tuple[torch.Tensor, torch.Tensor]:", "\n", "#     \"\"\" Prepare masked tokens inputs/labels for masked language modeling: 80% MASK, 10% random, 10% original. \"\"\"", "\n", "#", "\n", "#     if tokenizer.mask_token is None:", "\n", "#         raise ValueError(", "\n", "#             \"This tokenizer does not have a mask token which is necessary for masked language modeling. Remove the --mlm flag if you want to use this tokenizer.\"", "\n", "#         )", "\n", "#", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_context.__len__": [[47, 49], ["len"], "methods", ["None"], ["#     labels = inputs.clone()", "\n", "#     # We sample a few tokens in each sequence for masked-LM training (with probability args.mlm_probability defaults to 0.15 in Bert/RoBERTa)", "\n", "#     probability_matrix = torch.full(labels.shape, args.mlm_probability)", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_context.shuffle_context": [[50, 74], ["[].split", "context.split", "random.shuffle", "txt.split", "all_text.append", "all_text.append", "txt.strip", "all_text.append", "text.strip().split", "text.strip"], "methods", ["None"], ["#     special_tokens_mask = [", "\n", "#         tokenizer.get_special_tokens_mask(val, already_has_special_tokens=True) for val in labels.tolist()", "\n", "#     ]", "\n", "#     probability_matrix.masked_fill_(torch.tensor(special_tokens_mask, dtype=torch.bool), value=0.0)", "\n", "#     if tokenizer._pad_token is not None:", "\n", "#         padding_mask = labels.eq(tokenizer.pad_token_id)", "\n", "#         probability_matrix.masked_fill_(padding_mask, value=0.0)", "\n", "#     masked_indices = torch.bernoulli(probability_matrix).bool()", "\n", "#     labels[~masked_indices] = -100  # We only compute loss on masked tokens", "\n", "#", "\n", "#     # 80% of the time, we replace masked input tokens with tokenizer.mask_token ([MASK])", "\n", "#     indices_replaced = torch.bernoulli(torch.full(labels.shape, 0.8)).bool() & masked_indices", "\n", "#     inputs[indices_replaced] = tokenizer.convert_tokens_to_ids(tokenizer.mask_token)", "\n", "#", "\n", "#     # 10% of the time, we replace masked input tokens with random word", "\n", "#     indices_random = torch.bernoulli(torch.full(labels.shape, 0.5)).bool() & masked_indices & ~indices_replaced", "\n", "#     random_words = torch.randint(len(tokenizer), labels.shape, dtype=torch.long)", "\n", "#     inputs[indices_random] = random_words[indices_random]", "\n", "#", "\n", "#     # The rest of the time (10% of the time) we keep the masked input tokens unchanged", "\n", "#     return inputs, labels", "", "", ""]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_context.__getitem__": [[76, 78], ["torch.tensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief.__init__": [[81, 94], ["os.path.isfile", "logger.info", "open", "tokenizer.batch_encode_plus", "language_model.LineByLineTextDataset_shuffle_belief.shuffle_belief", "f.read().splitlines", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.shuffle_belief"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief.__len__": [[95, 97], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief.shuffle_belief": [[98, 107], ["[].split", "belief.split", "random.shuffle", "text.strip().split", "text.strip", "text.strip().split", "text.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief.shuffle_action": [[108, 117], ["[].split", "action.split", "random.shuffle", "text.strip().split", "text.strip", "text.strip().split", "text.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief.__getitem__": [[119, 121], ["torch.tensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.__init__": [[124, 139], ["os.path.isfile", "logger.info", "open", "tokenizer.batch_encode_plus", "language_model.LineByLineTextDataset_shuffle_belief_action.shuffle_belief", "language_model.LineByLineTextDataset_shuffle_belief_action.shuffle_action", "f.read().splitlines", "f.read", "len", "line.isspace"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.shuffle_belief", "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.shuffle_action"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.__len__": [[140, 142], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.shuffle_belief": [[143, 152], ["[].split", "belief.split", "random.shuffle", "text.strip().split", "text.strip", "text.strip().split", "text.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.shuffle_action": [[153, 162], ["[].split", "action.split", "random.shuffle", "text.strip().split", "text.strip", "text.strip().split", "text.strip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.LineByLineTextDataset_shuffle_belief_action.__getitem__": [[164, 166], ["torch.tensor"], "methods", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.load_and_cache_examples": [[168, 183], ["language_model.LineByLineTextDataset", "language_model.LineByLineTextDataset_shuffle_context", "language_model.LineByLineTextDataset_shuffle_belief_action", "language_model.LineByLineTextDataset_shuffle_belief", "language_model.LineByLineTextDataset"], "function", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.language_model.get_dataloader": [[185, 204], ["torch.utils.data.DataLoader", "torch.nn.utils.rnn.pad_sequence", "torch.utils.data.SequentialSampler", "torch.nn.utils.rnn.pad_sequence", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "max"], "function", ["None"], []], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__init__": [[35, 147], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "json.load", "list", "os.path.join", "os.path.join", "open", "open", "open", "open", "open", "open", "multiwoz.MultiWozDataset.dialogues.keys", "random.shuffle", "os.path.isfile", "print", "pickle.load", "print", "print", "open", "enumerate", "open", "pickle.dump", "zip", "input_tensor.append", "target_tensor.append", "input_raw.append", "target_raw.append", "action_raw.append", "belief_raw.append", "bs_tensor.append", "db_tensor.append", "torch.LongTensor", "torch.LongTensor", "float", "float", "usr.strip().split", "sys.strip().split", "usr.strip", "sys.strip"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "args", ",", "split", "=", "'train'", ",", "shuffle", "=", "True", ")", ":", "\n", "        ", "self", ".", "args", "=", "args", "\n", "self", ".", "split", "=", "split", "\n", "self", ".", "data_dir", "=", "args", ".", "data_dir", "\n", "self", ".", "batch_size", "=", "args", ".", "batch_size", "\n", "if", "args", ".", "lexical", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'{}_dials_lexicalized.json'", ".", "format", "(", "split", ")", ")", "\n", "", "else", ":", "\n", "            ", "file_path", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "'{}_dials.json'", ".", "format", "(", "split", ")", ")", "\n", "\n", "", "if", "args", ".", "no_history", ":", "\n", "            ", "if", "args", ".", "lexical", ":", "\n", "                ", "input_word2index_name", "=", "'input_lang.word2index_lexicalized.json'", "\n", "output_word2index_name", "=", "'output_lang.word2index_lexicalized.json'", "\n", "input_index2word_name", "=", "'input_lang.index2word_lexicalized.json'", "\n", "output_index2word_name", "=", "'output_lang.index2word_lexicalized.json'", "\n", "", "else", ":", "\n", "                ", "input_word2index_name", "=", "'input_lang.word2index.json'", "\n", "output_word2index_name", "=", "'output_lang.word2index.json'", "\n", "input_index2word_name", "=", "'input_lang.index2word.json'", "\n", "output_index2word_name", "=", "'output_lang.index2word.json'", "\n", "", "", "else", ":", "\n", "            ", "if", "args", ".", "lexical", ":", "\n", "                ", "input_word2index_name", "=", "'history_lang.word2index_lexicalized.json'", "\n", "output_word2index_name", "=", "'history_lang.word2index_lexicalized.json'", "\n", "input_index2word_name", "=", "'history_lang.index2word_lexicalized.json'", "\n", "output_index2word_name", "=", "'history_lang.index2word_lexicalized.json'", "\n", "", "else", ":", "\n", "                ", "input_word2index_name", "=", "'history_lang.word2index.json'", "\n", "output_word2index_name", "=", "'history_lang.word2index.json'", "\n", "input_index2word_name", "=", "'history_lang.index2word.json'", "\n", "output_index2word_name", "=", "'history_lang.index2word.json'", "\n", "\n", "", "", "input_word2index_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "input_word2index_name", ")", "\n", "output_word2index_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "output_word2index_name", ")", "\n", "input_index2word_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "input_index2word_name", ")", "\n", "output_index2word_filepath", "=", "os", ".", "path", ".", "join", "(", "self", ".", "data_dir", ",", "output_index2word_name", ")", "\n", "\n", "\n", "self", ".", "dialogues", "=", "json", ".", "load", "(", "open", "(", "file_path", ",", "'rt'", ")", ")", "\n", "self", ".", "actions", "=", "json", ".", "load", "(", "open", "(", "'resources/multi-woz/dialogue_acts.json'", ",", "'r'", ")", ")", "\n", "\n", "self", ".", "input_word2index", "=", "json", ".", "load", "(", "open", "(", "input_word2index_filepath", ",", "'rt'", ")", ")", "\n", "self", ".", "output_word2index", "=", "json", ".", "load", "(", "open", "(", "output_word2index_filepath", ",", "'rt'", ")", ")", "\n", "self", ".", "input_index2word", "=", "json", ".", "load", "(", "open", "(", "input_index2word_filepath", ",", "'rt'", ")", ")", "\n", "self", ".", "output_index2word", "=", "json", ".", "load", "(", "open", "(", "output_index2word_filepath", ",", "'rt'", ")", ")", "\n", "\n", "# special tokens", "\n", "self", ".", "sos_token", "=", "SOS_token", "\n", "self", ".", "eos_token", "=", "EOS_token", "\n", "self", ".", "unk_token", "=", "UNK_token", "\n", "self", ".", "pad_token", "=", "PAD_token", "\n", "\n", "dial_names", "=", "list", "(", "self", ".", "dialogues", ".", "keys", "(", ")", ")", "\n", "if", "shuffle", ":", "\n", "            ", "random", ".", "shuffle", "(", "dial_names", ")", "\n", "\n", "", "if", "args", ".", "lexical", ":", "\n", "            ", "cached_filename", "=", "'resources/cached_data_lexical_{}.pkl'", ".", "format", "(", "split", ")", "\n", "", "else", ":", "\n", "            ", "cached_filename", "=", "'resources/cached_data_delex_{}.pkl'", ".", "format", "(", "split", ")", "\n", "\n", "\n", "", "if", "os", ".", "path", ".", "isfile", "(", "cached_filename", ")", "and", "not", "args", ".", "no_cached", ":", "\n", "            ", "print", "(", "'loading cached data from {}'", ".", "format", "(", "cached_filename", ")", ")", "\n", "self", ".", "data", "=", "pickle", ".", "load", "(", "open", "(", "cached_filename", ",", "'rb'", ")", ")", "\n", "", "else", ":", "\n", "            ", "print", "(", "'no cached! creating data'", ")", "\n", "self", ".", "data", "=", "{", "}", "\n", "for", "name", "in", "dial_names", ":", "\n", "                ", "val_file", "=", "self", ".", "dialogues", "[", "name", "]", "\n", "input_tensor", "=", "[", "]", "\n", "target_tensor", "=", "[", "]", "\n", "bs_tensor", "=", "[", "]", "\n", "db_tensor", "=", "[", "]", "\n", "input_raw", "=", "[", "]", "\n", "target_raw", "=", "[", "]", "\n", "action_raw", "=", "[", "]", "\n", "belief_raw", "=", "[", "]", "\n", "for", "idx", ",", "(", "usr", ",", "sys", ",", "bs", ",", "db", ",", "bstate", ",", "sys_act", ")", "in", "enumerate", "(", "\n", "zip", "(", "val_file", "[", "'usr'", "]", ",", "val_file", "[", "'sys'", "]", ",", "val_file", "[", "'bs'", "]", ",", "val_file", "[", "'db'", "]", ",", "val_file", "[", "'bstate'", "]", ",", "val_file", "[", "'sys_act'", "]", ")", ")", ":", "\n", "                    ", "tensor", "=", "[", "self", ".", "input_word2index", "[", "word", "]", "for", "word", "in", "usr", ".", "strip", "(", "' '", ")", ".", "split", "(", "' '", ")", "]", "+", "[", "\n", "EOS_token", "]", "\n", "input_tensor", ".", "append", "(", "torch", ".", "LongTensor", "(", "tensor", ")", ")", "# .view(-1, 1))", "\n", "\n", "tensor", "=", "[", "self", ".", "output_word2index", "[", "word", "]", "for", "word", "in", "sys", ".", "strip", "(", "' '", ")", ".", "split", "(", "' '", ")", "]", "+", "[", "EOS_token", "]", "\n", "target_tensor", ".", "append", "(", "torch", ".", "LongTensor", "(", "tensor", ")", ")", "# .view(-1, 1)", "\n", "\n", "input_raw", ".", "append", "(", "usr", ")", "\n", "target_raw", ".", "append", "(", "sys", ")", "\n", "action_raw", ".", "append", "(", "sys_act", ")", "\n", "belief_raw", ".", "append", "(", "bstate", ")", "\n", "\n", "bs_tensor", ".", "append", "(", "[", "float", "(", "belief", ")", "for", "belief", "in", "bs", "]", ")", "\n", "db_tensor", ".", "append", "(", "[", "float", "(", "pointer", ")", "for", "pointer", "in", "db", "]", ")", "\n", "\n", "\n", "", "self", ".", "data", "[", "name", "]", "=", "{", "\n", "'input'", ":", "input_tensor", ",", "\n", "'target'", ":", "target_tensor", ",", "\n", "'bs'", ":", "bs_tensor", ",", "\n", "'db'", ":", "db_tensor", "\n", "}", "\n", "\n", "self", ".", "data", "[", "name", "]", "[", "'input_raw'", "]", "=", "input_raw", "\n", "self", ".", "data", "[", "name", "]", "[", "'target_raw'", "]", "=", "target_raw", "\n", "self", ".", "data", "[", "name", "]", "[", "'action_raw'", "]", "=", "action_raw", "\n", "self", ".", "data", "[", "name", "]", "[", "'belief_raw'", "]", "=", "belief_raw", "\n", "\n", "", "print", "(", "'caching data to {}'", ".", "format", "(", "cached_filename", ")", ")", "\n", "with", "open", "(", "cached_filename", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "self", ".", "data", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.process_action": [[148, 155], ["len", "concat.extend"], "methods", ["None"], ["", "", "", "def", "process_action", "(", "self", ",", "action", ")", ":", "\n", "        ", "concat", "=", "[", "]", "\n", "if", "len", "(", "action", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "for", "domain", ",", "act", ",", "slot", "in", "action", ":", "\n", "            ", "concat", ".", "extend", "(", "[", "domain", ",", "act", ",", "slot", ",", "'_SEP1'", "]", ")", "\n", "", "return", "' '", ".", "join", "(", "concat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.process_belief_state": [[156, 165], ["len", "concat.extend", "value.strip().split", "value.strip"], "methods", ["None"], ["", "def", "process_belief_state", "(", "self", ",", "beliefs", ")", ":", "\n", "        ", "concat", "=", "[", "]", "\n", "if", "len", "(", "beliefs", ")", "==", "0", ":", "\n", "            ", "return", "None", "\n", "", "for", "domain", ",", "slot", ",", "value", "in", "beliefs", ":", "\n", "            ", "if", "value", "==", "'not mentioned'", ":", "\n", "                ", "continue", "\n", "", "concat", ".", "extend", "(", "[", "domain", ",", "slot", "]", "+", "value", ".", "strip", "(", ")", ".", "split", "(", "' '", ")", "+", "[", "'_SEP0'", "]", ")", "\n", "", "return", "' '", ".", "join", "(", "concat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__len__": [[167, 169], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence": [[170, 187], ["numpy.array", "len", "enumerate", "max", "numpy.ones", "len"], "methods", ["None"], ["", "def", "_pad_sequence", "(", "self", ",", "tensor", ")", ":", "\n", "        ", "tensor_lengths", "=", "np", ".", "array", "(", "[", "len", "(", "sentence", ")", "for", "sentence", "in", "tensor", "]", ")", "\n", "if", "self", ".", "args", ".", "seq_len", ":", "\n", "            ", "longest_sent", "=", "self", ".", "args", ".", "seq_len", "\n", "", "else", ":", "\n", "            ", "longest_sent", "=", "max", "(", "tensor_lengths", ")", "\n", "", "batch_size", "=", "len", "(", "tensor", ")", "\n", "padded_tensor", "=", "np", ".", "ones", "(", "(", "batch_size", ",", "longest_sent", ")", ")", "*", "self", ".", "pad_token", "\n", "\n", "# copy over the actual sequences", "\n", "for", "i", ",", "x_len", "in", "enumerate", "(", "tensor_lengths", ")", ":", "\n", "            ", "sequence", "=", "tensor", "[", "i", "]", "\n", "if", "x_len", ">", "longest_sent", ":", "\n", "                ", "sequence", "=", "sequence", "[", "-", "longest_sent", ":", "]", "\n", "", "padded_tensor", "[", "i", ",", "0", ":", "x_len", "]", "=", "sequence", "\n", "\n", "", "return", "padded_tensor", ",", "tensor_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence_target_action": [[188, 211], ["zip", "numpy.array", "len", "enumerate", "isinstance", "tensor.append", "max", "numpy.ones", "tensor.append", "torch.cat", "len"], "methods", ["None"], ["", "def", "_pad_sequence_target_action", "(", "self", ",", "tensor1", ",", "tensor2", ")", ":", "\n", "        ", "tensor", "=", "[", "]", "\n", "for", "seq1", ",", "seq2", "in", "zip", "(", "tensor1", ",", "tensor2", ")", ":", "\n", "            ", "if", "isinstance", "(", "seq1", ",", "list", ")", ":", "\n", "                ", "tensor", ".", "append", "(", "seq2", ")", "\n", "continue", "\n", "", "tensor", ".", "append", "(", "torch", ".", "cat", "(", "(", "seq1", ",", "seq2", ")", ",", "0", ")", ")", "\n", "", "tensor_lengths", "=", "np", ".", "array", "(", "[", "len", "(", "sentence", ")", "for", "sentence", "in", "tensor", "]", ")", "\n", "if", "self", ".", "args", ".", "seq_len", ":", "\n", "            ", "longest_sent", "=", "self", ".", "args", ".", "seq_len", "\n", "", "else", ":", "\n", "            ", "longest_sent", "=", "max", "(", "tensor_lengths", ")", "\n", "", "batch_size", "=", "len", "(", "tensor", ")", "\n", "padded_tensor", "=", "np", ".", "ones", "(", "(", "batch_size", ",", "longest_sent", ")", ")", "*", "self", ".", "pad_token", "\n", "\n", "# copy over the actual sequences", "\n", "for", "i", ",", "x_len", "in", "enumerate", "(", "tensor_lengths", ")", ":", "\n", "            ", "sequence", "=", "tensor", "[", "i", "]", "\n", "if", "x_len", ">", "longest_sent", ":", "\n", "                ", "sequence", "=", "sequence", "[", "-", "longest_sent", ":", "]", "\n", "", "padded_tensor", "[", "i", ",", "0", ":", "x_len", "]", "=", "sequence", "\n", "\n", "", "return", "padded_tensor", ",", "tensor_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence_target_action_belief": [[212, 240], ["zip", "numpy.array", "len", "enumerate", "max", "numpy.ones", "tensor.append", "len", "len", "len", "torch.cat", "tensor.append", "len", "len", "len", "tensor.append", "torch.cat", "len", "tensor.append", "torch.cat"], "methods", ["None"], ["", "def", "_pad_sequence_target_action_belief", "(", "self", ",", "tensor1", ",", "tensor2", ",", "tensor3", ")", ":", "\n", "        ", "tensor", "=", "[", "]", "\n", "for", "seq1", ",", "seq2", ",", "seq3", "in", "zip", "(", "tensor1", ",", "tensor2", ",", "tensor3", ")", ":", "\n", "            ", "if", "len", "(", "seq1", ")", ">", "0", "and", "len", "(", "seq2", ")", ">", "0", ":", "\n", "                ", "tensor", ".", "append", "(", "torch", ".", "cat", "(", "(", "seq1", ",", "seq2", ",", "seq3", ")", ",", "0", ")", ")", "\n", "", "elif", "len", "(", "seq1", ")", "==", "0", "and", "len", "(", "seq2", ")", "==", "0", ":", "\n", "                ", "tensor", ".", "append", "(", "seq3", ")", "\n", "", "elif", "len", "(", "seq1", ")", "==", "0", ":", "\n", "                ", "tensor", ".", "append", "(", "torch", ".", "cat", "(", "(", "seq2", ",", "seq3", ")", ",", "0", ")", ")", "\n", "", "elif", "len", "(", "seq2", ")", "==", "0", ":", "\n", "                ", "tensor", ".", "append", "(", "torch", ".", "cat", "(", "(", "seq1", ",", "seq3", ")", ",", "0", ")", ")", "\n", "\n", "", "", "tensor_lengths", "=", "np", ".", "array", "(", "[", "len", "(", "sentence", ")", "for", "sentence", "in", "tensor", "]", ")", "\n", "if", "self", ".", "args", ".", "seq_len", ":", "\n", "            ", "longest_sent", "=", "self", ".", "args", ".", "seq_len", "\n", "", "else", ":", "\n", "            ", "longest_sent", "=", "max", "(", "tensor_lengths", ")", "\n", "", "batch_size", "=", "len", "(", "tensor", ")", "\n", "padded_tensor", "=", "np", ".", "ones", "(", "(", "batch_size", ",", "longest_sent", ")", ")", "*", "self", ".", "pad_token", "\n", "\n", "# copy over the actual sequences", "\n", "for", "i", ",", "x_len", "in", "enumerate", "(", "tensor_lengths", ")", ":", "\n", "            ", "sequence", "=", "tensor", "[", "i", "]", "\n", "if", "x_len", ">", "longest_sent", ":", "\n", "                ", "sequence", "=", "sequence", "[", "-", "longest_sent", ":", "]", "\n", "", "padded_tensor", "[", "i", ",", "0", ":", "x_len", "]", "=", "sequence", "\n", "\n", "", "return", "padded_tensor", ",", "tensor_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.pad_dialogue": [[241, 257], ["multiwoz.MultiWozDataset._pad_sequence", "multiwoz.MultiWozDataset._pad_sequence", "max", "warnings.warn", "numpy.array", "numpy.array"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence", "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence"], ["", "def", "pad_dialogue", "(", "self", ",", "dial", ",", "name", ")", ":", "\n", "        ", "input", "=", "dial", "[", "'input'", "]", "\n", "target", "=", "dial", "[", "'target'", "]", "\n", "if", "max", "(", "[", "h", ".", "shape", "[", "0", "]", "for", "h", "in", "input", "]", ")", ">", "self", ".", "args", ".", "seq_len", ":", "\n", "            ", "warnings", ".", "warn", "(", "'input length bigger than max sequence length'", ")", "\n", "return", "None", "\n", "", "padded_input", ",", "input_length", "=", "self", ".", "_pad_sequence", "(", "input", ")", "\n", "padded_target", ",", "target_length", "=", "self", ".", "_pad_sequence", "(", "target", ")", "\n", "ret_dial", "=", "{", "'input'", ":", "padded_input", ",", "\n", "'input_length'", ":", "input_length", ",", "\n", "'target'", ":", "padded_target", ",", "\n", "'target_length'", ":", "target_length", ",", "\n", "'bs'", ":", "np", ".", "array", "(", "dial", "[", "'bs'", "]", ")", ",", "\n", "'db'", ":", "np", ".", "array", "(", "dial", "[", "'db'", "]", ")", ",", "\n", "}", "\n", "return", "ret_dial", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.pad_dialogue_with_history": [[258, 295], ["enumerate", "enumerate", "multiwoz.MultiWozDataset._pad_sequence", "multiwoz.MultiWozDataset._pad_sequence", "multiwoz.MultiWozDataset._pad_sequence", "zip", "torch.cat", "history_pairs.append", "zip", "history.append", "numpy.array", "numpy.array", "torch.cat", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence", "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence", "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset._pad_sequence"], ["", "def", "pad_dialogue_with_history", "(", "self", ",", "dial", ",", "name", ")", ":", "\n", "        ", "input", "=", "dial", "[", "'input'", "]", "\n", "target", "=", "dial", "[", "'target'", "]", "\n", "history", "=", "[", "]", "\n", "history_pairs", "=", "[", "]", "\n", "for", "i", ",", "(", "inp", ",", "tgt", ")", "in", "enumerate", "(", "zip", "(", "input", ",", "target", ")", ")", ":", "\n", "            ", "tmp", "=", "torch", ".", "cat", "(", "(", "inp", ",", "tgt", ")", ")", "\n", "history_pairs", ".", "append", "(", "tmp", ")", "\n", "\n", "", "for", "i", ",", "(", "inp", ",", "tgt", ")", "in", "enumerate", "(", "zip", "(", "input", ",", "target", ")", ")", ":", "\n", "            ", "if", "i", "==", "0", ":", "\n", "                ", "hist", "=", "inp", "\n", "", "elif", "i", ">", "self", ".", "args", ".", "history_length", ":", "\n", "                ", "hist", "=", "torch", ".", "cat", "(", "(", "*", "history_pairs", "[", "-", "i", ":", "i", "]", ",", "inp", ")", ")", "\n", "", "else", ":", "\n", "                ", "hist", "=", "torch", ".", "cat", "(", "(", "*", "history_pairs", "[", ":", "i", "]", ",", "inp", ")", ")", "\n", "", "history", ".", "append", "(", "hist", ")", "\n", "\n", "", "padded_input", ",", "input_length", "=", "self", ".", "_pad_sequence", "(", "input", ")", "\n", "padded_target", ",", "target_length", "=", "self", ".", "_pad_sequence", "(", "target", ")", "\n", "padded_history", ",", "history_length", "=", "self", ".", "_pad_sequence", "(", "history", ")", "\n", "\n", "ret_dial", "=", "{", "'input'", ":", "padded_input", ",", "\n", "'input_length'", ":", "input_length", ",", "\n", "'target'", ":", "padded_target", ",", "\n", "'target_length'", ":", "target_length", ",", "\n", "'history'", ":", "padded_history", ",", "\n", "'history_length'", ":", "history_length", ",", "\n", "'bs'", ":", "np", ".", "array", "(", "dial", "[", "'bs'", "]", ")", ",", "\n", "'db'", ":", "np", ".", "array", "(", "dial", "[", "'db'", "]", ")", ",", "\n", "'input_raw'", ":", "dial", "[", "'input_raw'", "]", ",", "\n", "'target_raw'", ":", "dial", "[", "'target_raw'", "]", ",", "\n", "'action_raw'", ":", "dial", "[", "'action_raw'", "]", ",", "\n", "'belief_raw'", ":", "dial", "[", "'belief_raw'", "]", "\n", "}", "\n", "\n", "return", "ret_dial", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.__getitem__": [[296, 304], ["list", "multiwoz.MultiWozDataset.pad_dialogue", "multiwoz.MultiWozDataset.pad_dialogue_with_history", "multiwoz.MultiWozDataset.data.keys"], "methods", ["home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.pad_dialogue", "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.multiwoz.MultiWozDataset.pad_dialogue_with_history"], ["", "def", "__getitem__", "(", "self", ",", "item", ")", ":", "\n", "        ", "ret_dial_name", "=", "list", "(", "self", ".", "data", ".", "keys", "(", ")", ")", "[", "item", "]", "\n", "if", "self", ".", "args", ".", "no_history", ":", "\n", "            ", "dial", "=", "self", ".", "pad_dialogue", "(", "self", ".", "data", "[", "ret_dial_name", "]", ",", "ret_dial_name", ")", "\n", "", "else", ":", "\n", "            ", "dial", "=", "self", ".", "pad_dialogue_with_history", "(", "self", ".", "data", "[", "ret_dial_name", "]", ",", "ret_dial_name", ")", "\n", "", "dial", "[", "'name'", "]", "=", "ret_dial_name", "\n", "return", "dial", "\n", "\n"]], "home.repos.pwc.inspect_result.salesforce_simpletod.dataset.__init__.get_dataset": [[5, 26], ["multiwoz.MultiWozDataset", "len", "len", "len", "len"], "function", ["None"], ["import", "copy", "\n", "import", "torch", "\n", "import", "logging", "\n", "logging", ".", "basicConfig", "(", ")", "\n", "\n", "import", "ipdb", "\n", "\n", "\n", "def", "get_logger", "(", "name", ")", ":", "\n", "    ", "logger", "=", "logging", ".", "getLogger", "(", "name", ")", "\n", "logger", ".", "setLevel", "(", "logging", ".", "INFO", ")", "\n", "return", "logger", "\n", "\n", "\n", "", "def", "get_writer", "(", "name", ")", ":", "\n", "    ", "writer", "=", "SummaryWriter", "(", "name", ")", "\n", "return", "writer", "\n", "\n", "\n", "", "def", "prepare_logger_writer", "(", "args", ")", ":", "\n", "# if args.resume or args.mode in ['evaluate', 'generate']:", "\n", "#     chekpoint_name = os.path.join(args.experiment_dir, '{}_best.chkpt'.format(args.model_type))", "\n"]]}