{"home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.print_spans.main": [[17, 38], ["src.Propaganda_Techniques", "src.Articles_annotations", "aa.Articles_annotations.load_article_annotations_from_csv_file", "aa.Articles_annotations.mark_text", "print", "print", "codecs.open", "f.read"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.load_article_annotations_from_csv_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.mark_text"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "span_file", "=", "args", ".", "spans_file", "\n", "article_file", "=", "args", ".", "article_file", "\n", "propaganda_techniques_list_file", "=", "args", ".", "propaganda_techniques_list_file", "\n", "\n", "propaganda_techniques", "=", "pt", ".", "Propaganda_Techniques", "(", "propaganda_techniques_list_file", ")", "\n", "annotations", "=", "aa", ".", "Articles_annotations", "(", ")", "\n", "aa", ".", "Articles_annotations", ".", "techniques", "=", "propaganda_techniques", "\n", "\n", "annotations", ".", "load_article_annotations_from_csv_file", "(", "span_file", ")", "\n", "\n", "with", "codecs", ".", "open", "(", "article_file", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "        ", "article_content", "=", "f", ".", "read", "(", ")", "\n", "\n", "#print(\"\\n\".join([str(i)+\") \"+x for i,x in enumerate(str(aa.techniques).split(\"\\n\"))]))", "\n", "#output_text, footnotes = annotations.tag_text_with_annotations(article_content)", "\n", "", "output_text", ",", "footnotes", ",", "legend", "=", "annotations", ".", "mark_text", "(", "article_content", ")", "\n", "\n", "print", "(", "output_text", ")", "\n", "print", "(", "footnotes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-TC_scorer.main": [[19, 62], ["bool", "src.Propaganda_Techniques", "src.Annotation.set_propaganda_technique_list_obj", "src.Annotations", "ans.Annotations.load_annotation_list_from_file", "ans.Annotations.get_article_id_list", "src.Annotations", "ans.Annotations.load_annotation_list_from_file", "ans.Annotations.get_article_id_list", "logger.info", "logger.info", "ans.Annotations.TC_score_to_string", "logger.info", "logger.addHandler", "ch.setLevel", "logger.info", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logger.addHandler", "ans.Annotations.get_article_annotations_obj().sort_spans", "ans.Annotations.get_article_annotations_obj().sort_spans", "logger.error", "sys.exit", "print", "ans.Annotations.compare_annotations_identical_article_lists", "ans.Annotations.compare_annotations_identical", "ans.Annotations.get_article_annotations_obj", "ans.Annotations.get_article_annotations_obj"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.set_propaganda_technique_list_obj", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.load_annotation_list_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.load_annotation_list_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.TC_score_to_string", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.sort_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.sort_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.compare_annotations_identical_article_lists", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.compare_annotations_identical", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_obj", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_obj"], ["def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "user_submission_file", "=", "args", ".", "submission", "\n", "gold_file", "=", "args", ".", "gold", "\n", "output_log_file", "=", "args", ".", "log_file", "\n", "propaganda_techniques_list_file", "=", "args", ".", "propaganda_techniques_list_file", "\n", "output_for_script", "=", "bool", "(", "args", ".", "output_for_script", ")", "\n", "\n", "if", "not", "output_for_script", ":", "\n", "        ", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "", "if", "args", ".", "debug_on_std", ":", "\n", "        ", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "", "if", "output_log_file", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Logging execution to file \"", "+", "output_log_file", ")", "\n", "fileLogger", "=", "logging", ".", "FileHandler", "(", "output_log_file", ")", "\n", "fileLogger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fileLogger", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fileLogger", ")", "\n", "\n", "", "propaganda_techniques", "=", "pt", ".", "Propaganda_Techniques", "(", "propaganda_techniques_list_file", ")", "\n", "an", ".", "Annotation", ".", "set_propaganda_technique_list_obj", "(", "propaganda_techniques", ")", "\n", "\n", "user_annotations", "=", "ans", ".", "Annotations", "(", ")", "\n", "user_annotations", ".", "load_annotation_list_from_file", "(", "user_submission_file", ")", "\n", "for", "article", "in", "user_annotations", ".", "get_article_id_list", "(", ")", ":", "\n", "        ", "user_annotations", ".", "get_article_annotations_obj", "(", "article", ")", ".", "sort_spans", "(", ")", "\n", "\n", "", "gold_annotations", "=", "ans", ".", "Annotations", "(", ")", "\n", "gold_annotations", ".", "load_annotation_list_from_file", "(", "gold_file", ")", "\n", "for", "article", "in", "gold_annotations", ".", "get_article_id_list", "(", ")", ":", "\n", "        ", "gold_annotations", ".", "get_article_annotations_obj", "(", "article", ")", ".", "sort_spans", "(", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Checking format: User Predictions -- Gold Annotations\"", ")", "\n", "if", "not", "user_annotations", ".", "compare_annotations_identical_article_lists", "(", "gold_annotations", ")", "or", "not", "user_annotations", ".", "compare_annotations_identical", "(", "gold_annotations", ")", ":", "\n", "        ", "logger", ".", "error", "(", "\"wrong format, no scoring will be performed\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "logger", ".", "info", "(", "\"OK: submission file format appears to be correct\"", ")", "\n", "res_for_output", ",", "res_for_script", "=", "user_annotations", ".", "TC_score_to_string", "(", "gold_annotations", ",", "output_for_script", ")", "\n", "logger", ".", "info", "(", "\"Scoring submission\"", "+", "res_for_output", ")", "\n", "if", "output_for_script", ":", "\n", "        ", "print", "(", "res_for_script", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_data_file_lists": [[31, 55], ["logger.debug", "len", "len", "logger.error", "sys.exit", "len", "logger.error", "gold_annotations.keys", "submission_annotations.keys", "submission_annotations.keys", "gold_annotations.keys", "str", "len", "len", "submission_annotations.keys", "gold_annotations.keys"], "function", ["None"], ["def", "check_data_file_lists", "(", "submission_annotations", ",", "gold_annotations", ",", "task_name", "=", "\"task3\"", ")", ":", "\n", "\n", "#checking that the number of articles for which the user has submitted annotations is correct", "\n", "    ", "if", "len", "(", "gold_annotations", ".", "keys", "(", ")", ")", "<", "len", "(", "submission_annotations", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "error", "(", "\"The number of articles in the submission, %d, is greater than the number of articles in the \"", "\n", "\"reference dataset, %d.\"", "%", "(", "len", "(", "submission_annotations", ".", "keys", "(", ")", ")", ",", "len", "(", "gold_annotations", ".", "keys", "(", ")", ")", ")", ")", ";", "sys", ".", "exit", "(", ")", "\n", "# logger.debug(\"OK: number of articles in the submission for %s is the same as the one in the gold file: %d\"", "\n", "#              % (task_name, len(gold_annotations.keys())))", "\n", "\n", "#check that all file names are correct", "\n", "", "errors", "=", "[", "article_id", "for", "article_id", "in", "submission_annotations", ".", "keys", "(", ")", "if", "article_id", "not", "in", "gold_annotations", ".", "keys", "(", ")", "]", "\n", "if", "len", "(", "errors", ")", ">", "0", ":", "\n", "        ", "logger", ".", "error", "(", "\"The following article_ids in the submission file do not have a correspondence in the reference \"", "\n", "\"dataset: %s\\n\"", "%", "(", "str", "(", "errors", ")", ")", ")", "\n", "# gold_file_article_id_set = set([article_id for article_id in gold_annotations.keys()])", "\n", "# submission_file_article_id_set = set([article_id for article_id in submission_annotations.keys()])", "\n", "# intersection_file_list = gold_file_article_id_set.intersection(submission_file_article_id_set)", "\n", "# if len(intersection_file_list) != len(gold_annotations):", "\n", "#     logger.error(\"The list of article ids is not identical.\\n\"", "\n", "#              \"The following article_ids in the submission file do not have a correspondence in the gold file: %s\\n\"", "\n", "#              \"The following article_ids in the gold file do not have a correspondence in the submission file: %s\"", "\n", "#              %(str(submission_file_article_id_set.difference(gold_file_article_id_set)),", "\n", "#                str(gold_file_article_id_set.difference(submission_file_article_id_set)))); sys.exit()", "\n", "", "logger", ".", "debug", "(", "\"OK: all article ids have a correspondence in the list of articles from the reference dataset\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.load_technique_names_from_file": [[57, 61], ["open", "line.rstrip", "f.readlines"], "function", ["None"], ["", "def", "load_technique_names_from_file", "(", "filename", "=", "TECHNIQUE_NAMES_FILE", ")", ":", "\n", "\n", "    ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.extract_article_id_from_file_name": [[63, 67], ["re.compile", "re.compile.match().group", "re.compile.match", "os.path.basename"], "function", ["None"], ["", "", "def", "extract_article_id_from_file_name", "(", "fullpathfilename", ")", ":", "\n", "\n", "    ", "regex", "=", "re", ".", "compile", "(", "\"article([0-9]+).*\"", ")", "\n", "return", "regex", ".", "match", "(", "os", ".", "path", ".", "basename", "(", "fullpathfilename", ")", ")", ".", "group", "(", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.print_annotations": [[69, 76], ["min", "max"], "function", ["None"], ["", "def", "print_annotations", "(", "annotation_list", ")", ":", "\n", "    ", "s", "=", "\"\"", "\n", "i", "=", "0", "\n", "for", "technique", ",", "span", "in", "annotation_list", ":", "\n", "        ", "s", "+=", "\"%d) %s: %d - %d\\n\"", "%", "(", "i", ",", "technique", ",", "min", "(", "span", ")", ",", "max", "(", "span", ")", ")", "\n", "i", "+=", "1", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.merge_spans": [[77, 104], ["range", "len", "print", "[].union", "task-SI_scorer.merge_spans", "len", "len", "len", "[].intersection"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.merge_spans"], ["", "def", "merge_spans", "(", "annotations_without_overlapping", ",", "i", ")", ":", "\n", "    ", "\"\"\"\n\n    :param spans: a list of spans of article annotations\n    :param i: the index in spans which needs to be tested for ovelapping\n    :param annotations: a list of annotations of an article\n    :return:\n    \"\"\"", "\n", "#print(\"checking element %d of %d\"%(i, len(spans)))", "\n", "for", "j", "in", "range", "(", "0", ",", "len", "(", "annotations_without_overlapping", ")", ")", ":", "\n", "        ", "assert", "i", "<", "len", "(", "annotations_without_overlapping", ")", "or", "print", "(", "i", ",", "len", "(", "annotations_without_overlapping", ")", ")", "\n", "if", "j", "!=", "i", "and", "len", "(", "annotations_without_overlapping", "[", "i", "]", "[", "1", "]", ".", "intersection", "(", "annotations_without_overlapping", "[", "j", "]", "[", "1", "]", ")", ")", ">", "0", ":", "\n", "# print(\"Found overlapping spans: %d-%d and %d-%d in annotations %d,%d:\\n%s\"", "\n", "#       %(min(annotations_without_overlapping[i][1]), max(annotations_without_overlapping[i][1]),", "\n", "#         min(annotations_without_overlapping[j][1]), max(annotations_without_overlapping[j][1]), i,j,", "\n", "#         print_annotations(annotations_without_overlapping)))", "\n", "            ", "annotations_without_overlapping", "[", "j", "]", "[", "1", "]", "=", "annotations_without_overlapping", "[", "j", "]", "[", "1", "]", ".", "union", "(", "annotations_without_overlapping", "[", "i", "]", "[", "1", "]", ")", "\n", "del", "(", "annotations_without_overlapping", "[", "i", "]", ")", "\n", "# print(\"Annotations after deletion:\\n%s\"%(print_annotations(annotations_without_overlapping)))", "\n", "if", "j", ">", "i", ":", "\n", "                ", "j", "-=", "1", "\n", "# print(\"calling recursively\")", "\n", "", "merge_spans", "(", "annotations_without_overlapping", ",", "j", ")", "\n", "# print(\"done\")", "\n", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_annotation_spans": [[106, 131], ["annotations.keys", "annotations_without_overlapping.append", "task-SI_scorer.merge_spans", "spans.append", "len", "len", "logger.error", "span.intersection", "min", "max", "min", "max"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.merge_spans"], ["", "def", "check_annotation_spans", "(", "annotations", ",", "merge_overlapping_spans", "=", "False", ")", ":", "\n", "\n", "    ", "for", "article_id", "in", "annotations", ".", "keys", "(", ")", ":", "# for each article", "\n", "#print(article_id)", "\n", "        ", "spans", "=", "[", "]", "\n", "annotations_without_overlapping", "=", "[", "]", "\n", "for", "annotation", "in", "annotations", "[", "article_id", "]", ":", "\n", "            ", "if", "merge_overlapping_spans", ":", "\n", "#spans.append(annotation[1])", "\n", "                ", "annotations_without_overlapping", ".", "append", "(", "[", "annotation", "[", "0", "]", ",", "annotation", "[", "1", "]", "]", ")", "\n", "#if merge_spans(spans, len(spans)-1, annotations[article_id]):", "\n", "merge_spans", "(", "annotations_without_overlapping", ",", "len", "(", "annotations_without_overlapping", ")", "-", "1", ")", "\n", "#if merge_spans(annotations_without_overlapping, len(annotations_without_overlapping) - 1):", "\n", "#    print(\"Done with merging:\\n\" + print_annotations(annotations_without_overlapping))", "\n", "", "else", ":", "\n", "                ", "for", "span", "in", "spans", ":", "\n", "                    ", "if", "len", "(", "span", ".", "intersection", "(", "annotation", "[", "1", "]", ")", ")", ">", "0", ":", "\n", "                        ", "logger", ".", "error", "(", "\"In article %s, the span [%s,%s] overlap with the following one from the same \"", "\n", "\"article: [%s,%s]\"", "%", "(", "article_id", ",", "min", "(", "annotation", "[", "1", "]", ")", ",", "max", "(", "annotation", "[", "1", "]", ")", ",", "\n", "min", "(", "span", ")", ",", "max", "(", "span", ")", ")", ")", "\n", "return", "False", "\n", "", "", "spans", ".", "append", "(", "annotation", "[", "1", "]", ")", "\n", "", "", "if", "merge_overlapping_spans", ":", "\n", "            ", "annotations", "[", "article_id", "]", "=", "annotations_without_overlapping", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_annotation_spans_with_category_matching": [[133, 167], ["annotations.keys", "annotation_list.keys", "annotation_list.keys", "annotation_list[].append", "task-SI_scorer.merge_spans", "annotation_list[].append", "len", "len", "logger.error", "curr_span.intersection", "min", "max", "min", "max"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.merge_spans"], ["", "def", "check_annotation_spans_with_category_matching", "(", "annotations", ",", "merge_overlapping_spans", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Check whether there are ovelapping spans for the same technique in the same article.\n    Two spans are overlapping if their associated techniques match (according to category_matching_func)\n    If merge_overlapping_spans==True then the overlapping spans are merged, otherwise an error is raised.\n\n    :param annotations: a dictionary with the full set of annotations for all articles\n    :param merge_overlapping_spans: if True merges the overlapping spans\n    :return:\n    \"\"\"", "\n", "\n", "for", "article_id", "in", "annotations", ".", "keys", "(", ")", ":", "# for each article", "\n", "\n", "        ", "annotation_list", "=", "{", "}", "\n", "for", "technique", ",", "curr_span", "in", "annotations", "[", "article_id", "]", ":", "\n", "            ", "if", "technique", "not", "in", "annotation_list", ".", "keys", "(", ")", ":", "\n", "                ", "annotation_list", "[", "technique", "]", "=", "[", "[", "technique", ",", "curr_span", "]", "]", "\n", "", "else", ":", "\n", "                ", "if", "merge_overlapping_spans", ":", "\n", "                    ", "annotation_list", "[", "technique", "]", ".", "append", "(", "[", "technique", ",", "curr_span", "]", ")", "\n", "merge_spans", "(", "annotation_list", "[", "technique", "]", ",", "len", "(", "annotation_list", "[", "technique", "]", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "for", "matching_technique", ",", "span", "in", "annotation_list", "[", "technique", "]", ":", "\n", "                        ", "if", "len", "(", "curr_span", ".", "intersection", "(", "span", ")", ")", ">", "0", ":", "\n", "                            ", "logger", ".", "error", "(", "\"In article %s, the span of the annotation %s, [%s,%s] overlap with \"", "\n", "\"the following one from the same article:%s, [%s,%s]\"", "%", "(", "article_id", ",", "matching_technique", ",", "\n", "min", "(", "span", ")", ",", "max", "(", "span", ")", ",", "technique", ",", "min", "(", "curr_span", ")", ",", "max", "(", "curr_span", ")", ")", ")", "\n", "return", "False", "\n", "", "", "annotation_list", "[", "technique", "]", ".", "append", "(", "[", "technique", ",", "curr_span", "]", ")", "\n", "", "", "", "if", "merge_overlapping_spans", ":", "\n", "            ", "annotations", "[", "article_id", "]", "=", "[", "]", "\n", "for", "technique", "in", "annotation_list", ".", "keys", "(", ")", ":", "\n", "                ", "annotations", "[", "article_id", "]", "+=", "annotation_list", "[", "technique", "]", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_format_of_annotation_in_file": [[169, 195], ["len", "logger.error", "sys.exit", "logger.error", "sys.exit", "int", "int", "logger.error", "sys.exit", "int", "int", "len"], "function", ["None"], ["", "def", "check_format_of_annotation_in_file", "(", "row", ",", "i", ",", "techniques_names", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n\n    :param row: a list of fields describing the annotation elements (technique name, start_span, end_span)\n    :param i:\n    :return:\n    \"\"\"", "\n", "\n", "if", "len", "(", "row", ")", "!=", "3", ":", "\n", "        ", "logger", ".", "error", "(", "\"Row %d in file %s is supposed to have 3 TAB-separated columns. Found %d.\"", "\n", "%", "(", "i", "+", "1", ",", "filename", ",", "len", "(", "row", ")", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "# checking the technique names are correct", "\n", "# if row[TASK_3_TECHNIQUE_NAME_COL] not in techniques_names:", "\n", "#     logger.error(\"On row %d in file %s the technique name, %s, is incorrect. Possible values are: %s\"", "\n", "#                  % (i + 1, filename, row[TASK_3_TECHNIQUE_NAME_COL], str(techniques_names)))", "\n", "#     sys.exit()", "\n", "# checking spans", "\n", "", "if", "int", "(", "row", "[", "TASK_3_FRAGMENT_START_COL", "]", ")", "<", "0", "or", "int", "(", "row", "[", "TASK_3_FRAGMENT_END_COL", "]", ")", "<", "0", ":", "\n", "        ", "logger", ".", "error", "(", "\"On row %d in file %s, start and end of position of the fragment must be non-negative. \"", "\n", "\"Found values %s, %s\"", "%", "(", "i", "+", "1", ",", "filename", ",", "row", "[", "TASK_3_FRAGMENT_START_COL", "]", ",", "row", "[", "TASK_3_FRAGMENT_END_COL", "]", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "if", "int", "(", "row", "[", "TASK_3_FRAGMENT_START_COL", "]", ")", ">=", "int", "(", "row", "[", "TASK_3_FRAGMENT_END_COL", "]", ")", ":", "\n", "        ", "logger", ".", "error", "(", "\"On row %d in file %s, end position of the fragment must be greater than the starting \"", "\n", "\"one. Found values %s, %s\"", "%", "(", "i", "+", "1", ",", "filename", ",", "row", "[", "TASK_3_FRAGMENT_START_COL", "]", ",", "row", "[", "TASK_3_FRAGMENT_END_COL", "]", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_article_annotations_format": [[197, 215], ["enumerate", "logger.debug", "check_annotation_format_from_file", "annotations[].append", "annotations.keys", "set", "range", "int", "int", "len", "logger.error", "sys.exit", "set().intersection", "set", "range", "int", "int"], "function", ["None"], ["", "", "def", "check_article_annotations_format", "(", "submission_article_annotations", ",", "article_id", ",", "techniques_names", ")", ":", "\n", "\n", "    ", "annotations", "=", "{", "}", "\n", "for", "i", ",", "row", "in", "enumerate", "(", "submission_article_annotations", ")", ":", "\n", "        ", "check_annotation_format_from_file", "(", "row", ",", "i", ")", "\n", "#checking that there are no overlapping spans flagged with the same technique name", "\n", "if", "row", "[", "0", "]", "not", "in", "annotations", ".", "keys", "(", ")", ":", "\n", "            ", "annotations", "[", "row", "[", "0", "]", "]", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "curr_span", "=", "set", "(", "range", "(", "int", "(", "row", "[", "1", "]", ")", ",", "int", "(", "row", "[", "2", "]", ")", ")", ")", "\n", "for", "span", "in", "annotations", "[", "row", "[", "0", "]", "]", ":", "\n", "                ", "if", "len", "(", "set", "(", "range", "(", "int", "(", "span", "[", "0", "]", ")", ",", "int", "(", "span", "[", "1", "]", ")", ")", ")", ".", "intersection", "(", "curr_span", ")", ")", ">", "0", ":", "\n", "                    ", "logger", ".", "error", "(", "\"On row %d in article %s, the span of the annotation %s, [%s,%s] overlap with the \"", "\n", "\"following one from the same file: [%s,%s]\"", "\n", "%", "(", "i", "+", "1", ",", "article_id", ",", "row", "[", "0", "]", ",", "row", "[", "1", "]", ",", "row", "[", "2", "]", ",", "span", "[", "0", "]", ",", "span", "[", "1", "]", ")", ")", ";", "\n", "sys", ".", "exit", "(", ")", "\n", "", "", "", "annotations", "[", "row", "[", "0", "]", "]", ".", "append", "(", "[", "row", "[", "1", "]", ",", "row", "[", "2", "]", "]", ")", "\n", "", "logger", ".", "debug", "(", "\"OK: article %s format is correct\"", "%", "(", "article_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.read_task3_output_file": [[217, 221], ["open", "line.rstrip().split", "f.readlines", "line.rstrip"], "function", ["None"], ["", "def", "read_task3_output_file", "(", "filename", ")", ":", "\n", "\n", "    ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "return", "[", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_technique_frequency": [[223, 226], ["sum", "len"], "function", ["None"], ["", "", "def", "compute_technique_frequency", "(", "annotations_list", ",", "technique_name", ")", ":", "\n", "    ", "return", "sum", "(", "[", "len", "(", "[", "example_annotation", "for", "example_annotation", "in", "x", "if", "example_annotation", "[", "0", "]", "==", "technique_name", "]", ")", "\n", "for", "x", "in", "annotations_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_score_max": [[228, 295], ["sum", "sum", "submission_annotations.keys", "task-SI_scorer.compute_prec_rec_f1", "logger.debug", "enumerate", "cumulative_Spr_max.keys", "len", "len", "len", "enumerate", "logger.debug", "task-SI_scorer.compute_prec_rec_f1", "logger.info", "submission_annotations.values", "gold_annotations.values", "task-SI_scorer.compute_technique_frequency", "task-SI_scorer.compute_technique_frequency", "str", "str", "len", "len", "submission_annotations.values", "gold_annotations.values", "sd[].intersection", "max", "min", "max", "min", "max"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_technique_frequency", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_technique_frequency"], ["", "def", "compute_score_max", "(", "submission_annotations", ",", "gold_annotations", ",", "technique_names", ",", "prop_vs_non_propaganda", "=", "False", ")", ":", "\n", "\n", "    ", "prec_denominator", "=", "sum", "(", "[", "len", "(", "annotations", ")", "for", "annotations", "in", "submission_annotations", ".", "values", "(", ")", "]", ")", "\n", "rec_denominator", "=", "sum", "(", "[", "len", "(", "annotations", ")", "for", "annotations", "in", "gold_annotations", ".", "values", "(", ")", "]", ")", "\n", "technique_Spr_max", "=", "{", "propaganda_technique", ":", "0", "for", "propaganda_technique", "in", "technique_names", "}", "\n", "cumulative_Spr_max", "=", "0", "\n", "for", "article_id", "in", "submission_annotations", ".", "keys", "(", ")", ":", "\n", "        ", "gold_data", "=", "gold_annotations", "[", "article_id", "]", "\n", "logger", ".", "debug", "(", "\"Computing contribution to the score of article id %s\\nand tuples %s\\n%s\\n\"", "\n", "%", "(", "article_id", ",", "str", "(", "submission_annotations", "[", "article_id", "]", ")", ",", "str", "(", "gold_data", ")", ")", ")", "\n", "for", "j", ",", "sd", "in", "enumerate", "(", "submission_annotations", "[", "article_id", "]", ")", ":", "#submission_data:", "\n", "            ", "s", "=", "\"\"", "\n", "sd_annotation_length", "=", "len", "(", "sd", "[", "1", "]", ")", "\n", "for", "i", ",", "gd", "in", "enumerate", "(", "gold_data", ")", ":", "\n", "                ", "if", "prop_vs_non_propaganda", "or", "gd", "[", "0", "]", "==", "sd", "[", "0", "]", ":", "\n", "#s += \"\\tmatch %s %s-%s - %s %s-%s\"%(sd[0],sd[1], sd[2], gd[0], gd[1], gd[2])", "\n", "                    ", "intersection", "=", "len", "(", "sd", "[", "1", "]", ".", "intersection", "(", "gd", "[", "1", "]", ")", ")", "\n", "gd_annotation_length", "=", "len", "(", "gd", "[", "1", "]", ")", "\n", "\n", "Spr", "=", "intersection", "/", "max", "(", "sd_annotation_length", ",", "gd_annotation_length", ")", "\n", "cumulative_Spr_max", "+=", "Spr", "\n", "s", "+=", "\"\\tmatch %s %s-%s - %s %s-%s: S(p,r)=|intersect(r, p)|/max(|p|,|r|) = %d/max(%d,%d) = %f (cumulative S(p,r)=%f)\\n\"", "%", "(", "sd", "[", "0", "]", ",", "min", "(", "sd", "[", "1", "]", ")", ",", "max", "(", "sd", "[", "1", "]", ")", ",", "gd", "[", "0", "]", ",", "min", "(", "gd", "[", "1", "]", ")", ",", "max", "(", "gd", "[", "1", "]", ")", ",", "intersection", ",", "sd_annotation_length", ",", "gd_annotation_length", ",", "Spr", ",", "cumulative_Spr_max", ")", "\n", "technique_Spr_max", "[", "gd", "[", "0", "]", "]", "+=", "Spr", "\n", "\n", "", "", "logger", ".", "debug", "(", "\"\\n%s\"", "%", "(", "s", ")", ")", "\n", "\n", "", "", "p", ",", "r", ",", "f1", "=", "compute_prec_rec_f1", "(", "cumulative_Spr_max", ",", "prec_denominator", ",", "cumulative_Spr_max", ",", "rec_denominator", ")", "\n", "\n", "if", "not", "prop_vs_non_propaganda", ":", "\n", "        ", "for", "technique_name", "in", "cumulative_Spr_max", ".", "keys", "(", ")", ":", "\n", "            ", "prec_tech", ",", "rec_tech", ",", "f1_tech", "=", "compute_prec_rec_f1", "(", "cumulative_Spr_max", "[", "technique_name", "]", ",", "\n", "compute_technique_frequency", "(", "submission_annotations", ".", "values", "(", ")", ",", "technique_name", ")", ",", "\n", "cumulative_Spr_max", "[", "technique_name", "]", ",", "\n", "compute_technique_frequency", "(", "gold_annotations", ".", "values", "(", ")", ",", "technique_name", ")", ",", "False", ")", "\n", "logger", ".", "info", "(", "\"%s: P=%f R=%f F1=%f\"", "%", "(", "technique_name", ",", "prec_tech", ",", "rec_tech", ",", "f1_tech", ")", ")", "\n", "\n", "# p,r,f1=(0,0,0)", "\n", "# if prec_denominator>0:", "\n", "#     p = cumulative_Spr_max/prec_denominator", "\n", "# if rec_denominator>0:", "\n", "#     r = cumulative_Spr_max/rec_denominator", "\n", "# logger.info(\"Precision=%f/%d=%f\\tRecall=%f/%d=%f\"", "\n", "#              %(cumulative_Spr_max, prec_denominator, p, cumulative_Spr_max, rec_denominator, r))", "\n", "# if prec_denominator == 0 and rec_denominator == 0:", "\n", "#     f1 = 1.0", "\n", "# if p>0 and r>0:", "\n", "#     f1 = 2*(p*r/(p+r))", "\n", "# logger.info(\"F1=%f\"%(f1))", "\n", "#", "\n", "# if not prop_vs_non_propaganda:", "\n", "#     for technique_name in technique_Spr_max.keys():", "\n", "#         prec_tech, rec_tech, f1_tech = (0,0,0)", "\n", "#         prec_tech_denominator = compute_technique_frequency(submission_annotations.values(), technique_name)", "\n", "#         rec_tech_denominator = compute_technique_frequency(gold_annotations.values(), technique_name)", "\n", "#         if prec_tech_denominator == 0 and rec_tech_denominator == 0: #", "\n", "#             f1_tech = 1.0", "\n", "#         else:", "\n", "#             if prec_tech_denominator > 0:", "\n", "#                 prec_tech = technique_Spr_max[technique_name] / prec_tech_denominator", "\n", "#             if rec_tech_denominator > 0:", "\n", "#                 rec_tech = technique_Spr_max[technique_name] / rec_tech_denominator", "\n", "#             if prec_tech>0 and rec_tech>0:", "\n", "#                 f1_tech = 2*(prec_tech*rec_tech/(prec_tech+rec_tech))", "\n", "#         logger.info(\"%s: P=%f R=%f F1=%f\"%(technique_name, prec_tech, rec_tech, f1_tech))", "\n", "\n", "", "", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_score_min": [[296, 363], ["sum", "sum", "submission_annotations.keys", "task-SI_scorer.compute_prec_rec_f1", "logger.debug", "enumerate", "cumulative_Spr_min.keys", "len", "len", "len", "enumerate", "logger.debug", "task-SI_scorer.compute_prec_rec_f1", "logger.info", "submission_annotations.values", "gold_annotations.values", "task-SI_scorer.compute_technique_frequency", "task-SI_scorer.compute_technique_frequency", "str", "str", "len", "len", "submission_annotations.values", "gold_annotations.values", "sd[].intersection", "min", "min", "max", "min", "max"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_technique_frequency", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_technique_frequency"], ["", "def", "compute_score_min", "(", "submission_annotations", ",", "gold_annotations", ",", "technique_names", ",", "prop_vs_non_propaganda", "=", "False", ")", ":", "\n", "\n", "    ", "prec_denominator", "=", "sum", "(", "[", "len", "(", "annotations", ")", "for", "annotations", "in", "submission_annotations", ".", "values", "(", ")", "]", ")", "\n", "rec_denominator", "=", "sum", "(", "[", "len", "(", "annotations", ")", "for", "annotations", "in", "gold_annotations", ".", "values", "(", ")", "]", ")", "\n", "technique_Spr_min", "=", "{", "propaganda_technique", ":", "0", "for", "propaganda_technique", "in", "technique_names", "}", "\n", "cumulative_Spr_min", "=", "0", "\n", "for", "article_id", "in", "submission_annotations", ".", "keys", "(", ")", ":", "\n", "        ", "gold_data", "=", "gold_annotations", "[", "article_id", "]", "\n", "logger", ".", "debug", "(", "\"Computing contribution to the score of article id %s\\nand tuples %s\\n%s\\n\"", "\n", "%", "(", "article_id", ",", "str", "(", "submission_annotations", "[", "article_id", "]", ")", ",", "str", "(", "gold_data", ")", ")", ")", "\n", "for", "j", ",", "sd", "in", "enumerate", "(", "submission_annotations", "[", "article_id", "]", ")", ":", "#submission_data:", "\n", "            ", "s", "=", "\"\"", "\n", "sd_annotation_length", "=", "len", "(", "sd", "[", "1", "]", ")", "\n", "for", "i", ",", "gd", "in", "enumerate", "(", "gold_data", ")", ":", "\n", "                ", "if", "prop_vs_non_propaganda", "or", "gd", "[", "0", "]", "==", "sd", "[", "0", "]", ":", "\n", "#s += \"\\tmatch %s %s-%s - %s %s-%s\"%(sd[0],sd[1], sd[2], gd[0], gd[1], gd[2])", "\n", "                    ", "intersection", "=", "len", "(", "sd", "[", "1", "]", ".", "intersection", "(", "gd", "[", "1", "]", ")", ")", "\n", "gd_annotation_length", "=", "len", "(", "gd", "[", "1", "]", ")", "\n", "\n", "Spr", "=", "intersection", "/", "min", "(", "sd_annotation_length", ",", "gd_annotation_length", ")", "\n", "cumulative_Spr_min", "+=", "Spr", "\n", "s", "+=", "\"\\tmatch %s %s-%s - %s %s-%s: S(p,r)=|intersect(r, p)|/min(|p|,|r|) = %d/min(%d,%d) = %f (cumulative S(p,r)=%f)\\n\"", "%", "(", "sd", "[", "0", "]", ",", "min", "(", "sd", "[", "1", "]", ")", ",", "max", "(", "sd", "[", "1", "]", ")", ",", "gd", "[", "0", "]", ",", "min", "(", "gd", "[", "1", "]", ")", ",", "max", "(", "gd", "[", "1", "]", ")", ",", "intersection", ",", "sd_annotation_length", ",", "gd_annotation_length", ",", "Spr", ",", "cumulative_Spr_min", ")", "\n", "technique_Spr_min", "[", "gd", "[", "0", "]", "]", "+=", "Spr", "\n", "\n", "", "", "logger", ".", "debug", "(", "\"\\n%s\"", "%", "(", "s", ")", ")", "\n", "\n", "", "", "p", ",", "r", ",", "f1", "=", "compute_prec_rec_f1", "(", "cumulative_Spr_min", ",", "prec_denominator", ",", "cumulative_Spr_min", ",", "rec_denominator", ")", "\n", "\n", "if", "not", "prop_vs_non_propaganda", ":", "\n", "        ", "for", "technique_name", "in", "cumulative_Spr_min", ".", "keys", "(", ")", ":", "\n", "            ", "prec_tech", ",", "rec_tech", ",", "f1_tech", "=", "compute_prec_rec_f1", "(", "cumulative_Spr_min", "[", "technique_name", "]", ",", "\n", "compute_technique_frequency", "(", "submission_annotations", ".", "values", "(", ")", ",", "technique_name", ")", ",", "\n", "cumulative_Spr_min", "[", "technique_name", "]", ",", "\n", "compute_technique_frequency", "(", "gold_annotations", ".", "values", "(", ")", ",", "technique_name", ")", ",", "False", ")", "\n", "logger", ".", "info", "(", "\"%s: P=%f R=%f F1=%f\"", "%", "(", "technique_name", ",", "prec_tech", ",", "rec_tech", ",", "f1_tech", ")", ")", "\n", "\n", "# p,r,f1=(0,0,0)", "\n", "# if prec_denominator>0:", "\n", "#     p = cumulative_Spr_min/prec_denominator", "\n", "# if rec_denominator>0:", "\n", "#     r = cumulative_Spr_min/rec_denominator", "\n", "# logger.info(\"Precision=%f/%d=%f\\tRecall=%f/%d=%f\"", "\n", "#              %(cumulative_Spr_min, prec_denominator, p, cumulative_Spr_min, rec_denominator, r))", "\n", "# if prec_denominator == 0 and rec_denominator == 0:", "\n", "#     f1 = 1.0", "\n", "# if p>0 and r>0:", "\n", "#     f1 = 2*(p*r/(p+r))", "\n", "# logger.info(\"F1=%f\"%(f1))", "\n", "#", "\n", "# if not prop_vs_non_propaganda:", "\n", "#     for technique_name in technique_Spr_min.keys():", "\n", "#         prec_tech, rec_tech, f1_tech = (0,0,0)", "\n", "#         prec_tech_denominator = compute_technique_frequency(submission_annotations.values(), technique_name)", "\n", "#         rec_tech_denominator = compute_technique_frequency(gold_annotations.values(), technique_name)", "\n", "#         if prec_tech_denominator == 0 and rec_tech_denominator == 0: #", "\n", "#             f1_tech = 1.0", "\n", "#         else:", "\n", "#             if prec_tech_denominator > 0:", "\n", "#                 prec_tech = technique_Spr_min[technique_name] / prec_tech_denominator", "\n", "#             if rec_tech_denominator > 0:", "\n", "#                 rec_tech = technique_Spr_min[technique_name] / rec_tech_denominator", "\n", "#             if prec_tech>0 and rec_tech>0:", "\n", "#                 f1_tech = 2*(prec_tech*rec_tech/(prec_tech+rec_tech))", "\n", "#         logger.info(\"%s: P=%f R=%f F1=%f\"%(technique_name, prec_tech, rec_tech, f1_tech))", "\n", "\n", "", "", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_score_pr": [[365, 433], ["sum", "sum", "submission_annotations.keys", "task-SI_scorer.compute_prec_rec_f1", "gold_annotations.get", "logger.debug", "enumerate", "task-SI_scorer.compute_prec_rec_f1", "f1_articles.append", "print", "logger.info", "len", "len", "len", "enumerate", "logger.debug", "len", "len", "task-SI_scorer.compute_prec_rec_f1", "logger.info", "submission_annotations.values", "gold_annotations.values", "gold_annotations.get", "task-SI_scorer.compute_technique_frequency", "task-SI_scorer.compute_technique_frequency", "str", "str", "str", "len", "len", "submission_annotations.values", "gold_annotations.values", "len", "sd[].intersection", "str.rstrip().rstrip", "str", "min", "max", "min", "max", "min", "max", "min", "max", "str.rstrip"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_technique_frequency", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_technique_frequency"], ["", "def", "compute_score_pr", "(", "submission_annotations", ",", "gold_annotations", ",", "technique_names", ",", "prop_vs_non_propaganda", "=", "False", ",", "\n", "per_article_evaluation", "=", "False", ",", "output_for_script", "=", "False", ")", ":", "\n", "\n", "    ", "prec_denominator", "=", "sum", "(", "[", "len", "(", "annotations", ")", "for", "annotations", "in", "submission_annotations", ".", "values", "(", ")", "]", ")", "\n", "rec_denominator", "=", "sum", "(", "[", "len", "(", "annotations", ")", "for", "annotations", "in", "gold_annotations", ".", "values", "(", ")", "]", ")", "\n", "technique_Spr_prec", "=", "{", "propaganda_technique", ":", "0", "for", "propaganda_technique", "in", "technique_names", "}", "\n", "technique_Spr_rec", "=", "{", "propaganda_technique", ":", "0", "for", "propaganda_technique", "in", "technique_names", "}", "\n", "cumulative_Spr_prec", ",", "cumulative_Spr_rec", "=", "(", "0", ",", "0", ")", "\n", "f1_articles", "=", "[", "]", "\n", "\n", "for", "article_id", "in", "submission_annotations", ".", "keys", "(", ")", ":", "\n", "        ", "gold_data", "=", "gold_annotations", ".", "get", "(", "article_id", ",", "[", "]", ")", "\n", "logger", ".", "debug", "(", "\"Computing contribution to the score of article id %s\\nand tuples %s\\n%s\\n\"", "\n", "%", "(", "article_id", ",", "str", "(", "submission_annotations", "[", "article_id", "]", ")", ",", "str", "(", "gold_data", ")", ")", ")", "\n", "\n", "article_cumulative_Spr_prec", ",", "article_cumulative_Spr_rec", "=", "(", "0", ",", "0", ")", "\n", "for", "j", ",", "sd", "in", "enumerate", "(", "submission_annotations", "[", "article_id", "]", ")", ":", "#submission annotations for article article_id:", "\n", "            ", "s", "=", "\"\"", "\n", "sd_annotation_length", "=", "len", "(", "sd", "[", "1", "]", ")", "\n", "for", "i", ",", "gd", "in", "enumerate", "(", "gold_data", ")", ":", "\n", "                ", "if", "prop_vs_non_propaganda", "or", "gd", "[", "0", "]", "==", "sd", "[", "0", "]", ":", "\n", "#s += \"\\tmatch %s %s-%s - %s %s-%s\"%(sd[0],sd[1], sd[2], gd[0], gd[1], gd[2])", "\n", "                    ", "intersection", "=", "len", "(", "sd", "[", "1", "]", ".", "intersection", "(", "gd", "[", "1", "]", ")", ")", "\n", "gd_annotation_length", "=", "len", "(", "gd", "[", "1", "]", ")", "\n", "Spr_prec", "=", "intersection", "/", "sd_annotation_length", "\n", "article_cumulative_Spr_prec", "+=", "Spr_prec", "\n", "cumulative_Spr_prec", "+=", "Spr_prec", "\n", "s", "+=", "\"\\tmatch %s %s-%s - %s %s-%s: S(p,r)=|intersect(r, p)|/|p| = %d/%d = %f (cumulative S(p,r)=%f)\\n\"", "%", "(", "sd", "[", "0", "]", ",", "min", "(", "sd", "[", "1", "]", ")", ",", "max", "(", "sd", "[", "1", "]", ")", ",", "gd", "[", "0", "]", ",", "min", "(", "gd", "[", "1", "]", ")", ",", "max", "(", "gd", "[", "1", "]", ")", ",", "intersection", ",", "sd_annotation_length", ",", "Spr_prec", ",", "cumulative_Spr_prec", ")", "\n", "technique_Spr_prec", "[", "gd", "[", "0", "]", "]", "+=", "Spr_prec", "\n", "\n", "Spr_rec", "=", "intersection", "/", "gd_annotation_length", "\n", "article_cumulative_Spr_rec", "+=", "Spr_rec", "\n", "cumulative_Spr_rec", "+=", "Spr_rec", "\n", "s", "+=", "\"\\tmatch %s %s-%s - %s %s-%s: S(p,r)=|intersect(r, p)|/|r| = %d/%d = %f (cumulative S(p,r)=%f)\\n\"", "%", "(", "sd", "[", "0", "]", ",", "min", "(", "sd", "[", "1", "]", ")", ",", "max", "(", "sd", "[", "1", "]", ")", ",", "gd", "[", "0", "]", ",", "min", "(", "gd", "[", "1", "]", ")", ",", "max", "(", "gd", "[", "1", "]", ")", ",", "intersection", ",", "gd_annotation_length", ",", "Spr_rec", ",", "cumulative_Spr_rec", ")", "\n", "technique_Spr_rec", "[", "gd", "[", "0", "]", "]", "+=", "Spr_rec", "\n", "", "", "logger", ".", "debug", "(", "\"\\n%s\"", "%", "(", "s", ")", ")", "\n", "\n", "", "p_article", ",", "r_article", ",", "f1_article", "=", "compute_prec_rec_f1", "(", "article_cumulative_Spr_prec", ",", "\n", "len", "(", "submission_annotations", "[", "article_id", "]", ")", ",", "\n", "article_cumulative_Spr_rec", ",", "\n", "len", "(", "gold_annotations", ".", "get", "(", "article_id", ",", "[", "]", ")", ")", ",", "False", ")", "\n", "f1_articles", ".", "append", "(", "f1_article", ")", "\n", "\n", "", "p", ",", "r", ",", "f1", "=", "compute_prec_rec_f1", "(", "cumulative_Spr_prec", ",", "prec_denominator", ",", "cumulative_Spr_rec", ",", "rec_denominator", ")", "\n", "out", "=", "\"\"", "\n", "if", "output_for_script", ":", "\n", "        ", "out", "+=", "\"%f\\t%f\\t%f\"", "%", "(", "f1", ",", "p", ",", "r", ")", "\n", "", "if", "not", "prop_vs_non_propaganda", ":", "\n", "        ", "for", "technique_name", "in", "technique_names", ":", "\n", "            ", "prec_tech", ",", "rec_tech", ",", "f1_tech", "=", "compute_prec_rec_f1", "(", "technique_Spr_prec", "[", "technique_name", "]", ",", "\n", "compute_technique_frequency", "(", "submission_annotations", ".", "values", "(", ")", ",", "technique_name", ")", ",", "\n", "technique_Spr_prec", "[", "technique_name", "]", ",", "\n", "compute_technique_frequency", "(", "gold_annotations", ".", "values", "(", ")", ",", "technique_name", ")", ",", "False", ")", "\n", "logger", ".", "info", "(", "\"%s: P=%f R=%f F1=%f\"", "%", "(", "technique_name", ",", "prec_tech", ",", "rec_tech", ",", "f1_tech", ")", ")", "\n", "if", "output_for_script", ":", "\n", "                ", "f1_str", "=", "str", "(", "f1_tech", ")", "\n", "if", "len", "(", "f1_str", ")", ">", "1", ":", "\n", "                    ", "out", "+=", "\"\\t\"", "+", "f1_str", ".", "rstrip", "(", "\"0\"", ")", ".", "rstrip", "(", "\".\"", ")", "\n", "", "else", ":", "\n", "                    ", "out", "+=", "\"\\t\"", "+", "f1_str", "\n", "", "", "", "", "if", "output_for_script", ":", "\n", "        ", "print", "(", "out", ")", "\n", "", "if", "per_article_evaluation", ":", "\n", "        ", "logger", ".", "info", "(", "\"Per article evaluation F1=%s\"", "%", "(", "\",\"", ".", "join", "(", "[", "str", "(", "f1_value", ")", "for", "f1_value", "in", "f1_articles", "]", ")", ")", ")", "\n", "\n", "", "return", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_prec_rec_f1": [[435, 452], ["logger.debug", "logger.info", "logger.info"], "function", ["None"], ["", "def", "compute_prec_rec_f1", "(", "prec_numerator", ",", "prec_denominator", ",", "rec_numerator", ",", "rec_denominator", ",", "print_results", "=", "True", ")", ":", "\n", "\n", "    ", "logger", ".", "debug", "(", "\"P=%f/%d, R=%f/%d\"", "%", "(", "prec_numerator", ",", "prec_denominator", ",", "rec_numerator", ",", "rec_denominator", ")", ")", "\n", "p", ",", "r", ",", "f1", "=", "(", "0", ",", "0", ",", "0", ")", "\n", "if", "prec_denominator", ">", "0", ":", "\n", "        ", "p", "=", "prec_numerator", "/", "prec_denominator", "\n", "", "if", "rec_denominator", ">", "0", ":", "\n", "        ", "r", "=", "rec_numerator", "/", "rec_denominator", "\n", "", "if", "print_results", ":", "logger", ".", "info", "(", "\"Precision=%f/%d=%f\\tRecall=%f/%d=%f\"", "%", "(", "prec_numerator", ",", "prec_denominator", ",", "p", ",", "\n", "rec_numerator", ",", "rec_denominator", ",", "r", ")", ")", "\n", "if", "prec_denominator", "==", "0", "and", "rec_denominator", "==", "0", ":", "\n", "        ", "f1", "=", "1.0", "\n", "", "if", "p", ">", "0", "and", "r", ">", "0", ":", "\n", "        ", "f1", "=", "2", "*", "(", "p", "*", "r", "/", "(", "p", "+", "r", ")", ")", "\n", "", "if", "print_results", ":", "\n", "        ", "logger", ".", "info", "(", "\"F1=%f\"", "%", "(", "f1", ")", ")", "\n", "", "return", "p", ",", "r", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.load_annotation_list_from_folder": [[454, 474], ["glob.glob", "os.path.join", "len", "logger.error", "sys.exit", "open", "enumerate", "task-SI_scorer.extract_article_id_from_file_name", "f.readlines", "line.rstrip().split", "task-SI_scorer.check_format_of_annotation_in_file", "annotations[].append", "line.rstrip", "set", "range", "int", "int"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.extract_article_id_from_file_name", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.check_format_of_annotation_in_file"], ["", "def", "load_annotation_list_from_folder", "(", "folder_name", ",", "techniques_names", ")", ":", "\n", "\n", "    ", "file_list", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder_name", ",", "\"*.labels\"", ")", ")", "\n", "if", "len", "(", "file_list", ")", "==", "0", ":", "\n", "        ", "logger", ".", "error", "(", "\"Cannot load file list in folder \"", "+", "folder_name", ")", ";", "\n", "sys", ".", "exit", "(", ")", "\n", "", "annotations", "=", "{", "}", "\n", "for", "filename", "in", "file_list", ":", "\n", "        ", "annotations", "[", "extract_article_id_from_file_name", "(", "filename", ")", "]", "=", "[", "]", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "row_number", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "                ", "row", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "check_format_of_annotation_in_file", "(", "row", ",", "row_number", ",", "techniques_names", ",", "filename", ")", "\n", "# annotations[row[TASK_3_ARTICLE_ID_COL]].append([ row[TASK_3_TECHNIQUE_NAME_COL],", "\n", "#                                                  row[TASK_3_FRAGMENT_START_COL],", "\n", "#                                                  row[TASK_3_FRAGMENT_END_COL] ])", "\n", "annotations", "[", "row", "[", "TASK_3_ARTICLE_ID_COL", "]", "]", ".", "append", "(", "[", "\"propaganda\"", ",", "\n", "set", "(", "range", "(", "int", "(", "row", "[", "TASK_3_FRAGMENT_START_COL", "]", ")", ",", "\n", "int", "(", "row", "[", "TASK_3_FRAGMENT_END_COL", "]", ")", ")", ")", "]", ")", "\n", "", "", "", "return", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.load_annotation_list_from_file": [[476, 492], ["open", "enumerate", "f.readlines", "line.rstrip().split", "task-SI_scorer.check_format_of_annotation_in_file", "annotations[].append", "annotations.keys", "line.rstrip", "set", "range", "int", "int"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.check_format_of_annotation_in_file"], ["", "def", "load_annotation_list_from_file", "(", "filename", ",", "techniques_names", ")", ":", "\n", "\n", "    ", "annotations", "=", "{", "}", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "row_number", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ")", ":", "\n", "            ", "row", "=", "line", ".", "rstrip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "check_format_of_annotation_in_file", "(", "row", ",", "row_number", ",", "techniques_names", ",", "filename", ")", "\n", "if", "row", "[", "TASK_3_ARTICLE_ID_COL", "]", "not", "in", "annotations", ".", "keys", "(", ")", ":", "\n", "                ", "annotations", "[", "row", "[", "TASK_3_ARTICLE_ID_COL", "]", "]", "=", "[", "]", "\n", "# annotations[row[TASK_3_ARTICLE_ID_COL]].append([ row[TASK_3_TECHNIQUE_NAME_COL],", "\n", "#                                                  row[TASK_3_FRAGMENT_START_COL],", "\n", "#                                                  row[TASK_3_FRAGMENT_END_COL]])", "\n", "", "annotations", "[", "row", "[", "TASK_3_ARTICLE_ID_COL", "]", "]", ".", "append", "(", "[", "\"propaganda\"", ",", "\n", "set", "(", "range", "(", "int", "(", "row", "[", "TASK_3_FRAGMENT_START_COL", "]", ")", ",", "\n", "int", "(", "row", "[", "TASK_3_FRAGMENT_END_COL", "]", ")", ")", ")", "]", ")", "\n", "", "", "return", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.main": [[494, 531], ["bool", "bool", "task-SI_scorer.load_annotation_list_from_file", "logger.info", "task-SI_scorer.load_annotation_list_from_file", "task-SI_scorer.check_data_file_lists", "task-SI_scorer.check_annotation_spans", "logger.info", "task-SI_scorer.compute_score_pr", "logger.addHandler", "ch.setLevel", "logger.info", "logging.FileHandler", "logging.FileHandler.setLevel", "logging.FileHandler.setFormatter", "logger.addHandler", "task-SI_scorer.check_annotation_spans", "logger.info", "sys.exit"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.load_annotation_list_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.load_annotation_list_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_data_file_lists", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_annotation_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.compute_score_pr", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.tools.task-SI_scorer.check_annotation_spans"], ["", "def", "main", "(", "args", ")", ":", "\n", "\n", "    ", "user_submission_file", "=", "args", ".", "submission", "\n", "gold_folder", "=", "args", ".", "gold", "\n", "output_log_file", "=", "args", ".", "log_file", "\n", "prop_vs_non_propaganda", "=", "True", "\n", "merge_user_annotations", "=", "bool", "(", "args", ".", "merge_user_annotations", ")", "\n", "per_article_evaluation", "=", "False", "\n", "output_for_script", "=", "bool", "(", "args", ".", "output_for_script", ")", "\n", "\n", "if", "not", "output_for_script", ":", "\n", "        ", "logger", ".", "addHandler", "(", "ch", ")", "\n", "\n", "", "if", "args", ".", "debug_on_std", ":", "\n", "        ", "ch", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "\n", "", "if", "output_log_file", "is", "not", "None", ":", "\n", "        ", "logger", ".", "info", "(", "\"Logging execution to file \"", "+", "output_log_file", ")", "\n", "fileLogger", "=", "logging", ".", "FileHandler", "(", "output_log_file", ")", "\n", "fileLogger", ".", "setLevel", "(", "logging", ".", "DEBUG", ")", "\n", "fileLogger", ".", "setFormatter", "(", "formatter", ")", "\n", "logger", ".", "addHandler", "(", "fileLogger", ")", "\n", "\n", "", "techniques_names", "=", "[", "\"propaganda\"", "]", "#load_technique_names_from_file(args.techniques_file)", "\n", "submission_annotations", "=", "load_annotation_list_from_file", "(", "user_submission_file", ",", "techniques_names", ")", "\n", "logger", ".", "info", "(", "'Checking user submitted file'", ")", "\n", "gold_annotations", "=", "load_annotation_list_from_file", "(", "gold_folder", ",", "techniques_names", ")", "\n", "check_data_file_lists", "(", "submission_annotations", ",", "gold_annotations", ")", "\n", "if", "not", "check_annotation_spans", "(", "submission_annotations", ",", "merge_user_annotations", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Error in submission file\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "check_annotation_spans", "(", "gold_annotations", ",", "True", ")", "\n", "\n", "logger", ".", "info", "(", "\"Scoring the submission with precision and recall method\"", ")", "\n", "score_pr", "=", "compute_score_pr", "(", "submission_annotations", ",", "gold_annotations", ",", "techniques_names", ",", "\n", "prop_vs_non_propaganda", ",", "per_article_evaluation", ",", "output_for_script", ")", "\n", "return", "score_pr", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.__init__": [[37, 41], ["src.AnnotationWithOutLabel.__init__"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "label", ":", "str", "=", "None", ",", "start_offset", ":", "str", "=", "None", ",", "end_offset", ":", "str", "=", "None", ")", ":", "\n", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "start_offset", ",", "end_offset", ")", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.__str__": [[43, 46], ["annotation.Annotation.get_label", "src.AnnotationWithOutLabel.__str__"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConfigurationError.__str__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "\n", "        ", "return", "super", "(", ")", ".", "__str__", "(", ")", "+", "\" -> \"", "+", "self", ".", "get_label", "(", ")", "\n", "#return self.get_label() + \"\\t\" + super().__str__()", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.__eq__": [[49, 55], ["src.AnnotationWithOutLabel.__eq__", "annotation.Annotation.get_label", "second_annotation.get_label"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.__eq__", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label"], ["", "def", "__eq__", "(", "self", ",", "second_annotation", ":", "Annotation", ")", ":", "\n", "        ", "\"\"\"\n        Checks whether two annotations are identical, i.e. if their spans are \n        identical and if they labels coincide\n        \"\"\"", "\n", "return", "super", "(", ")", ".", "__eq__", "(", "second_annotation", ")", "and", "self", ".", "get_label", "(", ")", "==", "second_annotation", ".", "get_label", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.get_label": [[57, 60], ["None"], "methods", ["None"], ["", "def", "get_label", "(", "self", ")", "->", "str", ":", "\n", "\n", "        ", "return", "self", ".", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.get_propaganda_techniques": [[62, 68], ["annotation.Annotation.propaganda_techniques.get_propaganda_techniques_list", "logger.error", "sys.exit"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_propaganda_techniques_list"], ["", "def", "get_propaganda_techniques", "(", "self", ")", "->", "list", ":", "\n", "\n", "        ", "if", "self", ".", "propaganda_techniques", "is", "None", ":", "\n", "            ", "logger", ".", "error", "(", "\"trying to access propaganda techniques list before initialising the corresponding object\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "return", "self", ".", "propaganda_techniques", ".", "get_propaganda_techniques_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.set_propaganda_technique_list_obj": [[70, 81], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "set_propaganda_technique_list_obj", "(", "cls", ",", "propaganda_technique_obj", ":", "pt", ".", "Propaganda_Techniques", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        propaganda_technique_obj is an object from the module src.propaganda_techniques.\n        Typical invokation: \n        `\n            propaganda_techniques = pt.Propaganda_Techniques(filename=propaganda_techniques_list_file)\n            an.Annotation.set_propaganda_technique_list_obj(propaganda_techniques)\n        `\n        \"\"\"", "\n", "cls", ".", "propaganda_techniques", "=", "propaganda_technique_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.load_annotation_from_string": [[83, 121], ["annotation_string.rstrip().split", "len", "logger.error", "sys.exit", "int", "int", "annotation.Annotation", "annotation_string.rstrip", "logger.error", "logger.error", "len", "str", "str", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_annotation_from_string", "(", "annotation_string", ":", "str", ",", "row_num", ":", "int", "=", "None", ",", "filename", ":", "str", "=", "None", ")", "->", "(", "Annotation", ",", "str", ")", ":", "\n", "        ", "\"\"\"\n        Read annotations from a csv-like string, with fields separated\n        by the class variable `separator`: \n\n        article id<separator>technique name<separator>starting_position<separator>ending_position\n        Fields order is determined by the class variables ARTICLE_ID_COL,\n        TECHNIQUE_NAME_COL, FRAGMENT_START_COL, FRAGMENT_END_COL\n\n        Besides reading the data, it performs basic checks.\n\n        :return a tuple (Annotation object, id of the article)\n        \"\"\"", "\n", "\n", "row", "=", "annotation_string", ".", "rstrip", "(", ")", ".", "split", "(", "Annotation", ".", "separator", ")", "\n", "if", "len", "(", "row", ")", "!=", "4", ":", "\n", "            ", "logger", ".", "error", "(", "\"Row%s%s is supposed to have 4 columns. Found %d: -%s-.\"", "\n", "%", "(", "\" \"", "+", "str", "(", "row_num", ")", "if", "row_num", "is", "not", "None", "else", "\"\"", ",", "\n", "\" in file \"", "+", "filename", "if", "filename", "is", "not", "None", "else", "\"\"", ",", "len", "(", "row", ")", ",", "annotation_string", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "article_id", "=", "row", "[", "Annotation", ".", "ARTICLE_ID_COL", "]", "\n", "label", "=", "row", "[", "Annotation", ".", "TECHNIQUE_NAME_COL", "]", "\n", "try", ":", "\n", "            ", "start_offset", "=", "int", "(", "row", "[", "Annotation", ".", "FRAGMENT_START_COL", "]", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "error", "(", "\"The column %d in row%s%s is supposed to be an integer: -%s-\"", "\n", "%", "(", "Annotation", ".", "FRAGMENT_START_COL", ",", "\" \"", "+", "str", "(", "row_num", ")", "if", "row_num", "is", "not", "None", "else", "\"\"", ",", "\n", "\" in file \"", "+", "filename", "if", "filename", "is", "not", "None", "else", "\"\"", ",", "annotation_string", ")", ")", "\n", "", "try", ":", "\n", "            ", "end_offset", "=", "int", "(", "row", "[", "Annotation", ".", "FRAGMENT_END_COL", "]", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "error", "(", "\"The column %d in row%s%s is supposed to be an integer: -%s-\"", "\n", "%", "(", "Annotation", ".", "FRAGMENT_END_COL", ",", "\" \"", "+", "str", "(", "row_num", ")", "if", "row_num", "is", "not", "None", "else", "\"\"", ",", "\n", "\" in file \"", "+", "filename", "if", "filename", "is", "not", "None", "else", "\"\"", ",", "annotation_string", ")", ")", "\n", "\n", "", "return", "Annotation", "(", "label", ",", "start_offset", ",", "end_offset", ")", ",", "article_id", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.is_technique_name_valid": [[123, 133], ["sys.exit", "annotation.Annotation.propaganda_techniques.is_valid_technique", "logger.error", "annotation.Annotation.get_label", "annotation.Annotation.get_label"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.is_valid_technique", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label"], ["", "def", "is_technique_name_valid", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Checks whether the technique names are correct\n        \"\"\"", "\n", "if", "self", ".", "propaganda_techniques", "is", "None", ":", "\n", "            ", "sys", ".", "exit", "(", "\"ERROR: propaganda techniques object has not been initialised\"", ")", "\n", "", "if", "not", "self", ".", "propaganda_techniques", ".", "is_valid_technique", "(", "self", ".", "get_label", "(", ")", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"label %s is not valid. Possible values are: %s\"", "%", "(", "self", ".", "get_label", "(", ")", ",", "self", ".", "propaganda_techniques", ")", ")", "\n", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.check_format_of_annotation_in_file": [[135, 143], ["annotation.Annotation.is_technique_name_valid", "sys.exit", "annotation.Annotation.is_span_valid", "sys.exit"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation.Annotation.is_technique_name_valid", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_valid"], ["", "def", "check_format_of_annotation_in_file", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs some checks on the fields of the annotation\n        \"\"\"", "\n", "if", "not", "self", ".", "is_technique_name_valid", "(", ")", ":", "\n", "            ", "sys", ".", "exit", "(", ")", "\n", "", "if", "not", "self", ".", "is_span_valid", "(", ")", ":", "\n", "            ", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.__init__": [[33, 39], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "annotations", ":", "aa", ".", "Articles_annotations", "=", "None", ")", ":", "\n", "\n", "        ", "if", "annotations", "is", "None", ":", "\n", "            ", "self", ".", "annotations", ":", "Dict", "[", "str", ",", "aa", ".", "Articles_annotations", "]", "=", "{", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "annotations", "=", "annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.__len__": [[41, 46], ["len", "__future__.annotations.Annotations.get_article_id_list"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list"], ["", "", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Returns the number of articles in the object\n        \"\"\"", "\n", "return", "len", "(", "self", ".", "get_article_id_list", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.add_annotation": [[48, 56], ["__future__.annotations.Annotations.annotations[].add_annotation", "__future__.annotations.Annotations.has_article", "__future__.annotations.Annotations.create_article_annotations_object"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.has_article", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.create_article_annotations_object"], ["", "def", "add_annotation", "(", "self", ",", "annotation", ":", "an", ".", "Annotation", ",", "article_id", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Add a single annotation to the article with id article_id. \n        If such article does not exists, the annotation is created. \n        \"\"\"", "\n", "if", "not", "self", ".", "has_article", "(", "article_id", ")", ":", "\n", "            ", "self", ".", "create_article_annotations_object", "(", "article_id", ")", "\n", "", "self", ".", "annotations", "[", "article_id", "]", ".", "add_annotation", "(", "annotation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.check_annotation_spans_with_category_matching": [[58, 100], ["__future__.annotations.Annotations.get_article_id_list", "__future__.annotations.Annotations.get_article_annotations_obj().groupby_technique", "__future__.annotations.Annotations.keys", "__future__.annotations.Annotations.get_article_annotations_obj", "__future__.annotations.Annotations.get_article_annotations_obj", "range", "len", "[].merge_spans"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.groupby_technique", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_obj", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_obj", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.merge_spans"], ["", "def", "check_annotation_spans_with_category_matching", "(", "self", ",", "merge_overlapping_spans", ":", "bool", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Check whether there are overlapping spans for the same technique in the same article.\n        Two spans are overlapping if their associated techniques match (according to category_matching_func)\n        If merge_overlapping_spans==True then the overlapping spans are merged, otherwise an error is raised.\n\n        :param merge_overlapping_spans: if True merges the overlapping spans\n        :return:\n        \"\"\"", "\n", "\n", "for", "article_id", "in", "self", ".", "get_article_id_list", "(", ")", ":", "\n", "\n", "            ", "annotation_list", "=", "self", ".", "get_article_annotations_obj", "(", "article_id", ")", ".", "groupby_technique", "(", ")", "\n", "if", "merge_overlapping_spans", ":", "\n", "                ", "for", "technique", "in", "annotation_list", ".", "keys", "(", ")", ":", "\n", "                    ", "for", "i", "in", "range", "(", "1", ",", "len", "(", "annotation_list", "[", "technique", "]", ")", ")", ":", "\n", "                        ", "annotation_list", "[", "technique", "]", "[", "i", "]", ".", "merge_spans", "(", "annotation_list", "[", "technique", "]", ",", "i", "-", "1", ")", "\n", "", "", "", "if", "not", "self", ".", "get_article_annotations_obj", "(", "article_id", ")", ":", "\n", "                ", "return", "False", "\n", "# annotation_list = {}", "\n", "# for annotation in self.annotations.get_article_annotations(article_id):", "\n", "#     technique = annotation.get_label()", "\n", "#     if technique not in annotation_list.keys():", "\n", "#         annotation_list[technique] = [[technique, curr_span]]", "\n", "#     else:", "\n", "#         if merge_overlapping_spans:", "\n", "#             annotation_list[technique].append([technique, curr_span])", "\n", "#             merge_spans(annotation_list[technique], len(annotation_list[technique]) - 1)", "\n", "#         else:", "\n", "#             for matching_technique, span in annotation_list[technique]:", "\n", "#                 if len(curr_span.intersection(span)) > 0:", "\n", "#                     logger.error(\"In article %s, the span of the annotation %s, [%s,%s] overlap with \"", "\n", "#                                  \"the following one from the same article:%s, [%s,%s]\" % (", "\n", "#                                  article_id, matching_technique,", "\n", "#                                  min(span), max(span), technique, min(curr_span), max(curr_span)))", "\n", "#                     return False", "\n", "#             annotation_list[technique].append([technique, curr_span])", "\n", "# if merge_overlapping_spans:", "\n", "#     annotations[article_id] = []", "\n", "#     for technique in annotation_list.keys():", "\n", "#         annotations[article_id] += annotation_list[technique]", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.compare_annotations_identical_article_lists": [[102, 119], ["set().difference", "logger.debug", "len", "len", "logger.error", "set", "len", "logger.error", "__future__.annotations.Annotations.get_article_id_list", "second_annotations.get_article_id_list", "set", "second_annotations.get_article_id_list", "__future__.annotations.Annotations.get_article_id_list", "len", "len", "__future__.annotations.Annotations.get_article_id_list", "second_annotations.get_article_id_list"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list"], ["", "def", "compare_annotations_identical_article_lists", "(", "self", ",", "second_annotations", ":", "Annotations", ")", ":", "\n", "        ", "\"\"\"\n        Compare if self and <second_annotations> have identical article id lists\n        :return: True if the lists are identical and False otherwise. \n        \"\"\"", "\n", "#checking that the number of articles in self and <second_annotations> is the same", "\n", "if", "len", "(", "self", ".", "get_article_id_list", "(", ")", ")", "!=", "len", "(", "second_annotations", ".", "get_article_id_list", "(", ")", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"The number of articles in the annotations is different: %d, %d\"", "\n", "%", "(", "len", "(", "self", ".", "get_article_id_list", "(", ")", ")", ",", "len", "(", "second_annotations", ".", "get_article_id_list", "(", ")", ")", ")", ")", "\n", "return", "False", "\n", "", "diff", "=", "set", "(", "self", ".", "get_article_id_list", "(", ")", ")", ".", "difference", "(", "set", "(", "second_annotations", ".", "get_article_id_list", "(", ")", ")", ")", "\n", "if", "len", "(", "diff", ")", ">", "0", ":", "\n", "            ", "logger", ".", "error", "(", "\"The two lists of article ids differ: %s\"", "%", "(", "diff", ")", ")", "\n", "return", "False", "\n", "\n", "", "logger", ".", "debug", "(", "\"OK: the list of article ids in the two sets of annotations is identical\"", ")", "\n", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.compare_annotations_identical": [[121, 137], ["__future__.annotations.Annotations.get_article_id_list", "__future__.annotations.Annotations.get_article_annotations_list", "second_annotations.get_article_annotations_list", "zip", "len", "len", "logger.error", "an1.is_span_equal_to", "logger.error", "len", "len", "an1.get_start_offset", "an1.get_end_offset", "an2.get_start_offset", "an2.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "compare_annotations_identical", "(", "self", ",", "second_annotations", ":", "Annotations", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Compare if self and <second_annotations> have identical annotations (without considering the technique labels)\n        :return: True if the lists are identical and False otherwise. \n        \"\"\"", "\n", "for", "article_id", "in", "self", ".", "get_article_id_list", "(", ")", ":", "\n", "            ", "an1_article_annotations", "=", "self", ".", "get_article_annotations_list", "(", "article_id", ")", "\n", "an2_article_annotations", "=", "second_annotations", ".", "get_article_annotations_list", "(", "article_id", ")", "\n", "if", "len", "(", "an1_article_annotations", ")", "!=", "len", "(", "an2_article_annotations", ")", ":", "\n", "                ", "logger", ".", "error", "(", "\"The number of annotations for article %s differs: %d vs %d\"", "%", "(", "article_id", ",", "len", "(", "an1_article_annotations", ")", ",", "len", "(", "an2_article_annotations", ")", ")", ")", "\n", "return", "False", "\n", "", "for", "an1", ",", "an2", "in", "zip", "(", "an1_article_annotations", ",", "an2_article_annotations", ")", ":", "\n", "                ", "if", "not", "an1", ".", "is_span_equal_to", "(", "an2", ")", ":", "\n", "                    ", "logger", ".", "error", "(", "\"The spans of the annotations of article %s do not match: [%s, %s] vs [%s, %s]\"", "%", "(", "article_id", ",", "an1", ".", "get_start_offset", "(", ")", ",", "an1", ".", "get_end_offset", "(", ")", ",", "an2", ".", "get_start_offset", "(", ")", ",", "an2", ".", "get_end_offset", "(", ")", ")", ")", "\n", "return", "False", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.align_annotations": [[201, 208], ["second_annotations.get_article_id_list", "__future__.annotations.Annotations.get_article_annotations_obj().align_annotations", "second_annotations.get_article_annotations_obj", "__future__.annotations.Annotations.get_article_annotations_obj"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.align_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_obj", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_obj"], ["", "def", "align_annotations", "(", "self", ",", "second_annotations", ":", "Annotations", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Reorder all annotations such that the matching between annotations' labels\n        and the ones from second_annotations is maximised. \n        \"\"\"", "\n", "for", "article_id", "in", "second_annotations", ".", "get_article_id_list", "(", ")", ":", "\n", "            ", "self", ".", "get_article_annotations_obj", "(", "article_id", ")", ".", "align_annotations", "(", "second_annotations", ".", "get_article_annotations_obj", "(", "article_id", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.compute_TC_score": [[210, 227], ["__future__.annotations.Annotations.align_annotations", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "x.get_label", "x.get_label", "src.Annotation.propaganda_techniques.get_propaganda_techniques_list_sorted", "src.Annotation.propaganda_techniques.get_propaganda_techniques_list_sorted", "sklearn.metrics.f1_score", "second_annotations.get_full_list_of_annotations", "__future__.annotations.Annotations.get_full_list_of_annotations"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.align_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_propaganda_techniques_list_sorted", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_propaganda_techniques_list_sorted", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_full_list_of_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_full_list_of_annotations"], ["", "", "def", "compute_TC_score", "(", "self", ",", "second_annotations", ":", "Annotations", ")", ":", "\n", "        ", "\"\"\"\n        second_annotations: gold labels\n        \"\"\"", "\n", "\n", "self", ".", "align_annotations", "(", "second_annotations", ")", "\n", "gold_labels", "=", "[", "x", ".", "get_label", "(", ")", "for", "x", "in", "second_annotations", ".", "get_full_list_of_annotations", "(", ")", "]", "\n", "submission_labels", "=", "[", "x", ".", "get_label", "(", ")", "for", "x", "in", "self", ".", "get_full_list_of_annotations", "(", ")", "]", "\n", "\n", "precision", "=", "precision_score", "(", "gold_labels", ",", "submission_labels", ",", "pos_label", "=", "None", ",", "average", "=", "'micro'", ")", "\n", "recall", "=", "recall_score", "(", "gold_labels", ",", "submission_labels", ",", "pos_label", "=", "None", ",", "average", "=", "'micro'", ")", "\n", "f1", "=", "f1_score", "(", "gold_labels", ",", "submission_labels", ",", "pos_label", "=", "None", ",", "average", "=", "'micro'", ")", "\n", "if", "an", ".", "Annotation", ".", "propaganda_techniques", "is", "not", "None", ":", "\n", "            ", "propaganda_techniques_list", "=", "an", ".", "Annotation", ".", "propaganda_techniques", ".", "get_propaganda_techniques_list_sorted", "(", ")", "\n", "f1_per_class", "=", "f1_score", "(", "gold_labels", ",", "submission_labels", ",", "average", "=", "None", ",", "labels", "=", "propaganda_techniques_list", ")", "\n", "return", "precision", ",", "recall", ",", "f1", ",", "f1_per_class", "\n", "", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.create_article_annotations_object": [[229, 231], ["src.Articles_annotations", "src.Articles_annotations"], "methods", ["None"], ["", "def", "create_article_annotations_object", "(", "self", ",", "article_id", ":", "str", ")", "->", "None", ":", "\n", "        ", "self", ".", "annotations", "[", "article_id", "]", "=", "aa", ".", "Articles_annotations", "(", "article_id", "=", "article_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.TC_score_to_string": [[233, 247], ["__future__.annotations.Annotations.compute_TC_score", "__future__.annotations.Annotations.compute_TC_score", "str", "str", "zip", "src.Annotation.propaganda_techniques.get_propaganda_techniques_list", "src.Annotation.propaganda_techniques.get_propaganda_techniques_list"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.compute_TC_score", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.compute_TC_score", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_propaganda_techniques_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_propaganda_techniques_list"], ["", "def", "TC_score_to_string", "(", "self", ",", "second_annotation", ":", "Annotations", ",", "output_for_script", "=", "False", ")", ":", "\n", "\n", "            ", "if", "an", ".", "Annotation", ".", "propaganda_techniques", "is", "None", ":", "#raise an error", "\n", "                ", "precision", ",", "recall", ",", "f1", "=", "self", ".", "compute_TC_score", "(", "second_annotation", ")", "\n", "res", "=", "\"\\nPrecision=%f\\nRecall=%f\\nF1=%f\\n\"", "%", "(", "precision", ",", "recall", ",", "f1", ")", "\n", "", "else", ":", "\n", "                ", "precision", ",", "recall", ",", "f1", ",", "f1_per_class", "=", "self", ".", "compute_TC_score", "(", "second_annotation", ")", "\n", "res_for_screen", "=", "\"\\nF1=%f\\nPrecision=%f\\nRecall=%f\\n%s\\n\"", "%", "(", "precision", ",", "recall", ",", "f1", ",", "\"\\n\"", ".", "join", "(", "[", "\"F1_\"", "+", "pr", "+", "\"=\"", "+", "str", "(", "f", ")", "for", "pr", ",", "f", "in", "zip", "(", "an", ".", "Annotation", ".", "propaganda_techniques", ".", "get_propaganda_techniques_list", "(", ")", ",", "f1_per_class", ")", "]", ")", ")", "\n", "if", "output_for_script", ":", "\n", "                    ", "res_for_script", "=", "\"%f\\t%f\\t%f\\t\"", "%", "(", "f1", ",", "precision", ",", "recall", ")", "\n", "res_for_script", "+=", "\"\\t\"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "f1_per_class", "]", ")", "\n", "", "else", ":", "\n", "                    ", "res_for_script", "=", "\"\"", "\n", "", "", "return", "res_for_screen", ",", "res_for_script", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_full_list_of_annotations": [[249, 255], ["__future__.annotations.Annotations.get_article_id_list", "__future__.annotations.Annotations.get_article_annotations_list", "full_list.append"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_list"], ["", "def", "get_full_list_of_annotations", "(", "self", ")", ":", "\n", "        ", "full_list", "=", "[", "]", "\n", "for", "article_id", "in", "self", ".", "get_article_id_list", "(", ")", ":", "\n", "            ", "for", "an", "in", "self", ".", "get_article_annotations_list", "(", "article_id", ")", ":", "\n", "                ", "full_list", ".", "append", "(", "an", ")", "\n", "", "", "return", "full_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.has_article": [[257, 262], ["__future__.annotations.Annotations.get_article_id_list"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list"], ["", "def", "has_article", "(", "self", ",", "article_id", ":", "str", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check whether article_id is in the list of articles whose annotations are in the object. \n        \"\"\"", "\n", "return", "article_id", "in", "self", ".", "get_article_id_list", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_id_list": [[264, 269], ["__future__.annotations.Annotations.annotations.keys"], "methods", ["None"], ["", "def", "get_article_id_list", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        All ids of the article in the object\n        \"\"\"", "\n", "return", "self", ".", "annotations", ".", "keys", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_obj": [[271, 276], ["None"], "methods", ["None"], ["", "def", "get_article_annotations_obj", "(", "self", ",", "article_id", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Returns all annotations of an article as an Article_annotations object.\n        \"\"\"", "\n", "return", "self", ".", "annotations", "[", "article_id", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.get_article_annotations_list": [[278, 283], ["__future__.annotations.Annotations.annotations[].get_article_annotations"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations"], ["", "def", "get_article_annotations_list", "(", "self", ",", "article_id", ":", "str", ")", ":", "\n", "        ", "\"\"\"\n        Returns all annotations of an article as a list of Annotation objects.\n        \"\"\"", "\n", "return", "self", ".", "annotations", "[", "article_id", "]", ".", "get_article_annotations", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations._guess_article_id_from_file_name": [[285, 290], ["re.compile", "re.compile.match().group", "re.compile.match", "os.path.basename"], "methods", ["None"], ["", "def", "_guess_article_id_from_file_name", "(", "self", ",", "filename", ":", "str", ")", "->", "str", ":", "\n", "\n", "        ", "regex", "=", "re", ".", "compile", "(", "\"article([0-9]+).*\"", ")", "\n", "article_id", "=", "regex", ".", "match", "(", "os", ".", "path", ".", "basename", "(", "filename", ")", ")", ".", "group", "(", "1", ")", "\n", "return", "article_id", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.load_annotation_list_from_file": [[292, 302], ["open", "enumerate", "f.readlines", "src.Annotation.load_annotation_from_string", "src.Annotation.load_annotation_from_string", "ann.check_format_of_annotation_in_file", "__future__.annotations.Annotations.add_annotation", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.load_annotation_from_string", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.load_annotation_from_string", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.check_format_of_annotation_in_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_annotation"], ["", "def", "load_annotation_list_from_file", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\"\n        Loads all annotations in file <filename>. The file is supposed to contain annotations for multiple articles. To load annotations for a single article use the function with the same name from module src.article_annotations. \n        Each annotation is checked according to check_format_of_annotation_in_file()\n        \"\"\"", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ",", "1", ")", ":", "\n", "                ", "ann", ",", "article_id", "=", "an", ".", "Annotation", ".", "load_annotation_from_string", "(", "line", ".", "rstrip", "(", ")", ",", "i", ",", "filename", ")", "\n", "ann", ".", "check_format_of_annotation_in_file", "(", ")", "\n", "self", ".", "add_annotation", "(", "ann", ",", "article_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.load_annotation_list_from_folder": [[304, 323], ["glob.glob", "os.path.exists", "logger.error", "os.path.isdir", "logger.error", "os.path.join", "len", "logger.error", "sys.exit", "__future__.annotations.Annotations.create_article_annotations_object", "__future__.annotations.Annotations.load_annotation_list_from_file", "__future__.annotations.Annotations._guess_article_id_from_file_name"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.create_article_annotations_object", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations.load_annotation_list_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotations.Annotations._guess_article_id_from_file_name"], ["", "", "", "def", "load_annotation_list_from_folder", "(", "self", ",", "folder_name", ",", "pattern", "=", "\"*.labels\"", ")", ":", "\n", "        ", "\"\"\"\n        Loads all annotations from all files in folder <folder_name>. \n        Files in the folder are selected according to <pattern>\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "folder_name", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"trying to load annotations from folder %s, which does not exists\"", "%", "(", "folder_name", ")", ")", "\n", "return", "False", "\n", "", "if", "not", "os", ".", "path", ".", "isdir", "(", "folder_name", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"trying to load annotations from folder %s, which does not appear to be a valid folder\"", "%", "(", "folder_name", ")", ")", "\n", "return", "False", "\n", "", "file_list", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder_name", ",", "pattern", ")", ")", "\n", "if", "len", "(", "file_list", ")", "==", "0", ":", "\n", "            ", "logger", ".", "error", "(", "\"Cannot load file list %s/%s\"", "%", "(", "folder_name", ",", "pattern", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "for", "filename", "in", "file_list", ":", "\n", "            ", "self", ".", "create_article_annotations_object", "(", "self", ".", "_guess_article_id_from_file_name", "(", "filename", ")", ")", "\n", "self", ".", "load_annotation_list_from_file", "(", "filename", ")", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.__init__": [[7, 11], ["open", "line.rstrip", "f.readlines"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "filename", "=", "TECHNIQUE_NAMES_FILE", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "             ", "self", ".", "techniques", "=", "[", "line", ".", "rstrip", "(", ")", "for", "line", "in", "f", ".", "readlines", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_propaganda_techniques_list": [[13, 16], ["None"], "methods", ["None"], ["", "", "def", "get_propaganda_techniques_list", "(", "self", ")", "->", "list", ":", "\n", "\n", "        ", "return", "self", ".", "techniques", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_propaganda_techniques_list_sorted": [[18, 21], ["sorted"], "methods", ["None"], ["", "def", "get_propaganda_techniques_list_sorted", "(", "self", ")", "->", "list", ":", "\n", "\n", "        ", "return", "sorted", "(", "self", ".", "techniques", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.is_valid_technique": [[23, 26], ["None"], "methods", ["None"], ["", "def", "is_valid_technique", "(", "self", ",", "technique_name", ")", ":", "\n", "\n", "        ", "return", "technique_name", "in", "self", ".", "techniques", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.__str__": [[28, 31], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "\n", "        ", "return", "\"\\n\"", ".", "join", "(", "self", ".", "techniques", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.__getitem__": [[33, 35], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "techniques", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_technique": [[37, 39], ["None"], "methods", ["None"], ["", "def", "get_technique", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "techniques", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.indexOf": [[41, 43], ["propaganda_techniques.Propaganda_Techniques.techniques.index"], "methods", ["None"], ["", "def", "indexOf", "(", "self", ",", "technique_name", ")", ":", "\n", "        ", "return", "self", ".", "techniques", ".", "index", "(", "technique_name", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.__init__": [[33, 37], ["int", "int"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "start_offset", ":", "str", "=", "None", ",", "end_offset", ":", "str", "=", "None", ")", ":", "\n", "\n", "        ", "self", ".", "start_offset", "=", "int", "(", "start_offset", ")", "\n", "self", ".", "end_offset", "=", "int", "(", "end_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.__str__": [[39, 42], ["None"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "\n", "        ", "return", "\"[%d, %d]\"", "%", "(", "self", ".", "start_offset", ",", "self", ".", "end_offset", ")", "\n", "#return \"%d\\t%d\"%(self.start_offset, self.end_offset)", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to": [[45, 52], ["annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "second_annotation.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "second_annotation.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "is_span_equal_to", "(", "self", ",", "second_annotation", ":", "AnnotationWithOutLabel", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Checks whether two annotations are identical, i.e. whether the two spans are identical. \n        \"\"\"", "\n", "if", "self", ".", "get_start_offset", "(", ")", "!=", "second_annotation", ".", "get_start_offset", "(", ")", "or", "self", ".", "get_end_offset", "(", ")", "!=", "second_annotation", ".", "get_end_offset", "(", ")", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.__eq__": [[54, 57], ["annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to"], ["", "def", "__eq__", "(", "self", ",", "second_annotation", ":", "AnnotationWithOutLabel", ")", ":", "\n", "\n", "        ", "return", "self", ".", "is_span_equal_to", "(", "second_annotation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset": [[59, 62], ["None"], "methods", ["None"], ["", "def", "get_start_offset", "(", "self", ")", "->", "int", ":", "\n", "\n", "        ", "return", "self", ".", "start_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset": [[64, 67], ["None"], "methods", ["None"], ["", "def", "get_end_offset", "(", "self", ")", "->", "int", ":", "\n", "\n", "        ", "return", "self", ".", "end_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_span": [[69, 74], ["set", "range", "annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "get_span", "(", "self", ")", "->", "set", ":", "\n", "        ", "\"\"\"\n        Returns a set of positions of all characters in the span\n        \"\"\"", "\n", "return", "set", "(", "range", "(", "self", ".", "get_start_offset", "(", ")", ",", "self", ".", "get_end_offset", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.load_annotation_from_string": [[76, 112], ["annotation_string.rstrip().split", "len", "logger.error", "sys.exit", "int", "int", "annotation_w_o_label.AnnotationWithOutLabel", "annotation_string.rstrip", "logger.error", "logger.error", "len", "str", "str", "str"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "load_annotation_from_string", "(", "annotation_string", ":", "str", ",", "row_num", ":", "int", "=", "None", ",", "filename", ":", "str", "=", "None", ")", "->", "(", "AnnotationWithOutLabel", ",", "str", ")", ":", "\n", "        ", "\"\"\"\n        Read annotations from a csv-like string, with fields separated\n        by the class variable `separator`: \n\n        article id<separator>starting_position<separator>ending_position\n        Fields order is determined by the class variables ARTICLE_ID_COL,\n        FRAGMENT_START_COL, FRAGMENT_END_COL\n\n        Besides reading the data, it performs basic checks.\n\n        :return a tuple (AnnotationWithOutLabel object, id of the article)\n        \"\"\"", "\n", "\n", "row", "=", "annotation_string", ".", "rstrip", "(", ")", ".", "split", "(", "AnnotationWithOutLabel", ".", "separator", ")", "\n", "if", "len", "(", "row", ")", "!=", "3", ":", "\n", "            ", "logger", ".", "error", "(", "\"Row%s%s is supposed to have 3 columns. Found %d: -%s-.\"", "\n", "%", "(", "\" \"", "+", "str", "(", "row_num", ")", "if", "row_num", "is", "not", "None", "else", "\"\"", ",", "\n", "\" in file \"", "+", "filename", "if", "filename", "is", "not", "None", "else", "\"\"", ",", "len", "(", "row", ")", ",", "annotation_string", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n", "", "article_id", "=", "row", "[", "AnnotationWithOutLabel", ".", "ARTICLE_ID_COL", "]", "\n", "try", ":", "\n", "            ", "start_offset", "=", "int", "(", "row", "[", "AnnotationWithOutLabel", ".", "FRAGMENT_START_COL", "]", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "error", "(", "\"The column %d in row%s%s is supposed to be an integer: -%s-\"", "\n", "%", "(", "AnnotationWithOutLabel", ".", "FRAGMENT_START_COL", ",", "\" \"", "+", "str", "(", "row_num", ")", "if", "row_num", "is", "not", "None", "else", "\"\"", ",", "\" in file \"", "+", "filename", "if", "filename", "is", "not", "None", "else", "\"\"", ",", "annotation_string", ")", ")", "\n", "", "try", ":", "\n", "            ", "end_offset", "=", "int", "(", "row", "[", "AnnotationWithOutLabel", ".", "FRAGMENT_END_COL", "]", ")", "\n", "", "except", ":", "\n", "            ", "logger", ".", "error", "(", "\"The column %d in row%s%s is supposed to be an integer: -%s-\"", "\n", "%", "(", "AnnotationWithOutLabel", ".", "FRAGMENT_END_COL", ",", "\" \"", "+", "str", "(", "row_num", ")", "if", "row_num", "is", "not", "None", "else", "\"\"", ",", "\n", "\" in file \"", "+", "filename", "if", "filename", "is", "not", "None", "else", "\"\"", ",", "annotation_string", ")", ")", "\n", "\n", "", "return", "AnnotationWithOutLabel", "(", "start_offset", ",", "end_offset", ")", ",", "article_id", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.merge_spans": [[114, 123], ["annotation_w_o_label.AnnotationWithOutLabel.set_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.set_end_offset", "min", "max", "annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "second_annotation.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "second_annotation.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "merge_spans", "(", "self", ",", "second_annotation", ":", "AnnotationWithOutLabel", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Merge the spans of two annotations. The function does not check whether the spans overlap. \n\n        :param second_annotation: the AnnotationWithOutLabel object whose span is being merged\n        :return:\n        \"\"\"", "\n", "self", ".", "set_start_offset", "(", "min", "(", "self", ".", "get_start_offset", "(", ")", ",", "second_annotation", ".", "get_start_offset", "(", ")", ")", ")", "\n", "self", ".", "set_end_offset", "(", "max", "(", "self", ".", "get_end_offset", "(", ")", ",", "second_annotation", ".", "get_end_offset", "(", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_start_offset": [[125, 128], ["None"], "methods", ["None"], ["", "def", "set_start_offset", "(", "self", ",", "new_start_offset", ":", "int", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "start_offset", "=", "new_start_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_end_offset": [[130, 133], ["None"], "methods", ["None"], ["", "def", "set_end_offset", "(", "self", ",", "new_end_offset", ":", "int", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "end_offset", "=", "new_end_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.shift_annotation": [[135, 139], ["annotation_w_o_label.AnnotationWithOutLabel.set_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.set_end_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "shift_annotation", "(", "self", ",", "offset", ":", "int", ")", "->", "None", ":", "\n", "\n", "        ", "self", ".", "set_start_offset", "(", "self", ".", "get_start_offset", "(", ")", "+", "offset", ")", "\n", "self", ".", "set_end_offset", "(", "self", ".", "get_end_offset", "(", ")", "+", "offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.span_overlapping": [[141, 143], ["len", "annotation_w_o_label.AnnotationWithOutLabel.get_span().intersection", "second_annotation.get_span", "annotation_w_o_label.AnnotationWithOutLabel.get_span"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_span", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_span"], ["", "def", "span_overlapping", "(", "self", ",", "second_annotation", ":", "AnnotationWithOutLabel", ")", "->", "bool", ":", "\n", "        ", "return", "len", "(", "self", ".", "get_span", "(", ")", ".", "intersection", "(", "second_annotation", ".", "get_span", "(", ")", ")", ")", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_valid": [[145, 159], ["logger.error", "annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "logger.error", "annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "is_span_valid", "(", "self", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Checks whether the span is valid, i.e. if the following conditions are met: \n        1) start and end offsets >= 0 \n        2) start offset < end offset\n        \"\"\"", "\n", "if", "self", ".", "get_start_offset", "(", ")", "<", "0", "or", "self", ".", "get_end_offset", "(", ")", "<", "0", ":", "\n", "            ", "logger", ".", "error", "(", "\"Start and end of position of the fragment must be non-negative: %d, %d\"", "\n", "%", "(", "self", ".", "get_start_offset", "(", ")", ",", "self", ".", "get_end_offset", "(", ")", ")", ")", "\n", "return", "False", "\n", "", "if", "self", ".", "get_start_offset", "(", ")", ">=", "self", ".", "get_end_offset", "(", ")", ":", "\n", "            ", "logger", ".", "error", "(", "\"End position of the fragment must be greater than the starting one: start=%d, end=%d\"", "%", "(", "self", ".", "get_start_offset", "(", ")", ",", "self", ".", "get_end_offset", "(", ")", ")", ")", "\n", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.check_format_of_annotation_in_file": [[161, 167], ["annotation_w_o_label.AnnotationWithOutLabel.is_span_valid", "sys.exit"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_valid"], ["", "def", "check_format_of_annotation_in_file", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Performs some checks on the fields of the annotation\n        \"\"\"", "\n", "if", "not", "self", ".", "is_span_valid", "(", ")", ":", "\n", "            ", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.__init__": [[39, 46], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "spans", ":", "anwol", ".", "AnnotationWithOutLabel", "=", "None", ",", "article_id", ":", "str", "=", "None", ")", ":", "\n", "\n", "        ", "if", "spans", "is", "None", ":", "\n", "            ", "self", ".", "spans", "=", "[", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "spans", "=", "spans", "\n", "", "self", ".", "article_id", "=", "article_id", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.__len__": [[48, 51], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "\n", "        ", "return", "len", "(", "self", ".", "spans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.__str__": [[53, 56], ["str"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "\n", "        ", "return", "\"article id: %s\\n%s\"", "%", "(", "self", ".", "article_id", ",", "\"\\n\"", ".", "join", "(", "[", "\"\\t\"", "+", "str", "(", "annotation", ")", "for", "annotation", "in", "self", ".", "spans", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_annotation": [[58, 68], ["article_annotations.Articles_annotations.add_article_id", "article_annotations.Articles_annotations.spans.append", "article_annotations.Articles_annotations.get_article_id"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_article_id", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_id"], ["", "def", "add_annotation", "(", "self", ",", "annotation", ",", "article_id", ":", "str", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        param annotation: an Annotation object\n        \"\"\"", "\n", "if", "article_id", "is", "None", ":", "\n", "            ", "article_id", "=", "self", ".", "get_article_id", "(", ")", "\n", "", "self", ".", "add_article_id", "(", "article_id", ")", "\n", "#if not isinstance(annotation, Annotation):", "\n", "#    sys.exit()", "\n", "self", ".", "spans", ".", "append", "(", "annotation", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_article_id": [[70, 78], ["logger.error", "sys.exit"], "methods", ["None"], ["", "def", "add_article_id", "(", "self", ",", "article_id", ":", "str", ")", ":", "\n", "\n", "        ", "if", "self", ".", "article_id", "is", "None", ":", "\n", "            ", "self", ".", "article_id", "=", "article_id", "\n", "", "else", ":", "\n", "            ", "if", "article_id", "is", "not", "None", "and", "self", ".", "article_id", "!=", "article_id", ":", "\n", "                ", "logger", ".", "error", "(", "\"Trying to add an annotation with a different article id\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations._matching_annotations": [[80, 91], ["list", "second_annotations[].is_span_equal_to", "len", "article_annotations.Articles_annotations.is_span_equal_to", "len"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to"], ["", "", "", "def", "_matching_annotations", "(", "self", ",", "second_annotations", ":", "Articles_annotations", ",", "i", ":", "int", ")", "->", "list", "(", "int", ",", "int", ")", ":", "\n", "\n", "            ", "j2", "=", "i", "\n", "while", "j2", "<", "len", "(", "second_annotations", ")", "and", "second_annotations", "[", "j2", "]", ".", "is_span_equal_to", "(", "second_annotations", "[", "i", "]", ")", ":", "\n", "                ", "j1", "=", "i", "\n", "while", "j1", "<", "len", "(", "self", ")", "and", "self", "[", "j1", "]", ".", "is_span_equal_to", "(", "self", "[", "i", "]", ")", ":", "\n", "                    ", "if", "self", "[", "j1", "]", "==", "second_annotations", "[", "j2", "]", ":", "\n", "                        ", "return", "j1", ",", "j2", "\n", "", "j1", "+=", "1", "\n", "", "j2", "+=", "1", "\n", "", "return", "-", "1", ",", "-", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.adapt_annotation_to_new_text": [[93, 113], ["len", "len", "article_annotations.Articles_annotations.shift_spans", "print", "sys.exit", "original_text[].encode"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.shift_spans"], ["", "def", "adapt_annotation_to_new_text", "(", "self", ",", "original_text", ":", "str", ",", "new_text", ":", "str", ")", "->", "Articles_annotations", ":", "\n", "        ", "\"\"\"\n        create a copy of the annotations such that they refer to new_text (a slightly modified version of original_text, the text the current annotation refers to). \n        This function currently assumes that original_text has only additional spaces w.r.t new_text. \n        \"\"\"", "\n", "i", ",", "j", "=", "(", "0", ",", "0", ")", "\n", "#a_txt = a_txt.replace('\\'\\'', '\"')", "\n", "\n", "while", "i", "<", "len", "(", "original_text", ")", "and", "j", "<", "len", "(", "new_text", ")", ":", "\n", "            ", "o", ",", "n", "=", "original_text", "[", "i", "]", ",", "new_text", "[", "j", "]", "\n", "if", "n", "==", "o", "or", "(", "o", "in", "[", "'\"'", ",", "'\u201c'", ",", "'\u201d'", "]", "and", "n", "in", "[", "'\"'", ",", "'\u201c'", ",", "'\u201d'", "]", ")", "or", "(", "o", "in", "[", "'\\''", ",", "'\u2019'", ",", "'`'", "]", "and", "n", "in", "[", "'\\''", ",", "'\u2019'", ",", "'`'", "]", ")", ":", "\n", "                ", "i", "+=", "1", "\n", "j", "+=", "1", "\n", "", "else", ":", "\n", "                ", "if", "original_text", "[", "i", "]", "!=", "\" \"", ":", "\n", "                    ", "print", "(", "\"different\"", ",", "original_text", "[", "i", "]", ",", "original_text", "[", "i", "]", ".", "encode", "(", "encoding", "=", "'UTF-8'", ")", ",", "new_text", "[", "j", "]", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "i", "+=", "1", "\n", "self", ".", "shift_spans", "(", "j", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.align_annotations": [[115, 136], ["len", "article_annotations.Articles_annotations._matching_annotations", "article_annotations.Articles_annotations.swap_annotations", "second_annotations.swap_annotations", "article_annotations.Articles_annotations.is_span_equal_to", "len"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations._matching_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.swap_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.swap_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to"], ["", "", "", "def", "align_annotations", "(", "self", ",", "second_annotations", ":", "Articles_annotations", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Reorder all annotations such that the matching between annotations' labels\n        and the ones from second_annotations is maximised. \n        Annotations are modified in place\n        \"\"\"", "\n", "i", ",", "j1", ",", "j2", "=", "0", ",", "0", ",", "0", "\n", "while", "i", "<", "len", "(", "self", ")", ":", "\n", "#if not self[j].is_span_equal_to(second_annotations[i]): ", "\n", "#    logger.error(\"trying to align annotations with different spans: %s, %s\"%(self[j], second_annotations[i]))", "\n", "#    sys.exit()", "\n", "            ", "j1", ",", "j2", "=", "self", ".", "_matching_annotations", "(", "second_annotations", ",", "i", ")", "\n", "if", "j1", ">", "i", ":", "\n", "                ", "self", ".", "swap_annotations", "(", "j1", ",", "i", ")", "\n", "", "if", "j2", ">", "i", ":", "\n", "                ", "second_annotations", ".", "swap_annotations", "(", "j2", ",", "i", ")", "\n", "#i+=1", "\n", "", "if", "j1", "==", "-", "1", ":", "# no match, can forward i skipping all annotations with same span", "\n", "                ", "while", "i", "+", "1", "<", "len", "(", "self", ")", "and", "self", "[", "i", "]", ".", "is_span_equal_to", "(", "self", "[", "i", "+", "1", "]", ")", ":", "\n", "                    ", "i", "+=", "1", "\n", "", "", "i", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations._get_annotation_offset_excluding_chars": [[138, 151], ["print", "sys.exit", "len"], "methods", ["None"], ["", "", "def", "_get_annotation_offset_excluding_chars", "(", "self", ",", "article_content", ":", "str", ",", "fragment_index", ":", "int", ",", "is_starting_fragment", ":", "bool", ")", ":", "\n", "\n", "        ", "new_offset", "=", "0", "\n", "try", ":", "\n", "            ", "while", "article_content", "[", "fragment_index", "+", "new_offset", "+", "(", "0", "if", "is_starting_fragment", "else", "-", "1", ")", "]", "in", "self", ".", "inadmissible_annotation_boundary_chars", ":", "\n", "                ", "if", "is_starting_fragment", ":", "\n", "                    ", "new_offset", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "new_offset", "-=", "1", "\n", "", "", "", "except", ":", "\n", "            ", "print", "(", "\"accessing char %d+%d+%d=%d of string of len %d\"", "%", "(", "fragment_index", ",", "new_offset", ",", "(", "0", "if", "is_starting_fragment", "else", "-", "1", ")", ",", "fragment_index", "+", "new_offset", "+", "(", "0", "if", "is_starting_fragment", "else", "-", "1", ")", ",", "len", "(", "article_content", ")", ")", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "return", "new_offset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.check_article_annotations_out_of_boundaries": [[153, 177], ["list", "article_annotations.Articles_annotations.get_article_annotations", "article_annotations.Articles_annotations.remove_annotation", "len", "ann.get_end_offset", "logger.error", "ann.get_start_offset", "annotations_to_be_removed.append", "ann.set_end_offset", "article_annotations.Articles_annotations.get_article_id", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.remove_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_id"], ["", "def", "check_article_annotations_out_of_boundaries", "(", "self", ",", "article_content", ":", "str", ",", "fix_errors", ":", "bool", "=", "False", ")", "->", "list", "(", "bool", ",", "bool", ")", ":", "\n", "        ", "\"\"\"\n        Check that all annotations for the article do not reference fragments beyond article length\n        \"\"\"", "\n", "annotations_correct", "=", "True", "\n", "need_saving", "=", "False", "\n", "annotations_to_be_removed", "=", "[", "]", "\n", "for", "ann", "in", "self", ".", "get_article_annotations", "(", ")", ":", "\n", "            ", "if", "len", "(", "article_content", ")", "<", "ann", ".", "get_end_offset", "(", ")", ":", "# making sure the offsets of the annotation are within the length of the article content", "\n", "                ", "logger", ".", "error", "(", "\"trying to access fragment beyond article length: %s, article %s length: %d\"", "%", "(", "ann", ",", "self", ".", "get_article_id", "(", ")", ",", "len", "(", "article_content", ")", ")", ")", "\n", "if", "fix_errors", ":", "\n", "                    ", "if", "ann", ".", "get_start_offset", "(", ")", ">", "len", "(", "article_content", ")", "-", "1", ":", "# the annotation is completely beyond the length of the article", "\n", "                        ", "annotations_to_be_removed", ".", "append", "(", "ann", ")", "\n", "#self.remove_annotation(ann)", "\n", "", "else", ":", "\n", "                        ", "ann", ".", "set_end_offset", "(", "len", "(", "article_content", ")", ")", "\n", "", "need_saving", "=", "True", "\n", "", "else", ":", "\n", "                    ", "annotations_correct", "=", "False", "\n", "\n", "", "", "", "for", "ann", "in", "annotations_to_be_removed", ":", "\n", "            ", "self", ".", "remove_annotation", "(", "ann", ")", "\n", "\n", "", "return", "annotations_correct", ",", "need_saving", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.check_article_annotations_start_end_chars": [[179, 206], ["list", "article_annotations.Articles_annotations.get_article_annotations", "article_annotations.Articles_annotations._get_annotation_offset_excluding_chars", "article_annotations.Articles_annotations._get_annotation_offset_excluding_chars", "ann.get_start_offset", "ann.get_end_offset", "logger.error", "ann.set_start_offset", "ann.set_end_offset", "ann.is_span_valid", "logger.error", "sys.exit", "article_annotations.Articles_annotations.get_article_id", "ann.get_start_offset", "ann.get_end_offset", "ann.get_start_offset", "ann.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations._get_annotation_offset_excluding_chars", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations._get_annotation_offset_excluding_chars", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.set_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_valid", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_id", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "check_article_annotations_start_end_chars", "(", "self", ",", "article_content", ":", "str", ",", "fix_errors", ":", "bool", "=", "False", ")", "->", "list", "(", "bool", ",", "bool", ")", ":", "\n", "        ", "\"\"\"\n        Check that all annotations for the article do not start or end with any of the characters\n        specified in the class variable `inadmissible_annotation_boundary_chars`. \n        If fix_errors==True, tries to correct the spans of the wrong annotations.\n        return: annotations_correct (True if the annotations did not have any issue or the issues have been fixed), annotations_need_saving (True if the annotation has been modified and need to be saved)\n        \"\"\"", "\n", "annotations_need_saving", "=", "False", "\n", "annotations_correct", "=", "True", "\n", "for", "ann", "in", "self", ".", "get_article_annotations", "(", ")", ":", "\n", "# check that the annotation does not start or end with an inadmissible char", "\n", "            ", "new_start_offset", "=", "self", ".", "_get_annotation_offset_excluding_chars", "(", "article_content", ",", "ann", ".", "get_start_offset", "(", ")", ",", "True", ")", "\n", "new_end_offset", "=", "self", ".", "_get_annotation_offset_excluding_chars", "(", "article_content", ",", "ann", ".", "get_end_offset", "(", ")", ",", "False", ")", "\n", "if", "new_start_offset", "!=", "0", "or", "new_end_offset", "!=", "0", ":", "\n", "                ", "logger", ".", "error", "(", "'annotation %s in article %s starts or ends with inadmissible characters: -%s-'", "%", "(", "ann", ",", "self", ".", "get_article_id", "(", ")", ",", "article_content", "[", "ann", ".", "get_start_offset", "(", ")", ":", "ann", ".", "get_end_offset", "(", ")", "]", ")", ")", "\n", "annotations_correct", "=", "False", "\n", "if", "fix_errors", ":", "\n", "                    ", "ann", ".", "set_start_offset", "(", "ann", ".", "get_start_offset", "(", ")", "+", "new_start_offset", ")", "\n", "ann", ".", "set_end_offset", "(", "ann", ".", "get_end_offset", "(", ")", "+", "new_end_offset", ")", "\n", "if", "not", "ann", ".", "is_span_valid", "(", ")", ":", "\n", "                        ", "logger", ".", "error", "(", "\"impossible to fix annotation\"", ")", "\n", "sys", ".", "exit", "(", ")", "\n", "", "else", ":", "\n", "                        ", "annotations_correct", "=", "True", "\n", "annotations_need_saving", "=", "True", "\n", "\n", "", "", "", "", "return", "annotations_correct", ",", "annotations_need_saving", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.check_article_annotations_no_duplicated_annotations": [[208, 226], ["enumerate", "article_annotations.Articles_annotations.get_article_annotations", "len", "ann.is_span_equal_to", "article_annotations.Articles_annotations.get_article_annotations", "logger.error", "article_annotations.Articles_annotations.remove_annotation", "logger.debug", "ann.get_label", "article_annotations.Articles_annotations.get_label", "article_annotations.Articles_annotations.get_article_id"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.is_span_equal_to", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.remove_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_id"], ["", "def", "check_article_annotations_no_duplicated_annotations", "(", "self", ",", "article_content", ":", "str", ",", "fix_errors", ":", "bool", "=", "False", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Check that there are no two duplicated annotations. If there are such annotations and if they have identical labels, one is removed and the annotation is considered correct\n        \"\"\"", "\n", "annotations_correct", "=", "True", "\n", "annotations_need_saving", "=", "False", "\n", "for", "i", ",", "ann", "in", "enumerate", "(", "self", ".", "get_article_annotations", "(", ")", ")", ":", "\n", "# check that the annotation is not identical to any other annotation of the same article", "\n", "            ", "j", "=", "i", "+", "1", "\n", "while", "j", "<", "len", "(", "self", ".", "get_article_annotations", "(", ")", ")", ":", "\n", "                ", "if", "ann", ".", "is_span_equal_to", "(", "self", "[", "j", "]", ")", ":", "\n", "                    ", "logger", ".", "error", "(", "\"article %s found two identical annotations: %s and %s\"", "%", "(", "self", ".", "get_article_id", "(", ")", ",", "ann", ",", "self", "[", "j", "]", ")", ")", "\n", "if", "ann", ".", "get_label", "(", ")", "==", "self", "[", "j", "]", ".", "get_label", "(", ")", "and", "fix_errors", ":", "\n", "                        ", "self", ".", "remove_annotation", "(", "self", "[", "j", "]", ")", "\n", "logger", ".", "debug", "(", "\"The two annotations have identical labels (%s, %s), deleted one.\"", "%", "(", "ann", ",", "self", "[", "j", "]", ")", ")", "\n", "annotations_need_saving", "=", "True", "\n", "", "", "j", "+=", "1", "\n", "", "", "return", "annotations_correct", ",", "annotations_need_saving", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.check_article_annotations": [[228, 256], ["article_annotations.Articles_annotations.check_article_annotations_out_of_boundaries", "article_annotations.Articles_annotations.check_article_annotations_start_end_chars", "article_annotations.Articles_annotations.check_article_annotations_no_duplicated_annotations"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.check_article_annotations_out_of_boundaries", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.check_article_annotations_start_end_chars", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.check_article_annotations_no_duplicated_annotations"], ["", "def", "check_article_annotations", "(", "self", ",", "article_content", ":", "str", ",", "fix_errors", ":", "bool", "=", "False", ",", "\n", "check_out_of_boundaries", "=", "False", ",", "check_start_end_chars", "=", "False", ",", "check_duplicated_annotations", "=", "False", ")", "->", "bool", ":", "\n", "        ", "\"\"\"\n        Performs the following checks on the annotations of the article:\n        1) check that an annotation does not reference a location in article_content beyond its length\n        2) check that an annotation does not start or end with a space, a full stop or a newline character. \n        3) there are no two annotations with identical spans \n\n        return value: annotations_correct (True if the annotations did not have any issue or the issues have been fixed), \n                      annotations_need_saving (True if the annotation has been modified and need to be saved)\n        \"\"\"", "\n", "\n", "annotations_correct", ",", "annotations_need_saving", "=", "True", ",", "False", "\n", "\n", "if", "check_out_of_boundaries", ":", "\n", "            ", "annotations_correct", ",", "annotations_need_saving", "=", "self", ".", "check_article_annotations_out_of_boundaries", "(", "article_content", ",", "fix_errors", ")", "\n", "\n", "", "if", "check_start_end_chars", ":", "\n", "            ", "start_end_chars_correct", ",", "need_saving", "=", "self", ".", "check_article_annotations_start_end_chars", "(", "article_content", ",", "fix_errors", ")", "\n", "annotations_correct", "=", "annotations_correct", "and", "start_end_chars_correct", "\n", "annotations_need_saving", "=", "annotations_need_saving", "or", "need_saving", "\n", "\n", "", "if", "check_duplicated_annotations", ":", "\n", "            ", "no_dup_annotations", ",", "dup_annotations_need_saving", "=", "self", ".", "check_article_annotations_no_duplicated_annotations", "(", "article_content", ",", "fix_errors", ")", "\n", "annotations_need_saving", "=", "annotations_need_saving", "or", "dup_annotations_need_saving", "\n", "annotations_correct", "=", "annotations_correct", "and", "no_dup_annotations", "\n", "\n", "", "return", "annotations_correct", ",", "annotations_need_saving", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_id": [[258, 261], ["None"], "methods", ["None"], ["", "def", "get_article_id", "(", "self", ")", "->", "str", ":", "\n", "\n", "        ", "return", "self", ".", "article_id", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations": [[263, 268], ["list"], "methods", ["None"], ["", "def", "get_article_annotations", "(", "self", ")", "->", "list", "(", "anwol", ".", "AnnotationWithOutLabel", ")", ":", "\n", "        ", "\"\"\"\n        returns a list of AnnotationWithoutLabel objects\n        \"\"\"", "\n", "return", "self", ".", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.__getitem__": [[270, 272], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "return", "self", ".", "spans", "[", "index", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_markers_from_spans": [[274, 282], ["article_annotations.Articles_annotations.sort_spans", "enumerate", "sorted", "article_annotations.Articles_annotations.markers.append", "article_annotations.Articles_annotations.markers.append", "annotation.get_start_offset", "annotation.get_label", "annotation.get_end_offset", "annotation.get_label"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.sort_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label"], ["", "def", "get_markers_from_spans", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "sort_spans", "(", ")", "\n", "self", ".", "markers", "=", "[", "]", "\n", "for", "i", ",", "annotation", "in", "enumerate", "(", "self", ".", "spans", ",", "1", ")", ":", "\n", "            ", "self", ".", "markers", ".", "append", "(", "(", "annotation", ".", "get_start_offset", "(", ")", ",", "annotation", ".", "get_label", "(", ")", ",", "i", ",", "\"start\"", ")", ")", "\n", "self", ".", "markers", ".", "append", "(", "(", "annotation", ".", "get_end_offset", "(", ")", ",", "annotation", ".", "get_label", "(", ")", ",", "i", ",", "\"end\"", ")", ")", "\n", "", "self", ".", "markers", "=", "sorted", "(", "self", ".", "markers", ",", "key", "=", "lambda", "ann", ":", "ann", "[", "0", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.groupby_technique": [[284, 293], ["enumerate", "article_annotations.Articles_annotations.get_article_annotations", "annotation.get_label", "annotation_list[].insert", "annotation_list.keys"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label"], ["", "def", "groupby_technique", "(", "self", ")", ":", "\n", "\n", "        ", "annotation_list", "=", "{", "}", "\n", "for", "i", ",", "annotation", "in", "enumerate", "(", "self", ".", "get_article_annotations", "(", ")", ")", ":", "\n", "            ", "technique", "=", "annotation", ".", "get_label", "(", ")", "\n", "if", "technique", "not", "in", "annotation_list", ".", "keys", "(", ")", ":", "\n", "                ", "annotation_list", "[", "technique", "]", "=", "[", "]", "\n", "", "annotation_list", "[", "technique", "]", ".", "insert", "(", "0", ",", "i", ")", "\n", "", "return", "annotation_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.has_overlapping_spans": [[296, 333], ["article_annotations.Articles_annotations.get_article_annotations", "article_annotations.Articles_annotations.reset_annotations", "annotation_list.values", "annotation.get_label", "annotation_list.keys", "annotation_list[].append", "article_annotations.Articles_annotations.merge_article_annotations", "annotation_list[].append", "article_annotations.Articles_annotations.add_annotation", "annotation.span_overlapping", "len", "logger.error", "article_annotations.Articles_annotations.get_article_id", "annotation.get_label", "annotation.get_start_offset", "annotation.get_end_offset", "matching_annotation.get_label", "matching_annotation.get_start_offset", "matching_annotation.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.reset_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.merge_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.span_overlapping", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_id", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "has_overlapping_spans", "(", "self", ",", "prop_vs_non_propaganda", ",", "merge_overlapping_spans", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Check whether there are ovelapping spans for the same technique in the same article.\n        Two spans are overlapping if their associated techniques match (according to category_matching_func)\n        If merge_overlapping_spans==True then the overlapping spans are merged, otherwise an error is raised.\n\n        :param merge_overlapping_spans: if True merges the overlapping spans\n        :return:\n        \"\"\"", "\n", "\n", "annotation_list", "=", "{", "}", "\n", "for", "annotation", "in", "self", ".", "get_article_annotations", "(", ")", ":", "\n", "            ", "if", "prop_vs_non_propaganda", ":", "\n", "                ", "technique", "=", "\"propaganda\"", "\n", "", "else", ":", "\n", "                ", "technique", "=", "annotation", ".", "get_label", "(", ")", "\n", "", "if", "technique", "not", "in", "annotation_list", ".", "keys", "(", ")", ":", "\n", "                ", "annotation_list", "[", "technique", "]", "=", "[", "annotation", "]", "#[[technique, curr_span]]", "\n", "", "else", ":", "\n", "                ", "if", "merge_overlapping_spans", ":", "\n", "                    ", "annotation_list", "[", "technique", "]", ".", "append", "(", "annotation", ")", "\n", "self", ".", "merge_article_annotations", "(", "annotation_list", "[", "technique", "]", ",", "len", "(", "annotation_list", "[", "technique", "]", ")", "-", "1", ")", "\n", "", "else", ":", "\n", "                    ", "for", "matching_annotation", "in", "annotation_list", "[", "technique", "]", ":", "\n", "                        ", "if", "annotation", ".", "span_overlapping", "(", "matching_annotation", ")", ":", "\n", "                            ", "logger", ".", "error", "(", "\"In article %s, the span of the annotation %s, [%s,%s] overlap with \"", "\n", "\"the following one from the same article:%s, [%s,%s]\"", "%", "(", "\n", "self", ".", "get_article_id", "(", ")", ",", "annotation", ".", "get_label", "(", ")", ",", "\n", "annotation", ".", "get_start_offset", "(", ")", ",", "annotation", ".", "get_end_offset", "(", ")", ",", "matching_annotation", ".", "get_label", "(", ")", ",", "matching_annotation", ".", "get_start_offset", "(", ")", ",", "matching_annotation", ".", "get_end_offset", "(", ")", ")", ")", "\n", "return", "False", "\n", "", "", "annotation_list", "[", "technique", "]", ".", "append", "(", "[", "annotation", "]", ")", "\n", "", "", "", "if", "merge_overlapping_spans", ":", "# recreate the list of annotations", "\n", "            ", "self", ".", "reset_annotations", "(", ")", "\n", "for", "anlist", "in", "annotation_list", ".", "values", "(", ")", ":", "\n", "                ", "for", "a", "in", "anlist", ":", "\n", "                    ", "self", ".", "add_annotation", "(", "a", ")", "\n", "", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.is_starting_marker": [[335, 341], ["len"], "methods", ["None"], ["", "def", "is_starting_marker", "(", "self", ",", "marker_index", "=", "None", ")", ":", "\n", "\n", "        ", "if", "marker_index", "is", "None", ":", "\n", "            ", "marker_index", "=", "self", ".", "curr_marker", "\n", "", "if", "marker_index", "<", "len", "(", "self", ".", "markers", ")", ":", "\n", "            ", "return", "self", ".", "markers", "[", "marker_index", "]", "[", "3", "]", "==", "\"start\"", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.is_ending_marker": [[343, 349], ["len"], "methods", ["None"], ["", "", "def", "is_ending_marker", "(", "self", ",", "marker_index", "=", "None", ")", ":", "\n", "\n", "        ", "if", "marker_index", "is", "None", ":", "\n", "            ", "marker_index", "=", "self", ".", "curr_marker", "\n", "", "if", "marker_index", "<", "len", "(", "self", ".", "markers", ")", ":", "\n", "            ", "return", "self", ".", "markers", "[", "marker_index", "]", "[", "3", "]", "==", "\"end\"", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.load_article_annotations_from_csv_file": [[351, 362], ["open", "enumerate", "f.readlines", "annotation_class.load_annotation_from_string", "article_annotations.Articles_annotations.add_annotation", "line.rstrip"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.load_annotation_from_string", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_annotation"], ["", "", "def", "load_article_annotations_from_csv_file", "(", "self", ",", "filename", ":", "str", ",", "annotation_class", "=", "ans", ".", "Annotation", ")", ":", "\n", "        ", "\"\"\"\n        Read annotations from a csv file and add the annotations \n        found in the file as a list of Annotation objects. \n        Check class Annotation for details on the format of the file.\n        \"\"\"", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "i", ",", "line", "in", "enumerate", "(", "f", ".", "readlines", "(", ")", ",", "1", ")", ":", "\n", "#an, article_id = ans.Annotation.load_annotation_from_string(line.rstrip(), i, filename)", "\n", "                ", "an", ",", "article_id", "=", "annotation_class", ".", "load_annotation_from_string", "(", "line", ".", "rstrip", "(", ")", ",", "i", ",", "filename", ")", "\n", "self", ".", "add_annotation", "(", "an", ",", "article_id", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_label": [[364, 370], ["len"], "methods", ["None"], ["", "", "", "def", "marker_label", "(", "self", ",", "marker_index", "=", "None", ")", ":", "\n", "\n", "        ", "if", "marker_index", "is", "None", ":", "\n", "            ", "marker_index", "=", "self", ".", "curr_marker", "\n", "", "if", "marker_index", "<", "len", "(", "self", ".", "markers", ")", ":", "\n", "            ", "return", "self", ".", "markers", "[", "marker_index", "]", "[", "1", "]", "\n", "# else:", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_position": [[374, 380], ["len"], "methods", ["None"], ["", "", "def", "marker_position", "(", "self", ",", "marker_index", "=", "None", ")", ":", "\n", "\n", "        ", "if", "marker_index", "is", "None", ":", "\n", "            ", "marker_index", "=", "self", ".", "curr_marker", "\n", "", "if", "marker_index", "<", "len", "(", "self", ".", "markers", ")", ":", "\n", "            ", "return", "self", ".", "markers", "[", "marker_index", "]", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation": [[382, 388], ["len"], "methods", ["None"], ["", "", "def", "marker_annotation", "(", "self", ",", "marker_index", "=", "None", ")", ":", "\n", "\n", "        ", "if", "marker_index", "is", "None", ":", "\n", "            ", "marker_index", "=", "self", ".", "curr_marker", "\n", "", "if", "marker_index", "<", "len", "(", "self", ".", "markers", ")", ":", "\n", "            ", "return", "self", ".", "markers", "[", "marker_index", "]", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.mark_text": [[390, 460], ["article_annotations.Articles_annotations.get_markers_from_spans", "set", "sorted", "len", "original_text.split", "src.propaganda_techniques.Propaganda_Techniques", "src.propaganda_techniques.Propaganda_Techniques", "len", "len", "indices.append", "article_annotations.Articles_annotations.marker_position", "article_annotations.Articles_annotations.is_starting_marker", "Articles_annotations.techniques.indexOf", "str", "set.add", "article_annotations.Articles_annotations.is_ending_marker", "article_annotations.Articles_annotations.marker_position", "len", "Articles_annotations.techniques.get_technique", "annotations_stack.append", "article_annotations.Articles_annotations.marker_label", "annotations_stack.remove", "enumerate", "article_annotations.Articles_annotations.marker_annotation", "article_annotations.Articles_annotations.marker_annotation", "len", "article_annotations.Articles_annotations.marker_position", "zip", "output_text.split", "len"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_markers_from_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_position", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.is_starting_marker", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.indexOf", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.is_ending_marker", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_position", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_technique", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_position"], ["", "", "def", "mark_text", "(", "self", ",", "original_text", ",", "print_line_numbers", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        mark the string original_text with object's annotations\n\n        original_text: string with the text to be marked\n        print_line_numbers: add line numbers to the text\n\n        :return output_text the text in string original_text with added marks\n                footnotes the list of techniques in the text\n                legend description of the marks added\n        \"\"\"", "\n", "\n", "self", ".", "get_markers_from_spans", "(", ")", "\n", "if", "Articles_annotations", ".", "techniques", "is", "None", ":", "\n", "            ", "if", "ans", ".", "Annotation", ".", "propaganda_techniques", "is", "None", ":", "\n", "                ", "Articles_annotations", ".", "techniques", "=", "Propaganda_Techniques", "(", ")", "\n", "", "else", ":", "\n", "                ", "Articles_annotations", ".", "techniques", "=", "ans", ".", "Annotation", ".", "propaganda_techniques", "\n", "\n", "", "", "output_text", ",", "curr_output_text_index", ",", "self", ".", "curr_marker", "=", "(", "\"\"", ",", "0", ",", "0", ")", "\n", "footnotes", "=", "\"List of techniques found in the article\\n\\n\"", "\n", "techniques_found", "=", "set", "(", ")", "\n", "annotations_stack", "=", "[", "]", "# to handle overlapping annotations when assigning color background", "\n", "while", "curr_output_text_index", "<", "len", "(", "original_text", ")", ":", "\n", "            ", "if", "self", ".", "curr_marker", ">=", "len", "(", "self", ".", "markers", ")", ":", "\n", "                ", "output_text", "+=", "original_text", "[", "curr_output_text_index", ":", "]", "\n", "curr_output_text_index", "=", "len", "(", "original_text", ")", "\n", "", "else", ":", "\n", "                ", "if", "self", ".", "marker_position", "(", ")", "<=", "curr_output_text_index", ":", "\n", "                    ", "if", "self", ".", "is_starting_marker", "(", ")", ":", "\n", "                        ", "output_text", "+=", "self", ".", "start_annotation_effect", "+", "self", ".", "start_annotation_str", "\n", "annotations_stack", ".", "append", "(", "self", ".", "marker_annotation", "(", ")", ")", "\n", "", "else", ":", "\n", "                        ", "output_text", "+=", "\"%s%s%s\"", "%", "(", "\n", "self", ".", "end_annotation_effect", ",", "\"\"", "if", "len", "(", "annotations_stack", ")", ">", "1", "else", "\" \"", ",", "\n", "self", ".", "start_annotation_effect", ")", "\n", "", "techniques_index", "=", "Articles_annotations", ".", "techniques", ".", "indexOf", "(", "self", ".", "marker_label", "(", ")", ")", "\n", "output_text", "+=", "str", "(", "techniques_index", ")", "\n", "techniques_found", ".", "add", "(", "techniques_index", ")", "\n", "if", "self", ".", "is_ending_marker", "(", ")", ":", "\n", "                        ", "output_text", "+=", "self", ".", "end_annotation_str", "+", "self", ".", "end_annotation_effect", "\n", "annotations_stack", ".", "remove", "(", "self", ".", "marker_annotation", "(", ")", ")", "\n", "if", "len", "(", "annotations_stack", ")", ">", "0", ":", "\n", "                            ", "output_text", "+=", "self", ".", "annotation_background_color", "\n", "", "", "else", ":", "\n", "                        ", "output_text", "+=", "self", ".", "end_annotation_effect", "+", "\" \"", "+", "self", ".", "annotation_background_color", "\n", "", "self", ".", "curr_marker", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "output_text", "+=", "original_text", "[", "curr_output_text_index", ":", "self", ".", "marker_position", "(", ")", "]", "\n", "curr_output_text_index", "=", "self", ".", "marker_position", "(", ")", "\n", "\n", "", "", "", "if", "print_line_numbers", ":", "\n", "            ", "indices", ",", "char_index", "=", "(", "[", "]", ",", "0", ")", "\n", "for", "line", "in", "original_text", ".", "split", "(", "\"\\n\"", ")", ":", "\n", "                ", "indices", ".", "append", "(", "char_index", ")", "\n", "char_index", "+=", "len", "(", "line", ")", "+", "1", "\n", "#output_text = \"\\n\".join([\"%d (%d) %s\"%(i, x[0], x[1])", "\n", "", "output_text", "=", "\"\\n\"", ".", "join", "(", "[", "\"%d %s\"", "%", "(", "i", ",", "x", "[", "1", "]", ")", "\n", "for", "i", ",", "x", "in", "enumerate", "(", "zip", "(", "indices", ",", "output_text", ".", "split", "(", "\"\\n\"", ")", ")", ",", "1", ")", "]", ")", "\n", "\n", "", "legend", "=", "\"---\\n%sHighlighted text%s: any propagandistic fragment\\n%s%si%s: start of the i-th technique\"", "\"\\n%si%s%s: end of the i-th technque\\n---\"", "%", "(", "self", ".", "annotation_background_color", ",", "self", ".", "end_annotation_effect", ",", "self", ".", "start_annotation_effect", ",", "\n", "self", ".", "start_annotation_str", ",", "self", ".", "end_annotation_effect", ",", "self", ".", "start_annotation_effect", ",", "\n", "self", ".", "end_annotation_str", ",", "self", ".", "end_annotation_effect", ")", "\n", "\n", "for", "technique_index", "in", "sorted", "(", "techniques_found", ")", ":", "\n", "            ", "footnotes", "+=", "\"%d: %s\\n\"", "%", "(", "technique_index", ",", "Articles_annotations", ".", "techniques", ".", "get_technique", "(", "technique_index", ")", ")", "\n", "\n", "", "return", "output_text", ",", "footnotes", ",", "legend", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_sentence_marker": [[462, 471], ["max", "line.find", "line.find", "len"], "methods", ["None"], ["", "def", "add_sentence_marker", "(", "self", ",", "line", ":", "str", ",", "row_counter", ":", "int", ")", "->", "str", ":", "\n", "\n", "        ", "if", "max", "(", "line", ".", "find", "(", "\"<span\"", ")", ",", "line", ".", "find", "(", "\"</span\"", ")", ")", ">", "-", "1", ":", "# there is an annotation in this row", "\n", "            ", "return", "'<div class=\"technique\" id=\"row%d\">%s</div>\\n'", "%", "(", "row_counter", ",", "line", ")", "\n", "", "else", ":", "\n", "            ", "if", "len", "(", "line", ")", "<=", "1", ":", "#empty line", "\n", "                ", "return", "'<br/>'", "\n", "", "else", ":", "\n", "                ", "return", "'<div>%s</div>\\n'", "%", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.annotation_stack_index_to_markers_index": [[473, 479], ["range", "sys.exit", "len", "article_annotations.Articles_annotations.marker_annotation"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation"], ["", "", "", "def", "annotation_stack_index_to_markers_index", "(", "self", ",", "ind", ":", "int", ")", "->", "int", ":", "\n", "\n", "        ", "for", "x", "in", "range", "(", "len", "(", "self", ".", "markers", ")", ")", ":", "\n", "            ", "if", "self", ".", "marker_annotation", "(", "x", ")", "==", "ind", ":", "\n", "                ", "return", "x", "\n", "", "", "sys", ".", "exit", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.technique_index_from_annotation_index": [[481, 484], ["article_annotations.Articles_annotations.techniques.indexOf", "article_annotations.Articles_annotations.marker_label", "article_annotations.Articles_annotations.annotation_stack_index_to_markers_index"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.indexOf", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.annotation_stack_index_to_markers_index"], ["", "def", "technique_index_from_annotation_index", "(", "self", ",", "x", ":", "int", ")", "->", "int", ":", "\n", "\n", "        ", "return", "self", ".", "techniques", ".", "indexOf", "(", "self", ".", "marker_label", "(", "self", ".", "annotation_stack_index_to_markers_index", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.start_annotation_marker_function": [[486, 490], ["article_annotations.Articles_annotations.marker_annotation", "article_annotations.Articles_annotations.technique_index_from_annotation_index", "article_annotations.Articles_annotations.marker_annotation"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.technique_index_from_annotation_index", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation"], ["", "def", "start_annotation_marker_function", "(", "self", ",", "annotations_stack", ":", "list", ",", "marker_index", ":", "int", ",", "row_counter", ":", "int", ")", "->", "str", ":", "\n", "\n", "        ", "return", "'<span id=\"row%dannotation%d\" class=\"%s\">'", "%", "(", "row_counter", ",", "self", ".", "marker_annotation", "(", "marker_index", ")", ",", "\" \"", ".", "join", "(", "[", "\"technique%d\"", "%", "(", "self", ".", "technique_index_from_annotation_index", "(", "x", ")", ")", "for", "x", "in", "annotations_stack", "+", "[", "self", ".", "marker_annotation", "(", "marker_index", ")", "]", "]", ")", ")", "\n", "#if len(annotations_stack) > 0: # there is at least another tag opened, this one will overlap with it", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.end_annotation_marker_function": [[497, 512], ["article_annotations.Articles_annotations.marker_annotation", "new_annotations_stack.remove", "article_annotations.Articles_annotations.techniques.indexOf", "article_annotations.Articles_annotations.techniques.indexOf", "article_annotations.Articles_annotations.marker_annotation", "article_annotations.Articles_annotations.marker_label", "new_annotations_stack.remove", "article_annotations.Articles_annotations.start_annotation_marker_function", "article_annotations.Articles_annotations.marker_label", "annotations_stack.index", "article_annotations.Articles_annotations.marker_annotation", "article_annotations.Articles_annotations.annotation_stack_index_to_markers_index", "article_annotations.Articles_annotations.marker_annotation", "article_annotations.Articles_annotations.marker_annotation"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.indexOf", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.indexOf", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.start_annotation_marker_function", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.annotation_stack_index_to_markers_index", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation"], ["", "def", "end_annotation_marker_function", "(", "self", ",", "annotations_stack", ":", "list", ",", "marker_index", ":", "int", ",", "row_counter", ":", "int", ")", "->", "str", ":", "\n", "\n", "        ", "if", "self", ".", "marker_annotation", "(", ")", "!=", "annotations_stack", "[", "-", "1", "]", ":", "# we are facing this case: <t1> <t2> </t1> </t2> and we are about to close </t1> (self.marker_annotation()==</t1>, annotations_stack[-1]==</t2>), however, that case above is not allowed in HTML, therefore we are about to transform it to <t1> <t2> </t2></t1><t2> </t2> below", "\n", "            ", "new_annotations_stack", "=", "annotations_stack", "[", "annotations_stack", ".", "index", "(", "self", ".", "marker_annotation", "(", ")", ")", ":", "]", "\n", "res", "=", "\"\"", ".", "join", "(", "[", "\"</span>\"", "for", "x", "in", "new_annotations_stack", "]", ")", "# closing all tags opened that are supposed to continue after </t2>", "\n", "new_annotations_stack", ".", "remove", "(", "self", ".", "marker_annotation", "(", ")", ")", "# removing </t1> from annotations_stack copy ", "\n", "technique_index", "=", "self", ".", "techniques", ".", "indexOf", "(", "self", ".", "marker_label", "(", "marker_index", ")", ")", "\n", "res", "+=", "'<sup id=\"row%dannotation%d\" class=\"technique%d\">%d</sup>'", "%", "(", "row_counter", ",", "self", ".", "marker_annotation", "(", ")", ",", "technique_index", ",", "technique_index", ")", "\n", "for", "x", "in", "new_annotations_stack", ":", "\n", "                ", "new_annotations_stack", ".", "remove", "(", "x", ")", "# self.start_annotation_marker_function() assumes x is not in the annotations_stack variable passed as parameter", "\n", "res", "+=", "self", ".", "start_annotation_marker_function", "(", "new_annotations_stack", ",", "self", ".", "annotation_stack_index_to_markers_index", "(", "x", ")", ",", "row_counter", ")", "\n", "", "return", "res", "\n", "", "else", ":", "# end of non-overlapping technique", "\n", "            ", "technique_index", "=", "self", ".", "techniques", ".", "indexOf", "(", "self", ".", "marker_label", "(", "marker_index", ")", ")", "\n", "return", "'</span><sup id=\"row%dannotation%d\" class=\"technique%d\">%d</sup>'", "%", "(", "row_counter", ",", "self", ".", "marker_annotation", "(", ")", ",", "technique_index", ",", "technique_index", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.tag_text_with_annotations": [[514, 569], ["article_annotations.Articles_annotations.get_markers_from_spans", "set", "enumerate", "sorted", "len", "output_text.split", "article_annotations.Articles_annotations.add_sentence_marker", "src.propaganda_techniques.Propaganda_Techniques", "src.propaganda_techniques.Propaganda_Techniques", "len", "len", "article_annotations.Articles_annotations.marker_position", "article_annotations.Articles_annotations.techniques.indexOf", "set.add", "article_annotations.Articles_annotations.is_starting_marker", "text_to_be_added.count", "article_annotations.Articles_annotations.marker_position", "article_annotations.Articles_annotations.techniques.get_technique", "article_annotations.Articles_annotations.marker_label", "article_annotations.Articles_annotations.start_annotation_marker_function", "annotations_stack.append", "article_annotations.Articles_annotations.end_annotation_marker_function", "annotations_stack.remove", "article_annotations.Articles_annotations.marker_annotation", "article_annotations.Articles_annotations.marker_annotation", "article_annotations.Articles_annotations.marker_position"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_markers_from_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.add_sentence_marker", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_position", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.indexOf", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.is_starting_marker", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_position", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.propaganda_techniques.Propaganda_Techniques.get_technique", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.start_annotation_marker_function", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.end_annotation_marker_function", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_annotation", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.marker_position"], ["", "", "def", "tag_text_with_annotations", "(", "self", ",", "original_text", ",", "print_line_numbers", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        mark the string original_text with object's annotations\n\n        original_text: string with the text to be marked\n        print_line_numbers: add line numbers to the text\n\n        :return output_text the text in string original_text with added marks\n                footnotes the list of techniques in the text\n                legend description of the marks added\n        \"\"\"", "\n", "\n", "if", "Articles_annotations", ".", "techniques", "is", "None", ":", "\n", "            ", "if", "ans", ".", "Annotation", ".", "propaganda_techniques", "is", "None", ":", "\n", "                ", "Articles_annotations", ".", "techniques", "=", "Propaganda_Techniques", "(", ")", "\n", "", "else", ":", "\n", "                ", "Articles_annotations", ".", "techniques", "=", "ans", ".", "Annotation", ".", "propaganda_techniques", "\n", "\n", "", "", "self", ".", "get_markers_from_spans", "(", ")", "\n", "\n", "output_text", ",", "curr_output_text_index", ",", "self", ".", "curr_marker", "=", "(", "\"\"", ",", "0", ",", "0", ")", "\n", "techniques_found", "=", "set", "(", ")", "\n", "row_counter", "=", "1", "\n", "#print(self.markers)", "\n", "annotations_stack", "=", "[", "]", "# to handle overlapping annotations when assigning color background", "\n", "while", "curr_output_text_index", "<", "len", "(", "original_text", ")", ":", "\n", "            ", "if", "self", ".", "curr_marker", ">=", "len", "(", "self", ".", "markers", ")", ":", "# done marking text, need to flush the remaining content of <original_text> into <output_text>", "\n", "                ", "output_text", "+=", "original_text", "[", "curr_output_text_index", ":", "]", "\n", "curr_output_text_index", "=", "len", "(", "original_text", ")", "\n", "", "else", ":", "# more markers have to be added to the content string", "\n", "                ", "if", "self", ".", "marker_position", "(", ")", "<=", "curr_output_text_index", ":", "# it is time to add a marker", "\n", "                    ", "techniques_index", "=", "self", ".", "techniques", ".", "indexOf", "(", "self", ".", "marker_label", "(", ")", ")", "\n", "techniques_found", ".", "add", "(", "techniques_index", ")", "\n", "if", "self", ".", "is_starting_marker", "(", ")", ":", "\n", "                        ", "output_text", "+=", "self", ".", "start_annotation_marker_function", "(", "annotations_stack", ",", "self", ".", "curr_marker", ",", "row_counter", ")", "\n", "annotations_stack", ".", "append", "(", "self", ".", "marker_annotation", "(", ")", ")", "\n", "", "else", ":", "\n", "                        ", "output_text", "+=", "self", ".", "end_annotation_marker_function", "(", "annotations_stack", ",", "self", ".", "curr_marker", ",", "row_counter", ")", "\n", "annotations_stack", ".", "remove", "(", "self", ".", "marker_annotation", "(", ")", ")", "\n", "", "self", ".", "curr_marker", "+=", "1", "\n", "", "else", ":", "# flush string content up to the next marker", "\n", "                    ", "text_to_be_added", "=", "original_text", "[", "curr_output_text_index", ":", "self", ".", "marker_position", "(", ")", "]", "\n", "row_counter", "+=", "text_to_be_added", ".", "count", "(", "'\\n'", ")", "\n", "output_text", "+=", "text_to_be_added", "\n", "curr_output_text_index", "=", "self", ".", "marker_position", "(", ")", "\n", "\n", "", "", "", "final_text", "=", "\"\"", "\n", "for", "row_counter", ",", "line", "in", "enumerate", "(", "output_text", ".", "split", "(", "\"\\n\"", ")", ",", "1", ")", ":", "\n", "            ", "final_text", "+=", "self", ".", "add_sentence_marker", "(", "line", ",", "row_counter", ")", "\n", "\n", "", "footnotes", "=", "\"\\n<div>List of techniques found in the article</div>\\n\\n\"", "\n", "for", "technique_index", "in", "sorted", "(", "techniques_found", ")", ":", "\n", "            ", "footnotes", "+=", "\"<div>%d: %s</div>\\n\"", "%", "(", "technique_index", ",", "self", ".", "techniques", ".", "get_technique", "(", "technique_index", ")", ")", "\n", "\n", "", "return", "final_text", ",", "footnotes", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.merge_article_annotations": [[571, 602], ["range", "print", "annotations_without_overlapping[].span_overlapping", "annotations_without_overlapping[].merge_spans", "article_annotations.Articles_annotations.merge_article_annotations", "len", "len"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.span_overlapping", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.merge_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.merge_article_annotations"], ["", "def", "merge_article_annotations", "(", "self", ",", "annotations_without_overlapping", ",", "i", ")", ":", "\n", "        ", "\"\"\"\n        Checks if annotations_without_overlapping\n        :param annotations_without_overlapping: a list of Annotations objects of an article assumed to be\n                without overlapping\n        :param i: the index in spans which needs to be tested for overlapping\n        :return: \n        \"\"\"", "\n", "#print(\"checking element %d of %d\"%(i, len(spans)))", "\n", "if", "i", "<", "0", ":", "\n", "            ", "return", "True", "\n", "", "for", "j", "in", "range", "(", "0", ",", "i", ")", ":", "#len(annotations_without_overlapping)):", "\n", "            ", "assert", "i", "<", "len", "(", "annotations_without_overlapping", ")", "or", "print", "(", "i", ",", "len", "(", "annotations_without_overlapping", ")", ")", "\n", "if", "j", "!=", "i", "and", "annotations_without_overlapping", "[", "i", "]", ".", "span_overlapping", "(", "annotations_without_overlapping", "[", "j", "]", ")", ":", "\n", "#   len(annotations_without_overlapping[i][1].intersection(annotations_without_overlapping[j][1])) > 0:", "\n", "# print(\"Found overlapping spans: %d-%d and %d-%d in annotations %d,%d:\\n%s\"", "\n", "#       %(min(annotations_without_overlapping[i][1]), max(annotations_without_overlapping[i][1]),", "\n", "#         min(annotations_without_overlapping[j][1]), max(annotations_without_overlapping[j][1]), i,j,", "\n", "#         print_annotations(annotations_without_overlapping)))", "\n", "                ", "annotations_without_overlapping", "[", "j", "]", ".", "merge_spans", "(", "annotations_without_overlapping", "[", "i", "]", ")", "\n", "#annotations_without_overlapping[j][1] = annotations_without_overlapping[j][1].union(annotations_without_overlapping[i][1])", "\n", "del", "(", "annotations_without_overlapping", "[", "i", "]", ")", "\n", "# print(\"Annotations after deletion:\\n%s\"%(print_annotations(annotations_without_overlapping)))", "\n", "if", "j", ">", "i", ":", "\n", "                    ", "j", "-=", "1", "\n", "# print(\"calling recursively\")", "\n", "", "self", ".", "merge_article_annotations", "(", "annotations_without_overlapping", ",", "j", ")", "\n", "# print(\"done\")", "\n", "return", "True", "\n", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_spans_content": [[604, 612], ["article_annotations.Articles_annotations.get_article_annotations", "annotation.get_start_offset", "annotation.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "get_spans_content", "(", "self", ",", "article_content", ":", "str", ")", "->", "str", ":", "\n", "        ", "\"\"\"\n        Given an article content as a string, prints the spans covered by the current annotations\n        \"\"\"", "\n", "s", "=", "\"\"", "\n", "for", "annotation", "in", "self", ".", "get_article_annotations", "(", ")", ":", "\n", "            ", "s", "+=", "article_content", "[", "annotation", ".", "get_start_offset", "(", ")", ":", "annotation", ".", "get_end_offset", "(", ")", "]", "+", "\"\\n\"", "\n", "", "return", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.remove_annotation": [[614, 617], ["article_annotations.Articles_annotations.get_article_annotations().remove", "article_annotations.Articles_annotations.get_article_annotations"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_annotations"], ["", "def", "remove_annotation", "(", "self", ",", "annotation_to_be_deleted", ":", "anwol", ".", "AnnotationWithOutLabel", ")", ":", "\n", "\n", "        ", "self", ".", "get_article_annotations", "(", ")", ".", "remove", "(", "annotation_to_be_deleted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.remove_empty_annotations": [[619, 622], ["None"], "methods", ["None"], ["", "def", "remove_empty_annotations", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "spans", "=", "[", "span", "for", "span", "in", "self", ".", "spans", "if", "span", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.set_output_format": [[624, 631], ["None"], "methods", ["None"], ["", "def", "set_output_format", "(", "self", ",", "article_id", "=", "True", ",", "span", "=", "True", ",", "label", "=", "True", ")", ":", "\n", "        ", "\"\"\"\n        Defines which fields are printed when annotations are written to standard output or file\n        \"\"\"", "\n", "self", ".", "output_format_article_id", "=", "article_id", "\n", "self", ".", "output_format_article_spans", "=", "span", "\n", "self", ".", "output_format_article_label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.annotations_to_string_csv": [[633, 650], ["span_data.append", "span_data.append", "span_data.append", "article_annotations.Articles_annotations.get_article_id", "span.get_label", "span.get_start_offset", "span.get_end_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.get_article_id", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_end_offset"], ["", "def", "annotations_to_string_csv", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        write article annotations, one per line, in the following format:\n        article_id  label   span_start  span_end\n        \"\"\"", "\n", "span_string", "=", "\"\"", "\n", "for", "span", "in", "self", ".", "spans", ":", "\n", "            ", "span_data", "=", "[", "]", "\n", "if", "self", ".", "output_format_article_id", ":", "\n", "                ", "span_data", ".", "append", "(", "self", ".", "get_article_id", "(", ")", ")", "\n", "", "if", "self", ".", "output_format_article_label", ":", "\n", "                ", "span_data", ".", "append", "(", "span", ".", "get_label", "(", ")", ")", "\n", "", "if", "self", ".", "output_format_article_spans", ":", "\n", "                ", "span_data", ".", "append", "(", "\"%d\\t%d\"", "%", "(", "span", ".", "get_start_offset", "(", ")", ",", "span", ".", "get_end_offset", "(", ")", ")", ")", "\n", "", "span_string", "+=", "\"\\t\"", ".", "join", "(", "span_data", ")", "+", "\"\\n\"", "\n", "\n", "", "return", "span_string", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.reset_annotations": [[652, 655], ["None"], "methods", ["None"], ["", "def", "reset_annotations", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "spans", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.set_start_annotation_effect": [[657, 661], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "set_start_annotation_effect", "(", "cls", ",", "new_effect", ":", "str", ")", "->", "None", ":", "\n", "\n", "        ", "cls", ".", "start_annotation_effect", "=", "new_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.set_end_annotation_effect": [[663, 667], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "set_end_annotation_effect", "(", "cls", ",", "new_effect", ":", "str", ")", "->", "None", ":", "\n", "\n", "        ", "cls", ".", "end_annotation_effect", "=", "new_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.set_start_annotation_str": [[669, 673], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "set_start_annotation_str", "(", "cls", ",", "new_effect", ":", "str", ")", "->", "None", ":", "\n", "\n", "        ", "cls", ".", "start_annotation_str", "=", "new_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.set_end_annotation_str": [[675, 679], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "set_end_annotation_str", "(", "cls", ",", "new_effect", ":", "str", ")", "->", "None", ":", "\n", "\n", "        ", "cls", ".", "end_annotation_str", "=", "new_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.set_annotation_background_color": [[681, 685], ["None"], "methods", ["None"], ["", "@", "classmethod", "\n", "def", "set_annotation_background_color", "(", "cls", ",", "new_effect", ":", "str", ")", "->", "None", ":", "\n", "\n", "        ", "cls", ".", "annotation_background_color", "=", "new_effect", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.save_annotations_to_file": [[687, 691], ["open", "f.write", "article_annotations.Articles_annotations.annotations_to_string_csv"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.annotations_to_string_csv"], ["", "def", "save_annotations_to_file", "(", "self", ",", "filename", ")", ":", "\n", "\n", "        ", "with", "open", "(", "filename", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "self", ".", "annotations_to_string_csv", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.shift_spans": [[693, 698], ["span.get_start_offset", "span.shift_annotation"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.shift_annotation"], ["", "", "def", "shift_spans", "(", "self", ",", "start_index", ",", "offset", ")", ":", "\n", "\n", "        ", "for", "span", "in", "self", ".", "spans", ":", "\n", "            ", "if", "span", ".", "get_start_offset", "(", ")", ">=", "start_index", ":", "\n", "                ", "span", ".", "shift_annotation", "(", "offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.sort_spans": [[700, 705], ["sorted", "span.get_start_offset"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_w_o_label.AnnotationWithOutLabel.get_start_offset"], ["", "", "", "def", "sort_spans", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        sort the list of annotations with respect to the starting offset\n        \"\"\"", "\n", "self", ".", "spans", "=", "sorted", "(", "self", ".", "spans", ",", "key", "=", "lambda", "span", ":", "span", ".", "get_start_offset", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.article_annotations.Articles_annotations.swap_annotations": [[707, 712], ["None"], "methods", ["None"], ["", "def", "swap_annotations", "(", "self", ",", "i", ":", "int", ",", "j", ":", "int", ")", "->", "None", ":", "\n", "        ", "\"\"\"\n        Swap the i-th and j-th annotations \n        \"\"\"", "\n", "self", ".", "spans", "[", "i", "]", ",", "self", ".", "spans", "[", "j", "]", "=", "self", ".", "spans", "[", "j", "]", ",", "self", ".", "spans", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.__init__": [[6, 11], ["int", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "label", "=", "None", ",", "start_offset", "=", "None", ",", "end_offset", "=", "None", ")", ":", "#, article_id=None):", "\n", "\n", "        ", "self", ".", "label", "=", "label", "\n", "self", ".", "start_offset", "=", "int", "(", "start_offset", ")", "\n", "self", ".", "end_offset", "=", "int", "(", "end_offset", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.src.annotation_task_si.AnnotationTaskSI.get_label": [[13, 16], ["sys.error"], "methods", ["None"], ["", "def", "get_label", "(", "self", ")", ":", "\n", "\n", "        ", "sys", ".", "error", "(", "\"ERRRO: trying to access technique label from file in SI task format\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.read_articles_from_file_list": [[10, 19], ["glob.glob", "sorted", "os.path.join", "codecs.open", "f.read", "os.path.basename().split", "os.path.basename"], "function", ["None"], ["def", "read_articles_from_file_list", "(", "folder_name", ",", "file_pattern", "=", "\"*.txt\"", ")", ":", "\n", "    ", "file_list", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder_name", ",", "file_pattern", ")", ")", "\n", "articles", "=", "{", "}", "\n", "article_id_list", ",", "sentence_id_list", ",", "sentence_list", "=", "(", "[", "]", ",", "[", "]", ",", "[", "]", ")", "\n", "for", "filename", "in", "sorted", "(", "file_list", ")", ":", "\n", "        ", "article_id", "=", "os", ".", "path", ".", "basename", "(", "filename", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "[", "7", ":", "]", "\n", "with", "codecs", ".", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "articles", "[", "article_id", "]", "=", "f", ".", "read", "(", ")", "\n", "", "", "return", "articles", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.read_predictions_from_file": [[21, 31], ["open", "f.readlines", "row.rstrip().split", "articles_id.append", "gold_labels.append", "span_starts.append", "span_ends.append", "row.rstrip"], "function", ["None"], ["", "def", "read_predictions_from_file", "(", "filename", ")", ":", "\n", "    ", "articles_id", ",", "span_starts", ",", "span_ends", ",", "gold_labels", "=", "(", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "row", "in", "f", ".", "readlines", "(", ")", ":", "\n", "            ", "article_id", ",", "gold_label", ",", "span_start", ",", "span_end", "=", "row", ".", "rstrip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "articles_id", ".", "append", "(", "article_id", ")", "\n", "gold_labels", ".", "append", "(", "gold_label", ")", "\n", "span_starts", ".", "append", "(", "span_start", ")", "\n", "span_ends", ".", "append", "(", "span_end", ")", "\n", "", "", "return", "articles_id", ",", "span_starts", ",", "span_ends", ",", "gold_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.load_data": [[33, 37], ["dataset.read_articles_from_file_list", "dataset.read_predictions_from_file"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.read_articles_from_file_list", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.read_predictions_from_file"], ["", "def", "load_data", "(", "data_folder", ",", "labels_file", ")", ":", "\n", "    ", "articles", "=", "read_articles_from_file_list", "(", "data_folder", ")", "\n", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", "=", "read_predictions_from_file", "(", "labels_file", ")", "\n", "return", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.sents_token_bounds": [[39, 45], ["nltk.tokenize.punkt.PunktSentenceTokenizer().span_tokenize", "sents_starts.append", "numpy.array", "sents_starts.append", "nltk.tokenize.punkt.PunktSentenceTokenizer"], "function", ["None"], ["", "def", "sents_token_bounds", "(", "text", ")", ":", "\n", "    ", "sents_starts", "=", "[", "]", "\n", "for", "start", ",", "end", "in", "PunktSentenceTokenizer", "(", ")", ".", "span_tokenize", "(", "text", ")", ":", "\n", "        ", "sents_starts", ".", "append", "(", "start", ")", "\n", "", "sents_starts", ".", "append", "(", "100000", ")", "\n", "return", "np", ".", "array", "(", "sents_starts", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.clear": [[47, 49], ["text.strip().replace().replace", "text.strip().replace", "text.strip"], "function", ["None"], ["", "def", "clear", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "strip", "(", ")", ".", "replace", "(", "'\\t'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.get_context": [[51, 56], ["dataset.sents_token_bounds", "dataset.clear", "numpy.where", "numpy.where"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.sents_token_bounds", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.clear"], ["", "def", "get_context", "(", "article", ",", "span_start", ",", "span_end", ")", ":", "\n", "    ", "bounds", "=", "sents_token_bounds", "(", "article", ")", "\n", "context_start", "=", "bounds", "[", "np", ".", "where", "(", "bounds", "<=", "span_start", ")", "[", "0", "]", "[", "-", "1", "]", "]", "\n", "context_end", "=", "bounds", "[", "np", ".", "where", "(", "bounds", ">=", "span_end", ")", "[", "0", "]", "[", "0", "]", "]", "\n", "return", "clear", "(", "article", "[", "context_start", ":", "context_end", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.balance_pandas": [[58, 64], ["data[].value_counts().max", "data.groupby", "pandas.concat", "lst.append", "data[].value_counts", "group.sample", "len"], "function", ["None"], ["", "def", "balance_pandas", "(", "data", ")", ":", "\n", "    ", "lst", "=", "[", "data", "]", "\n", "max_size", "=", "data", "[", "'label'", "]", ".", "value_counts", "(", ")", ".", "max", "(", ")", "\n", "for", "class_index", ",", "group", "in", "data", ".", "groupby", "(", "'label'", ")", ":", "\n", "        ", "lst", ".", "append", "(", "group", ".", "sample", "(", "max_size", "-", "len", "(", "group", ")", ",", "replace", "=", "True", ")", ")", "\n", "", "return", "pd", ".", "concat", "(", "lst", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.dataset_to_pandas": [[66, 76], ["pandas.DataFrame.from_dict", "pd.DataFrame.from_dict.apply", "pd.DataFrame.from_dict.apply", "numpy.array().astype", "numpy.array().astype", "dataset.clear", "dataset.get_context", "numpy.array", "numpy.array"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.clear", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.get_context"], ["", "def", "dataset_to_pandas", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "train_gold_labels", ")", ":", "\n", "    ", "data", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "{", "'article_id'", ":", "ref_articles_id", ",", "\n", "'article'", ":", "[", "articles", "[", "id", "]", "for", "id", "in", "ref_articles_id", "]", ",", "\n", "'span_start'", ":", "np", ".", "array", "(", "ref_span_starts", ")", ".", "astype", "(", "int", ")", ",", "\n", "'span_end'", ":", "np", ".", "array", "(", "ref_span_ends", ")", ".", "astype", "(", "int", ")", ",", "\n", "'label'", ":", "train_gold_labels", "\n", "}", ")", "\n", "data", "[", "'span'", "]", "=", "data", ".", "apply", "(", "lambda", "x", ":", "clear", "(", "x", "[", "'article'", "]", "[", "x", "[", "'span_start'", "]", ":", "x", "[", "'span_end'", "]", "]", ")", ",", "axis", "=", "1", ")", "\n", "data", "[", "'context'", "]", "=", "data", ".", "apply", "(", "lambda", "x", ":", "get_context", "(", "x", "[", "'article'", "]", ",", "x", "[", "'span_start'", "]", ",", "x", "[", "'span_end'", "]", ")", ",", "axis", "=", "1", ")", "\n", "return", "data", "[", "[", "'article_id'", ",", "'span_start'", ",", "'span_end'", ",", "'span'", ",", "'context'", ",", "'label'", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.get_train_dev_files": [[78, 95], ["dataset.dataset_to_pandas", "dataset.save_dataset", "dataset.save_dataset", "sklearn.model_selection.train_test_split", "sklearn.model_selection.train_test_split", "dataset.balance_pandas", "train.sample().reset_index.sample().reset_index", "dataset_to_pandas.article_id.unique", "dataset_to_pandas.article_id.isin", "dataset_to_pandas.article_id.isin", "train.sample().reset_index.sample"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.dataset_to_pandas", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.save_dataset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.save_dataset", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.balance_pandas"], ["", "def", "get_train_dev_files", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ",", "train_file", ",", "dev_file", ",", "\n", "split_by_ids", "=", "False", ",", "dev_size", "=", "0.3", ",", "random_state", "=", "40", ",", "balance", "=", "False", ",", "shuffle", "=", "True", ")", ":", "\n", "    ", "data", "=", "dataset_to_pandas", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ")", "\n", "if", "split_by_ids", ":", "\n", "        ", "train_ids", ",", "dev_ids", "=", "train_test_split", "(", "data", ".", "article_id", ".", "unique", "(", ")", ",", "test_size", "=", "dev_size", ",", "random_state", "=", "random_state", ")", "\n", "train", "=", "data", "[", "data", ".", "article_id", ".", "isin", "(", "train_ids", ")", "]", "\n", "dev", "=", "data", "[", "data", ".", "article_id", ".", "isin", "(", "dev_ids", ")", "]", "\n", "", "else", ":", "\n", "        ", "train", ",", "dev", "=", "train_test_split", "(", "data", ",", "test_size", "=", "dev_size", ",", "random_state", "=", "random_state", ")", "\n", "\n", "", "if", "balance", ":", "\n", "        ", "train", "=", "balance_pandas", "(", "train", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "train", "=", "train", ".", "sample", "(", "frac", "=", "1", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "", "save_dataset", "(", "train", ",", "train_file", ")", "\n", "save_dataset", "(", "dev", ",", "dev_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.get_test_file": [[97, 100], ["dataset.dataset_to_pandas", "dataset.save_dataset"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.dataset_to_pandas", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.save_dataset"], ["", "def", "get_test_file", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ",", "test_file", ")", ":", "\n", "    ", "test", "=", "dataset_to_pandas", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ")", "\n", "save_dataset", "(", "test", ",", "test_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.dataset.save_dataset": [[102, 104], ["data.to_csv"], "function", ["None"], ["", "def", "save_dataset", "(", "data", ",", "file_path", ")", ":", "\n", "    ", "data", ".", "to_csv", "(", "file_path", ",", "sep", "=", "'\\t'", ",", "index", "=", "False", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.get_insides": [[17, 32], ["collections.defaultdict", "list", "range", "zip", "len", "range", "insides[].get", "insides[].get"], "function", ["None"], ["def", "get_insides", "(", "data", ")", ":", "\n", "    ", "insides", "=", "defaultdict", "(", "dict", ")", "\n", "spans_coords", "=", "list", "(", "zip", "(", "data", "[", "'span_start'", "]", ".", "values", ",", "data", "[", "'span_end'", "]", ".", "values", ")", ")", "\n", "labels", "=", "data", "[", "'label'", "]", ".", "values", "\n", "article_ids", "=", "data", "[", "'article_id'", "]", ".", "values", "\n", "for", "i", "in", "range", "(", "len", "(", "spans_coords", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", ")", ":", "\n", "            ", "if", "article_ids", "[", "i", "]", "==", "article_ids", "[", "j", "]", ":", "\n", "                ", "if", "spans_coords", "[", "i", "]", "[", "0", "]", ">=", "spans_coords", "[", "j", "]", "[", "0", "]", "and", "spans_coords", "[", "i", "]", "[", "1", "]", "<=", "spans_coords", "[", "j", "]", "[", "1", "]", ":", "\n", "                    ", "if", "spans_coords", "[", "i", "]", "[", "0", "]", "!=", "spans_coords", "[", "j", "]", "[", "0", "]", "or", "spans_coords", "[", "i", "]", "[", "1", "]", "!=", "spans_coords", "[", "j", "]", "[", "1", "]", ":", "\n", "                        ", "insides", "[", "labels", "[", "i", "]", "]", "[", "labels", "[", "j", "]", "]", "=", "insides", "[", "labels", "[", "i", "]", "]", ".", "get", "(", "labels", "[", "j", "]", ",", "0", ")", "+", "1", "\n", "", "", "if", "spans_coords", "[", "j", "]", "[", "0", "]", ">=", "spans_coords", "[", "i", "]", "[", "0", "]", "and", "spans_coords", "[", "j", "]", "[", "1", "]", "<=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                    ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", "!=", "spans_coords", "[", "i", "]", "[", "0", "]", "or", "spans_coords", "[", "j", "]", "[", "1", "]", "!=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                        ", "insides", "[", "labels", "[", "j", "]", "]", "[", "labels", "[", "i", "]", "]", "=", "insides", "[", "labels", "[", "j", "]", "]", ".", "get", "(", "labels", "[", "i", "]", ",", "0", ")", "+", "1", "\n", "", "", "", "", "", "return", "insides", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.correct_preds_for_insides": [[34, 63], ["range", "len", "range", "len", "sklearn.utils.extmath.softmax", "sklearn.utils.extmath.softmax", "insides.get", "numpy.sort", "numpy.sort", "numpy.argmax", "numpy.argmax"], "function", ["None"], ["", "def", "correct_preds_for_insides", "(", "preds", ",", "spans_coords", ",", "logits", ",", "insides", ",", "mapping", ",", "inverse_mapping", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "            ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", ">=", "spans_coords", "[", "i", "]", "[", "0", "]", "and", "spans_coords", "[", "j", "]", "[", "1", "]", "<=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", "!=", "spans_coords", "[", "i", "]", "[", "0", "]", "or", "spans_coords", "[", "j", "]", "[", "1", "]", "!=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                    ", "def_i", "=", "preds", "[", "i", "]", "\n", "def_j", "=", "preds", "[", "j", "]", "\n", "log", "=", "softmax", "(", "[", "logits", "[", "i", "]", "]", ")", "[", "0", "]", "\n", "login", "=", "softmax", "(", "[", "logits", "[", "j", "]", "]", ")", "[", "0", "]", "\n", "def_prob_i", "=", "log", "[", "inverse_mapping", "[", "preds", "[", "i", "]", "]", "]", "\n", "def_prob_j", "=", "login", "[", "inverse_mapping", "[", "preds", "[", "j", "]", "]", "]", "\n", "while", "preds", "[", "j", "]", "not", "in", "insides", ".", "get", "(", "preds", "[", "i", "]", ",", "[", "]", ")", ":", "\n", "                        ", "if", "log", "[", "inverse_mapping", "[", "preds", "[", "i", "]", "]", "]", ">", "login", "[", "inverse_mapping", "[", "preds", "[", "j", "]", "]", "]", ":", "\n", "                            ", "values", "=", "np", ".", "sort", "(", "login", ")", "[", "-", "2", ":", "]", "\n", "if", "values", "[", "1", "]", "/", "(", "values", "[", "0", "]", "+", "1e-6", ")", ">", "1.4", ":", "\n", "                                ", "preds", "[", "i", "]", "=", "def_i", "\n", "preds", "[", "j", "]", "=", "def_j", "\n", "break", "\n", "", "login", "[", "inverse_mapping", "[", "preds", "[", "j", "]", "]", "]", "=", "0", "\n", "preds", "[", "j", "]", "=", "mapping", "[", "np", ".", "argmax", "(", "login", ")", "]", "\n", "", "else", ":", "\n", "                            ", "values", "=", "np", ".", "sort", "(", "log", ")", "[", "-", "2", ":", "]", "\n", "if", "values", "[", "1", "]", "/", "(", "values", "[", "0", "]", "+", "1e-6", ")", ">", "1.4", ":", "\n", "                                ", "preds", "[", "i", "]", "=", "def_i", "\n", "preds", "[", "j", "]", "=", "def_j", "\n", "break", "\n", "", "log", "[", "inverse_mapping", "[", "preds", "[", "i", "]", "]", "]", "=", "0", "\n", "preds", "[", "i", "]", "=", "mapping", "[", "np", ".", "argmax", "(", "log", ")", "]", "\n", "", "", "", "", "", "", "return", "preds", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.stem_spans": [[65, 73], ["nltk.stem.PorterStemmer", "len", "res.append", "nltk.stem.PorterStemmer.stem", "nltk.tokenize.word_tokenize", "el.lower"], "function", ["None"], ["", "def", "stem_spans", "(", "spans", ")", ":", "\n", "    ", "ps", "=", "PorterStemmer", "(", ")", "\n", "res", "=", "[", "]", "\n", "for", "el", "in", "spans", ":", "\n", "        ", "result", "=", "\" \"", ".", "join", "(", "ps", ".", "stem", "(", "word", ")", "for", "word", "in", "word_tokenize", "(", "el", ".", "lower", "(", ")", ")", ")", "\n", "if", "len", "(", "result", ")", ">", "0", ":", "\n", "            ", "res", ".", "append", "(", "result", ")", "\n", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.get_train_instances": [[75, 88], ["dict", "submission.stem_spans", "range", "len", "dict.setdefault", "train_instances[].add", "open", "pickle.dump", "set", "os.path.join"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.stem_spans"], ["", "def", "get_train_instances", "(", "data", ",", "data_dir", ",", "save", "=", "True", ")", ":", "\n", "    ", "train_instances", "=", "dict", "(", ")", "\n", "stemmed_spans", "=", "stem_spans", "(", "data", ".", "span", ".", "values", ")", "\n", "labels", "=", "data", ".", "label", ".", "values", "\n", "for", "i", "in", "range", "(", "len", "(", "stemmed_spans", ")", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "!=", "'Repetition'", ":", "\n", "            ", "span", "=", "stemmed_spans", "[", "i", "]", "\n", "train_instances", ".", "setdefault", "(", "span", ",", "set", "(", ")", ")", "\n", "train_instances", "[", "span", "]", ".", "add", "(", "labels", "[", "i", "]", ")", "\n", "", "", "if", "save", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train_instances_train'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "train_instances", ",", "f", ")", "\n", "", "", "return", "train_instances", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.postprocess": [[90, 135], ["list", "dict", "range", "range", "submission.correct_preds_for_insides", "zip", "len", "dict.setdefault", "counts[].add", "len", "numpy.array", "len", "train_instances.get", "spans_source[].startswith", "range", "set", "log.split", "set", "len", "ps.stem", "ps.stem", "prev_same.append", "numpy.argmax", "nltk.tokenize.word_tokenize", "nltk.tokenize.word_tokenize", "len", "span.lower", "unidecode.unidecode", "spans[].split", "span.lower"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.correct_preds_for_insides"], ["", "def", "postprocess", "(", "x", ",", "mapping", ",", "inverse_mapping", ",", "insides", ",", "stop_words", ",", "ps", ",", "train_instances", ")", ":", "\n", "    ", "spans_coords", "=", "list", "(", "zip", "(", "x", "[", "'span_start'", "]", ".", "values", ",", "x", "[", "'span_end'", "]", ".", "values", ")", ")", "\n", "spans_source", "=", "x", "[", "'span'", "]", ".", "values", "\n", "spans_text", "=", "[", "' '", ".", "join", "(", "[", "ps", ".", "stem", "(", "word", ")", "for", "word", "in", "word_tokenize", "(", "span", ".", "lower", "(", ")", ")", "]", ")", "for", "span", "in", "spans_source", "]", "\n", "spans", "=", "[", "' '", ".", "join", "(", "[", "ps", ".", "stem", "(", "word", ")", "for", "word", "in", "word_tokenize", "(", "unidecode", "(", "span", ".", "lower", "(", ")", ")", ")", "\n", "if", "word", "not", "in", "stop_words", "and", "word", "not", "in", "string", ".", "punctuation", "]", ")", "for", "span", "in", "spans_source", "]", "\n", "\n", "counts", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "spans", ")", ")", ":", "\n", "        ", "counts", ".", "setdefault", "(", "spans", "[", "i", "]", ",", "set", "(", ")", ")", "\n", "counts", "[", "spans", "[", "i", "]", "]", ".", "add", "(", "spans_coords", "[", "i", "]", "[", "0", "]", ")", "\n", "", "for", "el", "in", "counts", ":", "\n", "        ", "counts", "[", "el", "]", "=", "len", "(", "counts", "[", "el", "]", ")", "\n", "\n", "", "preds", "=", "x", "[", "'pred'", "]", ".", "values", "\n", "logits", "=", "[", "np", ".", "array", "(", "log", ".", "split", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", "for", "log", "in", "x", "[", "'logits'", "]", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "        ", "log", "=", "logits", "[", "i", "]", "\n", "\n", "if", "counts", "[", "spans", "[", "i", "]", "]", ">=", "3", "or", "(", "counts", "[", "spans", "[", "i", "]", "]", ">=", "2", "and", "logits", "[", "i", "]", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", ">", "0.001", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", "=", "100", "\n", "\n", "", "if", "counts", "[", "spans", "[", "i", "]", "]", "==", "1", "and", "(", "logits", "[", "i", "]", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", "<", "0.99", "or", "len", "(", "spans", "[", "i", "]", ".", "split", "(", ")", ")", "<=", "1", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", "=", "0", "\n", "\n", "", "for", "prediction", "in", "train_instances", ".", "get", "(", "spans_text", "[", "i", "]", ",", "set", "(", ")", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "prediction", "]", "]", "+=", "0.5", "\n", "", "if", "spans_source", "[", "i", "]", ".", "startswith", "(", "'#'", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "'Slogans'", "]", "]", "=", "20", "\n", "\n", "\n", "", "prev_same", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", ")", ":", "\n", "            ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", "==", "spans_coords", "[", "i", "]", "[", "0", "]", "and", "spans_coords", "[", "j", "]", "[", "1", "]", "==", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                ", "prev_same", ".", "append", "(", "j", ")", "\n", "", "", "if", "len", "(", "prev_same", ")", ">", "0", ":", "\n", "            ", "for", "prediction", "in", "preds", "[", "prev_same", "]", ":", "\n", "                ", "log", "[", "inverse_mapping", "[", "prediction", "]", "]", "=", "0", "\n", "\n", "", "", "logits", "[", "i", "]", "=", "log", "\n", "preds", "[", "i", "]", "=", "mapping", "[", "np", ".", "argmax", "(", "log", ")", "]", "\n", "\n", "", "x", "[", "\"pred\"", "]", "=", "correct_preds_for_insides", "(", "preds", ",", "spans_coords", ",", "logits", ",", "insides", ",", "mapping", ",", "inverse_mapping", ")", "\n", "#x[\"pred\"] = preds", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.postprocess_predictions": [[137, 155], ["set", "nltk.stem.PorterStemmer", "numpy.argmax", "data.groupby().apply.groupby().apply", "numpy.array", "nltk.corpus.stopwords.words", "enumerate", "mapping.items", "numpy.array", "data.groupby().apply.groupby"], "function", ["None"], ["", "def", "postprocess_predictions", "(", "predictions_logits", ",", "data", ",", "insides", ",", "train_instances", ")", ":", "\n", "    ", "mapping", "=", "{", "i", ":", "el", "for", "i", ",", "el", "in", "enumerate", "(", "\n", "[", "'Appeal_to_Authority'", ",", "'Doubt'", ",", "'Repetition'", ",", "'Appeal_to_fear-prejudice'", ",", "'Slogans'", ",", "'Black-and-White_Fallacy'", ",", "\n", "'Loaded_Language'", ",", "'Flag-Waving'", ",", "'Name_Calling,Labeling'", ",", "'Whataboutism,Straw_Men,Red_Herring'", ",", "\n", "'Causal_Oversimplification'", ",", "'Exaggeration,Minimisation'", ",", "'Bandwagon,Reductio_ad_hitlerum'", ",", "\n", "'Thought-terminating_Cliches'", "]", "\n", ")", "}", "\n", "inverse_mapping", "=", "{", "b", ":", "a", "for", "(", "a", ",", "b", ")", "in", "mapping", ".", "items", "(", ")", "}", "\n", "\n", "stop_words", "=", "set", "(", "stopwords", ".", "words", "(", "'english'", ")", ")", "\n", "ps", "=", "PorterStemmer", "(", ")", "\n", "\n", "predictions", "=", "np", ".", "argmax", "(", "predictions_logits", ",", "axis", "=", "1", ")", "\n", "data", "[", "'pred'", "]", "=", "[", "mapping", "[", "p", "]", "for", "p", "in", "predictions", "]", "\n", "data", "[", "'logits'", "]", "=", "[", "' '", ".", "join", "(", "np", ".", "array", "(", "log", ",", "dtype", "=", "str", ")", ")", "for", "log", "in", "predictions_logits", "]", "\n", "data", "=", "data", ".", "groupby", "(", "'article_id'", ",", "as_index", "=", "False", ")", ".", "apply", "(", "postprocess", ",", "mapping", ",", "inverse_mapping", ",", "insides", ",", "\n", "stop_words", ",", "ps", ",", "train_instances", ")", "\n", "return", "np", ".", "array", "(", "data", "[", "\"pred\"", "]", ".", "values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.softmax_with_temperature": [[157, 162], ["numpy.max().reshape", "numpy.exp", "numpy.sum().reshape", "numpy.max", "numpy.sum"], "function", ["None"], ["", "def", "softmax_with_temperature", "(", "z", ",", "T", ")", ":", "\n", "    ", "z", "=", "z", "/", "T", "\n", "max_z", "=", "np", ".", "max", "(", "z", ",", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "exp_z", "=", "np", ".", "exp", "(", "z", "-", "max_z", ")", "\n", "return", "exp_z", "/", "np", ".", "sum", "(", "exp_z", ",", "axis", "=", "1", ")", ".", "reshape", "(", "-", "1", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.create_submission_file": [[164, 203], ["pandas.read_csv", "pandas.read_csv", "submission.get_insides", "submission.get_train_instances", "pandas.read_csv", "zip", "submission.postprocess_predictions", "len", "len", "joblib.load", "joblib.load.predict", "open", "zip", "open", "pickle.load", "numpy.concatenate", "fout.write", "len", "range", "predictions_logits_list.append", "len", "float", "submission.softmax_with_temperature", "float", "submission.softmax_with_temperature"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.get_insides", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.get_train_instances", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.postprocess_predictions", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.softmax_with_temperature", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.softmax_with_temperature"], ["", "def", "create_submission_file", "(", "predicted_logits_files", ",", "train_file_path", ",", "dev_file_path", ",", "test_file_path", ",", "\n", "article_ids", ",", "span_starts", ",", "span_ends", ",", "output_file", ",", "weights", "=", "None", ",", "data_dir", "=", "None", ",", "agg_model", "=", "None", ")", ":", "\n", "    ", "data_train", "=", "pd", ".", "read_csv", "(", "train_file_path", ",", "sep", "=", "'\\t'", ")", "\n", "data_eval", "=", "pd", ".", "read_csv", "(", "dev_file_path", ",", "sep", "=", "'\\t'", ")", "\n", "#data_train = pd.concat([data_train, data_eval], ignore_index=True)", "\n", "\n", "insides", "=", "get_insides", "(", "data_train", ")", "\n", "train_instances", "=", "get_train_instances", "(", "data_train", ",", "data_dir", ")", "\n", "\n", "data", "=", "pd", ".", "read_csv", "(", "test_file_path", ",", "sep", "=", "'\\t'", ")", "\n", "\n", "if", "weights", "is", "None", ":", "\n", "        ", "weights", "=", "[", "1.", "/", "len", "(", "predicted_logits_files", ")", "for", "_", "in", "range", "(", "len", "(", "predicted_logits_files", ")", ")", "]", "\n", "", "assert", "len", "(", "weights", ")", "==", "len", "(", "predicted_logits_files", ")", "\n", "\n", "predictions_logits", "=", "None", "\n", "predictions_logits_list", "=", "[", "]", "\n", "for", "file", ",", "weight", "in", "zip", "(", "predicted_logits_files", ",", "weights", ")", ":", "\n", "        ", "with", "open", "(", "file", ",", "'rb'", ")", "as", "f", ":", "\n", "            ", "logits", "=", "pickle", ".", "load", "(", "f", ")", "\n", "if", "predictions_logits", "is", "None", ":", "\n", "                ", "predictions_logits", "=", "float", "(", "weight", ")", "*", "softmax_with_temperature", "(", "logits", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "predictions_logits", "+=", "float", "(", "weight", ")", "*", "softmax_with_temperature", "(", "logits", ",", "1", ")", "\n", "", "if", "agg_model", "is", "not", "None", ":", "\n", "                ", "predictions_logits_list", ".", "append", "(", "logits", ")", "\n", "\n", "", "", "", "predictions", "=", "postprocess_predictions", "(", "predictions_logits", ",", "data", ",", "insides", ",", "train_instances", ")", "\n", "\n", "if", "agg_model", "is", "not", "None", ":", "\n", "        ", "clf", "=", "load", "(", "agg_model", ")", "\n", "predictions_sklearn_agg", "=", "clf", ".", "predict", "(", "np", ".", "concatenate", "(", "predictions_logits_list", ",", "axis", "=", "1", ")", ")", "\n", "predictions_sklearn_agg", "[", "predictions_sklearn_agg", "==", "'Repetition'", "]", "=", "predictions", "[", "predictions_sklearn_agg", "==", "'Repetition'", "]", "\n", "predictions_sklearn_agg", "[", "predictions", "==", "'Repetition'", "]", "=", "'Repetition'", "\n", "predictions", "=", "predictions_sklearn_agg", "\n", "\n", "", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "fout", ":", "\n", "        ", "for", "article_id", ",", "prediction", ",", "span_start", ",", "span_end", "in", "zip", "(", "article_ids", ",", "predictions", ",", "span_starts", ",", "span_ends", ")", ":", "\n", "            ", "fout", ".", "write", "(", "\"%s\\t%s\\t%s\\t%s\\n\"", "%", "(", "article_id", ",", "prediction", ",", "span_start", ",", "span_end", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.load_result": [[205, 213], ["collections.defaultdict", "open", "line.split", "result[].setdefault", "[].append", "int", "int"], "function", ["None"], ["", "", "", "def", "load_result", "(", "file", ")", ":", "\n", "    ", "result", "=", "defaultdict", "(", "dict", ")", "\n", "with", "open", "(", "file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "article_id", ",", "prediction", ",", "spl", ",", "spr", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "result", "[", "article_id", "]", ".", "setdefault", "(", "prediction", ",", "[", "]", ")", "\n", "result", "[", "article_id", "]", "[", "prediction", "]", ".", "append", "(", "[", "int", "(", "spl", ")", ",", "int", "(", "spr", ")", "]", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.read_ground_truth": [[215, 223], ["open", "[].strip", "ground_truth.append", "line.split"], "function", ["None"], ["", "def", "read_ground_truth", "(", "gt_file_path", ",", "label_names", ")", ":", "\n", "    ", "ground_truth", "=", "[", "]", "\n", "with", "open", "(", "gt_file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "gold_label", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "-", "1", "]", ".", "strip", "(", ")", "\n", "if", "gold_label", "in", "label_names", ":", "\n", "                ", "ground_truth", ".", "append", "(", "gold_label", ")", "\n", "", "", "", "return", "ground_truth", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.eval_submission": [[225, 241], ["sorted", "submission.read_ground_truth", "sklearn.metrics.accuracy_score", "list", "open", "zip", "[].strip", "predictions.append", "sklearn.metrics.f1_score", "line.split"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.read_ground_truth"], ["", "def", "eval_submission", "(", "result_file_path", ",", "gt_file_path", ")", ":", "\n", "    ", "predictions", "=", "[", "]", "\n", "with", "open", "(", "result_file_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "prediction", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "1", "]", ".", "strip", "(", ")", "\n", "predictions", ".", "append", "(", "prediction", ")", "\n", "\n", "", "", "label_names", "=", "sorted", "(", "[", "'Appeal_to_Authority'", ",", "'Doubt'", ",", "'Repetition'", ",", "'Appeal_to_fear-prejudice'", ",", "'Slogans'", ",", "\n", "'Black-and-White_Fallacy'", ",", "'Loaded_Language'", ",", "'Flag-Waving'", ",", "'Name_Calling,Labeling'", ",", "\n", "'Whataboutism,Straw_Men,Red_Herring'", ",", "'Causal_Oversimplification'", ",", "'Exaggeration,Minimisation'", ",", "\n", "'Bandwagon,Reductio_ad_hitlerum'", ",", "'Thought-terminating_Cliches'", "]", ")", "\n", "ground_truth", "=", "read_ground_truth", "(", "gt_file_path", ",", "label_names", ")", "\n", "\n", "acc", "=", "accuracy_score", "(", "ground_truth", ",", "predictions", ")", "\n", "f1", "=", "list", "(", "zip", "(", "label_names", ",", "f1_score", "(", "ground_truth", ",", "predictions", ",", "average", "=", "None", ",", "labels", "=", "label_names", ")", ")", ")", "\n", "return", "acc", ",", "f1", "\n", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.__main__.Main": [[19, 64], ["os.path.exists", "os.makedirs", "load_data", "os.path.join", "os.path.join", "os.path.join", "load_data", "transformers_clf", "os.path.join", "logger.info", "create_submission_file", "os.path.join", "logger.info", "logger.info", "get_train_dev_files", "logger.info", "get_test_file", "os.path.exists", "os.makedirs", "eval_submission", "logger.info", "print", "subprocess.run", "os.path.exists", "os.path.exists", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.load_data", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.load_data", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.transformers_clf", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.create_submission_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.get_train_dev_files", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.get_test_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.submission.eval_submission"], ["def", "Main", "(", "args", ")", ":", "\n", "    ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "data_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "if", "args", ".", "do_train", "or", "args", ".", "do_eval", "or", "args", ".", "split_dataset", "or", "args", ".", "create_submission_file", ":", "\n", "        ", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", "=", "load_data", "(", "args", ".", "train_data_folder", ",", "\n", "args", ".", "labels_path", ")", "\n", "train_file_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "train_file", ")", "\n", "dev_file_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "dev_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_file_path", ")", "or", "not", "os", ".", "path", ".", "exists", "(", "dev_file_path", ")", "or", "args", ".", "overwrite_cache", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating train/dev files: %s, %s\"", ",", "train_file_path", ",", "dev_file_path", ")", "\n", "get_train_dev_files", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ",", "train_file_path", ",", "\n", "dev_file_path", ",", "args", ".", "split_by_ids", ",", "args", ".", "dev_size", ",", "args", ".", "random_state", ",", "args", ".", "balance", ",", "\n", "args", ".", "shuffle", ")", "\n", "\n", "", "", "if", "args", ".", "do_predict", "or", "args", ".", "create_submission_file", "or", "args", ".", "eval_submission", ":", "\n", "        ", "test_file_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "test_file", ")", "\n", "test_articles", ",", "test_articles_id", ",", "test_span_starts", ",", "test_span_ends", ",", "test_labels", "=", "load_data", "(", "args", ".", "test_data_folder", ",", "\n", "args", ".", "test_template_labels_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "test_file_path", ")", "or", "args", ".", "overwrite_cache", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating roberta-type test file: %s\"", ",", "test_file_path", ")", "\n", "get_test_file", "(", "test_articles", ",", "test_articles_id", ",", "test_span_starts", ",", "test_span_ends", ",", "test_labels", ",", "test_file_path", ")", "\n", "\n", "", "", "if", "args", ".", "do_train", "or", "args", ".", "do_eval", "or", "args", ".", "do_predict", ":", "\n", "        ", "transformers_clf", "(", "args", ")", "\n", "\n", "", "if", "args", ".", "create_submission_file", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "'results'", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "'results'", ")", "\n", "", "output_file", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "args", ".", "output_file", ")", "\n", "logger", ".", "info", "(", "\"Creating the submission file: %s\"", ",", "output_file", ")", "\n", "create_submission_file", "(", "args", ".", "predicted_logits_files", ",", "train_file_path", ",", "dev_file_path", ",", "test_file_path", ",", "\n", "test_articles_id", ",", "test_span_starts", ",", "test_span_ends", ",", "output_file", ",", "args", ".", "weights", ",", "args", ".", "data_dir", ")", "\n", "\n", "", "if", "args", ".", "eval_submission", ":", "\n", "        ", "output_file", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "args", ".", "output_file", ")", "\n", "logger", ".", "info", "(", "\"Evaluating the submission file: %s\"", ",", "output_file", ")", "\n", "if", "args", ".", "test_labels_path", "is", "None", ":", "\n", "            ", "acc", ",", "f1", "=", "eval_submission", "(", "output_file", ",", "test_file_path", ")", "\n", "logger", ".", "info", "(", "'accuracy: %f'", ",", "acc", ")", "\n", "print", "(", "'f1-macro:'", ",", "f1", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "\"python tools/task-TC_scorer.py -s {} -r {} -p {}\"", ".", "format", "(", "output_file", ",", "args", ".", "test_labels_path", ",", "\n", "args", ".", "propaganda_techniques_file", ")", "\n", "subprocess", ".", "run", "(", "cmd", ",", "shell", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.technique_classification.__main__.main": [[66, 194], ["configargparse.ArgumentParser", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.parse_args", "logging.basicConfig", "__main__.Main"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.__main__.Main"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "configargparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "required", "=", "True", ",", "is_config_file", "=", "True", ",", "help", "=", "'Config file path.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_data_folder\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Source directory with the train articles.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_folder\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Source directory with the test articles.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--propaganda_techniques_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The file with propaganda techniques.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--labels_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The file with train labels.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_template_labels_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The file with test template labels.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The directory for cached preprocessed data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The filename for cached preprocessed train data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The filename for cached preprocessed dev data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The filename for cached preprocessed test data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--predicted_logits_files\"", ",", "default", "=", "None", ",", "nargs", "=", "'*'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The predicted filenames of logits that will be used to obtain the final result\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weights\"", ",", "default", "=", "None", ",", "nargs", "=", "'*'", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The list of weights for predicted logits at the aggregation stage\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The submission filename\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_size\"", ",", "default", "=", "0.3", ",", "type", "=", "float", ",", "help", "=", "\"Dev data size.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--split_dataset\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Split the dataset into the train/dev parts.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--split_by_ids\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use articles ids while splitting the dataset into the train/dev parts.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--random_state\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "'Random state for the dataset splitting.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--shuffle\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Shuffle the train dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--balance\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Balance the train dataset with oversampling.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--create_submission_file\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Creats file in the submission (source) format\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_submission\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Do evaluating for the dev subset.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_length'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--join_embeddings'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_matchings'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "MODEL_CLASSES", "=", "[", "\"bert\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_labels_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "False", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run prediction\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "logging", ".", "basicConfig", "(", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "\n", "Main", "(", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.__init__": [[195, 222], ["torch.nn.Module.__init__", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "XLNetLayerNorm", "torch.nn.Dropout", "ValueError", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetRelativeAttention", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "\n", "if", "config", ".", "d_model", "%", "config", ".", "n_head", "!=", "0", ":", "\n", "            ", "raise", "ValueError", "(", "\n", "\"The hidden size (%d) is not a multiple of the number of attention \"", "\n", "\"heads (%d)\"", "%", "(", "config", ".", "d_model", ",", "config", ".", "n_head", ")", ")", "\n", "\n", "", "self", ".", "n_head", "=", "config", ".", "n_head", "\n", "self", ".", "d_head", "=", "config", ".", "d_head", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "scale", "=", "1", "/", "(", "config", ".", "d_head", "**", "0.5", ")", "\n", "\n", "self", ".", "q", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "k", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "v", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "o", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "config", ".", "d_model", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "r_r_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_s_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "r_w_bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "self", ".", "seg_embed", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "2", ",", "self", ".", "n_head", ",", "self", ".", "d_head", ")", ")", "\n", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.prune_heads": [[223, 225], ["None"], "methods", ["None"], ["", "def", "prune_heads", "(", "self", ",", "heads", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_shift": [[226, 238], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "\"\"\"perform relative shift to form the relative attention score.\"\"\"", "\n", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "1", "]", ",", "x_size", "[", "0", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "x", "=", "x", "[", "1", ":", ",", "...", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", "-", "1", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", ")", "\n", "# x = x[:, 0:klen, :, :]", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "1", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij": [[239, 253], ["torch.index_select.reshape", "torch.index_select.reshape", "torch.index_select", "torch.arange"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "rel_shift_bnij", "(", "x", ",", "klen", "=", "-", "1", ")", ":", "\n", "        ", "x_size", "=", "x", ".", "shape", "\n", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", ",", "x_size", "[", "3", "]", ",", "x_size", "[", "2", "]", ")", "\n", "x", "=", "x", "[", ":", ",", ":", ",", "1", ":", ",", ":", "]", "\n", "x", "=", "x", ".", "reshape", "(", "x_size", "[", "0", "]", ",", "x_size", "[", "1", "]", ",", "x_size", "[", "2", "]", ",", "x_size", "[", "3", "]", "-", "1", ")", "\n", "# Note: the tensor-slice form was faster in my testing than torch.index_select", "\n", "#       However, tracing doesn't like the nature of the slice, and if klen changes", "\n", "#       during the run then it'll fail, whereas index_select will be fine.", "\n", "x", "=", "torch", ".", "index_select", "(", "x", ",", "3", ",", "torch", ".", "arange", "(", "klen", ",", "device", "=", "x", ".", "device", ",", "dtype", "=", "torch", ".", "long", ")", ")", "\n", "# x = x[:, :, :, :klen]", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_attn_core": [[254, 295], ["torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij", "torch.nn.functional.softmax", "modeling_xlnet.XLNetRelativeAttention.dropout", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_shift_bnij"], ["", "def", "rel_attn_core", "(", "self", ",", "q_head", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "None", ",", "attn_mask", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "\"\"\"Core relative positional attention operations.\"\"\"", "\n", "\n", "# content based attention score", "\n", "ac", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->bnij'", ",", "q_head", "+", "self", ".", "r_w_bias", ",", "k_head_h", ")", "\n", "\n", "# position based attention score", "\n", "bd", "=", "torch", ".", "einsum", "(", "'ibnd,jbnd->bnij'", ",", "q_head", "+", "self", ".", "r_r_bias", ",", "k_head_r", ")", "\n", "bd", "=", "self", ".", "rel_shift_bnij", "(", "bd", ",", "klen", "=", "ac", ".", "shape", "[", "3", "]", ")", "\n", "\n", "# segment based attention score", "\n", "if", "seg_mat", "is", "None", ":", "\n", "            ", "ef", "=", "0", "\n", "", "else", ":", "\n", "            ", "ef", "=", "torch", ".", "einsum", "(", "'ibnd,snd->ibns'", ",", "q_head", "+", "self", ".", "r_s_bias", ",", "self", ".", "seg_embed", ")", "\n", "ef", "=", "torch", ".", "einsum", "(", "'ijbs,ibns->bnij'", ",", "seg_mat", ",", "ef", ")", "\n", "\n", "# merge attention scores and perform masking", "\n", "", "attn_score", "=", "(", "ac", "+", "bd", "+", "ef", ")", "*", "self", ".", "scale", "\n", "if", "attn_mask", "is", "not", "None", ":", "\n", "# attn_score = attn_score * (1 - attn_mask) - 1e30 * attn_mask", "\n", "            ", "if", "attn_mask", ".", "dtype", "==", "torch", ".", "float16", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "65500", "*", "torch", ".", "einsum", "(", "'ijbn->bnij'", ",", "attn_mask", ")", "\n", "", "else", ":", "\n", "                ", "attn_score", "=", "attn_score", "-", "1e30", "*", "torch", ".", "einsum", "(", "'ijbn->bnij'", ",", "attn_mask", ")", "\n", "\n", "# attention probability", "\n", "", "", "attn_prob", "=", "F", ".", "softmax", "(", "attn_score", ",", "dim", "=", "3", ")", "\n", "attn_prob", "=", "self", ".", "dropout", "(", "attn_prob", ")", "\n", "\n", "# Mask heads if we want to", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "attn_prob", "=", "attn_prob", "*", "torch", ".", "einsum", "(", "'ijbn->bnij'", ",", "head_mask", ")", "\n", "\n", "# attention output", "\n", "", "attn_vec", "=", "torch", ".", "einsum", "(", "'bnij,jbnd->ibnd'", ",", "attn_prob", ",", "v_head_h", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "return", "attn_vec", ",", "torch", ".", "einsum", "(", "'bnij->ijbn'", ",", "attn_prob", ")", "\n", "\n", "", "return", "attn_vec", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.post_attention": [[296, 307], ["torch.einsum", "modeling_xlnet.XLNetRelativeAttention.dropout", "modeling_xlnet.XLNetRelativeAttention.layer_norm"], "methods", ["None"], ["", "def", "post_attention", "(", "self", ",", "h", ",", "attn_vec", ",", "residual", "=", "True", ")", ":", "\n", "        ", "\"\"\"Post-attention processing.\"\"\"", "\n", "# post-attention projection (back to `d_model`)", "\n", "attn_out", "=", "torch", ".", "einsum", "(", "'ibnd,hnd->ibh'", ",", "attn_vec", ",", "self", ".", "o", ")", "\n", "\n", "attn_out", "=", "self", ".", "dropout", "(", "attn_out", ")", "\n", "if", "residual", ":", "\n", "            ", "attn_out", "=", "attn_out", "+", "h", "\n", "", "output", "=", "self", ".", "layer_norm", "(", "attn_out", ")", "\n", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.forward": [[308, 400], ["torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "modeling_xlnet.XLNetRelativeAttention.post_attention", "torch.cat", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.einsum", "modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "torch.cat", "mems.dim", "mems.dim"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.post_attention", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_attn_core", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetRelativeAttention.rel_attn_core"], ["", "def", "forward", "(", "self", ",", "h", ",", "g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "\n", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "###### Two-stream attention with relative positional encoding.", "\n", "# content based attention score", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content-based key head", "\n", "", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "\n", "# content-based value head", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# position-based key head", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "##### h-stream", "\n", "# content-stream query head", "\n", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec_h", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec_h", ",", "attn_prob_h", "=", "attn_vec_h", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec_h", ")", "\n", "\n", "##### g-stream", "\n", "# query-stream query head", "\n", "q_head_g", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "g", ",", "self", ".", "q", ")", "\n", "\n", "# core attention ops", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "                ", "q_head_g", "=", "torch", ".", "einsum", "(", "'mbnd,mlb->lbnd'", ",", "q_head_g", ",", "target_mapping", ")", "\n", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "", "attn_vec_g", "=", "torch", ".", "einsum", "(", "'lbnd,mlb->mbnd'", ",", "attn_vec_g", ",", "target_mapping", ")", "\n", "", "else", ":", "\n", "                ", "attn_vec_g", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_g", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_g", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                    ", "attn_vec_g", ",", "attn_prob_g", "=", "attn_vec_g", "\n", "\n", "# post processing", "\n", "", "", "output_g", "=", "self", ".", "post_attention", "(", "g", ",", "attn_vec_g", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_prob", "=", "attn_prob_h", ",", "attn_prob_g", "\n", "\n", "", "", "else", ":", "\n", "###### Multi-head attention with relative positional encoding", "\n", "            ", "if", "mems", "is", "not", "None", "and", "mems", ".", "dim", "(", ")", ">", "1", ":", "\n", "                ", "cat", "=", "torch", ".", "cat", "(", "[", "mems", ",", "h", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat", "=", "h", "\n", "\n", "# content heads", "\n", "", "q_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "h", ",", "self", ".", "q", ")", "\n", "k_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "k", ")", "\n", "v_head_h", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "cat", ",", "self", ".", "v", ")", "\n", "\n", "# positional heads", "\n", "k_head_r", "=", "torch", ".", "einsum", "(", "'ibh,hnd->ibnd'", ",", "r", ",", "self", ".", "r", ")", "\n", "\n", "# core attention ops", "\n", "attn_vec", "=", "self", ".", "rel_attn_core", "(", "\n", "q_head_h", ",", "k_head_h", ",", "v_head_h", ",", "k_head_r", ",", "seg_mat", "=", "seg_mat", ",", "attn_mask", "=", "attn_mask_h", ",", "head_mask", "=", "head_mask", ")", "\n", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attn_vec", ",", "attn_prob", "=", "attn_vec", "\n", "\n", "# post processing", "\n", "", "output_h", "=", "self", ".", "post_attention", "(", "h", ",", "attn_vec", ")", "\n", "output_g", "=", "None", "\n", "\n", "", "outputs", "=", "(", "output_h", ",", "output_g", ")", "\n", "if", "self", ".", "output_attentions", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "attn_prob", ",", ")", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetFeedForward.__init__": [[402, 413], ["torch.nn.Module.__init__", "XLNetLayerNorm", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Dropout", "isinstance", "isinstance"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetFeedForward", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "layer_norm", "=", "XLNetLayerNorm", "(", "config", ".", "d_model", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "self", ".", "layer_1", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "d_inner", ")", "\n", "self", ".", "layer_2", "=", "nn", ".", "Linear", "(", "config", ".", "d_inner", ",", "config", ".", "d_model", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "if", "isinstance", "(", "config", ".", "ff_activation", ",", "str", ")", "or", "(", "sys", ".", "version_info", "[", "0", "]", "==", "2", "and", "isinstance", "(", "config", ".", "ff_activation", ",", "unicode", ")", ")", ":", "\n", "            ", "self", ".", "activation_function", "=", "ACT2FN", "[", "config", ".", "ff_activation", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "activation_function", "=", "config", ".", "ff_activation", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetFeedForward.forward": [[414, 423], ["modeling_xlnet.XLNetFeedForward.layer_1", "modeling_xlnet.XLNetFeedForward.activation_function", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_2", "modeling_xlnet.XLNetFeedForward.dropout", "modeling_xlnet.XLNetFeedForward.layer_norm"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "inp", ")", ":", "\n", "        ", "output", "=", "inp", "\n", "output", "=", "self", ".", "layer_1", "(", "output", ")", "\n", "output", "=", "self", ".", "activation_function", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_2", "(", "output", ")", "\n", "output", "=", "self", ".", "dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "layer_norm", "(", "output", "+", "inp", ")", "\n", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetLayer.__init__": [[425, 430], ["torch.nn.Module.__init__", "modeling_xlnet.XLNetRelativeAttention", "modeling_xlnet.XLNetFeedForward", "torch.nn.Dropout"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["    ", "def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLayer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "rel_attn", "=", "XLNetRelativeAttention", "(", "config", ")", "\n", "self", ".", "ff", "=", "XLNetFeedForward", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetLayer.forward": [[431, 445], ["modeling_xlnet.XLNetLayer.rel_attn", "modeling_xlnet.XLNetLayer.ff", "modeling_xlnet.XLNetLayer.ff"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output_h", ",", "output_g", ",", "\n", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "None", ",", "target_mapping", "=", "None", ",", "head_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "rel_attn", "(", "output_h", ",", "output_g", ",", "attn_mask_h", ",", "attn_mask_g", ",", "\n", "r", ",", "seg_mat", ",", "mems", "=", "mems", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "output_g", "is", "not", "None", ":", "\n", "            ", "output_g", "=", "self", ".", "ff", "(", "output_g", ")", "\n", "", "output_h", "=", "self", ".", "ff", "(", "output_h", ")", "\n", "\n", "outputs", "=", "(", "output_h", ",", "output_g", ")", "+", "outputs", "[", "2", ":", "]", "# Add again attentions if there are there", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetPreTrainedModel._init_weights": [[456, 475], ["isinstance", "module.weight.data.normal_", "isinstance", "isinstance", "module.bias.data.zero_", "module.bias.data.zero_", "module.weight.data.fill_", "isinstance", "isinstance", "param.data.normal_", "module.mask_emb.data.normal_"], "methods", ["None"], ["def", "_init_weights", "(", "self", ",", "module", ")", ":", "\n", "        ", "\"\"\" Initialize the weights.\n        \"\"\"", "\n", "if", "isinstance", "(", "module", ",", "(", "nn", ".", "Linear", ",", "nn", ".", "Embedding", ")", ")", ":", "\n", "# Slightly different from the TF version which uses truncated_normal for initialization", "\n", "# cf https://github.com/pytorch/pytorch/pull/5617", "\n", "            ", "module", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "if", "isinstance", "(", "module", ",", "nn", ".", "Linear", ")", "and", "module", ".", "bias", "is", "not", "None", ":", "\n", "                ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetLayerNorm", ")", ":", "\n", "            ", "module", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "module", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", ")", "\n", "", "elif", "isinstance", "(", "module", ",", "XLNetRelativeAttention", ")", ":", "\n", "            ", "for", "param", "in", "[", "module", ".", "q", ",", "module", ".", "k", ",", "module", ".", "v", ",", "module", ".", "o", ",", "module", ".", "r", ",", "\n", "module", ".", "r_r_bias", ",", "module", ".", "r_s_bias", ",", "module", ".", "r_w_bias", ",", "\n", "module", ".", "seg_embed", "]", ":", "\n", "                ", "param", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "", "", "elif", "isinstance", "(", "module", ",", "XLNetModel", ")", ":", "\n", "                ", "module", ".", "mask_emb", ".", "data", ".", "normal_", "(", "mean", "=", "0.0", ",", "std", "=", "self", ".", "config", ".", "initializer_range", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.__init__": [[597, 618], ["transformers.modeling_utils.PreTrainedModel.__init__", "torch.nn.Embedding", "torch.nn.Parameter", "torch.nn.ModuleList", "torch.nn.Dropout", "modeling_xlnet.XLNetModel.init_weights", "torch.FloatTensor", "modeling_xlnet.XLNetLayer", "range"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "output_attentions", "=", "config", ".", "output_attentions", "\n", "self", ".", "output_hidden_states", "=", "config", ".", "output_hidden_states", "\n", "self", ".", "output_past", "=", "config", ".", "output_past", "\n", "\n", "self", ".", "mem_len", "=", "config", ".", "mem_len", "\n", "self", ".", "reuse_len", "=", "config", ".", "reuse_len", "\n", "self", ".", "d_model", "=", "config", ".", "d_model", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "bi_data", "=", "config", ".", "bi_data", "\n", "self", ".", "clamp_len", "=", "config", ".", "clamp_len", "\n", "self", ".", "n_layer", "=", "config", ".", "n_layer", "\n", "\n", "self", ".", "word_embedding", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "d_model", ")", "\n", "self", ".", "mask_emb", "=", "nn", ".", "Parameter", "(", "torch", ".", "FloatTensor", "(", "1", ",", "1", ",", "config", ".", "d_model", ")", ")", "\n", "self", ".", "layer", "=", "nn", ".", "ModuleList", "(", "[", "XLNetLayer", "(", "config", ")", "for", "_", "in", "range", "(", "config", ".", "n_layer", ")", "]", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "dropout", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.get_input_embeddings": [[619, 621], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "word_embedding", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.set_input_embeddings": [[622, 624], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "new_embeddings", ")", ":", "\n", "        ", "self", ".", "word_embedding", "=", "new_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel._prune_heads": [[625, 627], ["None"], "methods", ["None"], ["", "def", "_prune_heads", "(", "self", ",", "heads_to_prune", ")", ":", "\n", "        ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.create_mask": [[628, 657], ["torch.ones", "torch.triu", "torch.zeros", "torch.cat", "torch.cat.to", "torch.tril", "torch.cat", "next", "modeling_xlnet.XLNetModel.parameters"], "methods", ["None"], ["", "def", "create_mask", "(", "self", ",", "qlen", ",", "mlen", ")", ":", "\n", "        ", "\"\"\"\n        Creates causal attention mask. Float mask where 1.0 indicates masked, 0.0 indicates not-masked.\n\n        Args:\n            qlen: TODO Lysandre didn't fill\n            mlen: TODO Lysandre didn't fill\n\n        ::\n\n                  same_length=False:      same_length=True:\n                  <mlen > <  qlen >       <mlen > <  qlen >\n               ^ [0 0 0 0 0 1 1 1 1]     [0 0 0 0 0 1 1 1 1]\n                 [0 0 0 0 0 0 1 1 1]     [1 0 0 0 0 0 1 1 1]\n            qlen [0 0 0 0 0 0 0 1 1]     [1 1 0 0 0 0 0 1 1]\n                 [0 0 0 0 0 0 0 0 1]     [1 1 1 0 0 0 0 0 1]\n               v [0 0 0 0 0 0 0 0 0]     [1 1 1 1 0 0 0 0 0]\n\n        \"\"\"", "\n", "attn_mask", "=", "torch", ".", "ones", "(", "[", "qlen", ",", "qlen", "]", ")", "\n", "mask_up", "=", "torch", ".", "triu", "(", "attn_mask", ",", "diagonal", "=", "1", ")", "\n", "attn_mask_pad", "=", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "attn_mask_pad", ",", "mask_up", "]", ",", "dim", "=", "1", ")", "\n", "if", "self", ".", "same_length", ":", "\n", "            ", "mask_lo", "=", "torch", ".", "tril", "(", "attn_mask", ",", "diagonal", "=", "-", "1", ")", "\n", "ret", "=", "torch", ".", "cat", "(", "[", "ret", "[", ":", ",", ":", "qlen", "]", "+", "mask_lo", ",", "ret", "[", ":", ",", "qlen", ":", "]", "]", ",", "dim", "=", "1", ")", "\n", "\n", "", "ret", "=", "ret", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.cache_mem": [[658, 669], ["new_mem.detach", "torch.cat"], "methods", ["None"], ["", "def", "cache_mem", "(", "self", ",", "curr_out", ",", "prev_mem", ")", ":", "\n", "        ", "\"\"\"cache hidden states into memory.\"\"\"", "\n", "if", "self", ".", "reuse_len", "is", "not", "None", "and", "self", ".", "reuse_len", ">", "0", ":", "\n", "            ", "curr_out", "=", "curr_out", "[", ":", "self", ".", "reuse_len", "]", "\n", "\n", "", "if", "prev_mem", "is", "None", ":", "\n", "            ", "new_mem", "=", "curr_out", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "", "else", ":", "\n", "            ", "new_mem", "=", "torch", ".", "cat", "(", "[", "prev_mem", ",", "curr_out", "]", ",", "dim", "=", "0", ")", "[", "-", "self", ".", "mem_len", ":", "]", "\n", "\n", "", "return", "new_mem", ".", "detach", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.positional_embedding": [[670, 680], ["torch.einsum", "torch.cat", "pos_emb.expand.expand.expand", "torch.sin", "torch.cos"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "positional_embedding", "(", "pos_seq", ",", "inv_freq", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "sinusoid_inp", "=", "torch", ".", "einsum", "(", "'i,d->id'", ",", "pos_seq", ",", "inv_freq", ")", "\n", "pos_emb", "=", "torch", ".", "cat", "(", "[", "torch", ".", "sin", "(", "sinusoid_inp", ")", ",", "torch", ".", "cos", "(", "sinusoid_inp", ")", "]", ",", "dim", "=", "-", "1", ")", "\n", "pos_emb", "=", "pos_emb", "[", ":", ",", "None", ",", ":", "]", "\n", "\n", "if", "bsz", "is", "not", "None", ":", "\n", "            ", "pos_emb", "=", "pos_emb", ".", "expand", "(", "-", "1", ",", "bsz", ",", "-", "1", ")", "\n", "\n", "", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.relative_positional_encoding": [[681, 719], ["torch.arange", "modeling_xlnet.XLNetModel.to", "torch.pow", "torch.arange", "torch.arange", "torch.cat", "torch.arange", "modeling_xlnet.XLNetModel.positional_embedding", "next", "ValueError", "fwd_pos_seq.clamp.clamp.clamp", "bwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "modeling_xlnet.XLNetModel.positional_embedding", "fwd_pos_seq.clamp.clamp.clamp", "modeling_xlnet.XLNetModel.parameters"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.positional_embedding", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.positional_embedding"], ["", "def", "relative_positional_encoding", "(", "self", ",", "qlen", ",", "klen", ",", "bsz", "=", "None", ")", ":", "\n", "        ", "\"\"\"create relative positional encoding.\"\"\"", "\n", "freq_seq", "=", "torch", ".", "arange", "(", "0", ",", "self", ".", "d_model", ",", "2.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "inv_freq", "=", "1", "/", "torch", ".", "pow", "(", "10000", ",", "(", "freq_seq", "/", "self", ".", "d_model", ")", ")", "\n", "\n", "if", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "# beg, end = klen - 1, -qlen", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "qlen", "\n", "", "elif", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "# beg, end = klen - 1, -1", "\n", "            ", "beg", ",", "end", "=", "klen", ",", "-", "1", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown `attn_type` {}.'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "", "if", "self", ".", "bi_data", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "bwd_pos_seq", "=", "torch", ".", "arange", "(", "-", "beg", ",", "-", "end", ",", "1.0", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "bwd_pos_seq", "=", "bwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "\n", "", "if", "bsz", "is", "not", "None", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ",", "bsz", "//", "2", ")", "\n", "", "else", ":", "\n", "                ", "fwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ")", "\n", "bwd_pos_emb", "=", "self", ".", "positional_embedding", "(", "bwd_pos_seq", ",", "inv_freq", ")", "\n", "\n", "", "pos_emb", "=", "torch", ".", "cat", "(", "[", "fwd_pos_emb", ",", "bwd_pos_emb", "]", ",", "dim", "=", "1", ")", "\n", "", "else", ":", "\n", "            ", "fwd_pos_seq", "=", "torch", ".", "arange", "(", "beg", ",", "end", ",", "-", "1.0", ")", "\n", "if", "self", ".", "clamp_len", ">", "0", ":", "\n", "                ", "fwd_pos_seq", "=", "fwd_pos_seq", ".", "clamp", "(", "-", "self", ".", "clamp_len", ",", "self", ".", "clamp_len", ")", "\n", "", "pos_emb", "=", "self", ".", "positional_embedding", "(", "fwd_pos_seq", ",", "inv_freq", ",", "bsz", ")", "\n", "\n", "", "pos_emb", "=", "pos_emb", ".", "to", "(", "next", "(", "self", ".", "parameters", "(", ")", ")", ")", "\n", "return", "pos_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.forward": [[720, 890], ["modeling_xlnet.XLNetModel.dropout", "modeling_xlnet.XLNetModel.relative_positional_encoding", "modeling_xlnet.XLNetModel.dropout", "enumerate", "modeling_xlnet.XLNetModel.dropout", "ValueError", "token_type_ids.transpose().contiguous", "input_mask.transpose().contiguous", "attention_mask.transpose().contiguous", "perm_mask.permute().contiguous", "target_mapping.permute().contiguous", "next", "next", "modeling_xlnet.XLNetModel.create_mask", "modeling_xlnet.XLNetModel.word_embedding", "modeling_xlnet.XLNetModel.mask_emb.expand", "modeling_xlnet.XLNetModel.dropout", "torch.nn.functional.one_hot().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.to", "layer_module", "tuple.append", "modeling_xlnet.XLNetModel.permute().contiguous", "input_ids.transpose().contiguous.transpose().contiguous.transpose().contiguous", "modeling_xlnet.XLNetModel.parameters", "modeling_xlnet.XLNetModel.parameters", "ValueError", "torch.zeros().to", "torch.cat", "torch.eye().to", "torch.cat", "torch.zeros", "torch.cat", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze().unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.expand", "len", "tuple.append", "tuple.append", "tuple", "tuple", "tuple", "tuple", "inputs_embeds.transpose().contiguous", "ValueError", "token_type_ids.transpose", "input_mask.transpose", "attention_mask.transpose", "perm_mask.permute", "target_mapping.permute", "torch.nn.functional.one_hot", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.dim", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.permute", "input_ids.transpose().contiguous.transpose().contiguous.transpose", "torch.zeros", "torch.eye", "torch.zeros().to", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze", "next", "modeling_xlnet.XLNetModel.cache_mem", "h.permute().contiguous", "hs.permute().contiguous", "tuple", "t.permute().contiguous", "inputs_embeds.transpose", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "modeling_xlnet.XLNetModel.parameters", "torch.zeros", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze", "h.permute", "hs.permute", "att_stream.permute().contiguous", "t.permute", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "head_mask.unsqueeze().unsqueeze().unsqueeze.unsqueeze().unsqueeze().unsqueeze.unsqueeze", "att_stream.permute"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.relative_positional_encoding", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.create_mask", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetModel.cache_mem"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "# the original code for XLNet uses shapes [len, bsz] with the batch dimension at the end", "\n", "# but we want a unified interface in the library with the batch size on the first dimension", "\n", "# so we move here the first dimension (batch) to the end", "\n", "        ", "if", "input_ids", "is", "not", "None", "and", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "raise", "ValueError", "(", "\"You cannot specify both input_ids and inputs_embeds at the same time\"", ")", "\n", "", "elif", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_ids", "=", "input_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "qlen", ",", "bsz", "=", "input_ids", ".", "shape", "[", "0", "]", ",", "input_ids", ".", "shape", "[", "1", "]", "\n", "", "elif", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "inputs_embeds", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "qlen", ",", "bsz", "=", "inputs_embeds", ".", "shape", "[", "0", "]", ",", "inputs_embeds", ".", "shape", "[", "1", "]", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "\"You have to specify either input_ids or inputs_embeds\"", ")", "\n", "\n", "", "token_type_ids", "=", "token_type_ids", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "input_mask", "=", "input_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "attention_mask", "=", "attention_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "perm_mask", "=", "perm_mask", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "perm_mask", "is", "not", "None", "else", "None", "\n", "target_mapping", "=", "target_mapping", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "contiguous", "(", ")", "if", "target_mapping", "is", "not", "None", "else", "None", "\n", "\n", "\n", "mlen", "=", "mems", "[", "0", "]", ".", "shape", "[", "0", "]", "if", "mems", "is", "not", "None", "and", "mems", "[", "0", "]", "is", "not", "None", "else", "0", "\n", "klen", "=", "mlen", "+", "qlen", "\n", "\n", "dtype_float", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", "\n", "device", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "device", "\n", "\n", "##### Attention mask", "\n", "# causal attention mask", "\n", "if", "self", ".", "attn_type", "==", "'uni'", ":", "\n", "            ", "attn_mask", "=", "self", ".", "create_mask", "(", "qlen", ",", "mlen", ")", "\n", "attn_mask", "=", "attn_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", "\n", "", "elif", "self", ".", "attn_type", "==", "'bi'", ":", "\n", "            ", "attn_mask", "=", "None", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unsupported attention type: {}'", ".", "format", "(", "self", ".", "attn_type", ")", ")", "\n", "\n", "# data mask: input mask & perm mask", "\n", "", "assert", "input_mask", "is", "None", "or", "attention_mask", "is", "None", ",", "\"You can only use one of input_mask (uses 1 for padding) \"", "\n", "\"or attention_mask (uses 0 for padding, added for compatbility with BERT). Please choose one.\"", "\n", "if", "input_mask", "is", "None", "and", "attention_mask", "is", "not", "None", ":", "\n", "            ", "input_mask", "=", "1.0", "-", "attention_mask", "\n", "", "if", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "+", "perm_mask", "\n", "", "elif", "input_mask", "is", "not", "None", "and", "perm_mask", "is", "None", ":", "\n", "            ", "data_mask", "=", "input_mask", "[", "None", "]", "\n", "", "elif", "input_mask", "is", "None", "and", "perm_mask", "is", "not", "None", ":", "\n", "            ", "data_mask", "=", "perm_mask", "\n", "", "else", ":", "\n", "            ", "data_mask", "=", "None", "\n", "\n", "", "if", "data_mask", "is", "not", "None", ":", "\n", "# all mems can be attended to", "\n", "            ", "if", "mlen", ">", "0", ":", "\n", "                ", "mems_mask", "=", "torch", ".", "zeros", "(", "[", "data_mask", ".", "shape", "[", "0", "]", ",", "mlen", ",", "bsz", "]", ")", ".", "to", "(", "data_mask", ")", "\n", "data_mask", "=", "torch", ".", "cat", "(", "[", "mems_mask", ",", "data_mask", "]", ",", "dim", "=", "1", ")", "\n", "", "if", "attn_mask", "is", "None", ":", "\n", "                ", "attn_mask", "=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "", "else", ":", "\n", "                ", "attn_mask", "+=", "data_mask", "[", ":", ",", ":", ",", ":", ",", "None", "]", "\n", "\n", "", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "attn_mask", "=", "(", "attn_mask", ">", "0", ")", ".", "to", "(", "dtype_float", ")", "\n", "\n", "", "if", "attn_mask", "is", "not", "None", ":", "\n", "            ", "non_tgt_mask", "=", "-", "torch", ".", "eye", "(", "qlen", ")", ".", "to", "(", "attn_mask", ")", "\n", "if", "mlen", ">", "0", ":", "\n", "                ", "non_tgt_mask", "=", "torch", ".", "cat", "(", "[", "torch", ".", "zeros", "(", "[", "qlen", ",", "mlen", "]", ")", ".", "to", "(", "attn_mask", ")", ",", "non_tgt_mask", "]", ",", "dim", "=", "-", "1", ")", "\n", "", "non_tgt_mask", "=", "(", "(", "attn_mask", "+", "non_tgt_mask", "[", ":", ",", ":", ",", "None", ",", "None", "]", ")", ">", "0", ")", ".", "to", "(", "attn_mask", ")", "\n", "", "else", ":", "\n", "            ", "non_tgt_mask", "=", "None", "\n", "\n", "##### Word embeddings and prepare h & g hidden states", "\n", "", "if", "inputs_embeds", "is", "not", "None", ":", "\n", "            ", "word_emb_k", "=", "inputs_embeds", "\n", "", "else", ":", "\n", "            ", "word_emb_k", "=", "self", ".", "word_embedding", "(", "input_ids", ")", "\n", "", "output_h", "=", "self", ".", "dropout", "(", "word_emb_k", ")", "\n", "if", "target_mapping", "is", "not", "None", ":", "\n", "            ", "word_emb_q", "=", "self", ".", "mask_emb", ".", "expand", "(", "target_mapping", ".", "shape", "[", "0", "]", ",", "bsz", ",", "-", "1", ")", "\n", "# else:  # We removed the inp_q input which was same as target mapping", "\n", "#     inp_q_ext = inp_q[:, :, None]", "\n", "#     word_emb_q = inp_q_ext * self.mask_emb + (1 - inp_q_ext) * word_emb_k", "\n", "output_g", "=", "self", ".", "dropout", "(", "word_emb_q", ")", "\n", "", "else", ":", "\n", "            ", "output_g", "=", "None", "\n", "\n", "##### Segment embedding", "\n", "", "if", "token_type_ids", "is", "not", "None", ":", "\n", "# Convert `token_type_ids` to one-hot `seg_mat`", "\n", "            ", "if", "mlen", ">", "0", ":", "\n", "                ", "mem_pad", "=", "torch", ".", "zeros", "(", "[", "mlen", ",", "bsz", "]", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "cat_ids", "=", "torch", ".", "cat", "(", "[", "mem_pad", ",", "token_type_ids", "]", ",", "dim", "=", "0", ")", "\n", "", "else", ":", "\n", "                ", "cat_ids", "=", "token_type_ids", "\n", "\n", "# `1` indicates not in the same segment [qlen x klen x bsz]", "\n", "", "seg_mat", "=", "(", "token_type_ids", "[", ":", ",", "None", "]", "!=", "cat_ids", "[", "None", ",", ":", "]", ")", ".", "long", "(", ")", "\n", "seg_mat", "=", "F", ".", "one_hot", "(", "seg_mat", ",", "num_classes", "=", "2", ")", ".", "to", "(", "dtype_float", ")", "\n", "", "else", ":", "\n", "            ", "seg_mat", "=", "None", "\n", "\n", "##### Positional encoding", "\n", "", "pos_emb", "=", "self", ".", "relative_positional_encoding", "(", "qlen", ",", "klen", ",", "bsz", "=", "bsz", ")", "\n", "pos_emb", "=", "self", ".", "dropout", "(", "pos_emb", ")", "\n", "\n", "# Prepare head mask if needed", "\n", "# 1.0 in head_mask indicate we keep the head", "\n", "# attention_probs has shape bsz x n_heads x N x N", "\n", "# input head_mask has shape [num_heads] or [num_hidden_layers x num_heads] (a head_mask for each layer)", "\n", "# and head_mask is converted to shape [num_hidden_layers x qlen x klen x bsz x n_head]", "\n", "if", "head_mask", "is", "not", "None", ":", "\n", "            ", "if", "head_mask", ".", "dim", "(", ")", "==", "1", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", ".", "unsqueeze", "(", "0", ")", "\n", "head_mask", "=", "head_mask", ".", "expand", "(", "self", ".", "n_layer", ",", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", ")", "\n", "", "elif", "head_mask", ".", "dim", "(", ")", "==", "2", ":", "\n", "                ", "head_mask", "=", "head_mask", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "1", ")", "\n", "", "head_mask", "=", "head_mask", ".", "to", "(", "dtype", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "dtype", ")", "# switch to fload if need + fp16 compatibility", "\n", "", "else", ":", "\n", "            ", "head_mask", "=", "[", "None", "]", "*", "self", ".", "n_layer", "\n", "\n", "", "new_mems", "=", "(", ")", "\n", "if", "mems", "is", "None", ":", "\n", "            ", "mems", "=", "[", "None", "]", "*", "len", "(", "self", ".", "layer", ")", "\n", "\n", "", "attentions", "=", "[", "]", "\n", "hidden_states", "=", "[", "]", "\n", "for", "i", ",", "layer_module", "in", "enumerate", "(", "self", ".", "layer", ")", ":", "\n", "            ", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "# cache new mems", "\n", "                ", "new_mems", "=", "new_mems", "+", "(", "self", ".", "cache_mem", "(", "output_h", ",", "mems", "[", "i", "]", ")", ",", ")", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "                ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "outputs", "=", "layer_module", "(", "output_h", ",", "output_g", ",", "attn_mask_h", "=", "non_tgt_mask", ",", "attn_mask_g", "=", "attn_mask", ",", "\n", "r", "=", "pos_emb", ",", "seg_mat", "=", "seg_mat", ",", "mems", "=", "mems", "[", "i", "]", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", "[", "i", "]", ")", "\n", "output_h", ",", "output_g", "=", "outputs", "[", ":", "2", "]", "\n", "if", "self", ".", "output_attentions", ":", "\n", "                ", "attentions", ".", "append", "(", "outputs", "[", "2", "]", ")", "\n", "\n", "# Add last hidden state", "\n", "", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "hidden_states", ".", "append", "(", "(", "output_h", ",", "output_g", ")", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "", "output", "=", "self", ".", "dropout", "(", "output_g", "if", "output_g", "is", "not", "None", "else", "output_h", ")", "\n", "\n", "# Prepare outputs, we transpose back here to shape [bsz, len, hidden_dim] (cf. beginning of forward() method)", "\n", "outputs", "=", "(", "output", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", ",", ")", "\n", "\n", "if", "self", ".", "mem_len", "is", "not", "None", "and", "self", ".", "mem_len", ">", "0", "and", "self", ".", "output_past", ":", "\n", "            ", "outputs", "=", "outputs", "+", "(", "new_mems", ",", ")", "\n", "\n", "", "if", "self", ".", "output_hidden_states", ":", "\n", "            ", "if", "output_g", "is", "not", "None", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "h", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", "for", "h", "in", "hs", ")", "\n", "", "else", ":", "\n", "                ", "hidden_states", "=", "tuple", "(", "hs", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ".", "contiguous", "(", ")", "for", "hs", "in", "hidden_states", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "hidden_states", ",", ")", "\n", "", "if", "self", ".", "output_attentions", ":", "\n", "            ", "if", "target_mapping", "is", "not", "None", ":", "\n", "# when target_mapping is provided, there are 2-tuple of attentions", "\n", "                ", "attentions", "=", "tuple", "(", "tuple", "(", "att_stream", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "att_stream", "in", "t", ")", "for", "t", "in", "attentions", ")", "\n", "", "else", ":", "\n", "                ", "attentions", "=", "tuple", "(", "t", ".", "permute", "(", "2", ",", "3", ",", "0", ",", "1", ")", ".", "contiguous", "(", ")", "for", "t", "in", "attentions", ")", "\n", "", "outputs", "=", "outputs", "+", "(", "attentions", ",", ")", "\n", "\n", "", "return", "outputs", "# outputs, (new_mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetLMHeadModel.__init__": [[937, 946], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetLMHeadModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetLMHeadModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "attn_type", "=", "config", ".", "attn_type", "\n", "self", ".", "same_length", "=", "config", ".", "same_length", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "lm_loss", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "vocab_size", ",", "bias", "=", "True", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetLMHeadModel.get_output_embeddings": [[947, 949], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetLMHeadModel.forward": [[950, 974], ["modeling_xlnet.XLNetLMHeadModel.transformer", "modeling_xlnet.XLNetLMHeadModel.lm_loss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetLMHeadModel.view", "labels.view", "modeling_xlnet.XLNetLMHeadModel.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "logits", "=", "self", ".", "lm_loss", "(", "transformer_outputs", "[", "0", "]", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "# Flatten the tokens", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "logits", ".", "size", "(", "-", "1", ")", ")", ",", "\n", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForSequenceClassification.__init__": [[1016, 1025], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_xlnet.SequenceSummary", "torch.nn.Linear", "modeling_xlnet.XLNetForSequenceClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "logits_proj", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForSequenceClassification.forward": [[1026, 1056], ["modeling_xlnet.XLNetForSequenceClassification.transformer", "modeling_xlnet.XLNetForSequenceClassification.sequence_summary", "modeling_xlnet.XLNetForSequenceClassification.logits_proj", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view", "modeling_xlnet.XLNetForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ",", "\n", "lengths", "=", "None", ",", "matchings", "=", "None", ",", "embeddings_mask", "=", "None", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ",", "sent_a_length", "=", "lengths", ",", "embeddings_mask", "=", "embeddings_mask", ",", "matchings", "=", "matchings", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForTokenClassification.__init__": [[1115, 1123], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForTokenClassification.forward": [[1124, 1155], ["modeling_xlnet.XLNetForTokenClassification.transformer", "modeling_xlnet.XLNetForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_xlnet.XLNetForTokenClassification.view", "labels.view", "modeling_xlnet.XLNetForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForMultipleChoice.__init__": [[1219, 1227], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "modeling_xlnet.SequenceSummary", "torch.nn.Linear", "modeling_xlnet.XLNetForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "sequence_summary", "=", "SequenceSummary", "(", "config", ")", "\n", "self", ".", "logits_proj", "=", "nn", ".", "Linear", "(", "config", ".", "d_model", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForMultipleChoice.forward": [[1228, 1257], ["input_ids.view", "modeling_xlnet.XLNetForMultipleChoice.transformer", "modeling_xlnet.XLNetForMultipleChoice.sequence_summary", "modeling_xlnet.XLNetForMultipleChoice.logits_proj", "modeling_xlnet.XLNetForMultipleChoice.view", "input_ids.size", "token_type_ids.view", "attention_mask.view", "input_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "token_type_ids.size", "attention_mask.size", "input_mask.size", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "attention_mask", "=", "None", ",", "\n", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "labels", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "flat_input_mask", "=", "input_mask", ".", "view", "(", "-", "1", ",", "input_mask", ".", "size", "(", "-", "1", ")", ")", "if", "input_mask", "is", "not", "None", "else", "None", "\n", "\n", "transformer_outputs", "=", "self", ".", "transformer", "(", "flat_input_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "input_mask", "=", "flat_input_mask", ",", "attention_mask", "=", "flat_attention_mask", ",", "\n", "mems", "=", "mems", ",", "perm_mask", "=", "perm_mask", ",", "target_mapping", "=", "target_mapping", ",", "\n", "head_mask", "=", "head_mask", ",", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "\n", "output", "=", "transformer_outputs", "[", "0", "]", "\n", "\n", "output", "=", "self", ".", "sequence_summary", "(", "output", ")", "\n", "logits", "=", "self", ".", "logits_proj", "(", "output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# return (loss), logits, (mems), (hidden states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForQuestionAnsweringSimple.__init__": [[1305, 1313], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "torch.nn.Linear", "modeling_xlnet.XLNetForQuestionAnsweringSimple.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForQuestionAnsweringSimple", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "qa_outputs", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForQuestionAnsweringSimple.forward": [[1314, 1354], ["modeling_xlnet.XLNetForQuestionAnsweringSimple.transformer", "modeling_xlnet.XLNetForQuestionAnsweringSimple.qa_outputs", "modeling_xlnet.XLNetForQuestionAnsweringSimple.split", "start_logits.squeeze.squeeze.squeeze", "end_logits.squeeze.squeeze.squeeze", "start_logits.squeeze.squeeze.size", "start_positions.squeeze.squeeze.clamp_", "end_positions.squeeze.squeeze.clamp_", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "len", "start_positions.squeeze.squeeze.squeeze", "len", "end_positions.squeeze.squeeze.squeeze", "start_positions.squeeze.squeeze.size", "end_positions.squeeze.squeeze.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "qa_outputs", "(", "sequence_output", ")", "\n", "start_logits", ",", "end_logits", "=", "logits", ".", "split", "(", "1", ",", "dim", "=", "-", "1", ")", "\n", "start_logits", "=", "start_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "end_logits", "=", "end_logits", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "outputs", "=", "(", "start_logits", ",", "end_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, split add a dimension", "\n", "            ", "if", "len", "(", "start_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "start_positions", "=", "start_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "", "if", "len", "(", "end_positions", ".", "size", "(", ")", ")", ">", "1", ":", "\n", "                ", "end_positions", "=", "end_positions", ".", "squeeze", "(", "-", "1", ")", "\n", "# sometimes the start/end positions are outside our model inputs, we ignore these terms", "\n", "", "ignored_index", "=", "start_logits", ".", "size", "(", "1", ")", "\n", "start_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "end_positions", ".", "clamp_", "(", "0", ",", "ignored_index", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "ignored_index", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), start_logits, end_logits, (mems), (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForQuestionAnswering.__init__": [[1420, 1431], ["transformers.modeling_utils.PreTrainedModel.__init__", "modeling_xlnet.XLNetModel", "transformers.modeling_utils.PoolerStartLogits", "transformers.modeling_utils.PoolerEndLogits", "transformers.modeling_utils.PoolerAnswerClass", "modeling_xlnet.XLNetForQuestionAnswering.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "XLNetForQuestionAnswering", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "start_n_top", "=", "config", ".", "start_n_top", "\n", "self", ".", "end_n_top", "=", "config", ".", "end_n_top", "\n", "\n", "self", ".", "transformer", "=", "XLNetModel", "(", "config", ")", "\n", "self", ".", "start_logits", "=", "PoolerStartLogits", "(", "config", ")", "\n", "self", ".", "end_logits", "=", "PoolerEndLogits", "(", "config", ")", "\n", "self", ".", "answer_class", "=", "PoolerAnswerClass", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.XLNetForQuestionAnswering.forward": [[1432, 1501], ["modeling_xlnet.XLNetForQuestionAnswering.transformer", "modeling_xlnet.XLNetForQuestionAnswering.start_logits", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "hidden_states.size", "torch.nn.functional.softmax", "torch.topk", "start_top_index.unsqueeze().expand", "torch.gather", "torch.einsum.unsqueeze().expand", "hidden_states.unsqueeze().expand_as", "modeling_xlnet.XLNetForQuestionAnswering.end_logits", "torch.nn.functional.softmax", "torch.topk", "end_top_log_probs.view.view.view", "end_top_index.view.view.view", "torch.einsum", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "modeling_xlnet.XLNetForQuestionAnswering.answer_class", "torch.nn.BCEWithLogitsLoss", "torch.nn.BCEWithLogitsLoss.", "p_mask.unsqueeze", "x.squeeze_", "start_top_index.unsqueeze", "torch.einsum.unsqueeze", "hidden_states.unsqueeze", "x.dim"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "mems", "=", "None", ",", "perm_mask", "=", "None", ",", "target_mapping", "=", "None", ",", "\n", "token_type_ids", "=", "None", ",", "input_mask", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "\n", "start_positions", "=", "None", ",", "end_positions", "=", "None", ",", "is_impossible", "=", "None", ",", "cls_index", "=", "None", ",", "p_mask", "=", "None", ",", ")", ":", "\n", "        ", "transformer_outputs", "=", "self", ".", "transformer", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "mems", "=", "mems", ",", "\n", "perm_mask", "=", "perm_mask", ",", "\n", "target_mapping", "=", "target_mapping", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "hidden_states", "=", "transformer_outputs", "[", "0", "]", "\n", "start_logits", "=", "self", ".", "start_logits", "(", "hidden_states", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "outputs", "=", "transformer_outputs", "[", "1", ":", "]", "# Keep mems, hidden states, attentions if there are in it", "\n", "\n", "if", "start_positions", "is", "not", "None", "and", "end_positions", "is", "not", "None", ":", "\n", "# If we are on multi-GPU, let's remove the dimension added by batch splitting", "\n", "            ", "for", "x", "in", "(", "start_positions", ",", "end_positions", ",", "cls_index", ",", "is_impossible", ")", ":", "\n", "                ", "if", "x", "is", "not", "None", "and", "x", ".", "dim", "(", ")", ">", "1", ":", "\n", "                    ", "x", ".", "squeeze_", "(", "-", "1", ")", "\n", "\n", "# during training, compute the end logits based on the ground truth of the start position", "\n", "", "", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "p_mask", "=", "p_mask", ")", "\n", "\n", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "start_loss", "=", "loss_fct", "(", "start_logits", ",", "start_positions", ")", "\n", "end_loss", "=", "loss_fct", "(", "end_logits", ",", "end_positions", ")", "\n", "total_loss", "=", "(", "start_loss", "+", "end_loss", ")", "/", "2", "\n", "\n", "if", "cls_index", "is", "not", "None", "and", "is_impossible", "is", "not", "None", ":", "\n", "# Predict answerability from the representation of CLS and START", "\n", "                ", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_positions", "=", "start_positions", ",", "cls_index", "=", "cls_index", ")", "\n", "loss_fct_cls", "=", "nn", ".", "BCEWithLogitsLoss", "(", ")", "\n", "cls_loss", "=", "loss_fct_cls", "(", "cls_logits", ",", "is_impossible", ")", "\n", "\n", "# note(zhiliny): by default multiply the loss by 0.5 so that the scale is comparable to start_loss and end_loss", "\n", "total_loss", "+=", "cls_loss", "*", "0.5", "\n", "\n", "", "outputs", "=", "(", "total_loss", ",", ")", "+", "outputs", "\n", "\n", "", "else", ":", "\n", "# during inference, compute the end logits based on beam search", "\n", "            ", "bsz", ",", "slen", ",", "hsz", "=", "hidden_states", ".", "size", "(", ")", "\n", "start_log_probs", "=", "F", ".", "softmax", "(", "start_logits", ",", "dim", "=", "-", "1", ")", "# shape (bsz, slen)", "\n", "\n", "start_top_log_probs", ",", "start_top_index", "=", "torch", ".", "topk", "(", "start_log_probs", ",", "self", ".", "start_n_top", ",", "dim", "=", "-", "1", ")", "# shape (bsz, start_n_top)", "\n", "start_top_index_exp", "=", "start_top_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "expand", "(", "-", "1", ",", "-", "1", ",", "hsz", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "torch", ".", "gather", "(", "hidden_states", ",", "-", "2", ",", "start_top_index_exp", ")", "# shape (bsz, start_n_top, hsz)", "\n", "start_states", "=", "start_states", ".", "unsqueeze", "(", "1", ")", ".", "expand", "(", "-", "1", ",", "slen", ",", "-", "1", ",", "-", "1", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "\n", "hidden_states_expanded", "=", "hidden_states", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "start_states", ")", "# shape (bsz, slen, start_n_top, hsz)", "\n", "p_mask", "=", "p_mask", ".", "unsqueeze", "(", "-", "1", ")", "if", "p_mask", "is", "not", "None", "else", "None", "\n", "end_logits", "=", "self", ".", "end_logits", "(", "hidden_states_expanded", ",", "start_states", "=", "start_states", ",", "p_mask", "=", "p_mask", ")", "\n", "end_log_probs", "=", "F", ".", "softmax", "(", "end_logits", ",", "dim", "=", "1", ")", "# shape (bsz, slen, start_n_top)", "\n", "\n", "end_top_log_probs", ",", "end_top_index", "=", "torch", ".", "topk", "(", "end_log_probs", ",", "self", ".", "end_n_top", ",", "dim", "=", "1", ")", "# shape (bsz, end_n_top, start_n_top)", "\n", "end_top_log_probs", "=", "end_top_log_probs", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "end_top_index", "=", "end_top_index", ".", "view", "(", "-", "1", ",", "self", ".", "start_n_top", "*", "self", ".", "end_n_top", ")", "\n", "\n", "start_states", "=", "torch", ".", "einsum", "(", "\"blh,bl->bh\"", ",", "hidden_states", ",", "start_log_probs", ")", "# get the representation of START as weighted sum of hidden states", "\n", "cls_logits", "=", "self", ".", "answer_class", "(", "hidden_states", ",", "start_states", "=", "start_states", ",", "cls_index", "=", "cls_index", ")", "# Shape (batch size,): one single `cls_logits` for each sample", "\n", "\n", "outputs", "=", "(", "start_top_log_probs", ",", "start_top_index", ",", "end_top_log_probs", ",", "end_top_index", ",", "cls_logits", ")", "+", "outputs", "\n", "\n", "# return start_top_log_probs, start_top_index, end_top_log_probs, end_top_index, cls_logits", "\n", "# or (if labels are provided) (total_loss,)", "\n", "", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.SequenceSummary.__init__": [[1517, 1557], ["torch.nn.Module.__init__", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "torch.nn.Identity", "hasattr", "hasattr", "hasattr", "torch.nn.Tanh", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Dropout", "hasattr", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "SequenceSummary", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "summary_type", "=", "config", ".", "summary_type", "if", "hasattr", "(", "config", ",", "'summary_type'", ")", "else", "'last'", "\n", "if", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "# We should use a standard multi-head attention module with absolute positional embedding for that.", "\n", "# Cf. https://github.com/zihangdai/xlnet/blob/master/modeling.py#L253-L276", "\n", "# We can probably just use the multi-head attention module of PyTorch >=1.1.0", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "self", ".", "summary", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_use_proj'", ")", "and", "config", ".", "summary_use_proj", ":", "\n", "            ", "if", "hasattr", "(", "config", ",", "'summary_proj_to_labels'", ")", "and", "config", ".", "summary_proj_to_labels", "and", "config", ".", "num_labels", ">", "0", ":", "\n", "                ", "num_classes", "=", "config", ".", "num_labels", "\n", "", "else", ":", "\n", "                ", "num_classes", "=", "config", ".", "hidden_size", "\n", "", "if", "config", ".", "use_length", ":", "\n", "                ", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "+", "1", ",", "num_classes", ")", "\n", "", "elif", "config", ".", "join_embeddings", ":", "\n", "                ", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "num_classes", ")", "\n", "", "elif", "config", ".", "use_matchings", ":", "\n", "                ", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "+", "14", ",", "num_classes", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "summary", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "num_classes", ")", "\n", "\n", "", "", "self", ".", "activation", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_activation'", ")", "and", "config", ".", "summary_activation", "==", "'tanh'", ":", "\n", "            ", "self", ".", "activation", "=", "nn", ".", "Tanh", "(", ")", "\n", "\n", "", "self", ".", "first_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_first_dropout'", ")", "and", "config", ".", "summary_first_dropout", ">", "0", ":", "\n", "            ", "self", ".", "first_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_first_dropout", ")", "\n", "\n", "", "self", ".", "last_dropout", "=", "Identity", "(", ")", "\n", "if", "hasattr", "(", "config", ",", "'summary_last_dropout'", ")", "and", "config", ".", "summary_last_dropout", ">", "0", ":", "\n", "            ", "self", ".", "last_dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "summary_last_dropout", ")", "\n", "\n", "", "self", ".", "use_length", "=", "config", ".", "use_length", "\n", "self", ".", "join_embeddings", "=", "config", ".", "join_embeddings", "\n", "self", ".", "use_matchings", "=", "config", ".", "use_matchings", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.SequenceSummary.forward": [[1558, 1599], ["modeling_xlnet.SequenceSummary.first_dropout", "modeling_xlnet.SequenceSummary.summary", "modeling_xlnet.SequenceSummary.activation", "modeling_xlnet.SequenceSummary.last_dropout", "torch.cat", "embeddings_mask.reshape().type().cuda", "torch.cat", "torch.cat", "[].sum", "embeddings_mask.reshape().type().cuda.sum", "hidden_states.mean", "embeddings_mask.reshape().type", "hidden_states.gather().squeeze", "torch.full_like", "cls_index.expand.expand.unsqueeze().unsqueeze", "cls_index.expand.expand.expand", "embeddings_mask.reshape", "hidden_states.gather", "cls_index.expand.expand.unsqueeze", "hidden_states.size", "cls_index.expand.expand.dim"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "hidden_states", ",", "sent_a_length", "=", "None", ",", "cls_index", "=", "None", ",", "embeddings_mask", "=", "None", ",", "matchings", "=", "None", ")", ":", "\n", "        ", "\"\"\" hidden_states: float Tensor in shape [bsz, ..., seq_len, hidden_size], the hidden-states of the last layer.\n            cls_index: [optional] position of the classification token if summary_type == 'cls_index',\n                shape (bsz,) or more generally (bsz, ...) where ... are optional leading dimensions of hidden_states.\n                if summary_type == 'cls_index' and cls_index is None:\n                    we take the last token of the sequence as classification token\n        \"\"\"", "\n", "if", "self", ".", "summary_type", "==", "'last'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "-", "1", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'first'", ":", "\n", "            ", "output", "=", "hidden_states", "[", ":", ",", "0", "]", "\n", "", "elif", "self", ".", "summary_type", "==", "'mean'", ":", "\n", "            ", "output", "=", "hidden_states", ".", "mean", "(", "dim", "=", "1", ")", "\n", "", "elif", "self", ".", "summary_type", "==", "'cls_index'", ":", "\n", "            ", "if", "cls_index", "is", "None", ":", "\n", "                ", "cls_index", "=", "torch", ".", "full_like", "(", "hidden_states", "[", "...", ",", ":", "1", ",", ":", "]", ",", "hidden_states", ".", "shape", "[", "-", "2", "]", "-", "1", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "else", ":", "\n", "                ", "cls_index", "=", "cls_index", ".", "unsqueeze", "(", "-", "1", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "cls_index", "=", "cls_index", ".", "expand", "(", "(", "-", "1", ",", ")", "*", "(", "cls_index", ".", "dim", "(", ")", "-", "1", ")", "+", "(", "hidden_states", ".", "size", "(", "-", "1", ")", ",", ")", ")", "\n", "# shape of cls_index: (bsz, XX, 1, hidden_size) where XX are optional leading dim of hidden_states", "\n", "", "output", "=", "hidden_states", ".", "gather", "(", "-", "2", ",", "cls_index", ")", ".", "squeeze", "(", "-", "2", ")", "# shape (bsz, XX, hidden_size)", "\n", "", "elif", "self", ".", "summary_type", "==", "'attn'", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n", "", "if", "self", ".", "use_length", ":", "\n", "            ", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "sent_a_length", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "self", ".", "join_embeddings", ":", "\n", "            ", "mask", "=", "embeddings_mask", ".", "reshape", "(", "hidden_states", ".", "shape", "[", "0", "]", ",", "hidden_states", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", ")", "\n", "embs", "=", "(", "hidden_states", "*", "mask", ")", "[", ":", ",", ":", "-", "1", ",", ":", "]", ".", "sum", "(", "dim", "=", "1", ")", "/", "mask", ".", "sum", "(", "dim", "=", "1", ")", "\n", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "embs", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "if", "self", ".", "use_matchings", ":", "\n", "            ", "output", "=", "torch", ".", "cat", "(", "(", "output", ",", "matchings", ")", ",", "dim", "=", "1", ")", "\n", "\n", "", "output", "=", "self", ".", "first_dropout", "(", "output", ")", "\n", "output", "=", "self", ".", "summary", "(", "output", ")", "\n", "output", "=", "self", ".", "activation", "(", "output", ")", "\n", "output", "=", "self", ".", "last_dropout", "(", "output", ")", "\n", "\n", "return", "output", "", "", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.build_tf_xlnet_to_pytorch_map": [[45, 114], ["hasattr", "tf_to_pt_map.update", "enumerate", "tf_to_pt_map.update", "hasattr", "tf_to_pt_map.update", "hasattr", "hasattr", "r_r_list.append", "r_w_list.append", "r_s_list.append", "seg_embed_list.append"], "function", ["None"], ["def", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", "=", "None", ")", ":", "\n", "    ", "\"\"\" A map of modules from TF to PyTorch.\n        I use a map to keep the PyTorch model as\n        identical to the original PyTorch model as possible.\n    \"\"\"", "\n", "\n", "tf_to_pt_map", "=", "{", "}", "\n", "\n", "if", "hasattr", "(", "model", ",", "'transformer'", ")", ":", "\n", "        ", "if", "hasattr", "(", "model", ",", "'lm_loss'", ")", ":", "\n", "# We will load also the output bias", "\n", "            ", "tf_to_pt_map", "[", "'model/lm_loss/bias'", "]", "=", "model", ".", "lm_loss", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'sequence_summary'", ")", "and", "'model/sequnece_summary/summary/kernel'", "in", "tf_weights", ":", "\n", "# We will load also the sequence summary", "\n", "            ", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/kernel'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/sequnece_summary/summary/bias'", "]", "=", "model", ".", "sequence_summary", ".", "summary", ".", "bias", "\n", "", "if", "hasattr", "(", "model", ",", "'logits_proj'", ")", "and", "config", ".", "finetuning_task", "is", "not", "None", "and", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "in", "tf_weights", ":", "\n", "            ", "tf_to_pt_map", "[", "'model/regression_{}/logit/kernel'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "weight", "\n", "tf_to_pt_map", "[", "'model/regression_{}/logit/bias'", ".", "format", "(", "config", ".", "finetuning_task", ")", "]", "=", "model", ".", "logits_proj", ".", "bias", "\n", "\n", "# Now load the rest of the transformer", "\n", "", "model", "=", "model", ".", "transformer", "\n", "\n", "# Embeddings and output", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "'model/transformer/word_embedding/lookup_table'", ":", "model", ".", "word_embedding", ".", "weight", ",", "\n", "'model/transformer/mask_emb/mask_emb'", ":", "model", ".", "mask_emb", "}", ")", "\n", "\n", "# Transformer blocks", "\n", "for", "i", ",", "b", "in", "enumerate", "(", "model", ".", "layer", ")", ":", "\n", "        ", "layer_str", "=", "\"model/transformer/layer_%d/\"", "%", "i", "\n", "tf_to_pt_map", ".", "update", "(", "{", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/gamma\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"rel_attn/LayerNorm/beta\"", ":", "b", ".", "rel_attn", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"rel_attn/o/kernel\"", ":", "b", ".", "rel_attn", ".", "o", ",", "\n", "layer_str", "+", "\"rel_attn/q/kernel\"", ":", "b", ".", "rel_attn", ".", "q", ",", "\n", "layer_str", "+", "\"rel_attn/k/kernel\"", ":", "b", ".", "rel_attn", ".", "k", ",", "\n", "layer_str", "+", "\"rel_attn/r/kernel\"", ":", "b", ".", "rel_attn", ".", "r", ",", "\n", "layer_str", "+", "\"rel_attn/v/kernel\"", ":", "b", ".", "rel_attn", ".", "v", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/gamma\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/LayerNorm/beta\"", ":", "b", ".", "ff", ".", "layer_norm", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_1/kernel\"", ":", "b", ".", "ff", ".", "layer_1", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_1/bias\"", ":", "b", ".", "ff", ".", "layer_1", ".", "bias", ",", "\n", "layer_str", "+", "\"ff/layer_2/kernel\"", ":", "b", ".", "ff", ".", "layer_2", ".", "weight", ",", "\n", "layer_str", "+", "\"ff/layer_2/bias\"", ":", "b", ".", "ff", ".", "layer_2", ".", "bias", ",", "\n", "}", ")", "\n", "\n", "# Relative positioning biases", "\n", "", "if", "config", ".", "untie_r", ":", "\n", "        ", "r_r_list", "=", "[", "]", "\n", "r_w_list", "=", "[", "]", "\n", "r_s_list", "=", "[", "]", "\n", "seg_embed_list", "=", "[", "]", "\n", "for", "b", "in", "model", ".", "layer", ":", "\n", "            ", "r_r_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_r_bias", ")", "\n", "r_w_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_w_bias", ")", "\n", "r_s_list", ".", "append", "(", "b", ".", "rel_attn", ".", "r_s_bias", ")", "\n", "seg_embed_list", ".", "append", "(", "b", ".", "rel_attn", ".", "seg_embed", ")", "\n", "", "", "else", ":", "\n", "        ", "r_r_list", "=", "[", "model", ".", "r_r_bias", "]", "\n", "r_w_list", "=", "[", "model", ".", "r_w_bias", "]", "\n", "r_s_list", "=", "[", "model", ".", "r_s_bias", "]", "\n", "seg_embed_list", "=", "[", "model", ".", "seg_embed", "]", "\n", "", "tf_to_pt_map", ".", "update", "(", "{", "\n", "'model/transformer/r_r_bias'", ":", "r_r_list", ",", "\n", "'model/transformer/r_w_bias'", ":", "r_w_list", ",", "\n", "'model/transformer/r_s_bias'", ":", "r_s_list", ",", "\n", "'model/transformer/seg_embed'", ":", "seg_embed_list", "}", ")", "\n", "return", "tf_to_pt_map", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.load_tf_weights_in_xlnet": [[115, 173], ["tf.train.list_variables", "modeling_xlnet.build_tf_xlnet_to_pytorch_map", "build_tf_xlnet_to_pytorch_map.items", "logger.info", "logger.info", "tf.train.load_variable", "logger.info", "isinstance", "tf_weights.pop", "tf_weights.pop", "tf_weights.pop", "logger.error", "logger.info", "logger.info", "np.transpose", "enumerate", "logger.info", "torch.from_numpy", "len", "logger.info", "torch.from_numpy", "tf_weights.keys"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.build_tf_xlnet_to_pytorch_map"], ["", "def", "load_tf_weights_in_xlnet", "(", "model", ",", "config", ",", "tf_path", ")", ":", "\n", "    ", "\"\"\" Load tf checkpoints in a pytorch model\n    \"\"\"", "\n", "try", ":", "\n", "        ", "import", "numpy", "as", "np", "\n", "import", "tensorflow", "as", "tf", "\n", "", "except", "ImportError", ":", "\n", "        ", "logger", ".", "error", "(", "\"Loading a TensorFlow models in PyTorch, requires TensorFlow to be installed. Please see \"", "\n", "\"https://www.tensorflow.org/install/ for installation instructions.\"", ")", "\n", "raise", "\n", "# Load weights from TF model", "\n", "", "init_vars", "=", "tf", ".", "train", ".", "list_variables", "(", "tf_path", ")", "\n", "tf_weights", "=", "{", "}", "\n", "for", "name", ",", "shape", "in", "init_vars", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading TF weight {} with shape {}\"", ".", "format", "(", "name", ",", "shape", ")", ")", "\n", "array", "=", "tf", ".", "train", ".", "load_variable", "(", "tf_path", ",", "name", ")", "\n", "tf_weights", "[", "name", "]", "=", "array", "\n", "\n", "# Build TF to PyTorch weights loading map", "\n", "", "tf_to_pt_map", "=", "build_tf_xlnet_to_pytorch_map", "(", "model", ",", "config", ",", "tf_weights", ")", "\n", "\n", "for", "name", ",", "pointer", "in", "tf_to_pt_map", ".", "items", "(", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"Importing {}\"", ".", "format", "(", "name", ")", ")", "\n", "if", "name", "not", "in", "tf_weights", ":", "\n", "            ", "logger", ".", "info", "(", "\"{} not in tf pre-trained weights, skipping\"", ".", "format", "(", "name", ")", ")", "\n", "continue", "\n", "", "array", "=", "tf_weights", "[", "name", "]", "\n", "# adam_v and adam_m are variables used in AdamWeightDecayOptimizer to calculated m and v", "\n", "# which are not required for using pretrained model", "\n", "if", "'kernel'", "in", "name", "and", "(", "'ff'", "in", "name", "or", "'summary'", "in", "name", "or", "'logit'", "in", "name", ")", ":", "\n", "            ", "logger", ".", "info", "(", "\"Transposing\"", ")", "\n", "array", "=", "np", ".", "transpose", "(", "array", ")", "\n", "", "if", "isinstance", "(", "pointer", ",", "list", ")", ":", "\n", "# Here we will split the TF weigths", "\n", "            ", "assert", "len", "(", "pointer", ")", "==", "array", ".", "shape", "[", "0", "]", "\n", "for", "i", ",", "p_i", "in", "enumerate", "(", "pointer", ")", ":", "\n", "                ", "arr_i", "=", "array", "[", "i", ",", "...", "]", "\n", "try", ":", "\n", "                    ", "assert", "p_i", ".", "shape", "==", "arr_i", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                    ", "e", ".", "args", "+=", "(", "p_i", ".", "shape", ",", "arr_i", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {} for layer {}\"", ".", "format", "(", "name", ",", "i", ")", ")", "\n", "p_i", ".", "data", "=", "torch", ".", "from_numpy", "(", "arr_i", ")", "\n", "", "", "else", ":", "\n", "            ", "try", ":", "\n", "                ", "assert", "pointer", ".", "shape", "==", "array", ".", "shape", "\n", "", "except", "AssertionError", "as", "e", ":", "\n", "                ", "e", ".", "args", "+=", "(", "pointer", ".", "shape", ",", "array", ".", "shape", ")", "\n", "raise", "\n", "", "logger", ".", "info", "(", "\"Initialize PyTorch weight {}\"", ".", "format", "(", "name", ")", ")", "\n", "pointer", ".", "data", "=", "torch", ".", "from_numpy", "(", "array", ")", "\n", "", "tf_weights", ".", "pop", "(", "name", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam'", ",", "None", ")", "\n", "tf_weights", ".", "pop", "(", "name", "+", "'/Adam_1'", ",", "None", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Weights not copied to PyTorch model: {}\"", ".", "format", "(", "', '", ".", "join", "(", "tf_weights", ".", "keys", "(", ")", ")", ")", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.gelu": [[175, 182], ["torch.tanh", "math.sqrt", "torch.pow"], "function", ["None"], ["", "def", "gelu", "(", "x", ")", ":", "\n", "    ", "\"\"\" Implementation of the gelu activation function.\n        XLNet is using OpenAI GPT's gelu (not exactly the same as BERT)\n        Also see https://arxiv.org/abs/1606.08415\n    \"\"\"", "\n", "cdf", "=", "0.5", "*", "(", "1.0", "+", "torch", ".", "tanh", "(", "math", ".", "sqrt", "(", "2", "/", "math", ".", "pi", ")", "*", "(", "x", "+", "0.044715", "*", "torch", ".", "pow", "(", "x", ",", "3", ")", ")", ")", ")", "\n", "return", "x", "*", "cdf", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.swish": [[184, 186], ["torch.sigmoid"], "function", ["None"], ["", "def", "swish", "(", "x", ")", ":", "\n", "    ", "return", "x", "*", "torch", ".", "sigmoid", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaEmbeddings.__init__": [[46, 52], ["transformers.modeling_bert.BertEmbeddings.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "self", ".", "padding_idx", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ",", "\n", "padding_idx", "=", "self", ".", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaEmbeddings.forward": [[53, 71], ["super().forward", "input_ids.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "inputs_embeds.size", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "# Position numbers begin at padding_idx+1. Padding symbols are ignored.", "\n", "# cf. fairseq's `utils.make_positions`", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "self", ".", "padding_idx", "+", "1", ",", "seq_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "", "return", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaModel.__init__": [[180, 185], ["transformers.modeling_bert.BertModel.__init__", "modeling_roberta.RobertaEmbeddings", "modeling_roberta.RobertaModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "RobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaModel.get_input_embeddings": [[186, 188], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaModel.set_input_embeddings": [[189, 191], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForMaskedLM.__init__": [[228, 235], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForMaskedLM.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForMaskedLM.get_output_embeddings": [[236, 238], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForMaskedLM.forward": [[239, 258], ["modeling_roberta.RobertaForMaskedLM.roberta", "modeling_roberta.RobertaForMaskedLM.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaLMHead.__init__": [[263, 270], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "transformers.modeling_bert.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaLMHead.forward": [[271, 280], ["modeling_roberta.RobertaLMHead.dense", "transformers.modeling_bert.gelu", "modeling_roberta.RobertaLMHead.layer_norm", "modeling_roberta.RobertaLMHead.decoder"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.gelu"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "gelu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForSequenceClassification.__init__": [[320, 336], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaClassificationHeadJoinedLenght", "modeling_roberta.RobertaClassificationHeadLength", "modeling_roberta.RobertaClassificationHeadJoined", "modeling_roberta.RobertaClassificationHeadMatchings", "modeling_roberta.RobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "if", "config", ".", "use_length", ":", "\n", "            ", "if", "config", ".", "join_embeddings", ":", "\n", "                ", "self", ".", "classifier", "=", "RobertaClassificationHeadJoinedLenght", "(", "config", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "classifier", "=", "RobertaClassificationHeadLength", "(", "config", ")", "\n", "", "", "elif", "config", ".", "join_embeddings", ":", "\n", "            ", "self", ".", "classifier", "=", "RobertaClassificationHeadJoined", "(", "config", ")", "\n", "", "elif", "config", ".", "use_matchings", ":", "\n", "            ", "self", ".", "classifier", "=", "RobertaClassificationHeadMatchings", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForSequenceClassification.forward": [[337, 362], ["modeling_roberta.RobertaForSequenceClassification.roberta", "modeling_roberta.RobertaForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ",", "lengths", "=", "None", ",", "matchings", "=", "None", ",", "embeddings_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ",", "sent_a_length", "=", "lengths", ",", "attention_mask", "=", "embeddings_mask", ",", "matchings", "=", "matchings", ")", "\n", "\n", "#logits = self.classifier(sequence_output)", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForMultipleChoice.__init__": [[441, 449], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForMultipleChoice.forward": [[450, 474], ["input_ids.view", "modeling_roberta.RobertaForMultipleChoice.roberta", "modeling_roberta.RobertaForMultipleChoice.dropout", "modeling_roberta.RobertaForMultipleChoice.classifier", "modeling_roberta.RobertaForMultipleChoice.view", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "position_ids.size", "token_type_ids.size", "attention_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "outputs", "=", "self", ".", "roberta", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForTokenClassification.__init__": [[512, 521], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForTokenClassification.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaForTokenClassification.forward": [[522, 552], ["modeling_roberta.RobertaForTokenClassification.roberta", "modeling_roberta.RobertaForTokenClassification.dropout", "modeling_roberta.RobertaForTokenClassification.classifier", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "attention_mask.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "#loss_fct = CrossEntropyLoss(ignore_index=-100)", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHead.__init__": [[557, 562], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHead.forward": [[563, 571], ["modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHead.dropout", "modeling_roberta.RobertaClassificationHead.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadLength.__init__": [[576, 581], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHeadLength", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "+", "1", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadLength.forward": [[582, 591], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_roberta.RobertaClassificationHeadLength.dropout", "modeling_roberta.RobertaClassificationHeadLength.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHeadLength.dropout", "modeling_roberta.RobertaClassificationHeadLength.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "sent_a_length", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "sent_a_length", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadMatchings.__init__": [[597, 602], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHeadMatchings", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "+", "14", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadMatchings.forward": [[603, 611], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_roberta.RobertaClassificationHeadMatchings.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHeadMatchings.dropout", "modeling_roberta.RobertaClassificationHeadMatchings.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "matchings", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "matchings", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadJoinedLenght.__init__": [[617, 622], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHeadJoinedLenght", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", "+", "1", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadJoinedLenght.forward": [[623, 636], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "features[].mean", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_roberta.RobertaClassificationHeadJoinedLenght.dropout", "modeling_roberta.RobertaClassificationHeadJoinedLenght.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHeadJoinedLenght.dropout", "modeling_roberta.RobertaClassificationHeadJoinedLenght.out_proj"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "sent_a_length", "=", "None", ",", "attention_mask", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "sent_a_length", ")", ",", "dim", "=", "1", ")", "\n", "#mask = attention_mask.reshape(features.shape[0], features.shape[1], 1).type(torch.FloatTensor).cuda()", "\n", "#embs = (features * mask)[:, 1:, :].sum(dim=1) / sent_a_length", "\n", "embs", "=", "features", "[", ":", ",", "1", ":", ",", ":", "]", ".", "mean", "(", "dim", "=", "1", ")", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "embs", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadJoined.__init__": [[641, 646], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHeadJoined", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadJoined.forward": [[647, 659], ["attention_mask.reshape().type().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_roberta.RobertaClassificationHeadJoined.dropout", "modeling_roberta.RobertaClassificationHeadJoined.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHeadJoined.dropout", "modeling_roberta.RobertaClassificationHeadJoined.out_proj", "[].sum", "attention_mask.reshape().type().cuda.sum", "attention_mask.reshape().type", "attention_mask.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "sent_a_length", "=", "None", ",", "attention_mask", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "mask", "=", "attention_mask", ".", "reshape", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", ")", "\n", "embs", "=", "(", "features", "*", "mask", ")", "[", ":", ",", "1", ":", ",", ":", "]", ".", "sum", "(", "dim", "=", "1", ")", "/", "mask", ".", "sum", "(", "dim", "=", "1", ")", "\n", "#embs, _ = (features * mask)[:, 1:, :].max(dim=1)", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "embs", ")", ",", "dim", "=", "1", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadJoinedAtt.__init__": [[665, 676], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHeadJoinedAtt", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", "*", "2", "+", "1", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "att_weights", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadJoinedAtt.forward": [[677, 691], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "attention_mask.reshape().type().cuda", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "modeling_roberta.RobertaClassificationHeadJoinedAtt.dropout", "modeling_roberta.RobertaClassificationHeadJoinedAtt.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHeadJoinedAtt.dropout", "modeling_roberta.RobertaClassificationHeadJoinedAtt.out_proj", "modeling_roberta.RobertaClassificationHeadJoinedAtt.att_weights", "[].sum", "attention_mask.reshape().type", "attention_mask.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "sent_a_length", ",", "attention_mask", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "features", "[", ":", ",", "0", ",", ":", "]", "# take <s> token (equiv. to [CLS])", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "sent_a_length", ")", ",", "dim", "=", "1", ")", "\n", "mask", "=", "attention_mask", ".", "reshape", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", ")", "\n", "att", "=", "self", ".", "att_weights", "(", "features", ")", "*", "mask", "\n", "embs", "=", "(", "features", "*", "att", ")", "[", ":", ",", "1", ":", ",", ":", "]", ".", "sum", "(", "dim", "=", "1", ")", "/", "sent_a_length", "\n", "x", "=", "torch", ".", "cat", "(", "(", "x", ",", "embs", ")", ",", "dim", "=", "1", ")", "\n", "#x = torch.cat((x, features[:, 1:, :].mean(dim=1)), dim=1)", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadVoting.__init__": [[696, 707], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Sequential", "torch.Sequential", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Tanh", "torch.Tanh", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaClassificationHeadVoting", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "att_weights", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", ")", "\n", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "out_proj", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_roberta.RobertaClassificationHeadVoting.forward": [[708, 718], ["attention_mask.reshape().type().cuda", "modeling_roberta.RobertaClassificationHeadVoting.dropout", "modeling_roberta.RobertaClassificationHeadVoting.dense", "torch.tanh", "torch.tanh", "torch.tanh", "torch.tanh", "modeling_roberta.RobertaClassificationHeadVoting.dropout", "modeling_roberta.RobertaClassificationHeadVoting.out_proj", "modeling_roberta.RobertaClassificationHeadVoting.att_weights", "attention_mask.reshape().type", "attention_mask.reshape"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "features", ",", "attention_mask", ",", "**", "kwargs", ")", ":", "\n", "        ", "mask", "=", "attention_mask", ".", "reshape", "(", "features", ".", "shape", "[", "0", "]", ",", "features", ".", "shape", "[", "1", "]", ",", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ".", "cuda", "(", ")", "\n", "att", "=", "self", ".", "att_weights", "(", "features", ")", "*", "mask", "\n", "x", "=", "self", ".", "dropout", "(", "features", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "x", "=", "torch", ".", "tanh", "(", "x", ")", "\n", "x", "=", "self", ".", "dropout", "(", "x", ")", "\n", "x", "=", "self", ".", "out_proj", "(", "x", ")", "\n", "x", "=", "(", "x", "*", "att", ")", ".", "sum", "(", "dim", "=", "1", ")", "\n", "return", "x", "\n", "", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.set_seed": [[85, 91], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.train": [[93, 240], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_glue.set_seed", "SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "SummaryWriter.close", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "loss.mean.backward", "transformers.AdamW.step", "transformers.get_linear_schedule_with_warmup.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "mask.sum().float", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "logs.items", "print", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_glue.evaluate", "evaluate.items", "transformers.get_linear_schedule_with_warmup.get_lr", "SummaryWriter.add_scalar", "json.dumps", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "mask.sum"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.set_seed", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.train", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "'bias'", ",", "'LayerNorm.weight'", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "'params'", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "'weight_decay'", ":", "0.0", "}", "\n", "]", "\n", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "position", "=", "0", ",", "leave", "=", "True", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'labels'", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "'distilbert'", ":", "\n", "                ", "inputs", "[", "'token_type_ids'", "]", "=", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", "# XLM, DistilBERT and RoBERTa don't use segment_ids", "\n", "", "if", "args", ".", "use_length", ":", "\n", "                ", "if", "args", ".", "model_type", "==", "'roberta'", ":", "\n", "                    ", "inputs", "[", "'lengths'", "]", "=", "(", "inputs", "[", "'attention_mask'", "]", "-", "inputs", "[", "'token_type_ids'", "]", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "float", "(", ")", "\n", "", "if", "args", ".", "model_type", "==", "'xlnet'", ":", "\n", "                    ", "mask", "=", "inputs", "[", "'attention_mask'", "]", "-", "inputs", "[", "'token_type_ids'", "]", "\n", "mask", "[", "mask", "<", "0", "]", "=", "0", "\n", "inputs", "[", "'lengths'", "]", "=", "mask", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "float", "(", ")", "\n", "", "", "if", "args", ".", "use_matchings", ":", "\n", "                ", "inputs", "[", "'matchings'", "]", "=", "batch", "[", "4", "]", "\n", "", "if", "args", ".", "join_embeddings", ":", "\n", "                ", "if", "args", ".", "model_type", "==", "'roberta'", ":", "\n", "                    ", "inputs", "[", "'embeddings_mask'", "]", "=", "inputs", "[", "'attention_mask'", "]", "-", "inputs", "[", "'token_type_ids'", "]", "\n", "", "if", "args", ".", "model_type", "==", "'xlnet'", ":", "\n", "                    ", "mask", "=", "inputs", "[", "'attention_mask'", "]", "-", "inputs", "[", "'token_type_ids'", "]", "\n", "mask", "[", "mask", "<", "0", "]", "=", "0", "\n", "inputs", "[", "'embeddings_mask'", "]", "=", "mask", "\n", "", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "                    ", "logs", "=", "{", "}", "\n", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "eval_key", "=", "'eval_{}'", ".", "format", "(", "key", ")", "\n", "logs", "[", "eval_key", "]", "=", "value", "\n", "\n", "", "", "loss_scalar", "=", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", "\n", "learning_rate_scalar", "=", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", "\n", "logs", "[", "'learning_rate'", "]", "=", "learning_rate_scalar", "\n", "logs", "[", "'loss'", "]", "=", "loss_scalar", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "for", "key", ",", "value", "in", "logs", ".", "items", "(", ")", ":", "\n", "                        ", "tb_writer", ".", "add_scalar", "(", "key", ",", "value", ",", "global_step", ")", "\n", "", "print", "(", "json", ".", "dumps", "(", "{", "**", "logs", ",", "**", "{", "'step'", ":", "global_step", "}", "}", ")", ")", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'checkpoint-{}'", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.evaluate": [[242, 349], ["zip", "run_glue.load_and_cache_examples", "torch.utils.data.SequentialSampler", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "tqdm.tqdm", "utils.glue_compute_metrics", "results.update", "os.makedirs", "max", "torch.nn.DataParallel", "len", "torch.nn.DataParallel.eval", "tuple", "numpy.argmax", "os.path.join", "open", "logger.info", "sorted", "os.path.exists", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean().item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "numpy.squeeze", "os.path.join", "utils.glue_compute_metrics.keys", "logger.info", "writer.write", "t.to", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "open", "pickle.dump", "open", "pickle.dump", "str", "mask.sum().float", "tmp_eval_loss.mean", "logits.detach().cpu", "inputs[].detach().cpu", "os.path.join", "open", "pickle.dump", "os.path.join", "open", "pickle.dump", "logits.detach().cpu", "inputs[].detach().cpu", "os.path.join", "os.path.join", "str", "mask.sum", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.load_and_cache_examples", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.glue_compute_metrics"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "\"\"", ")", ":", "\n", "# Loop to handle MNLI double evaluation (matched, mis-matched)", "\n", "    ", "eval_task_names", "=", "(", "\"mnli\"", ",", "\"mnli-mm\"", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "task_name", ",", ")", "\n", "eval_outputs_dirs", "=", "(", "args", ".", "output_dir", ",", "args", ".", "output_dir", "+", "'-MM'", ")", "if", "args", ".", "task_name", "==", "\"mnli\"", "else", "(", "args", ".", "output_dir", ",", ")", "\n", "\n", "results", "=", "{", "}", "\n", "for", "eval_task", ",", "eval_output_dir", "in", "zip", "(", "eval_task_names", ",", "eval_outputs_dirs", ")", ":", "\n", "        ", "if", "args", ".", "do_eval", ":", "\n", "            ", "mode", "=", "'eval'", "\n", "", "if", "args", ".", "do_predict", ":", "\n", "            ", "mode", "=", "'predict'", "\n", "", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "eval_task", ",", "tokenizer", ",", "evaluate", "=", "True", ",", "mode", "=", "mode", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "eval_output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "eval_output_dir", ")", "\n", "\n", "", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu eval", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "            ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "            ", "model", ".", "eval", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "                ", "inputs", "=", "{", "'input_ids'", ":", "batch", "[", "0", "]", ",", "\n", "'attention_mask'", ":", "batch", "[", "1", "]", ",", "\n", "'labels'", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "'distilbert'", ":", "\n", "                    ", "inputs", "[", "'token_type_ids'", "]", "=", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "'bert'", ",", "'xlnet'", "]", "else", "None", "# XLM, DistilBERT and RoBERTa don't use segment_ids", "\n", "", "if", "args", ".", "use_length", ":", "\n", "                    ", "if", "args", ".", "model_type", "==", "'roberta'", ":", "\n", "                        ", "inputs", "[", "'lengths'", "]", "=", "(", "batch", "[", "1", "]", "-", "batch", "[", "2", "]", ")", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "float", "(", ")", "\n", "", "if", "args", ".", "model_type", "==", "'xlnet'", ":", "\n", "                        ", "mask", "=", "inputs", "[", "'attention_mask'", "]", "-", "inputs", "[", "'token_type_ids'", "]", "\n", "mask", "[", "mask", "<", "0", "]", "=", "0", "\n", "inputs", "[", "'lengths'", "]", "=", "mask", ".", "sum", "(", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ".", "float", "(", ")", "\n", "", "", "if", "args", ".", "use_matchings", ":", "\n", "                    ", "inputs", "[", "'matchings'", "]", "=", "batch", "[", "4", "]", "\n", "", "if", "args", ".", "join_embeddings", ":", "\n", "                    ", "if", "args", ".", "model_type", "==", "'roberta'", ":", "\n", "                        ", "inputs", "[", "'embeddings_mask'", "]", "=", "inputs", "[", "'attention_mask'", "]", "-", "batch", "[", "2", "]", "\n", "", "if", "args", ".", "model_type", "==", "'xlnet'", ":", "\n", "                        ", "mask", "=", "inputs", "[", "'attention_mask'", "]", "-", "inputs", "[", "'token_type_ids'", "]", "\n", "mask", "[", "mask", "<", "0", "]", "=", "0", "\n", "inputs", "[", "'embeddings_mask'", "]", "=", "mask", "\n", "", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "eval_loss", "+=", "tmp_eval_loss", ".", "mean", "(", ")", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "                ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "                ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "'labels'", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "\n", "if", "args", ".", "do_predict", ":", "\n", "            ", "try", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "'predicted_logits'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "pickle", ".", "dump", "(", "preds", ",", "f", ")", "\n", "", "", "except", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "'predicted_logits'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "pickle", ".", "dump", "(", "preds", ",", "f", ")", "\n", "\n", "", "", "", "if", "args", ".", "output_mode", "==", "\"classification\"", ":", "\n", "            ", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "1", ")", "\n", "", "elif", "args", ".", "output_mode", "==", "\"regression\"", ":", "\n", "            ", "preds", "=", "np", ".", "squeeze", "(", "preds", ")", "\n", "\n", "", "result", "=", "compute_metrics", "(", "eval_task", ",", "preds", ",", "out_label_ids", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "try", ":", "\n", "            ", "if", "args", ".", "do_predict", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "'predictions'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "pickle", ".", "dump", "(", "preds", ",", "f", ")", "\n", "", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "prefix", ",", "\"eval_results.txt\"", ")", "\n", "", "except", ":", "\n", "            ", "if", "args", ".", "do_predict", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "'predictions'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "                    ", "pickle", ".", "dump", "(", "preds", ",", "f", ")", "\n", "", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "eval_output_dir", ",", "\"eval_results.txt\"", ")", "\n", "\n", "", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "logger", ".", "info", "(", "\"***** Eval results {} *****\"", ".", "format", "(", "prefix", ")", ")", "\n", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", "\n", "writer", ".", "write", "(", "\"%s = %s\\n\"", "%", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.get_matchings": [[351, 368], ["numpy.zeros", "len", "len", "train_examples.get", "numpy.sum", "numpy.sum", "enumerate", "mapping.items", "ps.stem", "set", "nltk.tokenize.word_tokenize", "span.lower"], "function", ["None"], ["", "def", "get_matchings", "(", "span", ",", "train_examples", ",", "ps", ")", ":", "\n", "    ", "mapping", "=", "{", "i", ":", "el", "for", "i", ",", "el", "in", "enumerate", "(", "[", "'Appeal_to_Authority'", ",", "'Doubt'", ",", "'Repetition'", ",", "\n", "'Appeal_to_fear-prejudice'", ",", "'Slogans'", ",", "'Black-and-White_Fallacy'", ",", "\n", "'Loaded_Language'", ",", "'Flag-Waving'", ",", "'Name_Calling,Labeling'", ",", "\n", "'Whataboutism,Straw_Men,Red_Herring'", ",", "'Causal_Oversimplification'", ",", "\n", "'Exaggeration,Minimisation'", ",", "'Bandwagon,Reductio_ad_hitlerum'", ",", "\n", "'Thought-terminating_Cliches'", "]", ")", "}", "\n", "inverse_mapping", "=", "{", "b", ":", "a", "for", "(", "a", ",", "b", ")", "in", "mapping", ".", "items", "(", ")", "}", "\n", "\n", "matchings", "=", "np", ".", "zeros", "(", "len", "(", "mapping", ")", ")", "\n", "clear_span", "=", "\" \"", ".", "join", "(", "[", "ps", ".", "stem", "(", "word", ")", "for", "word", "in", "word_tokenize", "(", "span", ".", "lower", "(", ")", ")", "]", ")", "\n", "if", "len", "(", "clear_span", ")", ">", "0", ":", "\n", "        ", "for", "class_label", "in", "train_examples", ".", "get", "(", "clear_span", ",", "set", "(", ")", ")", ":", "\n", "            ", "matchings", "[", "inverse_mapping", "[", "class_label", "]", "]", "+=", "1", "\n", "", "", "if", "np", ".", "sum", "(", "matchings", ")", "!=", "0", ":", "\n", "        ", "matchings", "/=", "np", ".", "sum", "(", "matchings", ")", "\n", "", "return", "matchings", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.load_and_cache_examples": [[370, 441], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "processor.get_labels", "transformers.glue_convert_examples_to_features", "torch.distributed.barrier", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "list().pop", "str", "str", "processor.get_train_examples", "nltk.stem.PorterStemmer", "range", "logger.info", "torch.save", "torch.tensor", "os.path.join", "processor.get_dev_examples", "bool", "len", "len", "len", "run_glue.get_matchings", "list", "os.path.join", "processor.get_test_examples", "tokenizer.convert_tokens_to_ids", "open", "pickle.load", "open", "pickle.load", "filter", "os.path.join", "os.path.join", "os.path.join", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.get_labels", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor.get_train_examples", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor.get_dev_examples", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.get_matchings", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor.get_test_examples"], ["", "def", "load_and_cache_examples", "(", "args", ",", "task", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "mode", "=", "None", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "", "processor", "=", "processors", "[", "task", "]", "(", ")", "\n", "output_mode", "=", "output_modes", "[", "task", "]", "\n", "# Load data features from cache or dataset file", "\n", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'cached_{}_{}_{}_{}'", ".", "format", "(", "\n", "'dev'", "if", "evaluate", "else", "'train'", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "'/'", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ",", "\n", "str", "(", "task", ")", ")", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", "and", "False", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "if", "task", "in", "[", "'mnli'", ",", "'mnli-mm'", "]", "and", "args", ".", "model_type", "in", "[", "'roberta'", "]", ":", "\n", "# HACK(label indices are swapped in RoBERTa pretrained model)", "\n", "            ", "label_list", "[", "1", "]", ",", "label_list", "[", "2", "]", "=", "label_list", "[", "2", "]", ",", "label_list", "[", "1", "]", "\n", "", "if", "mode", "==", "'train'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_train_examples", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "train_file", ")", ")", "\n", "", "elif", "mode", "==", "'eval'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_dev_examples", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "dev_file", ")", ")", "\n", "", "elif", "mode", "==", "'predict'", ":", "\n", "            ", "examples", "=", "processor", ".", "get_test_examples", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "test_file", ")", ")", "\n", "\n", "", "features", "=", "convert_examples_to_features", "(", "examples", ",", "\n", "tokenizer", ",", "\n", "label_list", "=", "label_list", ",", "\n", "max_length", "=", "args", ".", "max_seq_length", ",", "\n", "output_mode", "=", "output_mode", ",", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "'xlnet'", "]", ")", ",", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "'xlnet'", "]", "else", "0", ",", "\n", ")", "\n", "if", "args", ".", "use_matchings", ":", "\n", "            ", "assert", "len", "(", "features", ")", "==", "len", "(", "examples", ")", "\n", "if", "args", ".", "do_eval", "or", "args", ".", "do_train", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'train_instances_train'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "train_examples", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "if", "args", ".", "do_predict", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "'train_instances'", ")", ",", "'rb'", ")", "as", "f", ":", "\n", "                    ", "train_examples", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "", "ps", "=", "PorterStemmer", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "                ", "features", "[", "i", "]", ".", "matchings", "=", "get_matchings", "(", "examples", "[", "i", "]", ".", "text_a", ",", "train_examples", ",", "ps", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "False", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_attention_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "attention_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_token_type_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "token_type_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "output_mode", "==", "\"classification\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "", "elif", "output_mode", "==", "\"regression\"", ":", "\n", "        ", "all_labels", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "\n", "", "if", "args", ".", "use_matchings", ":", "\n", "        ", "all_matchings", "=", "torch", ".", "tensor", "(", "[", "f", ".", "matchings", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "float", ")", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_token_type_ids", ",", "all_labels", ",", "all_matchings", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_attention_mask", ",", "all_token_type_ids", ",", "all_labels", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.run_glue.transformers_clf": [[443, 563], ["logging.basicConfig", "logger.warning", "run_glue.set_seed", "args.task_name.lower", "processor.get_labels", "len", "args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "ValueError", "torch.distributed.barrier", "torch.distributed.barrier", "run_glue.load_and_cache_examples", "run_glue.train", "logger.info", "logger.info", "model_to_save.save_pretrained", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "model_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained.to", "tokenizer_class.from_pretrained", "logger.info", "bool", "os.makedirs", "hasattr", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_glue.evaluate", "dict", "results.update", "torch.distributed.get_rank", "os.path.exists", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "checkpoint.find", "checkpoint.split", "sorted", "dict.items", "glob.glob"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.set_seed", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.get_labels", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.load_and_cache_examples", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.train", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate"], ["", "def", "transformers_clf", "(", "args", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", ":", "\n", "        ", "raise", "ValueError", "(", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "args", ".", "output_dir", ")", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "'nccl'", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "'%(asctime)s - %(levelname)s - %(name)s -   %(message)s'", ",", "\n", "datefmt", "=", "'%m/%d/%Y %H:%M:%S'", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare GLUE task", "\n", "args", ".", "task_name", "=", "args", ".", "task_name", ".", "lower", "(", ")", "\n", "if", "args", ".", "task_name", "not", "in", "processors", ":", "\n", "        ", "raise", "ValueError", "(", "\"Task not found: %s\"", "%", "(", "args", ".", "task_name", ")", ")", "\n", "", "processor", "=", "processors", "[", "args", ".", "task_name", "]", "(", ")", "\n", "args", ".", "output_mode", "=", "output_modes", "[", "args", ".", "task_name", "]", "\n", "label_list", "=", "processor", ".", "get_labels", "(", ")", "\n", "num_labels", "=", "len", "(", "label_list", ")", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "finetuning_task", "=", "args", ".", "task_name", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "config", ".", "use_length", "=", "args", ".", "use_length", "\n", "config", ".", "join_embeddings", "=", "args", ".", "join_embeddings", "\n", "config", ".", "use_matchings", "=", "args", ".", "use_matchings", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "'.ckpt'", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "args", ".", "task_name", ",", "tokenizer", ",", "evaluate", "=", "False", ",", "mode", "=", "'train'", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "'module'", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "'training_args.bin'", ")", ")", "\n", "\n", "# Load a trained model and vocabulary that you have fine-tuned", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "or", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "'/**/'", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "'-'", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "prefix", "=", "checkpoint", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", "if", "checkpoint", ".", "find", "(", "'checkpoint'", ")", "!=", "-", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "prefix", "=", "prefix", ")", "\n", "result", "=", "dict", "(", "(", "k", "+", "'_{}'", ".", "format", "(", "global_step", ")", ",", "v", ")", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", ")", "\n", "results", ".", "update", "(", "result", ")", "\n", "\n", "", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor.get_train_examples": [[47, 50], ["utils.PropProcessor._create_examples", "utils.PropProcessor._read_tsv"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor._create_examples"], ["    ", "def", "get_train_examples", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "file_path", ")", ",", "\"train\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor.get_dev_examples": [[51, 54], ["utils.PropProcessor._create_examples", "utils.PropProcessor._read_tsv"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor._create_examples"], ["", "def", "get_dev_examples", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "file_path", ")", ",", "\"dev_matched\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor.get_test_examples": [[55, 58], ["utils.PropProcessor._create_examples", "utils.PropProcessor._read_tsv"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor._create_examples"], ["", "def", "get_test_examples", "(", "self", ",", "file_path", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "self", ".", "_create_examples", "(", "self", ".", "_read_tsv", "(", "file_path", ")", ",", "\"test\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor.get_labels": [[59, 67], ["None"], "methods", ["None"], ["", "def", "get_labels", "(", "self", ")", ":", "\n", "        ", "\"\"\"See base class.\"\"\"", "\n", "return", "[", "'Appeal_to_Authority'", ",", "'Doubt'", ",", "'Repetition'", ",", "\n", "'Appeal_to_fear-prejudice'", ",", "'Slogans'", ",", "'Black-and-White_Fallacy'", ",", "\n", "'Loaded_Language'", ",", "'Flag-Waving'", ",", "'Name_Calling,Labeling'", ",", "\n", "'Whataboutism,Straw_Men,Red_Herring'", ",", "'Causal_Oversimplification'", ",", "\n", "'Exaggeration,Minimisation'", ",", "'Bandwagon,Reductio_ad_hitlerum'", ",", "\n", "'Thought-terminating_Cliches'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.PropProcessor._create_examples": [[68, 94], ["autocorrect.Speller", "enumerate", "examples.append", "transformers.InputExample", "len", "utils.PropProcessor.get_labels"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.get_labels"], ["", "def", "_create_examples", "(", "self", ",", "lines", ",", "set_type", ")", ":", "\n", "        ", "\"\"\"Creates examples for the training and dev sets.\"\"\"", "\n", "examples", "=", "[", "]", "\n", "spell", "=", "Speller", "(", "lang", "=", "'en'", ")", "\n", "for", "(", "i", ",", "line", ")", "in", "enumerate", "(", "lines", ")", ":", "\n", "            ", "if", "i", "==", "0", "or", "line", "==", "[", "]", ":", "\n", "                ", "continue", "\n", "", "guid", "=", "\"%s-%s\"", "%", "(", "set_type", ",", "i", ")", "\n", "text_a", "=", "line", "[", "3", "]", "# generate_misspelling(line[3])", "\n", "#try:", "\n", "#    text_a = spell(text_a)", "\n", "#except:", "\n", "#    pass", "\n", "\n", "text_b", "=", "line", "[", "4", "]", "\n", "\n", "#pos = text_b.find(text_a)", "\n", "#text_a = text_b[:pos] + \" <b> \" + text_b[pos:pos + len(text_a)] + \" </b> \" + text_b[pos + len(text_a):]", "\n", "#text_b = None", "\n", "\n", "if", "len", "(", "line", ")", "<", "6", "or", "line", "[", "5", "]", "==", "'?'", ":", "\n", "                ", "label", "=", "self", ".", "get_labels", "(", ")", "[", "0", "]", "\n", "", "else", ":", "\n", "                ", "label", "=", "line", "[", "5", "]", "\n", "", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "guid", ",", "text_a", "=", "text_a", ",", "text_b", "=", "text_b", ",", "label", "=", "label", ")", ")", "\n", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.generate_misspelling": [[10, 22], ["phrase.split", "random.random", "random.choice", "new_phrase.append", "new_phrase.append", "range", "len", "random.choice", "range", "len"], "function", ["None"], ["def", "generate_misspelling", "(", "phrase", ",", "p", "=", "0.5", ")", ":", "\n", "    ", "new_phrase", "=", "[", "]", "\n", "words", "=", "phrase", ".", "split", "(", "' '", ")", "\n", "for", "word", "in", "words", ":", "\n", "        ", "outcome", "=", "random", ".", "random", "(", ")", "\n", "if", "outcome", "<=", "p", ":", "\n", "            ", "ix", "=", "random", ".", "choice", "(", "range", "(", "len", "(", "word", ")", ")", ")", "\n", "new_word", "=", "''", ".", "join", "(", "[", "word", "[", "w", "]", "if", "w", "!=", "ix", "else", "random", ".", "choice", "(", "string", ".", "ascii_letters", ")", "for", "w", "in", "range", "(", "len", "(", "word", ")", ")", "]", ")", "\n", "new_phrase", ".", "append", "(", "new_word", ")", "\n", "", "else", ":", "\n", "            ", "new_phrase", ".", "append", "(", "word", ")", "\n", "", "", "return", "' '", ".", "join", "(", "new_phrase", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.simple_accuracy": [[24, 26], ["None"], "function", ["None"], ["", "def", "simple_accuracy", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "return", "(", "preds", "==", "labels", ")", ".", "mean", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.acc_and_f1_macro": [[28, 35], ["utils.simple_accuracy", "sklearn.metrics.f1_score"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.simple_accuracy"], ["", "def", "acc_and_f1_macro", "(", "preds", ",", "labels", ")", ":", "\n", "    ", "acc", "=", "simple_accuracy", "(", "preds", ",", "labels", ")", "\n", "f1", "=", "f1_score", "(", "y_true", "=", "labels", ",", "y_pred", "=", "preds", ",", "average", "=", "'macro'", ")", "\n", "return", "{", "\n", "\"acc\"", ":", "acc", ",", "\n", "\"f1\"", ":", "f1", ",", "\n", "\"acc_and_f1\"", ":", "(", "acc", "+", "f1", ")", "/", "2", ",", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.glue_compute_metrics": [[38, 44], ["len", "len", "utils.acc_and_f1_macro", "KeyError"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.utils.acc_and_f1_macro"], ["", "def", "glue_compute_metrics", "(", "task_name", ",", "preds", ",", "labels", ")", ":", "\n", "    ", "assert", "len", "(", "preds", ")", "==", "len", "(", "labels", ")", "\n", "if", "task_name", "==", "\"prop\"", ":", "\n", "        ", "return", "acc_and_f1_macro", "(", "preds", ",", "labels", ")", "\n", "", "else", ":", "\n", "        ", "raise", "KeyError", "(", "task_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.get_highlight_color": [[20, 25], ["len", "len", "math.floor", "len"], "function", ["None"], ["def", "get_highlight_color", "(", "index", ")", ":", "\n", "    ", "if", "index", "<=", "len", "(", "HIGHLIGHT_COLORS", ")", ":", "\n", "        ", "return", "HIGHLIGHT_COLORS", "[", "index", "]", "\n", "", "else", ":", "\n", "        ", "return", "HIGHLIGHT_COLORS", "[", "index", "-", "(", "len", "(", "HIGHLIGHT_COLORS", ")", "*", "math", ".", "floor", "(", "index", "/", "len", "(", "HIGHLIGHT_COLORS", ")", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.transform_to_tree": [[27, 67], ["enumerate", "enumerate", "sorted", "[].append", "inside_clusters.append", "inside_clusters.pop", "[].append", "functools.cmp_to_key", "len", "sorted.append"], "function", ["None"], ["", "", "def", "transform_to_tree", "(", "tokens", ",", "clusters", ")", ":", "\n", "    ", "def", "contains", "(", "span", ",", "index", ")", ":", "\n", "        ", "return", "index", ">=", "span", "[", "0", "]", "and", "index", "<=", "span", "[", "1", "]", "\n", "\n", "", "inside_clusters", "=", "[", "{", "\n", "'cluster'", ":", "-", "1", ",", "\n", "'contents'", ":", "[", "]", ",", "\n", "'end'", ":", "-", "1", "\n", "}", "]", "\n", "\n", "for", "i", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "# Find all the new clusters we are entering at the current index", "\n", "        ", "new_clusters", "=", "[", "]", "\n", "for", "j", ",", "cluster", "in", "enumerate", "(", "clusters", ")", ":", "\n", "#Make sure we're not already in this cluster", "\n", "            ", "if", "j", "not", "in", "[", "c", "[", "'cluster'", "]", "for", "c", "in", "inside_clusters", "]", ":", "\n", "                ", "for", "span", "in", "cluster", ":", "\n", "                    ", "if", "i", "in", "span", ":", "\n", "                        ", "new_clusters", ".", "append", "(", "{", "'end'", ":", "span", "[", "1", "]", ",", "'cluster'", ":", "j", "}", ")", "\n", "\n", "# Enter each new cluster, starting with the leftmost", "\n", "", "", "", "", "new_clusters", "=", "sorted", "(", "new_clusters", ",", "key", "=", "functools", ".", "cmp_to_key", "(", "lambda", "a", ",", "b", ":", "b", "[", "'end'", "]", "-", "a", "[", "'end'", "]", ")", ")", "\n", "for", "new_cluster", "in", "new_clusters", ":", "\n", "#Descend into the new cluster", "\n", "            ", "inside_clusters", ".", "append", "(", "{", "\n", "'cluster'", ":", "new_cluster", "[", "'cluster'", "]", ",", "\n", "'contents'", ":", "[", "]", ",", "\n", "'end'", ":", "new_cluster", "[", "'end'", "]", "\n", "}", ")", "\n", "\n", "#Add the current token into the current cluster", "\n", "", "inside_clusters", "[", "-", "1", "]", "[", "'contents'", "]", ".", "append", "(", "token", ")", "\n", "\n", "# Exit each cluster we're at the end of", "\n", "while", "(", "len", "(", "inside_clusters", ")", ">", "0", "and", "inside_clusters", "[", "-", "1", "]", "[", "'end'", "]", "==", "i", ")", ":", "\n", "            ", "top_cluster", "=", "inside_clusters", "[", "-", "1", "]", "\n", "inside_clusters", ".", "pop", "(", ")", "\n", "inside_clusters", "[", "-", "1", "]", "[", "'contents'", "]", ".", "append", "(", "top_cluster", ")", "\n", "\n", "", "", "return", "inside_clusters", "[", "0", "]", "[", "'contents'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.gen_elem": [[77, 96], ["isinstance", "isinstance", "html_template.get_highlight_color", "html_template.span_wrapper"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.get_highlight_color", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.span_wrapper"], ["def", "gen_elem", "(", "token", ",", "idx", ",", "depth", ",", "task", ")", ":", "\n", "    ", "if", "isinstance", "(", "token", ",", "dict", ")", "or", "isinstance", "(", "token", ",", "list", ")", ":", "\n", "        ", "if", "task", "==", "'TC'", ":", "\n", "            ", "title", "=", "mapping", "[", "token", "[", "'cluster'", "]", "]", "\n", "", "elif", "task", "==", "'SI'", ":", "\n", "            ", "title", "=", "'PROP'", "\n", "", "else", ":", "\n", "            ", "title", "=", "token", "[", "'cluster'", "]", "\n", "", "return", "'<span key={} class=\"highlight {}\" depth={} id={} onmouseover=\"handleHighlightMouseOver(this)\" \\\n                onmouseout=\"handleHighlightMouseOut(this)\" labelPosition=\"left\">\\\n                <span class=\"highlight__label\"><strong>{}</strong></span>\\\n                <span class=\"highlight__content\">{}</span></span>'", ".", "format", "(", "idx", ",", "\n", "get_highlight_color", "(", "token", "[", "'cluster'", "]", ")", ",", "\n", "depth", ",", "\n", "title", ",", "\n", "title", ",", "\n", "' '", ".", "join", "(", "span_wrapper", "(", "token", "[", "'contents'", "]", ",", "depth", "+", "1", ",", "task", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "'<span>{} </span>'", ".", "format", "(", "token", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.span_wrapper": [[98, 100], ["html_template.gen_elem", "enumerate"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.gen_elem"], ["", "", "def", "span_wrapper", "(", "tree", ",", "depth", ",", "task", ")", ":", "\n", "      ", "return", "[", "gen_elem", "(", "token", ",", "idx", ",", "depth", ",", "task", ")", "for", "idx", ",", "token", "in", "enumerate", "(", "tree", ")", "]", "", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.unify_data_format": [[7, 21], ["kwargs.get", "kwargs.get", "kwargs.get", "kwargs.get", "fn", "__init__.stanford_data_adapter", "__init__.allen_data_adapter", "__init__.huggingface_data_adapter", "__init__.labelled_pronoun"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.stanford_data_adapter", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.allen_data_adapter", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.huggingface_data_adapter", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.labelled_pronoun"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.render": [[25, 41], ["__init__.to_html", "IPython.core.display.display", "IPython.core.display.HTML"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.to_html"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.stanford_data_adapter": [[42, 59], ["sents.append", "data[].items", "sum", "sents[].append", "clusters.append", "clusters[].append", "numpy.cumsum", "numpy.cumsum", "list", "list", "map", "map"], "function", ["None"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.allen_data_adapter": [[60, 62], ["None"], "function", ["None"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.huggingface_data_adapter": [[63, 74], ["clusters.append", "clusters[].append"], "function", ["None"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.labelled_pronoun": [[75, 95], ["txt.split", "len", "len", "len", "clusters[].append", "txt[].split", "txt[].split", "txt[].split", "clusters[].append", "clusters.append", "len", "len", "len", "row.a.split", "row.b.split", "row.pronoun.split", "len", "row.pronoun.split", "len", "row.pronoun.split"], "function", ["None"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.__init__.to_html": [[96, 101], ["html_template.transform_to_tree", "html_template.span_wrapper"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.transform_to_tree", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.visualization.html_template.span_wrapper"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.load_data": [[12, 24], ["glob.glob", "sorted", "os.path.join", "open", "open", "articles_content.append", "articles_id.append", "line.rstrip", "f.read", "f.readlines", "os.path.basename().split", "os.path.basename"], "function", ["None"], ["articles", "=", "{", "}", "\n", "article_id_list", ",", "sentence_id_list", ",", "sentence_list", "=", "(", "[", "]", ",", "[", "]", ",", "[", "]", ")", "\n", "for", "filename", "in", "sorted", "(", "file_list", ")", ":", "\n", "        ", "article_id", "=", "os", ".", "path", ".", "basename", "(", "filename", ")", ".", "split", "(", "\".\"", ")", "[", "0", "]", "[", "7", ":", "]", "\n", "with", "codecs", ".", "open", "(", "filename", ",", "\"r\"", ",", "encoding", "=", "\"utf8\"", ")", "as", "f", ":", "\n", "            ", "articles", "[", "article_id", "]", "=", "f", ".", "read", "(", ")", "\n", "", "", "return", "articles", "\n", "\n", "\n", "", "def", "read_predictions_from_file", "(", "filename", ")", ":", "\n", "    ", "articles_id", ",", "span_starts", ",", "span_ends", ",", "gold_labels", "=", "(", "[", "]", ",", "[", "]", ",", "[", "]", ",", "[", "]", ")", "\n", "with", "open", "(", "filename", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "for", "row", "in", "f", ".", "readlines", "(", ")", ":", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.read_predictions_from_file": [[26, 34], ["open", "f.readlines", "row.rstrip().split", "articles_id.append", "gold_spans.append", "tuple", "row.rstrip", "int"], "function", ["None"], ["articles_id", ".", "append", "(", "article_id", ")", "\n", "gold_labels", ".", "append", "(", "gold_label", ")", "\n", "span_starts", ".", "append", "(", "span_start", ")", "\n", "span_ends", ".", "append", "(", "span_end", ")", "\n", "", "", "return", "articles_id", ",", "span_starts", ",", "span_ends", ",", "gold_labels", "\n", "\n", "\n", "", "def", "load_data", "(", "data_folder", ",", "labels_file", ")", ":", "\n", "    ", "articles", "=", "read_articles_from_file_list", "(", "data_folder", ")", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.group_spans_by_article_ids": [[36, 43], ["data.setdefault", "data[].append"], "function", ["None"], ["return", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", "\n", "\n", "\n", "", "def", "sents_token_bounds", "(", "text", ")", ":", "\n", "    ", "sents_starts", "=", "[", "]", "\n", "for", "start", ",", "end", "in", "PunktSentenceTokenizer", "(", ")", ".", "span_tokenize", "(", "text", ")", ":", "\n", "        ", "sents_starts", ".", "append", "(", "start", ")", "\n", "", "sents_starts", ".", "append", "(", "100000", ")", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.get_train_dev_files": [[45, 67], ["dict", "dataset.read_predictions_from_file", "list", "dataset.create_BIO_labeled", "dataset.create_BIO_labeled", "zip", "zip", "dataset.group_spans_by_article_ids", "sklearn.model_selection.train_test_split", "sorted", "sorted", "sklearn.model_selection.train_test_split", "sorted", "sorted", "numpy.unique", "group_spans_by_article_ids().items", "group_spans_by_article_ids().items", "group_spans_by_article_ids.items", "group_spans_by_article_ids.items", "dataset.group_spans_by_article_ids", "dataset.group_spans_by_article_ids"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.read_predictions_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_BIO_labeled", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_BIO_labeled", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.group_spans_by_article_ids", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.group_spans_by_article_ids", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.group_spans_by_article_ids"], ["\n", "\n", "", "def", "clear", "(", "text", ")", ":", "\n", "    ", "return", "text", ".", "strip", "(", ")", ".", "replace", "(", "'\\t'", ",", "' '", ")", ".", "replace", "(", "'\\n'", ",", "' '", ")", "\n", "\n", "\n", "", "def", "get_context", "(", "article", ",", "span_start", ",", "span_end", ")", ":", "\n", "    ", "bounds", "=", "sents_token_bounds", "(", "article", ")", "\n", "context_start", "=", "bounds", "[", "np", ".", "where", "(", "bounds", "<=", "span_start", ")", "[", "0", "]", "[", "-", "1", "]", "]", "\n", "context_end", "=", "bounds", "[", "np", ".", "where", "(", "bounds", ">=", "span_end", ")", "[", "0", "]", "[", "0", "]", "]", "\n", "return", "clear", "(", "article", "[", "context_start", ":", "context_end", "]", ")", "\n", "\n", "\n", "", "def", "balance_pandas", "(", "data", ")", ":", "\n", "    ", "lst", "=", "[", "data", "]", "\n", "max_size", "=", "data", "[", "'label'", "]", ".", "value_counts", "(", ")", ".", "max", "(", ")", "\n", "for", "class_index", ",", "group", "in", "data", ".", "groupby", "(", "'label'", ")", ":", "\n", "        ", "lst", ".", "append", "(", "group", ".", "sample", "(", "max_size", "-", "len", "(", "group", ")", ",", "replace", "=", "True", ")", ")", "\n", "", "return", "pd", ".", "concat", "(", "lst", ")", "\n", "\n", "\n", "", "def", "dataset_to_pandas", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "train_gold_labels", ")", ":", "\n", "    ", "data", "=", "pd", ".", "DataFrame", ".", "from_dict", "(", "{", "'article_id'", ":", "ref_articles_id", ",", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.get_test_file": [[69, 71], ["dataset.create_BIO_unlabeled"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_BIO_unlabeled"], ["'span_start'", ":", "np", ".", "array", "(", "ref_span_starts", ")", ".", "astype", "(", "int", ")", ",", "\n", "'span_end'", ":", "np", ".", "array", "(", "ref_span_ends", ")", ".", "astype", "(", "int", ")", ",", "\n", "'label'", ":", "train_gold_labels", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.token_label_from_spans": [[73, 78], ["int"], "function", ["None"], ["data", "[", "'span'", "]", "=", "data", ".", "apply", "(", "lambda", "x", ":", "clear", "(", "x", "[", "'article'", "]", "[", "x", "[", "'span_start'", "]", ":", "x", "[", "'span_end'", "]", "]", ")", ",", "axis", "=", "1", ")", "\n", "data", "[", "'context'", "]", "=", "data", ".", "apply", "(", "lambda", "x", ":", "get_context", "(", "x", "[", "'article'", "]", ",", "x", "[", "'span_start'", "]", ",", "x", "[", "'span_end'", "]", ")", ",", "axis", "=", "1", ")", "\n", "return", "data", "[", "[", "'article_id'", ",", "'span_start'", ",", "'span_end'", ",", "'span'", ",", "'context'", ",", "'label'", "]", "]", "\n", "\n", "\n", "", "def", "get_train_dev_files", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ",", "train_file", ",", "dev_file", ",", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_BIO_labeled": [[80, 108], ["open", "tqdm.tqdm", "range", "numpy.array", "numpy.array", "len", "tokens[].replace().replace().strip", "nlp", "tokens[].strip().replace().replace", "dataset.token_label_from_spans", "f.write", "tokens[].replace().replace", "len", "repr", "repr", "repr", "repr", "f.write", "tokens[].strip().replace", "tokens[].replace", "tokens[].strip"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.token_label_from_spans"], ["    ", "data", "=", "dataset_to_pandas", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ")", "\n", "if", "split_by_ids", ":", "\n", "        ", "train_ids", ",", "dev_ids", "=", "train_test_split", "(", "data", ".", "article_id", ".", "unique", "(", ")", ",", "test_size", "=", "dev_size", ",", "random_state", "=", "random_state", ")", "\n", "train", "=", "data", "[", "data", ".", "article_id", ".", "isin", "(", "train_ids", ")", "]", "\n", "dev", "=", "data", "[", "data", ".", "article_id", ".", "isin", "(", "dev_ids", ")", "]", "\n", "", "else", ":", "\n", "        ", "train", ",", "dev", "=", "train_test_split", "(", "data", ",", "test_size", "=", "dev_size", ",", "random_state", "=", "random_state", ")", "\n", "\n", "", "if", "balance", ":", "\n", "        ", "train", "=", "balance_pandas", "(", "train", ")", "\n", "", "if", "shuffle", ":", "\n", "        ", "train", "=", "train", ".", "sample", "(", "frac", "=", "1", ")", ".", "reset_index", "(", "drop", "=", "True", ")", "\n", "\n", "", "save_dataset", "(", "train", ",", "train_file", ")", "\n", "save_dataset", "(", "dev", ",", "dev_file", ")", "\n", "\n", "\n", "", "def", "get_test_file", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ",", "test_file", ")", ":", "\n", "    ", "test", "=", "dataset_to_pandas", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ")", "\n", "save_dataset", "(", "test", ",", "test_file", ")", "\n", "\n", "\n", "", "def", "save_dataset", "(", "data", ",", "file_path", ")", ":", "\n", "    ", "data", ".", "to_csv", "(", "file_path", ",", "sep", "=", "'\\t'", ",", "index", "=", "False", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_BIO_unlabeled": [[110, 132], ["open", "tqdm.tqdm", "zip", "range", "numpy.array", "numpy.array", "len", "tokens[].replace().replace().strip", "nlp", "tokens[].strip().replace().replace", "f.write", "tokens[].replace().replace", "len", "repr", "repr", "repr", "repr", "f.write", "tokens[].strip().replace", "tokens[].replace", "tokens[].strip"], "function", ["None"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_subfolder": [[134, 141], ["os.path.exists", "os.makedirs", "shutil.rmtree", "shutil.copyfile", "os.path.join", "os.path.join", "str"], "function", ["None"], []], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.merge_spans": [[9, 33], ["dict", "dict", "zip", "numpy.zeros", "range", "len", "len", "res[].append"], "function", ["None"], ["from", "nltk", ".", "corpus", "import", "stopwords", "\n", "import", "string", "\n", "import", "pickle", "\n", "import", "os", "\n", "from", "unidecode", "import", "unidecode", "\n", "from", "joblib", "import", "dump", ",", "load", "\n", "\n", "\n", "def", "get_insides", "(", "data", ")", ":", "\n", "    ", "insides", "=", "defaultdict", "(", "dict", ")", "\n", "spans_coords", "=", "list", "(", "zip", "(", "data", "[", "'span_start'", "]", ".", "values", ",", "data", "[", "'span_end'", "]", ".", "values", ")", ")", "\n", "labels", "=", "data", "[", "'label'", "]", ".", "values", "\n", "article_ids", "=", "data", "[", "'article_id'", "]", ".", "values", "\n", "for", "i", "in", "range", "(", "len", "(", "spans_coords", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "i", ")", ":", "\n", "            ", "if", "article_ids", "[", "i", "]", "==", "article_ids", "[", "j", "]", ":", "\n", "                ", "if", "spans_coords", "[", "i", "]", "[", "0", "]", ">=", "spans_coords", "[", "j", "]", "[", "0", "]", "and", "spans_coords", "[", "i", "]", "[", "1", "]", "<=", "spans_coords", "[", "j", "]", "[", "1", "]", ":", "\n", "                    ", "if", "spans_coords", "[", "i", "]", "[", "0", "]", "!=", "spans_coords", "[", "j", "]", "[", "0", "]", "or", "spans_coords", "[", "i", "]", "[", "1", "]", "!=", "spans_coords", "[", "j", "]", "[", "1", "]", ":", "\n", "                        ", "insides", "[", "labels", "[", "i", "]", "]", "[", "labels", "[", "j", "]", "]", "=", "insides", "[", "labels", "[", "i", "]", "]", ".", "get", "(", "labels", "[", "j", "]", ",", "0", ")", "+", "1", "\n", "", "", "if", "spans_coords", "[", "j", "]", "[", "0", "]", ">=", "spans_coords", "[", "i", "]", "[", "0", "]", "and", "spans_coords", "[", "j", "]", "[", "1", "]", "<=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                    ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", "!=", "spans_coords", "[", "i", "]", "[", "0", "]", "or", "spans_coords", "[", "j", "]", "[", "1", "]", "!=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                        ", "insides", "[", "labels", "[", "j", "]", "]", "[", "labels", "[", "i", "]", "]", "=", "insides", "[", "labels", "[", "j", "]", "]", ".", "get", "(", "labels", "[", "i", "]", ",", "0", ")", "+", "1", "\n", "", "", "", "", "", "return", "insides", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.correct_spans": [[35, 94], ["set", "dict", "dict", "nltk.corpus.stopwords.words", "zip", "numpy.zeros", "range", "len", "len", "unidecode.unidecode", "unidecode.unidecode", "unidecode.unidecode", "res[].append", "article[].isalnum", "unidecode.unidecode", "unidecode.unidecode", "unidecode.unidecode", "article[].isalnum", "article[].isalnum", "article[].lower", "res[].append"], "function", ["None"], ["    ", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "            ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", ">=", "spans_coords", "[", "i", "]", "[", "0", "]", "and", "spans_coords", "[", "j", "]", "[", "1", "]", "<=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", "!=", "spans_coords", "[", "i", "]", "[", "0", "]", "or", "spans_coords", "[", "j", "]", "[", "1", "]", "!=", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                    ", "def_i", "=", "preds", "[", "i", "]", "\n", "def_j", "=", "preds", "[", "j", "]", "\n", "log", "=", "softmax", "(", "[", "logits", "[", "i", "]", "]", ")", "[", "0", "]", "\n", "login", "=", "softmax", "(", "[", "logits", "[", "j", "]", "]", ")", "[", "0", "]", "\n", "def_prob_i", "=", "log", "[", "inverse_mapping", "[", "preds", "[", "i", "]", "]", "]", "\n", "def_prob_j", "=", "login", "[", "inverse_mapping", "[", "preds", "[", "j", "]", "]", "]", "\n", "while", "preds", "[", "j", "]", "not", "in", "insides", ".", "get", "(", "preds", "[", "i", "]", ",", "[", "]", ")", ":", "\n", "                        ", "if", "log", "[", "inverse_mapping", "[", "preds", "[", "i", "]", "]", "]", ">", "login", "[", "inverse_mapping", "[", "preds", "[", "j", "]", "]", "]", ":", "\n", "                            ", "values", "=", "np", ".", "sort", "(", "login", ")", "[", "-", "2", ":", "]", "\n", "if", "values", "[", "1", "]", "/", "(", "values", "[", "0", "]", "+", "1e-6", ")", ">", "1.4", ":", "\n", "                                ", "preds", "[", "i", "]", "=", "def_i", "\n", "preds", "[", "j", "]", "=", "def_j", "\n", "break", "\n", "", "login", "[", "inverse_mapping", "[", "preds", "[", "j", "]", "]", "]", "=", "0", "\n", "preds", "[", "j", "]", "=", "mapping", "[", "np", ".", "argmax", "(", "login", ")", "]", "\n", "", "else", ":", "\n", "                            ", "values", "=", "np", ".", "sort", "(", "log", ")", "[", "-", "2", ":", "]", "\n", "if", "values", "[", "1", "]", "/", "(", "values", "[", "0", "]", "+", "1e-6", ")", ">", "1.4", ":", "\n", "                                ", "preds", "[", "i", "]", "=", "def_i", "\n", "preds", "[", "j", "]", "=", "def_j", "\n", "break", "\n", "", "log", "[", "inverse_mapping", "[", "preds", "[", "i", "]", "]", "]", "=", "0", "\n", "preds", "[", "i", "]", "=", "mapping", "[", "np", ".", "argmax", "(", "log", ")", "]", "\n", "", "", "", "", "", "", "return", "preds", "\n", "\n", "\n", "", "def", "stem_spans", "(", "spans", ")", ":", "\n", "    ", "ps", "=", "PorterStemmer", "(", ")", "\n", "res", "=", "[", "]", "\n", "for", "el", "in", "spans", ":", "\n", "        ", "result", "=", "\" \"", ".", "join", "(", "ps", ".", "stem", "(", "word", ")", "for", "word", "in", "word_tokenize", "(", "el", ".", "lower", "(", ")", ")", ")", "\n", "if", "len", "(", "result", ")", ">", "0", ":", "\n", "            ", "res", ".", "append", "(", "result", ")", "\n", "", "", "return", "res", "\n", "\n", "\n", "", "def", "get_train_instances", "(", "data", ",", "data_dir", ",", "save", "=", "True", ")", ":", "\n", "    ", "train_instances", "=", "dict", "(", ")", "\n", "stemmed_spans", "=", "stem_spans", "(", "data", ".", "span", ".", "values", ")", "\n", "labels", "=", "data", ".", "label", ".", "values", "\n", "for", "i", "in", "range", "(", "len", "(", "stemmed_spans", ")", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "!=", "'Repetition'", ":", "\n", "            ", "span", "=", "stemmed_spans", "[", "i", "]", "\n", "train_instances", ".", "setdefault", "(", "span", ",", "set", "(", ")", ")", "\n", "train_instances", "[", "span", "]", ".", "add", "(", "labels", "[", "i", "]", ")", "\n", "", "", "if", "save", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'train_instances_train'", ")", ",", "'wb'", ")", "as", "f", ":", "\n", "            ", "pickle", ".", "dump", "(", "train_instances", ",", "f", ")", "\n", "", "", "return", "train_instances", "\n", "\n", "\n", "", "def", "postprocess", "(", "x", ",", "mapping", ",", "inverse_mapping", ",", "insides", ",", "stop_words", ",", "ps", ",", "train_instances", ")", ":", "\n", "    ", "spans_coords", "=", "list", "(", "zip", "(", "x", "[", "'span_start'", "]", ".", "values", ",", "x", "[", "'span_end'", "]", ".", "values", ")", ")", "\n", "spans_source", "=", "x", "[", "'span'", "]", ".", "values", "\n", "spans_text", "=", "[", "' '", ".", "join", "(", "[", "ps", ".", "stem", "(", "word", ")", "for", "word", "in", "word_tokenize", "(", "span", ".", "lower", "(", ")", ")", "]", ")", "for", "span", "in", "spans_source", "]", "\n", "spans", "=", "[", "' '", ".", "join", "(", "[", "ps", ".", "stem", "(", "word", ")", "for", "word", "in", "word_tokenize", "(", "unidecode", "(", "span", ".", "lower", "(", ")", ")", ")", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.get_spans_from_file": [[96, 132], ["dict", "submission.correct_spans", "open", "zip", "dict.setdefault", "range", "numpy.array", "numpy.array", "token.strip().replace().replace", "len", "nlp", "f.readline().split", "label.strip.strip", "token.strip().replace", "len", "repr", "repr", "repr", "repr", "int", "f.readline", "f.readline", "pred_spans[].append", "pred_spans[].append", "token.strip", "int", "int", "len", "int", "len", "int", "len"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.correct_spans"], ["\n", "counts", "=", "dict", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "spans", ")", ")", ":", "\n", "        ", "counts", ".", "setdefault", "(", "spans", "[", "i", "]", ",", "set", "(", ")", ")", "\n", "counts", "[", "spans", "[", "i", "]", "]", ".", "add", "(", "spans_coords", "[", "i", "]", "[", "0", "]", ")", "\n", "", "for", "el", "in", "counts", ":", "\n", "        ", "counts", "[", "el", "]", "=", "len", "(", "counts", "[", "el", "]", ")", "\n", "\n", "", "preds", "=", "x", "[", "'pred'", "]", ".", "values", "\n", "logits", "=", "[", "np", ".", "array", "(", "log", ".", "split", "(", ")", ",", "dtype", "=", "np", ".", "float32", ")", "for", "log", "in", "x", "[", "'logits'", "]", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "preds", ")", ")", ":", "\n", "        ", "log", "=", "logits", "[", "i", "]", "\n", "\n", "if", "counts", "[", "spans", "[", "i", "]", "]", ">=", "3", "or", "(", "counts", "[", "spans", "[", "i", "]", "]", ">=", "2", "and", "logits", "[", "i", "]", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", ">", "0.001", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", "=", "100", "\n", "\n", "", "if", "counts", "[", "spans", "[", "i", "]", "]", "==", "1", "and", "(", "logits", "[", "i", "]", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", "<", "0.99", "or", "len", "(", "spans", "[", "i", "]", ".", "split", "(", ")", ")", "<=", "1", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "\"Repetition\"", "]", "]", "=", "0", "\n", "\n", "", "for", "prediction", "in", "train_instances", ".", "get", "(", "spans_text", "[", "i", "]", ",", "set", "(", ")", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "prediction", "]", "]", "+=", "0.5", "\n", "", "if", "spans_source", "[", "i", "]", ".", "startswith", "(", "'#'", ")", ":", "\n", "            ", "log", "[", "inverse_mapping", "[", "'Slogans'", "]", "]", "=", "20", "\n", "\n", "\n", "", "prev_same", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "i", ")", ":", "\n", "            ", "if", "spans_coords", "[", "j", "]", "[", "0", "]", "==", "spans_coords", "[", "i", "]", "[", "0", "]", "and", "spans_coords", "[", "j", "]", "[", "1", "]", "==", "spans_coords", "[", "i", "]", "[", "1", "]", ":", "\n", "                ", "prev_same", ".", "append", "(", "j", ")", "\n", "", "", "if", "len", "(", "prev_same", ")", ">", "0", ":", "\n", "            ", "for", "prediction", "in", "preds", "[", "prev_same", "]", ":", "\n", "                ", "log", "[", "inverse_mapping", "[", "prediction", "]", "]", "=", "0", "\n", "\n", "", "", "logits", "[", "i", "]", "=", "log", "\n", "preds", "[", "i", "]", "=", "mapping", "[", "np", ".", "argmax", "(", "log", ")", "]", "\n", "\n", "", "x", "[", "\"pred\"", "]", "=", "correct_preds_for_insides", "(", "preds", ",", "spans_coords", ",", "logits", ",", "insides", ",", "mapping", ",", "inverse_mapping", ")", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.get_submission_format": [[134, 146], ["dict", "submission.merge_spans", "submission.get_spans_from_file", "open", "merge_spans.items", "merge_spans.get", "fout.write"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.merge_spans", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.get_spans_from_file"], ["return", "x", "\n", "\n", "\n", "", "def", "postprocess_predictions", "(", "predictions_logits", ",", "data", ",", "insides", ",", "train_instances", ")", ":", "\n", "    ", "mapping", "=", "{", "i", ":", "el", "for", "i", ",", "el", "in", "enumerate", "(", "\n", "[", "'Appeal_to_Authority'", ",", "'Doubt'", ",", "'Repetition'", ",", "'Appeal_to_fear-prejudice'", ",", "'Slogans'", ",", "'Black-and-White_Fallacy'", ",", "\n", "'Loaded_Language'", ",", "'Flag-Waving'", ",", "'Name_Calling,Labeling'", ",", "'Whataboutism,Straw_Men,Red_Herring'", ",", "\n", "'Causal_Oversimplification'", ",", "'Exaggeration,Minimisation'", ",", "'Bandwagon,Reductio_ad_hitlerum'", ",", "\n", "'Thought-terminating_Cliches'", "]", "\n", ")", "}", "\n", "inverse_mapping", "=", "{", "b", ":", "a", "for", "(", "a", ",", "b", ")", "in", "mapping", ".", "items", "(", ")", "}", "\n", "\n", "stop_words", "=", "set", "(", "stopwords", ".", "words", "(", "'english'", ")", ")", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.__main__.Main": [[21, 72], ["spacy.load", "os.path.exists", "os.makedirs", "load_data", "os.path.join", "os.path.join", "load_data", "os.path.join", "logger.info", "os.path.join", "get_submission_format", "subprocess.run", "os.path.join", "logger.info", "get_submission_format", "logger.info", "get_train_dev_files", "logger.info", "get_test_file", "transformers_ner_crf", "transformers_ner", "next", "get_submission_format", "os.remove", "os.path.exists", "os.makedirs", "os.path.exists", "os.path.exists", "create_subfolder", "create_subfolder", "tempfile._get_candidate_names", "os.path.join", "os.path.join", "os.path.exists"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.load_data", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.load_data", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.get_submission_format", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.get_submission_format", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.get_train_dev_files", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.get_test_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.transformers_ner_crf", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner.transformers_ner", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.submission.get_submission_format", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_subfolder", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.dataset.create_subfolder"], ["        ", "os", ".", "makedirs", "(", "args", ".", "data_dir", ")", "\n", "\n", "", "if", "args", ".", "do_train", "or", "args", ".", "do_eval", "or", "args", ".", "split_dataset", "or", "args", ".", "create_submission_file", ":", "\n", "        ", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", "=", "load_data", "(", "args", ".", "train_data_folder", ",", "\n", "args", ".", "labels_path", ")", "\n", "train_file_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "train_file", ")", "\n", "dev_file_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "dev_file", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "train_file_path", ")", "or", "not", "os", ".", "path", ".", "exists", "(", "dev_file_path", ")", "or", "args", ".", "overwrite_cache", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating train/dev files: %s, %s\"", ",", "train_file_path", ",", "dev_file_path", ")", "\n", "get_train_dev_files", "(", "articles", ",", "ref_articles_id", ",", "ref_span_starts", ",", "ref_span_ends", ",", "labels", ",", "train_file_path", ",", "\n", "dev_file_path", ",", "args", ".", "split_by_ids", ",", "args", ".", "dev_size", ",", "args", ".", "random_state", ",", "args", ".", "balance", ",", "\n", "args", ".", "shuffle", ")", "\n", "\n", "", "", "if", "args", ".", "do_predict", "or", "args", ".", "create_submission_file", "or", "args", ".", "eval_submission", ":", "\n", "        ", "test_file_path", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "test_file", ")", "\n", "test_articles", ",", "test_articles_id", ",", "test_span_starts", ",", "test_span_ends", ",", "test_labels", "=", "load_data", "(", "args", ".", "test_data_folder", ",", "\n", "args", ".", "test_template_labels_path", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "test_file_path", ")", "or", "args", ".", "overwrite_cache", ":", "\n", "            ", "logger", ".", "info", "(", "\"Creating roberta-type test file: %s\"", ",", "test_file_path", ")", "\n", "get_test_file", "(", "test_articles", ",", "test_articles_id", ",", "test_span_starts", ",", "test_span_ends", ",", "test_labels", ",", "test_file_path", ")", "\n", "\n", "", "", "if", "args", ".", "do_train", "or", "args", ".", "do_eval", "or", "args", ".", "do_predict", ":", "\n", "        ", "transformers_clf", "(", "args", ")", "\n", "\n", "", "if", "args", ".", "create_submission_file", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "'results'", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "'results'", ")", "\n", "", "output_file", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "args", ".", "output_file", ")", "\n", "logger", ".", "info", "(", "\"Creating the submission file: %s\"", ",", "output_file", ")", "\n", "create_submission_file", "(", "args", ".", "predicted_logits_files", ",", "train_file_path", ",", "dev_file_path", ",", "test_file_path", ",", "\n", "test_articles_id", ",", "test_span_starts", ",", "test_span_ends", ",", "output_file", ",", "args", ".", "weights", ",", "args", ".", "data_dir", ")", "\n", "\n", "", "if", "args", ".", "eval_submission", ":", "\n", "        ", "output_file", "=", "os", ".", "path", ".", "join", "(", "'results'", ",", "args", ".", "output_file", ")", "\n", "logger", ".", "info", "(", "\"Evaluating the submission file: %s\"", ",", "output_file", ")", "\n", "if", "args", ".", "test_labels_path", "is", "None", ":", "\n", "            ", "acc", ",", "f1", "=", "eval_submission", "(", "output_file", ",", "test_file_path", ")", "\n", "logger", ".", "info", "(", "'accuracy: %f'", ",", "acc", ")", "\n", "print", "(", "'f1-macro:'", ",", "f1", ")", "\n", "", "else", ":", "\n", "            ", "cmd", "=", "\"python tools/task-TC_scorer.py -s {} -r {} -p {}\"", ".", "format", "(", "output_file", ",", "args", ".", "test_labels_path", ",", "\n", "args", ".", "propaganda_techniques_file", ")", "\n", "subprocess", ".", "run", "(", "cmd", ",", "shell", "=", "True", ")", "\n", "\n", "\n", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "configargparse", ".", "ArgumentParser", "(", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--config'", ",", "required", "=", "True", ",", "is_config_file", "=", "True", ",", "help", "=", "'Config file path.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_data_folder\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Source directory with the train articles.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_data_folder\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.__main__.main": [[74, 195], ["configargparse.ArgumentParser", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.add_argument", "configargparse.ArgumentParser.parse_args", "logging.basicConfig", "__main__.Main"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.span_identification.__main__.Main"], ["parser", ".", "add_argument", "(", "\"--propaganda_techniques_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The file with propaganda techniques.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--labels_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The file with train labels.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_template_labels_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The file with test template labels.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--data_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The directory for cached preprocessed data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The filename for cached preprocessed train data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The filename for cached preprocessed dev data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The filename for cached preprocessed test data.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--predicted_logits_files\"", ",", "default", "=", "None", ",", "nargs", "=", "'*'", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The predicted filenames of logits that will be used to obtain the final result\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weights\"", ",", "default", "=", "None", ",", "nargs", "=", "'*'", ",", "required", "=", "False", ",", "\n", "help", "=", "\"The list of weights for predicted logits at the aggregation stage\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_file\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The submission filename\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_size\"", ",", "default", "=", "0.3", ",", "type", "=", "float", ",", "help", "=", "\"Dev data size.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--split_dataset\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Split the dataset into the train/dev parts.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--split_by_ids\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use articles ids while splitting the dataset into the train/dev parts.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--random_state\"", ",", "default", "=", "42", ",", "type", "=", "int", ",", "help", "=", "'Random state for the dataset splitting.'", ")", "\n", "parser", ".", "add_argument", "(", "\"--shuffle\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Shuffle the train dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--balance\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Balance the train dataset with oversampling.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--create_submission_file\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Creats file in the submission (source) format\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_submission\"", ",", "action", "=", "\"store_true\"", ",", "help", "=", "\"Do evaluating for the dev subset.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--use_length'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--join_embeddings'", ",", "action", "=", "'store_true'", ")", "\n", "parser", ".", "add_argument", "(", "'--use_matchings'", ",", "action", "=", "'store_true'", ")", "\n", "\n", "MODEL_CLASSES", "=", "[", "\"bert\"", ",", "\"roberta\"", ",", "\"distilbert\"", ",", "\"camembert\"", "]", "\n", "parser", ".", "add_argument", "(", "\"--model_type\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Model type selected in the list: \"", "+", "\", \"", ".", "join", "(", "MODEL_CLASSES", ")", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name_or_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"Path to pre-trained model or shortcut name.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--task_name\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The name of the task to train.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--output_dir\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "True", ",", "\n", "help", "=", "\"The output directory where the model predictions and checkpoints will be written.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_labels_path\"", ",", "default", "=", "None", ",", "type", "=", "str", ",", "required", "=", "False", ")", "\n", "\n", "## Other parameters", "\n", "parser", ".", "add_argument", "(", "\"--config_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained config name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--tokenizer_name\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Pretrained tokenizer name or path if not the same as model_name\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--cache_dir\"", ",", "default", "=", "\"\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Where do you want to store the pre-trained models downloaded from s3\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_seq_length\"", ",", "default", "=", "128", ",", "type", "=", "int", ",", "\n", "help", "=", "\"The maximum total input sequence length after tokenization. Sequences longer \"", "\n", "\"than this will be truncated, sequences shorter will be padded.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_train\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_eval\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run eval on the dev set.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_predict\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to run prediction\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--evaluate_during_training\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Rul evaluation during training at each logging step.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--do_lower_case\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Set this flag if you are using an uncased model.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_train_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for training.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--per_gpu_eval_batch_size\"", ",", "default", "=", "8", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Batch size per GPU/CPU for evaluation.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--gradient_accumulation_steps'", ",", "type", "=", "int", ",", "default", "=", "1", ",", "\n", "help", "=", "\"Number of updates steps to accumulate before performing a backward/update pass.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--learning_rate\"", ",", "default", "=", "5e-5", ",", "type", "=", "float", ",", "\n", "help", "=", "\"The initial learning rate for Adam.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight_decay\"", ",", "default", "=", "0.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Weight deay if we apply some.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--adam_epsilon\"", ",", "default", "=", "1e-8", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Epsilon for Adam optimizer.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_grad_norm\"", ",", "default", "=", "1.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Max gradient norm.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--num_train_epochs\"", ",", "default", "=", "3.0", ",", "type", "=", "float", ",", "\n", "help", "=", "\"Total number of training epochs to perform.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_steps\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "\n", "help", "=", "\"If > 0: set total number of training steps to perform. Override num_train_epochs.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--warmup_steps\"", ",", "default", "=", "0", ",", "type", "=", "int", ",", "\n", "help", "=", "\"Linear warmup over warmup_steps.\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--logging_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Log every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--save_steps'", ",", "type", "=", "int", ",", "default", "=", "50", ",", "\n", "help", "=", "\"Save checkpoint every X updates steps.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--eval_all_checkpoints\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Evaluate all checkpoints starting with the same prefix as model_name ending and ending with step number\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--no_cuda\"", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Avoid using CUDA when available\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_output_dir'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the content of the output directory\"", ")", "\n", "parser", ".", "add_argument", "(", "'--overwrite_cache'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Overwrite the cached training and evaluation sets\"", ")", "\n", "parser", ".", "add_argument", "(", "'--seed'", ",", "type", "=", "int", ",", "default", "=", "42", ",", "\n", "help", "=", "\"random seed for initialization\"", ")", "\n", "\n", "parser", ".", "add_argument", "(", "'--fp16'", ",", "action", "=", "'store_true'", ",", "\n", "help", "=", "\"Whether to use 16-bit (mixed) precision (through NVIDIA apex) instead of 32-bit\"", ")", "\n", "parser", ".", "add_argument", "(", "'--fp16_opt_level'", ",", "type", "=", "str", ",", "default", "=", "'O1'", ",", "\n", "help", "=", "\"For fp16: Apex AMP optimization level selected in ['O0', 'O1', 'O2', and 'O3'].\"", "\n", "\"See details at https://nvidia.github.io/apex/amp.html\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--local_rank\"", ",", "type", "=", "int", ",", "default", "=", "-", "1", ",", "\n", "help", "=", "\"For distributed training: local_rank\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_ip'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "parser", ".", "add_argument", "(", "'--server_port'", ",", "type", "=", "str", ",", "default", "=", "''", ",", "help", "=", "\"For distant debugging.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "logging", ".", "basicConfig", "(", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "\n", "Main", "(", "args", ")", "\n", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.bert_lstm_crf.BertLstmCrf.__init__": [[29, 74], ["torch.Module.__init__", "conditional_random_field.allowed_transitions", "conditional_random_field.ConditionalRandomField", "torch.Linear", "torch.Linear", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "dict", "enumerate"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.allowed_transitions"], ["def", "__init__", "(", "self", ",", "bert_model", ",", "\n", "num_labels", "=", "9", ",", "\n", "embedding_dim", "=", "512", ",", "\n", "hidden_dim", "=", "512", ",", "\n", "rnn_layers", "=", "1", ",", "\n", "rnn_dropout", "=", "0.1", ",", "\n", "output_dropout", "=", "0.1", ",", "\n", "use_cuda", "=", "False", ")", ":", "\n", "        ", "super", "(", "BertLstmCrf", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "bert_encoder", "=", "bert_model", "\n", "\n", "self", ".", "embedding_dim", "=", "embedding_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "rnn_layers", "=", "rnn_layers", "\n", "\n", "self", ".", "lstm", "=", "None", "\n", "if", "rnn_layers", ">", "0", ":", "\n", "            ", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "\n", "embedding_dim", ",", "\n", "hidden_dim", ",", "\n", "num_layers", "=", "rnn_layers", ",", "\n", "bidirectional", "=", "True", ",", "\n", "dropout", "=", "rnn_dropout", ",", "\n", "batch_first", "=", "True", "\n", ")", "\n", "\n", "# self.crf = CRF(", "\n", "#     target_size=num_labels,", "\n", "#     average_batch=True,", "\n", "#     use_cuda=use_cuda", "\n", "# )", "\n", "\n", "# TODO: add contraints", "\n", "", "constraints", "=", "allowed_transitions", "(", "'BIO'", ",", "dict", "(", "enumerate", "(", "[", "\"O\"", ",", "\"B\"", ",", "\"I\"", "]", ")", ")", ")", "\n", "include_start_end_transitions", "=", "True", "\n", "self", ".", "crf", "=", "ConditionalRandomField", "(", "\n", "num_labels", ",", "\n", "constraints", ",", "\n", "include_start_end_transitions", "=", "include_start_end_transitions", "\n", ")", "\n", "\n", "self", ".", "liner", "=", "nn", ".", "Linear", "(", "hidden_dim", "*", "2", ",", "num_labels", ")", "\n", "self", ".", "num_labels", "=", "num_labels", "\n", "\n", "self", ".", "output_dropout", "=", "nn", ".", "Dropout", "(", "p", "=", "output_dropout", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.bert_lstm_crf.BertLstmCrf.rand_init_hidden": [[75, 82], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn", "torch.randn"], "methods", ["None"], ["", "def", "rand_init_hidden", "(", "self", ",", "batch_size", ")", ":", "\n", "        ", "\"\"\"\n        random initialize hidden variable\n        \"\"\"", "\n", "return", "Variable", "(", "\n", "torch", ".", "randn", "(", "2", "*", "self", ".", "rnn_layers", ",", "batch_size", ",", "self", ".", "hidden_dim", ")", ")", ",", "Variable", "(", "\n", "torch", ".", "randn", "(", "2", "*", "self", ".", "rnn_layers", ",", "batch_size", ",", "self", ".", "hidden_dim", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.bert_lstm_crf.BertLstmCrf.clear_subtokens": [[83, 95], ["torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "torch.zeros_like", "range", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "clear_subtokens", "(", "self", ",", "logits", ",", "labels", ",", "mask", ")", ":", "\n", "        ", "clear_labels", "=", "torch", ".", "zeros_like", "(", "labels", ")", "\n", "clear_logits", "=", "torch", ".", "zeros_like", "(", "logits", ")", "\n", "clear_mask", "=", "torch", ".", "zeros_like", "(", "mask", ")", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "            ", "assert", "(", "mask", "[", "i", "]", "[", "labels", "[", "i", "]", "!=", "-", "100", "]", "==", "1", ")", ".", "all", "(", ")", "\n", "cor", "=", "labels", "[", "i", "]", "[", "labels", "[", "i", "]", "!=", "-", "100", "]", "\n", "clear_labels", "[", "i", "]", "[", ":", "len", "(", "cor", ")", "]", "=", "cor", "\n", "clear_logits", "[", "i", "]", "[", ":", "len", "(", "cor", ")", "]", "=", "logits", "[", "i", "]", "[", "labels", "[", "i", "]", "!=", "-", "100", "]", "\n", "clear_mask", "[", "i", "]", "[", ":", "len", "(", "cor", ")", "]", "=", "1", "\n", "", "return", "clear_logits", ",", "clear_labels", ",", "clear_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.bert_lstm_crf.BertLstmCrf.forward": [[96, 160], ["copy.deepcopy", "kwargs[].size", "kwargs[].size", "bert_lstm_crf.BertLstmCrf.bert_encoder", "out.contiguous().view", "bert_lstm_crf.BertLstmCrf.clear_subtokens", "bert_lstm_crf.BertLstmCrf.crf.viterbi_tags", "typing.cast", "copy.deepcopy.pop", "bert_lstm_crf.BertLstmCrf.rand_init_hidden", "bert_lstm_crf.BertLstmCrf.lstm", "bert_lstm_crf.BertLstmCrf.contiguous().view", "bert_lstm_crf.BertLstmCrf.output_dropout", "bert_lstm_crf.BertLstmCrf.liner", "clear_mask.long", "kwargs.get", "kwargs.get().cpu", "bert_lstm_crf.BertLstmCrf.crf", "numpy.zeros_like", "range", "out.contiguous", "len", "list", "i.cuda", "bert_lstm_crf.BertLstmCrf.contiguous", "kwargs.get"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.bert_lstm_crf.BertLstmCrf.clear_subtokens", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.viterbi_tags", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.bert_lstm_crf.BertLstmCrf.rand_init_hidden"], ["", "def", "forward", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "'''\n        args:\n            sentence (word_seq_len, batch_size) : word-level representation of sentence\n            hidden: initial hidden state\n\n        return:\n            crf output (word_seq_len, batch_size, tag_size, tag_size), hidden\n        '''", "\n", "\n", "kwargs_copy", "=", "copy", ".", "deepcopy", "(", "kwargs", ")", "\n", "if", "\"labels\"", "in", "kwargs_copy", ":", "\n", "            ", "kwargs_copy", ".", "pop", "(", "\"labels\"", ")", "\n", "\n", "", "batch_size", "=", "kwargs", "[", "\"input_ids\"", "]", ".", "size", "(", "0", ")", "\n", "seq_length", "=", "kwargs", "[", "\"input_ids\"", "]", ".", "size", "(", "1", ")", "\n", "\n", "bert_outputs", "=", "self", ".", "bert_encoder", "(", "\n", "**", "kwargs", "\n", ")", "\n", "sequence_output", "=", "bert_outputs", "[", "1", "]", "\n", "\n", "if", "self", ".", "lstm", "is", "not", "None", ":", "\n", "            ", "hidden", "=", "self", ".", "rand_init_hidden", "(", "batch_size", ")", "\n", "if", "kwargs", "[", "\"input_ids\"", "]", ".", "is_cuda", ":", "\n", "                ", "hidden", "=", "(", "i", ".", "cuda", "(", ")", "for", "i", "in", "hidden", ")", "\n", "", "sequence_output", ",", "hidden", "=", "self", ".", "lstm", "(", "sequence_output", ",", "hidden", ")", "\n", "sequence_output", "=", "sequence_output", ".", "contiguous", "(", ")", ".", "view", "(", "-", "1", ",", "self", ".", "hidden_dim", "*", "2", ")", "\n", "sequence_output", "=", "self", ".", "output_dropout", "(", "sequence_output", ")", "\n", "\n", "sequence_output", "=", "self", ".", "liner", "(", "sequence_output", ")", "\n", "\n", "#out = self.liner(sequence_output)", "\n", "", "out", "=", "sequence_output", "\n", "logits", "=", "out", ".", "contiguous", "(", ")", ".", "view", "(", "batch_size", ",", "seq_length", ",", "-", "1", ")", "\n", "\n", "clear_logits", ",", "clear_labels", ",", "clear_mask", "=", "self", ".", "clear_subtokens", "(", "logits", ",", "kwargs", "[", "'labels'", "]", ",", "kwargs", "[", "\"attention_mask\"", "]", ")", "\n", "\n", "\"\"\"\n        best_paths = self.crf.viterbi_tags(\n            logits,\n            kwargs[\"attention_mask\"].long(),\n            top_k=1\n        )\n        \"\"\"", "\n", "best_paths", "=", "self", ".", "crf", ".", "viterbi_tags", "(", "\n", "clear_logits", ",", "\n", "clear_mask", ".", "long", "(", ")", ",", "\n", "top_k", "=", "1", "\n", ")", "\n", "# Just get the top tags and ignore the scores.", "\n", "predicted_tags", "=", "cast", "(", "List", "[", "List", "[", "int", "]", "]", ",", "[", "x", "[", "0", "]", "[", "0", "]", "for", "x", "in", "best_paths", "]", ")", "\n", "\n", "if", "kwargs", ".", "get", "(", "\"labels\"", ")", "is", "not", "None", ":", "\n", "            ", "labels", "=", "kwargs", ".", "get", "(", "\"labels\"", ")", ".", "cpu", "(", ")", "\n", "#log_likelihood = self.crf(logits, kwargs.get(\"labels\"), kwargs[\"attention_mask\"])", "\n", "log_likelihood", "=", "self", ".", "crf", "(", "clear_logits", ",", "clear_labels", ",", "clear_mask", ")", "\n", "loss", "=", "-", "log_likelihood", "\n", "correct_predicted_tags", "=", "np", ".", "zeros_like", "(", "labels", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "labels", ")", ")", ":", "\n", "                ", "correct_predicted_tags", "[", "i", "]", "[", "labels", "[", "i", "]", "!=", "-", "100", "]", "=", "predicted_tags", "[", "i", "]", "\n", "", "return", "(", "loss", ",", "logits", ",", "list", "(", "correct_predicted_tags", ")", ")", "\n", "\n", "", "return", "(", "None", ",", "logits", ",", "predicted_tags", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner.set_seed": [[65, 71], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner.train": [[73, 199], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_ner.set_seed", "tensorboardX.SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "tensorboardX.SummaryWriter.close", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "loss.mean.backward", "transformers.get_linear_schedule_with_warmup.step", "transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "model_to_save.save_pretrained", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_ner.evaluate", "results.items", "os.path.exists", "os.makedirs", "hasattr", "os.path.join", "tensorboardX.SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.set_seed", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.train", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "position", "=", "0", ",", "leave", "=", "True", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "# XLM and RoBERTa don\"t use segment_ids", "\n", "", "if", "args", ".", "use_quotes", ":", "\n", "                ", "inputs", "[", "'quotes'", "]", "=", "batch", "[", "4", "]", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in pytorch-transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "model_to_save", ".", "save_pretrained", "(", "output_dir", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner.evaluate": [[201, 279], ["run_ner.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "scipy.special.softmax", "numpy.argmax", "range", "logger.info", "sorted", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "tuple", "range", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "sklearn_crfsuite.metrics.flat_f1_score", "results.keys", "logger.info", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean.item", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "numpy.append", "numpy.append", "enumerate", "range", "range", "str", "t.to", "tmp_eval_loss.mean.mean", "logits.detach().cpu().numpy", "inputs[].detach().cpu().numpy", "out_label_list[].append", "logits.detach().cpu", "inputs[].detach().cpu", "numpy.max", "preds_list[].append", "preds_list[].append", "logits.detach().cpu", "inputs[].detach().cpu", "logits.detach", "inputs[].detach", "logits.detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "mode", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation %s *****\"", ",", "prefix", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "# XLM and RoBERTa don\"t use segment_ids", "\n", "", "if", "args", ".", "use_quotes", ":", "\n", "                ", "inputs", "[", "'quotes'", "]", "=", "batch", "[", "4", "]", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", "=", "outputs", "[", ":", "2", "]", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "tmp_eval_loss", "=", "tmp_eval_loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel evaluating", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "            ", "preds", "=", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "            ", "preds", "=", "np", ".", "append", "(", "preds", ",", "logits", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "preds_logits", "=", "softmax", "(", "preds", ",", "axis", "=", "2", ")", "\n", "preds", "=", "np", ".", "argmax", "(", "preds", ",", "axis", "=", "2", ")", "\n", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "\n", "out_label_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "preds_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "out_label_ids", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "out_label_ids", "[", "i", ",", "j", "]", "!=", "pad_token_label_id", ":", "\n", "                ", "out_label_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "out_label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "if", "np", ".", "max", "(", "preds_logits", "[", "i", "]", "[", "j", "]", ")", ">", "0", ":", "\n", "                    ", "preds_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "preds", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "", "else", ":", "\n", "                    ", "preds_list", "[", "i", "]", ".", "append", "(", "'O'", ")", "\n", "\n", "", "", "", "", "results", "=", "{", "\n", "\"loss\"", ":", "eval_loss", ",", "\n", "\"precision\"", ":", "precision_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"recall\"", ":", "recall_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"f1\"", ":", "f1_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"flat_f1\"", ":", "metrics", ".", "flat_f1_score", "(", "out_label_list", ",", "preds_list", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "\"B-PROP\"", ",", "\"I-PROP\"", "]", ")", "\n", "}", "\n", "\n", "logger", ".", "info", "(", "\"***** Eval results %s *****\"", ",", "prefix", ")", "\n", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "results", ",", "preds_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner.load_and_cache_examples": [[281, 342], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_ner.read_examples_from_file", "utils_ner.convert_examples_to_features", "torch.distributed.barrier", "torch.tensor", "torch.utils.data.TensorDataset", "torch.utils.data.TensorDataset", "list().pop", "str", "os.path.join", "range", "logger.info", "torch.save", "bool", "bool", "bool", "len", "len", "len", "numpy.zeros", "range", "list", "tokenizer.convert_tokens_to_ids", "tokenizer.tokenize", "tokens.extend", "min", "filter", "len", "unidecode.unidecode", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.read_examples_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.convert_examples_to_features"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Load data features from cache or dataset file", "\n", "", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"cached_{}_{}_{}\"", ".", "format", "(", "mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ")", ")", "\n", "if", "False", "and", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "files", "=", "{", "'train'", ":", "args", ".", "train_file", ",", "'dev'", ":", "args", ".", "dev_file", ",", "'test'", ":", "args", ".", "test_file", "}", "\n", "examples", "=", "read_examples_from_file", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "files", "[", "mode", "]", ")", ",", "mode", ")", "\n", "features", "=", "convert_examples_to_features", "(", "examples", ",", "labels", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "sep_token_extra", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"roberta\"", "]", ")", ",", "\n", "# roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", "\n", ")", "\n", "if", "args", ".", "use_quotes", ":", "\n", "            ", "assert", "len", "(", "features", ")", "==", "len", "(", "examples", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "features", ")", ")", ":", "\n", "                ", "tokens", "=", "[", "]", "\n", "for", "word", "in", "examples", "[", "i", "]", ".", "words", ":", "\n", "                    ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "", "tokens", "=", "[", "'cls_token'", "]", "+", "tokens", "\n", "quotes", "=", "np", ".", "zeros", "(", "args", ".", "max_seq_length", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "for", "j", "in", "range", "(", "1", ",", "min", "(", "len", "(", "tokens", ")", ",", "args", ".", "max_seq_length", ")", ")", ":", "\n", "                    ", "if", "unidecode", "(", "tokens", "[", "j", "]", ")", "==", "'\"'", ":", "\n", "                        ", "quotes", "[", "j", "]", "=", "1", "\n", "", "", "features", "[", "i", "]", ".", "quotes", "=", "quotes", "[", ":", ",", "None", "]", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "if", "args", ".", "use_quotes", ":", "\n", "        ", "all_quotes", "=", "torch", ".", "tensor", "(", "[", "f", ".", "quotes", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ",", "all_quotes", ")", "\n", "", "else", ":", "\n", "        ", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner.transformers_ner": [[344, 497], ["logging.basicConfig", "logger.warning", "run_ner.set_seed", "utils_ner.get_labels", "len", "args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "model_class.from_pretrained.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.nn.CrossEntropyLoss", "torch.distributed.barrier", "torch.distributed.barrier", "run_ner.load_and_cache_examples", "run_ner.train", "logger.info", "logger.info", "os.path.join", "torch.save", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "tokenizer_class.from_pretrained", "logger.info", "os.path.join", "tokenizer_class.from_pretrained", "logger.info", "bool", "os.makedirs", "hasattr", "model_to_save.state_dict", "os.path.join", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ner.evaluate", "results.update", "open", "sorted", "list", "logging.getLogger().setLevel", "model_class.from_pretrained", "model_class.from_pretrained.to", "run_ner.evaluate", "results.update", "os.path.join", "os.path.join", "torch.distributed.get_rank", "os.path.exists", "results.keys", "writer.write", "open", "sorted", "open", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "os.path.dirname", "logging.getLogger", "len", "checkpoint.split", "result.keys", "writer.write", "open", "sorted", "result.items", "str", "sorted", "result.items", "os.path.join", "glob.glob", "glob.glob", "str", "line.startswith", "writer.write", "writer.write", "logger.warning", "predictions[].pop", "line.split", "line.split"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.set_seed", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.get_labels", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.load_and_cache_examples", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.train", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate"], ["", "def", "transformers_ner", "(", "args", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "\n", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", ")", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare CONLL-2003 task", "\n", "labels", "=", "get_labels", "(", "args", ".", "labels", ")", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "# Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later", "\n", "pad_token_label_id", "=", "CrossEntropyLoss", "(", ")", ".", "ignore_index", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "config", ".", "use_quotes", "=", "args", ".", "use_quotes", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"train\"", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "model_save_path_", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"pytorch_model.bin\"", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "model_save_path_", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "global_step", ")", "\n", "if", "global_step", ":", "\n", "                ", "result", "=", "{", "\"{}_{}\"", ".", "format", "(", "global_step", ",", "k", ")", ":", "v", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "", "results", ".", "update", "(", "result", ")", "\n", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "                ", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "\n", "model", "=", "model_class", ".", "from_pretrained", "(", "checkpoint", ")", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "predictions", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"test\"", ")", "\n", "if", "global_step", ":", "\n", "                ", "result", "=", "{", "\"{}_{}\"", ".", "format", "(", "global_step", ",", "k", ")", ":", "v", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "", "results", ".", "update", "(", "result", ")", "\n", "# Save results", "\n", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint", ",", "\"test_results.txt\"", ")", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                    ", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "# Save predictions", "\n", "", "", "output_test_predictions_file", "=", "os", ".", "path", ".", "join", "(", "checkpoint", ",", "\"test_predictions.txt\"", ")", "\n", "with", "open", "(", "output_test_predictions_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "test_file", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "                    ", "example_id", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                        ", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", "or", "line", "==", "\"\"", "or", "line", "==", "\"\\n\"", ":", "\n", "                            ", "writer", ".", "write", "(", "line", ")", "\n", "if", "not", "predictions", "[", "example_id", "]", ":", "\n", "                                ", "example_id", "+=", "1", "\n", "", "", "elif", "predictions", "[", "example_id", "]", ":", "\n", "                            ", "output_line", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "0", "]", "+", "\"\\t\"", "+", "predictions", "[", "example_id", "]", ".", "pop", "(", "0", ")", "+", "\"\\n\"", "\n", "writer", ".", "write", "(", "output_line", ")", "\n", "", "else", ":", "\n", "                            ", "logger", ".", "warning", "(", "\"Maximum sequence length exceeded: No prediction for '%s'.\"", ",", "line", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "return", "results", "\n", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.InputExample.__init__": [[30, 42], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "guid", ",", "words", ",", "labels", ")", ":", "\n", "        ", "\"\"\"Constructs a InputExample.\n\n        Args:\n            guid: Unique id for the example.\n            words: list. The words of the sequence.\n            labels: (Optional) list. The labels for each word of the sequence. This should be\n            specified for train and dev examples, but not for test examples.\n        \"\"\"", "\n", "self", ".", "guid", "=", "guid", "\n", "self", ".", "words", "=", "words", "\n", "self", ".", "labels", "=", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.InputFeatures.__init__": [[47, 52], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "input_ids", ",", "input_mask", ",", "segment_ids", ",", "label_ids", ")", ":", "\n", "        ", "self", ".", "input_ids", "=", "input_ids", "\n", "self", ".", "input_mask", "=", "input_mask", "\n", "self", ".", "segment_ids", "=", "segment_ids", "\n", "self", ".", "label_ids", "=", "label_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.read_examples_from_file": [[54, 82], ["io.open", "examples.append", "line.startswith", "line.split", "words.append", "utils_ner.InputExample", "examples.append", "len", "labels.append", "labels.append", "utils_ner.InputExample", "splits[].replace"], "function", ["None"], ["", "", "def", "read_examples_from_file", "(", "file_path", ",", "mode", ")", ":", "\n", "    ", "guid_index", "=", "1", "\n", "examples", "=", "[", "]", "\n", "with", "open", "(", "file_path", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "for", "line", "in", "f", ":", "\n", "            ", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", "or", "line", "==", "\"\"", "or", "line", "==", "\"\\n\"", ":", "\n", "                ", "if", "words", ":", "\n", "                    ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "\"{}-{}\"", ".", "format", "(", "mode", ",", "guid_index", ")", ",", "\n", "words", "=", "words", ",", "\n", "labels", "=", "labels", ")", ")", "\n", "guid_index", "+=", "1", "\n", "words", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "", "", "else", ":", "\n", "                ", "splits", "=", "line", ".", "split", "(", "'\\t'", ")", "# \" \"", "\n", "words", ".", "append", "(", "splits", "[", "0", "]", ")", "\n", "if", "len", "(", "splits", ")", ">", "1", ":", "\n", "                    ", "labels", ".", "append", "(", "splits", "[", "-", "1", "]", ".", "replace", "(", "\"\\n\"", ",", "\"\"", ")", ")", "\n", "", "else", ":", "\n", "# Examples could have no label for mode = \"test\"", "\n", "                    ", "labels", ".", "append", "(", "\"O\"", ")", "\n", "", "", "", "if", "words", ":", "\n", "            ", "examples", ".", "append", "(", "InputExample", "(", "guid", "=", "\"%s-%d\"", ".", "format", "(", "mode", ",", "guid_index", ")", ",", "\n", "words", "=", "words", ",", "\n", "labels", "=", "labels", ")", ")", "\n", "", "", "return", "examples", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.convert_examples_to_features": [[84, 201], ["enumerate", "zip", "tokenizer.convert_tokens_to_ids", "features.append", "enumerate", "logger.info", "tokenizer.tokenize", "tokens.extend", "label_ids.extend", "len", "len", "len", "len", "len", "len", "len", "len", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "utils_ner.InputFeatures", "len", "str", "str", "str", "str", "str", "len"], "function", ["None"], ["", "def", "convert_examples_to_features", "(", "examples", ",", "\n", "label_list", ",", "\n", "max_seq_length", ",", "\n", "tokenizer", ",", "\n", "cls_token_at_end", "=", "False", ",", "\n", "cls_token", "=", "\"[CLS]\"", ",", "\n", "cls_token_segment_id", "=", "1", ",", "\n", "sep_token", "=", "\"[SEP]\"", ",", "\n", "sep_token_extra", "=", "False", ",", "\n", "pad_on_left", "=", "False", ",", "\n", "pad_token", "=", "0", ",", "\n", "pad_token_segment_id", "=", "0", ",", "\n", "pad_token_label_id", "=", "-", "1", ",", "\n", "sequence_a_segment_id", "=", "0", ",", "\n", "mask_padding_with_zero", "=", "True", ")", ":", "\n", "    ", "\"\"\" Loads a data file into a list of `InputBatch`s\n        `cls_token_at_end` define the location of the CLS token:\n            - False (Default, BERT/XLM pattern): [CLS] + A + [SEP] + B + [SEP]\n            - True (XLNet/GPT pattern): A + [SEP] + B + [SEP] + [CLS]\n        `cls_token_segment_id` define the segment id associated to the CLS token (0 for BERT, 2 for XLNet)\n    \"\"\"", "\n", "\n", "label_map", "=", "{", "label", ":", "i", "for", "i", ",", "label", "in", "enumerate", "(", "label_list", ")", "}", "\n", "\n", "features", "=", "[", "]", "\n", "for", "(", "ex_index", ",", "example", ")", "in", "enumerate", "(", "examples", ")", ":", "\n", "        ", "if", "ex_index", "%", "10000", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\"Writing example %d of %d\"", ",", "ex_index", ",", "len", "(", "examples", ")", ")", "\n", "\n", "", "tokens", "=", "[", "]", "\n", "label_ids", "=", "[", "]", "\n", "for", "word", ",", "label", "in", "zip", "(", "example", ".", "words", ",", "example", ".", "labels", ")", ":", "\n", "            ", "word_tokens", "=", "tokenizer", ".", "tokenize", "(", "word", ")", "\n", "tokens", ".", "extend", "(", "word_tokens", ")", "\n", "# Use the real label id for the first token of the word, and padding ids for the remaining tokens", "\n", "label_ids", ".", "extend", "(", "[", "label_map", "[", "label", "]", "]", "+", "[", "pad_token_label_id", "]", "*", "(", "len", "(", "word_tokens", ")", "-", "1", ")", ")", "\n", "\n", "# Account for [CLS] and [SEP] with \"- 2\" and with \"- 3\" for RoBERTa.", "\n", "", "special_tokens_count", "=", "3", "if", "sep_token_extra", "else", "2", "\n", "if", "len", "(", "tokens", ")", ">", "max_seq_length", "-", "special_tokens_count", ":", "\n", "            ", "tokens", "=", "tokens", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "label_ids", "=", "label_ids", "[", ":", "(", "max_seq_length", "-", "special_tokens_count", ")", "]", "\n", "\n", "# The convention in BERT is:", "\n", "# (a) For sequence pairs:", "\n", "#  tokens:   [CLS] is this jack ##son ##ville ? [SEP] no it is not . [SEP]", "\n", "#  type_ids:   0   0  0    0    0     0       0   0   1  1  1  1   1   1", "\n", "# (b) For single sequences:", "\n", "#  tokens:   [CLS] the dog is hairy . [SEP]", "\n", "#  type_ids:   0   0   0   0  0     0   0", "\n", "#", "\n", "# Where \"type_ids\" are used to indicate whether this is the first", "\n", "# sequence or the second sequence. The embedding vectors for `type=0` and", "\n", "# `type=1` were learned during pre-training and are added to the wordpiece", "\n", "# embedding vector (and position vector). This is not *strictly* necessary", "\n", "# since the [SEP] token unambiguously separates the sequences, but it makes", "\n", "# it easier for the model to learn the concept of sequences.", "\n", "#", "\n", "# For classification tasks, the first vector (corresponding to [CLS]) is", "\n", "# used as as the \"sentence vector\". Note that this only makes sense because", "\n", "# the entire model is fine-tuned.", "\n", "", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "if", "sep_token_extra", ":", "\n", "# roberta uses an extra separator b/w pairs of sentences", "\n", "            ", "tokens", "+=", "[", "sep_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "", "segment_ids", "=", "[", "sequence_a_segment_id", "]", "*", "len", "(", "tokens", ")", "\n", "\n", "if", "cls_token_at_end", ":", "\n", "            ", "tokens", "+=", "[", "cls_token", "]", "\n", "label_ids", "+=", "[", "pad_token_label_id", "]", "\n", "segment_ids", "+=", "[", "cls_token_segment_id", "]", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "[", "cls_token", "]", "+", "tokens", "\n", "label_ids", "=", "[", "pad_token_label_id", "]", "+", "label_ids", "\n", "segment_ids", "=", "[", "cls_token_segment_id", "]", "+", "segment_ids", "\n", "\n", "", "input_ids", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "tokens", ")", "\n", "\n", "# The mask has 1 for real tokens and 0 for padding tokens. Only real", "\n", "# tokens are attended to.", "\n", "input_mask", "=", "[", "1", "if", "mask_padding_with_zero", "else", "0", "]", "*", "len", "(", "input_ids", ")", "\n", "\n", "# Zero-pad up to the sequence length.", "\n", "padding_length", "=", "max_seq_length", "-", "len", "(", "input_ids", ")", "\n", "if", "pad_on_left", ":", "\n", "            ", "input_ids", "=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "+", "input_ids", "\n", "input_mask", "=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "+", "input_mask", "\n", "segment_ids", "=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "+", "segment_ids", "\n", "label_ids", "=", "(", "[", "pad_token_label_id", "]", "*", "padding_length", ")", "+", "label_ids", "\n", "", "else", ":", "\n", "            ", "input_ids", "+=", "(", "[", "pad_token", "]", "*", "padding_length", ")", "\n", "input_mask", "+=", "(", "[", "0", "if", "mask_padding_with_zero", "else", "1", "]", "*", "padding_length", ")", "\n", "segment_ids", "+=", "(", "[", "pad_token_segment_id", "]", "*", "padding_length", ")", "\n", "label_ids", "+=", "(", "[", "pad_token_label_id", "]", "*", "padding_length", ")", "\n", "\n", "", "assert", "len", "(", "input_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "input_mask", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "segment_ids", ")", "==", "max_seq_length", "\n", "assert", "len", "(", "label_ids", ")", "==", "max_seq_length", "\n", "\n", "if", "ex_index", "<", "5", ":", "\n", "            ", "logger", ".", "info", "(", "\"*** Example ***\"", ")", "\n", "logger", ".", "info", "(", "\"guid: %s\"", ",", "example", ".", "guid", ")", "\n", "logger", ".", "info", "(", "\"tokens: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "tokens", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"input_mask: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "input_mask", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"segment_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "segment_ids", "]", ")", ")", "\n", "logger", ".", "info", "(", "\"label_ids: %s\"", ",", "\" \"", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "label_ids", "]", ")", ")", "\n", "\n", "", "features", ".", "append", "(", "\n", "InputFeatures", "(", "input_ids", "=", "input_ids", ",", "\n", "input_mask", "=", "input_mask", ",", "\n", "segment_ids", "=", "segment_ids", ",", "\n", "label_ids", "=", "label_ids", ")", ")", "\n", "", "return", "features", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.get_labels": [[203, 214], ["io.open", "f.read().splitlines", "f.read"], "function", ["None"], ["", "def", "get_labels", "(", "path", ")", ":", "\n", "    ", "if", "path", ":", "\n", "        ", "with", "open", "(", "path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "labels", "=", "f", ".", "read", "(", ")", ".", "splitlines", "(", ")", "\n", "", "if", "\"O\"", "not", "in", "labels", ":", "\n", "            ", "labels", "=", "[", "\"O\"", "]", "+", "labels", "\n", "", "return", "labels", "\n", "", "else", ":", "\n", "#return [\"O\", \"B-MISC\", \"I-MISC\",  \"B-PER\", \"I-PER\", \"B-ORG\", \"I-ORG\", \"B-LOC\", \"I-LOC\"]", "\n", "#return [\"O\", \"B-PROP\", \"I-PROP\", 'E-PROP', 'U-PROP']", "\n", "        ", "return", "[", "\"O\"", ",", "\"B-PROP\"", ",", "\"I-PROP\"", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaEmbeddings.__init__": [[46, 52], ["transformers.modeling_bert.BertEmbeddings.__init__", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "padding_idx", "=", "1", "\n", "self", ".", "word_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "vocab_size", ",", "config", ".", "hidden_size", ",", "padding_idx", "=", "self", ".", "padding_idx", ")", "\n", "self", ".", "position_embeddings", "=", "nn", ".", "Embedding", "(", "config", ".", "max_position_embeddings", ",", "config", ".", "hidden_size", ",", "\n", "padding_idx", "=", "self", ".", "padding_idx", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaEmbeddings.forward": [[53, 71], ["super().forward", "input_ids.size", "torch.arange", "torch.arange", "torch.arange", "torch.arange", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze().expand", "inputs_embeds.size", "position_ids.unsqueeze().expand.unsqueeze().expand.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.forward"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "if", "input_ids", "is", "not", "None", ":", "\n", "            ", "input_shape", "=", "input_ids", ".", "size", "(", ")", "\n", "", "else", ":", "\n", "            ", "input_shape", "=", "inputs_embeds", ".", "size", "(", ")", "[", ":", "-", "1", "]", "\n", "\n", "", "seq_length", "=", "input_shape", "[", "1", "]", "\n", "device", "=", "input_ids", ".", "device", "if", "input_ids", "is", "not", "None", "else", "inputs_embeds", ".", "device", "\n", "\n", "if", "position_ids", "is", "None", ":", "\n", "# Position numbers begin at padding_idx+1. Padding symbols are ignored.", "\n", "# cf. fairseq's `utils.make_positions`", "\n", "            ", "position_ids", "=", "torch", ".", "arange", "(", "self", ".", "padding_idx", "+", "1", ",", "seq_length", "+", "self", ".", "padding_idx", "+", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "device", ")", "\n", "position_ids", "=", "position_ids", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "input_shape", ")", "\n", "", "return", "super", "(", "RobertaEmbeddings", ",", "self", ")", ".", "forward", "(", "input_ids", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaModel.__init__": [[180, 185], ["transformers.modeling_bert.BertModel.__init__", "modeling_roberta.RobertaEmbeddings", "modeling_roberta.RobertaModel.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaModel", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "embeddings", "=", "RobertaEmbeddings", "(", "config", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaModel.get_input_embeddings": [[186, 188], ["None"], "methods", ["None"], ["", "def", "get_input_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embeddings", ".", "word_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaModel.set_input_embeddings": [[189, 191], ["None"], "methods", ["None"], ["", "def", "set_input_embeddings", "(", "self", ",", "value", ")", ":", "\n", "        ", "self", ".", "embeddings", ".", "word_embeddings", "=", "value", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForMaskedLM.__init__": [[228, 235], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "modeling_roberta.RobertaLMHead", "modeling_roberta.RobertaForMaskedLM.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMaskedLM", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "lm_head", "=", "RobertaLMHead", "(", "config", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForMaskedLM.get_output_embeddings": [[236, 238], ["None"], "methods", ["None"], ["", "def", "get_output_embeddings", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "lm_head", ".", "decoder", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForMaskedLM.forward": [[239, 258], ["modeling_roberta.RobertaForMaskedLM.roberta", "modeling_roberta.RobertaForMaskedLM.lm_head", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForMaskedLM.view", "masked_lm_labels.view"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "\n", "masked_lm_labels", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "prediction_scores", "=", "self", ".", "lm_head", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "prediction_scores", ",", ")", "+", "outputs", "[", "2", ":", "]", "# Add hidden states and attention if they are here", "\n", "\n", "if", "masked_lm_labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", "ignore_index", "=", "-", "1", ")", "\n", "masked_lm_loss", "=", "loss_fct", "(", "prediction_scores", ".", "view", "(", "-", "1", ",", "self", ".", "config", ".", "vocab_size", ")", ",", "masked_lm_labels", ".", "view", "(", "-", "1", ")", ")", "\n", "outputs", "=", "(", "masked_lm_loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (masked_lm_loss), prediction_scores, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaLMHead.__init__": [[263, 270], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "transformers.modeling_bert.BertLayerNorm", "torch.Linear", "torch.Linear", "torch.Parameter", "torch.Parameter", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaLMHead", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "hidden_size", ")", "\n", "self", ".", "layer_norm", "=", "BertLayerNorm", "(", "config", ".", "hidden_size", ",", "eps", "=", "config", ".", "layer_norm_eps", ")", "\n", "\n", "self", ".", "decoder", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "vocab_size", ",", "bias", "=", "False", ")", "\n", "self", ".", "bias", "=", "nn", ".", "Parameter", "(", "torch", ".", "zeros", "(", "config", ".", "vocab_size", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaLMHead.forward": [[271, 280], ["modeling_roberta.RobertaLMHead.dense", "transformers.modeling_bert.gelu", "modeling_roberta.RobertaLMHead.layer_norm", "modeling_roberta.RobertaLMHead.decoder"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.transformers_classifier.modeling_xlnet.gelu"], ["", "def", "forward", "(", "self", ",", "features", ",", "**", "kwargs", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "features", ")", "\n", "x", "=", "gelu", "(", "x", ")", "\n", "x", "=", "self", ".", "layer_norm", "(", "x", ")", "\n", "\n", "# project back to size of vocabulary with bias", "\n", "x", "=", "self", ".", "decoder", "(", "x", ")", "+", "self", ".", "bias", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForSequenceClassification.__init__": [[320, 336], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "RobertaClassificationHeadJoinedLenght", "RobertaClassificationHeadLength", "RobertaClassificationHeadJoined", "RobertaClassificationHeadMatchings", "RobertaClassificationHead"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForSequenceClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "if", "config", ".", "use_length", ":", "\n", "            ", "if", "config", ".", "join_embeddings", ":", "\n", "                ", "self", ".", "classifier", "=", "RobertaClassificationHeadJoinedLenght", "(", "config", ")", "\n", "", "else", ":", "\n", "                ", "self", ".", "classifier", "=", "RobertaClassificationHeadLength", "(", "config", ")", "\n", "", "", "elif", "config", ".", "join_embeddings", ":", "\n", "            ", "self", ".", "classifier", "=", "RobertaClassificationHeadJoined", "(", "config", ")", "\n", "", "elif", "config", ".", "use_matchings", ":", "\n", "            ", "self", ".", "classifier", "=", "RobertaClassificationHeadMatchings", "(", "config", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "classifier", "=", "RobertaClassificationHead", "(", "config", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForSequenceClassification.forward": [[337, 362], ["modeling_roberta.RobertaForSequenceClassification.roberta", "modeling_roberta.RobertaForSequenceClassification.classifier", "torch.nn.MSELoss", "torch.nn.MSELoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view", "modeling_roberta.RobertaForSequenceClassification.view", "labels.view"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ",", "lengths", "=", "None", ",", "matchings", "=", "None", ",", "embeddings_mask", "=", "None", ")", ":", "\n", "        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ",", "sent_a_length", "=", "lengths", ",", "attention_mask", "=", "embeddings_mask", ",", "matchings", "=", "matchings", ")", "\n", "\n", "#logits = self.classifier(sequence_output)", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "num_labels", "==", "1", ":", "\n", "#  We are doing regression", "\n", "                ", "loss_fct", "=", "MSELoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "else", ":", "\n", "                ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForMultipleChoice.__init__": [[441, 449], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "modeling_roberta.RobertaForMultipleChoice.init_weights"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForMultipleChoice", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "1", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForMultipleChoice.forward": [[450, 474], ["input_ids.view", "modeling_roberta.RobertaForMultipleChoice.roberta", "modeling_roberta.RobertaForMultipleChoice.dropout", "modeling_roberta.RobertaForMultipleChoice.classifier", "modeling_roberta.RobertaForMultipleChoice.view", "input_ids.size", "position_ids.view", "token_type_ids.view", "attention_mask.view", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "position_ids.size", "token_type_ids.size", "attention_mask.size"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "token_type_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "labels", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ")", ":", "\n", "        ", "num_choices", "=", "input_ids", ".", "shape", "[", "1", "]", "\n", "\n", "flat_input_ids", "=", "input_ids", ".", "view", "(", "-", "1", ",", "input_ids", ".", "size", "(", "-", "1", ")", ")", "\n", "flat_position_ids", "=", "position_ids", ".", "view", "(", "-", "1", ",", "position_ids", ".", "size", "(", "-", "1", ")", ")", "if", "position_ids", "is", "not", "None", "else", "None", "\n", "flat_token_type_ids", "=", "token_type_ids", ".", "view", "(", "-", "1", ",", "token_type_ids", ".", "size", "(", "-", "1", ")", ")", "if", "token_type_ids", "is", "not", "None", "else", "None", "\n", "flat_attention_mask", "=", "attention_mask", ".", "view", "(", "-", "1", ",", "attention_mask", ".", "size", "(", "-", "1", ")", ")", "if", "attention_mask", "is", "not", "None", "else", "None", "\n", "outputs", "=", "self", ".", "roberta", "(", "flat_input_ids", ",", "position_ids", "=", "flat_position_ids", ",", "token_type_ids", "=", "flat_token_type_ids", ",", "\n", "attention_mask", "=", "flat_attention_mask", ",", "head_mask", "=", "head_mask", ")", "\n", "pooled_output", "=", "outputs", "[", "1", "]", "\n", "\n", "pooled_output", "=", "self", ".", "dropout", "(", "pooled_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "pooled_output", ")", "\n", "reshaped_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "num_choices", ")", "\n", "\n", "outputs", "=", "(", "reshaped_logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "\n", "if", "labels", "is", "not", "None", ":", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "loss", "=", "loss_fct", "(", "reshaped_logits", ",", "labels", ")", "\n", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), reshaped_logits, (hidden_states), (attentions)", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForTokenClassification.__init__": [[512, 524], ["transformers.modeling_bert.BertPreTrainedModel.__init__", "modeling_roberta.RobertaModel", "torch.Dropout", "torch.Dropout", "modeling_roberta.RobertaForTokenClassification.init_weights", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "config", ")", ":", "\n", "        ", "super", "(", "RobertaForTokenClassification", ",", "self", ")", ".", "__init__", "(", "config", ")", "\n", "self", ".", "num_labels", "=", "config", ".", "num_labels", "\n", "\n", "self", ".", "roberta", "=", "RobertaModel", "(", "config", ")", "\n", "self", ".", "dropout", "=", "nn", ".", "Dropout", "(", "config", ".", "hidden_dropout_prob", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "config", ".", "hidden_size", ",", "config", ".", "num_labels", ")", "\n", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n", "", "def", "forward", "(", "self", ",", "input_ids", "=", "None", ",", "attention_mask", "=", "None", ",", "token_type_ids", "=", "None", ",", "\n", "position_ids", "=", "None", ",", "head_mask", "=", "None", ",", "inputs_embeds", "=", "None", ",", "labels", "=", "None", ")", ":", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.modeling_roberta.RobertaForTokenClassification.forward": [[525, 556], ["modeling_roberta.RobertaForTokenClassification.roberta", "modeling_roberta.RobertaForTokenClassification.dropout", "modeling_roberta.RobertaForTokenClassification.classifier", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "torch.nn.CrossEntropyLoss.", "quotes.type().cuda", "attention_mask.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view", "modeling_roberta.RobertaForTokenClassification.view", "labels.view", "quotes.type"], "methods", ["None"], ["        ", "outputs", "=", "self", ".", "roberta", "(", "input_ids", ",", "\n", "attention_mask", "=", "attention_mask", ",", "\n", "token_type_ids", "=", "token_type_ids", ",", "\n", "position_ids", "=", "position_ids", ",", "\n", "head_mask", "=", "head_mask", ",", "\n", "inputs_embeds", "=", "inputs_embeds", ")", "\n", "\n", "sequence_output", "=", "outputs", "[", "0", "]", "\n", "\n", "sequence_output", "=", "self", ".", "dropout", "(", "sequence_output", ")", "\n", "logits", "=", "self", ".", "classifier", "(", "sequence_output", ")", "\n", "\n", "outputs", "=", "(", "logits", ",", ")", "+", "outputs", "[", "2", ":", "]", "# add hidden states and attention if they are here", "\n", "if", "labels", "is", "not", "None", ":", "\n", "#loss_fct = CrossEntropyLoss(ignore_index=-100)", "\n", "            ", "loss_fct", "=", "CrossEntropyLoss", "(", ")", "\n", "# Only keep active parts of the loss", "\n", "if", "attention_mask", "is", "not", "None", ":", "\n", "                ", "active_loss", "=", "attention_mask", ".", "view", "(", "-", "1", ")", "==", "1", "\n", "active_logits", "=", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", "[", "active_loss", "]", "\n", "active_labels", "=", "labels", ".", "view", "(", "-", "1", ")", "[", "active_loss", "]", "\n", "loss", "=", "loss_fct", "(", "active_logits", ",", "active_labels", ")", "\n", "", "else", ":", "\n", "                ", "loss", "=", "loss_fct", "(", "logits", ".", "view", "(", "-", "1", ",", "self", ".", "num_labels", ")", ",", "labels", ".", "view", "(", "-", "1", ")", ")", "\n", "", "outputs", "=", "(", "loss", ",", ")", "+", "outputs", "\n", "\n", "", "return", "outputs", "# (loss), scores, (hidden_states), (attentions)", "\n", "\n", "\n", "", "", "class", "RobertaClassificationHead", "(", "nn", ".", "Module", ")", ":", "\n", "    ", "\"\"\"Head for sentence-level classification tasks.\"\"\"", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.set_seed": [[62, 68], ["random.seed", "numpy.random.seed", "torch.manual_seed", "torch.cuda.manual_seed_all"], "function", ["None"], ["def", "set_seed", "(", "args", ")", ":", "\n", "    ", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "if", "args", ".", "n_gpu", ">", "0", ":", "\n", "        ", "torch", ".", "cuda", ".", "manual_seed_all", "(", "args", ".", "seed", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.train": [[70, 197], ["torch.utils.data.DataLoader", "transformers.AdamW", "transformers.get_linear_schedule_with_warmup", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "logger.info", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.trange", "run_ner_crf.set_seed", "tensorboardX.SummaryWriter", "max", "torch.utils.data.RandomSampler", "torch.utils.data.distributed.DistributedSampler", "amp.initialize", "torch.nn.DataParallel", "torch.nn.parallel.DistributedDataParallel", "len", "int", "tqdm.tqdm", "enumerate", "tensorboardX.SummaryWriter.close", "torch.nn.parallel.DistributedDataParallel.train", "tuple", "torch.nn.parallel.DistributedDataParallel.", "loss.mean.item", "tqdm.trange.close", "len", "ImportError", "torch.distributed.get_world_size", "loss.mean.mean", "loss.mean.backward", "transformers.get_linear_schedule_with_warmup.step", "transformers.AdamW.step", "torch.nn.parallel.DistributedDataParallel.zero_grad", "tqdm.tqdm.close", "len", "torch.nn.parallel.DistributedDataParallel.named_parameters", "torch.nn.parallel.DistributedDataParallel.named_parameters", "any", "t.to", "amp.scale_loss", "scaled_loss.backward", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "tensorboardX.SummaryWriter.add_scalar", "tensorboardX.SummaryWriter.add_scalar", "os.path.join", "os.path.join", "torch.save", "torch.save", "logger.info", "any", "amp.master_params", "torch.nn.parallel.DistributedDataParallel.parameters", "run_ner_crf.evaluate", "results.items", "os.path.exists", "os.makedirs", "hasattr", "model_to_save.state_dict", "os.path.join", "tensorboardX.SummaryWriter.add_scalar", "transformers.get_linear_schedule_with_warmup.get_lr"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.set_seed", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.train", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate"], ["", "", "def", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", ":", "\n", "    ", "\"\"\" Train the model \"\"\"", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", "=", "SummaryWriter", "(", ")", "\n", "\n", "", "args", ".", "train_batch_size", "=", "args", ".", "per_gpu_train_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "train_sampler", "=", "RandomSampler", "(", "train_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "train_dataset", ")", "\n", "train_dataloader", "=", "DataLoader", "(", "train_dataset", ",", "sampler", "=", "train_sampler", ",", "batch_size", "=", "args", ".", "train_batch_size", ")", "\n", "\n", "if", "args", ".", "max_steps", ">", "0", ":", "\n", "        ", "t_total", "=", "args", ".", "max_steps", "\n", "args", ".", "num_train_epochs", "=", "args", ".", "max_steps", "//", "(", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", ")", "+", "1", "\n", "", "else", ":", "\n", "        ", "t_total", "=", "len", "(", "train_dataloader", ")", "//", "args", ".", "gradient_accumulation_steps", "*", "args", ".", "num_train_epochs", "\n", "\n", "# Prepare optimizer and schedule (linear warmup and decay)", "\n", "", "no_decay", "=", "[", "\"bias\"", ",", "\"LayerNorm.weight\"", "]", "\n", "optimizer_grouped_parameters", "=", "[", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "not", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\n", "\"weight_decay\"", ":", "args", ".", "weight_decay", "}", ",", "\n", "{", "\"params\"", ":", "[", "p", "for", "n", ",", "p", "in", "model", ".", "named_parameters", "(", ")", "if", "any", "(", "nd", "in", "n", "for", "nd", "in", "no_decay", ")", "]", ",", "\"weight_decay\"", ":", "0.0", "}", "\n", "]", "\n", "optimizer", "=", "AdamW", "(", "optimizer_grouped_parameters", ",", "lr", "=", "args", ".", "learning_rate", ",", "eps", "=", "args", ".", "adam_epsilon", ")", "\n", "scheduler", "=", "get_linear_schedule_with_warmup", "(", "optimizer", ",", "num_warmup_steps", "=", "args", ".", "warmup_steps", ",", "num_training_steps", "=", "t_total", ")", "\n", "if", "args", ".", "fp16", ":", "\n", "        ", "try", ":", "\n", "            ", "from", "apex", "import", "amp", "\n", "", "except", "ImportError", ":", "\n", "            ", "raise", "ImportError", "(", "\"Please install apex from https://www.github.com/nvidia/apex to use fp16 training.\"", ")", "\n", "", "model", ",", "optimizer", "=", "amp", ".", "initialize", "(", "model", ",", "optimizer", ",", "opt_level", "=", "args", ".", "fp16_opt_level", ")", "\n", "\n", "# multi-gpu training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Distributed training (should be after apex fp16 initialization)", "\n", "", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "model", ",", "device_ids", "=", "[", "args", ".", "local_rank", "]", ",", "\n", "output_device", "=", "args", ".", "local_rank", ",", "\n", "find_unused_parameters", "=", "True", ")", "\n", "\n", "# Train!", "\n", "", "logger", ".", "info", "(", "\"***** Running training *****\"", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "train_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Num Epochs = %d\"", ",", "args", ".", "num_train_epochs", ")", "\n", "logger", ".", "info", "(", "\"  Instantaneous batch size per GPU = %d\"", ",", "args", ".", "per_gpu_train_batch_size", ")", "\n", "logger", ".", "info", "(", "\"  Total train batch size (w. parallel, distributed & accumulation) = %d\"", ",", "\n", "args", ".", "train_batch_size", "*", "args", ".", "gradient_accumulation_steps", "*", "(", "\n", "torch", ".", "distributed", ".", "get_world_size", "(", ")", "if", "args", ".", "local_rank", "!=", "-", "1", "else", "1", ")", ")", "\n", "logger", ".", "info", "(", "\"  Gradient Accumulation steps = %d\"", ",", "args", ".", "gradient_accumulation_steps", ")", "\n", "logger", ".", "info", "(", "\"  Total optimization steps = %d\"", ",", "t_total", ")", "\n", "\n", "global_step", "=", "0", "\n", "tr_loss", ",", "logging_loss", "=", "0.0", ",", "0.0", "\n", "model", ".", "zero_grad", "(", ")", "\n", "train_iterator", "=", "trange", "(", "int", "(", "args", ".", "num_train_epochs", ")", ",", "desc", "=", "\"Epoch\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ")", "\n", "set_seed", "(", "args", ")", "# Added here for reproductibility (even between python 2 and 3)", "\n", "for", "_", "in", "train_iterator", ":", "\n", "        ", "epoch_iterator", "=", "tqdm", "(", "train_dataloader", ",", "desc", "=", "\"Iteration\"", ",", "disable", "=", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ",", "position", "=", "0", ",", "leave", "=", "True", ")", "\n", "for", "step", ",", "batch", "in", "enumerate", "(", "epoch_iterator", ")", ":", "\n", "            ", "model", ".", "train", "(", ")", "\n", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "# XLM and RoBERTa don\"t use segment_ids", "\n", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "loss", "=", "outputs", "[", "0", "]", "# model outputs are always tuple in pytorch-transformers (see doc)", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "loss", "=", "loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel training", "\n", "", "if", "args", ".", "gradient_accumulation_steps", ">", "1", ":", "\n", "                ", "loss", "=", "loss", "/", "args", ".", "gradient_accumulation_steps", "\n", "\n", "", "if", "args", ".", "fp16", ":", "\n", "                ", "with", "amp", ".", "scale_loss", "(", "loss", ",", "optimizer", ")", "as", "scaled_loss", ":", "\n", "                    ", "scaled_loss", ".", "backward", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "loss", ".", "backward", "(", ")", "\n", "\n", "", "tr_loss", "+=", "loss", ".", "item", "(", ")", "\n", "if", "(", "step", "+", "1", ")", "%", "args", ".", "gradient_accumulation_steps", "==", "0", ":", "\n", "                ", "if", "args", ".", "fp16", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "amp", ".", "master_params", "(", "optimizer", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "", "else", ":", "\n", "                    ", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "args", ".", "max_grad_norm", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "# Update learning rate schedule", "\n", "optimizer", ".", "step", "(", ")", "\n", "model", ".", "zero_grad", "(", ")", "\n", "global_step", "+=", "1", "\n", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "logging_steps", ">", "0", "and", "global_step", "%", "args", ".", "logging_steps", "==", "0", ":", "\n", "# Log metrics", "\n", "                    ", "if", "args", ".", "local_rank", "==", "-", "1", "and", "args", ".", "evaluate_during_training", ":", "# Only evaluate when single GPU otherwise metrics may not average well", "\n", "                        ", "results", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ")", "\n", "for", "key", ",", "value", "in", "results", ".", "items", "(", ")", ":", "\n", "                            ", "tb_writer", ".", "add_scalar", "(", "\"eval_{}\"", ".", "format", "(", "key", ")", ",", "value", ",", "global_step", ")", "\n", "", "", "tb_writer", ".", "add_scalar", "(", "\"lr\"", ",", "scheduler", ".", "get_lr", "(", ")", "[", "0", "]", ",", "global_step", ")", "\n", "tb_writer", ".", "add_scalar", "(", "\"loss\"", ",", "(", "tr_loss", "-", "logging_loss", ")", "/", "args", ".", "logging_steps", ",", "global_step", ")", "\n", "logging_loss", "=", "tr_loss", "\n", "\n", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "and", "args", ".", "save_steps", ">", "0", "and", "global_step", "%", "args", ".", "save_steps", "==", "0", ":", "\n", "# Save model checkpoint", "\n", "                    ", "output_dir", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"checkpoint-{}\"", ".", "format", "(", "global_step", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "                        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "# model_to_save.save_pretrained(output_dir)", "\n", "model_save_path_", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"pytorch_model.bin\"", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "model_save_path_", ")", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "output_dir", ")", "\n", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "                ", "epoch_iterator", ".", "close", "(", ")", "\n", "break", "\n", "", "", "if", "args", ".", "max_steps", ">", "0", "and", "global_step", ">", "args", ".", "max_steps", ":", "\n", "            ", "train_iterator", ".", "close", "(", ")", "\n", "break", "\n", "\n", "", "", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tb_writer", ".", "close", "(", ")", "\n", "\n", "", "return", "global_step", ",", "tr_loss", "/", "global_step", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate": [[199, 274], ["run_ner_crf.load_and_cache_examples", "torch.utils.data.DataLoader", "logger.info", "logger.info", "logger.info", "torch.nn.DataParallel.eval", "tqdm.tqdm", "range", "logger.info", "sorted", "max", "torch.utils.data.SequentialSampler", "torch.utils.data.distributed.DistributedSampler", "torch.nn.DataParallel", "len", "tuple", "range", "seqeval.metrics.precision_score", "seqeval.metrics.recall_score", "seqeval.metrics.f1_score", "sklearn_crfsuite.metrics.flat_f1_score", "results.keys", "logger.info", "torch.no_grad", "torch.nn.DataParallel.", "tmp_eval_loss.mean.item", "inputs[].detach().cpu().numpy", "preds.extend", "numpy.append", "enumerate", "range", "range", "str", "t.to", "tmp_eval_loss.mean.mean", "inputs[].detach().cpu().numpy", "out_label_list[].append", "preds_list[].append", "inputs[].detach().cpu", "inputs[].detach().cpu", "inputs[].detach", "inputs[].detach"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.load_and_cache_examples"], ["", "def", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ",", "prefix", "=", "\"\"", ")", ":", "\n", "    ", "eval_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "mode", ")", "\n", "\n", "args", ".", "eval_batch_size", "=", "args", ".", "per_gpu_eval_batch_size", "*", "max", "(", "1", ",", "args", ".", "n_gpu", ")", "\n", "# Note that DistributedSampler samples randomly", "\n", "eval_sampler", "=", "SequentialSampler", "(", "eval_dataset", ")", "if", "args", ".", "local_rank", "==", "-", "1", "else", "DistributedSampler", "(", "eval_dataset", ")", "\n", "eval_dataloader", "=", "DataLoader", "(", "eval_dataset", ",", "sampler", "=", "eval_sampler", ",", "batch_size", "=", "args", ".", "eval_batch_size", ")", "\n", "\n", "# multi-gpu evaluate", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", "\n", "\n", "# Eval!", "\n", "", "logger", ".", "info", "(", "\"***** Running evaluation %s *****\"", ",", "prefix", ")", "\n", "logger", ".", "info", "(", "\"  Num examples = %d\"", ",", "len", "(", "eval_dataset", ")", ")", "\n", "logger", ".", "info", "(", "\"  Batch size = %d\"", ",", "args", ".", "eval_batch_size", ")", "\n", "eval_loss", "=", "0.0", "\n", "nb_eval_steps", "=", "0", "\n", "preds", "=", "None", "\n", "out_label_ids", "=", "None", "\n", "model", ".", "eval", "(", ")", "\n", "for", "batch", "in", "tqdm", "(", "eval_dataloader", ",", "desc", "=", "\"Evaluating\"", ")", ":", "\n", "        ", "batch", "=", "tuple", "(", "t", ".", "to", "(", "args", ".", "device", ")", "for", "t", "in", "batch", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "inputs", "=", "{", "\"input_ids\"", ":", "batch", "[", "0", "]", ",", "\n", "\"attention_mask\"", ":", "batch", "[", "1", "]", ",", "\n", "\"labels\"", ":", "batch", "[", "3", "]", "}", "\n", "if", "args", ".", "model_type", "!=", "\"distilbert\"", ":", "\n", "                ", "inputs", "[", "\"token_type_ids\"", "]", "=", "batch", "[", "2", "]", "if", "args", ".", "model_type", "in", "[", "\"bert\"", ",", "\"xlnet\"", "]", "else", "None", "# XLM and RoBERTa don\"t use segment_ids", "\n", "", "outputs", "=", "model", "(", "**", "inputs", ")", "\n", "tmp_eval_loss", ",", "logits", ",", "predicted_tags", "=", "outputs", "\n", "\n", "if", "args", ".", "n_gpu", ">", "1", ":", "\n", "                ", "tmp_eval_loss", "=", "tmp_eval_loss", ".", "mean", "(", ")", "# mean() to average on multi-gpu parallel evaluating", "\n", "\n", "", "eval_loss", "+=", "tmp_eval_loss", ".", "item", "(", ")", "\n", "", "nb_eval_steps", "+=", "1", "\n", "if", "preds", "is", "None", ":", "\n", "#preds = logits.detach().cpu().numpy()", "\n", "            ", "preds", "=", "predicted_tags", "\n", "out_label_ids", "=", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "", "else", ":", "\n", "#preds = np.append(preds, logits.detach().cpu().numpy(), axis=0)", "\n", "            ", "preds", ".", "extend", "(", "predicted_tags", ")", "\n", "out_label_ids", "=", "np", ".", "append", "(", "out_label_ids", ",", "inputs", "[", "\"labels\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ",", "axis", "=", "0", ")", "\n", "\n", "", "", "eval_loss", "=", "eval_loss", "/", "nb_eval_steps", "\n", "#preds_logits = softmax(preds, axis=2)", "\n", "#preds = np.argmax(preds, axis=2)", "\n", "\n", "label_map", "=", "{", "i", ":", "label", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", "}", "\n", "\n", "out_label_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "preds_list", "=", "[", "[", "]", "for", "_", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", "]", "\n", "\n", "for", "i", "in", "range", "(", "out_label_ids", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "for", "j", "in", "range", "(", "out_label_ids", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "if", "out_label_ids", "[", "i", ",", "j", "]", "!=", "pad_token_label_id", ":", "\n", "                ", "out_label_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "out_label_ids", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "preds_list", "[", "i", "]", ".", "append", "(", "label_map", "[", "preds", "[", "i", "]", "[", "j", "]", "]", ")", "\n", "\n", "", "", "", "results", "=", "{", "\n", "\"loss\"", ":", "eval_loss", ",", "\n", "\"precision\"", ":", "precision_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"recall\"", ":", "recall_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"f1\"", ":", "f1_score", "(", "out_label_list", ",", "preds_list", ")", ",", "\n", "\"flat_f1\"", ":", "metrics", ".", "flat_f1_score", "(", "out_label_list", ",", "preds_list", ",", "average", "=", "'micro'", ",", "labels", "=", "[", "\"B-PROP\"", ",", "\"I-PROP\"", "]", ")", "\n", "}", "\n", "\n", "logger", ".", "info", "(", "\"***** Eval results %s *****\"", ",", "prefix", ")", "\n", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "        ", "logger", ".", "info", "(", "\"  %s = %s\"", ",", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", "\n", "\n", "", "return", "results", ",", "preds_list", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.load_and_cache_examples": [[276, 320], ["os.path.join", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.utils.data.TensorDataset", "torch.distributed.barrier", "os.path.exists", "logger.info", "torch.load", "logger.info", "utils_ner.read_examples_from_file", "utils_ner.convert_examples_to_features", "torch.distributed.barrier", "list().pop", "str", "os.path.join", "logger.info", "torch.save", "bool", "bool", "bool", "list", "tokenizer.convert_tokens_to_ids", "filter", "args.model_name_or_path.split"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.read_examples_from_file", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.convert_examples_to_features"], ["", "def", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", ")", ":", "\n", "    ", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Load data features from cache or dataset file", "\n", "", "cached_features_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "\"cached_{}_{}_{}\"", ".", "format", "(", "mode", ",", "\n", "list", "(", "filter", "(", "None", ",", "args", ".", "model_name_or_path", ".", "split", "(", "\"/\"", ")", ")", ")", ".", "pop", "(", ")", ",", "\n", "str", "(", "args", ".", "max_seq_length", ")", ")", ")", "\n", "if", "False", "and", "os", ".", "path", ".", "exists", "(", "cached_features_file", ")", "and", "not", "args", ".", "overwrite_cache", ":", "\n", "        ", "logger", ".", "info", "(", "\"Loading features from cached file %s\"", ",", "cached_features_file", ")", "\n", "features", "=", "torch", ".", "load", "(", "cached_features_file", ")", "\n", "", "else", ":", "\n", "        ", "logger", ".", "info", "(", "\"Creating features from dataset file at %s\"", ",", "args", ".", "data_dir", ")", "\n", "files", "=", "{", "'train'", ":", "args", ".", "train_file", ",", "'dev'", ":", "args", ".", "dev_file", ",", "'test'", ":", "args", ".", "test_file", "}", "\n", "examples", "=", "read_examples_from_file", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "files", "[", "mode", "]", ")", ",", "mode", ")", "\n", "features", "=", "convert_examples_to_features", "(", "examples", ",", "labels", ",", "args", ".", "max_seq_length", ",", "tokenizer", ",", "\n", "cls_token_at_end", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# xlnet has a cls token at the end", "\n", "cls_token", "=", "tokenizer", ".", "cls_token", ",", "\n", "cls_token_segment_id", "=", "2", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "sep_token", "=", "tokenizer", ".", "sep_token", ",", "\n", "sep_token_extra", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"roberta\"", "]", ")", ",", "\n", "# roberta uses an extra separator b/w pairs of sentences, cf. github.com/pytorch/fairseq/commit/1684e166e3da03f5b600dbb7855cb98ddfcd0805", "\n", "pad_on_left", "=", "bool", "(", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", ")", ",", "\n", "# pad on the left for xlnet", "\n", "pad_token", "=", "tokenizer", ".", "convert_tokens_to_ids", "(", "[", "tokenizer", ".", "pad_token", "]", ")", "[", "0", "]", ",", "\n", "pad_token_segment_id", "=", "4", "if", "args", ".", "model_type", "in", "[", "\"xlnet\"", "]", "else", "0", ",", "\n", "pad_token_label_id", "=", "pad_token_label_id", "\n", ")", "\n", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "logger", ".", "info", "(", "\"Saving features into cached file %s\"", ",", "cached_features_file", ")", "\n", "torch", ".", "save", "(", "features", ",", "cached_features_file", ")", "\n", "\n", "", "", "if", "args", ".", "local_rank", "==", "0", "and", "not", "evaluate", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training process the dataset, and the others will use the cache", "\n", "\n", "# Convert to Tensors and build dataset", "\n", "", "all_input_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_input_mask", "=", "torch", ".", "tensor", "(", "[", "f", ".", "input_mask", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_segment_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "segment_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "all_label_ids", "=", "torch", ".", "tensor", "(", "[", "f", ".", "label_ids", "for", "f", "in", "features", "]", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "dataset", "=", "TensorDataset", "(", "all_input_ids", ",", "all_input_mask", ",", "all_segment_ids", ",", "all_label_ids", ")", "\n", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.transformers_ner_crf": [[322, 512], ["logging.basicConfig", "logger.warning", "run_ner_crf.set_seed", "utils_ner.get_labels", "len", "args.model_type.lower", "config_class.from_pretrained", "tokenizer_class.from_pretrained", "model_class.from_pretrained", "bert_lstm_crf.BertLstmCrf", "bert_lstm_crf.BertLstmCrf.to", "logger.info", "os.path.exists", "os.listdir", "ValueError", "print", "ptvsd.enable_attach", "ptvsd.wait_for_attach", "torch.device", "torch.cuda.device_count", "torch.cuda.set_device", "torch.device", "torch.distributed.init_process_group", "bool", "torch.nn.CrossEntropyLoss", "torch.distributed.barrier", "hasattr", "torch.distributed.barrier", "run_ner_crf.load_and_cache_examples", "run_ner_crf.train", "logger.info", "logger.info", "os.path.join", "torch.save", "tokenizer_class.from_pretrained.save_pretrained", "torch.save", "tokenizer_class.from_pretrained", "os.path.join", "logger.info", "os.path.join", "tokenizer_class.from_pretrained", "logger.info", "bool", "int", "os.makedirs", "hasattr", "model_to_save.state_dict", "os.path.join", "list", "logging.getLogger().setLevel", "bert_lstm_crf.BertLstmCrf", "torch.load", "bert_lstm_crf.BertLstmCrf.load_state_dict", "bert_lstm_crf.BertLstmCrf.to", "run_ner_crf.evaluate", "results.update", "open", "sorted", "list", "logging.getLogger().setLevel", "bert_lstm_crf.BertLstmCrf", "os.path.join", "torch.load", "bert_lstm_crf.BertLstmCrf.load_state_dict", "bert_lstm_crf.BertLstmCrf.to", "run_ner_crf.evaluate", "os.path.join", "os.path.join", "torch.distributed.get_rank", "os.path.exists", "results.keys", "writer.write", "open", "sorted", "open", "torch.cuda.is_available", "os.path.dirname", "logging.getLogger", "len", "os.path.join.split", "int", "os.path.dirname", "logging.getLogger", "int", "result.keys", "writer.write", "open", "sorted", "result.items", "str", "sorted", "os.path.join", "glob.glob", "glob.glob", "str", "line.startswith", "writer.write", "writer.write", "logger.warning", "predictions[].pop", "line.split", "line.split"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.set_seed", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.utils_ner.get_labels", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.load_and_cache_examples", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.train", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.run_ner_crf.evaluate"], ["", "def", "transformers_ner_crf", "(", "args", ")", ":", "\n", "    ", "if", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "os", ".", "listdir", "(", "\n", "args", ".", "output_dir", ")", "and", "args", ".", "do_train", "and", "not", "args", ".", "overwrite_output_dir", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "\"Output directory ({}) already exists and is not empty. Use --overwrite_output_dir to overcome.\"", ".", "format", "(", "\n", "args", ".", "output_dir", ")", ")", "\n", "\n", "# Setup distant debugging if needed", "\n", "", "if", "args", ".", "server_ip", "and", "args", ".", "server_port", ":", "\n", "# Distant debugging - see https://code.visualstudio.com/docs/python/debugging#_attach-to-a-local-script", "\n", "        ", "import", "ptvsd", "\n", "print", "(", "\"Waiting for debugger attach\"", ")", "\n", "ptvsd", ".", "enable_attach", "(", "address", "=", "(", "args", ".", "server_ip", ",", "args", ".", "server_port", ")", ",", "redirect_output", "=", "True", ")", "\n", "ptvsd", ".", "wait_for_attach", "(", ")", "\n", "\n", "# Setup CUDA, GPU & distributed training", "\n", "", "if", "args", ".", "local_rank", "==", "-", "1", "or", "args", ".", "no_cuda", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", "if", "torch", ".", "cuda", ".", "is_available", "(", ")", "and", "not", "args", ".", "no_cuda", "else", "\"cpu\"", ")", "\n", "args", ".", "n_gpu", "=", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "", "else", ":", "# Initializes the distributed backend which will take care of sychronizing nodes/GPUs", "\n", "        ", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "local_rank", ")", "\n", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ",", "args", ".", "local_rank", ")", "\n", "torch", ".", "distributed", ".", "init_process_group", "(", "backend", "=", "\"nccl\"", ")", "\n", "args", ".", "n_gpu", "=", "1", "\n", "", "args", ".", "device", "=", "device", "\n", "\n", "# Setup logging", "\n", "logging", ".", "basicConfig", "(", "format", "=", "\"%(asctime)s - %(levelname)s - %(name)s -   %(message)s\"", ",", "\n", "datefmt", "=", "\"%m/%d/%Y %H:%M:%S\"", ",", "\n", "level", "=", "logging", ".", "INFO", "if", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", "else", "logging", ".", "WARN", ")", "\n", "logger", ".", "warning", "(", "\"Process rank: %s, device: %s, n_gpu: %s, distributed training: %s, 16-bits training: %s\"", ",", "\n", "args", ".", "local_rank", ",", "device", ",", "args", ".", "n_gpu", ",", "bool", "(", "args", ".", "local_rank", "!=", "-", "1", ")", ",", "args", ".", "fp16", ")", "\n", "\n", "# Set seed", "\n", "set_seed", "(", "args", ")", "\n", "\n", "# Prepare CONLL-2003 task", "\n", "labels", "=", "get_labels", "(", "args", ".", "labels", ")", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "# Use cross entropy ignore index as padding label id so that only real label ids contribute to the loss later", "\n", "pad_token_label_id", "=", "CrossEntropyLoss", "(", ")", ".", "ignore_index", "\n", "\n", "# Load pretrained model and tokenizer", "\n", "if", "args", ".", "local_rank", "not", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "args", ".", "model_type", "=", "args", ".", "model_type", ".", "lower", "(", ")", "\n", "config_class", ",", "model_class", ",", "tokenizer_class", "=", "MODEL_CLASSES", "[", "args", ".", "model_type", "]", "\n", "config", "=", "config_class", ".", "from_pretrained", "(", "args", ".", "config_name", "if", "args", ".", "config_name", "else", "args", ".", "model_name_or_path", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "tokenizer_name", "if", "args", ".", "tokenizer_name", "else", "args", ".", "model_name_or_path", ",", "\n", "do_lower_case", "=", "args", ".", "do_lower_case", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "\n", "bert_model", "=", "model_class", ".", "from_pretrained", "(", "args", ".", "model_name_or_path", ",", "\n", "from_tf", "=", "bool", "(", "\".ckpt\"", "in", "args", ".", "model_name_or_path", ")", ",", "\n", "config", "=", "config", ",", "\n", "cache_dir", "=", "args", ".", "cache_dir", "if", "args", ".", "cache_dir", "else", "None", ")", "\n", "if", "not", "hasattr", "(", "config", ",", "\"hidden_dropout_prob\"", ")", ":", "\n", "        ", "config", ".", "hidden_dropout_prob", "=", "config", ".", "dropout", "\n", "", "model", "=", "BertLstmCrf", "(", "\n", "bert_model", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "embedding_dim", "=", "config", ".", "hidden_size", ",", "\n", "hidden_dim", "=", "int", "(", "config", ".", "hidden_size", "/", "2", ")", ",", "\n", "rnn_layers", "=", "0", ",", "\n", "rnn_dropout", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "output_dropout", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "use_cuda", "=", "True", "\n", ")", "\n", "\n", "if", "args", ".", "local_rank", "==", "0", ":", "\n", "        ", "torch", ".", "distributed", ".", "barrier", "(", ")", "# Make sure only the first process in distributed training will download model & vocab", "\n", "\n", "", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "\n", "logger", ".", "info", "(", "\"Training/evaluation parameters %s\"", ",", "args", ")", "\n", "\n", "# Training", "\n", "if", "args", ".", "do_train", ":", "\n", "        ", "train_dataset", "=", "load_and_cache_examples", "(", "args", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"train\"", ")", "\n", "global_step", ",", "tr_loss", "=", "train", "(", "args", ",", "train_dataset", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ")", "\n", "logger", ".", "info", "(", "\" global_step = %s, average loss = %s\"", ",", "global_step", ",", "tr_loss", ")", "\n", "\n", "# Saving best-practices: if you use defaults names for the model, you can reload it using from_pretrained()", "\n", "", "if", "args", ".", "do_train", "and", "(", "args", ".", "local_rank", "==", "-", "1", "or", "torch", ".", "distributed", ".", "get_rank", "(", ")", "==", "0", ")", ":", "\n", "# Create output directory if needed", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "args", ".", "output_dir", ")", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "            ", "os", ".", "makedirs", "(", "args", ".", "output_dir", ")", "\n", "\n", "", "logger", ".", "info", "(", "\"Saving model checkpoint to %s\"", ",", "args", ".", "output_dir", ")", "\n", "# Save a trained model, configuration and tokenizer using `save_pretrained()`.", "\n", "# They can then be reloaded using `from_pretrained()`", "\n", "model_to_save", "=", "model", ".", "module", "if", "hasattr", "(", "model", ",", "\"module\"", ")", "else", "model", "# Take care of distributed/parallel training", "\n", "#model_to_save.save_pretrained(args.output_dir)", "\n", "model_save_path_", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"pytorch_model.bin\"", ")", "\n", "torch", ".", "save", "(", "model_to_save", ".", "state_dict", "(", ")", ",", "model_save_path_", ")", "\n", "tokenizer", ".", "save_pretrained", "(", "args", ".", "output_dir", ")", "\n", "\n", "# Good practice: save your training arguments together with the trained model", "\n", "torch", ".", "save", "(", "args", ",", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"training_args.bin\"", ")", ")", "\n", "\n", "# Evaluation", "\n", "", "results", "=", "{", "}", "\n", "if", "args", ".", "do_eval", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "#checkpoints = [args.output_dir]", "\n", "output_dir_", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "WEIGHTS_NAME", ")", "\n", "checkpoints", "=", "[", "output_dir_", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkpoint", "in", "checkpoints", ":", "\n", "            ", "global_step", "=", "checkpoint", ".", "split", "(", "\"-\"", ")", "[", "-", "1", "]", "if", "len", "(", "checkpoints", ")", ">", "1", "else", "\"\"", "\n", "\n", "model", "=", "BertLstmCrf", "(", "\n", "bert_model", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "embedding_dim", "=", "config", ".", "hidden_size", ",", "\n", "hidden_dim", "=", "int", "(", "config", ".", "hidden_size", "/", "2", ")", ",", "\n", "rnn_layers", "=", "0", ",", "\n", "rnn_dropout", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "output_dropout", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "use_cuda", "=", "True", "\n", ")", "\n", "if", "checkpoint", "[", "-", "3", ":", "]", "!=", "'bin'", ":", "\n", "                ", "checkpoint", "+=", "\"/pytorch_model.bin\"", "\n", "", "state_dict", "=", "torch", ".", "load", "(", "checkpoint", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "# model = model_class.from_pretrained(checkpoint)", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "_", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"dev\"", ",", "prefix", "=", "global_step", ")", "\n", "if", "global_step", ":", "\n", "                ", "result", "=", "{", "\"{}_{}\"", ".", "format", "(", "global_step", ",", "k", ")", ":", "v", "for", "k", ",", "v", "in", "result", ".", "items", "(", ")", "}", "\n", "", "results", ".", "update", "(", "result", ")", "\n", "", "output_eval_file", "=", "os", ".", "path", ".", "join", "(", "args", ".", "output_dir", ",", "\"eval_results.txt\"", ")", "\n", "with", "open", "(", "output_eval_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "            ", "for", "key", "in", "sorted", "(", "results", ".", "keys", "(", ")", ")", ":", "\n", "                ", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "results", "[", "key", "]", ")", ")", ")", "\n", "\n", "", "", "", "if", "args", ".", "do_predict", "and", "args", ".", "local_rank", "in", "[", "-", "1", ",", "0", "]", ":", "\n", "        ", "tokenizer", "=", "tokenizer_class", ".", "from_pretrained", "(", "args", ".", "output_dir", ",", "do_lower_case", "=", "args", ".", "do_lower_case", ")", "\n", "checkpoints", "=", "[", "args", ".", "output_dir", "]", "\n", "if", "args", ".", "eval_all_checkpoints", ":", "\n", "            ", "checkpoints", "=", "list", "(", "os", ".", "path", ".", "dirname", "(", "c", ")", "for", "c", "in", "sorted", "(", "glob", ".", "glob", "(", "args", ".", "output_dir", "+", "\"/**/\"", "+", "WEIGHTS_NAME", ",", "recursive", "=", "True", ")", ")", ")", "\n", "logging", ".", "getLogger", "(", "\"pytorch_transformers.modeling_utils\"", ")", ".", "setLevel", "(", "logging", ".", "WARN", ")", "# Reduce logging", "\n", "", "logger", ".", "info", "(", "\"Evaluate the following checkpoints: %s\"", ",", "checkpoints", ")", "\n", "for", "checkp", "in", "checkpoints", ":", "\n", "            ", "model", "=", "BertLstmCrf", "(", "\n", "bert_model", ",", "\n", "num_labels", "=", "num_labels", ",", "\n", "embedding_dim", "=", "config", ".", "hidden_size", ",", "\n", "hidden_dim", "=", "int", "(", "config", ".", "hidden_size", "/", "2", ")", ",", "\n", "rnn_layers", "=", "0", ",", "\n", "rnn_dropout", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "output_dropout", "=", "config", ".", "hidden_dropout_prob", ",", "\n", "use_cuda", "=", "True", "\n", ")", "\n", "checkpoint", "=", "os", ".", "path", ".", "join", "(", "checkp", ",", "WEIGHTS_NAME", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "checkpoint", ")", "\n", "model", ".", "load_state_dict", "(", "state_dict", ")", "\n", "\n", "model", ".", "to", "(", "args", ".", "device", ")", "\n", "result", ",", "predictions", "=", "evaluate", "(", "args", ",", "model", ",", "tokenizer", ",", "labels", ",", "pad_token_label_id", ",", "mode", "=", "\"test\"", ")", "\n", "\n", "# Save results", "\n", "output_test_results_file", "=", "os", ".", "path", ".", "join", "(", "checkp", ",", "\"test_results.txt\"", ")", "\n", "with", "open", "(", "output_test_results_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "for", "key", "in", "sorted", "(", "result", ".", "keys", "(", ")", ")", ":", "\n", "                    ", "writer", ".", "write", "(", "\"{} = {}\\n\"", ".", "format", "(", "key", ",", "str", "(", "result", "[", "key", "]", ")", ")", ")", "\n", "# Save predictions", "\n", "", "", "output_test_predictions_file", "=", "os", ".", "path", ".", "join", "(", "checkp", ",", "\"test_predictions.txt\"", ")", "\n", "with", "open", "(", "output_test_predictions_file", ",", "\"w\"", ")", "as", "writer", ":", "\n", "                ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "args", ".", "data_dir", ",", "args", ".", "test_file", ")", ",", "\"r\"", ")", "as", "f", ":", "\n", "                    ", "example_id", "=", "0", "\n", "for", "line", "in", "f", ":", "\n", "                        ", "if", "line", ".", "startswith", "(", "\"-DOCSTART-\"", ")", "or", "line", "==", "\"\"", "or", "line", "==", "\"\\n\"", ":", "\n", "                            ", "writer", ".", "write", "(", "line", ")", "\n", "if", "not", "predictions", "[", "example_id", "]", ":", "\n", "                                ", "example_id", "+=", "1", "\n", "", "", "elif", "predictions", "[", "example_id", "]", ":", "\n", "                            ", "output_line", "=", "line", ".", "split", "(", "'\\t'", ")", "[", "0", "]", "+", "\"\\t\"", "+", "predictions", "[", "example_id", "]", ".", "pop", "(", "0", ")", "+", "\"\\n\"", "\n", "writer", ".", "write", "(", "output_line", ")", "\n", "", "else", ":", "\n", "                            ", "logger", ".", "warning", "(", "\"Maximum sequence length exceeded: No prediction for '%s'.\"", ",", "line", ".", "split", "(", ")", "[", "0", "]", ")", "\n", "\n", "", "", "", "", "", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConfigurationError.__init__": [[44, 47], ["Exception.__init__"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__"], ["def", "__init__", "(", "self", ",", "message", ")", ":", "\n", "        ", "super", "(", "ConfigurationError", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "message", "=", "message", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConfigurationError.__str__": [[48, 50], ["repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "repr", "(", "self", ".", "message", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__": [[212, 243], ["super().__init__", "torch.nn.Parameter", "torch.nn.Parameter", "conditional_random_field.ConditionalRandomField.reset_parameters", "torch.Tensor", "torch.Tensor().fill_", "torch.Tensor().fill_", "torch.nn.Parameter", "torch.nn.Parameter", "torch.Tensor", "torch.Tensor", "torch.Tensor", "torch.Tensor"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.__init__", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.reset_parameters"], ["def", "__init__", "(", "\n", "self", ",", "\n", "num_tags", ":", "int", ",", "\n", "constraints", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "None", ",", "\n", "include_start_end_transitions", ":", "bool", "=", "True", ",", "\n", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "self", ".", "num_tags", "=", "num_tags", "\n", "\n", "# transitions[i, j] is the logit for transitioning from state i to state j.", "\n", "self", ".", "transitions", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_tags", ",", "num_tags", ")", ")", "\n", "\n", "# _constraint_mask indicates valid transitions (based on supplied constraints).", "\n", "# Include special start of sequence (num_tags + 1) and end of sequence tags (num_tags + 2)", "\n", "if", "constraints", "is", "None", ":", "\n", "# All transitions are valid.", "\n", "            ", "constraint_mask", "=", "torch", ".", "Tensor", "(", "num_tags", "+", "2", ",", "num_tags", "+", "2", ")", ".", "fill_", "(", "1.0", ")", "\n", "", "else", ":", "\n", "            ", "constraint_mask", "=", "torch", ".", "Tensor", "(", "num_tags", "+", "2", ",", "num_tags", "+", "2", ")", ".", "fill_", "(", "0.0", ")", "\n", "for", "i", ",", "j", "in", "constraints", ":", "\n", "                ", "constraint_mask", "[", "i", ",", "j", "]", "=", "1.0", "\n", "\n", "", "", "self", ".", "_constraint_mask", "=", "torch", ".", "nn", ".", "Parameter", "(", "constraint_mask", ",", "requires_grad", "=", "False", ")", "\n", "\n", "# Also need logits for transitioning from \"start\" state and to \"end\" state.", "\n", "self", ".", "include_start_end_transitions", "=", "include_start_end_transitions", "\n", "if", "include_start_end_transitions", ":", "\n", "            ", "self", ".", "start_transitions", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_tags", ")", ")", "\n", "self", ".", "end_transitions", "=", "torch", ".", "nn", ".", "Parameter", "(", "torch", ".", "Tensor", "(", "num_tags", ")", ")", "\n", "\n", "", "self", ".", "reset_parameters", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.reset_parameters": [[244, 249], ["torch.nn.init.xavier_normal_", "torch.nn.init.normal_", "torch.nn.init.normal_"], "methods", ["None"], ["", "def", "reset_parameters", "(", "self", ")", ":", "\n", "        ", "torch", ".", "nn", ".", "init", ".", "xavier_normal_", "(", "self", ".", "transitions", ")", "\n", "if", "self", ".", "include_start_end_transitions", ":", "\n", "            ", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "start_transitions", ")", "\n", "torch", ".", "nn", ".", "init", ".", "normal_", "(", "self", ".", "end_transitions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField._input_likelihood": [[250, 296], ["logits.transpose().contiguous.transpose().contiguous.size", "mask.float().transpose().contiguous.float().transpose().contiguous.float().transpose().contiguous", "logits.transpose().contiguous.transpose().contiguous.transpose().contiguous", "range", "conditional_random_field.logsumexp", "logits[].view", "conditional_random_field.ConditionalRandomField.transitions.view", "alpha.view", "mask.float().transpose().contiguous.float().transpose().contiguous.float().transpose", "logits.transpose().contiguous.transpose().contiguous.transpose", "conditional_random_field.ConditionalRandomField.start_transitions.view", "conditional_random_field.ConditionalRandomField.end_transitions.view", "conditional_random_field.logsumexp", "mask[].view", "mask.float().transpose().contiguous.float().transpose().contiguous.float"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.logsumexp", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.logsumexp"], ["", "", "def", "_input_likelihood", "(", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the (batch_size,) denominator term for the log-likelihood, which is the\n        sum of the likelihoods across all possible state sequences.\n        \"\"\"", "\n", "batch_size", ",", "sequence_length", ",", "num_tags", "=", "logits", ".", "size", "(", ")", "\n", "\n", "# Transpose batch size and sequence dimensions", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "logits", "=", "logits", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Initial alpha is the (batch_size, num_tags) tensor of likelihoods combining the", "\n", "# transitions to the initial states and the logits for the first timestep.", "\n", "if", "self", ".", "include_start_end_transitions", ":", "\n", "            ", "alpha", "=", "self", ".", "start_transitions", ".", "view", "(", "1", ",", "num_tags", ")", "+", "logits", "[", "0", "]", "\n", "", "else", ":", "\n", "            ", "alpha", "=", "logits", "[", "0", "]", "\n", "\n", "# For each i we compute logits for the transitions from timestep i-1 to timestep i.", "\n", "# We do so in a (batch_size, num_tags, num_tags) tensor where the axes are", "\n", "# (instance, current_tag, next_tag)", "\n", "", "for", "i", "in", "range", "(", "1", ",", "sequence_length", ")", ":", "\n", "# The emit scores are for time i (\"next_tag\") so we broadcast along the current_tag axis.", "\n", "            ", "emit_scores", "=", "logits", "[", "i", "]", ".", "view", "(", "batch_size", ",", "1", ",", "num_tags", ")", "\n", "# Transition scores are (current_tag, next_tag) so we broadcast along the instance axis.", "\n", "transition_scores", "=", "self", ".", "transitions", ".", "view", "(", "1", ",", "num_tags", ",", "num_tags", ")", "\n", "# Alpha is for the current_tag, so we broadcast along the next_tag axis.", "\n", "broadcast_alpha", "=", "alpha", ".", "view", "(", "batch_size", ",", "num_tags", ",", "1", ")", "\n", "\n", "# Add all the scores together and logexp over the current_tag axis.", "\n", "inner", "=", "broadcast_alpha", "+", "emit_scores", "+", "transition_scores", "\n", "\n", "# In valid positions (mask == 1) we want to take the logsumexp over the current_tag dimension", "\n", "# of ``inner``. Otherwise (mask == 0) we want to retain the previous alpha.", "\n", "alpha", "=", "logsumexp", "(", "inner", ",", "1", ")", "*", "mask", "[", "i", "]", ".", "view", "(", "batch_size", ",", "1", ")", "+", "alpha", "*", "(", "\n", "1", "-", "mask", "[", "i", "]", "\n", ")", ".", "view", "(", "batch_size", ",", "1", ")", "\n", "\n", "# Every sequence needs to end with a transition to the stop_tag.", "\n", "", "if", "self", ".", "include_start_end_transitions", ":", "\n", "            ", "stops", "=", "alpha", "+", "self", ".", "end_transitions", ".", "view", "(", "1", ",", "num_tags", ")", "\n", "", "else", ":", "\n", "            ", "stops", "=", "alpha", "\n", "\n", "# Finally we log_sum_exp along the num_tags dim, result is (batch_size,)", "\n", "", "return", "logsumexp", "(", "stops", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField._joint_likelihood": [[297, 360], ["logits.transpose().contiguous.transpose().contiguous.transpose().contiguous", "mask.float().transpose().contiguous.float().transpose().contiguous.float().transpose().contiguous", "tags.transpose().contiguous", "range", "tags.transpose().contiguous.gather().squeeze", "last_inputs.gather", "last_input_score.squeeze.squeeze.squeeze", "conditional_random_field.ConditionalRandomField.start_transitions.index_select", "logits[].gather().squeeze", "mask.float().transpose().contiguous.float().transpose().contiguous.sum().long", "conditional_random_field.ConditionalRandomField.end_transitions.index_select", "tags.transpose().contiguous.gather().squeeze.view", "logits.transpose().contiguous.transpose().contiguous.transpose", "mask.float().transpose().contiguous.float().transpose().contiguous.float().transpose", "tags.transpose", "tags.transpose().contiguous.gather", "logits[].gather", "mask.float().transpose().contiguous.float().transpose().contiguous.sum", "last_tag_index.view", "mask.float().transpose().contiguous.float().transpose().contiguous.float", "current_tag.view", "next_tag.view", "current_tag.view"], "methods", ["None"], ["", "def", "_joint_likelihood", "(", "\n", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "tags", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "LongTensor", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the numerator term for the log-likelihood, which is just score(inputs, tags)\n        \"\"\"", "\n", "batch_size", ",", "sequence_length", ",", "_", "=", "logits", ".", "data", ".", "shape", "\n", "\n", "# Transpose batch size and sequence dimensions:", "\n", "logits", "=", "logits", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "mask", "=", "mask", ".", "float", "(", ")", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "tags_", "=", "tags", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "#tags_ = tags.clone()", "\n", "#tags_[0][tags_[0] == -100] = 0", "\n", "#for i in range(1, len(tags)):", "\n", "#    tags_[i][tags_[i] == -100] = tags_[i - 1][tags_[i] == -100]", "\n", "#tags_[tags_ == -100] = 0", "\n", "\n", "# Start with the transition scores from start_tag to the first tag in each input", "\n", "if", "self", ".", "include_start_end_transitions", ":", "\n", "            ", "score", "=", "self", ".", "start_transitions", ".", "index_select", "(", "0", ",", "tags_", "[", "0", "]", ")", "\n", "", "else", ":", "\n", "            ", "score", "=", "0.0", "\n", "\n", "# Add up the scores for the observed transitions and all the inputs but the last", "\n", "", "for", "i", "in", "range", "(", "sequence_length", "-", "1", ")", ":", "\n", "# Each is shape (batch_size,)", "\n", "            ", "current_tag", ",", "next_tag", "=", "tags_", "[", "i", "]", ",", "tags_", "[", "i", "+", "1", "]", "\n", "\n", "# print(\"current_tag: \", current_tag)", "\n", "# print(\"next_tag: \", next_tag)", "\n", "# print(\"self.transitions: \", self.transitions)", "\n", "# print(\"self.transitions: \", self.transitions.size())", "\n", "\n", "# The scores for transitioning from current_tag to next_tag", "\n", "transition_score", "=", "self", ".", "transitions", "[", "current_tag", ".", "view", "(", "-", "1", ")", ",", "next_tag", ".", "view", "(", "-", "1", ")", "]", "\n", "\n", "# The score for using current_tag", "\n", "emit_score", "=", "logits", "[", "i", "]", ".", "gather", "(", "1", ",", "current_tag", ".", "view", "(", "batch_size", ",", "1", ")", ")", ".", "squeeze", "(", "1", ")", "\n", "\n", "# Include transition score if next element is unmasked,", "\n", "# input_score if this element is unmasked.", "\n", "score", "=", "score", "+", "transition_score", "*", "mask", "[", "i", "+", "1", "]", "+", "emit_score", "*", "mask", "[", "i", "]", "\n", "\n", "# Transition from last state to \"stop\" state. To start with, we need to find the last tag", "\n", "# for each instance.", "\n", "", "last_tag_index", "=", "mask", ".", "sum", "(", "0", ")", ".", "long", "(", ")", "-", "1", "\n", "last_tags", "=", "tags_", ".", "gather", "(", "0", ",", "last_tag_index", ".", "view", "(", "1", ",", "batch_size", ")", ")", ".", "squeeze", "(", "0", ")", "\n", "\n", "# Compute score of transitioning to `stop_tag` from each \"last tag\".", "\n", "if", "self", ".", "include_start_end_transitions", ":", "\n", "            ", "last_transition_score", "=", "self", ".", "end_transitions", ".", "index_select", "(", "0", ",", "last_tags", ")", "\n", "", "else", ":", "\n", "            ", "last_transition_score", "=", "0.0", "\n", "\n", "# Add the last input if it's not masked.", "\n", "", "last_inputs", "=", "logits", "[", "-", "1", "]", "# (batch_size, num_tags)", "\n", "last_input_score", "=", "last_inputs", ".", "gather", "(", "1", ",", "last_tags", ".", "view", "(", "-", "1", ",", "1", ")", ")", "# (batch_size, 1)", "\n", "last_input_score", "=", "last_input_score", ".", "squeeze", "(", ")", "# (batch_size,)", "\n", "\n", "score", "=", "score", "+", "last_transition_score", "+", "last_input_score", "*", "mask", "[", "-", "1", "]", "\n", "\n", "return", "score", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.forward": [[361, 375], ["conditional_random_field.ConditionalRandomField._input_likelihood", "conditional_random_field.ConditionalRandomField._joint_likelihood", "torch.sum", "torch.ones", "tags.size"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField._input_likelihood", "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField._joint_likelihood"], ["", "def", "forward", "(", "\n", "self", ",", "inputs", ":", "torch", ".", "Tensor", ",", "tags", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "ByteTensor", "=", "None", "\n", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "\"\"\"\n        Computes the log likelihood.\n        \"\"\"", "\n", "\n", "if", "mask", "is", "None", ":", "\n", "            ", "mask", "=", "torch", ".", "ones", "(", "*", "tags", ".", "size", "(", ")", ",", "dtype", "=", "torch", ".", "long", ")", "\n", "\n", "", "log_denominator", "=", "self", ".", "_input_likelihood", "(", "inputs", ",", "mask", ")", "\n", "log_numerator", "=", "self", ".", "_joint_likelihood", "(", "inputs", ",", "tags", ",", "mask", ")", "\n", "\n", "return", "torch", ".", "sum", "(", "log_numerator", "-", "log_denominator", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.ConditionalRandomField.viterbi_tags": [[376, 462], ["logits.size", "torch.Tensor().fill_", "torch.Tensor", "zip", "torch.sum", "torch.Tensor.fill_", "conditional_random_field.viterbi_decode", "zip", "best_paths.append", "torch.Tensor", "top_k_paths.append", "conditional_random_field.ConditionalRandomField.start_transitions.detach", "conditional_random_field.ConditionalRandomField.end_transitions.detach", "conditional_random_field.ConditionalRandomField._constraint_mask[].detach", "conditional_random_field.ConditionalRandomField._constraint_mask[].detach", "conditional_random_field.ConditionalRandomField._constraint_mask[].detach", "conditional_random_field.ConditionalRandomField._constraint_mask[].detach", "viterbi_score.item"], "methods", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.viterbi_decode"], ["", "def", "viterbi_tags", "(", "\n", "self", ",", "logits", ":", "torch", ".", "Tensor", ",", "mask", ":", "torch", ".", "Tensor", ",", "top_k", ":", "int", "=", "None", "\n", ")", "->", "Union", "[", "List", "[", "VITERBI_DECODING", "]", ",", "List", "[", "List", "[", "VITERBI_DECODING", "]", "]", "]", ":", "\n", "        ", "\"\"\"\n        Uses viterbi algorithm to find most likely tags for the given inputs.\n        If constraints are applied, disallows all other transitions.\n        Returns a list of results, of the same size as the batch (one result per batch member)\n        Each result is a List of length top_k, containing the top K viterbi decodings\n        Each decoding is a tuple  (tag_sequence, viterbi_score)\n        For backwards compatibility, if top_k is None, then instead returns a flat list of\n        tag sequences (the top tag sequence for each batch item).\n        \"\"\"", "\n", "if", "top_k", "is", "None", ":", "\n", "            ", "top_k", "=", "1", "\n", "flatten_output", "=", "True", "\n", "", "else", ":", "\n", "            ", "flatten_output", "=", "False", "\n", "\n", "", "_", ",", "max_seq_length", ",", "num_tags", "=", "logits", ".", "size", "(", ")", "\n", "\n", "# Get the tensors out of the variables", "\n", "logits", ",", "mask", "=", "logits", ".", "data", ",", "mask", ".", "data", "\n", "\n", "# Augment transitions matrix with start and end transitions", "\n", "start_tag", "=", "num_tags", "\n", "end_tag", "=", "num_tags", "+", "1", "\n", "transitions", "=", "torch", ".", "Tensor", "(", "num_tags", "+", "2", ",", "num_tags", "+", "2", ")", ".", "fill_", "(", "-", "10000.0", ")", "\n", "\n", "# Apply transition constraints", "\n", "constrained_transitions", "=", "self", ".", "transitions", "*", "self", ".", "_constraint_mask", "[", "\n", ":", "num_tags", ",", ":", "num_tags", "\n", "]", "+", "-", "10000.0", "*", "(", "1", "-", "self", ".", "_constraint_mask", "[", ":", "num_tags", ",", ":", "num_tags", "]", ")", "\n", "transitions", "[", ":", "num_tags", ",", ":", "num_tags", "]", "=", "constrained_transitions", ".", "data", "\n", "\n", "if", "self", ".", "include_start_end_transitions", ":", "\n", "            ", "transitions", "[", "\n", "start_tag", ",", ":", "num_tags", "\n", "]", "=", "self", ".", "start_transitions", ".", "detach", "(", ")", "*", "self", ".", "_constraint_mask", "[", "\n", "start_tag", ",", ":", "num_tags", "\n", "]", ".", "data", "+", "-", "10000.0", "*", "(", "\n", "1", "-", "self", ".", "_constraint_mask", "[", "start_tag", ",", ":", "num_tags", "]", ".", "detach", "(", ")", "\n", ")", "\n", "transitions", "[", ":", "num_tags", ",", "end_tag", "]", "=", "self", ".", "end_transitions", ".", "detach", "(", ")", "*", "self", ".", "_constraint_mask", "[", "\n", ":", "num_tags", ",", "end_tag", "\n", "]", ".", "data", "+", "-", "10000.0", "*", "(", "1", "-", "self", ".", "_constraint_mask", "[", ":", "num_tags", ",", "end_tag", "]", ".", "detach", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "transitions", "[", "start_tag", ",", ":", "num_tags", "]", "=", "-", "10000.0", "*", "(", "\n", "1", "-", "self", ".", "_constraint_mask", "[", "start_tag", ",", ":", "num_tags", "]", ".", "detach", "(", ")", "\n", ")", "\n", "transitions", "[", ":", "num_tags", ",", "end_tag", "]", "=", "-", "10000.0", "*", "(", "\n", "1", "-", "self", ".", "_constraint_mask", "[", ":", "num_tags", ",", "end_tag", "]", ".", "detach", "(", ")", "\n", ")", "\n", "\n", "", "best_paths", "=", "[", "]", "\n", "# Pad the max sequence length by 2 to account for start_tag + end_tag.", "\n", "tag_sequence", "=", "torch", ".", "Tensor", "(", "max_seq_length", "+", "2", ",", "num_tags", "+", "2", ")", "\n", "\n", "for", "prediction", ",", "prediction_mask", "in", "zip", "(", "logits", ",", "mask", ")", ":", "\n", "            ", "sequence_length", "=", "torch", ".", "sum", "(", "prediction_mask", ")", "\n", "\n", "# Start with everything totally unlikely", "\n", "tag_sequence", ".", "fill_", "(", "-", "10000.0", ")", "\n", "# At timestep 0 we must have the START_TAG", "\n", "tag_sequence", "[", "0", ",", "start_tag", "]", "=", "0.0", "\n", "# At steps 1, ..., sequence_length we just use the incoming prediction", "\n", "tag_sequence", "[", "1", ":", "(", "sequence_length", "+", "1", ")", ",", ":", "num_tags", "]", "=", "prediction", "[", ":", "sequence_length", "]", "\n", "# And at the last timestep we must have the END_TAG", "\n", "tag_sequence", "[", "sequence_length", "+", "1", ",", "end_tag", "]", "=", "0.0", "\n", "\n", "# We pass the tags and the transitions to ``viterbi_decode``.", "\n", "viterbi_paths", ",", "viterbi_scores", "=", "viterbi_decode", "(", "\n", "tag_sequence", "=", "tag_sequence", "[", ":", "(", "sequence_length", "+", "2", ")", "]", ",", "\n", "transition_matrix", "=", "transitions", ",", "\n", "top_k", "=", "top_k", ",", "\n", ")", "\n", "top_k_paths", "=", "[", "]", "\n", "for", "viterbi_path", ",", "viterbi_score", "in", "zip", "(", "viterbi_paths", ",", "viterbi_scores", ")", ":", "\n", "# Get rid of START and END sentinels and append.", "\n", "                ", "viterbi_path", "=", "viterbi_path", "[", "1", ":", "-", "1", "]", "\n", "top_k_paths", ".", "append", "(", "(", "viterbi_path", ",", "viterbi_score", ".", "item", "(", ")", ")", ")", "\n", "", "best_paths", ".", "append", "(", "top_k_paths", ")", "\n", "\n", "", "if", "flatten_output", ":", "\n", "            ", "return", "[", "top_k_paths", "[", "0", "]", "for", "top_k_paths", "in", "best_paths", "]", "\n", "\n", "", "return", "best_paths", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.logsumexp": [[13, 36], ["tensor.max", "stable_vec.exp().sum().log", "max_score.unsqueeze", "stable_vec.exp().sum", "stable_vec.exp"], "function", ["None"], ["def", "logsumexp", "(", "tensor", ":", "torch", ".", "Tensor", ",", "\n", "dim", ":", "int", "=", "-", "1", ",", "\n", "keepdim", ":", "bool", "=", "False", ")", "->", "torch", ".", "Tensor", ":", "\n", "    ", "\"\"\"\n    A numerically stable computation of logsumexp. This is mathematically equivalent to\n    `tensor.exp().sum(dim, keep=keepdim).log()`.  This function is typically used for summing log\n    probabilities.\n\n    Parameters\n    ----------\n    tensor : torch.FloatTensor, required.\n        A tensor of arbitrary size.\n    dim : int, optional (default = -1)\n        The dimension of the tensor to apply the logsumexp to.\n    keepdim: bool, optional (default = False)\n        Whether to retain a dimension of size one at the dimension we reduce over.\n    \"\"\"", "\n", "max_score", ",", "_", "=", "tensor", ".", "max", "(", "dim", ",", "keepdim", "=", "keepdim", ")", "\n", "if", "keepdim", ":", "\n", "        ", "stable_vec", "=", "tensor", "-", "max_score", "\n", "", "else", ":", "\n", "        ", "stable_vec", "=", "tensor", "-", "max_score", ".", "unsqueeze", "(", "dim", ")", "\n", "", "return", "max_score", "+", "(", "stable_vec", ".", "exp", "(", ")", ".", "sum", "(", "dim", ",", "keepdim", "=", "keepdim", ")", ")", ".", "log", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.allowed_transitions": [[53, 94], ["len", "list", "labels.items", "conditional_random_field.is_transition_allowed", "allowed.append"], "function", ["home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.is_transition_allowed"], ["", "", "def", "allowed_transitions", "(", "constraint_type", ":", "str", ",", "labels", ":", "Dict", "[", "int", ",", "str", "]", ")", "->", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ":", "\n", "    ", "\"\"\"\n    Given labels and a constraint type, returns the allowed transitions. It will\n    additionally include transitions for the start and end states, which are used\n    by the conditional random field.\n    Parameters\n    ----------\n    constraint_type : ``str``, required\n        Indicates which constraint to apply. Current choices are\n        \"BIO\", \"IOB1\", \"BIOUL\", and \"BMES\".\n    labels : ``Dict[int, str]``, required\n        A mapping {label_id -> label}. Most commonly this would be the value from\n        Vocabulary.get_index_to_token_vocabulary()\n    Returns\n    -------\n    ``List[Tuple[int, int]]``\n        The allowed transitions (from_label_id, to_label_id).\n    \"\"\"", "\n", "num_labels", "=", "len", "(", "labels", ")", "\n", "start_tag", "=", "num_labels", "\n", "end_tag", "=", "num_labels", "+", "1", "\n", "labels_with_boundaries", "=", "list", "(", "labels", ".", "items", "(", ")", ")", "+", "[", "(", "start_tag", ",", "\"START\"", ")", ",", "(", "end_tag", ",", "\"END\"", ")", "]", "\n", "\n", "allowed", "=", "[", "]", "\n", "for", "from_label_index", ",", "from_label", "in", "labels_with_boundaries", ":", "\n", "        ", "if", "from_label", "in", "(", "\"START\"", ",", "\"END\"", ")", ":", "\n", "            ", "from_tag", "=", "from_label", "\n", "from_entity", "=", "\"\"", "\n", "", "else", ":", "\n", "            ", "from_tag", "=", "from_label", "[", "0", "]", "\n", "from_entity", "=", "from_label", "[", "1", ":", "]", "\n", "", "for", "to_label_index", ",", "to_label", "in", "labels_with_boundaries", ":", "\n", "            ", "if", "to_label", "in", "(", "\"START\"", ",", "\"END\"", ")", ":", "\n", "                ", "to_tag", "=", "to_label", "\n", "to_entity", "=", "\"\"", "\n", "", "else", ":", "\n", "                ", "to_tag", "=", "to_label", "[", "0", "]", "\n", "to_entity", "=", "to_label", "[", "1", ":", "]", "\n", "", "if", "is_transition_allowed", "(", "constraint_type", ",", "from_tag", ",", "from_entity", ",", "to_tag", ",", "to_entity", ")", ":", "\n", "                ", "allowed", ".", "append", "(", "(", "from_label_index", ",", "to_label_index", ")", ")", "\n", "", "", "", "return", "allowed", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.is_transition_allowed": [[96, 192], ["any", "any", "any", "any", "conditional_random_field.ConfigurationError"], "function", ["None"], ["", "def", "is_transition_allowed", "(", "\n", "constraint_type", ":", "str", ",", "from_tag", ":", "str", ",", "from_entity", ":", "str", ",", "to_tag", ":", "str", ",", "to_entity", ":", "str", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Given a constraint type and strings ``from_tag`` and ``to_tag`` that\n    represent the origin and destination of the transition, return whether\n    the transition is allowed under the given constraint type.\n    Parameters\n    ----------\n    constraint_type : ``str``, required\n        Indicates which constraint to apply. Current choices are\n        \"BIO\", \"IOB1\", \"BIOUL\", and \"BMES\".\n    from_tag : ``str``, required\n        The tag that the transition originates from. For example, if the\n        label is ``I-PER``, the ``from_tag`` is ``I``.\n    from_entity: ``str``, required\n        The entity corresponding to the ``from_tag``. For example, if the\n        label is ``I-PER``, the ``from_entity`` is ``PER``.\n    to_tag : ``str``, required\n        The tag that the transition leads to. For example, if the\n        label is ``I-PER``, the ``to_tag`` is ``I``.\n    to_entity: ``str``, required\n        The entity corresponding to the ``to_tag``. For example, if the\n        label is ``I-PER``, the ``to_entity`` is ``PER``.\n    Returns\n    -------\n    ``bool``\n        Whether the transition is allowed under the given ``constraint_type``.\n    \"\"\"", "\n", "\n", "if", "to_tag", "==", "\"START\"", "or", "from_tag", "==", "\"END\"", ":", "\n", "# Cannot transition into START or from END", "\n", "        ", "return", "False", "\n", "\n", "", "if", "constraint_type", "==", "\"BIOUL\"", ":", "\n", "        ", "if", "from_tag", "==", "\"START\"", ":", "\n", "            ", "return", "to_tag", "in", "(", "\"O\"", ",", "\"B\"", ",", "\"U\"", ")", "\n", "", "if", "to_tag", "==", "\"END\"", ":", "\n", "            ", "return", "from_tag", "in", "(", "\"O\"", ",", "\"L\"", ",", "\"U\"", ")", "\n", "", "return", "any", "(", "\n", "[", "\n", "# O can transition to O, B-* or U-*", "\n", "# L-x can transition to O, B-*, or U-*", "\n", "# U-x can transition to O, B-*, or U-*", "\n", "from_tag", "in", "(", "\"O\"", ",", "\"L\"", ",", "\"U\"", ")", "and", "to_tag", "in", "(", "\"O\"", ",", "\"B\"", ",", "\"U\"", ")", ",", "\n", "# B-x can only transition to I-x or L-x", "\n", "# I-x can only transition to I-x or L-x", "\n", "from_tag", "in", "(", "\"B\"", ",", "\"I\"", ")", "and", "to_tag", "in", "(", "\"I\"", ",", "\"L\"", ")", "and", "from_entity", "==", "to_entity", ",", "\n", "]", "\n", ")", "\n", "", "elif", "constraint_type", "==", "\"BIO\"", ":", "\n", "        ", "if", "from_tag", "==", "\"START\"", ":", "\n", "            ", "return", "to_tag", "in", "(", "\"O\"", ",", "\"B\"", ")", "\n", "", "if", "to_tag", "==", "\"END\"", ":", "\n", "            ", "return", "from_tag", "in", "(", "\"O\"", ",", "\"B\"", ",", "\"I\"", ")", "\n", "", "return", "any", "(", "\n", "[", "\n", "# Can always transition to O or B-x", "\n", "to_tag", "in", "(", "\"O\"", ",", "\"B\"", ")", ",", "\n", "# Can only transition to I-x from B-x or I-x", "\n", "to_tag", "==", "\"I\"", "and", "from_tag", "in", "(", "\"B\"", ",", "\"I\"", ")", "and", "from_entity", "==", "to_entity", ",", "\n", "]", "\n", ")", "\n", "", "elif", "constraint_type", "==", "\"IOB1\"", ":", "\n", "        ", "if", "from_tag", "==", "\"START\"", ":", "\n", "            ", "return", "to_tag", "in", "(", "\"O\"", ",", "\"I\"", ")", "\n", "", "if", "to_tag", "==", "\"END\"", ":", "\n", "            ", "return", "from_tag", "in", "(", "\"O\"", ",", "\"B\"", ",", "\"I\"", ")", "\n", "", "return", "any", "(", "\n", "[", "\n", "# Can always transition to O or I-x", "\n", "to_tag", "in", "(", "\"O\"", ",", "\"I\"", ")", ",", "\n", "# Can only transition to B-x from B-x or I-x, where", "\n", "# x is the same tag.", "\n", "to_tag", "==", "\"B\"", "and", "from_tag", "in", "(", "\"B\"", ",", "\"I\"", ")", "and", "from_entity", "==", "to_entity", ",", "\n", "]", "\n", ")", "\n", "", "elif", "constraint_type", "==", "\"BMES\"", ":", "\n", "        ", "if", "from_tag", "==", "\"START\"", ":", "\n", "            ", "return", "to_tag", "in", "(", "\"B\"", ",", "\"S\"", ")", "\n", "", "if", "to_tag", "==", "\"END\"", ":", "\n", "            ", "return", "from_tag", "in", "(", "\"E\"", ",", "\"S\"", ")", "\n", "", "return", "any", "(", "\n", "[", "\n", "# Can only transition to B or S from E or S.", "\n", "to_tag", "in", "(", "\"B\"", ",", "\"S\"", ")", "and", "from_tag", "in", "(", "\"E\"", ",", "\"S\"", ")", ",", "\n", "# Can only transition to M-x from B-x, where", "\n", "# x is the same tag.", "\n", "to_tag", "==", "\"M\"", "and", "from_tag", "in", "(", "\"B\"", ",", "\"M\"", ")", "and", "from_entity", "==", "to_entity", ",", "\n", "# Can only transition to E-x from B-x or M-x, where", "\n", "# x is the same tag.", "\n", "to_tag", "==", "\"E\"", "and", "from_tag", "in", "(", "\"B\"", ",", "\"M\"", ")", "and", "from_entity", "==", "to_entity", ",", "\n", "]", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ConfigurationError", "(", "f\"Unknown constraint type: {constraint_type}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.aschern_semeval2020_task11.ner.conditional_random_field.viterbi_decode": [[464, 639], ["list", "range", "path_scores[].view", "min", "torch.topk", "range", "torch.cat.size", "torch.zeros", "torch.cat", "torch.cat", "torch.zeros", "torch.cat", "torch.cat", "torch.cat.size", "torch.zeros", "path_scores.append", "path_scores.append", "summed_potentials.view.view", "min", "torch.topk", "path_indices.append", "reversed", "viterbi_path.reverse", "viterbi_paths.append", "ValueError", "torch.zeros", "torch.zeros", "len", "conditional_random_field.ConfigurationError", "torch.ones", "torch.zeros.unsqueeze", "tag_sequence[].unsqueeze", "path_scores[].unsqueeze", "torch.zeros", "path_scores.append", "path_scores.append", "paths.squeeze", "path_scores[].view.size", "viterbi_path.append", "torch.tensor", "torch.tensor", "range", "summed_potentials.view.size", "logger.warning", "torch.zeros.unsqueeze", "int", "backward_timestep.view"], "function", ["None"], ["", "", "def", "viterbi_decode", "(", "\n", "tag_sequence", ":", "torch", ".", "Tensor", ",", "\n", "transition_matrix", ":", "torch", ".", "Tensor", ",", "\n", "tag_observations", ":", "Optional", "[", "List", "[", "int", "]", "]", "=", "None", ",", "\n", "allowed_start_transitions", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "allowed_end_transitions", ":", "torch", ".", "Tensor", "=", "None", ",", "\n", "top_k", ":", "int", "=", "None", ",", "\n", ")", ":", "\n", "    ", "\"\"\"\n    Perform Viterbi decoding in log space over a sequence given a transition matrix\n    specifying pairwise (transition) potentials between tags and a matrix of shape\n    (sequence_length, num_tags) specifying unary potentials for possible tags per\n    timestep.\n    Parameters\n    ----------\n    tag_sequence : torch.Tensor, required.\n        A tensor of shape (sequence_length, num_tags) representing scores for\n        a set of tags over a given sequence.\n    transition_matrix : torch.Tensor, required.\n        A tensor of shape (num_tags, num_tags) representing the binary potentials\n        for transitioning between a given pair of tags.\n    tag_observations : Optional[List[int]], optional, (default = None)\n        A list of length ``sequence_length`` containing the class ids of observed\n        elements in the sequence, with unobserved elements being set to -1. Note that\n        it is possible to provide evidence which results in degenerate labelings if\n        the sequences of tags you provide as evidence cannot transition between each\n        other, or those transitions are extremely unlikely. In this situation we log a\n        warning, but the responsibility for providing self-consistent evidence ultimately\n        lies with the user.\n    allowed_start_transitions : torch.Tensor, optional, (default = None)\n        An optional tensor of shape (num_tags,) describing which tags the START token\n        may transition *to*. If provided, additional transition constraints will be used for\n        determining the start element of the sequence.\n    allowed_end_transitions : torch.Tensor, optional, (default = None)\n        An optional tensor of shape (num_tags,) describing which tags may transition *to* the\n        end tag. If provided, additional transition constraints will be used for determining\n        the end element of the sequence.\n    top_k : int, optional, (default = None)\n        Optional integer specifying how many of the top paths to return. For top_k>=1, returns\n        a tuple of two lists: top_k_paths, top_k_scores, For top_k==None, returns a flattened\n        tuple with just the top path and its score (not in lists, for backwards compatibility).\n    Returns\n    -------\n    viterbi_path : List[int]\n        The tag indices of the maximum likelihood tag sequence.\n    viterbi_score : torch.Tensor\n        The score of the viterbi path.\n    \"\"\"", "\n", "if", "top_k", "is", "None", ":", "\n", "        ", "top_k", "=", "1", "\n", "flatten_output", "=", "True", "\n", "", "elif", "top_k", ">=", "1", ":", "\n", "        ", "flatten_output", "=", "False", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"top_k must be either None or an integer >=1. Instead received {top_k}\"", ")", "\n", "\n", "", "sequence_length", ",", "num_tags", "=", "list", "(", "tag_sequence", ".", "size", "(", ")", ")", "\n", "\n", "has_start_end_restrictions", "=", "(", "\n", "allowed_end_transitions", "is", "not", "None", "or", "allowed_start_transitions", "is", "not", "None", "\n", ")", "\n", "\n", "if", "has_start_end_restrictions", ":", "\n", "\n", "        ", "if", "allowed_end_transitions", "is", "None", ":", "\n", "            ", "allowed_end_transitions", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "", "if", "allowed_start_transitions", "is", "None", ":", "\n", "            ", "allowed_start_transitions", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "\n", "", "num_tags", "=", "num_tags", "+", "2", "\n", "new_transition_matrix", "=", "torch", ".", "zeros", "(", "num_tags", ",", "num_tags", ")", "\n", "new_transition_matrix", "[", ":", "-", "2", ",", ":", "-", "2", "]", "=", "transition_matrix", "\n", "\n", "# Start and end transitions are fully defined, but cannot transition between each other.", "\n", "\n", "allowed_start_transitions", "=", "torch", ".", "cat", "(", "\n", "[", "allowed_start_transitions", ",", "torch", ".", "tensor", "(", "[", "-", "math", ".", "inf", ",", "-", "math", ".", "inf", "]", ")", "]", "\n", ")", "\n", "allowed_end_transitions", "=", "torch", ".", "cat", "(", "\n", "[", "allowed_end_transitions", ",", "torch", ".", "tensor", "(", "[", "-", "math", ".", "inf", ",", "-", "math", ".", "inf", "]", ")", "]", "\n", ")", "\n", "\n", "# First define how we may transition FROM the start and end tags.", "\n", "new_transition_matrix", "[", "-", "2", ",", ":", "]", "=", "allowed_start_transitions", "\n", "# We cannot transition from the end tag to any tag.", "\n", "new_transition_matrix", "[", "-", "1", ",", ":", "]", "=", "-", "math", ".", "inf", "\n", "\n", "new_transition_matrix", "[", ":", ",", "-", "1", "]", "=", "allowed_end_transitions", "\n", "# We cannot transition to the start tag from any tag.", "\n", "new_transition_matrix", "[", ":", ",", "-", "2", "]", "=", "-", "math", ".", "inf", "\n", "\n", "transition_matrix", "=", "new_transition_matrix", "\n", "\n", "", "if", "tag_observations", ":", "\n", "        ", "if", "len", "(", "tag_observations", ")", "!=", "sequence_length", ":", "\n", "            ", "raise", "ConfigurationError", "(", "\n", "\"Observations were provided, but they were not the same length \"", "\n", "\"as the sequence. Found sequence of length: {} and evidence: {}\"", ".", "format", "(", "\n", "sequence_length", ",", "tag_observations", "\n", ")", "\n", ")", "\n", "", "", "else", ":", "\n", "        ", "tag_observations", "=", "[", "-", "1", "for", "_", "in", "range", "(", "sequence_length", ")", "]", "\n", "\n", "", "if", "has_start_end_restrictions", ":", "\n", "        ", "tag_observations", "=", "[", "num_tags", "-", "2", "]", "+", "tag_observations", "+", "[", "num_tags", "-", "1", "]", "\n", "zero_sentinel", "=", "torch", ".", "zeros", "(", "1", ",", "num_tags", ")", "\n", "extra_tags_sentinel", "=", "torch", ".", "ones", "(", "sequence_length", ",", "2", ")", "*", "-", "math", ".", "inf", "\n", "tag_sequence", "=", "torch", ".", "cat", "(", "[", "tag_sequence", ",", "extra_tags_sentinel", "]", ",", "-", "1", ")", "\n", "tag_sequence", "=", "torch", ".", "cat", "(", "[", "zero_sentinel", ",", "tag_sequence", ",", "zero_sentinel", "]", ",", "0", ")", "\n", "sequence_length", "=", "tag_sequence", ".", "size", "(", "0", ")", "\n", "\n", "", "path_scores", "=", "[", "]", "\n", "path_indices", "=", "[", "]", "\n", "\n", "if", "tag_observations", "[", "0", "]", "!=", "-", "1", ":", "\n", "        ", "one_hot", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "one_hot", "[", "tag_observations", "[", "0", "]", "]", "=", "100000.0", "\n", "path_scores", ".", "append", "(", "one_hot", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "        ", "path_scores", ".", "append", "(", "tag_sequence", "[", "0", ",", ":", "]", ".", "unsqueeze", "(", "0", ")", ")", "\n", "\n", "# Evaluate the scores for all possible paths.", "\n", "", "for", "timestep", "in", "range", "(", "1", ",", "sequence_length", ")", ":", "\n", "# Add pairwise potentials to current scores.", "\n", "        ", "summed_potentials", "=", "path_scores", "[", "timestep", "-", "1", "]", ".", "unsqueeze", "(", "2", ")", "+", "transition_matrix", "\n", "summed_potentials", "=", "summed_potentials", ".", "view", "(", "-", "1", ",", "num_tags", ")", "\n", "\n", "# Best pairwise potential path score from the previous timestep.", "\n", "max_k", "=", "min", "(", "summed_potentials", ".", "size", "(", ")", "[", "0", "]", ",", "top_k", ")", "\n", "scores", ",", "paths", "=", "torch", ".", "topk", "(", "summed_potentials", ",", "k", "=", "max_k", ",", "dim", "=", "0", ")", "\n", "\n", "# If we have an observation for this timestep, use it", "\n", "# instead of the distribution over tags.", "\n", "observation", "=", "tag_observations", "[", "timestep", "]", "\n", "# Warn the user if they have passed", "\n", "# invalid/extremely unlikely evidence.", "\n", "if", "tag_observations", "[", "timestep", "-", "1", "]", "!=", "-", "1", "and", "observation", "!=", "-", "1", ":", "\n", "            ", "if", "transition_matrix", "[", "tag_observations", "[", "timestep", "-", "1", "]", ",", "observation", "]", "<", "-", "10000", ":", "\n", "                ", "logger", ".", "warning", "(", "\n", "\"The pairwise potential between tags you have passed as \"", "\n", "\"observations is extremely unlikely. Double check your evidence \"", "\n", "\"or transition potentials!\"", "\n", ")", "\n", "", "", "if", "observation", "!=", "-", "1", ":", "\n", "            ", "one_hot", "=", "torch", ".", "zeros", "(", "num_tags", ")", "\n", "one_hot", "[", "observation", "]", "=", "100000.0", "\n", "path_scores", ".", "append", "(", "one_hot", ".", "unsqueeze", "(", "0", ")", ")", "\n", "", "else", ":", "\n", "            ", "path_scores", ".", "append", "(", "tag_sequence", "[", "timestep", ",", ":", "]", "+", "scores", ")", "\n", "", "path_indices", ".", "append", "(", "paths", ".", "squeeze", "(", ")", ")", "\n", "\n", "# Construct the most likely sequence backwards.", "\n", "", "path_scores_v", "=", "path_scores", "[", "-", "1", "]", ".", "view", "(", "-", "1", ")", "\n", "max_k", "=", "min", "(", "path_scores_v", ".", "size", "(", ")", "[", "0", "]", ",", "top_k", ")", "\n", "viterbi_scores", ",", "best_paths", "=", "torch", ".", "topk", "(", "path_scores_v", ",", "k", "=", "max_k", ",", "dim", "=", "0", ")", "\n", "viterbi_paths", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "max_k", ")", ":", "\n", "        ", "viterbi_path", "=", "[", "best_paths", "[", "i", "]", "]", "\n", "for", "backward_timestep", "in", "reversed", "(", "path_indices", ")", ":", "\n", "            ", "viterbi_path", ".", "append", "(", "int", "(", "backward_timestep", ".", "view", "(", "-", "1", ")", "[", "viterbi_path", "[", "-", "1", "]", "]", ")", ")", "\n", "# Reverse the backward path.", "\n", "", "viterbi_path", ".", "reverse", "(", ")", "\n", "\n", "if", "has_start_end_restrictions", ":", "\n", "            ", "viterbi_path", "=", "viterbi_path", "[", "1", ":", "-", "1", "]", "\n", "\n", "# Viterbi paths uses (num_tags * n_permutations) nodes; therefore, we need to modulo.", "\n", "", "viterbi_path", "=", "[", "j", "%", "num_tags", "for", "j", "in", "viterbi_path", "]", "\n", "viterbi_paths", ".", "append", "(", "viterbi_path", ")", "\n", "\n", "", "if", "flatten_output", ":", "\n", "        ", "return", "viterbi_paths", "[", "0", "]", ",", "viterbi_scores", "[", "0", "]", "\n", "\n", "", "return", "viterbi_paths", ",", "viterbi_scores", "\n", "", ""]]}