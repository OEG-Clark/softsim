{"home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_classifier.get_x_y": [[21, 35], ["os.listdir", "numpy.load", "numpy.zeros", "tqdm.tqdm", "enumerate", "numpy.load", "numpy.vstack", "numpy.append", "numpy.full"], "function", ["None"], ["def", "get_x_y", "(", "FEATURES_PATH", ")", ":", "\n", "    ", "labels", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "\n", "# Getting first arrays", "\n", "X", "=", "np", ".", "load", "(", "FEATURES_PATH", "+", "labels", "[", "0", "]", "+", "'.npy'", ")", "\n", "y", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "\n", "# Append all of the dataset into one single array, same goes for y", "\n", "for", "i", ",", "label", "in", "tqdm", "(", "enumerate", "(", "labels", "[", "1", ":", "]", ")", ")", ":", "\n", "        ", "x", "=", "np", ".", "load", "(", "FEATURES_PATH", "+", "label", "+", "'.npy'", ")", "\n", "X", "=", "np", ".", "vstack", "(", "(", "X", ",", "x", ")", ")", "\n", "y", "=", "np", ".", "append", "(", "y", ",", "np", ".", "full", "(", "x", ".", "shape", "[", "0", "]", ",", "fill_value", "=", "(", "i", "+", "1", ")", ")", ")", "\n", "\n", "", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_classifier.create_model": [[36, 83], ["keras.layers.Input", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.models.Model", "keras.models.Model.compile", "keras.optimizers.Adam"], "function", ["None"], ["", "def", "create_model", "(", ")", ":", "\n", "    ", "input_shape", "=", "Input", "(", "shape", "=", "(", "90", ",", "80", ",", "1", ")", ")", "\n", "\n", "#Layers", "\n", "c_conv_1", "=", "Conv2D", "(", "8", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_1", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_1", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_2", "=", "Conv2D", "(", "16", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_2", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_2", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_3", "=", "Conv2D", "(", "32", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_3", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_3", "=", "Dropout", "(", "0.2", ")", "\n", "c_flatten", "=", "Flatten", "(", ")", "\n", "c_dense_1", "=", "Dense", "(", "512", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_4", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_2", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_5", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_3", "=", "Dense", "(", "128", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_6", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_output", "=", "Dense", "(", "35", ",", "activation", "=", "'softmax'", ")", "\n", "\n", "classifier", "=", "c_conv_1", "(", "input_shape", ")", "\n", "classifier", "=", "c_max_pool_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_1", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_2", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_2", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_3", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_3", "(", "classifier", ")", "\n", "classifier", "=", "c_flatten", "(", "classifier", ")", "\n", "\n", "classifier", "=", "c_dense_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_4", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_5", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_6", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_output", "(", "classifier", ")", "\n", "\n", "model", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "classifier", ")", "\n", "model", ".", "compile", "(", "loss", "=", "keras", ".", "losses", ".", "categorical_crossentropy", ",", "\n", "optimizer", "=", "keras", ".", "optimizers", ".", "Adam", "(", ")", ",", "\n", "metrics", "=", "[", "'accuracy'", "]", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_classifier.main": [[84, 158], ["numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "numpy.load", "sklearn.utils.shuffle", "sklearn.utils.shuffle", "sklearn.utils.shuffle", "X_train.reshape.reshape", "X_valid.reshape.reshape", "X_test.reshape.reshape", "keras.utils.to_categorical", "keras.utils.to_categorical", "keras.utils.to_categorical", "train_classifier.create_model", "create_model.summary", "create_model.fit", "create_model.save", "create_model.save_weights", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.legend", "matplotlib.savefig", "matplotlib.clf", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.legend", "matplotlib.savefig", "create_model.evaluate", "print", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_classifier.create_model"], ["", "def", "main", "(", ")", ":", "\n", "# load up training, validation and testing data", "\n", "# X_train, y_train = get_x_y('features/training/')", "\n", "# X_valid, y_valid = get_x_y('features/validation/')", "\n", "# X_test, y_test = get_x_y('features/testing/')", "\n", "\n", "# Save the features after combining as that steps takes time", "\n", "# np.save('features/full_train_x.npy', X_train)", "\n", "# np.save('features/full_train_y.npy', y_train)", "\n", "# np.save('features/full_valid_x.npy', X_valid)", "\n", "# np.save('features/full_valid_y.npy', y_valid)", "\n", "# np.save('features/full_test_x.npy', X_test)", "\n", "# np.save('features/full_test_y.npy', y_test)", "\n", "\n", "# Loading the features", "\n", "    ", "X_train", "=", "np", ".", "load", "(", "'features/full_train_x.npy'", ")", "\n", "y_train", "=", "np", ".", "load", "(", "'features/full_train_y.npy'", ")", "\n", "X_valid", "=", "np", ".", "load", "(", "'features/full_valid_x.npy'", ")", "\n", "y_valid", "=", "np", ".", "load", "(", "'features/full_valid_y.npy'", ")", "\n", "X_test", "=", "np", ".", "load", "(", "'features/full_test_x.npy'", ")", "\n", "y_test", "=", "np", ".", "load", "(", "'features/full_test_y.npy'", ")", "\n", "\n", "\n", "# shuffle the data (Use different random state to train separate classifier)", "\n", "X_train", ",", "y_train", "=", "shuffle", "(", "X_train", ",", "y_train", ",", "random_state", "=", "0", ")", "\n", "X_valid", ",", "y_valid", "=", "shuffle", "(", "X_train", ",", "y_train", ",", "random_state", "=", "0", ")", "\n", "X_test", ",", "y_test", "=", "shuffle", "(", "X_train", ",", "y_train", ",", "random_state", "=", "0", ")", "\n", "\n", "X_train", "=", "X_train", ".", "reshape", "(", "X_train", ".", "shape", "[", "0", "]", ",", "90", ",", "80", ",", "1", ")", "\n", "X_valid", "=", "X_valid", ".", "reshape", "(", "X_valid", ".", "shape", "[", "0", "]", ",", "90", ",", "80", ",", "1", ")", "\n", "X_test", "=", "X_test", ".", "reshape", "(", "X_test", ".", "shape", "[", "0", "]", ",", "90", ",", "80", ",", "1", ")", "\n", "\n", "# Change labels to one-hot encoding", "\n", "y_train_hot", "=", "to_categorical", "(", "y_train", ")", "\n", "y_valid_hot", "=", "to_categorical", "(", "y_valid", ")", "\n", "y_test_hot", "=", "to_categorical", "(", "y_test", ")", "\n", "\n", "model", "=", "create_model", "(", ")", "\n", "model", ".", "summary", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "'models'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'models'", ")", "\n", "\n", "", "history1", "=", "model", ".", "fit", "(", "X_train", ",", "y_train_hot", ",", "epochs", "=", "50", ",", "verbose", "=", "1", ",", "validation_data", "=", "(", "X_valid", ",", "y_valid_hot", ")", ")", "\n", "model", ".", "save", "(", "'models/speech_classifier_model.h5'", ")", "\n", "model", ".", "save_weights", "(", "'models/speech_classifier_weights.h5'", ")", "\n", "# model.save('models/speech_classifier_model_2.h5')", "\n", "# model.save_weights('models/speech_classifier_weights_2.h5')", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "'figures'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'figures'", ")", "\n", "\n", "", "plt", ".", "plot", "(", "history1", ".", "history", "[", "'acc'", "]", ")", "\n", "plt", ".", "plot", "(", "history1", ".", "history", "[", "'val_acc'", "]", ")", "\n", "plt", ".", "title", "(", "'Model Accuracy'", ")", "\n", "plt", ".", "ylabel", "(", "'Accuracy'", ")", "\n", "plt", ".", "xlabel", "(", "'Epoch'", ")", "\n", "plt", ".", "legend", "(", "[", "'Train'", ",", "'Valid'", "]", ",", "loc", "=", "'upper right'", ")", "\n", "plt", ".", "savefig", "(", "'figures/speech_classifer_training_curve.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "# plt.savefig('figures/speech_classifer_training_curve_2.png', bbox_inches='tight')", "\n", "plt", ".", "clf", "(", ")", "\n", "\n", "plt", ".", "plot", "(", "history1", ".", "history", "[", "'loss'", "]", ")", "\n", "plt", ".", "plot", "(", "history1", ".", "history", "[", "'val_loss'", "]", ")", "\n", "plt", ".", "title", "(", "'Model Loss'", ")", "\n", "plt", ".", "ylabel", "(", "'Loss'", ")", "\n", "plt", ".", "xlabel", "(", "'Epoch'", ")", "\n", "plt", ".", "legend", "(", "[", "'Train'", ",", "'Valid'", "]", ",", "loc", "=", "'upper right'", ")", "\n", "plt", ".", "savefig", "(", "'figures/speech_classifer_loss_curve.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "# plt.savefig('figures/speech_classifer_loss_curve_2.png', bbox_inches='tight')", "\n", "\n", "\n", "acc", "=", "model", ".", "evaluate", "(", "X_test", ",", "y_test_hot", ")", "\n", "print", "(", "'Model acc: '", ",", "acc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.extract_features.main": [[15, 48], ["os.getcwd", "os.chdir", "subprocess.call", "os.chdir", "subprocess.call", "subprocess.call", "subprocess.call", "os.path.isfile", "subprocess.call", "os.path.isfile", "subprocess.call", "os.path.exists", "os.makedirs"], "function", ["None"], ["def", "main", "(", ")", ":", "\n", "# Create directories to extract features to", "\n", "    ", "directories", "=", "[", "'features'", ",", "train_features_dir", ",", "valid_features_dir", ",", "test_features_dir", "]", "\n", "for", "d", "in", "directories", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n", "# Download pre-trained LJSpeech model hyperparameters", "\n", "", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "wavenet_dir", "+", "'/'", "+", "'20180510_mixture_lj_checkpoint_step000320000_ema.json'", ")", ":", "\n", "        ", "subprocess", ".", "call", "(", "[", "'wget'", ",", "'-P'", ",", "wavenet_dir", ",", "'https://www.dropbox.com/s/0vsd7973w20eskz/20180510_mixture_lj_checkpoint_step000320000_ema.json'", "]", ")", "\n", "\n", "# Download pre-trained LJSpeech model", "\n", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "wavenet_dir", "+", "'/'", "+", "'20180510_mixture_lj_checkpoint_step000320000_ema.pth'", ")", ":", "\n", "        ", "subprocess", ".", "call", "(", "[", "'wget'", ",", "'-P'", ",", "wavenet_dir", ",", "'https://www.dropbox.com/s/zdbfprugbagfp2w/20180510_mixture_lj_checkpoint_step000320000_ema.pth'", "]", ")", "\n", "\n", "# Install WaveNet", "\n", "", "owd", "=", "os", ".", "getcwd", "(", ")", "\n", "os", ".", "chdir", "(", "wavenet_dir", ")", "\n", "subprocess", ".", "call", "(", "[", "'pip3'", ",", "'install'", ",", "'-U'", ",", "'-e'", ",", "'.[train]'", "]", ")", "\n", "\n", "os", ".", "chdir", "(", "owd", ")", "\n", "\n", "# Extract features from training set", "\n", "subprocess", ".", "call", "(", "[", "'python3'", ",", "wavenet_dir", "+", "'preprocess.py'", ",", "'speechcommands'", ",", "\n", "train_data_dir", ",", "train_features_dir", ",", "'--preset='", "+", "params", "]", ")", "\n", "\n", "# Extract features from validation set", "\n", "subprocess", ".", "call", "(", "[", "'python3'", ",", "wavenet_dir", "+", "'preprocess.py'", ",", "'speechcommands'", ",", "\n", "valid_data_dir", ",", "valid_features_dir", ",", "'--preset='", "+", "params", "]", ")", "\n", "\n", "# Extract features from testing set", "\n", "subprocess", ".", "call", "(", "[", "'python3'", ",", "wavenet_dir", "+", "'preprocess.py'", ",", "'speechcommands'", ",", "\n", "test_data_dir", ",", "test_features_dir", ",", "'--preset='", "+", "params", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_autoencoder.get_x_y": [[19, 33], ["os.listdir", "numpy.load", "numpy.zeros", "tqdm.tqdm", "enumerate", "numpy.load", "numpy.vstack", "numpy.append", "numpy.full"], "function", ["None"], ["def", "get_x_y", "(", "FEATURES_PATH", ")", ":", "\n", "    ", "labels", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "\n", "# Getting first arrays", "\n", "X", "=", "np", ".", "load", "(", "FEATURES_PATH", "+", "labels", "[", "0", "]", "+", "'.npy'", ")", "\n", "y", "=", "np", ".", "zeros", "(", "X", ".", "shape", "[", "0", "]", ")", "\n", "\n", "# Append all of the dataset into one single array, same goes for y", "\n", "for", "i", ",", "label", "in", "tqdm", "(", "enumerate", "(", "labels", "[", "1", ":", "]", ")", ")", ":", "\n", "        ", "x", "=", "np", ".", "load", "(", "FEATURES_PATH", "+", "label", "+", "'.npy'", ")", "\n", "X", "=", "np", ".", "vstack", "(", "(", "X", ",", "x", ")", ")", "\n", "y", "=", "np", ".", "append", "(", "y", ",", "np", ".", "full", "(", "x", ".", "shape", "[", "0", "]", ",", "fill_value", "=", "(", "i", "+", "1", ")", ")", ")", "\n", "\n", "", "return", "X", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_autoencoder.create_models": [[34, 122], ["keras.layers.Input", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.models.Model", "keras.layers.Input", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model"], "function", ["None"], ["", "def", "create_models", "(", ")", ":", "\n", "    ", "input_shape", "=", "Input", "(", "shape", "=", "(", "90", ",", "80", ",", "1", ")", ")", "\n", "\n", "# Encoder Layers", "\n", "conv_1", "=", "Conv2D", "(", "16", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_1", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_2", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_2", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_3", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_3", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_4", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "\n", "encoded", "=", "Flatten", "(", "name", "=", "'encoder'", ")", "\n", "\n", "# Bottleneck", "\n", "dense_1", "=", "Dense", "(", "256", ",", "name", "=", "'bottleneck'", ")", "\n", "dense_2", "=", "Dense", "(", "6400", ")", "\n", "reshape", "=", "Reshape", "(", "(", "5", ",", "10", ",", "128", ")", ")", "\n", "\n", "# Decoder Layers", "\n", "conv_5", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_1", "=", "UpSampling2D", "(", "(", "2", ",", "2", ")", ")", "\n", "conv_6", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_2", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "conv_7", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_3", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "\n", "decoded", "=", "Conv2D", "(", "1", ",", "(", "3", ",", "3", ")", ",", "activation", "=", "'sigmoid'", ",", "padding", "=", "'same'", ",", "name", "=", "'decoder'", ")", "\n", "\n", "####################################################################################################", "\n", "#-----------------------------------------Full Autoencoder-----------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "autoencoder", "=", "conv_1", "(", "input_shape", ")", "\n", "autoencoder", "=", "max_pool_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_4", "(", "autoencoder", ")", "\n", "autoencoder", "=", "encoded", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "reshape", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_5", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_6", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_7", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "decoded", "(", "autoencoder", ")", "\n", "\n", "autoencoder", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "autoencoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Encoder-------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "encoder", "=", "conv_1", "(", "input_shape", ")", "\n", "encoder", "=", "max_pool_1", "(", "encoder", ")", "\n", "encoder", "=", "conv_2", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_2", "(", "encoder", ")", "\n", "encoder", "=", "conv_3", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_3", "(", "encoder", ")", "\n", "encoder", "=", "conv_4", "(", "encoder", ")", "\n", "encoder", "=", "encoded", "(", "encoder", ")", "\n", "encoder", "=", "dense_1", "(", "encoder", ")", "\n", "\n", "encoder_model", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "encoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Decoder------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "bottleneck_input_shape", "=", "Input", "(", "shape", "=", "(", "256", ",", ")", ")", "\n", "decoder_model", "=", "dense_2", "(", "bottleneck_input_shape", ")", "\n", "decoder_model", "=", "reshape", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_5", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_1", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_6", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_2", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_7", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_3", "(", "decoder_model", ")", "\n", "decoder_model", "=", "decoded", "(", "decoder_model", ")", "\n", "\n", "decoder_model", "=", "Model", "(", "inputs", "=", "bottleneck_input_shape", ",", "outputs", "=", "decoder_model", ")", "\n", "\n", "return", "encoder_model", ",", "decoder_model", ",", "autoencoder", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_autoencoder.plotDecodedSamples": [[123, 156], ["range", "matplotlib.subplots_adjust", "matplotlib.savefig", "numpy.random.normal", "numpy.save", "numpy.expand_dims", "decoder_model.predict", "matplotlib.subplot", "plt.subplot.set_title", "plt.subplot.tick_params", "numpy.flipud", "matplotlib.imshow", "numpy.save", "decoder_model.predict.squeeze", "str", "decoder_model.predict.squeeze", "str", "str"], "function", ["None"], ["", "def", "plotDecodedSamples", "(", "decoder_model", ")", ":", "\n", "    ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "# plot bottleneck code", "\n", "\n", "        ", "mu", ",", "sigma", "=", "0", ",", "0.1", "# mean and standard deviation", "\n", "s", "=", "np", ".", "random", ".", "normal", "(", "mu", ",", "sigma", ",", "256", ")", "\n", "\n", "np", ".", "save", "(", "'figures/autoencoder_'", "+", "str", "(", "i", ")", "+", "'_before.npy'", ",", "s", ")", "\n", "s", "=", "np", ".", "expand_dims", "(", "s", ",", "0", ")", "\n", "decoded_noise", "=", "decoder_model", ".", "predict", "(", "s", ")", "\n", "\n", "# plot decoded utterance", "\n", "\n", "ax2", "=", "plt", ".", "subplot", "(", "1", ",", "3", ",", "i", "+", "1", ")", "\n", "ax2", ".", "set_title", "(", "\"Sample \"", "+", "str", "(", "i", "+", "1", ")", ")", "\n", "ax2", ".", "tick_params", "(", "\n", "axis", "=", "'both'", ",", "# changes apply to the x-axis", "\n", "which", "=", "'both'", ",", "# both major and minor ticks are affected", "\n", "bottom", "=", "False", ",", "# ticks along the bottom edge are off", "\n", "top", "=", "False", ",", "# ticks along the top edge are off", "\n", "right", "=", "False", ",", "\n", "left", "=", "False", ",", "\n", "labelbottom", "=", "False", ",", "\n", "labelright", "=", "False", ",", "\n", "labelleft", "=", "False", ",", "\n", "labeltop", "=", "False", ")", "# labels along the bottom edge are off", "\n", "\n", "visual", "=", "np", ".", "flipud", "(", "decoded_noise", ".", "squeeze", "(", ")", ".", "T", ")", "\n", "plt", ".", "imshow", "(", "visual", ",", "origin", "=", "'lower'", ")", "\n", "np", ".", "save", "(", "'figures/autoencoder_'", "+", "str", "(", "i", ")", "+", "'_after.npy'", ",", "decoded_noise", ".", "squeeze", "(", ")", ")", "\n", "\n", "", "plt", ".", "subplots_adjust", "(", "wspace", "=", "0.1", ",", "hspace", "=", "0.1", ")", "\n", "plt", ".", "savefig", "(", "'figures/test_decoded_samples.png'", ",", "bbox_inches", "=", "'tight'", ",", "dpi", "=", "1000", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_autoencoder.plotSingleDecodedNoiseSample": [[157, 172], ["numpy.random.normal", "numpy.expand_dims", "decoder_model.predict", "matplotlib.figure", "matplotlib.subplot", "numpy.flipud", "matplotlib.imshow", "plt.subplot.get_xaxis().set_visible", "plt.subplot.get_yaxis().set_visible", "matplotlib.savefig", "decoder_model.predict.reshape", "plt.subplot.get_xaxis", "plt.subplot.get_yaxis"], "function", ["None"], ["", "def", "plotSingleDecodedNoiseSample", "(", "decoder_model", ")", ":", "\n", "    ", "mu", ",", "sigma", "=", "0", ",", "0.1", "# mean and standard deviation", "\n", "s", "=", "np", ".", "random", ".", "normal", "(", "mu", ",", "sigma", ",", "256", ")", "\n", "s", "=", "np", ".", "expand_dims", "(", "s", ",", "0", ")", "\n", "\n", "decoded_noise", "=", "decoder_model", ".", "predict", "(", "s", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "18", ",", "4", ")", ")", "\n", "ax", "=", "plt", ".", "subplot", "(", "2", ",", "2", ",", "1", ")", "\n", "visual", "=", "np", ".", "flipud", "(", "decoded_noise", ".", "reshape", "(", "90", ",", "80", ")", ".", "T", ")", "\n", "plt", ".", "imshow", "(", "visual", ",", "origin", "=", "\"lower\"", ")", "\n", "ax", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "\n", "plt", ".", "savefig", "(", "'figures/decoded_gaussian_noise.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_autoencoder.plot_encoded_decoded_samples": [[173, 203], ["numpy.random.seed", "numpy.random.randint", "encoder.predict", "decoder.predict", "enumerate", "matplotlib.savefig", "matplotlib.subplot", "numpy.flipud", "matplotlib.imshow", "plt.subplot.get_xaxis().set_visible", "plt.subplot.get_yaxis().set_visible", "matplotlib.subplot", "matplotlib.imshow", "plt.subplot.get_xaxis().set_visible", "plt.subplot.get_yaxis().set_visible", "matplotlib.subplot", "numpy.flipud", "matplotlib.imshow", "plt.subplot.get_xaxis().set_visible", "plt.subplot.get_yaxis().set_visible", "encoded_utterances[].reshape", "x_test[].reshape", "plt.subplot.get_xaxis", "plt.subplot.get_yaxis", "plt.subplot.get_xaxis", "plt.subplot.get_yaxis", "decoded_utterances[].reshape", "plt.subplot.get_xaxis", "plt.subplot.get_yaxis"], "function", ["None"], ["", "def", "plot_encoded_decoded_samples", "(", "encoder", ",", "decoder", ",", "x_test", ")", ":", "\n", "    ", "num_speeches", "=", "10", "\n", "np", ".", "random", ".", "seed", "(", "0", ")", "\n", "random_test_utterances", "=", "np", ".", "random", ".", "randint", "(", "x_test", ".", "shape", "[", "0", "]", ",", "size", "=", "num_speeches", ")", "\n", "\n", "encoded_utterances", "=", "encoder", ".", "predict", "(", "x_test", ")", "\n", "decoded_utterances", "=", "decoder", ".", "predict", "(", "encoded_utterances", ")", "\n", "\n", "for", "i", ",", "utterance_idx", "in", "enumerate", "(", "random_test_utterances", ")", ":", "\n", "# plot original image", "\n", "        ", "ax", "=", "plt", ".", "subplot", "(", "3", ",", "num_speeches", ",", "i", "+", "1", ")", "\n", "visual", "=", "np", ".", "flipud", "(", "x_test", "[", "utterance_idx", "]", ".", "reshape", "(", "90", ",", "80", ")", ".", "T", ")", "\n", "plt", ".", "imshow", "(", "visual", ")", "\n", "ax", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "\n", "# plot encoded image", "\n", "ax", "=", "plt", ".", "subplot", "(", "3", ",", "num_speeches", ",", "num_speeches", "+", "i", "+", "1", ")", "\n", "plt", ".", "imshow", "(", "encoded_utterances", "[", "utterance_idx", "]", ".", "reshape", "(", "16", ",", "16", ")", ")", "\n", "ax", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "\n", "# plot reconstructed image", "\n", "ax", "=", "plt", ".", "subplot", "(", "3", ",", "num_speeches", ",", "2", "*", "num_speeches", "+", "i", "+", "1", ")", "\n", "visual", "=", "np", ".", "flipud", "(", "decoded_utterances", "[", "utterance_idx", "]", ".", "reshape", "(", "90", ",", "80", ")", ".", "T", ")", "\n", "plt", ".", "imshow", "(", "visual", ")", "\n", "ax", ".", "get_xaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "ax", ".", "get_yaxis", "(", ")", ".", "set_visible", "(", "False", ")", "\n", "\n", "", "plt", ".", "savefig", "(", "'figures/autoencoder_results.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_autoencoder.main": [[204, 251], ["numpy.load", "numpy.load", "numpy.load", "X_train.reshape.reshape", "X_valid.reshape.reshape", "X_test.reshape.reshape", "train_autoencoder.create_models", "autoencoder.compile", "autoencoder.fit", "autoencoder.save", "autoencoder.save_weights", "range", "numpy.save", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.legend", "matplotlib.savefig", "os.path.exists", "os.makedirs", "encoder.predict", "encoded_features.append", "os.path.exists", "os.makedirs", "numpy.expand_dims"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.train_autoencoder.create_models"], ["", "def", "main", "(", ")", ":", "\n", "# load up training, validation and testing data", "\n", "# X_train, _ = get_x_y('features/training/')", "\n", "# X_valid, _ = get_x_y('features/validation/')", "\n", "# X_test, _ = get_x_y('features/testing/')", "\n", "\n", "# Save the features after combining as that steps takes time", "\n", "# np.save('features/full_train_x.npy', X_train)", "\n", "# np.save('features/full_valid_x.npy', X_valid)", "\n", "# np.save('features/full_test_x.npy', X_test)", "\n", "\n", "# Loading the features", "\n", "    ", "X_train", "=", "np", ".", "load", "(", "'features/full_train_x.npy'", ")", "\n", "X_valid", "=", "np", ".", "load", "(", "'features/full_valid_x.npy'", ")", "\n", "X_test", "=", "np", ".", "load", "(", "'features/full_test_x.npy'", ")", "\n", "\n", "X_train", "=", "X_train", ".", "reshape", "(", "X_train", ".", "shape", "[", "0", "]", ",", "90", ",", "80", ",", "1", ")", "\n", "X_valid", "=", "X_valid", ".", "reshape", "(", "X_valid", ".", "shape", "[", "0", "]", ",", "90", ",", "80", ",", "1", ")", "\n", "X_test", "=", "X_test", ".", "reshape", "(", "X_test", ".", "shape", "[", "0", "]", ",", "90", ",", "80", ",", "1", ")", "\n", "\n", "encoder", ",", "decoder", ",", "autoencoder", "=", "create_models", "(", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "'models'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'models'", ")", "\n", "\n", "", "autoencoder", ".", "compile", "(", "optimizer", "=", "'adam'", ",", "loss", "=", "'binary_crossentropy'", ")", "\n", "history1", "=", "autoencoder", ".", "fit", "(", "X_train", ",", "X_train", ",", "epochs", "=", "50", ",", "validation_data", "=", "(", "X_valid", ",", "X_valid", ")", ")", "\n", "autoencoder", ".", "save", "(", "'models/autoencoder.h5'", ")", "\n", "autoencoder", ".", "save_weights", "(", "'models/autoencoder_weights.h5'", ")", "\n", "\n", "encoded_features", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "X_test", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "encoded_utterance", "=", "encoder", ".", "predict", "(", "np", ".", "expand_dims", "(", "X_test", "[", "i", "]", ",", "0", ")", ")", "\n", "encoded_features", ".", "append", "(", "encoded_utterance", ")", "\n", "\n", "", "np", ".", "save", "(", "'features/full_test_x_encoded.npy'", ",", "encoded_features", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "'figures'", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "'figures'", ")", "\n", "\n", "", "plt", ".", "plot", "(", "history1", ".", "history", "[", "'loss'", "]", ")", "\n", "plt", ".", "plot", "(", "history1", ".", "history", "[", "'val_loss'", "]", ")", "\n", "plt", ".", "title", "(", "'Model Loss'", ")", "\n", "plt", ".", "ylabel", "(", "'Loss'", ")", "\n", "plt", ".", "xlabel", "(", "'Epoch'", ")", "\n", "plt", ".", "legend", "(", "[", "'Train'", ",", "'Valid'", "]", ",", "loc", "=", "'upper right'", ")", "\n", "plt", ".", "savefig", "(", "'figures/autoencoder_loss_curve.png'", ",", "bbox_inches", "=", "'tight'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.initial_setup.extract_dataset": [[8, 21], ["open", "line.rstrip.rstrip", "line.rstrip.split", "shutil.copy", "os.path.exists", "os.makedirs", "os.path.isfile", "print", "os.remove"], "function", ["None"], ["def", "extract_dataset", "(", "input_file", ",", "output_dir", ")", ":", "\n", "    ", "with", "open", "(", "input_file", ")", "as", "in_file", ":", "\n", "        ", "for", "line", "in", "in_file", ":", "\n", "            ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "directory", "=", "line", ".", "split", "(", "'/'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", "+", "directory", "[", "0", "]", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "output_dir", "+", "directory", "[", "0", "]", ")", "\n", "\n", "", "newpath", "=", "shutil", ".", "copy", "(", "'dataset/training/'", "+", "line", ",", "output_dir", "+", "line", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "newpath", ")", ":", "\n", "                ", "print", "(", "'file not copied: '", "+", "newpath", ")", "\n", "", "else", ":", "\n", "                ", "os", ".", "remove", "(", "'dataset/training/'", "+", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.initial_setup.main": [[22, 43], ["os.path.isfile", "subprocess.call", "subprocess.call", "initial_setup.extract_dataset", "initial_setup.extract_dataset", "subprocess.call", "subprocess.call", "subprocess.call", "subprocess.call", "subprocess.call", "subprocess.call", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.initial_setup.extract_dataset", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.None.initial_setup.extract_dataset"], ["", "", "", "", "def", "main", "(", ")", ":", "\n", "# Create directories for dataset", "\n", "    ", "directories", "=", "[", "'dataset'", ",", "'dataset/training'", ",", "'dataset/validation'", ",", "'dataset/testing'", "]", "\n", "for", "d", "in", "directories", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n", "# Download Speech Commands V2 dataset and split data to training, validation & testing", "\n", "", "", "if", "not", "os", ".", "path", ".", "isfile", "(", "'speech_commands_v0.02.tar.gz'", ")", ":", "\n", "        ", "subprocess", ".", "call", "(", "[", "'wget'", ",", "'http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz'", "]", ")", "\n", "subprocess", ".", "call", "(", "[", "'tar'", ",", "'-xzfv'", ",", "'speech_commands_v0.02.tar.gz'", ",", "'-C'", ",", "'dataset/training'", "]", ")", "\n", "extract_dataset", "(", "'dataset/training/validation_list.txt'", ",", "'dataset/validation/'", ")", "\n", "extract_dataset", "(", "'dataset/training/testing_list.txt'", ",", "'dataset/testing/'", ")", "\n", "\n", "# These files are removed because the feature extraction code will not require these", "\n", "subprocess", ".", "call", "(", "[", "'rm'", ",", "'-rf'", ",", "'dataset/training/validation_list.txt'", "]", ")", "\n", "subprocess", ".", "call", "(", "[", "'rm'", ",", "'-rf'", ",", "'dataset/training/testing_list.txt'", "]", ")", "\n", "subprocess", ".", "call", "(", "[", "'rm'", ",", "'-rf'", ",", "'dataset/training/README.md'", "]", ")", "\n", "subprocess", ".", "call", "(", "[", "'rm'", ",", "'-rf'", ",", "'dataset/training/LICENSE'", "]", ")", "\n", "subprocess", ".", "call", "(", "[", "'rm'", ",", "'-rf'", ",", "'dataset/training/_background_noise_'", "]", ")", "\n", "subprocess", ".", "call", "(", "[", "'rm'", ",", "'-rf'", ",", "'dataset/training/.DS_Store'", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.speechcommands.build_from_path": [[17, 44], ["concurrent.futures.ProcessPoolExecutor", "os.listdir", "tqdm", "tqdm", "print", "numpy.save", "futures.append", "future.result", "mel_vectors.append", "str", "os.listdir", "concurrent.futures.ProcessPoolExecutor.submit", "numpy.delete", "numpy.zeros", "numpy.vstack", "numpy.shape", "functools.partial"], "function", ["None"], ["def", "build_from_path", "(", "in_dir", ",", "out_dir", ",", "num_workers", "=", "1", ",", "tqdm", "=", "lambda", "x", ":", "x", ")", ":", "\n", "    ", "executor", "=", "ProcessPoolExecutor", "(", "max_workers", "=", "num_workers", ")", "\n", "\n", "labels", "=", "os", ".", "listdir", "(", "in_dir", ")", "\n", "for", "label", "in", "tqdm", "(", "labels", ")", ":", "\n", "        ", "mel_vectors", "=", "[", "]", "\n", "futures", "=", "[", "]", "\n", "\n", "wavfiles", "=", "[", "in_dir", "+", "label", "+", "'/'", "+", "wavfile", "for", "wavfile", "in", "os", ".", "listdir", "(", "in_dir", "+", "label", ")", "]", "\n", "for", "wavfile", "in", "wavfiles", ":", "\n", "            ", "futures", ".", "append", "(", "executor", ".", "submit", "(", "\n", "partial", "(", "_process_utterance", ",", "out_dir", ",", "wavfile", ")", ")", ")", "\n", "\n", "", "for", "future", "in", "tqdm", "(", "futures", ")", ":", "\n", "            ", "mel", "=", "future", ".", "result", "(", ")", "\n", "# To make fixed size inputs for models", "\n", "while", "mel", ".", "shape", "[", "0", "]", ">", "90", ":", "\n", "                ", "mel", "=", "np", ".", "delete", "(", "mel", ",", "1", ",", "0", ")", "\n", "", "while", "mel", ".", "shape", "[", "0", "]", "<", "90", ":", "\n", "                ", "padding", "=", "np", ".", "zeros", "(", "80", ")", "\n", "mel", "=", "np", ".", "vstack", "(", "[", "mel", ",", "padding", "]", ")", "\n", "\n", "# print('mel shape', np.shape(mel))", "\n", "", "mel_vectors", ".", "append", "(", "mel", ")", "\n", "\n", "", "print", "(", "'mel shape: '", ",", "str", "(", "np", ".", "shape", "(", "mel_vectors", ")", ")", ")", "\n", "np", ".", "save", "(", "out_dir", "+", "label", "+", "'.npy'", ",", "mel_vectors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.speechcommands._process_utterance": [[45, 79], ["audio.load_wav", "wavenet_vocoder.util.is_mulaw_quantize", "mel_spectrogram.astype", "nnmnkwii.preprocessing.mulaw_quantize", "audio.start_and_end_indices", "nnmnkwii.preprocessing.mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "audio.melspectrogram().astype", "nnmnkwii.preprocessing.mulaw", "nnmnkwii.preprocessing.mulaw", "numpy.abs().max", "audio.melspectrogram", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.load_wav", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.start_and_end_indices", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.melspectrogram"], ["", "", "def", "_process_utterance", "(", "out_dir", ",", "wav_path", ")", ":", "\n", "# Load the audio to a numpy array:", "\n", "    ", "wav", "=", "audio", ".", "load_wav", "(", "wav_path", ")", "\n", "\n", "if", "hparams", ".", "rescaling", ":", "\n", "        ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "\n", "# Mu-law quantize", "\n", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [0, quantize_channels)", "\n", "        ", "out", "=", "P", ".", "mulaw_quantize", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "\n", "# Trim silences", "\n", "start", ",", "end", "=", "audio", ".", "start_and_end_indices", "(", "out", ",", "hparams", ".", "silence_threshold", ")", "\n", "wav", "=", "wav", "[", "start", ":", "end", "]", "\n", "out", "=", "out", "[", "start", ":", "end", "]", "\n", "constant_values", "=", "P", ".", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "int16", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [-1, 1]", "\n", "        ", "out", "=", "P", ".", "mulaw", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "constant_values", "=", "P", ".", "mulaw", "(", "0.0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "", "else", ":", "\n", "# [-1, 1]", "\n", "        ", "out", "=", "wav", "\n", "constant_values", "=", "0.0", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "# Compute a mel-scale spectrogram from the trimmed wav:", "\n", "# (N, D)", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "wav", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "\n", "return", "mel_spectrogram", ".", "astype", "(", "np", ".", "float32", ")", "", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.cmu_arctic.build_from_path": [[18, 33], ["concurrent.futures.ProcessPoolExecutor", "nnmnkwii.datasets.cmu_arctic.WavFileDataSource", "cmu_arctic.WavFileDataSource.collect_files", "enumerate", "zip", "futures.append", "future.result", "concurrent.futures.ProcessPoolExecutor.submit", "tqdm", "functools.partial"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._NPYDataSource.collect_files"], ["def", "build_from_path", "(", "in_dir", ",", "out_dir", ",", "num_workers", "=", "1", ",", "tqdm", "=", "lambda", "x", ":", "x", ")", ":", "\n", "    ", "executor", "=", "ProcessPoolExecutor", "(", "max_workers", "=", "num_workers", ")", "\n", "futures", "=", "[", "]", "\n", "\n", "speakers", "=", "cmu_arctic", ".", "available_speakers", "\n", "\n", "wd", "=", "cmu_arctic", ".", "WavFileDataSource", "(", "in_dir", ",", "speakers", "=", "speakers", ")", "\n", "wav_paths", "=", "wd", ".", "collect_files", "(", ")", "\n", "speaker_ids", "=", "wd", ".", "labels", "\n", "\n", "for", "index", ",", "(", "speaker_id", ",", "wav_path", ")", "in", "enumerate", "(", "\n", "zip", "(", "speaker_ids", ",", "wav_paths", ")", ")", ":", "\n", "        ", "futures", ".", "append", "(", "executor", ".", "submit", "(", "\n", "partial", "(", "_process_utterance", ",", "out_dir", ",", "index", "+", "1", ",", "speaker_id", ",", "wav_path", ",", "\"N/A\"", ")", ")", ")", "\n", "", "return", "[", "future", ".", "result", "(", ")", "for", "future", "in", "tqdm", "(", "futures", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.cmu_arctic.start_at": [[35, 43], ["range", "len"], "function", ["None"], ["", "def", "start_at", "(", "labels", ")", ":", "\n", "    ", "has_silence", "=", "labels", "[", "0", "]", "[", "-", "1", "]", "==", "\"pau\"", "\n", "if", "not", "has_silence", ":", "\n", "        ", "return", "labels", "[", "0", "]", "[", "0", "]", "\n", "", "for", "i", "in", "range", "(", "1", ",", "len", "(", "labels", ")", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "[", "-", "1", "]", "!=", "\"pau\"", ":", "\n", "            ", "return", "labels", "[", "i", "]", "[", "0", "]", "\n", "", "", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.cmu_arctic.end_at": [[45, 53], ["range", "len"], "function", ["None"], ["", "def", "end_at", "(", "labels", ")", ":", "\n", "    ", "has_silence", "=", "labels", "[", "-", "1", "]", "[", "-", "1", "]", "==", "\"pau\"", "\n", "if", "not", "has_silence", ":", "\n", "        ", "return", "labels", "[", "-", "1", "]", "[", "1", "]", "\n", "", "for", "i", "in", "range", "(", "len", "(", "labels", ")", "-", "2", ",", "0", ",", "-", "1", ")", ":", "\n", "        ", "if", "labels", "[", "i", "]", "[", "-", "1", "]", "!=", "\"pau\"", ":", "\n", "            ", "return", "labels", "[", "i", "]", "[", "1", "]", "\n", "", "", "assert", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.cmu_arctic._process_utterance": [[55, 129], ["audio.load_wav", "wav_path.replace().replace", "wavenet_vocoder.util.is_mulaw_quantize", "audio.lws_pad_lr", "numpy.pad", "len", "numpy.save", "numpy.save", "os.path.exists", "nnmnkwii.io.hts.load", "int", "int", "librosa.effects.trim", "librosa.effects.trim", "nnmnkwii.preprocessing.mulaw_quantize", "audio.start_and_end_indices", "nnmnkwii.preprocessing.mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "audio.melspectrogram().astype", "audio.get_hop_size", "len", "os.path.join", "P.mulaw.astype", "os.path.join", "mel_spectrogram.astype", "wav_path.replace", "nnmnkwii.preprocessing.mulaw", "nnmnkwii.preprocessing.mulaw", "audio.get_hop_size", "len", "audio.get_hop_size", "numpy.abs().max", "audio.melspectrogram", "audio.get_hop_size", "cmu_arctic.start_at", "cmu_arctic.end_at", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.load_wav", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.lws_pad_lr", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.trim", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.trim", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.start_and_end_indices", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.melspectrogram", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.cmu_arctic.start_at", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.cmu_arctic.end_at"], ["", "def", "_process_utterance", "(", "out_dir", ",", "index", ",", "speaker_id", ",", "wav_path", ",", "text", ")", ":", "\n", "    ", "sr", "=", "hparams", ".", "sample_rate", "\n", "\n", "# Load the audio to a numpy array. Resampled if needed", "\n", "wav", "=", "audio", ".", "load_wav", "(", "wav_path", ")", "\n", "\n", "lab_path", "=", "wav_path", ".", "replace", "(", "\"wav/\"", ",", "\"lab/\"", ")", ".", "replace", "(", "\".wav\"", ",", "\".lab\"", ")", "\n", "\n", "# Trim silence from hts labels if available", "\n", "# TODO", "\n", "if", "exists", "(", "lab_path", ")", "and", "False", ":", "\n", "        ", "labels", "=", "hts", ".", "load", "(", "lab_path", ")", "\n", "b", "=", "int", "(", "start_at", "(", "labels", ")", "*", "1e-7", "*", "sr", ")", "\n", "e", "=", "int", "(", "end_at", "(", "labels", ")", "*", "1e-7", "*", "sr", ")", "\n", "wav", "=", "wav", "[", "b", ":", "e", "]", "\n", "wav", ",", "_", "=", "librosa", ".", "effects", ".", "trim", "(", "wav", ",", "top_db", "=", "20", ")", "\n", "", "else", ":", "\n", "        ", "wav", ",", "_", "=", "librosa", ".", "effects", ".", "trim", "(", "wav", ",", "top_db", "=", "20", ")", "\n", "\n", "", "if", "hparams", ".", "rescaling", ":", "\n", "        ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "\n", "# Mu-law quantize", "\n", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [0, quantize_channels)", "\n", "        ", "out", "=", "P", ".", "mulaw_quantize", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "\n", "# Trim silences", "\n", "start", ",", "end", "=", "audio", ".", "start_and_end_indices", "(", "out", ",", "hparams", ".", "silence_threshold", ")", "\n", "wav", "=", "wav", "[", "start", ":", "end", "]", "\n", "out", "=", "out", "[", "start", ":", "end", "]", "\n", "constant_values", "=", "P", ".", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "int16", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [-1, 1]", "\n", "        ", "out", "=", "P", ".", "mulaw", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "constant_values", "=", "P", ".", "mulaw", "(", "0.0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "", "else", ":", "\n", "# [-1, 1]", "\n", "        ", "out", "=", "wav", "\n", "constant_values", "=", "0.0", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "# Compute a mel-scale spectrogram from the trimmed wav:", "\n", "# (N, D)", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "wav", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "# lws pads zeros internally before performing stft", "\n", "# this is needed to adjust time resolution between audio and mel-spectrogram", "\n", "l", ",", "r", "=", "audio", ".", "lws_pad_lr", "(", "wav", ",", "hparams", ".", "fft_size", ",", "audio", ".", "get_hop_size", "(", ")", ")", "\n", "\n", "# zero pad for quantized signal", "\n", "out", "=", "np", ".", "pad", "(", "out", ",", "(", "l", ",", "r", ")", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "constant_values", ")", "\n", "N", "=", "mel_spectrogram", ".", "shape", "[", "0", "]", "\n", "assert", "len", "(", "out", ")", ">=", "N", "*", "audio", ".", "get_hop_size", "(", ")", "\n", "\n", "# time resolution adjustment", "\n", "# ensure length of raw audio is multiple of hop_size so that we can use", "\n", "# transposed convolution to upsample", "\n", "out", "=", "out", "[", ":", "N", "*", "audio", ".", "get_hop_size", "(", ")", "]", "\n", "assert", "len", "(", "out", ")", "%", "audio", ".", "get_hop_size", "(", ")", "==", "0", "\n", "\n", "timesteps", "=", "len", "(", "out", ")", "\n", "\n", "# Write the spectrograms to disk:", "\n", "audio_filename", "=", "'cmu_arctic-audio-%05d.npy'", "%", "index", "\n", "mel_filename", "=", "'cmu_arctic-mel-%05d.npy'", "%", "index", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "audio_filename", ")", ",", "\n", "out", ".", "astype", "(", "out_dtype", ")", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "mel_filename", ")", ",", "\n", "mel_spectrogram", ".", "astype", "(", "np", ".", "float32", ")", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "# Return a tuple describing this training example:", "\n", "return", "(", "audio_filename", ",", "mel_filename", ",", "timesteps", ",", "text", ",", "speaker_id", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.build_py.run": [[28, 31], ["setuptools.setup.build_py.create_version_file", "setuptools.command.build_py.build_py.run", "setuptools.command.build_py.build_py.run", "setuptools.command.build_py.build_py.run", "setuptools.command.build_py.build_py.run"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.build_py.create_version_file", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run"], ["    ", "def", "run", "(", "self", ")", ":", "\n", "        ", "self", ".", "create_version_file", "(", ")", "\n", "setuptools", ".", "command", ".", "build_py", ".", "build_py", ".", "run", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.build_py.create_version_file": [[32, 39], ["print", "os.path.join", "open", "f.write"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "create_version_file", "(", ")", ":", "\n", "        ", "global", "version", ",", "cwd", "\n", "print", "(", "'-- Building version '", "+", "version", ")", "\n", "version_path", "=", "os", ".", "path", ".", "join", "(", "cwd", ",", "'wavenet_vocoder'", ",", "'version.py'", ")", "\n", "with", "open", "(", "version_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "\"__version__ = '{}'\\n\"", ".", "format", "(", "version", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run": [[43, 46], ["setuptools.setup.build_py.create_version_file", "setuptools.command.develop.develop.run", "setuptools.command.develop.develop.run", "setuptools.command.develop.develop.run", "setuptools.command.develop.develop.run"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.build_py.create_version_file", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.setup.develop.run"], ["    ", "def", "run", "(", "self", ")", ":", "\n", "        ", "build_py", ".", "create_version_file", "(", ")", "\n", "setuptools", ".", "command", ".", "develop", ".", "develop", ".", "run", "(", "self", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.load_wav": [[12, 14], ["librosa.core.load", "librosa.core.load"], "function", ["None"], ["def", "load_wav", "(", "path", ")", ":", "\n", "    ", "return", "librosa", ".", "core", ".", "load", "(", "path", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.save_wav": [[16, 19], ["scipy.io.wavfile.write", "max", "wav.astype", "numpy.max", "numpy.abs"], "function", ["None"], ["", "def", "save_wav", "(", "wav", ",", "path", ")", ":", "\n", "    ", "wav", "*=", "32767", "/", "max", "(", "0.01", ",", "np", ".", "max", "(", "np", ".", "abs", "(", "wav", ")", ")", ")", "\n", "wavfile", ".", "write", "(", "path", ",", "hparams", ".", "sample_rate", ",", "wav", ".", "astype", "(", "np", ".", "int16", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.trim": [[21, 24], ["audio.start_and_end_indices"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.start_and_end_indices"], ["", "def", "trim", "(", "quantized", ")", ":", "\n", "    ", "start", ",", "end", "=", "start_and_end_indices", "(", "quantized", ",", "hparams", ".", "silence_threshold", ")", "\n", "return", "quantized", "[", "start", ":", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.adjust_time_resolution": [[26, 50], ["numpy.repeat", "audio.start_and_end_indices", "len", "len", "numpy.pad"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.start_and_end_indices"], ["", "def", "adjust_time_resolution", "(", "quantized", ",", "mel", ")", ":", "\n", "    ", "\"\"\"Adjust time resolution by repeating features\n\n    Args:\n        quantized (ndarray): (T,)\n        mel (ndarray): (N, D)\n\n    Returns:\n        tuple: Tuple of (T,) and (T, D)\n    \"\"\"", "\n", "assert", "len", "(", "quantized", ".", "shape", ")", "==", "1", "\n", "assert", "len", "(", "mel", ".", "shape", ")", "==", "2", "\n", "\n", "upsample_factor", "=", "quantized", ".", "size", "//", "mel", ".", "shape", "[", "0", "]", "\n", "mel", "=", "np", ".", "repeat", "(", "mel", ",", "upsample_factor", ",", "axis", "=", "0", ")", "\n", "n_pad", "=", "quantized", ".", "size", "-", "mel", ".", "shape", "[", "0", "]", "\n", "if", "n_pad", "!=", "0", ":", "\n", "        ", "assert", "n_pad", ">", "0", "\n", "mel", "=", "np", ".", "pad", "(", "mel", ",", "[", "(", "0", ",", "n_pad", ")", ",", "(", "0", ",", "0", ")", "]", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "0", ")", "\n", "\n", "# trim", "\n", "", "start", ",", "end", "=", "start_and_end_indices", "(", "quantized", ",", "hparams", ".", "silence_threshold", ")", "\n", "\n", "return", "quantized", "[", "start", ":", "end", "]", ",", "mel", "[", "start", ":", "end", ",", ":", "]", "\n", "", "adjast_time_resolution", "=", "adjust_time_resolution", "# 'adjust' is correct spelling, this is for compatibility", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.start_and_end_indices": [[53, 65], ["range", "range", "abs", "abs", "abs", "abs", "hparams.hparams.silence_threshold", "hparams.hparams.silence_threshold"], "function", ["None"], ["def", "start_and_end_indices", "(", "quantized", ",", "silence_threshold", "=", "2", ")", ":", "\n", "    ", "for", "start", "in", "range", "(", "quantized", ".", "size", ")", ":", "\n", "        ", "if", "abs", "(", "quantized", "[", "start", "]", "-", "127", ")", ">", "silence_threshold", ":", "\n", "            ", "break", "\n", "", "", "for", "end", "in", "range", "(", "quantized", ".", "size", "-", "1", ",", "1", ",", "-", "1", ")", ":", "\n", "        ", "if", "abs", "(", "quantized", "[", "end", "]", "-", "127", ")", ">", "silence_threshold", ":", "\n", "            ", "break", "\n", "\n", "", "", "assert", "abs", "(", "quantized", "[", "start", "]", "-", "127", ")", ">", "silence_threshold", "\n", "assert", "abs", "(", "quantized", "[", "end", "]", "-", "127", ")", ">", "silence_threshold", "\n", "\n", "return", "start", ",", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.melspectrogram": [[67, 73], ["audio._normalize", "_lws_processor().stft", "audio._amp_to_db", "audio._linear_to_mel", "audio._lws_processor", "numpy.abs", "S.max", "S.min"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._normalize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._amp_to_db", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._linear_to_mel", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._lws_processor"], ["", "def", "melspectrogram", "(", "y", ")", ":", "\n", "    ", "D", "=", "_lws_processor", "(", ")", ".", "stft", "(", "y", ")", ".", "T", "\n", "S", "=", "_amp_to_db", "(", "_linear_to_mel", "(", "np", ".", "abs", "(", "D", ")", ")", ")", "-", "hparams", ".", "ref_level_db", "\n", "if", "not", "hparams", ".", "allow_clipping_in_normalization", ":", "\n", "        ", "assert", "S", ".", "max", "(", ")", "<=", "0", "and", "S", ".", "min", "(", ")", "-", "hparams", ".", "min_level_db", ">=", "0", "\n", "", "return", "_normalize", "(", "S", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size": [[75, 81], ["int"], "function", ["None"], ["", "def", "get_hop_size", "(", ")", ":", "\n", "    ", "hop_size", "=", "hparams", ".", "hop_size", "\n", "if", "hop_size", "is", "None", ":", "\n", "        ", "assert", "hparams", ".", "frame_shift_ms", "is", "not", "None", "\n", "hop_size", "=", "int", "(", "hparams", ".", "frame_shift_ms", "/", "1000", "*", "hparams", ".", "sample_rate", ")", "\n", "", "return", "hop_size", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._lws_processor": [[83, 85], ["lws.lws", "audio.get_hop_size"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size"], ["", "def", "_lws_processor", "(", ")", ":", "\n", "    ", "return", "lws", ".", "lws", "(", "hparams", ".", "fft_size", ",", "get_hop_size", "(", ")", ",", "mode", "=", "\"speech\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.lws_num_frames": [[87, 96], ["None"], "function", ["None"], ["", "def", "lws_num_frames", "(", "length", ",", "fsize", ",", "fshift", ")", ":", "\n", "    ", "\"\"\"Compute number of time frames of lws spectrogram\n    \"\"\"", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "if", "length", "%", "fshift", "==", "0", ":", "\n", "        ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "1", "\n", "", "else", ":", "\n", "        ", "M", "=", "(", "length", "+", "pad", "*", "2", "-", "fsize", ")", "//", "fshift", "+", "2", "\n", "", "return", "M", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.lws_pad_lr": [[98, 106], ["audio.lws_num_frames", "len", "len"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.lws_num_frames"], ["", "def", "lws_pad_lr", "(", "x", ",", "fsize", ",", "fshift", ")", ":", "\n", "    ", "\"\"\"Compute left and right padding lws internally uses\n    \"\"\"", "\n", "M", "=", "lws_num_frames", "(", "len", "(", "x", ")", ",", "fsize", ",", "fshift", ")", "\n", "pad", "=", "(", "fsize", "-", "fshift", ")", "\n", "T", "=", "len", "(", "x", ")", "+", "2", "*", "pad", "\n", "r", "=", "(", "M", "-", "1", ")", "*", "fshift", "+", "fsize", "-", "T", "\n", "return", "pad", ",", "pad", "+", "r", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._linear_to_mel": [[113, 118], ["numpy.dot", "audio._build_mel_basis"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._build_mel_basis"], ["def", "_linear_to_mel", "(", "spectrogram", ")", ":", "\n", "    ", "global", "_mel_basis", "\n", "if", "_mel_basis", "is", "None", ":", "\n", "        ", "_mel_basis", "=", "_build_mel_basis", "(", ")", "\n", "", "return", "np", ".", "dot", "(", "_mel_basis", ",", "spectrogram", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._build_mel_basis": [[120, 125], ["librosa.filters.mel", "librosa.filters.mel"], "function", ["None"], ["", "def", "_build_mel_basis", "(", ")", ":", "\n", "    ", "assert", "hparams", ".", "fmax", "<=", "hparams", ".", "sample_rate", "//", "2", "\n", "return", "librosa", ".", "filters", ".", "mel", "(", "hparams", ".", "sample_rate", ",", "hparams", ".", "fft_size", ",", "\n", "fmin", "=", "hparams", ".", "fmin", ",", "fmax", "=", "hparams", ".", "fmax", ",", "\n", "n_mels", "=", "hparams", ".", "num_mels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._amp_to_db": [[127, 130], ["numpy.exp", "numpy.log10", "numpy.log", "numpy.maximum"], "function", ["None"], ["", "def", "_amp_to_db", "(", "x", ")", ":", "\n", "    ", "min_level", "=", "np", ".", "exp", "(", "hparams", ".", "min_level_db", "/", "20", "*", "np", ".", "log", "(", "10", ")", ")", "\n", "return", "20", "*", "np", ".", "log10", "(", "np", ".", "maximum", "(", "min_level", ",", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._db_to_amp": [[132, 134], ["numpy.power"], "function", ["None"], ["", "def", "_db_to_amp", "(", "x", ")", ":", "\n", "    ", "return", "np", ".", "power", "(", "10.0", ",", "x", "*", "0.05", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._normalize": [[136, 138], ["numpy.clip"], "function", ["None"], ["", "def", "_normalize", "(", "S", ")", ":", "\n", "    ", "return", "np", ".", "clip", "(", "(", "S", "-", "hparams", ".", "min_level_db", ")", "/", "-", "hparams", ".", "min_level_db", ",", "0", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._denormalize": [[140, 142], ["numpy.clip"], "function", ["None"], ["", "def", "_denormalize", "(", "S", ")", ":", "\n", "    ", "return", "(", "np", ".", "clip", "(", "S", ",", "0", ",", "1", ")", "*", "-", "hparams", ".", "min_level_db", ")", "+", "hparams", ".", "min_level_db", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._NPYDataSource.__init__": [[102, 114], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "col", ",", "speaker_id", "=", "None", ",", "\n", "train", "=", "True", ",", "test_size", "=", "0.05", ",", "test_num_samples", "=", "None", ",", "random_state", "=", "1234", ")", ":", "\n", "        ", "self", ".", "data_root", "=", "data_root", "\n", "self", ".", "col", "=", "col", "\n", "self", ".", "lengths", "=", "[", "]", "\n", "self", ".", "speaker_id", "=", "speaker_id", "\n", "self", ".", "multi_speaker", "=", "False", "\n", "self", ".", "speaker_ids", "=", "None", "\n", "self", ".", "train", "=", "train", "\n", "self", ".", "test_size", "=", "test_size", "\n", "self", ".", "test_num_samples", "=", "test_num_samples", "\n", "self", ".", "random_state", "=", "random_state", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._NPYDataSource.interest_indices": [[115, 124], ["numpy.arange", "sklearn.model_selection.train_test_split", "len", "len"], "methods", ["None"], ["", "def", "interest_indices", "(", "self", ",", "paths", ")", ":", "\n", "        ", "indices", "=", "np", ".", "arange", "(", "len", "(", "paths", ")", ")", "\n", "if", "self", ".", "test_size", "is", "None", ":", "\n", "            ", "test_size", "=", "self", ".", "test_num_samples", "/", "len", "(", "paths", ")", "\n", "", "else", ":", "\n", "            ", "test_size", "=", "self", ".", "test_size", "\n", "", "train_indices", ",", "test_indices", "=", "train_test_split", "(", "\n", "indices", ",", "test_size", "=", "test_size", ",", "random_state", "=", "self", ".", "random_state", ")", "\n", "return", "train_indices", "if", "self", ".", "train", "else", "test_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._NPYDataSource.collect_files": [[125, 171], ["os.path.join", "lines[].decode().split", "list", "list", "list", "train._NPYDataSource.interest_indices", "list", "list", "list", "open", "f.readlines", "len", "map", "map", "map", "list", "map", "list", "list", "lines[].decode", "len", "len", "map", "list", "list", "train._NPYDataSource.interest_indices", "list", "list", "list", "numpy.array", "numpy.array", "map", "len", "len", "int", "os.path.join", "numpy.array", "map", "numpy.array", "lines[].decode().split.decode().split", "int", "numpy.array", "numpy.array", "numpy.array", "numpy.array", "lines[].decode().split.decode().split", "lines[].decode().split.decode", "lines[].decode().split.decode().split", "lines[].decode().split.decode", "lines[].decode().split.decode"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._NPYDataSource.interest_indices", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._NPYDataSource.interest_indices"], ["", "def", "collect_files", "(", "self", ")", ":", "\n", "        ", "meta", "=", "join", "(", "self", ".", "data_root", ",", "\"train.txt\"", ")", "\n", "with", "open", "(", "meta", ",", "\"rb\"", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "", "l", "=", "lines", "[", "0", "]", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "\"|\"", ")", "\n", "assert", "len", "(", "l", ")", "==", "4", "or", "len", "(", "l", ")", "==", "5", "\n", "self", ".", "multi_speaker", "=", "len", "(", "l", ")", "==", "5", "\n", "self", ".", "lengths", "=", "list", "(", "\n", "map", "(", "lambda", "l", ":", "int", "(", "l", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "\"|\"", ")", "[", "2", "]", ")", ",", "lines", ")", ")", "\n", "\n", "paths_relative", "=", "list", "(", "map", "(", "lambda", "l", ":", "l", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "\"|\"", ")", "[", "self", ".", "col", "]", ",", "lines", ")", ")", "\n", "paths", "=", "list", "(", "map", "(", "lambda", "f", ":", "join", "(", "self", ".", "data_root", ",", "f", ")", ",", "paths_relative", ")", ")", "\n", "\n", "if", "self", ".", "multi_speaker", ":", "\n", "            ", "speaker_ids", "=", "list", "(", "map", "(", "lambda", "l", ":", "int", "(", "l", ".", "decode", "(", "\"utf-8\"", ")", ".", "split", "(", "\"|\"", ")", "[", "-", "1", "]", ")", ",", "lines", ")", ")", "\n", "self", ".", "speaker_ids", "=", "speaker_ids", "\n", "if", "self", ".", "speaker_id", "is", "not", "None", ":", "\n", "# Filter by speaker_id", "\n", "# using multi-speaker dataset as a single speaker dataset", "\n", "                ", "indices", "=", "np", ".", "array", "(", "speaker_ids", ")", "==", "self", ".", "speaker_id", "\n", "paths", "=", "list", "(", "np", ".", "array", "(", "paths", ")", "[", "indices", "]", ")", "\n", "self", ".", "lengths", "=", "list", "(", "np", ".", "array", "(", "self", ".", "lengths", ")", "[", "indices", "]", ")", "\n", "\n", "# Filter by train/tset", "\n", "indices", "=", "self", ".", "interest_indices", "(", "paths", ")", "\n", "paths", "=", "list", "(", "np", ".", "array", "(", "paths", ")", "[", "indices", "]", ")", "\n", "self", ".", "lengths", "=", "list", "(", "np", ".", "array", "(", "self", ".", "lengths", ")", "[", "indices", "]", ")", "\n", "\n", "# aha, need to cast numpy.int64 to int", "\n", "self", ".", "lengths", "=", "list", "(", "map", "(", "int", ",", "self", ".", "lengths", ")", ")", "\n", "self", ".", "multi_speaker", "=", "False", "\n", "\n", "return", "paths", "\n", "\n", "# Filter by train/test", "\n", "", "", "indices", "=", "self", ".", "interest_indices", "(", "paths", ")", "\n", "paths", "=", "list", "(", "np", ".", "array", "(", "paths", ")", "[", "indices", "]", ")", "\n", "lengths_np", "=", "list", "(", "np", ".", "array", "(", "self", ".", "lengths", ")", "[", "indices", "]", ")", "\n", "self", ".", "lengths", "=", "list", "(", "map", "(", "int", ",", "lengths_np", ")", ")", "\n", "\n", "if", "self", ".", "multi_speaker", ":", "\n", "            ", "speaker_ids_np", "=", "list", "(", "np", ".", "array", "(", "self", ".", "speaker_ids", ")", "[", "indices", "]", ")", "\n", "self", ".", "speaker_ids", "=", "list", "(", "map", "(", "int", ",", "speaker_ids_np", ")", ")", "\n", "assert", "len", "(", "paths", ")", "==", "len", "(", "self", ".", "speaker_ids", ")", "\n", "\n", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._NPYDataSource.collect_features": [[172, 174], ["numpy.load"], "methods", ["None"], ["", "def", "collect_features", "(", "self", ",", "path", ")", ":", "\n", "        ", "return", "np", ".", "load", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.RawAudioDataSource.__init__": [[177, 179], ["train._NPYDataSource.__init__"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "RawAudioDataSource", ",", "self", ")", ".", "__init__", "(", "data_root", ",", "0", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.MelSpecDataSource.__init__": [[182, 184], ["train._NPYDataSource.__init__"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__"], ["    ", "def", "__init__", "(", "self", ",", "data_root", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "MelSpecDataSource", ",", "self", ")", ".", "__init__", "(", "data_root", ",", "1", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.PartialyRandomizedSimilarTimeLengthSampler.__init__": [[194, 207], ["torch.sort", "torch.sort", "torch.sort", "torch.sort", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "min", "len"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "lengths", ",", "batch_size", "=", "16", ",", "batch_group_size", "=", "None", ",", "\n", "permutate", "=", "True", ")", ":", "\n", "        ", "self", ".", "lengths", ",", "self", ".", "sorted_indices", "=", "torch", ".", "sort", "(", "torch", ".", "LongTensor", "(", "lengths", ")", ")", "\n", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "if", "batch_group_size", "is", "None", ":", "\n", "            ", "batch_group_size", "=", "min", "(", "batch_size", "*", "32", ",", "len", "(", "self", ".", "lengths", ")", ")", "\n", "if", "batch_group_size", "%", "batch_size", "!=", "0", ":", "\n", "                ", "batch_group_size", "-=", "batch_group_size", "%", "batch_size", "\n", "\n", "", "", "self", ".", "batch_group_size", "=", "batch_group_size", "\n", "assert", "batch_group_size", "%", "batch_size", "==", "0", "\n", "self", ".", "permutate", "=", "permutate", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.PartialyRandomizedSimilarTimeLengthSampler.__iter__": [[208, 229], ["train.PartialyRandomizedSimilarTimeLengthSampler.sorted_indices.clone", "range", "iter", "random.shuffle", "numpy.arange", "random.shuffle", "[].view", "len", "random.shuffle", "len", "len", "indices[].view"], "methods", ["None"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "indices", "=", "self", ".", "sorted_indices", ".", "clone", "(", ")", "\n", "batch_group_size", "=", "self", ".", "batch_group_size", "\n", "s", ",", "e", "=", "0", ",", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "indices", ")", "//", "batch_group_size", ")", ":", "\n", "            ", "s", "=", "i", "*", "batch_group_size", "\n", "e", "=", "s", "+", "batch_group_size", "\n", "random", ".", "shuffle", "(", "indices", "[", "s", ":", "e", "]", ")", "\n", "\n", "# Permutate batches", "\n", "", "if", "self", ".", "permutate", ":", "\n", "            ", "perm", "=", "np", ".", "arange", "(", "len", "(", "indices", "[", ":", "e", "]", ")", "//", "self", ".", "batch_size", ")", "\n", "random", ".", "shuffle", "(", "perm", ")", "\n", "indices", "[", ":", "e", "]", "=", "indices", "[", ":", "e", "]", ".", "view", "(", "-", "1", ",", "self", ".", "batch_size", ")", "[", "perm", ",", ":", "]", ".", "view", "(", "-", "1", ")", "\n", "\n", "# Handle last elements", "\n", "", "s", "+=", "batch_group_size", "\n", "if", "s", "<", "len", "(", "indices", ")", ":", "\n", "            ", "random", ".", "shuffle", "(", "indices", "[", "s", ":", "]", ")", "\n", "\n", "", "return", "iter", "(", "indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.PartialyRandomizedSimilarTimeLengthSampler.__len__": [[230, 232], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sorted_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.PyTorchDataset.__init__": [[235, 240], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "X", ",", "Mel", ")", ":", "\n", "        ", "self", ".", "X", "=", "X", "\n", "self", ".", "Mel", "=", "Mel", "\n", "# alias", "\n", "self", ".", "multi_speaker", "=", "X", ".", "file_data_source", ".", "multi_speaker", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.PyTorchDataset.__getitem__": [[241, 255], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "        ", "if", "self", ".", "Mel", "is", "None", ":", "\n", "            ", "mel", "=", "None", "\n", "", "else", ":", "\n", "            ", "mel", "=", "self", ".", "Mel", "[", "idx", "]", "\n", "\n", "", "raw_audio", "=", "self", ".", "X", "[", "idx", "]", "\n", "if", "self", ".", "multi_speaker", ":", "\n", "            ", "speaker_id", "=", "self", ".", "X", ".", "file_data_source", ".", "speaker_ids", "[", "idx", "]", "\n", "", "else", ":", "\n", "            ", "speaker_id", "=", "None", "\n", "\n", "# (x,c,g)", "\n", "", "return", "raw_audio", ",", "mel", ",", "speaker_id", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.PyTorchDataset.__len__": [[256, 258], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "X", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ExponentialMovingAverage.__init__": [[276, 279], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "decay", ")", ":", "\n", "        ", "self", ".", "decay", "=", "decay", "\n", "self", ".", "shadow", "=", "{", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ExponentialMovingAverage.register": [[280, 282], ["val.clone"], "methods", ["None"], ["", "def", "register", "(", "self", ",", "name", ",", "val", ")", ":", "\n", "        ", "self", ".", "shadow", "[", "name", "]", "=", "val", ".", "clone", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ExponentialMovingAverage.update": [[283, 287], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "name", ",", "x", ")", ":", "\n", "        ", "assert", "name", "in", "self", ".", "shadow", "\n", "update_delta", "=", "self", ".", "shadow", "[", "name", "]", "-", "x", "\n", "self", ".", "shadow", "[", "name", "]", "-=", "(", "1.0", "-", "self", ".", "decay", ")", "*", "update_delta", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.MaskedCrossEntropyLoss.__init__": [[300, 303], ["torch.nn.Module.__init__", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "MaskedCrossEntropyLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduce", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.MaskedCrossEntropyLoss.forward": [[304, 316], ["sequence_mask().unsqueeze.expand_as", "train.MaskedCrossEntropyLoss.criterion", "RuntimeError", "sequence_mask().unsqueeze", "sequence_mask().unsqueeze.expand_as.sum", "train.sequence_mask"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.sequence_mask"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "lengths", "=", "None", ",", "mask", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "if", "lengths", "is", "None", "and", "mask", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Should provide either lengths or mask\"", ")", "\n", "\n", "# (B, T, 1)", "\n", "", "if", "mask", "is", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "lengths", ",", "max_len", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# (B, T, D)", "\n", "", "mask_", "=", "mask", ".", "expand_as", "(", "target", ")", "\n", "losses", "=", "self", ".", "criterion", "(", "input", ",", "target", ")", "\n", "return", "(", "(", "losses", "*", "mask_", ")", ".", "sum", "(", ")", ")", "/", "mask_", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.DiscretizedMixturelogisticLoss.__init__": [[319, 321], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "DiscretizedMixturelogisticLoss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.DiscretizedMixturelogisticLoss.forward": [[322, 338], ["sequence_mask().unsqueeze.expand_as", "wavenet_vocoder.mixture.discretized_mix_logistic_loss", "RuntimeError", "sequence_mask().unsqueeze", "wavenet_vocoder.mixture.discretized_mix_logistic_loss.size", "target.size", "sequence_mask().unsqueeze.expand_as.sum", "train.sequence_mask"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.discretized_mix_logistic_loss", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.sequence_mask"], ["", "def", "forward", "(", "self", ",", "input", ",", "target", ",", "lengths", "=", "None", ",", "mask", "=", "None", ",", "max_len", "=", "None", ")", ":", "\n", "        ", "if", "lengths", "is", "None", "and", "mask", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"Should provide either lengths or mask\"", ")", "\n", "\n", "# (B, T, 1)", "\n", "", "if", "mask", "is", "None", ":", "\n", "            ", "mask", "=", "sequence_mask", "(", "lengths", ",", "max_len", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# (B, T, 1)", "\n", "", "mask_", "=", "mask", ".", "expand_as", "(", "target", ")", "\n", "\n", "losses", "=", "discretized_mix_logistic_loss", "(", "\n", "input", ",", "target", ",", "num_classes", "=", "hparams", ".", "quantize_channels", ",", "\n", "log_scale_min", "=", "hparams", ".", "log_scale_min", ",", "reduce", "=", "False", ")", "\n", "assert", "losses", ".", "size", "(", ")", "==", "target", ".", "size", "(", ")", "\n", "return", "(", "(", "losses", "*", "mask_", ")", ".", "sum", "(", ")", ")", "/", "mask_", ".", "sum", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.sanity_check": [[72, 88], ["model.has_speaker_embedding", "model.local_conditioning_enabled", "RuntimeError", "RuntimeError", "RuntimeError", "RuntimeError"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.has_speaker_embedding", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.local_conditioning_enabled"], ["", "def", "sanity_check", "(", "model", ",", "c", ",", "g", ")", ":", "\n", "    ", "if", "model", ".", "has_speaker_embedding", "(", ")", ":", "\n", "        ", "if", "g", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"WaveNet expects speaker embedding, but speaker-id is not provided\"", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "g", "is", "not", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"WaveNet expects no speaker embedding, but speaker-id is provided\"", ")", "\n", "\n", "", "", "if", "model", ".", "local_conditioning_enabled", "(", ")", ":", "\n", "        ", "if", "c", "is", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"WaveNet expects conditional features, but not given\"", ")", "\n", "", "", "else", ":", "\n", "        ", "if", "c", "is", "not", "None", ":", "\n", "            ", "raise", "RuntimeError", "(", "\"WaveNet expects no conditional features, but given\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._pad": [[90, 93], ["numpy.pad", "len"], "function", ["None"], ["", "", "", "def", "_pad", "(", "seq", ",", "max_len", ",", "constant_values", "=", "0", ")", ":", "\n", "    ", "return", "np", ".", "pad", "(", "seq", ",", "(", "0", ",", "max_len", "-", "len", "(", "seq", ")", ")", ",", "\n", "mode", "=", "'constant'", ",", "constant_values", "=", "constant_values", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._pad_2d": [[95, 99], ["numpy.pad", "len"], "function", ["None"], ["", "def", "_pad_2d", "(", "x", ",", "max_len", ",", "b_pad", "=", "0", ")", ":", "\n", "    ", "x", "=", "np", ".", "pad", "(", "x", ",", "[", "(", "b_pad", ",", "max_len", "-", "len", "(", "x", ")", "-", "b_pad", ")", ",", "(", "0", ",", "0", ")", "]", ",", "\n", "mode", "=", "\"constant\"", ",", "constant_values", "=", "0", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.sequence_mask": [[260, 271], ["sequence_length.size", "torch.arange().long", "torch.arange().long", "torch.arange().long.unsqueeze().expand", "sequence_length.unsqueeze().expand_as", "sequence_length.data.max", "seq_range_expand.cuda.cuda", "torch.arange", "torch.arange", "torch.arange().long.unsqueeze", "sequence_length.unsqueeze"], "function", ["None"], ["", "", "def", "sequence_mask", "(", "sequence_length", ",", "max_len", "=", "None", ")", ":", "\n", "    ", "if", "max_len", "is", "None", ":", "\n", "        ", "max_len", "=", "sequence_length", ".", "data", ".", "max", "(", ")", "\n", "", "batch_size", "=", "sequence_length", ".", "size", "(", "0", ")", "\n", "seq_range", "=", "torch", ".", "arange", "(", "0", ",", "max_len", ")", ".", "long", "(", ")", "\n", "seq_range_expand", "=", "seq_range", ".", "unsqueeze", "(", "0", ")", ".", "expand", "(", "batch_size", ",", "max_len", ")", "\n", "if", "sequence_length", ".", "is_cuda", ":", "\n", "        ", "seq_range_expand", "=", "seq_range_expand", ".", "cuda", "(", ")", "\n", "", "seq_length_expand", "=", "sequence_length", ".", "unsqueeze", "(", "1", ")", ".", "expand_as", "(", "seq_range_expand", ")", "\n", "return", "(", "seq_range_expand", "<", "seq_length_expand", ")", ".", "float", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.clone_as_averaged_model": [[289, 297], ["build_model().to", "build_model().to.load_state_dict", "build_model().to.named_parameters", "model.state_dict", "train.build_model", "ema.shadow[].clone"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.build_model"], ["", "", "def", "clone_as_averaged_model", "(", "device", ",", "model", ",", "ema", ")", ":", "\n", "    ", "assert", "ema", "is", "not", "None", "\n", "averaged_model", "=", "build_model", "(", ")", ".", "to", "(", "device", ")", "\n", "averaged_model", ".", "load_state_dict", "(", "model", ".", "state_dict", "(", ")", ")", "\n", "for", "name", ",", "param", "in", "averaged_model", ".", "named_parameters", "(", ")", ":", "\n", "        ", "if", "name", "in", "ema", ".", "shadow", ":", "\n", "            ", "param", ".", "data", "=", "ema", ".", "shadow", "[", "name", "]", ".", "clone", "(", ")", "\n", "", "", "return", "averaged_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ensure_divisible": [[340, 347], ["None"], "function", ["None"], ["", "", "def", "ensure_divisible", "(", "length", ",", "divisible_by", "=", "256", ",", "lower", "=", "True", ")", ":", "\n", "    ", "if", "length", "%", "divisible_by", "==", "0", ":", "\n", "        ", "return", "length", "\n", "", "if", "lower", ":", "\n", "        ", "return", "length", "-", "length", "%", "divisible_by", "\n", "", "else", ":", "\n", "        ", "return", "length", "+", "(", "divisible_by", "-", "length", "%", "divisible_by", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.assert_ready_for_upsampling": [[349, 351], ["audio.get_hop_size", "len", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size"], ["", "", "def", "assert_ready_for_upsampling", "(", "x", ",", "c", ")", ":", "\n", "    ", "assert", "len", "(", "x", ")", "%", "len", "(", "c", ")", "==", "0", "and", "len", "(", "x", ")", "//", "len", "(", "c", ")", "==", "audio", ".", "get_hop_size", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.collate_fn": [[353, 464], ["max", "wavenet_vocoder.util.is_mulaw_quantize", "wavenet_vocoder.util.is_mulaw_quantize", "torch.FloatTensor().transpose().contiguous", "torch.FloatTensor().transpose().contiguous", "wavenet_vocoder.util.is_mulaw_quantize", "torch.LongTensor", "torch.LongTensor", "int", "range", "range", "len", "numpy.array", "numpy.array", "len", "numpy.array", "numpy.array", "len", "max", "numpy.array", "torch.FloatTensor().transpose().contiguous", "torch.FloatTensor().transpose().contiguous", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor().unsqueeze().contiguous", "torch.LongTensor().unsqueeze().contiguous", "torch.FloatTensor().unsqueeze().contiguous", "torch.FloatTensor().unsqueeze().contiguous", "len", "len", "len", "new_batch.append", "len", "audio.trim", "new_batch.append", "len", "torch.FloatTensor().transpose", "torch.FloatTensor().transpose", "train.assert_ready_for_upsampling", "audio.adjust_time_resolution", "numpy.random.randint", "train._pad_2d", "train._pad_2d", "train._pad", "train._pad", "len", "train._pad_2d", "torch.FloatTensor().transpose", "torch.FloatTensor().transpose", "torch.LongTensor().unsqueeze", "torch.LongTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "torch.FloatTensor().unsqueeze", "train.ensure_divisible", "numpy.random.randint", "len", "len", "len", "keras.utils.np_utils.to_categorical", "x[].reshape", "torch.FloatTensor", "torch.FloatTensor", "audio.get_hop_size", "len", "numpy.random.randint", "train.assert_ready_for_upsampling", "len", "len", "torch.FloatTensor", "torch.FloatTensor", "torch.LongTensor", "torch.LongTensor", "torch.FloatTensor", "torch.FloatTensor", "audio.get_hop_size", "audio.get_hop_size", "len", "len", "audio.get_hop_size"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.trim", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.assert_ready_for_upsampling", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.adjust_time_resolution", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._pad_2d", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._pad_2d", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._pad", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._pad", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._pad_2d", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ensure_divisible", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.assert_ready_for_upsampling", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size"], ["", "def", "collate_fn", "(", "batch", ")", ":", "\n", "    ", "\"\"\"Create batch\n\n    Args:\n        batch(tuple): List of tuples\n            - x[0] (ndarray,int) : list of (T,)\n            - x[1] (ndarray,int) : list of (T, D)\n            - x[2] (ndarray,int) : list of (1,), speaker id\n    Returns:\n        tuple: Tuple of batch\n            - x (FloatTensor) : Network inputs (B, C, T)\n            - y (LongTensor)  : Network targets (B, T, 1)\n    \"\"\"", "\n", "\n", "local_conditioning", "=", "len", "(", "batch", "[", "0", "]", ")", ">=", "2", "and", "hparams", ".", "cin_channels", ">", "0", "\n", "global_conditioning", "=", "len", "(", "batch", "[", "0", "]", ")", ">=", "3", "and", "hparams", ".", "gin_channels", ">", "0", "\n", "\n", "if", "hparams", ".", "max_time_sec", "is", "not", "None", ":", "\n", "        ", "max_time_steps", "=", "int", "(", "hparams", ".", "max_time_sec", "*", "hparams", ".", "sample_rate", ")", "\n", "", "elif", "hparams", ".", "max_time_steps", "is", "not", "None", ":", "\n", "        ", "max_time_steps", "=", "hparams", ".", "max_time_steps", "\n", "", "else", ":", "\n", "        ", "max_time_steps", "=", "None", "\n", "\n", "# Time resolution adjustment", "\n", "", "if", "local_conditioning", ":", "\n", "        ", "new_batch", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "batch", ")", ")", ":", "\n", "            ", "x", ",", "c", ",", "g", "=", "batch", "[", "idx", "]", "\n", "if", "hparams", ".", "upsample_conditional_features", ":", "\n", "                ", "assert_ready_for_upsampling", "(", "x", ",", "c", ")", "\n", "if", "max_time_steps", "is", "not", "None", ":", "\n", "                    ", "max_steps", "=", "ensure_divisible", "(", "max_time_steps", ",", "audio", ".", "get_hop_size", "(", ")", ",", "True", ")", "\n", "if", "len", "(", "x", ")", ">", "max_steps", ":", "\n", "                        ", "max_time_frames", "=", "max_steps", "//", "audio", ".", "get_hop_size", "(", ")", "\n", "s", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "c", ")", "-", "max_time_frames", ")", "\n", "#print(\"Size of file=%6d, t_offset=%6d\"  % (len(c), s,))", "\n", "ts", "=", "s", "*", "audio", ".", "get_hop_size", "(", ")", "\n", "x", "=", "x", "[", "ts", ":", "ts", "+", "audio", ".", "get_hop_size", "(", ")", "*", "max_time_frames", "]", "\n", "c", "=", "c", "[", "s", ":", "s", "+", "max_time_frames", ",", ":", "]", "\n", "assert_ready_for_upsampling", "(", "x", ",", "c", ")", "\n", "", "", "", "else", ":", "\n", "                ", "x", ",", "c", "=", "audio", ".", "adjust_time_resolution", "(", "x", ",", "c", ")", "\n", "if", "max_time_steps", "is", "not", "None", "and", "len", "(", "x", ")", ">", "max_time_steps", ":", "\n", "                    ", "s", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "x", ")", "-", "max_time_steps", ")", "\n", "x", ",", "c", "=", "x", "[", "s", ":", "s", "+", "max_time_steps", "]", ",", "c", "[", "s", ":", "s", "+", "max_time_steps", ",", ":", "]", "\n", "", "assert", "len", "(", "x", ")", "==", "len", "(", "c", ")", "\n", "", "new_batch", ".", "append", "(", "(", "x", ",", "c", ",", "g", ")", ")", "\n", "", "batch", "=", "new_batch", "\n", "", "else", ":", "\n", "        ", "new_batch", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "batch", ")", ")", ":", "\n", "            ", "x", ",", "c", ",", "g", "=", "batch", "[", "idx", "]", "\n", "x", "=", "audio", ".", "trim", "(", "x", ")", "\n", "if", "max_time_steps", "is", "not", "None", "and", "len", "(", "x", ")", ">", "max_time_steps", ":", "\n", "                ", "s", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "x", ")", "-", "max_time_steps", ")", "\n", "if", "local_conditioning", ":", "\n", "                    ", "x", ",", "c", "=", "x", "[", "s", ":", "s", "+", "max_time_steps", "]", ",", "c", "[", "s", ":", "s", "+", "max_time_steps", ",", ":", "]", "\n", "", "else", ":", "\n", "                    ", "x", "=", "x", "[", "s", ":", "s", "+", "max_time_steps", "]", "\n", "", "", "new_batch", ".", "append", "(", "(", "x", ",", "c", ",", "g", ")", ")", "\n", "", "batch", "=", "new_batch", "\n", "\n", "# Lengths", "\n", "", "input_lengths", "=", "[", "len", "(", "x", "[", "0", "]", ")", "for", "x", "in", "batch", "]", "\n", "max_input_len", "=", "max", "(", "input_lengths", ")", "\n", "\n", "# (B, T, C)", "\n", "# pad for time-axis", "\n", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "x_batch", "=", "np", ".", "array", "(", "[", "_pad_2d", "(", "np_utils", ".", "to_categorical", "(", "\n", "x", "[", "0", "]", ",", "num_classes", "=", "hparams", ".", "quantize_channels", ")", ",", "\n", "max_input_len", ")", "for", "x", "in", "batch", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "x_batch", "=", "np", ".", "array", "(", "[", "_pad_2d", "(", "x", "[", "0", "]", ".", "reshape", "(", "-", "1", ",", "1", ")", ",", "max_input_len", ")", "\n", "for", "x", "in", "batch", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "assert", "len", "(", "x_batch", ".", "shape", ")", "==", "3", "\n", "\n", "# (B, T)", "\n", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "y_batch", "=", "np", ".", "array", "(", "[", "_pad", "(", "x", "[", "0", "]", ",", "max_input_len", ")", "for", "x", "in", "batch", "]", ",", "dtype", "=", "np", ".", "int", ")", "\n", "", "else", ":", "\n", "        ", "y_batch", "=", "np", ".", "array", "(", "[", "_pad", "(", "x", "[", "0", "]", ",", "max_input_len", ")", "for", "x", "in", "batch", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "", "assert", "len", "(", "y_batch", ".", "shape", ")", "==", "2", "\n", "\n", "# (B, T, D)", "\n", "if", "local_conditioning", ":", "\n", "        ", "max_len", "=", "max", "(", "[", "len", "(", "x", "[", "1", "]", ")", "for", "x", "in", "batch", "]", ")", "\n", "c_batch", "=", "np", ".", "array", "(", "[", "_pad_2d", "(", "x", "[", "1", "]", ",", "max_len", ")", "for", "x", "in", "batch", "]", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "assert", "len", "(", "c_batch", ".", "shape", ")", "==", "3", "\n", "# (B x C x T)", "\n", "c_batch", "=", "torch", ".", "FloatTensor", "(", "c_batch", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "        ", "c_batch", "=", "None", "\n", "\n", "", "if", "global_conditioning", ":", "\n", "        ", "g_batch", "=", "torch", ".", "LongTensor", "(", "[", "x", "[", "2", "]", "for", "x", "in", "batch", "]", ")", "\n", "", "else", ":", "\n", "        ", "g_batch", "=", "None", "\n", "\n", "# Covnert to channel first i.e., (B, C, T)", "\n", "", "x_batch", "=", "torch", ".", "FloatTensor", "(", "x_batch", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "# Add extra axis", "\n", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "y_batch", "=", "torch", ".", "LongTensor", "(", "y_batch", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "        ", "y_batch", "=", "torch", ".", "FloatTensor", "(", "y_batch", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "input_lengths", "=", "torch", ".", "LongTensor", "(", "input_lengths", ")", "\n", "\n", "return", "x_batch", ",", "y_batch", ",", "c_batch", ",", "g_batch", ",", "input_lengths", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.time_string": [[466, 468], ["datetime.datetime.now().strftime", "datetime.datetime.now"], "function", ["None"], ["", "def", "time_string", "(", ")", ":", "\n", "    ", "return", "datetime", ".", "now", "(", ")", ".", "strftime", "(", "'%Y-%m-%d %H:%M'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.save_waveplot": [[470, 481], ["matplotlib.figure", "matplotlib.subplot", "librosa.display.waveplot", "matplotlib.subplot", "librosa.display.waveplot", "matplotlib.tight_layout", "matplotlib.savefig", "matplotlib.close"], "function", ["None"], ["", "def", "save_waveplot", "(", "path", ",", "y_hat", ",", "y_target", ")", ":", "\n", "    ", "sr", "=", "hparams", ".", "sample_rate", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "16", ",", "6", ")", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "1", ")", "\n", "librosa", ".", "display", ".", "waveplot", "(", "y_target", ",", "sr", "=", "sr", ")", "\n", "plt", ".", "subplot", "(", "2", ",", "1", ",", "2", ")", "\n", "librosa", ".", "display", ".", "waveplot", "(", "y_hat", ",", "sr", "=", "sr", ")", "\n", "plt", ".", "tight_layout", "(", ")", "\n", "plt", ".", "savefig", "(", "path", ",", "format", "=", "\"png\"", ")", "\n", "plt", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.eval_model": [[483, 550], ["clone_as_averaged_model.eval", "numpy.random.randint", "input_lengths[].data.cpu().item", "wavenet_vocoder.util.is_mulaw_quantize", "print", "wavenet_vocoder.util.is_mulaw_quantize", "torch.zeros().fill_.to", "wavenet_vocoder.util.is_mulaw_quantize", "os.makedirs", "os.path.join", "librosa.output.write_wav", "os.path.join", "librosa.output.write_wav", "os.path.join", "train.save_waveplot", "print", "train.clone_as_averaged_model", "clone_as_averaged_model.make_generation_fast_", "len", "y[].view().data.cpu().numpy", "c[].unsqueeze", "print", "print", "nnmnkwii.preprocessing.mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "keras.utils.np_utils.to_categorical().astype", "torch.from_numpy().view", "torch.from_numpy().view", "torch.zeros().fill_", "torch.zeros().fill_", "torch.no_grad", "torch.no_grad", "clone_as_averaged_model.incremental_forward", "[].view().long().cpu().data.numpy", "nnmnkwii.preprocessing.inv_mulaw_quantize", "nnmnkwii.preprocessing.inv_mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "input_lengths[].data.cpu", "c[].unsqueeze.dim", "nnmnkwii.preprocessing.mulaw", "nnmnkwii.preprocessing.inv_mulaw", "nnmnkwii.preprocessing.inv_mulaw", "y_hat.view().cpu().data.numpy.view().cpu().data.numpy", "y[].view().data.cpu", "c[].unsqueeze.size", "g.size", "keras.utils.np_utils.to_categorical", "torch.from_numpy", "torch.from_numpy", "torch.zeros", "torch.zeros", "y_hat.view().cpu().data.numpy.view().cpu().data.numpy", "[].view().long().cpu", "y_hat.view().cpu().data.numpy.view().cpu", "y[].view", "[].view().long", "y_hat.view().cpu().data.numpy.view().cpu", "y_hat.view().cpu().data.numpy.view", "[].view", "y_hat.view().cpu().data.numpy.view", "y_hat.view().cpu().data.numpy.max"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.save_waveplot", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.clone_as_averaged_model", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.make_generation_fast_", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical"], ["", "def", "eval_model", "(", "global_step", ",", "writer", ",", "device", ",", "model", ",", "y", ",", "c", ",", "g", ",", "input_lengths", ",", "eval_dir", ",", "ema", "=", "None", ")", ":", "\n", "    ", "if", "ema", "is", "not", "None", ":", "\n", "        ", "print", "(", "\"Using averaged model for evaluation\"", ")", "\n", "model", "=", "clone_as_averaged_model", "(", "device", ",", "model", ",", "ema", ")", "\n", "model", ".", "make_generation_fast_", "(", ")", "\n", "\n", "", "model", ".", "eval", "(", ")", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "y", ")", ")", "\n", "length", "=", "input_lengths", "[", "idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "\n", "# (T,)", "\n", "y_target", "=", "y", "[", "idx", "]", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "[", ":", "length", "]", "\n", "\n", "if", "c", "is", "not", "None", ":", "\n", "        ", "c", "=", "c", "[", "idx", ",", ":", ",", ":", "length", "]", ".", "unsqueeze", "(", "0", ")", "\n", "assert", "c", ".", "dim", "(", ")", "==", "3", "\n", "print", "(", "\"Shape of local conditioning features: {}\"", ".", "format", "(", "c", ".", "size", "(", ")", ")", ")", "\n", "", "if", "g", "is", "not", "None", ":", "\n", "# TODO: test", "\n", "        ", "g", "=", "g", "[", "idx", "]", "\n", "print", "(", "\"Shape of global conditioning features: {}\"", ".", "format", "(", "g", ".", "size", "(", ")", ")", ")", "\n", "\n", "# Dummy silence", "\n", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "initial_value", "=", "P", ".", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "initial_value", "=", "P", ".", "mulaw", "(", "0.0", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "else", ":", "\n", "        ", "initial_value", "=", "0.0", "\n", "", "print", "(", "\"Intial value:\"", ",", "initial_value", ")", "\n", "\n", "# (C,)", "\n", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "initial_input", "=", "np_utils", ".", "to_categorical", "(", "\n", "initial_value", ",", "num_classes", "=", "hparams", ".", "quantize_channels", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "initial_input", "=", "torch", ".", "from_numpy", "(", "initial_input", ")", ".", "view", "(", "\n", "1", ",", "1", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "else", ":", "\n", "        ", "initial_input", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ")", ".", "fill_", "(", "initial_value", ")", "\n", "", "initial_input", "=", "initial_input", ".", "to", "(", "device", ")", "\n", "\n", "# Run the model in fast eval mode", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y_hat", "=", "model", ".", "incremental_forward", "(", "\n", "initial_input", ",", "c", "=", "c", ",", "g", "=", "g", ",", "T", "=", "length", ",", "softmax", "=", "True", ",", "quantize", "=", "True", ",", "tqdm", "=", "tqdm", ",", "\n", "log_scale_min", "=", "hparams", ".", "log_scale_min", ")", "\n", "\n", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "y_hat", "=", "y_hat", ".", "max", "(", "1", ")", "[", "1", "]", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "y_hat", "=", "P", ".", "inv_mulaw_quantize", "(", "y_hat", ",", "hparams", ".", "quantize_channels", ")", "\n", "y_target", "=", "P", ".", "inv_mulaw_quantize", "(", "y_target", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "y_hat", "=", "P", ".", "inv_mulaw", "(", "y_hat", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "hparams", ".", "quantize_channels", ")", "\n", "y_target", "=", "P", ".", "inv_mulaw", "(", "y_target", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "else", ":", "\n", "        ", "y_hat", "=", "y_hat", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "# Save audio", "\n", "", "os", ".", "makedirs", "(", "eval_dir", ",", "exist_ok", "=", "True", ")", "\n", "path", "=", "join", "(", "eval_dir", ",", "\"step{:09d}_predicted.wav\"", ".", "format", "(", "global_step", ")", ")", "\n", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "y_hat", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "path", "=", "join", "(", "eval_dir", ",", "\"step{:09d}_target.wav\"", ".", "format", "(", "global_step", ")", ")", "\n", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "y_target", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "\n", "# save figure", "\n", "path", "=", "join", "(", "eval_dir", ",", "\"step{:09d}_waveplots.png\"", ".", "format", "(", "global_step", ")", ")", "\n", "save_waveplot", "(", "path", ",", "y_hat", ",", "y_target", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.save_states": [[552, 594], ["print", "numpy.random.randint", "input_lengths[].data.cpu().item", "wavenet_vocoder.util.is_mulaw_quantize", "os.path.join", "os.makedirs", "os.path.join", "librosa.output.write_wav", "os.path.join", "librosa.output.write_wav", "len", "P.inv_mulaw.dim", "P.inv_mulaw.squeeze", "y_hat[].data.cpu().long().numpy", "y[].view().data.cpu().long().numpy", "nnmnkwii.preprocessing.inv_mulaw_quantize", "nnmnkwii.preprocessing.inv_mulaw_quantize", "wavenet_vocoder.mixture.sample_from_discretized_mix_logistic", "y_hat[].view().data.cpu().numpy", "y[].view().data.cpu().numpy", "wavenet_vocoder.util.is_mulaw", "input_lengths[].data.cpu", "torch.nn.functional.softmax().max", "nnmnkwii.preprocessing.inv_mulaw", "nnmnkwii.preprocessing.inv_mulaw", "y_hat[].data.cpu().long", "y[].view().data.cpu().long", "y_hat[].view().data.cpu", "y[].view().data.cpu", "torch.nn.functional.softmax", "y_hat[].data.cpu", "y[].view().data.cpu", "y_hat[].view", "y[].view", "y[].view"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.sample_from_discretized_mix_logistic", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw"], ["", "def", "save_states", "(", "global_step", ",", "writer", ",", "y_hat", ",", "y", ",", "input_lengths", ",", "checkpoint_dir", "=", "None", ")", ":", "\n", "    ", "print", "(", "\"Save intermediate states at step {}\"", ".", "format", "(", "global_step", ")", ")", "\n", "idx", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "len", "(", "y_hat", ")", ")", "\n", "length", "=", "input_lengths", "[", "idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "item", "(", ")", "\n", "\n", "# (B, C, T)", "\n", "if", "y_hat", ".", "dim", "(", ")", "==", "4", ":", "\n", "        ", "y_hat", "=", "y_hat", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "# (B, T)", "\n", "        ", "y_hat", "=", "F", ".", "softmax", "(", "y_hat", ",", "dim", "=", "1", ")", ".", "max", "(", "1", ")", "[", "1", "]", "\n", "\n", "# (T,)", "\n", "y_hat", "=", "y_hat", "[", "idx", "]", ".", "data", ".", "cpu", "(", ")", ".", "long", "(", ")", ".", "numpy", "(", ")", "\n", "y", "=", "y", "[", "idx", "]", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "long", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "y_hat", "=", "P", ".", "inv_mulaw_quantize", "(", "y_hat", ",", "hparams", ".", "quantize_channels", ")", "\n", "y", "=", "P", ".", "inv_mulaw_quantize", "(", "y", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "else", ":", "\n", "# (B, T)", "\n", "        ", "y_hat", "=", "sample_from_discretized_mix_logistic", "(", "\n", "y_hat", ",", "log_scale_min", "=", "hparams", ".", "log_scale_min", ")", "\n", "# (T,)", "\n", "y_hat", "=", "y_hat", "[", "idx", "]", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y", "=", "y", "[", "idx", "]", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "\n", "if", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "            ", "y_hat", "=", "P", ".", "inv_mulaw", "(", "y_hat", ",", "hparams", ".", "quantize_channels", ")", "\n", "y", "=", "P", ".", "inv_mulaw", "(", "y", ",", "hparams", ".", "quantize_channels", ")", "\n", "\n", "# Mask by length", "\n", "", "", "y_hat", "[", "length", ":", "]", "=", "0", "\n", "y", "[", "length", ":", "]", "=", "0", "\n", "\n", "# Save audio", "\n", "audio_dir", "=", "join", "(", "checkpoint_dir", ",", "\"audio\"", ")", "\n", "os", ".", "makedirs", "(", "audio_dir", ",", "exist_ok", "=", "True", ")", "\n", "path", "=", "join", "(", "audio_dir", ",", "\"step{:09d}_predicted.wav\"", ".", "format", "(", "global_step", ")", ")", "\n", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "y_hat", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "path", "=", "join", "(", "audio_dir", ",", "\"step{:09d}_target.wav\"", ".", "format", "(", "global_step", ")", ")", "\n", "librosa", ".", "output", ".", "write_wav", "(", "path", ",", "y", ",", "sr", "=", "hparams", ".", "sample_rate", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.__train_step": [[596, 679], ["train.sanity_check", "optimizer.zero_grad", "input_lengths.to.to", "sequence_mask().unsqueeze", "torch.nn.parallel.data_parallel", "torch.nn.parallel.data_parallel", "wavenet_vocoder.util.is_mulaw_quantize", "writer.add_scalar", "criterion.item", "model.train", "model.eval", "getattr", "getattr.", "x.to", "y.to", "c.to", "g.to", "y_hat.unsqueeze.unsqueeze", "criterion", "criterion", "train.save_states", "train.save_checkpoint", "train.eval_model", "criterion.backward", "optimizer.step", "float", "writer.add_scalar", "train.sequence_mask", "torch.nn.utils.clip_grad_norm_", "torch.nn.utils.clip_grad_norm_", "model.named_parameters", "criterion.item", "writer.add_scalar", "model.parameters", "x.size", "ema.update"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.sanity_check", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.save_states", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.save_checkpoint", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.eval_model", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.sequence_mask", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ExponentialMovingAverage.update"], ["", "def", "__train_step", "(", "device", ",", "phase", ",", "epoch", ",", "global_step", ",", "global_test_step", ",", "\n", "model", ",", "optimizer", ",", "writer", ",", "criterion", ",", "\n", "x", ",", "y", ",", "c", ",", "g", ",", "input_lengths", ",", "\n", "checkpoint_dir", ",", "eval_dir", "=", "None", ",", "do_eval", "=", "False", ",", "ema", "=", "None", ")", ":", "\n", "    ", "sanity_check", "(", "model", ",", "c", ",", "g", ")", "\n", "\n", "# x : (B, C, T)", "\n", "# y : (B, T, 1)", "\n", "# c : (B, C, T)", "\n", "# g : (B,)", "\n", "train", "=", "(", "phase", "==", "\"train\"", ")", "\n", "clip_thresh", "=", "hparams", ".", "clip_thresh", "\n", "if", "train", ":", "\n", "        ", "model", ".", "train", "(", ")", "\n", "step", "=", "global_step", "\n", "", "else", ":", "\n", "        ", "model", ".", "eval", "(", ")", "\n", "step", "=", "global_test_step", "\n", "\n", "# Learning rate schedule", "\n", "", "current_lr", "=", "hparams", ".", "initial_learning_rate", "\n", "if", "train", "and", "hparams", ".", "lr_schedule", "is", "not", "None", ":", "\n", "        ", "lr_schedule_f", "=", "getattr", "(", "lrschedule", ",", "hparams", ".", "lr_schedule", ")", "\n", "current_lr", "=", "lr_schedule_f", "(", "\n", "hparams", ".", "initial_learning_rate", ",", "step", ",", "**", "hparams", ".", "lr_schedule_kwargs", ")", "\n", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "            ", "param_group", "[", "'lr'", "]", "=", "current_lr", "\n", "", "", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# Prepare data", "\n", "x", ",", "y", "=", "x", ".", "to", "(", "device", ")", ",", "y", ".", "to", "(", "device", ")", "\n", "input_lengths", "=", "input_lengths", ".", "to", "(", "device", ")", "\n", "c", "=", "c", ".", "to", "(", "device", ")", "if", "c", "is", "not", "None", "else", "None", "\n", "g", "=", "g", ".", "to", "(", "device", ")", "if", "g", "is", "not", "None", "else", "None", "\n", "\n", "# (B, T, 1)", "\n", "mask", "=", "sequence_mask", "(", "input_lengths", ",", "max_len", "=", "x", ".", "size", "(", "-", "1", ")", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "mask", "=", "mask", "[", ":", ",", "1", ":", ",", ":", "]", "\n", "\n", "# Apply model: Run the model in regular eval mode", "\n", "# NOTE: softmax is handled in F.cross_entrypy_loss", "\n", "# y_hat: (B x C x T)", "\n", "\n", "# multi gpu support", "\n", "# you must make sure that batch size % num gpu == 0", "\n", "y_hat", "=", "torch", ".", "nn", ".", "parallel", ".", "data_parallel", "(", "model", ",", "(", "x", ",", "c", ",", "g", ",", "False", ")", ")", "\n", "\n", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "# wee need 4d inputs for spatial cross entropy loss", "\n", "# (B, C, T, 1)", "\n", "        ", "y_hat", "=", "y_hat", ".", "unsqueeze", "(", "-", "1", ")", "\n", "loss", "=", "criterion", "(", "y_hat", "[", ":", ",", ":", ",", ":", "-", "1", ",", ":", "]", ",", "y", "[", ":", ",", "1", ":", ",", ":", "]", ",", "mask", "=", "mask", ")", "\n", "", "else", ":", "\n", "        ", "loss", "=", "criterion", "(", "y_hat", "[", ":", ",", ":", ",", ":", "-", "1", "]", ",", "y", "[", ":", ",", "1", ":", ",", ":", "]", ",", "mask", "=", "mask", ")", "\n", "\n", "", "if", "train", "and", "step", ">", "0", "and", "step", "%", "hparams", ".", "checkpoint_interval", "==", "0", ":", "\n", "        ", "save_states", "(", "step", ",", "writer", ",", "y_hat", ",", "y", ",", "input_lengths", ",", "checkpoint_dir", ")", "\n", "save_checkpoint", "(", "device", ",", "model", ",", "optimizer", ",", "step", ",", "checkpoint_dir", ",", "epoch", ",", "ema", ")", "\n", "\n", "", "if", "do_eval", ":", "\n", "# NOTE: use train step (i.e., global_step) for filename", "\n", "        ", "eval_model", "(", "global_step", ",", "writer", ",", "device", ",", "model", ",", "y", ",", "c", ",", "g", ",", "input_lengths", ",", "eval_dir", ",", "ema", ")", "\n", "\n", "# Update", "\n", "", "if", "train", ":", "\n", "        ", "loss", ".", "backward", "(", ")", "\n", "if", "clip_thresh", ">", "0", ":", "\n", "            ", "grad_norm", "=", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm_", "(", "model", ".", "parameters", "(", ")", ",", "clip_thresh", ")", "\n", "", "optimizer", ".", "step", "(", ")", "\n", "# update moving average", "\n", "if", "ema", "is", "not", "None", ":", "\n", "            ", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "name", "in", "ema", ".", "shadow", ":", "\n", "                    ", "ema", ".", "update", "(", "name", ",", "param", ".", "data", ")", "\n", "\n", "# Logs", "\n", "", "", "", "", "writer", ".", "add_scalar", "(", "\"{} loss\"", ".", "format", "(", "phase", ")", ",", "float", "(", "loss", ".", "item", "(", ")", ")", ",", "step", ")", "\n", "if", "train", ":", "\n", "        ", "if", "clip_thresh", ">", "0", ":", "\n", "            ", "writer", ".", "add_scalar", "(", "\"gradient norm\"", ",", "grad_norm", ",", "step", ")", "\n", "", "writer", ".", "add_scalar", "(", "\"learning rate\"", ",", "current_lr", ",", "step", ")", "\n", "\n", "", "return", "loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.train_loop": [[681, 739], ["wavenet_vocoder.util.is_mulaw_quantize", "train.MaskedCrossEntropyLoss", "train.DiscretizedMixturelogisticLoss", "train.ExponentialMovingAverage", "model.named_parameters", "data_loaders.items", "tqdm.tqdm", "writer.add_scalar", "print", "train.ExponentialMovingAverage.register", "enumerate", "os.path.join", "train.__train_step", "len", "print", "len"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ExponentialMovingAverage.register", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.__train_step"], ["", "def", "train_loop", "(", "device", ",", "model", ",", "data_loaders", ",", "optimizer", ",", "writer", ",", "checkpoint_dir", "=", "None", ")", ":", "\n", "    ", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "criterion", "=", "MaskedCrossEntropyLoss", "(", ")", "\n", "", "else", ":", "\n", "        ", "criterion", "=", "DiscretizedMixturelogisticLoss", "(", ")", "\n", "\n", "", "if", "hparams", ".", "exponential_moving_average", ":", "\n", "        ", "ema", "=", "ExponentialMovingAverage", "(", "hparams", ".", "ema_decay", ")", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "param", ".", "requires_grad", ":", "\n", "                ", "ema", ".", "register", "(", "name", ",", "param", ".", "data", ")", "\n", "", "", "", "else", ":", "\n", "        ", "ema", "=", "None", "\n", "\n", "", "global", "global_step", ",", "global_epoch", ",", "global_test_step", "\n", "while", "global_epoch", "<", "hparams", ".", "nepochs", ":", "\n", "        ", "for", "phase", ",", "data_loader", "in", "data_loaders", ".", "items", "(", ")", ":", "\n", "            ", "train", "=", "(", "phase", "==", "\"train\"", ")", "\n", "running_loss", "=", "0.", "\n", "test_evaluated", "=", "False", "\n", "for", "step", ",", "(", "x", ",", "y", ",", "c", ",", "g", ",", "input_lengths", ")", "in", "tqdm", "(", "enumerate", "(", "data_loader", ")", ")", ":", "\n", "# Whether to save eval (i.e., online decoding) result", "\n", "                ", "do_eval", "=", "False", "\n", "eval_dir", "=", "join", "(", "checkpoint_dir", ",", "\"{}_eval\"", ".", "format", "(", "phase", ")", ")", "\n", "# Do eval per eval_interval for train", "\n", "if", "train", "and", "global_step", ">", "0", "and", "global_step", "%", "hparams", ".", "train_eval_interval", "==", "0", ":", "\n", "                    ", "do_eval", "=", "True", "\n", "# Do eval for test", "\n", "# NOTE: Decoding WaveNet is quite time consuming, so", "\n", "# do only once in a single epoch for testset", "\n", "", "if", "not", "train", "and", "not", "test_evaluated", "and", "global_epoch", "%", "hparams", ".", "test_eval_epoch_interval", "==", "0", ":", "\n", "                    ", "do_eval", "=", "True", "\n", "test_evaluated", "=", "True", "\n", "", "if", "do_eval", ":", "\n", "                    ", "print", "(", "\"[{}] Eval at train step {}\"", ".", "format", "(", "phase", ",", "global_step", ")", ")", "\n", "\n", "# Do step", "\n", "", "running_loss", "+=", "__train_step", "(", "device", ",", "\n", "phase", ",", "global_epoch", ",", "global_step", ",", "global_test_step", ",", "model", ",", "\n", "optimizer", ",", "writer", ",", "criterion", ",", "x", ",", "y", ",", "c", ",", "g", ",", "input_lengths", ",", "\n", "checkpoint_dir", ",", "eval_dir", ",", "do_eval", ",", "ema", ")", "\n", "\n", "# update global state", "\n", "if", "train", ":", "\n", "                    ", "global_step", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "global_test_step", "+=", "1", "\n", "\n", "# log per epoch", "\n", "", "", "averaged_loss", "=", "running_loss", "/", "len", "(", "data_loader", ")", "\n", "writer", ".", "add_scalar", "(", "\"{} loss (per epoch)\"", ".", "format", "(", "phase", ")", ",", "\n", "averaged_loss", ",", "global_epoch", ")", "\n", "print", "(", "\"Step {} [{}] Loss: {}\"", ".", "format", "(", "\n", "global_step", ",", "phase", ",", "running_loss", "/", "len", "(", "data_loader", ")", ")", ")", "\n", "\n", "", "global_epoch", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.save_checkpoint": [[741, 767], ["os.path.join", "torch.save", "torch.save", "print", "optimizer.state_dict", "train.clone_as_averaged_model", "os.path.join", "torch.save", "torch.save", "print", "model.state_dict", "clone_as_averaged_model.state_dict"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.clone_as_averaged_model"], ["", "", "def", "save_checkpoint", "(", "device", ",", "model", ",", "optimizer", ",", "step", ",", "checkpoint_dir", ",", "epoch", ",", "ema", "=", "None", ")", ":", "\n", "    ", "checkpoint_path", "=", "join", "(", "\n", "checkpoint_dir", ",", "\"checkpoint_step{:09d}.pth\"", ".", "format", "(", "global_step", ")", ")", "\n", "optimizer_state", "=", "optimizer", ".", "state_dict", "(", ")", "if", "hparams", ".", "save_optimizer_state", "else", "None", "\n", "global", "global_test_step", "\n", "torch", ".", "save", "(", "{", "\n", "\"state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer_state", ",", "\n", "\"global_step\"", ":", "step", ",", "\n", "\"global_epoch\"", ":", "epoch", ",", "\n", "\"global_test_step\"", ":", "global_test_step", ",", "\n", "}", ",", "checkpoint_path", ")", "\n", "print", "(", "\"Saved checkpoint:\"", ",", "checkpoint_path", ")", "\n", "\n", "if", "ema", "is", "not", "None", ":", "\n", "        ", "averaged_model", "=", "clone_as_averaged_model", "(", "device", ",", "model", ",", "ema", ")", "\n", "checkpoint_path", "=", "join", "(", "\n", "checkpoint_dir", ",", "\"checkpoint_step{:09d}_ema.pth\"", ".", "format", "(", "global_step", ")", ")", "\n", "torch", ".", "save", "(", "{", "\n", "\"state_dict\"", ":", "averaged_model", ".", "state_dict", "(", ")", ",", "\n", "\"optimizer\"", ":", "optimizer_state", ",", "\n", "\"global_step\"", ":", "step", ",", "\n", "\"global_epoch\"", ":", "epoch", ",", "\n", "\"global_test_step\"", ":", "global_test_step", ",", "\n", "}", ",", "checkpoint_path", ")", "\n", "print", "(", "\"Saved averaged checkpoint:\"", ",", "checkpoint_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.build_model": [[769, 798], ["wavenet_vocoder.util.is_mulaw_quantize", "warnings.warn", "getattr", "RuntimeError", "wavenet_vocoder.util.is_scalar_input"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_scalar_input"], ["", "", "def", "build_model", "(", ")", ":", "\n", "    ", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "if", "hparams", ".", "out_channels", "!=", "hparams", ".", "quantize_channels", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"out_channels must equal to quantize_chennels if input_type is 'mulaw-quantize'\"", ")", "\n", "", "", "if", "hparams", ".", "upsample_conditional_features", "and", "hparams", ".", "cin_channels", "<", "0", ":", "\n", "        ", "s", "=", "\"Upsample conv layers were specified while local conditioning disabled. \"", "\n", "s", "+=", "\"Notice that upsample conv layers will never be used.\"", "\n", "warn", "(", "s", ")", "\n", "\n", "", "model", "=", "getattr", "(", "builder", ",", "hparams", ".", "builder", ")", "(", "\n", "out_channels", "=", "hparams", ".", "out_channels", ",", "\n", "layers", "=", "hparams", ".", "layers", ",", "\n", "stacks", "=", "hparams", ".", "stacks", ",", "\n", "residual_channels", "=", "hparams", ".", "residual_channels", ",", "\n", "gate_channels", "=", "hparams", ".", "gate_channels", ",", "\n", "skip_out_channels", "=", "hparams", ".", "skip_out_channels", ",", "\n", "cin_channels", "=", "hparams", ".", "cin_channels", ",", "\n", "gin_channels", "=", "hparams", ".", "gin_channels", ",", "\n", "weight_normalization", "=", "hparams", ".", "weight_normalization", ",", "\n", "n_speakers", "=", "hparams", ".", "n_speakers", ",", "\n", "dropout", "=", "hparams", ".", "dropout", ",", "\n", "kernel_size", "=", "hparams", ".", "kernel_size", ",", "\n", "upsample_conditional_features", "=", "hparams", ".", "upsample_conditional_features", ",", "\n", "upsample_scales", "=", "hparams", ".", "upsample_scales", ",", "\n", "freq_axis_kernel_size", "=", "hparams", ".", "freq_axis_kernel_size", ",", "\n", "scalar_input", "=", "is_scalar_input", "(", "hparams", ".", "input_type", ")", ",", "\n", ")", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._load": [[800, 807], ["torch.load", "torch.load", "torch.load", "torch.load"], "function", ["None"], ["", "def", "_load", "(", "checkpoint_path", ")", ":", "\n", "    ", "if", "use_cuda", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ")", "\n", "", "else", ":", "\n", "        ", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "", "return", "checkpoint", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.load_checkpoint": [[809, 827], ["print", "train._load", "model.load_state_dict", "_load.get", "print", "optimizer.load_state_dict"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._load"], ["", "def", "load_checkpoint", "(", "path", ",", "model", ",", "optimizer", ",", "reset_optimizer", ")", ":", "\n", "    ", "global", "global_step", "\n", "global", "global_epoch", "\n", "global", "global_test_step", "\n", "\n", "print", "(", "\"Load checkpoint from: {}\"", ".", "format", "(", "path", ")", ")", "\n", "checkpoint", "=", "_load", "(", "path", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "if", "not", "reset_optimizer", ":", "\n", "        ", "optimizer_state", "=", "checkpoint", "[", "\"optimizer\"", "]", "\n", "if", "optimizer_state", "is", "not", "None", ":", "\n", "            ", "print", "(", "\"Load optimizer state from {}\"", ".", "format", "(", "path", ")", ")", "\n", "optimizer", ".", "load_state_dict", "(", "checkpoint", "[", "\"optimizer\"", "]", ")", "\n", "", "", "global_step", "=", "checkpoint", "[", "\"global_step\"", "]", "\n", "global_epoch", "=", "checkpoint", "[", "\"global_epoch\"", "]", "\n", "global_test_step", "=", "checkpoint", ".", "get", "(", "\"global_test_step\"", ",", "0", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.restore_parts": [[830, 850], ["print", "model.state_dict", "train._load", "model.state_dict.update", "model.load_state_dict", "state.items", "print", "model.state_dict", "valid_state_dict.items", "str", "model.load_state_dict", "print", "warnings.warn", "str"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train._load", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.ExponentialMovingAverage.update"], ["", "def", "restore_parts", "(", "path", ",", "model", ")", ":", "\n", "    ", "print", "(", "\"Restore part of the model from: {}\"", ".", "format", "(", "path", ")", ")", "\n", "state", "=", "_load", "(", "path", ")", "[", "\"state_dict\"", "]", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "valid_state_dict", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "state", ".", "items", "(", ")", "if", "k", "in", "model_dict", "}", "\n", "\n", "try", ":", "\n", "        ", "model_dict", ".", "update", "(", "valid_state_dict", ")", "\n", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "# there should be invalid size of weight(s), so load them per parameter", "\n", "        ", "print", "(", "str", "(", "e", ")", ")", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "for", "k", ",", "v", "in", "valid_state_dict", ".", "items", "(", ")", ":", "\n", "            ", "model_dict", "[", "k", "]", "=", "v", "\n", "try", ":", "\n", "                ", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "", "except", "RuntimeError", "as", "e", ":", "\n", "                ", "print", "(", "str", "(", "e", ")", ")", "\n", "warn", "(", "\"{}: may contain invalid size of weight. skipping...\"", ".", "format", "(", "k", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.get_data_loaders": [[852, 904], ["nnmnkwii.datasets.FileSourceDataset", "print", "train.PyTorchDataset", "torch.utils.data.DataLoader", "enumerate", "train.RawAudioDataSource", "nnmnkwii.datasets.FileSourceDataset", "print", "numpy.array", "train.PartialyRandomizedSimilarTimeLengthSampler", "len", "print", "train.MelSpecDataSource", "len", "len", "len"], "function", ["None"], ["", "", "", "", "def", "get_data_loaders", "(", "data_root", ",", "speaker_id", ",", "test_shuffle", "=", "True", ")", ":", "\n", "    ", "data_loaders", "=", "{", "}", "\n", "local_conditioning", "=", "hparams", ".", "cin_channels", ">", "0", "\n", "for", "phase", "in", "[", "\"train\"", ",", "\"test\"", "]", ":", "\n", "        ", "train", "=", "phase", "==", "\"train\"", "\n", "X", "=", "FileSourceDataset", "(", "RawAudioDataSource", "(", "data_root", ",", "speaker_id", "=", "speaker_id", ",", "\n", "train", "=", "train", ",", "\n", "test_size", "=", "hparams", ".", "test_size", ",", "\n", "test_num_samples", "=", "hparams", ".", "test_num_samples", ",", "\n", "random_state", "=", "hparams", ".", "random_state", ")", ")", "\n", "if", "local_conditioning", ":", "\n", "            ", "Mel", "=", "FileSourceDataset", "(", "MelSpecDataSource", "(", "data_root", ",", "speaker_id", "=", "speaker_id", ",", "\n", "train", "=", "train", ",", "\n", "test_size", "=", "hparams", ".", "test_size", ",", "\n", "test_num_samples", "=", "hparams", ".", "test_num_samples", ",", "\n", "random_state", "=", "hparams", ".", "random_state", ")", ")", "\n", "assert", "len", "(", "X", ")", "==", "len", "(", "Mel", ")", "\n", "print", "(", "\"Local conditioning enabled. Shape of a sample: {}.\"", ".", "format", "(", "\n", "Mel", "[", "0", "]", ".", "shape", ")", ")", "\n", "", "else", ":", "\n", "            ", "Mel", "=", "None", "\n", "", "print", "(", "\"[{}]: length of the dataset is {}\"", ".", "format", "(", "phase", ",", "len", "(", "X", ")", ")", ")", "\n", "\n", "if", "train", ":", "\n", "            ", "lengths", "=", "np", ".", "array", "(", "X", ".", "file_data_source", ".", "lengths", ")", "\n", "# Prepare sampler", "\n", "sampler", "=", "PartialyRandomizedSimilarTimeLengthSampler", "(", "\n", "lengths", ",", "batch_size", "=", "hparams", ".", "batch_size", ")", "\n", "shuffle", "=", "False", "\n", "", "else", ":", "\n", "            ", "sampler", "=", "None", "\n", "shuffle", "=", "test_shuffle", "\n", "\n", "", "dataset", "=", "PyTorchDataset", "(", "X", ",", "Mel", ")", "\n", "data_loader", "=", "data_utils", ".", "DataLoader", "(", "\n", "dataset", ",", "batch_size", "=", "hparams", ".", "batch_size", ",", "\n", "num_workers", "=", "hparams", ".", "num_workers", ",", "sampler", "=", "sampler", ",", "shuffle", "=", "shuffle", ",", "\n", "collate_fn", "=", "collate_fn", ",", "pin_memory", "=", "hparams", ".", "pin_memory", ")", "\n", "\n", "speaker_ids", "=", "{", "}", "\n", "for", "idx", ",", "(", "x", ",", "c", ",", "g", ")", "in", "enumerate", "(", "dataset", ")", ":", "\n", "            ", "if", "g", "is", "not", "None", ":", "\n", "                ", "try", ":", "\n", "                    ", "speaker_ids", "[", "g", "]", "+=", "1", "\n", "", "except", "KeyError", ":", "\n", "                    ", "speaker_ids", "[", "g", "]", "=", "1", "\n", "", "", "", "if", "len", "(", "speaker_ids", ")", ">", "0", ":", "\n", "            ", "print", "(", "\"Speaker stats:\"", ",", "speaker_ids", ")", "\n", "\n", "", "data_loaders", "[", "phase", "]", "=", "data_loader", "\n", "\n", "", "return", "data_loaders", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.preprocess.preprocess": [[21, 24], ["os.makedirs", "mod.build_from_path"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.ljspeech.build_from_path"], ["def", "preprocess", "(", "mod", ",", "in_dir", ",", "out_root", ",", "num_workers", ")", ":", "\n", "    ", "os", ".", "makedirs", "(", "out_dir", ",", "exist_ok", "=", "True", ")", "\n", "mod", ".", "build_from_path", "(", "in_dir", ",", "out_dir", ",", "num_workers", ",", "tqdm", "=", "tqdm", ")", "\n", "# metadata = mod.build_from_path(in_dir, out_dir, num_workers, tqdm=tqdm)", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.preprocess.write_metadata": [[28, 38], ["sum", "print", "print", "print", "open", "os.path.join", "f.write", "max", "max", "len", "len", "str"], "function", ["None"], ["", "def", "write_metadata", "(", "metadata", ",", "out_dir", ")", ":", "\n", "    ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "'train.txt'", ")", ",", "'w'", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "m", "in", "metadata", ":", "\n", "            ", "f", ".", "write", "(", "'|'", ".", "join", "(", "[", "str", "(", "x", ")", "for", "x", "in", "m", "]", ")", "+", "'\\n'", ")", "\n", "", "", "frames", "=", "sum", "(", "[", "m", "[", "2", "]", "for", "m", "in", "metadata", "]", ")", "\n", "sr", "=", "hparams", ".", "sample_rate", "\n", "hours", "=", "frames", "/", "sr", "/", "3600", "\n", "print", "(", "'Wrote %d utterances, %d time steps (%.2f hours)'", "%", "(", "len", "(", "metadata", ")", ",", "frames", ",", "hours", ")", ")", "\n", "print", "(", "'Max input length:  %d'", "%", "max", "(", "len", "(", "m", "[", "3", "]", ")", "for", "m", "in", "metadata", ")", ")", "\n", "print", "(", "'Max output length: %d'", "%", "max", "(", "m", "[", "2", "]", "for", "m", "in", "metadata", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.librivox.build_from_path": [[17, 42], ["concurrent.futures.ProcessPoolExecutor", "sorted", "os.listdir", "sum", "os.path.join", "futures.append", "concurrent.futures.ProcessPoolExecutor.submit", "tqdm", "future.result", "f.endswith", "functools.partial"], "function", ["None"], ["def", "build_from_path", "(", "in_dir", ",", "out_dir", ",", "num_workers", "=", "1", ",", "tqdm", "=", "lambda", "x", ":", "x", ")", ":", "\n", "    ", "executor", "=", "ProcessPoolExecutor", "(", "max_workers", "=", "num_workers", ")", "\n", "futures", "=", "[", "]", "\n", "index", "=", "1", "\n", "\n", "#with open(os.path.join(in_dir, 'metadata.csv'), encoding='utf-8') as f:", "\n", "#    for line in f:", "\n", "#        parts = line.strip().split('|')", "\n", "#        wav_path = os.path.join(in_dir, 'wavs', '%s.wav' % parts[0])", "\n", "#        text = parts[2]", "\n", "#        futures.append(executor.submit(", "\n", "#            partial(_process_utterance, out_dir, index, wav_path, text)))", "\n", "#        index += 1", "\n", "\n", "valid_ext", "=", "'.ogg .wav .mp3'", ".", "split", "(", ")", "\n", "for", "f", "in", "sorted", "(", "os", ".", "listdir", "(", "in_dir", ")", ")", ":", "\n", "      ", "valid", "=", "sum", "(", "[", "f", ".", "endswith", "(", "ext", ")", "for", "ext", "in", "valid_ext", "]", ")", "\n", "if", "valid", "<", "1", ":", "continue", "\n", "\n", "audio_filepath", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "f", ")", "\n", "text", "=", "audio_filepath", "# Not very informative", "\n", "futures", ".", "append", "(", "executor", ".", "submit", "(", "\n", "partial", "(", "_process_utterance", ",", "out_dir", ",", "index", ",", "audio_filepath", ",", "text", ")", ")", ")", "\n", "index", "+=", "1", "\n", "", "return", "[", "tup", "for", "future", "in", "tqdm", "(", "futures", ")", "for", "tup", "in", "future", ".", "result", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.librivox._process_utterance": [[44, 121], ["audio.load_wav", "int", "range", "wavenet_vocoder.util.is_mulaw_quantize", "audio.lws_pad_lr", "numpy.pad", "len", "numpy.save", "numpy.save", "tup_results.append", "nnmnkwii.preprocessing.mulaw_quantize", "audio.start_and_end_indices", "nnmnkwii.preprocessing.mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "audio.melspectrogram().astype", "audio.get_hop_size", "len", "os.path.join", "P.mulaw.astype", "os.path.join", "mel_spectrogram.astype", "numpy.abs().max", "nnmnkwii.preprocessing.mulaw", "nnmnkwii.preprocessing.mulaw", "audio.get_hop_size", "len", "audio.get_hop_size", "audio.melspectrogram", "audio.get_hop_size", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.load_wav", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.lws_pad_lr", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.start_and_end_indices", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.melspectrogram", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size"], ["", "def", "_process_utterance", "(", "out_dir", ",", "index", ",", "audio_filepath", ",", "text", ")", ":", "\n", "# Load the audio to a numpy array:", "\n", "    ", "wav_whole", "=", "audio", ".", "load_wav", "(", "audio_filepath", ")", "\n", "\n", "if", "hparams", ".", "rescaling", ":", "\n", "        ", "wav_whole", "=", "wav_whole", "/", "np", ".", "abs", "(", "wav_whole", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "\n", "# This is a librivox source, so the audio files are going to be v. long ", "\n", "# compared to a typical 'utterance' : So split the wav into chunks", "\n", "\n", "", "tup_results", "=", "[", "]", "\n", "\n", "n_samples", "=", "int", "(", "8.0", "*", "hparams", ".", "sample_rate", ")", "# All 8 second utterances", "\n", "n_chunks", "=", "wav_whole", ".", "shape", "[", "0", "]", "//", "n_samples", "\n", "\n", "for", "chunk_idx", "in", "range", "(", "n_chunks", ")", ":", "\n", "        ", "chunk_start", ",", "chunk_end", "=", "chunk_idx", "*", "n_samples", ",", "(", "chunk_idx", "+", "1", ")", "*", "n_samples", "\n", "if", "chunk_idx", "==", "n_chunks", "-", "1", ":", "# This is the last chunk - allow it to extend to the end of the file", "\n", "            ", "chunk_end", "=", "None", "\n", "", "wav", "=", "wav_whole", "[", "chunk_start", ":", "chunk_end", "]", "\n", "\n", "# Mu-law quantize", "\n", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [0, quantize_channels)", "\n", "            ", "out", "=", "P", ".", "mulaw_quantize", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "\n", "# Trim silences", "\n", "start", ",", "end", "=", "audio", ".", "start_and_end_indices", "(", "out", ",", "hparams", ".", "silence_threshold", ")", "\n", "wav", "=", "wav", "[", "start", ":", "end", "]", "\n", "out", "=", "out", "[", "start", ":", "end", "]", "\n", "constant_values", "=", "P", ".", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "int16", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [-1, 1]", "\n", "            ", "out", "=", "P", ".", "mulaw", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "constant_values", "=", "P", ".", "mulaw", "(", "0.0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "", "else", ":", "\n", "# [-1, 1]", "\n", "            ", "out", "=", "wav", "\n", "constant_values", "=", "0.0", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "# Compute a mel-scale spectrogram from the trimmed wav:", "\n", "# (N, D)", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "wav", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "# lws pads zeros internally before performing stft", "\n", "# this is needed to adjust time resolution between audio and mel-spectrogram", "\n", "l", ",", "r", "=", "audio", ".", "lws_pad_lr", "(", "wav", ",", "hparams", ".", "fft_size", ",", "audio", ".", "get_hop_size", "(", ")", ")", "\n", "\n", "# zero pad for quantized signal", "\n", "out", "=", "np", ".", "pad", "(", "out", ",", "(", "l", ",", "r", ")", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "constant_values", ")", "\n", "N", "=", "mel_spectrogram", ".", "shape", "[", "0", "]", "\n", "assert", "len", "(", "out", ")", ">=", "N", "*", "audio", ".", "get_hop_size", "(", ")", "\n", "\n", "# time resolution adjustment", "\n", "# ensure length of raw audio is multiple of hop_size so that we can use", "\n", "# transposed convolution to upsample", "\n", "out", "=", "out", "[", ":", "N", "*", "audio", ".", "get_hop_size", "(", ")", "]", "\n", "assert", "len", "(", "out", ")", "%", "audio", ".", "get_hop_size", "(", ")", "==", "0", "\n", "\n", "timesteps", "=", "len", "(", "out", ")", "\n", "\n", "# Write the spectrograms to disk:", "\n", "audio_filename", "=", "'librivox-audio-%04d-%05d.npy'", "%", "(", "index", ",", "chunk_idx", ",", ")", "\n", "mel_filename", "=", "'librivox-mel-%04d-%05d.npy'", "%", "(", "index", ",", "chunk_idx", ",", ")", "\n", "text_idx", "=", "'%s - %05d'", "%", "(", "text", ",", "chunk_idx", ",", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "audio_filename", ")", ",", "\n", "out", ".", "astype", "(", "out_dtype", ")", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "mel_filename", ")", ",", "\n", "mel_spectrogram", ".", "astype", "(", "np", ".", "float32", ")", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "# Add results tuple describing this training example:", "\n", "tup_results", ".", "append", "(", "(", "audio_filename", ",", "mel_filename", ",", "timesteps", ",", "text_idx", ")", ")", "\n", "\n", "# Return all the audio results tuples (unpack in caller)", "\n", "", "return", "tup_results", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.synthesis._to_numpy": [[43, 53], ["x.squeeze.numpy", "isinstance", "numpy.isscalar", "x.squeeze.dim", "x.squeeze.squeeze"], "function", ["None"], ["def", "_to_numpy", "(", "x", ")", ":", "\n", "# this is ugly", "\n", "    ", "if", "x", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "if", "isinstance", "(", "x", ",", "np", ".", "ndarray", ")", "or", "np", ".", "isscalar", "(", "x", ")", ":", "\n", "        ", "return", "x", "\n", "# remove batch axis", "\n", "", "if", "x", ".", "dim", "(", ")", "==", "3", ":", "\n", "        ", "x", "=", "x", ".", "squeeze", "(", "0", ")", "\n", "", "return", "x", ".", "numpy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.synthesis.wavegen": [[55, 138], ["sanity_check", "synthesis._to_numpy", "synthesis._to_numpy", "model.eval", "wavenet_vocoder.util.is_mulaw_quantize", "torch.zeros().fill_.to", "wavenet_vocoder.util.is_mulaw_quantize", "model.make_generation_fast_", "audio.get_hop_size", "torch.FloatTensor().unsqueeze", "wavenet_vocoder.util.is_mulaw_quantize", "keras.utils.np_utils.to_categorical().astype", "torch.from_numpy().view", "torch.zeros().fill_", "torch.LongTensor", "_to_numpy.to", "np.repeat.to", "torch.no_grad", "model.incremental_forward", "[].view().long().cpu().data.numpy", "nnmnkwii.preprocessing.inv_mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "RuntimeError", "numpy.repeat", "nnmnkwii.preprocessing.mulaw_quantize", "nnmnkwii.preprocessing.inv_mulaw", "y_hat.view().cpu().data.numpy.view().cpu().data.numpy", "torch.FloatTensor", "keras.utils.np_utils.to_categorical", "torch.from_numpy", "torch.zeros", "y_hat.view().cpu().data.numpy.view().cpu().data.numpy", "[].view().long().cpu", "y_hat.view().cpu().data.numpy.view().cpu", "[].view().long", "y_hat.view().cpu().data.numpy.view().cpu", "y_hat.view().cpu().data.numpy.view", "[].view", "y_hat.view().cpu().data.numpy.view", "y_hat.view().cpu().data.numpy.max"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.train.sanity_check", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.synthesis._to_numpy", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.synthesis._to_numpy", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.make_generation_fast_", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical"], ["", "def", "wavegen", "(", "model", ",", "length", "=", "None", ",", "c", "=", "None", ",", "g", "=", "None", ",", "initial_value", "=", "None", ",", "\n", "fast", "=", "False", ",", "tqdm", "=", "tqdm", ")", ":", "\n", "    ", "\"\"\"Generate waveform samples by WaveNet.\n\n    Args:\n        model (nn.Module) : WaveNet decoder\n        length (int): Time steps to generate. If conditinlal features are given,\n          then this is determined by the feature size.\n        c (numpy.ndarray): Conditional features, of shape T x C\n        g (scaler): Speaker ID\n        initial_value (int) : initial_value for the WaveNet decoder.\n        fast (Bool): Whether to remove weight normalization or not.\n        tqdm (lambda): tqdm\n\n    Returns:\n        numpy.ndarray : Generated waveform samples\n    \"\"\"", "\n", "from", "train", "import", "sanity_check", "\n", "sanity_check", "(", "model", ",", "c", ",", "g", ")", "\n", "\n", "c", "=", "_to_numpy", "(", "c", ")", "\n", "g", "=", "_to_numpy", "(", "g", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "if", "fast", ":", "\n", "        ", "model", ".", "make_generation_fast_", "(", ")", "\n", "\n", "", "if", "c", "is", "None", ":", "\n", "        ", "assert", "length", "is", "not", "None", "\n", "", "else", ":", "\n", "# (Tc, D)", "\n", "        ", "if", "c", ".", "ndim", "!=", "2", ":", "\n", "            ", "raise", "RuntimeError", "(", "\n", "\"Expected 2-dim shape (T, {}) for the conditional feature, but {} was actually given.\"", ".", "format", "(", "hparams", ".", "cin_channels", ",", "c", ".", "shape", ")", ")", "\n", "assert", "c", ".", "ndim", "==", "2", "\n", "", "Tc", "=", "c", ".", "shape", "[", "0", "]", "\n", "upsample_factor", "=", "audio", ".", "get_hop_size", "(", ")", "\n", "# Overwrite length according to feature size", "\n", "length", "=", "Tc", "*", "upsample_factor", "\n", "# (Tc, D) -> (Tc', D)", "\n", "# Repeat features before feeding it to the network", "\n", "if", "not", "hparams", ".", "upsample_conditional_features", ":", "\n", "            ", "c", "=", "np", ".", "repeat", "(", "c", ",", "upsample_factor", ",", "axis", "=", "0", ")", "\n", "\n", "# B x C x T", "\n", "", "c", "=", "torch", ".", "FloatTensor", "(", "c", ".", "T", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "", "if", "initial_value", "is", "None", ":", "\n", "        ", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "            ", "initial_value", "=", "P", ".", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "else", ":", "\n", "            ", "initial_value", "=", "0.0", "\n", "\n", "", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "assert", "initial_value", ">=", "0", "and", "initial_value", "<", "hparams", ".", "quantize_channels", "\n", "initial_input", "=", "np_utils", ".", "to_categorical", "(", "\n", "initial_value", ",", "num_classes", "=", "hparams", ".", "quantize_channels", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "initial_input", "=", "torch", ".", "from_numpy", "(", "initial_input", ")", ".", "view", "(", "\n", "1", ",", "1", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "else", ":", "\n", "        ", "initial_input", "=", "torch", ".", "zeros", "(", "1", ",", "1", ",", "1", ")", ".", "fill_", "(", "initial_value", ")", "\n", "\n", "", "g", "=", "None", "if", "g", "is", "None", "else", "torch", ".", "LongTensor", "(", "[", "g", "]", ")", "\n", "\n", "# Transform data to GPU", "\n", "initial_input", "=", "initial_input", ".", "to", "(", "device", ")", "\n", "g", "=", "None", "if", "g", "is", "None", "else", "g", ".", "to", "(", "device", ")", "\n", "c", "=", "None", "if", "c", "is", "None", "else", "c", ".", "to", "(", "device", ")", "\n", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "y_hat", "=", "model", ".", "incremental_forward", "(", "\n", "initial_input", ",", "c", "=", "c", ",", "g", "=", "g", ",", "T", "=", "length", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "True", ",", "\n", "log_scale_min", "=", "hparams", ".", "log_scale_min", ")", "\n", "\n", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "y_hat", "=", "y_hat", ".", "max", "(", "1", ")", "[", "1", "]", ".", "view", "(", "-", "1", ")", ".", "long", "(", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "y_hat", "=", "P", ".", "inv_mulaw_quantize", "(", "y_hat", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "        ", "y_hat", "=", "P", ".", "inv_mulaw", "(", "y_hat", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "hparams", ".", "quantize_channels", ")", "\n", "", "else", ":", "\n", "        ", "y_hat", "=", "y_hat", ".", "view", "(", "-", "1", ")", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", "\n", "\n", "", "return", "y_hat", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.lrschedule.noam_learning_rate_decay": [[5, 12], ["float", "numpy.minimum"], "function", ["None"], ["def", "noam_learning_rate_decay", "(", "init_lr", ",", "global_step", ",", "warmup_steps", "=", "4000", ")", ":", "\n", "# Noam scheme from tensor2tensor:", "\n", "    ", "warmup_steps", "=", "float", "(", "warmup_steps", ")", "\n", "step", "=", "global_step", "+", "1.", "\n", "lr", "=", "init_lr", "*", "warmup_steps", "**", "0.5", "*", "np", ".", "minimum", "(", "\n", "step", "*", "warmup_steps", "**", "-", "1.5", ",", "step", "**", "-", "0.5", ")", "\n", "return", "lr", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.lrschedule.step_learning_rate_decay": [[14, 18], ["None"], "function", ["None"], ["", "def", "step_learning_rate_decay", "(", "init_lr", ",", "global_step", ",", "\n", "anneal_rate", "=", "0.98", ",", "\n", "anneal_interval", "=", "30000", ")", ":", "\n", "    ", "return", "init_lr", "*", "anneal_rate", "**", "(", "global_step", "//", "anneal_interval", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.lrschedule.cyclic_cosine_annealing": [[20, 36], ["numpy.cos"], "function", ["None"], ["", "def", "cyclic_cosine_annealing", "(", "init_lr", ",", "global_step", ",", "T", ",", "M", ")", ":", "\n", "    ", "\"\"\"Cyclic cosine annealing\n\n    https://arxiv.org/pdf/1704.00109.pdf\n\n    Args:\n        init_lr (float): Initial learning rate\n        global_step (int): Current iteration number\n        T (int): Total iteration number (i,e. nepoch)\n        M (int): Number of ensembles we want\n\n    Returns:\n        float: Annealed learning rate\n    \"\"\"", "\n", "TdivM", "=", "T", "//", "M", "\n", "return", "init_lr", "/", "2.0", "*", "(", "np", ".", "cos", "(", "np", ".", "pi", "*", "(", "(", "global_step", "-", "1", ")", "%", "TdivM", ")", "/", "TdivM", ")", "+", "1.0", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.hparams.hparams_debug_string": [[129, 133], ["hparams.values", "sorted"], "function", ["None"], ["def", "hparams_debug_string", "(", ")", ":", "\n", "    ", "values", "=", "hparams", ".", "values", "(", ")", "\n", "hp", "=", "[", "'  %s: %s'", "%", "(", "name", ",", "values", "[", "name", "]", ")", "for", "name", "in", "sorted", "(", "values", ")", "]", "\n", "return", "'Hyperparameters:\\n'", "+", "'\\n'", ".", "join", "(", "hp", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.ljspeech.build_from_path": [[17, 30], ["concurrent.futures.ProcessPoolExecutor", "open", "future.result", "os.path.join", "line.strip().split", "os.path.join", "futures.append", "tqdm", "concurrent.futures.ProcessPoolExecutor.submit", "line.strip", "functools.partial"], "function", ["None"], ["def", "build_from_path", "(", "in_dir", ",", "out_dir", ",", "num_workers", "=", "1", ",", "tqdm", "=", "lambda", "x", ":", "x", ")", ":", "\n", "    ", "executor", "=", "ProcessPoolExecutor", "(", "max_workers", "=", "num_workers", ")", "\n", "futures", "=", "[", "]", "\n", "index", "=", "1", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "'metadata.csv'", ")", ",", "encoding", "=", "'utf-8'", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "parts", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "'|'", ")", "\n", "wav_path", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "'wavs'", ",", "'%s.wav'", "%", "parts", "[", "0", "]", ")", "\n", "text", "=", "parts", "[", "2", "]", "\n", "futures", ".", "append", "(", "executor", ".", "submit", "(", "\n", "partial", "(", "_process_utterance", ",", "out_dir", ",", "index", ",", "wav_path", ",", "text", ")", ")", ")", "\n", "index", "+=", "1", "\n", "", "", "return", "[", "future", ".", "result", "(", ")", "for", "future", "in", "tqdm", "(", "futures", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.ljspeech._process_utterance": [[32, 91], ["audio.load_wav", "wavenet_vocoder.util.is_mulaw_quantize", "audio.lws_pad_lr", "numpy.pad", "len", "numpy.save", "numpy.save", "nnmnkwii.preprocessing.mulaw_quantize", "audio.start_and_end_indices", "nnmnkwii.preprocessing.mulaw_quantize", "wavenet_vocoder.util.is_mulaw", "audio.melspectrogram().astype", "audio.get_hop_size", "len", "os.path.join", "P.mulaw.astype", "os.path.join", "mel_spectrogram.astype", "nnmnkwii.preprocessing.mulaw", "nnmnkwii.preprocessing.mulaw", "audio.get_hop_size", "len", "audio.get_hop_size", "numpy.abs().max", "audio.melspectrogram", "audio.get_hop_size", "numpy.abs"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.load_wav", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.lws_pad_lr", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.start_and_end_indices", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.melspectrogram", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.get_hop_size"], ["", "def", "_process_utterance", "(", "out_dir", ",", "index", ",", "wav_path", ",", "text", ")", ":", "\n", "# Load the audio to a numpy array:", "\n", "    ", "wav", "=", "audio", ".", "load_wav", "(", "wav_path", ")", "\n", "\n", "if", "hparams", ".", "rescaling", ":", "\n", "        ", "wav", "=", "wav", "/", "np", ".", "abs", "(", "wav", ")", ".", "max", "(", ")", "*", "hparams", ".", "rescaling_max", "\n", "\n", "# Mu-law quantize", "\n", "", "if", "is_mulaw_quantize", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [0, quantize_channels)", "\n", "        ", "out", "=", "P", ".", "mulaw_quantize", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "\n", "# Trim silences", "\n", "start", ",", "end", "=", "audio", ".", "start_and_end_indices", "(", "out", ",", "hparams", ".", "silence_threshold", ")", "\n", "wav", "=", "wav", "[", "start", ":", "end", "]", "\n", "out", "=", "out", "[", "start", ":", "end", "]", "\n", "constant_values", "=", "P", ".", "mulaw_quantize", "(", "0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "int16", "\n", "", "elif", "is_mulaw", "(", "hparams", ".", "input_type", ")", ":", "\n", "# [-1, 1]", "\n", "        ", "out", "=", "P", ".", "mulaw", "(", "wav", ",", "hparams", ".", "quantize_channels", ")", "\n", "constant_values", "=", "P", ".", "mulaw", "(", "0.0", ",", "hparams", ".", "quantize_channels", ")", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "", "else", ":", "\n", "# [-1, 1]", "\n", "        ", "out", "=", "wav", "\n", "constant_values", "=", "0.0", "\n", "out_dtype", "=", "np", ".", "float32", "\n", "\n", "# Compute a mel-scale spectrogram from the trimmed wav:", "\n", "# (N, D)", "\n", "", "mel_spectrogram", "=", "audio", ".", "melspectrogram", "(", "wav", ")", ".", "astype", "(", "np", ".", "float32", ")", ".", "T", "\n", "# lws pads zeros internally before performing stft", "\n", "# this is needed to adjust time resolution between audio and mel-spectrogram", "\n", "l", ",", "r", "=", "audio", ".", "lws_pad_lr", "(", "wav", ",", "hparams", ".", "fft_size", ",", "audio", ".", "get_hop_size", "(", ")", ")", "\n", "\n", "# zero pad for quantized signal", "\n", "out", "=", "np", ".", "pad", "(", "out", ",", "(", "l", ",", "r", ")", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "constant_values", ")", "\n", "N", "=", "mel_spectrogram", ".", "shape", "[", "0", "]", "\n", "assert", "len", "(", "out", ")", ">=", "N", "*", "audio", ".", "get_hop_size", "(", ")", "\n", "\n", "# time resolution adjustment", "\n", "# ensure length of raw audio is multiple of hop_size so that we can use", "\n", "# transposed convolution to upsample", "\n", "out", "=", "out", "[", ":", "N", "*", "audio", ".", "get_hop_size", "(", ")", "]", "\n", "assert", "len", "(", "out", ")", "%", "audio", ".", "get_hop_size", "(", ")", "==", "0", "\n", "\n", "timesteps", "=", "len", "(", "out", ")", "\n", "\n", "# Write the spectrograms to disk:", "\n", "audio_filename", "=", "'ljspeech-audio-%05d.npy'", "%", "index", "\n", "mel_filename", "=", "'ljspeech-mel-%05d.npy'", "%", "index", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "audio_filename", ")", ",", "\n", "out", ".", "astype", "(", "out_dtype", ")", ",", "allow_pickle", "=", "False", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "out_dir", ",", "mel_filename", ")", ",", "\n", "mel_spectrogram", ".", "astype", "(", "np", ".", "float32", ")", ",", "allow_pickle", "=", "False", ")", "\n", "\n", "# Return a tuple describing this training example:", "\n", "return", "(", "audio_filename", ",", "mel_filename", ",", "timesteps", ",", "text", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.log_sum_exp": [[16, 23], ["torch.max", "torch.max", "len", "torch.log", "x.size", "torch.sum", "torch.exp"], "function", ["None"], ["def", "log_sum_exp", "(", "x", ")", ":", "\n", "    ", "\"\"\" numerically stable log_sum_exp implementation that prevents overflow \"\"\"", "\n", "# TF ordering", "\n", "axis", "=", "len", "(", "x", ".", "size", "(", ")", ")", "-", "1", "\n", "m", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "axis", ")", "\n", "m2", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "axis", ",", "keepdim", "=", "True", ")", "\n", "return", "m", "+", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "x", "-", "m2", ")", ",", "dim", "=", "axis", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.discretized_mix_logistic_loss": [[25, 106], ["y_hat.transpose.transpose", "torch.clamp", "y.expand_as.expand_as", "torch.exp", "torch.nn.functional.sigmoid", "torch.nn.functional.sigmoid", "y_hat.transpose.dim", "y_hat.transpose.size", "torch.nn.functional.softplus", "torch.nn.functional.softplus", "torch.nn.functional.log_softmax", "y_hat.transpose.size", "torch.nn.functional.softplus", "torch.log", "torch.sum", "log_sum_exp().unsqueeze", "torch.clamp", "numpy.log", "mixture.log_sum_exp", "mixture.log_sum_exp"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.log_sum_exp", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.log_sum_exp"], ["", "def", "discretized_mix_logistic_loss", "(", "y_hat", ",", "y", ",", "num_classes", "=", "256", ",", "\n", "log_scale_min", "=", "-", "7.0", ",", "reduce", "=", "True", ")", ":", "\n", "    ", "\"\"\"Discretized mixture of logistic distributions loss\n\n    Note that it is assumed that input is scaled to [-1, 1].\n\n    Args:\n        y_hat (Tensor): Predicted output (B x C x T)\n        y (Tensor): Target (B x T x 1).\n        num_classes (int): Number of classes\n        log_scale_min (float): Log scale minimum value\n        reduce (bool): If True, the losses are averaged or summed for each\n          minibatch.\n\n    Returns\n        Tensor: loss\n    \"\"\"", "\n", "assert", "y_hat", ".", "dim", "(", ")", "==", "3", "\n", "assert", "y_hat", ".", "size", "(", "1", ")", "%", "3", "==", "0", "\n", "nr_mix", "=", "y_hat", ".", "size", "(", "1", ")", "//", "3", "\n", "\n", "# (B x T x C)", "\n", "y_hat", "=", "y_hat", ".", "transpose", "(", "1", ",", "2", ")", "\n", "\n", "# unpack parameters. (B, T, num_mixtures) x 3", "\n", "logit_probs", "=", "y_hat", "[", ":", ",", ":", ",", ":", "nr_mix", "]", "\n", "means", "=", "y_hat", "[", ":", ",", ":", ",", "nr_mix", ":", "2", "*", "nr_mix", "]", "\n", "log_scales", "=", "torch", ".", "clamp", "(", "y_hat", "[", ":", ",", ":", ",", "2", "*", "nr_mix", ":", "3", "*", "nr_mix", "]", ",", "min", "=", "log_scale_min", ")", "\n", "\n", "# B x T x 1 -> B x T x num_mixtures", "\n", "y", "=", "y", ".", "expand_as", "(", "means", ")", "\n", "\n", "centered_y", "=", "y", "-", "means", "\n", "inv_stdv", "=", "torch", ".", "exp", "(", "-", "log_scales", ")", "\n", "plus_in", "=", "inv_stdv", "*", "(", "centered_y", "+", "1.", "/", "(", "num_classes", "-", "1", ")", ")", "\n", "cdf_plus", "=", "F", ".", "sigmoid", "(", "plus_in", ")", "\n", "min_in", "=", "inv_stdv", "*", "(", "centered_y", "-", "1.", "/", "(", "num_classes", "-", "1", ")", ")", "\n", "cdf_min", "=", "F", ".", "sigmoid", "(", "min_in", ")", "\n", "\n", "# log probability for edge case of 0 (before scaling)", "\n", "# equivalent: torch.log(F.sigmoid(plus_in))", "\n", "log_cdf_plus", "=", "plus_in", "-", "F", ".", "softplus", "(", "plus_in", ")", "\n", "\n", "# log probability for edge case of 255 (before scaling)", "\n", "# equivalent: (1 - F.sigmoid(min_in)).log()", "\n", "log_one_minus_cdf_min", "=", "-", "F", ".", "softplus", "(", "min_in", ")", "\n", "\n", "# probability for all other cases", "\n", "cdf_delta", "=", "cdf_plus", "-", "cdf_min", "\n", "\n", "mid_in", "=", "inv_stdv", "*", "centered_y", "\n", "# log probability in the center of the bin, to be used in extreme cases", "\n", "# (not actually used in our code)", "\n", "log_pdf_mid", "=", "mid_in", "-", "log_scales", "-", "2.", "*", "F", ".", "softplus", "(", "mid_in", ")", "\n", "\n", "# tf equivalent", "\n", "\"\"\"\n    log_probs = tf.where(x < -0.999, log_cdf_plus,\n                         tf.where(x > 0.999, log_one_minus_cdf_min,\n                                  tf.where(cdf_delta > 1e-5,\n                                           tf.log(tf.maximum(cdf_delta, 1e-12)),\n                                           log_pdf_mid - np.log(127.5))))\n    \"\"\"", "\n", "# TODO: cdf_delta <= 1e-5 actually can happen. How can we choose the value", "\n", "# for num_classes=65536 case? 1e-7? not sure..", "\n", "inner_inner_cond", "=", "(", "cdf_delta", ">", "1e-5", ")", ".", "float", "(", ")", "\n", "\n", "inner_inner_out", "=", "inner_inner_cond", "*", "torch", ".", "log", "(", "torch", ".", "clamp", "(", "cdf_delta", ",", "min", "=", "1e-12", ")", ")", "+", "(", "1.", "-", "inner_inner_cond", ")", "*", "(", "log_pdf_mid", "-", "np", ".", "log", "(", "(", "num_classes", "-", "1", ")", "/", "2", ")", ")", "\n", "inner_cond", "=", "(", "y", ">", "0.999", ")", ".", "float", "(", ")", "\n", "inner_out", "=", "inner_cond", "*", "log_one_minus_cdf_min", "+", "(", "1.", "-", "inner_cond", ")", "*", "inner_inner_out", "\n", "cond", "=", "(", "y", "<", "-", "0.999", ")", ".", "float", "(", ")", "\n", "log_probs", "=", "cond", "*", "log_cdf_plus", "+", "(", "1.", "-", "cond", ")", "*", "inner_out", "\n", "\n", "log_probs", "=", "log_probs", "+", "F", ".", "log_softmax", "(", "logit_probs", ",", "-", "1", ")", "\n", "\n", "if", "reduce", ":", "\n", "        ", "return", "-", "torch", ".", "sum", "(", "log_sum_exp", "(", "log_probs", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "-", "log_sum_exp", "(", "log_probs", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.to_one_hot": [[108, 115], ["torch.FloatTensor().zero_", "one_hot.cuda.scatter_", "one_hot.cuda.cuda", "len", "tensor.unsqueeze", "torch.FloatTensor", "tensor.size", "tensor.size"], "function", ["None"], ["", "", "def", "to_one_hot", "(", "tensor", ",", "n", ",", "fill_with", "=", "1.", ")", ":", "\n", "# we perform one hot encore with respect to the last axis", "\n", "    ", "one_hot", "=", "torch", ".", "FloatTensor", "(", "tensor", ".", "size", "(", ")", "+", "(", "n", ",", ")", ")", ".", "zero_", "(", ")", "\n", "if", "tensor", ".", "is_cuda", ":", "\n", "        ", "one_hot", "=", "one_hot", ".", "cuda", "(", ")", "\n", "", "one_hot", ".", "scatter_", "(", "len", "(", "tensor", ".", "size", "(", ")", ")", ",", "tensor", ".", "unsqueeze", "(", "-", "1", ")", ",", "fill_with", ")", "\n", "return", "one_hot", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.sample_from_discretized_mix_logistic": [[117, 154], ["y.transpose.transpose", "logit_probs.data.new().uniform_", "logit_probs.data.new().uniform_.max", "mixture.to_one_hot", "torch.sum", "torch.clamp", "torch.sum.data.new().uniform_", "torch.clamp", "y.transpose.size", "torch.log", "torch.sum", "torch.clamp", "y.transpose.size", "logit_probs.data.new", "torch.sum.data.new", "torch.exp", "logit_probs.size", "torch.log", "torch.sum.size", "torch.log", "torch.log"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.to_one_hot"], ["", "def", "sample_from_discretized_mix_logistic", "(", "y", ",", "log_scale_min", "=", "-", "7.0", ")", ":", "\n", "    ", "\"\"\"\n    Sample from discretized mixture of logistic distributions\n\n    Args:\n        y (Tensor): B x C x T\n        log_scale_min (float): Log scale minimum value\n\n    Returns:\n        Tensor: sample in range of [-1, 1].\n    \"\"\"", "\n", "assert", "y", ".", "size", "(", "1", ")", "%", "3", "==", "0", "\n", "nr_mix", "=", "y", ".", "size", "(", "1", ")", "//", "3", "\n", "\n", "# B x T x C", "\n", "y", "=", "y", ".", "transpose", "(", "1", ",", "2", ")", "\n", "logit_probs", "=", "y", "[", ":", ",", ":", ",", ":", "nr_mix", "]", "\n", "\n", "# sample mixture indicator from softmax", "\n", "temp", "=", "logit_probs", ".", "data", ".", "new", "(", "logit_probs", ".", "size", "(", ")", ")", ".", "uniform_", "(", "1e-5", ",", "1.0", "-", "1e-5", ")", "\n", "temp", "=", "logit_probs", ".", "data", "-", "torch", ".", "log", "(", "-", "torch", ".", "log", "(", "temp", ")", ")", "\n", "_", ",", "argmax", "=", "temp", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "\n", "# (B, T) -> (B, T, nr_mix)", "\n", "one_hot", "=", "to_one_hot", "(", "argmax", ",", "nr_mix", ")", "\n", "# select logistic parameters", "\n", "means", "=", "torch", ".", "sum", "(", "y", "[", ":", ",", ":", ",", "nr_mix", ":", "2", "*", "nr_mix", "]", "*", "one_hot", ",", "dim", "=", "-", "1", ")", "\n", "log_scales", "=", "torch", ".", "clamp", "(", "torch", ".", "sum", "(", "\n", "y", "[", ":", ",", ":", ",", "2", "*", "nr_mix", ":", "3", "*", "nr_mix", "]", "*", "one_hot", ",", "dim", "=", "-", "1", ")", ",", "min", "=", "log_scale_min", ")", "\n", "# sample from logistic & clip to interval", "\n", "# we don't actually round to the nearest 8bit value when sampling", "\n", "u", "=", "means", ".", "data", ".", "new", "(", "means", ".", "size", "(", ")", ")", ".", "uniform_", "(", "1e-5", ",", "1.0", "-", "1e-5", ")", "\n", "x", "=", "means", "+", "torch", ".", "exp", "(", "log_scales", ")", "*", "(", "torch", ".", "log", "(", "u", ")", "-", "torch", ".", "log", "(", "1.", "-", "u", ")", ")", "\n", "\n", "x", "=", "torch", ".", "clamp", "(", "torch", ".", "clamp", "(", "x", ",", "min", "=", "-", "1.", ")", ",", "max", "=", "1.", ")", "\n", "\n", "return", "x", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ResidualConv1dGLU.__init__": [[82, 130], ["torch.nn.Module.__init__", "modules.Conv1d1x1", "modules.Conv1d1x1", "modules.Conv1d", "wavenet_vocoder.conv.Conv1d", "modules.Conv1d1x1", "modules.Conv1d1x1"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1"], ["def", "__init__", "(", "self", ",", "residual_channels", ",", "gate_channels", ",", "kernel_size", ",", "\n", "skip_out_channels", "=", "None", ",", "\n", "cin_channels", "=", "-", "1", ",", "gin_channels", "=", "-", "1", ",", "\n", "dropout", "=", "1", "-", "0.95", ",", "padding", "=", "None", ",", "dilation", "=", "1", ",", "causal", "=", "True", ",", "\n", "bias", "=", "True", ",", "weight_normalization", "=", "True", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", "ResidualConv1dGLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "dropout", "=", "dropout", "\n", "if", "skip_out_channels", "is", "None", ":", "\n", "            ", "skip_out_channels", "=", "residual_channels", "\n", "", "if", "padding", "is", "None", ":", "\n", "# no future time stamps available", "\n", "            ", "if", "causal", ":", "\n", "                ", "padding", "=", "(", "kernel_size", "-", "1", ")", "*", "dilation", "\n", "", "else", ":", "\n", "                ", "padding", "=", "(", "kernel_size", "-", "1", ")", "//", "2", "*", "dilation", "\n", "", "", "self", ".", "causal", "=", "causal", "\n", "\n", "if", "weight_normalization", ":", "\n", "            ", "assert", "bias", "\n", "self", ".", "conv", "=", "Conv1d", "(", "residual_channels", ",", "gate_channels", ",", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ",", "std_mul", "=", "1.0", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv", "=", "conv", ".", "Conv1d", "(", "residual_channels", ",", "gate_channels", ",", "kernel_size", ",", "\n", "padding", "=", "padding", ",", "dilation", "=", "dilation", ",", "\n", "bias", "=", "bias", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "\n", "# local conditioning", "\n", "", "if", "cin_channels", ">", "0", ":", "\n", "            ", "self", ".", "conv1x1c", "=", "Conv1d1x1", "(", "cin_channels", ",", "gate_channels", ",", "\n", "bias", "=", "bias", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1x1c", "=", "None", "\n", "\n", "# global conditioning", "\n", "", "if", "gin_channels", ">", "0", ":", "\n", "            ", "self", ".", "conv1x1g", "=", "Conv1d1x1", "(", "gin_channels", ",", "gate_channels", ",", "bias", "=", "bias", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "conv1x1g", "=", "None", "\n", "\n", "# conv output is split into two groups", "\n", "", "gate_out_channels", "=", "gate_channels", "//", "2", "\n", "self", ".", "conv1x1_out", "=", "Conv1d1x1", "(", "gate_out_channels", ",", "residual_channels", ",", "bias", "=", "bias", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", "\n", "self", ".", "conv1x1_skip", "=", "Conv1d1x1", "(", "gate_out_channels", ",", "skip_out_channels", ",", "bias", "=", "bias", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ResidualConv1dGLU.forward": [[131, 133], ["modules.ResidualConv1dGLU._forward"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ResidualConv1dGLU._forward"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "g", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "_forward", "(", "x", ",", "c", ",", "g", ",", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ResidualConv1dGLU.incremental_forward": [[134, 136], ["modules.ResidualConv1dGLU._forward"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ResidualConv1dGLU._forward"], ["", "def", "incremental_forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "g", "=", "None", ")", ":", "\n", "        ", "return", "self", ".", "_forward", "(", "x", ",", "c", ",", "g", ",", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ResidualConv1dGLU._forward": [[137, 186], ["torch.nn.functional.dropout", "modules.ResidualConv1dGLU.split", "modules._conv1x1_forward", "modules._conv1x1_forward", "modules.ResidualConv1dGLU.conv.incremental_forward", "modules.ResidualConv1dGLU.conv", "modules._conv1x1_forward", "_conv1x1_forward.split", "modules._conv1x1_forward", "_conv1x1_forward.split", "torch.nn.functional.tanh", "torch.nn.functional.sigmoid", "math.sqrt", "modules.ResidualConv1dGLU.size", "_conv1x1_forward.size", "_conv1x1_forward.size", "residual.size"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules._conv1x1_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules._conv1x1_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules._conv1x1_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules._conv1x1_forward"], ["", "def", "_forward", "(", "self", ",", "x", ",", "c", ",", "g", ",", "is_incremental", ")", ":", "\n", "        ", "\"\"\"Forward\n\n        Args:\n            x (Tensor): B x C x T\n            c (Tensor): B x C x T, Local conditioning features\n            g (Tensor): B x C x T, Expanded global conditioning features\n            is_incremental (Bool) : Whether incremental mode or not\n\n        Returns:\n            Tensor: output\n        \"\"\"", "\n", "residual", "=", "x", "\n", "x", "=", "F", ".", "dropout", "(", "x", ",", "p", "=", "self", ".", "dropout", ",", "training", "=", "self", ".", "training", ")", "\n", "if", "is_incremental", ":", "\n", "            ", "splitdim", "=", "-", "1", "\n", "x", "=", "self", ".", "conv", ".", "incremental_forward", "(", "x", ")", "\n", "", "else", ":", "\n", "            ", "splitdim", "=", "1", "\n", "x", "=", "self", ".", "conv", "(", "x", ")", "\n", "# remove future time steps", "\n", "x", "=", "x", "[", ":", ",", ":", ",", ":", "residual", ".", "size", "(", "-", "1", ")", "]", "if", "self", ".", "causal", "else", "x", "\n", "\n", "", "a", ",", "b", "=", "x", ".", "split", "(", "x", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "\n", "\n", "# local conditioning", "\n", "if", "c", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "conv1x1c", "is", "not", "None", "\n", "c", "=", "_conv1x1_forward", "(", "self", ".", "conv1x1c", ",", "c", ",", "is_incremental", ")", "\n", "ca", ",", "cb", "=", "c", ".", "split", "(", "c", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "\n", "a", ",", "b", "=", "a", "+", "ca", ",", "b", "+", "cb", "\n", "\n", "# global conditioning", "\n", "", "if", "g", "is", "not", "None", ":", "\n", "            ", "assert", "self", ".", "conv1x1g", "is", "not", "None", "\n", "g", "=", "_conv1x1_forward", "(", "self", ".", "conv1x1g", ",", "g", ",", "is_incremental", ")", "\n", "ga", ",", "gb", "=", "g", ".", "split", "(", "g", ".", "size", "(", "splitdim", ")", "//", "2", ",", "dim", "=", "splitdim", ")", "\n", "a", ",", "b", "=", "a", "+", "ga", ",", "b", "+", "gb", "\n", "\n", "", "x", "=", "F", ".", "tanh", "(", "a", ")", "*", "F", ".", "sigmoid", "(", "b", ")", "\n", "\n", "# For skip connection", "\n", "s", "=", "_conv1x1_forward", "(", "self", ".", "conv1x1_skip", ",", "x", ",", "is_incremental", ")", "\n", "\n", "# For residual connection", "\n", "x", "=", "_conv1x1_forward", "(", "self", ".", "conv1x1_out", ",", "x", ",", "is_incremental", ")", "\n", "\n", "x", "=", "(", "x", "+", "residual", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "return", "x", ",", "s", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ResidualConv1dGLU.clear_buffer": [[187, 192], ["modules.ResidualConv1dGLU.conv.clear_buffer"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer"], ["", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "for", "conv", "in", "[", "self", ".", "conv", ",", "self", ".", "conv1x1_out", ",", "self", ".", "conv1x1_skip", ",", "\n", "self", ".", "conv1x1c", ",", "self", ".", "conv1x1g", "]", ":", "\n", "            ", "if", "conv", "is", "not", "None", ":", "\n", "                ", "self", ".", "conv", ".", "clear_buffer", "(", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d": [[13, 19], ["wavenet_vocoder.conv.Conv1d", "math.sqrt", "conv.Conv1d.weight.data.normal_", "conv.Conv1d.bias.data.zero_", "torch.nn.utils.weight_norm"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d"], ["def", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "dropout", "=", "0", ",", "std_mul", "=", "4.0", ",", "**", "kwargs", ")", ":", "\n", "    ", "m", "=", "conv", ".", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "std", "=", "math", ".", "sqrt", "(", "(", "std_mul", "*", "(", "1.0", "-", "dropout", ")", ")", "/", "(", "m", ".", "kernel_size", "[", "0", "]", "*", "in_channels", ")", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "mean", "=", "0", ",", "std", "=", "std", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Embedding": [[21, 25], ["torch.nn.Embedding", "nn.Embedding.weight.data.normal_"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Embedding"], ["", "def", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", ",", "std", "=", "0.01", ")", ":", "\n", "    ", "m", "=", "nn", ".", "Embedding", "(", "num_embeddings", ",", "embedding_dim", ",", "padding_idx", "=", "padding_idx", ")", "\n", "m", ".", "weight", ".", "data", ".", "normal_", "(", "0", ",", "std", ")", "\n", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ConvTranspose2d": [[27, 37], ["torch.nn.ConvTranspose2d", "nn.ConvTranspose2d.weight.data.fill_", "nn.ConvTranspose2d.bias.data.zero_", "torch.nn.utils.weight_norm"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ConvTranspose2d"], ["", "def", "ConvTranspose2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "\n", "weight_normalization", "=", "True", ",", "**", "kwargs", ")", ":", "\n", "    ", "freq_axis_kernel_size", "=", "kernel_size", "[", "0", "]", "\n", "m", "=", "nn", ".", "ConvTranspose2d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", ",", "**", "kwargs", ")", "\n", "m", ".", "weight", ".", "data", ".", "fill_", "(", "1.0", "/", "freq_axis_kernel_size", ")", "\n", "m", ".", "bias", ".", "data", ".", "zero_", "(", ")", "\n", "if", "weight_normalization", ":", "\n", "        ", "return", "nn", ".", "utils", ".", "weight_norm", "(", "m", ")", "\n", "", "else", ":", "\n", "        ", "return", "m", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1": [[39, 49], ["modules.Conv1d", "wavenet_vocoder.conv.Conv1d"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d"], ["", "", "def", "Conv1d1x1", "(", "in_channels", ",", "out_channels", ",", "bias", "=", "True", ",", "weight_normalization", "=", "True", ")", ":", "\n", "    ", "\"\"\"1-by-1 convolution layer\n    \"\"\"", "\n", "if", "weight_normalization", ":", "\n", "        ", "assert", "bias", "\n", "return", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "bias", "=", "bias", ",", "std_mul", "=", "1.0", ")", "\n", "", "else", ":", "\n", "        ", "return", "conv", ".", "Conv1d", "(", "in_channels", ",", "out_channels", ",", "kernel_size", "=", "1", ",", "padding", "=", "0", ",", "\n", "dilation", "=", "1", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules._conv1x1_forward": [[51, 59], ["wavenet_vocoder.conv.incremental_forward", "wavenet_vocoder.conv"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward"], ["", "", "def", "_conv1x1_forward", "(", "conv", ",", "x", ",", "is_incremental", ")", ":", "\n", "    ", "\"\"\"Conv1x1 forward\n    \"\"\"", "\n", "if", "is_incremental", ":", "\n", "        ", "x", "=", "conv", ".", "incremental_forward", "(", "x", ")", "\n", "", "else", ":", "\n", "        ", "x", "=", "conv", "(", "x", ")", "\n", "", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.conv.Conv1d.__init__": [[11, 16], ["torch.nn.Conv1d.__init__", "conv.Conv1d.clear_buffer", "conv.Conv1d.register_backward_hook"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer"], ["def", "__init__", "(", "self", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "*", "args", ",", "**", "kwargs", ")", "\n", "self", ".", "clear_buffer", "(", ")", "\n", "self", ".", "_linearized_weight", "=", "None", "\n", "self", ".", "register_backward_hook", "(", "self", ".", "_clear_linearized_weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.conv.Conv1d.incremental_forward": [[17, 47], ["conv.Conv1d._forward_pre_hooks.values", "conv.Conv1d._get_linearized_weight", "input[].contiguous.size", "torch.nn.functional.linear", "torch.nn.functional.linear.view", "RuntimeError", "hook", "input[].contiguous.view", "input[].contiguous.new", "conv.Conv1d.input_buffer.zero_", "conv.Conv1d.input_buffer[].clone", "input[].contiguous", "input[].contiguous.size"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.conv.Conv1d._get_linearized_weight"], ["", "def", "incremental_forward", "(", "self", ",", "input", ")", ":", "\n", "# input: (B, T, C)", "\n", "        ", "if", "self", ".", "training", ":", "\n", "            ", "raise", "RuntimeError", "(", "'incremental_forward only supports eval mode'", ")", "\n", "\n", "# run forward pre hooks (e.g., weight norm)", "\n", "", "for", "hook", "in", "self", ".", "_forward_pre_hooks", ".", "values", "(", ")", ":", "\n", "            ", "hook", "(", "self", ",", "input", ")", "\n", "\n", "# reshape weight", "\n", "", "weight", "=", "self", ".", "_get_linearized_weight", "(", ")", "\n", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "dilation", "=", "self", ".", "dilation", "[", "0", "]", "\n", "\n", "bsz", "=", "input", ".", "size", "(", "0", ")", "# input: bsz x len x dim", "\n", "if", "kw", ">", "1", ":", "\n", "            ", "input", "=", "input", ".", "data", "\n", "if", "self", ".", "input_buffer", "is", "None", ":", "\n", "                ", "self", ".", "input_buffer", "=", "input", ".", "new", "(", "bsz", ",", "kw", "+", "(", "kw", "-", "1", ")", "*", "(", "dilation", "-", "1", ")", ",", "input", ".", "size", "(", "2", ")", ")", "\n", "self", ".", "input_buffer", ".", "zero_", "(", ")", "\n", "", "else", ":", "\n", "# shift buffer", "\n", "                ", "self", ".", "input_buffer", "[", ":", ",", ":", "-", "1", ",", ":", "]", "=", "self", ".", "input_buffer", "[", ":", ",", "1", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "# append next input", "\n", "", "self", ".", "input_buffer", "[", ":", ",", "-", "1", ",", ":", "]", "=", "input", "[", ":", ",", "-", "1", ",", ":", "]", "\n", "input", "=", "self", ".", "input_buffer", "\n", "if", "dilation", ">", "1", ":", "\n", "                ", "input", "=", "input", "[", ":", ",", "0", ":", ":", "dilation", ",", ":", "]", ".", "contiguous", "(", ")", "\n", "", "", "output", "=", "F", ".", "linear", "(", "input", ".", "view", "(", "bsz", ",", "-", "1", ")", ",", "weight", ",", "self", ".", "bias", ")", "\n", "return", "output", ".", "view", "(", "bsz", ",", "1", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.conv.Conv1d.clear_buffer": [[48, 50], ["None"], "methods", ["None"], ["", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "self", ".", "input_buffer", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.conv.Conv1d._get_linearized_weight": [[51, 63], ["conv.Conv1d.view", "conv.Conv1d.weight.size", "conv.Conv1d.weight.transpose().contiguous", "conv.Conv1d.weight.transpose().transpose().contiguous", "conv.Conv1d.size", "conv.Conv1d.weight.transpose", "conv.Conv1d.weight.transpose().transpose", "conv.Conv1d.weight.transpose"], "methods", ["None"], ["", "def", "_get_linearized_weight", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "_linearized_weight", "is", "None", ":", "\n", "            ", "kw", "=", "self", ".", "kernel_size", "[", "0", "]", "\n", "# nn.Conv1d", "\n", "if", "self", ".", "weight", ".", "size", "(", ")", "==", "(", "self", ".", "out_channels", ",", "self", ".", "in_channels", ",", "kw", ")", ":", "\n", "                ", "weight", "=", "self", ".", "weight", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "# fairseq.modules.conv_tbc.ConvTBC", "\n", "                ", "weight", "=", "self", ".", "weight", ".", "transpose", "(", "2", ",", "1", ")", ".", "transpose", "(", "1", ",", "0", ")", ".", "contiguous", "(", ")", "\n", "", "assert", "weight", ".", "size", "(", ")", "==", "(", "self", ".", "out_channels", ",", "kw", ",", "self", ".", "in_channels", ")", "\n", "self", ".", "_linearized_weight", "=", "weight", ".", "view", "(", "self", ".", "out_channels", ",", "-", "1", ")", "\n", "", "return", "self", ".", "_linearized_weight", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.conv.Conv1d._clear_linearized_weight": [[64, 66], ["None"], "methods", ["None"], ["", "def", "_clear_linearized_weight", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_linearized_weight", "=", "None", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.builder.wavenet": [[5, 41], ["WaveNet"], "function", ["None"], ["def", "wavenet", "(", "out_channels", "=", "256", ",", "\n", "layers", "=", "20", ",", "\n", "stacks", "=", "2", ",", "\n", "residual_channels", "=", "512", ",", "\n", "gate_channels", "=", "512", ",", "\n", "skip_out_channels", "=", "512", ",", "\n", "cin_channels", "=", "-", "1", ",", "\n", "gin_channels", "=", "-", "1", ",", "\n", "weight_normalization", "=", "True", ",", "\n", "dropout", "=", "1", "-", "0.95", ",", "\n", "kernel_size", "=", "3", ",", "\n", "n_speakers", "=", "None", ",", "\n", "upsample_conditional_features", "=", "False", ",", "\n", "upsample_scales", "=", "[", "16", ",", "16", "]", ",", "\n", "freq_axis_kernel_size", "=", "3", ",", "\n", "scalar_input", "=", "False", ",", "\n", "use_speaker_embedding", "=", "True", ",", "\n", ")", ":", "\n", "    ", "from", "wavenet_vocoder", "import", "WaveNet", "\n", "\n", "model", "=", "WaveNet", "(", "out_channels", "=", "out_channels", ",", "layers", "=", "layers", ",", "stacks", "=", "stacks", ",", "\n", "residual_channels", "=", "residual_channels", ",", "\n", "gate_channels", "=", "gate_channels", ",", "\n", "skip_out_channels", "=", "skip_out_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "dropout", "=", "dropout", ",", "\n", "weight_normalization", "=", "weight_normalization", ",", "\n", "cin_channels", "=", "cin_channels", ",", "gin_channels", "=", "gin_channels", ",", "\n", "n_speakers", "=", "n_speakers", ",", "\n", "upsample_conditional_features", "=", "upsample_conditional_features", ",", "\n", "upsample_scales", "=", "upsample_scales", ",", "\n", "freq_axis_kernel_size", "=", "freq_axis_kernel_size", ",", "\n", "scalar_input", "=", "scalar_input", ",", "\n", "use_speaker_embedding", "=", "use_speaker_embedding", ",", "\n", ")", "\n", "\n", "return", "model", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util._assert_valid_input_type": [[5, 7], ["None"], "function", ["None"], ["def", "_assert_valid_input_type", "(", "s", ")", ":", "\n", "    ", "assert", "s", "==", "\"mulaw-quantize\"", "or", "s", "==", "\"mulaw\"", "or", "s", "==", "\"raw\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw_quantize": [[9, 12], ["util._assert_valid_input_type"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util._assert_valid_input_type"], ["", "def", "is_mulaw_quantize", "(", "s", ")", ":", "\n", "    ", "_assert_valid_input_type", "(", "s", ")", "\n", "return", "s", "==", "\"mulaw-quantize\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw": [[14, 17], ["util._assert_valid_input_type"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util._assert_valid_input_type"], ["", "def", "is_mulaw", "(", "s", ")", ":", "\n", "    ", "_assert_valid_input_type", "(", "s", ")", "\n", "return", "s", "==", "\"mulaw\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_raw": [[19, 22], ["util._assert_valid_input_type"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util._assert_valid_input_type"], ["", "def", "is_raw", "(", "s", ")", ":", "\n", "    ", "_assert_valid_input_type", "(", "s", ")", "\n", "return", "s", "==", "\"raw\"", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_scalar_input": [[24, 26], ["util.is_raw", "util.is_mulaw"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_raw", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.util.is_mulaw"], ["", "def", "is_scalar_input", "(", "s", ")", ":", "\n", "    ", "return", "is_raw", "(", "s", ")", "or", "is_mulaw", "(", "s", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__": [[98, 168], ["torch.nn.Module.__init__", "torch.nn.ModuleList", "range", "torch.nn.ModuleList", "wavenet.receptive_field_size", "modules.Conv1d1x1", "modules.Conv1d1x1", "modules.ResidualConv1dGLU", "wavenet.WaveNet.conv_layers.append", "modules.Embedding", "torch.nn.ModuleList", "torch.nn.ReLU", "modules.Conv1d1x1", "torch.nn.ReLU", "modules.Conv1d1x1", "modules.ConvTranspose2d", "wavenet.WaveNet.upsample_conv.append", "wavenet.WaveNet.upsample_conv.append", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.__init__", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.receptive_field_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Embedding", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.Conv1d1x1", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.modules.ConvTranspose2d"], ["def", "__init__", "(", "self", ",", "out_channels", "=", "256", ",", "layers", "=", "20", ",", "stacks", "=", "2", ",", "\n", "residual_channels", "=", "512", ",", "\n", "gate_channels", "=", "512", ",", "\n", "skip_out_channels", "=", "512", ",", "\n", "kernel_size", "=", "3", ",", "dropout", "=", "1", "-", "0.95", ",", "\n", "cin_channels", "=", "-", "1", ",", "gin_channels", "=", "-", "1", ",", "n_speakers", "=", "None", ",", "\n", "weight_normalization", "=", "True", ",", "\n", "upsample_conditional_features", "=", "False", ",", "\n", "upsample_scales", "=", "None", ",", "\n", "freq_axis_kernel_size", "=", "3", ",", "\n", "scalar_input", "=", "False", ",", "\n", "use_speaker_embedding", "=", "True", ",", "\n", ")", ":", "\n", "        ", "super", "(", "WaveNet", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "scalar_input", "=", "scalar_input", "\n", "self", ".", "out_channels", "=", "out_channels", "\n", "self", ".", "cin_channels", "=", "cin_channels", "\n", "assert", "layers", "%", "stacks", "==", "0", "\n", "layers_per_stack", "=", "layers", "//", "stacks", "\n", "if", "scalar_input", ":", "\n", "            ", "self", ".", "first_conv", "=", "Conv1d1x1", "(", "1", ",", "residual_channels", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "first_conv", "=", "Conv1d1x1", "(", "out_channels", ",", "residual_channels", ")", "\n", "\n", "", "self", ".", "conv_layers", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "layer", "in", "range", "(", "layers", ")", ":", "\n", "            ", "dilation", "=", "2", "**", "(", "layer", "%", "layers_per_stack", ")", "\n", "conv", "=", "ResidualConv1dGLU", "(", "\n", "residual_channels", ",", "gate_channels", ",", "\n", "kernel_size", "=", "kernel_size", ",", "\n", "skip_out_channels", "=", "skip_out_channels", ",", "\n", "bias", "=", "True", ",", "# magenda uses bias, but musyoku doesn't", "\n", "dilation", "=", "dilation", ",", "dropout", "=", "dropout", ",", "\n", "cin_channels", "=", "cin_channels", ",", "\n", "gin_channels", "=", "gin_channels", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", "\n", "self", ".", "conv_layers", ".", "append", "(", "conv", ")", "\n", "", "self", ".", "last_conv_layers", "=", "nn", ".", "ModuleList", "(", "[", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "skip_out_channels", ",", "skip_out_channels", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", ",", "\n", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ",", "\n", "Conv1d1x1", "(", "skip_out_channels", ",", "out_channels", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", ",", "\n", "]", ")", "\n", "\n", "if", "gin_channels", ">", "0", "and", "use_speaker_embedding", ":", "\n", "            ", "assert", "n_speakers", "is", "not", "None", "\n", "self", ".", "embed_speakers", "=", "Embedding", "(", "\n", "n_speakers", ",", "gin_channels", ",", "padding_idx", "=", "None", ",", "std", "=", "0.1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "embed_speakers", "=", "None", "\n", "\n", "# Upsample conv net", "\n", "", "if", "upsample_conditional_features", ":", "\n", "            ", "self", ".", "upsample_conv", "=", "nn", ".", "ModuleList", "(", ")", "\n", "for", "s", "in", "upsample_scales", ":", "\n", "                ", "freq_axis_padding", "=", "(", "freq_axis_kernel_size", "-", "1", ")", "//", "2", "\n", "convt", "=", "ConvTranspose2d", "(", "1", ",", "1", ",", "(", "freq_axis_kernel_size", ",", "s", ")", ",", "\n", "padding", "=", "(", "freq_axis_padding", ",", "0", ")", ",", "\n", "dilation", "=", "1", ",", "stride", "=", "(", "1", ",", "s", ")", ",", "\n", "weight_normalization", "=", "weight_normalization", ")", "\n", "self", ".", "upsample_conv", ".", "append", "(", "convt", ")", "\n", "# assuming we use [0, 1] scaled features", "\n", "# this should avoid non-negative upsampling output", "\n", "self", ".", "upsample_conv", ".", "append", "(", "nn", ".", "ReLU", "(", "inplace", "=", "True", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "upsample_conv", "=", "None", "\n", "\n", "", "self", ".", "receptive_field", "=", "receptive_field_size", "(", "layers", ",", "stacks", ",", "kernel_size", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.has_speaker_embedding": [[169, 171], ["None"], "methods", ["None"], ["", "def", "has_speaker_embedding", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "embed_speakers", "is", "not", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.local_conditioning_enabled": [[172, 174], ["None"], "methods", ["None"], ["", "def", "local_conditioning_enabled", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "cin_channels", ">", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.forward": [[175, 234], ["f.size", "wavenet._expand_global_features", "wavenet.WaveNet.first_conv", "f.unsqueeze", "f.squeeze", "f", "f", "torch.nn.functional.softmax", "wavenet.WaveNet.embed_speakers", "g.transpose.transpose.transpose", "f", "f.size", "f.size", "math.sqrt", "g.transpose.transpose.view", "g.transpose.transpose.dim"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet._expand_global_features"], ["", "def", "forward", "(", "self", ",", "x", ",", "c", "=", "None", ",", "g", "=", "None", ",", "softmax", "=", "False", ")", ":", "\n", "        ", "\"\"\"Forward step\n\n        Args:\n            x (Tensor): One-hot encoded audio signal, shape (B x C x T)\n            c (Tensor): Local conditioning features,\n              shape (B x cin_channels x T)\n            g (Tensor): Global conditioning features,\n              shape (B x gin_channels x 1) or speaker Ids of shape (B x 1).\n              Note that ``self.use_speaker_embedding`` must be False when you\n              want to disable embedding layer and use external features\n              directly (e.g., one-hot vector).\n              Also type of input tensor must be FloatTensor, not LongTensor\n              in case of ``self.use_speaker_embedding`` equals False.\n            softmax (bool): Whether applies softmax or not.\n\n        Returns:\n            Tensor: output, shape B x out_channels x T\n        \"\"\"", "\n", "B", ",", "_", ",", "T", "=", "x", ".", "size", "(", ")", "\n", "\n", "if", "g", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "embed_speakers", "is", "not", "None", ":", "\n", "# (B x 1) -> (B x 1 x gin_channels)", "\n", "                ", "g", "=", "self", ".", "embed_speakers", "(", "g", ".", "view", "(", "B", ",", "-", "1", ")", ")", "\n", "# (B x gin_channels x 1)", "\n", "g", "=", "g", ".", "transpose", "(", "1", ",", "2", ")", "\n", "assert", "g", ".", "dim", "(", ")", "==", "3", "\n", "# Expand global conditioning features to all time steps", "\n", "", "", "g_bct", "=", "_expand_global_features", "(", "B", ",", "T", ",", "g", ",", "bct", "=", "True", ")", "\n", "\n", "if", "c", "is", "not", "None", "and", "self", ".", "upsample_conv", "is", "not", "None", ":", "\n", "# B x 1 x C x T", "\n", "            ", "c", "=", "c", ".", "unsqueeze", "(", "1", ")", "\n", "for", "f", "in", "self", ".", "upsample_conv", ":", "\n", "                ", "c", "=", "f", "(", "c", ")", "\n", "# B x C x T", "\n", "", "c", "=", "c", ".", "squeeze", "(", "1", ")", "\n", "assert", "c", ".", "size", "(", "-", "1", ")", "==", "x", ".", "size", "(", "-", "1", ")", "\n", "\n", "# Feed data to network", "\n", "", "x", "=", "self", ".", "first_conv", "(", "x", ")", "\n", "skips", "=", "None", "\n", "for", "f", "in", "self", ".", "conv_layers", ":", "\n", "            ", "x", ",", "h", "=", "f", "(", "x", ",", "c", ",", "g_bct", ")", "\n", "if", "skips", "is", "None", ":", "\n", "                ", "skips", "=", "h", "\n", "", "else", ":", "\n", "                ", "skips", "+=", "h", "\n", "skips", "*=", "math", ".", "sqrt", "(", "0.5", ")", "\n", "# skips = h if skips is None else (skips + h) * math.sqrt(0.5)", "\n", "\n", "", "", "x", "=", "skips", "\n", "for", "f", "in", "self", ".", "last_conv_layers", ":", "\n", "            ", "x", "=", "f", "(", "x", ")", "\n", "\n", "", "x", "=", "F", ".", "softmax", "(", "x", ",", "dim", "=", "1", ")", "if", "softmax", "else", "x", "\n", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward": [[235, 363], ["wavenet.WaveNet.clear_buffer", "int", "wavenet._expand_global_features", "tqdm", "torch.stack", "outputs.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose().transpose().contiguous", "wavenet.WaveNet.clear_buffer", "test_inputs.transpose().contiguous.transpose().contiguous.size", "f.unsqueeze", "f.squeeze", "f.transpose().contiguous", "range", "wavenet.WaveNet.first_conv.incremental_forward", "test_inputs.transpose().contiguous.transpose().contiguous.size", "max", "wavenet.WaveNet.embed_speakers", "g.transpose.transpose.transpose", "f", "f.size", "f.size", "torch.zeros", "torch.zeros", "next", "initial_input.transpose().contiguous.transpose().contiguous.cuda", "initial_input.transpose().contiguous.transpose().contiguous.size", "initial_input.transpose().contiguous.transpose().contiguous.transpose().contiguous", "test_inputs[].unsqueeze", "c[].unsqueeze", "g_btc[].unsqueeze", "f.incremental_forward", "mixture.sample_from_discretized_mix_logistic", "outputs.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose().transpose", "test_inputs.transpose().contiguous.transpose().contiguous.size", "test_inputs.transpose().contiguous.transpose().contiguous.transpose().contiguous", "test_inputs.transpose().contiguous.transpose().contiguous.size", "test_inputs.transpose().contiguous.transpose().contiguous.transpose().contiguous", "test_inputs.transpose().contiguous.transpose().contiguous.size", "g.transpose.transpose.view", "g.transpose.transpose.dim", "f.transpose", "wavenet.WaveNet.parameters", "test_inputs.transpose().contiguous.transpose().contiguous.size", "f.incremental_forward", "f.view", "torch.nn.functional.softmax", "f.view", "numpy.random.choice", "f.zero_", "initial_input.transpose().contiguous.transpose().contiguous.transpose", "math.sqrt", "f", "f.view", "numpy.arange", "outputs.transpose().transpose().contiguous.transpose().transpose().contiguous.transpose", "test_inputs.transpose().contiguous.transpose().contiguous.transpose", "test_inputs.transpose().contiguous.transpose().contiguous.transpose", "f.view().data.cpu().numpy", "f.view().data.cpu", "f.view"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet._expand_global_features", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.sample_from_discretized_mix_logistic", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward"], ["", "def", "incremental_forward", "(", "self", ",", "initial_input", "=", "None", ",", "c", "=", "None", ",", "g", "=", "None", ",", "\n", "T", "=", "100", ",", "test_inputs", "=", "None", ",", "\n", "tqdm", "=", "lambda", "x", ":", "x", ",", "softmax", "=", "True", ",", "quantize", "=", "True", ",", "\n", "log_scale_min", "=", "-", "7.0", ")", ":", "\n", "        ", "\"\"\"Incremental forward step\n\n        Due to linearized convolutions, inputs of shape (B x C x T) are reshaped\n        to (B x T x C) internally and fed to the network for each time step.\n        Input of each time step will be of shape (B x 1 x C).\n\n        Args:\n            initial_input (Tensor): Initial decoder input, (B x C x 1)\n            c (Tensor): Local conditioning features, shape (B x C' x T)\n            g (Tensor): Global conditioning features, shape (B x C'' or B x C''x 1)\n            T (int): Number of time steps to generate.\n            test_inputs (Tensor): Teacher forcing inputs (for debugging)\n            tqdm (lamda) : tqdm\n            softmax (bool) : Whether applies softmax or not\n            quantize (bool): Whether quantize softmax output before feeding the\n              network output to input for the next time step. TODO: rename\n            log_scale_min (float):  Log scale minimum value.\n\n        Returns:\n            Tensor: Generated one-hot encoded samples. B x C x T\u3000\n              or scaler vector B x 1 x T\n        \"\"\"", "\n", "self", ".", "clear_buffer", "(", ")", "\n", "B", "=", "1", "\n", "\n", "# Note: shape should be **(B x T x C)**, not (B x C x T) opposed to", "\n", "# batch forward due to linealized convolution", "\n", "if", "test_inputs", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "scalar_input", ":", "\n", "                ", "if", "test_inputs", ".", "size", "(", "1", ")", "==", "1", ":", "\n", "                    ", "test_inputs", "=", "test_inputs", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "", "", "else", ":", "\n", "                ", "if", "test_inputs", ".", "size", "(", "1", ")", "==", "self", ".", "out_channels", ":", "\n", "                    ", "test_inputs", "=", "test_inputs", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "", "B", "=", "test_inputs", ".", "size", "(", "0", ")", "\n", "if", "T", "is", "None", ":", "\n", "                ", "T", "=", "test_inputs", ".", "size", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "T", "=", "max", "(", "T", ",", "test_inputs", ".", "size", "(", "1", ")", ")", "\n", "# cast to int in case of numpy.int64...", "\n", "", "", "T", "=", "int", "(", "T", ")", "\n", "\n", "# Global conditioning", "\n", "if", "g", "is", "not", "None", ":", "\n", "            ", "if", "self", ".", "embed_speakers", "is", "not", "None", ":", "\n", "                ", "g", "=", "self", ".", "embed_speakers", "(", "g", ".", "view", "(", "B", ",", "-", "1", ")", ")", "\n", "# (B x gin_channels, 1)", "\n", "g", "=", "g", ".", "transpose", "(", "1", ",", "2", ")", "\n", "assert", "g", ".", "dim", "(", ")", "==", "3", "\n", "", "", "g_btc", "=", "_expand_global_features", "(", "B", ",", "T", ",", "g", ",", "bct", "=", "False", ")", "\n", "\n", "# Local conditioning", "\n", "if", "c", "is", "not", "None", "and", "self", ".", "upsample_conv", "is", "not", "None", ":", "\n", "            ", "assert", "c", "is", "not", "None", "\n", "# B x 1 x C x T", "\n", "c", "=", "c", ".", "unsqueeze", "(", "1", ")", "\n", "for", "f", "in", "self", ".", "upsample_conv", ":", "\n", "                ", "c", "=", "f", "(", "c", ")", "\n", "# B x C x T", "\n", "", "c", "=", "c", ".", "squeeze", "(", "1", ")", "\n", "assert", "c", ".", "size", "(", "-", "1", ")", "==", "T", "\n", "", "if", "c", "is", "not", "None", "and", "c", ".", "size", "(", "-", "1", ")", "==", "T", ":", "\n", "            ", "c", "=", "c", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "outputs", "=", "[", "]", "\n", "if", "initial_input", "is", "None", ":", "\n", "            ", "if", "self", ".", "scalar_input", ":", "\n", "                ", "initial_input", "=", "torch", ".", "zeros", "(", "B", ",", "1", ",", "1", ")", "\n", "", "else", ":", "\n", "                ", "initial_input", "=", "torch", ".", "zeros", "(", "B", ",", "1", ",", "self", ".", "out_channels", ")", "\n", "initial_input", "[", ":", ",", ":", ",", "127", "]", "=", "1", "# TODO: is this ok?", "\n", "# https://github.com/pytorch/pytorch/issues/584#issuecomment-275169567", "\n", "", "if", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "is_cuda", ":", "\n", "                ", "initial_input", "=", "initial_input", ".", "cuda", "(", ")", "\n", "", "", "else", ":", "\n", "            ", "if", "initial_input", ".", "size", "(", "1", ")", "==", "self", ".", "out_channels", ":", "\n", "                ", "initial_input", "=", "initial_input", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "", "", "current_input", "=", "initial_input", "\n", "\n", "for", "t", "in", "tqdm", "(", "range", "(", "T", ")", ")", ":", "\n", "            ", "if", "test_inputs", "is", "not", "None", "and", "t", "<", "test_inputs", ".", "size", "(", "1", ")", ":", "\n", "                ", "current_input", "=", "test_inputs", "[", ":", ",", "t", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "if", "t", ">", "0", ":", "\n", "                    ", "current_input", "=", "outputs", "[", "-", "1", "]", "\n", "\n", "# Conditioning features for single time step", "\n", "", "", "ct", "=", "None", "if", "c", "is", "None", "else", "c", "[", ":", ",", "t", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "gt", "=", "None", "if", "g", "is", "None", "else", "g_btc", "[", ":", ",", "t", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "x", "=", "current_input", "\n", "x", "=", "self", ".", "first_conv", ".", "incremental_forward", "(", "x", ")", "\n", "skips", "=", "None", "\n", "for", "f", "in", "self", ".", "conv_layers", ":", "\n", "                ", "x", ",", "h", "=", "f", ".", "incremental_forward", "(", "x", ",", "ct", ",", "gt", ")", "\n", "skips", "=", "h", "if", "skips", "is", "None", "else", "(", "skips", "+", "h", ")", "*", "math", ".", "sqrt", "(", "0.5", ")", "\n", "", "x", "=", "skips", "\n", "for", "f", "in", "self", ".", "last_conv_layers", ":", "\n", "                ", "try", ":", "\n", "                    ", "x", "=", "f", ".", "incremental_forward", "(", "x", ")", "\n", "", "except", "AttributeError", ":", "\n", "                    ", "x", "=", "f", "(", "x", ")", "\n", "\n", "# Generate next input by sampling", "\n", "", "", "if", "self", ".", "scalar_input", ":", "\n", "                ", "x", "=", "sample_from_discretized_mix_logistic", "(", "\n", "x", ".", "view", "(", "B", ",", "-", "1", ",", "1", ")", ",", "log_scale_min", "=", "log_scale_min", ")", "\n", "", "else", ":", "\n", "                ", "x", "=", "F", ".", "softmax", "(", "x", ".", "view", "(", "B", ",", "-", "1", ")", ",", "dim", "=", "1", ")", "if", "softmax", "else", "x", ".", "view", "(", "B", ",", "-", "1", ")", "\n", "if", "quantize", ":", "\n", "                    ", "sample", "=", "np", ".", "random", ".", "choice", "(", "\n", "np", ".", "arange", "(", "self", ".", "out_channels", ")", ",", "p", "=", "x", ".", "view", "(", "-", "1", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", "\n", "x", ".", "zero_", "(", ")", "\n", "x", "[", ":", ",", "sample", "]", "=", "1.0", "\n", "", "", "outputs", "+=", "[", "x", ".", "data", "]", "\n", "# T x B x C", "\n", "", "outputs", "=", "torch", ".", "stack", "(", "outputs", ")", "\n", "# B x C x T", "\n", "outputs", "=", "outputs", ".", "transpose", "(", "0", ",", "1", ")", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "self", ".", "clear_buffer", "(", ")", "\n", "return", "outputs", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer": [[364, 373], ["wavenet.WaveNet.first_conv.clear_buffer", "f.clear_buffer", "f.clear_buffer"], "methods", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.clear_buffer"], ["", "def", "clear_buffer", "(", "self", ")", ":", "\n", "        ", "self", ".", "first_conv", ".", "clear_buffer", "(", ")", "\n", "for", "f", "in", "self", ".", "conv_layers", ":", "\n", "            ", "f", ".", "clear_buffer", "(", ")", "\n", "", "for", "f", "in", "self", ".", "last_conv_layers", ":", "\n", "            ", "try", ":", "\n", "                ", "f", ".", "clear_buffer", "(", ")", "\n", "", "except", "AttributeError", ":", "\n", "                ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.make_generation_fast_": [[374, 381], ["wavenet.WaveNet.apply", "torch.nn.utils.remove_weight_norm"], "methods", ["None"], ["", "", "", "def", "make_generation_fast_", "(", "self", ")", ":", "\n", "        ", "def", "remove_weight_norm", "(", "m", ")", ":", "\n", "            ", "try", ":", "\n", "                ", "nn", ".", "utils", ".", "remove_weight_norm", "(", "m", ")", "\n", "", "except", "ValueError", ":", "# this module didn't have weight norm", "\n", "                ", "return", "\n", "", "", "self", ".", "apply", "(", "remove_weight_norm", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet._expand_global_features": [[17, 38], ["g.unsqueeze", "g.expand", "g.expand.contiguous", "g.expand().transpose", "g.expand().transpose.contiguous", "g.dim", "g.expand"], "function", ["None"], ["def", "_expand_global_features", "(", "B", ",", "T", ",", "g", ",", "bct", "=", "True", ")", ":", "\n", "    ", "\"\"\"Expand global conditioning features to all time steps\n\n    Args:\n        B (int): Batch size.\n        T (int): Time length.\n        g (Tensor): Global features, (B x C) or (B x C x 1).\n        bct (bool) : returns (B x C x T) if True, otherwise (B x T x C)\n\n    Returns:\n        Tensor: B x C x T or B x T x C or None\n    \"\"\"", "\n", "if", "g", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "g", "=", "g", ".", "unsqueeze", "(", "-", "1", ")", "if", "g", ".", "dim", "(", ")", "==", "2", "else", "g", "\n", "if", "bct", ":", "\n", "        ", "g_bct", "=", "g", ".", "expand", "(", "B", ",", "-", "1", ",", "T", ")", "\n", "return", "g_bct", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "        ", "g_btc", "=", "g", ".", "expand", "(", "B", ",", "-", "1", ",", "T", ")", ".", "transpose", "(", "1", ",", "2", ")", "\n", "return", "g_btc", ".", "contiguous", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.receptive_field_size": [[40, 59], ["dilation", "range", "sum"], "function", ["None"], ["", "", "def", "receptive_field_size", "(", "total_layers", ",", "num_cycles", ",", "kernel_size", ",", "\n", "dilation", "=", "lambda", "x", ":", "2", "**", "x", ")", ":", "\n", "    ", "\"\"\"Compute receptive field size\n\n    Args:\n        total_layers (int): total layers\n        num_cycles (int): cycles\n        kernel_size (int): kernel size\n        dilation (lambda): lambda to compute dilation factor. ``lambda x : 1``\n          to disable dilated convolution.\n\n    Returns:\n        int: receptive field size in sample\n\n    \"\"\"", "\n", "assert", "total_layers", "%", "num_cycles", "==", "0", "\n", "layers_per_cycle", "=", "total_layers", "//", "num_cycles", "\n", "dilations", "=", "[", "dilation", "(", "i", "%", "layers_per_cycle", ")", "for", "i", "in", "range", "(", "total_layers", ")", "]", "\n", "return", "(", "kernel_size", "-", "1", ")", "*", "sum", "(", "dilations", ")", "+", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_misc.test_receptive_field_size": [[7, 14], ["wavenet_vocoder.receptive_field_size", "wavenet_vocoder.receptive_field_size", "wavenet_vocoder.receptive_field_size", "wavenet_vocoder.receptive_field_size"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.receptive_field_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.receptive_field_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.receptive_field_size", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.receptive_field_size"], ["def", "test_receptive_field_size", "(", ")", ":", "\n", "# Table 4 in https://arxiv.org/abs/1711.10433", "\n", "    ", "assert", "receptive_field_size", "(", "total_layers", "=", "30", ",", "num_cycles", "=", "3", ",", "kernel_size", "=", "3", ")", "==", "6139", "\n", "assert", "receptive_field_size", "(", "total_layers", "=", "24", ",", "num_cycles", "=", "4", ",", "kernel_size", "=", "3", ")", "==", "505", "\n", "assert", "receptive_field_size", "(", "total_layers", "=", "12", ",", "num_cycles", "=", "2", ",", "kernel_size", "=", "3", ")", "==", "253", "\n", "assert", "receptive_field_size", "(", "total_layers", "=", "30", ",", "num_cycles", "=", "1", ",", "\n", "kernel_size", "=", "3", ",", "dilation", "=", "lambda", "x", ":", "1", ")", "==", "61", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_audio.test_amp_to_db": [[15, 21], ["nose.plugins.attrib.attr", "numpy.random.rand", "audio._db_to_amp", "numpy.allclose", "audio._amp_to_db"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._db_to_amp", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio._amp_to_db"], ["@", "attr", "(", "\"local_only\"", ")", "\n", "def", "test_amp_to_db", "(", ")", ":", "\n", "    ", "import", "audio", "\n", "x", "=", "np", ".", "random", ".", "rand", "(", "10", ")", "\n", "x_hat", "=", "audio", ".", "_db_to_amp", "(", "audio", ".", "_amp_to_db", "(", "x", ")", ")", "\n", "assert", "np", ".", "allclose", "(", "x", ",", "x_hat", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical": [[31, 54], ["numpy.array", "y.ravel.ravel", "numpy.zeros", "numpy.reshape", "tuple", "len", "numpy.max", "numpy.arange"], "function", ["None"], ["def", "to_categorical", "(", "y", ",", "num_classes", "=", "None", ")", ":", "\n", "    ", "\"\"\"Converts a class vector (integers) to binary class matrix.\n    E.g. for use with categorical_crossentropy.\n    # Arguments\n        y: class vector to be converted into a matrix\n            (integers from 0 to num_classes).\n        num_classes: total number of classes.\n    # Returns\n        A binary matrix representation of the input.\n    \"\"\"", "\n", "y", "=", "np", ".", "array", "(", "y", ",", "dtype", "=", "'int'", ")", "\n", "input_shape", "=", "y", ".", "shape", "\n", "if", "input_shape", "and", "input_shape", "[", "-", "1", "]", "==", "1", "and", "len", "(", "input_shape", ")", ">", "1", ":", "\n", "        ", "input_shape", "=", "tuple", "(", "input_shape", "[", ":", "-", "1", "]", ")", "\n", "", "y", "=", "y", ".", "ravel", "(", ")", "\n", "if", "not", "num_classes", ":", "\n", "        ", "num_classes", "=", "np", ".", "max", "(", "y", ")", "+", "1", "\n", "", "n", "=", "y", ".", "shape", "[", "0", "]", "\n", "categorical", "=", "np", ".", "zeros", "(", "(", "n", ",", "num_classes", ")", ")", "\n", "categorical", "[", "np", ".", "arange", "(", "n", ")", ",", "y", "]", "=", "1", "\n", "output_shape", "=", "input_shape", "+", "(", "num_classes", ",", ")", "\n", "categorical", "=", "np", ".", "reshape", "(", "categorical", ",", "output_shape", ")", "\n", "return", "categorical", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_conv_block": [[56, 62], ["wavenet_vocoder.modules.ResidualConv1dGLU", "print", "torch.zeros", "wavenet_vocoder.modules.ResidualConv1dGLU.", "print", "y.size", "h.size"], "function", ["None"], ["", "def", "test_conv_block", "(", ")", ":", "\n", "    ", "conv", "=", "ResidualConv1dGLU", "(", "30", ",", "30", ",", "kernel_size", "=", "3", ",", "dropout", "=", "1", "-", "0.95", ")", "\n", "print", "(", "conv", ")", "\n", "x", "=", "torch", ".", "zeros", "(", "16", ",", "30", ",", "16000", ")", "\n", "y", ",", "h", "=", "conv", "(", "x", ")", "\n", "print", "(", "y", ".", "size", "(", ")", ",", "h", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_wavenet": [[64, 70], ["build_compact_model", "print", "torch.zeros", "build_compact_model.", "print", "model.size"], "function", ["None"], ["", "def", "test_wavenet", "(", ")", ":", "\n", "    ", "model", "=", "build_compact_model", "(", ")", "\n", "print", "(", "model", ")", "\n", "x", "=", "torch", ".", "zeros", "(", "16", ",", "256", ",", "1000", ")", "\n", "y", "=", "model", "(", "x", ")", "\n", "print", "(", "y", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data": [[72, 109], ["librosa.load", "librosa.effects.trim", "pysptk.util.example_audio_file", "librosa.feature.rmse", "numpy.repeat", "np.pad.reshape", "nnmnkwii.preprocessing.mulaw_quantize", "nnmnkwii.preprocessing.inv_mulaw_quantize", "x.reshape.reshape().astype", "x.reshape.reshape", "numpy.pad", "test_model.to_categorical", "x.reshape.reshape"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.audio.trim", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical"], ["", "def", "_test_data", "(", "sr", "=", "4000", ",", "N", "=", "3000", ",", "returns_power", "=", "False", ",", "mulaw", "=", "True", ")", ":", "\n", "    ", "x", ",", "_", "=", "librosa", ".", "load", "(", "example_audio_file", "(", ")", ",", "sr", "=", "sr", ")", "\n", "x", ",", "_", "=", "librosa", ".", "effects", ".", "trim", "(", "x", ",", "top_db", "=", "15", ")", "\n", "\n", "# To save computational cost", "\n", "x", "=", "x", "[", ":", "N", "]", "\n", "\n", "# For power conditioning wavenet", "\n", "if", "returns_power", ":", "\n", "# (1 x N')", "\n", "        ", "p", "=", "librosa", ".", "feature", ".", "rmse", "(", "x", ",", "frame_length", "=", "256", ",", "hop_length", "=", "128", ")", "\n", "upsample_factor", "=", "x", ".", "size", "//", "p", ".", "size", "\n", "# (1 x N)", "\n", "p", "=", "np", ".", "repeat", "(", "p", ",", "upsample_factor", ",", "axis", "=", "-", "1", ")", "\n", "if", "p", ".", "size", "<", "x", ".", "size", ":", "\n", "# pad against time axis", "\n", "            ", "p", "=", "np", ".", "pad", "(", "p", ",", "[", "(", "0", ",", "0", ")", ",", "(", "0", ",", "x", ".", "size", "-", "p", ".", "size", ")", "]", ",", "mode", "=", "\"constant\"", ",", "constant_values", "=", "0", ")", "\n", "\n", "# shape adajst", "\n", "", "p", "=", "p", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "# (T,)", "\n", "", "if", "mulaw", ":", "\n", "        ", "x", "=", "P", ".", "mulaw_quantize", "(", "x", ")", "\n", "x_org", "=", "P", ".", "inv_mulaw_quantize", "(", "x", ")", "\n", "# (C, T)", "\n", "x", "=", "to_categorical", "(", "x", ",", "num_classes", "=", "256", ")", ".", "T", "\n", "# (1, C, T)", "\n", "x", "=", "x", ".", "reshape", "(", "1", ",", "256", ",", "-", "1", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "", "else", ":", "\n", "        ", "x_org", "=", "x", "\n", "x", "=", "x", ".", "reshape", "(", "1", ",", "1", ",", "-", "1", ")", "\n", "\n", "", "if", "returns_power", ":", "\n", "        ", "return", "x", ",", "x_org", ",", "p", "\n", "\n", "", "return", "x", ",", "x_org", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_mixture_wavenet": [[111, 141], ["nose.plugins.attrib.attr", "test_model._test_data", "build_compact_model", "print", "torch.from_numpy().contiguous().to", "torch.from_numpy().contiguous().to", "print", "build_compact_model.eval", "build_compact_model.incremental_forward", "build_compact_model.incremental_forward", "print", "torch.from_numpy().contiguous().to.size", "model.incremental_forward.size", "torch.from_numpy().contiguous().to.size", "model.incremental_forward.size", "torch.from_numpy().contiguous().to.size", "torch.from_numpy().contiguous().to.size", "torch.from_numpy().contiguous", "torch.from_numpy().contiguous", "torch.from_numpy", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward"], ["", "@", "attr", "(", "\"mixture\"", ")", "\n", "def", "test_mixture_wavenet", "(", ")", ":", "\n", "    ", "x", ",", "x_org", ",", "c", "=", "_test_data", "(", "returns_power", "=", "True", ",", "mulaw", "=", "False", ")", "\n", "# 10 mixtures", "\n", "model", "=", "build_compact_model", "(", "out_channels", "=", "3", "*", "10", ",", "cin_channels", "=", "1", ",", "\n", "scalar_input", "=", "True", ")", "\n", "T", "=", "x", ".", "shape", "[", "-", "1", "]", "\n", "print", "(", "model", ".", "first_conv", ")", "\n", "\n", "# scalar input, not one-hot", "\n", "assert", "x", ".", "shape", "[", "1", "]", "==", "1", "\n", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "c", "=", "torch", ".", "from_numpy", "(", "c", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "print", "(", "c", ".", "size", "(", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Incremental forward with forced teaching", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "\n", "test_inputs", "=", "x", ",", "c", "=", "c", ",", "T", "=", "None", ",", "tqdm", "=", "tqdm", ")", "\n", "\n", "assert", "y_online", ".", "size", "(", ")", "==", "x", ".", "size", "(", ")", "\n", "\n", "y_online2", "=", "model", ".", "incremental_forward", "(", "\n", "test_inputs", "=", "None", ",", "c", "=", "c", ",", "T", "=", "T", ",", "tqdm", "=", "tqdm", ")", "\n", "\n", "assert", "y_online2", ".", "size", "(", ")", "==", "x", ".", "size", "(", ")", "\n", "print", "(", "x", ".", "size", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_local_conditioning_correctness": [[143, 174], ["nose.plugins.attrib.attr", "test_model._test_data", "build_compact_model", "build_compact_model.local_conditioning_enabled", "torch.from_numpy().contiguous().to", "torch.from_numpy().contiguous().to", "print", "build_compact_model.eval", "build_compact_model.", "build_compact_model.incremental_forward", "print", "build_compact_model.has_speaker_embedding", "torch.from_numpy().contiguous().to.size", "torch.from_numpy().contiguous().to.size", "torch.from_numpy().contiguous().to.mean", "torch.from_numpy().contiguous().to.max", "numpy.allclose", "torch.from_numpy().contiguous", "torch.from_numpy().contiguous", "model.cpu().data.numpy", "model.incremental_forward.cpu().data.numpy", "warn", "torch.from_numpy", "torch.from_numpy", "model.cpu", "model.incremental_forward.cpu"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.local_conditioning_enabled", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.has_speaker_embedding"], ["", "@", "attr", "(", "\"local_conditioning\"", ")", "\n", "def", "test_local_conditioning_correctness", "(", ")", ":", "\n", "# condition by power", "\n", "    ", "x", ",", "x_org", ",", "c", "=", "_test_data", "(", "returns_power", "=", "True", ")", "\n", "model", "=", "build_compact_model", "(", "cin_channels", "=", "1", ")", "\n", "assert", "model", ".", "local_conditioning_enabled", "(", ")", "\n", "assert", "not", "model", ".", "has_speaker_embedding", "(", ")", "\n", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "c", "=", "torch", ".", "from_numpy", "(", "c", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "print", "(", "x", ".", "size", "(", ")", ",", "c", ".", "size", "(", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "y_offline", "=", "model", "(", "x", ",", "c", "=", "c", ",", "softmax", "=", "True", ")", "\n", "\n", "# Incremental forward with forced teaching", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "\n", "test_inputs", "=", "x", ",", "c", "=", "c", ",", "T", "=", "None", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "False", ")", "\n", "\n", "# (1 x C x T)", "\n", "c", "=", "(", "y_offline", "-", "y_online", ")", ".", "abs", "(", ")", "\n", "print", "(", "c", ".", "mean", "(", ")", ",", "c", ".", "max", "(", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "assert", "np", ".", "allclose", "(", "y_offline", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "\n", "y_online", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "atol", "=", "1e-4", ")", "\n", "", "except", ":", "\n", "        ", "from", "warnings", "import", "warn", "\n", "warn", "(", "\"oops! must be a bug!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_local_conditioning_upsample_correctness": [[176, 214], ["nose.plugins.attrib.attr", "test_model._test_data", "build_compact_model", "build_compact_model.local_conditioning_enabled", "torch.from_numpy().contiguous().to", "torch.from_numpy().contiguous().to", "print", "build_compact_model.eval", "build_compact_model.", "build_compact_model.incremental_forward", "print", "build_compact_model.has_speaker_embedding", "torch.from_numpy().contiguous().to.size", "torch.from_numpy().contiguous().to.size", "torch.from_numpy().contiguous().to.mean", "torch.from_numpy().contiguous().to.max", "numpy.allclose", "torch.from_numpy().contiguous", "torch.from_numpy().contiguous", "model.cpu().data.numpy", "model.incremental_forward.cpu().data.numpy", "warn", "torch.from_numpy", "torch.from_numpy", "model.cpu", "model.incremental_forward.cpu"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.local_conditioning_enabled", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.has_speaker_embedding"], ["", "", "@", "attr", "(", "\"local_conditioning\"", ")", "\n", "def", "test_local_conditioning_upsample_correctness", "(", ")", ":", "\n", "# condition by power", "\n", "    ", "x", ",", "x_org", ",", "c", "=", "_test_data", "(", "returns_power", "=", "True", ")", "\n", "\n", "# downsample by 4", "\n", "assert", "c", ".", "shape", "[", "-", "1", "]", "%", "4", "==", "0", "\n", "c", "=", "c", "[", ":", ",", ":", ",", "0", ":", ":", "4", "]", "\n", "\n", "model", "=", "build_compact_model", "(", "\n", "cin_channels", "=", "1", ",", "upsample_conditional_features", "=", "True", ",", "\n", "upsample_scales", "=", "[", "2", ",", "2", "]", ")", "\n", "assert", "model", ".", "local_conditioning_enabled", "(", ")", "\n", "assert", "not", "model", ".", "has_speaker_embedding", "(", ")", "\n", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "c", "=", "torch", ".", "from_numpy", "(", "c", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "print", "(", "x", ".", "size", "(", ")", ",", "c", ".", "size", "(", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "y_offline", "=", "model", "(", "x", ",", "c", "=", "c", ",", "softmax", "=", "True", ")", "\n", "\n", "# Incremental forward with forced teaching", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "\n", "test_inputs", "=", "x", ",", "c", "=", "c", ",", "T", "=", "None", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "False", ")", "\n", "\n", "# (1 x C x T)", "\n", "c", "=", "(", "y_offline", "-", "y_online", ")", ".", "abs", "(", ")", "\n", "print", "(", "c", ".", "mean", "(", ")", ",", "c", ".", "max", "(", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "assert", "np", ".", "allclose", "(", "y_offline", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "\n", "y_online", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "atol", "=", "1e-4", ")", "\n", "", "except", ":", "\n", "        ", "from", "warnings", "import", "warn", "\n", "warn", "(", "\"oops! must be a bug!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_global_conditioning_with_embedding_correctness": [[216, 249], ["nose.plugins.attrib.attr", "test_model._test_data", "c.mean().astype", "build_compact_model", "build_compact_model.has_speaker_embedding", "torch.from_numpy().contiguous().to", "torch.from_numpy().long().contiguous().to", "print", "build_compact_model.eval", "build_compact_model.", "build_compact_model.incremental_forward", "print", "build_compact_model.local_conditioning_enabled", "torch.from_numpy().long().contiguous().to.size", "c.mean", "c.max", "numpy.allclose", "c.mean", "torch.from_numpy().contiguous", "torch.from_numpy().long().contiguous", "model.cpu().data.numpy", "model.incremental_forward.cpu().data.numpy", "warn", "torch.from_numpy", "torch.from_numpy().long", "model.cpu", "model.incremental_forward.cpu", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.has_speaker_embedding", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.local_conditioning_enabled"], ["", "", "@", "attr", "(", "\"global_conditioning\"", ")", "\n", "def", "test_global_conditioning_with_embedding_correctness", "(", ")", ":", "\n", "# condition by mean power", "\n", "    ", "x", ",", "x_org", ",", "c", "=", "_test_data", "(", "returns_power", "=", "True", ")", "\n", "g", "=", "c", ".", "mean", "(", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "model", "=", "build_compact_model", "(", "gin_channels", "=", "16", ",", "n_speakers", "=", "256", ",", "\n", "use_speaker_embedding", "=", "True", ")", "\n", "assert", "not", "model", ".", "local_conditioning_enabled", "(", ")", "\n", "assert", "model", ".", "has_speaker_embedding", "(", ")", "\n", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "g", "=", "torch", ".", "from_numpy", "(", "g", ")", ".", "long", "(", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "print", "(", "g", ".", "size", "(", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "y_offline", "=", "model", "(", "x", ",", "g", "=", "g", ",", "softmax", "=", "True", ")", "\n", "\n", "# Incremental forward with forced teaching", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "\n", "test_inputs", "=", "x", ",", "g", "=", "g", ",", "T", "=", "None", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "False", ")", "\n", "\n", "# (1 x C x T)", "\n", "c", "=", "(", "y_offline", "-", "y_online", ")", ".", "abs", "(", ")", "\n", "print", "(", "c", ".", "mean", "(", ")", ",", "c", ".", "max", "(", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "assert", "np", ".", "allclose", "(", "y_offline", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "\n", "y_online", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "atol", "=", "1e-4", ")", "\n", "", "except", ":", "\n", "        ", "from", "warnings", "import", "warn", "\n", "warn", "(", "\"oops! must be a bug!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_global_conditioning_correctness": [[251, 284], ["nose.plugins.attrib.attr", "test_model._test_data", "c.mean().astype", "build_compact_model", "torch.from_numpy().contiguous().to", "torch.from_numpy().contiguous().to", "print", "build_compact_model.eval", "build_compact_model.", "build_compact_model.incremental_forward", "print", "build_compact_model.local_conditioning_enabled", "build_compact_model.has_speaker_embedding", "torch.from_numpy().contiguous().to.size", "c.mean", "c.max", "numpy.allclose", "c.mean", "torch.from_numpy().contiguous", "torch.from_numpy().contiguous", "model.cpu().data.numpy", "model.incremental_forward.cpu().data.numpy", "warn", "torch.from_numpy", "torch.from_numpy", "model.cpu", "model.incremental_forward.cpu"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.local_conditioning_enabled", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.has_speaker_embedding"], ["", "", "@", "attr", "(", "\"global_conditioning\"", ")", "\n", "def", "test_global_conditioning_correctness", "(", ")", ":", "\n", "# condition by mean power", "\n", "    ", "x", ",", "x_org", ",", "c", "=", "_test_data", "(", "returns_power", "=", "True", ")", "\n", "# must be floating-point type", "\n", "g", "=", "c", ".", "mean", "(", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "model", "=", "build_compact_model", "(", "gin_channels", "=", "1", ",", "use_speaker_embedding", "=", "False", ")", "\n", "assert", "not", "model", ".", "local_conditioning_enabled", "(", ")", "\n", "# `use_speaker_embedding` False should diable embedding layer", "\n", "assert", "not", "model", ".", "has_speaker_embedding", "(", ")", "\n", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "g", "=", "torch", ".", "from_numpy", "(", "g", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "print", "(", "g", ".", "size", "(", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "y_offline", "=", "model", "(", "x", ",", "g", "=", "g", ",", "softmax", "=", "True", ")", "\n", "\n", "# Incremental forward with forced teaching", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "\n", "test_inputs", "=", "x", ",", "g", "=", "g", ",", "T", "=", "None", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "False", ")", "\n", "\n", "# (1 x C x T)", "\n", "c", "=", "(", "y_offline", "-", "y_online", ")", ".", "abs", "(", ")", "\n", "print", "(", "c", ".", "mean", "(", ")", ",", "c", ".", "max", "(", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "assert", "np", ".", "allclose", "(", "y_offline", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "\n", "y_online", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "atol", "=", "1e-4", ")", "\n", "", "except", ":", "\n", "        ", "from", "warnings", "import", "warn", "\n", "warn", "(", "\"oops! must be a bug!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_global_and_local_conditioning_correctness": [[286, 322], ["nose.plugins.attrib.attr", "test_model._test_data", "torch.from_numpy().contiguous().to.mean().astype", "build_compact_model", "build_compact_model.local_conditioning_enabled", "build_compact_model.has_speaker_embedding", "torch.from_numpy().contiguous().to", "torch.from_numpy().contiguous().to", "torch.from_numpy().long().contiguous().to", "print", "build_compact_model.eval", "build_compact_model.", "build_compact_model.incremental_forward", "print", "torch.from_numpy().contiguous().to.size", "torch.from_numpy().long().contiguous().to.size", "torch.from_numpy().contiguous().to.mean", "torch.from_numpy().contiguous().to.max", "numpy.allclose", "torch.from_numpy().contiguous().to.mean", "torch.from_numpy().contiguous", "torch.from_numpy().contiguous", "torch.from_numpy().long().contiguous", "model.cpu().data.numpy", "model.incremental_forward.cpu().data.numpy", "warn", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy().long", "model.cpu", "model.incremental_forward.cpu", "torch.from_numpy"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.local_conditioning_enabled", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.has_speaker_embedding", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward"], ["", "", "@", "attr", "(", "\"local_and_global_conditioning\"", ")", "\n", "def", "test_global_and_local_conditioning_correctness", "(", ")", ":", "\n", "    ", "x", ",", "x_org", ",", "c", "=", "_test_data", "(", "returns_power", "=", "True", ")", "\n", "g", "=", "c", ".", "mean", "(", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", ".", "astype", "(", "np", ".", "int", ")", "\n", "model", "=", "build_compact_model", "(", "cin_channels", "=", "1", ",", "gin_channels", "=", "16", ",", "n_speakers", "=", "256", ")", "\n", "assert", "model", ".", "local_conditioning_enabled", "(", ")", "\n", "assert", "model", ".", "has_speaker_embedding", "(", ")", "\n", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# per-sample power", "\n", "c", "=", "torch", ".", "from_numpy", "(", "c", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "# mean power", "\n", "g", "=", "torch", ".", "from_numpy", "(", "g", ")", ".", "long", "(", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "print", "(", "c", ".", "size", "(", ")", ",", "g", ".", "size", "(", ")", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "y_offline", "=", "model", "(", "x", ",", "c", "=", "c", ",", "g", "=", "g", ",", "softmax", "=", "True", ")", "\n", "\n", "# Incremental forward with forced teaching", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "\n", "test_inputs", "=", "x", ",", "c", "=", "c", ",", "g", "=", "g", ",", "T", "=", "None", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "False", ")", "\n", "# (1 x C x T)", "\n", "\n", "c", "=", "(", "y_offline", "-", "y_online", ")", ".", "abs", "(", ")", "\n", "print", "(", "c", ".", "mean", "(", ")", ",", "c", ".", "max", "(", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "assert", "np", ".", "allclose", "(", "y_offline", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "\n", "y_online", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "atol", "=", "1e-4", ")", "\n", "", "except", ":", "\n", "        ", "from", "warnings", "import", "warn", "\n", "warn", "(", "\"oops! must be a bug!\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.test_incremental_forward_correctness": [[324, 408], ["nose.plugins.attrib.attr", "build_compact_model().to", "os.path.join", "os.path.exists", "test_model._test_data", "torch.from_numpy().contiguous().to", "build_compact_model().to.eval", "build_compact_model().to.", "build_compact_model().to.incremental_forward", "build_compact_model().to.incremental_forward", "print", "torch.from_numpy().contiguous().to.transpose().contiguous", "xt[].unsqueeze().contiguous", "print", "print", "[].view", "[].view", "[].view", "nnmnkwii.preprocessing.inv_mulaw_quantize", "nnmnkwii.preprocessing.inv_mulaw_quantize", "nnmnkwii.preprocessing.inv_mulaw_quantize", "plt.figure", "plt.subplot", "librosa.display.waveplot", "plt.subplot", "librosa.display.waveplot", "plt.subplot", "librosa.display.waveplot", "plt.subplot", "librosa.display.waveplot", "plt.show", "os.path.dirname", "print", "torch.load", "build_compact_model().to.load_state_dict", "c.mean", "c.max", "numpy.allclose", "xt[].unsqueeze().contiguous.size", "build_compact_model().to.incremental_forward", "build_compact_model().to.incremental_forward", "P.inv_mulaw_quantize.cpu().data.long().numpy", "P.inv_mulaw_quantize.cpu().data.long().numpy", "model.incremental_forward.cpu().data.long().numpy", "librosa.output.write_wav", "librosa.output.write_wav", "librosa.output.write_wav", "build_compact_model", "torch.from_numpy().contiguous", "P.inv_mulaw_quantize.cpu().data.numpy", "P.inv_mulaw_quantize.cpu().data.numpy", "warn", "torch.from_numpy().contiguous().to.transpose", "xt[].unsqueeze", "xt[].unsqueeze().contiguous.view().max", "x.transpose().contiguous.size", "x.transpose().contiguous.size", "P.inv_mulaw_quantize.max", "P.inv_mulaw_quantize.max", "model.incremental_forward.max", "P.inv_mulaw_quantize.cpu().data.long", "P.inv_mulaw_quantize.cpu().data.long", "model.incremental_forward.cpu().data.long", "torch.from_numpy", "xt[].unsqueeze().contiguous.view", "P.inv_mulaw_quantize.cpu", "P.inv_mulaw_quantize.cpu", "P.inv_mulaw_quantize.cpu", "P.inv_mulaw_quantize.cpu", "model.incremental_forward.cpu"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model._test_data", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.wavenet.WaveNet.incremental_forward"], ["", "", "@", "attr", "(", "\"local_only\"", ")", "\n", "def", "test_incremental_forward_correctness", "(", ")", ":", "\n", "    ", "import", "librosa", ".", "display", "\n", "from", "matplotlib", "import", "pyplot", "as", "plt", "\n", "\n", "model", "=", "build_compact_model", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "checkpoint_path", "=", "join", "(", "dirname", "(", "__file__", ")", ",", "\"..\"", ",", "\"foobar/checkpoint_step000058000.pth\"", ")", "\n", "if", "exists", "(", "checkpoint_path", ")", ":", "\n", "        ", "print", "(", "\"Loading from:\"", ",", "checkpoint_path", ")", "\n", "checkpoint", "=", "torch", ".", "load", "(", "checkpoint_path", ")", "\n", "model", ".", "load_state_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "\n", "", "sr", "=", "4000", "\n", "x", ",", "x_org", "=", "_test_data", "(", "sr", "=", "sr", ",", "N", "=", "3000", ")", "\n", "x", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "contiguous", "(", ")", ".", "to", "(", "device", ")", "\n", "\n", "model", ".", "eval", "(", ")", "\n", "\n", "# Batch forward", "\n", "y_offline", "=", "model", "(", "x", ",", "softmax", "=", "True", ")", "\n", "\n", "# Test from zero start", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "initial_input", "=", "None", ",", "T", "=", "100", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ")", "\n", "\n", "# Incremental forward with forced teaching", "\n", "y_online", "=", "model", ".", "incremental_forward", "(", "test_inputs", "=", "x", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "False", ")", "\n", "\n", "# (1 x C x T)", "\n", "c", "=", "(", "y_offline", "-", "y_online", ")", ".", "abs", "(", ")", "\n", "print", "(", "c", ".", "mean", "(", ")", ",", "c", ".", "max", "(", ")", ")", "\n", "\n", "try", ":", "\n", "        ", "assert", "np", ".", "allclose", "(", "y_offline", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "\n", "y_online", ".", "cpu", "(", ")", ".", "data", ".", "numpy", "(", ")", ",", "atol", "=", "1e-4", ")", "\n", "", "except", ":", "\n", "        ", "from", "warnings", "import", "warn", "\n", "warn", "(", "\"oops! must be a bug!\"", ")", "\n", "\n", "# (1, T, C)", "\n", "", "xt", "=", "x", ".", "transpose", "(", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "initial_input", "=", "xt", "[", ":", ",", "0", ",", ":", "]", ".", "unsqueeze", "(", "1", ")", ".", "contiguous", "(", ")", "\n", "print", "(", "initial_input", ".", "size", "(", ")", ")", "\n", "print", "(", "\"Inital value:\"", ",", "initial_input", ".", "view", "(", "-", "1", ")", ".", "max", "(", "0", ")", "[", "1", "]", ")", "\n", "\n", "# With zero start", "\n", "zerostart", "=", "True", "\n", "if", "zerostart", ":", "\n", "        ", "y_inference", "=", "model", ".", "incremental_forward", "(", "\n", "initial_input", "=", "initial_input", ",", "T", "=", "xt", ".", "size", "(", "1", ")", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "True", ")", "\n", "", "else", ":", "\n", "# Feed a few samples as test_inputs and then generate auto-regressively", "\n", "        ", "N", "=", "1000", "\n", "y_inference", "=", "model", ".", "incremental_forward", "(", "\n", "initial_input", "=", "None", ",", "test_inputs", "=", "xt", "[", ":", ",", ":", "N", ",", ":", "]", ",", "\n", "T", "=", "xt", ".", "size", "(", "1", ")", ",", "tqdm", "=", "tqdm", ",", "softmax", "=", "True", ",", "quantize", "=", "True", ")", "\n", "\n", "# Waveforms", "\n", "# (T,)", "\n", "", "y_offline", "=", "y_offline", ".", "max", "(", "1", ")", "[", "1", "]", ".", "view", "(", "-", "1", ")", "\n", "y_online", "=", "y_online", ".", "max", "(", "1", ")", "[", "1", "]", ".", "view", "(", "-", "1", ")", "\n", "y_inference", "=", "y_inference", ".", "max", "(", "1", ")", "[", "1", "]", ".", "view", "(", "-", "1", ")", "\n", "\n", "y_offline", "=", "P", ".", "inv_mulaw_quantize", "(", "y_offline", ".", "cpu", "(", ")", ".", "data", ".", "long", "(", ")", ".", "numpy", "(", ")", ")", "\n", "y_online", "=", "P", ".", "inv_mulaw_quantize", "(", "y_online", ".", "cpu", "(", ")", ".", "data", ".", "long", "(", ")", ".", "numpy", "(", ")", ")", "\n", "y_inference", "=", "P", ".", "inv_mulaw_quantize", "(", "y_inference", ".", "cpu", "(", ")", ".", "data", ".", "long", "(", ")", ".", "numpy", "(", ")", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "16", ",", "10", ")", ")", "\n", "plt", ".", "subplot", "(", "4", ",", "1", ",", "1", ")", "\n", "librosa", ".", "display", ".", "waveplot", "(", "x_org", ",", "sr", "=", "sr", ")", "\n", "plt", ".", "subplot", "(", "4", ",", "1", ",", "2", ")", "\n", "librosa", ".", "display", ".", "waveplot", "(", "y_offline", ",", "sr", "=", "sr", ")", "\n", "plt", ".", "subplot", "(", "4", ",", "1", ",", "3", ")", "\n", "librosa", ".", "display", ".", "waveplot", "(", "y_online", ",", "sr", "=", "sr", ")", "\n", "plt", ".", "subplot", "(", "4", ",", "1", ",", "4", ")", "\n", "librosa", ".", "display", ".", "waveplot", "(", "y_inference", ",", "sr", "=", "sr", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "save_audio", "=", "False", "\n", "if", "save_audio", ":", "\n", "        ", "librosa", ".", "output", ".", "write_wav", "(", "\"target.wav\"", ",", "x_org", ",", "sr", "=", "sr", ")", "\n", "librosa", ".", "output", ".", "write_wav", "(", "\"online.wav\"", ",", "y_online", ",", "sr", "=", "sr", ")", "\n", "librosa", ".", "output", ".", "write_wav", "(", "\"inference.wav\"", ",", "y_inference", ",", "sr", "=", "sr", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_mixture.log_prob_from_logits": [[16, 22], ["torch.max", "len", "torch.log", "x.size", "torch.sum", "torch.exp"], "function", ["None"], ["def", "log_prob_from_logits", "(", "x", ")", ":", "\n", "    ", "\"\"\" numerically stable log_softmax implementation that prevents overflow \"\"\"", "\n", "# TF ordering", "\n", "axis", "=", "len", "(", "x", ".", "size", "(", ")", ")", "-", "1", "\n", "m", ",", "_", "=", "torch", ".", "max", "(", "x", ",", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "return", "x", "-", "m", "-", "torch", ".", "log", "(", "torch", ".", "sum", "(", "torch", ".", "exp", "(", "x", "-", "m", ")", ",", "dim", "=", "axis", ",", "keepdim", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_mixture.test_log_softmax": [[24, 32], ["torch.rand", "test_mixture.log_prob_from_logits", "torch.nn.functional.log_softmax", "y.data.cpu().numpy.data.cpu().numpy", "y_hat.data.cpu().numpy.data.cpu().numpy", "numpy.allclose", "y.data.cpu().numpy.data.cpu", "y_hat.data.cpu().numpy.data.cpu"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_mixture.log_prob_from_logits"], ["", "def", "test_log_softmax", "(", ")", ":", "\n", "    ", "x", "=", "torch", ".", "rand", "(", "2", ",", "16000", ",", "30", ")", "\n", "y", "=", "log_prob_from_logits", "(", "x", ")", "\n", "y_hat", "=", "F", ".", "log_softmax", "(", "x", ",", "-", "1", ")", "\n", "\n", "y", "=", "y", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "y_hat", "=", "y_hat", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "assert", "np", ".", "allclose", "(", "y", ",", "y_hat", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_mixture.test_mixture": [[34, 56], ["numpy.random.seed", "librosa.load", "len", "x.reshape.reshape", "torch.from_numpy().float", "torch.rand().float", "print", "wavenet_vocoder.mixture.discretized_mix_logistic_loss", "print", "wavenet_vocoder.mixture.discretized_mix_logistic_loss", "print", "wavenet_vocoder.mixture.sample_from_discretized_mix_logistic", "print", "pysptk.util.example_audio_file", "wavenet_vocoder.mixture.discretized_mix_logistic_loss.size", "wavenet_vocoder.mixture.sample_from_discretized_mix_logistic.size", "wavenet_vocoder.mixture.discretized_mix_logistic_loss.size", "wavenet_vocoder.mixture.sample_from_discretized_mix_logistic.size", "torch.from_numpy", "torch.rand"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.discretized_mix_logistic_loss", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.discretized_mix_logistic_loss", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.wavenet_vocoder.mixture.sample_from_discretized_mix_logistic"], ["", "def", "test_mixture", "(", ")", ":", "\n", "    ", "np", ".", "random", ".", "seed", "(", "1234", ")", "\n", "\n", "x", ",", "sr", "=", "librosa", ".", "load", "(", "pysptk", ".", "util", ".", "example_audio_file", "(", ")", ",", "sr", "=", "None", ")", "\n", "assert", "sr", "==", "16000", "\n", "\n", "T", "=", "len", "(", "x", ")", "\n", "x", "=", "x", ".", "reshape", "(", "1", ",", "T", ",", "1", ")", "\n", "y", "=", "torch", ".", "from_numpy", "(", "x", ")", ".", "float", "(", ")", "\n", "y_hat", "=", "torch", ".", "rand", "(", "1", ",", "30", ",", "T", ")", ".", "float", "(", ")", "\n", "\n", "print", "(", "y", ".", "shape", ",", "y_hat", ".", "shape", ")", "\n", "\n", "loss", "=", "discretized_mix_logistic_loss", "(", "y_hat", ",", "y", ")", "\n", "print", "(", "loss", ")", "\n", "\n", "loss", "=", "discretized_mix_logistic_loss", "(", "y_hat", ",", "y", ",", "reduce", "=", "False", ")", "\n", "print", "(", "loss", ".", "size", "(", ")", ",", "y", ".", "size", "(", ")", ")", "\n", "assert", "loss", ".", "size", "(", ")", "==", "y", ".", "size", "(", ")", "\n", "\n", "y", "=", "sample_from_discretized_mix_logistic", "(", "y_hat", ")", "\n", "print", "(", "y", ".", "shape", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_mixture.test_misc": [[58, 78], ["torch.rand", "numpy.allclose", "torch.rand", "torch.nn.functional.sigmoid().log", "numpy.allclose", "torch.rand", "numpy.allclose", "torch.log", "log_pdf_mid1.data.numpy", "log_pdf_mid2.data.numpy", "torch.nn.functional.softplus", "F.sigmoid().log.data.numpy", "log_cdf_plus2.data.numpy", "torch.nn.functional.softplus", "log_one_minus_cdf_min1.data.numpy", "log_one_minus_cdf_min2.data.numpy", "torch.nn.functional.softplus", "torch.nn.functional.sigmoid", "torch.exp", "torch.exp", "torch.nn.functional.sigmoid"], "function", ["None"], ["", "def", "test_misc", "(", ")", ":", "\n", "# https://en.wikipedia.org/wiki/Logistic_distribution", "\n", "# what i have learned", "\n", "# m = (x - mu) / s", "\n", "    ", "m", "=", "torch", ".", "rand", "(", "10", ",", "10", ")", "\n", "log_pdf_mid1", "=", "-", "2", "*", "torch", ".", "log", "(", "torch", ".", "exp", "(", "m", "/", "2", ")", "+", "torch", ".", "exp", "(", "-", "m", "/", "2", ")", ")", "\n", "log_pdf_mid2", "=", "m", "-", "2", "*", "F", ".", "softplus", "(", "m", ")", "\n", "assert", "np", ".", "allclose", "(", "log_pdf_mid1", ".", "data", ".", "numpy", "(", ")", ",", "log_pdf_mid2", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "# Edge case for 0", "\n", "plus_in", "=", "torch", ".", "rand", "(", "10", ",", "10", ")", "\n", "log_cdf_plus1", "=", "F", ".", "sigmoid", "(", "m", ")", ".", "log", "(", ")", "\n", "log_cdf_plus2", "=", "m", "-", "F", ".", "softplus", "(", "m", ")", "\n", "assert", "np", ".", "allclose", "(", "log_cdf_plus1", ".", "data", ".", "numpy", "(", ")", ",", "log_cdf_plus2", ".", "data", ".", "numpy", "(", ")", ")", "\n", "\n", "# Edge case for 255", "\n", "min_in", "=", "torch", ".", "rand", "(", "10", ",", "10", ")", "\n", "log_one_minus_cdf_min1", "=", "(", "1", "-", "F", ".", "sigmoid", "(", "min_in", ")", ")", ".", "log", "(", ")", "\n", "log_one_minus_cdf_min2", "=", "-", "F", ".", "softplus", "(", "min_in", ")", "\n", "assert", "np", ".", "allclose", "(", "log_one_minus_cdf_min1", ".", "data", ".", "numpy", "(", ")", ",", "log_one_minus_cdf_min2", ".", "data", ".", "numpy", "(", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.produce_csv.getExperiment": [[12, 21], ["None"], "function", ["None"], ["def", "getExperiment", "(", "filename", ")", ":", "\n", "    ", "if", "'_classifier_maximized_noise_to_class_'", "in", "filename", ":", "\n", "        ", "return", "1", "\n", "", "elif", "'_classifier_before_maximized_class_to_class_'", "in", "filename", "or", "'_classifier_after_maximized_class_to_class_'", "in", "filename", ":", "\n", "        ", "return", "2", "\n", "", "elif", "'_classifier_decoder_maximized_noise_to_class_'", "in", "filename", ":", "\n", "        ", "return", "3", "\n", "", "elif", "'_classifier_decoder_before_maximized_class_to_class_'", "in", "filename", "or", "'_classifier_decoder_after_maximized_class_to_class_'", "in", "filename", ":", "\n", "        ", "return", "4", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.produce_csv.main": [[22, 59], ["keras.models.load_model", "keras.models.load_model", "os.listdir", "pathlib.Path().iterdir", "numpy.random.shuffle", "print", "len", "open", "csv.writer", "csv.writer.writerow", "tqdm.tqdm", "pathlib.Path", "wav_paths.append", "numpy.load", "np.load.reshape", "keras.models.load_model.predict", "numpy.argmax", "keras.models.load_model.predict", "numpy.argmax", "os.path.basename", "wav_filename.split", "csv.writer.writerow", "str", "filename_split[].split", "produce_csv.getExperiment"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.produce_csv.getExperiment"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "first_model", "=", "load_model", "(", "'../../models/speech_classifier_model.h5'", ")", "\n", "second_model", "=", "load_model", "(", "'../../models/speech_classifier_model_2.h5'", ")", "\n", "\n", "classes", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "\n", "wav_paths", "=", "[", "]", "\n", "for", "pth", "in", "Path", "(", "'results/synthesize'", ")", ".", "iterdir", "(", ")", ":", "\n", "        ", "if", "pth", ".", "suffix", "==", "'.npy'", ":", "\n", "            ", "wav_paths", ".", "append", "(", "str", "(", "pth", ")", ")", "\n", "\n", "", "", "np", ".", "random", ".", "shuffle", "(", "wav_paths", ")", "\n", "print", "(", "'total files'", ",", "len", "(", "wav_paths", ")", ")", "\n", "\n", "with", "open", "(", "'input.csv'", ",", "'w'", ",", "newline", "=", "''", ")", "as", "csvfile", ":", "\n", "        ", "spamwriter", "=", "csv", ".", "writer", "(", "csvfile", ",", "quotechar", "=", "'|'", ",", "quoting", "=", "csv", ".", "QUOTE_MINIMAL", ")", "\n", "spamwriter", ".", "writerow", "(", "[", "'experiment'", ",", "'timestamp'", ",", "'class_label'", ",", "'audio_url'", ",", "'pred_1_class'", ",", "'pred_2_class'", "]", ")", "\n", "\n", "for", "path", "in", "tqdm", "(", "wav_paths", ")", ":", "\n", "\n", "            ", "original_feature", "=", "np", ".", "load", "(", "path", ")", "\n", "feature", "=", "original_feature", ".", "reshape", "(", "1", ",", "90", ",", "80", ",", "1", ")", "\n", "\n", "orig_scores", "=", "first_model", ".", "predict", "(", "feature", ")", "\n", "class_idx_1", "=", "np", ".", "argmax", "(", "orig_scores", "[", "0", "]", ")", "\n", "\n", "new_scores", "=", "second_model", ".", "predict", "(", "feature", ")", "\n", "class_idx_2", "=", "np", ".", "argmax", "(", "new_scores", "[", "0", "]", ")", "\n", "\n", "filename", "=", "os", ".", "path", ".", "basename", "(", "path", ")", "\n", "wav_filename", "=", "'20180510_mixture_lj_checkpoint_step000320000_ema_'", "+", "filename", "\n", "\n", "filename_split", "=", "wav_filename", ".", "split", "(", "'_'", ")", "\n", "class_label", "=", "filename_split", "[", "-", "1", "]", ".", "split", "(", "'.'", ")", "[", "0", "]", "\n", "timestamp", "=", "filename_split", "[", "7", "]", "\n", "\n", "spamwriter", ".", "writerow", "(", "[", "getExperiment", "(", "filename", ")", ",", "timestamp", ",", "class_label", ",", "'audio_directory/'", "+", "wav_filename", "+", "'.wav'", ",", "classes", "[", "class_idx_1", "]", ",", "classes", "[", "class_idx_2", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.to_int": [[14, 27], ["RuntimeError"], "function", ["None"], ["def", "to_int", "(", "x", ")", ":", "\n", "    ", "if", "\"Bad -\"", "in", "x", ":", "\n", "        ", "return", "0", "\n", "", "elif", "\"Poor -\"", "in", "x", ":", "\n", "        ", "return", "1", "\n", "", "elif", "\"Fair -\"", "in", "x", ":", "\n", "        ", "return", "2", "\n", "", "elif", "\"Good -\"", "in", "x", ":", "\n", "        ", "return", "3", "\n", "", "elif", "\"Excellent -\"", "in", "x", ":", "\n", "        ", "return", "4", "\n", "", "else", ":", "\n", "        ", "raise", "RuntimeError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.get_bad_worker_idxs": [[28, 35], ["set", "numpy.array"], "function", ["None"], ["", "", "def", "get_bad_worker_idxs", "(", "answer_labels", ",", "workers", ",", "experiment_id", ")", ":", "\n", "# Return indexes of bad workers", "\n", "# (those who answered 3 or 4 in complete noise scenarios)", "\n", "    ", "bad_idxs", "=", "(", "(", "(", "answer_labels", "==", "3", ")", "|", "(", "answer_labels", "==", "4", ")", ")", "&", "(", "experiment_id", "==", "1", ")", ")", "\n", "bad_workers", "=", "set", "(", "workers", "[", "bad_idxs", "]", ")", "\n", "bad_idxs", "=", "np", ".", "array", "(", "[", "worker", "in", "bad_workers", "for", "worker", "in", "workers", "]", ")", "\n", "return", "bad_idxs", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.original_or_not": [[36, 38], ["numpy.array"], "function", ["None"], ["", "def", "original_or_not", "(", "audio_urls", ")", ":", "\n", "    ", "return", "np", ".", "array", "(", "[", "\"original\"", "in", "x", "for", "x", "in", "audio_urls", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.per_class_perceptual_qualities": [[39, 129], ["pandas.read_csv", "numpy.array", "numpy.array", "turk_analysis.original_or_not", "turk_analysis.get_bad_worker_idxs", "sorted", "matplotlib.pyplot.figure", "enumerate", "sorted", "enumerate", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.xticks", "matplotlib.pyplot.gca().tick_params", "matplotlib.pyplot.gca().tick_params", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.legend", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "list", "list", "answer_labels[].mean", "answer_labels[].mean", "answer_labels[].mean", "sorted.append", "matplotlib.pyplot.bar", "matplotlib.pyplot.bar", "matplotlib.pyplot.bar", "ticks.append", "ticklabels.append", "map", "set", "answer_labels[].std", "answer_labels[].std", "answer_labels[].std", "matplotlib.pyplot.gca", "matplotlib.pyplot.gca"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.original_or_not", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.get_bad_worker_idxs"], ["", "def", "per_class_perceptual_qualities", "(", "args", ")", ":", "\n", "    ", "input_file", "=", "args", ".", "input", "\n", "data", "=", "pandas", ".", "read_csv", "(", "input_file", ")", "\n", "\n", "answer_labels", "=", "np", ".", "array", "(", "list", "(", "map", "(", "to_int", ",", "data", "[", "\"Answer.audio-naturalness.label\"", "]", ")", ")", ")", "\n", "experiment_id", "=", "np", ".", "array", "(", "data", "[", "\"Input.experiment\"", "]", ")", "\n", "workers", "=", "data", "[", "\"WorkerId\"", "]", "\n", "audio_classes", "=", "data", "[", "\"Input.class_label\"", "]", "\n", "original", "=", "original_or_not", "(", "data", "[", "\"Input.audio_url\"", "]", ")", "\n", "\n", "bad_idxs", "=", "get_bad_worker_idxs", "(", "answer_labels", ",", "workers", ",", "experiment_id", ")", "\n", "\n", "experiment_id", "=", "experiment_id", "[", "~", "bad_idxs", "]", "\n", "answer_labels", "=", "answer_labels", "[", "~", "bad_idxs", "]", "\n", "original", "=", "original", "[", "~", "bad_idxs", "]", "\n", "audio_classes", "=", "audio_classes", "[", "~", "bad_idxs", "]", "\n", "\n", "unique_classes", "=", "sorted", "(", "list", "(", "set", "(", "audio_classes", ")", ")", ",", "reverse", "=", "False", ")", "\n", "\n", "fig", "=", "pyplot", ".", "figure", "(", "figsize", "=", "[", "6.4", "*", "1.5", ",", "4.8", "]", ",", "dpi", "=", "200", ")", "\n", "bars_ticklabels", "=", "[", "]", "\n", "for", "i", ",", "audio_class", "in", "enumerate", "(", "unique_classes", ")", ":", "\n", "        ", "class_idxs_orig", "=", "(", "(", "audio_classes", "==", "audio_class", ")", "&", "(", "original", ")", ")", "\n", "class_idxs_max_class", "=", "(", "(", "audio_classes", "==", "audio_class", ")", "&", "(", "~", "original", ")", "&", "(", "experiment_id", "==", "1", ")", ")", "\n", "class_idxs_max_decod", "=", "(", "(", "audio_classes", "==", "audio_class", ")", "&", "(", "~", "original", ")", "&", "(", "experiment_id", "==", "3", ")", ")", "\n", "\n", "original_quality", "=", "answer_labels", "[", "class_idxs_orig", "]", ".", "mean", "(", ")", "\n", "classifier_quality", "=", "answer_labels", "[", "class_idxs_max_class", "]", ".", "mean", "(", ")", "\n", "decoder_quality", "=", "answer_labels", "[", "class_idxs_max_decod", "]", ".", "mean", "(", ")", "\n", "\n", "original_quality_std", "=", "answer_labels", "[", "class_idxs_orig", "]", ".", "std", "(", ")", "/", "2", "\n", "classifier_quality_std", "=", "answer_labels", "[", "class_idxs_max_class", "]", ".", "std", "(", ")", "/", "2", "\n", "decoder_quality_std", "=", "answer_labels", "[", "class_idxs_max_decod", "]", ".", "std", "(", ")", "/", "2", "\n", "\n", "#pyplot.bar([(i*2)-BAR_WIDTH,i*2,(i*2)+BAR_WIDTH], ", "\n", "#           [original_quality, classifier_quality, decoder_quality],", "\n", "#           #yerr=[original_quality_std, classifier_quality_std, decoder_quality_std],", "\n", "#           width=BAR_WIDTH, ", "\n", "#           edgecolor=\"black\",   ", "\n", "#           color=[\"g\", \"r\", \"b\"])", "\n", "\n", "bars_ticklabels", ".", "append", "(", "(", "original_quality", ",", "classifier_quality", ",", "decoder_quality", ",", "audio_class", ")", ")", "\n", "#ticklabels.append(audio_class)", "\n", "\n", "", "bars_ticklabels", "=", "sorted", "(", "bars_ticklabels", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "ticks", "=", "[", "]", "\n", "ticklabels", "=", "[", "]", "\n", "for", "i", ",", "bars_ticklabel", "in", "enumerate", "(", "bars_ticklabels", ")", ":", "\n", "\n", "#pyplot.bar([(i*2)-BAR_WIDTH,i*2,(i*2)+BAR_WIDTH],", "\n", "#           [bars_ticklabel[0], bars_ticklabel[1], bars_ticklabel[2]],", "\n", "#           width=BAR_WIDTH, ", "\n", "#           edgecolor=\"black\",", "\n", "#           linewidth=1,", "\n", "#           color=[\"g\", \"r\", \"b\"])", "\n", "\n", "        ", "pyplot", ".", "bar", "(", "[", "(", "i", "*", "2", ")", "-", "BAR_WIDTH", "]", ",", "\n", "[", "bars_ticklabel", "[", "0", "]", "]", ",", "\n", "width", "=", "BAR_WIDTH", ",", "\n", "#edgecolor=\"black\",", "\n", "linewidth", "=", "1", ",", "\n", "color", "=", "[", "\"g\"", "]", ",", "\n", "label", "=", "\"Original\"", "if", "i", "==", "0", "else", "None", ")", "\n", "pyplot", ".", "bar", "(", "[", "(", "i", "*", "2", ")", "]", ",", "\n", "[", "bars_ticklabel", "[", "1", "]", "]", ",", "\n", "width", "=", "BAR_WIDTH", ",", "\n", "#edgecolor=\"black\",", "\n", "linewidth", "=", "1", ",", "\n", "color", "=", "[", "\"r\"", "]", ",", "\n", "label", "=", "\"Classifier\"", "if", "i", "==", "0", "else", "None", ")", "\n", "pyplot", ".", "bar", "(", "[", "(", "i", "*", "2", ")", "+", "BAR_WIDTH", "]", ",", "\n", "[", "bars_ticklabel", "[", "2", "]", "]", ",", "\n", "width", "=", "BAR_WIDTH", ",", "\n", "#edgecolor=\"black\",", "\n", "linewidth", "=", "1", ",", "\n", "color", "=", "[", "\"b\"", "]", ",", "\n", "label", "=", "\"Decoder\"", "if", "i", "==", "0", "else", "None", ")", "\n", "\n", "ticks", ".", "append", "(", "i", "*", "2", ")", "\n", "ticklabels", ".", "append", "(", "bars_ticklabel", "[", "3", "]", ")", "\n", "\n", "", "pyplot", ".", "ylabel", "(", "\"Mean quality\"", ",", "fontsize", "=", "18", ")", "\n", "pyplot", ".", "xticks", "(", "ticks", ",", "ticklabels", ",", "rotation", "=", "\"vertical\"", ")", "\n", "pyplot", ".", "gca", "(", ")", ".", "tick_params", "(", "axis", "=", "'x'", ",", "which", "=", "'major'", ",", "labelsize", "=", "18", ")", "\n", "pyplot", ".", "gca", "(", ")", ".", "tick_params", "(", "axis", "=", "'y'", ",", "which", "=", "'major'", ",", "labelsize", "=", "16", ")", "\n", "pyplot", ".", "tight_layout", "(", ")", "\n", "pyplot", ".", "legend", "(", "fontsize", "=", "15", ")", "\n", "pyplot", ".", "savefig", "(", "args", ".", "output", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "pyplot", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.main_exp_histograms": [[130, 164], ["pandas.read_csv", "numpy.array", "numpy.array", "turk_analysis.original_or_not", "turk_analysis.get_bad_worker_idxs", "dict", "numpy.unique", "numpy.unique", "numpy.unique", "numpy.unique", "matplotlib.pyplot.bar", "matplotlib.pyplot.bar", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "matplotlib.pyplot.bar", "matplotlib.pyplot.bar", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "list", "args.output.replace", "args.output.replace", "map"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.original_or_not", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.turk_analysis.get_bad_worker_idxs"], ["", "def", "main_exp_histograms", "(", "args", ")", ":", "\n", "# Plot histograms of experiment 1 vs 3 and 2 vs 4", "\n", "    ", "input_file", "=", "args", ".", "input", "\n", "data", "=", "pandas", ".", "read_csv", "(", "input_file", ")", "\n", "\n", "answer_labels", "=", "np", ".", "array", "(", "list", "(", "map", "(", "to_int", ",", "data", "[", "\"Answer.audio-naturalness.label\"", "]", ")", ")", ")", "\n", "experiment_id", "=", "np", ".", "array", "(", "data", "[", "\"Input.experiment\"", "]", ")", "\n", "workers", "=", "data", "[", "\"WorkerId\"", "]", "\n", "original", "=", "original_or_not", "(", "data", "[", "\"Input.audio_url\"", "]", ")", "\n", "\n", "# Remove bad workers and original samples", "\n", "bad_idxs", "=", "get_bad_worker_idxs", "(", "answer_labels", ",", "workers", ",", "experiment_id", ")", "\n", "bad_idxs", "=", "bad_idxs", "|", "original", "\n", "\n", "experiment_id", "=", "experiment_id", "[", "~", "bad_idxs", "]", "\n", "answer_labels", "=", "answer_labels", "[", "~", "bad_idxs", "]", "\n", "\n", "# Plot 1 vs 3", "\n", "split_by_exp", "=", "dict", "(", "[", "(", "exp_id", ",", "answer_labels", "[", "experiment_id", "==", "exp_id", "]", ")", "for", "exp_id", "in", "[", "1", ",", "2", ",", "3", ",", "4", "]", "]", ")", "\n", "\n", "unique_1", ",", "counts_1", "=", "np", ".", "unique", "(", "split_by_exp", "[", "1", "]", ",", "return_counts", "=", "True", ")", "\n", "unique_3", ",", "counts_3", "=", "np", ".", "unique", "(", "split_by_exp", "[", "3", "]", ",", "return_counts", "=", "True", ")", "\n", "unique_2", ",", "counts_2", "=", "np", ".", "unique", "(", "split_by_exp", "[", "2", "]", ",", "return_counts", "=", "True", ")", "\n", "unique_4", ",", "counts_4", "=", "np", ".", "unique", "(", "split_by_exp", "[", "4", "]", ",", "return_counts", "=", "True", ")", "\n", "\n", "pyplot", ".", "bar", "(", "unique_1", "-", "BAR_WIDTH", "/", "2", ",", "counts_1", ",", "width", "=", "BAR_WIDTH", ")", "\n", "pyplot", ".", "bar", "(", "unique_3", "+", "BAR_WIDTH", "/", "2", ",", "counts_3", ",", "width", "=", "BAR_WIDTH", ")", "\n", "pyplot", ".", "savefig", "(", "args", ".", "output", ".", "replace", "(", "\".\"", ",", "\"_noise2class.\"", ")", ")", "\n", "pyplot", ".", "show", "(", ")", "\n", "\n", "pyplot", ".", "bar", "(", "unique_2", "-", "BAR_WIDTH", "/", "2", ",", "counts_2", ",", "width", "=", "BAR_WIDTH", ")", "\n", "pyplot", ".", "bar", "(", "unique_4", "+", "BAR_WIDTH", "/", "2", ",", "counts_4", ",", "width", "=", "BAR_WIDTH", ")", "\n", "pyplot", ".", "savefig", "(", "args", ".", "output", ".", "replace", "(", "\".\"", ",", "\"_class2class.\"", ")", ")", "\n", "pyplot", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.get_loss_and_gradients": [[24, 34], ["keras.backend.mean", "keras.backend.function", "keras.backend.gradients", "keras.backend.sqrt", "keras.backend.mean", "keras.backend.square"], "function", ["None"], ["def", "get_loss_and_gradients", "(", "model", ",", "class_chosen", ")", ":", "\n", "# build a loss function that maximizes the activation of a specific class", "\n", "    ", "loss", "=", "K", ".", "mean", "(", "model", ".", "output", "[", ":", ",", "class_chosen", "]", ")", "\n", "# compute the gradient of the input picture wrt this loss", "\n", "grads", "=", "K", ".", "gradients", "(", "loss", ",", "model", ".", "input", ")", "[", "0", "]", "\n", "# normalization trick: we normalize the gradient", "\n", "grads", "/=", "(", "K", ".", "sqrt", "(", "K", ".", "mean", "(", "K", ".", "square", "(", "grads", ")", ")", ")", "+", "1e-5", ")", "\n", "# this function returns the loss and grads given the input speech", "\n", "iterate", "=", "K", ".", "function", "(", "[", "model", ".", "input", "]", ",", "[", "loss", ",", "grads", "]", ")", "\n", "return", "iterate", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.maximizeInput": [[35, 45], ["numpy.copy", "range", "iterate", "gradients.append", "numpy.linalg.norm"], "function", ["None"], ["", "def", "maximizeInput", "(", "iterate", ",", "selected_input", ",", "lr", ")", ":", "\n", "    ", "gradients", "=", "[", "]", "\n", "val", "=", "np", ".", "copy", "(", "selected_input", ")", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "_", ",", "grads_value", "=", "iterate", "(", "[", "val", "]", ")", "\n", "val", "+=", "grads_value", "*", "lr", "\n", "gradients", ".", "append", "(", "np", ".", "linalg", ".", "norm", "(", "grads_value", ")", ")", "\n", "\n", "", "return", "val", ",", "gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.init_models": [[47, 218], ["keras.layers.Input", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.models.Model", "keras.layers.Input", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model", "keras.models.Model.load_weights", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.models.Model", "keras.models.Model.load_weights", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.models.Model"], "function", ["None"], ["", "def", "init_models", "(", "autoencoder_weights", ",", "classifier_weights", ")", ":", "\n", "\n", "    ", "input_shape", "=", "Input", "(", "shape", "=", "(", "90", ",", "80", ",", "1", ")", ")", "\n", "\n", "# Encoder Layers", "\n", "conv_1", "=", "Conv2D", "(", "16", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_1", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_2", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_2", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_3", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_3", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_4", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "\n", "encoded", "=", "Flatten", "(", "name", "=", "'encoder'", ")", "\n", "\n", "# Bottleneck", "\n", "dense_1", "=", "Dense", "(", "256", ",", "name", "=", "'bottleneck'", ")", "\n", "dense_2", "=", "Dense", "(", "6400", ")", "\n", "reshape", "=", "Reshape", "(", "(", "5", ",", "10", ",", "128", ")", ")", "\n", "\n", "# Decoder Layers", "\n", "conv_5", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_1", "=", "UpSampling2D", "(", "(", "2", ",", "2", ")", ")", "\n", "conv_6", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_2", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "conv_7", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_3", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "\n", "decoded", "=", "Conv2D", "(", "1", ",", "(", "3", ",", "3", ")", ",", "activation", "=", "'sigmoid'", ",", "padding", "=", "'same'", ",", "name", "=", "'decoder'", ")", "\n", "\n", "####################################################################################################", "\n", "#-----------------------------------------Full Autoencoder-----------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "autoencoder", "=", "conv_1", "(", "input_shape", ")", "\n", "autoencoder", "=", "max_pool_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_4", "(", "autoencoder", ")", "\n", "autoencoder", "=", "encoded", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "reshape", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_5", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_6", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_7", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "decoded", "(", "autoencoder", ")", "\n", "\n", "autoencoder", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "autoencoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Encoder-------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "encoder", "=", "conv_1", "(", "input_shape", ")", "\n", "encoder", "=", "max_pool_1", "(", "encoder", ")", "\n", "encoder", "=", "conv_2", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_2", "(", "encoder", ")", "\n", "encoder", "=", "conv_3", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_3", "(", "encoder", ")", "\n", "encoder", "=", "conv_4", "(", "encoder", ")", "\n", "encoder", "=", "encoded", "(", "encoder", ")", "\n", "encoder", "=", "dense_1", "(", "encoder", ")", "\n", "\n", "encoder_model", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "encoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Decoder------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "bottleneck_input_shape", "=", "Input", "(", "shape", "=", "(", "256", ",", ")", ")", "\n", "decoder_model", "=", "dense_2", "(", "bottleneck_input_shape", ")", "\n", "decoder_model", "=", "reshape", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_5", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_1", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_6", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_2", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_7", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_3", "(", "decoder_model", ")", "\n", "decoder_model", "=", "decoded", "(", "decoder_model", ")", "\n", "\n", "decoder_model", "=", "Model", "(", "inputs", "=", "bottleneck_input_shape", ",", "outputs", "=", "decoder_model", ")", "\n", "\n", "# Initializes the layers with weights", "\n", "autoencoder", ".", "load_weights", "(", "autoencoder_weights", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Classifier----------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "# Layers", "\n", "c_conv_1", "=", "Conv2D", "(", "8", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_1", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_1", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_2", "=", "Conv2D", "(", "16", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_2", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_2", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_3", "=", "Conv2D", "(", "32", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_3", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_3", "=", "Dropout", "(", "0.2", ")", "\n", "c_flatten", "=", "Flatten", "(", ")", "\n", "c_dense_1", "=", "Dense", "(", "512", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_4", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_2", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_5", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_3", "=", "Dense", "(", "128", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_6", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_output", "=", "Dense", "(", "35", ",", "activation", "=", "'softmax'", ")", "\n", "\n", "# Model", "\n", "classifier", "=", "c_conv_1", "(", "input_shape", ")", "\n", "classifier", "=", "c_max_pool_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_1", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_2", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_2", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_3", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_3", "(", "classifier", ")", "\n", "classifier", "=", "c_flatten", "(", "classifier", ")", "\n", "\n", "classifier", "=", "c_dense_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_4", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_5", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_6", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_output", "(", "classifier", ")", "\n", "\n", "classifier", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "classifier", ")", "\n", "\n", "# Initializes the classifier's layers with weights", "\n", "classifier", ".", "load_weights", "(", "classifier_weights", ")", "\n", "\n", "combined_model", "=", "dense_2", "(", "bottleneck_input_shape", ")", "\n", "combined_model", "=", "reshape", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_5", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_1", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_6", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_2", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_7", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_3", "(", "combined_model", ")", "\n", "combined_model", "=", "decoded", "(", "combined_model", ")", "\n", "\n", "combined_model", "=", "c_conv_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_conv_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_conv_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_flatten", "(", "combined_model", ")", "\n", "\n", "combined_model", "=", "c_dense_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_4", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_5", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_6", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_output", "(", "combined_model", ")", "\n", "\n", "full_model", "=", "Model", "(", "inputs", "=", "bottleneck_input_shape", ",", "outputs", "=", "combined_model", ")", "\n", "\n", "return", "full_model", ",", "decoder_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure": [[220, 225], ["matplotlib.imshow", "matplotlib.colorbar", "matplotlib.savefig", "matplotlib.clf"], "function", ["None"], ["", "def", "plotFigure", "(", "selected_input", ",", "filename", ")", ":", "\n", "    ", "plt", ".", "imshow", "(", "selected_input", ",", "origin", "=", "'lower'", ")", "\n", "plt", ".", "colorbar", "(", ")", "\n", "plt", ".", "savefig", "(", "filename", ",", "bbox_inches", "=", "'tight'", ")", "\n", "plt", ".", "clf", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_noise_samples_classifier": [[226, 278], ["tqdm.tqdm", "range", "max_samples_perceptual.get_loss_and_gradients", "len", "print", "str", "numpy.random.normal", "original_model.predict", "max_samples_perceptual.maximizeInput", "original_model.predict", "numpy.argmax", "int", "print", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "numpy.save", "time.time", "np.random.normal.squeeze", "maximized_noise.squeeze", "maximized_noise.squeeze", "open", "pickle.dump", "np.random.normal.squeeze", "maximized_noise.squeeze"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.get_loss_and_gradients", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure"], ["", "def", "max_noise_samples_classifier", "(", "original_model", ",", "classes", ")", ":", "\n", "    ", "for", "class_idx", "in", "tqdm", "(", "range", "(", "len", "(", "classes", ")", ")", ")", ":", "\n", "\n", "# Get function which returns loss and gradients of specific neuron in output layer", "\n", "        ", "loss_grads", "=", "get_loss_and_gradients", "(", "original_model", ",", "class_idx", ")", "\n", "samples_maximized", "=", "0", "\n", "\n", "# Stop when we maximize 3 samples successfully", "\n", "while", "samples_maximized", "<", "3", ":", "\n", "            ", "print", "(", "'Trying to maximize noise to class:'", ",", "classes", "[", "class_idx", "]", ")", "\n", "timestamp", "=", "str", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "# Generate random gaussian noise", "\n", "mu", ",", "sigma", "=", "0", ",", "0.1", "# mean and standard deviation", "\n", "original_input", "=", "np", ".", "random", ".", "normal", "(", "mu", ",", "sigma", ",", "(", "(", "1", ",", "90", ",", "80", ",", "1", ")", ")", ")", "\n", "\n", "# Calculate accuracy of noise input", "\n", "orig_scores", "=", "original_model", ".", "predict", "(", "original_input", ")", "\n", "\n", "# Perform activation maximization", "\n", "maximized_noise", ",", "gradients", "=", "maximizeInput", "(", "loss_grads", ",", "original_input", ",", "0.01", ")", "\n", "\n", "# Calculate accuracy of maximized input", "\n", "new_scores", "=", "original_model", ".", "predict", "(", "maximized_noise", ")", "\n", "max_pred_class", "=", "np", ".", "argmax", "(", "new_scores", "[", "0", "]", ")", "\n", "\n", "# if sample is successfully maximized to specificed class", "\n", "if", "max_pred_class", "==", "class_idx", ":", "\n", "                ", "print", "(", "'Successfully maximized noise sample to class'", ",", "classes", "[", "class_idx", "]", ",", "'using classifier'", ")", "\n", "samples_maximized", "+=", "1", "\n", "# Plot figures of original input", "\n", "filename", "=", "'results/classifier_noise_max/sample_'", "+", "timestamp", "+", "'_before_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "original_input", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Plot figures of maximized input", "\n", "filename", "=", "'results/classifier_noise_max/sample_'", "+", "timestamp", "+", "'_after_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "maximized_noise", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Get the difference between the original and maximized input", "\n", "difference", "=", "original_input", ".", "squeeze", "(", ")", "-", "maximized_noise", ".", "squeeze", "(", ")", "\n", "filename", "=", "'results/classifier_noise_max/sample_'", "+", "timestamp", "+", "'_diff_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "difference", ".", "T", ",", "filename", ")", "\n", "\n", "# Save the maximized input for synthesis", "\n", "np", ".", "save", "(", "'results/synthesize/sample_'", "+", "timestamp", "+", "'_classifier_maximized_noise_to_class_'", "+", "classes", "[", "class_idx", "]", "+", "'.npy'", ",", "maximized_noise", ".", "squeeze", "(", ")", ")", "\n", "\n", "data", "=", "{", "\n", "0", ":", "orig_scores", ",", "\n", "1", ":", "new_scores", ",", "\n", "3", ":", "gradients", "\n", "}", "\n", "\n", "with", "open", "(", "'results/classifier_noise_max/sample_'", "+", "timestamp", "+", "'_scores_'", "+", "classes", "[", "class_idx", "]", "+", "'.pickle'", ",", "'wb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "                    ", "pickle", ".", "dump", "(", "data", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_test_samples_classifier": [[279, 349], ["numpy.load", "numpy.load", "keras.utils.to_categorical", "tqdm.tqdm", "range", "range", "numpy.random.shuffle", "max_samples_perceptual.get_loss_and_gradients", "len", "str", "numpy.random.choice", "print", "original_input.reshape.reshape", "original_model.predict", "max_samples_perceptual.maximizeInput", "original_model.predict", "numpy.argmax", "numpy.shape", "test_samples_indices.append", "int", "print", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "numpy.save", "numpy.save", "time.time", "original_input.reshape.squeeze", "maximized_input.squeeze", "original_input.reshape.squeeze", "maximized_input.squeeze", "open", "pickle.dump", "original_input.reshape.squeeze", "maximized_input.squeeze"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.get_loss_and_gradients", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure"], ["", "", "", "", "", "def", "max_test_samples_classifier", "(", "original_model", ",", "classes", ")", ":", "\n", "# Get test features", "\n", "    ", "X_test", "=", "np", ".", "load", "(", "'../../features/full_test_x.npy'", ")", "\n", "y_test", "=", "np", ".", "load", "(", "'../../features/full_test_y.npy'", ")", "\n", "y_test_hot", "=", "to_categorical", "(", "y_test", ")", "\n", "\n", "for", "class_idx", "in", "tqdm", "(", "range", "(", "len", "(", "classes", ")", ")", ")", ":", "\n", "\n", "        ", "test_samples_indices", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "np", ".", "shape", "(", "y_test_hot", ")", "[", "0", "]", ")", ":", "\n", "            ", "if", "(", "y_test_hot", "[", "j", "]", "[", "class_idx", "]", "==", "1", ")", ":", "\n", "                ", "test_samples_indices", ".", "append", "(", "j", ")", "\n", "\n", "", "", "np", ".", "random", ".", "shuffle", "(", "test_samples_indices", ")", "\n", "\n", "# Get function which returns loss and gradients of specific neuron in output layer", "\n", "loss_grads", "=", "get_loss_and_gradients", "(", "original_model", ",", "class_idx", ")", "\n", "samples_maximized", "=", "0", "\n", "\n", "# Stop when we maximize 3 samples successfully", "\n", "while", "samples_maximized", "<", "3", ":", "\n", "            ", "timestamp", "=", "str", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "\n", "# Pick sample from test set", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "test_samples_indices", ")", "\n", "print", "(", "'Trying to max sample idx:'", ",", "idx", ")", "\n", "# Pick sample from test set", "\n", "original_input", "=", "X_test", "[", "idx", "]", "\n", "original_input", "=", "original_input", ".", "reshape", "(", "1", ",", "90", ",", "80", ",", "1", ")", "\n", "\n", "# Calculate accuracy of original input", "\n", "orig_scores", "=", "original_model", ".", "predict", "(", "original_input", ")", "\n", "\n", "# Perform activation maximization", "\n", "maximized_input", ",", "gradients", "=", "maximizeInput", "(", "loss_grads", ",", "original_input", ",", "0.01", ")", "\n", "\n", "# Calculate accuracy of maximized input", "\n", "new_scores", "=", "original_model", ".", "predict", "(", "maximized_input", ")", "\n", "max_pred_class", "=", "np", ".", "argmax", "(", "new_scores", "[", "0", "]", ")", "\n", "\n", "# if sample is successfully maximized to specificed class", "\n", "if", "max_pred_class", "==", "class_idx", ":", "\n", "                ", "print", "(", "'Successfully maximized test sample to class'", ",", "classes", "[", "class_idx", "]", ",", "'using classifier'", ")", "\n", "samples_maximized", "+=", "1", "\n", "# Plot figures of original input", "\n", "filename", "=", "'results/classifier_test_max/sample_'", "+", "timestamp", "+", "'_before_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "original_input", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Plot figures of maximized input", "\n", "filename", "=", "'results/classifier_test_max/sample_'", "+", "timestamp", "+", "'_after_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "maximized_input", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Get the difference between the original and maximized input", "\n", "difference", "=", "original_input", ".", "squeeze", "(", ")", "-", "maximized_input", ".", "squeeze", "(", ")", "\n", "filename", "=", "'results/classifier_test_max/sample_'", "+", "timestamp", "+", "'_diff_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "difference", ".", "T", ",", "filename", ")", "\n", "\n", "# Save the original input for synthesis", "\n", "np", ".", "save", "(", "'results/synthesize/sample_'", "+", "timestamp", "+", "'_classifier_before_maximized_class_to_class_'", "+", "classes", "[", "class_idx", "]", "+", "'.npy'", ",", "original_input", ".", "squeeze", "(", ")", ")", "\n", "# Save the maximized input for synthesis", "\n", "np", ".", "save", "(", "'results/synthesize/sample_'", "+", "timestamp", "+", "'_classifier_after_maximized_class_to_class_'", "+", "classes", "[", "class_idx", "]", "+", "'.npy'", ",", "maximized_input", ".", "squeeze", "(", ")", ")", "\n", "\n", "\n", "data", "=", "{", "\n", "0", ":", "orig_scores", ",", "\n", "1", ":", "new_scores", ",", "\n", "3", ":", "gradients", "\n", "}", "\n", "\n", "with", "open", "(", "'results/classifier_test_max/sample_'", "+", "timestamp", "+", "'_scores_'", "+", "classes", "[", "class_idx", "]", "+", "'.pickle'", ",", "'wb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "                    ", "pickle", ".", "dump", "(", "data", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_noise_samples_classifier_decoder": [[350, 409], ["tqdm.tqdm", "range", "max_samples_perceptual.get_loss_and_gradients", "len", "print", "str", "numpy.random.normal", "numpy.expand_dims", "decoder_model.predict", "combined_model.predict", "max_samples_perceptual.maximizeInput", "decoder_model.predict", "combined_model.predict", "numpy.argmax", "int", "print", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "numpy.save", "time.time", "decoder_model.predict.squeeze", "decoder_model.predict.squeeze", "decoder_model.predict.squeeze", "open", "pickle.dump", "decoder_model.predict.squeeze", "decoder_model.predict.squeeze"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.get_loss_and_gradients", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure"], ["", "", "", "", "", "def", "max_noise_samples_classifier_decoder", "(", "combined_model", ",", "decoder_model", ",", "classes", ")", ":", "\n", "    ", "for", "class_idx", "in", "tqdm", "(", "range", "(", "len", "(", "classes", ")", ")", ")", ":", "\n", "\n", "# Get function which returns loss and gradients of specific neuron in output layer", "\n", "        ", "loss_grads", "=", "get_loss_and_gradients", "(", "combined_model", ",", "class_idx", ")", "\n", "samples_maximized", "=", "0", "\n", "\n", "# Stop when we maximize 3 samples successfully", "\n", "while", "samples_maximized", "<", "3", ":", "\n", "            ", "print", "(", "'Trying to maximize noise to class:'", ",", "classes", "[", "class_idx", "]", ")", "\n", "timestamp", "=", "str", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "# Generate random gaussian noise", "\n", "mu", ",", "sigma", "=", "0", ",", "0.1", "# mean and standard deviation", "\n", "original_input", "=", "np", ".", "random", ".", "normal", "(", "mu", ",", "sigma", ",", "256", ")", "\n", "original_input", "=", "np", ".", "expand_dims", "(", "original_input", ",", "0", ")", "\n", "\n", "# Decode original bottleneck code", "\n", "original_input_decoded", "=", "decoder_model", ".", "predict", "(", "original_input", ")", "\n", "\n", "# Calculate accuracy of noise input", "\n", "orig_scores", "=", "combined_model", ".", "predict", "(", "original_input", ")", "\n", "\n", "# Perform activation maximization", "\n", "maximized_noise", ",", "gradients", "=", "maximizeInput", "(", "loss_grads", ",", "original_input", ",", "0.1", ")", "\n", "\n", "# Decode maximized bottleneck code", "\n", "maximized_input_decoded", "=", "decoder_model", ".", "predict", "(", "maximized_noise", ")", "\n", "\n", "# Calculate accuracy of maximized input", "\n", "new_scores", "=", "combined_model", ".", "predict", "(", "maximized_noise", ")", "\n", "max_pred_class", "=", "np", ".", "argmax", "(", "new_scores", "[", "0", "]", ")", "\n", "\n", "# if sample is successfully maximized to specificed class", "\n", "if", "max_pred_class", "==", "class_idx", ":", "\n", "                ", "print", "(", "'Successfully maximized noise sample to class'", ",", "classes", "[", "class_idx", "]", ",", "'using classifier and decoder'", ")", "\n", "samples_maximized", "+=", "1", "\n", "# Plot figures of original input", "\n", "filename", "=", "'results/combined_noise_max/sample_'", "+", "timestamp", "+", "'_before_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "original_input_decoded", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Plot figures of maximized input", "\n", "filename", "=", "'results/combined_noise_max/sample_'", "+", "timestamp", "+", "'_after_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "maximized_input_decoded", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Get the difference between the original and maximized input", "\n", "difference", "=", "original_input_decoded", ".", "squeeze", "(", ")", "-", "maximized_input_decoded", ".", "squeeze", "(", ")", "\n", "filename", "=", "'results/combined_noise_max/sample_'", "+", "timestamp", "+", "'_diff_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "difference", ".", "T", ",", "filename", ")", "\n", "\n", "# Save the maximized input for synthesis", "\n", "np", ".", "save", "(", "'results/synthesize/sample_'", "+", "timestamp", "+", "'_classifier_decoder_maximized_noise_to_class_'", "+", "classes", "[", "class_idx", "]", "+", "'.npy'", ",", "maximized_input_decoded", ".", "squeeze", "(", ")", ")", "\n", "\n", "data", "=", "{", "\n", "0", ":", "orig_scores", ",", "\n", "1", ":", "new_scores", ",", "\n", "3", ":", "gradients", "\n", "}", "\n", "\n", "with", "open", "(", "'results/combined_noise_max/sample_'", "+", "timestamp", "+", "'_scores_'", "+", "classes", "[", "class_idx", "]", "+", "'.pickle'", ",", "'wb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "                    ", "pickle", ".", "dump", "(", "data", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_test_samples_classifier_decoder": [[410, 487], ["numpy.load", "numpy.load", "keras.utils.to_categorical", "tqdm.tqdm", "range", "range", "numpy.random.shuffle", "max_samples_perceptual.get_loss_and_gradients", "len", "str", "numpy.random.choice", "print", "print", "decoder_model.predict", "combined_model.predict", "numpy.argmax", "print", "max_samples_perceptual.maximizeInput", "decoder_model.predict", "combined_model.predict", "numpy.argmax", "numpy.shape", "test_samples_indices.append", "int", "str", "print", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "max_samples_perceptual.plotFigure", "numpy.save", "numpy.save", "time.time", "decoder_model.predict.squeeze", "decoder_model.predict.squeeze", "decoder_model.predict.squeeze", "decoder_model.predict.squeeze", "open", "pickle.dump", "int", "decoder_model.predict.squeeze", "decoder_model.predict.squeeze"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.get_loss_and_gradients", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.plotFigure"], ["", "", "", "", "", "def", "max_test_samples_classifier_decoder", "(", "combined_model", ",", "decoder_model", ",", "classes", ")", ":", "\n", "# Get test features", "\n", "    ", "X_test", "=", "np", ".", "load", "(", "'../../features/full_test_x_encoded.npy'", ")", "\n", "y_test", "=", "np", ".", "load", "(", "'../../features/full_test_y.npy'", ")", "\n", "y_test_hot", "=", "to_categorical", "(", "y_test", ")", "\n", "\n", "for", "class_idx", "in", "tqdm", "(", "range", "(", "len", "(", "classes", ")", ")", ")", ":", "\n", "\n", "        ", "test_samples_indices", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "np", ".", "shape", "(", "y_test_hot", ")", "[", "0", "]", ")", ":", "\n", "            ", "if", "(", "y_test_hot", "[", "j", "]", "[", "class_idx", "]", "==", "1", ")", ":", "\n", "                ", "test_samples_indices", ".", "append", "(", "j", ")", "\n", "\n", "", "", "np", ".", "random", ".", "shuffle", "(", "test_samples_indices", ")", "\n", "\n", "# Get function which returns loss and gradients of specific neuron in output layer", "\n", "loss_grads", "=", "get_loss_and_gradients", "(", "combined_model", ",", "class_idx", ")", "\n", "samples_maximized", "=", "0", "\n", "\n", "# Stop when we maximize 3 samples successfully", "\n", "while", "samples_maximized", "<", "3", ":", "\n", "            ", "timestamp", "=", "str", "(", "int", "(", "time", ".", "time", "(", ")", ")", ")", "\n", "\n", "idx", "=", "np", ".", "random", ".", "choice", "(", "test_samples_indices", ")", "\n", "print", "(", "'y label sample idx:'", ",", "str", "(", "idx", ")", ",", "'belongs to class'", ",", "classes", "[", "int", "(", "y_test", "[", "idx", "]", ")", "]", ")", "\n", "print", "(", "'Maximizing to class'", ",", "classes", "[", "class_idx", "]", ")", "\n", "# Pick sample from test set", "\n", "original_input", "=", "X_test", "[", "idx", "]", "\n", "\n", "# Decode original bottleneck code", "\n", "original_input_decoded", "=", "decoder_model", ".", "predict", "(", "original_input", ")", "\n", "\n", "# Calculate accuracy of noise input", "\n", "orig_scores", "=", "combined_model", ".", "predict", "(", "original_input", ")", "\n", "max_idx_orig", "=", "np", ".", "argmax", "(", "orig_scores", "[", "0", "]", ")", "\n", "print", "(", "'Predicted originally as:'", ",", "max_idx_orig", ")", "\n", "\n", "# Perform activation maximization", "\n", "maximized_input", ",", "gradients", "=", "maximizeInput", "(", "loss_grads", ",", "original_input", ",", "0.1", ")", "\n", "\n", "# Decode maximized bottleneck code", "\n", "maximized_input_decoded", "=", "decoder_model", ".", "predict", "(", "maximized_input", ")", "\n", "\n", "# Calculate accuracy of maximized input", "\n", "new_scores", "=", "combined_model", ".", "predict", "(", "maximized_input", ")", "\n", "max_pred_class", "=", "np", ".", "argmax", "(", "new_scores", "[", "0", "]", ")", "\n", "\n", "# if sample is successfully maximized to specificed class", "\n", "if", "max_pred_class", "==", "class_idx", ":", "\n", "                ", "print", "(", "'Successfully maximized test sample to class'", ",", "classes", "[", "class_idx", "]", ",", "'using classifier and decoder'", ")", "\n", "samples_maximized", "+=", "1", "\n", "# Plot figures of original input", "\n", "filename", "=", "'results/combined_text_max/sample_'", "+", "timestamp", "+", "'_before_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "original_input_decoded", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Plot figures of maximized input", "\n", "filename", "=", "'results/combined_text_max/sample_'", "+", "timestamp", "+", "'_after_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "maximized_input_decoded", ".", "squeeze", "(", ")", ".", "T", ",", "filename", ")", "\n", "# Get the difference between the original and maximized input", "\n", "difference", "=", "original_input_decoded", ".", "squeeze", "(", ")", "-", "maximized_input_decoded", ".", "squeeze", "(", ")", "\n", "filename", "=", "'results/combined_text_max/sample_'", "+", "timestamp", "+", "'_diff_class_'", "+", "classes", "[", "class_idx", "]", "+", "'_maximized.png'", "\n", "plotFigure", "(", "difference", ".", "T", ",", "filename", ")", "\n", "\n", "# Save the original input for synthesis", "\n", "np", ".", "save", "(", "'results/synthesize/sample_'", "+", "timestamp", "+", "'_classifier_decoder_before_maximized_class_to_class_'", "+", "classes", "[", "class_idx", "]", "+", "'.npy'", ",", "original_input_decoded", ".", "squeeze", "(", ")", ")", "\n", "# Save the maximized input for synthesis", "\n", "np", ".", "save", "(", "'results/synthesize/sample_'", "+", "timestamp", "+", "'_classifier_decoder_after_maximized_class_to_class_'", "+", "classes", "[", "class_idx", "]", "+", "'.npy'", ",", "maximized_input_decoded", ".", "squeeze", "(", ")", ")", "\n", "\n", "\n", "data", "=", "{", "\n", "0", ":", "orig_scores", ",", "\n", "1", ":", "new_scores", ",", "\n", "3", ":", "gradients", "\n", "}", "\n", "\n", "with", "open", "(", "'results/combined_text_max/sample_'", "+", "timestamp", "+", "'_scores_'", "+", "classes", "[", "class_idx", "]", "+", "'.pickle'", ",", "'wb'", ")", "as", "f", ":", "\n", "# Pickle the 'data' dictionary using the highest protocol available.", "\n", "                    ", "pickle", ".", "dump", "(", "data", ",", "f", ",", "pickle", ".", "HIGHEST_PROTOCOL", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.main": [[488, 514], ["max_samples_perceptual.init_models", "keras.models.load_model", "os.listdir", "max_samples_perceptual.max_noise_samples_classifier", "max_samples_perceptual.max_test_samples_classifier", "max_samples_perceptual.max_noise_samples_classifier_decoder", "max_samples_perceptual.max_test_samples_classifier_decoder", "os.path.exists", "os.makedirs"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_decoder_10k.init_models", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_noise_samples_classifier", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_test_samples_classifier", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_noise_samples_classifier_decoder", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.perceptual.max_samples_perceptual.max_test_samples_classifier_decoder"], ["", "", "", "", "", "def", "main", "(", ")", ":", "\n", "# \"combined_models\" is the speech classifier and decoder (prior) combined.", "\n", "    ", "combined_model", ",", "decoder_model", "=", "init_models", "(", "'../../models/autoencoder_weights.h5'", ",", "'../../models/speech_classifier_weights.h5'", ")", "\n", "# \"original_model\" is the original speech classifier model", "\n", "original_model", "=", "load_model", "(", "'../../models/speech_classifier_model.h5'", ")", "\n", "\n", "# Gets labels", "\n", "classes", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "\n", "directories", "=", "[", "'results'", ",", "'results/classifier_noise_max'", ",", "'results/classifier_test_max'", ",", "\n", "'results/combined_noise_max'", ",", "'results/combined_text_max'", ",", "'results/synthesize'", "]", "\n", "for", "d", "in", "directories", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n", "# Generate maximized features from noise using only classifier", "\n", "", "", "max_noise_samples_classifier", "(", "original_model", ",", "classes", ")", "\n", "\n", "# Generate maximized features from test samples using only classifier", "\n", "max_test_samples_classifier", "(", "original_model", ",", "classes", ")", "\n", "\n", "# Generate maximized features from noise samples using combined classifier and decoder model", "\n", "max_noise_samples_classifier_decoder", "(", "combined_model", ",", "decoder_model", ",", "classes", ")", "\n", "\n", "# Generate maximized features from test samples using combined classifier and decoder model", "\n", "max_test_samples_classifier_decoder", "(", "combined_model", ",", "decoder_model", ",", "classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.latent_tsne.get_indices": [[34, 40], ["numpy.array", "enumerate", "zip"], "function", ["None"], ["def", "get_indices", "(", "speaker_set", ",", "command_set", ")", ":", "\n", "  ", "return", "np", ".", "array", "(", "\n", "[", "i", "\n", "for", "i", ",", "(", "s", ",", "c", ")", "in", "enumerate", "(", "zip", "(", "y_speaker", ",", "y_command", ")", ")", "\n", "if", "s", "in", "speaker_set", "and", "\n", "c", "in", "command_set", "]", ",", "dtype", "=", "'int32'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.latent_tsne.get_data": [[41, 75], ["latent_tsne.get_indices", "TSNE", "TSNE.fit_transform", "scipy.stats.itemfreq", "scipy.stats.itemfreq", "scipy.stats.itemfreq", "scipy.stats.itemfreq", "numpy.array", "numpy.concatenate", "numpy.argsort", "numpy.argsort", "y_missed.astype", "y_missed.astype", "top_spk[].astype"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.latent_tsne.get_indices"], ["", "def", "get_data", "(", "n_cmd", ",", "n_spk", ",", "only_missed", "=", "False", ")", ":", "\n", "  ", "if", "only_missed", ":", "\n", "# most popular MIS-CLASSIFIED command based on utterances count", "\n", "    ", "top_cmd", "=", "itemfreq", "(", "y_command", "[", "y_missed", ".", "astype", "(", "'int32'", ")", "]", ")", "\n", "top_spk", "=", "itemfreq", "(", "y_speaker", "[", "y_missed", ".", "astype", "(", "'int32'", ")", "]", ")", "\n", "", "else", ":", "\n", "    ", "top_spk", "=", "itemfreq", "(", "y_speaker", ")", "\n", "top_cmd", "=", "itemfreq", "(", "y_command", ")", "\n", "", "top_cmd", "=", "top_cmd", "[", "np", ".", "argsort", "(", "top_cmd", "[", ":", ",", "1", "]", ")", "]", "[", ":", ":", "-", "1", "]", "\n", "top_cmd", "=", "top_cmd", "[", ":", ",", "0", "]", "\n", "\n", "# most speaker command based on utterances count", "\n", "top_spk", "=", "top_spk", "[", "np", ".", "argsort", "(", "top_spk", "[", ":", ",", "1", "]", ".", "astype", "(", "'int32'", ")", ")", "]", "[", ":", ":", "-", "1", "]", "\n", "top_spk", "=", "top_spk", "[", ":", ",", "0", "]", "\n", "\n", "spk", "=", "top_spk", "[", ":", "n_spk", "]", "\n", "cmd", "=", "top_cmd", "[", ":", "n_cmd", "]", "\n", "ids", "=", "get_indices", "(", "speaker_set", "=", "spk", ",", "command_set", "=", "cmd", ")", "\n", "if", "only_missed", ":", "\n", "    ", "ids", "=", "np", ".", "array", "(", "[", "i", "for", "i", "in", "ids", "if", "i", "in", "y_missed", "]", ",", "\n", "dtype", "=", "'int32'", ")", "\n", "\n", "", "y_cmd", "=", "y_command", "[", "ids", "]", "\n", "y_spk", "=", "y_speaker", "[", "ids", "]", "\n", "\n", "z_org", "=", "Z_original", "[", "ids", "]", "\n", "z_max", "=", "Z_maximize", "[", "ids", "]", "\n", "\n", "tsne", "=", "TSNE", "(", "random_state", "=", "SEED", ")", "\n", "t", "=", "tsne", ".", "fit_transform", "(", "np", ".", "concatenate", "(", "(", "z_org", ",", "z_max", ")", ",", "axis", "=", "0", ")", ")", "\n", "t_org", "=", "t", "[", ":", "z_org", ".", "shape", "[", "0", "]", "]", "\n", "t_max", "=", "t", "[", "z_org", ".", "shape", "[", "0", "]", ":", "]", "\n", "\n", "return", "t_org", ",", "t_max", ",", "y_cmd", ",", "y_spk", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.latent_tsne.plot_maximizing_command_differences": [[80, 126], ["seaborn.color_palette", "latent_tsne.get_data", "numpy.concatenate", "numpy.array", "matplotlib.pyplot.figure", "seaborn.scatterplot", "zip", "matplotlib.pyplot.legend", "matplotlib.pyplot.xticks", "matplotlib.pyplot.yticks", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.gcf().savefig", "numpy.max", "numpy.min", "matplotlib.pyplot.arrow", "pandas.DataFrame", "matplotlib.pyplot.gcf", "numpy.abs", "numpy.abs", "numpy.concatenate", "numpy.concatenate"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.latent_tsne.get_data"], ["", "def", "plot_maximizing_command_differences", "(", "n_cmd", ",", "n_spk", ",", "save_path", ",", "\n", "arrow_head", "=", "0.25", ")", ":", "\n", "  ", "palette", "=", "sns", ".", "color_palette", "(", "n_colors", "=", "n_cmd", ")", "\n", "t_org", ",", "t_max", ",", "y_cmd", ",", "y_spk", "=", "get_data", "(", "n_cmd", ",", "n_spk", ",", "only_missed", "=", "True", ")", "\n", "t", "=", "np", ".", "concatenate", "(", "(", "t_org", ",", "t_max", ")", ",", "axis", "=", "0", ")", "\n", "status", "=", "np", ".", "array", "(", "[", "'Original'", "]", "*", "t_org", ".", "shape", "[", "0", "]", "+", "\n", "[", "'Maximized'", "]", "*", "t_max", ".", "shape", "[", "0", "]", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "12", ")", ")", "\n", "\n", "sns", ".", "scatterplot", "(", "\n", "x", "=", "'x'", ",", "y", "=", "'y'", ",", "\n", "hue", "=", "'Command ID'", ",", "\n", "style", "=", "'Status'", ",", "\n", "# size=500,", "\n", "# size_order=['Maximize', 'Original'],", "\n", "alpha", "=", "0.66", ",", "\n", "data", "=", "pd", ".", "DataFrame", "(", "{", "\n", "'x'", ":", "t", "[", ":", ",", "0", "]", ",", "'y'", ":", "t", "[", ":", ",", "1", "]", ",", "\n", "'Command ID'", ":", "np", ".", "concatenate", "(", "(", "y_cmd", ",", "y_cmd", ")", ")", ",", "\n", "'Speaker ID'", ":", "np", ".", "concatenate", "(", "(", "y_spk", ",", "y_spk", ")", ")", ",", "\n", "'Status'", ":", "status", "}", ")", ",", "\n", "palette", "=", "palette", ",", "\n", "s", "=", "120", ")", "\n", "# ====== draw the arrow ====== #", "\n", "max_d", "=", "np", ".", "max", "(", "t", ")", "-", "np", ".", "min", "(", "t", ")", "\n", "for", "x_org", ",", "x_max", "in", "zip", "(", "t_org", ",", "t_max", ")", ":", "\n", "    ", "if", "np", ".", "abs", "(", "x_max", "[", "0", "]", "-", "x_org", "[", "0", "]", ")", "<", "0.01", "*", "max_d", "and", "np", ".", "abs", "(", "x_max", "[", "1", "]", "-", "x_org", "[", "1", "]", ")", "<", "0.01", "*", "max_d", ":", "\n", "      ", "continue", "\n", "", "plt", ".", "arrow", "(", "\n", "x_org", "[", "0", "]", ",", "x_org", "[", "1", "]", ",", "\n", "0.95", "*", "(", "x_max", "[", "0", "]", "-", "x_org", "[", "0", "]", ")", ",", "\n", "0.95", "*", "(", "x_max", "[", "1", "]", "-", "x_org", "[", "1", "]", ")", ",", "\n", "linewidth", "=", "1", ",", "\n", "linestyle", "=", "'--'", ",", "\n", "head_width", "=", "arrow_head", ",", "\n", "head_length", "=", "arrow_head", ",", "\n", "color", "=", "'red'", ",", "\n", "alpha", "=", "0.8", "\n", ")", "\n", "\n", "", "plt", ".", "legend", "(", "fontsize", "=", "16", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ",", "[", "]", ")", ";", "plt", ".", "yticks", "(", "[", "]", ",", "[", "]", ")", "\n", "plt", ".", "xlabel", "(", "None", ")", ";", "plt", ".", "ylabel", "(", "None", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "savefig", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.latent_tsne.plot_speaker_effect": [[134, 184], ["seaborn.color_palette", "latent_tsne.get_data", "numpy.concatenate", "numpy.array", "matplotlib.pyplot.figure", "seaborn.scatterplot", "zip", "zip", "matplotlib.pyplot.legend", "matplotlib.pyplot.xticks", "matplotlib.pyplot.yticks", "matplotlib.pyplot.xlabel", "matplotlib.pyplot.ylabel", "matplotlib.pyplot.gcf().savefig", "matplotlib.pyplot.text", "pandas.DataFrame", "numpy.random.rand", "float", "matplotlib.pyplot.arrow", "matplotlib.pyplot.gcf", "numpy.concatenate", "numpy.concatenate", "str"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.latent_tsne.get_data"], ["def", "plot_speaker_effect", "(", "n_cmd", ",", "n_spk", ",", "save_path", ",", "\n", "arrow_head", "=", "0.25", ",", "\n", "arrow_percent", "=", "1.0", ")", ":", "\n", "  ", "palette", "=", "sns", ".", "color_palette", "(", "n_colors", "=", "n_spk", ")", "\n", "t_org", ",", "t_max", ",", "y_cmd", ",", "y_spk", "=", "get_data", "(", "n_cmd", ",", "n_spk", ",", "only_missed", "=", "False", ")", "\n", "t", "=", "np", ".", "concatenate", "(", "(", "t_org", ",", "t_max", ")", ",", "axis", "=", "0", ")", "\n", "status", "=", "np", ".", "array", "(", "[", "'Original'", "]", "*", "t_org", ".", "shape", "[", "0", "]", "+", "\n", "[", "'Maximized'", "]", "*", "t_max", ".", "shape", "[", "0", "]", ")", "\n", "\n", "plt", ".", "figure", "(", "figsize", "=", "(", "12", ",", "12", ")", ")", "\n", "sns", ".", "scatterplot", "(", "\n", "x", "=", "'x'", ",", "y", "=", "'y'", ",", "\n", "hue", "=", "'Speaker ID'", ",", "\n", "style", "=", "'Status'", ",", "\n", "# size=500,", "\n", "# size_order=['Maximize', 'Original'],", "\n", "alpha", "=", "0.66", ",", "\n", "data", "=", "pd", ".", "DataFrame", "(", "{", "\n", "'x'", ":", "t", "[", ":", ",", "0", "]", ",", "'y'", ":", "t", "[", ":", ",", "1", "]", ",", "\n", "'Command ID'", ":", "np", ".", "concatenate", "(", "(", "y_cmd", ",", "y_cmd", ")", ")", ",", "\n", "'Speaker ID'", ":", "np", ".", "concatenate", "(", "(", "y_spk", ",", "y_spk", ")", ")", ",", "\n", "'Status'", ":", "status", "}", ")", ",", "\n", "palette", "=", "palette", ",", "\n", "s", "=", "188", ")", "\n", "# ====== add the text of the command ====== #", "\n", "for", "(", "x", ",", "y", ")", ",", "c", "in", "zip", "(", "t_max", ",", "y_cmd", ")", ":", "\n", "    ", "plt", ".", "text", "(", "x", ",", "y", ",", "s", "=", "'  '", "+", "str", "(", "c", ")", ",", "\n", "fontsize", "=", "12", ",", "\n", "# horizontalalignment='center',", "\n", "# verticalalignment='center'", "\n", ")", "\n", "# ====== draw the arrow ====== #", "\n", "", "for", "x_org", ",", "x_max", "in", "zip", "(", "t_org", ",", "t_max", ")", ":", "\n", "    ", "if", "np", ".", "random", ".", "rand", "(", ")", "<", "float", "(", "arrow_percent", ")", ":", "\n", "      ", "plt", ".", "arrow", "(", "\n", "x_org", "[", "0", "]", ",", "x_org", "[", "1", "]", ",", "\n", "0.95", "*", "(", "x_max", "[", "0", "]", "-", "x_org", "[", "0", "]", ")", ",", "\n", "0.95", "*", "(", "x_max", "[", "1", "]", "-", "x_org", "[", "1", "]", ")", ",", "\n", "linewidth", "=", "1", ",", "\n", "linestyle", "=", "'--'", ",", "\n", "head_width", "=", "arrow_head", ",", "\n", "head_length", "=", "arrow_head", ",", "\n", "color", "=", "'red'", ",", "\n", "alpha", "=", "0.8", "\n", ")", "\n", "\n", "", "", "plt", ".", "legend", "(", "fontsize", "=", "16", ")", "\n", "plt", ".", "xticks", "(", "[", "]", ",", "[", "]", ")", ";", "plt", ".", "yticks", "(", "[", "]", ",", "[", "]", ")", "\n", "plt", ".", "xlabel", "(", "None", ")", ";", "plt", ".", "ylabel", "(", "None", ")", "\n", "plt", ".", "gcf", "(", ")", ".", "savefig", "(", "save_path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.prepare_data.maximizeInput": [[18, 29], ["numpy.copy", "range", "iterate", "gradients.append", "numpy.linalg.norm"], "function", ["None"], ["def", "maximizeInput", "(", "iterate", ",", "selected_input", ")", ":", "\n", "    ", "rate", "=", "0.1", "\n", "gradients", "=", "[", "]", "\n", "val", "=", "np", ".", "copy", "(", "selected_input", ")", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "_", ",", "grads_value", "=", "iterate", "(", "[", "val", "]", ")", "\n", "val", "+=", "grads_value", "*", "rate", "\n", "gradients", ".", "append", "(", "np", ".", "linalg", ".", "norm", "(", "grads_value", ")", ")", "\n", "\n", "", "return", "val", ",", "gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.prepare_data.init_models": [[30, 200], ["keras.layers.Input", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.models.Model", "keras.layers.Input", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model", "keras.models.Model.load_weights", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.models.Model", "keras.models.Model.load_weights", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.models.Model"], "function", ["None"], ["", "def", "init_models", "(", "autoencoder_weights", ",", "classifier_weights", ")", ":", "\n", "    ", "input_shape", "=", "Input", "(", "shape", "=", "(", "90", ",", "80", ",", "1", ")", ")", "\n", "\n", "# Encoder Layers", "\n", "conv_1", "=", "Conv2D", "(", "16", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_1", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_2", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_2", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_3", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_3", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_4", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "\n", "encoded", "=", "Flatten", "(", "name", "=", "'encoder'", ")", "\n", "\n", "# Bottleneck", "\n", "dense_1", "=", "Dense", "(", "256", ",", "name", "=", "'bottleneck'", ")", "\n", "dense_2", "=", "Dense", "(", "6400", ")", "\n", "reshape", "=", "Reshape", "(", "(", "5", ",", "10", ",", "128", ")", ")", "\n", "\n", "# Decoder Layers", "\n", "conv_5", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_1", "=", "UpSampling2D", "(", "(", "2", ",", "2", ")", ")", "\n", "conv_6", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_2", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "conv_7", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_3", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "\n", "decoded", "=", "Conv2D", "(", "1", ",", "(", "3", ",", "3", ")", ",", "activation", "=", "'sigmoid'", ",", "padding", "=", "'same'", ",", "name", "=", "'decoder'", ")", "\n", "\n", "####################################################################################################", "\n", "#-----------------------------------------Full Autoencoder-----------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "autoencoder", "=", "conv_1", "(", "input_shape", ")", "\n", "autoencoder", "=", "max_pool_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_4", "(", "autoencoder", ")", "\n", "autoencoder", "=", "encoded", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "reshape", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_5", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_6", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_7", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "decoded", "(", "autoencoder", ")", "\n", "\n", "autoencoder", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "autoencoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Encoder-------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "encoder", "=", "conv_1", "(", "input_shape", ")", "\n", "encoder", "=", "max_pool_1", "(", "encoder", ")", "\n", "encoder", "=", "conv_2", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_2", "(", "encoder", ")", "\n", "encoder", "=", "conv_3", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_3", "(", "encoder", ")", "\n", "encoder", "=", "conv_4", "(", "encoder", ")", "\n", "encoder", "=", "encoded", "(", "encoder", ")", "\n", "encoder", "=", "dense_1", "(", "encoder", ")", "\n", "\n", "encoder_model", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "encoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Decoder------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "bottleneck_input_shape", "=", "Input", "(", "shape", "=", "(", "256", ",", ")", ")", "\n", "decoder_model", "=", "dense_2", "(", "bottleneck_input_shape", ")", "\n", "decoder_model", "=", "reshape", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_5", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_1", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_6", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_2", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_7", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_3", "(", "decoder_model", ")", "\n", "decoder_model", "=", "decoded", "(", "decoder_model", ")", "\n", "\n", "decoder_model", "=", "Model", "(", "inputs", "=", "bottleneck_input_shape", ",", "outputs", "=", "decoder_model", ")", "\n", "\n", "# Initializes the layers with weights", "\n", "autoencoder", ".", "load_weights", "(", "autoencoder_weights", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Classifier----------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "# Layers", "\n", "c_conv_1", "=", "Conv2D", "(", "8", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_1", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_1", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_2", "=", "Conv2D", "(", "16", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_2", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_2", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_3", "=", "Conv2D", "(", "32", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_3", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_3", "=", "Dropout", "(", "0.2", ")", "\n", "c_flatten", "=", "Flatten", "(", ")", "\n", "c_dense_1", "=", "Dense", "(", "512", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_4", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_2", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_5", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_3", "=", "Dense", "(", "128", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_6", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_output", "=", "Dense", "(", "35", ",", "activation", "=", "'softmax'", ")", "\n", "\n", "# Model", "\n", "classifier", "=", "c_conv_1", "(", "input_shape", ")", "\n", "classifier", "=", "c_max_pool_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_1", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_2", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_2", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_3", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_3", "(", "classifier", ")", "\n", "classifier", "=", "c_flatten", "(", "classifier", ")", "\n", "\n", "classifier", "=", "c_dense_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_4", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_5", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_6", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_output", "(", "classifier", ")", "\n", "\n", "classifier", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "classifier", ")", "\n", "\n", "# Initializes the classifier's layers with weights", "\n", "classifier", ".", "load_weights", "(", "classifier_weights", ")", "\n", "\n", "combined_model", "=", "dense_2", "(", "bottleneck_input_shape", ")", "\n", "combined_model", "=", "reshape", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_5", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_1", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_6", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_2", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_7", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_3", "(", "combined_model", ")", "\n", "combined_model", "=", "decoded", "(", "combined_model", ")", "\n", "\n", "combined_model", "=", "c_conv_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_conv_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_conv_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_flatten", "(", "combined_model", ")", "\n", "\n", "combined_model", "=", "c_dense_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_4", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_5", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_6", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_output", "(", "combined_model", ")", "\n", "\n", "full_model", "=", "Model", "(", "inputs", "=", "bottleneck_input_shape", ",", "outputs", "=", "combined_model", ")", "\n", "\n", "return", "full_model", ",", "decoder_model", ",", "encoder_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.prepare_data.extract_speaker_labels": [[201, 211], ["os.listdir", "tqdm.tqdm", "speaker_labels.append", "os.listdir", "os.path.splitext", "filename.split", "os.path.basename"], "function", ["None"], ["", "def", "extract_speaker_labels", "(", "in_dir", ")", ":", "\n", "    ", "labels", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "speaker_labels", "=", "[", "]", "\n", "for", "label", "in", "tqdm", "(", "labels", ")", ":", "\n", "        ", "wavfiles", "=", "[", "in_dir", "+", "label", "+", "'/'", "+", "wavfile", "for", "wavfile", "in", "os", ".", "listdir", "(", "in_dir", "+", "label", ")", "]", "\n", "for", "wavfile", "in", "wavfiles", ":", "\n", "            ", "filename", "=", "os", ".", "path", ".", "splitext", "(", "os", ".", "path", ".", "basename", "(", "wavfile", ")", ")", "[", "0", "]", "\n", "speaker_id", "=", "filename", ".", "split", "(", "'_'", ")", "[", "0", "]", "\n", "speaker_labels", ".", "append", "(", "speaker_id", ")", "\n", "", "", "return", "speaker_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.prepare_data.get_maximized_latents": [[212, 246], ["range", "tqdm.tqdm", "len", "keras.backend.mean", "keras.backend.function", "range", "full_model.predict", "numpy.argmax", "numpy.argmax", "prepare_data.maximizeInput", "maximized_samples.append", "keras.backend.gradients", "keras.backend.sqrt", "misclassified_indices.append", "keras.backend.mean", "numpy.shape", "keras.backend.square"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput"], ["", "def", "get_maximized_latents", "(", "classes", ",", "full_model", ",", "X_test", ",", "y_test", ")", ":", "\n", "    ", "maximized_samples", "=", "[", "]", "\n", "misclassified_indices", "=", "[", "]", "\n", "\n", "iterate_func", "=", "{", "}", "\n", "\n", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", ":", "\n", "# build a loss function that maximizes the activation of a specific class", "\n", "        ", "loss", "=", "K", ".", "mean", "(", "full_model", ".", "output", "[", ":", ",", "i", "]", ")", "\n", "# compute the gradient of the input picture wrt this loss", "\n", "grads", "=", "K", ".", "gradients", "(", "loss", ",", "full_model", ".", "input", ")", "[", "0", "]", "\n", "# normalization trick: we normalize the gradient", "\n", "grads", "/=", "(", "K", ".", "sqrt", "(", "K", ".", "mean", "(", "K", ".", "square", "(", "grads", ")", ")", ")", "+", "1e-5", ")", "\n", "# this function returns the loss and grads given the input speech", "\n", "iterate", "=", "K", ".", "function", "(", "[", "full_model", ".", "input", "]", ",", "[", "loss", ",", "grads", "]", ")", "\n", "\n", "iterate_func", "[", "i", "]", "=", "iterate", "\n", "\n", "", "for", "i", "in", "tqdm", "(", "range", "(", "np", ".", "shape", "(", "X_test", ")", "[", "0", "]", ")", ")", ":", "\n", "        ", "original_input", "=", "X_test", "[", "i", "]", "\n", "\n", "# Calculate accuracy of noise input with both classifiers", "\n", "o_score_1", "=", "full_model", ".", "predict", "(", "original_input", ")", "\n", "class_predicted", "=", "np", ".", "argmax", "(", "o_score_1", "[", "0", "]", ")", "\n", "\n", "class_index", "=", "np", ".", "argmax", "(", "y_test", "[", "i", "]", ")", "\n", "\n", "if", "class_index", "!=", "class_predicted", ":", "\n", "            ", "misclassified_indices", ".", "append", "(", "i", ")", "\n", "\n", "", "maximized_noise", ",", "_", "=", "maximizeInput", "(", "iterate_func", "[", "class_index", "]", ",", "original_input", ")", "\n", "maximized_samples", ".", "append", "(", "maximized_noise", ")", "\n", "\n", "", "return", "maximized_samples", ",", "misclassified_indices", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.prepare_data.main": [[247, 262], ["prepare_data.init_models", "os.listdir", "prepare_data.extract_speaker_labels", "numpy.save", "numpy.load", "numpy.load", "keras.utils.to_categorical", "prepare_data.get_maximized_latents", "numpy.save", "numpy.save"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_decoder_10k.init_models", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.prepare_data.extract_speaker_labels", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tests.test_model.to_categorical", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.tsne.prepare_data.get_maximized_latents"], ["", "def", "main", "(", ")", ":", "\n", "    ", "full_model", ",", "_", ",", "_", "=", "init_models", "(", "'../../models/autoencoder_weights.h5'", ",", "'../../models/speech_classifier_weights.h5'", ")", "\n", "classes", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "\n", "speaker_labels", "=", "extract_speaker_labels", "(", "'../../dataset/testing/'", ")", "\n", "np", ".", "save", "(", "'../../features/full_test_speaker_ids.npy'", ",", "speaker_labels", ")", "\n", "\n", "X_test", "=", "np", ".", "load", "(", "'../../features/full_test_x_encoded.npy'", ")", "\n", "y_test", "=", "np", ".", "load", "(", "'../../features/full_test_y.npy'", ")", "\n", "\n", "y_test", "=", "to_categorical", "(", "y_test", ")", "\n", "\n", "maximized_samples", ",", "misclassified_indices", "=", "get_maximized_latents", "(", "classes", ",", "full_model", ",", "X_test", ",", "y_test", ")", "\n", "np", ".", "save", "(", "'../../features/full_maximized_test_x_encoded.npy'", ",", "maximized_samples", ")", "\n", "np", ".", "save", "(", "'../../features/misclassified_encoded_test_samples_indices.npy'", ",", "misclassified_indices", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.noise_to_class_heatmaps.main_heatmaps": [[14, 52], ["glob.glob", "matplotlib.pyplot.figure", "sorted", "numpy.array", "matplotlib.pyplot.imshow", "list", "matplotlib.pyplot.yticks", "matplotlib.pyplot.xticks", "matplotlib.pyplot.tight_layout", "matplotlib.pyplot.savefig", "matplotlib.pyplot.show", "os.path.join", "numpy.load", "data[].item", "data[].squeeze", "max_scores_2.mean.mean", "sorted.append", "range", "[].split", "numpy.flipud", "len", "os.path.basename().split", "os.path.basename"], "function", ["None"], ["def", "main_heatmaps", "(", "args", ")", ":", "\n", "    ", "files", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "input", ",", "\"*\"", ")", ")", "\n", "\n", "fig", "=", "pyplot", ".", "figure", "(", "figsize", "=", "FIGSIZE", ",", "dpi", "=", "200", ")", "\n", "\n", "# Only handling maximized scores here,", "\n", "# no sense to plot all noise scores for", "\n", "# each class separately", "\n", "idx_and_score_and_name", "=", "[", "]", "\n", "for", "filename", "in", "files", ":", "\n", "        ", "data", "=", "np", ".", "load", "(", "filename", ")", "\n", "class_name", "=", "os", ".", "path", ".", "basename", "(", "filename", ")", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ".", "split", "(", "\".\"", ")", "[", "0", "]", "\n", "class_idx", "=", "data", "[", "\"class_index\"", "]", ".", "item", "(", ")", "\n", "\n", "max_scores_2", "=", "data", "[", "\"max_score_2\"", "]", ".", "squeeze", "(", ")", "\n", "max_scores_2", "=", "max_scores_2", ".", "mean", "(", "axis", "=", "0", ")", "\n", "\n", "idx_and_score_and_name", ".", "append", "(", "(", "class_idx", ",", "max_scores_2", ",", "class_name", ")", ")", "\n", "\n", "# Sort by class index", "\n", "", "idx_and_score_and_name", "=", "sorted", "(", "idx_and_score_and_name", ",", "key", "=", "lambda", "x", ":", "x", "[", "0", "]", ",", "reverse", "=", "True", ")", "\n", "\n", "# plot N1 x N2 heatmap, where", "\n", "# each pixel represents average score", "\n", "# of N2 when noise was maximized to N1", "\n", "heatmap", "=", "np", ".", "array", "(", "[", "x", "[", "1", "]", "for", "x", "in", "idx_and_score_and_name", "]", ")", "\n", "\n", "pyplot", ".", "imshow", "(", "1", "-", "np", ".", "flipud", "(", "heatmap", ")", ",", "cmap", "=", "\"gray\"", ",", "vmin", "=", "0", ",", "vmax", "=", "1", ")", "\n", "\n", "ticks", "=", "list", "(", "range", "(", "len", "(", "heatmap", ")", ")", ")", "\n", "ticknames", "=", "[", "x", "[", "2", "]", "for", "x", "in", "idx_and_score_and_name", "]", "\n", "\n", "pyplot", ".", "yticks", "(", "ticks", ",", "ticknames", ")", "\n", "pyplot", ".", "xticks", "(", "ticks", ",", "ticknames", ",", "rotation", "=", "\"vertical\"", ")", "\n", "\n", "pyplot", ".", "tight_layout", "(", ")", "\n", "pyplot", ".", "savefig", "(", "args", ".", "output", ",", "bbox_inches", "=", "\"tight\"", ")", "\n", "pyplot", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.noise_to_class_heatmaps.classification_results": [[53, 73], ["glob.glob", "numpy.array().ravel", "numpy.array().ravel", "print", "print", "os.path.join", "numpy.load", "data[].item", "data[].squeeze", "data[].squeeze", "np.array().ravel.append", "np.array().ravel.append", "numpy.array", "numpy.array", "np.array().ravel.mean", "np.array().ravel.mean", "numpy.argmax", "numpy.argmax"], "function", ["None"], ["", "def", "classification_results", "(", "args", ")", ":", "\n", "    ", "files", "=", "glob", "(", "os", ".", "path", ".", "join", "(", "args", ".", "input", ",", "\"*\"", ")", ")", "\n", "\n", "classifier_1_corrects", "=", "[", "]", "\n", "classifier_2_corrects", "=", "[", "]", "\n", "for", "filename", "in", "files", ":", "\n", "        ", "data", "=", "np", ".", "load", "(", "filename", ")", "\n", "\n", "class_idx", "=", "data", "[", "\"class_index\"", "]", ".", "item", "(", ")", "\n", "scores_1", "=", "data", "[", "\"max_score_1\"", "]", ".", "squeeze", "(", ")", "\n", "scores_2", "=", "data", "[", "\"max_score_2\"", "]", ".", "squeeze", "(", ")", "\n", "\n", "classifier_1_corrects", ".", "append", "(", "class_idx", "==", "np", ".", "argmax", "(", "scores_1", ",", "axis", "=", "1", ")", ")", "\n", "classifier_2_corrects", ".", "append", "(", "class_idx", "==", "np", ".", "argmax", "(", "scores_2", ",", "axis", "=", "1", ")", ")", "\n", "\n", "", "classifier_1_corrects", "=", "np", ".", "array", "(", "classifier_1_corrects", ")", ".", "ravel", "(", ")", "\n", "classifier_2_corrects", "=", "np", ".", "array", "(", "classifier_2_corrects", ")", ".", "ravel", "(", ")", "\n", "\n", "print", "(", "\"Orig. class accuracy: %.4f\"", "%", "classifier_1_corrects", ".", "mean", "(", ")", ")", "\n", "print", "(", "\"Seco. class accuracy: %.4f\"", "%", "classifier_2_corrects", ".", "mean", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_decoder_10k.maximizeInput": [[17, 28], ["numpy.copy", "range", "iterate", "gradients.append", "numpy.linalg.norm"], "function", ["None"], ["def", "maximizeInput", "(", "iterate", ",", "selected_input", ")", ":", "\n", "    ", "rate", "=", "0.1", "\n", "gradients", "=", "[", "]", "\n", "val", "=", "np", ".", "copy", "(", "selected_input", ")", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "_", ",", "grads_value", "=", "iterate", "(", "[", "val", "]", ")", "\n", "val", "+=", "grads_value", "*", "rate", "\n", "gradients", ".", "append", "(", "np", ".", "linalg", ".", "norm", "(", "grads_value", ")", ")", "\n", "\n", "", "return", "val", ",", "gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_decoder_10k.init_models": [[30, 201], ["keras.layers.Input", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Conv2D", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dense", "keras.layers.Reshape", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.UpSampling2D", "keras.layers.Conv2D", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Conv2D.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.models.Model", "keras.layers.Input", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.models.Model", "keras.models.Model.load_weights", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Conv2D", "keras.layers.MaxPooling2D", "keras.layers.Dropout", "keras.layers.Flatten", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Dropout", "keras.layers.Dense", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.models.Model", "keras.models.Model.load_weights", "keras.layers.Dense.", "keras.layers.Reshape.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.UpSampling2D.", "keras.layers.Conv2D.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Conv2D.", "keras.layers.MaxPooling2D.", "keras.layers.Dropout.", "keras.layers.Flatten.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.layers.Dropout.", "keras.layers.Dense.", "keras.models.Model"], "function", ["None"], ["", "def", "init_models", "(", "autoencoder_weights", ",", "classifier_weights", ")", ":", "\n", "\n", "    ", "input_shape", "=", "Input", "(", "shape", "=", "(", "90", ",", "80", ",", "1", ")", ")", "\n", "\n", "# Encoder Layers", "\n", "conv_1", "=", "Conv2D", "(", "16", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_1", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_2", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_2", "=", "MaxPooling2D", "(", "(", "3", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_3", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "max_pool_3", "=", "MaxPooling2D", "(", "(", "2", ",", "2", ")", ",", "padding", "=", "'same'", ")", "\n", "conv_4", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "\n", "encoded", "=", "Flatten", "(", "name", "=", "'encoder'", ")", "\n", "\n", "# Bottleneck", "\n", "dense_1", "=", "Dense", "(", "256", ",", "name", "=", "'bottleneck'", ")", "\n", "dense_2", "=", "Dense", "(", "6400", ")", "\n", "reshape", "=", "Reshape", "(", "(", "5", ",", "10", ",", "128", ")", ")", "\n", "\n", "# Decoder Layers", "\n", "conv_5", "=", "Conv2D", "(", "128", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_1", "=", "UpSampling2D", "(", "(", "2", ",", "2", ")", ")", "\n", "conv_6", "=", "Conv2D", "(", "64", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_2", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "conv_7", "=", "Conv2D", "(", "32", ",", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ",", "padding", "=", "'same'", ")", "\n", "up_samp_3", "=", "UpSampling2D", "(", "(", "3", ",", "2", ")", ")", "\n", "\n", "decoded", "=", "Conv2D", "(", "1", ",", "(", "3", ",", "3", ")", ",", "activation", "=", "'sigmoid'", ",", "padding", "=", "'same'", ",", "name", "=", "'decoder'", ")", "\n", "\n", "####################################################################################################", "\n", "#-----------------------------------------Full Autoencoder-----------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "autoencoder", "=", "conv_1", "(", "input_shape", ")", "\n", "autoencoder", "=", "max_pool_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "max_pool_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_4", "(", "autoencoder", ")", "\n", "autoencoder", "=", "encoded", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "dense_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "reshape", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_5", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_1", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_6", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_2", "(", "autoencoder", ")", "\n", "autoencoder", "=", "conv_7", "(", "autoencoder", ")", "\n", "autoencoder", "=", "up_samp_3", "(", "autoencoder", ")", "\n", "autoencoder", "=", "decoded", "(", "autoencoder", ")", "\n", "\n", "autoencoder", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "autoencoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Encoder-------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "encoder", "=", "conv_1", "(", "input_shape", ")", "\n", "encoder", "=", "max_pool_1", "(", "encoder", ")", "\n", "encoder", "=", "conv_2", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_2", "(", "encoder", ")", "\n", "encoder", "=", "conv_3", "(", "encoder", ")", "\n", "encoder", "=", "max_pool_3", "(", "encoder", ")", "\n", "encoder", "=", "conv_4", "(", "encoder", ")", "\n", "encoder", "=", "encoded", "(", "encoder", ")", "\n", "encoder", "=", "dense_1", "(", "encoder", ")", "\n", "\n", "encoder_model", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "encoder", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Decoder------------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "bottleneck_input_shape", "=", "Input", "(", "shape", "=", "(", "256", ",", ")", ")", "\n", "decoder_model", "=", "dense_2", "(", "bottleneck_input_shape", ")", "\n", "decoder_model", "=", "reshape", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_5", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_1", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_6", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_2", "(", "decoder_model", ")", "\n", "decoder_model", "=", "conv_7", "(", "decoder_model", ")", "\n", "decoder_model", "=", "up_samp_3", "(", "decoder_model", ")", "\n", "decoder_model", "=", "decoded", "(", "decoder_model", ")", "\n", "\n", "decoder_model", "=", "Model", "(", "inputs", "=", "bottleneck_input_shape", ",", "outputs", "=", "decoder_model", ")", "\n", "\n", "# Initializes the layers with weights", "\n", "autoencoder", ".", "load_weights", "(", "autoencoder_weights", ")", "\n", "\n", "####################################################################################################", "\n", "#------------------------------------------Classifier----------------------------------------------#", "\n", "####################################################################################################", "\n", "\n", "# Layers", "\n", "c_conv_1", "=", "Conv2D", "(", "8", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_1", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_1", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_2", "=", "Conv2D", "(", "16", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_2", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_2", "=", "Dropout", "(", "0.2", ")", "\n", "c_conv_3", "=", "Conv2D", "(", "32", ",", "kernel_size", "=", "(", "2", ",", "2", ")", ",", "activation", "=", "'relu'", ")", "\n", "c_max_pool_3", "=", "MaxPooling2D", "(", "pool_size", "=", "(", "2", ",", "2", ")", ")", "\n", "c_drop_3", "=", "Dropout", "(", "0.2", ")", "\n", "c_flatten", "=", "Flatten", "(", ")", "\n", "c_dense_1", "=", "Dense", "(", "512", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_4", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_2", "=", "Dense", "(", "256", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_5", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_3", "=", "Dense", "(", "128", ",", "activation", "=", "'relu'", ")", "\n", "c_drop_6", "=", "Dropout", "(", "0.2", ")", "\n", "c_dense_output", "=", "Dense", "(", "35", ",", "activation", "=", "'softmax'", ")", "\n", "\n", "# Model", "\n", "classifier", "=", "c_conv_1", "(", "input_shape", ")", "\n", "classifier", "=", "c_max_pool_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_1", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_2", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_2", "(", "classifier", ")", "\n", "classifier", "=", "c_conv_3", "(", "classifier", ")", "\n", "classifier", "=", "c_max_pool_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_3", "(", "classifier", ")", "\n", "classifier", "=", "c_flatten", "(", "classifier", ")", "\n", "\n", "classifier", "=", "c_dense_1", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_4", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_2", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_5", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_3", "(", "classifier", ")", "\n", "classifier", "=", "c_drop_6", "(", "classifier", ")", "\n", "classifier", "=", "c_dense_output", "(", "classifier", ")", "\n", "\n", "classifier", "=", "Model", "(", "inputs", "=", "input_shape", ",", "outputs", "=", "classifier", ")", "\n", "\n", "# Initializes the classifier's layers with weights", "\n", "classifier", ".", "load_weights", "(", "classifier_weights", ")", "\n", "\n", "combined_model", "=", "dense_2", "(", "bottleneck_input_shape", ")", "\n", "combined_model", "=", "reshape", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_5", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_1", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_6", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_2", "(", "combined_model", ")", "\n", "combined_model", "=", "conv_7", "(", "combined_model", ")", "\n", "combined_model", "=", "up_samp_3", "(", "combined_model", ")", "\n", "combined_model", "=", "decoded", "(", "combined_model", ")", "\n", "\n", "combined_model", "=", "c_conv_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_conv_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_conv_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_max_pool_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_flatten", "(", "combined_model", ")", "\n", "\n", "combined_model", "=", "c_dense_1", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_4", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_2", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_5", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_3", "(", "combined_model", ")", "\n", "combined_model", "=", "c_drop_6", "(", "combined_model", ")", "\n", "combined_model", "=", "c_dense_output", "(", "combined_model", ")", "\n", "\n", "full_model", "=", "Model", "(", "inputs", "=", "bottleneck_input_shape", ",", "outputs", "=", "combined_model", ")", "\n", "\n", "return", "full_model", ",", "decoder_model", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_decoder_10k.main": [[202, 267], ["maximize_noise_decoder_10k.init_models", "keras.models.load_model", "os.listdir", "int", "print", "keras.backend.mean", "keras.backend.function", "tqdm.tqdm", "numpy.savez", "keras.backend.gradients", "keras.backend.sqrt", "range", "numpy.random.normal", "numpy.expand_dims", "full_model.predict", "original_scores.append", "decoder_model.predict", "keras.models.load_model.predict", "original_scores_2.append", "maximize_noise_decoder_10k.maximizeInput", "decoder_model.predict", "full_model.predict", "new_scores.append", "keras.models.load_model.predict", "new_scores_2.append", "keras.backend.mean", "os.path.exists", "os.makedirs", "keras.backend.square"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_decoder_10k.init_models", "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput"], ["", "def", "main", "(", ")", ":", "\n", "# Load model", "\n", "    ", "full_model", ",", "decoder_model", "=", "init_models", "(", "'../../models/autoencoder_weights.h5'", ",", "'../../models/speech_classifier_weights.h5'", ")", "\n", "second_model", "=", "load_model", "(", "'../../models/speech_classifier_model_2.h5'", ")", "\n", "\n", "classes", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "\n", "class_1", "=", "int", "(", "sys", ".", "argv", "[", "1", "]", ")", "\n", "print", "(", "'class_chosen'", ",", "class_1", ",", "classes", "[", "class_1", "]", ")", "\n", "\n", "# build a loss function that maximizes the activation of a specific class", "\n", "loss", "=", "K", ".", "mean", "(", "full_model", ".", "output", "[", ":", ",", "class_1", "]", ")", "\n", "# compute the gradient of the input picture wrt this loss", "\n", "grads", "=", "K", ".", "gradients", "(", "loss", ",", "full_model", ".", "input", ")", "[", "0", "]", "\n", "# normalization trick: we normalize the gradient", "\n", "grads", "/=", "(", "K", ".", "sqrt", "(", "K", ".", "mean", "(", "K", ".", "square", "(", "grads", ")", ")", ")", "+", "1e-5", ")", "\n", "# this function returns the loss and grads given the input speech", "\n", "iterate", "=", "K", ".", "function", "(", "[", "full_model", ".", "input", "]", ",", "[", "loss", ",", "grads", "]", ")", "\n", "\n", "# Stores the prediction score of noise sample according to original combined decoder + speech classifier before maximization", "\n", "original_scores", "=", "[", "]", "\n", "# Stores the prediction score of noise sample according to separate speech classifier before maximization", "\n", "original_scores_2", "=", "[", "]", "\n", "# Stores the prediction score of noise sample according to original combined decoder + speech classifier after maximization", "\n", "new_scores", "=", "[", "]", "\n", "# Stores the prediction score of noise sample according to separate speech classifier after maximization", "\n", "new_scores_2", "=", "[", "]", "\n", "\n", "# Number of samples", "\n", "samples", "=", "10000", "\n", "\n", "for", "_", "in", "tqdm", "(", "range", "(", "samples", ")", ")", ":", "\n", "# Generate random gaussian noise", "\n", "        ", "mu", ",", "sigma", "=", "0", ",", "0.1", "# mean and standard deviation", "\n", "original_input", "=", "np", ".", "random", ".", "normal", "(", "mu", ",", "sigma", ",", "256", ")", "\n", "original_input", "=", "np", ".", "expand_dims", "(", "original_input", ",", "0", ")", "\n", "\n", "# Calculate accuracy of noise input with both classifiers", "\n", "o_score_1", "=", "full_model", ".", "predict", "(", "original_input", ")", "\n", "original_scores", ".", "append", "(", "o_score_1", ")", "\n", "\n", "# Decode original bottleneck code", "\n", "original_input_decoded", "=", "decoder_model", ".", "predict", "(", "original_input", ")", "\n", "\n", "o_score_2", "=", "second_model", ".", "predict", "(", "original_input_decoded", ")", "\n", "original_scores_2", ".", "append", "(", "o_score_2", ")", "\n", "\n", "maximized_noise", ",", "_", "=", "maximizeInput", "(", "iterate", ",", "original_input", ")", "\n", "\n", "# Decode maximized bottleneck code", "\n", "maximized_input_decoded", "=", "decoder_model", ".", "predict", "(", "maximized_noise", ")", "\n", "\n", "# Calculate accuracy of maximized input with both classifiers", "\n", "n_score_1", "=", "full_model", ".", "predict", "(", "maximized_noise", ")", "\n", "new_scores", ".", "append", "(", "n_score_1", ")", "\n", "n_score_2", "=", "second_model", ".", "predict", "(", "maximized_input_decoded", ")", "\n", "new_scores_2", ".", "append", "(", "n_score_2", ")", "\n", "\n", "", "directories", "=", "[", "'results'", ",", "'results/decoder'", "]", "\n", "for", "d", "in", "directories", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n", "# Save all prediction scores for analysis", "\n", "", "", "np", ".", "savez", "(", "'results/decoder/10k_class_'", "+", "classes", "[", "class_1", "]", ",", "class_index", "=", "class_1", ",", "orig_score_1", "=", "original_scores", ",", "max_score_1", "=", "new_scores", ",", "orig_score_2", "=", "original_scores_2", ",", "max_score_2", "=", "new_scores_2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput": [[16, 27], ["numpy.copy", "range", "iterate", "gradients.append", "numpy.linalg.norm"], "function", ["None"], ["def", "maximizeInput", "(", "iterate", ",", "selected_input", ")", ":", "\n", "    ", "rate", "=", "0.01", "\n", "gradients", "=", "[", "]", "\n", "val", "=", "np", ".", "copy", "(", "selected_input", ")", "\n", "\n", "for", "_", "in", "range", "(", "20", ")", ":", "\n", "        ", "_", ",", "grads_value", "=", "iterate", "(", "[", "val", "]", ")", "\n", "val", "+=", "grads_value", "*", "rate", "\n", "gradients", ".", "append", "(", "np", ".", "linalg", ".", "norm", "(", "grads_value", ")", ")", "\n", "\n", "", "return", "val", ",", "gradients", "\n", "\n"]], "home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.main": [[28, 85], ["keras.models.load_model", "keras.models.load_model", "os.listdir", "int", "print", "keras.backend.mean", "keras.backend.function", "tqdm.tqdm", "numpy.savez", "keras.backend.gradients", "keras.backend.sqrt", "range", "numpy.random.normal", "keras.models.load_model.predict", "original_scores.append", "keras.models.load_model.predict", "original_scores_2.append", "maximize_noise_classifier_10k.maximizeInput", "keras.models.load_model.predict", "new_scores.append", "keras.models.load_model.predict", "new_scores_2.append", "keras.backend.mean", "os.path.exists", "os.makedirs", "keras.backend.square"], "function", ["home.repos.pwc.inspect_result.bilalsoomro_debugging-deep-neural-networks.objective.maximize_noise_classifier_10k.maximizeInput"], ["", "def", "main", "(", ")", ":", "\n", "# Load model", "\n", "    ", "model", "=", "load_model", "(", "'../../models/speech_classifier_model.h5'", ")", "\n", "second_model", "=", "load_model", "(", "'../../models/speech_classifier_model_2.h5'", ")", "\n", "classes", "=", "os", ".", "listdir", "(", "DATA_PATH", ")", "\n", "\n", "class_1", "=", "int", "(", "sys", ".", "argv", "[", "1", "]", ")", "\n", "print", "(", "'class_chosen'", ",", "class_1", ",", "classes", "[", "class_1", "]", ")", "\n", "\n", "# build a loss function that maximizes the activation of a specific class", "\n", "loss", "=", "K", ".", "mean", "(", "model", ".", "output", "[", ":", ",", "class_1", "]", ")", "\n", "# compute the gradient of the input picture wrt this loss", "\n", "grads", "=", "K", ".", "gradients", "(", "loss", ",", "model", ".", "input", ")", "[", "0", "]", "\n", "# normalization trick: we normalize the gradient", "\n", "grads", "/=", "(", "K", ".", "sqrt", "(", "K", ".", "mean", "(", "K", ".", "square", "(", "grads", ")", ")", ")", "+", "1e-5", ")", "\n", "# this function returns the loss and grads given the input speech", "\n", "iterate", "=", "K", ".", "function", "(", "[", "model", ".", "input", "]", ",", "[", "loss", ",", "grads", "]", ")", "\n", "\n", "# Stores the prediction score of noise sample according to original speech classifier before maximization", "\n", "original_scores", "=", "[", "]", "\n", "# Stores the prediction score of noise sample according to separate speech classifier before maximization", "\n", "original_scores_2", "=", "[", "]", "\n", "# Stores the prediction score of noise sample according to original speech classifier after maximization", "\n", "new_scores", "=", "[", "]", "\n", "# Stores the prediction score of noise sample according to separate speech classifier after maximization", "\n", "new_scores_2", "=", "[", "]", "\n", "\n", "# Number of samples", "\n", "samples", "=", "10000", "\n", "\n", "for", "_", "in", "tqdm", "(", "range", "(", "samples", ")", ")", ":", "\n", "# Generate random gaussian noise", "\n", "        ", "mu", ",", "sigma", "=", "0", ",", "0.1", "# mean and standard deviation", "\n", "original_input", "=", "np", ".", "random", ".", "normal", "(", "mu", ",", "sigma", ",", "(", "(", "1", ",", "90", ",", "80", ",", "1", ")", ")", ")", "\n", "\n", "# Calculate accuracy of noise input with both classifiers", "\n", "o_score_1", "=", "model", ".", "predict", "(", "original_input", ")", "\n", "original_scores", ".", "append", "(", "o_score_1", ")", "\n", "\n", "o_score_2", "=", "second_model", ".", "predict", "(", "original_input", ")", "\n", "original_scores_2", ".", "append", "(", "o_score_2", ")", "\n", "\n", "maximized_noise", ",", "_", "=", "maximizeInput", "(", "iterate", ",", "original_input", ")", "\n", "\n", "# Calculate accuracy of maximized input with both classifiers", "\n", "n_score_1", "=", "model", ".", "predict", "(", "maximized_noise", ")", "\n", "new_scores", ".", "append", "(", "n_score_1", ")", "\n", "n_score_2", "=", "second_model", ".", "predict", "(", "maximized_noise", ")", "\n", "new_scores_2", ".", "append", "(", "n_score_2", ")", "\n", "\n", "", "directories", "=", "[", "'results'", ",", "'results/classifier'", "]", "\n", "for", "d", "in", "directories", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "d", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "d", ")", "\n", "\n", "# Save all prediction scores for analysis", "\n", "", "", "np", ".", "savez", "(", "'results/classifier/10k_class_'", "+", "classes", "[", "class_1", "]", ",", "class_index", "=", "class_1", ",", "orig_score_1", "=", "original_scores", ",", "max_score_1", "=", "new_scores", ",", "orig_score_2", "=", "original_scores_2", ",", "max_score_2", "=", "new_scores_2", ")", "\n", "\n"]]}