{"home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.data_loader.heter_data.__init__": [[12, 37], ["numpy.array", "utils.load_pickle", "data_loader.heter_data.data.extend", "data_loader.heter_data.targets.extend", "data_loader.heter_data.targets.extend", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.load_pickle"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "target", "=", "\"hot\"", ")", ":", "\n", "        ", "\"\"\"\n            Args:\n                filename: a list of pickle files.\n                transform: transform applied to the feature data.\n                target_transform: transform applied to the label data.\n                target: target label encoding approach.\n            Notes:\n                Input data with key values: \"feature\", \"label\" (already one-hot encoded), \"user\"(optional).\n                Feature with shape [seq_len, 8*2,  interval_len] ([12, 16, 7])\n                For a single file we have:\n        \"\"\"", "\n", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "\n", "for", "file", "in", "filename", ":", "\n", "            ", "data", "=", "utils", ".", "load_pickle", "(", "file", ")", "\n", "self", ".", "data", ".", "extend", "(", "data", "[", "\"feature\"", "]", ")", "\n", "if", "target", "==", "\"hot\"", ":", "# is one-hot required?", "\n", "                ", "self", ".", "targets", ".", "extend", "(", "data", "[", "\"label\"", "]", ")", "\n", "", "else", ":", "# Train classifier, don't need one-hot encoding", "\n", "                ", "self", ".", "targets", ".", "extend", "(", "np", ".", "argmax", "(", "data", "[", "\"label\"", "]", ",", "axis", "=", "1", ")", ")", "\n", "", "", "self", ".", "targets", "=", "np", ".", "array", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.data_loader.heter_data.__getitem__": [[38, 45], ["data_loader.heter_data.transform", "data_loader.heter_data.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.data_loader.heter_data.__len__": [[46, 48], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.data_loader.heter_data2.__init__": [[51, 68], ["numpy.array", "utils.load_pickle", "data_loader.heter_data2.data.extend", "data_loader.heter_data2.targets_t.extend", "data_loader.heter_data2.targets.extend", "data_loader.heter_data2.targets.extend", "numpy.argmax"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.load_pickle"], ["    ", "def", "__init__", "(", "self", ",", "filename", ",", "transform", "=", "None", ",", "target_transform", "=", "None", ",", "target", "=", "\"hot\"", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "targets", "=", "[", "]", "\n", "self", ".", "targets_t", "=", "[", "]", "\n", "\n", "for", "file", "in", "filename", ":", "\n", "            ", "data_tmp", "=", "utils", ".", "load_pickle", "(", "file", ")", "\n", "self", ".", "data", ".", "extend", "(", "data_tmp", "[", "\"feature\"", "]", ")", "\n", "if", "target", "==", "\"hot\"", ":", "# is one-hot required?", "\n", "                ", "self", ".", "targets", ".", "extend", "(", "data_tmp", "[", "\"label\"", "]", ")", "\n", "", "else", ":", "# Train classifier, don't need one-hot encoding", "\n", "                ", "self", ".", "targets", ".", "extend", "(", "np", ".", "argmax", "(", "data_tmp", "[", "\"label\"", "]", ",", "axis", "=", "1", ")", ")", "\n", "", "self", ".", "targets_t", ".", "extend", "(", "data_tmp", "[", "\"label_t\"", "]", ")", "\n", "\n", "", "self", ".", "targets", "=", "np", ".", "array", "(", "self", ".", "targets", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.data_loader.heter_data2.__getitem__": [[69, 86], ["data_loader.heter_data2.transform", "data_loader.heter_data2.target_transform", "data_loader.heter_data2.target_transform"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "\"\"\"\n        Args:\n            index (int): Index\n        Returns:\n            tuple: (image, target, target_t) \n            target is index of the global target class.\n            target is index of the local target class.            \n        \"\"\"", "\n", "img", ",", "target", ",", "target_t", "=", "self", ".", "data", "[", "index", "]", ",", "self", ".", "targets", "[", "index", "]", ",", "self", ".", "targets_t", "[", "index", "]", "\n", "if", "self", ".", "transform", "is", "not", "None", ":", "\n", "            ", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "", "if", "self", ".", "target_transform", "is", "not", "None", ":", "\n", "            ", "target", "=", "self", ".", "target_transform", "(", "target", ")", "\n", "target_t", "=", "self", ".", "target_transform", "(", "target_t", ")", "\n", "\n", "", "return", "img", ",", "target", ",", "target_t", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.data_loader.heter_data2.__len__": [[87, 89], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.__init__": [[45, 60], ["object.__init__", "graph", "reptile.reptile_meta.model.to", "torch.Adam", "torch.Adam", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR", "reptile.reptile_meta.model.parameters"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ",", "graph", ",", "lr", ",", "device", ",", "loss_fun", ",", "number_class", ",", "beta", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"graph can be norm_cce, merge_cce\"\"\"", "\n", "super", "(", "reptile_meta", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "model", "=", "graph", "(", "bidirectional", "=", "False", ",", "num_classes", "=", "number_class", ")", "# cross entropy based model", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "device", ")", "\n", "# self.model = self.model.double()", "\n", "self", ".", "training_op", "=", "{", "}", "\n", "self", ".", "training_op", "[", "\"optimizer\"", "]", "=", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "weight_decay", "=", "1e-4", ")", "\n", "# self.training_op[\"optimizer\"] = optim.SGD(self.model.parameters(),", "\n", "# lr= self.args.lr, momentum=0.9, weight_decay=5e-4)", "\n", "self", ".", "training_op", "[", "\"scheduler\"", "]", "=", "StepLR", "(", "self", ".", "training_op", "[", "\"optimizer\"", "]", ",", "step_size", "=", "2", ",", "gamma", "=", "0.85", ")", "\n", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "=", "loss_fun", "\n", "self", ".", "training_res", "=", "{", "\"train_acc\"", ":", "[", "]", ",", "\"test_acc\"", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.save_model": [[61, 70], ["torch.save", "torch.save", "torch.save", "torch.save", "reptile.reptile_meta.model.state_dict"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\" filename example: /path/checkpoint/model-100.t7\n            State dict contains: \"model\" key at least.\n        \"\"\"", "\n", "state", "=", "{", "\n", "\"model\"", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "\"client\"", ":", "self", ".", "model_name", ",", "\n", "}", "\n", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.build_data_loader": [[71, 79], ["utils.dataloader_gen", "utils.dataloader_gen", "utils.dataloader_gen"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen"], ["", "def", "build_data_loader", "(", "self", ")", ":", "\n", "        ", "self", ".", "training_op", "[", "\"trainloader\"", "]", "=", "utils", ".", "dataloader_gen", "(", "self", ".", "training_op", "[", "\"train_file\"", "]", ",", "\n", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "\n", "target", "=", "\"hot\"", ")", "# (one_hot?)", "\n", "self", ".", "training_op", "[", "\"adaptloader\"", "]", "=", "utils", ".", "dataloader_gen", "(", "self", ".", "training_op", "[", "\"adapt_file\"", "]", ",", "\n", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "\n", "target", "=", "\"hot\"", ")", "\n", "self", ".", "training_op", "[", "\"testloader\"", "]", "=", "utils", ".", "dataloader_gen", "(", "self", ".", "training_op", "[", "\"test_file\"", "]", ",", "1", ",", "target", "=", "\"hot\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.set_train_test_file": [[80, 84], ["None"], "methods", ["None"], ["", "def", "set_train_test_file", "(", "self", ",", "train", ",", "test", ",", "adapt", ")", ":", "\n", "        ", "self", ".", "training_op", "[", "\"train_file\"", "]", "=", "train", "\n", "self", ".", "training_op", "[", "\"test_file\"", "]", "=", "test", "\n", "self", ".", "training_op", "[", "\"adapt_file\"", "]", "=", "adapt", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.get_model_weights": [[85, 87], ["reptile.reptile_meta.model.state_dict"], "methods", ["None"], ["", "def", "get_model_weights", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.assign_new_weights": [[88, 90], ["reptile.reptile_meta.model.load_state_dict"], "methods", ["None"], ["", "def", "assign_new_weights", "(", "self", ",", "weights_dict", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_state_dict", "(", "weights_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.train": [[91, 125], ["range", "reptile.reptile_meta.model.train", "enumerate", "print", "print", "reptile.reptile_meta.training_op[].step", "reptile.reptile_meta.training_op[].zero_grad", "loss.backward", "reptile.reptile_meta.training_op[].step", "loss.item", "targets.max", "outputs.max", "targets.size", "predicted.eq().sum().item", "inputs.to", "targets.to", "reptile.reptile_meta.model", "reptile.reptile_meta.model", "inputs.unsqueeze().type", "[].type", "inputs.unsqueeze().type", "[].type", "predicted.eq().sum", "reptile.reptile_meta.training_op[].get_lr", "inputs.unsqueeze", "inputs.unsqueeze", "predicted.eq", "targets.max", "targets.max"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "def", "train", "(", "self", ",", "num_epoch", ",", "global_center", "=", "None", ")", ":", "\n", "# print(\"=== train on: %s\" % self.training_op[\"train_file\"])", "\n", "        ", "for", "epoch", "in", "range", "(", "num_epoch", ")", ":", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "train_loss", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "self", ".", "training_op", "[", "\"trainloader\"", "]", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "training_op", "[", "\"optimizer\"", "]", ".", "zero_grad", "(", ")", "\n", "# add the channel dimension, return logits and embedding for cce model", "\n", "# outputs, _ = self.model(inputs.unsqueeze(1).double())", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "# as here we use targets.max() the target should be in one-hot form.", "\n", "", "else", ":", "\n", "                    ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "# back propogation", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "training_op", "[", "\"optimizer\"", "]", ".", "step", "(", ")", "\n", "# loss and accuracy", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "target_cce", "=", "targets", ".", "max", "(", "1", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "target_cce", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "print", "(", "\"===== local epoch: %d =======\"", "%", "epoch", ")", "\n", "print", "(", "\"train loss % .3f, train acc: % .3f ,lr: %f \"", "%", "(", "\n", "train_loss", "/", "(", "batch_idx", "+", "1", ")", ",", "100.0", "*", "correct", "/", "total", ",", "self", ".", "training_op", "[", "\"scheduler\"", "]", ".", "get_lr", "(", ")", "[", "0", "]", ")", ")", "\n", "\n", "# learning rate", "\n", "self", ".", "training_op", "[", "\"scheduler\"", "]", ".", "step", "(", ")", "\n", "# self.test()", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.test": [[127, 150], ["reptile.reptile_meta.model.eval", "enumerate", "loss.item", "targets.max", "outputs.max", "targets.size", "predicted.eq().sum().item", "print", "inputs.to", "targets.to", "reptile.reptile_meta.model", "reptile.reptile_meta.model", "inputs.unsqueeze().type", "[].type", "inputs.unsqueeze().type", "[].type", "predicted.eq().sum", "inputs.unsqueeze", "inputs.unsqueeze", "predicted.eq", "targets.max", "targets.max"], "methods", ["None"], ["", "", "def", "test", "(", "self", ",", "print_ind", "=", "False", ")", ":", "\n", "# print(\"===test on: %s\" % self.training_op[\"test_file\"])", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "self", ".", "training_op", "[", "\"testloader\"", "]", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "", "test_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "target_cce", "=", "targets", ".", "max", "(", "1", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "target_cce", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "if", "print_ind", ":", "\n", "            ", "print", "(", "\"============Test loss: %.3f, Test acc: %.3f\"", "%", "(", "\n", "test_loss", "/", "(", "total", "+", "1", ")", ",", "100.0", "*", "correct", "/", "total", ")", ")", "\n", "", "return", "100.0", "*", "correct", "/", "total", ",", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.adapt": [[151, 178], ["reptile.reptile_meta.model.train", "enumerate", "reptile.reptile_meta.training_op[].zero_grad", "loss.backward", "reptile.reptile_meta.training_op[].step", "loss.item", "targets.max", "outputs.max", "targets.size", "predicted.eq().sum().item", "inputs.to", "targets.to", "reptile.reptile_meta.model", "reptile.reptile_meta.model", "inputs.unsqueeze().type", "[].type", "inputs.unsqueeze().type", "[].type", "predicted.eq().sum", "inputs.unsqueeze", "inputs.unsqueeze", "predicted.eq", "targets.max", "targets.max"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "def", "adapt", "(", "self", ",", "num_batch", ")", ":", "\n", "        ", "\"\"\"\n        Used for test only\n        \"\"\"", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "train_loss", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "self", ".", "training_op", "[", "\"adaptloader\"", "]", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "training_op", "[", "\"optimizer\"", "]", ".", "zero_grad", "(", ")", "\n", "# torch cross entropy", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "# back propogation", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "training_op", "[", "\"optimizer\"", "]", ".", "step", "(", ")", "\n", "# loss and accuracy", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "target_cce", "=", "targets", ".", "max", "(", "1", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "target_cce", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.adapt_train": [[179, 203], ["reptile.reptile_meta.model.train", "enumerate", "reptile.reptile_meta.training_op[].zero_grad", "loss.backward", "reptile.reptile_meta.training_op[].step", "loss.item", "targets.max", "outputs.max", "targets.size", "predicted.eq().sum().item", "inputs.to", "targets.to", "reptile.reptile_meta.model", "reptile.reptile_meta.model", "inputs.unsqueeze().type", "[].type", "inputs.unsqueeze().type", "[].type", "predicted.eq().sum", "inputs.unsqueeze", "inputs.unsqueeze", "predicted.eq", "targets.max", "targets.max"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "", "def", "adapt_train", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "train_loss", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "self", ".", "training_op", "[", "\"trainloader\"", "]", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "training_op", "[", "\"optimizer\"", "]", ".", "zero_grad", "(", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "training_op", "[", "\"optimizer\"", "]", ".", "step", "(", ")", "\n", "\n", "# loss and accuracy", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "target_cce", "=", "targets", ".", "max", "(", "1", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "target_cce", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.load_pickle": [[32, 36], ["_pickle.load", "print", "open"], "function", ["None"], ["def", "load_pickle", "(", "filename", ",", "show_name", "=", "False", ")", ":", "\n", "    ", "if", "show_name", ":", "\n", "        ", "print", "(", "filename", ")", "\n", "", "return", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.save_pickle": [[38, 41], ["open", "_pickle.dump"], "function", ["None"], ["", "def", "save_pickle", "(", "data_dict", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "myfile", ":", "\n", "        ", "pickle", ".", "dump", "(", "data_dict", ",", "myfile", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.update_server_weights": [[205, 218], ["copy.deepcopy", "w.keys", "range", "len", "torch.mul", "torch.mul", "torch.div().sub", "torch.div().sub", "torch.div", "torch.div", "len"], "function", ["None"], ["", "", "", "def", "update_server_weights", "(", "w_list", ",", "w", ",", "sigma", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"\n    model_1 and model_2 with same structure\n    return weights dictionary with values w_model_1 - w_model_2\n\n    sigma = 1 : federated learning\n    \"\"\"", "\n", "w_avg", "=", "copy", ".", "deepcopy", "(", "w_list", "[", "0", "]", ")", "\n", "for", "k", "in", "w", ".", "keys", "(", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "w_list", ")", ")", ":", "\n", "            ", "w_avg", "[", "k", "]", "+=", "w_list", "[", "idx", "]", "[", "k", "]", "\n", "", "w_avg", "[", "k", "]", "=", "w", "[", "k", "]", "+", "torch", ".", "mul", "(", "(", "torch", ".", "div", "(", "w_avg", "[", "k", "]", ",", "len", "(", "w_list", ")", ")", ".", "sub", "(", "w", "[", "k", "]", ")", ")", ",", "sigma", ")", "\n", "", "return", "w_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.update_server_weights_weighted": [[220, 278], ["w.keys", "enumerate", "torch.cat", "torch.cat", "range", "range", "range", "numpy.sum", "copy.deepcopy", "w.keys", "w.keys", "w_param.append", "len", "weights_flattened.append", "len", "len", "weights.append", "weights_norm.append", "range", "used_keys.append", "torch.flatten", "torch.flatten", "model_params.append", "torch.cat", "torch.cat", "l2.append", "cosine_dis.append", "l2.append", "cosine_dis.append", "len", "torch.mul", "torch.mul", "torch.flatten", "torch.flatten", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.abs", "w_avg[].sub", "torch.dist().numpy", "torch.dist().numpy", "cosine_similarity().numpy", "torch.dist().cpu().numpy", "torch.dist().cpu().numpy", "cosine_similarity().cpu().numpy", "torch.dist", "torch.dist", "cosine_similarity", "torch.dist().cpu", "torch.dist().cpu", "cosine_similarity().cpu", "weights_flattened[].unsqueeze", "torch.cat.unsqueeze", "torch.dist", "torch.dist", "cosine_similarity", "weights_flattened[].unsqueeze", "torch.cat.unsqueeze"], "function", ["None"], ["", "def", "update_server_weights_weighted", "(", "w_list", ",", "w", ",", "sigma", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"\n    abandon: more complicated way to update the model on the server side.   \n    \"\"\"", "\n", "# flatten all model weights", "\n", "weights_flattened", "=", "[", "]", "\n", "keys", "=", "w", ".", "keys", "(", ")", "\n", "used_keys", "=", "[", "]", "\n", "for", "ind", ",", "key", "in", "enumerate", "(", "keys", ")", ":", "\n", "        ", "if", "\"batches_tracked\"", "not", "in", "key", ":", "\n", "            ", "used_keys", ".", "append", "(", "key", ")", "\n", "# flatten w", "\n", "", "", "w_param", "=", "[", "]", "\n", "for", "key", "in", "used_keys", ":", "\n", "        ", "w_param", ".", "append", "(", "torch", ".", "flatten", "(", "w", "[", "key", "]", ")", ")", "\n", "", "w_flatten", "=", "torch", ".", "cat", "(", "w_param", ",", "dim", "=", "0", ")", "\n", "# print(w_flatten.size())", "\n", "# flatten w_list", "\n", "for", "idx", "in", "range", "(", "len", "(", "w_list", ")", ")", ":", "\n", "        ", "model_params", "=", "[", "]", "\n", "for", "key", "in", "used_keys", ":", "\n", "            ", "model_params", ".", "append", "(", "torch", ".", "flatten", "(", "w_list", "[", "idx", "]", "[", "key", "]", ")", ")", "\n", "", "weights_flattened", ".", "append", "(", "torch", ".", "cat", "(", "model_params", ",", "dim", "=", "0", ")", ")", "\n", "# calculate l2 norm", "\n", "", "l2", "=", "[", "]", "\n", "cosine_dis", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "w_list", ")", ")", ":", "\n", "        ", "if", "device", "==", "\"cpu\"", ":", "\n", "            ", "l2", ".", "append", "(", "np", ".", "squeeze", "(", "torch", ".", "dist", "(", "weights_flattened", "[", "idx", "]", ",", "w_flatten", ")", ".", "numpy", "(", ")", ")", ")", "\n", "cosine_dis", ".", "append", "(", "np", ".", "squeeze", "(", "\n", "cosine_similarity", "(", "weights_flattened", "[", "idx", "]", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "w_flatten", ".", "unsqueeze", "(", "dim", "=", "0", ")", ")", ".", "numpy", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "l2", ".", "append", "(", "np", ".", "squeeze", "(", "torch", ".", "dist", "(", "weights_flattened", "[", "idx", "]", ",", "w_flatten", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "cosine_dis", ".", "append", "(", "np", ".", "squeeze", "(", "\n", "cosine_similarity", "(", "weights_flattened", "[", "idx", "]", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "w_flatten", ".", "unsqueeze", "(", "dim", "=", "0", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "", "", "weights", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "w_list", ")", ")", ":", "\n", "# weights.append(np.sqrt(l2[index] ** 2 + cosine_dis[index] ** 2))", "\n", "        ", "weights", ".", "append", "(", "l2", "[", "index", "]", "*", "np", ".", "abs", "(", "cosine_dis", "[", "index", "]", ")", ")", "\n", "# normalize weights", "\n", "", "weights_norm", "=", "[", "]", "\n", "total", "=", "np", ".", "sum", "(", "weights", ")", "\n", "for", "val", "in", "weights", ":", "\n", "        ", "weights_norm", ".", "append", "(", "val", "/", "total", ")", "\n", "###################", "\n", "# print(weights_norm)", "\n", "# sys.exit()", "\n", "###################", "\n", "# weighted average", "\n", "", "w_avg", "=", "copy", ".", "deepcopy", "(", "w_list", "[", "0", "]", ")", "\n", "for", "k", "in", "w", ".", "keys", "(", ")", ":", "\n", "        ", "w_avg", "[", "k", "]", "=", "w_avg", "[", "k", "]", "*", "weights_norm", "[", "0", "]", "\n", "", "for", "k", "in", "w", ".", "keys", "(", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "w_list", ")", ")", ":", "\n", "            ", "w_avg", "[", "k", "]", "+=", "w_list", "[", "idx", "]", "[", "k", "]", "*", "weights_norm", "[", "idx", "]", "\n", "", "w_avg", "[", "k", "]", "=", "w", "[", "k", "]", "+", "torch", ".", "mul", "(", "w_avg", "[", "k", "]", ".", "sub", "(", "w", "[", "k", "]", ")", ",", "sigma", ")", "\n", "\n", "", "return", "w_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.main": [[280, 420], ["reptile.load_pickle", "reptile.load_pickle", "print", "print", "reptile.reptile_meta", "range", "os.path.join", "os.path.join", "utils.save_pickle", "utils.save_pickle", "len", "client_models.append", "client_models[].set_train_test_file", "client_models[].build_data_loader", "len", "leave_out_modules.append", "leave_out_modules[].set_train_test_file", "leave_out_modules[].build_data_loader", "numpy.random.choice", "print", "reptile_meta.assign_new_weights", "str", "reptile.reptile_meta", "os.path.join", "os.path.join", "reptile.reptile_meta", "os.path.join", "os.path.join", "len", "client_models[].assign_new_weights", "client_models[].train", "updated_weights.append", "print", "reptile.update_server_weights", "print", "range", "fed_test_result[].append", "range", "leave_test_result[].append", "reptile_meta.get_model_weights", "client_models[].get_model_weights", "reptile_meta.get_model_weights", "len", "client_models[].assign_new_weights", "client_models[].test", "before_test.append", "before_num.append", "numpy.average", "range", "fed_test_result[].append", "len", "leave_out_modules[].assign_new_weights", "leave_out_modules[].test", "before_test.append", "before_num.append", "numpy.average", "range", "leave_test_result[].append", "reptile_meta.get_model_weights", "len", "print", "client_models[].adapt_train", "client_models[].test", "adapt_acc.append", "weights.append", "numpy.average", "reptile_meta.get_model_weights", "len", "leave_out_modules[].adapt", "client_models[].test", "adapt_acc.append", "weights.append", "numpy.average"], "function", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.load_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.load_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.set_train_test_file", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.build_data_loader", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.set_train_test_file", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.build_data_loader", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.update_server_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.reptile.reptile_meta.adapt_train", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.adapt", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test"], ["", "def", "main", "(", "rounds", ",", "out_dir", ",", "lr", "=", "0.001", ",", "local_e", "=", "1", ",", "leave_out", "=", "[", "0", "]", ",", "sigma", "=", "0.1", ",", "tmp", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    :param rounds: global rounds for federated learning: type: float\n    :param in_dir: input data dir: type: string\n    :param out_dir: output result dir: type: string\n    :param lr: initial learning rate: type float\n    :param local_e: local update epoches for federated learning: type: int\n    :param adapt_num: number of batch go through when used for adaptation: type: int\n    :param leave_out: leave out user index: 0-8 type: int\n    :param sigma: w_new = w + sigma* (avg_updated_w - w): sigma: float 0-1\n    :return: None\n    Save test acc result in output dir:\n        1. model acc on leave out user: before and after adapt\n        2. model acc on fed users: before and after adapt\n    \"\"\"", "\n", "\n", "train_users", "=", "load_pickle", "(", "\"../final_selected_user_collect.pickle\"", ")", "# meta-train users", "\n", "leave_users", "=", "load_pickle", "(", "\"../final_selected_user_mine.pickle\"", ")", "# meta-test users", "\n", "collect_dir", "=", "\"/data/ceph/seqrec/fl_data/www21/data/feature_fft/collect\"", "# data dir part1", "\n", "my_dir", "=", "\"/data/ceph/seqrec/fl_data/www21/data/feature_fft/mine\"", "# data dir part2", "\n", "\n", "# Meta-train set-up", "\n", "print", "(", "\"# meta-train user setup ...\"", ",", "len", "(", "train_users", ")", ")", "\n", "client_models", "=", "[", "]", "\n", "for", "val", "in", "train_users", ":", "\n", "        ", "client_models", ".", "append", "(", "reptile_meta", "(", "har_model", ".", "norm_cce", ",", "lr", ",", "device", ",", "cross_entropy", ",", "number_class", "=", "7", ")", ")", "\n", "\n", "# with the cross_entropy loss, this is the reptile model, when there is no fine-tune the results ", "\n", "# is the same as the fedavg. ", "\n", "\n", "client_train_file", "=", "[", "os", ".", "path", ".", "join", "(", "collect_dir", ",", "val", "+", "\"_train.pickle\"", ")", "]", "\n", "client_test_file", "=", "[", "os", ".", "path", ".", "join", "(", "collect_dir", ",", "val", "+", "\"_test.pickle\"", ")", "]", "\n", "# client_adapt_file = os.path.join(in_dir, val, \"stress/fine_tune_data\")", "\n", "client_adapt_file", "=", "client_train_file", "\n", "client_models", "[", "-", "1", "]", ".", "set_train_test_file", "(", "client_train_file", ",", "client_test_file", ",", "client_adapt_file", ")", "\n", "client_models", "[", "-", "1", "]", ".", "build_data_loader", "(", ")", "\n", "\n", "# build result dir", "\n", "# Meta-test users", "\n", "", "print", "(", "\"# meta-train user setup ...\"", ",", "len", "(", "leave_users", ")", ")", "\n", "leave_out_modules", "=", "[", "]", "\n", "for", "leave_user_name", "in", "leave_users", ":", "\n", "        ", "leave_out_modules", ".", "append", "(", "reptile_meta", "(", "har_model", ".", "norm_cce", ",", "lr", ",", "device", ",", "cross_entropy", ",", "number_class", "=", "7", ")", ")", "\n", "leave_train", "=", "[", "os", ".", "path", ".", "join", "(", "my_dir", ",", "leave_user_name", "+", "\"_train.pickle\"", ")", "]", "# fine-tune data", "\n", "leave_test", "=", "[", "os", ".", "path", ".", "join", "(", "my_dir", ",", "leave_user_name", "+", "\"_test.pickle\"", ")", "]", "# test data", "\n", "# leave_adapt_file = os.path.join(in_dir, leave_user_name, \"stress/fine_tune_data\")", "\n", "leave_adapt_file", "=", "leave_train", "\n", "leave_out_modules", "[", "-", "1", "]", ".", "set_train_test_file", "(", "leave_train", ",", "leave_test", ",", "leave_adapt_file", ")", "\n", "leave_out_modules", "[", "-", "1", "]", ".", "build_data_loader", "(", ")", "\n", "\n", "# server model for meta updating", "\n", "", "server_model", "=", "reptile_meta", "(", "har_model", ".", "norm_cce", ",", "lr", ",", "device", ",", "cross_entropy", ",", "number_class", "=", "7", ")", "\n", "\n", "# server_model result dir    ", "\n", "fed_test_result", "=", "{", "\"before\"", ":", "[", "]", "}", "# result  before personalization", "\n", "leave_test_result", "=", "{", "\"before\"", ":", "[", "]", "}", "\n", "init_after", "=", "0", "\n", "for", "val", "in", "[", "1", ",", "1", ",", "1", "]", ":", "# different number of fine-tune steps.", "\n", "        ", "fed_test_result", "[", "\"tune_%d\"", "%", "(", "init_after", "+", "val", ")", "]", "=", "[", "]", "\n", "leave_test_result", "[", "\"tune_%d\"", "%", "(", "init_after", "+", "val", ")", "]", "=", "[", "]", "\n", "# leave_test_result[\"after_%d_1\" % (init_after + val)] = []", "\n", "init_after", "+=", "val", "\n", "\n", "", "for", "i", "in", "range", "(", "rounds", ")", ":", "# global rounds", "\n", "# sampling users ", "\n", "        ", "chosen_client", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "train_users", ")", ",", "5", ",", "replace", "=", "False", ")", "\n", "updated_weights", "=", "[", "]", "\n", "for", "user_idx", "in", "chosen_client", ":", "\n", "# pull weights theta from center", "\n", "            ", "client_models", "[", "user_idx", "]", ".", "assign_new_weights", "(", "server_model", ".", "get_model_weights", "(", ")", ")", "\n", "# local train", "\n", "client_models", "[", "user_idx", "]", ".", "train", "(", "num_epoch", "=", "local_e", ")", "\n", "# get updated para difference.", "\n", "updated_weights", ".", "append", "(", "client_models", "[", "user_idx", "]", ".", "get_model_weights", "(", ")", ")", "\n", "print", "(", "\"done local train on user: %s\"", "%", "train_users", "[", "user_idx", "]", ")", "\n", "\n", "", "print", "(", "\"======= update global meta model ========\"", ")", "\n", "server_model", ".", "assign_new_weights", "(", "\n", "update_server_weights", "(", "updated_weights", ",", "server_model", ".", "get_model_weights", "(", ")", ",", "sigma", "=", "sigma", ")", ")", "\n", "\n", "if", "i", ">", "30", ":", "# start to evaluate current model after 30 global rounds.", "\n", "            ", "print", "(", "\"========== Testing ===========\"", ")", "\n", "# Meta-train users", "\n", "before_test", "=", "[", "]", "\n", "before_num", "=", "[", "]", "\n", "for", "user_idx", "in", "range", "(", "len", "(", "train_users", ")", ")", ":", "\n", "                ", "client_models", "[", "user_idx", "]", ".", "assign_new_weights", "(", "server_model", ".", "get_model_weights", "(", ")", ")", "\n", "acc", ",", "num", "=", "client_models", "[", "user_idx", "]", ".", "test", "(", ")", "\n", "before_test", ".", "append", "(", "acc", ")", "\n", "before_num", ".", "append", "(", "num", ")", "\n", "", "fed_test_result", "[", "\"before\"", "]", ".", "append", "(", "np", ".", "average", "(", "before_test", ",", "weights", "=", "before_num", ")", ")", "\n", "\n", "adapt_val", "=", "0", "\n", "for", "val", "in", "[", "1", ",", "1", ",", "1", "]", ":", "# three adapt steps", "\n", "                ", "adapt_acc", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "user_idx", "in", "range", "(", "len", "(", "train_users", ")", ")", ":", "\n", "# client_models[user_idx].assign_new_weights(server_model.get_model_weights())", "\n", "                    ", "print", "(", "\"======user: %d, adapt: %d\"", "%", "(", "user_idx", ",", "adapt_val", "+", "val", ")", ")", "\n", "client_models", "[", "user_idx", "]", ".", "adapt_train", "(", ")", "\n", "acc", ",", "num", "=", "client_models", "[", "user_idx", "]", ".", "test", "(", ")", "\n", "adapt_acc", ".", "append", "(", "acc", ")", "\n", "weights", ".", "append", "(", "num", ")", "\n", "", "fed_test_result", "[", "\"tune_%d\"", "%", "(", "adapt_val", "+", "val", ")", "]", ".", "append", "(", "np", ".", "average", "(", "adapt_acc", ",", "weights", "=", "weights", ")", ")", "\n", "adapt_val", "+=", "val", "\n", "\n", "# Meta-test users", "\n", "", "before_test", "=", "[", "]", "\n", "before_num", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "leave_users", ")", ")", ":", "\n", "# for every Meta-test user", "\n", "                ", "leave_out_modules", "[", "j", "]", ".", "assign_new_weights", "(", "server_model", ".", "get_model_weights", "(", ")", ")", "\n", "acc", ",", "num", "=", "leave_out_modules", "[", "j", "]", ".", "test", "(", ")", "\n", "before_test", ".", "append", "(", "acc", ")", "\n", "before_num", ".", "append", "(", "num", ")", "\n", "", "leave_test_result", "[", "\"before\"", "]", ".", "append", "(", "np", ".", "average", "(", "before_test", ",", "weights", "=", "before_num", ")", ")", "\n", "\n", "# for different number of adapt batch", "\n", "adapt_val", "=", "0", "\n", "for", "val", "in", "[", "1", ",", "1", ",", "1", "]", ":", "\n", "                ", "adapt_acc", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "len", "(", "leave_users", ")", ")", ":", "\n", "                    ", "leave_out_modules", "[", "j", "]", ".", "adapt", "(", "num_batch", "=", "val", ")", "\n", "acc", ",", "num", "=", "client_models", "[", "user_idx", "]", ".", "test", "(", ")", "\n", "adapt_acc", ".", "append", "(", "acc", ")", "\n", "weights", ".", "append", "(", "num", ")", "\n", "", "leave_test_result", "[", "\"tune_%d\"", "%", "(", "adapt_val", "+", "val", ")", "]", ".", "append", "(", "np", ".", "average", "(", "adapt_acc", ",", "weights", "=", "weights", ")", ")", "\n", "adapt_val", "+=", "val", "\n", "\n", "# save test results\tlocal_sigma_tmp_leave", "\n", "", "", "", "leave_str", "=", "\"\"", "\n", "for", "val", "in", "leave_out", ":", "\n", "        ", "leave_str", "+=", "str", "(", "val", ")", "\n", "", "fed_test_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\n", "\"fed_test_N0_%d_%.2f_%d_%s\"", "%", "(", "local_e", ",", "sigma", ",", "tmp", ",", "leave_str", ")", ")", "\n", "leave_test_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\n", "\"leave_test_N0_%d_%.2f_%d_%s\"", "%", "(", "local_e", ",", "sigma", ",", "tmp", ",", "leave_str", ")", ")", "\n", "utils", ".", "save_pickle", "(", "fed_test_result", ",", "fed_test_file", ")", "\n", "utils", ".", "save_pickle", "(", "leave_test_result", ",", "leave_test_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.merge_sensor_block.__init__": [[10, 21], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ")", ":", "\n", "        ", "super", "(", "merge_sensor_block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Between freq and magnitute", "\n", "self", ".", "conv1", "=", "nn", ".", "Conv3d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "2", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "# Between sensor axis", "\n", "self", ".", "conv2", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "4", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "4", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "# between sensor data", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "2", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.merge_sensor_block.forward": [[22, 27], ["torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "har_model.merge_sensor_block.bn1", "har_model.merge_sensor_block.bn2", "har_model.merge_sensor_block.bn3", "har_model.merge_sensor_block.conv1", "har_model.merge_sensor_block.conv2", "har_model.merge_sensor_block.conv3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn2", "(", "self", ".", "conv2", "(", "out", ")", ")", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "out", ")", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.norm_sensor_block.__init__": [[31, 49], ["torch.Module.__init__", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.Conv3d", "torch.Conv3d", "torch.Conv3d", "torch.BatchNorm3d", "torch.BatchNorm3d", "torch.BatchNorm3d"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_planes", ",", "planes", ")", ":", "\n", "        ", "super", "(", "norm_sensor_block", ",", "self", ")", ".", "__init__", "(", ")", "\n", "# Acc", "\n", "self", ".", "acc_conv1", "=", "nn", ".", "Conv3d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "2", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "acc_bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "# Between sensor axis", "\n", "self", ".", "acc_conv2", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "4", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "4", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "acc_bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "\n", "# gyro", "\n", "self", ".", "gyro_conv1", "=", "nn", ".", "Conv3d", "(", "in_planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "2", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "2", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "gyro_bn1", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "# Between sensor axis", "\n", "self", ".", "gyro_conv2", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "4", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "4", ",", "1", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "gyro_bn2", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "# merge conv", "\n", "self", ".", "conv3", "=", "nn", ".", "Conv3d", "(", "planes", ",", "planes", ",", "kernel_size", "=", "(", "1", ",", "2", ",", "3", ")", ",", "stride", "=", "(", "1", ",", "1", ",", "2", ")", ",", "padding", "=", "(", "0", ",", "0", ",", "1", ")", ")", "\n", "self", ".", "bn3", "=", "nn", ".", "BatchNorm3d", "(", "planes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.norm_sensor_block.forward": [[50, 65], ["torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.relu", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.relu", "torch.relu", "torch.relu", "har_model.norm_sensor_block.acc_bn1", "har_model.norm_sensor_block.acc_bn2", "har_model.norm_sensor_block.gyro_bn1", "har_model.norm_sensor_block.gyro_bn2", "har_model.norm_sensor_block.bn3", "har_model.norm_sensor_block.acc_conv1", "har_model.norm_sensor_block.acc_conv2", "har_model.norm_sensor_block.gyro_conv1", "har_model.norm_sensor_block.gyro_conv2", "har_model.norm_sensor_block.conv3"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" input x with shape b, c = 1, seq_len, sensor_dim = 16, interval_len = (7 /12 ?)\"\"\"", "\n", "# Is it possible to calculate the acc and gyro convolution in parallel??? TO DO", "\n", "# split x", "\n", "x_split", "=", "torch", ".", "split", "(", "x", ",", "8", ",", "dim", "=", "3", ")", "\n", "# acc", "\n", "acc_out", "=", "F", ".", "relu", "(", "self", ".", "acc_bn1", "(", "self", ".", "acc_conv1", "(", "x_split", "[", "0", "]", ")", ")", ")", "\n", "acc_out", "=", "F", ".", "relu", "(", "self", ".", "acc_bn2", "(", "self", ".", "acc_conv2", "(", "acc_out", ")", ")", ")", "\n", "# gyro", "\n", "gyro_out", "=", "F", ".", "relu", "(", "self", ".", "gyro_bn1", "(", "self", ".", "gyro_conv1", "(", "x_split", "[", "1", "]", ")", ")", ")", "\n", "gyro_out", "=", "F", ".", "relu", "(", "self", ".", "gyro_bn2", "(", "self", ".", "gyro_conv2", "(", "gyro_out", ")", ")", ")", "\n", "\n", "sensor_data", "=", "torch", ".", "cat", "(", "[", "acc_out", ",", "gyro_out", "]", ",", "3", ")", "\n", "out", "=", "F", ".", "relu", "(", "self", ".", "bn3", "(", "self", ".", "conv3", "(", "sensor_data", ")", ")", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.main_model.__init__": [[68, 83], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.LSTM", "torch.LSTM", "torch.LSTM", "sensor_block", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ",", "sensor_block", ",", "seq_len", ",", "batch_size", ",", "logits_len", "=", "None", ",", "embed", "=", "False", ",", "embed_len", "=", "100", ",", "rnn_layer", "=", "2", ",", "\n", "bidirectional", "=", "False", ")", ":", "\n", "        ", "super", "(", "main_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "embed", "=", "embed", "\n", "self", ".", "seq_len", "=", "seq_len", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "if", "bidirectional", ":", "\n", "            ", "bid", "=", "2", "\n", "", "else", ":", "\n", "            ", "bid", "=", "1", "\n", "#", "\n", "", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "sensor_block", "(", "1", ",", "64", ")", ")", "# [batch, planes, seq_len, 1, 4]", "\n", "self", ".", "lstm", "=", "nn", ".", "LSTM", "(", "64", "*", "1", "*", "4", ",", "embed_len", ",", "rnn_layer", ",", "bidirectional", "=", "bidirectional", ")", "\n", "if", "not", "embed", ":", "\n", "            ", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "embed_len", "*", "bid", ",", "logits_len", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.main_model.forward": [[84, 94], ["har_model.main_model.conv", "har_model.main_model.lstm", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean.permute().contiguous().view", "torch.mean.permute().contiguous().view", "torch.mean.permute().contiguous().view", "torch.mean.permute", "torch.mean.permute", "torch.mean.permute", "har_model.main_model.linear", "torch.mean.permute().contiguous", "torch.mean.permute().contiguous", "torch.mean.permute().contiguous", "torch.mean.permute", "torch.mean.permute", "torch.mean.permute"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "\"\"\" x with shape [batch, channel, seq_len, H, W] \"\"\"", "\n", "out", "=", "self", ".", "conv", "(", "x", ")", "# out with shape", "\n", "out", ",", "_", "=", "self", ".", "lstm", "(", "out", ".", "permute", "(", "2", ",", "0", ",", "1", ",", "3", ",", "4", ")", ".", "contiguous", "(", ")", ".", "view", "(", "self", ".", "seq_len", ",", "-", "1", ",", "64", "*", "1", "*", "4", ")", ")", "\n", "out", "=", "torch", ".", "mean", "(", "out", ".", "permute", "(", "1", ",", "0", ",", "2", ")", ",", "1", ")", "# [batch, num_directions * hidden_size]", "\n", "if", "self", ".", "embed", ":", "\n", "            ", "return", "out", "\n", "", "else", ":", "\n", "            ", "logits", "=", "self", ".", "linear", "(", "out", ")", "\n", "return", "logits", ",", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.last_layer.__init__": [[97, 101], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ",", "embed_len", ",", "number_class", ")", ":", "\n", "        ", "super", "(", "last_layer", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "number_class", "=", "number_class", "\n", "self", ".", "linear", "=", "nn", ".", "Linear", "(", "embed_len", ",", "number_class", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.last_layer.forward": [[102, 104], ["har_model.last_layer.linear"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "return", "self", ".", "linear", "(", "x", ")", "# logits", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.merge_embed": [[106, 110], ["har_model.main_model"], "function", ["None"], ["", "", "def", "merge_embed", "(", "bidirectional", ")", ":", "\n", "    ", "return", "main_model", "(", "sensor_block", "=", "merge_sensor_block", ",", "seq_len", "=", "utils", ".", "parameter", "[", "\"SEQUENCE_LEN\"", "]", ",", "\n", "batch_size", "=", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "\n", "embed", "=", "True", ",", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.merge_cce": [[112, 116], ["har_model.main_model"], "function", ["None"], ["", "def", "merge_cce", "(", "bidirectional", ",", "num_classes", "=", "6", ")", ":", "\n", "    ", "return", "main_model", "(", "sensor_block", "=", "merge_sensor_block", ",", "seq_len", "=", "utils", ".", "parameter", "[", "\"SEQUENCE_LEN\"", "]", ",", "\n", "batch_size", "=", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "\n", "logits_len", "=", "num_classes", ",", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.norm_embed": [[118, 122], ["har_model.main_model"], "function", ["None"], ["", "def", "norm_embed", "(", "bidirectional", ")", ":", "\n", "    ", "return", "main_model", "(", "sensor_block", "=", "norm_sensor_block", ",", "seq_len", "=", "utils", ".", "parameter", "[", "\"SEQUENCE_LEN\"", "]", ",", "\n", "batch_size", "=", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "\n", "embed", "=", "True", ",", "bidirectional", "=", "bidirectional", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.norm_cce": [[124, 128], ["har_model.main_model"], "function", ["None"], ["", "def", "norm_cce", "(", "bidirectional", ",", "num_classes", "=", "6", ")", ":", "\n", "    ", "return", "main_model", "(", "sensor_block", "=", "norm_sensor_block", ",", "seq_len", "=", "utils", ".", "parameter", "[", "\"SEQUENCE_LEN\"", "]", ",", "\n", "batch_size", "=", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "\n", "logits_len", "=", "num_classes", ",", "bidirectional", "=", "bidirectional", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.central_model.__init__": [[25, 32], ["har_model.norm_cce", "Central.central_model.model.to", "torch.Adam", "torch.Adam", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "Central.central_model.model.parameters"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.har_model.norm_cce"], ["    ", "def", "__init__", "(", "self", ",", "trainloader", ",", "testloader", ")", ":", "\n", "        ", "self", ".", "trainloader", "=", "trainloader", "\n", "self", ".", "testloader", "=", "testloader", "\n", "self", ".", "model", "=", "har_model", ".", "norm_cce", "(", "bidirectional", "=", "False", ",", "num_classes", "=", "7", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "device", ")", "\n", "self", ".", "opt", "=", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "utils", ".", "parameter", "[", "\"lr\"", "]", ",", "weight_decay", "=", "1e-4", ")", "\n", "self", ".", "cross_entropy", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.central_model.valid": [[33, 54], ["Central.central_model.model.eval", "enumerate", "print", "Central.central_model.opt.zero_grad", "Central.central_model.item", "outputs.max", "predicted.eq().sum().item", "inputs.to", "targets.to", "Central.central_model.model", "Central.central_model.cross_entropy", "Central.central_model.model", "Central.central_model.cross_entropy", "targets.size", "inputs.unsqueeze().type", "targets.type", "inputs.unsqueeze().type", "targets.type", "predicted.eq().sum", "inputs.unsqueeze", "inputs.unsqueeze", "predicted.eq"], "methods", ["None"], ["", "def", "valid", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "epoch_loss", "=", "0.0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "self", ".", "testloader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "cross_entropy", "(", "outputs", ",", "targets", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "# .max(1)[1].type()", "\n", "", "else", ":", "\n", "                ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "cross_entropy", "(", "outputs", ",", "targets", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", ")", "[", "0", "]", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "acc", "=", "100.0", "*", "correct", "/", "total", "\n", "print", "(", "f\" === test acc: {acc}\"", ")", "\n", "return", "acc", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.central_model.train_step": [[55, 88], ["Central.central_model.model.train", "range", "tqdm.tqdm.tqdm", "tqdm.tqdm.tqdm.set_description", "print", "Central.central_model.valid", "enumerate", "Central.central_model.opt.zero_grad", "Central.central_model.backward", "Central.central_model.opt.step", "Central.central_model.item", "outputs.max", "predicted.eq().sum().item", "tqdm.tqdm.tqdm.set_postfix", "inputs.to", "targets.to", "Central.central_model.model", "Central.central_model.cross_entropy", "Central.central_model.model", "Central.central_model.cross_entropy", "targets.size", "inputs.unsqueeze().type", "targets.type", "inputs.unsqueeze().type", "targets.type", "predicted.eq().sum", "predicted.eq().sum().item", "targets.size", "Central.central_model.item", "inputs.unsqueeze", "inputs.unsqueeze", "predicted.eq", "predicted.eq().sum", "predicted.eq"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.central_model.valid"], ["", "def", "train_step", "(", "self", ",", "epochs", ")", ":", "\n", "        ", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "round_num", "in", "range", "(", "epochs", ")", ":", "\n", "            ", "correct", "=", "0", "\n", "total", "=", "0", "\n", "epoch_loss", "=", "0.0", "\n", "\n", "pbar", "=", "tqdm", "(", "enumerate", "(", "self", ".", "trainloader", ")", ")", "\n", "pbar", ".", "set_description", "(", "f'[Train epoch {round_num}]'", ")", "\n", "# for batch_idx, (inputs, targets) in enumerate(self.trainloader):", "\n", "for", "batch_idx", ",", "data_batch", "in", "pbar", ":", "\n", "                ", "inputs", ",", "targets", "=", "data_batch", "[", "0", "]", ",", "data_batch", "[", "1", "]", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "opt", ".", "zero_grad", "(", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "cross_entropy", "(", "outputs", ",", "targets", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "# .max(1)[1].type()", "\n", "", "else", ":", "\n", "                    ", "outputs", ",", "_", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "cross_entropy", "(", "outputs", ",", "targets", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "# back", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "opt", ".", "step", "(", ")", "\n", "epoch_loss", "+=", "loss", ".", "item", "(", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", ")", "[", "0", "]", "# \uff08batch size\uff09", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "acc_step", "=", "100.0", "*", "predicted", ".", "eq", "(", "targets", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "/", "targets", ".", "size", "(", ")", "[", "0", "]", "\n", "pbar", ".", "set_postfix", "(", "accuracy", "=", "acc_step", ",", "ce_loss", "=", "loss", ".", "item", "(", ")", ")", "\n", "# epoch metric", "\n", "", "acc", "=", "100.0", "*", "correct", "/", "total", "\n", "print", "(", "f\"epoch {round_num}: epoch acc: {acc}\"", ")", "\n", "self", ".", "valid", "(", ")", "\n", "# return self.valid()", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.save_pickle": [[91, 94], ["open", "_pickle.dump"], "function", ["None"], ["", "", "", "def", "save_pickle", "(", "data_dict", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "fid", ":", "\n", "        ", "pickle", ".", "dump", "(", "data_dict", ",", "fid", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.load_pickle": [[96, 100], ["_pickle.load", "print", "open"], "function", ["None"], ["", "", "def", "load_pickle", "(", "filename", ",", "show_name", "=", "False", ")", ":", "\n", "    ", "if", "show_name", ":", "\n", "        ", "print", "(", "filename", ")", "\n", "", "return", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.self_test_all": [[102, 120], ["print", "print", "os.path.join", "os.path.join", "print", "utils.dataloader_gen", "utils.dataloader_gen", "Central.central_model", "Central.central_model.train_step", "open", "os.listdir", "fid.write", "file.split", "str"], "function", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.central_model.train_step"], ["", "def", "self_test_all", "(", "in_dir", ")", ":", "\n", "    ", "filename", "=", "[", "\"_\"", ".", "join", "(", "file", ".", "split", "(", "\"_\"", ")", "[", "0", ":", "2", "]", ")", "for", "file", "in", "os", ".", "listdir", "(", "in_dir", ")", "if", "\"train\"", "in", "file", "]", "\n", "result", "=", "{", "}", "\n", "for", "file", "in", "filename", ":", "\n", "        ", "print", "(", "\"user:\"", ",", "file", ")", "\n", "train_file", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "file", "+", "\"_train.pickle\"", ")", "\n", "test_file", "=", "os", ".", "path", ".", "join", "(", "in_dir", ",", "file", "+", "\"_test.pickle\"", ")", "\n", "print", "(", "train_file", ")", "\n", "trainloader", "=", "utils", ".", "dataloader_gen", "(", "[", "train_file", "]", ",", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "target", "=", "\"number\"", ")", "\n", "testloader", "=", "utils", ".", "dataloader_gen", "(", "[", "test_file", "]", ",", "1", ",", "train", "=", "False", ",", "target", "=", "\"number\"", ")", "\n", "model", "=", "central_model", "(", "trainloader", ",", "testloader", ")", "\n", "test_acc", "=", "model", ".", "train_step", "(", "args", ".", "epochs", ")", "\n", "result", "[", "file", "]", "=", "test_acc", "\n", "", "print", "(", "result", ")", "\n", "with", "open", "(", "\"self_test.txt\"", ",", "\"w\"", ")", "as", "fid", ":", "\n", "        ", "for", "key", "in", "result", ":", "\n", "            ", "line", "=", "key", "+", "\"\\t\"", "+", "str", "(", "result", "[", "key", "]", ")", "+", "\"\\n\"", "\n", "fid", ".", "write", "(", "line", ")", "\n", "# save_pickle(result, \"self_test.pickle\")", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.all_central": [[123, 134], ["print", "utils.dataloader_gen", "utils.dataloader_gen", "Central.central_model", "Central.central_model.train_step", "os.path.join", "os.path.join", "len", "len", "os.listdir", "os.listdir"], "function", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.Central.central_model.train_step"], ["", "", "", "def", "all_central", "(", ")", ":", "\n", "# data loader", "\n", "    ", "data_dir", "=", "\"F:\\\\www21\\\\final_version\\\\Meta-HAR\\\\Data\\\\collected_pickle\"", "\n", "train_files", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file", ")", "for", "file", "in", "os", ".", "listdir", "(", "data_dir", ")", "if", "'train'", "in", "file", "]", "\n", "test_files", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file", ")", "for", "file", "in", "os", ".", "listdir", "(", "data_dir", ")", "if", "'test'", "in", "file", "]", "\n", "print", "(", "len", "(", "train_files", ")", ",", "len", "(", "test_files", ")", ")", "\n", "trainloader", "=", "utils", ".", "dataloader_gen", "(", "train_files", ",", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ",", "target", "=", "\"number\"", ")", "\n", "testloader", "=", "utils", ".", "dataloader_gen", "(", "test_files", ",", "1", ",", "train", "=", "False", ",", "target", "=", "\"number\"", ")", "\n", "# model and train", "\n", "model", "=", "central_model", "(", "trainloader", ",", "testloader", ")", "\n", "model", ".", "train_step", "(", "args", ".", "epochs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.pairwiseloss.__init__": [[75, 77], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "pairwiseloss", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.pairwiseloss.forward": [[78, 93], ["numpy.float64", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "softplus", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "cosine_similarity", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "embed", ",", "target", ",", "chunck_size", ",", "Expand", "=", "10", ")", ":", "\n", "        ", "Expand", "=", "np", ".", "float64", "(", "Expand", "*", "1.0", ")", "\n", "embed_split", "=", "torch", ".", "split", "(", "embed", ",", "chunck_size", ",", "dim", "=", "0", ")", "\n", "target_split", "=", "torch", ".", "split", "(", "target", ",", "chunck_size", ",", "dim", "=", "0", ")", "\n", "Phi", "=", "cosine_similarity", "(", "embed_split", "[", "0", "]", ",", "embed_split", "[", "1", "]", ")", "*", "Expand", "\n", "soft_phi", "=", "softplus", "(", "Phi", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "            ", "mask", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "target_split", "[", "0", "]", ",", "target_split", "[", "1", "]", ")", ",", "dim", "=", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "target_split", "[", "0", "]", ",", "target_split", "[", "1", "]", ")", ",", "dim", "=", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "# print(mask.type())", "\n", "# print(Phi.type())", "\n", "", "mask_phi", "=", "torch", ".", "mul", "(", "mask", ",", "Phi", ")", "\n", "pairwiseloss", "=", "torch", ".", "sub", "(", "soft_phi", ",", "mask_phi", ")", ".", "mean", "(", ")", "\n", "return", "pairwiseloss", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.pairwiseloss_global.__init__": [[96, 98], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "pairwiseloss_global", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.pairwiseloss_global.forward": [[99, 124], ["numpy.float64", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "softplus", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "cosine_similarity", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "cosine_similarity", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "target.type", "target.type", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "softplus"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "embed", ",", "target", ",", "chunk_size", ",", "global_center", "=", "None", ",", "beta", "=", "2.0", ",", "Expand", "=", "10", ")", ":", "\n", "# Expand=10 equals to the temperature=0.1 in a commonly used temperature based formula.", "\n", "        ", "Expand", "=", "np", ".", "float64", "(", "Expand", "*", "1.0", ")", "\n", "embed_split", "=", "torch", ".", "split", "(", "embed", ",", "chunk_size", ",", "dim", "=", "0", ")", "\n", "target_split", "=", "torch", ".", "split", "(", "target", ",", "chunk_size", ",", "dim", "=", "0", ")", "\n", "Phi", "=", "cosine_similarity", "(", "embed_split", "[", "0", "]", ",", "embed_split", "[", "1", "]", ")", "*", "Expand", "\n", "soft_phi", "=", "softplus", "(", "Phi", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "            ", "mask", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "target_split", "[", "0", "]", ",", "target_split", "[", "1", "]", ")", ",", "dim", "=", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "", "else", ":", "\n", "            ", "mask", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "target_split", "[", "0", "]", ",", "target_split", "[", "1", "]", ")", ",", "dim", "=", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "", "mask_phi", "=", "torch", ".", "mul", "(", "mask", ",", "Phi", ")", "\n", "pairwiseloss", "=", "torch", ".", "sub", "(", "soft_phi", ",", "mask_phi", ")", ".", "mean", "(", ")", "\n", "if", "global_center", "is", "not", "None", ":", "\n", "            ", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "sample_centers", "=", "torch", ".", "mm", "(", "target", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ",", "global_center", ")", "\n", "", "else", ":", "\n", "                ", "sample_centers", "=", "torch", ".", "mm", "(", "target", ".", "type", "(", "torch", ".", "FloatTensor", ")", ",", "global_center", ")", "\n", "", "phi_1", "=", "cosine_similarity", "(", "embed", ",", "sample_centers", ")", "*", "Expand", "\n", "global_sim_loss", "=", "torch", ".", "sub", "(", "softplus", "(", "phi_1", ")", ",", "phi_1", ")", ".", "mean", "(", ")", "\n", "# print(pairwiseloss)", "\n", "# print(global_sim_loss)", "\n", "return", "pairwiseloss", "+", "beta", "*", "global_sim_loss", "\n", "", "else", ":", "\n", "            ", "return", "pairwiseloss", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.crossentropy_global.__init__": [[127, 129], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "crossentropy_global", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.crossentropy_global.forward": [[130, 148], ["target.max", "cross_entropy", "numpy.float64", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "target.type", "cosine_similarity", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "softplus"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ",", "embed", ",", "chuck_size", ",", "global_center", "=", "None", ",", "beta", "=", "0.25", ",", "Expand", "=", "10", ")", ":", "\n", "# cross entropy loss", "\n", "# print(target.size())", "\n", "        ", "_", ",", "target_cce", "=", "target", ".", "max", "(", "1", ")", "\n", "# print(target_cce.size())", "\n", "# sys.exit()", "\n", "cross_loss", "=", "cross_entropy", "(", "output", ",", "target_cce", ")", "\n", "\n", "if", "global_center", "is", "not", "None", ":", "\n", "# print(\"hello=================\")", "\n", "# global_center.to(device)", "\n", "            ", "Expand", "=", "np", ".", "float64", "(", "Expand", "*", "1.0", ")", "\n", "sample_centers", "=", "torch", ".", "mm", "(", "target", ".", "type", "(", "torch", ".", "float64", ")", ",", "global_center", ")", "\n", "phi_1", "=", "cosine_similarity", "(", "embed", ",", "sample_centers", ")", "*", "Expand", "\n", "global_sim_loss", "=", "torch", ".", "sub", "(", "softplus", "(", "phi_1", ")", ",", "phi_1", ")", ".", "mean", "(", ")", "\n", "return", "cross_loss", "+", "beta", "*", "global_sim_loss", "\n", "", "else", ":", "\n", "            ", "return", "cross_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.crossentropy_pairwise.__init__": [[151, 153], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "crossentropy_pairwise", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.crossentropy_pairwise.forward": [[154, 188], ["target.max", "cross_entropy", "numpy.float64", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "torch.split", "softplus", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "numpy.float64", "torch.mm", "torch.mm", "torch.mm", "torch.mm", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "torch.sub().mean", "embed.size", "cosine_similarity", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "torch.sum().type", "target.type", "cosine_similarity", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.sub", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "softplus", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "output", ",", "target", ",", "embed", ",", "chunck_size", ",", "global_center", "=", "None", ",", "beta", "=", "0.25", ",", "Expand", "=", "10", ")", ":", "\n", "# cross entropy loss", "\n", "        ", "_", ",", "target_cce", "=", "target", ".", "max", "(", "1", ")", "\n", "# print(target_cce.size())", "\n", "# sys.exit()", "\n", "loss", "=", "cross_entropy", "(", "output", ",", "target_cce", ")", "\n", "# Pairwise loss", "\n", "if", "embed", ".", "size", "(", ")", "[", "0", "]", ">", "4", ":", "# in case of test phase when batch_size is 1 ", "\n", "            ", "Expand", "=", "np", ".", "float64", "(", "Expand", "*", "1.0", ")", "\n", "embed_split", "=", "torch", ".", "split", "(", "embed", ",", "chunck_size", ",", "dim", "=", "0", ")", "\n", "target_split", "=", "torch", ".", "split", "(", "target", ",", "chunck_size", ",", "dim", "=", "0", ")", "\n", "Phi", "=", "cosine_similarity", "(", "embed_split", "[", "0", "]", ",", "embed_split", "[", "1", "]", ")", "*", "Expand", "\n", "soft_phi", "=", "softplus", "(", "Phi", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "mask", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "target_split", "[", "0", "]", ",", "target_split", "[", "1", "]", ")", ",", "dim", "=", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", "\n", "", "else", ":", "\n", "                ", "mask", "=", "torch", ".", "sum", "(", "torch", ".", "mul", "(", "target_split", "[", "0", "]", ",", "target_split", "[", "1", "]", ")", ",", "dim", "=", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", "\n", "", "mask_phi", "=", "torch", ".", "mul", "(", "mask", ",", "Phi", ")", "\n", "pairwiseloss", "=", "torch", ".", "sub", "(", "soft_phi", ",", "mask_phi", ")", ".", "mean", "(", ")", "\n", "\n", "# print(\"cross loss: % .3f\" % cross_loss)", "\n", "# print(\"pairwise loss: % .3f\" % pairwiseloss)", "\n", "loss", "+=", "0.25", "*", "pairwiseloss", "\n", "# Possible global loss", "\n", "", "if", "global_center", "is", "not", "None", ":", "\n", "# print(\"hello=================\")", "\n", "# global_center.to(device)", "\n", "            ", "Expand", "=", "np", ".", "float64", "(", "Expand", "*", "1.0", ")", "\n", "sample_centers", "=", "torch", ".", "mm", "(", "target", ".", "type", "(", "torch", ".", "float64", ")", ",", "global_center", ")", "\n", "phi_1", "=", "cosine_similarity", "(", "embed", ",", "sample_centers", ")", "*", "Expand", "\n", "global_sim_loss", "=", "torch", ".", "sub", "(", "softplus", "(", "phi_1", ")", ",", "phi_1", ")", ".", "mean", "(", ")", "\n", "return", "loss", "+", "beta", "*", "global_sim_loss", "\n", "", "else", ":", "\n", "            ", "return", "loss", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen": [[43, 55], ["data_loader.heter_data", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["def", "dataloader_gen", "(", "filename", ",", "batch_size", ",", "train", "=", "True", ",", "target", "=", "\"logits\"", ")", ":", "\n", "    ", "\"\"\"\n        Args:\n            filename: a list of pickle files that stores the processed HAR data (after FFT)\n            batch_size: batch size\n            train: is for training?\n            target: encoder method for the label: \"hot\": one-hot encoding, else int number\n    \"\"\"", "\n", "dataset", "=", "data_loader", ".", "heter_data", "(", "filename", ",", "target", "=", "target", ")", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "train", ",", "num_workers", "=", "2", ",", "\n", "drop_last", "=", "True", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen2": [[57, 62], ["data_loader.heter_data2", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "dataloader_gen2", "(", "filename", ",", "batch_size", ",", "train", "=", "True", ",", "target", "=", "\"logits\"", ")", ":", "\n", "    ", "dataset", "=", "data_loader", ".", "heter_data2", "(", "filename", ",", "target", "=", "target", ")", "\n", "dataloader", "=", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "dataset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "train", ",", "num_workers", "=", "2", ",", "\n", "drop_last", "=", "True", ")", "\n", "return", "dataloader", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.load_pickle": [[64, 67], ["open", "_pickle.load"], "function", ["None"], ["", "def", "load_pickle", "(", "filename", ")", ":", "\n", "    ", "f", "=", "open", "(", "filename", ",", "\"rb\"", ")", "\n", "return", "pickle", ".", "load", "(", "f", ",", "encoding", "=", "\"latin\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.save_pickle": [[69, 72], ["open", "_pickle.dump"], "function", ["None"], ["", "def", "save_pickle", "(", "dict_name", ",", "file_name", ")", ":", "\n", "    ", "with", "open", "(", "file_name", ",", "\"wb\"", ")", "as", "myfile", ":", "\n", "        ", "pickle", ".", "dump", "(", "dict_name", ",", "myfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.MyEnsemble.__init__": [[22, 26], ["torch.nn.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ",", "modelA", ",", "modelB", ")", ":", "\n", "        ", "super", "(", "MyEnsemble", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "modelA", "=", "modelA", "\n", "self", ".", "modelB", "=", "modelB", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.MyEnsemble.forward": [[27, 31], ["met-har.MyEnsemble.modelA", "met-har.MyEnsemble.modelB"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x1", "=", "self", ".", "modelA", "(", "x", ")", "\n", "x2", "=", "self", ".", "modelB", "(", "x1", ")", "\n", "return", "x2", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__": [[35, 52], ["object.__init__", "graph", "met-har.reptile_meta.model.to", "har_model.last_layer", "met-har.reptile_meta.last_layer.to", "met-har.MyEnsemble", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "met-har.reptile_meta.last_layer.parameters", "met-har.reptile_meta.model.parameters"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.__init__"], ["    ", "def", "__init__", "(", "self", ",", "graph", ",", "lr", ",", "device_i", ",", "loss_fun", ",", "embed_len", ",", "number_class", ",", "class_map", "=", "None", ",", "beta", "=", "0.5", ")", ":", "\n", "        ", "\"\"\"graph can be norm_embed\"\"\"", "\n", "super", "(", "reptile_meta", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "beta", "=", "beta", "\n", "self", ".", "class_map", "=", "class_map", "\n", "self", ".", "number_class", "=", "number_class", "\n", "# initialize embed model and last layer", "\n", "self", ".", "model", "=", "graph", "(", "bidirectional", "=", "False", ")", "\n", "self", ".", "model", "=", "self", ".", "model", ".", "to", "(", "device_i", ")", "\n", "self", ".", "last_layer", "=", "har_model", ".", "last_layer", "(", "embed_len", ",", "number_class", ")", "\n", "self", ".", "last_layer", "=", "self", ".", "last_layer", ".", "to", "(", "device_i", ")", "\n", "self", ".", "merge_model", "=", "MyEnsemble", "(", "self", ".", "model", ",", "self", ".", "last_layer", ")", "\n", "self", ".", "training_op", "=", "{", "\"last_optimizer\"", ":", "optim", ".", "Adam", "(", "self", ".", "last_layer", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "weight_decay", "=", "1e-4", ")", ",", "\n", "\"embed_optimizer\"", ":", "optim", ".", "Adam", "(", "self", ".", "model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "weight_decay", "=", "1e-4", ")", ",", "\n", "\"loss_fun\"", ":", "loss_fun", ",", "\"loss_fun_last\"", ":", "cross_entropy", "}", "\n", "self", ".", "training_res", "=", "{", "\"train_acc\"", ":", "[", "]", ",", "\"test_acc\"", ":", "[", "]", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.label_transfer": [[53, 57], ["[].numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "target.max"], "methods", ["None"], ["", "def", "label_transfer", "(", "self", ",", "target", ")", ":", "\n", "        ", "int_label", "=", "target", ".", "max", "(", "1", ")", "[", "1", "]", ".", "numpy", "(", ")", "# [B, 1]", "\n", "result", "=", "self", ".", "class_map", "[", "int_label", "]", "\n", "return", "torch", ".", "from_numpy", "(", "result", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.save_model": [[58, 67], ["torch.save", "torch.save", "torch.save", "torch.save", "met-har.reptile_meta.model.state_dict"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "filename", ")", ":", "\n", "        ", "\"\"\" filename example: /path/checkpoint/model-100.t7\n            State dict contains: \"model\" key at least.\n        \"\"\"", "\n", "state", "=", "{", "\n", "\"model\"", ":", "self", ".", "model", ".", "state_dict", "(", ")", ",", "\n", "\"client\"", ":", "self", ".", "model_name", ",", "\n", "}", "\n", "torch", ".", "save", "(", "state", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.build_data_loader": [[68, 80], ["utils.dataloader_gen2", "utils.dataloader_gen2", "utils.dataloader_gen2", "torch.optim.lr_scheduler.StepLR", "torch.optim.lr_scheduler.StepLR"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen2", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen2", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.utils.dataloader_gen2"], ["", "def", "build_data_loader", "(", "self", ")", ":", "\n", "        ", "self", ".", "training_op", "[", "\"trainloader\"", "]", "=", "utils", ".", "dataloader_gen2", "(", "self", ".", "training_op", "[", "\"train_file\"", "]", ",", "\n", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", "*", "2", ",", "\n", "target", "=", "\"hot\"", ",", "\n", "train", "=", "True", ")", "\n", "self", ".", "training_op", "[", "\"adaptloader\"", "]", "=", "utils", ".", "dataloader_gen2", "(", "self", ".", "training_op", "[", "\"adapt_file\"", "]", ",", "\n", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", "*", "2", ",", "\n", "target", "=", "\"hot\"", ",", "\n", "train", "=", "True", ")", "\n", "self", ".", "training_op", "[", "\"testloader\"", "]", "=", "utils", ".", "dataloader_gen2", "(", "self", ".", "training_op", "[", "\"test_file\"", "]", ",", "1", ",", "target", "=", "\"hot\"", ",", "\n", "train", "=", "False", ")", "\n", "self", ".", "training_op", "[", "\"scheduler\"", "]", "=", "StepLR", "(", "self", ".", "training_op", "[", "\"embed_optimizer\"", "]", ",", "step_size", "=", "2", ",", "gamma", "=", "0.85", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.set_train_test_file": [[81, 86], ["[].split", "[].split"], "methods", ["None"], ["", "def", "set_train_test_file", "(", "self", ",", "train", ",", "test", ",", "adapt", ")", ":", "\n", "        ", "self", ".", "training_op", "[", "\"train_file\"", "]", "=", "train", "\n", "self", ".", "training_op", "[", "\"test_file\"", "]", "=", "test", "\n", "self", ".", "training_op", "[", "\"adapt_file\"", "]", "=", "adapt", "\n", "self", ".", "user_id", "=", "self", ".", "training_op", "[", "\"train_file\"", "]", "[", "0", "]", ".", "split", "(", "os", ".", "sep", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "+", "\"_act\"", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights": [[87, 89], ["met-har.reptile_meta.model.state_dict"], "methods", ["None"], ["", "def", "get_model_weights", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "model", ".", "state_dict", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights": [[90, 92], ["met-har.reptile_meta.model.load_state_dict"], "methods", ["None"], ["", "def", "assign_new_weights", "(", "self", ",", "weights_dict", ")", ":", "\n", "        ", "self", ".", "model", ".", "load_state_dict", "(", "weights_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train": [[93, 113], ["range", "met-har.reptile_meta.model.train", "enumerate", "met-har.reptile_meta.training_op[].step", "met-har.reptile_meta.training_op[].zero_grad", "loss.backward", "met-har.reptile_meta.training_op[].step", "loss.item", "inputs.to", "targets.to", "met-har.reptile_meta.model", "met-har.reptile_meta.model", "inputs.unsqueeze().type", "inputs.unsqueeze().type", "inputs.unsqueeze", "inputs.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "def", "train", "(", "self", ",", "num_epoch", ")", ":", "\n", "# print(\"=== train on: %s\" % self.training_op[\"train_file\"])", "\n", "        ", "for", "epoch", "in", "range", "(", "2", "*", "num_epoch", ")", ":", "\n", "            ", "self", ".", "model", ".", "train", "(", ")", "\n", "train_loss", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ",", "_", ")", "in", "enumerate", "(", "self", ".", "training_op", "[", "\"trainloader\"", "]", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "training_op", "[", "\"embed_optimizer\"", "]", ".", "zero_grad", "(", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "embeddings", ",", "targets", ",", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ")", "\n", "", "else", ":", "\n", "                    ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "embeddings", ",", "targets", ",", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", ")", "\n", "# back propogation", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "training_op", "[", "\"embed_optimizer\"", "]", ".", "step", "(", ")", "\n", "# loss and accuracy", "\n", "train_loss", "+=", "loss", ".", "item", "(", ")", "\n", "", "self", ".", "training_op", "[", "\"scheduler\"", "]", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test_2": [[114, 138], ["met-har.reptile_meta.merge_model.eval", "enumerate", "inputs.to.to.to", "targets_t.to.to.to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "met-har.reptile_meta.max", "targets.size", "predicted.eq().sum().item", "print", "met-har.reptile_meta.merge_model", "met-har.reptile_meta.merge_model", "inputs.to.to.unsqueeze().type", "inputs.to.to.unsqueeze().type", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "predicted.eq().sum", "inputs.to.to.unsqueeze", "inputs.to.to.unsqueeze", "predicted.eq", "[].numpy", "targets.max"], "methods", ["None"], ["", "", "def", "test_2", "(", "self", ",", "print_ind", "=", "False", ")", ":", "\n", "        ", "self", ".", "merge_model", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ",", "targets_t", ")", "in", "enumerate", "(", "self", ".", "training_op", "[", "\"testloader\"", "]", ")", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", ")", "\n", "targets_t", "=", "targets_t", ".", "to", "(", "device", ")", "\n", "# outputs = self.merge_model(inputs.unsqueeze(1).double())", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "outputs", "=", "self", ".", "merge_model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "", "else", ":", "\n", "                ", "outputs", "=", "self", ".", "merge_model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "# outputs = self.last_layer(embeddings)", "\n", "# _, target_cce = targets.max(1)", "\n", "", "target_cce", "=", "torch", ".", "from_numpy", "(", "all_trans_dict", "[", "self", ".", "user_id", "]", "[", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "numpy", "(", ")", "]", ")", ".", "to", "(", "device", ")", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "if", "print_ind", ":", "\n", "            ", "print", "(", "\"============Test loss: %.3f, Test acc: %.3f\"", "%", "(", "\n", "test_loss", "/", "(", "total", "+", "1", ")", ",", "100.0", "*", "correct", "/", "total", ")", ")", "\n", "# self.training_res[\"test_acc\"].append(100.0 * correct / total)", "\n", "", "return", "100.0", "*", "correct", "/", "total", ",", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test": [[139, 165], ["met-har.reptile_meta.model.eval", "met-har.reptile_meta.last_layer.eval", "enumerate", "inputs.to.to.to", "targets_t.to.to.to", "met-har.reptile_meta.last_layer", "met-har.reptile_meta.max", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "torch.from_numpy().to", "targets.size", "predicted.eq().sum().item", "print", "met-har.reptile_meta.model", "met-har.reptile_meta.model", "inputs.to.to.unsqueeze().type", "inputs.to.to.unsqueeze().type", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "predicted.eq().sum", "inputs.to.to.unsqueeze", "inputs.to.to.unsqueeze", "predicted.eq", "[].numpy", "targets.max"], "methods", ["None"], ["", "def", "test", "(", "self", ",", "print_ind", "=", "False", ")", ":", "\n", "# print(\"===test on: %s\" % self.training_op[\"test_file\"])", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "\n", "self", ".", "last_layer", ".", "eval", "(", ")", "\n", "test_loss", "=", "0", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ",", "targets_t", ")", "in", "enumerate", "(", "self", ".", "training_op", "[", "\"testloader\"", "]", ")", ":", "\n", "            ", "inputs", "=", "inputs", ".", "to", "(", "device", ")", "\n", "targets_t", "=", "targets_t", ".", "to", "(", "device", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "", "else", ":", "\n", "                ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "\n", "", "outputs", "=", "self", ".", "last_layer", "(", "embeddings", ")", "\n", "# _, target_cce = targets.max(1)", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "target_cce", "=", "torch", ".", "from_numpy", "(", "all_trans_dict", "[", "self", ".", "user_id", "]", "[", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "numpy", "(", ")", "]", ")", ".", "to", "(", "device", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "targets_t", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "", "if", "print_ind", ":", "\n", "            ", "print", "(", "\"============Test loss: %.3f, Test acc: %.3f\"", "%", "(", "\n", "test_loss", "/", "(", "total", "+", "1", ")", ",", "100.0", "*", "correct", "/", "total", ")", ")", "\n", "# self.training_res[\"test_acc\"].append(100.0 * correct / total)", "\n", "", "return", "100.0", "*", "correct", "/", "total", ",", "total", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.adapt": [[166, 212], ["met-har.reptile_meta.model.train", "enumerate", "met-har.reptile_meta.last_layer.train", "torch.Adam", "torch.Adam", "range", "met-har.reptile_meta.training_op[].zero_grad", "loss.backward", "met-har.reptile_meta.training_op[].step", "met-har.reptile_meta.last_layer.parameters", "enumerate", "inputs.to", "targets.to", "met-har.reptile_meta.model", "met-har.reptile_meta.model", "torch.Adam.zero_grad", "met-har.reptile_meta.detach", "met-har.reptile_meta.last_layer", "loss.backward", "torch.Adam.step", "inputs.unsqueeze().type", "int", "inputs.unsqueeze().type", "int", "inputs.to", "targets.to", "targets_t.to", "met-har.reptile_meta.model", "met-har.reptile_meta.model", "inputs.unsqueeze().type", "inputs.unsqueeze().type", "targets_t.type", "targets_t.type", "inputs.unsqueeze", "inputs.unsqueeze", "inputs.unsqueeze", "inputs.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "def", "adapt", "(", "self", ",", "num_batch", ",", "train", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        First Adapt embedding net, then fine-tune the last layer.\n        \"\"\"", "\n", "# Fine-tune the embedding net", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "train", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"trainloader\"", "]", "\n", "", "else", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"adaptloader\"", "]", "\n", "\n", "", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ",", "targets_t", ")", "in", "enumerate", "(", "adapt_loader", ")", ":", "\n", "            ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "training_op", "[", "\"embed_optimizer\"", "]", ".", "zero_grad", "(", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "embeddings", ",", "targets", ",", "int", "(", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", "/", "2", ")", ")", "\n", "", "else", ":", "\n", "                ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "embeddings", ",", "targets", ",", "int", "(", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", "/", "2", ")", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "training_op", "[", "\"embed_optimizer\"", "]", ".", "step", "(", ")", "\n", "\n", "# Fine-tune last layer", "\n", "", "self", ".", "last_layer", ".", "train", "(", ")", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "last_opt", "=", "optim", ".", "Adam", "(", "self", ".", "last_layer", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "weight_decay", "=", "1e-4", ")", "\n", "for", "epoch", "in", "range", "(", "num_batch", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ",", "targets_t", ")", "in", "enumerate", "(", "adapt_loader", ")", ":", "\n", "                ", "inputs", ",", "targets", ",", "targets_t", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", ",", "targets_t", ".", "to", "(", "device", ")", "\n", "# self.training_op[\"last_optimizer\"].zero_grad()", "\n", "last_opt", ".", "zero_grad", "(", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "", "else", ":", "\n", "                    ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "", "embeddings", ".", "detach", "(", ")", "# TODO detach or not?", "\n", "outputs", "=", "self", ".", "last_layer", "(", "embeddings", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets_t", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets_t", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "last_opt", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.adapt_fixed": [[213, 248], ["met-har.reptile_meta.model.train", "met-har.reptile_meta.last_layer.train", "torch.Adam", "torch.Adam", "range", "met-har.reptile_meta.last_layer.parameters", "enumerate", "torch.Adam.zero_grad", "met-har.reptile_meta.model", "met-har.reptile_meta.detach", "met-har.reptile_meta.last_layer", "loss.backward", "torch.Adam.step", "met-har.reptile_meta.max", "targets.max", "targets.size", "predicted.eq().sum().item", "inputs.to", "targets.to", "inputs.unsqueeze().double", "[].type", "[].type", "predicted.eq().sum", "inputs.unsqueeze", "predicted.eq", "targets.max", "targets.max"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "", "", "def", "adapt_fixed", "(", "self", ",", "num_batch", ",", "train", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        First Adapt embedding net, then fine-tune the last layer.\n        \"\"\"", "\n", "# Fine-tune the embedding net", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "if", "train", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"trainloader\"", "]", "\n", "", "else", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"adaptloader\"", "]", "\n", "# Fine-tune last layer", "\n", "", "self", ".", "last_layer", ".", "train", "(", ")", "\n", "correct", "=", "0", "\n", "total", "=", "0", "\n", "last_opt", "=", "optim", ".", "Adam", "(", "self", ".", "last_layer", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "weight_decay", "=", "1e-4", ")", "\n", "for", "epoch", "in", "range", "(", "num_batch", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "adapt_loader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "# self.training_op[\"last_optimizer\"].zero_grad()", "\n", "last_opt", ".", "zero_grad", "(", ")", "\n", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "double", "(", ")", ")", "\n", "embeddings", ".", "detach", "(", ")", "\n", "# print(embeddings.size())", "\n", "outputs", "=", "self", ".", "last_layer", "(", "embeddings", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "last_opt", ".", "step", "(", ")", "\n", "# fine_tune acc", "\n", "_", ",", "predicted", "=", "outputs", ".", "max", "(", "1", ")", "\n", "_", ",", "target_cce", "=", "targets", ".", "max", "(", "1", ")", "\n", "total", "+=", "targets", ".", "size", "(", "0", ")", "\n", "correct", "+=", "predicted", ".", "eq", "(", "target_cce", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.asign_merge_model": [[249, 251], ["None"], "methods", ["None"], ["", "", "", "def", "asign_merge_model", "(", "self", ")", ":", "\n", "        ", "pass", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.adapt_merged": [[252, 282], ["met-har.reptile_meta.merge_model.train", "torch.Adam", "torch.Adam", "range", "met-har.reptile_meta.merge_model.parameters", "enumerate", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.Adam.zero_grad", "met-har.reptile_meta.merge_model", "loss.backward", "torch.Adam.step", "inputs.to", "torch.from_numpy.to", "torch.from_numpy.to", "inputs.unsqueeze().double", "torch.from_numpy.type", "torch.from_numpy.type", "torch.from_numpy.type", "torch.from_numpy.type", "[].numpy", "inputs.unsqueeze", "torch.from_numpy.max", "torch.from_numpy.max"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "def", "adapt_merged", "(", "self", ",", "num_batch", ",", "train", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        First Adapt embedding net, then fine-tune the last layer.\n        \"\"\"", "\n", "# Fine-tune the embedding net", "\n", "self", ".", "merge_model", ".", "train", "(", ")", "\n", "if", "train", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"trainloader\"", "]", "\n", "", "else", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"adaptloader\"", "]", "\n", "# Fine-tune last layer", "\n", "", "correct", "=", "0", "\n", "total", "=", "0", "\n", "last_opt", "=", "optim", ".", "Adam", "(", "self", ".", "merge_model", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "lr", ",", "weight_decay", "=", "1e-4", ")", "\n", "for", "epoch", "in", "range", "(", "num_batch", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ")", "in", "enumerate", "(", "adapt_loader", ")", ":", "\n", "                ", "targets", "=", "torch", ".", "from_numpy", "(", "all_trans_dict", "[", "self", ".", "user_id", "]", "[", "targets", ".", "max", "(", "1", ")", "[", "1", "]", ".", "numpy", "(", ")", "]", ")", "\n", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "# self.training_op[\"last_optimizer\"].zero_grad()", "\n", "last_opt", ".", "zero_grad", "(", ")", "\n", "outputs", "=", "self", ".", "merge_model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "double", "(", ")", ")", "\n", "# print(embeddings.size())", "\n", "# outputs = self.last_layer(embeddings)", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "# loss = self.training_op[\"loss_fun_last\"](outputs, targets.max(1)[1].type(torch.cuda.LongTensor))", "\n", "", "else", ":", "\n", "                    ", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "last_opt", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.adapt_merged_2": [[283, 328], ["met-har.reptile_meta.merge_model.train", "torch.Adam", "torch.Adam", "met-har.reptile_meta.model.train", "range", "range", "met-har.reptile_meta.merge_model.parameters", "enumerate", "enumerate", "met-har.reptile_meta.training_op[].zero_grad", "loss.backward", "met-har.reptile_meta.training_op[].step", "torch.Adam.zero_grad", "loss.backward", "torch.Adam.step", "inputs.to", "targets.to", "met-har.reptile_meta.model", "met-har.reptile_meta.model", "inputs.to", "targets.to", "targets_t.to", "met-har.reptile_meta.merge_model", "met-har.reptile_meta.merge_model", "inputs.unsqueeze().type", "int", "inputs.unsqueeze().type", "int", "inputs.unsqueeze().type", "targets_t.type", "inputs.unsqueeze().type", "targets_t.type", "inputs.unsqueeze", "inputs.unsqueeze", "inputs.unsqueeze", "inputs.unsqueeze"], "methods", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train"], ["", "", "", "def", "adapt_merged_2", "(", "self", ",", "num_batch", ",", "train", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        First Adapt embedding net, then fine-tune the last layer.\n        \"\"\"", "\n", "# Fine-tune the embedding net", "\n", "self", ".", "merge_model", ".", "train", "(", ")", "\n", "if", "train", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"trainloader\"", "]", "\n", "", "else", ":", "\n", "            ", "adapt_loader", "=", "self", ".", "training_op", "[", "\"adaptloader\"", "]", "\n", "# Fine-tune last layer", "\n", "", "correct", "=", "0", "\n", "total", "=", "0", "\n", "last_opt", "=", "optim", ".", "Adam", "(", "self", ".", "merge_model", ".", "parameters", "(", ")", ",", "lr", "=", "utils", ".", "parameter", "[", "\"lr\"", "]", ",", "weight_decay", "=", "1e-4", ")", "\n", "self", ".", "model", ".", "train", "(", ")", "\n", "for", "embed_epoch", "in", "range", "(", "10", "*", "num_batch", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ",", "_", ")", "in", "enumerate", "(", "adapt_loader", ")", ":", "\n", "                ", "inputs", ",", "targets", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", "\n", "self", ".", "training_op", "[", "\"embed_optimizer\"", "]", ".", "zero_grad", "(", ")", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "embeddings", ",", "targets", ",", "int", "(", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", "/", "2", ")", ")", "\n", "", "else", ":", "\n", "                    ", "embeddings", "=", "self", ".", "model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun\"", "]", "(", "embeddings", ",", "targets", ",", "int", "(", "utils", ".", "parameter", "[", "\"BATCH_SIZE\"", "]", "/", "2", ")", ")", "\n", "\n", "", "loss", ".", "backward", "(", ")", "\n", "self", ".", "training_op", "[", "\"embed_optimizer\"", "]", ".", "step", "(", ")", "\n", "\n", "", "", "for", "epoch", "in", "range", "(", "num_batch", "*", "10", ")", ":", "\n", "            ", "for", "batch_idx", ",", "(", "inputs", ",", "targets", ",", "targets_t", ")", "in", "enumerate", "(", "adapt_loader", ")", ":", "\n", "# targets = torch.from_numpy(all_trans_dict[self.user_id][targets.max(1)[1].numpy()])", "\n", "                ", "inputs", ",", "targets", ",", "targets_t", "=", "inputs", ".", "to", "(", "device", ")", ",", "targets", ".", "to", "(", "device", ")", ",", "targets_t", ".", "to", "(", "device", ")", "\n", "# self.training_op[\"last_optimizer\"].zero_grad()", "\n", "last_opt", ".", "zero_grad", "(", ")", "\n", "\n", "if", "device", "==", "\"cuda\"", ":", "\n", "                    ", "outputs", "=", "self", ".", "merge_model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "cuda", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets_t", ".", "type", "(", "torch", ".", "cuda", ".", "LongTensor", ")", ")", "\n", "# targets.max(1)[1].type(torch.cuda.LongTensor)", "\n", "", "else", ":", "\n", "                    ", "outputs", "=", "self", ".", "merge_model", "(", "inputs", ".", "unsqueeze", "(", "1", ")", ".", "type", "(", "torch", ".", "FloatTensor", ")", ")", "\n", "loss", "=", "self", ".", "training_op", "[", "\"loss_fun_last\"", "]", "(", "outputs", ",", "targets_t", ".", "type", "(", "torch", ".", "LongTensor", ")", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "last_opt", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.update_server_weights": [[330, 343], ["copy.deepcopy", "w.keys", "range", "len", "torch.mul", "torch.mul", "torch.div().sub", "torch.div().sub", "torch.div", "torch.div", "len"], "function", ["None"], ["", "", "", "", "def", "update_server_weights", "(", "w_list", ",", "w", ",", "sigma", "=", "0.2", ")", ":", "\n", "    ", "\"\"\"\n    model 1 and model 2 with same structure\n    return weights dict with values w_model1 - w_model2\n\n    sigma = 1 : federated learning\n    \"\"\"", "\n", "w_avg", "=", "copy", ".", "deepcopy", "(", "w_list", "[", "0", "]", ")", "\n", "for", "k", "in", "w", ".", "keys", "(", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "w_list", ")", ")", ":", "\n", "            ", "w_avg", "[", "k", "]", "+=", "w_list", "[", "idx", "]", "[", "k", "]", "\n", "", "w_avg", "[", "k", "]", "=", "w", "[", "k", "]", "+", "torch", ".", "mul", "(", "(", "torch", ".", "div", "(", "w_avg", "[", "k", "]", ",", "len", "(", "w_list", ")", ")", ".", "sub", "(", "w", "[", "k", "]", ")", ")", ",", "sigma", ")", "\n", "", "return", "w_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.update_server_weights_weighted": [[345, 401], ["w.keys", "enumerate", "torch.cat", "torch.cat", "range", "range", "range", "numpy.sum", "copy.deepcopy", "w.keys", "w.keys", "w_param.append", "len", "weights_flattened.append", "len", "len", "weights.append", "weights_norm.append", "range", "used_keys.append", "torch.flatten", "torch.flatten", "model_params.append", "torch.cat", "torch.cat", "l2.append", "cosine_dis.append", "l2.append", "cosine_dis.append", "len", "torch.mul", "torch.mul", "torch.flatten", "torch.flatten", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.squeeze", "numpy.abs", "w_avg[].sub", "torch.dist().numpy", "torch.dist().numpy", "cosine_similarity().numpy", "torch.dist().cpu().numpy", "torch.dist().cpu().numpy", "cosine_similarity().cpu().numpy", "torch.dist", "torch.dist", "cosine_similarity", "torch.dist().cpu", "torch.dist().cpu", "cosine_similarity().cpu", "weights_flattened[].unsqueeze", "torch.cat.unsqueeze", "torch.dist", "torch.dist", "cosine_similarity", "weights_flattened[].unsqueeze", "torch.cat.unsqueeze"], "function", ["None"], ["", "def", "update_server_weights_weighted", "(", "w_list", ",", "w", ",", "sigma", "=", "0.2", ")", ":", "# TO BE DONE", "\n", "# weights:", "\n", "# flatten all model weights", "\n", "    ", "weights_flattened", "=", "[", "]", "\n", "keys", "=", "w", ".", "keys", "(", ")", "\n", "used_keys", "=", "[", "]", "\n", "for", "ind", ",", "key", "in", "enumerate", "(", "keys", ")", ":", "\n", "        ", "if", "\"batches_tracked\"", "not", "in", "key", ":", "\n", "            ", "used_keys", ".", "append", "(", "key", ")", "\n", "# flatten w", "\n", "", "", "w_param", "=", "[", "]", "\n", "for", "key", "in", "used_keys", ":", "\n", "        ", "w_param", ".", "append", "(", "torch", ".", "flatten", "(", "w", "[", "key", "]", ")", ")", "\n", "", "w_flatten", "=", "torch", ".", "cat", "(", "w_param", ",", "dim", "=", "0", ")", "\n", "# print(w_flatten.size())", "\n", "# flatten w_list", "\n", "for", "idx", "in", "range", "(", "len", "(", "w_list", ")", ")", ":", "\n", "        ", "model_params", "=", "[", "]", "\n", "for", "key", "in", "used_keys", ":", "\n", "            ", "model_params", ".", "append", "(", "torch", ".", "flatten", "(", "w_list", "[", "idx", "]", "[", "key", "]", ")", ")", "\n", "", "weights_flattened", ".", "append", "(", "torch", ".", "cat", "(", "model_params", ",", "dim", "=", "0", ")", ")", "\n", "# calculate l2 norm", "\n", "", "l2", "=", "[", "]", "\n", "cosine_dis", "=", "[", "]", "\n", "for", "idx", "in", "range", "(", "len", "(", "w_list", ")", ")", ":", "\n", "        ", "if", "device", "==", "\"cpu\"", ":", "\n", "            ", "l2", ".", "append", "(", "np", ".", "squeeze", "(", "torch", ".", "dist", "(", "weights_flattened", "[", "idx", "]", ",", "w_flatten", ")", ".", "numpy", "(", ")", ")", ")", "\n", "cosine_dis", ".", "append", "(", "np", ".", "squeeze", "(", "\n", "cosine_similarity", "(", "weights_flattened", "[", "idx", "]", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "w_flatten", ".", "unsqueeze", "(", "dim", "=", "0", ")", ")", ".", "numpy", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "l2", ".", "append", "(", "np", ".", "squeeze", "(", "torch", ".", "dist", "(", "weights_flattened", "[", "idx", "]", ",", "w_flatten", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "cosine_dis", ".", "append", "(", "np", ".", "squeeze", "(", "\n", "cosine_similarity", "(", "weights_flattened", "[", "idx", "]", ".", "unsqueeze", "(", "dim", "=", "0", ")", ",", "w_flatten", ".", "unsqueeze", "(", "dim", "=", "0", ")", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ")", ")", "\n", "", "", "weights", "=", "[", "]", "\n", "for", "index", "in", "range", "(", "len", "(", "w_list", ")", ")", ":", "\n", "# weights.append(np.sqrt(l2[index] ** 2 + cosine_dis[index] ** 2))", "\n", "        ", "weights", ".", "append", "(", "l2", "[", "index", "]", "*", "np", ".", "abs", "(", "cosine_dis", "[", "index", "]", ")", ")", "\n", "# normalize weights", "\n", "", "weights_norm", "=", "[", "]", "\n", "total", "=", "np", ".", "sum", "(", "weights", ")", "\n", "for", "val", "in", "weights", ":", "\n", "        ", "weights_norm", ".", "append", "(", "val", "/", "total", ")", "\n", "###################", "\n", "# print(weights_norm)", "\n", "# sys.exit()", "\n", "###################", "\n", "# weighted average", "\n", "", "w_avg", "=", "copy", ".", "deepcopy", "(", "w_list", "[", "0", "]", ")", "\n", "for", "k", "in", "w", ".", "keys", "(", ")", ":", "\n", "        ", "w_avg", "[", "k", "]", "=", "w_avg", "[", "k", "]", "*", "weights_norm", "[", "0", "]", "\n", "", "for", "k", "in", "w", ".", "keys", "(", ")", ":", "\n", "        ", "for", "idx", "in", "range", "(", "1", ",", "len", "(", "w_list", ")", ")", ":", "\n", "            ", "w_avg", "[", "k", "]", "+=", "w_list", "[", "idx", "]", "[", "k", "]", "*", "weights_norm", "[", "idx", "]", "\n", "", "w_avg", "[", "k", "]", "=", "w", "[", "k", "]", "+", "torch", ".", "mul", "(", "w_avg", "[", "k", "]", ".", "sub", "(", "w", "[", "k", "]", ")", ",", "sigma", ")", "\n", "\n", "", "return", "w_avg", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.main": [[403, 539], ["all_trans_dict.keys", "random.Random().shuffle", "random.Random().shuffle", "range", "range", "met-har.reptile_meta", "range", "os.path.join", "os.path.join", "utils.save_pickle", "utils.save_pickle", "numpy.sum", "os.path.join", "os.path.join", "len", "client_models.append", "client_models[].set_train_test_file", "client_models[].build_data_loader", "leave_out_modules.append", "leave_out_modules[].set_train_test_file", "leave_out_modules[].build_data_loader", "utils.pairwiseloss", "numpy.random.choice", "print", "met-har.reptile_meta.assign_new_weights", "str", "os.listdir", "os.listdir", "random.Random", "random.Random", "[].split", "met-har.reptile_meta", "[].split", "met-har.reptile_meta", "len", "print", "client_models[].assign_new_weights", "client_models[].train", "updated_weights.append", "met-har.update_server_weights", "print", "print", "os.path.join", "os.path.join", "utils.save_pickle", "utils.save_pickle", "utils.pairwiseloss", "utils.pairwiseloss", "met-har.reptile_meta.get_model_weights", "client_models[].get_model_weights", "met-har.reptile_meta.get_model_weights", "range", "fed_test_result[].append", "range", "leave_test_result[].append", "len", "client_models[].assign_new_weights", "client_models[].adapt_merged_2", "client_models[].test", "adapt_acc.append", "weights.append", "numpy.average", "leave_out_modules[].assign_new_weights", "leave_out_modules[].adapt_merged_2", "leave_out_modules[].test", "adapt_acc.append", "weights.append", "numpy.average", "train_users_train[].split", "test_users_train[].split", "met-har.reptile_meta.get_model_weights", "met-har.reptile_meta.get_model_weights"], "function", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.set_train_test_file", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.build_data_loader", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.set_train_test_file", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.build_data_loader", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.train", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.update_server_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.adapt_merged_2", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.assign_new_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.adapt_merged_2", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.test", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.None.met-har.reptile_meta.get_model_weights"], ["", "def", "main", "(", "rounds", ",", "data_dir", ",", "out_dir", ",", "lr", "=", "0.001", ",", "local_e", "=", "1", ",", "leave_out", "=", "None", ",", "sigma", "=", "0.1", ",", "all_trans_dict", "=", "None", ")", ":", "\n", "    ", "\"\"\"\n    :param rounds: global rounds for federated learning: type: float\n    :param out_dir: output result dir: type: string\n    :param lr: initial learning rate: type float\n    :param local_e: local update epochs for federated learning: type: int\n    :param leave_out: leave out user index: 0-8 type: int\n    :param sigma: w_new = w + sigma* (avg_updated_w - w): sigma: float 0-1\n    :return: None\n    Save test acc result in output dir:\n        1. model acc on leave out user: before and after adapt\n        2. model acc on fed users: before and after adapt\n    \"\"\"", "\n", "if", "leave_out", "is", "None", ":", "\n", "        ", "leave_out", "=", "[", "0", "]", "\n", "\n", "# all_act_num = utils.load_pickle(\"/data/ceph/seqrec/fl_data/www21/source/num_act_user_all.pickle\")", "\n", "", "all_act_num", "=", "{", "}", "\n", "for", "user", "in", "all_trans_dict", ".", "keys", "(", ")", ":", "\n", "        ", "all_act_num", "[", "user", "]", "=", "np", ".", "sum", "(", "all_trans_dict", "[", "user", "]", "!=", "-", "1", ")", "# number of local activities of `user'", "\n", "# the number of local act for each users.", "\n", "\n", "", "all_train", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file", ")", "for", "file", "in", "os", ".", "listdir", "(", "data_dir", ")", "if", "\"train\"", "in", "file", "]", "\n", "all_test", "=", "[", "os", ".", "path", ".", "join", "(", "data_dir", ",", "file", ")", "for", "file", "in", "os", ".", "listdir", "(", "data_dir", ")", "if", "'test'", "in", "file", "]", "\n", "random", ".", "Random", "(", "0", ")", ".", "shuffle", "(", "all_train", ")", "\n", "random", ".", "Random", "(", "0", ")", ".", "shuffle", "(", "all_test", ")", "\n", "\n", "# 5 leave out for meta testing", "\n", "train_users_train", "=", "all_train", "[", "0", ":", "-", "5", "]", "\n", "train_user_test", "=", "all_test", "[", "0", ":", "-", "5", "]", "\n", "test_users_train", "=", "all_train", "[", "-", "5", ":", "]", "\n", "test_user_test", "=", "all_test", "[", "-", "5", ":", "]", "\n", "\n", "# Meta-train users", "\n", "client_models", "=", "[", "]", "\n", "for", "ind", "in", "range", "(", "len", "(", "train_users_train", ")", ")", ":", "\n", "        ", "file_name", "=", "train_users_train", "[", "ind", "]", ".", "split", "(", "os", ".", "sep", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "client_models", ".", "append", "(", "\n", "reptile_meta", "(", "har_model", ".", "norm_embed", ",", "lr", ",", "device", ",", "utils", ".", "pairwiseloss", "(", ")", ",", "100", ",", "all_act_num", "[", "file_name", "]", ")", ")", "\n", "client_train_file", "=", "[", "train_users_train", "[", "ind", "]", "]", "\n", "client_test_file", "=", "[", "train_user_test", "[", "ind", "]", "]", "\n", "client_adapt_file", "=", "client_train_file", "\n", "\n", "client_models", "[", "-", "1", "]", ".", "set_train_test_file", "(", "client_train_file", ",", "client_test_file", ",", "client_adapt_file", ")", "\n", "client_models", "[", "-", "1", "]", ".", "build_data_loader", "(", ")", "\n", "\n", "# Meta-test users", "\n", "# Note: By replacing `norm_embed' with the `norm_cce' and removing the local fine-tune we get the reptile method.", "\n", "", "leave_out_modules", "=", "[", "]", "\n", "for", "ind", "in", "range", "(", "5", ")", ":", "\n", "        ", "file_name", "=", "test_users_train", "[", "ind", "]", ".", "split", "(", "os", ".", "sep", ")", "[", "-", "1", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "leave_out_modules", ".", "append", "(", "\n", "reptile_meta", "(", "har_model", ".", "norm_embed", ",", "lr", ",", "device", ",", "utils", ".", "pairwiseloss", "(", ")", ",", "100", ",", "all_act_num", "[", "file_name", "]", ")", ")", "\n", "leave_train", "=", "[", "test_users_train", "[", "ind", "]", "]", "\n", "leave_test", "=", "[", "test_user_test", "[", "ind", "]", "]", "\n", "leave_adapt_file", "=", "leave_train", "\n", "leave_out_modules", "[", "-", "1", "]", ".", "set_train_test_file", "(", "leave_train", ",", "leave_test", ",", "leave_adapt_file", ")", "\n", "leave_out_modules", "[", "-", "1", "]", ".", "build_data_loader", "(", ")", "\n", "\n", "# server model", "\n", "", "server_model", "=", "reptile_meta", "(", "har_model", ".", "norm_embed", ",", "lr", ",", "device", ",", "utils", ".", "pairwiseloss", "(", ")", ",", "100", ",", "7", ")", "\n", "# there are totally 7 activities in global act set.", "\n", "# server_model result dir", "\n", "fed_test_result", "=", "{", "\"before\"", ":", "[", "]", "}", "# result before fine-tune", "\n", "leave_test_result", "=", "{", "\"before\"", ":", "[", "]", "}", "\n", "init_after", "=", "0", "\n", "for", "val", "in", "[", "1", ",", "1", ",", "1", "]", ":", "# result after x steps of local fine-tune", "\n", "        ", "fed_test_result", "[", "\"tune_%d\"", "%", "(", "init_after", "+", "val", ")", "]", "=", "[", "]", "\n", "leave_test_result", "[", "\"tune_%d\"", "%", "(", "init_after", "+", "val", ")", "]", "=", "[", "]", "\n", "init_after", "+=", "val", "\n", "\n", "", "for", "i", "in", "range", "(", "rounds", ")", ":", "# global rounds", "\n", "# sampling tasks/ here is the users", "\n", "        ", "chosen_client", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "train_users_train", ")", ",", "5", ",", "replace", "=", "False", ")", "\n", "updated_weights", "=", "[", "]", "\n", "for", "user_idx", "in", "chosen_client", ":", "\n", "# pull weights theta from center", "\n", "###############################", "\n", "# print(server_model.get_model_weights().keys())", "\n", "# sys.exit()", "\n", "###############################", "\n", "            ", "print", "(", "\"      -- Start local training on user:  \"", ",", "train_users_train", "[", "user_idx", "]", ")", "\n", "client_models", "[", "user_idx", "]", ".", "assign_new_weights", "(", "server_model", ".", "get_model_weights", "(", ")", ")", "\n", "# local train", "\n", "client_models", "[", "user_idx", "]", ".", "train", "(", "num_epoch", "=", "local_e", ")", "\n", "# get updated para difference.", "\n", "updated_weights", ".", "append", "(", "client_models", "[", "user_idx", "]", ".", "get_model_weights", "(", ")", ")", "\n", "# print(\"done local train on user: %s\" % train_users[user_idx])", "\n", "\n", "", "print", "(", "\"# update global meta model ========\"", ")", "\n", "server_model", ".", "assign_new_weights", "(", "\n", "update_server_weights", "(", "updated_weights", ",", "server_model", ".", "get_model_weights", "(", ")", ",", "sigma", "=", "sigma", ")", ")", "\n", "\n", "if", "i", ">", "70", "and", "i", "%", "2", "==", "0", ":", "\n", "            ", "print", "(", "\"# ====== Testing ===========\"", ")", "\n", "adapt_val", "=", "0", "\n", "for", "val", "in", "[", "1", ",", "1", ",", "1", "]", ":", "\n", "                ", "adapt_acc", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "user_idx", "in", "range", "(", "len", "(", "train_users_train", ")", ")", ":", "\n", "                    ", "client_models", "[", "user_idx", "]", ".", "assign_new_weights", "(", "server_model", ".", "get_model_weights", "(", ")", ")", "\n", "client_models", "[", "user_idx", "]", ".", "adapt_merged_2", "(", "num_batch", "=", "val", "+", "adapt_val", ",", "train", "=", "False", ")", "\n", "acc", ",", "num", "=", "client_models", "[", "user_idx", "]", ".", "test", "(", ")", "\n", "adapt_acc", ".", "append", "(", "acc", ")", "\n", "weights", ".", "append", "(", "num", ")", "\n", "\n", "", "adapt_val", "+=", "val", "\n", "fed_test_result", "[", "\"tune_%d\"", "%", "adapt_val", "]", ".", "append", "(", "np", ".", "average", "(", "adapt_acc", ",", "weights", "=", "weights", ")", ")", "\n", "\n", "# Meta-test users", "\n", "", "print", "(", "\"# Testing meta-test user ===========\"", ")", "\n", "adapt_val", "=", "0", "\n", "for", "val", "in", "[", "1", ",", "1", ",", "1", "]", ":", "\n", "                ", "adapt_acc", "=", "[", "]", "\n", "weights", "=", "[", "]", "\n", "for", "j", "in", "range", "(", "5", ")", ":", "\n", "                    ", "leave_out_modules", "[", "j", "]", ".", "assign_new_weights", "(", "server_model", ".", "get_model_weights", "(", ")", ")", "\n", "leave_out_modules", "[", "j", "]", ".", "adapt_merged_2", "(", "num_batch", "=", "val", "+", "adapt_val", ",", "train", "=", "False", ")", "\n", "acc", ",", "num", "=", "leave_out_modules", "[", "j", "]", ".", "test", "(", ")", "\n", "adapt_acc", ".", "append", "(", "acc", ")", "\n", "weights", ".", "append", "(", "num", ")", "\n", "", "adapt_val", "+=", "val", "\n", "leave_test_result", "[", "\"tune_%d\"", "%", "adapt_val", "]", ".", "append", "(", "np", ".", "average", "(", "adapt_acc", ",", "weights", "=", "weights", ")", ")", "\n", "", "fed_test_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"metahar_train_b2.pickle\"", ")", "\n", "leave_test_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"metahar_test_b2.pcikle\"", ")", "\n", "utils", ".", "save_pickle", "(", "fed_test_result", ",", "fed_test_file", ")", "\n", "utils", ".", "save_pickle", "(", "leave_test_result", ",", "leave_test_file", ")", "\n", "\n", "# save test results\tlocal_sigma_tmp_leave", "\n", "", "", "leave_str", "=", "\"\"", "\n", "for", "val", "in", "leave_out", ":", "\n", "        ", "leave_str", "+=", "str", "(", "val", ")", "\n", "", "fed_test_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"metahar_train_b2.pickle\"", ")", "# meta-train users", "\n", "leave_test_file", "=", "os", ".", "path", ".", "join", "(", "out_dir", ",", "\"metahar_test_b2.pcikle\"", ")", "# meta-test users", "\n", "utils", ".", "save_pickle", "(", "fed_test_result", ",", "fed_test_file", ")", "\n", "utils", ".", "save_pickle", "(", "leave_test_result", ",", "leave_test_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.load_pickle": [[18, 22], ["_pickle.load", "print", "open"], "function", ["None"], ["def", "load_pickle", "(", "filename", ",", "show_name", "=", "False", ")", ":", "\n", "    ", "if", "show_name", ":", "\n", "        ", "print", "(", "filename", ")", "\n", "", "return", "pickle", ".", "load", "(", "open", "(", "filename", ",", "\"rb\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle": [[24, 27], ["open", "_pickle.dump"], "function", ["None"], ["", "def", "save_pickle", "(", "data_dict", ",", "filename", ")", ":", "\n", "    ", "with", "open", "(", "filename", ",", "\"wb\"", ")", "as", "myfile", ":", "\n", "        ", "pickle", ".", "dump", "(", "data_dict", ",", "myfile", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.axisData_split": [[29, 45], ["type", "len", "result.append"], "function", ["None"], ["", "", "def", "axisData_split", "(", "sensor_data", ",", "interval_len", ")", ":", "\n", "    ", "\"\"\"\n    split sensor data into small interval, for LSTM unit training\n    sensor_data: numpy.array with shape [seq_len, 8]\n    interval_len: int, the length of the resulting small interval\n    :return: list of numpy.array with shape [seq_len/interval_len, interval_len. 8]\n    \"\"\"", "\n", "assert", "type", "(", "interval_len", ")", "==", "int", "\n", "result", "=", "[", "]", "\n", "# print(len(sensor_data[0]) / tao)", "\n", "start", ",", "end", "=", "0", ",", "interval_len", "\n", "while", "end", "<=", "len", "(", "sensor_data", ")", ":", "\n", "        ", "result", ".", "append", "(", "sensor_data", "[", "start", ":", "end", "]", ")", "\n", "start", "=", "end", "\n", "end", "+=", "interval_len", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.dim_expansion": [[47, 65], ["numpy.zeros", "range", "range", "numpy.sqrt", "numpy.power", "numpy.power", "numpy.power"], "function", ["None"], ["", "def", "dim_expansion", "(", "data", ")", ":", "\n", "    ", "\"\"\"\n    add the fourth dim for the original\n    :param data: numpy.array ax, ay, az, mx, my, mz data with shape [interval_len, 6]\n    :return: numpy.array with shape [interval_len, 8]\n    \"\"\"", "\n", "data_new", "=", "np", ".", "zeros", "(", "(", "data", ".", "shape", "[", "0", "]", ",", "8", ")", ",", "dtype", "=", "float", ")", "\n", "for", "i", "in", "range", "(", "data", ".", "shape", "[", "0", "]", ")", ":", "\n", "        ", "original_axis_index", "=", "0", "\n", "for", "j", "in", "range", "(", "8", ")", ":", "\n", "            ", "if", "j", "!=", "3", "and", "j", "!=", "7", ":", "\n", "                ", "data_new", "[", "i", "]", "[", "j", "]", "=", "data", "[", "i", "]", "[", "original_axis_index", "]", "\n", "original_axis_index", "+=", "1", "\n", "", "else", ":", "\n", "                ", "data_new", "[", "i", "]", "[", "j", "]", "=", "np", ".", "sqrt", "(", "\n", "np", ".", "power", "(", "data_new", "[", "i", "]", "[", "j", "-", "1", "]", ",", "2", ")", "+", "np", ".", "power", "(", "data_new", "[", "i", "]", "[", "j", "-", "2", "]", ",", "2", ")", "+", "np", ".", "power", "(", "data_new", "[", "i", "]", "[", "j", "-", "3", "]", ",", "\n", "2", ")", ")", "\n", "", "", "", "return", "data_new", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.feature_extraction_dict": [[67, 98], ["feature_extraction.axisData_split", "numpy.array", "numpy.rollaxis", "feature_extraction.dim_expansion", "range", "sample_feature.append", "numpy.fft.fft", "numpy.sqrt", "numpy.array", "unit_feature.append", "unit_feature.append", "numpy.array", "numpy.power", "numpy.power", "int", "float", "range", "float", "len", "len", "int", "len"], "function", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.axisData_split", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.dim_expansion"], ["", "def", "feature_extraction_dict", "(", "data_np", ",", "dim", "=", "4", ",", "tao", "=", "0.5", ",", "freq", "=", "50", ")", ":", "\n", "    ", "\"\"\"Feature extraction for each data sample, FFT, frequency and magnitude\"\"\"", "\n", "if", "data_np", ".", "shape", "[", "0", "]", "<", "data_np", ".", "shape", "[", "1", "]", ":", "\n", "        ", "data_np", "=", "np", ".", "rollaxis", "(", "data_np", ",", "1", ",", "0", ")", "\n", "", "if", "dim", "==", "4", ":", "\n", "        ", "data_expand", "=", "dim_expansion", "(", "data_np", ")", "# calculate the amplitude", "\n", "", "else", ":", "\n", "        ", "data_expand", "=", "data_np", "\n", "\n", "# split according to time interval: e.g. tao = 0.5 seconds", "\n", "# small_interval_len = int(freq * tao)  # [lstm_len, interval_len, 8]", "\n", "# small_interval_len = int(freq * tao)", "\n", "\n", "# split with a fixed length of signal.", "\n", "", "small_interval_len", "=", "12", "\n", "axis_split_result", "=", "axisData_split", "(", "sensor_data", "=", "data_expand", ",", "interval_len", "=", "small_interval_len", ")", "\n", "# feature extraction                  # [lstm_len. interval_len/2, 16]", "\n", "sample_feature", "=", "[", "]", "\n", "for", "lstm_unit", "in", "axis_split_result", ":", "#", "\n", "        ", "unit_feature", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "lstm_unit", ".", "shape", "[", "-", "1", "]", ")", ":", "\n", "# fft_result = np.fft.fft(lstm_unit[:, i]) / len(lstm_unit)", "\n", "            ", "fft_result", "=", "np", ".", "fft", ".", "fft", "(", "lstm_unit", "[", ":", ",", "i", "]", ")", "\n", "amplitutde", "=", "np", ".", "sqrt", "(", "np", ".", "power", "(", "fft_result", ".", "real", ",", "2", ")", "+", "np", ".", "power", "(", "fft_result", ".", "imag", ",", "2", ")", ")", "\n", "amplitutde", "=", "amplitutde", "[", "0", ":", "int", "(", "len", "(", "lstm_unit", ")", "/", "2", ")", "+", "1", "]", "\n", "freq_val", "=", "np", ".", "array", "(", "[", "val", "*", "float", "(", "freq", ")", "/", "float", "(", "len", "(", "lstm_unit", ")", ")", "for", "val", "in", "\n", "range", "(", "int", "(", "len", "(", "lstm_unit", ")", "/", "2", ")", "+", "1", ")", "]", ")", "\n", "unit_feature", ".", "append", "(", "freq_val", ")", "\n", "unit_feature", ".", "append", "(", "amplitutde", ")", "\n", "", "sample_feature", ".", "append", "(", "np", ".", "array", "(", "unit_feature", ")", ")", "\n", "", "return", "np", ".", "array", "(", "sample_feature", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.action_encoding": [[100, 108], ["numpy.zeros", "len"], "function", ["None"], ["", "def", "action_encoding", "(", "act", ",", "one_hot", "=", "False", ")", ":", "\n", "    ", "act_int", "=", "action_dict", "[", "act", "]", "\n", "if", "one_hot", ":", "\n", "        ", "result", "=", "np", ".", "zeros", "(", "len", "(", "action_dict", ")", ",", "dtype", "=", "int", ")", "\n", "result", "[", "act_int", "]", "=", "1", "\n", "return", "result", "\n", "", "else", ":", "\n", "        ", "return", "act_int", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.data_process_sensor": [[110, 123], ["data_str.strip().split", "range", "numpy.array", "numpy.array", "numpy.array", "numpy.stack", "int", "np.array.append", "np.array.append", "np.array.append", "data_str.strip", "float", "float", "float", "len"], "function", ["None"], ["", "", "def", "data_process_sensor", "(", "data_str", ",", "length", "=", "150", ")", ":", "\n", "    ", "data_list", "=", "data_str", ".", "strip", "(", ")", ".", "split", "(", "\",\"", ")", "\n", "acc_x", "=", "[", "]", "\n", "acc_y", "=", "[", "]", "\n", "acc_z", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "int", "(", "len", "(", "data_list", ")", "/", "3", ")", ")", ":", "\n", "        ", "acc_x", ".", "append", "(", "float", "(", "data_list", "[", "i", "*", "3", "]", ")", ")", "\n", "acc_y", ".", "append", "(", "float", "(", "data_list", "[", "i", "*", "3", "+", "1", "]", ")", ")", "\n", "acc_z", ".", "append", "(", "float", "(", "data_list", "[", "i", "*", "3", "+", "2", "]", ")", ")", "\n", "", "acc_x", "=", "np", ".", "array", "(", "acc_x", "[", "0", ":", "length", "]", ")", "\n", "acc_y", "=", "np", ".", "array", "(", "acc_y", "[", "0", ":", "length", "]", ")", "\n", "acc_z", "=", "np", ".", "array", "(", "acc_z", "[", "0", ":", "length", "]", ")", "\n", "return", "np", ".", "stack", "(", "[", "acc_x", ",", "acc_y", ",", "acc_z", "]", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.feature_extract": [[125, 166], ["feature_extraction.save_pickle", "print", "os.path.isdir", "os.mkdir", "set", "open", "list", "list.sort", "enumerate", "any", "feature_extraction.save_pickle", "os.listdir", "file.split", "os.path.join", "line.strip().split", "feature_extraction.action_encoding", "numpy.concatenate", "result[].append", "result[].append", "list.add", "numpy.ones", "print", "os.path.join", "feature_extraction.feature_extraction_dict", "numpy.array", "line.strip", "feature_extraction.data_process_sensor", "feature_extraction.data_process_sensor", "len", "len", "numpy.argmax", "acc.split", "gyro.split", "file.split"], "function", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.save_pickle", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.action_encoding", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.feature_extraction_dict", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.data_process_sensor", "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.data_process_sensor"], ["", "def", "feature_extract", "(", "in_dir", ",", "out_dir", ",", "one_hot", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Args:\n        in_dir: folder where the original txt data stores (format of the txt file can be found in readme)\n        out_dir: output .pickle files\n        one_hot: where to use one-hot encoding for the activity label\n    \"\"\"", "\n", "act_num", "=", "{", "}", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "", "files", "=", "[", "val", "for", "val", "in", "os", ".", "listdir", "(", "in_dir", ")", "if", "'txt'", "in", "val", "]", "\n", "for", "file", "in", "files", ":", "\n", "        ", "user", "=", "file", ".", "split", "(", "\"_\"", ")", "[", "0", "]", "\n", "result", "=", "{", "\"label\"", ":", "[", "]", ",", "\"feature\"", ":", "[", "]", ",", "\"label_t\"", ":", "[", "]", "}", "# result for all samples stored in this file", "\n", "local_act_sets", "=", "set", "(", ")", "\n", "data", "=", "open", "(", "os", ".", "path", ".", "join", "(", "in_dir", ",", "file", ")", ")", "\n", "for", "line", "in", "data", ":", "\n", "            ", "uid", ",", "act", ",", "acc", ",", "gyro", "=", "line", ".", "strip", "(", ")", ".", "split", "(", "\"\\t\"", ")", "\n", "# action", "\n", "act_enc", "=", "action_encoding", "(", "act", ",", "one_hot", "=", "one_hot", ")", "\n", "# sensor signal, [2 * 3, length] (length = 150)", "\n", "signal", "=", "np", ".", "concatenate", "(", "(", "data_process_sensor", "(", "acc", ")", ",", "data_process_sensor", "(", "gyro", ")", ")", ",", "axis", "=", "0", ")", "\n", "# frequency based on the 7 seconds of acc and gyro signals.", "\n", "acc_freq", "=", "(", "len", "(", "acc", ".", "split", "(", "\",\"", ")", ")", "+", "len", "(", "gyro", ".", "split", "(", "\",\"", ")", ")", ")", "/", "14.0", "# 7's", "\n", "# feature", "\n", "result", "[", "\"feature\"", "]", ".", "append", "(", "feature_extraction_dict", "(", "signal", ",", "dim", "=", "4", ",", "tao", "=", "0.5", ",", "freq", "=", "acc_freq", ")", ")", "# FFT", "\n", "result", "[", "\"label\"", "]", ".", "append", "(", "act_enc", ")", "\n", "local_act_sets", ".", "add", "(", "action_dict", "[", "act", "]", ")", "\n", "# get all local activities.", "\n", "", "user_local_label", "=", "np", ".", "ones", "(", "7", ")", "*", "-", "1", "\n", "local_act_sets", "=", "list", "(", "local_act_sets", ")", "\n", "local_act_sets", ".", "sort", "(", ")", "\n", "for", "ind", ",", "val", "in", "enumerate", "(", "local_act_sets", ")", ":", "\n", "            ", "user_local_label", "[", "val", "]", "=", "ind", "\n", "", "act_num", "[", "user", "]", "=", "user_local_label", "\n", "result", "[", "\"label_t\"", "]", "=", "user_local_label", "[", "np", ".", "array", "(", "np", ".", "argmax", "(", "result", "[", "\"label\"", "]", ",", "axis", "=", "1", ")", ")", "]", "\n", "if", "any", "(", "result", "[", "\"label_t\"", "]", "<", "0", ")", ":", "\n", "            ", "print", "(", "\"local label error.\"", ")", "\n", "", "save_pickle", "(", "result", ",", "os", ".", "path", ".", "join", "(", "out_dir", ",", "file", ".", "split", "(", "\".\"", ")", "[", "0", "]", "+", "\".pickle\"", ")", ")", "\n", "", "save_pickle", "(", "act_num", ",", "\"F:\\\\www21\\\\final_version\\\\Meta-HAR\\\\Data\\\\trans_dict_collect.pickle\"", ")", "\n", "print", "(", "\"Done !\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.main": [[185, 187], ["feature_extraction.feature_extract"], "function", ["home.repos.pwc.inspect_result.Chain123_Meta-HAR.data_process.feature_extraction.feature_extract"], ["", "def", "main", "(", "in_dir", ",", "out_dir", ")", ":", "\n", "    ", "feature_extract", "(", "in_dir", ",", "out_dir", ",", "one_hot", "=", "True", ")", "\n", "\n"]]}