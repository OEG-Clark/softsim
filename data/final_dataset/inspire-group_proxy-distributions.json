{"home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.eval.main": [[17, 125], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.get_metadata", "print", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "os.makedirs", "logging.basicConfig", "logging.getLogger", "logging.getLogger.addHandler", "logging.getLogger.info", "utils.get_model().cuda", "torch.load", "torch.load", "utils.fix_legacy_dict", "logging.getLogger.info", "torch.nn.parallel.DataParallel().eval.load_state_dict", "logging.getLogger.info", "logging.getLogger.info", "torch.nn.parallel.DataParallel().eval", "torch.nn.parallel.DataParallel().eval", "torch.CrossEntropyLoss().cuda", "data.get_real_dataloaders", "utils.evalfxn", "logging.getLogger.info", "os.path.join", "logging.FileHandler", "os.path.join", "utils.get_model", "torch.nn.parallel.DataParallel", "torch.nn.parallel.DataParallel", "torch.CrossEntropyLoss", "set", "set", "utils.evalfxn.items", "utils.fix_legacy_dict.keys", "torch.nn.parallel.DataParallel().eval.state_dict().keys", "torch.nn.parallel.DataParallel().eval.state_dict"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_metadata", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.fix_legacy_dict", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_real_dataloaders", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.evalfxn", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_model"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Evalution script\"", ")", "\n", "\n", "# common args", "\n", "parser", ".", "add_argument", "(", "\"--exp-name\"", ",", "type", "=", "str", ",", "default", "=", "\"temp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--checkpoint-path\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--results-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./trained_models/eval_logs/\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--val-method\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"pgd\"", ",", "\n", "choices", "=", "(", "\"baseline\"", ",", "\"pgd\"", ",", "\"auto\"", ")", ",", "\n", ")", "\n", "\n", "# data", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "(", "\"cifar10\"", ",", "\"cifar100\"", ",", "\"imagnet64\"", ",", "\"celebA\"", ",", "\"afhq\"", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--data-dir\"", ",", "type", "=", "str", ",", "help", "=", "\"dir where data is stored\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--workers\"", ",", "type", "=", "int", ",", "default", "=", "8", ")", "\n", "\n", "# model", "\n", "parser", ".", "add_argument", "(", "\"--arch\"", ",", "type", "=", "str", ")", "\n", "\n", "# adversarial attack", "\n", "parser", ".", "add_argument", "(", "\"--attack\"", ",", "type", "=", "str", ",", "choices", "=", "(", "\"linf\"", ",", "\"l2\"", ")", ",", "default", "=", "\"linf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epsilon\"", ",", "type", "=", "float", ",", "default", "=", "8.0", "/", "255", ")", "\n", "parser", ".", "add_argument", "(", "\"--step-size\"", ",", "type", "=", "float", ",", "default", "=", "2.0", "/", "255", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-steps\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "\"--clip-min\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--clip-max\"", ",", "type", "=", "float", ",", "default", "=", "1.0", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--autoattack-attack-subset\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"subset of attacks from autoattack default set of attacks (default uses all attacks)\"", ",", "\n", ")", "\n", "\n", "# misc", "\n", "parser", ".", "add_argument", "(", "\"--trial\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--print-freq\"", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "12345", ")", "\n", "\n", "######################### Basic setup #########################", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "metadata", "=", "get_metadata", "(", "args", ".", "dataset", ")", "\n", "args", ".", "gpu", ",", "args", ".", "rank", "=", "\"cuda:0\"", ",", "0", "# now its compatible with training utils", "\n", "print", "(", "args", ")", "\n", "\n", "# set up cuda + seeds", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "# a few percentage speedup", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "assert", "(", "\n", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", ")", ",", "\"we assume cuda is available, too slow to eval on cpus.\"", "\n", "assert", "args", ".", "checkpoint_path", ",", "\"Need a checkpoint to evaluate\"", "\n", "\n", "# recursively create all directories needed to log results", "\n", "args", ".", "log_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "results_dir", ",", "args", ".", "exp_name", ")", ",", "f\"trial_{args.trial}\"", "\n", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "log_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# logger", "\n", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ",", "format", "=", "\"%(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "addHandler", "(", "\n", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "args", ".", "log_dir", ",", "\"eval_log.txt\"", ")", ",", "\"a\"", ")", "\n", ")", "\n", "logger", ".", "info", "(", "args", ")", "\n", "\n", "model", "=", "get_model", "(", "args", ".", "arch", ",", "args", ".", "metadata", ".", "num_classes", ")", ".", "cuda", "(", ")", "\n", "\n", "# load checkpoint", "\n", "checkpoint", "=", "torch", ".", "load", "(", "args", ".", "checkpoint_path", ",", "map_location", "=", "\"cpu\"", ")", "\n", "d", "=", "fix_legacy_dict", "(", "checkpoint", "[", "\"state_dict\"", "]", ")", "\n", "logger", ".", "info", "(", "f\"Loaded state dict from {args.checkpoint_path}\"", ")", "\n", "model", ".", "load_state_dict", "(", "d", ",", "strict", "=", "True", ")", "\n", "logger", ".", "info", "(", "f\"Mismatched keys {set(d.keys()) ^ set(model.state_dict().keys())}\"", ")", "\n", "logger", ".", "info", "(", "f\"Checkpoint loaded from {args.checkpoint_path}\"", ")", "\n", "\n", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DataParallel", "(", "model", ")", ".", "eval", "(", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", ")", "\n", "\n", "_", ",", "val_loader", ",", "_", ",", "_", "=", "get_real_dataloaders", "(", "\n", "args", ".", "dataset", ",", "\n", "args", ".", "data_dir", ",", "\n", "args", ".", "batch_size", ",", "\n", "args", ".", "workers", ",", "\n", "args", ".", "metadata", ",", "\n", "distributed", "=", "False", ",", "\n", ")", "\n", "results_val", "=", "evalfxn", "(", "\n", "args", ".", "val_method", ",", "\n", "model", ",", "\n", "val_loader", ",", "\n", "criterion", ",", "\n", "args", ",", "\n", "args", ".", "metadata", ".", "num_classes", ",", "\n", ")", "\n", "logger", ".", "info", "(", "\n", "\", \"", ".", "join", "(", "\n", "[", "\"{}: {:.3f}\"", ".", "format", "(", "k", "+", "\"_val\"", ",", "v", ")", "for", "(", "k", ",", "v", ")", "in", "results_val", ".", "items", "(", ")", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.train.main": [[25, 179], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "utils.get_metadata", "torch.manual_seed", "torch.manual_seed", "torch.manual_seed", "numpy.random.seed", "torch.cuda.is_available", "torch.cuda.is_available", "torch.cuda.is_available", "os.path.join", "os.makedirs", "train.main_worker", "os.path.join", "warnings.warn", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "torch.distributed.init_process_group", "len", "len", "int", "int", "torch.cuda.device_count", "torch.cuda.device_count", "torch.cuda.device_count"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_metadata", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.train.main_worker"], ["def", "main", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\"Robust training with proxy distributions\"", ")", "\n", "\n", "# common args", "\n", "parser", ".", "add_argument", "(", "\"--exp-name\"", ",", "type", "=", "str", ",", "default", "=", "\"temp\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--results-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./trained_models/\"", ")", "\n", "\n", "# data", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dataset\"", ",", "\n", "type", "=", "str", ",", "\n", "choices", "=", "(", "\"cifar10\"", ",", "\"cifar100\"", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--data-dir\"", ",", "type", "=", "str", ",", "default", "=", "\"./datasets/\"", ",", "help", "=", "\"dir where data is stored\"", ")", "\n", "\n", "# synthetic data", "\n", "parser", ".", "add_argument", "(", "\n", "\"--syn-data-list\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "choices", "=", "(", "\"ddpm_cifar10\"", ",", "\"ddpm_cifar100\"", ")", ",", "\n", "help", "=", "\"list of all synthetic datasets to uses\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--syn-data-dir\"", ",", "\n", "nargs", "=", "\"+\"", ",", "\n", "help", "=", "\"individual dir where data is stored for each synthetic dataset\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--batch-size-syn\"", ",", "type", "=", "int", ",", "default", "=", "128", ",", "help", "=", "\"batch-size for synthetic data\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--gamma\"", ",", "type", "=", "float", ",", "default", "=", "0.5", ")", "\n", "\n", "# model", "\n", "parser", ".", "add_argument", "(", "\"--arch\"", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--sync-bn\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Synchronize batch-norm across all devices.\"", ",", "\n", ")", "\n", "\n", "# training details", "\n", "parser", ".", "add_argument", "(", "\"--lr\"", ",", "type", "=", "float", ",", "default", "=", "0.1", ")", "\n", "parser", ".", "add_argument", "(", "\"--momentum\"", ",", "type", "=", "float", ",", "default", "=", "0.9", ")", "\n", "parser", ".", "add_argument", "(", "\"--weight-decay\"", ",", "type", "=", "float", ",", "default", "=", "5e-4", ")", "\n", "parser", ".", "add_argument", "(", "\"--epochs\"", ",", "type", "=", "int", ",", "default", "=", "100", ")", "\n", "parser", ".", "add_argument", "(", "\"--batch-size\"", ",", "type", "=", "int", ",", "default", "=", "128", ")", "\n", "parser", ".", "add_argument", "(", "\"--workers\"", ",", "type", "=", "int", ",", "default", "=", "8", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--trainer\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"pgd\"", ",", "\n", "choices", "=", "(", "\"baseline\"", ",", "\"trades\"", ",", "\"pgd\"", ",", "\"fgsm\"", ")", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--val-method\"", ",", "\n", "type", "=", "str", ",", "\n", "default", "=", "\"pgd\"", ",", "\n", "choices", "=", "(", "\"baseline\"", ",", "\"pgd\"", ",", "\"auto\"", ")", ",", "\n", ")", "\n", "\n", "# adversarial attack", "\n", "parser", ".", "add_argument", "(", "\"--attack\"", ",", "type", "=", "str", ",", "choices", "=", "(", "\"linf\"", ",", "\"l2\"", ")", ",", "default", "=", "\"linf\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--epsilon\"", ",", "type", "=", "float", ",", "default", "=", "8.0", "/", "255", ")", "\n", "parser", ".", "add_argument", "(", "\"--step-size\"", ",", "type", "=", "float", ",", "default", "=", "2.0", "/", "255", ")", "\n", "parser", ".", "add_argument", "(", "\"--num-steps\"", ",", "type", "=", "int", ",", "default", "=", "10", ")", "\n", "parser", ".", "add_argument", "(", "\"--clip-min\"", ",", "type", "=", "float", ",", "default", "=", "0.0", ")", "\n", "parser", ".", "add_argument", "(", "\"--clip-max\"", ",", "type", "=", "float", ",", "default", "=", "1.0", ")", "\n", "\n", "# distributed training", "\n", "parser", ".", "add_argument", "(", "\n", "\"--rank\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"node rank for distributed training\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--local_rank\"", ",", "default", "=", "-", "1", ",", "type", "=", "int", ",", "help", "=", "\"local rank for distributed training\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--world-size\"", ",", "\n", "default", "=", "-", "1", ",", "\n", "type", "=", "int", ",", "\n", "help", "=", "\"number of nodes for distributed training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dist-url\"", ",", "\n", "default", "=", "\"env://\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"url used to set up distributed training\"", ",", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--dist-backend\"", ",", "default", "=", "\"nccl\"", ",", "type", "=", "str", ",", "help", "=", "\"distributed backend\"", "\n", ")", "\n", "parser", ".", "add_argument", "(", "\"--gpu\"", ",", "default", "=", "None", ",", "type", "=", "int", ",", "help", "=", "\"GPU id to use.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--no-dist\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "default", "=", "False", ",", "\n", "help", "=", "\"Don't use distributed training (E.g, set it to true for single-gpu)\"", ",", "\n", ")", "\n", "\n", "# misc", "\n", "parser", ".", "add_argument", "(", "\"--trial\"", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "\"--print-freq\"", ",", "type", "=", "int", ",", "default", "=", "50", ")", "\n", "parser", ".", "add_argument", "(", "\"--seed\"", ",", "type", "=", "int", ",", "default", "=", "12345", ")", "\n", "\n", "######################### Basic setup #########################", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "args", ".", "metadata", "=", "get_metadata", "(", "args", ".", "dataset", ")", "\n", "\n", "# set up cuda + seeds", "\n", "torch", ".", "backends", ".", "cudnn", ".", "benchmark", "=", "True", "# ~20% speedup", "\n", "torch", ".", "manual_seed", "(", "args", ".", "seed", ")", "\n", "np", ".", "random", ".", "seed", "(", "args", ".", "seed", ")", "\n", "assert", "(", "\n", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", ")", ",", "\"we assume cuda is available, too slow to train on cpus.\"", "\n", "if", "args", ".", "syn_data_list", "or", "args", ".", "syn_data_dir", ":", "\n", "        ", "assert", "len", "(", "args", ".", "syn_data_list", ")", "==", "len", "(", "args", ".", "syn_data_dir", ")", "\n", "\n", "# recursively create all directories needed to log results", "\n", "", "args", ".", "checkpoint_dir", "=", "os", ".", "path", ".", "join", "(", "\n", "os", ".", "path", ".", "join", "(", "args", ".", "results_dir", ",", "args", ".", "exp_name", ")", ",", "f\"trial_{args.trial}\"", "\n", ")", "\n", "os", ".", "makedirs", "(", "args", ".", "checkpoint_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "######################### Multiprocessing #########################", "\n", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "        ", "warnings", ".", "warn", "(", "\n", "\"You have chosen a specific GPU. This will completely \"", "\n", "\"disable data parallelism.\"", "\n", ")", "\n", "", "if", "args", ".", "dist_url", "==", "\"env://\"", "and", "args", ".", "world_size", "==", "-", "1", ":", "\n", "        ", "if", "args", ".", "no_dist", ":", "\n", "            ", "args", ".", "world_size", "=", "1", "\n", "", "else", ":", "\n", "            ", "args", ".", "world_size", "=", "int", "(", "os", ".", "environ", "[", "\"WORLD_SIZE\"", "]", ")", "\n", "", "", "args", ".", "multiprocessing_distributed", "=", "args", ".", "world_size", ">", "1", "\n", "\n", "if", "args", ".", "multiprocessing_distributed", ":", "\n", "        ", "if", "args", ".", "local_rank", "!=", "-", "1", ":", "# for torch.distributed.launch", "\n", "            ", "args", ".", "rank", "=", "args", ".", "local_rank", "\n", "args", ".", "gpu", "=", "args", ".", "local_rank", "\n", "", "elif", "\"SLURM_PROCID\"", "in", "os", ".", "environ", ":", "# for slurm scheduler", "\n", "            ", "args", ".", "rank", "=", "int", "(", "os", ".", "environ", "[", "\"SLURM_PROCID\"", "]", ")", "\n", "args", ".", "gpu", "=", "args", ".", "rank", "%", "torch", ".", "cuda", ".", "device_count", "(", ")", "\n", "\n", "", "torch", ".", "distributed", ".", "init_process_group", "(", "\n", "backend", "=", "args", ".", "dist_backend", ",", "\n", "init_method", "=", "args", ".", "dist_url", ",", "\n", "world_size", "=", "args", ".", "world_size", ",", "\n", "rank", "=", "args", ".", "rank", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "args", ".", "rank", "=", "0", "\n", "", "main_worker", "(", "args", ".", "gpu", ",", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.train.main_worker": [[181, 346], ["utils.get_model", "data.get_real_dataloaders", "torch.CrossEntropyLoss().cuda", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.SGD", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "torch.optim.lr_scheduler.CosineAnnealingLR", "range", "logging.basicConfig", "logging.getLogger", "logging.getLogger.addHandler", "logging.getLogger.info", "int", "int", "int", "torch.cuda.set_device", "torch.cuda.set_device", "torch.cuda.set_device", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.cuda", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.parallel.DistributedDataParallel", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "torch.nn.DataParallel().cuda", "logging.getLogger.info", "zip", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.parameters", "logging.getLogger.info", "utils.trainfxn", "utils.evalfxn", "logging.FileHandler", "print", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "torch.nn.SyncBatchNorm.convert_sync_batchnorm", "logging.getLogger.info", "data.get_synthetic_dataloaders", "samplers.append", "utils.combine_dataloaders", "logging.getLogger.info", "torch.CrossEntropyLoss", "len", "max", "utils.save_checkpoint", "logging.getLogger.info", "os.path.join", "torch.nn.DataParallel", "torch.nn.DataParallel", "torch.nn.DataParallel", "sam.set_epoch", "torch.nn.SyncBatchNorm.convert_sync_batchnorm.state_dict", "torch.optim.SGD.state_dict", "ValueError", "len", "len", "utils.trainfxn.items", "utils.evalfxn.items"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_model", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_real_dataloaders", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.trainfxn", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.evalfxn", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_synthetic_dataloaders", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.save_checkpoint"], ["", "def", "main_worker", "(", "gpu", ",", "args", ")", ":", "\n", "    ", "global", "best_prec", "\n", "args", ".", "gpu", "=", "gpu", "\n", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logging", ".", "basicConfig", "(", "level", "=", "logging", ".", "INFO", ",", "format", "=", "\"%(message)s\"", ")", "\n", "logger", "=", "logging", ".", "getLogger", "(", ")", "\n", "logger", ".", "addHandler", "(", "\n", "logging", ".", "FileHandler", "(", "os", ".", "path", ".", "join", "(", "args", ".", "checkpoint_dir", ",", "\"train_log.txt\"", ")", ",", "\"a\"", ")", "\n", ")", "\n", "logger", ".", "info", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "logger", "=", "None", "\n", "\n", "", "model", "=", "get_model", "(", "args", ".", "arch", ",", "args", ".", "metadata", ".", "num_classes", ")", "\n", "if", "args", ".", "gpu", "is", "not", "None", ":", "\n", "# Single GPU per process -> divide batch size based by number of GPUs", "\n", "        ", "args", ".", "batch_size", "=", "int", "(", "args", ".", "batch_size", "/", "args", ".", "world_size", ")", "\n", "args", ".", "batch_size_syn", "=", "int", "(", "args", ".", "batch_size_syn", "/", "args", ".", "world_size", ")", "\n", "args", ".", "workers", "=", "int", "(", "(", "args", ".", "workers", "+", "args", ".", "world_size", "-", "1", ")", "/", "args", ".", "world_size", ")", "\n", "\n", "torch", ".", "cuda", ".", "set_device", "(", "args", ".", "gpu", ")", "\n", "model", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "# batchnorm will use local device batch data for normalization.", "\n", "# synchronized-batchnorm will pool data from all devices for normalization", "\n", "# its take ~1.4x longer to train  with syncBN but it makes BN stable", "\n", "# (for very small batch-size) 2) Slighly better convergence", "\n", "if", "args", ".", "sync_bn", ":", "\n", "            ", "print", "(", "\"Using synchronize batch-normalization!\"", ")", "\n", "model", "=", "torch", ".", "nn", ".", "SyncBatchNorm", ".", "convert_sync_batchnorm", "(", "model", ")", "\n", "", "else", ":", "\n", "            ", "assert", "args", ".", "batch_size", ">=", "4", ",", "(", "\n", "f\"Please use modestly large-batch size per GPU \"", "\n", "+", "f\"(current batch-size/GPU = {args.batch_size}), since only local stats \"", "\n", "+", "\"are used for batch-norm. Smaller batch-size makes BN unstable.\"", "\n", ")", "\n", "# Using Broadcast_buffers=False due to Batch-norm using mean/var buffers.", "\n", "# If true it broadcast buffers of rank 0 process to all others. Without it", "\n", "# this sync won't happen and each device will maintain its own running mean/var.", "\n", "# Doing so allows us to do more than one forward pass on Batch-norm", "\n", "# in train() mode (https://github.com/pytorch/pytorch/issues/22095)", "\n", "", "model", "=", "torch", ".", "nn", ".", "parallel", ".", "DistributedDataParallel", "(", "\n", "model", ",", "device_ids", "=", "[", "args", ".", "gpu", "]", ",", "broadcast_buffers", "=", "False", "\n", ")", "\n", "", "else", ":", "\n", "# Use DistributedDataParallel since it is much faster than DataParallel", "\n", "# We added DataParallel just for the sake of it.", "\n", "        ", "model", "=", "torch", ".", "nn", ".", "DataParallel", "(", "model", ")", ".", "cuda", "(", ")", "\n", "\n", "######################### Dataloaders #########################", "\n", "", "train_loader", ",", "val_loader", ",", "train_sampler", ",", "val_sampler", "=", "get_real_dataloaders", "(", "\n", "args", ".", "dataset", ",", "\n", "args", ".", "data_dir", ",", "\n", "args", ".", "batch_size", ",", "\n", "args", ".", "workers", ",", "\n", "args", ".", "metadata", ",", "\n", "distributed", "=", "False", "if", "args", ".", "no_dist", "else", "True", ",", "\n", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "\"Using distributed sampler on validation data. This speed up validation process \"", "\n", "+", "\"(which matters when doing adversarial validation), but may end up being just a little bit inaccurate. \"", "\n", "\"MAKE SURE TO RUN THE FINAL EVALUATION WITH EVAL.PY. Remove val_sampler if you want \"", "\n", "+", "\"to do a correct but slow evaluation.\"", "\n", ")", "\n", "", "samplers", "=", "[", "train_sampler", ",", "val_sampler", "]", "\n", "if", "args", ".", "syn_data_list", ":", "\n", "        ", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Using following synthetic dataset in addition to real data: {args.syn_data_list}\"", "\n", ")", "\n", "", "for", "s", ",", "d", "in", "zip", "(", "args", ".", "syn_data_list", ",", "args", ".", "syn_data_dir", ")", ":", "\n", "            ", "syn_data_loader", ",", "syn_data_sampler", "=", "get_synthetic_dataloaders", "(", "\n", "syn_dataset", "=", "s", ",", "\n", "syn_data_dir", "=", "d", ",", "\n", "real_dataset", "=", "args", ".", "dataset", ",", "\n", "batch_size", "=", "args", ".", "batch_size_syn", ",", "\n", "num_workers", "=", "args", ".", "workers", ",", "\n", "metadata", "=", "args", ".", "metadata", ",", "\n", "distributed", "=", "False", "if", "args", ".", "no_dist", "else", "True", ",", "\n", ")", "# using identical batch-size for all synthetic datasets in list", "\n", "samplers", ".", "append", "(", "syn_data_sampler", ")", "\n", "# One can easily manipulate this line to use only real or synthetic data", "\n", "# by default we combine both of them", "\n", "train_loader", "=", "combine_dataloaders", "(", "train_loader", ",", "syn_data_loader", ")", "\n", "", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Ratio of real to synthetic data {1}:{(len(args.syn_data_list)*args.batch_size_syn)/args.batch_size}\"", "\n", ")", "\n", "\n", "######################### Training setup #########################", "\n", "", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", ".", "cuda", "(", "args", ".", "gpu", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "SGD", "(", "\n", "model", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "args", ".", "lr", ",", "\n", "momentum", "=", "args", ".", "momentum", ",", "\n", "weight_decay", "=", "args", ".", "weight_decay", ",", "\n", ")", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "        ", "logger", ".", "info", "(", "\n", "f\"no. of batches = {len(train_loader)}, real data batch_size/GPU = {args.batch_size} \"", "\n", "+", "f\"synthetic data batch_size/GPU = {args.batch_size_syn}\"", "\n", "if", "args", ".", "syn_data_list", "\n", "else", "\"\"", ",", "\n", ")", "\n", "", "lr_scheduler", "=", "torch", ".", "optim", ".", "lr_scheduler", ".", "CosineAnnealingLR", "(", "\n", "optimizer", ",", "args", ".", "epochs", "*", "len", "(", "train_loader", ")", ",", "eta_min", "=", "0.001", "\n", ")", "\n", "\n", "######################### Let's roll #########################", "\n", "for", "epoch", "in", "range", "(", "args", ".", "epochs", ")", ":", "\n", "        ", "for", "sam", "in", "samplers", ":", "\n", "            ", "if", "sam", "is", "not", "None", ":", "\n", "                ", "sam", ".", "set_epoch", "(", "epoch", ")", "\n", "\n", "", "", "results_train", "=", "trainfxn", "(", "\n", "args", ".", "trainer", ",", "\n", "model", ",", "\n", "train_loader", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "epoch", ",", "\n", "args", ",", "\n", "args", ".", "metadata", ".", "num_classes", ",", "\n", "logger", ",", "\n", ")", "\n", "results_val", "=", "evalfxn", "(", "\n", "args", ".", "val_method", ",", "\n", "model", ",", "\n", "val_loader", ",", "\n", "criterion", ",", "\n", "args", ",", "\n", "args", ".", "metadata", ".", "num_classes", ",", "\n", ")", "\n", "\n", "if", "args", ".", "rank", "==", "0", ":", "\n", "            ", "if", "args", ".", "val_method", "==", "\"baseline\"", ":", "\n", "                ", "prec", "=", "results_val", "[", "\"top1\"", "]", "\n", "", "elif", "args", ".", "val_method", "in", "[", "\"pgd\"", ",", "\"trades\"", ",", "\"fgsm\"", "]", ":", "\n", "                ", "prec", "=", "results_val", "[", "\"top1_adv\"", "]", "\n", "", "else", ":", "\n", "                ", "raise", "ValueError", "(", ")", "\n", "", "is_best", "=", "prec", ">", "best_prec", "\n", "best_prec", "=", "max", "(", "prec", ",", "best_prec", ")", "\n", "\n", "state_dict", "=", "{", "\n", "\"epoch\"", ":", "epoch", "+", "1", ",", "\n", "\"arch\"", ":", "args", ".", "arch", ",", "\n", "\"state_dict\"", ":", "model", ".", "state_dict", "(", ")", ",", "\n", "\"best_prec1\"", ":", "best_prec", ",", "\n", "\"optimizer\"", ":", "optimizer", ".", "state_dict", "(", ")", ",", "\n", "}", "\n", "save_checkpoint", "(", "state_dict", ",", "is_best", ",", "save_dir", "=", "args", ".", "checkpoint_dir", ")", "\n", "\n", "logger", ".", "info", "(", "\n", "f\"Epoch {epoch}, \"", "\n", "+", "\", \"", ".", "join", "(", "\n", "[", "\n", "\"{}: {:.3f}\"", ".", "format", "(", "k", "+", "\"_train\"", ",", "v", ")", "\n", "for", "(", "k", ",", "v", ")", "in", "results_train", ".", "items", "(", ")", "\n", "]", "\n", "+", "[", "\n", "\"{}: {:.3f}\"", ".", "format", "(", "k", "+", "\"_val\"", ",", "v", ")", "\n", "for", "(", "k", ",", "v", ")", "in", "results_val", ".", "items", "(", ")", "\n", "]", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.SyntheticImagesDdpmCIFAR10.__init__": [[150, 158], ["numpy.load"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "src", ",", "labels", ")", ":", "\n", "        ", "\"\"\"\n        src: .bin file of data\n        labels: .numpy file of labels (in exact same order as src images)\n        \"\"\"", "\n", "self", ".", "src", "=", "src", "\n", "self", ".", "labels", "=", "np", ".", "load", "(", "labels", ")", "\n", "self", ".", "nddpm", ",", "self", ".", "nIddpm", "=", "6002688", ",", "9400000", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.SyntheticImagesDdpmCIFAR10.sample_image": [[159, 163], ["df.seek", "numpy.array", "numpy.frombuffer().reshape", "torch.from_numpy().permute().float", "numpy.frombuffer", "torch.from_numpy().permute", "df.read", "torch.from_numpy"], "methods", ["None"], ["", "def", "sample_image", "(", "self", ",", "df", ",", "idx", ")", ":", "\n", "        ", "df", ".", "seek", "(", "idx", "*", "3072", ")", "\n", "image", "=", "np", ".", "array", "(", "np", ".", "frombuffer", "(", "df", ".", "read", "(", "3072", ")", ",", "dtype", "=", "\"uint8\"", ")", ".", "reshape", "(", "32", ",", "32", ",", "3", ")", ")", "\n", "return", "torch", ".", "from_numpy", "(", "image", ")", ".", "permute", "(", "2", ",", "0", ",", "1", ")", ".", "float", "(", ")", "/", "255.0", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.SyntheticImagesDdpmCIFAR10.__len__": [[164, 166], ["None"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "15402688", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.SyntheticImagesDdpmCIFAR10.__getitem__": [[167, 175], ["open", "data.SyntheticImagesDdpmCIFAR10.sample_image", "df.close"], "methods", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.SyntheticImagesDdpmCIFAR10.sample_image"], ["", "def", "__getitem__", "(", "self", ",", "idx", ")", ":", "\n", "# opening src at initializing only leads to a race condition between workers in df.seek().", "\n", "# Opening it here avoids the race condition.", "\n", "        ", "with", "open", "(", "self", ".", "src", ",", "\"rb\"", ")", "as", "df", ":", "\n", "            ", "img", "=", "self", ".", "sample_image", "(", "df", ",", "idx", ")", "\n", "df", ".", "close", "(", ")", "\n", "", "label", "=", "self", ".", "labels", "[", "idx", "]", "\n", "return", "img", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_transforms": [[17, 56], ["torchvision.transforms.Compose", "torchvision.transforms.ToTensor", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Compose", "torchvision.transforms.ToTensor", "ValueError", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Resize", "torchvision.transforms.CenterCrop", "torchvision.transforms.ToTensor", "int", "int", "torchvision.transforms.RandomResizedCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor"], "function", ["None"], ["def", "get_transforms", "(", "name", ",", "image_size", ")", ":", "\n", "    ", "if", "name", "==", "\"cifar_style\"", ":", "\n", "        ", "transform_train", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomCrop", "(", "image_size", ",", "padding", "=", "int", "(", "image_size", "/", "8", ")", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", "\n", ")", "\n", "transform_val", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "", "elif", "name", "==", "\"imagenet_style\"", ":", "\n", "        ", "transform_train", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", "\n", ")", "\n", "transform_val", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "Resize", "(", "int", "(", "1.14", "*", "image_size", ")", ")", ",", "\n", "transforms", ".", "CenterCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", "\n", ")", "\n", "", "elif", "name", "==", "\"imagenet_fixed_size_style\"", ":", "\n", "        ", "transform_train", "=", "transforms", ".", "Compose", "(", "\n", "[", "\n", "transforms", ".", "RandomResizedCrop", "(", "image_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "]", "\n", ")", "\n", "# assuming all images are resized to a fixed resolution (e.g., 224x224)", "\n", "# which makes resizing unnecessary for validation set", "\n", "transform_val", "=", "transforms", ".", "ToTensor", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{name} data transformation not supported!\"", ")", "\n", "", "return", "transform_train", ",", "transform_val", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_dataset": [[58, 100], ["torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR10", "torchvision.datasets.CIFAR100", "torchvision.datasets.CIFAR100", "torch.utils.data.distributed.DistributedSampler", "torch.utils.data.distributed.DistributedSampler", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "ValueError", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "get_dataset", "(", "dataset", ",", "data_dir", ",", "transform_train", ",", "transform_val", ",", "distributed", ")", ":", "\n", "    ", "if", "dataset", "==", "\"cifar10\"", ":", "\n", "        ", "train_set", "=", "datasets", ".", "CIFAR10", "(", "\n", "root", "=", "data_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "transform_train", ",", "\n", ")", "\n", "val_set", "=", "datasets", ".", "CIFAR10", "(", "\n", "root", "=", "data_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "transform_val", ",", "\n", ")", "\n", "", "elif", "dataset", "==", "\"cifar100\"", ":", "\n", "        ", "train_set", "=", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "data_dir", ",", "\n", "train", "=", "True", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "transform_train", ",", "\n", ")", "\n", "val_set", "=", "datasets", ".", "CIFAR100", "(", "\n", "root", "=", "data_dir", ",", "\n", "train", "=", "False", ",", "\n", "download", "=", "True", ",", "\n", "transform", "=", "transform_val", ",", "\n", ")", "\n", "", "elif", "dataset", "==", "\"celebA\"", ":", "\n", "        ", "train_set", "=", "datasets", ".", "ImageFolder", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"train\"", ")", ",", "transform", "=", "transform_train", "\n", ")", "\n", "val_set", "=", "datasets", ".", "ImageFolder", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"val\"", ")", ",", "transform", "=", "transform_val", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{dataset} dataset not supported!\"", ")", "\n", "\n", "", "return", "(", "\n", "train_set", ",", "\n", "val_set", ",", "\n", "DistributedSampler", "(", "train_set", ")", "if", "distributed", "else", "None", ",", "\n", "DistributedSampler", "(", "val_set", ")", "if", "distributed", "else", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_dataloader": [[103, 111], ["torch.utils.data.DataLoader"], "function", ["None"], ["", "def", "get_dataloader", "(", "dset", ",", "batch_size", ",", "num_workers", ",", "sampler", "=", "None", ")", ":", "\n", "    ", "return", "DataLoader", "(", "\n", "dset", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "(", "sampler", "is", "None", ")", ",", "\n", "sampler", "=", "sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_real_dataloaders": [[114, 143], ["data.get_transforms", "data.get_dataset", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_transforms", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_dataset"], ["", "def", "get_real_dataloaders", "(", "\n", "dataset", ",", "data_dir", ",", "batch_size", ",", "num_workers", ",", "metadata", ",", "distributed", "=", "True", "\n", ")", ":", "\n", "    ", "transform_train", ",", "transform_val", "=", "get_transforms", "(", "\n", "TRANFORMS_MAPPING", "[", "dataset", "]", ",", "metadata", ".", "image_size", "\n", ")", "\n", "train_set", ",", "val_set", ",", "train_sampler", ",", "val_sampler", "=", "get_dataset", "(", "\n", "dataset", ",", "data_dir", ",", "transform_train", ",", "transform_val", ",", "distributed", "\n", ")", "\n", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "\n", "# Ref: https://github.com/pytorch/examples/issues/769", "\n", "val_loader", "=", "DataLoader", "(", "\n", "val_set", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "(", "val_sampler", "is", "None", ")", ",", "\n", "sampler", "=", "val_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "return", "train_loader", ",", "val_loader", ",", "train_sampler", ",", "val_sampler", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_synthetic_dataset": [[177, 193], ["data.SyntheticImagesDdpmCIFAR10", "os.path.join", "os.path.join", "torchvision.datasets.ImageFolder", "ValueError", "torch.utils.data.distributed.DistributedSampler"], "function", ["None"], ["", "", "def", "get_synthetic_dataset", "(", "dataset", ",", "data_dir", ",", "transform_train", ",", "distributed", ")", ":", "\n", "# TODO: Clean datasets such that we can simplify dataloading.add()", "\n", "# i.e., make all have same structure: data-dir => classes => images", "\n", "    ", "if", "dataset", "==", "\"ddpm_cifar10\"", ":", "\n", "        ", "train_set", "=", "SyntheticImagesDdpmCIFAR10", "(", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"cifar_ddpm_improvedddpm_sorted_images.bin\"", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "data_dir", ",", "\"cifar_ddpm_improvedddpm_sorted_labels.npy\"", ")", ",", "\n", ")", "\n", "", "elif", "dataset", "in", "[", "\"ddpm_cifar100\"", ",", "\"ddpm_celebA\"", "]", ":", "\n", "        ", "train_set", "=", "datasets", ".", "ImageFolder", "(", "data_dir", ",", "transform", "=", "transform_train", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{dataset} dataset not supported!\"", ")", "\n", "\n", "", "return", "(", "\n", "train_set", ",", "\n", "DistributedSampler", "(", "train_set", ")", "if", "distributed", "else", "None", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_synthetic_dataloaders": [[196, 220], ["data.get_transforms", "data.get_synthetic_dataset", "torch.utils.data.DataLoader"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_transforms", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.data.get_synthetic_dataset"], ["", "def", "get_synthetic_dataloaders", "(", "\n", "syn_dataset", ",", "\n", "syn_data_dir", ",", "\n", "real_dataset", ",", "\n", "batch_size", ",", "\n", "num_workers", ",", "\n", "metadata", ",", "\n", "distributed", "=", "True", ",", "\n", ")", ":", "\n", "    ", "transform_train", ",", "_", "=", "get_transforms", "(", "\n", "TRANFORMS_MAPPING", "[", "real_dataset", "]", ",", "metadata", ".", "image_size", "\n", ")", "\n", "train_set", ",", "train_sampler", "=", "get_synthetic_dataset", "(", "\n", "syn_dataset", ",", "syn_data_dir", ",", "transform_train", ",", "distributed", "\n", ")", "\n", "train_loader", "=", "DataLoader", "(", "\n", "train_set", ",", "\n", "batch_size", "=", "batch_size", ",", "\n", "shuffle", "=", "(", "train_sampler", "is", "None", ")", ",", "\n", "sampler", "=", "train_sampler", ",", "\n", "num_workers", "=", "num_workers", ",", "\n", "pin_memory", "=", "True", ",", "\n", ")", "\n", "return", "train_loader", ",", "train_sampler", "\n", "", ""]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.CustomResNet.__init__": [[31, 33], ["robustbench.model_zoo.architectures.resnet.ResNet.__init__"], "methods", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.ProgressMeter.__init__"], ["def", "__init__", "(", "self", ",", "block", ",", "num_blocks", ",", "num_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", "CustomResNet", ",", "self", ")", ".", "__init__", "(", "block", ",", "num_blocks", ",", "num_classes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.CustomResNet.forward": [[34, 44], ["torch.relu", "torch.relu", "utils.CustomResNet.layer1", "utils.CustomResNet.layer2", "utils.CustomResNet.layer3", "utils.CustomResNet.layer4", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool2d", "torch.nn.functional.adaptive_avg_pool2d", "utils.CustomResNet.view", "utils.CustomResNet.linear", "utils.CustomResNet.bn1", "utils.CustomResNet.size", "utils.CustomResNet.conv1"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "out", "=", "F", ".", "relu", "(", "self", ".", "bn1", "(", "self", ".", "conv1", "(", "x", ")", ")", ")", "\n", "out", "=", "self", ".", "layer1", "(", "out", ")", "\n", "out", "=", "self", ".", "layer2", "(", "out", ")", "\n", "out", "=", "self", ".", "layer3", "(", "out", ")", "\n", "out", "=", "self", ".", "layer4", "(", "out", ")", "\n", "out", "=", "torch", ".", "nn", ".", "functional", ".", "adaptive_avg_pool2d", "(", "out", ",", "1", ")", "\n", "out", "=", "out", ".", "view", "(", "out", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "out", "=", "self", ".", "linear", "(", "out", ")", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.combine_dataloaders.__init__": [[121, 124], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "dataloader1", ",", "dataloader2", ")", ":", "\n", "        ", "self", ".", "dataloader1", "=", "dataloader1", "\n", "self", ".", "dataloader2", "=", "dataloader2", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.combine_dataloaders.__iter__": [[125, 127], ["utils.combine_dataloaders._iterator"], "methods", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.combine_dataloaders._iterator"], ["", "def", "__iter__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "_iterator", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.combine_dataloaders.__len__": [[128, 130], ["min", "len", "len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "min", "(", "len", "(", "self", ".", "dataloader1", ")", ",", "len", "(", "self", ".", "dataloader2", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.combine_dataloaders._iterator": [[131, 137], ["zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.randperm", "torch.randperm", "torch.randperm", "torch.randperm", "len"], "methods", ["None"], ["", "def", "_iterator", "(", "self", ")", ":", "\n", "        ", "for", "(", "img1", ",", "label1", ")", ",", "(", "img2", ",", "label2", ")", "in", "zip", "(", "self", ".", "dataloader1", ",", "self", ".", "dataloader2", ")", ":", "\n", "            ", "images", "=", "torch", ".", "cat", "(", "[", "img1", ",", "img2", "]", ")", "\n", "labels", "=", "torch", ".", "cat", "(", "[", "label1", ",", "label2", "]", ")", "\n", "indices", "=", "torch", ".", "randperm", "(", "len", "(", "images", ")", ")", "\n", "yield", "images", "[", "indices", "]", ",", "labels", "[", "indices", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.__init__": [[143, 147], ["utils.AverageMeter.reset"], "methods", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.reset"], ["def", "__init__", "(", "self", ",", "name", ",", "fmt", "=", "\":f\"", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "fmt", "=", "fmt", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.reset": [[148, 153], ["None"], "methods", ["None"], ["", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "val", "=", "0", "\n", "self", ".", "avg", "=", "0", "\n", "self", ".", "sum", "=", "0", "\n", "self", ".", "count", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update": [[154, 159], ["None"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "val", ",", "n", "=", "1", ")", ":", "\n", "        ", "self", ".", "val", "=", "val", "\n", "self", ".", "sum", "+=", "val", "*", "n", "\n", "self", ".", "count", "+=", "n", "\n", "self", ".", "avg", "=", "self", ".", "sum", "/", "self", ".", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.__str__": [[160, 163], ["fmtstr.format"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "fmtstr", "=", "\"{name} {val\"", "+", "self", ".", "fmt", "+", "\"} ({avg\"", "+", "self", ".", "fmt", "+", "\"})\"", "\n", "return", "fmtstr", ".", "format", "(", "**", "self", ".", "__dict__", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.ProgressMeter.__init__": [[166, 170], ["utils.ProgressMeter._get_batch_fmtstr"], "methods", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.ProgressMeter._get_batch_fmtstr"], ["    ", "def", "__init__", "(", "self", ",", "num_batches", ",", "meters", ",", "prefix", "=", "\"\"", ")", ":", "\n", "        ", "self", ".", "batch_fmtstr", "=", "self", ".", "_get_batch_fmtstr", "(", "num_batches", ")", "\n", "self", ".", "meters", "=", "meters", "\n", "self", ".", "prefix", "=", "prefix", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.ProgressMeter.display": [[171, 175], ["print", "str", "utils.ProgressMeter.batch_fmtstr.format"], "methods", ["None"], ["", "def", "display", "(", "self", ",", "batch", ")", ":", "\n", "        ", "entries", "=", "[", "self", ".", "prefix", "+", "self", ".", "batch_fmtstr", ".", "format", "(", "batch", ")", "]", "\n", "entries", "+=", "[", "str", "(", "meter", ")", "for", "meter", "in", "self", ".", "meters", "]", "\n", "print", "(", "\"\\t\"", ".", "join", "(", "entries", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.ProgressMeter._get_batch_fmtstr": [[176, 180], ["len", "str", "str", "fmt.format"], "methods", ["None"], ["", "def", "_get_batch_fmtstr", "(", "self", ",", "num_batches", ")", ":", "\n", "        ", "num_digits", "=", "len", "(", "str", "(", "num_batches", "//", "1", ")", ")", "\n", "fmt", "=", "\"{:\"", "+", "str", "(", "num_digits", ")", "+", "\"d}\"", "\n", "return", "\"[\"", "+", "fmt", "+", "\"/\"", "+", "fmt", ".", "format", "(", "num_batches", ")", "+", "\"]\"", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_model": [[46, 77], ["robustbench.model_zoo.architectures.wide_resnet.WideResNet", "int", "int", "robustbench.model_zoo.architectures.resnet.ResNet", "robustbench.model_zoo.architectures.resnet.ResNet", "utils.CustomResNet", "utils.CustomResNet", "arch.split", "arch.split", "robustbench.model_zoo.architectures.resnest.ResNest152", "ValueError", "arch.lower"], "function", ["None"], ["", "", "def", "get_model", "(", "arch", ",", "num_classes", ")", ":", "\n", "# we use lower case letter for cifar10 (i.e., for 32x32 and 64x64 images) style models and", "\n", "# upper case letter, such as ResNet18, for ImageNet (224x224 size images) style models.", "\n", "\n", "    ", "if", "arch", "in", "[", "\"wrn_28_1\"", ",", "\"wrn_28_10\"", ",", "\"wrn_34_10\"", ",", "\"wrn_70_16\"", "]", ":", "\n", "        ", "model", "=", "WideResNet", "(", "\n", "depth", "=", "int", "(", "arch", ".", "split", "(", "\"_\"", ")", "[", "-", "2", "]", ")", ",", "\n", "widen_factor", "=", "int", "(", "arch", ".", "split", "(", "\"_\"", ")", "[", "-", "1", "]", ")", ",", "\n", "num_classes", "=", "num_classes", ",", "\n", ")", "\n", "", "elif", "arch", "in", "[", "\"resnet18\"", ",", "\"resnet50\"", "]", ":", "\n", "        ", "if", "arch", "==", "\"resnet18\"", ":", "\n", "            ", "model", "=", "ResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "num_classes", "=", "num_classes", ")", "\n", "", "if", "arch", "==", "\"resnet50\"", ":", "\n", "            ", "model", "=", "ResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "num_classes", "=", "num_classes", ")", "\n", "", "", "elif", "arch", "in", "[", "\"resnet18_64\"", ",", "\"resnet50_64\"", "]", ":", "\n", "        ", "if", "arch", "==", "\"resnet18_64\"", ":", "\n", "            ", "model", "=", "CustomResNet", "(", "BasicBlock", ",", "[", "2", ",", "2", ",", "2", ",", "2", "]", ",", "num_classes", "=", "num_classes", ")", "\n", "", "if", "arch", "==", "\"resnet50_64\"", ":", "\n", "            ", "model", "=", "CustomResNet", "(", "Bottleneck", ",", "[", "3", ",", "4", ",", "6", ",", "3", "]", ",", "num_classes", "=", "num_classes", ")", "\n", "", "", "elif", "arch", "in", "[", "\"ResNet18\"", ",", "\"ResNet50\"", "]", ":", "\n", "        ", "model", "=", "tv_models", ".", "__dict__", "[", "arch", ".", "lower", "(", ")", "]", "(", "\n", "num_classes", "=", "num_classes", ",", "pretrained", "=", "False", "\n", ")", "\n", "", "elif", "arch", "==", "\"resnest152\"", ":", "\n", "        ", "model", "=", "ResNest152", "(", "num_classes", "=", "num_classes", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\n", "f\"{arch} is not imported! Please import it from robustbench or torchvision model zoo and update this function accordingly.\"", "\n", ")", "\n", "", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_metadata": [[79, 109], ["easydict.EasyDict", "metadata.keys"], "function", ["None"], ["", "def", "get_metadata", "(", "dataset", ")", ":", "\n", "    ", "metadata", "=", "{", "\n", "\"cifar10\"", ":", "{", "\n", "\"num_classes\"", ":", "10", ",", "\n", "\"image_size\"", ":", "32", ",", "\n", "\"train_images\"", ":", "50000", ",", "\n", "\"val_images\"", ":", "10000", ",", "\n", "}", ",", "\n", "\"cifar100\"", ":", "{", "\n", "\"num_classes\"", ":", "10", ",", "\n", "\"image_size\"", ":", "32", ",", "\n", "\"train_images\"", ":", "50000", ",", "\n", "\"val_images\"", ":", "10000", ",", "\n", "}", ",", "\n", "\"imagenet64\"", ":", "{", "\n", "\"num_classes\"", ":", "1000", ",", "\n", "\"image_size\"", ":", "224", ",", "\n", "\"train_images\"", ":", "1281167", ",", "\n", "\"val_images\"", ":", "50000", ",", "\n", "}", ",", "\n", "\"celebA\"", ":", "{", "\n", "\"num_classes\"", ":", "4", ",", "\n", "\"image_size\"", ":", "64", ",", "\n", "\"train_images\"", ":", "109036", ",", "\n", "\"val_images\"", ":", "12376", ",", "\n", "}", ",", "\n", "}", "\n", "\n", "assert", "dataset", "in", "metadata", ".", "keys", "(", ")", ",", "f\"metdata not available for {dataset} dataset.\"", "\n", "return", "EasyDict", "(", "metadata", "[", "dataset", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.save_checkpoint": [[111, 117], ["torch.save", "torch.save", "os.path.join", "shutil.copyfile", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "save_checkpoint", "(", "state", ",", "is_best", ",", "save_dir", ",", "filename", "=", "\"checkpoint.pth.tar\"", ")", ":", "\n", "    ", "torch", ".", "save", "(", "state", ",", "os", ".", "path", ".", "join", "(", "save_dir", ",", "filename", ")", ")", "\n", "if", "is_best", ":", "\n", "        ", "shutil", ".", "copyfile", "(", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "filename", ")", ",", "\n", "os", ".", "path", ".", "join", "(", "save_dir", ",", "\"model_best.pth.tar\"", ")", ",", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.fix_legacy_dict": [[182, 193], ["list", "list", "remove_module.keys", "remove_module.keys", "utils.remove_module"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.remove_module"], ["", "", "def", "fix_legacy_dict", "(", "d", ")", ":", "\n", "    ", "keys", "=", "list", "(", "d", ".", "keys", "(", ")", ")", "\n", "if", "\"model\"", "in", "keys", ":", "\n", "        ", "d", "=", "d", "[", "\"model\"", "]", "\n", "", "if", "\"state_dict\"", "in", "keys", ":", "\n", "        ", "d", "=", "d", "[", "\"state_dict\"", "]", "\n", "", "keys", "=", "list", "(", "d", ".", "keys", "(", ")", ")", "\n", "# remove multi-gpu module.", "\n", "if", "\"module.\"", "in", "keys", "[", "1", "]", ":", "\n", "        ", "d", "=", "remove_module", "(", "d", ")", "\n", "", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.remove_module": [[195, 197], ["collections.OrderedDict", "d.items", "len"], "function", ["None"], ["", "def", "remove_module", "(", "d", ")", ":", "\n", "    ", "return", "OrderedDict", "(", "{", "(", "k", "[", "len", "(", "\"module.\"", ")", ":", "]", ",", "v", ")", "for", "(", "k", ",", "v", ")", "in", "d", ".", "items", "(", ")", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.accuracy": [[199, 214], ["torch.no_grad", "torch.no_grad", "max", "target.size", "output.topk", "pred.t.t", "pred.t.eq", "target.view().expand_as", "correct[].reshape().float().sum", "res.append", "correct[].reshape().float().sum.mul_", "target.view", "correct[].reshape().float", "correct[].reshape"], "function", ["None"], ["", "def", "accuracy", "(", "output", ",", "target", ",", "topk", "=", "(", "1", ",", ")", ")", ":", "\n", "    ", "\"\"\"Computes the accuracy over the k top predictions for the specified values of k\"\"\"", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "        ", "maxk", "=", "max", "(", "topk", ")", "\n", "batch_size", "=", "target", ".", "size", "(", "0", ")", "\n", "\n", "_", ",", "pred", "=", "output", ".", "topk", "(", "maxk", ",", "1", ",", "True", ",", "True", ")", "\n", "pred", "=", "pred", ".", "t", "(", ")", "\n", "correct", "=", "pred", ".", "eq", "(", "target", ".", "view", "(", "1", ",", "-", "1", ")", ".", "expand_as", "(", "pred", ")", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "k", "in", "topk", ":", "\n", "            ", "correct_k", "=", "correct", "[", ":", "k", "]", ".", "reshape", "(", "-", "1", ")", ".", "float", "(", ")", ".", "sum", "(", "0", ",", "keepdim", "=", "True", ")", "\n", "res", ".", "append", "(", "correct_k", ".", "mul_", "(", "100.0", "/", "batch_size", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.trainfxn": [[216, 318], ["utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "model.train", "time.time", "enumerate", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.ProgressMeter", "utils.AverageMeter.update", "model", "utils.accuracy", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "optimizer.zero_grad", "criterion.backward", "optimizer.step", "lr_scheduler.step", "utils.AverageMeter.update", "time.time", "utils.AverageMeter", "utils.AverageMeter", "len", "utils.ProgressMeter", "ValueError", "logger.info", "images.cuda", "targets.cuda", "images.size", "images.size", "utils.get_adversarial_loss", "utils.accuracy", "utils.AverageMeter.update", "utils.AverageMeter.update", "criterion.item", "images.size", "utils.ProgressMeter.display", "len", "time.time", "images.size", "images.size", "criterion", "time.time", "images.min().item", "images.max().item", "len", "images.min", "images.max"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.accuracy", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_adversarial_loss", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.accuracy", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.ProgressMeter.display"], ["", "", "def", "trainfxn", "(", "\n", "trainer", ",", "\n", "model", ",", "\n", "dataloader", ",", "\n", "criterion", ",", "\n", "optimizer", ",", "\n", "lr_scheduler", ",", "\n", "epoch", ",", "\n", "args", ",", "\n", "num_classes", ",", "\n", "logger", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", "\"Time\"", ",", "\":6.3f\"", ")", "\n", "data_time", "=", "AverageMeter", "(", "\"Data\"", ",", "\":6.3f\"", ")", "\n", "losses", "=", "AverageMeter", "(", "\"Loss\"", ",", "\":.4f\"", ")", "\n", "top1", "=", "AverageMeter", "(", "\"Acc@1\"", ",", "\":6.2f\"", ")", "\n", "if", "num_classes", ">=", "5", ":", "\n", "        ", "top5", "=", "AverageMeter", "(", "\"Acc@5\"", ",", "\":6.2f\"", ")", "\n", "", "else", ":", "\n", "        ", "top5", "=", "AverageMeter", "(", "\"Acc@2\"", ",", "\":6.2f\"", ")", "# measuring top-2", "\n", "", "if", "trainer", "in", "[", "\"pgd\"", ",", "\"fgsm\"", ",", "\"trades\"", "]", ":", "\n", "        ", "top1_adv", "=", "AverageMeter", "(", "\"AccAdv@1\"", ",", "\":6.2f\"", ")", "\n", "if", "num_classes", ">=", "5", ":", "\n", "            ", "top5_adv", "=", "AverageMeter", "(", "\"AccAdv@5\"", ",", "\":6.2f\"", ")", "\n", "", "else", ":", "\n", "            ", "top5_adv", "=", "AverageMeter", "(", "\"AccAdv@2\"", ",", "\":6.2f\"", ")", "# measuring top-2", "\n", "", "progress", "=", "ProgressMeter", "(", "\n", "len", "(", "dataloader", ")", ",", "\n", "[", "batch_time", ",", "data_time", ",", "losses", ",", "top1", ",", "top5", ",", "top1_adv", ",", "top5_adv", "]", ",", "\n", "prefix", "=", "\"Epoch: [{}]\"", ".", "format", "(", "epoch", ")", ",", "\n", ")", "\n", "", "elif", "trainer", "==", "\"baseline\"", ":", "\n", "        ", "progress", "=", "ProgressMeter", "(", "\n", "len", "(", "dataloader", ")", ",", "\n", "[", "batch_time", ",", "data_time", ",", "losses", ",", "top1", ",", "top5", "]", ",", "\n", "prefix", "=", "\"Epoch: [{}]\"", ".", "format", "(", "epoch", ")", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"trainer {trainer} not supported\"", ")", "\n", "\n", "# switch to train mode", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "\n", "# basic properties", "\n", "if", "i", "==", "0", "and", "args", ".", "rank", "==", "0", ":", "\n", "            ", "logger", ".", "info", "(", "\n", "f\"Batch images shape: {images.shape}, targets shape: {targets.shape}, \"", "\n", "+", "f\"World-size: {args.world_size}, \"", "\n", "f\"Effective batch size: {args.world_size * len(images)}, \"", "\n", "+", "f\"Learning rate (epoch {epoch}/{args.epochs}): {optimizer.param_groups[0]['lr']:.5f}, \"", "\n", "+", "f\"pixel range: {[images.min().item(), images.max().item()]}\"", "\n", ")", "\n", "", "images", ",", "targets", "=", "images", ".", "cuda", "(", "args", ".", "gpu", ",", "non_blocking", "=", "True", ")", ",", "targets", ".", "cuda", "(", "\n", "args", ".", "gpu", ",", "non_blocking", "=", "True", "\n", ")", "\n", "logits", "=", "model", "(", "images", ")", "\n", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "logits", ",", "targets", ",", "topk", "=", "(", "1", ",", "5", "if", "num_classes", ">=", "5", "else", "2", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "\n", "if", "trainer", "in", "[", "\"fgsm\"", ",", "\"pgd\"", ",", "\"trades\"", "]", ":", "\n", "            ", "logits_adv", ",", "loss", "=", "get_adversarial_loss", "(", "\n", "trainer", ",", "model", ",", "images", ",", "targets", ",", "logits", ",", "criterion", ",", "optimizer", ",", "args", "\n", ")", "\n", "acc1_adv", ",", "acc5_adv", "=", "accuracy", "(", "\n", "logits_adv", ",", "targets", ",", "topk", "=", "(", "1", ",", "5", "if", "num_classes", ">=", "5", "else", "2", ")", "\n", ")", "\n", "top1_adv", ".", "update", "(", "acc1_adv", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top5_adv", ".", "update", "(", "acc5_adv", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "", "elif", "trainer", "in", "[", "\"baseline\"", "]", ":", "\n", "            ", "loss", "=", "criterion", "(", "logits", ",", "targets", ")", "\n", "\n", "", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "lr_scheduler", ".", "step", "(", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", "and", "args", ".", "rank", "==", "0", ":", "\n", "            ", "progress", ".", "display", "(", "i", ")", "\n", "\n", "", "", "if", "trainer", "in", "[", "\"fgsm\"", ",", "\"pgd\"", ",", "\"trades\"", "]", ":", "\n", "        ", "result", "=", "{", "\n", "\"top1\"", ":", "top1", ".", "avg", ",", "\n", "f\"top{5 if num_classes >= 5 else 2}\"", ":", "top5", ".", "avg", ",", "\n", "\"top1_adv\"", ":", "top1_adv", ".", "avg", ",", "\n", "f\"top{5 if num_classes >= 5 else 2}_adv\"", ":", "top5_adv", ".", "avg", ",", "\n", "}", "\n", "", "elif", "trainer", "in", "[", "\"baseline\"", "]", ":", "\n", "        ", "result", "=", "{", "\"top1\"", ":", "top1", ".", "avg", ",", "f\"top{5 if num_classes >= 5 else 2}\"", ":", "top5", ".", "avg", "}", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.evalfxn": [[320, 406], ["utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "model.eval", "time.time", "enumerate", "utils.AverageMeter", "utils.AverageMeter", "utils.AverageMeter", "utils.ProgressMeter", "utils.AverageMeter.update", "model", "utils.accuracy", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "utils.AverageMeter.update", "time.time", "utils.AverageMeter", "utils.AverageMeter", "len", "utils.ProgressMeter", "ValueError", "images.cuda", "targets.cuda", "images.size", "images.size", "utils.get_adversarial_loss", "utils.accuracy", "utils.AverageMeter.update", "utils.AverageMeter.update", "criterion.item", "images.size", "utils.ProgressMeter.display", "ValueError", "len", "time.time", "images.size", "images.size", "criterion", "time.time"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.accuracy", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_adversarial_loss", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.accuracy", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.AverageMeter.update", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.ProgressMeter.display"], ["", "def", "evalfxn", "(", "\n", "val_method", ",", "\n", "model", ",", "\n", "dataloader", ",", "\n", "criterion", ",", "\n", "args", ",", "\n", "num_classes", ",", "\n", "**", "kwargs", ",", "\n", ")", ":", "\n", "    ", "batch_time", "=", "AverageMeter", "(", "\"Time\"", ",", "\":6.3f\"", ")", "\n", "data_time", "=", "AverageMeter", "(", "\"Data\"", ",", "\":6.3f\"", ")", "\n", "losses", "=", "AverageMeter", "(", "\"Loss\"", ",", "\":.4f\"", ")", "\n", "top1", "=", "AverageMeter", "(", "\"Acc@1\"", ",", "\":6.2f\"", ")", "\n", "if", "num_classes", ">=", "5", ":", "\n", "        ", "top5", "=", "AverageMeter", "(", "\"Acc@5\"", ",", "\":6.2f\"", ")", "\n", "", "else", ":", "\n", "        ", "top5", "=", "AverageMeter", "(", "\"Acc@2\"", ",", "\":6.2f\"", ")", "# measuring top-2", "\n", "", "if", "val_method", "in", "[", "\"pgd\"", ",", "\"auto\"", "]", ":", "\n", "        ", "top1_adv", "=", "AverageMeter", "(", "\"AccAdv@1\"", ",", "\":6.2f\"", ")", "\n", "if", "num_classes", ">=", "5", ":", "\n", "            ", "top5_adv", "=", "AverageMeter", "(", "\"AccAdv@5\"", ",", "\":6.2f\"", ")", "\n", "", "else", ":", "\n", "            ", "top5_adv", "=", "AverageMeter", "(", "\"AccAdv@2\"", ",", "\":6.2f\"", ")", "# measuring top-2", "\n", "", "progress", "=", "ProgressMeter", "(", "\n", "len", "(", "dataloader", ")", ",", "\n", "[", "batch_time", ",", "data_time", ",", "losses", ",", "top1", ",", "top5", ",", "top1_adv", ",", "top5_adv", "]", ",", "\n", "prefix", "=", "\"Test: \"", ",", "\n", ")", "\n", "", "elif", "val_method", "==", "\"baseline\"", ":", "\n", "        ", "progress", "=", "ProgressMeter", "(", "\n", "len", "(", "dataloader", ")", ",", "\n", "[", "batch_time", ",", "data_time", ",", "losses", ",", "top1", ",", "top5", "]", ",", "\n", "prefix", "=", "\"Test: \"", ",", "\n", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"Trainer {val_method} not supported\"", ")", "\n", "\n", "# switch to eval mode", "\n", "", "model", ".", "eval", "(", ")", "\n", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "images", ",", "targets", ")", "in", "enumerate", "(", "dataloader", ")", ":", "\n", "        ", "data_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "images", ",", "targets", "=", "images", ".", "cuda", "(", "args", ".", "gpu", ",", "non_blocking", "=", "True", ")", ",", "targets", ".", "cuda", "(", "\n", "args", ".", "gpu", ",", "non_blocking", "=", "True", "\n", ")", "\n", "\n", "logits", "=", "model", "(", "images", ")", "\n", "\n", "acc1", ",", "acc5", "=", "accuracy", "(", "logits", ",", "targets", ",", "topk", "=", "(", "1", ",", "5", "if", "num_classes", ">=", "5", "else", "2", ")", ")", "\n", "top1", ".", "update", "(", "acc1", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top5", ".", "update", "(", "acc5", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "\n", "if", "val_method", "in", "[", "\"pgd\"", ",", "\"auto\"", "]", ":", "\n", "            ", "logits_adv", ",", "loss", "=", "get_adversarial_loss", "(", "\n", "val_method", ",", "model", ",", "images", ",", "targets", ",", "logits", ",", "criterion", ",", "None", ",", "args", "\n", ")", "\n", "acc1_adv", ",", "acc5_adv", "=", "accuracy", "(", "\n", "logits_adv", ",", "targets", ",", "topk", "=", "(", "1", ",", "5", "if", "num_classes", ">=", "5", "else", "2", ")", "\n", ")", "\n", "top1_adv", ".", "update", "(", "acc1_adv", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "top5_adv", ".", "update", "(", "acc5_adv", "[", "0", "]", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "", "elif", "val_method", "in", "[", "\"baseline\"", "]", ":", "\n", "            ", "loss", "=", "criterion", "(", "logits", ",", "targets", ")", "\n", "\n", "", "losses", ".", "update", "(", "loss", ".", "item", "(", ")", ",", "images", ".", "size", "(", "0", ")", ")", "\n", "\n", "# measure elapsed time", "\n", "batch_time", ".", "update", "(", "time", ".", "time", "(", ")", "-", "end", ")", "\n", "end", "=", "time", ".", "time", "(", ")", "\n", "\n", "if", "i", "%", "args", ".", "print_freq", "==", "0", "and", "args", ".", "rank", "==", "0", ":", "\n", "            ", "progress", ".", "display", "(", "i", ")", "\n", "\n", "", "", "if", "val_method", "in", "[", "\"pgd\"", ",", "\"auto\"", "]", ":", "\n", "        ", "result", "=", "{", "\n", "\"top1\"", ":", "top1", ".", "avg", ",", "\n", "f\"top{5 if num_classes >= 5 else 2}\"", ":", "top5", ".", "avg", ",", "\n", "\"top1_adv\"", ":", "top1_adv", ".", "avg", ",", "\n", "f\"top{5 if num_classes >= 5 else 2}_adv\"", ":", "top5_adv", ".", "avg", ",", "\n", "}", "\n", "", "elif", "val_method", "in", "[", "\"baseline\"", "]", ":", "\n", "        ", "result", "=", "{", "\"top1\"", ":", "top1", ".", "avg", ",", "f\"top{5 if num_classes >= 5 else 2}\"", ":", "top5", ".", "avg", "}", "\n", "", "else", ":", "\n", "        ", "ValueError", "(", "f\"{val_method} validation method not supported!\"", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.pgd_attack": [[408, 438], ["images.detach", "targets.detach", "ValueError", "torch.enable_grad", "torch.enable_grad", "torch.nn.Parameter", "torch.nn.Parameter", "range", "torch.nn.Parameter.detach", "torch.zeros_like().uniform_", "torch.zeros_like().uniform_", "model", "criterion", "torch.autograd.grad", "torch.autograd.grad", "torch.zeros_like", "torch.zeros_like", "grad.sign", "torch.nn.Parameter.data.clamp"], "function", ["None"], ["", "def", "pgd_attack", "(", "\n", "model", ",", "\n", "criterion", ",", "\n", "images", ",", "\n", "targets", ",", "\n", "epsilon", ",", "\n", "step_size", ",", "\n", "num_steps", ",", "\n", "attack", ",", "\n", "clip_min", ",", "\n", "clip_max", ",", "\n", ")", ":", "\n", "    ", "images", ",", "targets", "=", "images", ".", "detach", "(", ")", ",", "targets", ".", "detach", "(", ")", "\n", "if", "attack", "==", "\"linf\"", ":", "\n", "        ", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "            ", "eps", "=", "torch", ".", "nn", ".", "Parameter", "(", "\n", "torch", ".", "zeros_like", "(", "images", ")", ".", "uniform_", "(", "-", "epsilon", ",", "epsilon", ")", ",", "requires_grad", "=", "True", "\n", ")", "\n", "for", "i", "in", "range", "(", "num_steps", ")", ":", "\n", "                ", "logits_adv", "=", "model", "(", "images", "+", "eps", ")", "\n", "loss_adv", "=", "criterion", "(", "logits_adv", ",", "targets", ")", "\n", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_adv", ",", "eps", ",", "create_graph", "=", "False", ")", "[", "0", "]", "\n", "eps", ".", "data", "=", "eps", ".", "data", "+", "step_size", "*", "grad", ".", "sign", "(", ")", "\n", "eps", ".", "data", "=", "(", "images", "+", "eps", ".", "data", ".", "clamp", "(", "-", "epsilon", ",", "epsilon", ")", ")", ".", "clamp", "(", "\n", "clip_min", ",", "clip_max", "\n", ")", "-", "images", "\n", "", "", "adv_images", "=", "images", "+", "eps", ".", "detach", "(", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "\"Attack not supported\"", ")", "\n", "", "return", "adv_images", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.trades_loss": [[442, 525], ["torch.nn.KLDivLoss", "torch.nn.KLDivLoss", "model.eval", "len", "model.train", "torch.autograd.Variable", "optimizer.zero_grad", "model", "model", "torch.cross_entropy", "x_natural.detach", "range", "torch.clamp", "torch.clamp", "torch.nn.KLDivLoss.", "torch.randn().cuda().detach", "torch.randn().cuda().detach", "torch.clamp.requires_grad_", "torch.min", "torch.min", "torch.clamp", "torch.clamp", "torch.autograd.Variable", "torch.optim.SGD", "torch.optim.SGD", "range", "torch.autograd.Variable", "torch.clamp", "torch.clamp", "torch.log_softmax", "torch.softmax", "torch.enable_grad", "torch.enable_grad", "torch.nn.KLDivLoss.", "torch.autograd.grad", "torch.autograd.grad", "torch.clamp.detach", "torch.max", "torch.max", "torch.randn().cuda().detach", "torch.randn().cuda().detach", "torch.optim.SGD.zero_grad", "loss.backward", "torch.autograd.Variable.grad.view().norm", "torch.autograd.Variable.grad.div_", "torch.optim.SGD.step", "torch.autograd.Variable.data.add_", "torch.autograd.Variable.data.clamp_().sub_", "torch.autograd.Variable.data.renorm_", "torch.randn().cuda", "torch.randn().cuda", "torch.log_softmax", "torch.softmax", "torch.sign", "torch.sign", "torch.enable_grad", "torch.enable_grad", "delta.grad.view().norm.view", "torch.randn_like", "torch.randn_like", "model", "logits_natural.detach", "grad.detach", "torch.randn().cuda", "torch.randn().cuda", "torch.nn.KLDivLoss.", "torch.autograd.Variable.grad.view", "torch.autograd.Variable.data.clamp_", "torch.randn", "torch.randn", "torch.log_softmax", "torch.softmax", "torch.randn", "torch.randn", "model", "logits_natural.detach"], "function", ["None"], ["", "def", "trades_loss", "(", "\n", "model", ",", "\n", "x_natural", ",", "\n", "y", ",", "\n", "logits_natural", ",", "\n", "optimizer", ",", "\n", "epsilon", "=", "0.031", ",", "\n", "step_size", "=", "0.003", ",", "\n", "perturb_steps", "=", "10", ",", "\n", "clip_min", "=", "0.0", ",", "\n", "clip_max", "=", "1.0", ",", "\n", "beta", "=", "1.0", ",", "\n", "distance", "=", "\"linf\"", ",", "\n", ")", ":", "\n", "# define KL-loss", "\n", "    ", "criterion_kl", "=", "torch", ".", "nn", ".", "KLDivLoss", "(", "size_average", "=", "False", ")", "\n", "model", ".", "eval", "(", ")", "\n", "batch_size", "=", "len", "(", "x_natural", ")", "\n", "# generate adversarial example", "\n", "x_adv", "=", "x_natural", ".", "detach", "(", ")", "+", "0.001", "*", "torch", ".", "randn", "(", "x_natural", ".", "shape", ")", ".", "cuda", "(", ")", ".", "detach", "(", ")", "\n", "if", "distance", "==", "\"linf\"", ":", "\n", "        ", "for", "_", "in", "range", "(", "perturb_steps", ")", ":", "\n", "            ", "x_adv", ".", "requires_grad_", "(", ")", "\n", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "                ", "loss_kl", "=", "criterion_kl", "(", "\n", "F", ".", "log_softmax", "(", "model", "(", "x_adv", ")", ",", "dim", "=", "1", ")", ",", "\n", "F", ".", "softmax", "(", "logits_natural", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ",", "\n", ")", "\n", "", "grad", "=", "torch", ".", "autograd", ".", "grad", "(", "loss_kl", ",", "[", "x_adv", "]", ")", "[", "0", "]", "\n", "x_adv", "=", "x_adv", ".", "detach", "(", ")", "+", "step_size", "*", "torch", ".", "sign", "(", "grad", ".", "detach", "(", ")", ")", "\n", "x_adv", "=", "torch", ".", "min", "(", "\n", "torch", ".", "max", "(", "x_adv", ",", "x_natural", "-", "epsilon", ")", ",", "x_natural", "+", "epsilon", "\n", ")", "\n", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "clip_min", ",", "clip_max", ")", "\n", "", "", "elif", "distance", "==", "\"l2\"", ":", "\n", "        ", "delta", "=", "0.001", "*", "torch", ".", "randn", "(", "x_natural", ".", "shape", ")", ".", "cuda", "(", ")", ".", "detach", "(", ")", "\n", "delta", "=", "Variable", "(", "delta", ".", "data", ",", "requires_grad", "=", "True", ")", "\n", "\n", "# Setup optimizers", "\n", "optimizer_delta", "=", "torch", ".", "optim", ".", "SGD", "(", "[", "delta", "]", ",", "lr", "=", "epsilon", "/", "perturb_steps", "*", "2", ")", "\n", "\n", "for", "_", "in", "range", "(", "perturb_steps", ")", ":", "\n", "            ", "adv", "=", "x_natural", "+", "delta", "\n", "\n", "# optimize", "\n", "optimizer_delta", ".", "zero_grad", "(", ")", "\n", "with", "torch", ".", "enable_grad", "(", ")", ":", "\n", "                ", "loss", "=", "(", "-", "1", ")", "*", "criterion_kl", "(", "\n", "F", ".", "log_softmax", "(", "model", "(", "adv", ")", ",", "dim", "=", "1", ")", ",", "\n", "F", ".", "softmax", "(", "logits_natural", ".", "detach", "(", ")", ",", "dim", "=", "1", ")", ",", "\n", ")", "\n", "", "loss", ".", "backward", "(", ")", "\n", "# renorming gradient", "\n", "grad_norms", "=", "delta", ".", "grad", ".", "view", "(", "batch_size", ",", "-", "1", ")", ".", "norm", "(", "p", "=", "2", ",", "dim", "=", "1", ")", "\n", "delta", ".", "grad", ".", "div_", "(", "grad_norms", ".", "view", "(", "-", "1", ",", "1", ",", "1", ",", "1", ")", ")", "\n", "# avoid nan or inf if gradient is 0", "\n", "if", "(", "grad_norms", "==", "0", ")", ".", "any", "(", ")", ":", "\n", "                ", "delta", ".", "grad", "[", "grad_norms", "==", "0", "]", "=", "torch", ".", "randn_like", "(", "\n", "delta", ".", "grad", "[", "grad_norms", "==", "0", "]", "\n", ")", "\n", "", "optimizer_delta", ".", "step", "(", ")", "\n", "\n", "# projection", "\n", "delta", ".", "data", ".", "add_", "(", "x_natural", ")", "\n", "delta", ".", "data", ".", "clamp_", "(", "0", ",", "1", ")", ".", "sub_", "(", "x_natural", ")", "\n", "delta", ".", "data", ".", "renorm_", "(", "p", "=", "2", ",", "dim", "=", "0", ",", "maxnorm", "=", "epsilon", ")", "\n", "", "x_adv", "=", "Variable", "(", "x_natural", "+", "delta", ",", "requires_grad", "=", "False", ")", "\n", "", "else", ":", "\n", "        ", "x_adv", "=", "torch", ".", "clamp", "(", "x_adv", ",", "clip_min", ",", "clip_max", ")", "\n", "", "model", ".", "train", "(", ")", "\n", "\n", "x_adv", "=", "Variable", "(", "torch", ".", "clamp", "(", "x_adv", ",", "clip_min", ",", "clip_max", ")", ",", "requires_grad", "=", "False", ")", "\n", "# zero gradient", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "# calculate robust loss", "\n", "logits", "=", "model", "(", "x_natural", ")", "\n", "logits_adv", "=", "model", "(", "x_adv", ")", "\n", "loss_natural", "=", "F", ".", "cross_entropy", "(", "logits", ",", "y", ")", "\n", "loss_robust", "=", "(", "1.0", "/", "batch_size", ")", "*", "criterion_kl", "(", "\n", "F", ".", "log_softmax", "(", "logits_adv", ",", "dim", "=", "1", ")", ",", "F", ".", "softmax", "(", "logits", ",", "dim", "=", "1", ")", "\n", ")", "\n", "loss", "=", "loss_natural", "+", "beta", "*", "loss_robust", "\n", "return", "logits_adv", ",", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.get_adversarial_loss": [[527, 571], ["utils.pgd_attack", "model", "criterion", "utils.trades_loss", "autoattack.AutoAttack", "autoattack.AutoAttack.run_standard_evaluation", "model", "criterion", "ValueError", "len"], "function", ["home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.pgd_attack", "home.repos.pwc.inspect_result.inspire-group_proxy-distributions.None.utils.trades_loss"], ["", "def", "get_adversarial_loss", "(", "\n", "trainer", ",", "model", ",", "images", ",", "targets", ",", "logits", ",", "criterion", ",", "optimizer", ",", "args", "\n", ")", ":", "\n", "    ", "if", "trainer", "==", "\"pgd\"", ":", "\n", "        ", "adv_images", "=", "pgd_attack", "(", "\n", "model", ",", "\n", "criterion", ",", "\n", "images", ",", "\n", "targets", ",", "\n", "args", ".", "epsilon", ",", "\n", "args", ".", "step_size", ",", "\n", "args", ".", "num_steps", ",", "\n", "args", ".", "attack", ",", "\n", "args", ".", "clip_min", ",", "\n", "args", ".", "clip_max", ",", "\n", ")", "\n", "logits_adv", "=", "model", "(", "adv_images", ")", "\n", "loss_adv", "=", "criterion", "(", "logits_adv", ",", "targets", ")", "\n", "", "elif", "trainer", "==", "\"trades\"", ":", "\n", "        ", "logits_adv", ",", "loss_adv", "=", "trades_loss", "(", "\n", "model", ",", "\n", "images", ",", "\n", "targets", ",", "\n", "logits", ",", "\n", "optimizer", ",", "\n", "args", ".", "epsilon", ",", "\n", "args", ".", "step_size", ",", "\n", "args", ".", "num_steps", ",", "\n", "args", ".", "clip_min", ",", "\n", "args", ".", "clip_max", ",", "\n", "6.0", ",", "\n", "args", ".", "attack", ",", "\n", ")", "\n", "", "elif", "trainer", "==", "\"auto\"", ":", "\n", "        ", "adversary", "=", "AutoAttack", "(", "\n", "model", ",", "norm", "=", "\"Linf\"", "if", "args", ".", "attack", "==", "\"linf\"", "else", "\"L2\"", ",", "eps", "=", "args", ".", "epsilon", "\n", ")", "\n", "adversary", ".", "attacks_to_run", "=", "[", "\"apgd-ce\"", ",", "\"apgd-t\"", "]", "\n", "adv_images", "=", "adversary", ".", "run_standard_evaluation", "(", "images", ",", "targets", ",", "bs", "=", "len", "(", "images", ")", ")", "\n", "logits_adv", "=", "model", "(", "adv_images", ")", "\n", "loss_adv", "=", "criterion", "(", "logits_adv", ",", "targets", ")", "\n", "", "else", ":", "\n", "        ", "raise", "ValueError", "(", "f\"{trainer} attack is not supported\"", ")", "\n", "", "return", "logits_adv", ",", "loss_adv", "\n", "", ""]]}