{"home.repos.pwc.inspect_result.opensuh_DFG.None.eval.EvalOps.__init__": [[25, 43], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "str", "time.time", "time.time"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "gpu_num", ",", "base_model_name", ",", "batch_size", ",", "data_set_name", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "gpu_num", ")", "\n", "self", ".", "base_model_name", "=", "base_model_name", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "data_set_name", "=", "data_set_name", "\n", "\n", "if", "base_model_name", "==", "'vgg'", ":", "\n", "            ", "self", ".", "feature_dimension", "=", "64", "\n", "self", ".", "resize_size", "=", "32", "\n", "self", ".", "crop_size", "=", "32", "\n", "", "elif", "base_model_name", "==", "'resnet'", ":", "\n", "            ", "self", ".", "feature_dimension", "=", "256", "\n", "self", ".", "resize_size", "=", "256", "\n", "self", ".", "crop_size", "=", "224", "\n", "\n", "", "tmp", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "curtime", "=", "tmp", "[", ":", "9", "]", "\n", "self", ".", "code_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.eval.EvalOps.load_data_set": [[44, 157], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torchvision.transforms.Resize", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.CinicDataset", "custom_data_loader.CinicDataset", "torchvision.transforms.Resize", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.Food101Dataset", "custom_data_loader.Food101Dataset", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.SvhnDataset", "custom_data_loader.SvhnDataset", "torchvision.transforms.Resize", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.FashionMnistDataset", "custom_data_loader.FashionMnistDataset", "ValueError", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["None"], ["", "def", "load_data_set", "(", "self", ",", "data_set_name", ",", "batch_size", ")", ":", "\n", "        ", "if", "data_set_name", "==", "'caltech'", ":", "# resnet", "\n", "            ", "self", ".", "num_labels", "=", "257", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/caltech256/caltech_256_train_60/'", ",", "transform_train", ")", "\n", "test_image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/caltech256/caltech_256_test_20/'", ",", "transform_test", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'stl'", ":", "# vgg", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/stl10/stl_train'", ",", "transform", "=", "transform_train", ")", "\n", "test_image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/stl10/stl_test'", ",", "transform", "=", "transform_test", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'cinic'", ":", "# vgg", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "trainset", "=", "CinicDataset", "(", "root", "=", "'/data/open_dataset/cinic10/train'", ",", "transform", "=", "transform_train", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "testset", "=", "CinicDataset", "(", "root", "=", "'/data/open_dataset/cinic10/test'", ",", "transform", "=", "transform_test", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'food'", ":", "# resnet", "\n", "            ", "self", ".", "num_labels", "=", "101", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "self", ".", "trainset", "=", "Food101Dataset", "(", "root", "=", "'/data/open_dataset/food-101/resized_train/'", ",", "transform", "=", "transform_train", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "test_image_datasets", "=", "Food101Dataset", "(", "root", "=", "'/data/open_dataset/food-101/resized_test/'", ",", "transform", "=", "transform_test", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "self", ".", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'svhn'", ":", "# lenet", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "trainset", "=", "SvhnDataset", "(", "root", "=", "'/data/open_dataset/svhn/'", ",", "transform", "=", "transform_train", ",", "split", "=", "'train'", ",", "\n", "major_len", "=", "5000", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "test_image_datasets", "=", "SvhnDataset", "(", "root", "=", "'/data/open_dataset/svhn/'", ",", "transform", "=", "transform_test", ",", "split", "=", "'test'", ",", "\n", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'fashion_mnist'", ":", "# lenet", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "trainset", "=", "FashionMnistDataset", "(", "root", "=", "'/data/open_dataset/fashion_mnist/'", ",", "transform", "=", "transform_train", ",", "train", "=", "True", ",", "\n", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "test_image_datasets", "=", "FashionMnistDataset", "(", "root", "=", "'/data/open_dataset/fashion_mnist/'", ",", "transform", "=", "transform_test", ",", "train", "=", "False", ",", "\n", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown data set'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.eval.EvalOps.evaluate": [[158, 199], ["eval.EvalOps.load_data_set", "print", "print", "model.Feature_Extractor", "eval.EvalOps.feature_extractor.load_state_dict", "eval.EvalOps.feature_extractor.eval", "eval.EvalOps.feature_extractor.to", "model.Feature_Classifier", "eval.EvalOps.feature_classifier.load_state_dict", "eval.EvalOps.feature_classifier.eval", "eval.EvalOps.feature_classifier.to", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "print", "print", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "inputs.to.to.to", "labels.to.to.to", "eval.EvalOps.feature_extractor", "eval.EvalOps.feature_classifier", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.double", "torch.sum.double", "torch.sum.double", "torch.sum.double", "inputs.to.to.size", "eval.EvalOps.criterion().item", "inputs.to.to.size", "print", "time.time", "eval.EvalOps.criterion", "len"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.load_data_set"], ["", "", "def", "evaluate", "(", "self", ",", "extractor_weight_path", ",", "classifier_weight_path", ")", ":", "\n", "        ", "_", ",", "self", ".", "data_loader_test", "=", "self", ".", "load_data_set", "(", "self", ".", "data_set_name", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "print", "(", "'data set name: %s'", "%", "(", "self", ".", "data_set_name", ")", ")", "\n", "print", "(", "'test data loader len: %d'", "%", "(", "len", "(", "self", ".", "data_loader_test", ")", ")", ")", "\n", "\n", "self", ".", "feature_extractor", "=", "Feature_Extractor", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "None", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_extractor", ".", "load_state_dict", "(", "torch", ".", "load", "(", "extractor_weight_path", ")", ")", "\n", "self", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "self", ".", "feature_extractor", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "feature_classifier", "=", "Feature_Classifier", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "None", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_classifier", ".", "load_state_dict", "(", "torch", ".", "load", "(", "classifier_weight_path", ")", ")", "\n", "self", ".", "feature_classifier", ".", "eval", "(", ")", "\n", "self", ".", "feature_classifier", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "loss", "=", "0.0", "\n", "step_acc", "=", "0.0", "\n", "total_inputs_len", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "idx", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "self", ".", "data_loader_test", ")", ":", "\n", "                ", "inputs", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "extracted_feature", "=", "self", ".", "feature_extractor", "(", "inputs", ")", "\n", "logits_real", "=", "self", ".", "feature_classifier", "(", "extracted_feature", ")", "\n", "_", ",", "preds", "=", "torch", ".", "max", "(", "logits_real", ",", "1", ")", "\n", "loss", "+=", "self", ".", "criterion", "(", "logits_real", ",", "labels", ")", ".", "item", "(", ")", "*", "inputs", ".", "size", "(", "0", ")", "\n", "\n", "corr_sum", "=", "torch", ".", "sum", "(", "preds", "==", "labels", ".", "data", ")", "\n", "step_acc", "+=", "corr_sum", ".", "double", "(", ")", "\n", "total_inputs_len", "+=", "inputs", ".", "size", "(", "0", ")", "\n", "if", "idx", "%", "20", "==", "0", ":", "\n", "                    ", "print", "(", "'%d / %d'", "%", "(", "idx", ",", "len", "(", "self", ".", "data_loader_test", ")", ")", ")", "\n", "\n", "", "", "", "loss", "/=", "total_inputs_len", "\n", "step_acc", "/=", "total_inputs_len", "\n", "\n", "print", "(", "'Test loss: [%.6f] accuracy: [%.4f]'", "%", "(", "loss", ",", "step_acc", ")", ")", "\n", "print", "(", "\"time: %.3f\"", "%", "(", "time", ".", "time", "(", ")", "-", "self", ".", "code_start_time", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.__init__": [[23, 92], ["torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "torch.device", "str", "time.time", "time.time", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "os.path.isdir", "os.makedirs", "ValueError"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "gpu_num", ",", "base_model_name", ",", "batch_size", ",", "data_set_name", ",", "extractor_learning_rate", ",", "classifier_learning_rate", ",", "discriminator_learning_rate", ",", "\n", "generator_learning_rate", ",", "minor_class_num", ",", "minor_class_ratio", ",", "with_regularization", ",", "model_save_path", ")", ":", "\n", "        ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda:%d\"", "%", "gpu_num", ")", "\n", "self", ".", "base_model_name", "=", "base_model_name", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "data_set_name", "=", "data_set_name", "\n", "\n", "#Learning rate", "\n", "self", ".", "extractor_learning_rate", "=", "extractor_learning_rate", "\n", "self", ".", "classifier_learning_rate", "=", "classifier_learning_rate", "\n", "self", ".", "discriminator_learning_rate", "=", "discriminator_learning_rate", "\n", "self", ".", "generator_learning_rate", "=", "generator_learning_rate", "\n", "\n", "if", "base_model_name", "==", "'vgg'", ":", "\n", "            ", "self", ".", "feature_dimension", "=", "64", "\n", "self", ".", "resize_size", "=", "32", "\n", "self", ".", "crop_size", "=", "32", "\n", "self", ".", "noise_dim", "=", "100", "\n", "", "elif", "base_model_name", "==", "'resnet'", ":", "\n", "            ", "self", ".", "feature_dimension", "=", "256", "\n", "self", ".", "resize_size", "=", "256", "\n", "self", ".", "crop_size", "=", "224", "\n", "self", ".", "noise_dim", "=", "4900", "\n", "", "elif", "base_model_name", "==", "'lenet'", ":", "\n", "            ", "self", ".", "feature_dimension", "=", "6", "\n", "self", ".", "resize_size", "=", "32", "\n", "self", ".", "crop_size", "=", "32", "\n", "self", ".", "noise_dim", "=", "100", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown base model'", ")", "\n", "\n", "# for hook layer output", "\n", "", "self", ".", "layer_outputs_source", "=", "[", "]", "\n", "self", ".", "layer_outputs_target", "=", "[", "]", "\n", "\n", "self", ".", "minor_class_num", "=", "minor_class_num", "\n", "self", ".", "minor_class_ratio", "=", "minor_class_ratio", "\n", "\n", "self", ".", "with_regularization", "=", "with_regularization", "\n", "\n", "tmp", "=", "str", "(", "time", ".", "time", "(", ")", ")", "\n", "self", ".", "curtime", "=", "tmp", "[", ":", "9", "]", "\n", "\n", "self", ".", "model_save_path", "=", "model_save_path", "+", "self", ".", "base_model_name", "+", "'_'", "+", "self", ".", "data_set_name", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "model_save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "model_save_path", ")", "\n", "\n", "", "self", ".", "csv_save_path", "=", "self", ".", "model_save_path", "+", "'/csv/'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "csv_save_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "csv_save_path", ")", "\n", "\n", "", "self", ".", "generator_attention_class", "=", "self", ".", "csv_save_path", "+", "'generator_attention_class_'", "+", "self", ".", "base_model_name", "+", "'_'", "+", "self", ".", "data_set_name", "+", "'_'", "+", "self", ".", "curtime", "+", "'.csv'", "\n", "self", ".", "wj_extractor_file", "=", "self", ".", "csv_save_path", "+", "'wj_extractor_'", "+", "self", ".", "base_model_name", "+", "'_'", "+", "self", ".", "data_set_name", "+", "'_'", "+", "self", ".", "curtime", "+", "'.csv'", "\n", "self", ".", "generator_attention_file", "=", "self", ".", "csv_save_path", "+", "'generator_attention_'", "+", "self", ".", "base_model_name", "+", "'_'", "+", "self", ".", "data_set_name", "+", "'_'", "+", "self", ".", "curtime", "+", "'.csv'", "\n", "\n", "self", ".", "cal_weight_path", "=", "self", ".", "model_save_path", "+", "'/config/'", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "self", ".", "cal_weight_path", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "self", ".", "cal_weight_path", ")", "\n", "\n", "", "self", ".", "transpose_wj_extractor_npy", "=", "self", ".", "cal_weight_path", "+", "'transpose_wj_extractor_%s_%s.npy'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ")", "\n", "self", ".", "generator_attention_npy", "=", "self", ".", "cal_weight_path", "+", "'generator_attention_%s_%s.npy'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ")", "\n", "self", ".", "channel_weight_json", "=", "self", ".", "cal_weight_path", "+", "'channel_weight_%s_%s.json'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ")", "\n", "\n", "self", ".", "optimal_attention_npy", "=", "self", ".", "model_save_path", "+", "'/optimal_attention_%s_%s_%s'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ",", "self", ".", "curtime", ")", "\n", "self", ".", "feature_extractor_target_pth", "=", "self", ".", "model_save_path", "+", "'/feature_extractor_target_%s_%s_%s.pth'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ",", "self", ".", "curtime", ")", "\n", "self", ".", "feature_classifier_target_pth", "=", "self", ".", "model_save_path", "+", "'/feature_classifier_target_%s_%s_%s.pth'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ",", "self", ".", "curtime", ")", "\n", "self", ".", "feature_generator_pth", "=", "self", ".", "model_save_path", "+", "'/feature_generator_%s_%s_%s.pth'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ",", "self", ".", "curtime", ")", "\n", "self", ".", "feature_discriminator_pth", "=", "self", ".", "model_save_path", "+", "'/feature_discriminator_%s_%s_%s.pth'", "%", "(", "self", ".", "base_model_name", ",", "self", ".", "data_set_name", ",", "self", ".", "curtime", ")", "\n", "self", ".", "code_start_time", "=", "time", ".", "time", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.load_data_set": [[93, 205], ["torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "torchvision.datasets.ImageFolder", "torchvision.datasets.ImageFolder", "torchvision.transforms.Resize", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.CinicDataset", "custom_data_loader.CinicDataset", "torchvision.transforms.Resize", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.Food101Dataset", "custom_data_loader.Food101Dataset", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.SvhnDataset", "custom_data_loader.SvhnDataset", "torchvision.transforms.Resize", "torchvision.transforms.RandomCrop", "torchvision.transforms.RandomHorizontalFlip", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Resize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Compose", "torchvision.transforms.Compose", "custom_data_loader.FashionMnistDataset", "custom_data_loader.FashionMnistDataset", "ValueError", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torch.utils.data.DataLoader", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize", "torchvision.transforms.Pad", "torchvision.transforms.ToTensor", "torchvision.transforms.Normalize"], "methods", ["None"], ["", "def", "load_data_set", "(", "self", ",", "data_set_name", ",", "batch_size", ")", ":", "\n", "        ", "if", "data_set_name", "==", "'caltech'", ":", "# resnet", "\n", "            ", "self", ".", "num_labels", "=", "257", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/caltech256/caltech_256_train_60/'", ",", "transform_train", ")", "\n", "test_image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/caltech256/caltech_256_test_20/'", ",", "transform_test", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'stl'", ":", "# vgg", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/stl10/stl_train'", ",", "transform", "=", "transform_train", ")", "\n", "test_image_datasets", "=", "datasets", ".", "ImageFolder", "(", "'/data/open_dataset/stl10/stl_test'", ",", "transform", "=", "transform_test", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'cinic'", ":", "# vgg", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ",", "padding", "=", "4", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "trainset", "=", "CinicDataset", "(", "root", "=", "'/data/open_dataset/cinic10/train'", ",", "transform", "=", "transform_train", ",", "minor_class_num", "=", "self", ".", "minor_class_num", ",", "ratio", "=", "self", ".", "minor_class_ratio", ")", "\n", "testset", "=", "CinicDataset", "(", "root", "=", "'/data/open_dataset/cinic10/test'", ",", "transform", "=", "transform_test", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "testset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'food'", ":", "# resnet", "\n", "            ", "self", ".", "num_labels", "=", "101", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "RandomCrop", "(", "self", ".", "crop_size", ")", ",", "\n", "transforms", ".", "RandomHorizontalFlip", "(", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Resize", "(", "(", "self", ".", "resize_size", ",", "self", ".", "resize_size", ")", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "trainset", "=", "Food101Dataset", "(", "root", "=", "'/data/open_dataset/food-101/resized_train/'", ",", "transform", "=", "transform_train", ",", "minor_class_num", "=", "self", ".", "minor_class_num", ",", "ratio", "=", "self", ".", "minor_class_ratio", ")", "\n", "test_image_datasets", "=", "Food101Dataset", "(", "root", "=", "'/data/open_dataset/food-101/resized_test/'", ",", "transform", "=", "transform_test", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'svhn'", ":", "# lenet", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "trainset", "=", "SvhnDataset", "(", "root", "=", "'/data/open_dataset/svhn/'", ",", "transform", "=", "transform_train", ",", "split", "=", "'train'", ",", "\n", "major_len", "=", "5000", ",", "minor_class_num", "=", "self", ".", "minor_class_num", ",", "ratio", "=", "self", ".", "minor_class_ratio", ")", "\n", "test_image_datasets", "=", "SvhnDataset", "(", "root", "=", "'/data/open_dataset/svhn/'", ",", "transform", "=", "transform_test", ",", "split", "=", "'test'", ",", "\n", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "\n", "", "elif", "data_set_name", "==", "'fashion_mnist'", ":", "# lenet", "\n", "            ", "self", ".", "num_labels", "=", "10", "\n", "transform_train", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "transform_test", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "Pad", "(", "2", ")", ",", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ")", ",", "(", "0.5", ")", ")", ",", "\n", "]", ")", "\n", "trainset", "=", "FashionMnistDataset", "(", "root", "=", "'/data/open_dataset/fashion_mnist/'", ",", "transform", "=", "transform_train", ",", "train", "=", "True", ",", "\n", "minor_class_num", "=", "self", ".", "minor_class_num", ",", "ratio", "=", "self", ".", "minor_class_ratio", ")", "\n", "test_image_datasets", "=", "FashionMnistDataset", "(", "root", "=", "'/data/open_dataset/fashion_mnist/'", ",", "transform", "=", "transform_test", ",", "train", "=", "False", ",", "\n", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ")", "\n", "return", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "trainset", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "True", ")", ",", "torch", ".", "utils", ".", "data", ".", "DataLoader", "(", "test_image_datasets", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "raise", "ValueError", "(", "'Unknown data set'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.calculate_weighting_feature_maps_extractor": [[206, 272], ["print", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "print", "time.time", "print", "train.TrainOps.layer_outputs_source.clear", "train.TrainOps.layer_outputs_target.clear", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "enumerate", "len", "range", "range", "time.time", "range", "class_label_list.extend", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "torch.stack", "class_inputs.to.to.to", "class_labels.to.to.to", "extractor_model", "classifier_model", "base_loss.extend", "train.TrainOps.layer_outputs_source.clear", "train.TrainOps.layer_outputs_target.clear", "range", "print", "extractor_model.state_dict", "inputs.size", "class_inputs.to.to.append", "class_labels.to.to.append", "len", "torch.CrossEntropyLoss.cpu", "[].clone", "extractor_model", "classifier_model", "jthfilter_loss_list[].extend", "train.TrainOps.layer_outputs_source.clear", "train.TrainOps.layer_outputs_target.clear", "len", "len", "min", "torch.CrossEntropyLoss.cpu", "time.time", "labels[].item", "torch.CrossEntropyLoss.", "extractor_model.state_dict", "extractor_model.state_dict", "len", "labels[].item", "torch.CrossEntropyLoss.", "time.time", "extractor_model.state_dict"], "methods", ["None"], ["", "", "def", "calculate_weighting_feature_maps_extractor", "(", "self", ",", "extractor_model", ",", "classifier_model", ",", "layer_name", ",", "label_min", "=", "10", ")", ":", "\n", "        ", "print", "(", "'weight data loader len : %d'", "%", "len", "(", "self", ".", "data_loader", ")", ")", "\n", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "'none'", ")", "\n", "\n", "channel", "=", "extractor_model", ".", "state_dict", "(", ")", "[", "layer_name", "+", "'.weight'", "]", ".", "shape", "[", "0", "]", "\n", "print", "(", "'channel number : %d'", "%", "channel", ")", "\n", "\n", "labels_cnt", "=", "[", "0", "for", "i", "in", "range", "(", "self", ".", "num_labels", ")", "]", "\n", "labels_min", "=", "label_min", "\n", "\n", "# calculate base, jth loss", "\n", "total_start_time", "=", "time", ".", "time", "(", ")", "\n", "base_loss", "=", "[", "]", "\n", "jthfilter_loss_list", "=", "[", "[", "]", "for", "i", "in", "range", "(", "channel", ")", "]", "\n", "class_label_list", "=", "[", "]", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "i", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "self", ".", "data_loader", ")", ":", "\n", "                ", "step_start_time", "=", "time", ".", "time", "(", ")", "\n", "class_inputs", "=", "[", "]", "\n", "class_labels", "=", "[", "]", "\n", "for", "batch_idx", "in", "range", "(", "inputs", ".", "size", "(", "0", ")", ")", ":", "\n", "                    ", "if", "labels_cnt", "[", "labels", "[", "batch_idx", "]", ".", "item", "(", ")", "]", ">=", "labels_min", ":", "\n", "                        ", "continue", "\n", "\n", "", "labels_cnt", "[", "labels", "[", "batch_idx", "]", ".", "item", "(", ")", "]", "+=", "1", "\n", "class_inputs", ".", "append", "(", "inputs", "[", "batch_idx", "]", ")", "\n", "class_labels", ".", "append", "(", "labels", "[", "batch_idx", "]", ")", "\n", "\n", "", "if", "len", "(", "class_inputs", ")", "==", "0", ":", "\n", "                    ", "if", "min", "(", "labels_cnt", ")", "<", "labels_min", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "break", "\n", "\n", "", "", "class_label_list", ".", "extend", "(", "class_labels", ")", "\n", "class_inputs", "=", "torch", ".", "stack", "(", "class_inputs", ")", "\n", "class_labels", "=", "torch", ".", "stack", "(", "class_labels", ")", "\n", "\n", "class_inputs", "=", "class_inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "class_labels", "=", "class_labels", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "feature_outputs", "=", "extractor_model", "(", "class_inputs", ")", "\n", "classifier_outputs", "=", "classifier_model", "(", "feature_outputs", ")", "\n", "base_loss", ".", "extend", "(", "criterion", "(", "classifier_outputs", ",", "class_labels", ")", ".", "cpu", "(", ")", ")", "\n", "self", ".", "layer_outputs_source", ".", "clear", "(", ")", "\n", "self", ".", "layer_outputs_target", ".", "clear", "(", ")", "\n", "\n", "for", "j", "in", "range", "(", "channel", ")", ":", "\n", "                    ", "j_tmp_weight", "=", "extractor_model", ".", "state_dict", "(", ")", "[", "layer_name", "+", "'.weight'", "]", "[", "j", ",", ":", ",", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "extractor_model", ".", "state_dict", "(", ")", "[", "layer_name", "+", "'.weight'", "]", "[", "j", ",", ":", ",", ":", ",", ":", "]", "=", "0", "\n", "\n", "feature_outputs", "=", "extractor_model", "(", "class_inputs", ")", "\n", "classifier_outputs", "=", "classifier_model", "(", "feature_outputs", ")", "\n", "jthfilter_loss_list", "[", "j", "]", ".", "extend", "(", "criterion", "(", "classifier_outputs", ",", "class_labels", ")", ".", "cpu", "(", ")", ")", "\n", "\n", "extractor_model", ".", "state_dict", "(", ")", "[", "layer_name", "+", "'.weight'", "]", "[", "j", ",", ":", ",", ":", ",", ":", "]", "=", "j_tmp_weight", "\n", "self", ".", "layer_outputs_source", ".", "clear", "(", ")", "\n", "self", ".", "layer_outputs_target", ".", "clear", "(", ")", "\n", "\n", "", "print", "(", "'%d step loss len : %d, time : %.5f'", "%", "(", "i", ",", "len", "(", "base_loss", ")", ",", "time", ".", "time", "(", ")", "-", "step_start_time", ")", ")", "\n", "\n", "", "", "print", "(", "'total loss len : %d, class label len : %d, total time : %.5f'", "%", "(", "len", "(", "base_loss", ")", ",", "len", "(", "class_label_list", ")", ",", "time", ".", "time", "(", ")", "-", "total_start_time", ")", ")", "\n", "# memory clear", "\n", "self", ".", "layer_outputs_source", ".", "clear", "(", ")", "\n", "self", ".", "layer_outputs_target", ".", "clear", "(", ")", "\n", "return", "base_loss", ",", "jthfilter_loss_list", ",", "class_label_list", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.calculate_weighting_feature_maps_classifier": [[273, 318], ["print", "range", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "time.time", "enumerate", "json.dump", "len", "filter_weight.append", "inputs.to.to.to", "labels.to.to.to", "extractor_model", "classifier_model", "torch.CrossEntropyLoss.", "classifier_model.named_modules", "print", "print", "open", "len", "layer_name.index", "range", "time.time", "[].clone", "extractor_model", "classifier_model", "torch.CrossEntropyLoss.", "diff.detach().cpu().numpy().item.detach().cpu().numpy().item.detach().cpu().numpy().item", "print", "classifier_model.state_dict", "classifier_model.state_dict", "classifier_model.state_dict", "diff.detach().cpu().numpy().item.detach().cpu().numpy().item.detach().cpu().numpy", "classifier_model.state_dict", "classifier_model.state_dict", "diff.detach().cpu().numpy().item.detach().cpu().numpy().item.detach().cpu", "diff.detach().cpu().numpy().item.detach().cpu().numpy().item.detach"], "methods", ["None"], ["", "def", "calculate_weighting_feature_maps_classifier", "(", "self", ",", "extractor_model", ",", "classifier_model", ",", "layer_name", ")", ":", "\n", "        ", "print", "(", "'weight data loader len : %d'", "%", "len", "(", "self", ".", "data_loader", ")", ")", "\n", "\n", "filter_weight", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "layer_name", ")", ")", ":", "\n", "            ", "channel", "=", "classifier_model", ".", "state_dict", "(", ")", "[", "layer_name", "[", "i", "]", "+", "'.weight'", "]", ".", "shape", "[", "0", "]", "\n", "layer_filter_weight", "=", "[", "0", "]", "*", "channel", "\n", "filter_weight", ".", "append", "(", "layer_filter_weight", ")", "\n", "\n", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "since", "=", "time", ".", "time", "(", ")", "\n", "for", "i", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "self", ".", "data_loader", ")", ":", "\n", "            ", "if", "i", ">=", "4", ":", "\n", "                ", "break", "\n", "", "inputs", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "outputs", "=", "extractor_model", "(", "inputs", ")", "\n", "outputs", "=", "classifier_model", "(", "outputs", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "\n", "for", "name", ",", "module", "in", "classifier_model", ".", "named_modules", "(", ")", ":", "\n", "                ", "if", "not", "name", "in", "layer_name", ":", "\n", "                    ", "continue", "\n", "", "layer_id", "=", "layer_name", ".", "index", "(", "name", ")", "\n", "channel", "=", "classifier_model", ".", "state_dict", "(", ")", "[", "name", "+", "'.weight'", "]", ".", "shape", "[", "0", "]", "\n", "for", "j", "in", "range", "(", "channel", ")", ":", "\n", "                    ", "tmp", "=", "classifier_model", ".", "state_dict", "(", ")", "[", "name", "+", "'.weight'", "]", "[", "j", ",", ":", ",", ":", ",", ":", "]", ".", "clone", "(", ")", "\n", "classifier_model", ".", "state_dict", "(", ")", "[", "name", "+", "'.weight'", "]", "[", "j", ",", ":", ",", ":", ",", ":", "]", "=", "0", "\n", "outputs", "=", "extractor_model", "(", "inputs", ")", "\n", "outputs", "=", "classifier_model", "(", "outputs", ")", "\n", "loss1", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "diff", "=", "loss1", "-", "loss", "\n", "diff", "=", "diff", ".", "detach", "(", ")", ".", "cpu", "(", ")", ".", "numpy", "(", ")", ".", "item", "(", ")", "\n", "hist", "=", "filter_weight", "[", "layer_id", "]", "[", "j", "]", "\n", "filter_weight", "[", "layer_id", "]", "[", "j", "]", "=", "1.0", "*", "(", "i", "*", "hist", "+", "diff", ")", "/", "(", "i", "+", "1", ")", "\n", "print", "(", "'%s:%d %.4f %.4f'", "%", "(", "name", ",", "j", ",", "diff", ",", "filter_weight", "[", "layer_id", "]", "[", "j", "]", ")", ")", "\n", "classifier_model", ".", "state_dict", "(", ")", "[", "name", "+", "'.weight'", "]", "[", "j", ",", ":", ",", ":", ",", ":", "]", "=", "tmp", "\n", "\n", "", "", "print", "(", "'step %d finished'", "%", "i", ")", "\n", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "since", "\n", "print", "(", "'step Training complete in {:.0f}m {:.0f}s'", ".", "format", "(", "\n", "time_elapsed", "//", "60", ",", "time_elapsed", "%", "60", ")", ")", "\n", "\n", "", "json", ".", "dump", "(", "filter_weight", ",", "open", "(", "self", ".", "channel_weight_json", ",", "'w'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.for_hook_source": [[319, 321], ["train.TrainOps.layer_outputs_source.append"], "methods", ["None"], ["", "def", "for_hook_source", "(", "self", ",", "module", ",", "input", ",", "output", ")", ":", "\n", "        ", "self", ".", "layer_outputs_source", ".", "append", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.for_hook_target": [[322, 324], ["train.TrainOps.layer_outputs_target.append"], "methods", ["None"], ["", "def", "for_hook_target", "(", "self", ",", "module", ",", "input", ",", "output", ")", ":", "\n", "        ", "self", ".", "layer_outputs_target", ".", "append", "(", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.register_hook": [[325, 329], ["model.named_modules", "layer.register_forward_hook"], "methods", ["None"], ["", "def", "register_hook", "(", "self", ",", "model", ",", "func", ",", "layer_name", ")", ":", "\n", "        ", "for", "name", ",", "layer", "in", "model", ".", "named_modules", "(", ")", ":", "\n", "            ", "if", "name", "in", "layer_name", ":", "\n", "                ", "layer", ".", "register_forward_hook", "(", "func", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_fc": [[330, 392], ["model.named_parameters", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.lr_scheduler.ExponentialLR", "torch.lr_scheduler.ExponentialLR", "torch.lr_scheduler.ExponentialLR", "torch.lr_scheduler.ExponentialLR", "torch.lr_scheduler.ExponentialLR", "time.time", "range", "print", "filter", "print", "print", "model.train", "len", "enumerate", "torch.lr_scheduler.ExponentialLR.step", "print", "print", "time.time", "name.startswith", "print", "model.parameters", "math.exp", "inputs.to.to.to", "labels.to.to.to", "feature_extractor", "model", "torch.SGD.zero_grad", "torch.CrossEntropyLoss.", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "nn.CrossEntropyLoss.backward", "torch.SGD.step", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "inputs.to.to.size", "running_corrects.double", "time.time", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "print", "nn.CrossEntropyLoss.item", "inputs.to.to.size", "math.log", "torch.sum.double", "torch.sum.double", "torch.sum.double", "torch.sum.double", "torch.sum.double", "len"], "methods", ["None"], ["", "", "", "def", "train_fc", "(", "self", ",", "feature_extractor", ",", "model", ")", ":", "\n", "\n", "        ", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "not", "name", ".", "startswith", "(", "'classifier.'", ")", ":", "\n", "                ", "param", ".", "requires_grad", "=", "False", "\n", "", "else", ":", "\n", "                ", "print", "(", "name", ")", "\n", "\n", "", "", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "optimizer", "=", "optim", ".", "SGD", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "model", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "0.01", ",", "momentum", "=", "0.9", ",", "weight_decay", "=", "1e-4", ")", "\n", "num_epochs", "=", "10", "\n", "decay_epochs", "=", "6", "\n", "scheduler", "=", "optim", ".", "lr_scheduler", ".", "ExponentialLR", "(", "optimizer", ",", "gamma", "=", "math", ".", "exp", "(", "math", ".", "log", "(", "0.1", ")", "/", "decay_epochs", ")", ")", "\n", "since", "=", "time", ".", "time", "(", ")", "\n", "for", "epoch", "in", "range", "(", "num_epochs", ")", ":", "\n", "            ", "print", "(", "'Epoch {}/{}'", ".", "format", "(", "epoch", ",", "num_epochs", "-", "1", ")", ")", "\n", "print", "(", "'-'", "*", "10", ")", "\n", "\n", "model", ".", "train", "(", ")", "\n", "running_loss", "=", "0.0", "\n", "running_corrects", "=", "0.0", "\n", "total", "=", "0.0", "\n", "nstep", "=", "len", "(", "self", ".", "data_loader", ")", "\n", "for", "i", ",", "(", "inputs", ",", "labels", ")", "in", "enumerate", "(", "self", ".", "data_loader", ")", ":", "\n", "                ", "inputs", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "features", "=", "feature_extractor", "(", "inputs", ")", "\n", "outputs", "=", "model", "(", "features", ")", "\n", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "loss", "=", "criterion", "(", "outputs", ",", "labels", ")", "\n", "_", ",", "preds", "=", "torch", ".", "max", "(", "outputs", ",", "1", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "i", "%", "10", "==", "0", ":", "\n", "                    ", "corr_sum", "=", "torch", ".", "sum", "(", "preds", "==", "labels", ".", "data", ")", "\n", "step_acc", "=", "corr_sum", ".", "double", "(", ")", "/", "len", "(", "labels", ")", "\n", "print", "(", "'step: %d/%d, loss = %.4f, top1 = %.4f'", "%", "(", "i", ",", "nstep", ",", "loss", ",", "step_acc", ")", ")", "\n", "\n", "# statistics", "\n", "", "running_loss", "+=", "loss", ".", "item", "(", ")", "*", "inputs", ".", "size", "(", "0", ")", "\n", "running_corrects", "+=", "torch", ".", "sum", "(", "preds", "==", "labels", ".", "data", ")", "\n", "total", "+=", "inputs", ".", "size", "(", "0", ")", "\n", "\n", "", "scheduler", ".", "step", "(", ")", "\n", "epoch_loss", "=", "running_loss", "/", "total", "\n", "epoch_acc", "=", "running_corrects", ".", "double", "(", ")", "/", "total", "\n", "\n", "print", "(", "'epoch: {:d} Loss: {:.4f} Acc: {:.4f}'", ".", "format", "(", "epoch", ",", "epoch_loss", ",", "epoch_acc", ")", ")", "\n", "\n", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "since", "\n", "print", "(", "'Training complete in {:.0f}m {:.0f}s'", ".", "format", "(", "\n", "time_elapsed", "//", "60", ",", "time_elapsed", "%", "60", ")", ")", "\n", "\n", "", "time_elapsed", "=", "time", ".", "time", "(", ")", "-", "since", "\n", "print", "(", "'Training complete in {:.0f}m {:.0f}s'", ".", "format", "(", "\n", "time_elapsed", "//", "60", ",", "time_elapsed", "%", "60", ")", ")", "\n", "\n", "return", "model", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.channel_evaluation": [[393, 486], ["print", "print", "train.TrainOps.load_data_set", "print", "print", "model.Feature_Extractor", "train.TrainOps.feature_extractor.to", "train.TrainOps.feature_extractor.parameters", "train.TrainOps.feature_extractor.eval", "model.Feature_Classifier", "train.TrainOps.feature_classifier.to", "train.TrainOps.feature_classifier.parameters", "train.TrainOps.feature_classifier.eval", "train.TrainOps.calculate_weighting_feature_maps_extractor", "len", "numpy.zeros", "numpy.array", "print", "range", "numpy.transpose", "print", "numpy.save", "numpy.zeros", "numpy.zeros", "numpy.save", "range", "train.TrainOps.calculate_weighting_feature_maps_classifier", "train.TrainOps.train_fc", "numpy.transpose.mean", "open", "csv.writer", "range", "class_num.item.item.item", "len", "len", "numpy.array", "train.TrainOps.channel_evaluation.softmax_loss"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.load_data_set", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.calculate_weighting_feature_maps_extractor", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.calculate_weighting_feature_maps_classifier", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_fc"], ["", "def", "channel_evaluation", "(", "self", ",", "pretrained_base_model", "=", "None", ")", ":", "\n", "        ", "print", "(", "'get weighting_feature_map'", ")", "\n", "\n", "print", "(", "'loading %s data set'", "%", "(", "self", ".", "data_set_name", ")", ")", "\n", "self", ".", "data_loader", ",", "self", ".", "data_loader_test", "=", "self", ".", "load_data_set", "(", "self", ".", "data_set_name", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "print", "(", "'data loader len: %d'", "%", "(", "len", "(", "self", ".", "data_loader", ")", ")", ")", "\n", "\n", "# set feature extractor", "\n", "print", "(", "pretrained_base_model", ")", "\n", "self", ".", "feature_extractor", "=", "Feature_Extractor", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "pretrained_base_model", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_extractor", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "param", "in", "self", ".", "feature_extractor", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "feature_extractor", ".", "eval", "(", ")", "\n", "\n", "# set extractor hook for feature map", "\n", "if", "self", ".", "base_model_name", "==", "'vgg'", ":", "\n", "            ", "self", ".", "layer_name_extractor", "=", "'model.2'", "# (64 in, 64 out)", "\n", "", "elif", "self", ".", "base_model_name", "==", "'resnet'", ":", "\n", "            ", "self", ".", "layer_name_extractor", "=", "'model.4.2.conv3'", "# (64 in, 256 out)", "\n", "", "elif", "self", ".", "base_model_name", "==", "'lenet'", ":", "\n", "            ", "self", ".", "layer_name_extractor", "=", "'model.0'", "# (6 in, 16 out)", "\n", "\n", "# set feature classifier", "\n", "", "self", ".", "feature_classifier", "=", "Feature_Classifier", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "pretrained_base_model", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_classifier", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "if", "self", ".", "base_model_name", "==", "'resnet'", "or", "(", "self", ".", "base_model_name", "==", "'vgg'", "and", "pretrained_base_model", "is", "None", ")", ":", "\n", "            ", "self", ".", "feature_classifer", "=", "self", ".", "train_fc", "(", "self", ".", "feature_extractor", ",", "self", ".", "feature_classifier", ")", "\n", "\n", "", "for", "param", "in", "self", ".", "feature_classifier", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "self", ".", "feature_classifier", ".", "eval", "(", ")", "\n", "\n", "# calculate weighting source extractor feature maps", "\n", "base_loss_extractor", ",", "jthfilter_loss_extractor", ",", "class_label_list", "=", "self", ".", "calculate_weighting_feature_maps_extractor", "(", "self", ".", "feature_extractor", ",", "\n", "self", ".", "feature_classifier", ",", "layer_name", "=", "self", ".", "layer_name_extractor", ",", "label_min", "=", "10", ")", "\n", "extractor_number_filter", "=", "len", "(", "jthfilter_loss_extractor", ")", "\n", "\n", "wj_extractor", "=", "np", ".", "zeros", "(", "(", "extractor_number_filter", ",", "len", "(", "base_loss_extractor", ")", ")", ")", "\n", "base_loss_extractor", "=", "np", ".", "array", "(", "base_loss_extractor", ")", "\n", "print", "(", "wj_extractor", ".", "shape", ",", "base_loss_extractor", ".", "shape", ")", "\n", "\n", "for", "fidx", "in", "range", "(", "extractor_number_filter", ")", ":", "\n", "            ", "wj_extractor", "[", "fidx", "]", "=", "base_loss_extractor", "-", "np", ".", "array", "(", "jthfilter_loss_extractor", "[", "fidx", "]", ")", "\n", "\n", "", "transpose_wj_extractor", "=", "np", ".", "transpose", "(", "wj_extractor", ")", "\n", "print", "(", "transpose_wj_extractor", ".", "shape", ")", "\n", "np", ".", "save", "(", "self", ".", "transpose_wj_extractor_npy", ",", "transpose_wj_extractor", ".", "mean", "(", "axis", "=", "0", ")", ")", "\n", "\n", "with", "open", "(", "self", ".", "wj_extractor_file", ",", "'w'", ")", "as", "wj_list", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "wj_list", ",", "delimiter", "=", "','", ",", "quoting", "=", "csv", ".", "QUOTE_ALL", ")", "\n", "for", "t", "in", "range", "(", "transpose_wj_extractor", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "def", "softmax_loss", "(", "loss", ")", ":", "\n", "                    ", "max_loss", "=", "np", ".", "max", "(", "loss", ")", "\n", "exp_loss", "=", "np", ".", "exp", "(", "loss", "-", "max_loss", ")", "\n", "sum_exp_loss", "=", "np", ".", "sum", "(", "exp_loss", ")", "\n", "result", "=", "exp_loss", "/", "sum_exp_loss", "\n", "return", "result", "\n", "\n", "", "transpose_wj_extractor", "[", "t", "]", "=", "softmax_loss", "(", "transpose_wj_extractor", "[", "t", "]", ")", "\n", "writer", ".", "writerow", "(", "list", "(", "transpose_wj_extractor", "[", "t", "]", ")", ")", "\n", "\n", "# initialize attention for feature generator      ", "\n", "", "", "self", ".", "generator_attention", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_labels", ",", "self", ".", "feature_dimension", ")", ")", "\n", "labels_count", "=", "np", ".", "zeros", "(", "self", ".", "num_labels", ")", "\n", "iCnt", "=", "0", "\n", "for", "class_num", "in", "class_label_list", ":", "\n", "            ", "class_num", "=", "class_num", ".", "item", "(", ")", "\n", "self", ".", "generator_attention", "[", "class_num", ",", ":", "]", "=", "1.0", "*", "(", "self", ".", "generator_attention", "[", "class_num", ",", ":", "]", "*", "labels_count", "[", "class_num", "]", "+", "transpose_wj_extractor", "[", "iCnt", ",", ":", "]", ")", "/", "(", "labels_count", "[", "class_num", "]", "+", "1", ")", "\n", "labels_count", "[", "class_num", "]", "+=", "1", "\n", "iCnt", "+=", "1", "\n", "\n", "", "np", ".", "save", "(", "self", ".", "generator_attention_npy", ",", "self", ".", "generator_attention", ")", "\n", "\n", "# save_generator_attention", "\n", "for", "filter_idx", "in", "range", "(", "self", ".", "generator_attention", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "filename", "=", "self", ".", "csv_save_path", "+", "\"/\"", "+", "\"generator_attention_\"", "+", "str", "(", "filter_idx", ")", "+", "\"_\"", "+", "self", ".", "curtime", "+", "\".csv\"", "\n", "with", "open", "(", "filename", ",", "'a'", ")", "as", "generator_attention_save", ":", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "generator_attention_save", ",", "delimiter", "=", "','", ",", "quoting", "=", "csv", ".", "QUOTE_ALL", ")", "\n", "writer", ".", "writerow", "(", "list", "(", "self", ".", "generator_attention", "[", ":", ",", "filter_idx", "]", ")", ")", "\n", "\n", "# set classifier hook for feature map", "\n", "", "", "if", "self", ".", "base_model_name", "==", "'vgg'", ":", "\n", "            ", "self", ".", "layer_name_classifier", "=", "[", "'feature.23'", "]", "# (512 in, 512 out)", "\n", "", "elif", "self", ".", "base_model_name", "==", "'resnet'", ":", "\n", "            ", "self", ".", "layer_name_classifier", "=", "[", "'feature.0.3.conv3'", ",", "'feature.1.5.conv3'", ",", "'feature.2.2.conv3'", "]", "# (512 in, 2048 out)", "\n", "", "elif", "self", ".", "base_model_name", "==", "'lenet'", ":", "\n", "            ", "self", ".", "layer_name_classifier", "=", "[", "'feature.0'", "]", "# (6 in, 16 out)", "\n", "\n", "# calculate weighting source classifier feature maps", "\n", "", "self", ".", "calculate_weighting_feature_maps_classifier", "(", "self", ".", "feature_extractor", ",", "\n", "self", ".", "feature_classifier", ",", "layer_name", "=", "self", ".", "layer_name_classifier", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.flatten_outputs": [[487, 489], ["torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape", "torch.reshape"], "methods", ["None"], ["", "def", "flatten_outputs", "(", "self", ",", "fea", ")", ":", "\n", "        ", "return", "torch", ".", "reshape", "(", "fea", ",", "(", "fea", ".", "shape", "[", "0", "]", ",", "fea", ".", "shape", "[", "1", "]", ",", "fea", ".", "shape", "[", "2", "]", "*", "fea", ".", "shape", "[", "3", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.extractor_att_fea_map": [[490, 501], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "train.TrainOps.flatten_outputs", "train.TrainOps.flatten_outputs", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "train.TrainOps.detach", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.flatten_outputs", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.flatten_outputs"], ["", "def", "extractor_att_fea_map", "(", "self", ",", "fm_src", ",", "fm_tgt", ")", ":", "\n", "        ", "fea_loss", "=", "torch", ".", "tensor", "(", "0.", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "b", ",", "c", ",", "h", ",", "w", "=", "fm_src", ".", "shape", "\n", "fm_src", "=", "self", ".", "flatten_outputs", "(", "fm_src", ")", "\n", "fm_tgt", "=", "self", ".", "flatten_outputs", "(", "fm_tgt", ")", "\n", "div_norm", "=", "h", "*", "w", "\n", "distance", "=", "torch", ".", "norm", "(", "fm_tgt", "-", "fm_src", ".", "detach", "(", ")", ",", "2", ",", "2", ")", "\n", "distance", "=", "c", "*", "torch", ".", "mul", "(", "self", ".", "extractor_channel_weights", ",", "distance", "**", "2", ")", "/", "(", "h", "*", "w", ")", "\n", "fea_loss", "+=", "0.5", "*", "torch", ".", "sum", "(", "distance", ")", "\n", "return", "fea_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.reg_att_fea_map": [[502, 514], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "enumerate", "zip", "train.TrainOps.flatten_outputs", "train.TrainOps.flatten_outputs", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "train.TrainOps.detach", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul", "torch.mul"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.flatten_outputs", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.flatten_outputs"], ["", "def", "reg_att_fea_map", "(", "self", ")", ":", "\n", "        ", "fea_loss", "=", "torch", ".", "tensor", "(", "0.", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "for", "i", ",", "(", "fm_src", ",", "fm_tgt", ")", "in", "enumerate", "(", "zip", "(", "self", ".", "layer_outputs_source", ",", "self", ".", "layer_outputs_target", ")", ")", ":", "\n", "            ", "b", ",", "c", ",", "h", ",", "w", "=", "fm_src", ".", "shape", "\n", "fm_src", "=", "self", ".", "flatten_outputs", "(", "fm_src", ")", "\n", "fm_tgt", "=", "self", ".", "flatten_outputs", "(", "fm_tgt", ")", "\n", "div_norm", "=", "h", "*", "w", "\n", "distance", "=", "torch", ".", "norm", "(", "fm_tgt", "-", "fm_src", ".", "detach", "(", ")", ",", "2", ",", "2", ")", "\n", "distance", "=", "c", "*", "torch", ".", "mul", "(", "self", ".", "channel_weights", "[", "i", "]", ",", "distance", "**", "2", ")", "/", "(", "h", "*", "w", ")", "\n", "fea_loss", "+=", "0.5", "*", "torch", ".", "sum", "(", "distance", ")", "\n", "", "return", "fea_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.reg_classifier": [[515, 521], ["torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "torch.tensor().to", "train.TrainOps.feature_classifier_target.named_parameters", "name.startswith", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "methods", ["None"], ["", "def", "reg_classifier", "(", "self", ")", ":", "\n", "        ", "l2_cls", "=", "torch", ".", "tensor", "(", "0.", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "for", "name", ",", "param", "in", "self", ".", "feature_classifier_target", ".", "named_parameters", "(", ")", ":", "\n", "            ", "if", "name", ".", "startswith", "(", "self", ".", "fc", ")", ":", "\n", "                ", "l2_cls", "+=", "0.5", "*", "torch", ".", "norm", "(", "param", ")", "**", "2", "\n", "", "", "return", "l2_cls", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.compute_gradient_penalty": [[523, 542], ["torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "torch.FloatTensor().to", "D", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "torch.autograd.Variable().to", "torch.grad", "torch.grad", "torch.grad", "torch.grad", "torch.grad", "gradients.view", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "gradients.size", "numpy.random.random", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "gradients.norm", "real_samples.size", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "compute_gradient_penalty", "(", "self", ",", "D", ",", "real_samples", ",", "fake_samples", ")", ":", "\n", "# Random weight term for interpolation between real and fake samples", "\n", "        ", "alpha", "=", "torch", ".", "FloatTensor", "(", "np", ".", "random", ".", "random", "(", "(", "real_samples", ".", "size", "(", "0", ")", ",", "1", ",", "1", ",", "1", ")", ")", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Get random interpolation between real and fake samples", "\n", "interpolates", "=", "(", "alpha", "*", "real_samples", "+", "(", "(", "1", "-", "alpha", ")", "*", "fake_samples", ")", ")", ".", "requires_grad_", "(", "True", ")", "\n", "d_interpolates", "=", "D", "(", "interpolates", ")", "\n", "fake", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "real_samples", ".", "shape", "[", "0", "]", ",", "1", ")", ".", "fill_", "(", "1.0", ")", ",", "requires_grad", "=", "False", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "# Get gradient w.r.t. interpolates", "\n", "gradients", "=", "autograd", ".", "grad", "(", "\n", "outputs", "=", "d_interpolates", ",", "\n", "inputs", "=", "interpolates", ",", "\n", "grad_outputs", "=", "fake", ",", "\n", "create_graph", "=", "True", ",", "\n", "retain_graph", "=", "True", ",", "\n", "only_inputs", "=", "True", ",", "\n", ")", "[", "0", "]", "\n", "gradients", "=", "gradients", ".", "view", "(", "gradients", ".", "size", "(", "0", ")", ",", "-", "1", ")", "+", "1e-16", "\n", "gradient_penalty", "=", "(", "(", "gradients", ".", "norm", "(", "2", ",", "dim", "=", "1", ")", "-", "1", ")", "**", "2", ")", ".", "mean", "(", ")", "\n", "return", "gradient_penalty", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_discriminator": [[543, 572], ["train.TrainOps.feature_discriminator.requires_grad_", "train.TrainOps.feature_extractor_target.requires_grad_", "train.TrainOps.feature_classifier_target.requires_grad_", "train.TrainOps.feature_generator.requires_grad_", "discriminator_loss.item", "utils.z_sampler", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "bz_input.to.to.to", "einsum.to.to.to", "train.TrainOps.feature_generator", "train.TrainOps.feature_extractor_target", "train.TrainOps.feature_discriminator", "train.TrainOps.feature_discriminator", "train.TrainOps.discriminator_optimizer.zero_grad", "train.TrainOps.compute_gradient_penalty", "discriminator_loss.backward", "train.TrainOps.discriminator_optimizer.step", "numpy.concatenate", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.utils.z_sampler", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.compute_gradient_penalty"], ["", "def", "train_discriminator", "(", "self", ")", ":", "\n", "        ", "self", ".", "feature_discriminator", ".", "requires_grad_", "(", "True", ")", "\n", "self", ".", "feature_extractor_target", ".", "requires_grad_", "(", "False", ")", "\n", "self", ".", "feature_classifier_target", ".", "requires_grad_", "(", "False", ")", "\n", "self", ".", "feature_generator", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "for", "inputs_tmp", "in", "self", ".", "inputs_gpu", ":", "\n", "            ", "bz_rand", ",", "bz_cat", ",", "_", "=", "utils", ".", "z_sampler", "(", "self", ".", "batch_size", ",", "self", ".", "noise_dim", ",", "self", ".", "num_labels", ")", "# (batch, noise_dim), (batch, num_labels)", "\n", "bz_input", "=", "torch", ".", "FloatTensor", "(", "np", ".", "concatenate", "(", "(", "bz_rand", ",", "bz_cat", ")", ",", "axis", "=", "1", ")", ")", "# (batch, noise_dim + num_labels)", "\n", "bz_cat", "=", "torch", ".", "FloatTensor", "(", "bz_cat", ")", "\n", "einsum", "=", "torch", ".", "matmul", "(", "bz_cat", ",", "self", ".", "generator_attention", ")", "# (batch, feature_dimension)", "\n", "\n", "bz_input", "=", "bz_input", ".", "to", "(", "self", ".", "device", ")", "\n", "einsum", "=", "einsum", ".", "to", "(", "self", ".", "device", ")", "\n", "generated_feature", "=", "self", ".", "feature_generator", "(", "bz_input", ",", "einsum", ")", "\n", "\n", "extracted_feature", "=", "self", ".", "feature_extractor_target", "(", "inputs_tmp", ")", "\n", "\n", "logits_fake", "=", "self", ".", "feature_discriminator", "(", "generated_feature", ")", "\n", "logits_real", "=", "self", ".", "feature_discriminator", "(", "extracted_feature", ")", "\n", "\n", "self", ".", "discriminator_optimizer", ".", "zero_grad", "(", ")", "\n", "# wgan gp", "\n", "gradient_penalty", "=", "self", ".", "compute_gradient_penalty", "(", "self", ".", "feature_discriminator", ",", "extracted_feature", ",", "generated_feature", ")", "\n", "discriminator_loss", "=", "-", "torch", ".", "mean", "(", "logits_real", ")", "+", "torch", ".", "mean", "(", "logits_fake", ")", "+", "self", ".", "lambda_gp", "*", "gradient_penalty", "\n", "discriminator_loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "discriminator_optimizer", ".", "step", "(", ")", "\n", "", "return", "discriminator_loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_generator": [[573, 595], ["train.TrainOps.feature_discriminator.requires_grad_", "train.TrainOps.feature_generator.requires_grad_", "utils.z_sampler", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "bz_input.to.to.to", "einsum.to.to.to", "train.TrainOps.feature_generator", "train.TrainOps.feature_discriminator", "train.TrainOps.generator_optimizer.zero_grad", "generator_loss.backward", "train.TrainOps.generator_optimizer.step", "generator_loss.item", "numpy.concatenate", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean", "torch.mean"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.utils.z_sampler"], ["", "def", "train_generator", "(", "self", ")", ":", "\n", "        ", "self", ".", "feature_discriminator", ".", "requires_grad_", "(", "False", ")", "\n", "self", ".", "feature_generator", ".", "requires_grad_", "(", "True", ")", "\n", "\n", "bz_rand", ",", "bz_cat", ",", "_", "=", "utils", ".", "z_sampler", "(", "self", ".", "batch_size", ",", "self", ".", "noise_dim", ",", "self", ".", "num_labels", ")", "# (batch, noise_dim), (batch, num_labels)", "\n", "bz_input", "=", "torch", ".", "FloatTensor", "(", "np", ".", "concatenate", "(", "(", "bz_rand", ",", "bz_cat", ")", ",", "axis", "=", "1", ")", ")", "# (batch, noise_dim + num_labels)", "\n", "bz_cat", "=", "torch", ".", "FloatTensor", "(", "bz_cat", ")", "\n", "einsum", "=", "torch", ".", "matmul", "(", "bz_cat", ",", "self", ".", "generator_attention", ")", "# (batch, feature_dimension)", "\n", "\n", "bz_input", "=", "bz_input", ".", "to", "(", "self", ".", "device", ")", "\n", "einsum", "=", "einsum", ".", "to", "(", "self", ".", "device", ")", "\n", "generated_feature", "=", "self", ".", "feature_generator", "(", "bz_input", ",", "einsum", ")", "\n", "\n", "logits_fake", "=", "self", ".", "feature_discriminator", "(", "generated_feature", ")", "\n", "\n", "self", ".", "generator_optimizer", ".", "zero_grad", "(", ")", "\n", "# wgan gp", "\n", "generator_loss", "=", "-", "torch", ".", "mean", "(", "logits_fake", ")", "\n", "generator_loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "generator_optimizer", ".", "step", "(", ")", "\n", "return", "generator_loss", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_generator_with_fake_feature": [[596, 621], ["utils.z_sampler", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "bz_input.to.to.to", "einsum.to.to.to", "train.TrainOps.feature_generator", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "train.TrainOps.feature_extractor_target", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.TrainOps.generator_optimizer.zero_grad", "train.TrainOps.feature_classifier_target", "train.TrainOps.criterion", "train.TrainOps.backward", "train.TrainOps.generator_optimizer.step", "numpy.concatenate", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.utils.z_sampler"], ["", "def", "train_generator_with_fake_feature", "(", "self", ")", ":", "\n", "        ", "bz_rand", ",", "bz_cat", ",", "fake_labels", "=", "utils", ".", "z_sampler", "(", "self", ".", "batch_size", ",", "self", ".", "noise_dim", ",", "self", ".", "num_labels", ")", "# (batch, noise_dim), (batch, num_labels)", "\n", "bz_input", "=", "torch", ".", "FloatTensor", "(", "np", ".", "concatenate", "(", "(", "bz_rand", ",", "bz_cat", ")", ",", "axis", "=", "1", ")", ")", "# (batch, noise_dim + num_labels)", "\n", "bz_cat", "=", "torch", ".", "FloatTensor", "(", "bz_cat", ")", "\n", "einsum", "=", "torch", ".", "matmul", "(", "bz_cat", ",", "self", ".", "generator_attention", ")", "# (batch, feature_dimension)", "\n", "\n", "bz_input", "=", "bz_input", ".", "to", "(", "self", ".", "device", ")", "\n", "einsum", "=", "einsum", ".", "to", "(", "self", ".", "device", ")", "\n", "generated_feature", "=", "self", ".", "feature_generator", "(", "bz_input", ",", "einsum", ")", "\n", "fake_labels", "=", "torch", ".", "LongTensor", "(", "fake_labels", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "extracted_feature", "=", "self", ".", "feature_extractor_target", "(", "self", ".", "inputs_gpu", "[", "0", "]", ")", "\n", "\n", "# merge gen, real feature", "\n", "merged_feature", "=", "torch", ".", "cat", "(", "(", "generated_feature", ",", "extracted_feature", ")", ",", "dim", "=", "0", ")", "# batch size * 2", "\n", "merged_labels", "=", "torch", ".", "cat", "(", "(", "fake_labels", ",", "self", ".", "labels_gpu", "[", "0", "]", ")", ",", "dim", "=", "0", ")", "\n", "\n", "self", ".", "generator_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "# predict fake feature", "\n", "c_logits_merged", "=", "self", ".", "feature_classifier_target", "(", "merged_feature", ")", "\n", "c_loss_merged", "=", "self", ".", "criterion", "(", "c_logits_merged", ",", "merged_labels", ")", "\n", "c_loss_merged", ".", "backward", "(", ")", "\n", "\n", "self", ".", "generator_optimizer", ".", "step", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_extractor_classifier": [[622, 672], ["train.TrainOps.feature_extractor_target.requires_grad_", "train.TrainOps.feature_classifier_target.requires_grad_", "train.TrainOps.feature_generator.requires_grad_", "train.TrainOps.feature_extractor_target", "train.TrainOps.feature_classifier_target", "train.TrainOps.criterion", "train.TrainOps.feature_extractor_source", "train.TrainOps.classifier_optimizer.zero_grad", "train.TrainOps.extractor_optimizer.zero_grad", "loss.backward", "train.TrainOps.extractor_optimizer.step", "train.TrainOps.classifier_optimizer.step", "train.TrainOps.layer_outputs_target.clear", "train.TrainOps.layer_outputs_source.clear", "train.TrainOps.extractor_att_fea_map", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "train.TrainOps.feature_classifier_source", "train.TrainOps.reg_att_fea_map", "train.TrainOps.reg_classifier", "e_loss.item", "c_loss_real.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.extractor_att_fea_map", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.reg_att_fea_map", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.reg_classifier"], ["", "def", "train_extractor_classifier", "(", "self", ")", ":", "\n", "        ", "self", ".", "feature_extractor_target", ".", "requires_grad_", "(", "True", ")", "\n", "self", ".", "feature_classifier_target", ".", "requires_grad_", "(", "True", ")", "\n", "self", ".", "feature_generator", ".", "requires_grad_", "(", "False", ")", "\n", "\n", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "self", ".", "layer_outputs_target", ".", "clear", "(", ")", "\n", "self", ".", "layer_outputs_source", ".", "clear", "(", ")", "\n", "\n", "# Feature Extractor by using Regularization", "\n", "", "extracted_feature_target", "=", "self", ".", "feature_extractor_target", "(", "self", ".", "inputs_gpu", "[", "0", "]", ")", "\n", "e_c_loss", "=", "self", ".", "feature_classifier_target", "(", "extracted_feature_target", ")", "\n", "e_c_loss", "=", "self", ".", "criterion", "(", "e_c_loss", ",", "self", ".", "labels_gpu", "[", "0", "]", ")", "\n", "\n", "extracted_feature_source", "=", "self", ".", "feature_extractor_source", "(", "self", ".", "inputs_gpu", "[", "0", "]", ")", "\n", "\n", "# omega1 for extractor", "\n", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "loss_extractor_feature", "=", "self", ".", "extractor_att_fea_map", "(", "extracted_feature_source", ",", "extracted_feature_target", ")", "\n", "e_loss", "=", "e_c_loss", "+", "self", ".", "alpha_extractor", "*", "loss_extractor_feature", "\n", "", "else", ":", "\n", "            ", "e_loss", "=", "e_c_loss", "\n", "loss_extractor_feature", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "# Feature Classifier by using Regularization", "\n", "# for hook layer", "\n", "", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "self", ".", "feature_classifier_source", "(", "extracted_feature_source", ")", "\n", "\n", "# omega1, omega2 for classifier", "\n", "", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "loss_feature", "=", "self", ".", "reg_att_fea_map", "(", ")", "\n", "loss_classifier", "=", "self", ".", "reg_classifier", "(", ")", "\n", "c_loss_real", "=", "e_c_loss", "+", "self", ".", "alpha_classifier", "*", "loss_feature", "+", "self", ".", "beta_classifier", "*", "loss_classifier", "\n", "", "else", ":", "\n", "            ", "c_loss_real", "=", "e_c_loss", "\n", "\n", "", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "loss", "=", "e_loss", "+", "c_loss_real", "\n", "", "else", ":", "\n", "            ", "loss", "=", "e_c_loss", "\n", "\n", "", "self", ".", "classifier_optimizer", ".", "zero_grad", "(", ")", "\n", "self", ".", "extractor_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "extractor_optimizer", ".", "step", "(", ")", "\n", "self", ".", "classifier_optimizer", ".", "step", "(", ")", "\n", "return", "e_loss", ".", "item", "(", ")", ",", "c_loss_real", ".", "item", "(", ")", ",", "loss_extractor_feature", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_classifier_with_fake": [[673, 725], ["train.TrainOps.feature_extractor_target", "train.TrainOps.feature_classifier_target", "train.TrainOps.criterion", "utils.z_sampler", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "torch.matmul", "bz_input.to.to.to", "einsum.to.to.to", "train.TrainOps.feature_generator", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "torch.LongTensor().to", "train.TrainOps.feature_classifier_target", "train.TrainOps.criterion", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "train.TrainOps.feature_classifier_target", "train.TrainOps.criterion", "train.TrainOps.classifier_optimizer.zero_grad", "c_loss.backward", "train.TrainOps.classifier_optimizer.step", "train.TrainOps.layer_outputs_target.clear", "train.TrainOps.layer_outputs_source.clear", "numpy.concatenate", "train.TrainOps.feature_extractor_source", "train.TrainOps.feature_classifier_source", "train.TrainOps.reg_att_fea_map", "train.TrainOps.reg_classifier", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "c_loss.item", "train.TrainOps.item", "train.TrainOps.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "torch.zeros.item", "train.TrainOps.item", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.utils.z_sampler", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.reg_att_fea_map", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.reg_classifier"], ["", "def", "train_classifier_with_fake", "(", "self", ")", ":", "\n", "        ", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "self", ".", "layer_outputs_target", ".", "clear", "(", ")", "\n", "self", ".", "layer_outputs_source", ".", "clear", "(", ")", "\n", "\n", "# Feature Extractor", "\n", "", "extracted_feature_target", "=", "self", ".", "feature_extractor_target", "(", "self", ".", "inputs_gpu", "[", "0", "]", ")", "\n", "e_c_logit_real", "=", "self", ".", "feature_classifier_target", "(", "extracted_feature_target", ")", "\n", "e_c_loss_real", "=", "self", ".", "criterion", "(", "e_c_logit_real", ",", "self", ".", "labels_gpu", "[", "0", "]", ")", "\n", "\n", "# Feature Classifier by using Regularization", "\n", "bz_rand", ",", "bz_cat", ",", "fake_labels", "=", "utils", ".", "z_sampler", "(", "self", ".", "batch_size", ",", "self", ".", "noise_dim", ",", "self", ".", "num_labels", ")", "# (batch, noise_dim), (batch, num_labels)", "\n", "bz_input", "=", "torch", ".", "FloatTensor", "(", "np", ".", "concatenate", "(", "(", "bz_rand", ",", "bz_cat", ")", ",", "axis", "=", "1", ")", ")", "# (batch, noise_dim + num_labels)", "\n", "bz_cat", "=", "torch", ".", "FloatTensor", "(", "bz_cat", ")", "\n", "einsum", "=", "torch", ".", "matmul", "(", "bz_cat", ",", "self", ".", "generator_attention", ")", "# (batch, feature_dimension)", "\n", "\n", "bz_input", "=", "bz_input", ".", "to", "(", "self", ".", "device", ")", "\n", "einsum", "=", "einsum", ".", "to", "(", "self", ".", "device", ")", "\n", "generated_feature", "=", "self", ".", "feature_generator", "(", "bz_input", ",", "einsum", ")", "\n", "\n", "fake_labels", "=", "torch", ".", "LongTensor", "(", "fake_labels", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "e_c_logits_fake", "=", "self", ".", "feature_classifier_target", "(", "generated_feature", ")", "\n", "e_c_loss_fake", "=", "self", ".", "criterion", "(", "e_c_logits_fake", ",", "fake_labels", ")", "\n", "\n", "merged_feature", "=", "torch", ".", "cat", "(", "(", "generated_feature", ",", "extracted_feature_target", ")", ",", "dim", "=", "0", ")", "# batch size * 2", "\n", "merged_labels", "=", "torch", ".", "cat", "(", "(", "fake_labels", ",", "self", ".", "labels_gpu", "[", "0", "]", ")", ",", "dim", "=", "0", ")", "\n", "\n", "c_logits_merged", "=", "self", ".", "feature_classifier_target", "(", "merged_feature", ")", "\n", "c_loss_merged", "=", "self", ".", "criterion", "(", "c_logits_merged", ",", "merged_labels", ")", "\n", "\n", "# for hook layer", "\n", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "extracted_feature_source", "=", "self", ".", "feature_extractor_source", "(", "self", ".", "inputs_gpu", "[", "0", "]", ")", "\n", "self", ".", "feature_classifier_source", "(", "extracted_feature_source", ")", "\n", "\n", "# omega1, omega2 for classifier", "\n", "loss_feature", "=", "self", ".", "reg_att_fea_map", "(", ")", "\n", "loss_classifier", "=", "self", ".", "reg_classifier", "(", ")", "\n", "e_c_loss_real", "=", "e_c_loss_real", "+", "self", ".", "alpha_classifier", "*", "loss_feature", "+", "self", ".", "beta_classifier", "*", "loss_classifier", "\n", "", "else", ":", "\n", "            ", "loss_feature", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "loss_classifier", "=", "torch", ".", "zeros", "(", "1", ")", "\n", "\n", "", "c_loss", "=", "1.0", "/", "3.0", "*", "e_c_loss_real", "+", "1.0", "/", "3.0", "*", "e_c_loss_fake", "+", "1.0", "/", "3.0", "*", "c_loss_merged", "\n", "\n", "self", ".", "classifier_optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "c_loss", ".", "backward", "(", ")", "\n", "\n", "self", ".", "classifier_optimizer", ".", "step", "(", ")", "\n", "\n", "return", "c_loss", ".", "item", "(", ")", ",", "e_c_loss_real", ".", "item", "(", ")", ",", "e_c_loss_fake", ".", "item", "(", ")", ",", "loss_feature", ".", "item", "(", ")", ",", "loss_classifier", ".", "item", "(", ")", ",", "c_loss_merged", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.update_generator_attention": [[726, 783], ["train.TrainOps.calculate_weighting_feature_maps_extractor", "len", "numpy.zeros", "print", "numpy.array", "range", "numpy.transpose", "range", "numpy.zeros", "numpy.zeros", "range", "range", "print", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "train.TrainOps.channel_evaluation.softmax_loss"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.calculate_weighting_feature_maps_extractor"], ["", "def", "update_generator_attention", "(", "self", ",", "feature_extractor_target", ",", "feature_classifier_target", ",", "layer_name_extractor", ")", ":", "\n", "# Calculate weighting feature maps for extractor", "\n", "        ", "base_loss_extractor", ",", "jthfilter_loss_extractor", ",", "class_label_list", "=", "self", ".", "calculate_weighting_feature_maps_extractor", "(", "feature_extractor_target", ",", "feature_classifier_target", ",", "\n", "layer_name", "=", "layer_name_extractor", ",", "label_min", "=", "10", ")", "\n", "\n", "extractor_number_filter", "=", "len", "(", "jthfilter_loss_extractor", ")", "\n", "wj_extractor", "=", "np", ".", "zeros", "(", "(", "extractor_number_filter", ",", "len", "(", "base_loss_extractor", ")", ")", ")", "\n", "print", "(", "wj_extractor", ".", "shape", ")", "\n", "base_loss_extractor", "=", "np", ".", "array", "(", "base_loss_extractor", ")", "\n", "\n", "for", "fidx", "in", "range", "(", "extractor_number_filter", ")", ":", "\n", "            ", "wj_extractor", "[", "fidx", "]", "=", "base_loss_extractor", "-", "np", ".", "array", "(", "jthfilter_loss_extractor", "[", "fidx", "]", ")", "\n", "\n", "", "transpose_wj_extractor", "=", "np", ".", "transpose", "(", "wj_extractor", ")", "\n", "for", "t", "in", "range", "(", "transpose_wj_extractor", ".", "shape", "[", "0", "]", ")", ":", "\n", "            ", "def", "softmax_loss", "(", "loss", ")", ":", "\n", "                ", "max_loss", "=", "np", ".", "max", "(", "loss", ")", "\n", "exp_loss", "=", "np", ".", "exp", "(", "loss", "-", "max_loss", ")", "\n", "sum_exp_loss", "=", "np", ".", "sum", "(", "exp_loss", ")", "\n", "result", "=", "exp_loss", "/", "sum_exp_loss", "\n", "return", "result", "\n", "", "transpose_wj_extractor", "[", "t", "]", "=", "softmax_loss", "(", "transpose_wj_extractor", "[", "t", "]", ")", "\n", "\n", "#Initialize Attention for feature generator", "\n", "", "target_generator_attention", "=", "np", ".", "zeros", "(", "(", "self", ".", "num_labels", ",", "self", ".", "feature_dimension", ")", ")", "\n", "labels_count", "=", "np", ".", "zeros", "(", "self", ".", "num_labels", ")", "\n", "iCnt", "=", "0", "\n", "for", "class_num", "in", "class_label_list", ":", "\n", "            ", "class_num", "=", "class_num", ".", "item", "(", ")", "\n", "target_generator_attention", "[", "class_num", ",", ":", "]", "=", "1.0", "*", "(", "target_generator_attention", "[", "class_num", ",", ":", "]", "*", "labels_count", "[", "class_num", "]", "+", "transpose_wj_extractor", "[", "iCnt", ",", ":", "]", ")", "/", "(", "labels_count", "[", "class_num", "]", "+", "1", ")", "\n", "labels_count", "[", "class_num", "]", "+=", "1", "\n", "iCnt", "+=", "1", "\n", "\n", "", "generator_attention_np", "=", "self", ".", "rho", "*", "self", ".", "generator_attention", ".", "numpy", "(", ")", "+", "(", "1", "-", "self", ".", "rho", ")", "*", "target_generator_attention", "\n", "\n", "#save_generator_attention", "\n", "for", "filter_idx", "in", "range", "(", "generator_attention_np", ".", "shape", "[", "1", "]", ")", ":", "\n", "            ", "filename", "=", "self", ".", "csv_save_path", "+", "\"/\"", "+", "\"generator_attention_\"", "+", "str", "(", "filter_idx", ")", "+", "\"_\"", "+", "self", ".", "curtime", "+", "\".csv\"", "\n", "with", "open", "(", "filename", ",", "'a'", ")", "as", "generator_attention_save", ":", "\n", "                ", "writer", "=", "csv", ".", "writer", "(", "generator_attention_save", ",", "delimiter", "=", "','", ",", "quoting", "=", "csv", ".", "QUOTE_ALL", ")", "\n", "writer", ".", "writerow", "(", "list", "(", "generator_attention_np", "[", ":", ",", "filter_idx", "]", ")", ")", "\n", "\n", "", "", "generator_attention_np", "=", "target_generator_attention", "*", "self", ".", "feature_dimension", "\n", "\n", "for", "class_label", "in", "range", "(", "self", ".", "num_labels", ")", ":", "\n", "            ", "generator_attention_np", "[", "class_label", ",", ":", "]", "=", "np", ".", "where", "(", "generator_attention_np", "[", "class_label", ",", ":", "]", ">=", "0.95", ",", "generator_attention_np", "[", "class_label", ",", ":", "]", "/", "self", ".", "feature_dimension", ",", "0.0", ")", "\n", "\n", "# write number of zero generator attention per class", "\n", "", "with", "open", "(", "self", ".", "generator_attention_class", ",", "'a'", ")", "as", "wj_list", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "wj_list", ",", "delimiter", "=", "','", ",", "quoting", "=", "csv", ".", "QUOTE_ALL", ")", "\n", "zero_generator_attention_list", "=", "[", "]", "\n", "for", "t", "in", "range", "(", "generator_attention_np", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "zero_generator_attention_list", ".", "append", "(", "len", "(", "generator_attention_np", "[", "t", "]", "[", "generator_attention_np", "[", "t", "]", "==", "0", "]", ")", ")", "\n", "", "writer", ".", "writerow", "(", "zero_generator_attention_list", ")", "\n", "\n", "", "print", "(", "len", "(", "generator_attention_np", "[", "generator_attention_np", "==", "0", "]", ")", ")", "\n", "self", ".", "generator_attention", "=", "torch", ".", "FloatTensor", "(", "generator_attention_np", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.evaluate": [[784, 821], ["train.TrainOps.feature_generator.eval", "train.TrainOps.feature_extractor_target.eval", "train.TrainOps.feature_classifier_target.eval", "train.TrainOps.feature_discriminator.eval", "print", "train.TrainOps.feature_generator.train", "train.TrainOps.feature_extractor_target.train", "train.TrainOps.feature_classifier_target.train", "train.TrainOps.feature_discriminator.train", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "torch.no_grad", "inputs.to.to.to", "labels.to.to.to", "train.TrainOps.feature_extractor_target", "train.TrainOps.feature_classifier_target", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.max", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum.double", "torch.sum.double", "torch.sum.double", "torch.sum.double", "torch.sum.double", "inputs.to.to.size", "train.TrainOps.criterion().item", "inputs.to.to.size", "train.TrainOps.layer_outputs_target.clear", "train.TrainOps.layer_outputs_source.clear", "train.TrainOps.criterion"], "methods", ["None"], ["", "def", "evaluate", "(", "self", ",", "step", ",", "generator_step", ")", ":", "\n", "        ", "self", ".", "feature_generator", ".", "eval", "(", ")", "\n", "self", ".", "feature_extractor_target", ".", "eval", "(", ")", "\n", "self", ".", "feature_classifier_target", ".", "eval", "(", ")", "\n", "self", ".", "feature_discriminator", ".", "eval", "(", ")", "\n", "\n", "loss", "=", "0.0", "\n", "step_acc", "=", "0.0", "\n", "total_inputs_len", "=", "0", "\n", "with", "torch", ".", "no_grad", "(", ")", ":", "\n", "            ", "for", "inputs", ",", "labels", "in", "self", ".", "data_loader_test", ":", "\n", "                ", "inputs", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "extracted_feature", "=", "self", ".", "feature_extractor_target", "(", "inputs", ")", "\n", "logits_real", "=", "self", ".", "feature_classifier_target", "(", "extracted_feature", ")", "\n", "_", ",", "preds", "=", "torch", ".", "max", "(", "logits_real", ",", "1", ")", "\n", "loss", "+=", "self", ".", "criterion", "(", "logits_real", ",", "labels", ")", ".", "item", "(", ")", "*", "inputs", ".", "size", "(", "0", ")", "\n", "\n", "corr_sum", "=", "torch", ".", "sum", "(", "preds", "==", "labels", ".", "data", ")", "\n", "step_acc", "+=", "corr_sum", ".", "double", "(", ")", "\n", "total_inputs_len", "+=", "inputs", ".", "size", "(", "0", ")", "\n", "# gpu memory", "\n", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "                    ", "self", ".", "layer_outputs_target", ".", "clear", "(", ")", "\n", "self", ".", "layer_outputs_source", ".", "clear", "(", ")", "\n", "\n", "", "", "", "loss", "/=", "total_inputs_len", "\n", "step_acc", "/=", "total_inputs_len", "\n", "\n", "print", "(", "'Step: [%d/%d] validation loss: [%.8f] validation accuracy: [%.4f]'", "%", "(", "step", ",", "generator_step", ",", "loss", ",", "step_acc", ")", ")", "\n", "\n", "self", ".", "feature_generator", ".", "train", "(", ")", "\n", "self", ".", "feature_extractor_target", ".", "train", "(", ")", "\n", "self", ".", "feature_classifier_target", ".", "train", "(", ")", "\n", "self", ".", "feature_discriminator", ".", "train", "(", ")", "\n", "return", "loss", ",", "step_acc", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_gan": [[822, 1012], ["train.TrainOps.load_data_set", "print", "print", "print", "model.Feature_Extractor", "train.TrainOps.feature_extractor_source.requires_grad_", "train.TrainOps.feature_extractor_source.to", "train.TrainOps.feature_extractor_source.eval", "model.Feature_Classifier", "train.TrainOps.feature_classifier_source.requires_grad_", "train.TrainOps.feature_classifier_source.to", "train.TrainOps.feature_classifier_source.eval", "model.Feature_Extractor", "train.TrainOps.feature_extractor_target.to", "model.Feature_Classifier", "train.TrainOps.feature_classifier_target.to", "model.Feature_Discriminator", "train.TrainOps.feature_discriminator.to", "model.Feature_Generator", "train.TrainOps.feature_generator.to", "train.TrainOps.feature_generator.train", "train.TrainOps.feature_extractor_target.train", "train.TrainOps.feature_classifier_target.train", "train.TrainOps.feature_discriminator.train", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "torch.CrossEntropyLoss", "numpy.load", "range", "print", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "print", "range", "print", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "train.TrainOps.generator_attention.numpy", "numpy.save", "train.TrainOps.feature_discriminator.parameters", "train.TrainOps.feature_generator.parameters", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.SGD", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.lr_scheduler.StepLR", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "numpy.load", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "print", "numpy.where", "train.TrainOps.generator_attention.size", "next", "inputs.to.to.to", "labels.to.to.to", "train.TrainOps.inputs_gpu.append", "train.TrainOps.labels_gpu.append", "train.TrainOps.train_discriminator", "train.TrainOps.train_generator", "train.TrainOps.inputs_gpu.pop", "train.TrainOps.labels_gpu.pop", "next", "inputs.to.to.to", "labels.to.to.to", "train.TrainOps.inputs_gpu.append", "train.TrainOps.labels_gpu.append", "train.TrainOps.feature_extractor_target.state_dict", "train.TrainOps.feature_classifier_target.state_dict", "train.TrainOps.feature_generator.state_dict", "train.TrainOps.feature_discriminator.state_dict", "len", "len", "train.TrainOps.register_hook", "train.TrainOps.register_hook", "filter", "filter", "train.TrainOps.feature_extractor_target.parameters", "train.TrainOps.feature_classifier_target.parameters", "numpy.std", "train.TrainOps.extractor_channel_weights.size", "json.load", "iter", "train.TrainOps.train_generator_with_fake_feature", "train.TrainOps.train_extractor_classifier", "train.TrainOps.train_classifier_with_fake", "train.TrainOps.update_generator_attention", "print", "print", "train.TrainOps.evaluate", "time.time", "print", "torch.lr_scheduler.StepLR.step", "torch.lr_scheduler.StepLR.step", "iter", "train.TrainOps.register_hook", "train.TrainOps.register_hook", "train.TrainOps.feature_extractor_target.parameters", "train.TrainOps.feature_classifier_target.parameters", "int", "numpy.mean", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "open", "numpy.array", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.from_numpy().float().to", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "torch.softmax().detach", "train.TrainOps.channel_weights.append", "print", "train.TrainOps.register_hook", "train.TrainOps.register_hook", "numpy.std", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "numpy.mean", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.from_numpy().float", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.softmax", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy", "torch.from_numpy"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.load_data_set", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_discriminator", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_generator", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.register_hook", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.register_hook", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_generator_with_fake_feature", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_extractor_classifier", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.train_classifier_with_fake", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.update_generator_attention", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.evaluate", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.register_hook", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.register_hook", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.register_hook", "home.repos.pwc.inspect_result.opensuh_DFG.None.train.TrainOps.register_hook"], ["", "def", "train_gan", "(", "self", ",", "generator_step", ",", "rho", ",", "lambda_gp", ",", "alpha_extractor", ",", "\n", "alpha_classifier", ",", "beta_classifier", ",", "num_d_iters", ",", "e_loss_for_6", ",", "\n", "step_for_3_4", ",", "step_for_5", ",", "step_for_6", ",", "pretrained_base_model", ")", ":", "\n", "\n", "# Loss weight for gradient penalty", "\n", "        ", "self", ".", "rho", "=", "rho", "\n", "self", ".", "lambda_gp", "=", "lambda_gp", "\n", "self", ".", "alpha_extractor", "=", "alpha_extractor", "\n", "self", ".", "alpha_classifier", "=", "alpha_classifier", "\n", "self", ".", "beta_classifier", "=", "beta_classifier", "\n", "\n", "# start gan training", "\n", "self", ".", "data_loader", ",", "self", ".", "data_loader_test", "=", "self", ".", "load_data_set", "(", "self", ".", "data_set_name", ",", "batch_size", "=", "self", ".", "batch_size", ")", "\n", "print", "(", "'data set name: %s'", "%", "self", ".", "data_set_name", ")", "\n", "print", "(", "'train data loader len: %d'", "%", "(", "len", "(", "self", ".", "data_loader", ")", ")", ")", "\n", "print", "(", "'test data loader len: %d'", "%", "(", "len", "(", "self", ".", "data_loader_test", ")", ")", ")", "\n", "\n", "self", ".", "feature_extractor_source", "=", "Feature_Extractor", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "pretrained_base_model", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_extractor_source", ".", "requires_grad_", "(", "False", ")", "\n", "self", ".", "feature_extractor_source", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "feature_extractor_source", ".", "eval", "(", ")", "\n", "\n", "self", ".", "feature_classifier_source", "=", "Feature_Classifier", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "pretrained_base_model", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_classifier_source", ".", "requires_grad_", "(", "False", ")", "\n", "self", ".", "feature_classifier_source", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "feature_classifier_source", ".", "eval", "(", ")", "\n", "\n", "self", ".", "feature_extractor_target", "=", "Feature_Extractor", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "pretrained_base_model", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_extractor_target", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "feature_classifier_target", "=", "Feature_Classifier", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "pretrained_weight", "=", "pretrained_base_model", ",", "num_classes", "=", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_classifier_target", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "# set extractor layer name for feature map", "\n", "if", "self", ".", "base_model_name", "==", "'vgg'", ":", "\n", "            ", "self", ".", "layer_name_extractor", "=", "'model.2'", "# (64 in, 64 out)", "\n", "", "elif", "self", ".", "base_model_name", "==", "'resnet'", ":", "\n", "            ", "self", ".", "layer_name_extractor", "=", "'model.4.2.conv3'", "# (64 in, 256 out)", "\n", "", "elif", "self", ".", "base_model_name", "==", "'lenet'", ":", "\n", "            ", "self", ".", "layer_name_extractor", "=", "'model.0'", "# ( 6 in,  16 out)", "\n", "\n", "", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "# set classifier hook for feature map", "\n", "            ", "if", "self", ".", "base_model_name", "==", "'vgg'", ":", "\n", "                ", "self", ".", "layer_name_classifier", "=", "[", "'feature.23'", "]", "# (512 in, 512 out)", "\n", "self", ".", "register_hook", "(", "self", ".", "feature_classifier_source", ",", "self", ".", "for_hook_source", ",", "self", ".", "layer_name_classifier", ")", "\n", "self", ".", "register_hook", "(", "self", ".", "feature_classifier_target", ",", "self", ".", "for_hook_target", ",", "self", ".", "layer_name_classifier", ")", "\n", "", "elif", "self", ".", "base_model_name", "==", "'resnet'", ":", "\n", "                ", "self", ".", "layer_name_classifier", "=", "[", "'feature.0.3.conv3'", ",", "'feature.1.5.conv3'", ",", "'feature.2.2.conv3'", "]", "# (512 in, 2048 out)", "\n", "self", ".", "register_hook", "(", "self", ".", "feature_classifier_source", ",", "self", ".", "for_hook_source", ",", "self", ".", "layer_name_classifier", ")", "\n", "self", ".", "register_hook", "(", "self", ".", "feature_classifier_target", ",", "self", ".", "for_hook_target", ",", "self", ".", "layer_name_classifier", ")", "\n", "", "elif", "self", ".", "base_model_name", "==", "'lenet'", ":", "\n", "                ", "self", ".", "layer_name_classifier", "=", "[", "'feature.0'", "]", "# (6 in, 16 out)", "\n", "self", ".", "register_hook", "(", "self", ".", "feature_classifier_source", ",", "self", ".", "for_hook_source", ",", "self", ".", "layer_name_classifier", ")", "\n", "self", ".", "register_hook", "(", "self", ".", "feature_classifier_target", ",", "self", ".", "for_hook_target", ",", "self", ".", "layer_name_classifier", ")", "\n", "\n", "# set fc name", "\n", "", "if", "self", ".", "base_model_name", "==", "'vgg'", ":", "\n", "                ", "self", ".", "fc", "=", "'classifier.6'", "\n", "", "elif", "self", ".", "base_model_name", "==", "'resnet'", ":", "\n", "                ", "self", ".", "fc", "=", "'classifier'", "\n", "", "elif", "self", ".", "base_model_name", "==", "'lenet'", ":", "\n", "                ", "self", ".", "fc", "=", "'classifier.4'", "\n", "\n", "", "", "self", ".", "feature_discriminator", "=", "Feature_Discriminator", "(", "in_channels", "=", "self", ".", "feature_dimension", ",", "base_model_name", "=", "self", ".", "base_model_name", ")", "\n", "self", ".", "feature_discriminator", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "feature_generator", "=", "Feature_Generator", "(", "base_model_name", "=", "self", ".", "base_model_name", ",", "noise_shape", "=", "self", ".", "noise_dim", "+", "self", ".", "num_labels", ")", "\n", "self", ".", "feature_generator", ".", "to", "(", "self", ".", "device", ")", "\n", "\n", "self", ".", "feature_generator", ".", "train", "(", ")", "\n", "self", ".", "feature_extractor_target", ".", "train", "(", ")", "\n", "self", ".", "feature_classifier_target", ".", "train", "(", ")", "\n", "self", ".", "feature_discriminator", ".", "train", "(", ")", "\n", "\n", "self", ".", "discriminator_optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "feature_discriminator", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "discriminator_learning_rate", ",", "betas", "=", "(", "0.5", ",", "0.9", ")", ")", "\n", "self", ".", "generator_optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "feature_generator", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "generator_learning_rate", ",", "betas", "=", "(", "0.5", ",", "0.9", ")", ")", "\n", "\n", "if", "self", ".", "base_model_name", "==", "'resnet'", ":", "\n", "            ", "self", ".", "extractor_optimizer", "=", "optim", ".", "SGD", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "feature_extractor_target", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "self", ".", "extractor_learning_rate", ",", "momentum", "=", "0.9", ")", "\n", "\n", "self", ".", "classifier_optimizer", "=", "optim", ".", "SGD", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "self", ".", "feature_classifier_target", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "self", ".", "classifier_learning_rate", ",", "momentum", "=", "0.9", ")", "\n", "\n", "decay_epochs", "=", "0.5", "*", "int", "(", "generator_step", ")", "+", "1", "\n", "lr_decay_extractor", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "self", ".", "extractor_optimizer", ",", "step_size", "=", "decay_epochs", ",", "gamma", "=", "0.1", ")", "\n", "lr_decay_classifier", "=", "optim", ".", "lr_scheduler", ".", "StepLR", "(", "self", ".", "classifier_optimizer", ",", "step_size", "=", "decay_epochs", ",", "gamma", "=", "0.1", ")", "\n", "\n", "", "else", ":", "\n", "            ", "self", ".", "extractor_optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "feature_extractor_target", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "extractor_learning_rate", ",", "betas", "=", "(", "0.5", ",", "0.9", ")", ")", "\n", "self", ".", "classifier_optimizer", "=", "optim", ".", "Adam", "(", "self", ".", "feature_classifier_target", ".", "parameters", "(", ")", ",", "lr", "=", "self", ".", "classifier_learning_rate", ",", "betas", "=", "(", "0.5", ",", "0.9", ")", ")", "\n", "\n", "", "self", ".", "criterion", "=", "nn", ".", "CrossEntropyLoss", "(", ")", "\n", "\n", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "js", "=", "np", ".", "load", "(", "self", ".", "transpose_wj_extractor_npy", ")", "\n", "js", "=", "(", "js", "-", "np", ".", "mean", "(", "js", ")", ")", "/", "np", ".", "std", "(", "js", ")", "\n", "cw", "=", "torch", ".", "from_numpy", "(", "js", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "cw", "=", "F", ".", "softmax", "(", "cw", "/", "5", ")", ".", "detach", "(", ")", "\n", "self", ".", "extractor_channel_weights", "=", "cw", "\n", "print", "(", "self", ".", "extractor_channel_weights", ".", "size", "(", ")", ")", "\n", "\n", "", "self", ".", "generator_attention", "=", "np", ".", "load", "(", "self", ".", "generator_attention_npy", ")", "\n", "self", ".", "generator_attention", "=", "self", ".", "generator_attention", "*", "self", ".", "feature_dimension", "\n", "\n", "for", "class_label", "in", "range", "(", "self", ".", "num_labels", ")", ":", "\n", "            ", "self", ".", "generator_attention", "[", "class_label", ",", ":", "]", "=", "np", ".", "where", "(", "self", ".", "generator_attention", "[", "class_label", ",", ":", "]", ">=", "0.9", ",", "self", ".", "generator_attention", "[", "class_label", ",", ":", "]", "/", "self", ".", "feature_dimension", ",", "0.0", ")", "\n", "", "print", "(", "self", ".", "generator_attention", ")", "\n", "self", ".", "generator_attention", "=", "torch", ".", "FloatTensor", "(", "self", ".", "generator_attention", ")", "\n", "print", "(", "self", ".", "generator_attention", ".", "size", "(", ")", ")", "\n", "\n", "if", "self", ".", "with_regularization", "==", "True", ":", "\n", "            ", "self", ".", "channel_weights", "=", "[", "]", "\n", "channel_wei", "=", "self", ".", "channel_weight_json", "\n", "if", "channel_wei", ":", "\n", "                ", "for", "js", "in", "json", ".", "load", "(", "open", "(", "channel_wei", ")", ")", ":", "\n", "                    ", "js", "=", "np", ".", "array", "(", "js", ")", "\n", "js", "=", "(", "js", "-", "np", ".", "mean", "(", "js", ")", ")", "/", "np", ".", "std", "(", "js", ")", "\n", "cw", "=", "torch", ".", "from_numpy", "(", "js", ")", ".", "float", "(", ")", ".", "to", "(", "self", ".", "device", ")", "\n", "cw", "=", "F", ".", "softmax", "(", "cw", "/", "5", ")", ".", "detach", "(", ")", "\n", "self", ".", "channel_weights", ".", "append", "(", "cw", ")", "\n", "\n", "", "", "", "best_step_acc", "=", "0.0", "\n", "step", "=", "0", "\n", "\n", "self", ".", "inputs_gpu", "=", "[", "]", "\n", "self", ".", "labels_gpu", "=", "[", "]", "\n", "for", "d_step", "in", "range", "(", "num_d_iters", ")", ":", "\n", "            ", "inputs", ",", "labels", "=", "next", "(", "iter", "(", "self", ".", "data_loader", ")", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "inputs_gpu", ".", "append", "(", "inputs", ")", "\n", "self", ".", "labels_gpu", ".", "append", "(", "labels", ")", "\n", "\n", "", "while", "step", "<", "generator_step", ":", "\n", "# 1. Train feature discriminator", "\n", "            ", "d_loss", "=", "self", ".", "train_discriminator", "(", ")", "\n", "\n", "# 2. train generator", "\n", "g_loss", "=", "self", ".", "train_generator", "(", ")", "\n", "\n", "if", "step", "%", "step_for_3_4", "==", "0", ":", "\n", "#3. Train generator using classifier with fake feature", "\n", "                ", "self", ".", "train_generator_with_fake_feature", "(", ")", "\n", "\n", "#4. Train Extractor and Classifier by using BR with real features", "\n", "e_loss", ",", "c_loss_real", ",", "omega1_weight_extractor", "=", "self", ".", "train_extractor_classifier", "(", ")", "\n", "\n", "", "if", "step", "%", "step_for_5", "==", "0", "and", "step", "!=", "0", ":", "\n", "#5. Train Classifier by using BR with real and generated features", "\n", "                ", "c_loss", ",", "c_loss_real", ",", "c_loss_fake", ",", "omega1_weight_classifier", ",", "omega2_weight_classifier", ",", "c_loss_merged", "=", "self", ".", "train_classifier_with_fake", "(", ")", "\n", "\n", "", "if", "step", "%", "step_for_6", "==", "0", "and", "step", "!=", "0", "and", "e_loss", "<", "e_loss_for_6", ":", "\n", "#6. Updating attention for feature generator", "\n", "                ", "self", ".", "update_generator_attention", "(", "self", ".", "feature_extractor_target", ",", "self", ".", "feature_classifier_target", ",", "self", ".", "layer_name_extractor", ")", "\n", "\n", "", "if", "step", "%", "100", "==", "0", "and", "step", "!=", "0", ":", "\n", "#7. print current step loss, write validation Log", "\n", "                ", "print", "(", "'Step: [%d/%d] d_loss: %.5f g_loss: %.5f c_loss: %.5f c_loss_real: %.5f c_loss_fake: %.5f e_loss: %.5f c_loss_merged: %.5f'", "%", "(", "step", ",", "generator_step", ",", "d_loss", ",", "g_loss", ",", "c_loss", ",", "c_loss_real", ",", "c_loss_fake", ",", "e_loss", ",", "c_loss_merged", ")", ")", "\n", "print", "(", "'Step: [%d/%d] Omega1 Extractor Loss: %.5f, Omega1 Classifier Loss: %.5f, Omega2 Classifier Loss: %.5f, best accuracy: %.5f'", "%", "(", "step", ",", "generator_step", ",", "omega1_weight_extractor", ",", "omega1_weight_classifier", ",", "omega2_weight_classifier", ",", "best_step_acc", ")", ")", "\n", "validation_loss", ",", "step_acc", "=", "self", ".", "evaluate", "(", "step", ",", "generator_step", ")", "\n", "test_time", "=", "time", ".", "time", "(", ")", "\n", "print", "(", "\"time: %.3f\"", "%", "(", "test_time", "-", "self", ".", "code_start_time", ")", ")", "\n", "if", "step_acc", ">", "best_step_acc", ":", "\n", "                    ", "best_step_acc", "=", "step_acc", "\n", "print", "(", "'best accuracy: %.4f'", "%", "best_step_acc", ")", "\n", "\n", "", "", "if", "self", ".", "base_model_name", "==", "'resnet'", ":", "\n", "                ", "lr_decay_extractor", ".", "step", "(", ")", "\n", "lr_decay_classifier", ".", "step", "(", ")", "\n", "\n", "", "step", "+=", "1", "\n", "self", ".", "inputs_gpu", ".", "pop", "(", "0", ")", "\n", "self", ".", "labels_gpu", ".", "pop", "(", "0", ")", "\n", "inputs", ",", "labels", "=", "next", "(", "iter", "(", "self", ".", "data_loader", ")", ")", "\n", "inputs", "=", "inputs", ".", "to", "(", "self", ".", "device", ")", "\n", "labels", "=", "labels", ".", "to", "(", "self", ".", "device", ")", "\n", "self", ".", "inputs_gpu", ".", "append", "(", "inputs", ")", "\n", "self", ".", "labels_gpu", ".", "append", "(", "labels", ")", "\n", "\n", "", "print", "(", "'best accuracy: %.4f'", "%", "best_step_acc", ")", "\n", "torch", ".", "save", "(", "self", ".", "feature_extractor_target", ".", "state_dict", "(", ")", ",", "self", ".", "feature_extractor_target_pth", ")", "\n", "torch", ".", "save", "(", "self", ".", "feature_classifier_target", ".", "state_dict", "(", ")", ",", "self", ".", "feature_classifier_target_pth", ")", "\n", "torch", ".", "save", "(", "self", ".", "feature_generator", ".", "state_dict", "(", ")", ",", "self", ".", "feature_generator_pth", ")", "\n", "torch", ".", "save", "(", "self", ".", "feature_discriminator", ".", "state_dict", "(", ")", ",", "self", ".", "feature_discriminator_pth", ")", "\n", "optimal_attention", "=", "self", ".", "generator_attention", ".", "numpy", "(", ")", "\n", "np", ".", "save", "(", "self", ".", "optimal_attention_npy", ",", "optimal_attention", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Generator.__init__": [[8, 71], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Sequential", "torch.Sequential", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.ConvTranspose2d", "torch.ConvTranspose2d", "torch.Tanh", "torch.Tanh", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "base_model_name", ",", "noise_shape", ")", ":", "\n", "        ", "super", "(", "Feature_Generator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_model_name", "=", "base_model_name", "\n", "if", "base_model_name", "!=", "'resnet'", ":", "\n", "            ", "self", ".", "dense", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "noise_shape", ",", "128", "*", "4", "*", "4", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "128", "*", "4", "*", "4", ")", "\n", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dense", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "noise_shape", ",", "512", "*", "4", "*", "4", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "512", "*", "4", "*", "4", ")", "\n", ")", "\n", "\n", "", "if", "base_model_name", "==", "'vgg'", ":", "# image_size 32 -> (batch, 64, 16, 16)", "\n", "            ", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "128", ",", "128", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "128", ",", "128", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "128", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "128", ",", "64", ",", "4", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "64", ",", "64", ",", "4", ",", "stride", "=", "1", ",", "padding", "=", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", ")", "\n", "", "elif", "base_model_name", "==", "'resnet'", ":", "# image_size 224 -> (batch, 256, 56, 56)", "\n", "            ", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "512", ",", "512", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "512", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "512", ",", "256", ",", "4", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "256", ",", "256", ",", "2", ",", "stride", "=", "2", ",", "padding", "=", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "256", ",", "256", ",", "2", ",", "stride", "=", "2", ",", "padding", "=", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", "\n", ")", "\n", "", "elif", "base_model_name", "==", "'lenet'", ":", "# image_size 32 -> (batch, 6, 14, 14)", "\n", "            ", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "ConvTranspose2d", "(", "128", ",", "48", ",", "3", ",", "stride", "=", "2", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "48", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "48", ",", "12", ",", "3", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "12", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "ConvTranspose2d", "(", "12", ",", "6", ",", "4", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "6", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Generator.forward": [[73, 82], ["model.Feature_Generator.dense", "model.Feature_Generator.model", "torch.einsum", "torch.einsum", "torch.einsum", "torch.einsum", "x.view.view.view", "x.view.view.view", "x.view.view.size", "x.view.view.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ",", "einsum", ")", ":", "\n", "        ", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "if", "self", ".", "base_model_name", "!=", "'resnet'", ":", "\n", "            ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "128", ",", "4", ",", "4", ")", "\n", "", "else", ":", "\n", "            ", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "512", ",", "4", ",", "4", ")", "\n", "", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "x", "=", "torch", ".", "einsum", "(", "'aijk, ai -> aijk'", ",", "x", ",", "einsum", ")", "# (batch, 256, 56, 56) * (batch, 256) -> (batch, 256, 56, 56)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Discriminator.__init__": [[86, 104], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.LeakyReLU", "torch.LeakyReLU", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "in_channels", ",", "base_model_name", ")", ":", "\n", "        ", "super", "(", "Feature_Discriminator", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "conv", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "in_channels", ",", "32", ",", "5", ",", "stride", "=", "2", ",", "padding", "=", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "5", ",", "stride", "=", "2", ",", "padding", "=", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "64", ",", "128", ",", "5", ",", "stride", "=", "2", ",", "padding", "=", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "True", ")", "\n", ")", "\n", "\n", "if", "base_model_name", "!=", "'resnet'", ":", "\n", "            ", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "128", "*", "2", "*", "2", ",", "1", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "dense", "=", "nn", ".", "Linear", "(", "128", "*", "7", "*", "7", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Discriminator.forward": [[105, 110], ["model.Feature_Discriminator.conv", "model.Feature_Discriminator.view", "model.Feature_Discriminator.dense", "model.Feature_Discriminator.size"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "conv", "(", "x", ")", "# (batch, 128, 2, 2)", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "# (batch, 128 * 2 * 2)", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "# (batch, 1)", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Extractor.__init__": [[114, 168], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "list", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "torchvision.models.vgg16.load_state_dict", "list", "torch.Sequential", "torch.Sequential", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torchvision.models.vgg16.children", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.load", "torch.load", "torch.load", "torch.load", "torchvision.models.vgg16.children", "list", "torchvision.models.resnet50", "torchvision.models.resnet50.load_state_dict", "list", "torch.Sequential", "torch.Sequential", "list", "torchvision.models.resnet50().children", "torch.load", "torch.load", "torch.load", "torch.load", "torchvision.models.resnet50.children", "list", "model.Lenet5", "Lenet5.load_state_dict", "list", "list", "Lenet5().children", "torch.load", "torch.load", "torch.load", "torch.load", "Lenet5.children", "torchvision.models.resnet50", "list", "model.Lenet5"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "base_model_name", ",", "pretrained_weight", "=", "None", ",", "num_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", "Feature_Extractor", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "if", "base_model_name", "==", "'vgg'", ":", "# (batch, 3, 32, 32) -> (batch, 3, 16, 16)", "\n", "            ", "if", "pretrained_weight", "is", "None", ":", "\n", "                ", "vgg16_", "=", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "vgg16_", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "num_classes", ")", "\n", ")", "\n", "vgg16_list", "=", "list", "(", "vgg16_", ".", "children", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "vgg16_", "=", "vgg16", "(", "pretrained", "=", "False", ",", "num_classes", "=", "num_classes", ")", "\n", "vgg16_", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "num_classes", ")", "\n", ")", "\n", "vgg16_", ".", "load_state_dict", "(", "torch", ".", "load", "(", "pretrained_weight", ",", "map_location", "=", "'cpu'", ")", ")", "\n", "vgg16_list", "=", "list", "(", "vgg16_", ".", "children", "(", ")", ")", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "# 'vgg16': [64, 64, 'M', /stop/ 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']", "\n", "*", "list", "(", "vgg16_list", "[", "0", "]", ")", "[", ":", "5", "]", "\n", ")", "\n", "", "elif", "base_model_name", "==", "'resnet'", ":", "# (batch, 3, 224, 224) -> (batch, 3, 56, 56)", "\n", "            ", "if", "pretrained_weight", "is", "None", ":", "\n", "                ", "resnet50_list", "=", "list", "(", "resnet50", "(", "pretrained", "=", "True", ")", ".", "children", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "resnet50_", "=", "resnet50", "(", "pretrained", "=", "False", ",", "num_classes", "=", "num_classes", ")", "\n", "resnet50_", ".", "load_state_dict", "(", "torch", ".", "load", "(", "pretrained_weight", ",", "map_location", "=", "'cpu'", ")", ")", "\n", "resnet50_list", "=", "list", "(", "resnet50_", ".", "children", "(", ")", ")", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "# stop at residual 1", "\n", "*", "list", "(", "resnet50_list", ")", "[", ":", "5", "]", "\n", ")", "\n", "", "elif", "base_model_name", "==", "'lenet'", ":", "# (batch, 1, 32, 32) -> (batch, 6, 14, 14)", "\n", "            ", "if", "pretrained_weight", "is", "None", ":", "\n", "                ", "lenet5_list", "=", "list", "(", "Lenet5", "(", "num_classes", "=", "num_classes", ")", ".", "children", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "lenet5_", "=", "Lenet5", "(", "num_classes", "=", "num_classes", ")", "\n", "lenet5_", ".", "load_state_dict", "(", "torch", ".", "load", "(", "pretrained_weight", ",", "map_location", "=", "'cpu'", ")", ")", "\n", "lenet5_list", "=", "list", "(", "lenet5_", ".", "children", "(", ")", ")", "\n", "", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "# stop after first conv layer", "\n", "*", "list", "(", "lenet5_list", "[", "0", "]", ")", "[", ":", "3", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Extractor.forward": [[170, 173], ["model.Feature_Extractor.model"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Classifier.__init__": [[177, 239], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "list", "torchvision.models.vgg16", "torch.Sequential", "torch.Sequential", "torchvision.models.vgg16.load_state_dict", "list", "torch.Sequential", "torch.Sequential", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torchvision.models.vgg16.children", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Dropout", "torch.Dropout", "torch.Linear", "torch.Linear", "torch.load", "torch.load", "torch.load", "torch.load", "torchvision.models.vgg16.children", "list", "torchvision.models.resnet50", "torchvision.models.resnet50.load_state_dict", "list", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "list", "torchvision.models.resnet50().children", "torch.load", "torch.load", "torch.load", "torch.load", "torchvision.models.resnet50.children", "list", "model.Lenet5", "Lenet5.load_state_dict", "list", "list", "Lenet5().children", "torch.load", "torch.load", "torch.load", "torch.load", "Lenet5.children", "torchvision.models.resnet50", "list", "list", "model.Lenet5"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "base_model_name", ",", "pretrained_weight", "=", "None", ",", "num_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", "Feature_Classifier", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "base_model_name", "=", "base_model_name", "\n", "if", "base_model_name", "==", "'vgg'", ":", "\n", "            ", "if", "pretrained_weight", "is", "None", ":", "\n", "                ", "vgg16_", "=", "vgg16", "(", "pretrained", "=", "True", ")", "\n", "vgg16_", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "num_classes", ")", "\n", ")", "\n", "vgg16_list", "=", "list", "(", "vgg16_", ".", "children", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "vgg16_", "=", "vgg16", "(", "pretrained", "=", "False", ",", "num_classes", "=", "num_classes", ")", "\n", "vgg16_", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "512", "*", "7", "*", "7", ",", "4096", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "4096", ",", "512", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Dropout", "(", ")", ",", "\n", "nn", ".", "Linear", "(", "512", ",", "num_classes", ")", "\n", ")", "\n", "vgg16_", ".", "load_state_dict", "(", "torch", ".", "load", "(", "pretrained_weight", ",", "map_location", "=", "'cpu'", ")", ")", "\n", "vgg16_list", "=", "list", "(", "vgg16_", ".", "children", "(", ")", ")", "\n", "", "self", ".", "feature", "=", "nn", ".", "Sequential", "(", "\n", "# 'vgg16': [64, 64, 'M', /after/ 128, 128, 'M', 256, 256, 256, 'M', 512, 512, 512, 'M', 512, 512, 512, 'M']", "\n", "*", "list", "(", "vgg16_list", "[", "0", "]", ")", "[", "5", ":", "]", "\n", ")", "\n", "# (batch, 512, 7, 7)", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "7", ",", "7", ")", ")", "\n", "self", ".", "classifier", "=", "vgg16_", ".", "classifier", "\n", "", "elif", "base_model_name", "==", "'resnet'", ":", "\n", "            ", "if", "pretrained_weight", "is", "None", ":", "\n", "                ", "resnet50_list", "=", "list", "(", "resnet50", "(", "pretrained", "=", "True", ")", ".", "children", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "resnet50_", "=", "resnet50", "(", "pretrained", "=", "False", ",", "num_classes", "=", "num_classes", ")", "\n", "resnet50_", ".", "load_state_dict", "(", "torch", ".", "load", "(", "pretrained_weight", ",", "map_location", "=", "'cpu'", ")", ")", "\n", "resnet50_list", "=", "list", "(", "resnet50_", ".", "children", "(", ")", ")", "\n", "", "self", ".", "feature", "=", "nn", ".", "Sequential", "(", "\n", "# after at residual 1", "\n", "*", "list", "(", "resnet50_list", ")", "[", "5", ":", "8", "]", "\n", ")", "\n", "# (batch, 2048, 1, 1)", "\n", "self", ".", "avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Linear", "(", "2048", ",", "num_classes", ")", "\n", "", "elif", "base_model_name", "==", "'lenet'", ":", "\n", "            ", "if", "pretrained_weight", "is", "None", ":", "\n", "                ", "lenet5_list", "=", "list", "(", "Lenet5", "(", "num_classes", "=", "num_classes", ")", ".", "children", "(", ")", ")", "\n", "", "else", ":", "\n", "                ", "lenet5_", "=", "Lenet5", "(", "num_classes", "=", "num_classes", ")", "\n", "lenet5_", ".", "load_state_dict", "(", "torch", ".", "load", "(", "pretrained_weight", ",", "map_location", "=", "'cpu'", ")", ")", "\n", "lenet5_list", "=", "list", "(", "lenet5_", ".", "children", "(", ")", ")", "\n", "", "self", ".", "feature", "=", "nn", ".", "Sequential", "(", "\n", "*", "list", "(", "lenet5_list", "[", "0", "]", ")", "[", "3", ":", "]", "\n", ")", "\n", "self", ".", "classifier", "=", "nn", ".", "Sequential", "(", "\n", "*", "list", "(", "lenet5_list", "[", "1", "]", ")", "[", ":", "]", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Feature_Classifier.forward": [[241, 248], ["model.Feature_Classifier.feature", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "model.Feature_Classifier.classifier", "model.Feature_Classifier.avgpool"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "feature", "(", "x", ")", "\n", "if", "self", ".", "base_model_name", "!=", "'lenet'", ":", "\n", "            ", "x", "=", "self", ".", "avgpool", "(", "x", ")", "\n", "", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "classifier", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Lenet5.__init__": [[252, 269], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Conv2d", "torch.Conv2d", "torch.ReLU", "torch.ReLU", "torch.MaxPool2d", "torch.MaxPool2d", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear", "torch.ReLU", "torch.ReLU", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__"], ["    ", "def", "__init__", "(", "self", ",", "num_classes", "=", "10", ")", ":", "\n", "        ", "super", "(", "Lenet5", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "model", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "1", ",", "6", ",", "5", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", ",", "\n", "\n", "nn", ".", "Conv2d", "(", "6", ",", "16", ",", "5", ",", "stride", "=", "1", ",", "padding", "=", "0", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "MaxPool2d", "(", "kernel_size", "=", "2", ",", "stride", "=", "2", ")", "\n", ")", "\n", "self", ".", "dense", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "16", "*", "5", "*", "5", ",", "1024", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "1024", ",", "128", ")", ",", "\n", "nn", ".", "ReLU", "(", "True", ")", ",", "\n", "nn", ".", "Linear", "(", "128", ",", "num_classes", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.model.Lenet5.forward": [[271, 276], ["model.Lenet5.model", "torch.flatten", "torch.flatten", "torch.flatten", "torch.flatten", "model.Lenet5.dense"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "x", "=", "self", ".", "model", "(", "x", ")", "\n", "x", "=", "torch", ".", "flatten", "(", "x", ",", "1", ")", "\n", "x", "=", "self", ".", "dense", "(", "x", ")", "\n", "return", "x", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.CinicDataset.__init__": [[48, 96], ["torchvision.transforms.ToTensor", "torch.utils.data.Dataset.__init__", "custom_data_loader.CinicDataset._find_classes", "custom_data_loader.make_dataset", "int", "print", "random.shuffle", "print", "print", "print", "len", "RuntimeError", "max", "len", "range", "print", "print", "len", "custom_data_loader.CinicDataset.data.append", "custom_data_loader.CinicDataset.data.append"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__", "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.Food101Dataset._find_classes", "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.make_dataset"], ["def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "transforms", ".", "ToTensor", "(", ")", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ",", "extensions", "=", "IMG_EXTENSIONS", ")", ":", "\n", "        ", "super", "(", "CinicDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "0.", "<=", "ratio", "+", "1e-10", "and", "ratio", "-", "1e-10", "<=", "1.", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "classes", ",", "class_to_idx", "=", "self", ".", "_find_classes", "(", "root", ")", "\n", "samples", "=", "make_dataset", "(", "root", ",", "class_to_idx", ",", "extensions", ")", "\n", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 files in subfolders of: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported extensions are: \"", "+", "\",\"", ".", "join", "(", "extensions", ")", ")", ")", "\n", "\n", "", "major_class_len", "=", "0", "\n", "for", "key", "in", "samples", ":", "\n", "            ", "major_class_len", "=", "max", "(", "major_class_len", ",", "len", "(", "samples", "[", "key", "]", ")", ")", "\n", "", "minor_class_len", "=", "int", "(", "major_class_len", "*", "ratio", ")", "\n", "print", "(", "'major len:'", ",", "major_class_len", ",", "'minor len:'", ",", "minor_class_len", ")", "\n", "\n", "tmp", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "]", "\n", "random", ".", "shuffle", "(", "tmp", ")", "\n", "\n", "self", ".", "major_class", "=", "tmp", "[", "minor_class_num", ":", "]", "\n", "minor_class", "=", "tmp", "[", "0", ":", "minor_class_num", "]", "\n", "print", "(", "'major'", ",", "self", ".", "major_class", ")", "\n", "print", "(", "'minor'", ",", "minor_class", ")", "\n", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "key", "in", "samples", ":", "\n", "            ", "image_pathes", "=", "samples", "[", "key", "]", "\n", "if", "key", "in", "self", ".", "major_class", ":", "\n", "                ", "tmp_len", "=", "0", "\n", "for", "image_path", "in", "image_pathes", ":", "\n", "                    ", "self", ".", "data", ".", "append", "(", "(", "image_path", ",", "key", ")", ")", "\n", "tmp_len", "+=", "1", "\n", "if", "tmp_len", ">=", "major_class_len", ":", "\n", "                        ", "break", "\n", "", "", "print", "(", "tmp_len", ",", "end", "=", "' '", ")", "\n", "", "else", ":", "\n", "                ", "tmp_len", "=", "0", "\n", "for", "image_path", "in", "image_pathes", ":", "\n", "                    ", "self", ".", "data", ".", "append", "(", "(", "image_path", ",", "key", ")", ")", "\n", "tmp_len", "+=", "1", "\n", "if", "tmp_len", ">=", "minor_class_len", ":", "\n", "                        ", "break", "\n", "", "", "print", "(", "tmp_len", ",", "end", "=", "' '", ")", "\n", "", "", "print", "(", ")", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "class_to_idx", "=", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.CinicDataset.__getitem__": [[97, 103], ["PIL.Image.open().convert", "custom_data_loader.CinicDataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_path", ",", "target", "=", "self", ".", "data", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.CinicDataset._find_classes": [[104, 113], ["classes.sort", "range", "os.scandir", "os.scandir", "os.scandir", "os.scandir", "d.is_dir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "os.path.isdir", "os.path.isdir", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_find_classes", "(", "self", ",", "directory", ")", ":", "\n", "        ", "if", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ":", "\n", "# Faster and available in Python 3.5 and above", "\n", "            ", "classes", "=", "[", "d", ".", "name", "for", "d", "in", "os", ".", "scandir", "(", "directory", ")", "if", "d", ".", "is_dir", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "classes", "=", "[", "d", "for", "d", "in", "os", ".", "listdir", "(", "directory", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "d", ")", ")", "]", "\n", "", "classes", ".", "sort", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "return", "classes", ",", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.CinicDataset.__len__": [[114, 116], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.Food101Dataset.__init__": [[128, 176], ["torchvision.transforms.ToTensor", "torch.utils.data.Dataset.__init__", "custom_data_loader.Food101Dataset._find_classes", "custom_data_loader.make_dataset", "int", "print", "random.shuffle", "print", "print", "print", "len", "RuntimeError", "max", "len", "range", "print", "print", "len", "custom_data_loader.Food101Dataset.data.append", "custom_data_loader.Food101Dataset.data.append"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__", "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.Food101Dataset._find_classes", "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.make_dataset"], ["def", "__init__", "(", "self", ",", "root", ",", "transform", "=", "transforms", ".", "ToTensor", "(", ")", ",", "minor_class_num", "=", "0", ",", "ratio", "=", "1.0", ",", "extensions", "=", "IMG_EXTENSIONS", ")", ":", "\n", "        ", "super", "(", "Food101Dataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "assert", "0.", "<=", "ratio", "+", "1e-10", "and", "ratio", "-", "1e-10", "<=", "1.", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "classes", ",", "class_to_idx", "=", "self", ".", "_find_classes", "(", "root", ")", "\n", "samples", "=", "make_dataset", "(", "root", ",", "class_to_idx", ",", "extensions", ")", "\n", "\n", "if", "len", "(", "samples", ")", "==", "0", ":", "\n", "            ", "raise", "(", "RuntimeError", "(", "\"Found 0 files in subfolders of: \"", "+", "root", "+", "\"\\n\"", "\n", "\"Supported extensions are: \"", "+", "\",\"", ".", "join", "(", "extensions", ")", ")", ")", "\n", "\n", "", "major_class_len", "=", "0", "\n", "for", "key", "in", "samples", ":", "\n", "            ", "major_class_len", "=", "max", "(", "major_class_len", ",", "len", "(", "samples", "[", "key", "]", ")", ")", "\n", "", "minor_class_len", "=", "int", "(", "major_class_len", "*", "ratio", ")", "\n", "print", "(", "'major len:'", ",", "major_class_len", ",", "'minor len:'", ",", "minor_class_len", ")", "\n", "\n", "tmp", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "]", "\n", "random", ".", "shuffle", "(", "tmp", ")", "\n", "\n", "self", ".", "major_class", "=", "tmp", "[", "minor_class_num", ":", "]", "\n", "minor_class", "=", "tmp", "[", "0", ":", "minor_class_num", "]", "\n", "print", "(", "'major'", ",", "self", ".", "major_class", ")", "\n", "print", "(", "'minor'", ",", "minor_class", ")", "\n", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "key", "in", "samples", ":", "\n", "            ", "image_pathes", "=", "samples", "[", "key", "]", "\n", "if", "key", "in", "self", ".", "major_class", ":", "\n", "                ", "tmp_len", "=", "0", "\n", "for", "image_path", "in", "image_pathes", ":", "\n", "                    ", "self", ".", "data", ".", "append", "(", "(", "image_path", ",", "key", ")", ")", "\n", "tmp_len", "+=", "1", "\n", "if", "tmp_len", ">=", "major_class_len", ":", "\n", "                        ", "break", "\n", "", "", "print", "(", "tmp_len", ",", "end", "=", "' '", ")", "\n", "", "else", ":", "\n", "                ", "tmp_len", "=", "0", "\n", "for", "image_path", "in", "image_pathes", ":", "\n", "                    ", "self", ".", "data", ".", "append", "(", "(", "image_path", ",", "key", ")", ")", "\n", "tmp_len", "+=", "1", "\n", "if", "tmp_len", ">=", "minor_class_len", ":", "\n", "                        ", "break", "\n", "", "", "print", "(", "tmp_len", ",", "end", "=", "' '", ")", "\n", "", "", "print", "(", ")", "\n", "self", ".", "classes", "=", "classes", "\n", "self", ".", "class_to_idx", "=", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.Food101Dataset.__getitem__": [[177, 183], ["PIL.Image.open().convert", "custom_data_loader.Food101Dataset.transform", "PIL.Image.open"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img_path", ",", "target", "=", "self", ".", "data", "[", "index", "]", "\n", "img", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.Food101Dataset._find_classes": [[184, 193], ["classes.sort", "range", "os.scandir", "os.scandir", "os.scandir", "os.scandir", "d.is_dir", "os.listdir", "os.listdir", "os.listdir", "os.listdir", "os.path.isdir", "os.path.isdir", "os.path.isdir", "os.path.isdir", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "_find_classes", "(", "self", ",", "directory", ")", ":", "\n", "        ", "if", "sys", ".", "version_info", ">=", "(", "3", ",", "5", ")", ":", "\n", "# Faster and available in Python 3.5 and above", "\n", "            ", "classes", "=", "[", "d", ".", "name", "for", "d", "in", "os", ".", "scandir", "(", "directory", ")", "if", "d", ".", "is_dir", "(", ")", "]", "\n", "", "else", ":", "\n", "            ", "classes", "=", "[", "d", "for", "d", "in", "os", ".", "listdir", "(", "directory", ")", "if", "os", ".", "path", ".", "isdir", "(", "os", ".", "path", ".", "join", "(", "directory", ",", "d", ")", ")", "]", "\n", "", "classes", ".", "sort", "(", ")", "\n", "class_to_idx", "=", "{", "classes", "[", "i", "]", ":", "i", "for", "i", "in", "range", "(", "len", "(", "classes", ")", ")", "}", "\n", "return", "classes", ",", "class_to_idx", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.Food101Dataset.__len__": [[194, 196], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.SvhnDataset.__init__": [[217, 294], ["torchvision.transforms.ToTensor", "torch.utils.data.Dataset.__init__", "sio.loadmat", "loaded_mat[].astype().squeeze", "numpy.place", "numpy.transpose", "int", "print", "random.shuffle", "print", "dict", "dict", "zip", "print", "print", "print", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "max", "print", "print", "custom_data_loader.SvhnDataset.data.extend", "custom_data_loader.SvhnDataset.labels.extend", "loaded_mat[].astype", "range", "range", "images[].append", "classes[].append", "len", "len", "range"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__"], ["def", "__init__", "(", "self", ",", "root", ",", "split", "=", "'train'", ",", "transform", "=", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "major_len", "=", "5000", ",", "minor_class_num", "=", "8", ",", "ratio", "=", "0.1", ")", ":", "\n", "        ", "super", "(", "SvhnDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "root", "=", "root", "\n", "filename", "=", "self", ".", "split_list", "[", "split", "]", "[", "1", "]", "\n", "self", ".", "transform", "=", "transform", "\n", "\n", "# import here rather than at top of file because this is", "\n", "# an optional dependency for torchvision", "\n", "import", "scipy", ".", "io", "as", "sio", "\n", "\n", "# reading mat file as array", "\n", "loaded_mat", "=", "sio", ".", "loadmat", "(", "os", ".", "path", ".", "join", "(", "root", ",", "filename", ")", ")", "\n", "\n", "data", "=", "loaded_mat", "[", "'X'", "]", "\n", "# loading from the .mat file gives an np array of type np.uint8", "\n", "# converting to np.int64, so that we have a LongTensor after", "\n", "# the conversion from the numpy array", "\n", "# the squeeze is needed to obtain a 1D tensor", "\n", "labels", "=", "loaded_mat", "[", "'y'", "]", ".", "astype", "(", "np", ".", "int64", ")", ".", "squeeze", "(", ")", "\n", "\n", "# the svhn dataset assigns the class label \"10\" to the digit 0", "\n", "# this makes it inconsistent with several loss functions", "\n", "# which expect the class labels to be in the range [0, C-1]", "\n", "np", ".", "place", "(", "labels", ",", "labels", "==", "10", ",", "0", ")", "\n", "data", "=", "np", ".", "transpose", "(", "data", ",", "(", "3", ",", "2", ",", "0", ",", "1", ")", ")", "\n", "\n", "if", "split", "==", "'test'", ":", "\n", "            ", "tmp_cnt", "=", "[", "0", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "for", "label", "in", "labels", ":", "\n", "                ", "tmp_cnt", "[", "label", "]", "+=", "1", "\n", "", "major_len", "=", "max", "(", "tmp_cnt", ")", "\n", "", "minor_len", "=", "int", "(", "major_len", "*", "ratio", ")", "\n", "\n", "print", "(", "'type: %s, major len: %d, minor len: %d'", "%", "(", "split", ",", "major_len", ",", "minor_len", ")", ")", "\n", "\n", "tmp", "=", "[", "i", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "random", ".", "shuffle", "(", "tmp", ")", "\n", "\n", "self", ".", "major_class", "=", "tmp", "[", "minor_class_num", ":", "]", "\n", "minor_class", "=", "tmp", "[", "0", ":", "minor_class_num", "]", "\n", "print", "(", "'major'", ",", "self", ".", "major_class", ",", "'minor:'", ",", "minor_class", ")", "\n", "\n", "images", "=", "dict", "(", ")", "\n", "classes", "=", "dict", "(", ")", "\n", "label_cnt", "=", "[", "0", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "for", "data_tmp", ",", "label_tmp", "in", "zip", "(", "data", ",", "labels", ")", ":", "\n", "            ", "if", "label_tmp", "in", "self", ".", "major_class", "and", "label_cnt", "[", "label_tmp", "]", ">=", "major_len", ":", "\n", "                ", "continue", "\n", "", "if", "label_tmp", "in", "minor_class", "and", "label_cnt", "[", "label_tmp", "]", ">=", "minor_len", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "not", "label_tmp", "in", "images", ":", "\n", "                ", "images", "[", "label_tmp", "]", "=", "[", "data_tmp", "]", "\n", "classes", "[", "label_tmp", "]", "=", "[", "label_tmp", "]", "\n", "label_cnt", "[", "label_tmp", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "images", "[", "label_tmp", "]", ".", "append", "(", "data_tmp", ")", "\n", "classes", "[", "label_tmp", "]", ".", "append", "(", "label_tmp", ")", "\n", "label_cnt", "[", "label_tmp", "]", "+=", "1", "\n", "\n", "", "", "print", "(", "'check:'", ",", "end", "=", "' '", ")", "\n", "for", "key", "in", "images", ":", "\n", "            ", "print", "(", "len", "(", "images", "[", "key", "]", ")", ",", "end", "=", "' '", ")", "\n", "", "print", "(", ")", "\n", "print", "(", "'check:'", ",", "end", "=", "' '", ")", "\n", "for", "key", "in", "classes", ":", "\n", "            ", "print", "(", "len", "(", "classes", "[", "key", "]", ")", ",", "end", "=", "' '", ")", "\n", "", "print", "(", ")", "\n", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "key", "in", "images", ":", "\n", "            ", "self", ".", "data", ".", "extend", "(", "images", "[", "key", "]", ")", "\n", "", "self", ".", "labels", "=", "[", "]", "\n", "for", "key", "in", "classes", ":", "\n", "            ", "self", ".", "labels", ".", "extend", "(", "classes", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.SvhnDataset.__getitem__": [[295, 304], ["PIL.Image.fromarray().convert", "custom_data_loader.SvhnDataset.transform", "int", "PIL.Image.fromarray", "numpy.transpose"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "        ", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "labels", "[", "index", "]", ")", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL gray Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "np", ".", "transpose", "(", "img", ",", "(", "1", ",", "2", ",", "0", ")", ")", ")", ".", "convert", "(", "'L'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.SvhnDataset.__len__": [[305, 307], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__": [[321, 381], ["torchvision.transforms.ToTensor", "torch.utils.data.Dataset.__init__", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.load", "int", "print", "random.shuffle", "print", "dict", "dict", "zip", "print", "print", "print", "print", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "label_tmp.item", "print", "print", "custom_data_loader.FashionMnistDataset.data.extend", "custom_data_loader.FashionMnistDataset.labels.extend", "range", "range", "images[].append", "classes[].append", "len", "len"], "methods", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__init__"], ["def", "__init__", "(", "self", ",", "root", ",", "train", "=", "True", ",", "transform", "=", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "minor_class_num", "=", "8", ",", "ratio", "=", "0.025", ")", ":", "\n", "        ", "super", "(", "FashionMnistDataset", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n", "self", ".", "transform", "=", "transform", "\n", "processed_folder", "=", "os", ".", "path", ".", "join", "(", "root", ",", "'FashionMNIST/processed'", ")", "\n", "\n", "if", "train", ":", "\n", "            ", "data_file", "=", "'training.pt'", "\n", "", "else", ":", "\n", "            ", "data_file", "=", "'test.pt'", "\n", "\n", "", "data", ",", "targets", "=", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "processed_folder", ",", "data_file", ")", ")", "\n", "\n", "major_len", "=", "6000", "\n", "minor_len", "=", "int", "(", "major_len", "*", "ratio", ")", "\n", "\n", "print", "(", "'type: %s, major len: %d, minor len: %d'", "%", "(", "(", "'train'", "if", "train", "else", "'test'", ")", ",", "major_len", ",", "minor_len", ")", ")", "\n", "\n", "tmp", "=", "[", "i", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "random", ".", "shuffle", "(", "tmp", ")", "\n", "\n", "self", ".", "major_class", "=", "tmp", "[", "minor_class_num", ":", "]", "\n", "minor_class", "=", "tmp", "[", "0", ":", "minor_class_num", "]", "\n", "print", "(", "'major'", ",", "self", ".", "major_class", ",", "'minor:'", ",", "minor_class", ")", "\n", "\n", "images", "=", "dict", "(", ")", "\n", "classes", "=", "dict", "(", ")", "\n", "label_cnt", "=", "[", "0", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "for", "data_tmp", ",", "label_tmp", "in", "zip", "(", "data", ",", "targets", ")", ":", "\n", "            ", "idx", "=", "label_tmp", ".", "item", "(", ")", "\n", "if", "idx", "in", "self", ".", "major_class", "and", "label_cnt", "[", "idx", "]", ">=", "major_len", ":", "\n", "                ", "continue", "\n", "", "if", "idx", "in", "minor_class", "and", "label_cnt", "[", "idx", "]", ">=", "minor_len", ":", "\n", "                ", "continue", "\n", "\n", "", "if", "not", "idx", "in", "images", ":", "\n", "                ", "images", "[", "idx", "]", "=", "[", "data_tmp", "]", "\n", "classes", "[", "idx", "]", "=", "[", "label_tmp", "]", "\n", "label_cnt", "[", "idx", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "images", "[", "idx", "]", ".", "append", "(", "data_tmp", ")", "\n", "classes", "[", "idx", "]", ".", "append", "(", "label_tmp", ")", "\n", "label_cnt", "[", "idx", "]", "+=", "1", "\n", "\n", "", "", "print", "(", "'check:'", ",", "end", "=", "' '", ")", "\n", "for", "key", "in", "images", ":", "\n", "            ", "print", "(", "len", "(", "images", "[", "key", "]", ")", ",", "end", "=", "' '", ")", "\n", "", "print", "(", ")", "\n", "print", "(", "'check:'", ",", "end", "=", "' '", ")", "\n", "for", "key", "in", "classes", ":", "\n", "            ", "print", "(", "len", "(", "classes", "[", "key", "]", ")", ",", "end", "=", "' '", ")", "\n", "", "print", "(", ")", "\n", "\n", "self", ".", "data", "=", "[", "]", "\n", "for", "key", "in", "images", ":", "\n", "            ", "self", ".", "data", ".", "extend", "(", "images", "[", "key", "]", ")", "\n", "", "self", ".", "labels", "=", "[", "]", "\n", "for", "key", "in", "classes", ":", "\n", "            ", "self", ".", "labels", ".", "extend", "(", "classes", "[", "key", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__getitem__": [[382, 392], ["PIL.Image.fromarray", "custom_data_loader.FashionMnistDataset.transform", "int", "custom_data_loader.FashionMnistDataset.numpy"], "methods", ["None"], ["", "", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "\n", "        ", "img", ",", "target", "=", "self", ".", "data", "[", "index", "]", ",", "int", "(", "self", ".", "labels", "[", "index", "]", ")", "\n", "\n", "# doing this so that it is consistent with all other datasets", "\n", "# to return a PIL Image", "\n", "img", "=", "Image", ".", "fromarray", "(", "img", ".", "numpy", "(", ")", ",", "mode", "=", "'L'", ")", "\n", "img", "=", "self", ".", "transform", "(", "img", ")", "\n", "\n", "return", "img", ",", "target", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.FashionMnistDataset.__len__": [[393, 395], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.has_file_allowed_extension": [[12, 14], ["filename.lower().endswith", "filename.lower"], "function", ["None"], ["def", "has_file_allowed_extension", "(", "filename", ",", "extensions", ")", ":", "\n", "    ", "return", "filename", ".", "lower", "(", ")", ".", "endswith", "(", "extensions", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.make_dataset": [[15, 37], ["os.path.expanduser", "os.path.expanduser", "dict", "range", "sorted", "len", "class_to_idx.keys", "os.path.join", "os.path.join", "sorted", "custom_data_loader.has_file_allowed_extension", "os.path.isdir", "os.path.isdir", "os.walk", "os.walk", "sorted", "os.path.join", "os.path.join", "custom_data_loader.make_dataset.is_valid_file"], "function", ["home.repos.pwc.inspect_result.opensuh_DFG.None.custom_data_loader.has_file_allowed_extension"], ["", "def", "make_dataset", "(", "directory", ",", "class_to_idx", ",", "extensions", "=", "None", ")", ":", "\n", "    ", "images", "=", "[", "]", "\n", "directory", "=", "os", ".", "path", ".", "expanduser", "(", "directory", ")", "\n", "if", "extensions", "is", "not", "None", ":", "\n", "        ", "def", "is_valid_file", "(", "x", ")", ":", "\n", "            ", "return", "has_file_allowed_extension", "(", "x", ",", "extensions", ")", "\n", "\n", "", "", "images", "=", "dict", "(", ")", "\n", "for", "idx", "in", "range", "(", "len", "(", "class_to_idx", ")", ")", ":", "\n", "        ", "images", "[", "idx", "]", "=", "[", "]", "\n", "\n", "", "for", "target", "in", "sorted", "(", "class_to_idx", ".", "keys", "(", ")", ")", ":", "\n", "        ", "d", "=", "os", ".", "path", ".", "join", "(", "directory", ",", "target", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "d", ")", ":", "\n", "            ", "continue", "\n", "", "for", "root", ",", "_", ",", "fnames", "in", "sorted", "(", "os", ".", "walk", "(", "d", ")", ")", ":", "\n", "            ", "for", "fname", "in", "sorted", "(", "fnames", ")", ":", "\n", "                ", "path", "=", "os", ".", "path", ".", "join", "(", "root", ",", "fname", ")", "\n", "if", "is_valid_file", "(", "path", ")", ":", "\n", "                    ", "images", "[", "class_to_idx", "[", "target", "]", "]", ".", "append", "(", "path", ")", "\n", "\n", "", "", "", "", "return", "images", "\n", "\n"]], "home.repos.pwc.inspect_result.opensuh_DFG.None.utils.z_sampler": [[3, 10], ["numpy.random.uniform().astype", "numpy.random.random_integers", "numpy.zeros", "numpy.random.uniform", "numpy.arange"], "function", ["None"], ["def", "z_sampler", "(", "batch_size", "=", "10", ",", "N_NOISE", "=", "100", ",", "N_CLASS", "=", "10", ")", ":", "\n", "    ", "bz", "=", "np", ".", "random", ".", "uniform", "(", "-", "1.", ",", "1.", ",", "size", "=", "[", "batch_size", ",", "N_NOISE", "]", ")", ".", "astype", "(", "np", ".", "float32", ")", "\n", "idx", "=", "np", ".", "random", ".", "random_integers", "(", "0", ",", "N_CLASS", "-", "1", ",", "size", "=", "(", "batch_size", ",", ")", ")", "\n", "by", "=", "np", ".", "zeros", "(", "(", "batch_size", ",", "N_CLASS", ")", ")", "\n", "by", "[", "np", ".", "arange", "(", "batch_size", ")", ",", "idx", "]", "=", "1", "\n", "\n", "return", "bz", ",", "by", ",", "idx", "", "", ""]]}