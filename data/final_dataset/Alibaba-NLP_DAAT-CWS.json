{"home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.gcnn.__init__": [[11, 22], ["gcnn.gcnn.encoder"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.gcnn.encoder"], ["    ", "def", "__init__", "(", "self", ",", "inputs", ",", "seq_lengths", ",", "stag_ids", ",", "vocab_size", ",", "emb_size", ",", "scope", "=", "'gcnn'", ",", "is_train", "=", "True", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "inputs", "=", "inputs", "\n", "self", ".", "seq_lengths", "=", "seq_lengths", "\n", "self", ".", "stag_ids", "=", "stag_ids", "\n", "self", ".", "scope", "=", "scope", "\n", "self", ".", "num_tags", "=", "4", "\n", "self", ".", "is_train", "=", "is_train", "\n", "self", ".", "reuse", "=", "reuse", "\n", "self", ".", "encoder", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.gcnn.encoder": [[23, 78], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "xrange", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer", "gcnn.gcnn.inputs.get_shape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "methods", ["None"], ["", "def", "encoder", "(", "self", ",", "is_training", "=", "False", ",", "hidden_layers", "=", "5", ",", "kernel_size", "=", "3", ",", "channels", "=", "[", "200", "]", "*", "5", ",", "dropout_emb", "=", "0.2", ",", "dropout_hidden", "=", "0.2", ",", "use_wn", "=", "True", ",", "use_bn", "=", "False", ")", ":", "\n", "# Define the encoder", "\n", "# embeddings = tf.get_variable('embeddings', [self.vocab_size, self.emb_size])", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ",", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", ")", ")", ":", "\n", "            ", "masks", "=", "tf", ".", "cast", "(", "tf", ".", "sequence_mask", "(", "self", ".", "seq_lengths", ",", "maxlen", "=", "64", ")", ",", "FLOAT_TYPE", ")", "\n", "# Dropout on embedding output.", "\n", "if", "dropout_emb", ":", "\n", "                ", "self", ".", "inputs", "=", "tf", ".", "cond", "(", "self", ".", "is_train", ",", "\n", "lambda", ":", "tf", ".", "nn", ".", "dropout", "(", "self", ".", "inputs", ",", "1", "-", "dropout_emb", ")", ",", "\n", "lambda", ":", "self", ".", "inputs", ")", "\n", "", "hidden_output", "=", "self", ".", "inputs", "\n", "pre_channels", "=", "self", ".", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "for", "i", "in", "xrange", "(", "hidden_layers", ")", ":", "\n", "                ", "k", "=", "kernel_size", "\n", "cur_channels", "=", "channels", "[", "i", "]", "\n", "filter_w", "=", "tf", ".", "get_variable", "(", "'filter_w_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "pre_channels", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "filter_v", "=", "tf", ".", "get_variable", "(", "'filter_v_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "pre_channels", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "bias_b", "=", "tf", ".", "get_variable", "(", "'bias_b_%d'", "%", "i", ",", "shape", "=", "[", "cur_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "FLOAT_TYPE", ")", ")", "\n", "bias_c", "=", "tf", ".", "get_variable", "(", "'bias_c_%d'", "%", "i", ",", "shape", "=", "[", "cur_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "FLOAT_TYPE", ")", ")", "\n", "\n", "# Weight normalization.", "\n", "if", "use_wn", ":", "\n", "                    ", "epsilon", "=", "1e-12", "\n", "g_w", "=", "tf", ".", "get_variable", "(", "'g_w_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "1", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "g_v", "=", "tf", ".", "get_variable", "(", "'g_v_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "1", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "# Perform wn", "\n", "filter_w", "=", "g_w", "*", "filter_w", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "filter_w", "**", "2", ",", "1", ",", "keep_dims", "=", "True", ")", ")", "+", "epsilon", ")", "\n", "filter_v", "=", "g_v", "*", "filter_v", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "filter_v", "**", "2", ",", "1", ",", "keep_dims", "=", "True", ")", ")", "+", "epsilon", ")", "\n", "\n", "", "w", "=", "tf", ".", "nn", ".", "conv1d", "(", "hidden_output", ",", "filter_w", ",", "1", ",", "'SAME'", ")", "+", "bias_b", "\n", "v", "=", "tf", ".", "nn", ".", "conv1d", "(", "hidden_output", ",", "filter_v", ",", "1", ",", "'SAME'", ")", "+", "bias_c", "\n", "\n", "if", "use_bn", ":", "\n", "                    ", "w", "=", "layers", ".", "batch_norm", "(", "inputs", "=", "v", ",", "decay", "=", "0.9", ",", "is_training", "=", "self", ".", "is_train", ",", "center", "=", "True", ",", "scale", "=", "True", ",", "\n", "scope", "=", "'BatchNorm_w_%d'", "%", "i", ")", "\n", "v", "=", "layers", ".", "batch_norm", "(", "inputs", "=", "w", ",", "decay", "=", "0.9", ",", "is_training", "=", "self", ".", "is_train", ",", "center", "=", "True", ",", "scale", "=", "True", ",", "\n", "scope", "=", "'BatchNorm_v_%d'", "%", "i", ")", "\n", "\n", "", "hidden_output", "=", "w", "*", "tf", ".", "nn", ".", "sigmoid", "(", "v", ")", "\n", "\n", "# Mask paddings.", "\n", "hidden_output", "=", "hidden_output", "*", "tf", ".", "expand_dims", "(", "masks", ",", "-", "1", ")", "\n", "# Dropout on hidden output.", "\n", "if", "dropout_hidden", ":", "\n", "                    ", "hidden_output", "=", "tf", ".", "cond", "(", "self", ".", "is_train", ",", "\n", "lambda", ":", "tf", ".", "nn", ".", "dropout", "(", "hidden_output", ",", "1", "-", "dropout_hidden", ")", ",", "\n", "lambda", ":", "hidden_output", "\n", ")", "\n", "\n", "", "pre_channels", "=", "cur_channels", "\n", "\n", "", "hidden_output", "=", "hidden_output", "\n", "self", ".", "fc1", "=", "hidden_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.Embedding_layer.__init__": [[80, 86], ["gcnn.Embedding_layer.init_embeddings"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.Embedding_layer.init_embeddings"], ["    ", "def", "__init__", "(", "self", ",", "scope", ",", "vocab_size", ",", "emb_size", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "self", ".", "scope", "=", "scope", "\n", "self", ".", "vocab_size", "=", "vocab_size", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "reuse", "=", "reuse", "\n", "self", ".", "init_embeddings", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.Embedding_layer.init_embeddings": [[87, 90], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer"], "methods", ["None"], ["", "def", "init_embeddings", "(", "self", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ",", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", ")", ")", ":", "\n", "            ", "self", ".", "embeddings", "=", "tf", ".", "get_variable", "(", "'embeddings'", ",", "[", "self", ".", "vocab_size", ",", "self", ".", "emb_size", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.Embedding_layer.get_embeddings": [[91, 94], ["tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "", "def", "get_embeddings", "(", "self", ",", "seq_ids", ")", ":", "\n", "        ", "inputs", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "embeddings", ",", "seq_ids", ")", "\n", "return", "inputs", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.CRF_Layer.__init__": [[97, 101], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_tags", "=", "4", ",", "scope", "=", "None", ",", "reuse", "=", "False", ")", ":", "\n", "        ", "self", ".", "num_tags", "=", "num_tags", "\n", "self", ".", "scope", "=", "scope", "\n", "self", ".", "reuse", "=", "reuse", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.CRF_Layer.tagger": [[102, 111], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.crf_log_likelihood", "tensorflow.crf_log_likelihood", "tensorflow.crf_log_likelihood", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "tagger", "(", "self", ",", "inputs", ",", "stag_ids", ",", "seq_lengths", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ")", ":", "\n", "            ", "scores", "=", "layers", ".", "fully_connected", "(", "inputs", ",", "self", ".", "num_tags", ",", "tf", ".", "identity", ")", "\n", "#self.fc2 = scores", "\n", "cost", ",", "transitions", "=", "crf", ".", "crf_log_likelihood", "(", "inputs", "=", "scores", ",", "tag_indices", "=", "stag_ids", ",", "sequence_lengths", "=", "seq_lengths", ")", "\n", "cost", "=", "-", "tf", ".", "reduce_mean", "(", "cost", ")", "\n", "trans", "=", "transitions", "\n", "cost", "=", "cost", "\n", "return", "scores", ",", "cost", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.GAN.__init__": [[113, 123], ["tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "tensorflow.random_normal_initializer", "len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scope", ",", "source_domain_labels", ",", "target_domain_labels", ")", ":", "\n", "# self.inpdduts = inputs", "\n", "        ", "self", ".", "scope", "=", "scope", "\n", "self", ".", "initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "0.1", ",", "seed", "=", "2018", ")", "\n", "self", ".", "source_domain_labels", "=", "source_domain_labels", "\n", "self", ".", "target_domain_labels", "=", "target_domain_labels", "\n", "self", ".", "embed_size", "=", "200", "\n", "self", ".", "num_filters", "=", "200", "\n", "self", ".", "filter_sizes", "=", "[", "3", ",", "4", ",", "5", "]", "\n", "self", ".", "num_filters_total", "=", "self", ".", "num_filters", "*", "len", "(", "self", ".", "filter_sizes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.GAN.discriminator": [[124, 145], ["tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "enumerate", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.nn.conv2d", "tensorflow.nn.conv2d", "tensorflow.contrib.layers.batch_norm", "tensorflow.contrib.layers.batch_norm", "tensorflow.contrib.layers.batch_norm", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "tensorflow.nn.max_pool", "pooled_outputs.append", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add"], "methods", ["None"], ["", "def", "discriminator", "(", "self", ",", "inputs", ",", "reuse", "=", "False", ",", "trainable", "=", "True", ")", ":", "\n", "# Text cnn model", "\n", "        ", "inputs_expanded", "=", "tf", ".", "expand_dims", "(", "inputs", ",", "-", "1", ")", "\n", "pooled_outputs", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "reuse", ")", ":", "\n", "            ", "for", "i", ",", "filter_size", "in", "enumerate", "(", "self", ".", "filter_sizes", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"convolution-pooling-%s\"", "%", "filter_size", ")", ":", "\n", "                    ", "filter", "=", "tf", ".", "get_variable", "(", "\"filter-%s\"", "%", "filter_size", ",", "[", "filter_size", ",", "self", ".", "embed_size", ",", "1", ",", "self", ".", "num_filters", "]", ",", "initializer", "=", "self", ".", "initializer", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs_expanded", ",", "filter", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "\"VALID\"", ",", "name", "=", "\"conv\"", ")", "\n", "conv", "=", "tf", ".", "contrib", ".", "layers", ".", "batch_norm", "(", "conv", ",", "is_training", "=", "True", ",", "scope", "=", "'cnn_bn_'", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b-%s\"", "%", "filter_size", ",", "[", "self", ".", "num_filters", "]", ")", "\n", "# h = tf.nn.leaky_relu(tf.nn.bias_add(conv, b), name=\"leaky_relu\")", "\n", "h", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "b", ")", ",", "name", "=", "\"relu\"", ")", "\n", "pooled", "=", "tf", ".", "nn", ".", "max_pool", "(", "h", ",", "ksize", "=", "[", "1", ",", "64", "-", "filter_size", "+", "1", ",", "1", ",", "1", "]", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "'VALID'", ",", "name", "=", "\"pool\"", ")", "\n", "#pooled = tf.reduce_max(h, axis=1, keep_dims=True)", "\n", "pooled_outputs", ".", "append", "(", "pooled", ")", "\n", "", "", "h_pool", "=", "tf", ".", "concat", "(", "pooled_outputs", ",", "3", ")", "\n", "h_pool_flat", "=", "tf", ".", "reshape", "(", "h_pool", ",", "[", "-", "1", ",", "self", ".", "num_filters_total", "]", ")", "\n", "h_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "h_pool_flat", ",", "keep_prob", "=", "0.5", ")", "\n", "fc3", "=", "tf", ".", "layers", ".", "dense", "(", "h_drop", ",", "2", ",", "activation", "=", "None", ",", "use_bias", "=", "True", ")", "\n", "return", "fc3", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.gcnn.GAN.build_ad_loss": [[146, 160], ["tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.zeros_like"], "methods", ["None"], ["", "", "def", "build_ad_loss", "(", "self", ",", "disc_s", ",", "disc_t", ")", ":", "\n", "#source_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=disc_s, labels=self.source_domain_labels)", "\n", "#target_loss = tf.nn.softmax_cross_entropy_with_logits_v2(logits=disc_t, labels=self.target_domain_labels)", "\n", "#target_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_t,labels=tf.ones_like(disc_t)*(1-0.6)+0.3)", "\n", "#target_loss = tf.reduce_mean(target_loss)", "\n", "#source_loss = tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_s,labels=tf.ones_like(disc_s)*(1-0.6)+0.3)", "\n", "#source_loss = tf.reduce_mean(source_loss)", "\n", "        ", "source_dis_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "disc_s", ",", "labels", "=", "tf", ".", "ones_like", "(", "disc_s", ")", "-", "0.2", ")", ")", "\n", "source_dis_loss_2", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "disc_s", ",", "labels", "=", "tf", ".", "zeros_like", "(", "disc_s", ")", "+", "0.2", ")", ")", "\n", "target_dis_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "disc_t", ",", "labels", "=", "tf", ".", "ones_like", "(", "disc_t", ")", "-", "0.2", ")", ")", "\n", "target_dis_loss_2", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "disc_t", ",", "labels", "=", "tf", ".", "zeros_like", "(", "disc_t", ")", "+", "0.2", ")", ")", "\n", "#d_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_s,labels=tf.ones_like(disc_s)*(1-0.6)+0.3))+tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_t, labels=tf.zeros_like(disc_t)*(1-0.6)+0.3))", "\n", "#g_loss = tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_s,labels=tf.zeros_like(disc_s)*(1-0.6)+0.3))+tf.reduce_mean(tf.nn.sigmoid_cross_entropy_with_logits(logits=disc_t, labels=tf.ones_like(disc_t)*(1-0.6)+0.3))", "\n", "return", "source_dis_loss", ",", "source_dis_loss_2", ",", "target_dis_loss", ",", "target_dis_loss_2", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.process_train_sentence": [[5, 20], ["sentence.strip.strip", "sentence.strip.split", "ret.append", "ret.append", "chars.extend", "list", "len", "tags.append", "tags.extend", "len"], "function", ["None"], ["def", "process_train_sentence", "(", "sentence", ")", ":", "\n", "    ", "sentence", "=", "sentence", ".", "strip", "(", ")", "\n", "words", "=", "sentence", ".", "split", "(", ")", "\n", "chars", "=", "[", "]", "\n", "tags", "=", "[", "]", "\n", "ret", "=", "[", "]", "\n", "for", "w", "in", "words", ":", "\n", "        ", "chars", ".", "extend", "(", "list", "(", "w", ")", ")", "\n", "if", "len", "(", "w", ")", "==", "1", ":", "\n", "            ", "tags", ".", "append", "(", "'S'", ")", "\n", "", "else", ":", "\n", "            ", "tags", ".", "extend", "(", "[", "'B'", "]", "+", "[", "'M'", "]", "*", "(", "len", "(", "w", ")", "-", "2", ")", "+", "[", "'E'", "]", ")", "\n", "", "", "ret", ".", "append", "(", "chars", ")", "\n", "ret", ".", "append", "(", "tags", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.data_iterator": [[21, 47], ["all", "zip", "len", "np.random.shuffle", "len", "max", "len", "batch.append", "zip", "len", "len", "min", "zip", "len", "max", "len", "len"], "function", ["None"], ["", "def", "data_iterator", "(", "inputs", ",", "batch_size", ",", "shuffle", "=", "True", ",", "max_length", "=", "200", ")", ":", "\n", "    ", "\"\"\"\n    A simple iterator for generating dynamic mini batches.\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", ">", "0", "\n", "assert", "all", "(", "[", "len", "(", "item", ")", "==", "len", "(", "inputs", "[", "0", "]", ")", "for", "item", "in", "inputs", "]", ")", "\n", "inputs", "=", "zip", "(", "*", "inputs", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "inputs", ")", "\n", "\n", "", "batch", "=", "[", "]", "\n", "bs", "=", "batch_size", "\n", "for", "d", "in", "inputs", ":", "\n", "        ", "if", "len", "(", "d", "[", "0", "]", ")", ">", "max_length", ":", "\n", "            ", "bs", "=", "max", "(", "1", ",", "min", "(", "batch_size", "*", "max_length", "/", "len", "(", "d", "[", "0", "]", ")", ",", "bs", ")", ")", "\n", "", "if", "len", "(", "batch", ")", "<", "bs", ":", "\n", "            ", "batch", ".", "append", "(", "d", ")", "\n", "", "else", ":", "\n", "            ", "yield", "zip", "(", "*", "batch", ")", "\n", "batch", "=", "[", "d", "]", "\n", "if", "len", "(", "d", "[", "0", "]", ")", "<", "max_length", ":", "\n", "                ", "bs", "=", "batch_size", "\n", "", "else", ":", "\n", "                ", "bs", "=", "max", "(", "1", ",", "batch_size", "*", "max_length", "/", "len", "(", "d", "[", "0", "]", ")", ")", "\n", "", "", "", "if", "batch", ":", "\n", "        ", "yield", "zip", "(", "*", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.read_train_file": [[49, 57], ["zip", "data.append", "cws.process_train_sentence"], "function", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.process_train_sentence"], ["", "", "def", "read_train_file", "(", "fin", ")", ":", "\n", "    ", "\"\"\"\n    Read training data.\n    \"\"\"", "\n", "data", "=", "[", "]", "\n", "for", "l", "in", "fin", ":", "\n", "        ", "data", ".", "append", "(", "process_train_sentence", "(", "l", ")", ")", "\n", "", "return", "zip", "(", "*", "data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.create_output": [[59, 72], ["itertools.izip", "itertools.izip", "output.append", "new_sen.append", "new_sen.append"], "function", ["None"], ["", "def", "create_output", "(", "seqs", ",", "stags", ")", ":", "\n", "    ", "\"\"\"\n    Create final output from characters and BMES tags.\n    \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "seq", ",", "stag", "in", "izip", "(", "seqs", ",", "stags", ")", ":", "\n", "        ", "new_sen", "=", "[", "]", "\n", "for", "c", ",", "tag", "in", "izip", "(", "seq", ",", "stag", ")", ":", "\n", "            ", "new_sen", ".", "append", "(", "c", ")", "\n", "if", "tag", "==", "'S'", "or", "tag", "==", "'E'", ":", "\n", "                ", "new_sen", ".", "append", "(", "'  '", ")", "\n", "", "", "output", ".", "append", "(", "''", ".", "join", "(", "new_sen", ")", ")", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.evaluator": [[74, 113], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "codecs.open", "codecs.open", "cws.create_output", "enumerate", "codecs.open.close", "codecs.open.close", "os.system", "os.system", "os.system", "os.remove", "os.remove", "os.remove", "os.remove", "len", "len", "len", "os.path.exists", "os.makedirs", "print", "cws.create_output", "print", "l.rstrip", "float", "float", "float", "codecs.open", "eval_lines[].split", "eval_lines[].split", "eval_lines[].split"], "function", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.create_output", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.create_output"], ["", "def", "evaluator", "(", "data", ",", "output_dir", ",", "output_flag", ")", ":", "\n", "    ", "\"\"\"\n    Evaluate presion, recall and F1.\n    \"\"\"", "\n", "seqs", ",", "gold_stags", ",", "pred_stags", "=", "data", "\n", "assert", "len", "(", "seqs", ")", "==", "len", "(", "gold_stags", ")", "==", "len", "(", "pred_stags", ")", "\n", "# Create and open temp files.", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "output_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "output_dir", ")", "\n", "\n", "", "ref_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'%s.ref'", "%", "output_flag", ")", "\n", "pred_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'%s.pred'", "%", "output_flag", ")", "\n", "score_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'%s.score'", "%", "output_flag", ")", "\n", "# Empty words file.", "\n", "temp_path", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'%s.temp'", "%", "output_flag", ")", "\n", "\n", "ref_file", "=", "codecs", ".", "open", "(", "ref_path", ",", "'w'", ",", "'utf8'", ")", "\n", "pred_file", "=", "codecs", ".", "open", "(", "pred_path", ",", "'w'", ",", "'utf8'", ")", "\n", "for", "l", "in", "create_output", "(", "seqs", ",", "gold_stags", ")", ":", "\n", "        ", "print", "(", "l", ",", "file", "=", "ref_file", ")", "\n", "", "for", "i", ",", "l", "in", "enumerate", "(", "create_output", "(", "seqs", ",", "pred_stags", ")", ")", ":", "\n", "        ", "print", "(", "l", ",", "file", "=", "pred_file", ")", "\n", "", "ref_file", ".", "close", "(", ")", "\n", "pred_file", ".", "close", "(", ")", "\n", "\n", "os", ".", "system", "(", "'echo > %s'", "%", "temp_path", ")", "\n", "os", ".", "system", "(", "'%s  %s %s %s > %s'", "%", "(", "'./score.perl'", ",", "temp_path", ",", "ref_path", ",", "pred_path", ",", "score_path", ")", ")", "\n", "# Sighan evaluation results", "\n", "os", ".", "system", "(", "'tail -n 7 %s > %s'", "%", "(", "score_path", ",", "temp_path", ")", ")", "\n", "eval_lines", "=", "[", "l", ".", "rstrip", "(", ")", "for", "l", "in", "codecs", ".", "open", "(", "temp_path", ",", "'r'", ",", "'utf8'", ")", "]", "\n", "# Remove temp files.", "\n", "os", ".", "remove", "(", "ref_path", ")", "\n", "os", ".", "remove", "(", "pred_path", ")", "\n", "os", ".", "remove", "(", "score_path", ")", "\n", "os", ".", "remove", "(", "temp_path", ")", "\n", "# Precision, Recall and F1 score", "\n", "return", "(", "float", "(", "eval_lines", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ",", "\n", "float", "(", "eval_lines", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ",", "\n", "float", "(", "eval_lines", "[", "2", "]", ".", "split", "(", "':'", ")", "[", "1", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.__init__": [[17, 53], ["cws.read_train_file", "cws.read_train_file", "cws.read_train_file", "cws.read_train_file", "train.DAATNet.add_placeholders", "train.DAATNet.read_data", "train.DAATNet.build_model", "codecs.open", "codecs.open", "codecs.open", "codecs.open"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.read_train_file", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.read_train_file", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.read_train_file", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.read_train_file", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.add_placeholders", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.read_data", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.build_model"], ["    ", "def", "__init__", "(", "self", ",", "src_train_path", ",", "src_test_path", ",", "tgt_train_path", ",", "tgt_test_path", ",", "emb_file", ",", "num_tags", ",", "batch_size", ",", "lr", ",", "epochs", ",", "emb_size", ",", "hidden_layers", ",", "\n", "kernel_size", ",", "channels", ",", "dropout_emb", ",", "dropout_hidden", ",", "use_wn", ",", "use_crf", ",", "share_crf", ",", "use_src_crf", ",", "num_filters", ",", "filter_sizes", ")", ":", "\n", "\n", "        ", "self", ".", "src_train_path", "=", "src_train_path", "\n", "self", ".", "src_test_path", "=", "src_test_path", "\n", "self", ".", "tgt_train_path", "=", "tgt_train_path", "\n", "self", ".", "tgt_test_path", "=", "tgt_test_path", "\n", "self", ".", "pre_trained_emb_path", "=", "emb_file", "\n", "\n", "self", ".", "num_tags", "=", "num_tags", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "lr", "=", "lr", "\n", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "epochs", "=", "epochs", "\n", "\n", "self", ".", "hidden_layers", "=", "hidden_layers", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "dropout_emb", "=", "dropout_emb", "\n", "self", ".", "dropout_hidden", "=", "dropout_hidden", "\n", "self", ".", "use_wn", "=", "use_wn", "\n", "self", ".", "use_crf", "=", "use_crf", "\n", "self", ".", "share_crf", "=", "share_crf", "\n", "self", ".", "use_src_crf", "=", "use_src_crf", "\n", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "filter_sizes", "=", "filter_sizes", "\n", "\n", "self", ".", "src_train_data", "=", "cws", ".", "read_train_file", "(", "codecs", ".", "open", "(", "self", ".", "src_train_path", ",", "'r'", ",", "'utf8'", ")", ")", "\n", "self", ".", "src_test_data", "=", "cws", ".", "read_train_file", "(", "codecs", ".", "open", "(", "self", ".", "src_test_path", ",", "'r'", ",", "'utf8'", ")", ")", "\n", "self", ".", "tgt_train_data", "=", "cws", ".", "read_train_file", "(", "codecs", ".", "open", "(", "self", ".", "tgt_train_path", ",", "'r'", ",", "'utf8'", ")", ")", "\n", "self", ".", "tgt_test_data", "=", "cws", ".", "read_train_file", "(", "codecs", ".", "open", "(", "self", ".", "tgt_test_path", ",", "'r'", ",", "'utf8'", ")", ")", "\n", "\n", "self", ".", "add_placeholders", "(", ")", "\n", "self", ".", "read_data", "(", ")", "\n", "self", ".", "build_model", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.add_placeholders": [[54, 62], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder"], "methods", ["None"], ["", "def", "add_placeholders", "(", "self", ")", ":", "\n", "        ", "self", ".", "src_seq_ids", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'src_seq_ids'", ")", "\n", "self", ".", "src_stag_ids", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'src_stag_ids'", ")", "\n", "self", ".", "src_seq_lengths", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "'src_seq_lengths'", ")", "\n", "self", ".", "tgt_seq_ids", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'tgt_seq_ids'", ")", "\n", "self", ".", "tgt_stag_ids", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'tgt_stag_ids'", ")", "\n", "self", ".", "tgt_seq_lengths", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "int32", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "'tgt_seq_lengths'", ")", "\n", "self", ".", "is_train", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "shape", "=", "[", "]", ",", "name", "=", "'is_train'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.read_data": [[63, 86], ["utils.create_mapping", "utils.create_mapping", "utils.data_to_ids", "utils.data_to_ids", "print", "os.path.isfile", "codecs.open", "utils.create_dic", "utils.create_dic", "l.split", "len", "numpy.array", "map"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_mapping", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_mapping", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_to_ids", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_to_ids", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_dic", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_dic"], ["", "def", "read_data", "(", "self", ")", ":", "\n", "# load character embeddings", "\n", "        ", "pre_trained", "=", "{", "}", "\n", "if", "self", ".", "pre_trained_emb_path", "and", "os", ".", "path", ".", "isfile", "(", "self", ".", "pre_trained_emb_path", ")", ":", "\n", "            ", "for", "l", "in", "codecs", ".", "open", "(", "self", ".", "pre_trained_emb_path", ",", "'r'", ",", "'utf8'", ")", ":", "\n", "                ", "we", "=", "l", ".", "split", "(", ")", "\n", "if", "len", "(", "we", ")", "==", "self", ".", "emb_size", "+", "1", ":", "\n", "                    ", "w", ",", "e", "=", "we", "[", "0", "]", ",", "np", ".", "array", "(", "map", "(", "float", ",", "we", "[", "1", ":", "]", ")", ")", "\n", "pre_trained", "[", "w", "]", "=", "e", "\n", "", "", "", "self", ".", "pre_trained", "=", "pre_trained", "\n", "\n", "# Load or create mappings.", "\n", "item2id", ",", "id2item", "=", "create_mapping", "(", "create_dic", "(", "self", ".", "src_train_data", "[", "0", "]", "+", "self", ".", "tgt_train_data", "[", "0", "]", ",", "add_unk", "=", "True", ",", "add_pad", "=", "True", ")", ")", "\n", "tag2id", ",", "id2tag", "=", "create_mapping", "(", "create_dic", "(", "self", ".", "src_train_data", "[", "-", "1", "]", ")", ")", "\n", "\n", "self", ".", "item2id", "=", "item2id", "\n", "self", ".", "id2item", "=", "id2item", "\n", "self", ".", "tag2id", "=", "tag2id", "\n", "self", ".", "id2tag", "=", "id2tag", "\n", "\n", "self", ".", "src_train_data_ids", "=", "data_to_ids", "(", "self", ".", "src_train_data", ",", "[", "self", ".", "item2id", "]", "+", "[", "self", ".", "tag2id", "]", ")", "\n", "self", ".", "tgt_train_data_ids", "=", "data_to_ids", "(", "self", ".", "tgt_train_data", ",", "[", "self", ".", "item2id", "]", "+", "[", "self", ".", "tag2id", "]", ")", "\n", "print", "(", "'Finishing loading the dataset!!!'", ",", "end", "=", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.inference_src": [[87, 101], ["numpy.argmax", "numpy.zeros", "xrange", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable().eval", "tensorflow.get_variable().eval", "tensorflow.get_variable().eval", "tensorflow.viterbi_decode", "tensorflow.viterbi_decode", "tensorflow.viterbi_decode", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable"], "methods", ["None"], ["", "def", "inference_src", "(", "self", ",", "scores", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_crf", ":", "\n", "            ", "return", "np", ".", "argmax", "(", "scores", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope_src_crf", ",", "reuse", "=", "True", ")", ":", "\n", "                ", "transitions", "=", "tf", ".", "get_variable", "(", "'transitions'", ")", ".", "eval", "(", "session", "=", "self", ".", "sess", ")", "\n", "", "paths", "=", "np", ".", "zeros", "(", "scores", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "xrange", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "tag_score", ",", "length", "=", "scores", "[", "i", "]", ",", "sequence_lengths", "[", "i", "]", "\n", "if", "length", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "path", ",", "_", "=", "crf", ".", "viterbi_decode", "(", "tag_score", "[", ":", "length", "]", ",", "transitions", ")", "\n", "paths", "[", "i", ",", ":", "length", "]", "=", "path", "\n", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.inference_tgt": [[102, 116], ["numpy.argmax", "numpy.zeros", "xrange", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable().eval", "tensorflow.get_variable().eval", "tensorflow.get_variable().eval", "tensorflow.viterbi_decode", "tensorflow.viterbi_decode", "tensorflow.viterbi_decode", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable"], "methods", ["None"], ["", "", "def", "inference_tgt", "(", "self", ",", "scores", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "        ", "if", "not", "self", ".", "use_crf", ":", "\n", "            ", "return", "np", ".", "argmax", "(", "scores", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope_tgt_crf", ",", "reuse", "=", "True", ")", ":", "\n", "                ", "transitions", "=", "tf", ".", "get_variable", "(", "'transitions'", ")", ".", "eval", "(", "session", "=", "self", ".", "sess", ")", "\n", "", "paths", "=", "np", ".", "zeros", "(", "scores", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "np", ".", "int32", ")", "\n", "for", "i", "in", "xrange", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "tag_score", ",", "length", "=", "scores", "[", "i", "]", ",", "sequence_lengths", "[", "i", "]", "\n", "if", "length", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "path", ",", "_", "=", "crf", ".", "viterbi_decode", "(", "tag_score", "[", ":", "length", "]", ",", "transitions", ")", "\n", "paths", "[", "i", ",", ":", "length", "]", "=", "path", "\n", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_sequence": [[117, 133], ["enumerate", "len", "len", "results.append", "tmp.append", "tmp.append", "tmp.append", "results.append"], "methods", ["None"], ["", "", "def", "tag_sequence", "(", "self", ",", "data", ",", "labels", ")", ":", "\n", "        ", "assert", "len", "(", "data", ")", "==", "len", "(", "labels", ")", "\n", "results", "=", "[", "]", "\n", "tmp", "=", "[", "]", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "if", "label", "==", "'S'", ":", "\n", "                ", "results", ".", "append", "(", "data", "[", "i", "]", ")", "\n", "", "elif", "label", "==", "'B'", ":", "\n", "                ", "tmp", ".", "append", "(", "data", "[", "i", "]", ")", "\n", "", "elif", "label", "==", "'M'", ":", "\n", "                ", "tmp", ".", "append", "(", "data", "[", "i", "]", ")", "\n", "", "else", ":", "\n", "                ", "tmp", ".", "append", "(", "data", "[", "i", "]", ")", "\n", "results", ".", "append", "(", "''", ".", "join", "(", "tmp", ")", ")", "\n", "tmp", "=", "[", "]", "\n", "", "", "return", "' '", ".", "join", "(", "results", ")", ".", "encode", "(", "'utf8'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.build_model": [[134, 206], ["layer.Embedding_layer", "layer.Embedding_layer", "layer.Embedding_layer.", "layer.Embedding_layer.", "layer.GCNN_layer", "layer.GCNN_layer", "layer.GCNN_layer", "layer.TextCNN_layer", "layer.CRF_layer", "layer.CRF_layer", "layer.GCNN_layer.", "layer.GCNN_layer.", "layer.GCNN_layer.", "layer.GCNN_layer.", "layer.TextCNN_layer.", "layer.TextCNN_layer.", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "layer.CRF_layer.", "layer.CRF_layer.", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer", "tensorflow.train.AdamOptimizer.compute_gradients", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.summary.histogram", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.train.AdamOptimizer.apply_gradients", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.nn.sigmoid_cross_entropy_with_logits", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "sum", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "sum", "len", "len", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.ones_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.zeros_like", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.pow", "tensorflow.pow", "tensorflow.pow", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.pow", "tensorflow.pow", "tensorflow.pow", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.reduce_max"], "methods", ["None"], ["", "def", "build_model", "(", "self", ")", ":", "\n", "# embedding layer", "\n", "        ", "src_embedding_layer", "=", "Embedding_layer", "(", "vocab_size", "=", "len", "(", "self", ".", "item2id", ")", ",", "emb_dim", "=", "self", ".", "emb_size", ",", "scope", "=", "'src_char_emb'", ")", "\n", "tgt_embedding_layer", "=", "Embedding_layer", "(", "vocab_size", "=", "len", "(", "self", ".", "item2id", ")", ",", "emb_dim", "=", "self", ".", "emb_size", ",", "scope", "=", "'tgt_char_emb'", ")", "\n", "\n", "src_input", "=", "src_embedding_layer", "(", "self", ".", "src_seq_ids", ")", "\n", "tgt_input", "=", "tgt_embedding_layer", "(", "self", ".", "tgt_seq_ids", ")", "\n", "\n", "# gcnn encoder", "\n", "src_gcnn", "=", "GCNN_layer", "(", "hidden_layers", "=", "self", ".", "hidden_layers", ",", "kernel_size", "=", "self", ".", "kernel_size", ",", "channels", "=", "self", ".", "channels", ",", "dropout_emb", "=", "self", ".", "dropout_emb", ",", "\n", "dropout_hidden", "=", "self", ".", "dropout_hidden", ",", "use_wn", "=", "self", ".", "use_wn", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "scope", "=", "'src_gcnn'", ")", "\n", "tgt_gcnn", "=", "GCNN_layer", "(", "hidden_layers", "=", "self", ".", "hidden_layers", ",", "kernel_size", "=", "self", ".", "kernel_size", ",", "channels", "=", "self", ".", "channels", ",", "dropout_emb", "=", "self", ".", "dropout_emb", ",", "\n", "dropout_hidden", "=", "self", ".", "dropout_hidden", ",", "use_wn", "=", "self", ".", "use_wn", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "scope", "=", "'tgt_gcnn'", ")", "\n", "share_gcnn", "=", "GCNN_layer", "(", "hidden_layers", "=", "self", ".", "hidden_layers", ",", "kernel_size", "=", "self", ".", "kernel_size", ",", "channels", "=", "self", ".", "channels", ",", "dropout_emb", "=", "self", ".", "dropout_emb", ",", "\n", "dropout_hidden", "=", "self", ".", "dropout_hidden", ",", "use_wn", "=", "self", ".", "use_wn", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "scope", "=", "'share_gcnn'", ")", "\n", "\n", "# discriminator", "\n", "textCNN", "=", "TextCNN_layer", "(", "emb_size", "=", "self", ".", "emb_size", ",", "num_filters", "=", "self", ".", "num_filters", ",", "filter_sizes", "=", "self", ".", "filter_sizes", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "scope", "=", "'textcnn'", ")", "\n", "\n", "if", "self", ".", "share_crf", ":", "\n", "            ", "self", ".", "scope_src_crf", "=", "self", ".", "scope_tgt_crf", "=", "'crf'", "\n", "", "else", ":", "\n", "            ", "self", ".", "scope_src_crf", "=", "'src_crf'", "\n", "self", ".", "scope_tgt_crf", "=", "'tgt_crf'", "\n", "\n", "# crf layer", "\n", "", "src_crf", "=", "CRF_layer", "(", "num_tags", "=", "self", ".", "num_tags", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "scope", "=", "self", ".", "scope_src_crf", ")", "\n", "tgt_crf", "=", "CRF_layer", "(", "num_tags", "=", "self", ".", "num_tags", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "scope", "=", "self", ".", "scope_tgt_crf", ")", "\n", "\n", "# output of gcnn encoder", "\n", "src_hidden", "=", "src_gcnn", "(", "inputs", "=", "src_input", ",", "seq_lengths", "=", "self", ".", "src_seq_lengths", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "tgt_hidden", "=", "src_gcnn", "(", "inputs", "=", "tgt_input", ",", "seq_lengths", "=", "self", ".", "tgt_seq_lengths", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "src_hidden_share", "=", "share_gcnn", "(", "inputs", "=", "src_input", ",", "seq_lengths", "=", "self", ".", "src_seq_lengths", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "tgt_hidden_share", "=", "share_gcnn", "(", "inputs", "=", "tgt_input", ",", "seq_lengths", "=", "self", ".", "tgt_seq_lengths", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "\n", "\n", "src_textcnn", "=", "textCNN", "(", "src_hidden_share", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "tgt_textcnn", "=", "textCNN", "(", "tgt_hidden_share", ",", "is_train", "=", "self", ".", "is_train", ")", "\n", "\n", "src_hidden_concat", "=", "tf", ".", "concat", "(", "[", "src_hidden", ",", "src_hidden_share", "]", ",", "axis", "=", "-", "1", ")", "\n", "tgt_hidden_concat", "=", "tf", ".", "concat", "(", "[", "tgt_hidden", ",", "tgt_hidden_share", "]", ",", "axis", "=", "-", "1", ")", "\n", "\n", "self", ".", "src_scores", ",", "self", ".", "src_loss", "=", "src_crf", "(", "src_hidden_concat", ",", "self", ".", "src_stag_ids", ",", "self", ".", "src_seq_lengths", ")", "\n", "self", ".", "tgt_scores", ",", "self", ".", "tgt_loss", "=", "tgt_crf", "(", "tgt_hidden_concat", ",", "self", ".", "tgt_stag_ids", ",", "self", ".", "tgt_seq_lengths", ")", "\n", "\n", "self", ".", "src_d_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "src_textcnn", ",", "labels", "=", "tf", ".", "ones_like", "(", "src_textcnn", ")", ")", ")", "\n", "self", ".", "src_c_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "src_textcnn", ",", "labels", "=", "tf", ".", "zeros_like", "(", "src_textcnn", ")", ")", ")", "\n", "self", ".", "tgt_d_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "tgt_textcnn", ",", "labels", "=", "tf", ".", "ones_like", "(", "tgt_textcnn", ")", ")", ")", "\n", "self", ".", "tgt_c_loss", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "sigmoid_cross_entropy_with_logits", "(", "logits", "=", "tgt_textcnn", ",", "labels", "=", "tf", ".", "zeros_like", "(", "tgt_textcnn", ")", ")", ")", "\n", "\n", "self", ".", "loss1", "=", "self", ".", "src_loss", "+", "self", ".", "tgt_loss", "+", "self", ".", "src_d_loss", "+", "self", ".", "tgt_c_loss", "\n", "self", ".", "loss2", "=", "self", ".", "src_loss", "+", "self", ".", "tgt_loss", "+", "self", ".", "src_c_loss", "+", "self", ".", "tgt_d_loss", "\n", "\n", "src_optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "lr", ")", "\n", "grads_and_vars_src", "=", "src_optimizer", ".", "compute_gradients", "(", "loss", "=", "self", ".", "loss1", ",", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "grads_and_vars_src", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars_src", "if", "g", "is", "not", "None", "]", "\n", "\n", "grads_summary_op_src", "=", "tf", ".", "summary", ".", "histogram", "(", "'grads_src'", ",", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "g", ",", "[", "-", "1", "]", ")", "for", "g", ",", "_", "in", "grads_and_vars_src", "]", ",", "0", ")", ")", "\n", "grads_norm_src", "=", "tf", ".", "sqrt", "(", "sum", "(", "[", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "g", ",", "2", ")", ")", "for", "g", ",", "_", "in", "grads_and_vars_src", "]", ")", ")", "\n", "grads_and_vars_src", "=", "[", "(", "g", "/", "(", "tf", ".", "reduce_max", "(", "[", "grads_norm_src", ",", "5", "]", ")", "/", "5", ")", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars_src", "]", "\n", "\n", "self", ".", "train_op_src", "=", "src_optimizer", ".", "apply_gradients", "(", "grads_and_vars_src", ")", "\n", "\n", "tgt_optimizer", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "self", ".", "lr", ")", "\n", "grads_and_vars_tgt", "=", "tgt_optimizer", ".", "compute_gradients", "(", "loss", "=", "self", ".", "loss2", ",", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "grads_and_vars_tgt", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars_tgt", "if", "g", "is", "not", "None", "]", "\n", "\n", "grads_summary_op_tgt", "=", "tf", ".", "summary", ".", "histogram", "(", "'grads_tgt'", ",", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "g", ",", "[", "-", "1", "]", ")", "for", "g", ",", "_", "in", "grads_and_vars_tgt", "]", ",", "0", ")", ")", "\n", "grads_norm_tgt", "=", "tf", ".", "sqrt", "(", "sum", "(", "[", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "g", ",", "2", ")", ")", "for", "g", ",", "_", "in", "grads_and_vars_tgt", "]", ")", ")", "\n", "grads_and_vars_tgt", "=", "[", "(", "g", "/", "(", "tf", ".", "reduce_max", "(", "[", "grads_norm_tgt", ",", "5", "]", ")", "/", "5", ")", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars_tgt", "]", "\n", "\n", "self", ".", "train_op_tgt", "=", "tgt_optimizer", ".", "apply_gradients", "(", "grads_and_vars_tgt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.train": [[207, 302], ["tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.global_variables_initializer", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.ConfigProto", "tensorflow.ConfigProto", "tensorflow.ConfigProto", "tensorflow.Session", "tensorflow.Session", "tensorflow.Session", "print", "print", "train.DAATNet.sess.run", "time.time", "print", "range", "train.DAATNet.sess.close", "tensorflow.global_variables", "tensorflow.global_variables", "tensorflow.global_variables", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "train.DAATNet.sess.run", "train.DAATNet.sess.run", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "train.DAATNet.sess.run", "train.DAATNet.sess.run", "print", "time.time", "utils.data_iterator", "utils.data_iterator", "range", "print", "tensorflow.get_variable.assign", "tensorflow.get_variable.assign", "utils.create_input", "src_seq_ids_all.append", "src_stag_ids_all.append", "src_seq_lengths_all.append", "utils.create_input", "tgt_seq_ids_all.append", "tgt_stag_ids_all.append", "tgt_seq_lengths_all.append", "min", "cws.evaluator", "cws.evaluator", "len", "len", "len", "src_seq_ids_all[].astype", "src_seq_lengths_all[].astype", "src_stag_ids_all[].astype", "tgt_seq_ids_all[].astype", "tgt_seq_lengths_all[].astype", "tgt_stag_ids_all[].astype", "train.DAATNet.sess.run", "train.DAATNet.sess.run", "print", "train.DAATNet.tag_all_src", "train.DAATNet.tag_all_tgt"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_iterator", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_iterator", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_input", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_input", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.evaluator", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.cws.evaluator", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_all_src", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_all_tgt"], ["", "def", "train", "(", "self", ")", ":", "\n", "        ", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "self", ".", "sess", "=", "tf", ".", "Session", "(", "config", "=", "config", ")", "\n", "print", "(", "'Finished.'", ")", "\n", "print", "(", "'Start training the network...'", ")", "\n", "self", ".", "sess", ".", "run", "(", "init_op", ")", "\n", "start_time_begin", "=", "time", ".", "time", "(", ")", "\n", "with", "tf", ".", "variable_scope", "(", "'src_char_emb'", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "embeddings", "=", "tf", ".", "get_variable", "(", "'embeddings'", ")", "\n", "value", "=", "self", ".", "sess", ".", "run", "(", "embeddings", ")", "\n", "count", "=", "0", "\n", "for", "item", "in", "self", ".", "item2id", ":", "\n", "                ", "item_id", "=", "self", ".", "item2id", "[", "item", "]", "\n", "if", "item", "in", "self", ".", "pre_trained", ":", "\n", "                    ", "value", "[", "item_id", "]", "=", "self", ".", "pre_trained", "[", "item", "]", "\n", "count", "+=", "1", "\n", "", "", "self", ".", "sess", ".", "run", "(", "embeddings", ".", "assign", "(", "value", ")", ")", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'tgt_char_emb'", ",", "reuse", "=", "True", ")", ":", "\n", "            ", "embeddings", "=", "tf", ".", "get_variable", "(", "'embeddings'", ")", "\n", "value", "=", "self", ".", "sess", ".", "run", "(", "embeddings", ")", "\n", "count", "=", "0", "\n", "for", "item", "in", "self", ".", "item2id", ":", "\n", "                ", "item_id", "=", "self", ".", "item2id", "[", "item", "]", "\n", "if", "item", "in", "self", ".", "pre_trained", ":", "\n", "                    ", "value", "[", "item_id", "]", "=", "self", ".", "pre_trained", "[", "item", "]", "\n", "count", "+=", "1", "\n", "", "", "self", ".", "sess", ".", "run", "(", "embeddings", ".", "assign", "(", "value", ")", ")", "\n", "\n", "", "print", "(", "'%d of %d character embeddings were loaded from pre-trained.'", "%", "(", "count", ",", "len", "(", "self", ".", "item2id", ")", ")", ")", "\n", "\n", "global_step", "=", "0", "\n", "for", "epoch", "in", "range", "(", "1", ",", "self", ".", "epochs", "+", "1", ")", ":", "\n", "            ", "print", "(", "'Starting training network epoch %d...'", "%", "epoch", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_ep", "=", "0", "\n", "n_step", "=", "0", "\n", "src_iterator", "=", "data_iterator", "(", "self", ".", "src_train_data_ids", ",", "self", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "tgt_iterator", "=", "data_iterator", "(", "self", ".", "tgt_train_data_ids", ",", "self", ".", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "src_seq_ids_all", "=", "[", "]", "\n", "src_stag_ids_all", "=", "[", "]", "\n", "src_seq_lengths_all", "=", "[", "]", "\n", "tgt_seq_ids_all", "=", "[", "]", "\n", "tgt_stag_ids_all", "=", "[", "]", "\n", "tgt_seq_lengths_all", "=", "[", "]", "\n", "\n", "for", "batch", "in", "src_iterator", ":", "\n", "                ", "batch", "=", "create_input", "(", "batch", ")", "\n", "seq_ids", ",", "seq_other_ids_list", ",", "stag_ids", ",", "seq_lengths", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", ":", "-", "2", "]", ",", "batch", "[", "-", "2", "]", ",", "batch", "[", "-", "1", "]", "\n", "src_seq_ids_all", ".", "append", "(", "seq_ids", ")", "\n", "src_stag_ids_all", ".", "append", "(", "stag_ids", ")", "\n", "src_seq_lengths_all", ".", "append", "(", "seq_lengths", ")", "\n", "\n", "", "for", "batch", "in", "tgt_iterator", ":", "\n", "                ", "batch", "=", "create_input", "(", "batch", ")", "\n", "seq_ids", ",", "seq_other_ids_list", ",", "stag_ids", ",", "seq_lengths", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", ":", "-", "2", "]", ",", "batch", "[", "-", "2", "]", ",", "batch", "[", "-", "1", "]", "\n", "tgt_seq_ids_all", ".", "append", "(", "seq_ids", ")", "\n", "tgt_stag_ids_all", ".", "append", "(", "stag_ids", ")", "\n", "tgt_seq_lengths_all", ".", "append", "(", "seq_lengths", ")", "\n", "\n", "", "eval_batch_size", "=", "1024", "\n", "for", "i", "in", "range", "(", "min", "(", "len", "(", "src_seq_ids_all", ")", ",", "len", "(", "tgt_seq_ids_all", ")", ")", ")", ":", "\n", "                ", "feed_dict", "=", "{", "self", ".", "src_seq_ids", ":", "src_seq_ids_all", "[", "i", "]", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "src_seq_lengths", ":", "src_seq_lengths_all", "[", "i", "]", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "src_stag_ids", ":", "src_stag_ids_all", "[", "i", "]", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "tgt_seq_ids", ":", "tgt_seq_ids_all", "[", "i", "]", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "tgt_seq_lengths", ":", "tgt_seq_lengths_all", "[", "i", "]", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "tgt_stag_ids", ":", "tgt_stag_ids_all", "[", "i", "]", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "is_train", ":", "True", "}", "\n", "\n", "n_step", "+=", "1", "\n", "global_step", "+=", "1", "\n", "if", "i", "%", "2", "==", "0", ":", "\n", "                    ", "_", ",", "src_loss", ",", "tgt_loss", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op_src", ",", "self", ".", "src_loss", ",", "self", ".", "tgt_loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "", "else", ":", "\n", "                    ", "_", ",", "src_loss", ",", "tgt_loss", "=", "self", ".", "sess", ".", "run", "(", "[", "self", ".", "train_op_tgt", ",", "self", ".", "src_loss", ",", "self", ".", "tgt_loss", "]", ",", "feed_dict", "=", "feed_dict", ")", "\n", "\n", "", "if", "global_step", "%", "100", "==", "0", ":", "\n", "                    ", "print", "(", "'Step %d, src_loss %.6f, tgt_loss %.6f'", "%", "(", "global_step", ",", "src_loss", ",", "tgt_loss", ")", ")", "\n", "\n", "", "", "if", "self", ".", "use_src_crf", ":", "\n", "                ", "t_test_pre", ",", "t_test_rec", ",", "t_test_f1", "=", "cws", ".", "evaluator", "(", "(", "self", ".", "tgt_test_data", "[", "0", "]", ",", "self", ".", "tgt_test_data", "[", "-", "1", "]", ",", "self", ".", "tag_all_src", "(", "self", ".", "tgt_test_data", "[", ":", "-", "1", "]", ",", "eval_batch_size", ")", "[", "1", "]", ")", ",", "\n", "'tgt_test'", ",", "epoch", ")", "\n", "", "else", ":", "\n", "                ", "t_test_pre", ",", "t_test_rec", ",", "t_test_f1", "=", "cws", ".", "evaluator", "(", "(", "self", ".", "tgt_test_data", "[", "0", "]", ",", "self", ".", "tgt_test_data", "[", "-", "1", "]", ",", "self", ".", "tag_all_tgt", "(", "self", ".", "tgt_test_data", "[", ":", "-", "1", "]", ",", "eval_batch_size", ")", "[", "1", "]", ")", ",", "\n", "'tgt_test'", ",", "epoch", ")", "\n", "\n", "", "print", "(", "\"Target domain test precision / recall / f1 score: %.2f / %.2f / %.2f\"", "%", "\n", "(", "t_test_pre", "*", "100", ",", "t_test_rec", "*", "100", ",", "t_test_f1", "*", "100", ")", ")", "\n", "", "self", ".", "sess", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_src": [[304, 319], ["utils.data_to_ids", "utils.create_input", "train.DAATNet.sess.run", "train.DAATNet.inference_src", "itertools.izip", "seq_ids.astype", "seq_lengths.astype", "output.append", "zip"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_to_ids", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_input", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.inference_src"], ["", "def", "tag_src", "(", "self", ",", "data_iter", ")", ":", "\n", "        ", "output", "=", "[", "]", "\n", "for", "data", "in", "data_iter", ":", "\n", "            ", "batch", "=", "data_to_ids", "(", "data", ",", "[", "self", ".", "item2id", "]", ")", "\n", "batch", "=", "create_input", "(", "batch", ")", "\n", "seq_ids", ",", "seq_other_ids_list", ",", "seq_lengths", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", ":", "-", "1", "]", ",", "batch", "[", "-", "1", "]", "\n", "feed_dict", "=", "{", "self", ".", "src_seq_ids", ":", "seq_ids", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "src_seq_lengths", ":", "seq_lengths", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "is_train", ":", "False", "}", "\n", "scores", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "src_scores", ",", "feed_dict", ")", "\n", "stag_ids", "=", "self", ".", "inference_src", "(", "scores", ",", "seq_lengths", ")", "\n", "for", "seq", ",", "stag_id", ",", "length", "in", "izip", "(", "data", "[", "0", "]", ",", "stag_ids", ",", "seq_lengths", ")", ":", "\n", "                ", "output", ".", "append", "(", "(", "seq", ",", "[", "self", ".", "id2tag", "[", "t", "]", "for", "t", "in", "stag_id", "[", ":", "length", "]", "]", ")", ")", "\n", "", "yield", "zip", "(", "*", "output", ")", "\n", "output", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_all_src": [[320, 326], ["utils.data_iterator", "train.DAATNet.tag_src", "zip", "output.extend", "zip"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_iterator", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_src"], ["", "", "def", "tag_all_src", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "        ", "data_iter", "=", "data_iterator", "(", "data", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "output", "=", "[", "]", "\n", "for", "b", "in", "self", ".", "tag_src", "(", "data_iter", ")", ":", "\n", "            ", "output", ".", "extend", "(", "zip", "(", "*", "b", ")", ")", "\n", "", "return", "zip", "(", "*", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_tgt": [[327, 342], ["utils.data_to_ids", "utils.create_input", "train.DAATNet.sess.run", "train.DAATNet.inference_tgt", "itertools.izip", "seq_ids.astype", "seq_lengths.astype", "output.append", "zip"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_to_ids", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_input", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.inference_tgt"], ["", "def", "tag_tgt", "(", "self", ",", "data_iter", ")", ":", "\n", "        ", "output", "=", "[", "]", "\n", "for", "data", "in", "data_iter", ":", "\n", "            ", "batch", "=", "data_to_ids", "(", "data", ",", "[", "self", ".", "item2id", "]", ")", "\n", "batch", "=", "create_input", "(", "batch", ")", "\n", "seq_ids", ",", "seq_other_ids_list", ",", "seq_lengths", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", ":", "-", "1", "]", ",", "batch", "[", "-", "1", "]", "\n", "feed_dict", "=", "{", "self", ".", "tgt_seq_ids", ":", "seq_ids", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "tgt_seq_lengths", ":", "seq_lengths", ".", "astype", "(", "np", ".", "int32", ")", ",", "\n", "self", ".", "is_train", ":", "False", "}", "\n", "scores", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "tgt_scores", ",", "feed_dict", ")", "\n", "stag_ids", "=", "self", ".", "inference_tgt", "(", "scores", ",", "seq_lengths", ")", "\n", "for", "seq", ",", "stag_id", ",", "length", "in", "izip", "(", "data", "[", "0", "]", ",", "stag_ids", ",", "seq_lengths", ")", ":", "\n", "                ", "output", ".", "append", "(", "(", "seq", ",", "[", "self", ".", "id2tag", "[", "t", "]", "for", "t", "in", "stag_id", "[", ":", "length", "]", "]", ")", ")", "\n", "", "yield", "zip", "(", "*", "output", ")", "\n", "output", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_all_tgt": [[343, 349], ["utils.data_iterator", "train.DAATNet.tag_tgt", "zip", "output.extend", "zip"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_iterator", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.train.DAATNet.tag_tgt"], ["", "", "def", "tag_all_tgt", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "        ", "data_iter", "=", "data_iterator", "(", "data", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "output", "=", "[", "]", "\n", "for", "b", "in", "self", ".", "tag_tgt", "(", "data_iter", ")", ":", "\n", "            ", "output", ".", "extend", "(", "zip", "(", "*", "b", ")", ")", "\n", "", "return", "zip", "(", "*", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.Embedding_layer.__init__": [[8, 18], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.layers.Dense", "tensorflow.layers.Dense", "tensorflow.layers.Dense"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "vocab_size", ",", "emb_dim", ",", "emb_project", "=", "False", ",", "scope", "=", "\"char_emb\"", ")", ":", "\n", "        ", "self", ".", "scope", "=", "scope", "\n", "self", ".", "emb_project", "=", "emb_project", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "\n", "            ", "self", ".", "embeddings", "=", "tf", ".", "get_variable", "(", "name", "=", "\"embeddings\"", ",", "shape", "=", "[", "vocab_size", ",", "emb_dim", "]", ",", "dtype", "=", "tf", ".", "float32", ",", "\n", "trainable", "=", "True", ")", "\n", "\n", "if", "self", ".", "emb_project", ":", "\n", "                ", "self", ".", "dense", "=", "tf", ".", "layers", ".", "Dense", "(", "units", "=", "emb_dim", ",", "use_bias", "=", "True", ",", "_reuse", "=", "tf", ".", "AUTO_REUSE", ",", "name", "=", "\"emb_project\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.Embedding_layer.__call__": [[19, 25], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "layer.Embedding_layer.dense"], "methods", ["None"], ["", "", "", "def", "__call__", "(", "self", ",", "char_ids", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ")", ":", "\n", "            ", "char_emb", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "self", ".", "embeddings", ",", "char_ids", ")", "\n", "if", "self", ".", "emb_project", ":", "\n", "                ", "char_emb", "=", "self", ".", "dense", "(", "char_emb", ")", "\n", "", "", "return", "char_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.GCNN_layer.__init__": [[28, 37], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "hidden_layers", ",", "kernel_size", ",", "channels", ",", "dropout_emb", ",", "dropout_hidden", ",", "use_wn", "=", "True", ",", "reuse", "=", "None", ",", "scope", "=", "'gcnn'", ")", ":", "\n", "        ", "self", ".", "hidden_layers", "=", "hidden_layers", "\n", "self", ".", "kernel_size", "=", "kernel_size", "\n", "self", ".", "channels", "=", "channels", "\n", "self", ".", "dropout_emb", "=", "dropout_emb", "\n", "self", ".", "dropout_hidden", "=", "dropout_hidden", "\n", "self", ".", "use_wn", "=", "use_wn", "\n", "self", ".", "reuse", "=", "reuse", "\n", "self", ".", "scope", "=", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.GCNN_layer.__call__": [[39, 86], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "xrange", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.cond.get_shape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "seq_lengths", ",", "is_train", ")", ":", "\n", "# Define the encoder", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ",", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", ")", ")", ":", "\n", "            ", "masks", "=", "tf", ".", "cast", "(", "tf", ".", "sequence_mask", "(", "seq_lengths", ")", ",", "tf", ".", "float32", ")", "\n", "# Dropout on embedding output.", "\n", "if", "self", ".", "dropout_emb", ":", "\n", "                ", "inputs", "=", "tf", ".", "cond", "(", "is_train", ",", "\n", "lambda", ":", "tf", ".", "nn", ".", "dropout", "(", "inputs", ",", "1", "-", "self", ".", "dropout_emb", ")", ",", "\n", "lambda", ":", "inputs", ")", "\n", "\n", "", "hidden_output", "=", "inputs", "\n", "pre_channels", "=", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "for", "i", "in", "xrange", "(", "self", ".", "hidden_layers", ")", ":", "\n", "                ", "k", "=", "self", ".", "kernel_size", "\n", "cur_channels", "=", "self", ".", "channels", "[", "i", "]", "\n", "filter_w", "=", "tf", ".", "get_variable", "(", "'filter_w_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "pre_channels", ",", "cur_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "filter_v", "=", "tf", ".", "get_variable", "(", "'filter_v_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "pre_channels", ",", "cur_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "bias_b", "=", "tf", ".", "get_variable", "(", "'bias_b_%d'", "%", "i", ",", "shape", "=", "[", "cur_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "bias_c", "=", "tf", ".", "get_variable", "(", "'bias_c_%d'", "%", "i", ",", "shape", "=", "[", "cur_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "tf", ".", "float32", ")", ")", "\n", "\n", "# Weight normalization.", "\n", "if", "self", ".", "use_wn", ":", "\n", "                    ", "epsilon", "=", "1e-12", "\n", "g_w", "=", "tf", ".", "get_variable", "(", "'g_w_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "1", ",", "cur_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "g_v", "=", "tf", ".", "get_variable", "(", "'g_v_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "1", ",", "cur_channels", "]", ",", "dtype", "=", "tf", ".", "float32", ")", "\n", "filter_w", "=", "g_w", "*", "filter_w", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "filter_w", "**", "2", ",", "1", ",", "keepdims", "=", "True", ")", ")", "+", "epsilon", ")", "\n", "filter_v", "=", "g_v", "*", "filter_v", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "filter_v", "**", "2", ",", "1", ",", "keepdims", "=", "True", ")", ")", "+", "epsilon", ")", "\n", "\n", "", "w", "=", "tf", ".", "nn", ".", "conv1d", "(", "hidden_output", ",", "filter_w", ",", "1", ",", "'SAME'", ")", "+", "bias_b", "\n", "v", "=", "tf", ".", "nn", ".", "conv1d", "(", "hidden_output", ",", "filter_v", ",", "1", ",", "'SAME'", ")", "+", "bias_c", "\n", "\n", "hidden_output", "=", "w", "*", "tf", ".", "nn", ".", "sigmoid", "(", "v", ")", "\n", "\n", "hidden_output", "=", "hidden_output", "*", "tf", ".", "expand_dims", "(", "masks", ",", "-", "1", ")", "\n", "\n", "if", "self", ".", "dropout_hidden", ":", "\n", "                    ", "hidden_output", "=", "tf", ".", "cond", "(", "is_train", ",", "\n", "lambda", ":", "tf", ".", "nn", ".", "dropout", "(", "hidden_output", ",", "1", "-", "self", ".", "dropout_hidden", ")", ",", "\n", "lambda", ":", "hidden_output", "\n", ")", "\n", "\n", "", "pre_channels", "=", "cur_channels", "\n", "\n", "", "hidden_output", "=", "hidden_output", "\n", "return", "hidden_output", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.CRF_layer.__init__": [[89, 93], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "num_tags", ",", "reuse", "=", "None", ",", "scope", "=", "\"crf\"", ")", ":", "\n", "        ", "self", ".", "num_tags", "=", "num_tags", "\n", "self", ".", "reuse", "=", "reuse", "\n", "self", ".", "scope", "=", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.CRF_layer.__call__": [[94, 99], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.crf_log_likelihood", "tensorflow.crf_log_likelihood", "tensorflow.crf_log_likelihood", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "stag_ids", ",", "seq_lengths", ")", ":", "\n", "        ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ")", ":", "\n", "            ", "scores", "=", "layers", ".", "fully_connected", "(", "inputs", ",", "self", ".", "num_tags", ",", "tf", ".", "identity", ")", "\n", "cost", ",", "transitions", "=", "crf", ".", "crf_log_likelihood", "(", "inputs", "=", "scores", ",", "tag_indices", "=", "stag_ids", ",", "sequence_lengths", "=", "seq_lengths", ")", "\n", "return", "scores", ",", "tf", ".", "reduce_mean", "(", "-", "cost", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.TextCNN_layer.__init__": [[102, 109], ["len"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "emb_size", ",", "num_filters", ",", "filter_sizes", ",", "reuse", "=", "None", ",", "scope", "=", "'textcnn'", ")", ":", "\n", "        ", "self", ".", "emb_size", "=", "emb_size", "\n", "self", ".", "num_filters", "=", "num_filters", "\n", "self", ".", "filter_sizes", "=", "filter_sizes", "\n", "self", ".", "num_filters_total", "=", "num_filters", "*", "len", "(", "filter_sizes", ")", "\n", "self", ".", "reuse", "=", "reuse", "\n", "self", ".", "scope", "=", "scope", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.layer.TextCNN_layer.__call__": [[110, 128], ["tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "enumerate", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.layers.dense", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.conv2d", "tensorflow.nn.conv2d", "tensorflow.nn.conv2d", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.reduce_max", "pooled_outputs.append", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "tensorflow.nn.bias_add", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.contrib.layers.xavier_initializer", "tensorflow.contrib.layers.xavier_initializer"], "methods", ["None"], ["", "def", "__call__", "(", "self", ",", "inputs", ",", "is_train", ")", ":", "\n", "# Text cnn model", "\n", "        ", "inputs_expanded", "=", "tf", ".", "expand_dims", "(", "inputs", ",", "-", "1", ")", "\n", "pooled_outputs", "=", "[", "]", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "self", ".", "reuse", ")", ":", "\n", "            ", "for", "i", ",", "filter_size", "in", "enumerate", "(", "self", ".", "filter_sizes", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "\"conv-%s\"", "%", "filter_size", ")", ":", "\n", "                    ", "w", "=", "tf", ".", "get_variable", "(", "\"filter-%s\"", "%", "filter_size", ",", "[", "filter_size", ",", "self", ".", "emb_size", ",", "1", ",", "self", ".", "num_filters", "]", ",", "initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ")", "\n", "b", "=", "tf", ".", "get_variable", "(", "\"b-%s\"", "%", "filter_size", ",", "[", "self", ".", "num_filters", "]", ")", "\n", "conv", "=", "tf", ".", "nn", ".", "conv2d", "(", "inputs_expanded", ",", "w", ",", "strides", "=", "[", "1", ",", "1", ",", "1", ",", "1", "]", ",", "padding", "=", "\"VALID\"", ",", "name", "=", "\"conv\"", ")", "\n", "h", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "nn", ".", "bias_add", "(", "conv", ",", "b", ")", ",", "name", "=", "\"relu\"", ")", "\n", "pooled", "=", "tf", ".", "reduce_max", "(", "h", ",", "axis", "=", "1", ",", "keepdims", "=", "True", ")", "\n", "pooled_outputs", ".", "append", "(", "pooled", ")", "\n", "", "", "h_pool", "=", "tf", ".", "concat", "(", "pooled_outputs", ",", "3", ")", "\n", "h_pool_flat", "=", "tf", ".", "reshape", "(", "h_pool", ",", "[", "-", "1", ",", "self", ".", "num_filters_total", "]", ")", "\n", "h_full_conn", "=", "tf", ".", "layers", ".", "dense", "(", "h_pool_flat", ",", "1", ",", "activation", "=", "None", ",", "use_bias", "=", "True", ",", "kernel_initializer", "=", "tf", ".", "contrib", ".", "layers", ".", "xavier_initializer", "(", ")", ")", "\n", "h_drop", "=", "tf", ".", "nn", ".", "dropout", "(", "h_full_conn", ",", "keep_prob", "=", "0.5", ")", "\n", "", "return", "h_drop", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.__init__": [[20, 23], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "scope", ",", "sess", ")", ":", "\n", "        ", "self", ".", "scope", "=", "scope", "\n", "self", ".", "sess", "=", "sess", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.build_input_graph": [[24, 39], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "range", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "word_outputs.append", "tensorflow.concat", "tensorflow.concat", "tensorflow.concat", "range", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup", "tensorflow.nn.embedding_lookup"], "methods", ["None"], ["", "def", "build_input_graph", "(", "self", ",", "vocab_size", ",", "emb_size", ",", "word_vocab_size", ",", "word_emb_size", ",", "word_window_size", ")", ":", "\n", "        ", "\"\"\"\n        Gather embeddings from lookup tables.\n        \"\"\"", "\n", "seq_ids", "=", "tf", ".", "placeholder", "(", "dtype", "=", "INT_TYPE", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'seq_ids'", ")", "\n", "seq_word_ids", "=", "[", "tf", ".", "placeholder", "(", "dtype", "=", "INT_TYPE", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'seq_feature_%d_ids'", "%", "i", ")", "\n", "for", "i", "in", "range", "(", "word_window_size", ")", "]", "\n", "embeddings", "=", "tf", ".", "get_variable", "(", "'embeddings'", ",", "[", "vocab_size", ",", "emb_size", "]", ")", "\n", "embedding_output", "=", "tf", ".", "nn", ".", "embedding_lookup", "(", "[", "embeddings", "]", ",", "seq_ids", ")", "\n", "word_outputs", "=", "[", "]", "\n", "word_embeddings", "=", "tf", ".", "get_variable", "(", "'word_embeddings'", ",", "[", "word_vocab_size", ",", "word_emb_size", "]", ")", "\n", "for", "i", "in", "range", "(", "word_window_size", ")", ":", "\n", "            ", "word_outputs", ".", "append", "(", "tf", ".", "nn", ".", "embedding_lookup", "(", "[", "word_embeddings", "]", ",", "seq_word_ids", "[", "i", "]", ")", ")", "\n", "\n", "", "return", "seq_ids", ",", "seq_word_ids", ",", "tf", ".", "concat", "(", "[", "embedding_output", "]", "+", "word_outputs", ",", "2", ",", "'inputs'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.build_tagging_graph": [[40, 149], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "xrange", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.fully_connected", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.merge_all", "tensorflow.summary.merge_all", "tensorflow.summary.merge_all", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.get_collection", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.sequence_mask", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.crf_log_likelihood", "tensorflow.crf_log_likelihood", "tensorflow.crf_log_likelihood", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.one_hot_encoding", "tensorflow.one_hot_encoding", "tensorflow.one_hot_encoding", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.nn.softmax_cross_entropy_with_logits", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.trainable_variables", "tensorflow.group", "tensorflow.group", "tensorflow.group", "tensorflow.cond.get_shape", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.nn.conv1d", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.batch_norm", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.expand_dims", "tensorflow.cond", "tensorflow.cond", "tensorflow.cond", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.cast", "tensorflow.cast", "tensorflow.cast", "tensorflow.control_dependencies", "tensorflow.control_dependencies", "tensorflow.control_dependencies", "tensorflow.identity", "tensorflow.identity", "tensorflow.identity", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.zeros_initializer", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.nn.relu", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.sqrt", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.nn.dropout", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.reshape", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.nn.l2_loss", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.nn.sigmoid", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.tanh", "tensorflow.shape", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "def", "build_tagging_graph", "(", "self", ",", "inputs", ",", "hidden_layers", ",", "channels", ",", "num_tags", ",", "use_crf", ",", "lamd", ",", "dropout_emb", ",", "\n", "dropout_hidden", ",", "kernel_size", ",", "use_bn", ",", "use_wn", ",", "active_type", ")", ":", "\n", "        ", "\"\"\"\n        Build a deep neural model for sequence tagging.\n        \"\"\"", "\n", "stag_ids", "=", "tf", ".", "placeholder", "(", "dtype", "=", "INT_TYPE", ",", "shape", "=", "[", "None", ",", "None", "]", ",", "name", "=", "'stag_ids'", ")", "\n", "seq_lengths", "=", "tf", ".", "placeholder", "(", "dtype", "=", "INT_TYPE", ",", "shape", "=", "[", "None", "]", ",", "name", "=", "'seq_lengths'", ")", "\n", "\n", "# Default is not train.", "\n", "is_train", "=", "tf", ".", "placeholder", "(", "dtype", "=", "tf", ".", "bool", ",", "shape", "=", "[", "]", ",", "name", "=", "'is_train'", ")", "\n", "\n", "masks", "=", "tf", ".", "cast", "(", "tf", ".", "sequence_mask", "(", "seq_lengths", ")", ",", "FLOAT_TYPE", ")", "\n", "\n", "# Dropout on embedding output.", "\n", "if", "dropout_emb", ":", "\n", "            ", "inputs", "=", "tf", ".", "cond", "(", "is_train", ",", "\n", "lambda", ":", "tf", ".", "nn", ".", "dropout", "(", "inputs", ",", "1", "-", "dropout_emb", ")", ",", "\n", "lambda", ":", "inputs", ")", "\n", "\n", "", "hidden_output", "=", "inputs", "\n", "pre_channels", "=", "inputs", ".", "get_shape", "(", ")", "[", "-", "1", "]", ".", "value", "\n", "for", "i", "in", "xrange", "(", "hidden_layers", ")", ":", "\n", "\n", "            ", "k", "=", "kernel_size", "\n", "cur_channels", "=", "channels", "[", "i", "]", "\n", "filter_w", "=", "tf", ".", "get_variable", "(", "'filter_w_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "pre_channels", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "filter_v", "=", "tf", ".", "get_variable", "(", "'filter_v_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "pre_channels", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "bias_b", "=", "tf", ".", "get_variable", "(", "'bias_b_%d'", "%", "i", ",", "shape", "=", "[", "cur_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "FLOAT_TYPE", ")", ")", "\n", "bias_c", "=", "tf", ".", "get_variable", "(", "'bias_c_%d'", "%", "i", ",", "shape", "=", "[", "cur_channels", "]", ",", "\n", "initializer", "=", "tf", ".", "zeros_initializer", "(", "dtype", "=", "FLOAT_TYPE", ")", ")", "\n", "\n", "# Weight normalization.", "\n", "if", "use_wn", ":", "\n", "                ", "epsilon", "=", "1e-12", "\n", "g_w", "=", "tf", ".", "get_variable", "(", "'g_w_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "1", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "g_v", "=", "tf", ".", "get_variable", "(", "'g_v_%d'", "%", "i", ",", "shape", "=", "[", "k", ",", "1", ",", "cur_channels", "]", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "# Perform wn", "\n", "filter_w", "=", "g_w", "*", "filter_w", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "filter_w", "**", "2", ",", "1", ",", "keep_dims", "=", "True", ")", ")", "+", "epsilon", ")", "\n", "filter_v", "=", "g_v", "*", "filter_v", "/", "(", "tf", ".", "sqrt", "(", "tf", ".", "reduce_sum", "(", "filter_v", "**", "2", ",", "1", ",", "keep_dims", "=", "True", ")", ")", "+", "epsilon", ")", "\n", "\n", "", "w", "=", "tf", ".", "nn", ".", "conv1d", "(", "hidden_output", ",", "filter_w", ",", "1", ",", "'SAME'", ")", "+", "bias_b", "\n", "v", "=", "tf", ".", "nn", ".", "conv1d", "(", "hidden_output", ",", "filter_v", ",", "1", ",", "'SAME'", ")", "+", "bias_c", "\n", "\n", "if", "use_bn", ":", "\n", "                ", "w", "=", "layers", ".", "batch_norm", "(", "inputs", "=", "v", ",", "decay", "=", "0.9", ",", "is_training", "=", "is_train", ",", "center", "=", "True", ",", "scale", "=", "True", ",", "\n", "scope", "=", "'BatchNorm_w_%d'", "%", "i", ")", "\n", "v", "=", "layers", ".", "batch_norm", "(", "inputs", "=", "w", ",", "decay", "=", "0.9", ",", "is_training", "=", "is_train", ",", "center", "=", "True", ",", "scale", "=", "True", ",", "\n", "scope", "=", "'BatchNorm_v_%d'", "%", "i", ")", "\n", "\n", "", "if", "active_type", "==", "'glu'", ":", "\n", "                ", "hidden_output", "=", "w", "*", "tf", ".", "nn", ".", "sigmoid", "(", "v", ")", "\n", "", "elif", "active_type", "==", "'relu'", ":", "\n", "                ", "hidden_output", "=", "tf", ".", "nn", ".", "relu", "(", "w", ")", "\n", "", "elif", "active_type", "==", "'gtu'", ":", "\n", "                ", "hidden_output", "=", "tf", ".", "tanh", "(", "w", ")", "*", "tf", ".", "nn", ".", "sigmoid", "(", "v", ")", "\n", "", "elif", "active_type", "==", "'tanh'", ":", "\n", "                ", "hidden_output", "=", "tf", ".", "tanh", "(", "w", ")", "\n", "", "elif", "active_type", "==", "'linear'", ":", "\n", "                ", "hidden_output", "=", "w", "\n", "", "elif", "active_type", "==", "'bilinear'", ":", "\n", "                ", "hidden_output", "=", "w", "*", "v", "\n", "\n", "# Mask paddings.", "\n", "", "hidden_output", "=", "hidden_output", "*", "tf", ".", "expand_dims", "(", "masks", ",", "-", "1", ")", "\n", "# Dropout on hidden output.", "\n", "if", "dropout_hidden", ":", "\n", "                ", "hidden_output", "=", "tf", ".", "cond", "(", "is_train", ",", "\n", "lambda", ":", "tf", ".", "nn", ".", "dropout", "(", "hidden_output", ",", "1", "-", "dropout_hidden", ")", ",", "\n", "lambda", ":", "hidden_output", "\n", ")", "\n", "\n", "", "pre_channels", "=", "cur_channels", "\n", "\n", "# Un-scaled log probabilities.", "\n", "", "scores", "=", "layers", ".", "fully_connected", "(", "hidden_output", ",", "num_tags", ",", "tf", ".", "identity", ")", "\n", "\n", "if", "use_crf", ":", "\n", "            ", "cost", ",", "transitions", "=", "crf", ".", "crf_log_likelihood", "(", "inputs", "=", "scores", ",", "tag_indices", "=", "stag_ids", ",", "\n", "sequence_lengths", "=", "seq_lengths", ")", "\n", "cost", "=", "-", "tf", ".", "reduce_mean", "(", "cost", ")", "\n", "", "else", ":", "\n", "            ", "reshaped_scores", "=", "tf", ".", "reshape", "(", "scores", ",", "[", "-", "1", ",", "num_tags", "]", ")", "\n", "reshaped_stag_ids", "=", "tf", ".", "reshape", "(", "stag_ids", ",", "[", "-", "1", "]", ")", "\n", "real_distribution", "=", "layers", ".", "one_hot_encoding", "(", "reshaped_stag_ids", ",", "num_tags", ")", "\n", "cost", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits", "(", "reshaped_scores", ",", "real_distribution", ")", "\n", "cost", "=", "tf", ".", "reduce_sum", "(", "tf", ".", "reshape", "(", "cost", ",", "tf", ".", "shape", "(", "stag_ids", ")", ")", "*", "masks", ")", "/", "tf", ".", "cast", "(", "tf", ".", "shape", "(", "inputs", ")", "[", "0", "]", ",", "\n", "FLOAT_TYPE", ")", "\n", "\n", "# Calculate L2 penalty.", "\n", "", "l2_penalty", "=", "0", "\n", "if", "lamd", ">", "0", ":", "\n", "            ", "for", "v", "in", "tf", ".", "trainable_variables", "(", ")", ":", "\n", "                ", "if", "'/B:'", "not", "in", "v", ".", "name", "and", "'/biases:'", "not", "in", "v", ".", "name", ":", "\n", "                    ", "l2_penalty", "+=", "lamd", "*", "tf", ".", "nn", ".", "l2_loss", "(", "v", ")", "\n", "", "", "", "train_cost", "=", "cost", "+", "l2_penalty", "\n", "\n", "# Summary cost.", "\n", "tf", ".", "summary", ".", "scalar", "(", "'cost'", ",", "cost", ")", "\n", "\n", "summaries", "=", "tf", ".", "summary", ".", "merge_all", "(", ")", "\n", "\n", "update_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "update_ops", ":", "\n", "            ", "updates", "=", "tf", ".", "group", "(", "*", "update_ops", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "updates", "]", ")", ":", "\n", "                ", "cost", "=", "tf", ".", "identity", "(", "cost", ")", "\n", "\n", "", "", "return", "stag_ids", ",", "seq_lengths", ",", "is_train", ",", "cost", ",", "train_cost", ",", "scores", ",", "summaries", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.build_graph": [[150, 180], ["tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tagger.Model.build_input_graph", "tagger.Model.build_tagging_graph", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer", "tensorflow.uniform_unit_scaling_initializer"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.build_input_graph", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.build_tagging_graph"], ["", "def", "build_graph", "(", "self", ")", ":", "\n", "        ", "parameters", "=", "self", ".", "parameters", "\n", "with", "tf", ".", "variable_scope", "(", "name_or_scope", "=", "self", ".", "scope", ",", "initializer", "=", "tf", ".", "uniform_unit_scaling_initializer", "(", ")", ")", ":", "\n", "            ", "seq_ids_pl", ",", "seq_other_ids_pls", ",", "inputs", "=", "self", ".", "build_input_graph", "(", "vocab_size", "=", "parameters", "[", "'vocab_size'", "]", ",", "\n", "emb_size", "=", "parameters", "[", "'emb_size'", "]", ",", "\n", "word_window_size", "=", "parameters", "[", "'word_window_size'", "]", ",", "\n", "word_vocab_size", "=", "parameters", "[", "'word_vocab_size'", "]", ",", "\n", "word_emb_size", "=", "parameters", "[", "'word_emb_size'", "]", ")", "\n", "stag_ids_pl", ",", "seq_lengths_pl", ",", "is_train_pl", ",", "cost_op", ",", "train_cost_op", ",", "scores_op", ",", "summary_op", "=", "self", ".", "build_tagging_graph", "(", "inputs", "=", "inputs", ",", "\n", "num_tags", "=", "parameters", "[", "'num_tags'", "]", ",", "\n", "use_crf", "=", "parameters", "[", "'use_crf'", "]", ",", "\n", "lamd", "=", "parameters", "[", "'lamd'", "]", ",", "\n", "dropout_emb", "=", "parameters", "[", "'dropout_emb'", "]", ",", "\n", "dropout_hidden", "=", "parameters", "[", "'dropout_hidden'", "]", ",", "\n", "hidden_layers", "=", "parameters", "[", "'hidden_layers'", "]", ",", "\n", "channels", "=", "parameters", "[", "'channels'", "]", ",", "\n", "kernel_size", "=", "parameters", "[", "'kernel_size'", "]", ",", "\n", "use_bn", "=", "parameters", "[", "'use_bn'", "]", ",", "\n", "use_wn", "=", "parameters", "[", "'use_wn'", "]", ",", "\n", "active_type", "=", "parameters", "[", "'active_type'", "]", ")", "\n", "", "self", ".", "seq_ids_pl", "=", "seq_ids_pl", "\n", "self", ".", "seq_other_ids_pls", "=", "seq_other_ids_pls", "\n", "self", ".", "stag_ids_pl", "=", "stag_ids_pl", "\n", "self", ".", "seq_lengths_pl", "=", "seq_lengths_pl", "\n", "self", ".", "is_train_pl", "=", "is_train_pl", "\n", "self", ".", "cost_op", "=", "cost_op", "\n", "self", ".", "train_cost_op", "=", "train_cost_op", "\n", "self", ".", "scores_op", "=", "scores_op", "\n", "self", ".", "summary_op", "=", "summary_op", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.inference": [[181, 207], ["numpy.argmax", "numpy.zeros", "xrange", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.variable_scope", "tensorflow.get_variable().eval", "tensorflow.get_variable().eval", "tensorflow.get_variable().eval", "tensorflow.viterbi_decode", "tensorflow.viterbi_decode", "tensorflow.viterbi_decode", "tensorflow.get_variable", "tensorflow.get_variable", "tensorflow.get_variable"], "methods", ["None"], ["", "def", "inference", "(", "self", ",", "scores", ",", "sequence_lengths", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        Inference label sequence given scores.\n        If transitions is given, then perform veterbi search, else perform greedy search.\n\n        Args:\n            scores: A numpy array with shape (batch, max_length, num_tags).\n            sequence_lengths: A numpy array with shape (batch,).\n\n        Returns:\n            A numpy array with shape (batch, max_length).\n        \"\"\"", "\n", "\n", "if", "not", "self", ".", "parameters", "[", "'use_crf'", "]", ":", "\n", "            ", "return", "np", ".", "argmax", "(", "scores", ",", "2", ")", "\n", "", "else", ":", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "True", ")", ":", "\n", "                ", "transitions", "=", "tf", ".", "get_variable", "(", "'transitions'", ")", ".", "eval", "(", "session", "=", "self", ".", "sess", ")", "\n", "", "paths", "=", "np", ".", "zeros", "(", "scores", ".", "shape", "[", ":", "2", "]", ",", "dtype", "=", "INT_TYPE", ")", "\n", "for", "i", "in", "xrange", "(", "scores", ".", "shape", "[", "0", "]", ")", ":", "\n", "                ", "tag_score", ",", "length", "=", "scores", "[", "i", "]", ",", "sequence_lengths", "[", "i", "]", "\n", "if", "length", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "path", ",", "_", "=", "crf", ".", "viterbi_decode", "(", "tag_score", "[", ":", "length", "]", ",", "transitions", ")", "\n", "paths", "[", "i", ",", ":", "length", "]", "=", "path", "\n", "", "return", "paths", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.train": [[208, 467], ["optimizer.split.split.split", "print", "os.path.join", "os.path.join", "os.path.isfile", "os.path.isfile", "tagger.data_to_ids", "print", "print", "tagger.Model.build_graph", "print", "tagger.Model.train.summary"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_to_ids", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.build_graph"], ["", "", "def", "train", "(", "self", ",", "train_data", ",", "dev_data", ",", "test_data", ",", "model_dir", ",", "log_dir", ",", "emb_size", ",", "word_emb_size", ",", "optimizer", ",", "\n", "hidden_layers", ",", "channels", ",", "kernel_size", ",", "active_type", ",", "use_bn", ",", "use_wn", ",", "use_crf", ",", "lamd", ",", "dropout_emb", ",", "\n", "dropout_hidden", ",", "evaluator", ",", "batch_size", ",", "eval_batch_size", ",", "pre_trained_emb_path", ",", "fix_word_emb", ",", "\n", "reserve_all_word_emb", ",", "pre_trained_word_emb_path", ",", "max_epoches", ",", "print_freq", ")", ":", "\n", "        ", "\"\"\"\n        This function is the main function for preparing data and training the model.\n        \"\"\"", "\n", "assert", "len", "(", "channels", ")", "==", "hidden_layers", "\n", "\n", "# Parse optimization method and parameters.", "\n", "optimizer", "=", "optimizer", ".", "split", "(", "'_'", ")", "\n", "optimizer_name", "=", "optimizer", "[", "0", "]", "\n", "optimizer_options", "=", "[", "eval", "(", "i", ")", "for", "i", "in", "optimizer", "[", "1", ":", "]", "]", "\n", "optimizer", "=", "{", "\n", "'sgd'", ":", "tf", ".", "train", ".", "GradientDescentOptimizer", ",", "\n", "'adadelta'", ":", "tf", ".", "train", ".", "AdadeltaOptimizer", ",", "\n", "'adam'", ":", "tf", ".", "train", ".", "AdamOptimizer", ",", "\n", "'mom'", ":", "tf", ".", "train", ".", "MomentumOptimizer", "\n", "}", "[", "optimizer_name", "]", "(", "*", "optimizer_options", ")", "\n", "\n", "print", "(", "'Preparing data...'", ",", "end", "=", "''", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "model_dir", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "model_dir", ")", "\n", "\n", "", "mappings_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'mappings.pkl'", ")", "\n", "parameters_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'parameters.pkl'", ")", "\n", "\n", "# Load character embeddings.", "\n", "pre_trained", "=", "{", "}", "\n", "if", "pre_trained_emb_path", "and", "os", ".", "path", ".", "isfile", "(", "pre_trained_emb_path", ")", ":", "\n", "            ", "for", "l", "in", "codecs", ".", "open", "(", "pre_trained_emb_path", ",", "'r'", ",", "'utf8'", ")", ":", "\n", "                ", "we", "=", "l", ".", "split", "(", ")", "\n", "if", "len", "(", "we", ")", "==", "emb_size", "+", "1", ":", "\n", "                    ", "w", ",", "e", "=", "we", "[", "0", "]", ",", "np", ".", "array", "(", "map", "(", "float", ",", "we", "[", "1", ":", "]", ")", ")", "\n", "pre_trained", "[", "w", "]", "=", "e", "\n", "\n", "# Load word embeddings.", "\n", "", "", "", "pre_trained_word", "=", "{", "}", "\n", "if", "pre_trained_word_emb_path", "and", "os", ".", "path", ".", "isfile", "(", "pre_trained_word_emb_path", ")", ":", "\n", "            ", "for", "l", "in", "codecs", ".", "open", "(", "pre_trained_word_emb_path", ",", "'r'", ",", "'utf8'", ",", "'ignore'", ")", ":", "\n", "                ", "we", "=", "l", ".", "split", "(", ")", "\n", "if", "len", "(", "we", ")", "==", "word_emb_size", "+", "1", ":", "\n", "                    ", "w", ",", "e", "=", "we", "[", "0", "]", ",", "np", ".", "array", "(", "map", "(", "float", ",", "we", "[", "1", ":", "]", ")", ")", "\n", "pre_trained_word", "[", "w", "]", "=", "e", "\n", "\n", "# Load or create mappings.", "\n", "", "", "", "if", "os", ".", "path", ".", "isfile", "(", "mappings_path", ")", ":", "\n", "            ", "item2id", ",", "id2item", ",", "tag2id", ",", "id2tag", ",", "word2id", ",", "id2word", "=", "pickle", ".", "load", "(", "open", "(", "mappings_path", ",", "'r'", ")", ")", "\n", "", "else", ":", "\n", "            ", "item2id", ",", "id2item", "=", "create_mapping", "(", "create_dic", "(", "train_data", "[", "0", "]", ",", "add_unk", "=", "True", ",", "add_pad", "=", "True", ")", ")", "\n", "tag2id", ",", "id2tag", "=", "create_mapping", "(", "create_dic", "(", "train_data", "[", "-", "1", "]", ")", ")", "\n", "\n", "words", "=", "[", "]", "\n", "for", "t", "in", "train_data", "[", "1", ":", "-", "1", "]", ":", "\n", "                ", "words", ".", "extend", "(", "t", ")", "\n", "", "for", "t", "in", "dev_data", "[", "1", ":", "-", "1", "]", ":", "\n", "                ", "words", ".", "extend", "(", "t", ")", "\n", "", "for", "t", "in", "test_data", "[", "1", ":", "-", "1", "]", ":", "\n", "                ", "words", ".", "extend", "(", "t", ")", "\n", "", "word_dic", "=", "create_dic", "(", "words", ",", "add_unk", "=", "True", ",", "add_pad", "=", "True", ")", "\n", "for", "k", "in", "word_dic", ".", "keys", "(", ")", ":", "\n", "                ", "if", "k", "not", "in", "pre_trained_word", "and", "k", "!=", "'<UNK>'", "and", "k", "!=", "'<PAD>'", ":", "\n", "                    ", "word_dic", ".", "pop", "(", "k", ")", "\n", "", "", "if", "reserve_all_word_emb", ":", "\n", "                ", "for", "w", "in", "pre_trained_word", ":", "\n", "                    ", "if", "w", "not", "in", "word_dic", ":", "\n", "                        ", "word_dic", "[", "w", "]", "=", "0", "\n", "", "", "", "word2id", ",", "id2word", "=", "create_mapping", "(", "word_dic", ")", "\n", "# Save the mappings to disk.", "\n", "pickle", ".", "dump", "(", "(", "item2id", ",", "id2item", ",", "tag2id", ",", "id2tag", ",", "word2id", ",", "id2word", ")", ",", "open", "(", "mappings_path", ",", "'w'", ")", ")", "\n", "\n", "# Hyper parameters.", "\n", "", "word_window_size", "=", "len", "(", "train_data", ")", "-", "2", "\n", "parameters", "=", "{", "\n", "'vocab_size'", ":", "len", "(", "item2id", ")", ",", "\n", "'emb_size'", ":", "emb_size", ",", "\n", "'word_window_size'", ":", "word_window_size", ",", "\n", "'word_vocab_size'", ":", "len", "(", "word2id", ")", ",", "\n", "'word_emb_size'", ":", "word_emb_size", ",", "\n", "'hidden_layers'", ":", "hidden_layers", ",", "\n", "'channels'", ":", "channels", ",", "\n", "'kernel_size'", ":", "kernel_size", ",", "\n", "'use_bn'", ":", "use_bn", ",", "\n", "'use_wn'", ":", "use_wn", ",", "\n", "'num_tags'", ":", "len", "(", "tag2id", ")", ",", "\n", "'use_crf'", ":", "use_crf", ",", "\n", "'lamd'", ":", "lamd", ",", "\n", "'dropout_emb'", ":", "dropout_emb", ",", "\n", "'dropout_hidden'", ":", "dropout_hidden", ",", "\n", "'active_type'", ":", "active_type", "\n", "}", "\n", "\n", "if", "os", ".", "path", ".", "isfile", "(", "parameters_path", ")", ":", "\n", "            ", "parameters_old", "=", "pickle", ".", "load", "(", "open", "(", "parameters_path", ",", "'r'", ")", ")", "\n", "if", "parameters", "!=", "parameters_old", ":", "\n", "                ", "raise", "Exception", "(", "'Network parameters are not consistent!'", ")", "\n", "", "", "else", ":", "\n", "            ", "pickle", ".", "dump", "(", "parameters", ",", "open", "(", "parameters_path", ",", "'w'", ")", ")", "\n", "\n", "", "self", ".", "item2id", "=", "item2id", "\n", "self", ".", "id2item", "=", "id2item", "\n", "self", ".", "tag2id", "=", "tag2id", "\n", "self", ".", "id2tag", "=", "id2tag", "\n", "self", ".", "word2id", "=", "word2id", "\n", "self", ".", "id2word", "=", "id2word", "\n", "self", ".", "parameters", "=", "parameters", "\n", "\n", "# Convert data to corresponding ids.", "\n", "train_data_ids", "=", "data_to_ids", "(", "\n", "train_data", ",", "[", "item2id", "]", "+", "[", "word2id", "]", "*", "word_window_size", "+", "[", "tag2id", "]", "\n", ")", "\n", "print", "(", "'Finished.'", ")", "\n", "\n", "print", "(", "\"Start building the network...\"", ",", "end", "=", "''", ")", "\n", "self", ".", "build_graph", "(", ")", "\n", "print", "(", "'Finished.'", ")", "\n", "\n", "def", "summary", "(", "name", ",", "dtype", "=", "FLOAT_TYPE", ")", ":", "\n", "            ", "value", "=", "tf", ".", "placeholder", "(", "dtype", ",", "shape", "=", "[", "]", ")", "\n", "return", "value", ",", "tf", ".", "summary", ".", "scalar", "(", "name", ",", "value", ")", "\n", "\n", "", "dev_f1_pl", ",", "dev_summary_op", "=", "summary", "(", "'dev f1'", ")", "\n", "test_f1_pl", ",", "test_summary_op", "=", "summary", "(", "'test f1'", ")", "\n", "\n", "print", "(", "'trainable variables:'", ",", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "# Clip gradients and apply.", "\n", "grads_and_vars", "=", "optimizer", ".", "compute_gradients", "(", "loss", "=", "self", ".", "train_cost_op", ",", "var_list", "=", "tf", ".", "trainable_variables", "(", ")", ")", "\n", "grads_and_vars", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars", "if", "g", "is", "not", "None", "]", "\n", "\n", "# If use fixed word embeddings, remove the grad", "\n", "if", "fix_word_emb", ":", "\n", "            ", "grads_and_vars", "=", "[", "(", "g", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars", "if", "'/word_embeddings'", "not", "in", "v", ".", "name", "]", "\n", "\n", "", "grads_summary_op", "=", "tf", ".", "summary", ".", "histogram", "(", "'grads'", ",", "tf", ".", "concat", "(", "[", "tf", ".", "reshape", "(", "g", ",", "[", "-", "1", "]", ")", "for", "g", ",", "_", "in", "grads_and_vars", "]", ",", "0", ")", ")", "\n", "grads_norm", "=", "tf", ".", "sqrt", "(", "sum", "(", "[", "tf", ".", "reduce_sum", "(", "tf", ".", "pow", "(", "g", ",", "2", ")", ")", "for", "g", ",", "_", "in", "grads_and_vars", "]", ")", ")", "\n", "grads_and_vars", "=", "[", "(", "g", "/", "(", "tf", ".", "reduce_max", "(", "[", "grads_norm", ",", "5", "]", ")", "/", "5", ")", ",", "v", ")", "for", "g", ",", "v", "in", "grads_and_vars", "]", "\n", "\n", "train_op", "=", "optimizer", ".", "apply_gradients", "(", "grads_and_vars", ")", "\n", "\n", "# Variables for recording training procedure.", "\n", "best_epoch", "=", "tf", ".", "get_variable", "(", "'best_epoch'", ",", "shape", "=", "[", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "INT_TYPE", ")", "\n", "best_step", "=", "tf", ".", "get_variable", "(", "'best_step'", ",", "shape", "=", "[", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "trainable", "=", "False", ",", "\n", "dtype", "=", "INT_TYPE", ")", "\n", "best_dev_score", "=", "tf", ".", "get_variable", "(", "'best_dev_score'", ",", "shape", "=", "[", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "best_test_score", "=", "tf", ".", "get_variable", "(", "'best_test_score'", ",", "shape", "=", "[", "]", ",", "initializer", "=", "tf", ".", "zeros_initializer", "(", ")", ",", "\n", "trainable", "=", "False", ",", "dtype", "=", "FLOAT_TYPE", ")", "\n", "\n", "init_op", "=", "tf", ".", "global_variables_initializer", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "summary_writer", "=", "tf", ".", "summary", ".", "FileWriter", "(", "log_dir", "+", "'/summaries'", ")", "\n", "\n", "print", "(", "'Finished.'", ")", "\n", "print", "(", "'Start training the network...'", ")", "\n", "self", ".", "sess", ".", "run", "(", "init_op", ")", "\n", "\n", "start_time_begin", "=", "time", ".", "time", "(", ")", "\n", "\n", "try", ":", "\n", "            ", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "model_dir", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "checkpoint", ")", "\n", "print", "(", "'Restore model from %s.'", "%", "checkpoint", ")", "\n", "", "except", "(", "tf", ".", "errors", ".", "DataLossError", ",", "TypeError", ",", "Exception", ")", ":", "\n", "# Failed to restore model from disk. Load pre-trained embeddings.", "\n", "# Load character embeddings.", "\n", "            ", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "True", ")", ":", "\n", "                ", "embeddings", "=", "tf", ".", "get_variable", "(", "'embeddings'", ")", "\n", "", "value", "=", "self", ".", "sess", ".", "run", "(", "embeddings", ")", "\n", "count", "=", "0", "\n", "for", "item", "in", "item2id", ":", "\n", "                ", "item_id", "=", "item2id", "[", "item", "]", "\n", "if", "item", "in", "pre_trained", ":", "\n", "                    ", "value", "[", "item_id", "]", "=", "pre_trained", "[", "item", "]", "\n", "count", "+=", "1", "\n", "# Run assign op.", "\n", "", "", "self", ".", "sess", ".", "run", "(", "embeddings", ".", "assign", "(", "value", ")", ")", "\n", "del", "(", "pre_trained", ")", "\n", "print", "(", "'%d of %d character embeddings were loaded from pre-trained.'", "%", "(", "count", ",", "len", "(", "item2id", ")", ")", ")", "\n", "\n", "# Load word embeddings.", "\n", "with", "tf", ".", "variable_scope", "(", "self", ".", "scope", ",", "reuse", "=", "True", ")", ":", "\n", "                ", "word_embeddings", "=", "tf", ".", "get_variable", "(", "'word_embeddings'", ")", "\n", "", "value", "=", "self", ".", "sess", ".", "run", "(", "word_embeddings", ")", "\n", "count", "=", "0", "\n", "for", "item", "in", "word2id", ":", "\n", "                ", "item_id", "=", "word2id", "[", "item", "]", "\n", "if", "item", "in", "pre_trained_word", ":", "\n", "                    ", "value", "[", "item_id", "]", "=", "pre_trained_word", "[", "item", "]", "\n", "count", "+=", "1", "\n", "# Run assign op.", "\n", "", "", "self", ".", "sess", ".", "run", "(", "word_embeddings", ".", "assign", "(", "value", ")", ")", "\n", "del", "(", "pre_trained_word", ")", "\n", "print", "(", "'%d of %d word embeddings were loaded from pre-trained.'", "%", "(", "count", ",", "len", "(", "word2id", ")", ")", ")", "\n", "\n", "", "start_epoch", ",", "global_step", ",", "best_dev_f1", "=", "self", ".", "sess", ".", "run", "(", "(", "best_epoch", ",", "best_step", ",", "best_dev_score", ")", ")", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", "+", "1", ",", "max_epoches", "+", "1", ")", ":", "\n", "            ", "print", "(", "'Starting epoch %d...'", "%", "epoch", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "loss_ep", "=", "0", "\n", "n_step", "=", "0", "\n", "iterator", "=", "data_iterator", "(", "train_data_ids", ",", "batch_size", ",", "shuffle", "=", "True", ")", "\n", "for", "batch", "in", "iterator", ":", "\n", "                ", "batch", "=", "create_input", "(", "batch", ")", "\n", "seq_ids", ",", "seq_other_ids_list", ",", "stag_ids", ",", "seq_lengths", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", ":", "-", "2", "]", ",", "batch", "[", "-", "2", "]", ",", "batch", "[", "-", "1", "]", "\n", "feed_dict", "=", "{", "self", ".", "seq_ids_pl", ":", "seq_ids", ".", "astype", "(", "INT_TYPE", ")", ",", "\n", "self", ".", "stag_ids_pl", ":", "stag_ids", ".", "astype", "(", "INT_TYPE", ")", ",", "\n", "self", ".", "seq_lengths_pl", ":", "seq_lengths", ".", "astype", "(", "INT_TYPE", ")", ",", "\n", "self", ".", "is_train_pl", ":", "True", "}", "\n", "assert", "len", "(", "self", ".", "seq_other_ids_pls", ")", "==", "len", "(", "seq_other_ids_list", ")", "\n", "for", "pl", ",", "v", "in", "zip", "(", "self", ".", "seq_other_ids_pls", ",", "seq_other_ids_list", ")", ":", "\n", "                    ", "feed_dict", "[", "pl", "]", "=", "v", "\n", "# feed_dict.update(drop_feed_dict)  # enable noise input", "\n", "", "loss", ",", "summaries", ",", "grads_summaries", ",", "_", "=", "self", ".", "sess", ".", "run", "(", "\n", "[", "self", ".", "cost_op", ",", "self", ".", "summary_op", ",", "grads_summary_op", ",", "train_op", "]", ",", "\n", "feed_dict", "=", "feed_dict", ")", "\n", "loss_ep", "+=", "loss", "\n", "n_step", "+=", "1", "\n", "global_step", "+=", "1", "\n", "summary_writer", ".", "add_summary", "(", "summaries", ",", "global_step", ")", "\n", "summary_writer", ".", "add_summary", "(", "grads_summaries", ",", "global_step", ")", "\n", "\n", "# Show training information.", "\n", "if", "global_step", "%", "print_freq", "==", "0", ":", "\n", "                    ", "print", "(", "'  Step %d, current cost %.6f, average cost %.6f'", "%", "(", "global_step", ",", "loss", ",", "loss_ep", "/", "n_step", ")", ")", "\n", "", "", "loss_ep", "=", "loss_ep", "/", "n_step", "\n", "print", "(", "'Epoch %d finished. Time: %ds Cost: %.6f'", "%", "(", "epoch", ",", "time", ".", "time", "(", ")", "-", "start_time", ",", "loss_ep", ")", ")", "\n", "\n", "# Evaluate precision, recall and f1 with an external script.", "\n", "dev_pre", ",", "dev_rec", ",", "dev_f1", "=", "evaluator", "(", "(", "dev_data", "[", "0", "]", ",", "dev_data", "[", "-", "1", "]", ",", "self", ".", "tag_all", "(", "dev_data", "[", ":", "-", "1", "]", ",", "eval_batch_size", ")", "[", "1", "]", ")", ",", "\n", "log_dir", "+", "'/dev'", ",", "epoch", ")", "\n", "test_pre", ",", "test_rec", ",", "test_f1", "=", "evaluator", "(", "(", "test_data", "[", "0", "]", ",", "test_data", "[", "-", "1", "]", ",", "self", ".", "tag_all", "(", "test_data", "[", ":", "-", "1", "]", ",", "eval_batch_size", ")", "[", "1", "]", ")", ",", "\n", "log_dir", "+", "'/test'", ",", "epoch", ")", "\n", "\n", "# Summary dev and test F1 score.", "\n", "summary_writer", ".", "add_summary", "(", "self", ".", "sess", ".", "run", "(", "dev_summary_op", ",", "{", "dev_f1_pl", ":", "dev_f1", "}", ")", ",", "epoch", ")", "\n", "summary_writer", ".", "add_summary", "(", "self", ".", "sess", ".", "run", "(", "test_summary_op", ",", "{", "test_f1_pl", ":", "test_f1", "}", ")", ",", "epoch", ")", "\n", "\n", "print", "(", "\"Dev   precision / recall / f1 score: %.2f / %.2f / %.2f\"", "%", "\n", "(", "dev_pre", "*", "100", ",", "dev_rec", "*", "100", ",", "dev_f1", "*", "100", ")", ")", "\n", "print", "(", "\"Test  precision / recall / f1 score: %.2f / %.2f / %.2f\"", "%", "\n", "(", "test_pre", "*", "100", ",", "test_rec", "*", "100", ",", "test_f1", "*", "100", ")", ")", "\n", "\n", "if", "dev_f1", ">", "best_dev_f1", ":", "\n", "                ", "best_dev_f1", "=", "dev_f1", "\n", "self", ".", "sess", ".", "run", "(", "(", "tf", ".", "assign", "(", "best_epoch", ",", "epoch", ")", ",", "\n", "tf", ".", "assign", "(", "best_dev_score", ",", "dev_f1", ")", ",", "\n", "tf", ".", "assign", "(", "best_test_score", ",", "test_f1", ")", ",", "\n", "tf", ".", "assign", "(", "best_step", ",", "global_step", ")", ")", ")", "\n", "\n", "path", "=", "saver", ".", "save", "(", "self", ".", "sess", ",", "model_dir", "+", "'/model'", ",", "epoch", ")", "\n", "print", "(", "'New best score on dev.'", ")", "\n", "print", "(", "'Save model at %s.'", "%", "path", ")", "\n", "\n", "", "", "print", "(", "'Finished.'", ")", "\n", "print", "(", "'Total training time: %fs.'", "%", "(", "time", ".", "time", "(", ")", "-", "start_time_begin", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.load_model": [[468, 496], ["os.path.join", "os.path.join", "cPickle.load", "cPickle.load", "print", "print", "tagger.Model.build_graph", "print", "print", "tensorflow.initialize_all_variables", "tensorflow.initialize_all_variables", "tensorflow.initialize_all_variables", "tagger.Model.sess.run", "print", "print", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.Saver", "tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.train.latest_checkpoint", "tensorflow.train.Saver.restore", "print", "open", "open", "tensorflow.global_variables", "tensorflow.global_variables", "tensorflow.global_variables"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.build_graph"], ["", "def", "load_model", "(", "self", ",", "model_dir", ")", ":", "\n", "        ", "mappings_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'mappings.pkl'", ")", "\n", "parameters_path", "=", "os", ".", "path", ".", "join", "(", "model_dir", ",", "'parameters.pkl'", ")", "\n", "item2id", ",", "id2item", ",", "tag2id", ",", "id2tag", ",", "word2id", ",", "id2word", "=", "pickle", ".", "load", "(", "open", "(", "mappings_path", ",", "'r'", ")", ")", "\n", "parameters", "=", "pickle", ".", "load", "(", "open", "(", "parameters_path", ")", ")", "\n", "\n", "self", ".", "item2id", "=", "item2id", "\n", "self", ".", "id2item", "=", "id2item", "\n", "self", ".", "tag2id", "=", "tag2id", "\n", "self", ".", "id2tag", "=", "id2tag", "\n", "self", ".", "word2id", "=", "word2id", "\n", "self", ".", "id2word", "=", "id2word", "\n", "self", ".", "parameters", "=", "parameters", "\n", "\n", "print", "(", "parameters", ")", "\n", "print", "(", "'Building input graph...'", ",", "end", "=", "''", ")", "\n", "self", ".", "build_graph", "(", ")", "\n", "print", "(", "'Finished.'", ")", "\n", "print", "(", "'Initializing variables...'", ",", "end", "=", "''", ")", "\n", "init_op", "=", "tf", ".", "initialize_all_variables", "(", ")", "\n", "self", ".", "sess", ".", "run", "(", "init_op", ")", "\n", "print", "(", "'Finished.'", ")", "\n", "print", "(", "'Reloading parameters...'", ",", "end", "=", "''", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "tf", ".", "global_variables", "(", ")", ")", "\n", "checkpoint", "=", "tf", ".", "train", ".", "latest_checkpoint", "(", "model_dir", ")", "\n", "saver", ".", "restore", "(", "self", ".", "sess", ",", "checkpoint", ")", "\n", "print", "(", "'Finished.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.tag": [[497, 522], ["tagger.data_to_ids", "tagger.create_input", "zip", "tagger.Model.sess.run", "tagger.Model.inference", "itertools.izip", "seq_ids.astype", "seq_lengths.astype", "v.astype", "output.append", "zip"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_to_ids", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_input", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.inference"], ["", "def", "tag", "(", "self", ",", "data_iter", ")", ":", "\n", "        ", "\"\"\"A tagging function.\n\n        Args:\n            data_iter: A iterator for generate batches.\n\n        Returns:\n            A generator for tagging result.\n        \"\"\"", "\n", "output", "=", "[", "]", "\n", "for", "data", "in", "data_iter", ":", "\n", "            ", "batch", "=", "data_to_ids", "(", "data", ",", "[", "self", ".", "item2id", "]", "+", "[", "self", ".", "word2id", "]", "*", "self", ".", "parameters", "[", "'word_window_size'", "]", ")", "\n", "batch", "=", "create_input", "(", "batch", ")", "\n", "seq_ids", ",", "seq_other_ids_list", ",", "seq_lengths", "=", "batch", "[", "0", "]", ",", "batch", "[", "1", ":", "-", "1", "]", ",", "batch", "[", "-", "1", "]", "\n", "feed_dict", "=", "{", "self", ".", "seq_ids_pl", ":", "seq_ids", ".", "astype", "(", "INT_TYPE", ")", ",", "\n", "self", ".", "seq_lengths_pl", ":", "seq_lengths", ".", "astype", "(", "INT_TYPE", ")", ",", "\n", "self", ".", "is_train_pl", ":", "False", "}", "\n", "for", "pl", ",", "v", "in", "zip", "(", "self", ".", "seq_other_ids_pls", ",", "seq_other_ids_list", ")", ":", "\n", "                ", "feed_dict", "[", "pl", "]", "=", "v", ".", "astype", "(", "INT_TYPE", ")", "\n", "", "scores", "=", "self", ".", "sess", ".", "run", "(", "self", ".", "scores_op", ",", "feed_dict", ")", "\n", "stag_ids", "=", "self", ".", "inference", "(", "scores", ",", "seq_lengths", ")", "\n", "for", "seq", ",", "stag_id", ",", "length", "in", "izip", "(", "data", "[", "0", "]", ",", "stag_ids", ",", "seq_lengths", ")", ":", "\n", "                ", "output", ".", "append", "(", "(", "seq", ",", "[", "self", ".", "id2tag", "[", "t", "]", "for", "t", "in", "stag_id", "[", ":", "length", "]", "]", ")", ")", "\n", "", "yield", "zip", "(", "*", "output", ")", "\n", "output", "=", "[", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.tag_all": [[523, 529], ["tagger.data_iterator", "tagger.Model.tag", "zip", "output.extend", "zip"], "methods", ["home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_iterator", "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.Model.tag"], ["", "", "def", "tag_all", "(", "self", ",", "data", ",", "batch_size", ")", ":", "\n", "        ", "data_iter", "=", "data_iterator", "(", "data", ",", "batch_size", "=", "batch_size", ",", "shuffle", "=", "False", ")", "\n", "output", "=", "[", "]", "\n", "for", "b", "in", "self", ".", "tag", "(", "data_iter", ")", ":", "\n", "            ", "output", ".", "extend", "(", "zip", "(", "*", "b", ")", ")", "\n", "", "return", "zip", "(", "*", "output", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.create_dic": [[534, 553], ["type"], "function", ["None"], ["", "", "def", "create_dic", "(", "item_list", ",", "add_unk", "=", "False", ",", "add_pad", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Create a dictionary of items from a list of list of items.\n    \"\"\"", "\n", "assert", "type", "(", "item_list", ")", "in", "(", "list", ",", "tuple", ")", "\n", "dic", "=", "{", "}", "\n", "for", "items", "in", "item_list", ":", "\n", "        ", "for", "item", "in", "items", ":", "\n", "            ", "if", "item", "not", "in", "dic", ":", "\n", "                ", "dic", "[", "item", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "dic", "[", "item", "]", "+=", "1", "\n", "# Make sure that <PAD> have a id 0.", "\n", "", "", "", "if", "add_pad", ":", "\n", "        ", "dic", "[", "'<PAD>'", "]", "=", "1e20", "\n", "# If specified, add a special item <UNK>.", "\n", "", "if", "add_unk", ":", "\n", "        ", "dic", "[", "'<UNK>'", "]", "=", "1e10", "\n", "", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.create_mapping": [[555, 569], ["type", "sorted", "items.items", "type", "enumerate", "id2item.items", "enumerate", "id2item.items"], "function", ["None"], ["", "def", "create_mapping", "(", "items", ")", ":", "\n", "    ", "\"\"\"\n    Create a mapping (item to ID / ID to item) from a dictionary.\n    Items are ordered by decreasing frequency.\n    \"\"\"", "\n", "if", "type", "(", "items", ")", "is", "dict", ":", "\n", "        ", "sorted_items", "=", "sorted", "(", "items", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "id2item", "=", "{", "i", ":", "v", "[", "0", "]", "for", "i", ",", "v", "in", "enumerate", "(", "sorted_items", ")", "}", "\n", "item2id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "id2item", ".", "items", "(", ")", "}", "\n", "return", "item2id", ",", "id2item", "\n", "", "elif", "type", "(", "items", ")", "is", "list", ":", "\n", "        ", "id2item", "=", "{", "i", ":", "v", "for", "i", ",", "v", "in", "enumerate", "(", "items", ")", "}", "\n", "item2id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "id2item", ".", "items", "(", ")", "}", "\n", "return", "item2id", ",", "id2item", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.create_input": [[571, 589], ["max", "ret.append", "len", "len", "max", "itertools.izip", "ret.append", "numpy.array", "dd.append", "numpy.array", "len"], "function", ["None"], ["", "", "def", "create_input", "(", "batch", ")", ":", "\n", "    ", "\"\"\"\n    Take each sentence data in batch and return an input for\n    the training or the evaluation function.\n    \"\"\"", "\n", "assert", "len", "(", "batch", ")", ">", "0", "\n", "lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "batch", "[", "0", "]", "]", "\n", "max_len", "=", "max", "(", "2", ",", "max", "(", "lengths", ")", ")", "\n", "ret", "=", "[", "]", "\n", "for", "d", "in", "batch", ":", "\n", "        ", "dd", "=", "[", "]", "\n", "for", "seq_id", ",", "pos", "in", "izip", "(", "d", ",", "lengths", ")", ":", "\n", "            ", "assert", "len", "(", "seq_id", ")", "==", "pos", "\n", "pad", "=", "[", "0", "]", "*", "(", "max_len", "-", "pos", ")", "\n", "dd", ".", "append", "(", "seq_id", "+", "pad", ")", "\n", "", "ret", ".", "append", "(", "np", ".", "array", "(", "dd", ")", ")", "\n", "", "ret", ".", "append", "(", "np", ".", "array", "(", "lengths", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.data_to_ids": [[591, 636], ["itertools.izip", "tuple", "tagger.data_to_ids.strB2Q"], "function", ["None"], ["", "def", "data_to_ids", "(", "data", ",", "mappings", ")", ":", "\n", "    ", "\"\"\"\n    Map text data to ids.\n    \"\"\"", "\n", "\n", "def", "strQ2B", "(", "ustring", ")", ":", "\n", "        ", "rstring", "=", "\"\"", "\n", "for", "uchar", "in", "ustring", ":", "\n", "            ", "inside_code", "=", "ord", "(", "uchar", ")", "\n", "if", "inside_code", "==", "12288", ":", "\n", "                ", "inside_code", "=", "32", "\n", "", "elif", "65281", "<=", "inside_code", "<=", "65374", ":", "\n", "                ", "inside_code", "-=", "65248", "\n", "", "rstring", "+=", "unichr", "(", "inside_code", ")", "\n", "", "return", "rstring", "\n", "\n", "", "def", "strB2Q", "(", "ustring", ")", ":", "\n", "        ", "rstring", "=", "\"\"", "\n", "for", "uchar", "in", "ustring", ":", "\n", "            ", "inside_code", "=", "ord", "(", "uchar", ")", "\n", "if", "inside_code", "==", "32", ":", "\n", "                ", "inside_code", "=", "12288", "\n", "", "elif", "32", "<=", "inside_code", "<=", "126", ":", "\n", "                ", "inside_code", "+=", "65248", "\n", "", "rstring", "+=", "unichr", "(", "inside_code", ")", "\n", "", "return", "rstring", "\n", "\n", "", "def", "map", "(", "item", ",", "mapping", ")", ":", "\n", "        ", "if", "item", "in", "mapping", ":", "\n", "            ", "return", "mapping", "[", "item", "]", "\n", "", "item", "=", "strB2Q", "(", "item", ")", "\n", "if", "item", "in", "mapping", ":", "\n", "            ", "return", "mapping", "[", "item", "]", "\n", "", "item", "=", "strQ2B", "(", "item", ")", "\n", "if", "item", "in", "mapping", ":", "\n", "            ", "return", "mapping", "[", "item", "]", "\n", "", "return", "mapping", "[", "'<UNK>'", "]", "\n", "\n", "", "def", "map_seq", "(", "seqs", ",", "mapping", ")", ":", "\n", "        ", "return", "[", "[", "map", "(", "item", ",", "mapping", ")", "for", "item", "in", "seq", "]", "for", "seq", "in", "seqs", "]", "\n", "\n", "", "ret", "=", "[", "]", "\n", "for", "d", ",", "m", "in", "izip", "(", "data", ",", "mappings", ")", ":", "\n", "        ", "ret", ".", "append", "(", "map_seq", "(", "d", ",", "m", ")", ")", "\n", "", "return", "tuple", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.tagger.data_iterator": [[638, 664], ["all", "zip", "len", "numpy.random.shuffle", "len", "max", "len", "batch.append", "zip", "len", "len", "min", "zip", "len", "max", "len", "len"], "function", ["None"], ["", "def", "data_iterator", "(", "inputs", ",", "batch_size", ",", "shuffle", "=", "True", ",", "max_length", "=", "200", ")", ":", "\n", "    ", "\"\"\"\n    A simple iterator for generating dynamic mini batches.\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", ">", "0", "\n", "assert", "all", "(", "[", "len", "(", "item", ")", "==", "len", "(", "inputs", "[", "0", "]", ")", "for", "item", "in", "inputs", "]", ")", "\n", "inputs", "=", "zip", "(", "*", "inputs", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "inputs", ")", "\n", "\n", "", "batch", "=", "[", "]", "\n", "bs", "=", "batch_size", "\n", "for", "d", "in", "inputs", ":", "\n", "        ", "if", "len", "(", "d", "[", "0", "]", ")", ">", "max_length", ":", "\n", "            ", "bs", "=", "max", "(", "1", ",", "min", "(", "batch_size", "*", "max_length", "/", "len", "(", "d", "[", "0", "]", ")", ",", "bs", ")", ")", "\n", "", "if", "len", "(", "batch", ")", "<", "bs", ":", "\n", "            ", "batch", ".", "append", "(", "d", ")", "\n", "", "else", ":", "\n", "            ", "yield", "zip", "(", "*", "batch", ")", "\n", "batch", "=", "[", "d", "]", "\n", "if", "len", "(", "d", "[", "0", "]", ")", "<", "max_length", ":", "\n", "                ", "bs", "=", "batch_size", "\n", "", "else", ":", "\n", "                ", "bs", "=", "max", "(", "1", ",", "batch_size", "*", "max_length", "/", "len", "(", "d", "[", "0", "]", ")", ")", "\n", "", "", "", "if", "batch", ":", "\n", "        ", "yield", "zip", "(", "*", "batch", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.fresh_dir": [[7, 11], ["tensorflow.gfile.Exists", "tensorflow.gfile.MakeDirs", "tensorflow.gfile.DeleteRecursively"], "function", ["None"], ["def", "fresh_dir", "(", "path", ")", ":", "\n", "    ", "if", "tf", ".", "gfile", ".", "Exists", "(", "path", ")", ":", "\n", "        ", "tf", ".", "gfile", ".", "DeleteRecursively", "(", "path", ")", "\n", "", "tf", ".", "gfile", ".", "MakeDirs", "(", "path", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_dic": [[12, 31], ["type"], "function", ["None"], ["", "def", "create_dic", "(", "item_list", ",", "add_unk", "=", "False", ",", "add_pad", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Create a dictionary of items from a list of list of items.\n    \"\"\"", "\n", "assert", "type", "(", "item_list", ")", "in", "(", "list", ",", "tuple", ")", "\n", "dic", "=", "{", "}", "\n", "for", "items", "in", "item_list", ":", "\n", "        ", "for", "item", "in", "items", ":", "\n", "            ", "if", "item", "not", "in", "dic", ":", "\n", "                ", "dic", "[", "item", "]", "=", "1", "\n", "", "else", ":", "\n", "                ", "dic", "[", "item", "]", "+=", "1", "\n", "# Make sure that <PAD> have a id 0.", "\n", "", "", "", "if", "add_pad", ":", "\n", "        ", "dic", "[", "'<PAD>'", "]", "=", "1e20", "\n", "# If specified, add a special item <UNK>.", "\n", "", "if", "add_unk", ":", "\n", "        ", "dic", "[", "'<UNK>'", "]", "=", "1e10", "\n", "", "return", "dic", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_mapping": [[33, 47], ["type", "sorted", "items.items", "type", "enumerate", "id2item.items", "enumerate", "id2item.items"], "function", ["None"], ["", "def", "create_mapping", "(", "items", ")", ":", "\n", "    ", "\"\"\"\n    Create a mapping (item to ID / ID to item) from a dictionary.\n    Items are ordered by decreasing frequency.\n    \"\"\"", "\n", "if", "type", "(", "items", ")", "is", "dict", ":", "\n", "        ", "sorted_items", "=", "sorted", "(", "items", ".", "items", "(", ")", ",", "key", "=", "lambda", "x", ":", "(", "-", "x", "[", "1", "]", ",", "x", "[", "0", "]", ")", ")", "\n", "id2item", "=", "{", "i", ":", "v", "[", "0", "]", "for", "i", ",", "v", "in", "enumerate", "(", "sorted_items", ")", "}", "\n", "item2id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "id2item", ".", "items", "(", ")", "}", "\n", "return", "item2id", ",", "id2item", "\n", "", "elif", "type", "(", "items", ")", "is", "list", ":", "\n", "        ", "id2item", "=", "{", "i", ":", "v", "for", "i", ",", "v", "in", "enumerate", "(", "items", ")", "}", "\n", "item2id", "=", "{", "v", ":", "k", "for", "k", ",", "v", "in", "id2item", ".", "items", "(", ")", "}", "\n", "return", "item2id", ",", "id2item", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.create_input": [[49, 67], ["max", "ret.append", "len", "len", "max", "itertools.izip", "ret.append", "numpy.array", "dd.append", "numpy.array", "len"], "function", ["None"], ["", "", "def", "create_input", "(", "batch", ")", ":", "\n", "    ", "\"\"\"\n    Take each sentence data in batch and return an input for\n    the training or the evaluation function.\n    \"\"\"", "\n", "assert", "len", "(", "batch", ")", ">", "0", "\n", "lengths", "=", "[", "len", "(", "seq", ")", "for", "seq", "in", "batch", "[", "0", "]", "]", "\n", "max_len", "=", "max", "(", "2", ",", "max", "(", "lengths", ")", ")", "\n", "ret", "=", "[", "]", "\n", "for", "d", "in", "batch", ":", "\n", "        ", "dd", "=", "[", "]", "\n", "for", "seq_id", ",", "pos", "in", "izip", "(", "d", ",", "lengths", ")", ":", "\n", "            ", "assert", "len", "(", "seq_id", ")", "==", "pos", "\n", "pad", "=", "[", "0", "]", "*", "(", "max_len", "-", "pos", ")", "\n", "dd", ".", "append", "(", "seq_id", "+", "pad", ")", "\n", "", "ret", ".", "append", "(", "np", ".", "array", "(", "dd", ")", ")", "\n", "", "ret", ".", "append", "(", "np", ".", "array", "(", "lengths", ")", ")", "\n", "return", "ret", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_to_ids": [[69, 114], ["itertools.izip", "tuple", "utils.data_to_ids.strB2Q"], "function", ["None"], ["", "def", "data_to_ids", "(", "data", ",", "mappings", ")", ":", "\n", "    ", "\"\"\"\n    Map text data to ids.\n    \"\"\"", "\n", "\n", "def", "strQ2B", "(", "ustring", ")", ":", "\n", "        ", "rstring", "=", "\"\"", "\n", "for", "uchar", "in", "ustring", ":", "\n", "            ", "inside_code", "=", "ord", "(", "uchar", ")", "\n", "if", "inside_code", "==", "12288", ":", "\n", "                ", "inside_code", "=", "32", "\n", "", "elif", "65281", "<=", "inside_code", "<=", "65374", ":", "\n", "                ", "inside_code", "-=", "65248", "\n", "", "rstring", "+=", "unichr", "(", "inside_code", ")", "\n", "", "return", "rstring", "\n", "\n", "", "def", "strB2Q", "(", "ustring", ")", ":", "\n", "        ", "rstring", "=", "\"\"", "\n", "for", "uchar", "in", "ustring", ":", "\n", "            ", "inside_code", "=", "ord", "(", "uchar", ")", "\n", "if", "inside_code", "==", "32", ":", "\n", "                ", "inside_code", "=", "12288", "\n", "", "elif", "32", "<=", "inside_code", "<=", "126", ":", "\n", "                ", "inside_code", "+=", "65248", "\n", "", "rstring", "+=", "unichr", "(", "inside_code", ")", "\n", "", "return", "rstring", "\n", "\n", "", "def", "map", "(", "item", ",", "mapping", ")", ":", "\n", "        ", "if", "item", "in", "mapping", ":", "\n", "            ", "return", "mapping", "[", "item", "]", "\n", "", "item", "=", "strB2Q", "(", "item", ")", "\n", "if", "item", "in", "mapping", ":", "\n", "            ", "return", "mapping", "[", "item", "]", "\n", "", "item", "=", "strQ2B", "(", "item", ")", "\n", "if", "item", "in", "mapping", ":", "\n", "            ", "return", "mapping", "[", "item", "]", "\n", "", "return", "mapping", "[", "'<UNK>'", "]", "\n", "\n", "", "def", "map_seq", "(", "seqs", ",", "mapping", ")", ":", "\n", "        ", "return", "[", "[", "map", "(", "item", ",", "mapping", ")", "for", "item", "in", "seq", "]", "for", "seq", "in", "seqs", "]", "\n", "\n", "", "ret", "=", "[", "]", "\n", "for", "d", ",", "m", "in", "izip", "(", "data", ",", "mappings", ")", ":", "\n", "        ", "ret", ".", "append", "(", "map_seq", "(", "d", ",", "m", ")", ")", "\n", "", "return", "tuple", "(", "ret", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Alibaba-NLP_DAAT-CWS.None.utils.data_iterator": [[116, 142], ["all", "zip", "len", "numpy.random.shuffle", "len", "max", "len", "batch.append", "zip", "len", "len", "min", "zip", "len", "max", "len", "len"], "function", ["None"], ["", "def", "data_iterator", "(", "inputs", ",", "batch_size", ",", "shuffle", "=", "True", ",", "max_length", "=", "200", ")", ":", "\n", "    ", "\"\"\"\n    A simple iterator for generating dynamic mini batches.\n    \"\"\"", "\n", "assert", "len", "(", "inputs", ")", ">", "0", "\n", "assert", "all", "(", "[", "len", "(", "item", ")", "==", "len", "(", "inputs", "[", "0", "]", ")", "for", "item", "in", "inputs", "]", ")", "\n", "inputs", "=", "zip", "(", "*", "inputs", ")", "\n", "if", "shuffle", ":", "\n", "        ", "np", ".", "random", ".", "shuffle", "(", "inputs", ")", "\n", "\n", "", "batch", "=", "[", "]", "\n", "bs", "=", "batch_size", "\n", "for", "d", "in", "inputs", ":", "\n", "        ", "if", "len", "(", "d", "[", "0", "]", ")", ">", "max_length", ":", "\n", "            ", "bs", "=", "max", "(", "1", ",", "min", "(", "batch_size", "*", "max_length", "/", "len", "(", "d", "[", "0", "]", ")", ",", "bs", ")", ")", "\n", "", "if", "len", "(", "batch", ")", "<", "bs", ":", "\n", "            ", "batch", ".", "append", "(", "d", ")", "\n", "", "else", ":", "\n", "            ", "yield", "zip", "(", "*", "batch", ")", "\n", "batch", "=", "[", "d", "]", "\n", "if", "len", "(", "d", "[", "0", "]", ")", "<", "max_length", ":", "\n", "                ", "bs", "=", "batch_size", "\n", "", "else", ":", "\n", "                ", "bs", "=", "max", "(", "1", ",", "batch_size", "*", "max_length", "/", "len", "(", "d", "[", "0", "]", ")", ")", "\n", "", "", "", "if", "batch", ":", "\n", "        ", "yield", "zip", "(", "*", "batch", ")", "\n", "", "", ""]]}