{"home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.augment": [[41, 43], ["None"], "methods", ["None"], ["    ", "def", "augment", "(", "self", ",", "x", ",", "l", ",", "beta", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "0", ",", "'Do not call.'", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.guess_label": [[44, 55], ["tensorflow.concat", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.pow", "tensorflow.reduce_sum", "easydict.EasyDict", "classifier", "tensorflow.nn.softmax", "len"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.MultiModel.classifier"], ["", "def", "guess_label", "(", "self", ",", "y", ",", "classifier", ",", "T", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "logits_y", "=", "[", "classifier", "(", "yi", ",", "training", "=", "True", ")", "for", "yi", "in", "y", "]", "\n", "logits_y", "=", "tf", ".", "concat", "(", "logits_y", ",", "0", ")", "\n", "# Compute predicted probability distribution py.", "\n", "p_model_y", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ")", ",", "[", "len", "(", "y", ")", ",", "-", "1", ",", "self", ".", "nclass", "]", ")", "\n", "p_model_y", "=", "tf", ".", "reduce_mean", "(", "p_model_y", ",", "axis", "=", "0", ")", "\n", "# Compute the target distribution.", "\n", "p_target", "=", "tf", ".", "pow", "(", "p_model_y", ",", "1.", "/", "T", ")", "\n", "p_target", "/=", "tf", ".", "reduce_sum", "(", "p_target", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "return", "EasyDict", "(", "p_target", "=", "p_target", ",", "p_model", "=", "p_model_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.get_tsa_threshold": [[56, 82], ["tensorflow.to_float", "tensorflow.to_float", "tensorflow.exp", "tensorflow.exp"], "methods", ["None"], ["", "def", "get_tsa_threshold", "(", "self", ",", "schedule", ",", "global_step", ",", "num_train_steps", ",", "start", ",", "end", ")", ":", "\n", "# Originally written in google-research/uda/image/main.py", "\n", "\n", "# Returns the current TSA (Training Signal Annealing) thresholds given the", "\n", "# schedule, current training step, total training steps, start threshold,", "\n", "# and end threshold.", "\n", "\n", "# Typical values are as follows:", "\n", "# schedule = \"linear_schedule\", \"exp_schedule\", \"log_schedule\"", "\n", "# global_step = self.step", "\n", "# num_train_step = FLAGS.train_kimg << 10, or FLAGS.train_kimg * FLAGS.epochs", "\n", "# start = 1. / FLAGS.nclass", "\n", "# end = 1", "\n", "\n", "        ", "step_ratio", "=", "tf", ".", "to_float", "(", "global_step", ")", "/", "tf", ".", "to_float", "(", "num_train_steps", ")", "\n", "if", "schedule", "==", "\"linear_schedule\"", ":", "\n", "            ", "coeff", "=", "step_ratio", "\n", "", "elif", "schedule", "==", "\"exp_schedule\"", ":", "\n", "            ", "scale", "=", "5", "\n", "# [exp(-5), exp(0)] = [1e-2, 1]", "\n", "coeff", "=", "tf", ".", "exp", "(", "(", "step_ratio", "-", "1", ")", "*", "scale", ")", "\n", "", "elif", "schedule", "==", "\"log_schedule\"", ":", "\n", "            ", "scale", "=", "5", "\n", "# [1 - exp(0), 1 - exp(-5)] = [0, 0.99]", "\n", "coeff", "=", "1", "-", "tf", ".", "exp", "(", "(", "-", "step_ratio", ")", "*", "scale", ")", "\n", "", "return", "coeff", "*", "(", "end", "-", "start", ")", "+", "start", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.anneal_sup_loss": [[84, 134], ["realmix.RealMix.get_tsa_threshold", "tensorflow.nn.softmax", "tensorflow.greater", "tensorflow.cast", "tensorflow.ones", "tensorflow.multiply", "tensorflow.multiply", "tensorflow.where", "tensorflow.reduce_mean", "tensorflow.ones", "tensorflow.zeros", "tensorflow.where", "tensorflow.stop_gradient", "tensorflow.constant", "tensorflow.shape", "tensorflow.less", "tensorflow.shape", "tensorflow.shape", "tensorflow.greater", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.get_tsa_threshold"], ["", "def", "anneal_sup_loss", "(", "self", ",", "sup_logits", ",", "sup_labels", ",", "sup_loss", ",", "global_step", ")", ":", "\n", "# Adapted from google-research/uda/image/main.py", "\n", "\n", "# This is a version of TSA (Training Signal Annealing) that has been", "\n", "# adapted for use with RealMix. Specifically, it can deal with ground", "\n", "# truth values between 0 and 1 as created by MixUp.", "\n", "\n", "# The start value for TSA.", "\n", "        ", "tsa_start", "=", "1.", "/", "FLAGS", ".", "nclass", "\n", "\n", "# Probability thresh above which loss for a sup image is not computed.", "\n", "eff_train_prob_threshold", "=", "self", ".", "get_tsa_threshold", "(", "\n", "FLAGS", ".", "tsa", ",", "global_step", ",", "FLAGS", ".", "train_kimg", "*", "FLAGS", ".", "epochs", ",", "\n", "tsa_start", ",", "end", "=", "1", ")", "\n", "\n", "# Calculate probabilities of each class for each image.", "\n", "sup_probs", "=", "tf", ".", "nn", ".", "softmax", "(", "sup_logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Mask the predicted probabilities to only ground truth classes.", "\n", "ground_truth_class_threshold", "=", "tf", ".", "greater", "(", "sup_labels", ",", "tf", ".", "constant", "(", "0.0", ",", "tf", ".", "float32", ")", ")", "\n", "ground_truth_class_mask", "=", "tf", ".", "cast", "(", "ground_truth_class_threshold", ",", "tf", ".", "float32", ")", "\n", "correct_label_probs", "=", "sup_probs", "*", "ground_truth_class_mask", "\n", "\n", "# Calculate TSA threshold for each ground truth probability.", "\n", "# This is necessary since MixUp generates values between 0 and 1.", "\n", "eff_train_prob_threshold", "=", "sup_logits", "*", "eff_train_prob_threshold", "\n", "\n", "ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "correct_label_probs", ")", ",", "tf", ".", "float32", ")", "\n", "pos_tensor", "=", "tf", ".", "multiply", "(", "ones", ",", "FLAGS", ".", "nclass", "+", "1", ")", "\n", "neg_tensor", "=", "tf", ".", "multiply", "(", "ones", ",", "-", "1", ")", "\n", "\n", "# Loss for an image is kept if all its ground truth thresholds", "\n", "# are not met. A temporary mask is created to find which images", "\n", "# contain unmet thresholds.", "\n", "imgs_to_train_mask", "=", "tf", ".", "where", "(", "tf", ".", "less", "(", "correct_label_probs", ",", "eff_train_prob_threshold", ")", ",", "pos_tensor", ",", "neg_tensor", ")", "\n", "imgs_to_train_mask", "=", "tf", ".", "reduce_mean", "(", "imgs_to_train_mask", ",", "axis", "=", "1", ")", "\n", "\n", "ones", "=", "tf", ".", "ones", "(", "tf", ".", "shape", "(", "imgs_to_train_mask", ")", ",", "tf", ".", "float32", ")", "\n", "zeros", "=", "tf", ".", "zeros", "(", "tf", ".", "shape", "(", "imgs_to_train_mask", ")", ",", "tf", ".", "float32", ")", "\n", "\n", "loss_mask", "=", "tf", ".", "where", "(", "tf", ".", "greater", "(", "imgs_to_train_mask", ",", "zeros", ")", ",", "ones", ",", "zeros", ")", "\n", "loss_mask", "=", "tf", ".", "stop_gradient", "(", "loss_mask", ")", "\n", "\n", "# Mask the supervised loss and return the average.", "\n", "sup_loss", "=", "sup_loss", "*", "loss_mask", "\n", "avg_sup_loss", "=", "(", "tf", ".", "reduce_sum", "(", "sup_loss", ")", "/", "\n", "tf", ".", "maximum", "(", "tf", ".", "reduce_sum", "(", "loss_mask", ")", ",", "1", ")", ")", "\n", "\n", "return", "avg_sup_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.confidence_mask_unsup": [[135, 157], ["tensorflow.nn.softmax", "tensorflow.reduce_max", "tensorflow.cast", "tensorflow.summary.scalar", "tensorflow.stop_gradient", "tensorflow.greater", "tensorflow.reduce_mean", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.reduce_sum"], "methods", ["None"], ["", "def", "confidence_mask_unsup", "(", "self", ",", "logits_y", ",", "labels_y", ",", "loss_l2u", ")", ":", "\n", "# Adapted from google-research/uda/image/main.py", "\n", "\n", "# This function masks the unsupervised predictions that are below", "\n", "# a set confidence threshold. # Note the following will only work", "\n", "# using MSE loss and not KL-divergence.", "\n", "\n", "# Calculate largest predicted probability for each image.", "\n", "        ", "unsup_prob", "=", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ",", "axis", "=", "-", "1", ")", "\n", "largest_prob", "=", "tf", ".", "reduce_max", "(", "unsup_prob", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Mask the loss for images that don't contain a predicted", "\n", "# probability above the threshold.", "\n", "loss_mask", "=", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "largest_prob", ",", "FLAGS", ".", "percent_mask", ")", ",", "tf", ".", "float32", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/high_prob_ratio'", ",", "tf", ".", "reduce_mean", "(", "loss_mask", ")", ")", "\n", "loss_mask", "=", "tf", ".", "stop_gradient", "(", "loss_mask", ")", "\n", "loss_l2u", "=", "loss_l2u", "*", "tf", ".", "expand_dims", "(", "loss_mask", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Return the average unsupervised loss.", "\n", "avg_unsup_loss", "=", "(", "tf", ".", "reduce_sum", "(", "loss_l2u", ")", "/", "\n", "tf", ".", "maximum", "(", "tf", ".", "reduce_sum", "(", "loss_mask", ")", "*", "FLAGS", ".", "nclass", ",", "1", ")", ")", "\n", "return", "avg_unsup_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.percent_confidence_mask_unsup": [[158, 190], ["tensorflow.nn.softmax", "tensorflow.reduce_max", "tensorflow.sort", "tensorflow.math.multiply", "tensorflow.slice", "tensorflow.cast", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.stop_gradient", "tensorflow.to_float", "tensorflow.greater", "tensorflow.reduce_mean", "tensorflow.reshape", "tensorflow.expand_dims", "tensorflow.reduce_sum", "tensorflow.maximum", "tensorflow.to_int64", "tensorflow.shape", "tensorflow.reduce_sum"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape"], ["", "def", "percent_confidence_mask_unsup", "(", "self", ",", "logits_y", ",", "labels_y", ",", "loss_l2u", ")", ":", "\n", "# Adapted from google-research/uda/image/main.py", "\n", "\n", "# This function masks the unsupervised predictions that are below", "\n", "# a set confidence threshold. # Note the following will only work", "\n", "# using MSE loss and not KL-divergence.", "\n", "\n", "# Calculate largest predicted probability for each image.", "\n", "        ", "unsup_prob", "=", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ",", "axis", "=", "-", "1", ")", "\n", "largest_prob", "=", "tf", ".", "reduce_max", "(", "unsup_prob", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Get the indices of the bottom x% of probabilities and mask those out.", "\n", "# In other words, get the probability of the image with the x%*#numofsamples", "\n", "# lowest probability and use that as the mask.", "\n", "\n", "# Calculate the current confidence_mask value using the specified schedule:", "\n", "sorted_probs", "=", "tf", ".", "sort", "(", "largest_prob", ",", "axis", "=", "-", "1", ",", "direction", "=", "'ASCENDING'", ")", "\n", "sort_index", "=", "tf", ".", "math", ".", "multiply", "(", "tf", ".", "to_float", "(", "tf", ".", "shape", "(", "sorted_probs", ")", "[", "0", "]", ")", ",", "FLAGS", ".", "percent_mask", ")", "\n", "curr_confidence_mask", "=", "tf", ".", "slice", "(", "sorted_probs", ",", "[", "tf", ".", "to_int64", "(", "sort_index", ")", "]", ",", "[", "1", "]", ")", "\n", "\n", "# Mask the loss for images that don't contain a predicted", "\n", "# probability above the threshold.", "\n", "loss_mask", "=", "tf", ".", "cast", "(", "tf", ".", "greater", "(", "largest_prob", ",", "curr_confidence_mask", ")", ",", "tf", ".", "float32", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/high_prob_ratio'", ",", "tf", ".", "reduce_mean", "(", "loss_mask", ")", ")", "# The ratio of unl images above the thresh", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/percent_confidence_mask'", ",", "tf", ".", "reshape", "(", "curr_confidence_mask", ",", "[", "]", ")", ")", "\n", "loss_mask", "=", "tf", ".", "stop_gradient", "(", "loss_mask", ")", "\n", "loss_l2u", "=", "loss_l2u", "*", "tf", ".", "expand_dims", "(", "loss_mask", ",", "axis", "=", "-", "1", ")", "\n", "\n", "# Return the average unsupervised loss.", "\n", "avg_unsup_loss", "=", "(", "tf", ".", "reduce_sum", "(", "loss_l2u", ")", "/", "\n", "tf", ".", "maximum", "(", "tf", ".", "reduce_sum", "(", "loss_mask", ")", "*", "FLAGS", ".", "nclass", ",", "1", ")", ")", "\n", "return", "avg_unsup_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.model": [[191, 279], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.clip_by_value", "libml.layers.MixMode", "functools.partial", "tensorflow.reshape", "realmix.RealMix.guess_label", "tensorflow.stop_gradient", "tensorflow.one_hot", "libml.layers.MixMode.", "libml.layers.interleave", "tensorflow.get_collection", "libml.layers.interleave", "tensorflow.concat", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.square", "tensorflow.nn.softmax", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "post_ops.append", "post_ops.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "tensorflow.transpose", "tensorflow.split", "tensorflow.concat", "functools.partial.", "libml.layers.interleave.append", "print", "realmix.RealMix.anneal_sup_loss", "tensorflow.reduce_mean", "print", "realmix.RealMix.percent_confidence_mask_unsup", "tensorflow.reduce_mean", "tensorflow.reduce_min", "tensorflow.reduce_mean", "tensorflow.reduce_max", "libml.utils.model_vars", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.cast", "tensorflow.split", "tensorflow.get_collection", "functools.partial.", "tensorflow.nn.softmax", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.reduce_max", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reduce_mean", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.get_collection", "functools.partial.", "tensorflow.one_hot"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape", "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixmatch.MixMatch.guess_label", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.interleave", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.interleave", "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.anneal_sup_loss", "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.RealMix.percent_confidence_mask_unsup", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["", "def", "model", "(", "self", ",", "batch", ",", "lr", ",", "wd", ",", "ema", ",", "beta", ",", "w_match", ",", "warmup_kimg", "=", "1024", ",", "nu", "=", "2", ",", "mixmode", "=", "'xxy.yxy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "\n", "# Create placeholders for the labeled images, unlabeled images,", "\n", "# and the ground truth supervised labels respectively.", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "nu", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "wd", "*=", "lr", "\n", "w_match", "*=", "tf", ".", "clip_by_value", "(", "tf", ".", "cast", "(", "self", ".", "step", ",", "tf", ".", "float32", ")", "/", "(", "warmup_kimg", "<<", "10", ")", ",", "0", ",", "1", ")", "\n", "augment", "=", "MixMode", "(", "mixmode", ")", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "\n", "y", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "y_in", ",", "[", "1", ",", "0", ",", "2", ",", "3", ",", "4", "]", ")", ",", "[", "-", "1", "]", "+", "hwc", ")", "\n", "guess", "=", "self", ".", "guess_label", "(", "tf", ".", "split", "(", "y", ",", "nu", ")", ",", "classifier", ",", "T", "=", "0.5", ",", "**", "kwargs", ")", "\n", "ly", "=", "tf", ".", "stop_gradient", "(", "guess", ".", "p_target", ")", "\n", "lx", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "\n", "# Create MixUp examples.", "\n", "xy", ",", "labels_xy", "=", "augment", "(", "[", "x_in", "]", "+", "tf", ".", "split", "(", "y", ",", "nu", ")", ",", "[", "lx", "]", "+", "[", "ly", "]", "*", "nu", ",", "[", "beta", ",", "beta", "]", ")", "\n", "x", ",", "y", "=", "xy", "[", "0", "]", ",", "xy", "[", "1", ":", "]", "\n", "labels_x", ",", "labels_y", "=", "labels_xy", "[", "0", "]", ",", "tf", ".", "concat", "(", "labels_xy", "[", "1", ":", "]", ",", "0", ")", "\n", "del", "xy", ",", "labels_xy", "\n", "\n", "# Create batches that represent both labeled and unlabeled batches.", "\n", "# For more, see google-research/mixmatch/issues/5.", "\n", "batches", "=", "layers", ".", "interleave", "(", "[", "x", "]", "+", "y", ",", "batch", ")", "\n", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "logits", "=", "[", "classifier", "(", "batches", "[", "0", "]", ",", "training", "=", "True", ")", "]", "\n", "post_ops", "=", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "if", "v", "not", "in", "skip_ops", "]", "\n", "for", "batchi", "in", "batches", "[", "1", ":", "]", ":", "\n", "            ", "logits", ".", "append", "(", "classifier", "(", "batchi", ",", "training", "=", "True", ")", ")", "\n", "", "logits", "=", "layers", ".", "interleave", "(", "logits", ",", "batch", ")", "\n", "logits_x", "=", "logits", "[", "0", "]", "\n", "logits_y", "=", "tf", ".", "concat", "(", "logits", "[", "1", ":", "]", ",", "0", ")", "\n", "\n", "# Calculate supervised and unsupervised losses.", "\n", "loss_xe", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "labels_x", ",", "logits", "=", "logits_x", ")", "\n", "if", "FLAGS", ".", "tsa", "!=", "\"none\"", ":", "\n", "            ", "print", "(", "\"Using training signal annealing...\"", ")", "\n", "loss_xe", "=", "self", ".", "anneal_sup_loss", "(", "logits_x", ",", "labels_x", ",", "loss_xe", ",", "self", ".", "step", ")", "\n", "", "else", ":", "\n", "            ", "loss_xe", "=", "tf", ".", "reduce_mean", "(", "loss_xe", ")", "\n", "\n", "", "loss_l2u", "=", "tf", ".", "square", "(", "labels_y", "-", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ")", ")", "\n", "\n", "\n", "if", "FLAGS", ".", "percent_mask", ">", "0", ":", "\n", "            ", "print", "(", "\"Using percent-based confidence masking...\"", ")", "\n", "loss_l2u", "=", "self", ".", "percent_confidence_mask_unsup", "(", "logits_y", ",", "labels_y", ",", "loss_l2u", ")", "\n", "", "else", ":", "\n", "            ", "loss_l2u", "=", "tf", ".", "reduce_mean", "(", "loss_l2u", ")", "\n", "\n", "# Calculate largest predicted probability for each image.", "\n", "", "unsup_prob", "=", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ",", "axis", "=", "-", "1", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/min_unsup_prob'", ",", "tf", ".", "reduce_min", "(", "tf", ".", "reduce_max", "(", "unsup_prob", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/mean_unsup_prob'", ",", "tf", ".", "reduce_mean", "(", "tf", ".", "reduce_max", "(", "unsup_prob", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/max_unsup_prob'", ",", "tf", ".", "reduce_max", "(", "tf", ".", "reduce_max", "(", "unsup_prob", ",", "axis", "=", "-", "1", ")", ")", ")", "\n", "\n", "# Print losses to tensorboard.", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss_xe", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/l2u'", ",", "loss_l2u", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/overall'", ",", "loss_xe", "+", "w_match", "*", "loss_l2u", ")", "\n", "\n", "# Applying EMA weights to model. Conceptualized by Tarvainen & Valpola, 2017", "\n", "# See https://arxiv.org/abs/1703.01780 for more.", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss_xe", "+", "w_match", "*", "loss_l2u", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "batches", "[", "0", "]", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ",", "\n", "eval_loss_op", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "logits", "=", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ",", "\n", "labels", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.get_dataset": [[281, 304], ["libml.data_pair.DATASETS.keys", "libml.data_pair.DATASETS.update", "libml.data_pair.DATASETS.keys", "int", "int", "libml.data.DataSet.creator", "itertools.product", "FLAGS.dataset.split", "libml.data_pair.stack_augment", "range"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data_pair.stack_augment"], ["", "", "def", "get_dataset", "(", ")", ":", "\n", "    ", "assert", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", "or", "FLAGS", ".", "custom_dataset", ",", "\"Please enter a valid dataset name or use the --custom_dataset flag.\"", "\n", "\n", "# CIFAR10, CIFAR100, STL10, and SVHN are the pre-configured datasets", "\n", "# with each dataset's default augmentation.", "\n", "if", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", ":", "\n", "        ", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "# If the dataset has not been pre-configured, create it.", "\n", "", "else", ":", "\n", "        ", "label_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "label_size", "]", "\n", "valid_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "valid_size", "]", "\n", "\n", "augment_dict", "=", "{", "\"cifar10\"", ":", "augment_cifar10", ",", "\"cutout\"", ":", "augment_cutout", ",", "\"svhn\"", ":", "augment_svhn", ",", "\"stl10\"", ":", "augment_stl10", ",", "\"color\"", ":", "augment_color", "}", "\n", "augmentation", "=", "augment_dict", "[", "FLAGS", ".", "augment", "]", "\n", "\n", "DATASETS", ".", "update", "(", "[", "DataSet", ".", "creator", "(", "FLAGS", ".", "dataset", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "seed", ",", "label", ",", "valid", ",", "[", "augmentation", ",", "stack_augment", "(", "augmentation", ")", "]", ",", "nclass", "=", "FLAGS", ".", "nclass", ",", "height", "=", "FLAGS", ".", "img_size", ",", "width", "=", "FLAGS", ".", "img_size", ",", "do_memoize", "=", "FLAGS", ".", "memoize", ")", "\n", "for", "seed", ",", "label", ",", "valid", "in", "\n", "itertools", ".", "product", "(", "range", "(", "2", ")", ",", "label_size", ",", "valid_size", ")", "]", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.realmix.main": [[306, 361], ["realmix.get_dataset", "libml.utils.ilog2", "realmix.RealMix", "print", "RealMix.train", "os.path.join"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mean_teacher.get_dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "\n", "\n", "# Num of augmentations to perform on each image and measure consistency loss.", "\n", "# Performance does not significantly increase with more augmentations.", "\n", "assert", "FLAGS", ".", "nu", "==", "2", "\n", "\n", "dataset", "=", "get_dataset", "(", ")", "\n", "\n", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "RealMix", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "beta", "=", "FLAGS", ".", "beta", ",", "\n", "w_match", "=", "FLAGS", ".", "w_match", ",", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ",", "\n", "tsa", "=", "FLAGS", ".", "tsa", ",", "\n", "ood_mask", "=", "FLAGS", ".", "percent_mask", ",", "\n", "augmentation", "=", "FLAGS", ".", "augment", ")", "\n", "\n", "# if FLAGS.perform_inference:", "\n", "#     print(\"Performing inference...\")", "\n", "#     assert FLAGS.inference_dir and FLAGS.inference_ckpt", "\n", "#     inference_dir = FLAGS.inference_dir", "\n", "#     inference_ckpt = FLAGS.inference_ckpt", "\n", "\n", "#     # images = model.session.run(memoize(default_parse(dataset([inference_dir]))).prefetch(10))", "\n", "\n", "#     if inference_dir[-1] != \"/\":", "\n", "#         inference_dir += \"/\"", "\n", "#     inference_img_paths = [path for path in glob.glob(inference_dir + \"*.png\")]", "\n", "#     images = np.asarray([plt.imread(img_path) for img_path in inference_img_paths])", "\n", "#     images = images * (2.0 / 255) - 1.0", "\n", "#     model.eval_mode(ckpt=inference_ckpt)", "\n", "#     # batch = FLAGS.batch", "\n", "#     feed_extra = None", "\n", "#     logits = [model.session.run(model.ops.classify_op, feed_dict={", "\n", "#         model.ops.x: images[0:10], **(feed_extra or {})})]", "\n", "\n", "#     print(np.asarray(logits).shape)", "\n", "#     print(logits)", "\n", "#     for i in range(10):", "\n", "#         print(np.amax(logits, axis=-1)[:, i], inference_img_paths[i])", "\n", "\n", "print", "(", "\"Preparing to train the %s dataset with %d classes, img_size of %d, %s augmentation, %s tsa schedule, %f weight decay, and learning rate of %f using RealMix\"", "%", "(", "FLAGS", ".", "dataset", ",", "FLAGS", ".", "nclass", ",", "FLAGS", ".", "img_size", ",", "FLAGS", ".", "augment", ",", "FLAGS", ".", "tsa", ",", "FLAGS", ".", "wd", ",", "FLAGS", ".", "lr", ")", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.pi_model.PiModel.model": [[35, 81], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "tensorflow.clip_by_value", "functools.partial", "functools.partial.", "tensorflow.get_collection", "tensorflow.reshape", "tensorflow.split", "functools.partial.", "tensorflow.stop_gradient", "functools.partial.", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "tensorflow.get_collection.append", "tensorflow.get_collection.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "tensorflow.transpose", "libml.utils.model_vars", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.to_float", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["    ", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "warmup_pos", ",", "consistency_weight", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "2", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "l", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "wd", "*=", "lr", "\n", "warmup", "=", "tf", ".", "clip_by_value", "(", "tf", ".", "to_float", "(", "self", ".", "step", ")", "/", "(", "warmup_pos", "*", "(", "FLAGS", ".", "train_kimg", "<<", "10", ")", ")", ",", "0", ",", "1", ")", "\n", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "logits_x", "=", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "# Take only first call to update batch norm.", "\n", "y", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "y_in", ",", "[", "1", ",", "0", ",", "2", ",", "3", ",", "4", "]", ")", ",", "[", "-", "1", "]", "+", "hwc", ")", "\n", "y_1", ",", "y_2", "=", "tf", ".", "split", "(", "y", ",", "2", ")", "\n", "logits_y", "=", "classifier", "(", "y_1", ",", "training", "=", "True", ")", "\n", "logits_teacher", "=", "tf", ".", "stop_gradient", "(", "logits_y", ")", "\n", "logits_student", "=", "classifier", "(", "y_2", ",", "training", "=", "True", ")", "\n", "loss_pm", "=", "tf", ".", "reduce_mean", "(", "(", "tf", ".", "nn", ".", "softmax", "(", "logits_teacher", ")", "-", "tf", ".", "nn", ".", "softmax", "(", "logits_student", ")", ")", "**", "2", ",", "-", "1", ")", "\n", "loss_pm", "=", "tf", ".", "reduce_mean", "(", "loss_pm", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "l", ",", "logits", "=", "logits_x", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/pm'", ",", "loss_pm", ")", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss", "+", "loss_pm", "*", "warmup", "*", "consistency_weight", ",", "\n", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.pi_model.main": [[83, 104], ["libml.utils.ilog2", "pi_model.PiModel", "PiModel.train", "os.path.join"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "PiModel", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "warmup_pos", "=", "FLAGS", ".", "warmup_pos", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "smoothing", "=", "FLAGS", ".", "smoothing", ",", "\n", "consistency_weight", "=", "FLAGS", ".", "consistency_weight", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.vat.VAT.model": [[38, 85], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.clip_by_value", "functools.partial", "tensorflow.one_hot", "functools.partial.", "tensorflow.get_collection", "functools.partial.", "third_party.vat_utils.generate_perturbation", "functools.partial.", "tensorflow.stop_gradient", "libml.layers.kl_divergence_from_logits", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "tensorflow.get_collection.append", "tensorflow.get_collection.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "tensorflow.distributions.Categorical().entropy", "libml.utils.model_vars", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.to_float", "functools.partial.", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.distributions.Categorical", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.generate_perturbation", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.kl_divergence_from_logits", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["    ", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "warmup_pos", ",", "vat", ",", "vat_eps", ",", "entmin_weight", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "wd", "*=", "lr", "\n", "warmup", "=", "tf", ".", "clip_by_value", "(", "tf", ".", "to_float", "(", "self", ".", "step", ")", "/", "(", "warmup_pos", "*", "(", "FLAGS", ".", "train_kimg", "<<", "10", ")", ")", ",", "0", ",", "1", ")", "\n", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "l", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "logits_x", "=", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "# Take only first call to update batch norm.", "\n", "logits_y", "=", "classifier", "(", "y_in", ",", "training", "=", "True", ")", "\n", "delta_y", "=", "vat_utils", ".", "generate_perturbation", "(", "y_in", ",", "logits_y", ",", "lambda", "x", ":", "classifier", "(", "x", ",", "training", "=", "True", ")", ",", "vat_eps", ")", "\n", "logits_student", "=", "classifier", "(", "y_in", "+", "delta_y", ",", "training", "=", "True", ")", "\n", "logits_teacher", "=", "tf", ".", "stop_gradient", "(", "logits_y", ")", "\n", "loss_vat", "=", "layers", ".", "kl_divergence_from_logits", "(", "logits_student", ",", "logits_teacher", ")", "\n", "loss_vat", "=", "tf", ".", "reduce_mean", "(", "loss_vat", ")", "\n", "loss_entmin", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "distributions", ".", "Categorical", "(", "logits", "=", "logits_y", ")", ".", "entropy", "(", ")", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "l", ",", "logits", "=", "logits_x", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/vat'", ",", "loss_vat", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/entmin'", ",", "loss_entmin", ")", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss", "+", "loss_vat", "*", "warmup", "*", "vat", "+", "entmin_weight", "*", "loss_entmin", ",", "\n", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.vat.main": [[87, 126], ["libml.utils.ilog2", "vat.VAT", "VAT.train", "libml.data_pair.DATASETS.keys", "os.path.join", "print", "libml.data_pair.DATASETS.update", "libml.data_pair.DATASETS.keys", "int", "int", "libml.data.DataSet.creator", "itertools.product", "FLAGS.dataset.split", "libml.data_pair.stack_augment", "range"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data_pair.stack_augment"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "if", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", ":", "\n", "        ", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "", "elif", "FLAGS", ".", "dataset", "not", "in", "DATASETS", ".", "keys", "(", ")", "and", "FLAGS", ".", "custom_dataset", ":", "\n", "        ", "print", "(", "\"Preparing to train the \"", "+", "FLAGS", ".", "dataset", "+", "\" dataset.\"", ")", "\n", "label_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "label_size", "]", "\n", "valid_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "valid_size", "]", "\n", "\n", "if", "FLAGS", ".", "augment", "==", "\"cifar10\"", ":", "\n", "            ", "augmentation", "=", "augment_cifar10", "\n", "", "else", ":", "\n", "            ", "augmentation", "=", "augment_custom", "\n", "\n", "", "DATASETS", ".", "update", "(", "[", "DataSet", ".", "creator", "(", "FLAGS", ".", "dataset", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "seed", ",", "label", ",", "valid", ",", "[", "augmentation", ",", "stack_augment", "(", "augmentation", ")", "]", ",", "nclass", "=", "FLAGS", ".", "nclass", ",", "height", "=", "FLAGS", ".", "img_size", ",", "width", "=", "FLAGS", ".", "img_size", ")", "\n", "for", "seed", ",", "label", ",", "valid", "in", "\n", "itertools", ".", "product", "(", "range", "(", "2", ")", ",", "label_size", ",", "valid_size", ")", "]", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "VAT", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "warmup_pos", "=", "FLAGS", ".", "warmup_pos", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "smoothing", "=", "FLAGS", ".", "smoothing", ",", "\n", "vat", "=", "FLAGS", ".", "vat", ",", "\n", "vat_eps", "=", "FLAGS", ".", "vat_eps", ",", "\n", "entmin_weight", "=", "FLAGS", ".", "entmin_weight", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.ict.ICT.model": [[38, 90], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "tensorflow.clip_by_value", "tensorflow.reshape", "tensorflow.split", "tensorflow.distributions.Beta().sample", "tensorflow.maximum", "functools.partial", "functools.partial.", "tensorflow.get_collection", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "functools.partial.", "tensorflow.stop_gradient", "functools.partial.", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.get_collection.append", "tensorflow.get_collection.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "tensorflow.transpose", "libml.utils.model_vars", "tensorflow.nn.softmax", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.to_float", "tensorflow.distributions.Beta", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.shape", "tensorflow.nn.softmax", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["    ", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "warmup_pos", ",", "consistency_weight", ",", "beta", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "2", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "l", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "wd", "*=", "lr", "\n", "warmup", "=", "tf", ".", "clip_by_value", "(", "tf", ".", "to_float", "(", "self", ".", "step", ")", "/", "(", "warmup_pos", "*", "(", "FLAGS", ".", "train_kimg", "<<", "10", ")", ")", ",", "0", ",", "1", ")", "\n", "\n", "y", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "y_in", ",", "[", "1", ",", "0", ",", "2", ",", "3", ",", "4", "]", ")", ",", "[", "-", "1", "]", "+", "hwc", ")", "\n", "y_1", ",", "y_2", "=", "tf", ".", "split", "(", "y", ",", "2", ")", "\n", "\n", "mix", "=", "tf", ".", "distributions", ".", "Beta", "(", "beta", ",", "beta", ")", ".", "sample", "(", "[", "tf", ".", "shape", "(", "x_in", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "mix", "=", "tf", ".", "maximum", "(", "mix", ",", "1", "-", "mix", ")", "\n", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "logits_x", "=", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "# Take only first call to update batch norm.", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "logits_teacher", "=", "classifier", "(", "y_1", ",", "training", "=", "True", ",", "getter", "=", "ema_getter", ")", "\n", "labels_teacher", "=", "tf", ".", "stop_gradient", "(", "tf", ".", "nn", ".", "softmax", "(", "logits_teacher", ")", ")", "\n", "labels_teacher", "=", "labels_teacher", "*", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", "+", "labels_teacher", "[", ":", ":", "-", "1", "]", "*", "(", "1", "-", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", ")", "\n", "logits_student", "=", "classifier", "(", "y_1", "*", "mix", "+", "y_1", "[", ":", ":", "-", "1", "]", "*", "(", "1", "-", "mix", ")", ",", "training", "=", "True", ")", "\n", "loss_mt", "=", "tf", ".", "reduce_mean", "(", "(", "labels_teacher", "-", "tf", ".", "nn", ".", "softmax", "(", "logits_student", ")", ")", "**", "2", ",", "-", "1", ")", "\n", "loss_mt", "=", "tf", ".", "reduce_mean", "(", "loss_mt", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "l", ",", "logits", "=", "logits_x", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/mt'", ",", "loss_mt", ")", "\n", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss", "+", "loss_mt", "*", "warmup", "*", "consistency_weight", ",", "\n", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.ict.main": [[92, 129], ["libml.utils.ilog2", "ict.ICT", "ICT.train", "libml.data_pair.DATASETS.keys", "os.path.join", "print", "libml.data_pair.DATASETS.update", "libml.data_pair.DATASETS.keys", "int", "int", "libml.data.DataSet.creator", "itertools.product", "FLAGS.dataset.split", "libml.data_pair.stack_augment", "range"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data_pair.stack_augment"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "if", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", ":", "\n", "        ", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "", "elif", "FLAGS", ".", "dataset", "not", "in", "DATASETS", ".", "keys", "(", ")", "and", "FLAGS", ".", "custom_dataset", ":", "\n", "        ", "print", "(", "\"Preparing to train the \"", "+", "FLAGS", ".", "dataset", "+", "\" dataset.\"", ")", "\n", "label_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "label_size", "]", "\n", "valid_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "valid_size", "]", "\n", "\n", "if", "FLAGS", ".", "augment", "==", "\"cifar10\"", ":", "\n", "            ", "augmentation", "=", "augment_cifar10", "\n", "", "else", ":", "\n", "            ", "augmentation", "=", "augment_custom", "\n", "\n", "", "DATASETS", ".", "update", "(", "[", "DataSet", ".", "creator", "(", "FLAGS", ".", "dataset", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "seed", ",", "label", ",", "valid", ",", "[", "augmentation", ",", "stack_augment", "(", "augmentation", ")", "]", ",", "nclass", "=", "FLAGS", ".", "nclass", ",", "height", "=", "FLAGS", ".", "img_size", ",", "width", "=", "FLAGS", ".", "img_size", ")", "\n", "for", "seed", ",", "label", ",", "valid", "in", "\n", "itertools", ".", "product", "(", "range", "(", "2", ")", ",", "label_size", ",", "valid_size", ")", "]", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "ICT", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "warmup_pos", "=", "FLAGS", ".", "warmup_pos", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "beta", "=", "FLAGS", ".", "beta", ",", "\n", "consistency_weight", "=", "FLAGS", ".", "consistency_weight", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixup.Mixup.augment": [[36, 43], ["tensorflow.distributions.Beta().sample", "tensorflow.maximum", "tensorflow.distributions.Beta", "tensorflow.shape"], "methods", ["None"], ["    ", "def", "augment", "(", "self", ",", "x", ",", "l", ",", "beta", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "mix", "=", "tf", ".", "distributions", ".", "Beta", "(", "beta", ",", "beta", ")", ".", "sample", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "mix", "=", "tf", ".", "maximum", "(", "mix", ",", "1", "-", "mix", ")", "\n", "xmix", "=", "x", "*", "mix", "+", "x", "[", ":", ":", "-", "1", "]", "*", "(", "1", "-", "mix", ")", "\n", "lmix", "=", "l", "*", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", "+", "l", "[", ":", ":", "-", "1", "]", "*", "(", "1", "-", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", ")", "\n", "return", "xmix", ",", "lmix", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixup.Mixup.model": [[44, 90], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "functools.partial", "mixup.Mixup.augment", "mixup.Mixup.model.get_logits"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment"], ["", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "wd", "*=", "lr", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "\n", "def", "get_logits", "(", "x", ")", ":", "\n", "            ", "logits", "=", "classifier", "(", "x", ",", "training", "=", "True", ")", "\n", "return", "logits", "\n", "\n", "", "x", ",", "labels_x", "=", "self", ".", "augment", "(", "x_in", ",", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", ",", "**", "kwargs", ")", "\n", "logits_x", "=", "get_logits", "(", "x", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "y", ",", "labels_y", "=", "self", ".", "augment", "(", "y_in", ",", "tf", ".", "nn", ".", "softmax", "(", "get_logits", "(", "y_in", ")", ")", ",", "**", "kwargs", ")", "\n", "labels_y", "=", "tf", ".", "stop_gradient", "(", "labels_y", ")", "\n", "logits_y", "=", "get_logits", "(", "y", ")", "\n", "\n", "loss_xe", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "labels_x", ",", "logits", "=", "logits_x", ")", "\n", "loss_xe", "=", "tf", ".", "reduce_mean", "(", "loss_xe", ")", "\n", "loss_xeu", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "labels_y", ",", "logits", "=", "logits_y", ")", "\n", "loss_xeu", "=", "tf", ".", "reduce_mean", "(", "loss_xeu", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss_xe", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xeu'", ",", "loss_xeu", ")", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss_xe", "+", "loss_xeu", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixup.get_dataset": [[91, 111], ["libml.data_pair.DATASETS.keys", "libml.data_pair.DATASETS.update", "libml.data_pair.DATASETS.keys", "int", "int", "libml.data.DataSet.creator", "itertools.product", "FLAGS.dataset.split", "libml.data_pair.stack_augment", "range"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data_pair.stack_augment"], ["", "", "def", "get_dataset", "(", ")", ":", "\n", "    ", "assert", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", "or", "FLAGS", ".", "custom_dataset", ",", "\"Please enter a valid dataset name or use the --custom_dataset flag.\"", "\n", "\n", "if", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", ":", "\n", "        ", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "", "else", ":", "\n", "        ", "label_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "label_size", "]", "\n", "valid_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "valid_size", "]", "\n", "\n", "if", "FLAGS", ".", "augment", "==", "\"cifar10\"", ":", "\n", "            ", "augmentation", "=", "augment_cifar10", "\n", "", "else", ":", "\n", "            ", "augmentation", "=", "augment_custom", "\n", "\n", "", "DATASETS", ".", "update", "(", "[", "DataSet", ".", "creator", "(", "FLAGS", ".", "dataset", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "seed", ",", "label", ",", "valid", ",", "[", "augmentation", ",", "stack_augment", "(", "augmentation", ")", "]", ",", "nclass", "=", "FLAGS", ".", "nclass", ",", "height", "=", "FLAGS", ".", "img_size", ",", "width", "=", "FLAGS", ".", "img_size", ")", "\n", "for", "seed", ",", "label", ",", "valid", "in", "\n", "itertools", ".", "product", "(", "range", "(", "2", ")", ",", "label_size", ",", "valid_size", ")", "]", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixup.main": [[112, 132], ["mixup.get_dataset", "libml.utils.ilog2", "mixup.Mixup", "Mixup.train", "os.path.join"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mean_teacher.get_dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "dataset", "=", "get_dataset", "(", ")", "\n", "\n", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "Mixup", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "beta", "=", "FLAGS", ".", "beta", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.pseudo_label.PseudoLabel.model": [[35, 91], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "tensorflow.clip_by_value", "functools.partial", "functools.partial.", "tensorflow.get_collection", "functools.partial.", "tensorflow.nn.sparse_softmax_cross_entropy_with_logits", "tensorflow.reduce_any", "tensorflow.cast", "tensorflow.reduce_mean", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "tensorflow.get_collection.append", "tensorflow.get_collection.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "tensorflow.greater", "libml.utils.model_vars", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.to_float", "tensorflow.argmax", "tensorflow.nn.softmax", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["    ", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "warmup_pos", ",", "consistency_weight", ",", "threshold", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "l", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "wd", "*=", "lr", "\n", "warmup", "=", "tf", ".", "clip_by_value", "(", "tf", ".", "to_float", "(", "self", ".", "step", ")", "/", "(", "warmup_pos", "*", "(", "FLAGS", ".", "train_kimg", "<<", "10", ")", ")", ",", "0", ",", "1", ")", "\n", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "logits_x", "=", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "# Take only first call to update batch norm.", "\n", "logits_y", "=", "classifier", "(", "y_in", ",", "training", "=", "True", ")", "\n", "# Get the pseudo-label loss", "\n", "loss_pl", "=", "tf", ".", "nn", ".", "sparse_softmax_cross_entropy_with_logits", "(", "\n", "labels", "=", "tf", ".", "argmax", "(", "logits_y", ",", "axis", "=", "-", "1", ")", ",", "logits", "=", "logits_y", "\n", ")", "\n", "# Masks denoting which data points have high-confidence predictions", "\n", "greater_than_thresh", "=", "tf", ".", "reduce_any", "(", "\n", "tf", ".", "greater", "(", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ")", ",", "threshold", ")", ",", "\n", "axis", "=", "-", "1", ",", "\n", "keepdims", "=", "True", ",", "\n", ")", "\n", "greater_than_thresh", "=", "tf", ".", "cast", "(", "greater_than_thresh", ",", "loss_pl", ".", "dtype", ")", "\n", "# Only enforce the loss when the model is confident", "\n", "loss_pl", "*=", "greater_than_thresh", "\n", "# Note that we also average over examples without confident outputs;", "\n", "# this is consistent with the realistic evaluation codebase", "\n", "loss_pl", "=", "tf", ".", "reduce_mean", "(", "loss_pl", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "l", ",", "logits", "=", "logits_x", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/pl'", ",", "loss_pl", ")", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss", "+", "loss_pl", "*", "warmup", "*", "consistency_weight", ",", "\n", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.pseudo_label.main": [[93, 116], ["mixmatch.get_dataset", "libml.utils.ilog2", "pseudo_label.PseudoLabel", "PseudoLabel.train", "os.path.join"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mean_teacher.get_dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "dataset", "=", "mixmatch", ".", "get_dataset", "(", ")", "\n", "\n", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "PseudoLabel", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "warmup_pos", "=", "FLAGS", ".", "warmup_pos", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "smoothing", "=", "FLAGS", ".", "smoothing", ",", "\n", "consistency_weight", "=", "FLAGS", ".", "consistency_weight", ",", "\n", "threshold", "=", "FLAGS", ".", "threshold", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixmatch.MixMatch.augment": [[39, 41], ["None"], "methods", ["None"], ["    ", "def", "augment", "(", "self", ",", "x", ",", "l", ",", "beta", ",", "**", "kwargs", ")", ":", "\n", "        ", "assert", "0", ",", "'Do not call.'", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixmatch.MixMatch.guess_label": [[42, 53], ["tensorflow.concat", "tensorflow.reshape", "tensorflow.reduce_mean", "tensorflow.pow", "tensorflow.reduce_sum", "easydict.EasyDict", "classifier", "tensorflow.nn.softmax", "len"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.MultiModel.classifier"], ["", "def", "guess_label", "(", "self", ",", "y", ",", "classifier", ",", "T", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "logits_y", "=", "[", "classifier", "(", "yi", ",", "training", "=", "True", ")", "for", "yi", "in", "y", "]", "\n", "logits_y", "=", "tf", ".", "concat", "(", "logits_y", ",", "0", ")", "\n", "# Compute predicted probability distribution py.", "\n", "p_model_y", "=", "tf", ".", "reshape", "(", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ")", ",", "[", "len", "(", "y", ")", ",", "-", "1", ",", "self", ".", "nclass", "]", ")", "\n", "p_model_y", "=", "tf", ".", "reduce_mean", "(", "p_model_y", ",", "axis", "=", "0", ")", "\n", "# Compute the target distribution.", "\n", "p_target", "=", "tf", ".", "pow", "(", "p_model_y", ",", "1.", "/", "T", ")", "\n", "p_target", "/=", "tf", ".", "reduce_sum", "(", "p_target", ",", "axis", "=", "1", ",", "keep_dims", "=", "True", ")", "\n", "return", "EasyDict", "(", "p_target", "=", "p_target", ",", "p_model", "=", "p_model_y", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixmatch.MixMatch.model": [[54, 110], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.clip_by_value", "libml.layers.MixMode", "functools.partial", "tensorflow.reshape", "mixmatch.MixMatch.guess_label", "tensorflow.stop_gradient", "tensorflow.one_hot", "libml.layers.MixMode.", "libml.layers.interleave", "tensorflow.get_collection", "libml.layers.interleave", "tensorflow.concat", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.reduce_mean", "tensorflow.square", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "post_ops.append", "post_ops.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "tensorflow.transpose", "tensorflow.split", "tensorflow.concat", "functools.partial.", "libml.layers.interleave.append", "libml.utils.model_vars", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.cast", "tensorflow.split", "tensorflow.get_collection", "functools.partial.", "tensorflow.nn.softmax", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape", "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixmatch.MixMatch.guess_label", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.interleave", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.interleave", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["", "def", "model", "(", "self", ",", "batch", ",", "lr", ",", "wd", ",", "ema", ",", "beta", ",", "w_match", ",", "warmup_kimg", "=", "1024", ",", "nu", "=", "2", ",", "mixmode", "=", "'xxy.yxy'", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "nu", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "wd", "*=", "lr", "\n", "w_match", "*=", "tf", ".", "clip_by_value", "(", "tf", ".", "cast", "(", "self", ".", "step", ",", "tf", ".", "float32", ")", "/", "(", "warmup_kimg", "<<", "10", ")", ",", "0", ",", "1", ")", "\n", "augment", "=", "MixMode", "(", "mixmode", ")", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "\n", "y", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "y_in", ",", "[", "1", ",", "0", ",", "2", ",", "3", ",", "4", "]", ")", ",", "[", "-", "1", "]", "+", "hwc", ")", "\n", "guess", "=", "self", ".", "guess_label", "(", "tf", ".", "split", "(", "y", ",", "nu", ")", ",", "classifier", ",", "T", "=", "0.5", ",", "**", "kwargs", ")", "\n", "ly", "=", "tf", ".", "stop_gradient", "(", "guess", ".", "p_target", ")", "\n", "lx", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "xy", ",", "labels_xy", "=", "augment", "(", "[", "x_in", "]", "+", "tf", ".", "split", "(", "y", ",", "nu", ")", ",", "[", "lx", "]", "+", "[", "ly", "]", "*", "nu", ",", "[", "beta", ",", "beta", "]", ")", "\n", "x", ",", "y", "=", "xy", "[", "0", "]", ",", "xy", "[", "1", ":", "]", "\n", "labels_x", ",", "labels_y", "=", "labels_xy", "[", "0", "]", ",", "tf", ".", "concat", "(", "labels_xy", "[", "1", ":", "]", ",", "0", ")", "\n", "del", "xy", ",", "labels_xy", "\n", "\n", "batches", "=", "layers", ".", "interleave", "(", "[", "x", "]", "+", "y", ",", "batch", ")", "\n", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "logits", "=", "[", "classifier", "(", "batches", "[", "0", "]", ",", "training", "=", "True", ")", "]", "\n", "post_ops", "=", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "if", "v", "not", "in", "skip_ops", "]", "\n", "for", "batchi", "in", "batches", "[", "1", ":", "]", ":", "\n", "            ", "logits", ".", "append", "(", "classifier", "(", "batchi", ",", "training", "=", "True", ")", ")", "\n", "", "logits", "=", "layers", ".", "interleave", "(", "logits", ",", "batch", ")", "\n", "logits_x", "=", "logits", "[", "0", "]", "\n", "logits_y", "=", "tf", ".", "concat", "(", "logits", "[", "1", ":", "]", ",", "0", ")", "\n", "\n", "loss_xe", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "labels_x", ",", "logits", "=", "logits_x", ")", "\n", "loss_xe", "=", "tf", ".", "reduce_mean", "(", "loss_xe", ")", "\n", "loss_l2u", "=", "tf", ".", "square", "(", "labels_y", "-", "tf", ".", "nn", ".", "softmax", "(", "logits_y", ")", ")", "\n", "loss_l2u", "=", "tf", ".", "reduce_mean", "(", "loss_l2u", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss_xe", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/l2u'", ",", "loss_l2u", ")", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss_xe", "+", "w_match", "*", "loss_l2u", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "batches", "[", "0", "]", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mixmatch.main": [[112, 134], ["libml.utils.ilog2", "mixmatch.MixMatch", "MixMatch.train", "os.path.join"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "assert", "FLAGS", ".", "nu", "==", "2", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "MixMatch", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "\n", "beta", "=", "FLAGS", ".", "beta", ",", "\n", "w_match", "=", "FLAGS", ".", "w_match", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mean_teacher.MeanTeacher.model": [[39, 85], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "tensorflow.clip_by_value", "functools.partial", "functools.partial.", "tensorflow.get_collection", "tensorflow.reshape", "tensorflow.split", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "functools.partial.", "tensorflow.stop_gradient", "functools.partial.", "tensorflow.reduce_mean", "tensorflow.reduce_mean", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.get_collection.append", "tensorflow.get_collection.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "tensorflow.transpose", "libml.utils.model_vars", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.to_float", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.get_collection"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["    ", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "warmup_pos", ",", "consistency_weight", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "y_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", ",", "2", "]", "+", "hwc", ",", "'y'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "l", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "wd", "*=", "lr", "\n", "warmup", "=", "tf", ".", "clip_by_value", "(", "tf", ".", "to_float", "(", "self", ".", "step", ")", "/", "(", "warmup_pos", "*", "(", "FLAGS", ".", "train_kimg", "<<", "10", ")", ")", ",", "0", ",", "1", ")", "\n", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "logits_x", "=", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "# Take only first call to update batch norm.", "\n", "y", "=", "tf", ".", "reshape", "(", "tf", ".", "transpose", "(", "y_in", ",", "[", "1", ",", "0", ",", "2", ",", "3", ",", "4", "]", ")", ",", "[", "-", "1", "]", "+", "hwc", ")", "\n", "y_1", ",", "y_2", "=", "tf", ".", "split", "(", "y", ",", "2", ")", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "logits_y", "=", "classifier", "(", "y_1", ",", "training", "=", "True", ",", "getter", "=", "ema_getter", ")", "\n", "logits_teacher", "=", "tf", ".", "stop_gradient", "(", "logits_y", ")", "\n", "logits_student", "=", "classifier", "(", "y_2", ",", "training", "=", "True", ")", "\n", "loss_mt", "=", "tf", ".", "reduce_mean", "(", "(", "tf", ".", "nn", ".", "softmax", "(", "logits_teacher", ")", "-", "tf", ".", "nn", ".", "softmax", "(", "logits_student", ")", ")", "**", "2", ",", "-", "1", ")", "\n", "loss_mt", "=", "tf", ".", "reduce_mean", "(", "loss_mt", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "l", ",", "logits", "=", "logits_x", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/mt'", ",", "loss_mt", ")", "\n", "\n", "post_ops", ".", "append", "(", "ema_op", ")", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss", "+", "loss_mt", "*", "warmup", "*", "consistency_weight", ",", "\n", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "y", "=", "y_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mean_teacher.get_dataset": [[87, 110], ["libml.data_pair.DATASETS.keys", "libml.data_pair.DATASETS.update", "libml.data_pair.DATASETS.keys", "int", "int", "libml.data.DataSet.creator", "itertools.product", "FLAGS.dataset.split", "libml.data_pair.stack_augment", "range"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data_pair.stack_augment"], ["", "", "def", "get_dataset", "(", ")", ":", "\n", "    ", "assert", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", "or", "FLAGS", ".", "custom_dataset", ",", "\"Please enter a valid dataset name or use the --custom_dataset flag.\"", "\n", "\n", "# CIFAR10, CIFAR100, STL10, and SVHN are the pre-configured datasets", "\n", "# with each dataset's default augmentation.", "\n", "if", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", ":", "\n", "        ", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "# If the dataset has not been pre-configured, create it.", "\n", "", "else", ":", "\n", "        ", "label_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "label_size", "]", "\n", "valid_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "valid_size", "]", "\n", "\n", "augment_dict", "=", "{", "\"cifar10\"", ":", "augment_cifar10", ",", "\"cutout\"", ":", "augment_cutout", ",", "\"svhn\"", ":", "augment_svhn", ",", "\"stl10\"", ":", "augment_stl10", ",", "\"color\"", ":", "augment_color", "}", "\n", "augmentation", "=", "augment_dict", "[", "FLAGS", ".", "augment", "]", "\n", "\n", "DATASETS", ".", "update", "(", "[", "DataSet", ".", "creator", "(", "FLAGS", ".", "dataset", ".", "split", "(", "\".\"", ")", "[", "0", "]", ",", "seed", ",", "label", ",", "valid", ",", "[", "augmentation", ",", "stack_augment", "(", "augmentation", ")", "]", ",", "nclass", "=", "FLAGS", ".", "nclass", ",", "height", "=", "FLAGS", ".", "img_size", ",", "width", "=", "FLAGS", ".", "img_size", ",", "do_memoize", "=", "FLAGS", ".", "memoize", ")", "\n", "for", "seed", ",", "label", ",", "valid", "in", "\n", "itertools", ".", "product", "(", "range", "(", "2", ")", ",", "label_size", ",", "valid_size", ")", "]", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "", "return", "dataset", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mean_teacher.main": [[111, 134], ["mean_teacher.get_dataset", "libml.utils.ilog2", "mean_teacher.MeanTeacher", "MeanTeacher.train", "os.path.join"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.None.mean_teacher.get_dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "\n", "dataset", "=", "get_dataset", "(", ")", "\n", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "MeanTeacher", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "warmup_pos", "=", "FLAGS", ".", "warmup_pos", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "smoothing", "=", "FLAGS", ".", "smoothing", ",", "\n", "consistency_weight", "=", "FLAGS", ".", "consistency_weight", ",", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "\n", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.fully_supervised.fs_baseline.FSBaseline.model": [[37, 74], ["tensorflow.placeholder", "tensorflow.placeholder", "tensorflow.one_hot", "fs_baseline.FSBaseline.augment", "functools.partial", "functools.partial.", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.reduce_mean", "tensorflow.summary.scalar", "tensorflow.train.ExponentialMovingAverage", "tensorflow.train.ExponentialMovingAverage.apply", "functools.partial", "post_ops.extend", "tensorflow.train.AdamOptimizer().minimize", "tensorflow.get_collection", "functools.partial.", "tensorflow.group", "easydict.EasyDict", "libml.utils.model_vars", "tensorflow.get_collection", "tensorflow.control_dependencies", "tensorflow.group", "tensorflow.assign", "tensorflow.train.AdamOptimizer", "tensorflow.nn.softmax", "tensorflow.nn.softmax", "tensorflow.reduce_mean", "libml.utils.model_vars", "functools.partial.", "functools.partial.", "tensorflow.nn.softmax_cross_entropy_with_logits_v2", "tensorflow.get_collection", "functools.partial.", "tensorflow.one_hot"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["    ", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "wd", "*=", "lr", "\n", "l", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", "\n", "\n", "x", ",", "l", "=", "self", ".", "augment", "(", "x_in", ",", "l", ",", "**", "kwargs", ")", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "logits", "=", "classifier", "(", "x", ",", "training", "=", "True", ")", "\n", "\n", "loss", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "l", ",", "logits", "=", "logits", ")", "\n", "loss", "=", "tf", ".", "reduce_mean", "(", "loss", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss", ")", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "+", "[", "ema_op", "]", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ",", "\n", "eval_loss_op", "=", "tf", ".", "reduce_mean", "(", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "logits", "=", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ",", "\n", "labels", "=", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.fully_supervised.fs_baseline.main": [[76, 111], ["libml.utils.ilog2", "fs_baseline.FSBaseline", "FSBaseline.train", "print", "fully_supervised.lib.data.DATASETS.update", "os.path.join", "fully_supervised.lib.data.DATASETS.keys", "int", "fully_supervised.lib.data.DataSetFS.creator", "FLAGS.dataset.split"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "\n", "assert", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", "or", "FLAGS", ".", "custom_dataset", ",", "\"Please specify a dataset which is in data.py or use --custom_dataset.\"", "\n", "\n", "if", "not", "FLAGS", ".", "custom_dataset", ":", "\n", "        ", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Preparing to train the \"", "+", "FLAGS", ".", "dataset", "+", "\" dataset.\"", ")", "\n", "valid_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "valid_size", "]", "\n", "\n", "augmentation", "=", "data", ".", "augment_cifar10", "\n", "\n", "# Do not name your dataset using a \"-\", otherwise the following line will not work for a custom dataset.", "\n", "DATASETS", ".", "update", "(", "[", "DataSetFS", ".", "creator", "(", "FLAGS", ".", "dataset", ".", "split", "(", "\"-\"", ")", "[", "0", "]", ",", "[", "FLAGS", ".", "train_record", "]", ",", "[", "FLAGS", ".", "test_record", "]", ",", "valid", ",", "\n", "augmentation", ",", "nclass", "=", "FLAGS", ".", "nclass", ",", "height", "=", "FLAGS", ".", "img_size", ",", "width", "=", "FLAGS", ".", "img_size", ")", "\n", "for", "valid", "in", "valid_size", "]", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "FSBaseline", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "smoothing", "=", "FLAGS", ".", "smoothing", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.fully_supervised.fs_mixup.FSMixup.augment": [[40, 47], ["tensorflow.distributions.Beta().sample", "tensorflow.maximum", "tensorflow.distributions.Beta", "tensorflow.shape"], "methods", ["None"], ["    ", "def", "augment", "(", "self", ",", "x", ",", "l", ",", "beta", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "mix", "=", "tf", ".", "distributions", ".", "Beta", "(", "beta", ",", "beta", ")", ".", "sample", "(", "[", "tf", ".", "shape", "(", "x", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "mix", "=", "tf", ".", "maximum", "(", "mix", ",", "1", "-", "mix", ")", "\n", "xmix", "=", "x", "*", "mix", "+", "x", "[", ":", ":", "-", "1", "]", "*", "(", "1", "-", "mix", ")", "\n", "lmix", "=", "l", "*", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", "+", "l", "[", ":", ":", "-", "1", "]", "*", "(", "1", "-", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", ")", "\n", "return", "xmix", ",", "lmix", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.fully_supervised.fs_mixup.FSMixup.model": [[48, 86], ["tensorflow.placeholder", "tensorflow.placeholder", "functools.partial", "fs_mixup.FSMixup.augment", "fs_mixup.FSMixup.model.get_logits"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment"], ["", "def", "model", "(", "self", ",", "lr", ",", "wd", ",", "ema", ",", "**", "kwargs", ")", ":", "\n", "        ", "hwc", "=", "[", "self", ".", "dataset", ".", "height", ",", "self", ".", "dataset", ".", "width", ",", "self", ".", "dataset", ".", "colors", "]", "\n", "x_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "float32", ",", "[", "None", "]", "+", "hwc", ",", "'x'", ")", "\n", "l_in", "=", "tf", ".", "placeholder", "(", "tf", ".", "int32", ",", "[", "None", "]", ",", "'labels'", ")", "\n", "wd", "*=", "lr", "\n", "classifier", "=", "functools", ".", "partial", "(", "self", ".", "classifier", ",", "**", "kwargs", ")", "\n", "\n", "def", "get_logits", "(", "x", ")", ":", "\n", "            ", "logits", "=", "classifier", "(", "x", ",", "training", "=", "True", ")", "\n", "return", "logits", "\n", "\n", "", "x", ",", "labels_x", "=", "self", ".", "augment", "(", "x_in", ",", "tf", ".", "one_hot", "(", "l_in", ",", "self", ".", "nclass", ")", ",", "**", "kwargs", ")", "\n", "logits_x", "=", "get_logits", "(", "x", ")", "\n", "\n", "loss_xe", "=", "tf", ".", "nn", ".", "softmax_cross_entropy_with_logits_v2", "(", "labels", "=", "labels_x", ",", "logits", "=", "logits_x", ")", "\n", "loss_xe", "=", "tf", ".", "reduce_mean", "(", "loss_xe", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'losses/xe'", ",", "loss_xe", ")", "\n", "\n", "ema", "=", "tf", ".", "train", ".", "ExponentialMovingAverage", "(", "decay", "=", "ema", ")", "\n", "ema_op", "=", "ema", ".", "apply", "(", "utils", ".", "model_vars", "(", ")", ")", "\n", "ema_getter", "=", "functools", ".", "partial", "(", "utils", ".", "getter_ema", ",", "ema", ")", "\n", "post_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "+", "[", "ema_op", "]", "\n", "post_ops", ".", "extend", "(", "[", "tf", ".", "assign", "(", "v", ",", "v", "*", "(", "1", "-", "wd", ")", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "'classify'", ")", "if", "'kernel'", "in", "v", ".", "name", "]", ")", "\n", "\n", "train_op", "=", "tf", ".", "train", ".", "AdamOptimizer", "(", "lr", ")", ".", "minimize", "(", "loss_xe", ",", "colocate_gradients_with_ops", "=", "True", ")", "\n", "with", "tf", ".", "control_dependencies", "(", "[", "train_op", "]", ")", ":", "\n", "            ", "train_op", "=", "tf", ".", "group", "(", "*", "post_ops", ")", "\n", "\n", "# Tuning op: only retrain batch norm.", "\n", "", "skip_ops", "=", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "classifier", "(", "x_in", ",", "training", "=", "True", ")", "\n", "train_bn", "=", "tf", ".", "group", "(", "*", "[", "v", "for", "v", "in", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "UPDATE_OPS", ")", "\n", "if", "v", "not", "in", "skip_ops", "]", ")", "\n", "\n", "return", "EasyDict", "(", "\n", "x", "=", "x_in", ",", "label", "=", "l_in", ",", "train_op", "=", "train_op", ",", "tune_op", "=", "train_bn", ",", "\n", "classify_raw", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "training", "=", "False", ")", ")", ",", "# No EMA, for debugging.", "\n", "classify_op", "=", "tf", ".", "nn", ".", "softmax", "(", "classifier", "(", "x_in", ",", "getter", "=", "ema_getter", ",", "training", "=", "False", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.fully_supervised.fs_mixup.main": [[88, 157], ["libml.utils.ilog2", "fs_mixup.FSMixup", "print", "fully_supervised.lib.data.DATASETS.update", "os.path.join", "print", "np.asarray", "FSMixup.eval_mode", "np.concatenate", "FSMixup.get_class_mapping", "enumerate", "np.asarray", "print", "np.save", "print", "FSMixup.train", "fully_supervised.lib.data.DATASETS.keys", "int", "np.asarray.append", "np.concatenate.argmax", "fully_supervised.lib.data.DataSetFS.creator", "glob.glob", "plt.imread", "FSMixup.session.run", "model.get_class_mapping.items", "class_names.index", "range", "FLAGS.dataset.split", "path.split", "np.concatenate.argmax"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.eval_mode", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator"], ["", "", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "# Unused.", "\n", "assert", "FLAGS", ".", "dataset", "in", "DATASETS", ".", "keys", "(", ")", "or", "FLAGS", ".", "custom_dataset", ",", "\"Please specify a dataset which is in data.py or use --custom_dataset.\"", "\n", "\n", "if", "not", "FLAGS", ".", "custom_dataset", ":", "\n", "        ", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Preparing to train the \"", "+", "FLAGS", ".", "dataset", "+", "\" dataset.\"", ")", "\n", "valid_size", "=", "[", "int", "(", "size", ")", "for", "size", "in", "FLAGS", ".", "valid_size", "]", "\n", "\n", "if", "FLAGS", ".", "augment", "==", "\"cifar10\"", ":", "\n", "            ", "augmentation", "=", "data", ".", "augment_cifar10", "\n", "", "else", ":", "\n", "            ", "augmentation", "=", "data", ".", "augment_color", "\n", "\n", "# Do not name your dataset using a \"-\", otherwise the following line will not work for a custom dataset.", "\n", "", "DATASETS", ".", "update", "(", "[", "DataSetFS", ".", "creator", "(", "FLAGS", ".", "dataset", ".", "split", "(", "\"-\"", ")", "[", "0", "]", ",", "[", "FLAGS", ".", "train_record", "]", ",", "[", "FLAGS", ".", "test_record", "]", ",", "valid", ",", "\n", "augmentation", ",", "nclass", "=", "FLAGS", ".", "nclass", ",", "height", "=", "FLAGS", ".", "img_size", ",", "width", "=", "FLAGS", ".", "img_size", ")", "\n", "for", "valid", "in", "valid_size", "]", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "\n", "", "log_width", "=", "utils", ".", "ilog2", "(", "dataset", ".", "width", ")", "\n", "model", "=", "FSMixup", "(", "\n", "os", ".", "path", ".", "join", "(", "FLAGS", ".", "train_dir", ",", "dataset", ".", "name", ")", ",", "\n", "dataset", ",", "\n", "lr", "=", "FLAGS", ".", "lr", ",", "\n", "wd", "=", "FLAGS", ".", "wd", ",", "\n", "arch", "=", "FLAGS", ".", "arch", ",", "\n", "batch", "=", "FLAGS", ".", "batch", ",", "\n", "nclass", "=", "dataset", ".", "nclass", ",", "\n", "ema", "=", "FLAGS", ".", "ema", ",", "\n", "beta", "=", "FLAGS", ".", "beta", ",", "\n", "\n", "scales", "=", "FLAGS", ".", "scales", "or", "(", "log_width", "-", "2", ")", ",", "\n", "filters", "=", "FLAGS", ".", "filters", ",", "\n", "repeat", "=", "FLAGS", ".", "repeat", ")", "\n", "\n", "if", "FLAGS", ".", "perform_inference", ":", "\n", "        ", "print", "(", "\"Performing inference...\"", ")", "\n", "assert", "FLAGS", ".", "inference_dir", "\n", "assert", "FLAGS", ".", "inference_ckpt", "\n", "inference_dir", "=", "FLAGS", ".", "inference_dir", "\n", "inference_ckpt", "=", "FLAGS", ".", "inference_ckpt", "\n", "\n", "if", "inference_dir", "[", "-", "1", "]", "!=", "\"/\"", ":", "\n", "            ", "inference_dir", "+=", "\"/\"", "\n", "", "inference_img_paths", "=", "[", "path", "for", "path", "in", "glob", ".", "glob", "(", "inference_dir", "+", "\"*.jpg\"", ")", "]", "\n", "images", "=", "np", ".", "asarray", "(", "[", "plt", ".", "imread", "(", "img_path", ")", "for", "img_path", "in", "inference_img_paths", "]", ")", "\n", "images", "=", "images", "*", "(", "2.0", "/", "255", ")", "-", "1.0", "\n", "model", ".", "eval_mode", "(", "ckpt", "=", "inference_ckpt", ")", "\n", "batch", "=", "FLAGS", ".", "batch", "\n", "feed_extra", "=", "None", "\n", "logits", "=", "np", ".", "concatenate", "(", "[", "model", ".", "session", ".", "run", "(", "model", ".", "ops", ".", "classify_op", ",", "feed_dict", "=", "{", "\n", "model", ".", "ops", ".", "x", ":", "images", "[", "x", ":", "x", "+", "batch", "]", ",", "**", "(", "feed_extra", "or", "{", "}", ")", "}", ")", "\n", "for", "x", "in", "range", "(", "0", ",", "images", ".", "shape", "[", "0", "]", ",", "batch", ")", "]", ",", "axis", "=", "0", ")", "\n", "class_dict", "=", "model", ".", "get_class_mapping", "(", ")", "\n", "class_names", "=", "[", "value", "for", "key", ",", "value", "in", "class_dict", ".", "items", "(", ")", "]", "\n", "gt_classes", "=", "[", "]", "\n", "\n", "for", "i", ",", "path", "in", "enumerate", "(", "inference_img_paths", ")", ":", "\n", "            ", "gt_classes", ".", "append", "(", "class_names", ".", "index", "(", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", ")", "\n", "\n", "", "gt_classes", "=", "np", ".", "asarray", "(", "gt_classes", ")", "\n", "print", "(", "\"Overall Acc: \"", ",", "(", "logits", ".", "argmax", "(", "1", ")", "==", "gt_classes", ")", ".", "mean", "(", ")", "*", "100", ")", "\n", "\n", "np", ".", "save", "(", "'predictions_fs_mixup.npy'", ",", "logits", ".", "argmax", "(", "1", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"Preparing to train the \"", "+", "FLAGS", ".", "dataset", "+", "\" dataset.\"", ")", "\n", "model", ".", "train", "(", "FLAGS", ".", "train_kimg", "<<", "10", ",", "FLAGS", ".", "report_kimg", "<<", "10", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.random_eraser.get_random_eraser": [[20, 49], ["numpy.random.rand", "numpy.random.uniform", "int", "int", "numpy.random.randint", "numpy.random.randint", "numpy.random.uniform", "numpy.random.uniform", "numpy.sqrt", "numpy.sqrt", "numpy.random.uniform"], "function", ["None"], ["def", "get_random_eraser", "(", "p", "=", "0.5", ",", "s_l", "=", "0.02", ",", "s_h", "=", "0.4", ",", "r_1", "=", "0.3", ",", "r_2", "=", "1", "/", "0.3", ",", "v_l", "=", "0", ",", "v_h", "=", "255", ",", "pixel_level", "=", "False", ")", ":", "\n", "    ", "def", "eraser", "(", "input_img", ")", ":", "\n", "        ", "img_h", ",", "img_w", ",", "img_c", "=", "input_img", ".", "shape", "\n", "p_1", "=", "np", ".", "random", ".", "rand", "(", ")", "\n", "\n", "if", "p_1", ">", "p", ":", "\n", "            ", "return", "input_img", "\n", "\n", "", "while", "True", ":", "\n", "            ", "s", "=", "np", ".", "random", ".", "uniform", "(", "s_l", ",", "s_h", ")", "*", "img_h", "*", "img_w", "\n", "r", "=", "np", ".", "random", ".", "uniform", "(", "r_1", ",", "r_2", ")", "\n", "w", "=", "int", "(", "np", ".", "sqrt", "(", "s", "/", "r", ")", ")", "\n", "h", "=", "int", "(", "np", ".", "sqrt", "(", "s", "*", "r", ")", ")", "\n", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "img_w", ")", "\n", "top", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "img_h", ")", "\n", "\n", "if", "left", "+", "w", "<=", "img_w", "and", "top", "+", "h", "<=", "img_h", ":", "\n", "                ", "break", "\n", "\n", "", "", "if", "pixel_level", ":", "\n", "            ", "c", "=", "np", ".", "random", ".", "uniform", "(", "v_l", ",", "v_h", ",", "(", "h", ",", "w", ",", "img_c", ")", ")", "\n", "", "else", ":", "\n", "            ", "c", "=", "np", ".", "random", ".", "uniform", "(", "v_l", ",", "v_h", ")", "\n", "\n", "", "input_img", "[", "top", ":", "top", "+", "h", ",", "left", ":", "left", "+", "w", ",", ":", "]", "=", "c", "\n", "\n", "return", "input_img", "\n", "\n", "", "return", "eraser", "\n", "", ""]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.random_eraser_tf.get_random_eraser": [[22, 53], ["numpy.random.rand", "numpy.random.uniform", "tensorflow.Variable", "tensorflow.assign", "numpy.random.uniform", "int", "int", "numpy.random.randint", "numpy.random.randint", "tensorflow.Session", "tensorflow.device", "sess.run", "sess.run", "tf.Variable.eval", "numpy.sqrt", "numpy.sqrt", "tensorflow.global_variables_initializer", "numpy.random.uniform"], "function", ["None"], ["def", "get_random_eraser", "(", "p", "=", "0.5", ",", "width", "=", "32", ",", "height", "=", "32", ",", "channels", "=", "32", ",", "s_l", "=", "0.02", ",", "s_h", "=", "0.4", ",", "r_1", "=", "0.3", ",", "r_2", "=", "1", "/", "0.3", ",", "v_l", "=", "0", ",", "v_h", "=", "255", ",", "pixel_level", "=", "False", ")", ":", "\n", "    ", "def", "eraser", "(", "input_img", ")", ":", "\n", "        ", "img_h", "=", "height", "\n", "img_w", "=", "width", "\n", "img_c", "=", "channels", "\n", "p_1", "=", "np", ".", "random", ".", "rand", "(", ")", "\n", "\n", "if", "p_1", ">", "p", ":", "\n", "            ", "return", "input_img", "\n", "\n", "", "while", "True", ":", "\n", "            ", "s", "=", "np", ".", "random", ".", "uniform", "(", "s_l", ",", "s_h", ")", "*", "img_h", "*", "img_w", "\n", "r", "=", "np", ".", "random", ".", "uniform", "(", "r_1", ",", "r_2", ")", "\n", "w", "=", "int", "(", "np", ".", "sqrt", "(", "s", "/", "r", ")", ")", "\n", "h", "=", "int", "(", "np", ".", "sqrt", "(", "s", "*", "r", ")", ")", "\n", "left", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "img_w", ")", "\n", "top", "=", "np", ".", "random", ".", "randint", "(", "0", ",", "img_h", ")", "\n", "\n", "if", "left", "+", "w", "<=", "img_w", "and", "top", "+", "h", "<=", "img_h", ":", "\n", "                ", "break", "\n", "\n", "", "", "c", "=", "np", ".", "random", ".", "uniform", "(", "v_l", ",", "v_h", ")", "\n", "input_img_var", "=", "tf", ".", "Variable", "(", "input_img", ",", "name", "=", "\"input_image\"", ",", "expected_shape", "=", "[", "height", ",", "width", ",", "3", "]", ")", "\n", "assign_x", "=", "tf", ".", "assign", "(", "input_img_var", "[", "top", ":", "top", "+", "h", ",", "left", ":", "left", "+", "w", ",", ":", "]", ",", "c", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ",", "tf", ".", "device", "(", "'cpu:0'", ")", ":", "\n", "            ", "sess", ".", "run", "(", "[", "assign_x", "]", ")", "\n", "sess", ".", "run", "(", "tf", ".", "global_variables_initializer", "(", ")", ")", "\n", "return", "input_img_var", ".", "eval", "(", ")", "\n", "\n", "", "", "return", "eraser", "\n", "", ""]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.generate_perturbation": [[5, 29], ["tensorflow.random_normal", "range", "forward", "vat_utils.kl_divergence_with_logit", "tensorflow.stop_gradient", "vat_utils.get_normalized_vector", "tensorflow.shape", "vat_utils.get_normalized_vector", "tensorflow.gradients", "tensorflow.reduce_mean"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.kl_divergence_with_logit", "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.get_normalized_vector", "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.get_normalized_vector"], ["def", "generate_perturbation", "(", "x", ",", "logit", ",", "forward", ",", "epsilon", ",", "xi", "=", "1e-6", ")", ":", "\n", "    ", "\"\"\"Generate an adversarial perturbation.\n\n    Args:\n        x: Model inputs.\n        logit: Original model output without perturbation.\n        forward: Callable which computs logits given input.\n        epsilon: Gradient multiplier.\n        xi: Small constant.\n\n    Returns:\n        Aversarial perturbation to be applied to x.\n    \"\"\"", "\n", "d", "=", "tf", ".", "random_normal", "(", "shape", "=", "tf", ".", "shape", "(", "x", ")", ")", "\n", "\n", "for", "_", "in", "range", "(", "1", ")", ":", "\n", "        ", "d", "=", "xi", "*", "get_normalized_vector", "(", "d", ")", "\n", "logit_p", "=", "logit", "\n", "logit_m", "=", "forward", "(", "x", "+", "d", ")", "\n", "dist", "=", "kl_divergence_with_logit", "(", "logit_p", ",", "logit_m", ")", "\n", "grad", "=", "tf", ".", "gradients", "(", "tf", ".", "reduce_mean", "(", "dist", ")", ",", "[", "d", "]", ",", "aggregation_method", "=", "2", ")", "[", "0", "]", "\n", "d", "=", "tf", ".", "stop_gradient", "(", "grad", ")", "\n", "\n", "", "return", "epsilon", "*", "get_normalized_vector", "(", "d", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.kl_divergence_with_logit": [[31, 37], ["tensorflow.nn.softmax", "tensorflow.reduce_sum", "tensorflow.reduce_sum", "vat_utils.logsoftmax", "vat_utils.logsoftmax"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.logsoftmax", "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.logsoftmax"], ["", "def", "kl_divergence_with_logit", "(", "q_logit", ",", "p_logit", ")", ":", "\n", "    ", "\"\"\"Compute the per-element KL-divergence of a batch.\"\"\"", "\n", "q", "=", "tf", ".", "nn", ".", "softmax", "(", "q_logit", ")", "\n", "qlogq", "=", "tf", ".", "reduce_sum", "(", "q", "*", "logsoftmax", "(", "q_logit", ")", ",", "1", ")", "\n", "qlogp", "=", "tf", ".", "reduce_sum", "(", "q", "*", "logsoftmax", "(", "p_logit", ")", ",", "1", ")", "\n", "return", "qlogq", "-", "qlogp", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.get_normalized_vector": [[39, 51], ["tensorflow.sqrt", "tensorflow.reduce_max", "tensorflow.abs", "list", "tensorflow.reduce_sum", "range", "tensorflow.pow", "list", "len", "range", "d.get_shape", "len", "d.get_shape"], "function", ["None"], ["", "def", "get_normalized_vector", "(", "d", ")", ":", "\n", "    ", "\"\"\"Normalize d by infinity and L2 norms.\"\"\"", "\n", "d", "/=", "1e-12", "+", "tf", ".", "reduce_max", "(", "\n", "tf", ".", "abs", "(", "d", ")", ",", "list", "(", "range", "(", "1", ",", "len", "(", "d", ".", "get_shape", "(", ")", ")", ")", ")", ",", "keepdims", "=", "True", "\n", ")", "\n", "d", "/=", "tf", ".", "sqrt", "(", "\n", "1e-6", "\n", "+", "tf", ".", "reduce_sum", "(", "\n", "tf", ".", "pow", "(", "d", ",", "2.0", ")", ",", "list", "(", "range", "(", "1", ",", "len", "(", "d", ".", "get_shape", "(", ")", ")", ")", ")", ",", "keepdims", "=", "True", "\n", ")", "\n", ")", "\n", "return", "d", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.vat_utils.logsoftmax": [[53, 58], ["tensorflow.reduce_max", "tensorflow.log", "tensorflow.reduce_sum", "tensorflow.exp"], "function", ["None"], ["", "def", "logsoftmax", "(", "x", ")", ":", "\n", "    ", "\"\"\"Compute log-domain softmax of logits.\"\"\"", "\n", "xdev", "=", "x", "-", "tf", ".", "reduce_max", "(", "x", ",", "1", ",", "keepdims", "=", "True", ")", "\n", "lsm", "=", "xdev", "-", "tf", ".", "log", "(", "tf", ".", "reduce_sum", "(", "tf", ".", "exp", "(", "xdev", ")", ",", "1", ",", "keepdims", "=", "True", ")", ")", "\n", "return", "lsm", "\n", "", ""]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.ConvNet.classifier": [[25, 38], ["dict", "tensorflow.variable_scope", "tensorflow.layers.conv2d", "range", "tensorflow.layers.conv2d", "tensorflow.reduce_mean", "tensorflow.layers.conv2d", "tensorflow.layers.conv2d", "tensorflow.layers.average_pooling2d"], "methods", ["None"], ["    ", "def", "classifier", "(", "self", ",", "x", ",", "scales", ",", "filters", ",", "getter", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "conv_args", "=", "dict", "(", "kernel_size", "=", "3", ",", "activation", "=", "tf", ".", "nn", ".", "leaky_relu", ",", "padding", "=", "'same'", ")", "\n", "\n", "with", "tf", ".", "variable_scope", "(", "'classify'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "custom_getter", "=", "getter", ")", ":", "\n", "            ", "y", "=", "tf", ".", "layers", ".", "conv2d", "(", "x", ",", "filters", ",", "**", "conv_args", ")", "\n", "for", "scale", "in", "range", "(", "scales", ")", ":", "\n", "                ", "y", "=", "tf", ".", "layers", ".", "conv2d", "(", "y", ",", "filters", "<<", "scale", ",", "**", "conv_args", ")", "\n", "y", "=", "tf", ".", "layers", ".", "conv2d", "(", "y", ",", "filters", "<<", "(", "scale", "+", "1", ")", ",", "**", "conv_args", ")", "\n", "y", "=", "tf", ".", "layers", ".", "average_pooling2d", "(", "y", ",", "2", ",", "2", ")", "\n", "", "y", "=", "tf", ".", "layers", ".", "conv2d", "(", "y", ",", "self", ".", "nclass", ",", "3", ",", "padding", "=", "'same'", ")", "\n", "logits", "=", "tf", ".", "reduce_mean", "(", "y", ",", "[", "1", ",", "2", "]", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.ResNet.classifier": [[41, 75], ["functools.partial", "dict", "dict", "functools.partial.", "tensorflow.layers.conv2d", "functools.partial.", "tensorflow.layers.conv2d", "tensorflow.variable_scope", "tensorflow.layers.conv2d", "range", "functools.partial.", "tensorflow.reduce_mean", "tensorflow.layers.dense", "tensorflow.layers.batch_normalization", "tensorflow.layers.batch_normalization", "tensorflow.layers.conv2d", "models.ResNet.classifier.residual"], "methods", ["None"], ["    ", "def", "classifier", "(", "self", ",", "x", ",", "scales", ",", "filters", ",", "repeat", ",", "training", ",", "getter", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "leaky_relu", "=", "functools", ".", "partial", "(", "tf", ".", "nn", ".", "leaky_relu", ",", "alpha", "=", "0.1", ")", "\n", "bn_args", "=", "dict", "(", "training", "=", "training", ",", "momentum", "=", "0.999", ")", "\n", "\n", "def", "conv_args", "(", "k", ",", "f", ")", ":", "\n", "            ", "return", "dict", "(", "padding", "=", "'same'", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "tf", ".", "rsqrt", "(", "0.5", "*", "k", "*", "k", "*", "f", ")", ")", ")", "\n", "\n", "", "def", "residual", "(", "x0", ",", "filters", ",", "stride", "=", "1", ",", "activate_before_residual", "=", "False", ")", ":", "\n", "            ", "x", "=", "leaky_relu", "(", "tf", ".", "layers", ".", "batch_normalization", "(", "x0", ",", "**", "bn_args", ")", ")", "\n", "if", "activate_before_residual", ":", "\n", "                ", "x0", "=", "x", "\n", "\n", "", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "x", ",", "filters", ",", "3", ",", "strides", "=", "stride", ",", "**", "conv_args", "(", "3", ",", "filters", ")", ")", "\n", "x", "=", "leaky_relu", "(", "tf", ".", "layers", ".", "batch_normalization", "(", "x", ",", "**", "bn_args", ")", ")", "\n", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "x", ",", "filters", ",", "3", ",", "**", "conv_args", "(", "3", ",", "filters", ")", ")", "\n", "\n", "if", "x0", ".", "get_shape", "(", ")", "[", "3", "]", "!=", "filters", ":", "\n", "                ", "x0", "=", "tf", ".", "layers", ".", "conv2d", "(", "x0", ",", "filters", ",", "1", ",", "strides", "=", "stride", ",", "**", "conv_args", "(", "1", ",", "filters", ")", ")", "\n", "\n", "", "return", "x0", "+", "x", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'classify'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "custom_getter", "=", "getter", ")", ":", "\n", "            ", "y", "=", "tf", ".", "layers", ".", "conv2d", "(", "(", "x", "-", "self", ".", "dataset", ".", "mean", ")", "/", "self", ".", "dataset", ".", "std", ",", "16", ",", "3", ",", "**", "conv_args", "(", "3", ",", "16", ")", ")", "\n", "for", "scale", "in", "range", "(", "scales", ")", ":", "\n", "                ", "y", "=", "residual", "(", "y", ",", "filters", "<<", "scale", ",", "stride", "=", "2", "if", "scale", "else", "1", ",", "activate_before_residual", "=", "scale", "==", "0", ")", "\n", "for", "i", "in", "range", "(", "repeat", "-", "1", ")", ":", "\n", "                    ", "y", "=", "residual", "(", "y", ",", "filters", "<<", "scale", ")", "\n", "\n", "", "", "y", "=", "leaky_relu", "(", "tf", ".", "layers", ".", "batch_normalization", "(", "y", ",", "**", "bn_args", ")", ")", "\n", "y", "=", "tf", ".", "reduce_mean", "(", "y", ",", "[", "1", ",", "2", "]", ")", "\n", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "y", ",", "self", ".", "nclass", ",", "kernel_initializer", "=", "tf", ".", "glorot_normal_initializer", "(", ")", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.ShakeNet.classifier": [[78, 120], ["dict", "dict", "libml.layers.shakeshake", "tensorflow.variable_scope", "tensorflow.layers.conv2d", "itertools.product", "tensorflow.reduce_mean", "tensorflow.layers.dense", "tensorflow.nn.relu", "tensorflow.layers.conv2d", "tensorflow.nn.relu", "tensorflow.layers.conv2d", "tensorflow.layers.batch_normalization", "branch"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.shakeshake"], ["    ", "def", "classifier", "(", "self", ",", "x", ",", "scales", ",", "filters", ",", "repeat", ",", "training", ",", "getter", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "bn_args", "=", "dict", "(", "training", "=", "training", ",", "momentum", "=", "0.999", ")", "\n", "\n", "def", "conv_args", "(", "k", ",", "f", ")", ":", "\n", "            ", "return", "dict", "(", "padding", "=", "'same'", ",", "use_bias", "=", "False", ",", "\n", "kernel_initializer", "=", "tf", ".", "random_normal_initializer", "(", "stddev", "=", "tf", ".", "rsqrt", "(", "0.5", "*", "k", "*", "k", "*", "f", ")", ")", ")", "\n", "\n", "", "def", "residual", "(", "x0", ",", "filters", ",", "stride", "=", "1", ")", ":", "\n", "            ", "def", "branch", "(", ")", ":", "\n", "                ", "x", "=", "tf", ".", "nn", ".", "relu", "(", "x0", ")", "\n", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "x", ",", "filters", ",", "3", ",", "strides", "=", "stride", ",", "**", "conv_args", "(", "3", ",", "filters", ")", ")", "\n", "x", "=", "tf", ".", "nn", ".", "relu", "(", "tf", ".", "layers", ".", "batch_normalization", "(", "x", ",", "**", "bn_args", ")", ")", "\n", "x", "=", "tf", ".", "layers", ".", "conv2d", "(", "x", ",", "filters", ",", "3", ",", "**", "conv_args", "(", "3", ",", "filters", ")", ")", "\n", "x", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "x", ",", "**", "bn_args", ")", "\n", "return", "x", "\n", "\n", "", "x", "=", "layers", ".", "shakeshake", "(", "branch", "(", ")", ",", "branch", "(", ")", ",", "training", ")", "\n", "\n", "if", "stride", "==", "2", ":", "\n", "                ", "x1", "=", "tf", ".", "layers", ".", "conv2d", "(", "tf", ".", "nn", ".", "relu", "(", "x0", "[", ":", ",", ":", ":", "2", ",", ":", ":", "2", "]", ")", ",", "filters", ">>", "1", ",", "1", ",", "**", "conv_args", "(", "1", ",", "filters", ">>", "1", ")", ")", "\n", "x2", "=", "tf", ".", "layers", ".", "conv2d", "(", "tf", ".", "nn", ".", "relu", "(", "x0", "[", ":", ",", "1", ":", ":", "2", ",", "1", ":", ":", "2", "]", ")", ",", "filters", ">>", "1", ",", "1", ",", "**", "conv_args", "(", "1", ",", "filters", ">>", "1", ")", ")", "\n", "x0", "=", "tf", ".", "concat", "(", "[", "x1", ",", "x2", "]", ",", "axis", "=", "3", ")", "\n", "x0", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "x0", ",", "**", "bn_args", ")", "\n", "", "elif", "x0", ".", "get_shape", "(", ")", "[", "3", "]", "!=", "filters", ":", "\n", "                ", "x0", "=", "tf", ".", "layers", ".", "conv2d", "(", "x0", ",", "filters", ",", "1", ",", "**", "conv_args", "(", "1", ",", "filters", ")", ")", "\n", "x0", "=", "tf", ".", "layers", ".", "batch_normalization", "(", "x0", ",", "**", "bn_args", ")", "\n", "\n", "", "return", "x0", "+", "x", "\n", "\n", "", "with", "tf", ".", "variable_scope", "(", "'classify'", ",", "reuse", "=", "tf", ".", "AUTO_REUSE", ",", "custom_getter", "=", "getter", ")", ":", "\n", "            ", "y", "=", "tf", ".", "layers", ".", "conv2d", "(", "(", "x", "-", "self", ".", "dataset", ".", "mean", ")", "/", "self", ".", "dataset", ".", "std", ",", "16", ",", "3", ",", "**", "conv_args", "(", "3", ",", "16", ")", ")", "\n", "for", "scale", ",", "i", "in", "itertools", ".", "product", "(", "range", "(", "scales", ")", ",", "range", "(", "repeat", ")", ")", ":", "\n", "                ", "with", "tf", ".", "variable_scope", "(", "'layer%d.%d'", "%", "(", "scale", "+", "1", ",", "i", ")", ")", ":", "\n", "                    ", "if", "i", "==", "0", ":", "\n", "                        ", "y", "=", "residual", "(", "y", ",", "filters", "<<", "scale", ",", "stride", "=", "2", "if", "scale", "else", "1", ")", "\n", "", "else", ":", "\n", "                        ", "y", "=", "residual", "(", "y", ",", "filters", "<<", "scale", ")", "\n", "\n", "", "", "", "y", "=", "tf", ".", "reduce_mean", "(", "y", ",", "[", "1", ",", "2", "]", ")", "\n", "logits", "=", "tf", ".", "layers", ".", "dense", "(", "y", ",", "self", ".", "nclass", ",", "kernel_initializer", "=", "tf", ".", "glorot_normal_initializer", "(", ")", ")", "\n", "", "return", "logits", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.MultiModel.augment": [[126, 129], ["None"], "methods", ["None"], ["def", "augment", "(", "self", ",", "x", ",", "l", ",", "smoothing", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "return", "x", ",", "l", "-", "smoothing", "*", "(", "l", "-", "1.", "/", "self", ".", "nclass", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.MultiModel.classifier": [[130, 138], ["ValueError", "models.ConvNet.classifier", "models.ResNet.classifier", "models.ShakeNet.classifier"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.MultiModel.classifier", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.MultiModel.classifier", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.models.MultiModel.classifier"], ["", "def", "classifier", "(", "self", ",", "x", ",", "arch", ",", "**", "kwargs", ")", ":", "\n", "        ", "if", "arch", "==", "self", ".", "MODEL_CONVNET", ":", "\n", "            ", "return", "ConvNet", ".", "classifier", "(", "self", ",", "x", ",", "**", "kwargs", ")", "\n", "", "elif", "arch", "==", "self", ".", "MODEL_RESNET", ":", "\n", "            ", "return", "ResNet", ".", "classifier", "(", "self", ",", "x", ",", "**", "kwargs", ")", "\n", "", "elif", "arch", "==", "self", ".", "MODEL_SHAKE", ":", "\n", "            ", "return", "ShakeNet", ".", "classifier", "(", "self", ",", "x", ",", "**", "kwargs", ")", "\n", "", "raise", "ValueError", "(", "'Model %s does not exists, available ones are %s'", "%", "(", "arch", ",", "self", ".", "MODELS", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.__init__": [[52, 83], ["os.path.join", "easydict.EasyDict", "tensorflow.Graph", "easydict.EasyDict", "print", "print", "print", "print", "sorted", "print", "to_print.append", "print", "print", "print", "train.Model._create_initial_files", "train.Model.experiment_name", "train.Model.graph.as_default", "tensorflow.train.get_or_create_global_step", "train.Model.model", "tensorflow.assign_add", "train.Model.add_summaries", "kwargs.items", "print", "train.Model.graph.as_default", "max", "tuple", "print", "easydict.EasyDict", "tuple", "str", "range", "libml.utils.model_vars", "sum", "len", "int", "numpy.prod"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model._create_initial_files", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.experiment_name", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.model", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.add_summaries", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars"], ["    ", "def", "__init__", "(", "self", ",", "train_dir", ":", "str", ",", "dataset", ":", "data", ".", "DataSet", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "train_dir", "=", "os", ".", "path", ".", "join", "(", "train_dir", ",", "self", ".", "experiment_name", "(", "**", "kwargs", ")", ")", "\n", "self", ".", "params", "=", "EasyDict", "(", "kwargs", ")", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "graph", "=", "tf", ".", "Graph", "(", ")", "\n", "self", ".", "session", "=", "None", "\n", "self", ".", "tmp", "=", "EasyDict", "(", "print_queue", "=", "[", "]", ",", "cache", "=", "EasyDict", "(", ")", ")", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "step", "=", "tf", ".", "train", ".", "get_or_create_global_step", "(", ")", "\n", "self", ".", "ops", "=", "self", ".", "model", "(", "**", "kwargs", ")", "\n", "self", ".", "ops", ".", "update_step", "=", "tf", ".", "assign_add", "(", "self", ".", "step", ",", "FLAGS", ".", "batch", ")", "\n", "self", ".", "add_summaries", "(", "**", "kwargs", ")", "\n", "\n", "", "print", "(", "' Config '", ".", "center", "(", "80", ",", "'-'", ")", ")", "\n", "print", "(", "'train_dir'", ",", "self", ".", "train_dir", ")", "\n", "print", "(", "'%-32s %s'", "%", "(", "'Model'", ",", "self", ".", "__class__", ".", "__name__", ")", ")", "\n", "print", "(", "'%-32s %s'", "%", "(", "'Dataset'", ",", "dataset", ".", "name", ")", ")", "\n", "for", "k", ",", "v", "in", "sorted", "(", "kwargs", ".", "items", "(", ")", ")", ":", "\n", "            ", "print", "(", "'%-32s %s'", "%", "(", "k", ",", "v", ")", ")", "\n", "", "print", "(", "' Model '", ".", "center", "(", "80", ",", "'-'", ")", ")", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "to_print", "=", "[", "tuple", "(", "[", "'%s'", "%", "x", "for", "x", "in", "(", "v", ".", "name", ",", "np", ".", "prod", "(", "v", ".", "shape", ")", ",", "v", ".", "shape", ")", "]", ")", "for", "v", "in", "utils", ".", "model_vars", "(", "None", ")", "]", "\n", "", "to_print", ".", "append", "(", "(", "'Total'", ",", "str", "(", "sum", "(", "int", "(", "x", "[", "1", "]", ")", "for", "x", "in", "to_print", ")", ")", ",", "''", ")", ")", "\n", "sizes", "=", "[", "max", "(", "[", "len", "(", "x", "[", "i", "]", ")", "for", "x", "in", "to_print", "]", ")", "for", "i", "in", "range", "(", "3", ")", "]", "\n", "fmt", "=", "'%%-%ds  %%%ds  %%%ds'", "%", "tuple", "(", "sizes", ")", "\n", "for", "x", "in", "to_print", "[", ":", "-", "1", "]", ":", "\n", "            ", "print", "(", "fmt", "%", "x", ")", "\n", "", "print", "(", ")", "\n", "print", "(", "fmt", "%", "to_print", "[", "-", "1", "]", ")", "\n", "print", "(", "'-'", "*", "80", ")", "\n", "self", ".", "_create_initial_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.arg_dir": [[84, 87], ["os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "arg_dir", "(", "self", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "train_dir", ",", "'args'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.checkpoint_dir": [[88, 91], ["os.path.join"], "methods", ["None"], ["", "@", "property", "\n", "def", "checkpoint_dir", "(", "self", ")", ":", "\n", "        ", "return", "os", ".", "path", ".", "join", "(", "self", ".", "train_dir", ",", "'tf'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.train_print": [[92, 94], ["train.Model.tmp.print_queue.append"], "methods", ["None"], ["", "def", "train_print", "(", "self", ",", "text", ")", ":", "\n", "        ", "self", ".", "tmp", ".", "print_queue", ".", "append", "(", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model._create_initial_files": [[95, 100], ["train.Model.save_args", "os.path.exists", "os.makedirs"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.save_args"], ["", "def", "_create_initial_files", "(", "self", ")", ":", "\n", "        ", "for", "dir", "in", "(", "self", ".", "checkpoint_dir", ",", "self", ".", "arg_dir", ")", ":", "\n", "            ", "if", "not", "os", ".", "path", ".", "exists", "(", "dir", ")", ":", "\n", "                ", "os", ".", "makedirs", "(", "dir", ")", "\n", "", "", "self", ".", "save_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model._reset_files": [[101, 104], ["shutil.rmtree", "train.Model._create_initial_files"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model._create_initial_files"], ["", "def", "_reset_files", "(", "self", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "train_dir", ")", "\n", "self", ".", "_create_initial_files", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.save_args": [[105, 108], ["open", "json.dump", "os.path.join"], "methods", ["None"], ["", "def", "save_args", "(", "self", ",", "**", "extra_params", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "arg_dir", ",", "'args.json'", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "{", "**", "self", ".", "params", ",", "**", "extra_params", "}", ",", "f", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.load": [[109, 116], ["cls", "open", "json.load", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.load"], ["", "", "@", "classmethod", "\n", "def", "load", "(", "cls", ",", "train_dir", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "train_dir", ",", "'args/args.json'", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "params", "=", "json", ".", "load", "(", "f", ")", "\n", "", "instance", "=", "cls", "(", "train_dir", "=", "train_dir", ",", "**", "params", ")", "\n", "instance", ".", "train_dir", "=", "train_dir", "\n", "return", "instance", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.experiment_name": [[117, 120], ["str", "sorted", "kwargs.items"], "methods", ["None"], ["", "def", "experiment_name", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "args", "=", "[", "x", "+", "str", "(", "y", ")", "for", "x", ",", "y", "in", "sorted", "(", "kwargs", ".", "items", "(", ")", ")", "]", "\n", "return", "'_'", ".", "join", "(", "[", "self", ".", "__class__", ".", "__name__", "]", "+", "args", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.eval_mode": [[121, 133], ["print", "train.Model.graph.as_default", "tensorflow.Session", "tensorflow.train.Saver", "tensorflow.train.Saver.restore", "train.Model.session.run", "libml.utils.find_latest_checkpoint", "os.path.abspath", "libml.utils.get_config"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.find_latest_checkpoint", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_config"], ["", "def", "eval_mode", "(", "self", ",", "ckpt", "=", "None", ")", ":", "\n", "        ", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "self", ".", "session", "=", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", ")", "\n", "if", "ckpt", "is", "None", ":", "\n", "                ", "ckpt", "=", "utils", ".", "find_latest_checkpoint", "(", "self", ".", "checkpoint_dir", ")", "\n", "", "else", ":", "\n", "                ", "ckpt", "=", "os", ".", "path", ".", "abspath", "(", "ckpt", ")", "\n", "", "saver", ".", "restore", "(", "self", ".", "session", ",", "ckpt", ")", "\n", "self", ".", "tmp", ".", "step", "=", "self", ".", "session", ".", "run", "(", "self", ".", "step", ")", "\n", "", "print", "(", "'Eval model %s at global_step %d'", "%", "(", "self", ".", "__class__", ".", "__name__", ",", "self", ".", "tmp", ".", "step", ")", ")", "\n", "return", "self", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.model": [[134, 136], ["NotImplementedError"], "methods", ["None"], ["", "def", "model", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.add_summaries": [[137, 139], ["NotImplementedError"], "methods", ["None"], ["", "def", "add_summaries", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "raise", "NotImplementedError", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.__init__": [[144, 147], ["train.Model.__init__"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.__init__"], ["def", "__init__", "(", "self", ",", "train_dir", ":", "str", ",", "dataset", ":", "data", ".", "DataSet", ",", "nclass", ":", "int", ",", "**", "kwargs", ")", ":", "\n", "        ", "self", ".", "nclass", "=", "nclass", "\n", "Model", ".", "__init__", "(", "self", ",", "train_dir", ",", "dataset", ",", "nclass", "=", "nclass", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train_step": [[148, 154], ["train.ClassifySemi.session.run", "train_session.run"], "methods", ["None"], ["", "def", "train_step", "(", "self", ",", "train_session", ",", "data_labeled", ",", "data_unlabeled", ")", ":", "\n", "        ", "x", ",", "y", "=", "self", ".", "session", ".", "run", "(", "[", "data_labeled", ",", "data_unlabeled", "]", ")", "\n", "self", ".", "tmp", ".", "step", "=", "train_session", ".", "run", "(", "[", "self", ".", "ops", ".", "train_op", ",", "self", ".", "ops", ".", "update_step", "]", ",", "\n", "feed_dict", "=", "{", "self", ".", "ops", ".", "x", ":", "x", "[", "'image'", "]", ",", "\n", "self", ".", "ops", ".", "y", ":", "y", "[", "'image'", "]", ",", "\n", "self", ".", "ops", ".", "label", ":", "x", "[", "'label'", "]", "}", ")", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train": [[155, 209], ["train.ClassifySemi.eval_checkpoint", "train.ClassifySemi.graph.as_default", "train.ClassifySemi.dataset.train_labeled.batch().prefetch", "train_labeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next", "train.ClassifySemi.dataset.train_unlabeled.batch().prefetch", "train_unlabeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next", "tensorflow.train.Saver", "tensorflow.train.Scaffold", "print", "tensorflow.train.Saver", "tensorflow.train.MonitoredTrainingSession", "print", "train_session._tf_sess", "train.ClassifySemi.session.run", "train.ClassifySemi.dataset.train_labeled.batch", "train_labeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator", "train.ClassifySemi.dataset.train_unlabeled.batch", "train_unlabeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator", "tensorflow.logging.info", "tensorflow.train.Saver.restore", "print", "tqdm.trange", "print", "tensorflow.all_variables", "libml.utils.get_config", "print", "train.ClassifySemi.train_step", "train.ClassifySemi.tmp.print_queue.pop", "tqdm.trange.write", "str", "train.ClassifySemi.tmp.print_queue.pop", "str"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_checkpoint", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_config", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.train_step"], ["", "def", "train", "(", "self", ",", "train_nimg", ",", "report_nimg", ")", ":", "\n", "        ", "if", "FLAGS", ".", "eval_ckpt", ":", "\n", "            ", "self", ".", "eval_checkpoint", "(", "FLAGS", ".", "eval_ckpt", ")", "\n", "return", "\n", "", "batch", "=", "FLAGS", ".", "batch", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "train_labeled", "=", "self", ".", "dataset", ".", "train_labeled", ".", "batch", "(", "batch", ")", ".", "prefetch", "(", "16", ")", "\n", "train_labeled", "=", "train_labeled", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "train_unlabeled", "=", "self", ".", "dataset", ".", "train_unlabeled", ".", "batch", "(", "batch", ")", ".", "prefetch", "(", "16", ")", "\n", "train_unlabeled", "=", "train_unlabeled", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "saver", "=", "tf", ".", "train", ".", "Saver", "(", "max_to_keep", "=", "FLAGS", ".", "keep_ckpt", ",", "pad_step_number", "=", "10", ")", "\n", "if", "FLAGS", ".", "load_checkpoint", ":", "\n", "                ", "vars_to_load", "=", "[", "\n", "v", "for", "v", "in", "tf", ".", "all_variables", "(", ")", "if", "\"dense\"", "not", "in", "v", ".", "name", "and", "\"global_step\"", "not", "in", "v", ".", "name", "]", "\n", "print", "(", "[", "v", ".", "name", "for", "v", "in", "vars_to_load", "]", ")", "\n", "finetuning_saver", "=", "tf", ".", "train", ".", "Saver", "(", "var_list", "=", "vars_to_load", ",", "max_to_keep", "=", "FLAGS", ".", "keep_ckpt", ",", "pad_step_number", "=", "10", ")", "\n", "\n", "", "def", "init_fn", "(", "_", ",", "sess", ")", ":", "\n", "                ", "if", "FLAGS", ".", "load_checkpoint", ":", "\n", "                    ", "tf", ".", "logging", ".", "info", "(", "\n", "\"Fine tuning from checkpoint: %s\"", ",", "FLAGS", ".", "load_checkpoint", "\n", ")", "\n", "finetuning_saver", ".", "restore", "(", "sess", ",", "FLAGS", ".", "load_checkpoint", ")", "\n", "\n", "", "", "scaffold", "=", "tf", ".", "train", ".", "Scaffold", "(", "saver", "=", "saver", ",", "init_fn", "=", "init_fn", ")", "\n", "\n", "with", "tf", ".", "train", ".", "MonitoredTrainingSession", "(", "\n", "scaffold", "=", "scaffold", ",", "\n", "checkpoint_dir", "=", "self", ".", "checkpoint_dir", ",", "\n", "config", "=", "utils", ".", "get_config", "(", ")", ",", "\n", "save_checkpoint_steps", "=", "FLAGS", ".", "save_kimg", "<<", "10", ",", "\n", "save_summaries_steps", "=", "report_nimg", "-", "batch", ")", "as", "train_session", ":", "\n", "                ", "print", "(", "\"Training...\"", ")", "\n", "self", ".", "session", "=", "train_session", ".", "_tf_sess", "(", ")", "\n", "self", ".", "tmp", ".", "step", "=", "self", ".", "session", ".", "run", "(", "self", ".", "step", ")", "\n", "\n", "if", "FLAGS", ".", "epochs", "<", "1", "+", "(", "self", ".", "tmp", ".", "step", "//", "report_nimg", ")", ":", "\n", "                    ", "print", "(", "\"Training of \"", "+", "str", "(", "FLAGS", ".", "epochs", ")", "+", "\" epochs complete.\"", ")", "\n", "return", "\n", "\n", "", "while", "self", ".", "tmp", ".", "step", "<", "train_nimg", ":", "\n", "                    ", "if", "FLAGS", ".", "epochs", "<", "1", "+", "(", "self", ".", "tmp", ".", "step", "//", "report_nimg", ")", ":", "\n", "                        ", "print", "(", "\"Training of \"", "+", "str", "(", "FLAGS", ".", "epochs", ")", "+", "\" epochs complete.\"", ")", "\n", "return", "\n", "\n", "", "loop", "=", "trange", "(", "self", ".", "tmp", ".", "step", "%", "report_nimg", ",", "report_nimg", ",", "batch", ",", "\n", "leave", "=", "False", ",", "unit", "=", "'img'", ",", "unit_scale", "=", "batch", ",", "\n", "desc", "=", "'Epoch %d/%d'", "%", "(", "1", "+", "(", "self", ".", "tmp", ".", "step", "//", "report_nimg", ")", ",", "train_nimg", "//", "report_nimg", ")", ")", "\n", "for", "_", "in", "loop", ":", "\n", "                        ", "self", ".", "train_step", "(", "train_session", ",", "train_labeled", ",", "train_unlabeled", ")", "\n", "while", "self", ".", "tmp", ".", "print_queue", ":", "\n", "                            ", "loop", ".", "write", "(", "self", ".", "tmp", ".", "print_queue", ".", "pop", "(", "0", ")", ")", "\n", "", "", "", "while", "self", ".", "tmp", ".", "print_queue", ":", "\n", "                    ", "print", "(", "self", ".", "tmp", ".", "print_queue", ".", "pop", "(", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.tune": [[210, 223], ["train.ClassifySemi.graph.as_default", "train.ClassifySemi.dataset.train_labeled.batch().prefetch", "train_labeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next", "train.ClassifySemi.dataset.train_unlabeled.batch().prefetch", "train_unlabeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next", "tqdm.trange", "train.ClassifySemi.session.run", "train.ClassifySemi.session.run", "train.ClassifySemi.dataset.train_labeled.batch", "train_labeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator", "train.ClassifySemi.dataset.train_unlabeled.batch", "train_unlabeled.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next.make_one_shot_iterator"], "methods", ["None"], ["", "", "", "", "def", "tune", "(", "self", ",", "train_nimg", ")", ":", "\n", "        ", "batch", "=", "FLAGS", ".", "batch", "\n", "with", "self", ".", "graph", ".", "as_default", "(", ")", ":", "\n", "            ", "train_labeled", "=", "self", ".", "dataset", ".", "train_labeled", ".", "batch", "(", "batch", ")", ".", "prefetch", "(", "16", ")", "\n", "train_labeled", "=", "train_labeled", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "train_unlabeled", "=", "self", ".", "dataset", ".", "train_unlabeled", ".", "batch", "(", "batch", ")", ".", "prefetch", "(", "16", ")", "\n", "train_unlabeled", "=", "train_unlabeled", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "for", "_", "in", "trange", "(", "0", ",", "train_nimg", ",", "batch", ",", "leave", "=", "False", ",", "unit", "=", "'img'", ",", "unit_scale", "=", "batch", ",", "desc", "=", "'Tuning'", ")", ":", "\n", "                ", "x", ",", "y", "=", "self", ".", "session", ".", "run", "(", "[", "train_labeled", ",", "train_unlabeled", "]", ")", "\n", "self", ".", "session", ".", "run", "(", "[", "self", ".", "ops", ".", "tune_op", "]", ",", "feed_dict", "=", "{", "self", ".", "ops", ".", "x", ":", "x", "[", "'image'", "]", ",", "\n", "self", ".", "ops", ".", "y", ":", "y", "[", "'image'", "]", ",", "\n", "self", ".", "ops", ".", "label", ":", "x", "[", "'label'", "]", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_checkpoint": [[224, 236], ["train.ClassifySemi.eval_mode", "train.ClassifySemi.eval_stats", "train.ClassifySemi.eval_stats", "train.ClassifySemi.tune", "train.ClassifySemi.eval_stats", "train.ClassifySemi.eval_stats", "print", "print", "print", "print", "print", "tuple", "tuple", "tuple", "tuple"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.eval_mode", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_stats", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_stats", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.tune", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_stats", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_stats"], ["", "", "", "def", "eval_checkpoint", "(", "self", ",", "ckpt", "=", "None", ")", ":", "\n", "        ", "self", ".", "eval_mode", "(", "ckpt", ")", "\n", "raw", "=", "self", ".", "eval_stats", "(", "classify_op", "=", "self", ".", "ops", ".", "classify_raw", ")", "\n", "ema", "=", "self", ".", "eval_stats", "(", "classify_op", "=", "self", ".", "ops", ".", "classify_op", ")", "\n", "self", ".", "tune", "(", "16384", ")", "\n", "tuned_raw", "=", "self", ".", "eval_stats", "(", "classify_op", "=", "self", ".", "ops", ".", "classify_raw", ")", "\n", "tuned_ema", "=", "self", ".", "eval_stats", "(", "classify_op", "=", "self", ".", "ops", ".", "classify_op", ")", "\n", "print", "(", "'%16s %8s %8s %8s'", "%", "(", "''", ",", "'labeled'", ",", "'valid'", ",", "'test'", ")", ")", "\n", "print", "(", "'%16s %8s %8s %8s'", "%", "(", "(", "'raw'", ",", ")", "+", "tuple", "(", "'%.2f'", "%", "x", "for", "x", "in", "raw", ")", ")", ")", "\n", "print", "(", "'%16s %8s %8s %8s'", "%", "(", "(", "'ema'", ",", ")", "+", "tuple", "(", "'%.2f'", "%", "x", "for", "x", "in", "ema", ")", ")", ")", "\n", "print", "(", "'%16s %8s %8s %8s'", "%", "(", "(", "'tuned_raw'", ",", ")", "+", "tuple", "(", "'%.2f'", "%", "x", "for", "x", "in", "tuned_raw", ")", ")", ")", "\n", "print", "(", "'%16s %8s %8s %8s'", "%", "(", "(", "'tuned_ema'", ",", ")", "+", "tuple", "(", "'%.2f'", "%", "x", "for", "x", "in", "tuned_ema", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_stats": [[237, 282], ["train.ClassifySemi.train_print", "train.ClassifySemi.train_print", "numpy.array", "libml.data.batch().prefetch().make_one_shot_iterator().get_next", "numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "stats.append", "numpy.concatenate.append", "numpy.concatenate.append", "tensorflow.Graph().as_default", "tensorflow.Session", "train.ClassifySemi.eval_stats.collect_samples"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.train_print", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.train_print"], ["", "def", "eval_stats", "(", "self", ",", "batch", "=", "None", ",", "feed_extra", "=", "None", ",", "classify_op", "=", "None", ")", ":", "\n", "        ", "def", "collect_samples", "(", "data", ")", ":", "\n", "            ", "data_it", "=", "data", ".", "batch", "(", "1", ")", ".", "prefetch", "(", "16", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "images", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "while", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "sess_data", ".", "run", "(", "data_it", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "", "images", ".", "append", "(", "v", "[", "'image'", "]", ")", "\n", "labels", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "\n", "", "images", "=", "np", ".", "concatenate", "(", "images", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "axis", "=", "0", ")", "\n", "return", "images", ",", "labels", "\n", "\n", "", "if", "'test'", "not", "in", "self", ".", "tmp", ".", "cache", ":", "\n", "            ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "sess_data", ":", "\n", "                ", "self", ".", "tmp", ".", "cache", ".", "test", "=", "collect_samples", "(", "self", ".", "dataset", ".", "test", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "valid", "=", "collect_samples", "(", "self", ".", "dataset", ".", "valid", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "train_labeled", "=", "collect_samples", "(", "self", ".", "dataset", ".", "eval_labeled", ")", "\n", "\n", "", "", "batch", "=", "batch", "or", "FLAGS", ".", "batch", "\n", "classify_op", "=", "self", ".", "ops", ".", "classify_op", "if", "classify_op", "is", "None", "else", "classify_op", "\n", "eval_loss_op", "=", "self", ".", "ops", ".", "classify_op", "\n", "stats", "=", "[", "]", "\n", "ood_masks", "=", "[", "]", "\n", "\n", "for", "subset", "in", "(", "'train_labeled'", ",", "'valid'", ",", "'test'", ")", ":", "\n", "            ", "images", ",", "labels", "=", "self", ".", "tmp", ".", "cache", "[", "subset", "]", "\n", "\n", "predicted", "=", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "session", ".", "run", "(", "classify_op", ",", "feed_dict", "=", "{", "\n", "self", ".", "ops", ".", "x", ":", "images", "[", "x", ":", "x", "+", "batch", "]", ",", "**", "(", "feed_extra", "or", "{", "}", ")", "}", ")", "\n", "for", "x", "in", "range", "(", "0", ",", "images", ".", "shape", "[", "0", "]", ",", "batch", ")", "\n", "]", ",", "axis", "=", "0", ")", "\n", "\n", "stats", ".", "append", "(", "(", "predicted", ".", "argmax", "(", "1", ")", "==", "labels", ")", ".", "mean", "(", ")", "*", "100", ")", "\n", "if", "subset", "==", "'test'", ":", "\n", "                ", "ood_masks", "=", "[", "np", ".", "amax", "(", "predicted", ",", "axis", "=", "-", "1", ")", "[", "i", "]", "for", "i", "in", "range", "(", "10", ")", "]", "\n", "\n", "", "", "self", ".", "train_print", "(", "'kimg %-5d  accuracy train/valid/test  %.2f  %.2f  %.2f'", "%", "\n", "tuple", "(", "[", "self", ".", "tmp", ".", "step", ">>", "10", "]", "+", "stats", "[", ":", "3", "]", ")", ")", "\n", "self", ".", "train_print", "(", "'ood %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f %.4f'", "%", "tuple", "(", "ood_masks", ")", ")", "\n", "return", "np", ".", "array", "(", "stats", "+", "ood_masks", ",", "'f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_class_stats": [[283, 327], ["numpy.concatenate", "enumerate", "numpy.array", "libml.data.batch().prefetch().make_one_shot_iterator().get_next", "numpy.concatenate", "numpy.concatenate", "max", "numpy.asarray().mean", "numpy.concatenate.append", "numpy.concatenate.append", "tensorflow.Graph().as_default", "tensorflow.Session", "train.ClassifySemi.eval_stats.collect_samples"], "methods", ["None"], ["", "def", "eval_class_stats", "(", "self", ",", "batch", "=", "None", ",", "feed_extra", "=", "None", ",", "classify_op", "=", "None", ")", ":", "\n", "        ", "def", "collect_samples", "(", "data", ")", ":", "\n", "            ", "data_it", "=", "data", ".", "batch", "(", "1", ")", ".", "prefetch", "(", "16", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "images", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "while", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "sess_data", ".", "run", "(", "data_it", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "", "images", ".", "append", "(", "v", "[", "'image'", "]", ")", "\n", "labels", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "\n", "", "images", "=", "np", ".", "concatenate", "(", "images", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "axis", "=", "0", ")", "\n", "return", "images", ",", "labels", "\n", "", "if", "'test'", "not", "in", "self", ".", "tmp", ".", "cache", ":", "\n", "            ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "sess_data", ":", "\n", "                ", "self", ".", "tmp", ".", "cache", ".", "test", "=", "collect_samples", "(", "self", ".", "dataset", ".", "test", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "valid", "=", "collect_samples", "(", "self", ".", "dataset", ".", "valid", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "train_labeled", "=", "collect_samples", "(", "self", ".", "dataset", ".", "eval_labeled", ")", "\n", "\n", "", "", "batch", "=", "batch", "or", "FLAGS", ".", "batch", "\n", "classify_op", "=", "self", ".", "ops", ".", "classify_op", "if", "classify_op", "is", "None", "else", "classify_op", "\n", "class_accuracies", "=", "[", "[", "]", "for", "i", "in", "range", "(", "FLAGS", ".", "nclass", ")", "]", "\n", "mean_class_accuracies", "=", "[", "]", "\n", "subset", "=", "'test'", "\n", "images", ",", "labels", "=", "self", ".", "tmp", ".", "cache", "[", "subset", "]", "\n", "\n", "predicted", "=", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "session", ".", "run", "(", "classify_op", ",", "feed_dict", "=", "{", "\n", "self", ".", "ops", ".", "x", ":", "images", "[", "x", ":", "x", "+", "batch", "]", ",", "**", "(", "feed_extra", "or", "{", "}", ")", "}", ")", "\n", "for", "x", "in", "range", "(", "0", ",", "images", ".", "shape", "[", "0", "]", ",", "batch", ")", "\n", "]", ",", "axis", "=", "0", ")", "\n", "\n", "assert", "max", "(", "labels", ")", "<=", "FLAGS", ".", "nclass", ",", "\"Please provide the correct number of class in --nclass\"", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "labels", ")", ":", "\n", "            ", "if", "label", "==", "predicted", ".", "argmax", "(", "1", ")", "[", "i", "]", ":", "\n", "                ", "class_accuracies", "[", "label", "]", ".", "append", "(", "1", ")", "\n", "", "else", ":", "\n", "                ", "class_accuracies", "[", "label", "]", ".", "append", "(", "0", ")", "\n", "", "", "mean_class_accuracies", "=", "[", "np", ".", "asarray", "(", "accuracy", "*", "100", ")", ".", "mean", "(", ")", "for", "accuracy", "in", "class_accuracies", "]", "\n", "\n", "return", "np", ".", "array", "(", "mean_class_accuracies", ",", "'f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_f1_pr": [[328, 372], ["numpy.concatenate", "scores.append", "scores.append", "scores.append", "scores.append", "scores.append", "scores.append", "numpy.array", "libml.data.batch().prefetch().make_one_shot_iterator().get_next", "numpy.concatenate", "numpy.concatenate", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "sklearn.metrics.f1_score", "sklearn.metrics.precision_score", "sklearn.metrics.recall_score", "numpy.asarray", "numpy.concatenate.append", "numpy.concatenate.append", "tensorflow.Graph().as_default", "tensorflow.Session", "train.ClassifySemi.eval_stats.collect_samples"], "methods", ["None"], ["", "def", "eval_f1_pr", "(", "self", ",", "batch", "=", "None", ",", "feed_extra", "=", "None", ",", "classify_op", "=", "None", ")", ":", "\n", "        ", "def", "collect_samples", "(", "data", ")", ":", "\n", "            ", "data_it", "=", "data", ".", "batch", "(", "1", ")", ".", "prefetch", "(", "16", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "images", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "while", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "sess_data", ".", "run", "(", "data_it", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "", "images", ".", "append", "(", "v", "[", "'image'", "]", ")", "\n", "labels", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "\n", "", "images", "=", "np", ".", "concatenate", "(", "images", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "axis", "=", "0", ")", "\n", "return", "images", ",", "labels", "\n", "", "if", "'test'", "not", "in", "self", ".", "tmp", ".", "cache", ":", "\n", "            ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "sess_data", ":", "\n", "                ", "self", ".", "tmp", ".", "cache", ".", "test", "=", "collect_samples", "(", "self", ".", "dataset", ".", "test", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "valid", "=", "collect_samples", "(", "self", ".", "dataset", ".", "valid", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "train_labeled", "=", "collect_samples", "(", "self", ".", "dataset", ".", "eval_labeled", ")", "\n", "\n", "", "", "batch", "=", "batch", "or", "FLAGS", ".", "batch", "\n", "classify_op", "=", "self", ".", "ops", ".", "classify_op", "if", "classify_op", "is", "None", "else", "classify_op", "\n", "accuracies", "=", "[", "]", "\n", "class_accuracies", "=", "[", "[", "]", "for", "i", "in", "range", "(", "FLAGS", ".", "nclass", ")", "]", "\n", "mean_class_accuracies", "=", "[", "]", "\n", "subset", "=", "'test'", "\n", "images", ",", "labels", "=", "self", ".", "tmp", ".", "cache", "[", "subset", "]", "\n", "scores", "=", "[", "]", "\n", "\n", "predicted", "=", "np", ".", "concatenate", "(", "[", "\n", "self", ".", "session", ".", "run", "(", "classify_op", ",", "feed_dict", "=", "{", "\n", "self", ".", "ops", ".", "x", ":", "images", "[", "x", ":", "x", "+", "batch", "]", ",", "**", "(", "feed_extra", "or", "{", "}", ")", "}", ")", "\n", "for", "x", "in", "range", "(", "0", ",", "images", ".", "shape", "[", "0", "]", ",", "batch", ")", "\n", "]", ",", "axis", "=", "0", ")", "\n", "\n", "scores", ".", "append", "(", "f1_score", "(", "labels", ",", "predicted", ".", "argmax", "(", "1", ")", ",", "average", "=", "'macro'", ")", ")", "\n", "scores", ".", "append", "(", "precision_score", "(", "labels", ",", "predicted", ".", "argmax", "(", "1", ")", ",", "average", "=", "'macro'", ")", ")", "\n", "scores", ".", "append", "(", "recall_score", "(", "labels", ",", "predicted", ".", "argmax", "(", "1", ")", ",", "average", "=", "'macro'", ")", ")", "\n", "scores", ".", "append", "(", "f1_score", "(", "labels", ",", "predicted", ".", "argmax", "(", "1", ")", ",", "average", "=", "'weighted'", ")", ")", "\n", "scores", ".", "append", "(", "precision_score", "(", "labels", ",", "predicted", ".", "argmax", "(", "1", ")", ",", "average", "=", "'weighted'", ")", ")", "\n", "scores", ".", "append", "(", "recall_score", "(", "labels", ",", "predicted", ".", "argmax", "(", "1", ")", ",", "average", "=", "'weighted'", ")", ")", "\n", "\n", "return", "np", ".", "array", "(", "np", ".", "asarray", "(", "scores", ")", ",", "'f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_val_loss": [[373, 404], ["numpy.array", "libml.data.batch().prefetch().make_one_shot_iterator().get_next", "numpy.concatenate", "numpy.concatenate", "train.ClassifySemi.session.run", "numpy.concatenate.append", "numpy.concatenate.append", "tensorflow.Graph().as_default", "tensorflow.Session", "train.ClassifySemi.eval_stats.collect_samples"], "methods", ["None"], ["", "def", "eval_val_loss", "(", "self", ",", "batch", "=", "None", ",", "feed_extra", "=", "None", ",", "classify_op", "=", "None", ")", ":", "\n", "        ", "def", "collect_samples", "(", "data", ")", ":", "\n", "            ", "data_it", "=", "data", ".", "batch", "(", "1", ")", ".", "prefetch", "(", "16", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "images", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "while", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "sess_data", ".", "run", "(", "data_it", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "", "images", ".", "append", "(", "v", "[", "'image'", "]", ")", "\n", "labels", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "\n", "", "images", "=", "np", ".", "concatenate", "(", "images", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "axis", "=", "0", ")", "\n", "return", "images", ",", "labels", "\n", "", "if", "'test'", "not", "in", "self", ".", "tmp", ".", "cache", ":", "\n", "            ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "sess_data", ":", "\n", "                ", "self", ".", "tmp", ".", "cache", ".", "test", "=", "collect_samples", "(", "self", ".", "dataset", ".", "test", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "valid", "=", "collect_samples", "(", "self", ".", "dataset", ".", "valid", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "train_labeled", "=", "collect_samples", "(", "self", ".", "dataset", ".", "eval_labeled", ")", "\n", "\n", "", "", "batch", "=", "batch", "or", "FLAGS", ".", "batch", "\n", "classify_op", "=", "self", ".", "ops", ".", "classify_op", "if", "classify_op", "is", "None", "else", "classify_op", "\n", "eval_loss_op", "=", "self", ".", "ops", ".", "eval_loss_op", "\n", "subset", "=", "'valid'", "\n", "images", ",", "labels", "=", "self", ".", "tmp", ".", "cache", "[", "subset", "]", "\n", "\n", "val_loss", "=", "[", "self", ".", "session", ".", "run", "(", "eval_loss_op", ",", "feed_dict", "=", "{", "\n", "self", ".", "ops", ".", "x", ":", "images", ",", "self", ".", "ops", ".", "label", ":", "labels", "}", ")", "]", "\n", "\n", "return", "np", ".", "array", "(", "val_loss", ",", "'f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_ood": [[406, 443], ["numpy.amax", "train.ClassifySemi.train_print", "train.ClassifySemi.train_print", "numpy.array", "libml.data.batch().prefetch().make_one_shot_iterator().get_next", "numpy.concatenate", "numpy.concatenate", "train.ClassifySemi.session.run", "numpy.concatenate.append", "numpy.concatenate.append", "tensorflow.Graph().as_default", "tensorflow.Session", "train.ClassifySemi.eval_stats.collect_samples"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.train_print", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.train_print"], ["", "def", "eval_ood", "(", "self", ",", "batch", "=", "None", ",", "feed_extra", "=", "None", ",", "classify_op", "=", "None", ")", ":", "\n", "        ", "def", "collect_samples", "(", "data", ")", ":", "\n", "            ", "data_it", "=", "data", ".", "batch", "(", "1", ")", ".", "prefetch", "(", "16", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "images", ",", "labels", "=", "[", "]", ",", "[", "]", "\n", "while", "1", ":", "\n", "                ", "try", ":", "\n", "                    ", "v", "=", "sess_data", ".", "run", "(", "data_it", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "", "images", ".", "append", "(", "v", "[", "'image'", "]", ")", "\n", "labels", ".", "append", "(", "v", "[", "'label'", "]", ")", "\n", "\n", "", "images", "=", "np", ".", "concatenate", "(", "images", ",", "axis", "=", "0", ")", "\n", "labels", "=", "np", ".", "concatenate", "(", "labels", ",", "axis", "=", "0", ")", "\n", "return", "images", ",", "labels", "\n", "", "if", "'valid'", "not", "in", "self", ".", "tmp", ".", "cache", ":", "\n", "            ", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "sess_data", ":", "\n", "                ", "self", ".", "tmp", ".", "cache", ".", "test", "=", "collect_samples", "(", "self", ".", "dataset", ".", "test", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "valid", "=", "collect_samples", "(", "self", ".", "dataset", ".", "valid", ")", "\n", "self", ".", "tmp", ".", "cache", ".", "train_labeled", "=", "collect_samples", "(", "self", ".", "dataset", ".", "eval_labeled", ")", "\n", "\n", "", "", "batch", "=", "batch", "or", "FLAGS", ".", "batch", "\n", "classify_op", "=", "self", ".", "ops", ".", "classify_op", "if", "classify_op", "is", "None", "else", "classify_op", "\n", "eval_loss_op", "=", "self", ".", "ops", ".", "eval_loss_op", "\n", "subset", "=", "'valid'", "\n", "images", ",", "labels", "=", "self", ".", "tmp", ".", "cache", "[", "subset", "]", "\n", "\n", "logits", "=", "[", "\n", "self", ".", "session", ".", "run", "(", "classify_op", ",", "feed_dict", "=", "{", "\n", "self", ".", "ops", ".", "x", ":", "images", ",", "**", "(", "feed_extra", "or", "{", "}", ")", "}", ")", "]", "\n", "\n", "max_probs", "=", "np", ".", "amax", "(", "logits", ",", "axis", "=", "-", "1", ")", "\n", "\n", "self", ".", "train_print", "(", "max_probs", ")", "\n", "self", ".", "train_print", "(", "labels", ")", "\n", "\n", "return", "np", ".", "array", "(", "[", "]", ",", "'f'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.add_summaries": [[444, 501], ["tensorflow.py_func", "tensorflow.py_func", "tensorflow.py_func", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "range", "tensorflow.summary.scalar", "tensorflow.py_func", "tensorflow.py_func", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "tensorflow.summary.scalar", "train.ClassifySemi.eval_stats", "train.ClassifySemi.eval_class_stats", "train.ClassifySemi.eval_f1_pr", "train.ClassifySemi.eval_val_loss", "train.ClassifySemi.eval_ood", "tensorflow.summary.scalar", "os.path.isfile", "json.loads", "train.ClassifySemi.add_summaries.get_class_mapping"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_stats", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_class_stats", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_f1_pr", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_val_loss", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.ClassifySemi.eval_ood"], ["", "def", "add_summaries", "(", "self", ",", "feed_extra", "=", "None", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "\n", "def", "gen_stats", "(", ")", ":", "\n", "            ", "return", "self", ".", "eval_stats", "(", "feed_extra", "=", "feed_extra", ")", "\n", "\n", "", "def", "gen_class_stats", "(", ")", ":", "\n", "            ", "return", "self", ".", "eval_class_stats", "(", "feed_extra", "=", "feed_extra", ")", "\n", "\n", "", "def", "gen_f1_pr", "(", ")", ":", "\n", "            ", "return", "self", ".", "eval_f1_pr", "(", "feed_extra", "=", "feed_extra", ")", "\n", "\n", "", "def", "gen_val_loss", "(", ")", ":", "\n", "             ", "return", "self", ".", "eval_val_loss", "(", "feed_extra", "=", "feed_extra", ")", "\n", "\n", "", "def", "gen_ood", "(", ")", ":", "\n", "            ", "return", "self", ".", "eval_ood", "(", "feed_extra", "=", "feed_extra", ")", "\n", "\n", "", "stats", "=", "tf", ".", "py_func", "(", "gen_stats", ",", "[", "]", ",", "tf", ".", "float32", ")", "\n", "val_loss", "=", "tf", ".", "py_func", "(", "gen_val_loss", ",", "[", "]", ",", "tf", ".", "float32", ")", "\n", "ood", "=", "tf", ".", "py_func", "(", "gen_ood", ",", "[", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "'accuracy_train_labeled/'", ",", "stats", "[", "0", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'accuracy_valid'", ",", "stats", "[", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'accuracy_test'", ",", "stats", "[", "2", "]", ")", "\n", "for", "i", "in", "range", "(", "10", ")", ":", "\n", "            ", "tf", ".", "summary", ".", "scalar", "(", "'ood_examples/'", "+", "str", "(", "i", "+", "1", ")", ",", "stats", "[", "3", "+", "i", "]", ")", "\n", "", "tf", ".", "summary", ".", "scalar", "(", "'losses/val_loss'", ",", "val_loss", "[", "0", "]", ")", "\n", "\n", "mean_class_accuracies", "=", "tf", ".", "py_func", "(", "gen_class_stats", ",", "[", "]", ",", "tf", ".", "float32", ")", "\n", "f1_pr_scores", "=", "tf", ".", "py_func", "(", "gen_f1_pr", ",", "[", "]", ",", "tf", ".", "float32", ")", "\n", "\n", "tf", ".", "summary", ".", "scalar", "(", "'f1_score/macro'", ",", "f1_pr_scores", "[", "0", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'precision/macro'", ",", "f1_pr_scores", "[", "1", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'recall/macro'", ",", "f1_pr_scores", "[", "2", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'f1_score/weighted'", ",", "f1_pr_scores", "[", "3", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'precision/weighted'", ",", "f1_pr_scores", "[", "4", "]", ")", "\n", "tf", ".", "summary", ".", "scalar", "(", "'recall/weighted'", ",", "f1_pr_scores", "[", "5", "]", ")", "\n", "\n", "def", "get_class_mapping", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "            ", "if", "FLAGS", ".", "class_mapping", ":", "\n", "                ", "json_filename", "=", "FLAGS", ".", "class_mapping", "\n", "", "elif", "'.'", "in", "FLAGS", ".", "dataset", ":", "\n", "                ", "json_filename", "=", "FLAGS", ".", "dataset", ".", "split", "(", "\".\"", ")", "[", "0", "]", "+", "\"_class_mappings.json\"", "\n", "", "else", ":", "\n", "                ", "json_filename", "=", "FLAGS", ".", "dataset", ".", "split", "(", "\"-\"", ")", "[", "0", "]", "+", "\"_class_mappings.json\"", "\n", "\n", "", "assert", "os", ".", "path", ".", "isfile", "(", "json_filename", ")", ",", "json_filename", "+", "\" not found. Please provide another class mapping.\"", "\n", "\n", "return", "json", ".", "loads", "(", "open", "(", "json_filename", ")", ".", "read", "(", ")", ")", "\n", "\n", "", "if", "FLAGS", ".", "class_mapping", "and", "FLAGS", ".", "class_mapping", "!=", "''", ":", "\n", "            ", "json_data", "=", "get_class_mapping", "(", "self", ")", "\n", "\n", "for", "index", "in", "range", "(", "FLAGS", ".", "nclass", ")", ":", "\n", "                ", "tf", ".", "summary", ".", "scalar", "(", "'accuracy_test/'", "+", "json_data", "[", "str", "(", "index", ")", "]", ",", "mean_class_accuracies", "[", "index", "]", ")", "\n", "", "", "", "", ""]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.__init__": [[138, 155], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "train_labeled", ",", "train_unlabeled", ",", "test", ",", "valid", ",", "eval_labeled", ",", "eval_unlabeled", ",", "\n", "height", "=", "32", ",", "width", "=", "32", ",", "colors", "=", "3", ",", "nclass", "=", "10", ",", "mean", "=", "0", ",", "std", "=", "1", ",", "p_labeled", "=", "None", ",", "p_unlabeled", "=", "None", ")", ":", "\n", "        ", "self", ".", "name", "=", "name", "\n", "self", ".", "train_labeled", "=", "train_labeled", "\n", "self", ".", "train_unlabeled", "=", "train_unlabeled", "\n", "self", ".", "eval_labeled", "=", "eval_labeled", "\n", "self", ".", "eval_unlabeled", "=", "eval_unlabeled", "\n", "self", ".", "test", "=", "test", "\n", "self", ".", "valid", "=", "valid", "\n", "self", ".", "height", "=", "height", "\n", "self", ".", "width", "=", "width", "\n", "self", ".", "colors", "=", "colors", "\n", "self", ".", "nclass", "=", "nclass", "\n", "self", ".", "mean", "=", "mean", "\n", "self", ".", "std", "=", "std", "\n", "self", ".", "p_labeled", "=", "p_labeled", "\n", "self", ".", "p_unlabeled", "=", "p_unlabeled", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.DataSet.creator": [[156, 194], ["os.path.join", "isinstance", "parse_fn", "parse_fn", "parse_fn", "cls", "x.repeat().shuffle", "max", "FLAGS.p_unlabeled.split", "numpy.array", "numpy.max", "data.dataset", "dataset().skip", "data.dataset", "data.compute_mean_std", "str", "len", "list", "parse_fn.concatenate", "str", "fn().map", "fn().map", "parse_fn", "parse_fn", "parse_fn", "x.repeat", "libml.utils.get_available_gpus", "map", "data.dataset", "os.path.join", "data.dataset", "dataset().skip", "dataset().take", "fn", "fn", "data.dataset", "data.dataset"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.compute_mean_std", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.dataset", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.dataset"], ["", "@", "classmethod", "\n", "def", "creator", "(", "cls", ",", "name", ",", "seed", ",", "label", ",", "valid", ",", "augment", ",", "parse_fn", "=", "default_parse", ",", "do_memoize", "=", "True", ",", "colors", "=", "3", ",", "\n", "nclass", "=", "10", ",", "height", "=", "32", ",", "width", "=", "32", ",", "name_suffix", "=", "''", ")", ":", "\n", "        ", "if", "not", "isinstance", "(", "augment", ",", "list", ")", ":", "\n", "            ", "augment", "=", "[", "augment", "]", "*", "2", "\n", "", "fullname", "=", "'.%d@%d'", "%", "(", "seed", ",", "label", ")", "\n", "root", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'SSL'", ",", "name", "+", "fullname", ")", "\n", "fn", "=", "memoize", "if", "do_memoize", "else", "lambda", "x", ":", "x", ".", "repeat", "(", ")", ".", "shuffle", "(", "FLAGS", ".", "shuffle", ")", "\n", "\n", "def", "create", "(", ")", ":", "\n", "            ", "p_labeled", "=", "p_unlabeled", "=", "None", "\n", "para", "=", "max", "(", "1", ",", "len", "(", "utils", ".", "get_available_gpus", "(", ")", ")", ")", "*", "FLAGS", ".", "para_augment", "\n", "\n", "if", "FLAGS", ".", "p_unlabeled", ":", "\n", "                ", "sequence", "=", "FLAGS", ".", "p_unlabeled", ".", "split", "(", "','", ")", "\n", "p_unlabeled", "=", "np", ".", "array", "(", "list", "(", "map", "(", "float", ",", "sequence", ")", ")", ",", "dtype", "=", "np", ".", "float32", ")", "\n", "p_unlabeled", "/=", "np", ".", "max", "(", "p_unlabeled", ")", "\n", "\n", "", "train_labeled", "=", "parse_fn", "(", "dataset", "(", "[", "root", "+", "'-label.tfrecord'", "]", ")", ")", "\n", "train_unlabeled", "=", "parse_fn", "(", "dataset", "(", "[", "root", "+", "'-unlabel.tfrecord'", "]", ")", ".", "skip", "(", "valid", ")", ")", "\n", "test_dataset", "=", "parse_fn", "(", "dataset", "(", "[", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'%s-test.tfrecord'", "%", "name", ")", "]", ")", ")", "\n", "\n", "if", "FLAGS", ".", "whiten", ":", "\n", "                ", "mean", ",", "std", "=", "compute_mean_std", "(", "train_labeled", ".", "concatenate", "(", "train_unlabeled", ")", ")", "\n", "", "else", ":", "\n", "                ", "mean", ",", "std", "=", "0", ",", "1", "\n", "\n", "", "return", "cls", "(", "name", "+", "name_suffix", "+", "fullname", "+", "'-'", "+", "str", "(", "valid", ")", ",", "\n", "train_labeled", "=", "fn", "(", "train_labeled", ")", ".", "map", "(", "augment", "[", "0", "]", ",", "para", ")", ",", "\n", "train_unlabeled", "=", "fn", "(", "train_unlabeled", ")", ".", "map", "(", "augment", "[", "1", "]", ",", "para", ")", ",", "\n", "eval_labeled", "=", "parse_fn", "(", "dataset", "(", "[", "root", "+", "'-label.tfrecord'", "]", ")", ")", ",", "\n", "eval_unlabeled", "=", "parse_fn", "(", "dataset", "(", "[", "root", "+", "'-unlabel.tfrecord'", "]", ")", ".", "skip", "(", "valid", ")", ")", ",", "\n", "valid", "=", "parse_fn", "(", "dataset", "(", "[", "root", "+", "'-unlabel.tfrecord'", "]", ")", ".", "take", "(", "valid", ")", ")", ",", "\n", "test", "=", "test_dataset", ",", "\n", "nclass", "=", "nclass", ",", "colors", "=", "colors", ",", "p_labeled", "=", "p_labeled", ",", "p_unlabeled", "=", "p_unlabeled", ",", "\n", "height", "=", "height", ",", "width", "=", "width", ",", "mean", "=", "mean", ",", "std", "=", "std", ")", "\n", "\n", "", "return", "name", "+", "name_suffix", "+", "fullname", "+", "'-'", "+", "str", "(", "valid", ")", ",", "create", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.record_parse": [[43, 52], ["tensorflow.parse_single_example", "tensorflow.image.decode_image", "dict", "tensorflow.cast", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature"], "function", ["None"], ["def", "record_parse", "(", "serialized_example", ")", ":", "\n", "    ", "features", "=", "tf", ".", "parse_single_example", "(", "\n", "serialized_example", ",", "\n", "features", "=", "{", "'image'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", "}", ")", "\n", "image", "=", "tf", ".", "image", ".", "decode_image", "(", "features", "[", "'image'", "]", ")", "\n", "image", "=", "tf", ".", "cast", "(", "image", ",", "tf", ".", "float32", ")", "*", "(", "2.0", "/", "255", ")", "-", "1.0", "\n", "label", "=", "features", "[", "'label'", "]", "\n", "return", "dict", "(", "image", "=", "image", ",", "label", "=", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.default_parse": [[54, 57], ["dataset.map", "max", "len", "libml.utils.get_available_gpus"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus"], ["", "def", "default_parse", "(", "dataset", ":", "tf", ".", "data", ".", "Dataset", ",", "parse_fn", "=", "record_parse", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "para", "=", "4", "*", "max", "(", "1", ",", "len", "(", "utils", ".", "get_available_gpus", "(", ")", ")", ")", "*", "FLAGS", ".", "para_parse", "\n", "return", "dataset", ".", "map", "(", "parse_fn", ",", "num_parallel_calls", "=", "para", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.dataset": [[59, 64], ["sorted", "tensorflow.data.TFRecordDataset", "sum", "ValueError", "glob.glob"], "function", ["None"], ["", "def", "dataset", "(", "filenames", ":", "list", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "filenames", "=", "sorted", "(", "sum", "(", "[", "glob", ".", "glob", "(", "x", ")", "for", "x", "in", "filenames", "]", ",", "[", "]", ")", ")", "\n", "if", "not", "filenames", ":", "\n", "        ", "raise", "ValueError", "(", "'Empty dataset, did you mount gcsfuse bucket?'", ")", "\n", "", "return", "tf", ".", "data", ".", "TFRecordDataset", "(", "filenames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.memoize": [[66, 89], ["numpy.stack", "numpy.stack", "tensorflow.data.Dataset.range().repeat", "dataset.prefetch.shuffle", "dataset.prefetch.map", "tensorflow.Graph().as_default", "tensorflow.Session", "dataset.prefetch.prefetch", "dataset.prefetch.make_one_shot_iterator().get_next", "tensorflow.py_func", "dict", "tensorflow.data.Dataset.range", "len", "tensorflow.Graph", "libml.utils.get_config", "dataset.prefetch.make_one_shot_iterator", "data.append", "len", "len", "session.run"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_config"], ["", "def", "memoize", "(", "dataset", ":", "tf", ".", "data", ".", "Dataset", ")", "->", "tf", ".", "data", ".", "Dataset", ":", "\n", "    ", "data", "=", "[", "]", "\n", "with", "tf", ".", "Graph", "(", ")", ".", "as_default", "(", ")", ",", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "session", ":", "\n", "        ", "dataset", "=", "dataset", ".", "prefetch", "(", "16", ")", "\n", "it", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "try", ":", "\n", "            ", "while", "1", ":", "\n", "                ", "data", ".", "append", "(", "session", ".", "run", "(", "it", ")", ")", "\n", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "            ", "pass", "\n", "", "", "images", "=", "np", ".", "stack", "(", "[", "x", "[", "'image'", "]", "for", "x", "in", "data", "]", ")", "\n", "labels", "=", "np", ".", "stack", "(", "[", "x", "[", "'label'", "]", "for", "x", "in", "data", "]", ")", "\n", "\n", "def", "tf_get", "(", "index", ")", ":", "\n", "        ", "def", "get", "(", "index", ")", ":", "\n", "            ", "return", "images", "[", "index", "]", ",", "labels", "[", "index", "]", "\n", "\n", "", "image", ",", "label", "=", "tf", ".", "py_func", "(", "get", ",", "[", "index", "]", ",", "[", "tf", ".", "float32", ",", "tf", ".", "int64", "]", ")", "\n", "return", "dict", "(", "image", "=", "image", ",", "label", "=", "label", ")", "\n", "\n", "", "dataset", "=", "tf", ".", "data", ".", "Dataset", ".", "range", "(", "len", "(", "data", ")", ")", ".", "repeat", "(", ")", "\n", "dataset", "=", "dataset", ".", "shuffle", "(", "len", "(", "data", ")", "if", "len", "(", "data", ")", "<", "FLAGS", ".", "shuffle", "else", "FLAGS", ".", "shuffle", ")", "\n", "return", "dataset", ".", "map", "(", "tf_get", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_cutout_func": [[91, 94], ["third_party.random_eraser_tf.get_random_eraser", "third_party.random_eraser_tf.get_random_eraser."], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.random_eraser_tf.get_random_eraser"], ["", "def", "augment_cutout_func", "(", "x", ",", "prob", "=", "0.3", ")", ":", "\n", "    ", "eraser", "=", "get_random_eraser", "(", "p", "=", "prob", ")", "\n", "return", "eraser", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_mirror": [[95, 97], ["tensorflow.image.random_flip_left_right"], "function", ["None"], ["", "def", "augment_mirror", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "image", ".", "random_flip_left_right", "(", "x", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_color_func": [[98, 103], ["tensorflow.image.random_brightness", "tensorflow.image.random_hue", "tensorflow.image.random_saturation", "tensorflow.image.random_contrast"], "function", ["None"], ["", "def", "augment_color_func", "(", "x", ")", ":", "\n", "    ", "x", "=", "tf", ".", "image", ".", "random_brightness", "(", "x", ",", "max_delta", "=", "0.1", ")", "\n", "x", "=", "tf", ".", "image", ".", "random_hue", "(", "image", "=", "x", ",", "max_delta", "=", "0.5", ")", "\n", "x", "=", "tf", ".", "image", ".", "random_saturation", "(", "image", "=", "x", ",", "lower", "=", "0.1", ",", "upper", "=", "3", ")", "\n", "return", "tf", ".", "image", ".", "random_contrast", "(", "x", ",", "lower", "=", "0.5", ",", "upper", "=", "1.5", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_shift": [[104, 107], ["tensorflow.pad", "tensorflow.random_crop", "tensorflow.shape"], "function", ["None"], ["", "def", "augment_shift", "(", "x", ",", "w", ")", ":", "\n", "    ", "y", "=", "tf", ".", "pad", "(", "x", ",", "[", "[", "w", "]", "*", "2", ",", "[", "w", "]", "*", "2", ",", "[", "0", "]", "*", "2", "]", ",", "mode", "=", "'REFLECT'", ")", "\n", "return", "tf", ".", "random_crop", "(", "y", ",", "tf", ".", "shape", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_noise": [[109, 111], ["tensorflow.random_normal", "tensorflow.shape"], "function", ["None"], ["", "def", "augment_noise", "(", "x", ",", "std", ")", ":", "\n", "    ", "return", "x", "+", "std", "*", "tf", ".", "random_normal", "(", "tf", ".", "shape", "(", "x", ")", ",", "dtype", "=", "x", ".", "dtype", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.compute_mean_std": [[113, 135], ["data.make_one_shot_iterator().get_next.map().batch().prefetch", "data.make_one_shot_iterator().get_next.make_one_shot_iterator().get_next", "numpy.sqrt", "print", "tensorflow.Session", "tqdm.tqdm", "sum", "data.make_one_shot_iterator().get_next.map().batch", "data.make_one_shot_iterator().get_next.make_one_shot_iterator", "data.compute_mean_std.iterator"], "function", ["None"], ["", "def", "compute_mean_std", "(", "data", ":", "tf", ".", "data", ".", "Dataset", ")", ":", "\n", "    ", "data", "=", "data", ".", "map", "(", "lambda", "x", ":", "x", "[", "'image'", "]", ")", ".", "batch", "(", "1024", ")", ".", "prefetch", "(", "1", ")", "\n", "data", "=", "data", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "count", "=", "0", "\n", "stats", "=", "[", "]", "\n", "with", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "sess", ":", "\n", "        ", "def", "iterator", "(", ")", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "yield", "sess", ".", "run", "(", "data", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "                    ", "break", "\n", "\n", "", "", "", "for", "batch", "in", "tqdm", "(", "iterator", "(", ")", ",", "unit", "=", "'kimg'", ",", "desc", "=", "'Computing dataset mean and std'", ")", ":", "\n", "            ", "ratio", "=", "batch", ".", "shape", "[", "0", "]", "/", "1024.", "\n", "count", "+=", "ratio", "\n", "stats", ".", "append", "(", "(", "batch", ".", "mean", "(", "(", "0", ",", "1", ",", "2", ")", ")", "*", "ratio", ",", "(", "batch", "**", "2", ")", ".", "mean", "(", "(", "0", ",", "1", ",", "2", ")", ")", "*", "ratio", ")", ")", "\n", "", "", "mean", "=", "sum", "(", "x", "[", "0", "]", "for", "x", "in", "stats", ")", "/", "count", "\n", "sigma", "=", "sum", "(", "x", "[", "1", "]", "for", "x", "in", "stats", ")", "/", "count", "-", "mean", "**", "2", "\n", "std", "=", "np", ".", "sqrt", "(", "sigma", ")", "\n", "print", "(", "'Mean %s  Std: %s'", "%", "(", "mean", ",", "std", ")", ")", "\n", "return", "mean", ",", "std", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PMovingAverage.__init__": [[123, 125], ["tensorflow.Variable", "tensorflow.ones"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "name", ",", "nclass", ",", "buf_size", ")", ":", "\n", "        ", "self", ".", "ma", "=", "tf", ".", "Variable", "(", "tf", ".", "ones", "(", "[", "buf_size", ",", "nclass", "]", ")", "/", "nclass", ",", "trainable", "=", "False", ",", "name", "=", "name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PMovingAverage.__call__": [[126, 129], ["tensorflow.reduce_mean", "tensorflow.reduce_sum"], "methods", ["None"], ["", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "v", "=", "tf", ".", "reduce_mean", "(", "self", ".", "ma", ",", "axis", "=", "0", ")", "\n", "return", "v", "/", "tf", ".", "reduce_sum", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PMovingAverage.update": [[130, 133], ["tensorflow.reduce_mean", "tensorflow.assign", "tensorflow.concat"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "entry", ")", ":", "\n", "        ", "entry", "=", "tf", ".", "reduce_mean", "(", "entry", ",", "axis", "=", "0", ")", "\n", "return", "tf", ".", "assign", "(", "self", ".", "ma", ",", "tf", ".", "concat", "(", "[", "self", ".", "ma", "[", "1", ":", "]", ",", "[", "entry", "]", "]", ",", "axis", "=", "0", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.__init__": [[136, 145], ["tensorflow.constant", "tensorflow.constant", "tensorflow.Variable", "layers.renorm", "tensorflow.ones"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.renorm"], ["    ", "def", "__init__", "(", "self", ",", "dataset", ":", "DataSet", ")", ":", "\n", "        ", "self", ".", "has_update", "=", "False", "\n", "if", "dataset", ".", "p_unlabeled", "is", "not", "None", ":", "\n", "            ", "self", ".", "p_data", "=", "tf", ".", "constant", "(", "dataset", ".", "p_unlabeled", ",", "name", "=", "'p_data'", ")", "\n", "", "elif", "dataset", ".", "p_labeled", "is", "not", "None", ":", "\n", "            ", "self", ".", "p_data", "=", "tf", ".", "constant", "(", "dataset", ".", "p_labeled", ",", "name", "=", "'p_data'", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "p_data", "=", "tf", ".", "Variable", "(", "renorm", "(", "tf", ".", "ones", "(", "[", "dataset", ".", "nclass", "]", ")", ")", ",", "trainable", "=", "False", ",", "name", "=", "'p_data'", ")", "\n", "self", ".", "has_update", "=", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.__call__": [[146, 148], ["tensorflow.reduce_sum"], "methods", ["None"], ["", "", "def", "__call__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "p_data", "/", "tf", ".", "reduce_sum", "(", "self", ".", "p_data", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update": [[149, 152], ["tensorflow.reduce_mean", "tensorflow.assign"], "methods", ["None"], ["", "def", "update", "(", "self", ",", "entry", ",", "decay", "=", "0.999", ")", ":", "\n", "        ", "entry", "=", "tf", ".", "reduce_mean", "(", "entry", ",", "axis", "=", "0", ")", "\n", "return", "tf", ".", "assign", "(", "self", ".", "p_data", ",", "self", ".", "p_data", "*", "decay", "+", "entry", "*", "(", "1", "-", "decay", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.__init__": [[161, 164], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "mode", ")", ":", "\n", "        ", "assert", "mode", "in", "self", ".", "MODES", "\n", "self", ".", "mode", "=", "mode", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment_pair": [[165, 176], ["tensorflow.distributions.Beta().sample", "tensorflow.maximum", "tensorflow.random_shuffle", "tensorflow.gather", "tensorflow.gather", "tensorflow.range", "tensorflow.distributions.Beta", "tensorflow.shape", "tensorflow.shape"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "augment_pair", "(", "x0", ",", "l0", ",", "x1", ",", "l1", ",", "beta", ",", "**", "kwargs", ")", ":", "\n", "        ", "del", "kwargs", "\n", "mix", "=", "tf", ".", "distributions", ".", "Beta", "(", "beta", ",", "beta", ")", ".", "sample", "(", "[", "tf", ".", "shape", "(", "x0", ")", "[", "0", "]", ",", "1", ",", "1", ",", "1", "]", ")", "\n", "mix", "=", "tf", ".", "maximum", "(", "mix", ",", "1", "-", "mix", ")", "\n", "index", "=", "tf", ".", "random_shuffle", "(", "tf", ".", "range", "(", "tf", ".", "shape", "(", "x0", ")", "[", "0", "]", ")", ")", "\n", "xs", "=", "tf", ".", "gather", "(", "x1", ",", "index", ")", "\n", "ls", "=", "tf", ".", "gather", "(", "l1", ",", "index", ")", "\n", "xmix", "=", "x0", "*", "mix", "+", "xs", "*", "(", "1", "-", "mix", ")", "\n", "lmix", "=", "l0", "*", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", "+", "ls", "*", "(", "1", "-", "mix", "[", ":", ",", ":", ",", "0", ",", "0", "]", ")", "\n", "return", "xmix", ",", "lmix", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment": [[177, 180], ["layers.MixMode.augment_pair"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment_pair"], ["", "@", "staticmethod", "\n", "def", "augment", "(", "x", ",", "l", ",", "beta", ",", "**", "kwargs", ")", ":", "\n", "        ", "return", "MixMode", ".", "augment_pair", "(", "x", ",", "l", ",", "x", ",", "l", ",", "beta", ",", "**", "kwargs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.__call__": [[181, 230], ["NotImplementedError", "len", "len", "len", "layers.MixMode.augment", "layers.MixMode.augment", "tensorflow.concat", "tensorflow.concat", "layers.MixMode.augment", "layers.MixMode.augment", "tensorflow.split", "tensorflow.split", "tensorflow.concat", "tensorflow.concat", "layers.MixMode.augment", "tensorflow.split", "tensorflow.split", "tensorflow.concat", "tensorflow.concat", "layers.MixMode.augment", "len", "len", "sum", "len", "tensorflow.concat", "tensorflow.concat", "layers.MixMode.augment", "len", "len", "tensorflow.split", "tensorflow.split", "sum", "len", "tensorflow.concat", "tensorflow.concat", "tensorflow.split", "tensorflow.split", "layers.MixMode.augment", "layers.MixMode.augment", "len", "len", "tensorflow.split", "tensorflow.split", "sum", "len", "len", "len", "tensorflow.concat", "tensorflow.concat", "layers.MixMode.augment", "zip", "len", "len", "tensorflow.split", "len", "list", "list", "layers.MixMode.augment_pair", "range", "len"], "methods", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment_pair"], ["", "def", "__call__", "(", "self", ",", "xl", ":", "list", ",", "ll", ":", "list", ",", "betal", ":", "list", ")", ":", "\n", "        ", "assert", "len", "(", "xl", ")", "==", "len", "(", "ll", ")", ">=", "2", "\n", "assert", "len", "(", "betal", ")", "==", "2", "\n", "if", "self", ".", "mode", "==", "'.'", ":", "\n", "            ", "return", "xl", ",", "ll", "\n", "", "elif", "self", ".", "mode", "==", "'xx.'", ":", "\n", "            ", "mx0", ",", "ml0", "=", "self", ".", "augment", "(", "xl", "[", "0", "]", ",", "ll", "[", "0", "]", ",", "betal", "[", "0", "]", ")", "\n", "return", "[", "mx0", "]", "+", "xl", "[", "1", ":", "]", ",", "[", "ml0", "]", "+", "ll", "[", "1", ":", "]", "\n", "", "elif", "self", ".", "mode", "==", "'.yy'", ":", "\n", "            ", "mx1", ",", "ml1", "=", "self", ".", "augment", "(", "\n", "tf", ".", "concat", "(", "xl", "[", "1", ":", "]", ",", "0", ")", ",", "tf", ".", "concat", "(", "ll", "[", "1", ":", "]", ",", "0", ")", ",", "betal", "[", "1", "]", ")", "\n", "return", "(", "xl", "[", ":", "1", "]", "+", "tf", ".", "split", "(", "mx1", ",", "len", "(", "xl", ")", "-", "1", ")", ",", "\n", "ll", "[", ":", "1", "]", "+", "tf", ".", "split", "(", "ml1", ",", "len", "(", "ll", ")", "-", "1", ")", ")", "\n", "", "elif", "self", ".", "mode", "==", "'xx.yy'", ":", "\n", "            ", "mx0", ",", "ml0", "=", "self", ".", "augment", "(", "xl", "[", "0", "]", ",", "ll", "[", "0", "]", ",", "betal", "[", "0", "]", ")", "\n", "mx1", ",", "ml1", "=", "self", ".", "augment", "(", "\n", "tf", ".", "concat", "(", "xl", "[", "1", ":", "]", ",", "0", ")", ",", "tf", ".", "concat", "(", "ll", "[", "1", ":", "]", ",", "0", ")", ",", "betal", "[", "1", "]", ")", "\n", "return", "(", "[", "mx0", "]", "+", "tf", ".", "split", "(", "mx1", ",", "len", "(", "xl", ")", "-", "1", ")", ",", "\n", "[", "ml0", "]", "+", "tf", ".", "split", "(", "ml1", ",", "len", "(", "ll", ")", "-", "1", ")", ")", "\n", "", "elif", "self", ".", "mode", "==", "'xxy.'", ":", "\n", "            ", "mx", ",", "ml", "=", "self", ".", "augment", "(", "\n", "tf", ".", "concat", "(", "xl", ",", "0", ")", ",", "tf", ".", "concat", "(", "ll", ",", "0", ")", ",", "\n", "sum", "(", "betal", ")", "/", "len", "(", "betal", ")", ")", "\n", "return", "(", "tf", ".", "split", "(", "mx", ",", "len", "(", "xl", ")", ")", "[", ":", "1", "]", "+", "xl", "[", "1", ":", "]", ",", "\n", "tf", ".", "split", "(", "ml", ",", "len", "(", "ll", ")", ")", "[", ":", "1", "]", "+", "ll", "[", "1", ":", "]", ")", "\n", "", "elif", "self", ".", "mode", "==", "'.yxy'", ":", "\n", "            ", "mx", ",", "ml", "=", "self", ".", "augment", "(", "\n", "tf", ".", "concat", "(", "xl", ",", "0", ")", ",", "tf", ".", "concat", "(", "ll", ",", "0", ")", ",", "\n", "sum", "(", "betal", ")", "/", "len", "(", "betal", ")", ")", "\n", "return", "(", "xl", "[", ":", "1", "]", "+", "tf", ".", "split", "(", "mx", ",", "len", "(", "xl", ")", ")", "[", "1", ":", "]", ",", "\n", "ll", "[", ":", "1", "]", "+", "tf", ".", "split", "(", "ml", ",", "len", "(", "ll", ")", ")", "[", "1", ":", "]", ")", "\n", "", "elif", "self", ".", "mode", "==", "'xxy.yxy'", ":", "\n", "            ", "mx", ",", "ml", "=", "self", ".", "augment", "(", "\n", "tf", ".", "concat", "(", "xl", ",", "0", ")", ",", "tf", ".", "concat", "(", "ll", ",", "0", ")", ",", "\n", "sum", "(", "betal", ")", "/", "len", "(", "betal", ")", ")", "\n", "return", "tf", ".", "split", "(", "mx", ",", "len", "(", "xl", ")", ")", ",", "tf", ".", "split", "(", "ml", ",", "len", "(", "ll", ")", ")", "\n", "", "elif", "self", ".", "mode", "==", "'xx.yxy'", ":", "\n", "            ", "mx0", ",", "ml0", "=", "self", ".", "augment", "(", "xl", "[", "0", "]", ",", "ll", "[", "0", "]", ",", "betal", "[", "0", "]", ")", "\n", "mx1", ",", "ml1", "=", "self", ".", "augment", "(", "tf", ".", "concat", "(", "xl", ",", "0", ")", ",", "tf", ".", "concat", "(", "ll", ",", "0", ")", ",", "betal", "[", "1", "]", ")", "\n", "mx1", ",", "ml1", "=", "[", "tf", ".", "split", "(", "m", ",", "len", "(", "xl", ")", ")", "[", "1", ":", "]", "for", "m", "in", "(", "mx1", ",", "ml1", ")", "]", "\n", "return", "[", "mx0", "]", "+", "mx1", ",", "[", "ml0", "]", "+", "ml1", "\n", "", "elif", "self", ".", "mode", "==", "'xx.yx'", ":", "\n", "            ", "mx0", ",", "ml0", "=", "self", ".", "augment", "(", "xl", "[", "0", "]", ",", "ll", "[", "0", "]", ",", "betal", "[", "0", "]", ")", "\n", "mx1", ",", "ml1", "=", "zip", "(", "*", "[", "\n", "self", ".", "augment_pair", "(", "xl", "[", "i", "]", ",", "ll", "[", "i", "]", ",", "xl", "[", "0", "]", ",", "ll", "[", "0", "]", ",", "betal", "[", "1", "]", ")", "\n", "for", "i", "in", "range", "(", "1", ",", "len", "(", "xl", ")", ")", "\n", "]", ")", "\n", "return", "[", "mx0", "]", "+", "list", "(", "mx1", ")", ",", "[", "ml0", "]", "+", "list", "(", "ml1", ")", "\n", "", "raise", "NotImplementedError", "(", "self", ".", "mode", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.smart_shape": [[21, 24], ["tensorflow.shape", "range", "len"], "function", ["None"], ["def", "smart_shape", "(", "x", ")", ":", "\n", "    ", "s", ",", "t", "=", "x", ".", "shape", ",", "tf", ".", "shape", "(", "x", ")", "\n", "return", "[", "t", "[", "i", "]", "if", "s", "[", "i", "]", ".", "value", "is", "None", "else", "s", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "s", ")", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.entropy_from_logits": [[26, 39], ["tensorflow.contrib.distributions.Categorical", "tf.contrib.distributions.Categorical.entropy"], "function", ["None"], ["", "def", "entropy_from_logits", "(", "logits", ")", ":", "\n", "    ", "\"\"\"Computes entropy from classifier logits.\n\n    Args:\n        logits: a tensor of shape (batch_size, class_count) representing the\n        logits of a classifier.\n\n    Returns:\n        A tensor of shape (batch_size,) of floats giving the entropies\n        batchwise.\n    \"\"\"", "\n", "distribution", "=", "tf", ".", "contrib", ".", "distributions", ".", "Categorical", "(", "logits", "=", "logits", ")", "\n", "return", "distribution", ".", "entropy", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.entropy_penalty": [[41, 57], ["layers.entropy_from_logits", "tensorflow.cast", "tensorflow.reduce_mean"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.entropy_from_logits"], ["", "def", "entropy_penalty", "(", "logits", ",", "entropy_penalty_multiplier", ",", "mask", ")", ":", "\n", "    ", "\"\"\"Computes an entropy penalty using the classifier logits.\n\n    Args:\n        logits: a tensor of shape (batch_size, class_count) representing the\n            logits of a classifier.\n        entropy_penalty_multiplier: A float by which the entropy is multiplied.\n        mask: A tensor that optionally masks out some of the costs.\n\n    Returns:\n        The mean entropy penalty\n    \"\"\"", "\n", "entropy", "=", "entropy_from_logits", "(", "logits", ")", "\n", "losses", "=", "entropy", "*", "entropy_penalty_multiplier", "\n", "losses", "*=", "tf", ".", "cast", "(", "mask", ",", "tf", ".", "float32", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "losses", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.kl_divergence_from_logits": [[59, 72], ["tensorflow.contrib.distributions.Categorical", "tensorflow.contrib.distributions.Categorical", "tensorflow.contrib.distributions.kl_divergence"], "function", ["None"], ["", "def", "kl_divergence_from_logits", "(", "logits_a", ",", "logits_b", ")", ":", "\n", "    ", "\"\"\"Gets KL divergence from logits parameterizing categorical distributions.\n\n    Args:\n        logits_a: A tensor of logits parameterizing the first distribution.\n        logits_b: A tensor of logits parameterizing the second distribution.\n\n    Returns:\n        The (batch_size,) shaped tensor of KL divergences.\n    \"\"\"", "\n", "distribution1", "=", "tf", ".", "contrib", ".", "distributions", ".", "Categorical", "(", "logits", "=", "logits_a", ")", "\n", "distribution2", "=", "tf", ".", "contrib", ".", "distributions", ".", "Categorical", "(", "logits", "=", "logits_b", ")", "\n", "return", "tf", ".", "contrib", ".", "distributions", ".", "kl_divergence", "(", "distribution1", ",", "distribution2", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.mse_from_logits": [[74, 87], ["tensorflow.square", "tensorflow.reduce_mean", "tensorflow.nn.softmax", "tensorflow.nn.softmax"], "function", ["None"], ["", "def", "mse_from_logits", "(", "output_logits", ",", "target_logits", ")", ":", "\n", "    ", "\"\"\"Computes MSE between predictions associated with logits.\n\n    Args:\n        output_logits: A tensor of logits from the primary model.\n        target_logits: A tensor of logits from the secondary model.\n\n    Returns:\n        The mean MSE\n    \"\"\"", "\n", "diffs", "=", "tf", ".", "nn", ".", "softmax", "(", "output_logits", ")", "-", "tf", ".", "nn", ".", "softmax", "(", "target_logits", ")", "\n", "squared_diffs", "=", "tf", ".", "square", "(", "diffs", ")", "\n", "return", "tf", ".", "reduce_mean", "(", "squared_diffs", ",", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.interleave_offsets": [[89, 98], ["range", "offsets.append", "sum"], "function", ["None"], ["", "def", "interleave_offsets", "(", "batch", ",", "nu", ")", ":", "\n", "    ", "groups", "=", "[", "batch", "//", "(", "nu", "+", "1", ")", "]", "*", "(", "nu", "+", "1", ")", "\n", "for", "x", "in", "range", "(", "batch", "-", "sum", "(", "groups", ")", ")", ":", "\n", "        ", "groups", "[", "-", "x", "-", "1", "]", "+=", "1", "\n", "", "offsets", "=", "[", "0", "]", "\n", "for", "g", "in", "groups", ":", "\n", "        ", "offsets", ".", "append", "(", "offsets", "[", "-", "1", "]", "+", "g", ")", "\n", "", "assert", "offsets", "[", "-", "1", "]", "==", "batch", "\n", "return", "offsets", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.interleave": [[100, 107], ["layers.interleave_offsets", "range", "len", "tensorflow.concat", "range"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.interleave_offsets"], ["", "def", "interleave", "(", "xy", ",", "batch", ")", ":", "\n", "    ", "nu", "=", "len", "(", "xy", ")", "-", "1", "\n", "offsets", "=", "interleave_offsets", "(", "batch", ",", "nu", ")", "\n", "xy", "=", "[", "[", "v", "[", "offsets", "[", "p", "]", ":", "offsets", "[", "p", "+", "1", "]", "]", "for", "p", "in", "range", "(", "nu", "+", "1", ")", "]", "for", "v", "in", "xy", "]", "\n", "for", "i", "in", "range", "(", "1", ",", "nu", "+", "1", ")", ":", "\n", "        ", "xy", "[", "0", "]", "[", "i", "]", ",", "xy", "[", "i", "]", "[", "i", "]", "=", "xy", "[", "i", "]", "[", "i", "]", ",", "xy", "[", "0", "]", "[", "i", "]", "\n", "", "return", "[", "tf", ".", "concat", "(", "v", ",", "axis", "=", "0", ")", "for", "v", "in", "xy", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.renorm": [[109, 111], ["tensorflow.reduce_sum"], "function", ["None"], ["", "def", "renorm", "(", "v", ")", ":", "\n", "    ", "return", "v", "/", "tf", ".", "reduce_sum", "(", "v", ",", "axis", "=", "-", "1", ",", "keepdims", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.shakeshake": [[113, 120], ["tensorflow.random_uniform", "tensorflow.stop_gradient", "tensorflow.shape", "len"], "function", ["None"], ["", "def", "shakeshake", "(", "a", ",", "b", ",", "training", ")", ":", "\n", "    ", "if", "not", "training", ":", "\n", "        ", "return", "0.5", "*", "(", "a", "+", "b", ")", "\n", "", "mu", "=", "tf", ".", "random_uniform", "(", "[", "tf", ".", "shape", "(", "a", ")", "[", "0", "]", "]", "+", "[", "1", "]", "*", "(", "len", "(", "a", ".", "shape", ")", "-", "1", ")", ",", "0", ",", "1", ")", "\n", "mixf", "=", "a", "+", "mu", "*", "(", "b", "-", "a", ")", "\n", "mixb", "=", "a", "+", "mu", "[", ":", ":", "1", "]", "*", "(", "b", "-", "a", ")", "\n", "return", "tf", ".", "stop_gradient", "(", "mixf", "-", "mixb", ")", "+", "mixb", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_config": [[30, 38], ["tensorflow.ConfigProto", "len", "utils.get_available_gpus"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus"], ["def", "get_config", "(", ")", ":", "\n", "    ", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "if", "len", "(", "get_available_gpus", "(", ")", ")", ">", "1", ":", "\n", "        ", "config", ".", "allow_soft_placement", "=", "True", "\n", "", "if", "FLAGS", ".", "log_device_placement", ":", "\n", "        ", "config", ".", "log_device_placement", "=", "True", "\n", "", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "return", "config", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.setup_tf": [[40, 43], ["tensorflow.logging.set_verbosity"], "function", ["None"], ["", "def", "setup_tf", "(", ")", ":", "\n", "    ", "os", ".", "environ", "[", "'TF_CPP_MIN_LOG_LEVEL'", "]", "=", "'2'", "\n", "tf", ".", "logging", ".", "set_verbosity", "(", "tf", ".", "logging", ".", "ERROR", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.smart_shape": [[45, 49], ["tensorflow.shape", "range"], "function", ["None"], ["", "def", "smart_shape", "(", "x", ")", ":", "\n", "    ", "s", "=", "x", ".", "shape", "\n", "st", "=", "tf", ".", "shape", "(", "x", ")", "\n", "return", "[", "s", "[", "i", "]", "if", "s", "[", "i", "]", ".", "value", "is", "not", "None", "else", "st", "[", "i", "]", "for", "i", "in", "range", "(", "4", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.ilog2": [[51, 54], ["int", "numpy.ceil", "numpy.log2"], "function", ["None"], ["", "def", "ilog2", "(", "x", ")", ":", "\n", "    ", "\"\"\"Integer log2.\"\"\"", "\n", "return", "int", "(", "np", ".", "ceil", "(", "np", ".", "log2", "(", "x", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.find_latest_checkpoint": [[56, 68], ["re.compile", "glob.glob", "os.path.join", "int", "max", "re.compile.match().group", "re.compile.match"], "function", ["None"], ["", "def", "find_latest_checkpoint", "(", "dir", ",", "glob_term", "=", "'model.ckpt-*.meta'", ")", ":", "\n", "    ", "\"\"\"Replacement for tf.train.latest_checkpoint.\n\n    It does not rely on the \"checkpoint\" file which sometimes contains\n    absolute path and is generally hard to work with when sharing files\n    between users / computers.\n    \"\"\"", "\n", "r_step", "=", "re", ".", "compile", "(", "'.*model\\.ckpt-(?P<step>\\d+)\\.meta'", ")", "\n", "matches", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "glob_term", ")", ")", "\n", "matches", "=", "[", "(", "int", "(", "r_step", ".", "match", "(", "x", ")", ".", "group", "(", "'step'", ")", ")", ",", "x", ")", "for", "x", "in", "matches", "]", "\n", "ckpt_file", "=", "max", "(", "matches", ")", "[", "1", "]", "[", ":", "-", "5", "]", "\n", "return", "ckpt_file", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_latest_global_step": [[70, 84], ["tensorflow.train.NewCheckpointReader", "tf.train.NewCheckpointReader.get_tensor", "utils.find_latest_checkpoint"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.find_latest_checkpoint"], ["", "def", "get_latest_global_step", "(", "dir", ")", ":", "\n", "    ", "\"\"\"Loads the global step from the latest checkpoint in directory.\n  \n    Args:\n      dir: string, path to the checkpoint directory.\n  \n    Returns:\n      int, the global step of the latest checkpoint or 0 if none was found.\n    \"\"\"", "\n", "try", ":", "\n", "        ", "checkpoint_reader", "=", "tf", ".", "train", ".", "NewCheckpointReader", "(", "find_latest_checkpoint", "(", "dir", ")", ")", "\n", "return", "checkpoint_reader", ".", "get_tensor", "(", "tf", ".", "GraphKeys", ".", "GLOBAL_STEP", ")", "\n", "", "except", ":", "# pylint: disable=bare-except", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_latest_global_step_in_subdir": [[86, 100], ["max", "glob.glob", "os.path.isdir", "utils.get_latest_global_step", "os.path.join"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_latest_global_step"], ["", "", "def", "get_latest_global_step_in_subdir", "(", "dir", ")", ":", "\n", "    ", "\"\"\"Loads the global step from the latest checkpoint in sub-directories.\n\n    Args:\n      dir: string, parent of the checkpoint directories.\n\n    Returns:\n      int, the global step of the latest checkpoint or 0 if none was found.\n    \"\"\"", "\n", "sub_dirs", "=", "(", "x", "for", "x", "in", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "dir", ",", "'*'", ")", ")", "if", "os", ".", "path", ".", "isdir", "(", "x", ")", ")", "\n", "step", "=", "0", "\n", "for", "x", "in", "sub_dirs", ":", "\n", "        ", "step", "=", "max", "(", "step", ",", "get_latest_global_step", "(", "x", ")", ")", "\n", "", "return", "step", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.getter_ema": [[102, 118], ["getter", "ema.average"], "function", ["None"], ["", "def", "getter_ema", "(", "ema", ",", "getter", ",", "name", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"Exponential moving average getter for variable scopes.\n\n    Args:\n        ema: ExponentialMovingAverage object, where to get variable moving averages.\n        getter: default variable scope getter.\n        name: variable name.\n        *args: extra args passed to default getter.\n        **kwargs: extra args passed to default getter.\n\n    Returns:\n        If found the moving average variable, otherwise the default variable.\n    \"\"\"", "\n", "var", "=", "getter", "(", "name", ",", "*", "args", ",", "**", "kwargs", ")", "\n", "ema_var", "=", "ema", ".", "average", "(", "var", ")", "\n", "return", "ema_var", "if", "ema_var", "else", "var", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.model_vars": [[120, 122], ["tensorflow.get_collection"], "function", ["None"], ["", "def", "model_vars", "(", "scope", "=", "None", ")", ":", "\n", "    ", "return", "tf", ".", "get_collection", "(", "tf", ".", "GraphKeys", ".", "TRAINABLE_VARIABLES", ",", "scope", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.gpu": [[124, 126], ["max", "len", "utils.get_available_gpus"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus"], ["", "def", "gpu", "(", "x", ")", ":", "\n", "    ", "return", "'/gpu:%d'", "%", "(", "x", "%", "max", "(", "1", ",", "len", "(", "get_available_gpus", "(", ")", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus": [[128, 136], ["tensorflow.ConfigProto", "tensorflow.python.client.device_lib.list_local_devices", "tuple"], "function", ["None"], ["", "def", "get_available_gpus", "(", ")", ":", "\n", "    ", "global", "_GPUS", "\n", "if", "_GPUS", "is", "None", ":", "\n", "        ", "config", "=", "tf", ".", "ConfigProto", "(", ")", "\n", "config", ".", "gpu_options", ".", "allow_growth", "=", "True", "\n", "local_device_protos", "=", "device_lib", ".", "list_local_devices", "(", "session_config", "=", "config", ")", "\n", "_GPUS", "=", "tuple", "(", "[", "x", ".", "name", "for", "x", "in", "local_device_protos", "if", "x", ".", "device_type", "==", "'GPU'", "]", ")", "\n", "", "return", "_GPUS", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.average_gradients": [[138, 157], ["zip", "len", "tensorflow.reduce_mean", "average_grads.append"], "function", ["None"], ["", "def", "average_gradients", "(", "tower_grads", ")", ":", "\n", "# Adapted from:", "\n", "#  https://github.com/tensorflow/models/blob/master/tutorials/image/cifar10/cifar10_multi_gpu_train.py", "\n", "    ", "\"\"\"Calculate the average gradient for each shared variable across all towers.\n    Note that this function provides a synchronization point across all towers.\n    Args:\n      tower_grads: List of lists of (gradient, variable) tuples. For each tower, a list of its gradients.\n    Returns:\n       List of pairs of (gradient, variable) where the gradient has been averaged\n       across all towers.\n    \"\"\"", "\n", "if", "len", "(", "tower_grads", ")", "<=", "1", ":", "\n", "        ", "return", "tower_grads", "[", "0", "]", "\n", "\n", "", "average_grads", "=", "[", "]", "\n", "for", "grads_and_vars", "in", "zip", "(", "*", "tower_grads", ")", ":", "\n", "        ", "grad", "=", "tf", ".", "reduce_mean", "(", "[", "gv", "[", "0", "]", "for", "gv", "in", "grads_and_vars", "]", ",", "0", ")", "\n", "average_grads", ".", "append", "(", "(", "grad", ",", "grads_and_vars", "[", "0", "]", "[", "1", "]", ")", ")", "\n", "", "return", "average_grads", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.para_list": [[159, 172], ["len", "enumerate", "zip", "utils.get_available_gpus", "zip", "tensorflow.split", "zip", "tensorflow.name_scope", "tensorflow.device", "outputs.append", "fn", "tensorflow.train.replica_device_setter", "fn"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus"], ["", "def", "para_list", "(", "fn", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Run on multiple GPUs in parallel and return list of results.\"\"\"", "\n", "gpus", "=", "len", "(", "get_available_gpus", "(", ")", ")", "\n", "if", "gpus", "<=", "1", ":", "\n", "        ", "return", "zip", "(", "*", "[", "fn", "(", "*", "args", ")", "]", ")", "\n", "", "splitted", "=", "[", "tf", ".", "split", "(", "x", ",", "gpus", ")", "for", "x", "in", "args", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "gpu", ",", "x", "in", "enumerate", "(", "zip", "(", "*", "splitted", ")", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'tower%d'", "%", "gpu", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "worker_device", "=", "'/gpu:%d'", "%", "gpu", ",", "ps_device", "=", "'/cpu:0'", ",", "ps_tasks", "=", "1", ")", ")", ":", "\n", "                ", "outputs", ".", "append", "(", "fn", "(", "*", "x", ")", ")", "\n", "", "", "", "return", "zip", "(", "*", "outputs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.para_mean": [[174, 189], ["len", "enumerate", "isinstance", "tensorflow.reduce_mean", "utils.get_available_gpus", "fn", "tensorflow.split", "zip", "tensorflow.name_scope", "tensorflow.reduce_mean", "tensorflow.device", "outputs.append", "zip", "tensorflow.train.replica_device_setter", "fn"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus"], ["", "def", "para_mean", "(", "fn", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Run on multiple GPUs in parallel and return means.\"\"\"", "\n", "gpus", "=", "len", "(", "get_available_gpus", "(", ")", ")", "\n", "if", "gpus", "<=", "1", ":", "\n", "        ", "return", "fn", "(", "*", "args", ")", "\n", "", "splitted", "=", "[", "tf", ".", "split", "(", "x", ",", "gpus", ")", "for", "x", "in", "args", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "gpu", ",", "x", "in", "enumerate", "(", "zip", "(", "*", "splitted", ")", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'tower%d'", "%", "gpu", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "worker_device", "=", "'/gpu:%d'", "%", "gpu", ",", "ps_device", "=", "'/cpu:0'", ",", "ps_tasks", "=", "1", ")", ")", ":", "\n", "                ", "outputs", ".", "append", "(", "fn", "(", "*", "x", ")", ")", "\n", "", "", "", "if", "isinstance", "(", "outputs", "[", "0", "]", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "return", "[", "tf", ".", "reduce_mean", "(", "x", ",", "0", ")", "for", "x", "in", "zip", "(", "*", "outputs", ")", "]", "\n", "", "return", "tf", ".", "reduce_mean", "(", "outputs", ",", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.para_cat": [[191, 206], ["len", "enumerate", "isinstance", "tensorflow.concat", "utils.get_available_gpus", "fn", "tensorflow.split", "zip", "tensorflow.name_scope", "tensorflow.concat", "tensorflow.device", "outputs.append", "zip", "tensorflow.train.replica_device_setter", "fn"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_available_gpus"], ["", "def", "para_cat", "(", "fn", ",", "*", "args", ")", ":", "\n", "    ", "\"\"\"Run on multiple GPUs in parallel and return concatenated outputs.\"\"\"", "\n", "gpus", "=", "len", "(", "get_available_gpus", "(", ")", ")", "\n", "if", "gpus", "<=", "1", ":", "\n", "        ", "return", "fn", "(", "*", "args", ")", "\n", "", "splitted", "=", "[", "tf", ".", "split", "(", "x", ",", "gpus", ")", "for", "x", "in", "args", "]", "\n", "outputs", "=", "[", "]", "\n", "for", "gpu", ",", "x", "in", "enumerate", "(", "zip", "(", "*", "splitted", ")", ")", ":", "\n", "        ", "with", "tf", ".", "name_scope", "(", "'tower%d'", "%", "gpu", ")", ":", "\n", "            ", "with", "tf", ".", "device", "(", "tf", ".", "train", ".", "replica_device_setter", "(", "\n", "worker_device", "=", "'/gpu:%d'", "%", "gpu", ",", "ps_device", "=", "'/cpu:0'", ",", "ps_tasks", "=", "1", ")", ")", ":", "\n", "                ", "outputs", ".", "append", "(", "fn", "(", "*", "x", ")", ")", "\n", "", "", "", "if", "isinstance", "(", "outputs", "[", "0", "]", ",", "(", "tuple", ",", "list", ")", ")", ":", "\n", "        ", "return", "[", "tf", ".", "concat", "(", "x", ",", "axis", "=", "0", ")", "for", "x", "in", "zip", "(", "*", "outputs", ")", "]", "\n", "", "return", "tf", ".", "concat", "(", "outputs", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.hash_float": [[210, 215], ["tensorflow.cast", "tensorflow.constant", "tensorflow.string_to_hash_bucket_fast", "float"], "function", ["None"], ["", "def", "hash_float", "(", "x", ",", "big_num", "=", "1000", "*", "1000", ")", ":", "\n", "    ", "\"\"\"Hash a tensor 'x' into a floating point number in the range [0, 1).\"\"\"", "\n", "return", "tf", ".", "cast", "(", "\n", "tf", ".", "string_to_hash_bucket_fast", "(", "x", ",", "big_num", ")", ",", "tf", ".", "float32", "\n", ")", "/", "tf", ".", "constant", "(", "float", "(", "big_num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.make_set_filter_fn": [[217, 238], ["tensorflow.contrib.lookup.HashTable", "tensorflow.contrib.lookup.KeyValueTensorInitializer", "tensorflow.equal", "tensorflow.tile", "tf.contrib.lookup.HashTable.lookup", "tensorflow.dtypes.cast", "len"], "function", ["None"], ["", "def", "make_set_filter_fn", "(", "elements", ")", ":", "\n", "    ", "\"\"\"Constructs a TensorFlow \"set\" data structure.\n\n    Note that sets returned by this function are uninitialized. Initialize them\n    by calling `sess.run(tf.tables_initializer())`\n\n    Args:\n        elements: A list of non-Tensor elements.\n\n    Returns:\n        A function that when called with a single tensor argument, returns\n        a boolean tensor if the argument is in the set.\n    \"\"\"", "\n", "table", "=", "tf", ".", "contrib", ".", "lookup", ".", "HashTable", "(", "\n", "tf", ".", "contrib", ".", "lookup", ".", "KeyValueTensorInitializer", "(", "\n", "elements", ",", "tf", ".", "tile", "(", "[", "1", "]", ",", "[", "len", "(", "elements", ")", "]", ")", "\n", ")", ",", "\n", "default_value", "=", "0", ",", "\n", ")", "\n", "\n", "return", "lambda", "x", ":", "tf", ".", "equal", "(", "table", ".", "lookup", "(", "tf", ".", "dtypes", ".", "cast", "(", "x", ",", "tf", ".", "int32", ")", ")", ",", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.filter_fn_from_comma_delimited": [[240, 259], ["utils.make_set_filter_fn", "list", "tensorflow.constant", "map", "string.split"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.make_set_filter_fn"], ["", "def", "filter_fn_from_comma_delimited", "(", "string", ")", ":", "\n", "    ", "\"\"\"Parses a string of comma delimited numbers, returning a filter function.\n\n    This utility function is useful for parsing flags that represent a set of\n    options, where the default is \"all options\".\n\n    Args:\n        string: e.g. \"1,2,3\", or empty string for \"set of all elements\"\n\n    Returns:\n        A function that when called with a single tensor argument, returns\n        a boolean tensor that evaluates to True if the argument is in the set.\n        If 'string' argument is None, the set is understood to contain all\n        elements and the function always returns a True tensor.\n    \"\"\"", "\n", "if", "string", ":", "\n", "        ", "return", "make_set_filter_fn", "(", "list", "(", "map", "(", "int", ",", "string", ".", "split", "(", "\",\"", ")", ")", ")", ")", "\n", "", "else", ":", "\n", "        ", "return", "lambda", "x", ":", "tf", ".", "constant", "(", "True", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data_pair.stack_augment": [[26, 34], ["dict", "augment", "range", "tensorflow.stack", "tensorflow.stack"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.MixMode.augment"], ["def", "stack_augment", "(", "augment", ")", ":", "\n", "    ", "def", "func", "(", "x", ")", ":", "\n", "        ", "xl", "=", "[", "augment", "(", "x", ")", "for", "_", "in", "range", "(", "FLAGS", ".", "nu", ")", "]", "\n", "\n", "return", "dict", "(", "image", "=", "tf", ".", "stack", "(", "[", "x", "[", "'image'", "]", "for", "x", "in", "xl", "]", ")", ",", "\n", "label", "=", "tf", ".", "stack", "(", "[", "x", "[", "'label'", "]", "for", "x", "in", "xl", "]", ")", ")", "\n", "\n", "", "return", "func", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.inspect_variables.main": [[26, 32], ["tensorflow.contrib.framework.python.framework.checkpoint_utils.list_variables", "open", "json.dump", "print"], "function", ["None"], ["def", "main", "(", "argv", ")", ":", "\n", "    ", "var_list", "=", "checkpoint_utils", ".", "list_variables", "(", "FLAGS", ".", "path", ")", "\n", "with", "open", "(", "FLAGS", ".", "json", "+", "\".json\"", ",", "'w'", ",", "encoding", "=", "\"utf-8\"", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "var_list", ",", "f", ",", "ensure_ascii", "=", "False", ",", "indent", "=", "4", ")", "\n", "", "for", "v", "in", "var_list", ":", "\n", "        ", "print", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.filter_dataset.get_class": [[38, 40], ["tensorflow.parse_single_example", "tensorflow.FixedLenFeature"], "function", ["None"], ["def", "get_class", "(", "serialized_example", ")", ":", "\n", "    ", "return", "tf", ".", "parse_single_example", "(", "serialized_example", ",", "features", "=", "{", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", "}", ")", "[", "'label'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.filter_dataset.main": [[42, 91], ["collections.defaultdict", "tensorflow.data.TFRecordDataset", "dataset.map().batch.map().batch", "dataset.map().batch.make_one_shot_iterator().get_next", "list", "set", "print", "len", "print", "print", "print", "map", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.tf_record_iterator", "loop.close", "dataset.map().batch.map", "dataset.map().batch.make_one_shot_iterator", "FLAGS.class_filter.split", "tensorflow.Session", "tqdm.tqdm", "range", "tqdm.trange", "loop.update", "session.run", "t.update", "writer_label.write", "input_file.split", "set.add", "id_class.append", "class_id[].append"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "assert", "FLAGS", ".", "class_filter", "and", "FLAGS", ".", "filter_dataset", "and", "FLAGS", ".", "save_name", ",", "\"Please provide all 3 arguments.\"", "\n", "input_file", "=", "FLAGS", ".", "filter_dataset", "\n", "save_path", "=", "\"/\"", ".", "join", "(", "input_file", ".", "split", "(", "\"/\"", ")", "[", ":", "-", "1", "]", ")", "+", "\"/\"", "+", "FLAGS", ".", "save_name", "\n", "count", "=", "0", "\n", "id_class", "=", "[", "]", "\n", "class_id", "=", "defaultdict", "(", "list", ")", "\n", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "input_file", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "get_class", ",", "4", ")", ".", "batch", "(", "1", "<<", "10", ")", "\n", "it", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "classes_to_keep", "=", "list", "(", "map", "(", "int", ",", "FLAGS", ".", "class_filter", ".", "split", "(", "\",\"", ")", ")", ")", "\n", "all_classes", "=", "set", "(", ")", "\n", "try", ":", "\n", "# Store each image in a dict by its class number and image id.", "\n", "        ", "with", "tf", ".", "Session", "(", ")", "as", "session", ",", "tqdm", "(", "leave", "=", "False", ")", "as", "t", ":", "\n", "            ", "while", "1", ":", "\n", "                ", "old_count", "=", "count", "\n", "for", "i", "in", "session", ".", "run", "(", "it", ")", ":", "\n", "                    ", "all_classes", ".", "add", "(", "i", ")", "\n", "if", "i", "in", "classes_to_keep", ":", "\n", "                        ", "id_class", ".", "append", "(", "count", ")", "\n", "class_id", "[", "i", "]", ".", "append", "(", "count", ")", "\n", "", "count", "+=", "1", "\n", "\n", "", "t", ".", "update", "(", "count", "-", "old_count", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "pass", "\n", "", "print", "(", "'%d records found'", "%", "count", ")", "\n", "\n", "nclass", "=", "len", "(", "class_id", ")", "\n", "\n", "print", "(", "all_classes", ",", "classes_to_keep", ")", "\n", "\n", "class_data", "=", "[", "[", "]", "for", "_", "in", "range", "(", "nclass", ")", "]", "\n", "label_writes", "=", "0", "\n", "print", "(", "\"Saving to: \"", ",", "save_path", ")", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "save_path", ")", "as", "writer_label", ":", "\n", "        ", "pos", ",", "loop", "=", "0", ",", "trange", "(", "count", ",", "desc", "=", "'Writing records'", ")", "\n", "for", "record", "in", "tf", ".", "python_io", ".", "tf_record_iterator", "(", "input_file", ")", ":", "\n", "            ", "if", "pos", "in", "id_class", ":", "\n", "                ", "writer_label", ".", "write", "(", "record", ")", "\n", "label_writes", "+=", "1", "\n", "", "pos", "+=", "1", "\n", "loop", ".", "update", "(", ")", "\n", "", "loop", ".", "close", "(", ")", "\n", "\n", "", "print", "(", "label_writes", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._encode_png": [[60, 68], ["tensorflow.Session", "tensorflow.device", "tensorflow.placeholder", "tensorflow.image.encode_png", "tqdm.trange", "raw.append", "sess.run"], "function", ["None"], ["def", "_encode_png", "(", "images", ")", ":", "\n", "    ", "raw", "=", "[", "]", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ",", "tf", ".", "device", "(", "'cpu:0'", ")", ":", "\n", "        ", "image_x", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "[", "None", ",", "None", ",", "None", "]", ",", "'image_x'", ")", "\n", "to_png", "=", "tf", ".", "image", ".", "encode_png", "(", "image_x", ")", "\n", "for", "x", "in", "tqdm", ".", "trange", "(", "images", ".", "shape", "[", "0", "]", ",", "desc", "=", "'PNG Encoding'", ",", "leave", "=", "False", ")", ":", "\n", "            ", "raw", ".", "append", "(", "sess", ".", "run", "(", "to_png", ",", "feed_dict", "=", "{", "image_x", ":", "images", "[", "x", "]", "}", ")", ")", "\n", "", "", "return", "raw", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._encode_and_aug_png": [[72, 122], ["keras.preprocessing.image.ImageDataGenerator", "tensorflow.Session", "tensorflow.device", "tensorflow.placeholder", "tensorflow.image.encode_png", "enumerate", "len", "len", "tqdm.tqdm", "raw.append", "new_labels.append", "class_ids[].pop", "sess.run", "range", "image.ImageDataGenerator.random_transform", "raw.append", "new_labels.append", "sess.run"], "function", ["None"], ["", "def", "_encode_and_aug_png", "(", "images", ",", "labels", ",", "num_aug_per_class", ",", "class_ids", ",", "imgs_per_class", ")", ":", "\n", "    ", "raw", "=", "[", "]", "\n", "new_labels", "=", "[", "]", "\n", "\n", "aug_datagen", "=", "image", ".", "ImageDataGenerator", "(", "\n", "rotation_range", "=", "40", ",", "\n", "width_shift_range", "=", "0.2", ",", "\n", "height_shift_range", "=", "0.2", ",", "\n", "shear_range", "=", "0.2", ",", "\n", "zoom_range", "=", "0.2", ",", "\n", "horizontal_flip", "=", "True", ",", "\n", "fill_mode", "=", "'nearest'", ")", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ",", "tf", ".", "device", "(", "'cpu:0'", ")", ":", "\n", "        ", "image_x", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "[", "None", ",", "None", ",", "None", "]", ",", "'image_x'", ")", "\n", "to_png", "=", "tf", ".", "image", ".", "encode_png", "(", "image_x", ")", "\n", "\n", "# Iterate through each class and perform class-balancing.", "\n", "# num_of_augs dictates the number of augmentations to be performed", "\n", "# if the class is to be oversampled.", "\n", "for", "classname", ",", "num_of_augs", "in", "enumerate", "(", "tqdm", ".", "tqdm", "(", "num_aug_per_class", ")", ")", ":", "\n", "            ", "if", "num_of_augs", "==", "0", ":", "\n", "                ", "continue", "\n", "\n", "", "img_num", "=", "0", "\n", "\n", "# Oversample the class until the required number of images has been met.", "\n", "while", "img_num", "<", "imgs_per_class", ":", "\n", "                ", "try", ":", "\n", "                    ", "img_id", "=", "class_ids", "[", "classname", "]", ".", "pop", "(", "0", ")", "\n", "", "except", ":", "\n", "                    ", "break", "\n", "", "raw", ".", "append", "(", "sess", ".", "run", "(", "to_png", ",", "feed_dict", "=", "{", "image_x", ":", "images", "[", "img_id", "]", "}", ")", ")", "\n", "new_labels", ".", "append", "(", "classname", ")", "\n", "img_num", "+=", "1", "\n", "\n", "# Data augmentation is used to oversample if the num_of_augs > 1.", "\n", "if", "num_of_augs", ">", "1", ":", "\n", "                    ", "for", "_", "in", "range", "(", "0", ",", "num_of_augs", "-", "1", ")", ":", "\n", "                        ", "if", "img_num", "<", "imgs_per_class", ":", "\n", "                            ", "aug_img", "=", "aug_datagen", ".", "random_transform", "(", "images", "[", "img_id", "]", ",", "seed", "=", "1", ")", "\n", "raw", ".", "append", "(", "sess", ".", "run", "(", "to_png", ",", "feed_dict", "=", "{", "image_x", ":", "aug_img", "}", ")", ")", "\n", "new_labels", ".", "append", "(", "classname", ")", "\n", "img_num", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "break", "\n", "\n", "", "", "", "", "", "", "assert", "len", "(", "raw", ")", "==", "len", "(", "new_labels", ")", "\n", "\n", "return", "raw", ",", "new_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._load_svhn": [[124, 138], ["collections.OrderedDict", "numpy.transpose", "create_datasets._encode_png", "data_dict[].reshape", "tempfile.NamedTemporaryFile", "urllib.request.urlretrieve", "scipy.io.loadmat", "URLS[].format"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape"], ["", "def", "_load_svhn", "(", ")", ":", "\n", "    ", "splits", "=", "collections", ".", "OrderedDict", "(", ")", "\n", "for", "split", "in", "[", "'train'", ",", "'test'", ",", "'extra'", "]", ":", "\n", "        ", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "f", ":", "\n", "            ", "request", ".", "urlretrieve", "(", "URLS", "[", "'svhn'", "]", ".", "format", "(", "split", ")", ",", "f", ".", "name", ")", "\n", "data_dict", "=", "scipy", ".", "io", ".", "loadmat", "(", "f", ".", "name", ")", "\n", "", "dataset", "=", "{", "}", "\n", "dataset", "[", "'images'", "]", "=", "np", ".", "transpose", "(", "data_dict", "[", "'X'", "]", ",", "[", "3", ",", "0", ",", "1", ",", "2", "]", ")", "\n", "dataset", "[", "'images'", "]", "=", "_encode_png", "(", "dataset", "[", "'images'", "]", ")", "\n", "dataset", "[", "'labels'", "]", "=", "data_dict", "[", "'y'", "]", ".", "reshape", "(", "(", "-", "1", ")", ")", "\n", "# SVHN raw data uses labels from 1 to 10; use 0 to 9 instead.", "\n", "dataset", "[", "'labels'", "]", "-=", "1", "\n", "splits", "[", "split", "]", "=", "dataset", "\n", "", "return", "splits", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._load_stl10": [[140, 176], ["create_datasets._encode_png", "create_datasets._encode_png", "create_datasets._encode_png", "dict", "numpy.transpose", "tempfile.NamedTemporaryFile", "os.path.exists", "tarfile.open", "tarfile.open.extractfile", "tarfile.open.extractfile", "tarfile.open.extractfile", "tarfile.open.extractfile", "tarfile.open.extractfile", "numpy.frombuffer", "tarfile.open.extractfile().read", "create_datasets._load_stl10.unflatten"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png"], ["", "def", "_load_stl10", "(", ")", ":", "\n", "    ", "def", "unflatten", "(", "images", ")", ":", "\n", "        ", "return", "np", ".", "transpose", "(", "images", ".", "reshape", "(", "(", "-", "1", ",", "3", ",", "96", ",", "96", ")", ")", ",", "\n", "[", "0", ",", "3", ",", "2", ",", "1", "]", ")", "\n", "\n", "", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "f", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "'stl10/stl10_binary.tar.gz'", ")", ":", "\n", "            ", "f", "=", "open", "(", "'stl10/stl10_binary.tar.gz'", ",", "'rb'", ")", "\n", "", "else", ":", "\n", "            ", "request", ".", "urlretrieve", "(", "URLS", "[", "'stl10'", "]", ",", "f", ".", "name", ")", "\n", "", "tar", "=", "tarfile", ".", "open", "(", "fileobj", "=", "f", ")", "\n", "train_X", "=", "tar", ".", "extractfile", "(", "'stl10_binary/train_X.bin'", ")", "\n", "train_y", "=", "tar", ".", "extractfile", "(", "'stl10_binary/train_y.bin'", ")", "\n", "\n", "test_X", "=", "tar", ".", "extractfile", "(", "'stl10_binary/test_X.bin'", ")", "\n", "test_y", "=", "tar", ".", "extractfile", "(", "'stl10_binary/test_y.bin'", ")", "\n", "\n", "unlabeled_X", "=", "tar", ".", "extractfile", "(", "'stl10_binary/unlabeled_X.bin'", ")", "\n", "\n", "train_set", "=", "{", "'images'", ":", "np", ".", "frombuffer", "(", "train_X", ".", "read", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "\n", "'labels'", ":", "np", ".", "frombuffer", "(", "train_y", ".", "read", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "-", "1", "}", "\n", "\n", "test_set", "=", "{", "'images'", ":", "np", ".", "frombuffer", "(", "test_X", ".", "read", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", ",", "\n", "'labels'", ":", "np", ".", "frombuffer", "(", "test_y", ".", "read", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "-", "1", "}", "\n", "\n", "_imgs", "=", "np", ".", "frombuffer", "(", "unlabeled_X", ".", "read", "(", ")", ",", "dtype", "=", "np", ".", "uint8", ")", "\n", "unlabeled_set", "=", "{", "'images'", ":", "_imgs", ",", "\n", "'labels'", ":", "np", ".", "zeros", "(", "100000", ",", "dtype", "=", "np", ".", "uint8", ")", "}", "\n", "\n", "fold_indices", "=", "tar", ".", "extractfile", "(", "'stl10_binary/fold_indices.txt'", ")", ".", "read", "(", ")", "\n", "\n", "", "train_set", "[", "'images'", "]", "=", "_encode_png", "(", "unflatten", "(", "train_set", "[", "'images'", "]", ")", ")", "\n", "test_set", "[", "'images'", "]", "=", "_encode_png", "(", "unflatten", "(", "test_set", "[", "'images'", "]", ")", ")", "\n", "unlabeled_set", "[", "'images'", "]", "=", "_encode_png", "(", "unflatten", "(", "unlabeled_set", "[", "'images'", "]", ")", ")", "\n", "return", "dict", "(", "train", "=", "train_set", ",", "test", "=", "test_set", ",", "unlabeled", "=", "unlabeled_set", ",", "\n", "files", "=", "[", "EasyDict", "(", "filename", "=", "\"stl10_fold_indices.txt\"", ",", "data", "=", "fold_indices", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._load_cifar10": [[178, 201], ["create_datasets._encode_png", "create_datasets._encode_png", "dict", "numpy.transpose", "tempfile.NamedTemporaryFile", "urllib.request.urlretrieve", "tarfile.open", "range", "scipy.io.loadmat", "create_datasets._load_stl10.unflatten"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png"], ["", "def", "_load_cifar10", "(", ")", ":", "\n", "    ", "def", "unflatten", "(", "images", ")", ":", "\n", "        ", "return", "np", ".", "transpose", "(", "images", ".", "reshape", "(", "(", "images", ".", "shape", "[", "0", "]", ",", "3", ",", "32", ",", "32", ")", ")", ",", "\n", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "f", ":", "\n", "        ", "request", ".", "urlretrieve", "(", "URLS", "[", "'cifar10'", "]", ",", "f", ".", "name", ")", "\n", "tar", "=", "tarfile", ".", "open", "(", "fileobj", "=", "f", ")", "\n", "train_data_batches", ",", "train_data_labels", "=", "[", "]", ",", "[", "]", "\n", "for", "batch", "in", "range", "(", "1", ",", "6", ")", ":", "\n", "            ", "data_dict", "=", "scipy", ".", "io", ".", "loadmat", "(", "tar", ".", "extractfile", "(", "\n", "'cifar-10-batches-mat/data_batch_{}.mat'", ".", "format", "(", "batch", ")", ")", ")", "\n", "train_data_batches", ".", "append", "(", "data_dict", "[", "'data'", "]", ")", "\n", "train_data_labels", ".", "append", "(", "data_dict", "[", "'labels'", "]", ".", "flatten", "(", ")", ")", "\n", "", "train_set", "=", "{", "'images'", ":", "np", ".", "concatenate", "(", "train_data_batches", ",", "axis", "=", "0", ")", ",", "\n", "'labels'", ":", "np", ".", "concatenate", "(", "train_data_labels", ",", "axis", "=", "0", ")", "}", "\n", "data_dict", "=", "scipy", ".", "io", ".", "loadmat", "(", "tar", ".", "extractfile", "(", "\n", "'cifar-10-batches-mat/test_batch.mat'", ")", ")", "\n", "test_set", "=", "{", "'images'", ":", "data_dict", "[", "'data'", "]", ",", "\n", "'labels'", ":", "data_dict", "[", "'labels'", "]", ".", "flatten", "(", ")", "}", "\n", "", "train_set", "[", "'images'", "]", "=", "_encode_png", "(", "unflatten", "(", "train_set", "[", "'images'", "]", ")", ")", "\n", "test_set", "[", "'images'", "]", "=", "_encode_png", "(", "unflatten", "(", "test_set", "[", "'images'", "]", ")", ")", "\n", "return", "dict", "(", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._load_cifar100": [[203, 220], ["create_datasets._encode_png", "create_datasets._encode_png", "dict", "numpy.transpose", "tempfile.NamedTemporaryFile", "urllib.request.urlretrieve", "tarfile.open", "scipy.io.loadmat", "scipy.io.loadmat", "create_datasets._load_stl10.unflatten"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png"], ["", "def", "_load_cifar100", "(", ")", ":", "\n", "    ", "def", "unflatten", "(", "images", ")", ":", "\n", "        ", "return", "np", ".", "transpose", "(", "images", ".", "reshape", "(", "(", "images", ".", "shape", "[", "0", "]", ",", "3", ",", "32", ",", "32", ")", ")", ",", "\n", "[", "0", ",", "2", ",", "3", ",", "1", "]", ")", "\n", "\n", "", "with", "tempfile", ".", "NamedTemporaryFile", "(", ")", "as", "f", ":", "\n", "        ", "request", ".", "urlretrieve", "(", "URLS", "[", "'cifar100'", "]", ",", "f", ".", "name", ")", "\n", "tar", "=", "tarfile", ".", "open", "(", "fileobj", "=", "f", ")", "\n", "data_dict", "=", "scipy", ".", "io", ".", "loadmat", "(", "tar", ".", "extractfile", "(", "'cifar-100-matlab/train.mat'", ")", ")", "\n", "train_set", "=", "{", "'images'", ":", "data_dict", "[", "'data'", "]", ",", "\n", "'labels'", ":", "data_dict", "[", "'fine_labels'", "]", ".", "flatten", "(", ")", "}", "\n", "data_dict", "=", "scipy", ".", "io", ".", "loadmat", "(", "tar", ".", "extractfile", "(", "'cifar-100-matlab/test.mat'", ")", ")", "\n", "test_set", "=", "{", "'images'", ":", "data_dict", "[", "'data'", "]", ",", "\n", "'labels'", ":", "data_dict", "[", "'fine_labels'", "]", ".", "flatten", "(", ")", "}", "\n", "", "train_set", "[", "'images'", "]", "=", "_encode_png", "(", "unflatten", "(", "train_set", "[", "'images'", "]", ")", ")", "\n", "test_set", "[", "'images'", "]", "=", "_encode_png", "(", "unflatten", "(", "test_set", "[", "'images'", "]", ")", ")", "\n", "return", "dict", "(", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._load_custom": [[222, 294], ["glob.glob", "glob.glob", "numpy.asarray", "list", "list.sort", "numpy.asarray", "create_datasets._encode_png", "create_datasets._save_class_mappings", "dict", "set", "list.index", "list.index", "float", "third_party.random_eraser.get_random_eraser", "int", "print", "enumerate", "numpy.random.seed", "range", "print", "create_datasets._encode_and_aug_png", "create_datasets._encode_png", "matplotlib.imread", "matplotlib.imread", "numpy.asarray", "math.ceil", "train_labels.count", "class_ids[].append", "len", "numpy.random.shuffle", "max", "range", "range", "int", "path.split", "path.split", "third_party.random_eraser.get_random_eraser.", "int", "len", "len", "str", "len", "math.ceil", "path.split", "tqdm.trange", "str"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._save_class_mappings", "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.random_eraser_tf.get_random_eraser", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._encode_and_aug_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png"], ["", "def", "_load_custom", "(", ")", ":", "\n", "    ", "assert", "args", ".", "traindir", "and", "args", ".", "testdir", ",", "\"A training and test image directory must be provided for custom datasets.\"", "\n", "\n", "if", "args", ".", "traindir", "[", "-", "1", "]", "is", "not", "\"/\"", ":", "\n", "        ", "args", ".", "traindir", "+=", "\"/\"", "\n", "\n", "", "if", "args", ".", "testdir", "[", "-", "1", "]", "is", "not", "\"/\"", ":", "\n", "        ", "args", ".", "testdir", "+=", "\"/\"", "\n", "\n", "# Read images and labels from local directories.", "\n", "# The labels are extracted through each image's filename.", "\n", "# Ex: 24628_dog.png -> \"dog\"", "\n", "# Ex: 73158_cat.png -> \"cat\"", "\n", "\n", "", "train_data_paths", "=", "glob", ".", "glob", "(", "args", ".", "traindir", "+", "\"*.jpg\"", ")", "\n", "test_data_paths", "=", "glob", ".", "glob", "(", "args", ".", "testdir", "+", "\"*.jpg\"", ")", "\n", "\n", "train_data", "=", "np", ".", "asarray", "(", "[", "plt", ".", "imread", "(", "path", ")", "for", "path", "in", "train_data_paths", "]", ")", "\n", "class_names", "=", "list", "(", "set", "(", "[", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "for", "path", "in", "train_data_paths", "]", ")", ")", "\n", "class_names", ".", "sort", "(", ")", "\n", "train_labels", "=", "[", "class_names", ".", "index", "(", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", "for", "path", "in", "train_data_paths", "]", "\n", "\n", "test_data", "=", "np", ".", "asarray", "(", "[", "plt", ".", "imread", "(", "path", ")", "for", "path", "in", "test_data_paths", "]", ")", "\n", "test_labels", "=", "[", "class_names", ".", "index", "(", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", "for", "path", "in", "test_data_paths", "]", "\n", "\n", "# If cutout augmentation is specified, here we apply it each image in the training set.", "\n", "if", "args", ".", "cutout", ":", "\n", "        ", "assert", "args", ".", "cutout_prob", ",", "\"Please specify a cutout parameter.\"", "\n", "cutout_prob", "=", "float", "(", "args", ".", "cutout_prob", ")", "\n", "eraser", "=", "get_random_eraser", "(", "p", "=", "cutout_prob", ")", "\n", "if", "\"train\"", "in", "args", ".", "cutout", "or", "args", ".", "cutout", "==", "\"all\"", ":", "\n", "            ", "train_data", "=", "np", ".", "asarray", "(", "[", "eraser", "(", "train_data", "[", "i", "]", ")", "for", "i", "in", "tqdm", ".", "trange", "(", "train_data", ".", "shape", "[", "0", "]", ",", "desc", "=", "\"Performing cutout on training images with probability of \"", "+", "str", "(", "cutout_prob", ")", ")", "]", ")", "\n", "\n", "", "", "train_set", "=", "{", "'images'", ":", "train_data", ",", "\n", "'labels'", ":", "train_labels", "}", "\n", "test_set", "=", "{", "'images'", ":", "test_data", ",", "\n", "'labels'", ":", "test_labels", "}", "\n", "\n", "if", "args", ".", "train_balance", ":", "\n", "# If the training set is to be balanced, we calculate how many imgs_per_class", "\n", "# are needed and how many of each class is currently present.", "\n", "        ", "imgs_per_class", "=", "int", "(", "math", ".", "ceil", "(", "int", "(", "args", ".", "train_balance", ")", "/", "len", "(", "class_names", ")", ")", ")", "\n", "train_class_count", "=", "[", "train_labels", ".", "count", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", "]", "\n", "\n", "print", "(", "\"Balancing training set to \"", "+", "str", "(", "imgs_per_class", ")", "+", "\" ...\"", ")", "\n", "class_ids", "=", "{", "class_num", ":", "[", "]", "for", "class_num", "in", "range", "(", "len", "(", "class_names", ")", ")", "}", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "train_set", "[", "'labels'", "]", ")", ":", "\n", "            ", "class_ids", "[", "label", "]", ".", "append", "(", "i", ")", "\n", "\n", "# We shuffle the dataset to sample evenly.", "\n", "", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "class_ids", "[", "i", "]", ")", "\n", "\n", "", "num_aug_per_class", "=", "[", "max", "(", "1", ",", "int", "(", "math", ".", "ceil", "(", "imgs_per_class", "/", "class_count", ")", ")", ")", "for", "class_count", "in", "train_class_count", "]", "\n", "\n", "# The class-balancing operation occurs in _encode_and_aug_png, which returns", "\n", "# the class-balanced set of images and labels.", "\n", "print", "(", "\"Number of augmentations needed: \"", ",", "num_aug_per_class", ")", "\n", "train_set", "[", "'images'", "]", ",", "train_set", "[", "'labels'", "]", "=", "_encode_and_aug_png", "(", "train_set", "[", "'images'", "]", ",", "train_set", "[", "'labels'", "]", ",", "num_aug_per_class", ",", "class_ids", ",", "imgs_per_class", ")", "\n", "\n", "", "else", ":", "\n", "        ", "train_set", "[", "'images'", "]", "=", "_encode_png", "(", "train_set", "[", "'images'", "]", ")", "\n", "\n", "\n", "", "test_set", "[", "'images'", "]", "=", "_encode_png", "(", "test_set", "[", "'images'", "]", ")", "\n", "\n", "_save_class_mappings", "(", "class_names", ")", "\n", "\n", "return", "dict", "(", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._load_custom_extra": [[296, 439], ["glob.glob", "glob.glob", "glob.glob", "numpy.asarray", "numpy.asarray", "list", "list.sort", "numpy.asarray", "print", "create_datasets._encode_png", "print", "print", "create_datasets._save_class_mappings", "dict", "set", "list.index", "list.index", "float", "third_party.random_eraser.get_random_eraser", "int", "print", "enumerate", "numpy.random.seed", "range", "print", "create_datasets._encode_and_aug_png", "create_datasets._encode_png", "len", "int", "print", "enumerate", "numpy.random.seed", "range", "print", "create_datasets._encode_and_aug_png", "print", "numpy.concatenate", "numpy.concatenate", "len", "len", "matplotlib.imread", "matplotlib.imread", "matplotlib.imread", "numpy.asarray", "numpy.asarray", "math.ceil", "train_labels.count", "class_ids[].append", "len", "numpy.random.shuffle", "max", "list.index", "math.ceil", "np.load.count", "class_ids[].append", "len", "numpy.random.shuffle", "print", "numpy.load", "print", "numpy.load", "len", "print", "numpy.load", "range", "range", "int", "range", "range", "create_datasets._encode_png", "path.split", "path.split", "third_party.random_eraser.get_random_eraser.", "third_party.random_eraser.get_random_eraser.", "int", "len", "len", "str", "len", "math.ceil", "int", "len", "len", "str", "len", "collections.Counter", "range", "max", "max", "max", "path.split", "tqdm.trange", "tqdm.trange", "path.split", "len", "int", "int", "int", "math.ceil", "math.ceil", "math.ceil", "str", "str"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._save_class_mappings", "home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.random_eraser_tf.get_random_eraser", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._encode_and_aug_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._encode_and_aug_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.load", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.load", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.train.Model.load", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png"], ["", "def", "_load_custom_extra", "(", ")", ":", "\n", "    ", "assert", "args", ".", "traindir", "and", "args", ".", "testdir", "and", "args", ".", "unlabeldir", ",", "\"A training, unlabeled, and test image directory must be provided for custom-extra datasets.\"", "\n", "\n", "if", "args", ".", "traindir", "[", "-", "1", "]", "is", "not", "\"/\"", ":", "\n", "        ", "args", ".", "traindir", "+=", "\"/\"", "\n", "\n", "", "if", "args", ".", "testdir", "[", "-", "1", "]", "is", "not", "\"/\"", ":", "\n", "        ", "args", ".", "testdir", "+=", "\"/\"", "\n", "\n", "", "if", "args", ".", "unlabeldir", "[", "-", "1", "]", "is", "not", "\"/\"", ":", "\n", "        ", "args", ".", "unlabeldir", "+=", "\"/\"", "\n", "\n", "", "train_data_paths", "=", "glob", ".", "glob", "(", "args", ".", "traindir", "+", "\"*.jpg\"", ")", "\n", "test_data_paths", "=", "glob", ".", "glob", "(", "args", ".", "testdir", "+", "\"*.jpg\"", ")", "\n", "unlabel_data_paths", "=", "glob", ".", "glob", "(", "args", ".", "unlabeldir", "+", "\"*.jpg\"", ")", "\n", "\n", "# Read images and labels from local directories.", "\n", "# The labels are extracted through each image's filename.", "\n", "# Ex: 24628_dog.png -> \"dog\"", "\n", "# Ex: 73158_cat.png -> \"cat\"", "\n", "\n", "train_data", "=", "np", ".", "asarray", "(", "[", "plt", ".", "imread", "(", "path", ")", "for", "path", "in", "train_data_paths", "]", ")", "\n", "unlabel_data", "=", "np", ".", "asarray", "(", "[", "plt", ".", "imread", "(", "path", ")", "for", "path", "in", "unlabel_data_paths", "]", ")", "\n", "class_names", "=", "list", "(", "set", "(", "[", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", "for", "path", "in", "train_data_paths", "]", ")", ")", "\n", "class_names", ".", "sort", "(", ")", "\n", "train_labels", "=", "[", "class_names", ".", "index", "(", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", "for", "path", "in", "train_data_paths", "]", "\n", "unlabel_labels", "=", "[", "0", "for", "path", "in", "unlabel_data_paths", "]", "\n", "\n", "test_data", "=", "np", ".", "asarray", "(", "[", "plt", ".", "imread", "(", "path", ")", "for", "path", "in", "test_data_paths", "]", ")", "\n", "test_labels", "=", "[", "class_names", ".", "index", "(", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", "for", "path", "in", "test_data_paths", "]", "\n", "\n", "train_set", "=", "{", "'images'", ":", "train_data", ",", "\n", "'labels'", ":", "train_labels", "}", "\n", "test_set", "=", "{", "'images'", ":", "test_data", ",", "\n", "'labels'", ":", "test_labels", "}", "\n", "\n", "if", "args", ".", "cutout", ":", "\n", "# If cutout augmentation is specified, here we apply it each image in the training set.", "\n", "        ", "assert", "args", ".", "cutout_prob", ",", "\"Please specify a cutout parameter.\"", "\n", "\n", "cutout_prob", "=", "float", "(", "args", ".", "cutout_prob", ")", "\n", "eraser", "=", "get_random_eraser", "(", "p", "=", "cutout_prob", ")", "\n", "\n", "if", "\"train\"", "in", "args", ".", "cutout", "or", "args", ".", "cutout", "==", "\"all\"", ":", "\n", "            ", "train_data", "=", "np", ".", "asarray", "(", "[", "eraser", "(", "train_data", "[", "i", "]", ")", "for", "i", "in", "tqdm", ".", "trange", "(", "train_data", ".", "shape", "[", "0", "]", ",", "desc", "=", "\"Performing cutout on training images with probability of \"", "+", "str", "(", "cutout_prob", ")", ")", "]", ")", "\n", "", "if", "\"unlabel\"", "in", "args", ".", "cutout", "or", "args", ".", "cutout", "==", "\"all\"", ":", "\n", "            ", "unlabel_data", "=", "np", ".", "asarray", "(", "[", "eraser", "(", "unlabel_data", "[", "i", "]", ")", "for", "i", "in", "tqdm", ".", "trange", "(", "unlabel_data", ".", "shape", "[", "0", "]", ",", "desc", "=", "\"Performing cutout on unlabeled images with probability of \"", "+", "str", "(", "cutout_prob", ")", ")", "]", ")", "\n", "\n", "", "", "if", "args", ".", "train_balance", ":", "\n", "# If the training set is to be balanced, we calculate how many imgs_per_class", "\n", "# are needed and how many of each class is currently present.", "\n", "        ", "imgs_per_class", "=", "int", "(", "math", ".", "ceil", "(", "int", "(", "args", ".", "train_balance", ")", "/", "len", "(", "class_names", ")", ")", ")", "\n", "train_class_count", "=", "[", "train_labels", ".", "count", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", "]", "\n", "print", "(", "\"Balancing training set to \"", "+", "str", "(", "imgs_per_class", ")", "+", "\" ...\"", ")", "\n", "\n", "class_ids", "=", "{", "class_num", ":", "[", "]", "for", "class_num", "in", "range", "(", "len", "(", "class_names", ")", ")", "}", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "train_set", "[", "'labels'", "]", ")", ":", "\n", "            ", "class_ids", "[", "label", "]", ".", "append", "(", "i", ")", "\n", "\n", "# We shuffle the dataset to sample evenly.", "\n", "", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "class_ids", "[", "i", "]", ")", "\n", "\n", "", "num_aug_per_class", "=", "[", "max", "(", "1", ",", "int", "(", "math", ".", "ceil", "(", "imgs_per_class", "/", "class_count", ")", ")", ")", "for", "class_count", "in", "train_class_count", "]", "\n", "\n", "# The class-balancing operation occurs in _encode_and_aug_png, which returns", "\n", "# the class-balanced set of images and labels.", "\n", "print", "(", "\"Number of augmentations needed: \"", ",", "num_aug_per_class", ")", "\n", "train_set", "[", "'images'", "]", ",", "train_set", "[", "'labels'", "]", "=", "_encode_and_aug_png", "(", "train_set", "[", "'images'", "]", ",", "train_set", "[", "'labels'", "]", ",", "num_aug_per_class", ",", "class_ids", ",", "imgs_per_class", ")", "\n", "\n", "", "else", ":", "\n", "        ", "train_set", "[", "'images'", "]", "=", "_encode_png", "(", "train_set", "[", "'images'", "]", ")", "\n", "\n", "", "print", "(", "\"Training Images: \"", ",", "len", "(", "train_set", "[", "'images'", "]", ")", ")", "\n", "\n", "if", "args", ".", "unlabel_balance", ":", "\n", "        ", "unlabel_labels", "=", "[", "class_names", ".", "index", "(", "path", ".", "split", "(", "'_'", ")", "[", "-", "1", "]", "[", ":", "-", "4", "]", ")", "for", "path", "in", "unlabel_data_paths", "]", "\n", "\n", "# If the unlabeled set is to be balanced, we calculate how many imgs_per_class", "\n", "# are needed and how many of each class is currently present.", "\n", "imgs_per_class", "=", "int", "(", "math", ".", "ceil", "(", "int", "(", "args", ".", "unlabel_balance", ")", "/", "len", "(", "class_names", ")", ")", ")", "\n", "unlabel_class_count", "=", "[", "unlabel_labels", ".", "count", "(", "i", ")", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", "]", "\n", "\n", "print", "(", "\"Balancing unlabeled set to \"", "+", "str", "(", "imgs_per_class", ")", "+", "\" ...\"", ")", "\n", "class_ids", "=", "{", "class_num", ":", "[", "]", "for", "class_num", "in", "range", "(", "len", "(", "class_names", ")", ")", "}", "\n", "\n", "for", "i", ",", "label", "in", "enumerate", "(", "unlabel_labels", ")", ":", "\n", "            ", "class_ids", "[", "label", "]", ".", "append", "(", "i", ")", "\n", "\n", "# We shuffle the dataset to sample evenly.", "\n", "", "np", ".", "random", ".", "seed", "(", "1", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "class_ids", "[", "i", "]", ")", "\n", "\n", "", "if", "args", ".", "prediction_balance", ":", "\n", "# The class balancing is performed on the predicted distribution of the unlabeled set,", "\n", "# given by predictions.npy. This is a more realistic scenario of class-balancing for unlabeled", "\n", "# sets, as one doesn't know the ground truth distribution of an unlabeled.", "\n", "\n", "            ", "print", "(", "\"Creating class balance from predictions on the unlabeled set.\"", ")", "\n", "\n", "unlabel_preds", "=", "np", ".", "load", "(", "'predictions.npy'", ")", "\n", "unlabel_pred_class_count", "=", "[", "collections", ".", "Counter", "(", "unlabel_preds", ")", "[", "i", "]", "for", "i", "in", "range", "(", "len", "(", "class_names", ")", ")", "]", "\n", "num_aug_per_class", "=", "[", "max", "(", "1", ",", "int", "(", "math", ".", "ceil", "(", "imgs_per_class", "/", "class_count", ")", ")", ")", "if", "class_count", ">", "0", "else", "0", "for", "class_count", "in", "unlabel_pred_class_count", "]", "\n", "", "else", ":", "\n", "            ", "num_aug_per_class", "=", "[", "max", "(", "1", ",", "int", "(", "math", ".", "ceil", "(", "imgs_per_class", "/", "class_count", ")", ")", ")", "if", "class_count", ">", "0", "else", "0", "for", "class_count", "in", "unlabel_class_count", "]", "\n", "\n", "", "if", "args", ".", "pseudolabel", ":", "\n", "# This assigns the unlabeled set labels from an external file,", "\n", "# here used from predictions.npy", "\n", "            ", "print", "(", "\"Reading pseduo labels to unlabel_labels...\"", ")", "\n", "unlabel_labels", "=", "np", ".", "load", "(", "'predictions.npy'", ")", "\n", "unlabel_labels", "=", "[", "label", "for", "label", "in", "unlabel_labels", "]", "\n", "\n", "# Perform class-balancing", "\n", "", "print", "(", "\"Number of augmentations needed: \"", ",", "num_aug_per_class", ",", "[", "max", "(", "1", ",", "int", "(", "math", ".", "ceil", "(", "imgs_per_class", "/", "class_count", ")", ")", ")", "if", "class_count", ">", "0", "else", "0", "for", "class_count", "in", "unlabel_class_count", "]", ")", "\n", "unlabel_data", ",", "unlabel_labels", "=", "_encode_and_aug_png", "(", "unlabel_data", ",", "unlabel_labels", ",", "num_aug_per_class", ",", "class_ids", ",", "imgs_per_class", ")", "\n", "print", "(", "\"Unlabeled Images after Balancing: \"", ",", "len", "(", "unlabel_data", ")", ")", "\n", "\n", "train_set", "[", "'images'", "]", "=", "np", ".", "concatenate", "(", "(", "train_set", "[", "'images'", "]", ",", "unlabel_data", ")", ")", "\n", "train_set", "[", "'labels'", "]", "=", "train_set", "[", "'labels'", "]", "+", "unlabel_labels", "\n", "\n", "", "else", ":", "\n", "        ", "train_set", "[", "'images'", "]", "=", "np", ".", "concatenate", "(", "(", "train_set", "[", "'images'", "]", ",", "_encode_png", "(", "unlabel_data", ")", ")", ")", "\n", "\n", "if", "args", ".", "pseudolabel", ":", "\n", "            ", "print", "(", "\"Reading pseduo labels to unlabel_labels...\"", ")", "\n", "unlabel_labels", "=", "np", ".", "load", "(", "'predictions.npy'", ")", "\n", "unlabel_labels", "=", "[", "label", "for", "label", "in", "unlabel_labels", "]", "\n", "\n", "", "train_set", "[", "'labels'", "]", "=", "train_set", "[", "'labels'", "]", "+", "unlabel_labels", "\n", "\n", "", "test_set", "[", "'images'", "]", "=", "_encode_png", "(", "test_set", "[", "'images'", "]", ")", "\n", "\n", "print", "(", "\"Training and Unlabeled Images: \"", ",", "len", "(", "train_set", "[", "'images'", "]", ")", ")", "\n", "print", "(", "\"Test Images: \"", ",", "len", "(", "test_set", "[", "'images'", "]", ")", ")", "\n", "\n", "_save_class_mappings", "(", "class_names", ")", "\n", "\n", "return", "dict", "(", "train", "=", "train_set", ",", "test", "=", "test_set", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._save_class_mappings": [[440, 444], ["open", "json.dump", "enumerate"], "function", ["None"], ["", "def", "_save_class_mappings", "(", "class_names", ")", ":", "\n", "    ", "class_mapping", "=", "{", "index", ":", "name", "for", "index", ",", "name", "in", "enumerate", "(", "class_names", ")", "}", "\n", "with", "open", "(", "args", ".", "name", "+", "'_class_mappings.json'", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "class_mapping", ",", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._int64_feature": [[445, 447], ["tensorflow.train.Feature", "tensorflow.train.Int64List"], "function", ["None"], ["", "", "def", "_int64_feature", "(", "value", ")", ":", "\n", "    ", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._bytes_feature": [[449, 451], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "_bytes_feature", "(", "value", ")", ":", "\n", "    ", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._save_as_tfrecord": [[453, 464], ["os.path.join", "print", "print", "len", "len", "tensorflow.python_io.TFRecordWriter", "tqdm.trange", "len", "dict", "tensorflow.train.Example", "writer.write", "tf.train.Example.SerializeToString", "create_datasets._bytes_feature", "create_datasets._int64_feature", "tensorflow.train.Features"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._bytes_feature", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._int64_feature"], ["", "def", "_save_as_tfrecord", "(", "data", ",", "filename", ")", ":", "\n", "    ", "assert", "len", "(", "data", "[", "'images'", "]", ")", "==", "len", "(", "data", "[", "'labels'", "]", ")", "\n", "filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "filename", "+", "'.tfrecord'", ")", "\n", "print", "(", "'Saving dataset:'", ",", "filename", ")", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "filename", ")", "as", "writer", ":", "\n", "        ", "for", "x", "in", "tqdm", ".", "trange", "(", "len", "(", "data", "[", "'images'", "]", ")", ",", "desc", "=", "'Building records'", ")", ":", "\n", "            ", "feat", "=", "dict", "(", "image", "=", "_bytes_feature", "(", "data", "[", "'images'", "]", "[", "x", "]", ")", ",", "\n", "label", "=", "_int64_feature", "(", "data", "[", "'labels'", "]", "[", "x", "]", ")", ")", "\n", "record", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "feat", ")", ")", "\n", "writer", ".", "write", "(", "record", ".", "SerializeToString", "(", ")", ")", "\n", "", "", "print", "(", "'Saved:'", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._is_installed": [[466, 472], ["checksums.items", "os.path.join", "os.path.exists"], "function", ["None"], ["", "def", "_is_installed", "(", "name", ",", "checksums", ")", ":", "\n", "    ", "for", "subset", ",", "checksum", "in", "checksums", ".", "items", "(", ")", ":", "\n", "        ", "filename", "=", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'%s-%s.tfrecord'", "%", "(", "name", ",", "subset", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "filename", ")", ":", "\n", "            ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._save_files": [[474, 481], ["frozenset", "files.items", "os.makedirs", "os.path.dirname", "os.path.join", "open", "f.write", "os.path.join"], "function", ["None"], ["", "def", "_save_files", "(", "files", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "del", "args", ",", "kwargs", "\n", "for", "folder", "in", "frozenset", "(", "os", ".", "path", ".", "dirname", "(", "x", ")", "for", "x", "in", "files", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "folder", ")", ",", "exist_ok", "=", "True", ")", "\n", "", "for", "filename", ",", "contents", "in", "files", ".", "items", "(", ")", ":", "\n", "        ", "with", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "filename", ")", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "contents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_datasets._is_installed_folder": [[483, 485], ["os.path.exists", "os.path.join"], "function", ["None"], ["", "", "", "def", "_is_installed_folder", "(", "name", ",", "folder", ")", ":", "\n", "    ", "return", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "name", ",", "folder", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.inspect_dataset.main": [[33, 56], ["libml.utils.setup_tf", "tensorflow.train.MonitoredSession", "dataset.test.repeat", "ds.batch().prefetch().make_one_shot_iterator().get_next", "numpy.zeros", "tqdm.trange", "print", "print", "print", "minmax[].append", "minmax[].append", "min", "max", "ds.batch().prefetch().make_one_shot_iterator", "sess.run", "v.min", "v.max", "ds.batch().prefetch", "np.zeros.max", "ds.batch"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.setup_tf"], ["def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "\n", "utils", ".", "setup_tf", "(", ")", "\n", "nbatch", "=", "FLAGS", ".", "samples", "//", "FLAGS", ".", "batch", "\n", "dataset", "=", "data", ".", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "groups", "=", "[", "(", "'labeled'", ",", "dataset", ".", "train_labeled", ")", ",", "\n", "(", "'unlabeled'", ",", "dataset", ".", "train_unlabeled", ")", ",", "\n", "(", "'test'", ",", "dataset", ".", "test", ".", "repeat", "(", ")", ")", "]", "\n", "groups", "=", "[", "(", "name", ",", "ds", ".", "batch", "(", "FLAGS", ".", "batch", ")", ".", "prefetch", "(", "16", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", ")", "\n", "for", "name", ",", "ds", "in", "groups", "]", "\n", "with", "tf", ".", "train", ".", "MonitoredSession", "(", ")", "as", "sess", ":", "\n", "        ", "for", "group", ",", "train_data", "in", "groups", ":", "\n", "            ", "stats", "=", "np", ".", "zeros", "(", "dataset", ".", "nclass", ",", "np", ".", "int32", ")", "\n", "minmax", "=", "[", "]", ",", "[", "]", "\n", "for", "_", "in", "trange", "(", "nbatch", ",", "leave", "=", "False", ",", "unit", "=", "'img'", ",", "unit_scale", "=", "FLAGS", ".", "batch", ",", "desc", "=", "group", ")", ":", "\n", "                ", "v", "=", "sess", ".", "run", "(", "train_data", ")", "[", "'label'", "]", "\n", "for", "u", "in", "v", ":", "\n", "                    ", "stats", "[", "u", "]", "+=", "1", "\n", "", "minmax", "[", "0", "]", ".", "append", "(", "v", ".", "min", "(", ")", ")", "\n", "minmax", "[", "1", "]", ".", "append", "(", "v", ".", "max", "(", ")", ")", "\n", "", "print", "(", "group", ")", "\n", "print", "(", "'  Label range'", ",", "min", "(", "minmax", "[", "0", "]", ")", ",", "max", "(", "minmax", "[", "1", "]", ")", ")", "\n", "print", "(", "'  Stats'", ",", "' '", ".", "join", "(", "[", "'%.2f'", "%", "(", "100", "*", "x", ")", "for", "x", "in", "(", "stats", "/", "stats", ".", "max", "(", ")", ")", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._int64_feature": [[35, 37], ["tensorflow.train.Feature", "tensorflow.train.Int64List"], "function", ["None"], ["def", "_int64_feature", "(", "value", ")", ":", "\n", "    ", "return", "tf", ".", "train", ".", "Feature", "(", "int64_list", "=", "tf", ".", "train", ".", "Int64List", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._bytes_feature": [[38, 40], ["tensorflow.train.Feature", "tensorflow.train.BytesList"], "function", ["None"], ["", "def", "_bytes_feature", "(", "value", ")", ":", "\n", "    ", "return", "tf", ".", "train", ".", "Feature", "(", "bytes_list", "=", "tf", ".", "train", ".", "BytesList", "(", "value", "=", "[", "value", "]", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.get_info": [[41, 47], ["tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.image.decode_png", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature"], "function", ["None"], ["", "def", "get_info", "(", "serialized_example", ")", ":", "\n", "    ", "features", "=", "tf", ".", "parse_single_example", "(", "\n", "serialized_example", ",", "\n", "features", "=", "{", "'image'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", "}", ")", "\n", "return", "tf", ".", "cast", "(", "tf", ".", "image", ".", "decode_png", "(", "features", "[", "'image'", "]", ")", ",", "tf", ".", "float32", ")", ",", "features", "[", "'label'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape": [[48, 50], ["tensorflow.reshape"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape"], ["", "def", "reshape", "(", "x", ")", ":", "\n", "    ", "return", "tf", ".", "reshape", "(", "x", ",", "[", "32", ",", "32", ",", "3", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.augment_cifar10": [[51, 53], ["libml.data.augment_shift", "libml.data.augment_mirror", "make_aug_copy.reshape"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_shift", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_mirror", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.reshape"], ["", "def", "augment_cifar10", "(", "image", ",", "label", ")", ":", "\n", "    ", "return", "data", ".", "augment_shift", "(", "data", ".", "augment_mirror", "(", "reshape", "(", "image", ")", ")", ",", "4", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.augment_cutout": [[54, 57], ["third_party.random_eraser_tf.get_random_eraser", "third_party.random_eraser_tf.get_random_eraser."], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.third_party.random_eraser_tf.get_random_eraser"], ["", "def", "augment_cutout", "(", "image", ",", "label", ")", ":", "\n", "    ", "eraser", "=", "get_random_eraser", "(", "p", "=", "0.3", ")", "\n", "return", "eraser", "(", "image", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.augment_color": [[58, 60], ["libml.data.augment_shift", "libml.data.augment_color_func", "libml.data.augment_mirror"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_shift", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_color_func", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_mirror"], ["", "def", "augment_color", "(", "image", ",", "label", ")", ":", "\n", "    ", "return", "data", ".", "augment_shift", "(", "data", ".", "augment_color_func", "(", "data", ".", "augment_mirror", "(", "image", ")", ")", ",", "4", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.augment_stl10": [[61, 63], ["libml.data.augment_shift", "libml.data.augment_mirror"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_shift", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_mirror"], ["", "def", "augment_stl10", "(", "image", ",", "label", ")", ":", "\n", "    ", "return", "data", ".", "augment_shift", "(", "data", ".", "augment_mirror", "(", "image", ")", ",", "12", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.augment_svhn": [[64, 66], ["libml.data.augment_shift"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.data.augment_shift"], ["", "def", "augment_svhn", "(", "image", ",", "label", ")", ":", "\n", "    ", "return", "data", ".", "augment_shift", "(", "image", ",", "4", ")", ",", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.save_as_tfrecord": [[67, 78], ["print", "print", "len", "len", "tensorflow.python_io.TFRecordWriter", "tqdm.trange", "len", "dict", "tensorflow.train.Example", "writer.write", "str", "tf.train.Example.SerializeToString", "make_aug_copy._bytes_feature", "make_aug_copy._int64_feature", "tensorflow.train.Features"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._bytes_feature", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._int64_feature"], ["", "def", "save_as_tfrecord", "(", "images", ",", "labels", ",", "filename", ")", ":", "\n", "    ", "assert", "len", "(", "images", ")", "==", "len", "(", "labels", ")", "\n", "# filename = os.path.join(DATA_DIR + \"/SSL\", filename)", "\n", "print", "(", "'Saving tfrecord with '", "+", "str", "(", "FLAGS", ".", "aug_copy", ")", "+", "' augmentations performed: '", ",", "filename", ")", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "filename", ")", "as", "writer", ":", "\n", "        ", "for", "x", "in", "tqdm", ".", "trange", "(", "len", "(", "images", ")", ",", "desc", "=", "'Building Records'", ")", ":", "\n", "            ", "feat", "=", "dict", "(", "image", "=", "_bytes_feature", "(", "images", "[", "x", "]", ")", ",", "\n", "label", "=", "_int64_feature", "(", "labels", "[", "x", "]", ")", ")", "\n", "record", "=", "tf", ".", "train", ".", "Example", "(", "features", "=", "tf", ".", "train", ".", "Features", "(", "feature", "=", "feat", ")", ")", "\n", "writer", ".", "write", "(", "record", ".", "SerializeToString", "(", ")", ")", "\n", "", "", "print", "(", "'Saved:'", ",", "filename", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png": [[79, 87], ["tensorflow.Session", "tensorflow.device", "tensorflow.placeholder", "tensorflow.image.encode_png", "tqdm.trange", "len", "raw.append", "sess.run"], "function", ["None"], ["", "def", "_encode_png", "(", "images", ")", ":", "\n", "    ", "raw", "=", "[", "]", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ",", "tf", ".", "device", "(", "'cpu:0'", ")", ":", "\n", "        ", "image_x", "=", "tf", ".", "placeholder", "(", "tf", ".", "uint8", ",", "[", "None", ",", "None", ",", "None", "]", ",", "'image_x'", ")", "\n", "to_png", "=", "tf", ".", "image", ".", "encode_png", "(", "image_x", ")", "\n", "for", "x", "in", "tqdm", ".", "trange", "(", "len", "(", "images", ")", ",", "desc", "=", "'Creating PNG Encoding'", ",", "leave", "=", "False", ")", ":", "\n", "            ", "raw", ".", "append", "(", "sess", ".", "run", "(", "to_png", ",", "feed_dict", "=", "{", "image_x", ":", "images", "[", "x", "]", "}", ")", ")", "\n", "", "", "return", "raw", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.main": [[88, 146], ["enumerate", "shutil.copyfile", "os.path.join", "os.path.isfile", "sorted", "tensorflow.data.TFRecordDataset", "dataset.map().repeat().map.map().repeat().map", "dataset.map().repeat().map.make_one_shot_iterator().get_next", "random.seed", "random.shuffle", "make_aug_copy._encode_png", "tfrecord.split", "make_aug_copy.save_as_tfrecord", "os.path.join", "os.path.join", "augment_dict.keys", "sum", "ValueError", "tensorflow.Session", "tqdm.trange", "tqdm.trange.close", "dataset.map().repeat().map.map().repeat", "dataset.map().repeat().map.make_one_shot_iterator", "range", "glob.glob", "int", "sess.run", "_encode_png.append", "labels.append", "tqdm.trange.update", "len", "str", "FLAGS.aug_dataset.split", "str", "dataset.map().repeat().map.map", "FLAGS.aug_dataset.split", "FLAGS.aug_dataset.split"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy._encode_png", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.make_aug_copy.save_as_tfrecord", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update"], ["", "def", "main", "(", "argv", ")", ":", "\n", "# Supported augmentations are contained in the following dict.", "\n", "    ", "augment_dict", "=", "{", "\"cifar10\"", ":", "augment_cifar10", ",", "\"color\"", ":", "augment_color", ",", "\"cutout\"", ":", "augment_cutout", ",", "\"svhn\"", ":", "augment_svhn", ",", "\"stl10\"", ":", "augment_stl10", "}", "\n", "\n", "# TODO: Make script keep a copy of unaugmented images in the dataset, investigate how to apply autoaugment policies", "\n", "\n", "assert", "FLAGS", ".", "aug_dataset", ",", "\"Please enter the name of the dataset to generate unlabeled augmentations.\"", "\n", "assert", "FLAGS", ".", "aug_copy", ",", "\"Please provide a number of augmented copies of the unlabeled data to produce.\"", "\n", "assert", "FLAGS", ".", "augment", ",", "\"Please provide a type of augmentation to perform, supported types are \"", "+", "\" \"", ".", "join", "(", "augment_dict", ".", "keys", "(", ")", ")", "\n", "assert", "FLAGS", ".", "unlabel_size", ",", "\"Please give the size of the labeled and unlabeled dataset.\"", "\n", "\n", "tfrecords", "=", "[", "os", ".", "path", ".", "join", "(", "DATA_DIR", "+", "\"/SSL\"", ",", "FLAGS", ".", "aug_dataset", "+", "\"-unlabel.tfrecord\"", ")", "]", "\n", "for", "index", ",", "tfrecord", "in", "enumerate", "(", "tfrecords", ")", ":", "\n", "        ", "assert", "os", ".", "path", ".", "isfile", "(", "tfrecord", ")", ",", "tfrecord", "+", "\" not found. Please provide a dataset that has been initialized.\"", "\n", "# Create TFRecordDataset using TFRecord containing labeled and unlabeled images.", "\n", "filenames", "=", "sorted", "(", "sum", "(", "[", "glob", ".", "glob", "(", "tfrecord", ")", "]", ",", "[", "]", ")", ")", "\n", "if", "not", "filenames", ":", "\n", "            ", "raise", "ValueError", "(", "'Dataset using '", "+", "tfrecord", "+", "' not found.'", ")", "\n", "", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "filenames", ")", "\n", "\n", "# Initialize dataset, create FLAGS.aug_copy number of copies, and apply augmentation.", "\n", "dataset", "=", "dataset", ".", "map", "(", "get_info", ",", "4", ")", ".", "repeat", "(", "FLAGS", ".", "aug_copy", ")", ".", "map", "(", "augment_dict", "[", "FLAGS", ".", "augment", "]", ",", "4", ")", "\n", "data", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "\n", "images", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "            ", "if", "tfrecord", "[", "-", "16", ":", "-", "9", "]", "is", "\"unlabel\"", ":", "\n", "                ", "num_of_images", "=", "int", "(", "FLAGS", ".", "aug_dataset", ".", "split", "(", "\"@\"", ")", "[", "1", "]", ")", "*", "FLAGS", ".", "aug_copy", "\n", "", "else", ":", "\n", "                ", "num_of_images", "=", "FLAGS", ".", "unlabel_size", "*", "FLAGS", ".", "aug_copy", "\n", "", "loop", "=", "tqdm", ".", "trange", "(", "num_of_images", ",", "desc", "=", "\"Performing \"", "+", "FLAGS", ".", "augment", "+", "\" augmentation\"", ")", "\n", "try", ":", "\n", "                ", "while", "True", ":", "\n", "                    ", "img", ",", "label", "=", "sess", ".", "run", "(", "data", ")", "\n", "images", ".", "append", "(", "img", ")", "\n", "labels", ".", "append", "(", "label", ")", "\n", "loop", ".", "update", "(", ")", "\n", "", "", "except", ":", "\n", "                ", "pass", "\n", "", "loop", ".", "close", "(", ")", "\n", "\n", "# Encode augmented images for saving as tfrecords.", "\n", "", "imgs_labels", "=", "[", "(", "images", "[", "i", "]", ",", "labels", "[", "i", "]", ")", "for", "i", "in", "range", "(", "0", ",", "len", "(", "images", ")", ")", "]", "\n", "random", ".", "seed", "(", "1", ")", "\n", "random", ".", "shuffle", "(", "imgs_labels", ")", "\n", "images", "=", "[", "img_label", "[", "0", "]", "for", "img_label", "in", "imgs_labels", "]", "\n", "labels", "=", "[", "img_label", "[", "1", "]", "for", "img_label", "in", "imgs_labels", "]", "\n", "images", "=", "_encode_png", "(", "images", ")", "\n", "filesplit", "=", "tfrecord", ".", "split", "(", "'.'", ")", "\n", "filename", "=", "filesplit", "[", "0", "]", "+", "\"_aug\"", "+", "str", "(", "FLAGS", ".", "aug_copy", ")", "+", "'.'", "+", "'.'", ".", "join", "(", "filesplit", "[", "1", ":", "]", ")", "\n", "save_as_tfrecord", "(", "images", ",", "labels", ",", "filename", ")", "\n", "\n", "# Copy the test file to the new name", "\n", "", "copyfile", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", "+", "\"/\"", ",", "FLAGS", ".", "aug_dataset", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "\"-test.tfrecord\"", ")", ",", "os", ".", "path", ".", "join", "(", "DATA_DIR", "+", "\"/\"", ",", "FLAGS", ".", "aug_dataset", ".", "split", "(", "'.'", ")", "[", "0", "]", "+", "\"_aug\"", "+", "str", "(", "FLAGS", ".", "aug_copy", ")", "+", "\"-test.tfrecord\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.extract_accuracy.summary_dict": [[35, 38], ["numpy.median"], "function", ["None"], ["def", "summary_dict", "(", "accuracies", ")", ":", "\n", "    ", "return", "{", "\n", "'last%02d'", "%", "x", ":", "np", ".", "median", "(", "accuracies", "[", "-", "x", ":", "]", ")", "for", "x", "in", "[", "1", ",", "10", ",", "20", ",", "50", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.extract_accuracy.main": [[41, 73], ["sorted", "set", "os.path.join", "os.path.join", "print", "print", "len", "absl.app.UsageError", "glob.glob", "tensorflow.train.summary_iterator", "os.path.isdir", "os.makedirs", "open", "json.dump", "extract_accuracy.summary_dict", "os.path.join", "extract_accuracy.summary_dict", "next", "accuracies.append", "set.add"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.extract_accuracy.summary_dict", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.extract_accuracy.summary_dict"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "if", "len", "(", "argv", ")", ">", "2", ":", "\n", "        ", "raise", "app", ".", "UsageError", "(", "'Too many command-line arguments.'", ")", "\n", "", "folder", "=", "argv", "[", "1", "]", "\n", "matches", "=", "sorted", "(", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "'tf/events.out.tfevents.*'", ")", ")", ")", "\n", "assert", "matches", ",", "'No events files found'", "\n", "tags", "=", "set", "(", ")", "\n", "accuracies", "=", "[", "]", "\n", "for", "event_file", "in", "matches", ":", "\n", "        ", "summaries", "=", "tf", ".", "train", ".", "summary_iterator", "(", "event_file", ")", "\n", "while", "True", ":", "\n", "            ", "try", ":", "\n", "                ", "e", "=", "next", "(", "summaries", ")", "\n", "", "except", ":", "\n", "                ", "break", "\n", "", "for", "v", "in", "e", ".", "summary", ".", "value", ":", "\n", "                ", "if", "v", ".", "tag", "==", "TAG", ":", "\n", "                    ", "accuracies", ".", "append", "(", "v", ".", "simple_value", ")", "\n", "break", "\n", "", "elif", "not", "accuracies", ":", "\n", "                    ", "tags", ".", "add", "(", "v", ".", "tag", ")", "\n", "\n", "", "", "", "", "assert", "accuracies", ",", "'No \"accuracy\" tag found. Found tags = %s'", "%", "tags", "\n", "target_dir", "=", "os", ".", "path", ".", "join", "(", "folder", ",", "'stats'", ")", "\n", "target_file", "=", "os", ".", "path", ".", "join", "(", "target_dir", ",", "'accuracy.json'", ")", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "target_dir", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "target_dir", ")", "\n", "\n", "", "with", "open", "(", "target_file", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "json", ".", "dump", "(", "summary_dict", "(", "accuracies", ")", ",", "f", ",", "sort_keys", "=", "True", ",", "indent", "=", "4", ")", "\n", "", "print", "(", "'Saved: %s'", "%", "target_file", ")", "\n", "print", "(", "summary_dict", "(", "accuracies", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.tfrecord_to_image.get_info": [[37, 43], ["tensorflow.parse_single_example", "tensorflow.cast", "tensorflow.image.decode_png", "tensorflow.FixedLenFeature", "tensorflow.FixedLenFeature"], "function", ["None"], ["def", "get_info", "(", "serialized_example", ")", ":", "\n", "    ", "features", "=", "tf", ".", "parse_single_example", "(", "\n", "serialized_example", ",", "\n", "features", "=", "{", "'image'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "string", ")", ",", "\n", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", "}", ")", "\n", "return", "tf", ".", "cast", "(", "tf", ".", "image", ".", "decode_png", "(", "features", "[", "'image'", "]", ")", ",", "tf", ".", "float32", ")", ",", "features", "[", "'label'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.tfrecord_to_image.main": [[44, 92], ["os.path.isfile", "tensorflow.data.TFRecordDataset().map", "tf.data.TFRecordDataset().map.make_one_shot_iterator().get_next", "print", "tqdm.trange", "tensorflow.Session", "len", "plt.imsave", "tensorflow.data.TFRecordDataset", "tf.data.TFRecordDataset().map.make_one_shot_iterator", "sorted", "sess.run", "numpy.asarray", "images.append", "labels.append", "str", "sum", "numpy.asarray", "str().zfill", "glob.glob", "len", "str", "str", "len"], "function", ["None"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "assert", "os", ".", "path", ".", "isfile", "(", "FLAGS", ".", "tfrecord", ")", ",", "FLAGS", ".", "tfrecord", "+", "\" not found. Please provide a dataset that has been initialized.\"", "\n", "# def unflatten(images):", "\n", "#     return np.transpose(images.reshape((images.shape[0], 3, 32, 32)),", "\n", "#                         [0, 2, 3, 1])", "\n", "\n", "# with tempfile.NamedTemporaryFile() as f:", "\n", "#     request.urlretrieve(\"https://www.cs.toronto.edu/~kriz/cifar-10-matlab.tar.gz\", f.name)", "\n", "#     tar = tarfile.open(fileobj=f)", "\n", "#     train_data_batches, train_data_labels = [], []", "\n", "#     for batch in range(1, 6):", "\n", "#         data_dict = scipy.io.loadmat(tar.extractfile(", "\n", "#             'cifar-10-batches-mat/data_batch_{}.mat'.format(batch)))", "\n", "#         train_data_batches.append(data_dict['data'])", "\n", "#         train_data_labels.append(data_dict['labels'].flatten())", "\n", "#     train_set = {'images': np.concatenate(train_data_batches, axis=0),", "\n", "#                  'labels': np.concatenate(train_data_labels, axis=0)}", "\n", "#     data_dict = scipy.io.loadmat(tar.extractfile(", "\n", "#         'cifar-10-batches-mat/test_batch.mat'))", "\n", "#     test_set = {'images': data_dict['data'],", "\n", "#                 'labels': data_dict['labels'].flatten()}", "\n", "\n", "#     train_set['images'] = unflatten(train_set['images'])", "\n", "\n", "#     for index in tqdm.tqdm(range(train_set['images'].shape[0])):", "\n", "#         im = Image.fromarray(np.asarray(train_set['images'][index, :, :, :]), mode='RGB')", "\n", "#         im.save(FLAGS.save_path + str(index).zfill(len(str(train_set['images'].shape[0]))) + ", "\n", "#             \"_\" + str(train_set['labels'][index]) + \".png\")", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "sorted", "(", "sum", "(", "[", "glob", ".", "glob", "(", "FLAGS", ".", "tfrecord", ")", "]", ",", "[", "]", ")", ")", ")", ".", "map", "(", "get_info", ",", "4", ")", "\n", "data", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "images", "=", "[", "]", "\n", "labels", "=", "[", "]", "\n", "\n", "with", "tf", ".", "Session", "(", ")", "as", "sess", ":", "\n", "        ", "try", ":", "\n", "            ", "while", "True", ":", "\n", "                ", "img", ",", "label", "=", "sess", ".", "run", "(", "data", ")", "\n", "img", "=", "np", ".", "asarray", "(", "img", ",", "dtype", "=", "np", ".", "intc", ")", "\n", "images", ".", "append", "(", "img", ")", "\n", "labels", ".", "append", "(", "np", ".", "asarray", "(", "label", ",", "dtype", "=", "np", ".", "intc", ")", ")", "\n", "", "", "except", ":", "\n", "            ", "pass", "\n", "", "", "print", "(", "images", "[", "0", "]", ".", "shape", ")", "\n", "for", "index", "in", "tqdm", ".", "trange", "(", "len", "(", "labels", ")", ")", ":", "\n", "        ", "import", "matplotlib", ".", "pyplot", "as", "plt", "\n", "path", "=", "FLAGS", ".", "save_path", "+", "str", "(", "index", ")", ".", "zfill", "(", "len", "(", "str", "(", "len", "(", "labels", ")", ")", ")", ")", "+", "\"_\"", "+", "str", "(", "labels", "[", "index", "]", ")", "+", "\".png\"", "\n", "plt", ".", "imsave", "(", "path", ",", "images", "[", "index", "]", ")", "\n", "#im = Image.fromarray(images[index], mode='RGB')", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_split.get_class": [[43, 45], ["tensorflow.parse_single_example", "tensorflow.FixedLenFeature"], "function", ["None"], ["def", "get_class", "(", "serialized_example", ")", ":", "\n", "    ", "return", "tf", ".", "parse_single_example", "(", "serialized_example", ",", "features", "=", "{", "'label'", ":", "tf", ".", "FixedLenFeature", "(", "[", "]", ",", "tf", ".", "int64", ")", "}", ")", "[", "'label'", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.create_split.main": [[47, 186], ["argv.pop", "any", "os.path.exists", "collections.defaultdict", "print", "tensorflow.data.TFRecordDataset", "dataset.map().batch.map().batch", "dataset.map().batch.make_one_shot_iterator().get_next", "print", "print", "len", "numpy.array", "np.array.max", "print", "numpy.zeros", "print", "print", "frozenset", "print", "numpy.zeros", "os.makedirs", "print", "FileNotFoundError", "FileExistsError", "set", "numpy.array", "numpy.random.seed", "range", "range", "range", "open().read", "frozenset", "os.path.dirname", "tensorflow.python_io.TFRecordWriter", "tensorflow.python_io.TFRecordWriter", "loop.close", "str", "open", "writer.write", "dataset.map().batch.map", "dataset.map().batch.make_one_shot_iterator", "tensorflow.Session", "tqdm.tqdm", "len", "min", "max", "range", "numpy.random.shuffle", "numpy.argmax", "frozenset.append", "int", "list", "range", "tqdm.trange", "tensorflow.python_io.tf_record_iterator", "json.dumps", "os.path.exists", "session.run", "t.update", "range", "collections.defaultdict.keys", "collections.defaultdict.keys", "open", "map", "loop.update", "unlabel.append", "writer_unlabel.write", "dict", "id_class.append", "frozenset.append", "os.path.join", "[].split", "writer_label.write", "class_data[].append", "class_id[].append", "max", "print", "numpy.argmax", "sorted", "np.zeros.max", "class_data[].pop", "unlabel.append", "writer_unlabel.write", "open().read.split", "max", "np.zeros.max"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.layers.PData.update"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "assert", "FLAGS", ".", "label_split_size", "and", "FLAGS", ".", "label_split_size", ">", "0", "\n", "if", "FLAGS", ".", "custom", ":", "\n", "        ", "assert", "(", "FLAGS", ".", "label_size", ">=", "FLAGS", ".", "label_split_size", ")", ",", "\"The size of labeled images in the split cannot exceed the total number of labeled \\\n            images in the dataset.\"", "\n", "\n", "", "argv", ".", "pop", "(", "0", ")", "\n", "if", "any", "(", "not", "os", ".", "path", ".", "exists", "(", "f", ")", "for", "f", "in", "argv", "[", "1", ":", "]", ")", ":", "\n", "        ", "raise", "FileNotFoundError", "(", "argv", "[", "1", ":", "]", ")", "\n", "", "target", "=", "'%s.%d@%d'", "%", "(", "argv", "[", "0", "]", ",", "FLAGS", ".", "seed", ",", "FLAGS", ".", "label_split_size", ")", "\n", "if", "os", ".", "path", ".", "exists", "(", "target", ")", ":", "\n", "        ", "raise", "FileExistsError", "(", "'For safety overwriting is not allowed'", ",", "target", ")", "\n", "\n", "", "input_files", "=", "argv", "[", "1", ":", "]", "\n", "count", "=", "0", "\n", "id_class", "=", "[", "]", "\n", "class_id", "=", "defaultdict", "(", "list", ")", "\n", "\n", "print", "(", "'Computing class distribution'", ")", "\n", "dataset", "=", "tf", ".", "data", ".", "TFRecordDataset", "(", "input_files", ")", "\n", "dataset", "=", "dataset", ".", "map", "(", "get_class", ",", "4", ")", ".", "batch", "(", "1", "<<", "10", ")", "\n", "it", "=", "dataset", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "try", ":", "\n", "# Store each image in a dict by its class number and image id.", "\n", "        ", "with", "tf", ".", "Session", "(", ")", "as", "session", ",", "tqdm", "(", "leave", "=", "False", ")", "as", "t", ":", "\n", "            ", "while", "1", ":", "\n", "                ", "old_count", "=", "count", "\n", "for", "i", "in", "session", ".", "run", "(", "it", ")", ":", "\n", "                    ", "id_class", ".", "append", "(", "i", ")", "\n", "\n", "# In a custom dataset, if the count has exceeded the total_size", "\n", "# of the labeled dataset, the remaining images are unlabeled images.", "\n", "if", "count", "<", "FLAGS", ".", "label_size", "or", "not", "FLAGS", ".", "custom", ":", "\n", "                        ", "class_id", "[", "i", "]", ".", "append", "(", "count", ")", "\n", "\n", "", "count", "+=", "1", "\n", "", "t", ".", "update", "(", "count", "-", "old_count", ")", "\n", "", "", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "        ", "pass", "\n", "", "print", "(", "'%d records found'", "%", "count", ")", "\n", "print", "(", "set", "(", "id_class", ")", ")", "\n", "\n", "nclass", "=", "len", "(", "class_id", ")", "\n", "train_stats", "=", "np", ".", "array", "(", "[", "len", "(", "class_id", "[", "i", "]", ")", "for", "i", "in", "range", "(", "nclass", ")", "]", ",", "np", ".", "float64", ")", "\n", "train_stats", "/=", "train_stats", ".", "max", "(", ")", "\n", "\n", "if", "'stl10'", "in", "argv", "[", "1", "]", ":", "\n", "# All of the unlabeled data is given label 0, but we know that", "\n", "# STL has equally distributed data among the 10 classes.", "\n", "        ", "train_stats", "[", ":", "]", "*=", "0", "\n", "train_stats", "[", ":", "]", "+=", "1", "\n", "\n", "# Compute the class distribution statistics for the labeled part of the dataset.", "\n", "", "print", "(", "'  Stats'", ",", "' '", ".", "join", "(", "[", "'%.2f'", "%", "(", "100", "*", "x", ")", "for", "x", "in", "train_stats", "]", ")", ")", "\n", "assert", "min", "(", "class_id", ".", "keys", "(", ")", ")", "==", "0", "and", "max", "(", "class_id", ".", "keys", "(", ")", ")", "==", "(", "nclass", "-", "1", ")", "\n", "class_id", "=", "[", "np", ".", "array", "(", "class_id", "[", "i", "]", ",", "dtype", "=", "np", ".", "int64", ")", "for", "i", "in", "range", "(", "nclass", ")", "]", "\n", "\n", "if", "FLAGS", ".", "seed", ":", "\n", "        ", "np", ".", "random", ".", "seed", "(", "FLAGS", ".", "seed", ")", "\n", "for", "i", "in", "range", "(", "nclass", ")", ":", "\n", "            ", "np", ".", "random", ".", "shuffle", "(", "class_id", "[", "i", "]", ")", "\n", "\n", "# Distribute labels to match the input distribution.", "\n", "", "", "npos", "=", "np", ".", "zeros", "(", "nclass", ",", "np", ".", "int64", ")", "\n", "label", "=", "[", "]", "\n", "print", "(", "npos", ")", "\n", "\n", "if", "FLAGS", ".", "class_balance", ":", "\n", "        ", "c", "=", "0", "\n", "for", "i", "in", "range", "(", "FLAGS", ".", "label_split_size", ")", ":", "\n", "            ", "if", "c", ">", "nclass", "-", "1", ":", "\n", "                ", "c", "=", "0", "\n", "", "while", "True", ":", "\n", "                ", "try", ":", "\n", "                    ", "label", ".", "append", "(", "class_id", "[", "c", "]", "[", "npos", "[", "c", "]", "]", ")", "\n", "npos", "[", "c", "]", "+=", "1", "\n", "c", "+=", "1", "\n", "break", "\n", "", "except", ":", "\n", "                    ", "if", "c", ">", "nclass", "-", "1", ":", "\n", "                        ", "c", "=", "0", "\n", "", "else", ":", "\n", "                        ", "c", "+=", "1", "\n", "", "continue", "\n", "", "", "", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "FLAGS", ".", "label_split_size", ")", ":", "\n", "            ", "c", "=", "np", ".", "argmax", "(", "train_stats", "-", "npos", "/", "max", "(", "npos", ".", "max", "(", ")", ",", "1", ")", ")", "\n", "label", ".", "append", "(", "class_id", "[", "c", "]", "[", "npos", "[", "c", "]", "]", ")", "\n", "npos", "[", "c", "]", "+=", "1", "\n", "\n", "", "", "print", "(", "npos", ")", "\n", "del", "npos", ",", "class_id", "\n", "\n", "label", "=", "frozenset", "(", "[", "int", "(", "x", ")", "for", "x", "in", "label", "]", ")", "\n", "if", "'stl10'", "in", "argv", "[", "1", "]", "and", "FLAGS", ".", "label_split_size", "==", "1000", ":", "\n", "        ", "data", "=", "open", "(", "os", ".", "path", ".", "join", "(", "DATA_DIR", ",", "'stl10_fold_indices.txt'", ")", ",", "'r'", ")", ".", "read", "(", ")", "\n", "label", "=", "frozenset", "(", "list", "(", "map", "(", "int", ",", "data", ".", "split", "(", "'\\n'", ")", "[", "FLAGS", ".", "seed", "]", ".", "split", "(", ")", ")", ")", ")", "\n", "", "print", "(", "'Creating split in %s'", "%", "target", ")", "\n", "npos", "=", "np", ".", "zeros", "(", "nclass", ",", "np", ".", "int64", ")", "\n", "class_data", "=", "[", "[", "]", "for", "_", "in", "range", "(", "nclass", ")", "]", "\n", "unlabel", "=", "[", "]", "\n", "unlabel_writes", "=", "0", "\n", "label_writes", "=", "0", "\n", "os", ".", "makedirs", "(", "os", ".", "path", ".", "dirname", "(", "target", ")", ",", "exist_ok", "=", "True", ")", "\n", "with", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "target", "+", "'-label.tfrecord'", ")", "as", "writer_label", ",", "tf", ".", "python_io", ".", "TFRecordWriter", "(", "\n", "target", "+", "'-unlabel.tfrecord'", ")", "as", "writer_unlabel", ":", "\n", "        ", "pos", ",", "loop", "=", "0", ",", "trange", "(", "count", ",", "desc", "=", "'Writing records'", ")", "\n", "for", "input_file", "in", "input_files", ":", "\n", "            ", "for", "record", "in", "tf", ".", "python_io", ".", "tf_record_iterator", "(", "input_file", ")", ":", "\n", "                ", "if", "pos", "in", "label", ":", "\n", "                    ", "if", "pos", "in", "[", "0", ",", "1", ",", "2", ",", "3", ",", "4", "]", ":", "\n", "                        ", "print", "(", ")", "\n", "", "writer_label", ".", "write", "(", "record", ")", "\n", "label_writes", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "class_data", "[", "id_class", "[", "pos", "]", "]", ".", "append", "(", "(", "pos", ",", "record", ")", ")", "\n", "while", "True", ":", "\n", "                        ", "c", "=", "np", ".", "argmax", "(", "train_stats", "-", "npos", "/", "max", "(", "npos", ".", "max", "(", ")", ",", "1", ")", ")", "\n", "if", "class_data", "[", "c", "]", ":", "\n", "                            ", "p", ",", "v", "=", "class_data", "[", "c", "]", ".", "pop", "(", "0", ")", "\n", "unlabel", ".", "append", "(", "p", ")", "\n", "writer_unlabel", ".", "write", "(", "v", ")", "\n", "unlabel_writes", "+=", "1", "\n", "npos", "[", "c", "]", "+=", "1", "\n", "", "else", ":", "\n", "                            ", "break", "\n", "", "", "", "pos", "+=", "1", "\n", "loop", ".", "update", "(", ")", "\n", "", "", "for", "remain", "in", "class_data", ":", "\n", "            ", "for", "p", ",", "v", "in", "remain", ":", "\n", "                ", "unlabel", ".", "append", "(", "p", ")", "\n", "writer_unlabel", ".", "write", "(", "v", ")", "\n", "unlabel_writes", "+=", "1", "\n", "", "", "loop", ".", "close", "(", ")", "\n", "\n", "", "print", "(", "label_writes", ",", "unlabel_writes", ",", "str", "(", "label_writes", "+", "unlabel_writes", ")", ")", "\n", "with", "open", "(", "target", "+", "'-map.json'", ",", "'w'", ")", "as", "writer", ":", "\n", "        ", "writer", ".", "write", "(", "json", ".", "dumps", "(", "\n", "dict", "(", "label", "=", "sorted", "(", "label", ")", ",", "unlabel", "=", "unlabel", ")", ",", "indent", "=", "2", ",", "sort_keys", "=", "True", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.check_split.to_byte": [[53, 55], ["tensorflow.to_int32", "tensorflow.round"], "function", ["None"], ["def", "to_byte", "(", "d", ":", "dict", ")", ":", "\n", "    ", "return", "tf", ".", "to_int32", "(", "tf", ".", "round", "(", "127.5", "*", "(", "d", "[", "'image'", "]", "+", "1", ")", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.check_split.collect_hashes": [[57, 69], ["data.map().batch().prefetch().make_one_shot_iterator().get_next.map().batch().prefetch().make_one_shot_iterator().get_next", "set", "tqdm.trange", "data.map().batch().prefetch().make_one_shot_iterator().get_next.map().batch().prefetch().make_one_shot_iterator", "sess.run", "set.add", "hasher().digest", "data.map().batch().prefetch().make_one_shot_iterator().get_next.map().batch().prefetch", "hasher", "data.map().batch().prefetch().make_one_shot_iterator().get_next.map().batch", "data.map().batch().prefetch().make_one_shot_iterator().get_next.map"], "function", ["None"], ["", "def", "collect_hashes", "(", "sess", ",", "group", ",", "data", ")", ":", "\n", "    ", "data", "=", "data", ".", "map", "(", "to_byte", ")", ".", "batch", "(", "FLAGS", ".", "batch", ")", ".", "prefetch", "(", "1", ")", ".", "make_one_shot_iterator", "(", ")", ".", "get_next", "(", ")", "\n", "hashes", "=", "set", "(", ")", "\n", "hasher", "=", "hashlib", ".", "sha512", "\n", "for", "_", "in", "trange", "(", "0", ",", "FLAGS", ".", "samples", ",", "FLAGS", ".", "batch", ",", "desc", "=", "'Building hashes for %s'", "%", "group", ",", "leave", "=", "False", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "batch", "=", "sess", ".", "run", "(", "data", ")", "\n", "", "except", "tf", ".", "errors", ".", "OutOfRangeError", ":", "\n", "            ", "break", "\n", "", "for", "img", "in", "batch", ":", "\n", "            ", "hashes", ".", "add", "(", "hasher", "(", "img", ")", ".", "digest", "(", ")", ")", "\n", "", "", "return", "hashes", "\n", "\n"]], "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.check_split.main": [[71, 87], ["libml.utils.setup_tf", "print", "print", "enumerate", "tensorflow.Session", "print", "check_split.collect_hashes", "check_split.collect_hashes", "check_split.collect_hashes", "check_split.collect_hashes", "tuple", "len", "libml.utils.get_config", "tuple"], "function", ["home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.setup_tf", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.check_split.collect_hashes", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.check_split.collect_hashes", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.check_split.collect_hashes", "home.repos.pwc.inspect_result.uizard-technologies_realmix.scripts.check_split.collect_hashes", "home.repos.pwc.inspect_result.uizard-technologies_realmix.libml.utils.get_config"], ["", "def", "main", "(", "argv", ")", ":", "\n", "    ", "del", "argv", "\n", "utils", ".", "setup_tf", "(", ")", "\n", "dataset", "=", "DATASETS", "[", "FLAGS", ".", "dataset", "]", "(", ")", "\n", "with", "tf", ".", "Session", "(", "config", "=", "utils", ".", "get_config", "(", ")", ")", "as", "sess", ":", "\n", "        ", "hashes", "=", "(", "collect_hashes", "(", "sess", ",", "'labeled'", ",", "dataset", ".", "eval_labeled", ")", ",", "\n", "collect_hashes", "(", "sess", ",", "'unlabeled'", ",", "dataset", ".", "eval_unlabeled", ")", ",", "\n", "collect_hashes", "(", "sess", ",", "'validation'", ",", "dataset", ".", "valid", ")", ",", "\n", "collect_hashes", "(", "sess", ",", "'test'", ",", "dataset", ".", "test", ")", ")", "\n", "", "print", "(", "'Overlap matrix (should be an almost perfect diagonal matrix with counts).'", ")", "\n", "groups", "=", "'labeled unlabeled validation test'", ".", "split", "(", ")", "\n", "fmt", "=", "'%-10s %10s %10s %10s %10s'", "\n", "print", "(", "fmt", "%", "tuple", "(", "[", "''", "]", "+", "groups", ")", ")", "\n", "for", "p", ",", "x", "in", "enumerate", "(", "hashes", ")", ":", "\n", "        ", "overlaps", "=", "[", "len", "(", "x", "&", "y", ")", "for", "y", "in", "hashes", "]", "\n", "print", "(", "fmt", "%", "tuple", "(", "[", "groups", "[", "p", "]", "]", "+", "overlaps", ")", ")", "\n", "\n"]]}