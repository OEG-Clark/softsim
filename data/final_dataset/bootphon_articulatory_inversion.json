{"home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_arti.preprocess_my_wav_files": [[38, 77], ["os.path.join", "int", "int", "os.listdir", "os.path.exists", "os.mkdir", "librosa.load", "Preprocessing.tools_preprocessing.get_delta_features", "Preprocessing.tools_preprocessing.get_delta_features", "numpy.concatenate", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "numpy.save", "os.path.join", "os.path.join", "filename.endswith", "os.path.join", "numpy.max", "librosa.feature.mfcc", "np.concatenate.std", "os.path.join", "np.concatenate.mean", "range", "len"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features"], ["def", "preprocess_my_wav_files", "(", "wav_folder", ",", "mfcc_folder", ",", "Nmax", "=", "0", ")", ":", "\n", "    ", "\"\"\"\n    Read all the wav files in \"my_wav_files_for_inversion\" and preprocess them the extract their acoustic features,\n    so that it can be used as input of the my_ac2art model.\n    Save the mfcc in \"my_mfcc_files_for_inversion\" , with the same filename as the corresponding wav.\n    Warning : the acoustic features are usually normalized at the speaker level when enough data is available for\n    the speaker.\n    We let future users modify the code to apply this normalization (coeff = (coeff-meancoeff)/stdcoeff  )\n    \"\"\"", "\n", "path_wav", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "wav_folder", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "mfcc_folder", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "mfcc_folder", ")", ")", "\n", "", "frame_time", "=", "25", "/", "1000", "\n", "hop_time", "=", "10", "/", "1000", "\n", "sampling_rate_wav_wanted", "=", "16000", "\n", "hop_length", "=", "int", "(", "hop_time", "*", "sampling_rate_wav_wanted", ")", "\n", "frame_length", "=", "int", "(", "frame_time", "*", "sampling_rate_wav_wanted", ")", "\n", "window", "=", "5", "\n", "n_coeff", "=", "13", "\n", "wav_files", "=", "os", ".", "listdir", "(", "path_wav", ")", "\n", "if", "Nmax", ">", "0", ":", "\n", "        ", "wav_files", "=", "wav_files", "[", ":", "Nmax", "]", "\n", "", "for", "filename", "in", "wav_files", ":", "\n", "        ", "if", "not", "filename", ".", "endswith", "(", "'.wav'", ")", ":", "\n", "            ", "continue", "\n", "", "filename", "=", "filename", "[", ":", "-", "4", "]", "#remove extension", "\n", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "os", ".", "path", ".", "join", "(", "path_wav", ",", "filename", "+", "\".wav\"", ")", ",", "sr", "=", "sampling_rate_wav_wanted", ")", "# chargement de donn\u00e9es", "\n", "wav", "=", "0.5", "*", "wav", "/", "np", ".", "max", "(", "wav", ")", "\n", "mfcc", "=", "librosa", ".", "feature", ".", "mfcc", "(", "y", "=", "wav", ",", "sr", "=", "sr", ",", "n_mfcc", "=", "n_coeff", ",", "n_fft", "=", "frame_length", ",", "hop_length", "=", "hop_length", ")", ".", "T", "\n", "dyna_features", "=", "get_delta_features", "(", "mfcc", ")", "\n", "dyna_features_2", "=", "get_delta_features", "(", "dyna_features", ")", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "(", "mfcc", ",", "dyna_features", ",", "dyna_features_2", ")", ",", "axis", "=", "1", ")", "\n", "padding", "=", "np", ".", "zeros", "(", "(", "window", ",", "mfcc", ".", "shape", "[", "1", "]", ")", ")", "\n", "frames", "=", "np", ".", "concatenate", "(", "[", "padding", ",", "mfcc", ",", "padding", "]", ")", "\n", "full_window", "=", "1", "+", "2", "*", "window", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "[", "frames", "[", "j", ":", "j", "+", "len", "(", "mfcc", ")", "]", "for", "j", "in", "range", "(", "full_window", ")", "]", ",", "axis", "=", "1", ")", "# add context", "\n", "# normalize", "\n", "mfcc", "=", "(", "mfcc", "-", "mfcc", ".", "mean", "(", "axis", "=", "0", ",", "keepdims", "=", "True", ")", ")", "/", "mfcc", ".", "std", "(", "axis", "=", "0", ",", "keepdims", "=", "True", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "mfcc_folder", ",", "filename", ")", ",", "mfcc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_arti.predictions_arti": [[79, 116], ["Training.model.my_ac2art_model", "model.double.double", "os.path.join", "torch.load", "model.double.load_state_dict", "os.listdir", "os.path.exists", "os.mkdir", "os.path.join", "numpy.load", "torch.from_numpy().view", "model.double.", "model.detach().numpy().reshape", "numpy.save", "os.path.join", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "torch.from_numpy", "model.detach().numpy", "model.detach"], "function", ["None"], ["", "", "def", "predictions_arti", "(", "model_name", ",", "mfcc_folder", "=", "\"my_mfcc_files_for_inversion\"", ",", "\n", "ema_folder", "=", "\"my_articulatory_prediction\"", ",", "output_dim", "=", "18", ")", ":", "\n", "    ", "\"\"\"\n    :param model_name: name of model we want to use for the articulatory predictions\n    with the weights in model_name, this script perform articulatory predictions corresponding to the wav files\n    it takes as input the mfcc features already calculated\n    the arti predictions are saved my \"my_articulatory_prediction\" as np array (K,18)\n    \"\"\"", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "ema_folder", ",", "model_name", ")", ")", ":", "\n", "        ", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "ema_folder", ")", ")", ":", "\n", "            ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "ema_folder", ")", ")", "\n", "", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "ema_folder", ",", "model_name", ")", ")", "\n", "\n", "", "hidden_dim", "=", "300", "\n", "input_dim", "=", "429", "\n", "batch_size", "=", "1", "\n", "output_dim", "=", "output_dim", "\n", "\n", "filter_type", "=", "\"fix\"", "\n", "batch_norma", "=", "False", "# future work : read from model name if true or false", "\n", "model", "=", "my_ac2art_model", "(", "hidden_dim", "=", "hidden_dim", ",", "input_dim", "=", "input_dim", ",", "output_dim", "=", "output_dim", ",", "\n", "batch_size", "=", "batch_size", ",", "cuda_avail", "=", "False", ",", "name_file", "=", "model_name", ",", "\n", "filter_type", "=", "filter_type", ",", "batch_norma", "=", "batch_norma", ")", "\n", "model", "=", "model", ".", "double", "(", ")", "\n", "file_weights", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Training\"", ",", "\"saved_models\"", ",", "model_name", "+", "\".txt\"", ")", "\n", "loaded_state", "=", "torch", ".", "load", "(", "file_weights", ",", "map_location", "=", "\"cpu\"", ")", "\n", "model", ".", "load_state_dict", "(", "loaded_state", ")", "\n", "\n", "all_my_mfcc_files", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "mfcc_folder", ")", ")", "\n", "\n", "for", "mfcc_file", "in", "all_my_mfcc_files", ":", "\n", "        ", "mfcc", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "mfcc_folder", ",", "mfcc_file", ")", ")", "\n", "mfcc_torch", "=", "torch", ".", "from_numpy", "(", "mfcc", ")", ".", "view", "(", "1", ",", "-", "1", ",", "input_dim", ")", "\n", "ema_torch", "=", "model", "(", "mfcc_torch", ")", "\n", "ema", "=", "ema_torch", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "(", "-", "1", ",", "output_dim", ")", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "ema_folder", ",", "model_name", ",", "mfcc_file", ")", ",", "ema", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.convert_mfccs_to_fea.write_fea_file": [[15, 30], ["numpy.zeros", "open", "f.writelines", "range", "range", "os.path.join", "str", "len"], "function", ["None"], ["def", "write_fea_file", "(", "prediction", ",", "filename", ")", ":", "\n", "    ", "\"\"\"\n    :param prediction: array with ema prediction for 1 sentence\n    :param filename:  name of the file with the sentence (will be the name of the fea)\n    save as a fea file the arti representations\n    \"\"\"", "\n", "prediction_with_time", "=", "np", ".", "zeros", "(", "(", "prediction", ".", "shape", "[", "0", "]", ",", "prediction", ".", "shape", "[", "1", "]", "+", "1", ")", ")", "\n", "prediction_with_time", "[", ":", ",", "1", ":", "]", "=", "prediction", "\n", "frame_hop", "=", "0.010", "\n", "frame_lenght", "=", "0.025", "\n", "all_times", "=", "[", "frame_lenght", "/", "2", "+", "frame_hop", "*", "i", "for", "i", "in", "range", "(", "prediction", ".", "shape", "[", "0", "]", ")", "]", "\n", "prediction_with_time", "[", ":", ",", "0", "]", "=", "all_times", "\n", "lines", "=", "[", "' '", ".", "join", "(", "str", "(", "ema", ")", "for", "ema", "in", "prediction_with_time", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "prediction_with_time", ")", ")", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "\"fea_ZS2017_1s_mfccs\"", ",", "filename", "[", ":", "-", "4", "]", "+", "\".fea\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "writelines", "(", "\"%s\\n\"", "%", "l", "for", "l", "in", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_ZS2017.prediction_arti_ZS": [[27, 51], ["print", "print", "print", "print", "os.listdir", "Predictions_arti.predictions_arti.preprocess_my_wav_files", "Predictions_arti.predictions_arti.predictions_arti", "os.path.join", "os.path.exists", "os.mkdir", "numpy.load", "predictions_ZS2017.write_fea_file", "os.path.join", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_arti.preprocess_my_wav_files", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_arti.predictions_arti", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_ZS2017.write_fea_file"], ["def", "prediction_arti_ZS", "(", "name_model", ",", "wav_folder", ",", "mfcc_folder", ",", "ema_folder", ",", "fea_folder", ",", "output_dim", "=", "18", ",", "Nmax", "=", "0", ",", "prepro_done", "=", "False", ",", "predic_done", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param name_model: name of the model we want to predict the trajectories with\n    :param Nmax: if we dont want to predict the traj of ALL wav files, precise how many\n    arti predictions for the wav files of ZS2017 with the asked model.\n    Also writes fea files in order to run the abx test\n    \"\"\"", "\n", "print", "(", "'Preprocessing...'", ")", "\n", "if", "not", "prepro_done", ":", "\n", "        ", "preprocess_my_wav_files", "(", "wav_folder", "=", "wav_folder", ",", "mfcc_folder", "=", "mfcc_folder", ",", "Nmax", "=", "Nmax", ")", "\n", "", "print", "(", "'Preprocessed done!'", ")", "\n", "print", "(", "'Predicting...'", ")", "\n", "if", "not", "predic_done", ":", "\n", "        ", "predictions_arti", "(", "model_name", "=", "name_model", ",", "mfcc_folder", "=", "mfcc_folder", ",", "ema_folder", "=", "ema_folder", ",", "output_dim", "=", "output_dim", ")", "\n", "", "print", "(", "'Predicting done!'", ")", "\n", "filenames", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "ema_folder", ",", "name_model", ")", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "\"fea_files\"", ",", "fea_folder", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "\"fea_files\"", ",", "fea_folder", ")", ")", "\n", "", "if", "Nmax", ">", "0", ":", "\n", "        ", "filenames", "=", "filenames", "[", ":", "Nmax", "]", "\n", "\n", "", "for", "filename", "in", "filenames", ":", "\n", "        ", "arti_pred", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "ema_folder", ",", "name_model", ",", "filename", ")", ")", "\n", "write_fea_file", "(", "arti_pred", ",", "filename", ",", "fea_folder", "=", "fea_folder", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_ZS2017.write_fea_file": [[53, 68], ["numpy.zeros", "open", "f.writelines", "range", "range", "os.path.join", "str", "len"], "function", ["None"], ["", "", "def", "write_fea_file", "(", "prediction", ",", "filename", ",", "fea_folder", ")", ":", "\n", "    ", "\"\"\"\n    :param prediction: array with ema prediction for 1 sentence\n    :param filename:  name of the file with the sentence (will be the name of the fea)\n    save as a fea file the arti representations\n    \"\"\"", "\n", "prediction_with_time", "=", "np", ".", "zeros", "(", "(", "prediction", ".", "shape", "[", "0", "]", ",", "prediction", ".", "shape", "[", "1", "]", "+", "1", ")", ")", "\n", "prediction_with_time", "[", ":", ",", "1", ":", "]", "=", "prediction", "\n", "frame_hop", "=", "0.010", "\n", "frame_lenght", "=", "0.025", "\n", "all_times", "=", "[", "frame_lenght", "/", "2", "+", "frame_hop", "*", "i", "for", "i", "in", "range", "(", "prediction", ".", "shape", "[", "0", "]", ")", "]", "\n", "prediction_with_time", "[", ":", ",", "0", "]", "=", "all_times", "\n", "lines", "=", "[", "' '", ".", "join", "(", "str", "(", "ema", ")", "for", "ema", "in", "prediction_with_time", "[", "i", "]", ")", "for", "i", "in", "range", "(", "len", "(", "prediction_with_time", ")", ")", "]", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Predictions_arti\"", ",", "\"fea_files\"", ",", "fea_folder", ",", "filename", "[", ":", "-", "4", "]", "+", "\".fea\"", ")", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "f", ".", "writelines", "(", "\"%s\\n\"", "%", "l", "for", "l", "in", "lines", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_ZS2017.rename": [[69, 73], ["os.listdir", "os.rename", "os.path.join", "os.path.join"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Predictions_arti.predictions_ZS2017.rename"], ["", "", "def", "rename", "(", "folder", ")", ":", "\n", "    ", "filenames", "=", "os", ".", "listdir", "(", "folder", ")", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "os", ".", "rename", "(", "os", ".", "path", ".", "join", "(", "folder", ",", "filename", ")", ",", "os", ".", "path", ".", "join", "(", "folder", ",", "filename", "[", ":", "-", "8", "]", "+", "'.fea'", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.pytorchtools.EarlyStopping.__init__": [[31, 48], ["None"], "methods", ["None"], ["def", "__init__", "(", "self", ",", "speaker", ",", "patience", "=", "7", ",", "verbose", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        # TODO\n        Args:\n            patience (int): How long to wait after last time validation loss improved.\n                            Default: 7\n            verbose (bool): If True, prints a message for each validation loss improvement. \n                            Default: False\n        \"\"\"", "\n", "self", ".", "speaker", "=", "speaker", "\n", "self", ".", "patience", "=", "patience", "\n", "self", ".", "verbose", "=", "verbose", "\n", "self", ".", "counter", "=", "0", "\n", "self", ".", "best_score", "=", "None", "\n", "self", ".", "early_stop", "=", "False", "\n", "self", ".", "val_loss_min", "=", "np", ".", "Inf", "\n", "self", ".", "epoch", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.pytorchtools.EarlyStopping.__call__": [[49, 65], ["pytorchtools.EarlyStopping.save_checkpoint", "print", "pytorchtools.EarlyStopping.save_checkpoint"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.pytorchtools.EarlyStopping.save_checkpoint", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.pytorchtools.EarlyStopping.save_checkpoint"], ["", "def", "__call__", "(", "self", ",", "val_loss", ",", "model", ")", ":", "\n", "# TODO", "\n", "        ", "score", "=", "-", "val_loss", "\n", "\n", "if", "self", ".", "best_score", "is", "None", ":", "\n", "            ", "self", ".", "best_score", "=", "score", "\n", "self", ".", "save_checkpoint", "(", "val_loss", ",", "model", ")", "\n", "", "elif", "score", "<", "self", ".", "best_score", ":", "\n", "            ", "self", ".", "counter", "+=", "1", "\n", "print", "(", "f'EarlyStopping counter: {self.counter} out of {self.patience}'", ")", "\n", "if", "self", ".", "counter", ">=", "self", ".", "patience", ":", "\n", "                ", "self", ".", "early_stop", "=", "True", "\n", "", "", "else", ":", "\n", "            ", "self", ".", "best_score", "=", "score", "\n", "self", ".", "save_checkpoint", "(", "val_loss", ",", "model", ")", "\n", "self", ".", "counter", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.pytorchtools.EarlyStopping.save_checkpoint": [[66, 76], ["torch.save", "print", "model.state_dict", "os.path.join"], "methods", ["None"], ["", "", "def", "save_checkpoint", "(", "self", ",", "val_loss", ",", "model", ")", ":", "\n", "# TODO", "\n", "        ", "'''Saves model when validation loss decrease.'''", "\n", "if", "self", ".", "verbose", ":", "\n", "            ", "print", "(", "f'Validation loss decreased ({self.val_loss_min:.6f} --> {val_loss:.6f}).  Saving model ...'", ")", "\n", "#   print(\"name file\",model.name_file)", "\n", "#  torch.save(model.state_dict(), os.path.join(path_checkpoint,\"epoch_\"+str(self.epoch)+\".pt\"))", "\n", "", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "model", ".", "name_file", "+", "\".pt\"", ")", ")", "\n", "\n", "self", ".", "val_loss_min", "=", "val_loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames": [[25, 40], ["os.path.join", "os.path.dirname", "os.getcwd", "open().read().split", "open().read", "open", "os.path.join"], "function", ["None"], ["def", "load_filenames", "(", "speakers", ",", "part", "=", "[", "\"train\"", "]", ")", ":", "\n", "    ", "\"\"\"\n    :param speakers: list of speakers we want the filesets\n    :param part: list [\"train\",\"valid\",\"test\"] (or less) of part of fileset we want from the speakers\n    :return: a list of the filenames corresponding to the asked part for asked speakers\n    based on the fileset files already\n\n    \"\"\"", "\n", "path_files", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "getcwd", "(", ")", ")", ",", "\"Preprocessed_data\"", ",", "\"fileset\"", ")", "\n", "filenames", "=", "[", "]", "\n", "for", "speaker", "in", "speakers", ":", "\n", "        ", "for", "p", "in", "part", ":", "\n", "            ", "names", "=", "open", "(", "os", ".", "path", ".", "join", "(", "path_files", ",", "speaker", "+", "\"_\"", "+", "p", "+", "\".txt\"", ")", ",", "\"r\"", ")", ".", "read", "(", ")", ".", "split", "(", ")", "\n", "filenames", "=", "filenames", "+", "names", "\n", "", "", "return", "filenames", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc": [[42, 62], ["os.path.join", "os.path.dirname", "os.path.join", "numpy.load", "numpy.load", "x.append", "y.append", "os.getcwd", "os.path.join", "os.path.join", "s.lower", "filename.lower"], "function", ["None"], ["", "def", "load_np_ema_and_mfcc", "(", "filenames", ")", ":", "\n", "    ", "\"\"\"\n    :param filenames: list of files we want to load the ema and mfcc data\n    :return: x : the list of mfcc features,\n            y : the list of ema traj\n    Load the numpy arrays correspondign the ema and mfcc of the files in the list filenames\n    \"\"\"", "\n", "folder", "=", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "dirname", "(", "os", ".", "getcwd", "(", ")", ")", ",", "\"Preprocessed_data\"", ")", "\n", "x", "=", "[", "]", "\n", "y", "=", "[", "]", "\n", "speakers", "=", "[", "\"F01\"", ",", "\"F02\"", ",", "\"F03\"", ",", "\"F04\"", ",", "\"M01\"", ",", "\"M02\"", ",", "\"M03\"", ",", "\"M04\"", ",", "\"F1\"", ",", "\"F5\"", ",", "\"M1\"", ",", "\"M3\"", "\n", ",", "\"maps0\"", ",", "\"faet0\"", ",", "'mjjn0'", ",", "\"ffes0\"", ",", "\"MNGU0\"", ",", "\"fsew0\"", ",", "\"msak0\"", ",", "\"falh0\"", "]", "\n", "for", "filename", "in", "filenames", ":", "\n", "        ", "speaker", "=", "[", "s", "for", "s", "in", "speakers", "if", "s", ".", "lower", "(", ")", "in", "filename", ".", "lower", "(", ")", "]", "[", "0", "]", "# we can deduce the speaker from the filename", "\n", "files_path", "=", "os", ".", "path", ".", "join", "(", "folder", ",", "speaker", ")", "\n", "the_ema_file", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "files_path", ",", "\"ema_final\"", ",", "filename", "+", "\".npy\"", ")", ")", "\n", "the_mfcc_file", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "files_path", ",", "\"mfcc\"", ",", "filename", "+", "\".npy\"", ")", ")", "\n", "x", ".", "append", "(", "the_mfcc_file", ")", "\n", "y", ".", "append", "(", "the_ema_file", ")", "\n", "", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.memReport": [[63, 75], ["gc.get_objects", "print", "torch.is_tensor", "print", "type", "obj.size"], "function", ["None"], ["", "def", "memReport", "(", "all", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param all: show size of each obj\n    use if memory errors\n    \"\"\"", "\n", "nb_object", "=", "0", "\n", "for", "obj", "in", "gc", ".", "get_objects", "(", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "obj", ")", ":", "\n", "            ", "if", "all", ":", "\n", "                ", "print", "(", "type", "(", "obj", ")", ",", "obj", ".", "size", "(", ")", ")", "\n", "", "nb_object", "+=", "1", "\n", "", "", "print", "(", "'nb objects tensor'", ",", "nb_object", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.cpuStats": [[77, 88], ["print", "print", "print", "os.getpid", "psutil.Process", "print", "psutil.cpu_percent", "psutil.virtual_memory", "psutil.Process.memory_info"], "function", ["None"], ["", "def", "cpuStats", "(", ")", ":", "\n", "    ", "\"\"\"\n    use in case of memory errors\n    \"\"\"", "\n", "print", "(", "sys", ".", "version", ")", "\n", "print", "(", "psutil", ".", "cpu_percent", "(", ")", ")", "\n", "print", "(", "psutil", ".", "virtual_memory", "(", ")", ")", "# physical memory usage", "\n", "pid", "=", "os", ".", "getpid", "(", ")", "\n", "py", "=", "psutil", ".", "Process", "(", "pid", ")", "\n", "memoryUse", "=", "py", ".", "memory_info", "(", ")", "[", "0", "]", "/", "2.", "**", "30", "# memory use in GB...I think", "\n", "print", "(", "'memory GB:'", ",", "memoryUse", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_pearson": [[91, 119], ["y.sub", "y_pred.sub", "torch.sum", "torch.tensor", "torch.div", "torch.sum", "torch.mean", "torch.mean", "torch.sqrt", "torch.sqrt", "minim.to.to", "deno.to.to", "nume.to.to", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "criterion_pearson", "(", "y", ",", "y_pred", ",", "cuda_avail", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n    :param y: nparray (B,K,18) target trajectories of the batch (size B) , padded (K = maxlenght)\n    :param y_pred: nparray (B,K,18) predicted trajectories of the batch (size B), padded (K = maxlenght\n    :param cuda_avail: bool whether gpu is available\n    :param device: the device\n    :return: loss function for this prediction for loss = pearson correlation\n    for each pair of trajectories (target & predicted) we calculate the pearson correlation between the two\n    we sum all the pearson correlation to obtain the loss function\n    // Idea : integrate the range of the traj here, making the loss for each sentence as the weighted average of the\n    losses with weight proportional to the range of the traj (?)\n    \"\"\"", "\n", "y_1", "=", "y", ".", "sub", "(", "torch", ".", "mean", "(", "y", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "y_pred_1", "=", "y_pred", ".", "sub", "(", "torch", ".", "mean", "(", "y_pred", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "nume", "=", "torch", ".", "sum", "(", "y_1", "*", "y_pred_1", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# (B,1,18)", "\n", "deno", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "y_1", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "*", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "y_pred_1", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "# (B,1,18)", "\n", "\n", "minim", "=", "torch", ".", "tensor", "(", "0.000001", ",", "dtype", "=", "torch", ".", "float64", ")", "# avoid division by 0", "\n", "if", "cuda_avail", ":", "\n", "        ", "minim", "=", "minim", ".", "to", "(", "device", "=", "device", ")", "\n", "deno", "=", "deno", ".", "to", "(", "device", "=", "device", ")", "\n", "nume", "=", "nume", ".", "to", "(", "device", "=", "device", ")", "\n", "", "nume", "=", "nume", "+", "minim", "\n", "deno", "=", "deno", "+", "minim", "\n", "my_loss", "=", "torch", ".", "div", "(", "nume", ",", "deno", ")", "# (B,1,18)", "\n", "my_loss", "=", "torch", ".", "sum", "(", "my_loss", ")", "\n", "return", "-", "my_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_pearson_no_reduction": [[120, 140], ["y.sub", "y_pred.sub", "torch.sum", "torch.div", "torch.div.numpy", "torch.mean", "torch.mean", "torch.sqrt", "torch.sqrt", "torch.sum", "torch.sum"], "function", ["None"], ["", "def", "criterion_pearson_no_reduction", "(", "y", ",", "y_pred", ",", "cuda_avail", ",", "device", ")", ":", "\n", "    ", "\"\"\"\n        :param y: nparray (B,K,18) target trajectories of the batch (size B) , padded (K = maxlenght)\n        :param y_pred: nparray (B,K,18) predicted trajectories of the batch (size B), padded (K = maxlenght\n        :param cuda_avail: bool whether gpu is available\n        :param device: the device\n        :return: loss function for this prediction for loss = pearson correlation\n        for each pair of trajectories (target & predicted) we calculate the pearson correlation between the two\n        we sum all the pearson correlation to obtain the loss function\n        // Idea : integrate the range of the traj here, making the loss for each sentence as the weighted average of the\n        losses with weight proportional to the range of the traj (?)\n        \"\"\"", "\n", "y_1", "=", "y", ".", "sub", "(", "torch", ".", "mean", "(", "y", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "y_pred_1", "=", "y_pred", ".", "sub", "(", "torch", ".", "mean", "(", "y_pred", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "\n", "nume", "=", "torch", ".", "sum", "(", "y_1", "*", "y_pred_1", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", "# (B,1,18)", "\n", "deno", "=", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "y_1", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "*", "torch", ".", "sqrt", "(", "torch", ".", "sum", "(", "y_pred_1", "**", "2", ",", "dim", "=", "1", ",", "keepdim", "=", "True", ")", ")", "# (B,1,18)", "\n", "\n", "my_loss", "=", "torch", ".", "div", "(", "nume", ",", "deno", ")", "# (B,1,18)", "\n", "return", "my_loss", ".", "numpy", "(", ")", "\n", "#my_loss = torch.sum(my_loss)", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both": [[144, 156], ["torch.tensor", "torch.tensor", "torch.tensor", "float", "alpha.to.to", "multip.to.to", "compl.to.to", "float", "tools_learning.criterion_pearson", "torch.nn.MSELoss", "float"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_pearson"], ["", "def", "criterion_both", "(", "my_y", ",", "my_ypred", ",", "alpha", ",", "cuda_avail", ",", "device", ")", ":", "\n", "    ", "compl", "=", "torch", ".", "tensor", "(", "1.", "-", "float", "(", "alpha", ")", "/", "100.", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "alpha", "=", "torch", ".", "tensor", "(", "float", "(", "alpha", ")", "/", "100.", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "multip", "=", "torch", ".", "tensor", "(", "float", "(", "1000", ")", ",", "dtype", "=", "torch", ".", "float64", ")", "\n", "if", "cuda_avail", ":", "\n", "        ", "alpha", "=", "alpha", ".", "to", "(", "device", "=", "device", ")", "\n", "multip", "=", "multip", ".", "to", "(", "device", "=", "device", ")", "\n", "compl", "=", "compl", ".", "to", "(", "device", "=", "device", ")", "\n", "", "a", "=", "alpha", "*", "criterion_pearson", "(", "my_y", ",", "my_ypred", ",", "cuda_avail", ",", "device", ")", "*", "multip", "\n", "b", "=", "compl", "*", "torch", ".", "nn", ".", "MSELoss", "(", "reduction", "=", "'sum'", ")", "(", "my_y", ",", "my_ypred", ")", "\n", "new_loss", "=", "a", "+", "b", "\n", "return", "new_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.plot_filtre": [[158, 171], ["print", "scipy.signal.freqz", "matplotlib.plot", "matplotlib.title", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.show", "sum", "numpy.log10", "abs"], "function", ["None"], ["", "def", "plot_filtre", "(", "weights", ")", ":", "\n", "    ", "\"\"\"\n    :param weights: weights of the low pass filter\n    plot the impulse response of the filter, with gain in GB\n    \"\"\"", "\n", "print", "(", "\"GAIN\"", ",", "sum", "(", "weights", ")", ")", "\n", "freqs", ",", "h", "=", "signal", ".", "freqz", "(", "weights", ")", "\n", "freqs", "=", "freqs", "*", "100", "/", "(", "2", "*", "np", ".", "pi", ")", "# freq in hz", "\n", "plt", ".", "plot", "(", "freqs", ",", "20", "*", "np", ".", "log10", "(", "abs", "(", "h", ")", ")", ",", "'r'", ")", "\n", "plt", ".", "title", "(", "\"Allure filtre passe bas \u00e0 la fin de l'Training pour filtre en dur\"", ")", "\n", "plt", ".", "ylabel", "(", "'Amplitude [dB]'", ")", "\n", "plt", ".", "xlabel", "(", "\"real frequency\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.which_speakers_to_train_on": [[174, 194], ["print", "Preprocessing.tools_preprocessing.get_speakers_per_corpus", "speakers_to_train_on.remove"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_speakers_per_corpus"], ["", "def", "which_speakers_to_train_on", "(", "corpus_to_train_on", ",", "test_on", ",", "config", ")", ":", "\n", "    ", "\"\"\"\n    :param corpus_to_train_on: list of all the corpus name to train on\n    :param test_on: the speaker test name\n    :param config:  either specific/dependant/independant\n    :return:\n            speaker_train_on : list of the speakers to train_on (except the test speaker)\n    \"\"\"", "\n", "if", "config", "==", "\"spec\"", ":", "# speaker specific", "\n", "        ", "speakers_to_train_on", "=", "[", "\"\"", "]", "# only train on the test speaker", "\n", "\n", "", "elif", "config", "in", "[", "\"indep\"", ",", "\"dep\"", "]", ":", "# train on other corpuses", "\n", "        ", "speakers_to_train_on", "=", "[", "]", "\n", "for", "corpus", "in", "corpus_to_train_on", ":", "\n", "            ", "print", "(", "\"corpus\"", ",", "corpus", ")", "\n", "sp", "=", "get_speakers_per_corpus", "(", "corpus", ")", "\n", "speakers_to_train_on", "=", "speakers_to_train_on", "+", "sp", "\n", "", "if", "test_on", "in", "speakers_to_train_on", ":", "\n", "            ", "speakers_to_train_on", ".", "remove", "(", "test_on", ")", "\n", "", "", "return", "speakers_to_train_on", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_common_articulators": [[195, 213], ["open", "open.readline().replace().split", "range", "line.replace().split", "open.readline().replace", "range", "list", "line.replace", "len", "set().intersection", "open.readline", "arti_dispo.append", "int", "set"], "function", ["None"], ["", "def", "give_me_common_articulators", "(", "list_speakers", ")", ":", "\n", "    ", "\"\"\"\n    Give the indexes of the articulators that are in common for a list of speakers\n    :param list_speakers: list of the speakers to consider\n    :return: list of indexes that correspond to tha articulators in common\n    \"\"\"", "\n", "f_artic", "=", "open", "(", "'articulators_per_speaker.csv'", ",", "'r'", ")", "\n", "ind", "=", "f_artic", ".", "readline", "(", ")", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "';'", ")", "\n", "list_arti_common", "=", "range", "(", "18", ")", "\n", "for", "line", "in", "f_artic", ":", "\n", "        ", "new_line", "=", "line", ".", "replace", "(", "'\\n'", ",", "''", ")", ".", "split", "(", "';'", ")", "\n", "if", "new_line", "[", "0", "]", "in", "list_speakers", ":", "\n", "            ", "arti_dispo", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "new_line", "[", "1", ":", "-", "2", "]", ")", ")", ":", "\n", "                ", "if", "new_line", "[", "1", "+", "i", "]", "==", "'1'", ":", "\n", "                    ", "arti_dispo", ".", "append", "(", "int", "(", "i", ")", ")", "\n", "", "", "list_arti_common", "=", "list", "(", "set", "(", "list_arti_common", ")", ".", "intersection", "(", "arti_dispo", ")", ")", "\n", "", "", "return", "list_arti_common", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_train_valid_test_filenames": [[217, 289], ["dict", "json.load.keys", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "open", "json.load", "tools_learning.load_filenames", "len", "dict", "random.shuffle", "random.shuffle", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "int", "len", "int", "len", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "sp.lower", "f.lower", "sp.lower", "f.lower", "len", "len"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames"], ["", "def", "give_me_train_valid_test_filenames", "(", "train_on", ",", "test_on", ",", "config", ",", "batch_size", ",", "valid_on", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"\n    :param train_on: list of corpus to train on\n    :param test_on: the speaker test\n    :param config: either spec/dep/indep\n    :param batch_size\n    :return: files_per_categ :  dictionnary where keys are the categories present in the training set. For each category\n    we have a dictionnary with 2 keys (train, valid), and the values is a list of the namefiles for this categ and this\n    part (train/valid)\n            files_for_test : list of the files of the test set\n    4 configurations that impacts the train/valid/test set (if we train a bit on test speaker, we have to be sure that\n    the don't test on files that were in the train set)\n    - spec : for speaker specific, learning and testing only on the speaker test\n    - dep : for speaker dependant, learning on speakers in train_on and a part of the speaker test\n    - indep : for speaker independant, learnong on other speakers.\n    - train_indep: when you want to train on a list of speakers, valid on another list and test on another speaker\n    \"\"\"", "\n", "if", "config", "==", "\"spec\"", ":", "\n", "        ", "files_for_train", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"valid\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"test\"", "]", ")", "\n", "\n", "", "elif", "config", "==", "\"dep\"", ":", "\n", "        ", "files_for_train", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"train\"", ",", "\"test\"", "]", ")", "+", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"valid\"", "]", ")", "+", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"valid\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"test\"", "]", ")", "\n", "\n", "", "elif", "config", "==", "\"indep\"", ":", "\n", "        ", "files_for_train", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"train\"", ",", "\"test\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"valid\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ")", "\n", "\n", "", "elif", "config", "==", "'train_indep'", "and", "valid_on", "!=", "[", "]", ":", "\n", "        ", "files_for_train", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "valid_on", ",", "part", "=", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ")", "\n", "\n", "", "with", "open", "(", "'categ_of_speakers.json'", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "categ_of_speakers", "=", "json", ".", "load", "(", "fp", ")", "# dictionnary { categ : dict_2} where", "\n", "# dict_2 :{  speakers : [sp_1,..], arti  : [0,1,1...]  }", "\n", "", "files_per_categ", "=", "dict", "(", ")", "\n", "\n", "for", "categ", "in", "categ_of_speakers", ".", "keys", "(", ")", ":", "\n", "        ", "sp_in_categ", "=", "categ_of_speakers", "[", "categ", "]", "[", "\"sp\"", "]", "\n", "\n", "files_train_this_categ", "=", "[", "[", "f", "for", "f", "in", "files_for_train", "if", "sp", ".", "lower", "(", ")", "in", "f", ".", "lower", "(", ")", "]", "\n", "for", "sp", "in", "sp_in_categ", "]", "# the speaker name is always in the namefile", "\n", "files_train_this_categ", "=", "[", "item", "for", "sublist", "in", "files_train_this_categ", "\n", "for", "item", "in", "sublist", "]", "# flatten the list of list", "\n", "\n", "files_valid_this_categ", "=", "[", "[", "f", "for", "f", "in", "files_for_valid", "if", "sp", ".", "lower", "(", ")", "in", "f", ".", "lower", "(", ")", "]", "for", "sp", "in", "sp_in_categ", "]", "\n", "files_valid_this_categ", "=", "[", "item", "for", "sublist", "in", "files_valid_this_categ", "for", "item", "in", "sublist", "]", "\n", "\n", "if", "len", "(", "files_train_this_categ", ")", ">", "0", ":", "# meaning we have at least one file in this categ", "\n", "            ", "files_per_categ", "[", "categ", "]", "=", "dict", "(", ")", "\n", "\n", "N_iter_categ", "=", "int", "(", "len", "(", "files_train_this_categ", ")", "/", "batch_size", ")", "+", "1", "\n", "n_a_ajouter", "=", "batch_size", "*", "N_iter_categ", "-", "len", "(", "files_train_this_categ", ")", "\n", "files_train_this_categ", "=", "files_train_this_categ", "+", "files_train_this_categ", "[", ":", "n_a_ajouter", "]", "#so that lenght is a multiple of batchsize", "\n", "random", ".", "shuffle", "(", "files_train_this_categ", ")", "\n", "files_per_categ", "[", "categ", "]", "[", "\"train\"", "]", "=", "files_train_this_categ", "\n", "\n", "N_iter_categ", "=", "int", "(", "len", "(", "files_valid_this_categ", ")", "/", "batch_size", ")", "+", "1", "\n", "n_a_ajouter", "=", "batch_size", "*", "N_iter_categ", "-", "len", "(", "files_valid_this_categ", ")", "\n", "files_valid_this_categ", "=", "files_valid_this_categ", "+", "files_valid_this_categ", "[", ":", "n_a_ajouter", "]", "\n", "random", ".", "shuffle", "(", "files_valid_this_categ", ")", "\n", "files_per_categ", "[", "categ", "]", "[", "\"valid\"", "]", "=", "files_valid_this_categ", "\n", "\n", "", "", "return", "files_per_categ", ",", "files_for_test", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_train_valid_test_filenames_no_cat": [[290, 334], ["tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "tools_learning.load_filenames", "print"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames"], ["", "def", "give_me_train_valid_test_filenames_no_cat", "(", "train_on", ",", "test_on", ",", "config", ",", "valid_on", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"\n    :param train_on: list of speakers to train on\n    :param test_on: the speaker test\n    :param config: either spec/dep/indep\n    :param batch_size\n    :return: files_per_categ :  dictionnary where keys are the categories present in the training set. For each category\n    we have a dictionnary with 2 keys (train, valid), and the values is a list of the namefiles for this categ and this\n    part (train/valid)\n            files_for_test : list of the files of the test set\n    4 configurations that impacts the train/valid/test set (if we train a bit on test speaker, we have to be sure that\n    the don't test on files that were in the train set)\n    - spec : for speaker specific, learning and testing only on the speaker test\n    - dep : for speaker dependant, learning on speakers in train_on and a part of the speaker test\n    - indep : for speaker independant, learnong on other speakers.\n    - train_indep: when you want to train on a list of speakers, valid on another list and test on another speaker\n    \"\"\"", "\n", "if", "config", "==", "\"spec\"", ":", "\n", "        ", "files_for_train", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"valid\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"test\"", "]", ")", "\n", "\n", "", "elif", "config", "==", "\"dep\"", ":", "\n", "        ", "files_for_train", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"train\"", ",", "\"test\"", "]", ")", "+", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"valid\"", "]", ")", "+", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"valid\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"test\"", "]", ")", "\n", "\n", "", "elif", "config", "==", "\"indep\"", ":", "\n", "        ", "files_for_train", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"train\"", ",", "\"test\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"valid\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ")", "\n", "", "elif", "config", "==", "\"train_indep\"", ":", "\n", "# this means that we have a speaker in valid_on", "\n", "        ", "if", "valid_on", "==", "[", "]", ":", "\n", "            ", "print", "(", "'ERROR, you did not choose speaker to valid on'", ")", "\n", "return", "\n", "", "files_for_train", "=", "load_filenames", "(", "train_on", ",", "part", "=", "[", "\"train\"", ",", "\"test\"", ",", "\"valid\"", "]", ")", "\n", "files_for_valid", "=", "load_filenames", "(", "valid_on", ",", "part", "=", "[", "\"train\"", ",", "\"test\"", ",", "\"valid\"", "]", ")", "\n", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ")", "\n", "\n", "\n", "", "return", "files_for_train", ",", "files_for_valid", ",", "files_for_test", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes": [[336, 358], ["numpy.concatenate", "numpy.concatenate", "numpy.concatenate", "list_array.append", "list_array.append", "list_array.append", "tuple", "tuple", "tuple"], "function", ["None"], ["", "def", "get_right_indexes", "(", "y", ",", "indexes_list", ",", "shape", "=", "3", ")", ":", "\n", "    ", "\"\"\"\n    Select only the right columns of y an return them\n    :param y:\n    :param indexes_list:\n    :param shape:\n    :return:\n    \"\"\"", "\n", "list_array", "=", "[", "]", "\n", "for", "i", "in", "indexes_list", ":", "\n", "        ", "if", "shape", "==", "3", ":", "\n", "            ", "list_array", ".", "append", "(", "y", "[", ":", ",", ":", ",", "i", ":", "i", "+", "1", "]", ")", "\n", "", "if", "shape", "==", "2", ":", "\n", "            ", "list_array", ".", "append", "(", "y", "[", ":", ",", "i", ":", "i", "+", "1", "]", ")", "\n", "", "if", "shape", "==", "1", ":", "\n", "            ", "list_array", ".", "append", "(", "y", "[", "i", ":", "i", "+", "1", "]", ")", "\n", "", "", "if", "shape", "==", "3", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "tuple", "(", "list_array", ")", ",", "axis", "=", "2", ")", "\n", "", "if", "shape", "==", "2", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "tuple", "(", "list_array", ")", ",", "axis", "=", "1", ")", "\n", "", "if", "shape", "==", "1", ":", "\n", "        ", "return", "np", ".", "concatenate", "(", "tuple", "(", "list_array", ")", ",", "axis", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.train.train_model": [[50, 347], ["open", "open", "corpus_to_train_on[].split", "speakers_to_train_on[].replace().replace().replace().split", "speakers_to_valid_on[].replace().replace().replace().split", "print", "print", "print", "os.listdir", "os.listdir", "os.listdir", "previous_models_2.count", "print", "torch.cuda.is_available", "print", "Training.pytorchtools.EarlyStopping", "Training.model.my_ac2art_model", "model.to.double", "os.path.join", "os.path.join", "os.path.join", "Training.tools_learning.give_me_train_valid_test_filenames", "torch.optim.Adam", "files_per_categ.keys", "range", "random.shuffle", "Training.tools_learning.load_np_ema_and_mfcc", "print", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "csv.register_dialect", "model.to.evaluate_on_test", "numpy.zeros", "numpy.mean", "print", "print", "model.to.lowpass.weight.data[].cpu", "Training.tools_learning.which_speakers_to_train_on", "str", "os.path.exists", "os.path.exists", "os.path.exists", "os.mkdir", "os.mkdir", "os.mkdir", "print", "print", "str", "torch.device", "torch.device", "model.to.to", "model.to.parameters", "open", "json.load", "model.to.lowpass.weight.data[].cpu", "random.shuffle", "torch.cuda.empty_cache", "print", "open.write", "torch.cuda.empty_cache", "model.to.all_validation_loss.append", "model.to.all_training_loss.append", "Training.pytorchtools.EarlyStopping.", "model.to.load_state_dict", "torch.save", "os.path.join", "os.path.join", "os.path.join", "open", "csv.reader", "next", "os.path.exists", "os.path.exists", "os.path.exists", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "Training.tools_learning.plot_filtre", "speakers_to_train_on[].replace().replace().replace", "speakers_to_valid_on[].replace().replace().replace", "x.endswith", "os.path.exists", "os.path.exists", "os.path.exists", "Training.tools_learning.plot_filtre", "list", "random.shuffle", "open.write", "print", "torch.load", "model.to.state_dict", "os.path.join", "os.path.join", "os.path.join", "len", "Training.tools_learning.load_np_ema_and_mfcc", "model.to.evaluate_on_test", "numpy.reshape", "numpy.concatenate", "numpy.isnan", "open", "csv.writer", "csv.writer.writerow", "rmse_per_arti_mean.tolist", "pearson_per_arti_mean.tolist", "np.concatenate.tolist", "str", "len", "print", "torch.load", "model.to.load_state_dict", "model.to.state_dict", "model.state_dict.update", "model.to.load_state_dict", "len", "Training.tools_learning.load_np_ema_and_mfcc", "model.to.prepare_batch", "model.to.double", "y.double.double", "torch.optim.Adam.zero_grad", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.backward", "torch.optim.Adam.step", "Training.tools_learning.criterion_pearson", "Training.tools_learning.criterion_pearson.item", "loss_3.item", "torch.cuda.empty_cache", "Training.tools_learning.criterion_both.item", "os.path.join", "os.path.join", "os.path.join", "numpy.array", "speakers_to_train_on[].replace().replace", "speakers_to_valid_on[].replace().replace", "y_pred.to.to", "torch.nn.MSELoss", "str", "len", "Training.tools_learning.load_np_ema_and_mfcc", "model.to.prepare_batch", "model.to.double", "torch.cuda.empty_cache", "y.double.double", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "Training.tools_learning.criterion_pearson", "Training.tools_learning.criterion_pearson.item", "loss_3.item", "int", "numpy.mean", "numpy.mean", "numpy.mean", "str", "torch.load.items", "torch.load.items", "x.to", "y.double.to", "model.to.", "y_pred.to.to", "torch.nn.MSELoss", "str", "speakers_to_train_on[].replace", "speakers_to_valid_on[].replace", "enumerate", "str", "x.to", "y.double.to", "model.to.", "enumerate", "str", "str", "str", "str", "str"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_train_valid_test_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.evaluate_on_test", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.which_speakers_to_train_on", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.plot_filtre", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.plot_filtre", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.evaluate_on_test", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.prepare_batch", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_pearson", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.prepare_batch", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_pearson"], ["def", "train_model", "(", "test_on", ",", "n_epochs", ",", "loss_train", ",", "patience", ",", "select_arti", ",", "corpus_to_train_on", ",", "batch_norma", ",", "filter_type", ",", "\n", "to_plot", ",", "lr", ",", "delta_test", ",", "config", ",", "speakers_to_train_on", "=", "\"\"", ",", "speakers_to_valid_on", "=", "\"\"", ",", "relearn", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param test_on: (str) one speaker's name we want to test on, the speakers and the corpus the come frome can be seen in\n    \"fonction_utiles.py\", in the function \"get_speakers_per_corpus'.\n\n    :param n_epochs: (int)  max number of epochs for the training. We use an early stopping criterion to stop the training,\n    so usually we dont go through the n_epochs and the early stopping happends before the 30th epoch (1 epoch is when\n    have trained over ALL the data in the training set)\n\n    :param loss_train: (int) alpha in the combined loss . can be anything between 0 and 100.\n    the loss is the combinated loss alpha*rmse/1000+(1-alpha)*pearson.\n\n    :param patience: (int) the number successive epochs with a validation loss increasing before stopping the training.\n    We usually set it to 5. The more data we have, the smaller it can be (i think)\n\n    :param select_arti: (bool) always true, either to use the trick to only train on available articulatory trajectories,\n    fixing the predicted trajectory (to zero) and then the gradient will be 0.\n\n    :param corpus_to_train_on: (list) list of the corpuses to train on. Usually at least the corpus the testspeaker comes from.\n    (the testspeaker will be by default removed from the training speakers).\n\n    :param batch_norma: (bool) whether or not add batch norm layer after the lstm layers (maybe better to add them after the\n    feedforward layers? )\n\n    :param filter_type: (int) either 0 1 or 2. 0 the filter is outside of the network, 1 it is inside and the weight are fixed\n    during the training, 2 the weights get adjusted during the training\n\n    :param to_plot: (bool) if true the trajectories of one random test sentence are saved in \"images_predictions\"\n\n    :param lr: initial learning rate, usually 0.001\n\n    :param delta_test: frequency of validation evaluation, 1 seems good\n\n    :param config : either \"spe\" \"dep\", or \"indep\", for specific (train only on test sp), dependant (train on test sp\n    and others), or independant, train only on other speakers\n\n    :return: [rmse, pearson] . rmse the is the list of the 18 rmse (1 per articulator), same for pearson.\n    \"\"\"", "\n", "f_loss_train", "=", "open", "(", "'training_loss.csv'", ",", "'w'", ")", "\n", "f_loss_valid", "=", "open", "(", "'valid_loss.csv'", ",", "'w'", ")", "\n", "corpus_to_train_on", "=", "corpus_to_train_on", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "speakers_to_train_on", "=", "speakers_to_train_on", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", ".", "replace", "(", "'\"'", ",", "''", ")", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "\",\"", ")", "\n", "if", "speakers_to_train_on", "==", "[", "\"\"", "]", "or", "speakers_to_train_on", "==", "[", "]", ":", "\n", "        ", "train_on", "=", "which_speakers_to_train_on", "(", "corpus_to_train_on", ",", "test_on", ",", "config", ")", "\n", "", "else", ":", "\n", "        ", "train_on", "=", "speakers_to_train_on", "\n", "\n", "", "speakers_to_valid_on", "=", "speakers_to_valid_on", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", ".", "replace", "(", "'\"'", ",", "''", ")", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "\",\"", ")", "\n", "if", "speakers_to_valid_on", "==", "[", "\"\"", "]", "or", "speakers_to_valid_on", "==", "[", "]", ":", "\n", "        ", "valid_on", "=", "[", "]", "\n", "", "else", ":", "\n", "        ", "valid_on", "=", "speakers_to_valid_on", "\n", "", "print", "(", "'train'", ",", "train_on", ")", "\n", "print", "(", "'valid'", ",", "valid_on", ")", "\n", "print", "(", "'test'", ",", "test_on", ")", "\n", "name_corpus_concat", "=", "\"\"", "\n", "if", "config", "!=", "\"spec\"", ":", "# if spec DOESNT train on other speakers", "\n", "        ", "for", "corpus", "in", "corpus_to_train_on", ":", "\n", "            ", "name_corpus_concat", "=", "name_corpus_concat", "+", "corpus", "+", "\"_\"", "\n", "\n", "", "", "name_file", "=", "test_on", "+", "\"_\"", "+", "config", "+", "\"_\"", "+", "name_corpus_concat", "+", "\"loss_\"", "+", "str", "(", "loss_train", ")", "+", "\"_filter_\"", "+", "str", "(", "filter_type", ")", "+", "\"_bn_\"", "+", "str", "(", "batch_norma", ")", "\n", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "\"saved_models\"", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "\"saved_models\"", ")", "\n", "\n", "", "previous_models", "=", "os", ".", "listdir", "(", "\"saved_models\"", ")", "\n", "previous_models_2", "=", "[", "x", "[", ":", "len", "(", "name_file", ")", "]", "for", "x", "in", "previous_models", "if", "x", ".", "endswith", "(", "\".txt\"", ")", "]", "\n", "n_previous_same", "=", "previous_models_2", ".", "count", "(", "name_file", ")", "# how many times our model was trained", "\n", "\n", "if", "n_previous_same", ">", "0", ":", "\n", "        ", "print", "(", "\"this models has alread be trained {} times\"", ".", "format", "(", "n_previous_same", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"first time for this model\"", ")", "\n", "", "name_file", "=", "name_file", "+", "\"_\"", "+", "str", "(", "n_previous_same", ")", "# each model trained only once ,", "\n", "# this script doesnt continue a previous training if it was ended ie if there is a .txt", "\n", "print", "(", "\"going to train the model with name\"", ",", "name_file", ")", "\n", "\n", "cuda_avail", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "print", "(", "\" cuda ?\"", ",", "cuda_avail", ")", "\n", "if", "cuda_avail", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "hidden_dim", "=", "300", "\n", "input_dim", "=", "429", "\n", "batch_size", "=", "10", "\n", "output_dim", "=", "18", "\n", "early_stopping", "=", "EarlyStopping", "(", "name_file", ",", "patience", "=", "patience", ",", "verbose", "=", "True", ")", "\n", "model", "=", "my_ac2art_model", "(", "hidden_dim", "=", "hidden_dim", ",", "input_dim", "=", "input_dim", ",", "name_file", "=", "name_file", ",", "output_dim", "=", "output_dim", ",", "\n", "batch_size", "=", "batch_size", ",", "cuda_avail", "=", "cuda_avail", ",", "\n", "filter_type", "=", "filter_type", ",", "batch_norma", "=", "batch_norma", ")", "\n", "model", "=", "model", ".", "double", "(", ")", "\n", "file_weights", "=", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "name_file", "+", "\".pt\"", ")", "\n", "if", "cuda_avail", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "", "if", "relearn", ":", "\n", "        ", "load_old_model", "=", "True", "\n", "if", "load_old_model", ":", "\n", "            ", "if", "os", ".", "path", ".", "exists", "(", "file_weights", ")", ":", "\n", "                ", "print", "(", "\"previous model did not finish learning\"", ")", "\n", "loaded_state", "=", "torch", ".", "load", "(", "file_weights", ",", "map_location", "=", "device", ")", "\n", "model", ".", "load_state_dict", "(", "loaded_state", ")", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "loaded_state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "loaded_state", ".", "items", "(", ")", "if", "\n", "k", "in", "model_dict", "}", "# only layers param that are in our current model", "\n", "loaded_state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "loaded_state", ".", "items", "(", ")", "if", "\n", "loaded_state", "[", "k", "]", ".", "shape", "==", "model_dict", "[", "k", "]", ".", "shape", "}", "# only if layers have correct shapes", "\n", "model_dict", ".", "update", "(", "loaded_state", ")", "\n", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n", "\n", "\n", "", "", "", "files_per_categ", ",", "files_for_test", "=", "give_me_train_valid_test_filenames", "(", "train_on", "=", "train_on", ",", "test_on", "=", "test_on", ",", "config", "=", "config", ",", "batch_size", "=", "batch_size", ",", "valid_on", "=", "valid_on", ")", "\n", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "categs_to_consider", "=", "files_per_categ", ".", "keys", "(", ")", "\n", "with", "open", "(", "'categ_of_speakers.json'", ",", "'r'", ")", "as", "fp", ":", "\n", "        ", "categ_of_speakers", "=", "json", ".", "load", "(", "fp", ")", "# dict that gives for each category the speakers in it and the available arti", "\n", "", "plot_filtre_chaque_epochs", "=", "False", "\n", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "weights", "=", "model", ".", "lowpass", ".", "weight", ".", "data", "[", "0", ",", "0", ",", ":", "]", ".", "cpu", "(", ")", "\n", "if", "plot_filtre_chaque_epochs", ":", "\n", "            ", "plot_filtre", "(", "weights", ")", "\n", "", "n_this_epoch", "=", "0", "\n", "random", ".", "shuffle", "(", "list", "(", "categs_to_consider", ")", ")", "\n", "loss_train_this_epoch", "=", "0", "\n", "loss_pearson", "=", "0", "\n", "loss_rmse", "=", "0", "\n", "for", "categ", "in", "categs_to_consider", ":", "\n", "            ", "files_this_categ_courant", "=", "files_per_categ", "[", "categ", "]", "[", "\"train\"", "]", "\n", "random", ".", "shuffle", "(", "files_this_categ_courant", ")", "\n", "while", "len", "(", "files_this_categ_courant", ")", ">", "0", ":", "# go through all  the files batch by batch", "\n", "                ", "n_this_epoch", "+=", "1", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_this_categ_courant", "[", ":", "batch_size", "]", ")", "\n", "\n", "files_this_categ_courant", "=", "files_this_categ_courant", "[", "batch_size", ":", "]", "#we a re going to train on this 10 files", "\n", "x", ",", "y", "=", "model", ".", "prepare_batch", "(", "x", ",", "y", ")", "\n", "if", "cuda_avail", ":", "\n", "                    ", "x", ",", "y", "=", "x", ".", "to", "(", "device", "=", "model", ".", "device", ")", ",", "y", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "", "y_pred", "=", "model", "(", "x", ")", ".", "double", "(", ")", "\n", "if", "cuda_avail", ":", "\n", "                    ", "y_pred", "=", "y_pred", ".", "to", "(", "device", "=", "device", ")", "\n", "", "y", "=", "y", ".", "double", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "if", "select_arti", ":", "\n", "                    ", "arti_to_consider", "=", "categ_of_speakers", "[", "categ", "]", "[", "\"arti\"", "]", "# liste de 18 0/1 qui indique les arti \u00e0 consid\u00e9rer", "\n", "idx_to_ignore", "=", "[", "i", "for", "i", ",", "n", "in", "enumerate", "(", "arti_to_consider", ")", "if", "n", "==", "\"0\"", "]", "\n", "y_pred", "[", ":", ",", ":", ",", "idx_to_ignore", "]", "=", "0", "#the grad associated to this value will be zero  : CHECK THAT", "\n", "# y_pred[:,:,idx_to_ignore].detach()", "\n", "#y[:,:,idx_to_ignore].requires_grad = False", "\n", "\n", "", "loss", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "loss_train", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# computation to have evolution of the losses", "\n", "loss_2", "=", "criterion_pearson", "(", "y", ",", "y_pred", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_pearson", "+=", "loss_2", ".", "item", "(", ")", "\n", "loss_3", "=", "torch", ".", "nn", ".", "MSELoss", "(", "reduction", "=", "'sum'", ")", "(", "y", ",", "y_pred", ")", "\n", "loss_rmse", "+=", "loss_3", ".", "item", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "loss_train_this_epoch", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "loss_train_this_epoch", "=", "loss_train_this_epoch", "/", "n_this_epoch", "\n", "print", "(", "\"Training loss for epoch\"", ",", "epoch", ",", "': '", ",", "loss_train_this_epoch", ")", "\n", "f_loss_train", ".", "write", "(", "str", "(", "epoch", ")", "+", "','", "+", "str", "(", "loss_train_this_epoch", ")", "+", "','", "+", "str", "(", "loss_pearson", "/", "n_this_epoch", "/", "batch_size", "/", "18.", "*", "(", "-", "1.", ")", ")", "+", "','", "+", "str", "(", "loss_rmse", "/", "n_this_epoch", "/", "batch_size", ")", "+", "'\\n'", ")", "\n", "if", "epoch", "%", "delta_test", "==", "0", ":", "#toutes les delta_test epochs on \u00e9value le mod\u00e8le sur validation et on sauvegarde le modele si le score est meilleur", "\n", "            ", "loss_vali", "=", "0", "\n", "n_valid", "=", "0", "\n", "loss_pearson", "=", "0", "\n", "loss_rmse", "=", "0", "\n", "for", "categ", "in", "categs_to_consider", ":", "# de A \u00e0 F pour le moment", "\n", "                ", "files_this_categ_courant", "=", "files_per_categ", "[", "categ", "]", "[", "\"valid\"", "]", "# on na pas encore apprit dessus au cours de cette epoch", "\n", "while", "len", "(", "files_this_categ_courant", ")", ">", "0", ":", "\n", "                    ", "n_valid", "+=", "1", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_this_categ_courant", "[", ":", "batch_size", "]", ")", "\n", "files_this_categ_courant", "=", "files_this_categ_courant", "[", "batch_size", ":", "]", "# on a appris sur ces 10 phrases", "\n", "x", ",", "y", "=", "model", ".", "prepare_batch", "(", "x", ",", "y", ")", "\n", "if", "cuda_avail", ":", "\n", "                        ", "x", ",", "y", "=", "x", ".", "to", "(", "device", "=", "model", ".", "device", ")", ",", "y", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "", "y_pred", "=", "model", "(", "x", ")", ".", "double", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "cuda_avail", ":", "\n", "                        ", "y_pred", "=", "y_pred", ".", "to", "(", "device", "=", "device", ")", "\n", "", "y", "=", "y", ".", "double", "(", ")", "# (Batchsize, maxL, 18)", "\n", "if", "select_arti", ":", "\n", "                        ", "arti_to_consider", "=", "categ_of_speakers", "[", "categ", "]", "[", "\"arti\"", "]", "# liste de 18 0/1 qui indique les arti \u00e0 consid\u00e9rer", "\n", "idx_to_ignore", "=", "[", "i", "for", "i", ",", "n", "in", "enumerate", "(", "arti_to_consider", ")", "if", "n", "==", "\"0\"", "]", "\n", "y_pred", "[", ":", ",", ":", ",", "idx_to_ignore", "]", "=", "0", "\n", "#    y_pred[:, :, idx_to_ignore].detach()", "\n", "#     y[:, :, idx_to_ignore].requires_grad = False", "\n", "", "loss_courant", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "loss_train", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_vali", "+=", "loss_courant", ".", "item", "(", ")", "\n", "# to follow both losses", "\n", "loss_2", "=", "criterion_pearson", "(", "y", ",", "y_pred", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_pearson", "+=", "loss_2", ".", "item", "(", ")", "\n", "loss_3", "=", "torch", ".", "nn", ".", "MSELoss", "(", "reduction", "=", "'sum'", ")", "(", "y", ",", "y_pred", ")", "\n", "loss_rmse", "+=", "loss_3", ".", "item", "(", ")", "\n", "\n", "", "", "loss_vali", "=", "loss_vali", "/", "n_valid", "\n", "f_loss_valid", ".", "write", "(", "str", "(", "epoch", ")", "+", "','", "+", "str", "(", "loss_vali", ")", "+", "','", "+", "str", "(", "loss_pearson", "/", "n_valid", "/", "batch_size", "/", "18.", "*", "(", "-", "1.", ")", ")", "+", "','", "+", "str", "(", "loss_rmse", "/", "n_this_epoch", "/", "batch_size", ")", "+", "'\\n'", ")", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "model", ".", "all_validation_loss", ".", "append", "(", "loss_vali", ")", "\n", "model", ".", "all_training_loss", ".", "append", "(", "loss_train_this_epoch", ")", "\n", "early_stopping", "(", "loss_vali", ",", "model", ")", "\n", "if", "early_stopping", ".", "early_stop", ":", "\n", "            ", "print", "(", "\"Early stopping, n epochs : \"", ",", "model", ".", "epoch_ref", "+", "epoch", ")", "\n", "break", "\n", "\n", "", "if", "epoch", ">", "0", ":", "# on divise le learning rate par deux d\u00e8s qu'on surapprend un peu par rapport au validation set", "\n", "            ", "if", "loss_vali", ">", "model", ".", "all_validation_loss", "[", "-", "1", "]", ":", "\n", "                ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "param_group", "[", "'lr'", "]", "/", "2", "\n", "(", "param_group", "[", "\"lr\"", "]", ")", "\n", "\n", "\n", "", "", "", "", "if", "n_epochs", ">", "0", ":", "\n", "        ", "model", ".", "epoch_ref", "=", "model", ".", "epoch_ref", "+", "epoch", "# voir si ca marche vrmt pour les rares cas ou on continue un training", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "name_file", "+", "'.pt'", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "name_file", "+", "\".txt\"", ")", ")", "#lorsque .txt ==> training termin\u00e9 !", "\n", "", "random", ".", "shuffle", "(", "files_for_test", ")", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_for_test", ")", "\n", "print", "(", "\"evaluation on speaker {}\"", ".", "format", "(", "test_on", ")", ")", "\n", "std_speaker", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessing\"", ",", "\"norm_values\"", ",", "\"std_ema_\"", "+", "test_on", "+", "\".npy\"", ")", ")", "\n", "arti_per_speaker", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessing\"", ",", "\"articulators_per_speaker.csv\"", ")", "\n", "csv", ".", "register_dialect", "(", "'myDialect'", ",", "delimiter", "=", "';'", ")", "\n", "with", "open", "(", "arti_per_speaker", ",", "'r'", ")", "as", "csvFile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "csvFile", ",", "dialect", "=", "\"myDialect\"", ")", "\n", "next", "(", "reader", ")", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "if", "row", "[", "0", "]", "==", "test_on", ":", "\n", "                ", "arti_to_consider", "=", "row", "[", "1", ":", "19", "]", "\n", "arti_to_consider", "=", "[", "int", "(", "x", ")", "for", "x", "in", "arti_to_consider", "]", "\n", "\n", "", "", "", "rmse_per_arti_mean", ",", "pearson_per_arti_mean", "=", "model", ".", "evaluate_on_test", "(", "x", ",", "y", ",", "std_speaker", "=", "std_speaker", ",", "to_plot", "=", "to_plot", "\n", ",", "to_consider", "=", "arti_to_consider", ")", "\n", "\n", "\n", "\"\"\"  RESULTS ON VALIDATION SET \"\"\"", "\n", "\n", "pearson_valid", "=", "np", ".", "zeros", "(", "(", "1", ",", "output_dim", ")", ")", "\n", "for", "categ", "in", "categs_to_consider", ":", "# de A \u00e0 F pour le moment", "\n", "        ", "files_this_categ_courant", "=", "files_per_categ", "[", "categ", "]", "[", "\"valid\"", "]", "# on na pas encore apprit dessus au cours de cette epoch", "\n", "while", "len", "(", "files_this_categ_courant", ")", ">", "0", ":", "\n", "            ", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_this_categ_courant", "[", ":", "batch_size", "]", ")", "\n", "files_this_categ_courant", "=", "files_this_categ_courant", "[", "batch_size", ":", "]", "# on a appris sur ces 10 phrases", "\n", "arti_to_consider", "=", "categ_of_speakers", "[", "categ", "]", "[", "\"arti\"", "]", "# liste de 18 0/1 qui indique les arti \u00e0 consid\u00e9rer", "\n", "\n", "rien", ",", "pearson_valid_temp", "=", "model", ".", "evaluate_on_test", "(", "x", ",", "y", ",", "std_speaker", "=", "1", ",", "to_plot", "=", "to_plot", ",", "\n", "to_consider", "=", "arti_to_consider", ",", "verbose", "=", "False", ")", "\n", "pearson_valid_temp", "=", "np", ".", "reshape", "(", "np", ".", "array", "(", "pearson_valid_temp", ")", ",", "(", "1", ",", "output_dim", ")", ")", "\n", "pearson_valid", "=", "np", ".", "concatenate", "(", "(", "pearson_valid", ",", "pearson_valid_temp", ")", ",", "axis", "=", "0", ")", "\n", "", "", "pearson_valid", "=", "pearson_valid", "[", "1", ":", ",", ":", "]", "\n", "pearson_valid", "[", "np", ".", "isnan", "(", "pearson_valid", ")", "]", "=", "0", "\n", "pearson_valid", "=", "np", ".", "mean", "(", "pearson_valid", ",", "axis", "=", "0", ")", "\n", "print", "(", "\"on validation set :mean :\\n\"", ",", "pearson_valid", ")", "\n", "print", "(", "\"training done for : \"", ",", "name_file", ")", "\n", "\n", "articulators", "=", "[", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", ",", "\n", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", ",", "'la'", ",", "'lp'", ",", "'ttcl'", ",", "'tbcl'", ",", "'v_x'", ",", "'v_y'", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "'model_results.csv'", ")", ":", "\n", "        ", "with", "open", "(", "'model_results.csv'", ",", "'a'", ",", "newline", "=", "\"\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "header", "=", "[", "\"name file\"", ",", "\"test on\"", ",", "\"configuration\"", ",", "\"train on (if not spec)\"", ",", "\"loss\"", ",", "\n", "\"n_epochs\"", ",", "\"evaluation with...\"", ",", "\"average\"", "]", "+", "articulators", "\n", "writer", ".", "writerow", "(", "header", ")", "\n", "\n", "# write result in csv", "\n", "", "", "with", "open", "(", "'model_results.csv'", ",", "'a'", ",", "newline", "=", "\"\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "row_details", "=", "[", "name_file", ",", "test_on", ",", "config", ",", "name_corpus_concat", ",", "loss_train", ",", "model", ".", "epoch_ref", "]", "\n", "row_rmse", "=", "row_details", "+", "[", "\"rmse_on_test\"", ",", "np", ".", "mean", "(", "rmse_per_arti_mean", "[", "rmse_per_arti_mean", "!=", "0", "]", ")", "]", "+", "rmse_per_arti_mean", ".", "tolist", "(", ")", "\n", "\n", "row_pearson", "=", "row_details", "+", "[", "\"pearson_on_test\"", ",", "np", ".", "mean", "(", "pearson_per_arti_mean", "[", "pearson_per_arti_mean", "!=", "0", "]", ")", "]", "+", "pearson_per_arti_mean", ".", "tolist", "(", ")", "\n", "\n", "row_pearson_val", "=", "row_details", "+", "[", "\"pearson_on_valid\"", ",", "np", ".", "mean", "(", "pearson_valid", "[", "pearson_valid", "!=", "0", "]", ")", "]", "+", "pearson_valid", ".", "tolist", "(", ")", "\n", "\n", "writer", ".", "writerow", "(", "row_rmse", ")", "\n", "writer", ".", "writerow", "(", "row_pearson", ")", "\n", "writer", ".", "writerow", "(", "row_pearson_val", ")", "\n", "\n", "", "weight_apres", "=", "model", ".", "lowpass", ".", "weight", ".", "data", "[", "0", ",", "0", ",", ":", "]", ".", "cpu", "(", ")", "\n", "plot_allure_filtre", "=", "True", "\n", "if", "plot_allure_filtre", ":", "\n", "        ", "plot_filtre", "(", "weight_apres", ")", "\n", "\n", "", "return", "rmse_per_arti_mean", ",", "pearson_per_arti_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.experiment.cross_val_indep": [[50, 113], ["str().split", "print", "open", "open.close", "numpy.mean", "numpy.mean", "numpy.std", "numpy.std", "print", "print", "print", "print", "datetime.date.today().strftime", "len", "numpy.zeros", "numpy.zeros", "str", "str", "open", "csv.writer", "str", "Preprocessing.tools_preprocessing.get_speakers_per_corpus", "Training.tools_learning.give_me_common_articulators", "Training.train_only_common.train_model_arti_common", "Training.train.train_model", "datetime.date.today", "np.mean.tolist", "np.std.tolist", "np.mean.tolist", "np.std.tolist", "csv.writer.writerow", "len", "len"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_speakers_per_corpus", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_common_articulators", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.train_only_common.train_model_arti_common", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.train.train_model"], ["def", "cross_val_indep", "(", "corpus_to_train_on", ",", "only_common", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n        performs the cross validation in config setting on corpus_to_train_on corpus\n        the parameters are defined above and can be modified\n        the results of the experiment are printed\n        \"\"\"", "\n", "speakers", "=", "[", "]", "\n", "for", "co", "in", "str", "(", "corpus_to_train_on", "[", "1", ":", "-", "1", "]", ")", ".", "split", "(", "\",\"", ")", ":", "\n", "        ", "speakers", "=", "speakers", "+", "get_speakers_per_corpus", "(", "co", ")", "\n", "", "print", "(", "speakers", ")", "\n", "\n", "name", "=", "'experiment_results_cross_'", "+", "'_'", ".", "join", "(", "speakers", ")", "+", "'.csv'", "\n", "f", "=", "open", "(", "name", ",", "'w'", ")", "\n", "f", ".", "close", "(", ")", "\n", "output_dim", "=", "18", "\n", "if", "only_common", ":", "\n", "        ", "output_dim", "=", "len", "(", "give_me_common_articulators", "(", "speakers", ")", ")", "\n", "\n", "\n", "\n", "", "count", "=", "0", "\n", "rmse_all", ",", "pearson_all", "=", "np", ".", "zeros", "(", "(", "len", "(", "speakers", ")", ",", "output_dim", ")", ")", ",", "np", ".", "zeros", "(", "(", "len", "(", "speakers", ")", ",", "output_dim", ")", ")", "\n", "\n", "for", "speaker", "in", "speakers", ":", "\n", "        ", "speaker_to_valid", "=", "str", "(", "[", "[", "sp", "for", "sp", "in", "speakers", "if", "sp", "!=", "speaker", "]", "[", "0", "]", "]", ")", "\n", "speaker_to_train", "=", "str", "(", "[", "sp", "for", "sp", "in", "speakers", "if", "(", "sp", "!=", "speaker", "and", "sp", "not", "in", "speaker_to_valid", ")", "]", ")", "\n", "\n", "if", "only_common", ":", "\n", "            ", "rmse", ",", "pearson", "=", "train_model_arti_common", "(", "test_on", "=", "speaker", ",", "n_epochs", "=", "n_epochs", ",", "loss_train", "=", "loss_train", ",", "patience", "=", "patience", ",", "\n", "corpus_to_train_on", "=", "corpus_to_train_on", ",", "\n", "batch_norma", "=", "batch_norma", ",", "filter_type", "=", "filter_type", ",", "to_plot", "=", "to_plot", ",", "\n", "lr", "=", "lr", ",", "delta_test", "=", "delta_test", ",", "config", "=", "'train_indep'", ",", "speakers_to_train_on", "=", "speaker_to_train", ",", "\n", "speakers_to_valid_on", "=", "speaker_to_valid", ",", "delta_valid", "=", "delta_valid", ")", "\n", "", "else", ":", "\n", "            ", "rmse", ",", "pearson", "=", "train_model", "(", "test_on", "=", "speaker", ",", "n_epochs", "=", "n_epochs", ",", "loss_train", "=", "loss_train", ",", "\n", "patience", "=", "patience", ",", "\n", "select_arti", "=", "select_arti", ",", "corpus_to_train_on", "=", "corpus_to_train_on", ",", "\n", "batch_norma", "=", "batch_norma", ",", "filter_type", "=", "filter_type", ",", "to_plot", "=", "to_plot", ",", "\n", "lr", "=", "lr", ",", "delta_test", "=", "delta_test", ",", "config", "=", "'train_indep'", ",", "\n", "speakers_to_train_on", "=", "speaker_to_train", ")", "\n", "", "rmse_all", "[", "count", ",", ":", "]", "=", "rmse", "\n", "pearson_all", "[", "count", ",", ":", "]", "=", "pearson", "\n", "count", "+=", "1", "\n", "\n", "", "results_rmse", "=", "np", ".", "mean", "(", "rmse_all", ",", "axis", "=", "0", ")", "\n", "results_pearson", "=", "np", ".", "mean", "(", "pearson_all", ",", "axis", "=", "0", ")", "\n", "std_rmse", "=", "np", ".", "std", "(", "rmse_all", ",", "axis", "=", "0", ")", "\n", "std_pearson", "=", "np", ".", "std", "(", "pearson_all", ",", "axis", "=", "0", ")", "\n", "#print(\"for speaker test {} results are\".format(speaker))", "\n", "print", "(", "\"RMSE mean \"", ",", "results_rmse", ")", "\n", "print", "(", "\"RMSE std \"", ",", "std_rmse", ")", "\n", "print", "(", "\"PEARSON \"", ",", "results_pearson", ")", "\n", "print", "(", "\" PEARSON STD\"", ",", "std_pearson", ")", "\n", "today", "=", "date", ".", "today", "(", ")", ".", "strftime", "(", "\"%d/%m/%Y\"", ")", "\n", "\n", "with", "open", "(", "name", ",", "'a'", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "row_rmse_mean", "=", "[", "today", ",", "corpus_to_train_on", ",", "loss_train", ",", "\"rmse_mean\"", "]", "+", "results_rmse", ".", "tolist", "(", ")", "\n", "row_rmse_std", "=", "[", "today", ",", "corpus_to_train_on", ",", "loss_train", ",", "\"rmse_std\"", "]", "+", "std_rmse", ".", "tolist", "(", ")", "\n", "row_pearson_mean", "=", "[", "today", ",", "corpus_to_train_on", ",", "loss_train", ",", "\"pearson_mean\"", "]", "+", "results_pearson", ".", "tolist", "(", ")", "\n", "row_pearson_std", "=", "[", "today", ",", "corpus_to_train_on", ",", "loss_train", ",", "\"pearson_std\"", "]", "+", "std_pearson", ".", "tolist", "(", ")", "\n", "for", "row", "in", "[", "row_rmse_mean", ",", "row_rmse_std", ",", "row_pearson_mean", ",", "row_pearson_std", "]", ":", "\n", "            ", "writer", ".", "writerow", "(", "row", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.experiment.cross_val_spec": [[114, 163], ["str().split", "print", "open", "open.close", "range", "print", "print", "print", "datetime.date.today().strftime", "str", "Preprocessing.tools_preprocessing.get_speakers_per_corpus", "Training.tools_learning.give_me_common_articulators", "Training.train_only_common.train_model_arti_common", "Training.train.train_model", "open", "csv.writer", "datetime.date.today", "rmse.tolist", "pearson.tolist", "csv.writer.writerow", "int"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_speakers_per_corpus", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_common_articulators", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.train_only_common.train_model_arti_common", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.train.train_model"], ["", "", "", "def", "cross_val_spec", "(", "corpus_to_train_on", ",", "only_common", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n        performs the cross validation in the specific speaker setting on corpus_to_train_on corpus\n        the parameters are defined above and can be modified\n        the results of the experiment are printed\n        \"\"\"", "\n", "art", "=", "[", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", ",", "\n", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", ",", "'la'", ",", "'lp'", ",", "'ttcl'", ",", "'tbcl'", ",", "'v_x'", ",", "'v_y'", "]", "\n", "speakers", "=", "[", "]", "\n", "for", "co", "in", "str", "(", "corpus_to_train_on", "[", "1", ":", "-", "1", "]", ")", ".", "split", "(", "\",\"", ")", ":", "\n", "        ", "speakers", "=", "speakers", "+", "get_speakers_per_corpus", "(", "co", ")", "\n", "", "print", "(", "speakers", ")", "\n", "\n", "name", "=", "'experiment_results_spec_'", "+", "'_'", ".", "join", "(", "speakers", ")", "+", "'.csv'", "\n", "f", "=", "open", "(", "name", ",", "'w'", ")", "\n", "f", ".", "close", "(", ")", "\n", "count", "=", "0", "\n", "output_dim", "=", "range", "(", "18", ")", "\n", "for", "speaker", "in", "speakers", ":", "\n", "\n", "        ", "if", "only_common", ":", "\n", "            ", "output_dim", "=", "give_me_common_articulators", "(", "speaker", ")", "\n", "\n", "rmse", ",", "pearson", "=", "train_model_arti_common", "(", "test_on", "=", "speaker", ",", "n_epochs", "=", "n_epochs", ",", "loss_train", "=", "loss_train", ",", "patience", "=", "patience", ",", "\n", "corpus_to_train_on", "=", "corpus_to_train_on", ",", "\n", "batch_norma", "=", "batch_norma", ",", "filter_type", "=", "filter_type", ",", "to_plot", "=", "to_plot", ",", "\n", "lr", "=", "lr", ",", "delta_test", "=", "delta_test", ",", "config", "=", "'spec'", ",", "delta_valid", "=", "delta_valid", ")", "\n", "", "else", ":", "\n", "            ", "rmse", ",", "pearson", "=", "train_model", "(", "test_on", "=", "speaker", ",", "n_epochs", "=", "n_epochs", ",", "loss_train", "=", "loss_train", ",", "\n", "patience", "=", "patience", ",", "\n", "select_arti", "=", "select_arti", ",", "corpus_to_train_on", "=", "corpus_to_train_on", ",", "\n", "batch_norma", "=", "batch_norma", ",", "filter_type", "=", "filter_type", ",", "to_plot", "=", "to_plot", ",", "\n", "lr", "=", "lr", ",", "delta_test", "=", "delta_test", ",", "config", "=", "'spec'", ")", "\n", "\n", "", "print", "(", "\"for speaker test {} results are\"", ".", "format", "(", "speaker", ")", ")", "\n", "print", "(", "\"RMSE mean \"", ",", "rmse", ")", "\n", "print", "(", "\"PEARSON \"", ",", "pearson", ")", "\n", "today", "=", "date", ".", "today", "(", ")", ".", "strftime", "(", "\"%d/%m/%Y\"", ")", "\n", "\n", "with", "open", "(", "name", ",", "'a'", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "row_arti", "=", "[", "art", "[", "int", "(", "i", ")", "]", "for", "i", "in", "output_dim", "]", "\n", "row_rmse_mean", "=", "[", "today", ",", "speaker", ",", "loss_train", ",", "\"rmse_mean\"", "]", "+", "rmse", ".", "tolist", "(", ")", "\n", "\n", "row_pearson_mean", "=", "[", "today", ",", "speaker", ",", "loss_train", ",", "\"pearson_mean\"", "]", "+", "pearson", ".", "tolist", "(", ")", "\n", "\n", "for", "row", "in", "[", "row_arti", ",", "row_rmse_mean", ",", "row_pearson_mean", "]", ":", "\n", "                ", "writer", ".", "writerow", "(", "row", ")", "\n", "", "", "count", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.test.test_model": [[34, 170], ["print", "print", "print", "print", "print", "torch.cuda.is_available", "Training.model.my_ac2art_model", "model.to.double", "os.path.join", "os.path.join", "torch.load", "model.to.load_state_dict", "random.shuffle", "Training.tools_learning.load_np_ema_and_mfcc", "print", "numpy.load", "os.path.join", "os.path.join", "csv.register_dialect", "model.to.evaluate_on_test_modified", "torch.device", "torch.device", "len", "model.to.to", "Training.tools_learning.load_filenames", "Training.tools_learning.load_filenames", "os.path.join", "os.path.join", "open", "csv.reader", "next", "print", "scipy.signal.freqz", "matplotlib.plot", "matplotlib.title", "matplotlib.ylabel", "matplotlib.xlabel", "matplotlib.show", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "print", "csv.writer.writerow", "model_name.split", "Training.tools_learning.give_me_common_articulators", "Training.tools_learning.give_me_common_articulators", "Training.tools_learning.give_me_common_articulators", "sum", "weight_apres.cpu", "csv.writer.writerow", "name[].split", "model_name.split", "model_name.split", "range", "weight_apres.cpu", "numpy.log10", "print", "rmse_per_arti_mean.tolist", "rmse_per_arti_mean_without_std.tolist", "pearson_per_arti_mean.tolist", "model_name.split", "int", "len", "abs", "[].split", "[].split", "name[].split", "[].split", "name[].split"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.evaluate_on_test_modified", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_filenames", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_common_articulators", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_common_articulators", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_common_articulators"], ["def", "test_model", "(", "test_on", ",", "model_name", ",", "test_on_per_default", "=", "False", ",", ")", ":", "\n", "    ", "\"\"\"\n    :param test_on:  the speaker test\n    :param model_name: the name of the model (of the .txt file, without the \".txt\")\n    Need to have to weights of the models saved in a txt file located in Training/saved_models/\n    for example F01_speaker_indep_Haskins__loss_both_90_filter_fix_0.txt\n    The test speaker has to be precised (in fact readable in the begining of the filename ==> future work)\n    Depending on the configuration (read in the filename) it tests on parts of the test-speaker the model was not\n    trained on.\n    It also saves the graphs for one sentence of the predicted and true arti trajectories\n    \"\"\"", "\n", "arti_indexes", "=", "[", "]", "\n", "if", "'only_arti_common'", "in", "model_name", ":", "\n", "        ", "if", "\"train_indep\"", "in", "model_name", ":", "\n", "            ", "name", "=", "model_name", ".", "split", "(", "'train_indep'", ")", "\n", "test", "=", "name", "[", "0", "]", ".", "split", "(", "'_'", ")", "[", "3", "]", "\n", "try", ":", "\n", "                ", "train", "=", "[", "sp", "for", "sp", "in", "name", "[", "1", "]", ".", "split", "(", "'valid'", ")", "[", "0", "]", ".", "split", "(", "'_'", ")", "if", "(", "sp", "!=", "''", "and", "sp", "!=", "'train'", ")", "]", "\n", "", "except", ":", "\n", "                ", "train", "=", "[", "]", "\n", "", "try", ":", "\n", "                ", "valid", "=", "[", "sp", "for", "sp", "in", "name", "[", "1", "]", ".", "split", "(", "'valid'", ")", "[", "1", "]", ".", "split", "(", "'loss'", ")", "[", "0", "]", ".", "split", "(", "'_'", ")", "if", "(", "sp", "!=", "''", "and", "sp", "!=", "'train'", ")", "]", "\n", "", "except", ":", "\n", "                ", "valid", "=", "[", "]", "\n", "", "arti_indexes", "=", "give_me_common_articulators", "(", "[", "test", "]", "+", "train", "+", "valid", ")", "\n", "", "if", "\"spec\"", "in", "model_name", ":", "\n", "            ", "test", "=", "model_name", ".", "split", "(", "'_'", ")", "[", "3", "]", "\n", "train", "=", "[", "]", "\n", "valid", "=", "[", "]", "\n", "arti_indexes", "=", "give_me_common_articulators", "(", "[", "test", "]", "+", "train", "+", "valid", ")", "\n", "", "if", "'valid__'", "in", "model_name", "and", "'indep'", "in", "model_name", ":", "\n", "            ", "test", "=", "model_name", ".", "split", "(", "'_'", ")", "[", "3", "]", "\n", "train", "=", "[", "model_name", ".", "split", "(", "'_'", ")", "[", "6", "]", "]", "\n", "valid", "=", "[", "]", "\n", "arti_indexes", "=", "give_me_common_articulators", "(", "[", "test", "]", "+", "train", "+", "valid", ")", "\n", "\n", "\n", "", "if", "test_on_per_default", ":", "\n", "            ", "test_on", "=", "test", "\n", "", "", "else", ":", "\n", "        ", "train", "=", "[", "]", "\n", "valid", "=", "[", "]", "\n", "test", "=", "[", "]", "\n", "\n", "", "print", "(", "model_name", ")", "\n", "print", "(", "'train on'", ",", "train", ")", "\n", "print", "(", "'valid on'", ",", "valid", ")", "\n", "print", "(", "'tested on'", ",", "test", ")", "\n", "print", "(", "'here test on'", ",", "test_on", ")", "\n", "batch_norma", "=", "False", "\n", "filter_type", "=", "\"fix\"", "\n", "to_plot", "=", "False", "\n", "\n", "cuda_avail", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "if", "cuda_avail", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "hidden_dim", "=", "300", "\n", "input_dim", "=", "429", "\n", "batch_size", "=", "10", "\n", "output_dim", "=", "len", "(", "arti_indexes", ")", "if", "arti_indexes", "!=", "[", "]", "else", "18", "\n", "\n", "model", "=", "my_ac2art_model", "(", "hidden_dim", "=", "hidden_dim", ",", "input_dim", "=", "input_dim", ",", "output_dim", "=", "output_dim", ",", "\n", "batch_size", "=", "batch_size", ",", "cuda_avail", "=", "cuda_avail", ",", "name_file", "=", "model_name", ",", "\n", "filter_type", "=", "filter_type", ",", "batch_norma", "=", "batch_norma", ")", "\n", "model", "=", "model", ".", "double", "(", ")", "\n", "\n", "file_weights", "=", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "model_name", "+", "\".txt\"", ")", "\n", "\n", "if", "cuda_avail", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "\n", "", "loaded_state", "=", "torch", ".", "load", "(", "file_weights", ",", "map_location", "=", "device", ")", "\n", "\n", "model", ".", "load_state_dict", "(", "loaded_state", ")", "\n", "\n", "if", "\"indep\"", "in", "model_name", ":", "# the model was not trained on the test speaker", "\n", "        ", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"train\"", ",", "\"valid\"", ",", "\"test\"", "]", ")", "\n", "\n", "", "else", ":", "# specific or dependant learning", "\n", "        ", "files_for_test", "=", "load_filenames", "(", "[", "test_on", "]", ",", "part", "=", "[", "\"test\"", "]", ")", "\n", "\n", "\n", "", "random", ".", "shuffle", "(", "files_for_test", ")", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_for_test", ")", "\n", "print", "(", "\"evaluation on speaker {}\"", ".", "format", "(", "test_on", ")", ")", "\n", "std_speaker", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessing\"", ",", "\"norm_values\"", ",", "\"std_ema_\"", "+", "test_on", "+", "\".npy\"", ")", ")", "\n", "arti_per_speaker", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessing\"", ",", "\"articulators_per_speaker.csv\"", ")", "\n", "csv", ".", "register_dialect", "(", "'myDialect'", ",", "delimiter", "=", "';'", ")", "\n", "weight_apres", "=", "model", ".", "lowpass", ".", "weight", ".", "data", "[", "0", ",", "0", ",", ":", "]", "\n", "\n", "with", "open", "(", "arti_per_speaker", ",", "'r'", ")", "as", "csvFile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "csvFile", ",", "dialect", "=", "\"myDialect\"", ")", "\n", "next", "(", "reader", ")", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "if", "row", "[", "0", "]", "==", "test_on", ":", "\n", "                ", "arti_to_consider", "=", "row", "[", "1", ":", "19", "]", "\n", "arti_to_consider", "=", "[", "int", "(", "x", ")", "for", "x", "in", "arti_to_consider", "]", "\n", "", "", "", "if", "arti_indexes", "!=", "[", "]", ":", "\n", "        ", "arti_to_consider", "=", "[", "1", "for", "k", "in", "range", "(", "len", "(", "arti_indexes", ")", ")", "]", "\n", "\n", "", "rmse_per_arti_mean", ",", "rmse_per_arti_mean_without_std", ",", "pearson_per_arti_mean", "=", "model", ".", "evaluate_on_test_modified", "(", "x", ",", "y", ",", "std_speaker", "=", "std_speaker", ",", "to_plot", "=", "to_plot", "\n", ",", "to_consider", "=", "arti_to_consider", ",", "verbose", "=", "False", ",", "\n", "index_common", "=", "arti_indexes", ")", "\n", "\n", "\n", "show_filter", "=", "False", "#add it in argument", "\n", "if", "show_filter", ":", "\n", "        ", "weight_apres", "=", "model", ".", "lowpass", ".", "weight", ".", "data", "[", "0", ",", "0", ",", ":", "]", "\n", "print", "(", "\"GAIN\"", ",", "sum", "(", "weight_apres", ".", "cpu", "(", ")", ")", ")", "\n", "freqs", ",", "h", "=", "signal", ".", "freqz", "(", "weight_apres", ".", "cpu", "(", ")", ")", "\n", "freqs", "=", "freqs", "*", "100", "/", "(", "2", "*", "np", ".", "pi", ")", "# freq in hz", "\n", "plt", ".", "plot", "(", "freqs", ",", "20", "*", "np", ".", "log10", "(", "abs", "(", "h", ")", ")", ",", "'r'", ")", "\n", "plt", ".", "title", "(", "\"Allure filtre passe bas \u00e0 la fin de l'Training pour filtre en dur\"", ")", "\n", "plt", ".", "ylabel", "(", "'Amplitude [dB]'", ")", "\n", "plt", ".", "xlabel", "(", "\"real frequency\"", ")", "\n", "plt", ".", "show", "(", ")", "\n", "\n", "", "with", "open", "(", "'model_results_test.csv'", ",", "'a'", ",", "newline", "=", "\"\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ",", "delimiter", "=", "\",\"", ")", "\n", "try", ":", "\n", "            ", "row_arti", "=", "[", "'model'", ",", "'test on'", ",", "'value'", "]", "+", "[", "articulators", "[", "i", "]", "for", "i", "in", "arti_indexes", "]", "\n", "writer", ".", "writerow", "(", "row_arti", ")", "\n", "", "except", ":", "\n", "            ", "print", "(", "'error'", ")", "\n", "", "row_rmse", "=", "[", "model_name", ",", "test_on", ",", "\"rmse\"", "]", "+", "rmse_per_arti_mean", ".", "tolist", "(", ")", "+", "[", "model", ".", "epoch_ref", "]", "\n", "writer", ".", "writerow", "(", "row_rmse", ")", "\n", "row_rmse_without_std", "=", "[", "model_name", ",", "test_on", ",", "\"rmse without std\"", "]", "+", "rmse_per_arti_mean_without_std", ".", "tolist", "(", ")", "+", "[", "model", ".", "epoch_ref", "]", "\n", "writer", ".", "writerow", "(", "row_rmse_without_std", ")", "\n", "row_pearson", "=", "[", "model_name", ",", "test_on", ",", "\"pearson\"", "]", "+", "pearson_per_arti_mean", ".", "tolist", "(", ")", "+", "[", "model", ".", "epoch_ref", "]", "\n", "print", "(", "row_pearson", ")", "\n", "writer", ".", "writerow", "(", "row_pearson", ")", "\n", "\n", "", "return", "rmse_per_arti_mean", ",", "pearson_per_arti_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.__init__": [[51, 105], ["super().__init__", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.LSTM", "torch.nn.BatchNorm1d", "torch.nn.LSTM", "torch.nn.BatchNorm1d", "torch.nn.Linear", "torch.nn.Sigmoid", "torch.nn.Softmax", "torch.nn.Tanh", "model.my_ac2art_model.init_filter_layer", "torch.device"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.__init__", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.init_filter_layer"], ["def", "__init__", "(", "self", ",", "hidden_dim", ",", "input_dim", ",", "output_dim", ",", "batch_size", ",", "name_file", "=", "\"\"", ",", "sampling_rate", "=", "100", ",", "\n", "cutoff", "=", "10", ",", "cuda_avail", "=", "False", ",", "filter_type", "=", "1", ",", "batch_norma", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param hidden_dim: int, hidden dimension of lstm (usually 300)\n        :param input_dim: int, input dimension of the acoustic features for 1 frame mfcc (usually 429)\n        :param output_dim: int, # of trajectories to predict (usually 18)\n        :param batch_size:  int, usually 10\n        :param name_file: str, name of the model\n        :param sampling_rate: int, sampling rate of the ema data for the smoothing (usually 100)\n        :param cutoff: int, intial cutoff frequency for the smoothing, usually 10Hz\n        :param cuda_avail: bool, whether gpu is available\n        :param filter type: str, \"out\": filter outside the nn, \"fix\" : weights are FIXED,\n        \"unfix\" : weights are updated during the training\n        :param batch_norma: bool, whether to add batch normalization after the lstm layers\n        \"\"\"", "\n", "super", "(", "my_ac2art_model", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "input_dim", "=", "input_dim", "\n", "self", ".", "output_dim", "=", "output_dim", "\n", "self", ".", "hidden_dim", "=", "hidden_dim", "\n", "self", ".", "first_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "input_dim", ",", "hidden_dim", ")", "\n", "self", ".", "second_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", ",", "hidden_dim", ")", "\n", "self", ".", "last_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "output_dim", ",", "output_dim", ")", "\n", "self", ".", "lstm_layer", "=", "torch", ".", "nn", ".", "LSTM", "(", "input_size", "=", "hidden_dim", ",", "\n", "hidden_size", "=", "hidden_dim", ",", "num_layers", "=", "1", ",", "\n", "bidirectional", "=", "True", ")", "\n", "self", ".", "batch_norm_layer", "=", "torch", ".", "nn", ".", "BatchNorm1d", "(", "hidden_dim", "*", "2", ")", "\n", "self", ".", "lstm_layer_2", "=", "torch", ".", "nn", ".", "LSTM", "(", "input_size", "=", "hidden_dim", "*", "2", ",", "\n", "hidden_size", "=", "hidden_dim", ",", "num_layers", "=", "1", ",", "\n", "bidirectional", "=", "True", ")", "\n", "self", ".", "batch_norm_layer_2", "=", "torch", ".", "nn", ".", "BatchNorm1d", "(", "hidden_dim", "*", "2", ")", "\n", "self", ".", "readout_layer", "=", "torch", ".", "nn", ".", "Linear", "(", "hidden_dim", "*", "2", ",", "output_dim", ")", "\n", "self", ".", "batch_size", "=", "batch_size", "\n", "self", ".", "sigmoid", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", "\n", "self", ".", "filter_type", "=", "filter_type", "\n", "self", ".", "softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "output_dim", ")", "\n", "self", ".", "tanh", "=", "torch", ".", "nn", ".", "Tanh", "(", ")", "\n", "self", ".", "sampling_rate", "=", "sampling_rate", "\n", "self", ".", "cutoff", "=", "cutoff", "\n", "self", ".", "N", "=", "None", "\n", "self", ".", "min_valid_error", "=", "100000", "\n", "self", ".", "all_training_loss", "=", "[", "]", "\n", "self", ".", "all_validation_loss", "=", "[", "]", "\n", "self", ".", "all_test_loss", "=", "[", "]", "\n", "self", ".", "name_file", "=", "name_file", "\n", "self", ".", "lowpass", "=", "None", "\n", "self", ".", "init_filter_layer", "(", ")", "\n", "self", ".", "cuda_avail", "=", "cuda_avail", "\n", "\n", "self", ".", "epoch_ref", "=", "0", "\n", "self", ".", "batch_norma", "=", "batch_norma", "\n", "if", "cuda_avail", ":", "\n", "            ", "self", ".", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "device", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.prepare_batch": [[106, 129], ["numpy.max", "len", "torch.zeros", "torch.zeros", "range", "torch.zeros.view", "torch.zeros.view", "torch.nn.ZeroPad2d", "torch.nn.ZeroPad2d.double", "torch.nn.ZeroPad2d.double", "len", "torch.nn.ZeroPad2d.", "torch.nn.ZeroPad2d.", "len", "torch.from_numpy", "torch.from_numpy"], "methods", ["None"], ["", "", "def", "prepare_batch", "(", "self", ",", "x", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        :param x: list of B(batchsize) acoustic trajectories of variable lenghts,\n        each element of the list is an array (K,18)  (K not always the same)\n        :param y: list of B(batchsize) articulatory features,\n        each element of the list is an array (K,429) (K not always the same)\n        :return: 2 np array of sizes (B, K_max, 18) and (B, K_max, 429\n        x,y initially data of the batch with different sizes . the script zeropad the acoustic and\n        articulatory sequences so that all element in the batch have the same size\n        \"\"\"", "\n", "\n", "max_length", "=", "np", ".", "max", "(", "[", "len", "(", "phrase", ")", "for", "phrase", "in", "x", "]", ")", "\n", "B", "=", "len", "(", "x", ")", "# often batch size but not for validation", "\n", "new_x", "=", "torch", ".", "zeros", "(", "(", "B", ",", "max_length", ",", "self", ".", "input_dim", ")", ",", "dtype", "=", "torch", ".", "double", ")", "\n", "new_y", "=", "torch", ".", "zeros", "(", "(", "B", ",", "max_length", ",", "self", ".", "output_dim", ")", ",", "dtype", "=", "torch", ".", "double", ")", "\n", "for", "j", "in", "range", "(", "B", ")", ":", "\n", "            ", "zeropad", "=", "torch", ".", "nn", ".", "ZeroPad2d", "(", "(", "0", ",", "0", ",", "0", ",", "max_length", "-", "len", "(", "x", "[", "j", "]", ")", ")", ")", "\n", "new_x", "[", "j", "]", "=", "zeropad", "(", "torch", ".", "from_numpy", "(", "x", "[", "j", "]", ")", ")", ".", "double", "(", ")", "\n", "new_y", "[", "j", "]", "=", "zeropad", "(", "torch", ".", "from_numpy", "(", "y", "[", "j", "]", ")", ")", ".", "double", "(", ")", "\n", "", "x", "=", "new_x", ".", "view", "(", "(", "B", ",", "max_length", ",", "self", ".", "input_dim", ")", ")", "\n", "y", "=", "new_y", ".", "view", "(", "(", "B", ",", "max_length", ",", "self", ".", "output_dim", ")", ")", "\n", "\n", "return", "x", ",", "y", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.forward": [[130, 157], ["torch.nn.functional.relu", "torch.nn.functional.relu", "model.my_ac2art_model.lstm_layer", "torch.nn.functional.relu", "model.my_ac2art_model.lstm_layer_2", "torch.nn.functional.relu", "model.my_ac2art_model.readout_layer", "model.my_ac2art_model.first_layer", "model.my_ac2art_model.second_layer", "torch.nn.functional.relu.view.view", "torch.nn.functional.relu", "torch.nn.functional.relu.view", "torch.nn.functional.relu.view.view", "torch.nn.functional.relu", "torch.nn.functional.relu.view", "model.my_ac2art_model.filter_layer", "model.my_ac2art_model.batch_norm_layer", "model.my_ac2art_model.batch_norm_layer_2"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.filter_layer"], ["", "def", "forward", "(", "self", ",", "x", ",", "filter_output", "=", "None", ")", ":", "\n", "        ", "\"\"\"\n        :param x: (Batchsize,K,429)  acoustic features corresponding to batch size\n        :param filter_output: whether or not to pass throught the convolutional layer\n        :return: the articulatory prediction (Batchsize, K,18) based on the current weights\n        \"\"\"", "\n", "if", "filter_output", "is", "None", ":", "\n", "            ", "filter_output", "=", "(", "self", ".", "filter_type", "!=", "\"out\"", ")", "\n", "", "dense_out", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "self", ".", "first_layer", "(", "x", ")", ")", "\n", "dense_out_2", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "self", ".", "second_layer", "(", "dense_out", ")", ")", "\n", "lstm_out", ",", "hidden_dim", "=", "self", ".", "lstm_layer", "(", "dense_out_2", ")", "\n", "B", "=", "lstm_out", ".", "shape", "[", "0", "]", "#presque tjrs batch size", "\n", "if", "self", ".", "batch_norma", ":", "\n", "            ", "lstm_out_temp", "=", "lstm_out", ".", "view", "(", "B", ",", "2", "*", "self", ".", "hidden_dim", ",", "-", "1", ")", "\n", "lstm_out_temp", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "self", ".", "batch_norm_layer", "(", "lstm_out_temp", ")", ")", "\n", "lstm_out", "=", "lstm_out_temp", ".", "view", "(", "B", ",", "-", "1", ",", "2", "*", "self", ".", "hidden_dim", ")", "\n", "", "lstm_out", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "lstm_out", ")", "\n", "lstm_out", ",", "hidden_dim", "=", "self", ".", "lstm_layer_2", "(", "lstm_out", ")", "\n", "if", "self", ".", "batch_norma", ":", "\n", "            ", "lstm_out_temp", "=", "lstm_out", ".", "view", "(", "B", ",", "2", "*", "self", ".", "hidden_dim", ",", "-", "1", ")", "\n", "lstm_out_temp", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "self", ".", "batch_norm_layer_2", "(", "lstm_out_temp", ")", ")", "\n", "lstm_out", "=", "lstm_out_temp", ".", "view", "(", "B", ",", "-", "1", ",", "2", "*", "self", ".", "hidden_dim", ")", "\n", "", "lstm_out", "=", "torch", ".", "nn", ".", "functional", ".", "relu", "(", "lstm_out", ")", "\n", "y_pred", "=", "self", ".", "readout_layer", "(", "lstm_out", ")", "\n", "if", "filter_output", ":", "\n", "            ", "y_pred", "=", "self", ".", "filter_layer", "(", "y_pred", ")", "\n", "", "return", "y_pred", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.get_filter_weights": [[158, 183], ["torch.tensor().view", "torch.div", "int", "torch.arange().double", "torch.mul().double", "torch.tensor", "torch.max", "torch.div", "torch.mul", "torch.div", "Exception", "numpy.ceil", "torch.sin", "torch.sum", "torch.tensor", "torch.arange", "torch.mul", "torch.cos"], "methods", ["None"], ["", "def", "get_filter_weights", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return: low pass filter weights based on calculus exclusively using tensors so pytorch compatible\n        \"\"\"", "\n", "cutoff", "=", "torch", ".", "tensor", "(", "self", ".", "cutoff", ",", "dtype", "=", "torch", ".", "float64", ",", "requires_grad", "=", "True", ")", ".", "view", "(", "1", ",", "1", ")", "\n", "fc", "=", "torch", ".", "div", "(", "cutoff", ",", "\n", "self", ".", "sampling_rate", ")", "# Cutoff frequency as a fraction of the sampling rate (in (0, 0.5)).", "\n", "if", "fc", ">", "0.5", ":", "\n", "            ", "raise", "Exception", "(", "\"cutoff frequency must be at least twice sampling rate\"", ")", "\n", "", "b", "=", "0.08", "# Transition band, as a fraction of the sampling rate (in (0, 0.5)).", "\n", "N", "=", "int", "(", "np", ".", "ceil", "(", "(", "4", "/", "b", ")", ")", ")", "# le window", "\n", "if", "not", "N", "%", "2", ":", "\n", "            ", "N", "+=", "1", "# Make sure that N is odd .", "\n", "", "self", ".", "N", "=", "N", "\n", "\n", "n", "=", "torch", ".", "arange", "(", "N", ")", ".", "double", "(", ")", "\n", "alpha", "=", "torch", ".", "mul", "(", "fc", ",", "2", "*", "(", "n", "-", "(", "N", "-", "1", ")", "/", "2", ")", ")", ".", "double", "(", ")", "\n", "minim", "=", "torch", ".", "tensor", "(", "0.01", ",", "dtype", "=", "torch", ".", "float64", ")", "#utile ?", "\n", "alpha", "=", "torch", ".", "max", "(", "alpha", ",", "minim", ")", "#utile ?", "\n", "h", "=", "torch", ".", "div", "(", "torch", ".", "sin", "(", "alpha", ")", ",", "alpha", ")", "\n", "beta", "=", "n", "*", "2", "*", "math", ".", "pi", "/", "(", "N", "-", "1", ")", "\n", "w", "=", "0.5", "*", "(", "1", "-", "torch", ".", "cos", "(", "beta", ")", ")", "# Compute hanning window.", "\n", "h", "=", "torch", ".", "mul", "(", "h", ",", "w", ")", "# Multiply sinc filter with window.", "\n", "h", "=", "torch", ".", "div", "(", "h", ",", "torch", ".", "sum", "(", "h", ")", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.get_filter_weights_en_dur": [[184, 202], ["int", "numpy.arange", "numpy.sinc", "torch.tensor", "Exception", "numpy.ceil", "numpy.sum", "numpy.cos"], "methods", ["None"], ["", "def", "get_filter_weights_en_dur", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        :return:  low pass filter weights using classical primitive (not on tensor)\n        \"\"\"", "\n", "fc", "=", "self", ".", "cutoff", "/", "self", ".", "sampling_rate", "\n", "if", "fc", ">", "0.5", ":", "\n", "            ", "raise", "Exception", "(", "\"La frequence de coupure doit etre au moins deux fois la frequence dechantillonnage\"", ")", "\n", "", "b", "=", "0.08", "# Transition band, as a fraction of the sampling rate (in (0, 0.5)).", "\n", "N", "=", "int", "(", "np", ".", "ceil", "(", "(", "4", "/", "b", ")", ")", ")", "# le window", "\n", "if", "not", "N", "%", "2", ":", "\n", "            ", "N", "+=", "1", "# Make sure that N is odd.", "\n", "", "self", ".", "N", "=", "N", "\n", "n", "=", "np", ".", "arange", "(", "N", ")", "\n", "h", "=", "np", ".", "sinc", "(", "fc", "*", "2", "*", "(", "n", "-", "(", "N", "-", "1", ")", "/", "2", ")", ")", "\n", "w", "=", "0.5", "*", "(", "1", "-", "np", ".", "cos", "(", "n", "*", "2", "*", "math", ".", "pi", "/", "(", "N", "-", "1", ")", ")", ")", "# Compute hanning window.", "\n", "h", "=", "h", "*", "w", "\n", "h", "=", "h", "/", "np", ".", "sum", "(", "h", ")", "\n", "return", "torch", ".", "tensor", "(", "h", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.init_filter_layer": [[203, 231], ["model.my_ac2art_model.view", "torch.nn.Conv1d", "lowpass.double.double.double", "model.my_ac2art_model.get_filter_weights_en_dur", "int", "torch.nn.Parameter", "torch.nn.Parameter", "model.my_ac2art_model.get_filter_weights"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.get_filter_weights_en_dur", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.get_filter_weights"], ["", "def", "init_filter_layer", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        intialize the weights of the convolution in the NN,  so that it acts as a lowpass filter.\n        the typefilter determines if the weights will be updated during the optim of the NN\n        \"\"\"", "\n", "\n", "\n", "# maybe the two functions do exactly the same...", "\n", "\n", "if", "self", ".", "filter_type", "in", "[", "\"out\"", ",", "\"fix\"", "]", ":", "\n", "            ", "weight_init", "=", "self", ".", "get_filter_weights_en_dur", "(", ")", "\n", "", "elif", "self", ".", "filter_type", "==", "\"unfix\"", ":", "\n", "            ", "weight_init", "=", "self", ".", "get_filter_weights", "(", ")", "\n", "", "C_in", "=", "1", "\n", "stride", "=", "1", "\n", "must_be_5", "=", "5", "\n", "padding", "=", "int", "(", "0.5", "*", "(", "(", "C_in", "-", "1", ")", "*", "stride", "-", "C_in", "+", "must_be_5", ")", ")", "+", "23", "\n", "weight_init", "=", "weight_init", ".", "view", "(", "(", "1", ",", "1", ",", "-", "1", ")", ")", "\n", "lowpass", "=", "torch", ".", "nn", ".", "Conv1d", "(", "C_in", ",", "self", ".", "output_dim", ",", "self", ".", "N", ",", "stride", "=", "1", ",", "padding", "=", "padding", ",", "bias", "=", "False", ")", "\n", "\n", "if", "self", ".", "filter_type", "==", "\"unfix\"", ":", "# we let the weights move", "\n", "            ", "lowpass", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "weight_init", ",", "requires_grad", "=", "True", ")", "\n", "\n", "", "else", ":", "# \"out\" we don't care the filter won't be applied, or \"fix\" the wieghts are fixed", "\n", "            ", "lowpass", ".", "weight", "=", "torch", ".", "nn", ".", "Parameter", "(", "weight_init", ",", "requires_grad", "=", "False", ")", "\n", "\n", "", "lowpass", "=", "lowpass", ".", "double", "(", ")", "\n", "self", ".", "lowpass", "=", "lowpass", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.filter_layer": [[232, 248], ["len", "len", "y.double.double.double", "torch.zeros", "range", "y[].view", "model.my_ac2art_model.lowpass", "traj_arti_smoothed.view.view.view"], "methods", ["None"], ["", "def", "filter_layer", "(", "self", ",", "y", ")", ":", "\n", "        ", "\"\"\"\n        :param y: (B,L,18) articulatory prediction not smoothed\n        :return:  smoothed articulatory prediction\n        apply the convolution to each articulation, maybe not the best solution (changing n_channel of the conv layer ?)\n        \"\"\"", "\n", "B", "=", "len", "(", "y", ")", "\n", "L", "=", "len", "(", "y", "[", "0", "]", ")", "\n", "y", "=", "y", ".", "double", "(", ")", "\n", "y_smoothed", "=", "torch", ".", "zeros", "(", "B", ",", "L", ",", "self", ".", "output_dim", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "output_dim", ")", ":", "\n", "            ", "traj_arti", "=", "y", "[", ":", ",", ":", ",", "i", "]", ".", "view", "(", "B", ",", "1", ",", "L", ")", "\n", "traj_arti_smoothed", "=", "self", ".", "lowpass", "(", "traj_arti", ")", "\n", "traj_arti_smoothed", "=", "traj_arti_smoothed", ".", "view", "(", "B", ",", "L", ")", "\n", "y_smoothed", "[", ":", ",", ":", ",", "i", "]", "=", "traj_arti_smoothed", "\n", "", "return", "y_smoothed", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.plot_results": [[249, 280], ["print", "matplotlib.figure", "matplotlib.figure", "matplotlib.plot", "matplotlib.plot", "matplotlib.title", "os.path.join", "matplotlib.savefig", "matplotlib.close", "range", "matplotlib.plot", "matplotlib.legend", "matplotlib.legend", "len"], "methods", ["None"], ["", "def", "plot_results", "(", "self", ",", "y_target", "=", "None", ",", "y_pred_smoothed", "=", "None", ",", "y_pred_not_smoothed", "=", "None", ",", "to_cons", "=", "[", "]", ")", ":", "\n", "        ", "\"\"\"\n        :param y: one TRUE arti trajectory\n        :param y_pred_not_smoothed: one predicted arti trajectory not smoothed (forward with filtered=False)\n        :param y_pred_smoothed:  one predicted arti trajectory (smoothed)\n        :param to_cons:  articulations available to consider (list of 0/1)\n        save the graph of each available trajectory predicted and true.\n        If y_pred is given, also plot the non smoothed pred\n        [future work : change filename and title of the graph]\n        \"\"\"", "\n", "print", "(", "\"you chose to plot\"", ")", "\n", "plt", ".", "figure", "(", ")", "\n", "articulators", "=", "[", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", ",", "\n", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", ",", "'la'", ",", "'lp'", ",", "'ttcl'", ",", "'tbcl'", ",", "'v_x'", ",", "'v_y'", "]", "\n", "idx_to_cons", "=", "[", "k", "for", "k", "in", "range", "(", "len", "(", "to_cons", ")", ")", "if", "to_cons", "[", "k", "]", "]", "\n", "for", "j", "in", "idx_to_cons", ":", "\n", "            ", "plt", ".", "figure", "(", ")", "\n", "\n", "plt", ".", "plot", "(", "y_target", "[", ":", ",", "j", "]", ")", "\n", "plt", ".", "plot", "(", "y_pred_smoothed", "[", ":", ",", "j", "]", ")", "\n", "if", "y_pred_not_smoothed", "is", "not", "None", ":", "\n", "                ", "plt", ".", "plot", "(", "y_pred_not_smoothed", "[", ":", ",", "j", "]", ",", "alpha", "=", "0.6", ")", "\n", "", "plt", ".", "title", "(", "\"{0}_{1}.png\"", ".", "format", "(", "self", ".", "name_file", ",", "articulators", "[", "j", "]", ")", ")", "\n", "if", "y_pred_not_smoothed", "is", "not", "None", ":", "\n", "                ", "plt", ".", "legend", "(", "[", "\"target\"", ",", "\"pred smoothed\"", ",", "\"pred not smoothed\"", "]", ")", "\n", "", "else", ":", "\n", "                ", "plt", ".", "legend", "(", "[", "\"target\"", ",", "\"pred smoothed\"", "]", ")", "\n", "", "save_pics_path", "=", "os", ".", "path", ".", "join", "(", "\n", "\"images_predictions\\\\{0}_{1}.png\"", ".", "format", "(", "self", ".", "name_file", ",", "articulators", "[", "j", "]", ")", ")", "\n", "plt", ".", "savefig", "(", "save_pics_path", ")", "\n", "plt", ".", "close", "(", "'all'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.evaluate_on_test": [[281, 344], ["numpy.zeros", "numpy.zeros", "range", "numpy.mean", "numpy.mean", "numpy.random.choice", "len", "len", "torch.from_numpy().view", "Y_test[].reshape", "model.my_ac2art_model.double", "model.my_ac2art_model.double", "y_pred_not_smoothed.cpu.cpu.detach().numpy().reshape", "y_pred_smoothed.cpu.cpu.detach().numpy().reshape", "numpy.sqrt", "numpy.reshape", "numpy.concatenate", "range", "numpy.array().reshape", "numpy.concatenate", "print", "print", "print", "print", "range", "len", "Training.tools_learning.get_right_indexes", "x_torch.to.to.to", "y_pred_not_smoothed.cpu.cpu.cpu", "y_pred_smoothed.cpu.cpu.cpu", "numpy.mean", "Training.tools_learning.get_right_indexes", "numpy.isnan", "numpy.mean", "numpy.mean", "len", "torch.from_numpy", "model.my_ac2art_model.", "model.my_ac2art_model.", "y_pred_not_smoothed.cpu.cpu.detach().numpy", "y_pred_smoothed.cpu.cpu.detach().numpy", "model.my_ac2art_model.plot_results", "numpy.square", "numpy.corrcoef", "numpy.array", "y_pred_not_smoothed.cpu.cpu.detach", "y_pred_smoothed.cpu.cpu.detach"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.plot_results"], ["", "", "def", "evaluate_on_test", "(", "self", ",", "X_test", ",", "Y_test", ",", "std_speaker", ",", "to_plot", "=", "False", ",", "to_consider", "=", "None", ",", "verbose", "=", "True", ",", "index_common", "=", "[", "]", ",", "no_std", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param X_test:  list of all the input of the test set\n        :param Y_test:  list of all the target of the test set\n        :param std_speaker : list of the std of each articulator, useful to calculate the RMSE of the predicction\n        :param to_plot: wether or not we want to save some predicted smoothed and not and true trajectory\n        :param to_consider: list of 0/1 for the test speaker , 1 if the articulator is ok for the test speaker\n        :return: print and return the pearson correlation and RMSE between real and predicted trajectories per articulators.\n        \"\"\"", "\n", "idx_to_ignore", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "to_consider", ")", ")", "if", "not", "(", "to_consider", "[", "i", "]", ")", "]", "\n", "all_diff", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "all_pearson", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "if", "to_plot", ":", "\n", "            ", "indices_to_plot", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "X_test", ")", ",", "2", ",", "replace", "=", "False", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "X_test", ")", ")", ":", "\n", "            ", "L", "=", "len", "(", "X_test", "[", "i", "]", ")", "\n", "x_torch", "=", "torch", ".", "from_numpy", "(", "X_test", "[", "i", "]", ")", ".", "view", "(", "1", ",", "L", ",", "self", ".", "input_dim", ")", "#x (1,L,429)", "\n", "y", "=", "Y_test", "[", "i", "]", ".", "reshape", "(", "(", "L", ",", "18", ")", ")", "#y (L,13)", "\n", "if", "index_common", "!=", "[", "]", ":", "\n", "                ", "y", "=", "get_right_indexes", "(", "y", ",", "index_common", ",", "shape", "=", "2", ")", "\n", "", "if", "self", ".", "cuda_avail", ":", "\n", "                ", "x_torch", "=", "x_torch", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "", "y_pred_not_smoothed", "=", "self", "(", "x_torch", ",", "False", ")", ".", "double", "(", ")", "#output y_pred (1,L,13)", "\n", "y_pred_smoothed", "=", "self", "(", "x_torch", ",", "True", ")", ".", "double", "(", ")", "\n", "if", "self", ".", "cuda_avail", ":", "\n", "                ", "y_pred_not_smoothed", "=", "y_pred_not_smoothed", ".", "cpu", "(", ")", "\n", "y_pred_smoothed", "=", "y_pred_smoothed", ".", "cpu", "(", ")", "\n", "", "y_pred_not_smoothed", "=", "y_pred_not_smoothed", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "(", "L", ",", "self", ".", "output_dim", ")", ")", "# y_pred (L,13)", "\n", "y_pred_smoothed", "=", "y_pred_smoothed", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "(", "L", ",", "self", ".", "output_dim", ")", ")", "# y_pred (L,13)", "\n", "if", "to_plot", ":", "\n", "                ", "if", "i", "in", "indices_to_plot", ":", "\n", "                    ", "self", ".", "plot_results", "(", "y_target", "=", "y", ",", "y_pred_smoothed", "=", "y_pred_smoothed", ",", "\n", "y_pred_not_smoothed", "=", "y_pred_not_smoothed", ",", "to_cons", "=", "to_consider", ")", "\n", "", "", "rmse", "=", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "np", ".", "square", "(", "y", "-", "y_pred_smoothed", ")", ",", "axis", "=", "0", ")", ")", "# calculate rmse", "\n", "rmse", "=", "np", ".", "reshape", "(", "rmse", ",", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "\n", "std_to_modify", "=", "std_speaker", "\n", "if", "index_common", "!=", "[", "]", "and", "not", "no_std", ":", "\n", "                ", "std_to_modify", "=", "get_right_indexes", "(", "std_to_modify", ",", "index_common", ",", "shape", "=", "1", ")", "\n", "", "rmse", "=", "rmse", "*", "std_to_modify", "# unormalize", "\n", "all_diff", "=", "np", ".", "concatenate", "(", "(", "all_diff", ",", "rmse", ")", ")", "\n", "pearson", "=", "[", "0", "]", "*", "self", ".", "output_dim", "\n", "for", "k", "in", "range", "(", "self", ".", "output_dim", ")", ":", "\n", "                ", "pearson", "[", "k", "]", "=", "np", ".", "corrcoef", "(", "y", "[", ":", ",", "k", "]", ".", "T", ",", "y_pred_smoothed", "[", ":", ",", "k", "]", ".", "T", ")", "[", "0", ",", "1", "]", "\n", "", "pearson", "=", "np", ".", "array", "(", "pearson", ")", ".", "reshape", "(", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "all_pearson", "=", "np", ".", "concatenate", "(", "(", "all_pearson", ",", "pearson", ")", ")", "\n", "", "all_pearson", "=", "all_pearson", "[", "1", ":", "]", "\n", "if", "index_common", "==", "[", "]", ":", "\n", "            ", "all_pearson", "[", ":", ",", "idx_to_ignore", "]", "=", "0", "\n", "", "all_diff", "=", "all_diff", "[", "1", ":", "]", "\n", "if", "index_common", "==", "[", "]", ":", "\n", "            ", "all_diff", "[", ":", ",", "idx_to_ignore", "]", "=", "0", "\n", "", "all_pearson", "[", "np", ".", "isnan", "(", "all_pearson", ")", "]", "=", "0", "\n", "\n", "pearson_per_arti_mean", "=", "np", ".", "mean", "(", "all_pearson", ",", "axis", "=", "0", ")", "\n", "rmse_per_arti_mean", "=", "np", ".", "mean", "(", "all_diff", ",", "axis", "=", "0", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"rmse final : \"", ",", "np", ".", "mean", "(", "rmse_per_arti_mean", "[", "rmse_per_arti_mean", "!=", "0", "]", ")", ")", "\n", "print", "(", "\"rmse mean per arti : \\n\"", ",", "rmse_per_arti_mean", ")", "\n", "print", "(", "\"pearson final : \"", ",", "np", ".", "mean", "(", "pearson_per_arti_mean", "[", "pearson_per_arti_mean", "!=", "0", "]", ")", ")", "\n", "print", "(", "\"pearson mean per arti : \\n\"", ",", "pearson_per_arti_mean", ")", "\n", "\n", "", "return", "rmse_per_arti_mean", ",", "pearson_per_arti_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.evaluate_on_test_modified": [[345, 414], ["numpy.zeros", "numpy.zeros", "numpy.zeros", "range", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.random.choice", "len", "len", "torch.from_numpy().view", "Y_test[].reshape", "model.my_ac2art_model.double", "model.my_ac2art_model.double", "y_pred_not_smoothed.cpu.cpu.detach().numpy().reshape", "y_pred_smoothed.cpu.cpu.detach().numpy().reshape", "numpy.sqrt", "numpy.reshape", "numpy.concatenate", "numpy.concatenate", "y_pred_smoothed.cpu.cpu.reshape", "torch.from_numpy", "torch.from_numpy", "Training.tools_learning.criterion_pearson_no_reduction", "pearson_per_art.reshape.reshape.reshape", "numpy.concatenate", "print", "print", "print", "print", "range", "len", "Training.tools_learning.get_right_indexes", "x_torch.to.to.to", "y_pred_not_smoothed.cpu.cpu.cpu", "y_pred_smoothed.cpu.cpu.cpu", "numpy.mean", "Training.tools_learning.get_right_indexes", "Training.tools_learning.get_right_indexes.reshape", "numpy.isnan", "numpy.mean", "numpy.mean", "len", "torch.from_numpy", "model.my_ac2art_model.", "model.my_ac2art_model.", "y_pred_not_smoothed.cpu.cpu.detach().numpy", "y_pred_smoothed.cpu.cpu.detach().numpy", "model.my_ac2art_model.plot_results", "numpy.square", "y_pred_not_smoothed.cpu.cpu.detach", "y_pred_smoothed.cpu.cpu.detach"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_pearson_no_reduction", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.plot_results"], ["", "def", "evaluate_on_test_modified", "(", "self", ",", "X_test", ",", "Y_test", ",", "std_speaker", ",", "to_plot", "=", "False", ",", "to_consider", "=", "None", ",", "verbose", "=", "True", ",", "index_common", "=", "[", "]", ",", "no_std", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        :param X_test:  list of all the input of the test set\n        :param Y_test:  list of all the target of the test set\n        :param std_speaker : list of the std of each articulator, useful to calculate the RMSE of the predicction\n        :param to_plot: wether or not we want to save some predicted smoothed and not and true trajectory\n        :param to_consider: list of 0/1 for the test speaker , 1 if the articulator is ok for the test speaker\n        :return: print and return the pearson correlation and RMSE between real and predicted trajectories per articulators.\n        \"\"\"", "\n", "idx_to_ignore", "=", "[", "i", "for", "i", "in", "range", "(", "len", "(", "to_consider", ")", ")", "if", "not", "(", "to_consider", "[", "i", "]", ")", "]", "\n", "all_diff", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "all_diff_without_std", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "all_pearson", "=", "np", ".", "zeros", "(", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "if", "to_plot", ":", "\n", "            ", "indices_to_plot", "=", "np", ".", "random", ".", "choice", "(", "len", "(", "X_test", ")", ",", "2", ",", "replace", "=", "False", ")", "\n", "", "for", "i", "in", "range", "(", "len", "(", "X_test", ")", ")", ":", "\n", "            ", "L", "=", "len", "(", "X_test", "[", "i", "]", ")", "\n", "x_torch", "=", "torch", ".", "from_numpy", "(", "X_test", "[", "i", "]", ")", ".", "view", "(", "1", ",", "L", ",", "self", ".", "input_dim", ")", "#x (1,L,429)", "\n", "y", "=", "Y_test", "[", "i", "]", ".", "reshape", "(", "(", "L", ",", "18", ")", ")", "#y (L,13)", "\n", "if", "index_common", "!=", "[", "]", ":", "\n", "                ", "y", "=", "get_right_indexes", "(", "y", ",", "index_common", ",", "shape", "=", "2", ")", "\n", "", "if", "self", ".", "cuda_avail", ":", "\n", "                ", "x_torch", "=", "x_torch", ".", "to", "(", "device", "=", "self", ".", "device", ")", "\n", "", "y_pred_not_smoothed", "=", "self", "(", "x_torch", ",", "False", ")", ".", "double", "(", ")", "#output y_pred (1,L,13)", "\n", "y_pred_smoothed", "=", "self", "(", "x_torch", ",", "True", ")", ".", "double", "(", ")", "\n", "if", "self", ".", "cuda_avail", ":", "\n", "                ", "y_pred_not_smoothed", "=", "y_pred_not_smoothed", ".", "cpu", "(", ")", "\n", "y_pred_smoothed", "=", "y_pred_smoothed", ".", "cpu", "(", ")", "\n", "", "y_pred_not_smoothed", "=", "y_pred_not_smoothed", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "(", "L", ",", "self", ".", "output_dim", ")", ")", "# y_pred (L,13)", "\n", "y_pred_smoothed", "=", "y_pred_smoothed", ".", "detach", "(", ")", ".", "numpy", "(", ")", ".", "reshape", "(", "(", "L", ",", "self", ".", "output_dim", ")", ")", "# y_pred (L,13)", "\n", "if", "to_plot", ":", "\n", "                ", "if", "i", "in", "indices_to_plot", ":", "\n", "                    ", "self", ".", "plot_results", "(", "y_target", "=", "y", ",", "y_pred_smoothed", "=", "y_pred_smoothed", ",", "\n", "y_pred_not_smoothed", "=", "y_pred_not_smoothed", ",", "to_cons", "=", "to_consider", ")", "\n", "", "", "rmse", "=", "np", ".", "sqrt", "(", "np", ".", "mean", "(", "np", ".", "square", "(", "y", "-", "y_pred_smoothed", ")", ",", "axis", "=", "0", ")", ")", "# calculate rmse", "\n", "rmse", "=", "np", ".", "reshape", "(", "rmse", ",", "(", "1", ",", "self", ".", "output_dim", ")", ")", "\n", "\n", "std_to_modify", "=", "std_speaker", "\n", "if", "index_common", "!=", "[", "]", "and", "not", "no_std", ":", "\n", "                ", "std_to_modify", "=", "get_right_indexes", "(", "std_to_modify", ",", "index_common", ",", "shape", "=", "1", ")", "\n", "\n", "", "rmse_with_std", "=", "rmse", "*", "std_to_modify", "# unormalize", "\n", "\n", "all_diff", "=", "np", ".", "concatenate", "(", "(", "all_diff", ",", "rmse_with_std", ")", ")", "\n", "all_diff_without_std", "=", "np", ".", "concatenate", "(", "(", "all_diff_without_std", ",", "rmse", ")", ")", "\n", "y_pred_smoothed", "=", "y_pred_smoothed", ".", "reshape", "(", "1", ",", "L", ",", "self", ".", "output_dim", ")", "\n", "y_pred_smoothed", "=", "torch", ".", "from_numpy", "(", "y_pred_smoothed", ")", "\n", "y", "=", "torch", ".", "from_numpy", "(", "y", ".", "reshape", "(", "1", ",", "L", ",", "self", ".", "output_dim", ")", ")", "\n", "pearson_per_art", "=", "criterion_pearson_no_reduction", "(", "y", ",", "y_pred_smoothed", ",", "cuda_avail", "=", "self", ".", "cuda_avail", ",", "device", "=", "self", ".", "device", ")", "# (1,1,18)", "\n", "pearson_per_art", "=", "pearson_per_art", ".", "reshape", "(", "1", ",", "self", ".", "output_dim", ")", "\n", "all_pearson", "=", "np", ".", "concatenate", "(", "(", "all_pearson", ",", "pearson_per_art", ")", ")", "\n", "", "all_pearson", "=", "all_pearson", "[", "1", ":", "]", "\n", "if", "index_common", "==", "[", "]", ":", "\n", "            ", "all_pearson", "[", ":", ",", "idx_to_ignore", "]", "=", "0", "\n", "", "all_diff", "=", "all_diff", "[", "1", ":", "]", "\n", "if", "index_common", "==", "[", "]", ":", "\n", "            ", "all_diff", "[", ":", ",", "idx_to_ignore", "]", "=", "0", "\n", "", "all_pearson", "[", "np", ".", "isnan", "(", "all_pearson", ")", "]", "=", "0", "\n", "\n", "pearson_per_arti_mean", "=", "np", ".", "mean", "(", "all_pearson", ",", "axis", "=", "0", ")", "\n", "rmse_per_arti_mean", "=", "np", ".", "mean", "(", "all_diff", ",", "axis", "=", "0", ")", "\n", "rmse_per_art_mean_without_std", "=", "np", ".", "mean", "(", "all_diff_without_std", ",", "axis", "=", "0", ")", "\n", "if", "verbose", ":", "\n", "            ", "print", "(", "\"rmse final : \"", ",", "np", ".", "mean", "(", "rmse_per_arti_mean", "[", "rmse_per_arti_mean", "!=", "0", "]", ")", ")", "\n", "print", "(", "\"rmse mean per arti : \\n\"", ",", "rmse_per_arti_mean", ")", "\n", "print", "(", "\"pearson final : \"", ",", "np", ".", "mean", "(", "pearson_per_arti_mean", "[", "pearson_per_arti_mean", "!=", "0", "]", ")", ")", "\n", "print", "(", "\"pearson mean per arti : \\n\"", ",", "pearson_per_arti_mean", ")", "\n", "\n", "", "return", "rmse_per_arti_mean", ",", "rmse_per_art_mean_without_std", ",", "pearson_per_arti_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.memReport": [[32, 45], ["gc.get_objects", "print", "torch.is_tensor", "print", "type", "obj.size"], "function", ["None"], ["def", "memReport", "(", "all", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    :param all: wheter to detail all size obj\n    :return: n objects\n    In case of memory troubles call this function\n    \"\"\"", "\n", "nb_object", "=", "0", "\n", "for", "obj", "in", "gc", ".", "get_objects", "(", ")", ":", "\n", "        ", "if", "torch", ".", "is_tensor", "(", "obj", ")", ":", "\n", "            ", "if", "all", ":", "\n", "                ", "print", "(", "type", "(", "obj", ")", ",", "obj", ".", "size", "(", ")", ")", "\n", "", "nb_object", "+=", "1", "\n", "", "", "print", "(", "'nb objects tensor'", ",", "nb_object", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.train_only_common.train_model_arti_common": [[50, 373], ["corpus_to_train_on[].split", "speakers_to_train_on[].replace().replace().replace().split", "speakers_to_valid_on[].replace().replace().replace().split", "Training.tools_learning.give_me_common_articulators", "print", "open", "open", "open", "open.write", "open.write", "open.write", "os.listdir", "os.listdir", "os.listdir", "previous_models_2.count", "print", "torch.cuda.is_available", "print", "len", "Training.pytorchtools.EarlyStopping", "Training.model.my_ac2art_model", "model.to.double", "os.path.join", "os.path.join", "os.path.join", "Training.tools_learning.give_me_train_valid_test_filenames_no_cat", "print", "torch.optim.Adam", "range", "random.shuffle", "Training.tools_learning.load_np_ema_and_mfcc", "print", "numpy.load", "model.to.evaluate_on_test", "numpy.zeros", "range", "numpy.mean", "print", "print", "model.to.lowpass.weight.data[].cpu", "Training.tools_learning.which_speakers_to_train_on", "print", "str", "os.path.exists", "os.path.exists", "os.path.exists", "os.mkdir", "os.mkdir", "os.mkdir", "print", "print", "str", "torch.device", "torch.device", "model.to.to", "os.path.exists", "os.path.exists", "os.path.exists", "len", "len", "len", "model.to.parameters", "model.to.lowpass.weight.data[].cpu", "random.shuffle", "range", "torch.cuda.empty_cache", "print", "open.write", "torch.cuda.empty_cache", "model.to.all_validation_loss.append", "model.to.all_training_loss.append", "Training.pytorchtools.EarlyStopping.", "model.to.load_state_dict", "torch.save", "os.path.join", "os.path.join", "os.path.join", "len", "int", "Training.tools_learning.load_np_ema_and_mfcc", "model.to.evaluate_on_test", "numpy.reshape", "numpy.concatenate", "os.path.exists", "os.path.exists", "os.path.exists", "open", "csv.writer", "csv.writer.writerow", "csv.writer.writerow", "csv.writer.writerow", "Training.tools_learning.plot_filtre", "speakers_to_train_on[].replace().replace().replace", "speakers_to_valid_on[].replace().replace().replace", "x.endswith", "print", "torch.load", "model.to.load_state_dict", "model.to.state_dict", "model.state_dict.update", "model.to.load_state_dict", "Training.tools_learning.plot_filtre", "len", "int", "Training.tools_learning.load_np_ema_and_mfcc", "model.to.prepare_batch", "len", "Training.tools_learning.get_right_indexes", "model.to.double", "y.double.double", "torch.optim.Adam.zero_grad", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.backward", "torch.optim.Adam.step", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "torch.cuda.empty_cache", "Training.tools_learning.criterion_both.item", "range", "open.write", "range", "open.write", "print", "torch.load", "model.to.state_dict", "os.path.join", "os.path.join", "os.path.join", "range", "numpy.array", "numpy.isnan", "open", "csv.writer", "csv.writer.writerow", "rmse_per_arti_mean.tolist", "pearson_per_arti_mean.tolist", "np.concatenate.tolist", "str", "len", "y_pred.to.to", "len", "int", "Training.tools_learning.load_np_ema_and_mfcc", "model.to.prepare_batch", "len", "Training.tools_learning.get_right_indexes", "model.to.double", "torch.cuda.empty_cache", "y.double.double", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "len", "int", "Training.tools_learning.load_np_ema_and_mfcc", "model.to.prepare_batch", "len", "Training.tools_learning.get_right_indexes", "model.to.double", "torch.cuda.empty_cache", "y.double.double", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "Training.tools_learning.criterion_both", "Training.tools_learning.criterion_both.item", "os.path.join", "os.path.join", "os.path.join", "len", "speakers_to_train_on[].replace().replace", "speakers_to_valid_on[].replace().replace", "torch.load.items", "torch.load.items", "x.to", "torch.from_numpy().double().to", "model.to.", "str", "y_pred.to.to", "y_pred.to.to", "numpy.mean", "numpy.mean", "numpy.mean", "str", "x.to", "torch.from_numpy().double().to", "model.to.", "str", "x.to", "torch.from_numpy().double().to", "model.to.", "str", "speakers_to_train_on[].replace", "speakers_to_valid_on[].replace", "torch.from_numpy().double", "str", "len", "torch.from_numpy().double", "str", "len", "torch.from_numpy().double", "str", "len", "torch.from_numpy", "str", "str", "len", "torch.from_numpy", "str", "torch.from_numpy", "str", "str", "len", "str", "len"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_common_articulators", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.give_me_train_valid_test_filenames_no_cat", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.evaluate_on_test", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.which_speakers_to_train_on", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.evaluate_on_test", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.plot_filtre", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.plot_filtre", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.prepare_batch", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.prepare_batch", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.load_np_ema_and_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.model.my_ac2art_model.prepare_batch", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.get_right_indexes", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Training.tools_learning.criterion_both"], ["def", "train_model_arti_common", "(", "test_on", ",", "n_epochs", ",", "loss_train", ",", "patience", ",", "corpus_to_train_on", ",", "batch_norma", ",", "filter_type", ",", "\n", "to_plot", ",", "lr", ",", "delta_valid", ",", "delta_test", ",", "config", ",", "speakers_to_train_on", "=", "\"\"", ",", "speakers_to_valid_on", "=", "\"\"", ")", ":", "\n", "    ", "\"\"\"\n    :param test_on: (str) one speaker's name we want to test on, the speakers and the corpus the come frome can be seen in\n    \"fonction_utiles.py\", in the function \"get_speakers_per_corpus'.\n\n    :param n_epochs: (int)  max number of epochs for the training. We use an early stopping criterion to stop the training,\n    so usually we dont go through the n_epochs and the early stopping happends before the 30th epoch (1 epoch is when\n    have trained over ALL the data in the training set)\n\n    :param loss_train: (int) alpha in the combined loss . can be anything between 0 and 100.\n    the loss is the combinated loss alpha*rmse/1000+(1-alpha)*pearson.\n\n    :param patience: (int) the number successive epochs with a validation loss increasing before stopping the training.\n    We usually set it to 5. The more data we have, the smaller it can be (i think)\n\n    :param select_arti: (bool) always true, either to use the trick to only train on available articulatory trajectories,\n    fixing the predicted trajectory (to zero) and then the gradient will be 0.\n\n    :param corpus_to_train_on: (list) list of the corpuses to train on. Usually at least the corpus the testspeaker comes from.\n    (the testspeaker will be by default removed from the training speakers).\n\n    :param batch_norma: (bool) whether or not add batch norm layer after the lstm layers (maybe better to add them after the\n    feedforward layers? )\n\n    :param filter_type: (int) either 0 1 or 2. 0 the filter is outside of the network, 1 it is inside and the weight are fixed\n    during the training, 2 the weights get adjusted during the training\n\n    :param to_plot: (bool) if true the trajectories of one random test sentence are saved in \"images_predictions\"\n\n    :param lr: initial learning rate, usually 0.001\n\n    :param delta_test: frequency of validation evaluation, 1 seems good\n\n    :param config : either \"spe\" \"dep\", or \"indep\" or \"train_indep\", for specific (train only on test sp), dependant (train on test sp\n    and others), or independant, train only on other speakers, and training independant for training on a certain list, validation\n    on another an d test on another speaker\n\n    :return: [rmse, pearson] . rmse the is the list of the 18 rmse (1 per articulator), same for pearson.\n    \"\"\"", "\n", "\n", "corpus_to_train_on", "=", "corpus_to_train_on", "[", "1", ":", "-", "1", "]", ".", "split", "(", "\",\"", ")", "\n", "speakers_to_train_on", "=", "speakers_to_train_on", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", ".", "replace", "(", "'\"'", ",", "''", ")", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "\",\"", ")", "\n", "speakers_to_valid_on", "=", "speakers_to_valid_on", "[", "1", ":", "-", "1", "]", ".", "replace", "(", "\"'\"", ",", "\"\"", ")", ".", "replace", "(", "'\"'", ",", "''", ")", ".", "replace", "(", "' '", ",", "''", ")", ".", "split", "(", "\",\"", ")", "\n", "if", "speakers_to_train_on", "==", "[", "\"\"", "]", "or", "speakers_to_train_on", "==", "[", "]", ":", "\n", "        ", "train_on", "=", "which_speakers_to_train_on", "(", "corpus_to_train_on", ",", "test_on", ",", "config", ")", "\n", "", "else", ":", "\n", "        ", "train_on", "=", "speakers_to_train_on", "\n", "\n", "", "if", "speakers_to_valid_on", "==", "[", "\"\"", "]", "or", "speakers_to_valid_on", "==", "[", "]", ":", "\n", "        ", "valid_on", "=", "[", "]", "\n", "", "else", ":", "\n", "\n", "        ", "valid_on", "=", "speakers_to_valid_on", "\n", "print", "(", "\"You choose to valid on\"", ",", "speakers_to_valid_on", ")", "\n", "\n", "", "arti_common", "=", "give_me_common_articulators", "(", "[", "test_on", "]", "+", "train_on", "+", "valid_on", ")", "\n", "print", "(", "arti_common", ")", "\n", "name_corpus_concat", "=", "\"\"", "\n", "if", "config", "!=", "\"spec\"", ":", "# if spec DOESNT train on other speakers", "\n", "        ", "for", "corpus", "in", "corpus_to_train_on", ":", "\n", "            ", "name_corpus_concat", "=", "name_corpus_concat", "+", "corpus", "+", "\"_\"", "\n", "\n", "", "", "name_file", "=", "'only_arti_common_'", "+", "test_on", "+", "\"_\"", "+", "config", "+", "\"_train_\"", "+", "'_'", ".", "join", "(", "train_on", ")", "+", "'_valid_'", "+", "'_'", ".", "join", "(", "valid_on", ")", "+", "\"_loss_\"", "+", "str", "(", "loss_train", ")", "+", "\"_filter_\"", "+", "str", "(", "filter_type", ")", "+", "\"_bn_\"", "+", "str", "(", "batch_norma", ")", "\n", "\n", "f_loss_train", "=", "open", "(", "'training_loss'", "+", "name_file", "+", "'.csv'", ",", "'w'", ")", "\n", "f_loss_valid", "=", "open", "(", "'valid_loss'", "+", "name_file", "+", "'.csv'", ",", "'w'", ")", "\n", "f_loss_test", "=", "open", "(", "'test_loss'", "+", "name_file", "+", "'.csv'", ",", "'w'", ")", "\n", "f_loss_valid", ".", "write", "(", "'epoch,training_loss,pearson,rmse\\n'", ")", "\n", "f_loss_train", ".", "write", "(", "'epoch,training_loss,pearson,rmse\\n'", ")", "\n", "f_loss_test", ".", "write", "(", "'epoch,training_loss,pearson,rmse\\n'", ")", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "\"saved_models\"", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "\"saved_models\"", ")", "\n", "\n", "", "previous_models", "=", "os", ".", "listdir", "(", "\"saved_models\"", ")", "\n", "previous_models_2", "=", "[", "x", "[", ":", "len", "(", "name_file", ")", "]", "for", "x", "in", "previous_models", "if", "x", ".", "endswith", "(", "\".txt\"", ")", "]", "\n", "n_previous_same", "=", "previous_models_2", ".", "count", "(", "name_file", ")", "# how many times our model was trained", "\n", "\n", "if", "n_previous_same", ">", "0", ":", "\n", "        ", "print", "(", "\"this models has alread be trained {} times\"", ".", "format", "(", "n_previous_same", ")", ")", "\n", "", "else", ":", "\n", "        ", "print", "(", "\"first time for this model\"", ")", "\n", "", "name_file", "=", "name_file", "+", "\"_\"", "+", "str", "(", "n_previous_same", ")", "# each model trained only once ,", "\n", "# this script doesnt continue a previous training if it was ended ie if there is a .txt", "\n", "print", "(", "\"going to train the model with name\"", ",", "name_file", ")", "\n", "\n", "cuda_avail", "=", "torch", ".", "cuda", ".", "is_available", "(", ")", "\n", "print", "(", "\" cuda ?\"", ",", "cuda_avail", ")", "\n", "if", "cuda_avail", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cuda\"", ")", "\n", "", "else", ":", "\n", "        ", "device", "=", "torch", ".", "device", "(", "\"cpu\"", ")", "\n", "\n", "", "hidden_dim", "=", "300", "\n", "input_dim", "=", "429", "\n", "batch_size", "=", "10", "\n", "output_dim", "=", "len", "(", "arti_common", ")", "\n", "early_stopping", "=", "EarlyStopping", "(", "name_file", ",", "patience", "=", "patience", ",", "verbose", "=", "True", ")", "\n", "model", "=", "my_ac2art_model", "(", "hidden_dim", "=", "hidden_dim", ",", "input_dim", "=", "input_dim", ",", "name_file", "=", "name_file", ",", "output_dim", "=", "output_dim", ",", "\n", "batch_size", "=", "batch_size", ",", "cuda_avail", "=", "cuda_avail", ",", "\n", "filter_type", "=", "filter_type", ",", "batch_norma", "=", "batch_norma", ")", "\n", "model", "=", "model", ".", "double", "(", ")", "\n", "file_weights", "=", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "name_file", "+", "\".pt\"", ")", "\n", "if", "cuda_avail", ":", "\n", "        ", "model", "=", "model", ".", "to", "(", "device", "=", "device", ")", "\n", "", "load_old_model", "=", "True", "\n", "if", "load_old_model", ":", "\n", "        ", "if", "os", ".", "path", ".", "exists", "(", "file_weights", ")", ":", "\n", "            ", "print", "(", "\"previous model did not finish learning\"", ")", "\n", "loaded_state", "=", "torch", ".", "load", "(", "file_weights", ",", "map_location", "=", "device", ")", "\n", "model", ".", "load_state_dict", "(", "loaded_state", ")", "\n", "model_dict", "=", "model", ".", "state_dict", "(", ")", "\n", "loaded_state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "loaded_state", ".", "items", "(", ")", "if", "\n", "k", "in", "model_dict", "}", "# only layers param that are in our current model", "\n", "loaded_state", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "loaded_state", ".", "items", "(", ")", "if", "\n", "loaded_state", "[", "k", "]", ".", "shape", "==", "model_dict", "[", "k", "]", ".", "shape", "}", "# only if layers have correct shapes", "\n", "model_dict", ".", "update", "(", "loaded_state", ")", "\n", "model", ".", "load_state_dict", "(", "model_dict", ")", "\n", "\n", "\n", "\n", "", "", "files_for_train", ",", "files_for_valid", ",", "files_for_test", "=", "give_me_train_valid_test_filenames_no_cat", "(", "train_on", ",", "test_on", ",", "config", ",", "valid_on", "=", "valid_on", ")", "\n", "print", "(", "'train on'", ",", "len", "(", "files_for_train", ")", ",", "'valid on'", ",", "len", "(", "files_for_valid", ")", ",", "'test on'", ",", "len", "(", "files_for_test", ")", ")", "\n", "optimizer", "=", "torch", ".", "optim", ".", "Adam", "(", "model", ".", "parameters", "(", ")", ",", "lr", "=", "lr", ")", "\n", "\n", "plot_filtre_chaque_epochs", "=", "False", "\n", "\n", "for", "epoch", "in", "range", "(", "n_epochs", ")", ":", "\n", "        ", "weights", "=", "model", ".", "lowpass", ".", "weight", ".", "data", "[", "0", ",", "0", ",", ":", "]", ".", "cpu", "(", ")", "\n", "if", "plot_filtre_chaque_epochs", ":", "\n", "            ", "plot_filtre", "(", "weights", ")", "\n", "", "n_this_epoch", "=", "0", "\n", "random", ".", "shuffle", "(", "files_for_train", ")", "\n", "loss_train_this_epoch", "=", "0", "\n", "loss_pearson", "=", "0", "\n", "loss_rmse", "=", "0", "\n", "nb_batch", "=", "len", "(", "files_for_train", ")", "/", "batch_size", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_batch", ")", ")", ":", "\n", "\n", "            ", "n_this_epoch", "+=", "1", "\n", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_for_train", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", ")", "\n", "model", ".", "output_dim", "=", "18", "\n", "x", ",", "y", "=", "model", ".", "prepare_batch", "(", "x", ",", "y", ")", "\n", "\n", "model", ".", "output_dim", "=", "len", "(", "arti_common", ")", "\n", "y", "=", "get_right_indexes", "(", "y", ",", "arti_common", ")", "\n", "if", "cuda_avail", ":", "\n", "                ", "x", ",", "y", "=", "x", ".", "to", "(", "device", "=", "model", ".", "device", ")", ",", "torch", ".", "from_numpy", "(", "y", ")", ".", "double", "(", ")", ".", "to", "(", "device", "=", "model", ".", "device", ")", "\n", "", "y_pred", "=", "model", "(", "x", ")", ".", "double", "(", ")", "\n", "if", "cuda_avail", ":", "\n", "                ", "y_pred", "=", "y_pred", ".", "to", "(", "device", "=", "device", ")", "\n", "", "y", "=", "y", ".", "double", "(", ")", "\n", "optimizer", ".", "zero_grad", "(", ")", "\n", "\n", "loss", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "loss_train", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss", ".", "backward", "(", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "# computation to have evolution of the losses", "\n", "loss_2", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "100", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_pearson", "+=", "loss_2", ".", "item", "(", ")", "\n", "loss_3", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "0", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_rmse", "+=", "loss_3", ".", "item", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "loss_train_this_epoch", "+=", "loss", ".", "item", "(", ")", "\n", "\n", "", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "\n", "loss_train_this_epoch", "=", "loss_train_this_epoch", "/", "n_this_epoch", "\n", "print", "(", "\"Training loss for epoch\"", ",", "epoch", ",", "': '", ",", "loss_train_this_epoch", ")", "\n", "f_loss_train", ".", "write", "(", "str", "(", "epoch", ")", "+", "','", "+", "str", "(", "loss_train_this_epoch", ")", "+", "','", "+", "str", "(", "loss_pearson", "/", "n_this_epoch", "/", "1000.", "/", "batch_size", "/", "len", "(", "arti_common", ")", "*", "(", "-", "1.", ")", ")", "+", "','", "+", "str", "(", "loss_rmse", "/", "n_this_epoch", "/", "batch_size", "/", "len", "(", "arti_common", ")", ")", "+", "'\\n'", ")", "\n", "real_batch_size", "=", "batch_size", "\n", "batch_size", "=", "1", "\n", "if", "epoch", "%", "delta_valid", "==", "0", ":", "#toutes les delta_test epochs on \u00e9value le mod\u00e8le sur validation et on sauvegarde le modele si le score est meilleur", "\n", "            ", "loss_vali", "=", "0", "\n", "n_valid", "=", "0", "\n", "loss_pearson", "=", "0", "\n", "loss_rmse", "=", "0", "\n", "nb_batch", "=", "len", "(", "files_for_valid", ")", "/", "batch_size", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_batch", ")", ")", ":", "\n", "                ", "n_valid", "+=", "1", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_for_valid", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", ")", "\n", "model", ".", "output_dim", "=", "18", "\n", "x", ",", "y", "=", "model", ".", "prepare_batch", "(", "x", ",", "y", ")", "\n", "model", ".", "output_dim", "=", "len", "(", "arti_common", ")", "\n", "y", "=", "get_right_indexes", "(", "y", ",", "arti_common", ")", "\n", "if", "cuda_avail", ":", "\n", "                    ", "x", ",", "y", "=", "x", ".", "to", "(", "device", "=", "model", ".", "device", ")", ",", "torch", ".", "from_numpy", "(", "y", ")", ".", "double", "(", ")", ".", "to", "(", "\n", "device", "=", "model", ".", "device", ")", "\n", "", "y_pred", "=", "model", "(", "x", ")", ".", "double", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "cuda_avail", ":", "\n", "                    ", "y_pred", "=", "y_pred", ".", "to", "(", "device", "=", "device", ")", "\n", "", "y", "=", "y", ".", "double", "(", ")", "# (Batchsize, maxL, art_common_nb)", "\n", "loss_courant", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "loss_train", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_vali", "+=", "loss_courant", ".", "item", "(", ")", "\n", "\n", "# to follow both losses", "\n", "loss_2", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "100", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_pearson", "+=", "loss_2", ".", "item", "(", ")", "\n", "loss_3", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "0", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_rmse", "+=", "loss_3", ".", "item", "(", ")", "\n", "\n", "", "loss_vali", "=", "loss_vali", "/", "n_valid", "\n", "f_loss_valid", ".", "write", "(", "str", "(", "epoch", ")", "+", "','", "+", "str", "(", "loss_vali", ")", "+", "','", "+", "str", "(", "loss_pearson", "/", "n_valid", "/", "1000.", "/", "batch_size", "/", "len", "(", "arti_common", ")", "*", "(", "-", "1.", ")", ")", "+", "\n", "','", "+", "str", "(", "loss_rmse", "/", "n_valid", "/", "batch_size", "/", "len", "(", "arti_common", ")", ")", "+", "'\\n'", ")", "\n", "# test on the test files", "\n", "", "if", "epoch", "%", "delta_test", "==", "0", ":", "# toutes les delta_test epochs on \u00e9value le mod\u00e8le sur validation et on sauvegarde le modele si le score est meilleur", "\n", "            ", "loss_test", "=", "0", "\n", "n_test", "=", "0", "\n", "loss_pearson", "=", "0", "\n", "loss_rmse", "=", "0", "\n", "nb_batch", "=", "len", "(", "files_for_test", ")", "/", "batch_size", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_batch", ")", ")", ":", "\n", "                ", "n_test", "+=", "1", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_for_test", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", ")", "\n", "model", ".", "output_dim", "=", "18", "\n", "x", ",", "y", "=", "model", ".", "prepare_batch", "(", "x", ",", "y", ")", "\n", "model", ".", "output_dim", "=", "len", "(", "arti_common", ")", "\n", "y", "=", "get_right_indexes", "(", "y", ",", "arti_common", ")", "\n", "if", "cuda_avail", ":", "\n", "                    ", "x", ",", "y", "=", "x", ".", "to", "(", "device", "=", "model", ".", "device", ")", ",", "torch", ".", "from_numpy", "(", "y", ")", ".", "double", "(", ")", ".", "to", "(", "\n", "device", "=", "model", ".", "device", ")", "\n", "", "y_pred", "=", "model", "(", "x", ")", ".", "double", "(", ")", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "if", "cuda_avail", ":", "\n", "                    ", "y_pred", "=", "y_pred", ".", "to", "(", "device", "=", "device", ")", "\n", "", "y", "=", "y", ".", "double", "(", ")", "# (Batchsize, maxL, art_common_nb)", "\n", "loss_courant", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "loss_train", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_test", "+=", "loss_courant", ".", "item", "(", ")", "\n", "\n", "# to follow both losses", "\n", "loss_2", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "100", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_pearson", "+=", "loss_2", ".", "item", "(", ")", "\n", "loss_3", "=", "criterion_both", "(", "y", ",", "y_pred", ",", "alpha", "=", "0", ",", "cuda_avail", "=", "cuda_avail", ",", "device", "=", "device", ")", "\n", "loss_rmse", "+=", "loss_3", ".", "item", "(", ")", "\n", "\n", "", "loss_test", "=", "loss_test", "/", "n_test", "\n", "f_loss_test", ".", "write", "(", "str", "(", "epoch", ")", "+", "','", "+", "str", "(", "loss_test", ")", "+", "','", "+", "str", "(", "\n", "loss_pearson", "/", "n_test", "/", "1000.", "/", "batch_size", "/", "len", "(", "arti_common", ")", "*", "(", "-", "1.", ")", ")", "+", "\n", "','", "+", "str", "(", "loss_rmse", "/", "n_test", "/", "batch_size", "/", "len", "(", "arti_common", ")", ")", "+", "'\\n'", ")", "\n", "", "batch_size", "=", "real_batch_size", "\n", "torch", ".", "cuda", ".", "empty_cache", "(", ")", "\n", "model", ".", "all_validation_loss", ".", "append", "(", "loss_vali", ")", "\n", "model", ".", "all_training_loss", ".", "append", "(", "loss_train_this_epoch", ")", "\n", "early_stopping", "(", "loss_vali", ",", "model", ")", "\n", "if", "early_stopping", ".", "early_stop", ":", "\n", "            ", "print", "(", "\"Early stopping, n epochs : \"", ",", "model", ".", "epoch_ref", "+", "epoch", ")", "\n", "break", "\n", "\n", "", "if", "epoch", ">", "0", ":", "# on divise le learning rate par deux d\u00e8s qu'on surapprend un peu par rapport au validation set", "\n", "            ", "if", "loss_vali", ">", "model", ".", "all_validation_loss", "[", "-", "1", "]", ":", "\n", "                ", "for", "param_group", "in", "optimizer", ".", "param_groups", ":", "\n", "                    ", "param_group", "[", "'lr'", "]", "=", "param_group", "[", "'lr'", "]", "/", "2.", "\n", "(", "param_group", "[", "\"lr\"", "]", ")", "\n", "\n", "\n", "", "", "", "", "if", "n_epochs", ">", "0", ":", "\n", "        ", "model", ".", "epoch_ref", "=", "model", ".", "epoch_ref", "+", "epoch", "# voir si ca marche vrmt pour les rares cas ou on continue un training", "\n", "model", ".", "load_state_dict", "(", "torch", ".", "load", "(", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "name_file", "+", "'.pt'", ")", ")", ")", "\n", "torch", ".", "save", "(", "model", ".", "state_dict", "(", ")", ",", "os", ".", "path", ".", "join", "(", "\"saved_models\"", ",", "name_file", "+", "\".txt\"", ")", ")", "#lorsque .txt ==> training termin\u00e9 !", "\n", "", "random", ".", "shuffle", "(", "files_for_test", ")", "\n", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_for_test", ")", "\n", "#y = get_right_indexes(y, arti_common)", "\n", "print", "(", "\"evaluation on speaker {}\"", ".", "format", "(", "test_on", ")", ")", "\n", "std_speaker", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessing\"", ",", "\"norm_values\"", ",", "\"std_ema_\"", "+", "test_on", "+", "\".npy\"", ")", ")", "\n", "arti_to_consider", "=", "[", "1", "for", "i", "in", "range", "(", "len", "(", "arti_common", ")", ")", "]", "\n", "rmse_per_arti_mean", ",", "pearson_per_arti_mean", "=", "model", ".", "evaluate_on_test", "(", "x", ",", "y", ",", "std_speaker", "=", "std_speaker", ",", "to_plot", "=", "to_plot", "\n", ",", "to_consider", "=", "arti_to_consider", ",", "index_common", "=", "arti_common", ")", "\n", "\n", "\n", "\"\"\"  RESULTS ON VALIDATION SET \"\"\"", "\n", "\n", "pearson_valid", "=", "np", ".", "zeros", "(", "(", "1", ",", "output_dim", ")", ")", "\n", "nb_batch", "=", "len", "(", "files_for_valid", ")", "/", "batch_size", "\n", "for", "i", "in", "range", "(", "int", "(", "nb_batch", ")", ")", ":", "\n", "        ", "x", ",", "y", "=", "load_np_ema_and_mfcc", "(", "files_for_valid", "[", "i", "*", "batch_size", ":", "(", "i", "+", "1", ")", "*", "batch_size", "]", ")", "\n", "#y = get_right_indexes(y, arti_common)", "\n", "rien", ",", "pearson_valid_temp", "=", "model", ".", "evaluate_on_test", "(", "x", ",", "y", ",", "std_speaker", "=", "1", ",", "to_plot", "=", "to_plot", ",", "\n", "to_consider", "=", "arti_to_consider", ",", "verbose", "=", "False", ",", "index_common", "=", "arti_common", ",", "no_std", "=", "True", ")", "\n", "pearson_valid_temp", "=", "np", ".", "reshape", "(", "np", ".", "array", "(", "pearson_valid_temp", ")", ",", "(", "1", ",", "output_dim", ")", ")", "\n", "pearson_valid", "=", "np", ".", "concatenate", "(", "(", "pearson_valid", ",", "pearson_valid_temp", ")", ",", "axis", "=", "0", ")", "\n", "", "pearson_valid", "=", "pearson_valid", "[", "1", ":", ",", ":", "]", "\n", "pearson_valid", "[", "np", ".", "isnan", "(", "pearson_valid", ")", "]", "=", "0", "\n", "pearson_valid", "=", "np", ".", "mean", "(", "pearson_valid", ",", "axis", "=", "0", ")", "\n", "print", "(", "\"on validation set :mean :\\n\"", ",", "pearson_valid", ")", "\n", "print", "(", "\"training done for : \"", ",", "name_file", ")", "\n", "\n", "articulators", "=", "[", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", ",", "\n", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", ",", "'la'", ",", "'lp'", ",", "'ttcl'", ",", "'tbcl'", ",", "'v_x'", ",", "'v_y'", "]", "\n", "articulators", "=", "[", "art", "for", "art", "in", "articulators", "if", "art", "in", "arti_common", "]", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "'model_results.csv'", ")", ":", "\n", "        ", "with", "open", "(", "'model_results.csv'", ",", "'a'", ",", "newline", "=", "\"\"", ")", "as", "f", ":", "\n", "            ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "header", "=", "[", "\"name file\"", ",", "\"test on\"", ",", "\"configuration\"", ",", "\"train on (if not spec)\"", ",", "\"loss\"", ",", "\n", "\"n_epochs\"", ",", "\"evaluation with...\"", ",", "\"average\"", "]", "+", "articulators", "\n", "writer", ".", "writerow", "(", "header", ")", "\n", "\n", "# write result in csv", "\n", "", "", "with", "open", "(", "'model_results.csv'", ",", "'a'", ",", "newline", "=", "\"\"", ")", "as", "f", ":", "\n", "        ", "writer", "=", "csv", ".", "writer", "(", "f", ")", "\n", "row_details", "=", "[", "'only_common'", ",", "name_file", ",", "test_on", ",", "config", ",", "name_corpus_concat", ",", "loss_train", ",", "model", ".", "epoch_ref", "]", "\n", "row_rmse", "=", "row_details", "+", "[", "\"rmse_on_test\"", ",", "np", ".", "mean", "(", "rmse_per_arti_mean", "[", "rmse_per_arti_mean", "!=", "0", "]", ")", "]", "+", "rmse_per_arti_mean", ".", "tolist", "(", ")", "\n", "\n", "row_pearson", "=", "row_details", "+", "[", "\"pearson_on_test\"", ",", "np", ".", "mean", "(", "pearson_per_arti_mean", "[", "pearson_per_arti_mean", "!=", "0", "]", ")", "]", "+", "pearson_per_arti_mean", ".", "tolist", "(", ")", "\n", "\n", "row_pearson_val", "=", "row_details", "+", "[", "\"pearson_on_valid\"", ",", "np", ".", "mean", "(", "pearson_valid", "[", "pearson_valid", "!=", "0", "]", ")", "]", "+", "pearson_valid", ".", "tolist", "(", ")", "\n", "\n", "writer", ".", "writerow", "(", "row_rmse", ")", "\n", "writer", ".", "writerow", "(", "row_pearson", ")", "\n", "writer", ".", "writerow", "(", "row_pearson_val", ")", "\n", "\n", "", "weight_apres", "=", "model", ".", "lowpass", ".", "weight", ".", "data", "[", "0", ",", "0", ",", ":", "]", ".", "cpu", "(", ")", "\n", "plot_allure_filtre", "=", "True", "\n", "if", "plot_allure_filtre", ":", "\n", "        ", "plot_filtre", "(", "weight_apres", ")", "\n", "\n", "", "return", "rmse_per_arti_mean", ",", "pearson_per_arti_mean", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.ABX_evaluation.script_compute_score.result_score": [[17, 81], ["pandas.read_csv", "pd.read_csv.groupby", "groups[].mean", "groups[].mean.groupby", "groups2[].mean", "pd.read_csv.groupby", "groups3[].sum", "range", "open", "dico_mean.keys", "sorted", "range", "len", "utils.conversion_arpa_ipa", "utils.conversion_arpa_ipa", "len", "float", "dico_mean.keys", "dico_mean[].append", "cont.split", "cont.split", "print", "open.write", "sorted.append", "contrast_done.append", "len", "[].split", "[].split", "numpy.array().mean", "utils.conversion_arpa_ipa", "utils.conversion_arpa_ipa", "numpy.array"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.ABX_evaluation.utils.conversion_arpa_ipa", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.ABX_evaluation.utils.conversion_arpa_ipa", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.ABX_evaluation.utils.conversion_arpa_ipa", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.ABX_evaluation.utils.conversion_arpa_ipa"], ["def", "result_score", "(", "file_model_results", ",", "nb_example", "=", "3", ",", "bad", "=", "False", ")", ":", "\n", "    ", "to_exclude", "=", "[", "'ao'", ",", "'aw'", ",", "'ax'", ",", "'ay'", ",", "'er'", "]", "\n", "df", "=", "pd", ".", "read_csv", "(", "file_model_results", ",", "sep", "=", "'\\t'", ")", "\n", "# aggregate on speakers", "\n", "groups", "=", "df", ".", "groupby", "(", "\n", "[", "'phone_1'", ",", "'phone_2'", ",", "'by'", "]", ",", "as_index", "=", "False", ")", "\n", "df2", "=", "groups", "[", "'score'", "]", ".", "mean", "(", ")", "\n", "\n", "# aggregate on context", "\n", "groups2", "=", "df2", ".", "groupby", "(", "[", "'phone_1'", ",", "'phone_2'", "]", ",", "as_index", "=", "False", ")", "\n", "df3", "=", "groups2", "[", "'score'", "]", ".", "mean", "(", ")", "\n", "\n", "groups3", "=", "df", ".", "groupby", "(", "[", "'phone_1'", ",", "'phone_2'", "]", ",", "as_index", "=", "False", ")", "\n", "df_sum", "=", "groups3", "[", "'n'", "]", ".", "sum", "(", ")", "\n", "\n", "val", "=", "df3", ".", "values", "\n", "dico_mean", "=", "{", "}", "\n", "for", "k", "in", "range", "(", "len", "(", "val", ")", ")", ":", "\n", "        ", "if", "val", "[", "k", "]", "[", "1", "]", "+", "':'", "+", "val", "[", "k", "]", "[", "0", "]", "not", "in", "dico_mean", ".", "keys", "(", ")", ":", "# we exclude some phones that can be wrong", "\n", "            ", "dico_mean", "[", "val", "[", "k", "]", "[", "0", "]", "+", "':'", "+", "val", "[", "k", "]", "[", "1", "]", "]", "=", "[", "val", "[", "k", "]", "[", "2", "]", "]", "\n", "", "else", ":", "\n", "            ", "dico_mean", "[", "val", "[", "k", "]", "[", "1", "]", "+", "':'", "+", "val", "[", "k", "]", "[", "0", "]", "]", ".", "append", "(", "val", "[", "k", "]", "[", "2", "]", ")", "\n", "\n", "", "", "val_new", "=", "[", "]", "\n", "f", "=", "open", "(", "'file_pair.csv'", ",", "'w'", ")", "\n", "for", "cont", "in", "dico_mean", ".", "keys", "(", ")", ":", "\n", "        ", "phone1", "=", "cont", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "phone2", "=", "cont", ".", "split", "(", "':'", ")", "[", "1", "]", "\n", "trad_1", "=", "conversion_arpa_ipa", "(", "phone1", ")", "\n", "trad_2", "=", "conversion_arpa_ipa", "(", "phone2", ")", "\n", "if", "trad_1", "==", "'g'", "or", "trad_2", "==", "'g'", ":", "\n", "            ", "print", "(", "cont", ")", "\n", "# we compute the contraste to exclude", "\n", "", "if", "not", "bad", ":", "\n", "            ", "excl", "=", "trad_1", "+", "':'", "+", "trad_2", "in", "contrast_to_exclude", "or", "trad_2", "+", "':'", "+", "trad_1", "in", "contrast_to_exclude", "\n", "", "else", ":", "\n", "            ", "excl", "=", "trad_1", "+", "':'", "+", "trad_2", "not", "in", "contrast_to_exclude", "and", "trad_2", "+", "':'", "+", "trad_1", "not", "in", "contrast_to_exclude", "\n", "", "if", "len", "(", "dico_mean", "[", "cont", "]", ")", ">", "1", "and", "phone1", "not", "in", "to_exclude", "and", "phone2", "not", "in", "to_exclude", "and", "not", "excl", ":", "# we take only contrast symetric", "\n", "\n", "            ", "f", ".", "write", "(", "conversion_arpa_ipa", "(", "phone1", ")", "+", "':'", "+", "conversion_arpa_ipa", "(", "phone2", ")", "+", "'\\n'", ")", "\n", "val_new", ".", "append", "(", "[", "cont", ",", "np", ".", "array", "(", "dico_mean", "[", "cont", "]", ")", ".", "mean", "(", ")", "]", ")", "\n", "\n", "\n", "", "", "val_new", "=", "sorted", "(", "val_new", ",", "key", "=", "lambda", "x", ":", "x", "[", "1", "]", ")", "\n", "\n", "\n", "count", "=", "0", "\n", "contrast_done", "=", "[", "]", "\n", "mean_error", "=", "0", "\n", "for", "i", "in", "range", "(", "len", "(", "val_new", ")", ")", ":", "\n", "        ", "if", "val_new", "[", "i", "]", "[", "0", "]", "not", "in", "contrast_done", ":", "\n", "            ", "contrast_done", ".", "append", "(", "val_new", "[", "i", "]", "[", "0", "]", ")", "\n", "phone1", "=", "val_new", "[", "i", "]", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "0", "]", "\n", "phone2", "=", "val_new", "[", "i", "]", "[", "0", "]", ".", "split", "(", "':'", ")", "[", "1", "]", "\n", "extract", "=", "df_sum", ".", "loc", "[", "(", "(", "df_sum", "[", "'phone_1'", "]", "==", "phone1", ")", "&", "(", "df_sum", "[", "'phone_2'", "]", "==", "phone2", ")", ")", "]", ".", "values", "\n", "n", "=", "extract", "[", "0", "]", "[", "2", "]", "\n", "extract2", "=", "df_sum", ".", "loc", "[", "(", "(", "df_sum", "[", "'phone_1'", "]", "==", "phone1", ")", "&", "(", "df_sum", "[", "'phone_2'", "]", "==", "phone2", ")", ")", "]", ".", "values", "\n", "n2", "=", "extract2", "[", "0", "]", "[", "2", "]", "\n", "if", "n", ">=", "nb_example", "and", "n2", ">=", "nb_example", ":", "# we take only the contrast that have at least nb_example context", "\n", "                ", "mean_error", "+=", "1.", "-", "val_new", "[", "i", "]", "[", "1", "]", "\n", "count", "+=", "1", "\n", "\n", "", "", "", "mean_error", "=", "mean_error", "/", "float", "(", "count", ")", "\n", "return", "mean_error", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.ABX_evaluation.utils.conversion_arpa_ipa": [[10, 24], ["dict", "symbol_arpa.upper", "print", "symbol_arpa.upper"], "function", ["None"], ["def", "conversion_arpa_ipa", "(", "symbol_arpa", ")", ":", "\n", "    ", "Arpabet_dict", "=", "dict", "(", "{", "\"AA\"", ":", "\"\u0251\"", ",", "\"AE\"", ":", "\"\u00e6\"", ",", "\"AH\"", ":", "\"\u028c\"", ",", "\"AO\"", ":", "\"\u0254\"", ",", "\"AW\"", ":", "\"a\u028a\"", ",", "\"AX\"", ":", "\"\u0259\"", ",", "\"AXR\"", ":", "\"\u025a\"", ",", "\"AY\"", ":", "\"a\u026a\"", ",", "\n", "\"EH\"", ":", "\"\u025b\"", ",", "\"ER\"", ":", "\"\u025d\"", ",", "\"EY\"", ":", "\"e\u026a\"", ",", "\"IH\"", ":", "\"\u026a\"", ",", "\"IX\"", ":", "\"\u0268\"", ",", "\"IY\"", ":", "\"i\"", ",", "\"OW\"", ":", "\"o\u028a\"", ",", "\"OY\"", ":", "\"\u0254\u026a\"", ",", "\n", "\"UH\"", ":", "\"\u028a\"", ",", "\"UW\"", ":", "\"u\"", ",", "\"UX\"", ":", "\"\u0289\"", ",", "\"B\"", ":", "\"b\"", ",", "\"CH\"", ":", "\"t\u0283\"", ",", "\n", "\"D\"", ":", "\"d\"", ",", "\"DH\"", ":", "\"\u00f0\"", ",", "\"DX\"", ":", "\"\u027e\"", ",", "\"EL\"", ":", "\"l\u0329\"", ",", "\"EM\"", ":", "\"m\u0329\"", ",", "\"EN\"", ":", "\"n\u0329\"", ",", "\"F\"", ":", "\"f\"", ",", "\"G\"", ":", "\"g\"", ",", "\n", "\"HH\"", ":", "\"h\"", ",", "\"JH\"", ":", "\"d\u0292\"", ",", "\"K\"", ":", "\"k\"", ",", "\n", "\"L\"", ":", "\"l\"", ",", "\"M\"", ":", "\"m\"", ",", "\"N\"", ":", "\"n\"", ",", "\"NG\"", ":", "\"\u014b\"", ",", "\"NX\"", ":", "\"\u027e\u0303\"", ",", "\"P\"", ":", "\"p\"", ",", "\"Q\"", ":", "\"\u0294\"", ",", "\"R\"", ":", "\"\u0279\"", ",", "\"S\"", ":", "\"s\"", ",", "\n", "\"SH\"", ":", "\"\u0283\"", ",", "\"T\"", ":", "\"t\"", ",", "\n", "\"TH\"", ":", "\"\u03b8\"", ",", "\"V\"", ":", "\"v\"", ",", "\"W\"", ":", "\"w\"", ",", "\"WH\"", ":", "\"\u028d\"", ",", "\"Y\"", ":", "\"j\"", ",", "\"Z\"", ":", "\"z\"", ",", "\"ZH\"", ":", "\"\u0292\"", "}", ")", "\n", "\n", "if", "symbol_arpa", ".", "upper", "(", ")", "not", "in", "Arpabet_dict", ":", "\n", "        ", "print", "(", "\"ERROR symbole not recognised\"", ",", "symbol_arpa", ")", "\n", "", "else", ":", "\n", "        ", "return", "Arpabet_dict", "[", "symbol_arpa", ".", "upper", "(", ")", "]", "", "", "", ""]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.__init__": [[30, 64], ["class_corpus.Speaker.get_corpus_name", "int", "int", "class_corpus.Speaker.init_corpus_param"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.get_corpus_name", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.init_corpus_param"], ["def", "__init__", "(", "self", ",", "speaker", ")", ":", "\n", "        ", "\"\"\"\n        :param name:  name of the speaker\n        \"\"\"", "\n", "self", ".", "speaker", "=", "speaker", "\n", "self", ".", "speakers", "=", "None", "\n", "self", ".", "corpus", "=", "None", "\n", "self", ".", "get_corpus_name", "(", ")", "\n", "self", ".", "sampling_rate_wav_wanted", "=", "16000", "\n", "self", ".", "frame_time", "=", "25", "/", "1000", "\n", "self", ".", "hop_time", "=", "10", "/", "1000", "\n", "self", ".", "hop_length", "=", "int", "(", "self", ".", "hop_time", "*", "self", ".", "sampling_rate_wav_wanted", ")", "\n", "self", ".", "frame_length", "=", "int", "(", "self", ".", "frame_time", "*", "self", ".", "sampling_rate_wav_wanted", ")", "\n", "self", ".", "window", "=", "5", "\n", "self", ".", "n_coeff", "=", "13", "\n", "self", ".", "sampling_rate_ema", "=", "None", "\n", "self", ".", "sampling_rate_wav", "=", "None", "\n", "self", ".", "speakers", "=", "None", "\n", "self", ".", "articulators", "=", "[", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", "\n", ",", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", "]", "\n", "self", ".", "speakers_with_velum", "=", "[", "\"fsew0\"", ",", "\"msak0\"", ",", "\"faet0\"", ",", "\"ffes0\"", ",", "\"falh0\"", "]", "\n", "self", ".", "init_corpus_param", "(", ")", "\n", "self", ".", "EMA_files", "=", "None", "\n", "if", "self", ".", "speaker", "in", "self", ".", "speakers_with_velum", ":", "\n", "            ", "self", ".", "articulators", "=", "[", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", ",", "\n", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", ",", "'v_x'", ",", "'v_y'", "]", "\n", "", "self", ".", "list_EMA_traj", "=", "[", "]", "\n", "self", ".", "list_MFCC_frames", "=", "[", "]", "\n", "\n", "self", ".", "std_ema", "=", "None", "\n", "self", ".", "moving_average_ema", "=", "None", "\n", "self", ".", "mean_ema", "=", "None", "\n", "self", ".", "std_mfcc", "=", "None", "\n", "self", ".", "mean_mfcc", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.get_corpus_name": [[65, 80], ["NameError"], "methods", ["None"], ["", "def", "get_corpus_name", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        define the corpus the speaker comes from\n        \"\"\"", "\n", "if", "self", ".", "speaker", "==", "\"MNGU0\"", ":", "\n", "            ", "corpus", "=", "\"MNGU0\"", "\n", "", "elif", "self", ".", "speaker", "in", "[", "\"F1\"", ",", "\"F5\"", ",", "\"M1\"", ",", "\"M3\"", "]", ":", "\n", "            ", "corpus", "=", "\"usc\"", "\n", "", "elif", "self", ".", "speaker", "in", "[", "\"F01\"", ",", "\"F02\"", ",", "\"F03\"", ",", "\"F04\"", ",", "\"M01\"", ",", "\"M02\"", ",", "\"M03\"", ",", "\"M04\"", "]", ":", "\n", "            ", "corpus", "=", "\"Haskins\"", "\n", "", "elif", "self", ".", "speaker", "in", "[", "\"fsew0\"", ",", "\"msak0\"", ",", "\"faet0\"", ",", "\"ffes0\"", ",", "\"maps0\"", ",", "\"mjjn0\"", ",", "\"falh0\"", "]", ":", "\n", "            ", "corpus", "=", "\"mocha\"", "\n", "", "else", ":", "\n", "            ", "raise", "NameError", "(", "\"vous navez pas choisi un des speasker\"", ")", "\n", "", "self", ".", "corpus", "=", "corpus", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.init_corpus_param": [[81, 104], ["None"], "methods", ["None"], ["", "def", "init_corpus_param", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Initialize some parameters depending on the corpus\n        \"\"\"", "\n", "if", "self", ".", "corpus", "==", "\"mocha\"", ":", "\n", "            ", "self", ".", "sampling_rate_wav", "=", "16000", "\n", "self", ".", "sampling_rate_ema", "=", "500", "\n", "self", ".", "cutoff", "=", "10", "\n", "\n", "", "elif", "self", ".", "corpus", "==", "\"MNGU0\"", ":", "\n", "            ", "self", ".", "sampling_rate_wav", "=", "16000", "\n", "self", ".", "sampling_rate_ema", "=", "200", "\n", "self", ".", "cutoff", "=", "10", "\n", "\n", "", "elif", "self", ".", "corpus", "==", "\"usc\"", ":", "\n", "            ", "self", ".", "sampling_rate_wav", "=", "20000", "\n", "self", ".", "sampling_rate_ema", "=", "100", "\n", "self", ".", "cutoff", "=", "10", "\n", "\n", "", "elif", "self", ".", "corpus", "==", "\"Haskins\"", ":", "\n", "            ", "self", ".", "sampling_rate_wav", "=", "44100", "\n", "self", ".", "sampling_rate_ema", "=", "100", "\n", "self", ".", "cutoff", "=", "20", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data": [[105, 124], ["Preprocessing.tools_preprocessing.low_pass_filter_weight", "numpy.concatenate", "numpy.concatenate", "numpy.expand_dims", "numpy.expand_dims", "numpy.pad", "range", "numpy.convolve"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.low_pass_filter_weight"], ["", "", "def", "smooth_data", "(", "self", ",", "ema", ",", "sr", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        :param ema: one ema trajectory\n        :param sr: sampling rate of the ema trajectory\n        :return:  the smoothed ema trajectory\n        \"\"\"", "\n", "pad", "=", "30", "\n", "if", "sr", "==", "0", ":", "\n", "            ", "sr", "=", "self", ".", "sampling_rate_ema", "\n", "", "cutoff", "=", "self", ".", "cutoff", "\n", "weights", "=", "low_pass_filter_weight", "(", "cut_off", "=", "cutoff", ",", "sampling_rate", "=", "sr", ")", "\n", "\n", "my_ema_filtered", "=", "np", ".", "concatenate", "(", "[", "np", ".", "expand_dims", "(", "np", ".", "pad", "(", "ema", "[", ":", ",", "k", "]", ",", "(", "pad", ",", "pad", ")", ",", "\"symmetric\"", ")", ",", "1", ")", "\n", "for", "k", "in", "range", "(", "ema", ".", "shape", "[", "1", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "my_ema_filtered", "=", "np", ".", "concatenate", "(", "[", "np", ".", "expand_dims", "(", "np", ".", "convolve", "(", "channel", ",", "weights", ",", "mode", "=", "'same'", ")", ",", "1", ")", "\n", "for", "channel", "in", "my_ema_filtered", ".", "T", "]", ",", "axis", "=", "1", ")", "\n", "my_ema_filtered", "=", "my_ema_filtered", "[", "pad", ":", "-", "pad", ",", ":", "]", "\n", "return", "my_ema_filtered", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.calculate_norm_values": [[125, 166], ["numpy.array", "numpy.save", "numpy.concatenate", "numpy.array", "numpy.concatenate", "numpy.std", "numpy.mean", "numpy.mean", "numpy.mean", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "numpy.save", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.array", "numpy.array", "numpy.array", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "numpy.mean", "numpy.expand_dims", "numpy.mean", "numpy.pad", "range", "range", "numpy.mean", "numpy.std", "numpy.mean", "len"], "methods", ["None"], ["", "def", "calculate_norm_values", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        based on all the EMA trajectories and frames MFCC calculate the norm values :\n        - mean of ema and mfcc\n        - std of ema and mfcc\n        - moving average for ema on 60 sentences\n        then save those norm values\n        \"\"\"", "\n", "list_EMA_traj", "=", "self", ".", "list_EMA_traj", "\n", "list_MFCC_frames", "=", "self", ".", "list_MFCC_frames", "\n", "\n", "pad", "=", "30", "\n", "all_mean_ema", "=", "np", ".", "array", "(", "[", "np", ".", "mean", "(", "traj", ",", "axis", "=", "0", ")", "for", "traj", "in", "list_EMA_traj", "]", ")", "# (18, n_sentences)", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "\"norm_values\"", ",", "\"all_mean_ema_\"", "+", "self", ".", "speaker", ")", ",", "all_mean_ema", ")", "\n", "#    weights_moving_average = low_pass_filter_weight(cut_off=10, sampling_rate=self.sampling_rate_ema)", "\n", "all_mean_ema", "=", "np", ".", "concatenate", "(", "[", "np", ".", "expand_dims", "(", "np", ".", "pad", "(", "all_mean_ema", "[", ":", ",", "k", "]", ",", "(", "pad", ",", "pad", ")", ",", "\"symmetric\"", ")", ",", "1", ")", "\n", "for", "k", "in", "range", "(", "all_mean_ema", ".", "shape", "[", "1", "]", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "moving_average", "=", "np", ".", "array", "(", "\n", "[", "np", ".", "mean", "(", "all_mean_ema", "[", "k", "-", "pad", ":", "k", "+", "pad", "]", ",", "axis", "=", "0", ")", "for", "k", "in", "range", "(", "pad", ",", "len", "(", "all_mean_ema", ")", "-", "pad", ")", "]", ")", "\n", "\n", "all_EMA_concat", "=", "np", ".", "concatenate", "(", "[", "traj", "for", "traj", "in", "list_EMA_traj", "]", ",", "axis", "=", "0", ")", "\n", "std_ema", "=", "np", ".", "std", "(", "all_EMA_concat", ",", "axis", "=", "0", ")", "\n", "std_ema", "[", "std_ema", "<", "1e-3", "]", "=", "1", "\n", "\n", "mean_ema", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "[", "np", ".", "mean", "(", "traj", ",", "axis", "=", "0", ")", "for", "traj", "in", "list_EMA_traj", "]", ")", ",", "\n", "axis", "=", "0", ")", "\n", "std_mfcc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "[", "np", ".", "std", "(", "frame", ",", "axis", "=", "0", ")", "for", "frame", "in", "list_MFCC_frames", "]", ")", ",", "axis", "=", "0", ")", "\n", "mean_mfcc", "=", "np", ".", "mean", "(", "np", ".", "array", "(", "[", "np", ".", "mean", "(", "frame", ",", "axis", "=", "0", ")", "for", "frame", "in", "list_MFCC_frames", "]", ")", ",", "axis", "=", "0", ")", "\n", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "\"norm_values\"", ",", "\"moving_average_ema_\"", "+", "self", ".", "speaker", ")", ",", "moving_average", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "\"norm_values\"", ",", "\"std_ema_\"", "+", "self", ".", "speaker", ")", ",", "std_ema", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "\"norm_values\"", ",", "\"mean_ema_\"", "+", "self", ".", "speaker", ")", ",", "mean_ema", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "\"norm_values\"", ",", "\"std_mfcc_\"", "+", "self", ".", "speaker", ")", ",", "std_mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "\"norm_values\"", ",", "\"mean_mfcc_\"", "+", "self", ".", "speaker", ")", ",", "mean_mfcc", ")", "\n", "\n", "self", ".", "std_ema", "=", "std_ema", "\n", "self", ".", "moving_average_ema", "=", "moving_average", "\n", "self", ".", "mean_ema", "=", "mean_ema", "\n", "self", ".", "mean_mfcc", "=", "mean_mfcc", "\n", "self", ".", "std_mfcc", "=", "std_mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.add_vocal_tract": [[167, 247], ["class_corpus.Speaker.add_vocal_tract.add_lip_aperture"], "methods", ["None"], ["", "def", "add_vocal_tract", "(", "self", ",", "my_ema", ")", ":", "\n", "        ", "\"\"\"\n        calculate 4 'vocal tract' and reorganize the data into a 18 trajectories in a precised order\n        :param my_ema: EMA trajectory with K points\n        :return: a np array (18,K) where the trajectories are sorted, and unavailable trajectories are at 0\n        \"\"\"", "\n", "def", "add_lip_aperture", "(", "ema", ")", ":", "\n", "            ", "\"\"\"\n            :param ema: 1 ema trajectory\n            :return: return lip aperture trajectory upperlip_y - lowerlip_y\n            \"\"\"", "\n", "ind_1", ",", "ind_2", "=", "[", "self", ".", "articulators", ".", "index", "(", "\"ul_y\"", ")", ",", "self", ".", "articulators", ".", "index", "(", "\"ll_y\"", ")", "]", "\n", "lip_aperture", "=", "ema", "[", ":", ",", "ind_1", "]", "-", "ema", "[", ":", ",", "ind_2", "]", "# upperlip_y - lowerlip_y", "\n", "return", "lip_aperture", "\n", "\n", "", "def", "add_lip_protrusion", "(", "ema", ")", ":", "\n", "            ", "\"\"\"\n            :param ema: 1 ema trajectory\n            :return: return lip protrusion trajectory (upperlip_x + lowerlip_x)/2\n            \"\"\"", "\n", "ind_1", ",", "ind_2", "=", "[", "self", ".", "articulators", ".", "index", "(", "\"ul_x\"", ")", ",", "self", ".", "articulators", ".", "index", "(", "\"ll_x\"", ")", "]", "\n", "lip_protrusion", "=", "(", "ema", "[", ":", ",", "ind_1", "]", "+", "ema", "[", ":", ",", "ind_2", "]", ")", "/", "2", "\n", "return", "lip_protrusion", "\n", "\n", "", "def", "add_TTCL", "(", "ema", ")", ":", "# tongue tip constriction location in degree", "\n", "            ", "\"\"\"\n           :param ema: 1 ema trajectory\n           :return: return tongue tip constriction location in degree trajectory .\n           Formula to check again , corresponds to the cos of the angle between the horizontal and the tongue tip location\n           \"\"\"", "\n", "ind_1", ",", "ind_2", "=", "[", "self", ".", "articulators", ".", "index", "(", "\"tt_x\"", ")", ",", "self", ".", "articulators", ".", "index", "(", "\"tt_y\"", ")", "]", "\n", "TTCL", "=", "ema", "[", ":", ",", "ind_1", "]", "/", "np", ".", "sqrt", "(", "ema", "[", ":", ",", "ind_1", "]", "**", "2", "+", "ema", "[", ":", ",", "ind_2", "]", "**", "2", ")", "\n", "return", "TTCL", "\n", "\n", "", "def", "add_TBCL", "(", "ema", ")", ":", "\n", "            ", "\"\"\"\n            :param ema: 1 ema trajectory\n           :return: return tongue body constriction location in degree trajectory .\n           Formula to check again , corresponds to the cos of the angle between the horizontal and the tongue body location\n            \"\"\"", "\n", "ind_1", ",", "ind_2", "=", "[", "self", ".", "articulators", ".", "index", "(", "\"tb_x\"", ")", ",", "self", ".", "articulators", ".", "index", "(", "\"tb_y\"", ")", "]", "\n", "TBCL", "=", "ema", "[", ":", ",", "ind_1", "]", "/", "np", ".", "sqrt", "(", "ema", "[", ":", ",", "ind_1", "]", "**", "2", "+", "ema", "[", ":", ",", "ind_2", "]", "**", "2", ")", "# upperlip_y - lowerlip_y", "\n", "return", "TBCL", "\n", "\n", "", "def", "arti_not_available", "(", ")", ":", "\n", "            ", "\"\"\"\n            reads a csv that contains for each speaker a list of 18 0/1 , element i is 1 if the arti i is available.\n            :return: index of articulations that are not available for this speaker. Based on the local csv file\n            \"\"\"", "\n", "arti_per_speaker", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessing\"", ",", "\"articulators_per_speaker.csv\"", ")", "\n", "csv", ".", "register_dialect", "(", "'myDialect'", ",", "delimiter", "=", "';'", ")", "\n", "with", "open", "(", "arti_per_speaker", ",", "'r'", ")", "as", "csvFile", ":", "\n", "                ", "reader", "=", "csv", ".", "reader", "(", "csvFile", ",", "dialect", "=", "\"myDialect\"", ")", "\n", "next", "(", "reader", ")", "\n", "for", "row", "in", "reader", ":", "\n", "                    ", "if", "row", "[", "0", "]", "==", "self", ".", "speaker", ":", "# we look for our speaker", "\n", "                        ", "arti_to_consider", "=", "row", "[", "1", ":", "19", "]", "# 1 if available", "\n", "", "", "", "arti_not_avail", "=", "[", "k", "for", "k", ",", "n", "in", "enumerate", "(", "arti_to_consider", ")", "if", "n", "==", "\"0\"", "]", "# 1 of NOT available", "\n", "return", "arti_not_avail", "\n", "\n", "", "lip_aperture", "=", "add_lip_aperture", "(", "my_ema", ")", "\n", "lip_protrusion", "=", "add_lip_protrusion", "(", "my_ema", ")", "\n", "TTCL", "=", "add_TTCL", "(", "my_ema", ")", "\n", "TBCL", "=", "add_TBCL", "(", "my_ema", ")", "\n", "\n", "if", "self", ".", "speaker", "in", "self", ".", "speakers_with_velum", ":", "# 14 arti de 0 \u00e0 13 (2*6 + 2)", "\n", "            ", "my_ema", "=", "np", ".", "concatenate", "(", "(", "my_ema", ",", "np", ".", "zeros", "(", "(", "len", "(", "my_ema", ")", ",", "4", ")", ")", ")", ",", "axis", "=", "1", ")", "\n", "my_ema", "[", ":", ",", "16", ":", "18", "]", "=", "my_ema", "[", ":", ",", "12", ":", "14", "]", "# met les velum dans les 2 dernieres arti", "\n", "my_ema", "[", ":", ",", "12", ":", "16", "]", "=", "0", "# les 4 autres colonnes vont etre remplies avec les VT par la suite", "\n", "\n", "", "else", ":", "\n", "            ", "my_ema", "=", "np", ".", "concatenate", "(", "(", "my_ema", ",", "np", ".", "zeros", "(", "(", "len", "(", "my_ema", ")", ",", "6", ")", ")", ")", ",", "axis", "=", "1", ")", "\n", "\n", "", "my_ema", "[", ":", ",", "12", "]", "=", "lip_aperture", "\n", "my_ema", "[", ":", ",", "13", "]", "=", "lip_protrusion", "\n", "my_ema", "[", ":", ",", "14", "]", "=", "TTCL", "\n", "my_ema", "[", ":", ",", "15", "]", "=", "TBCL", "\n", "idx_to_ignore", "=", "arti_not_available", "(", ")", "\n", "my_ema", "[", ":", ",", "idx_to_ignore", "]", "=", "0", "\n", "return", "my_ema", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.normalize_sentence": [[248, 258], ["None"], "methods", ["None"], ["", "def", "normalize_sentence", "(", "self", ",", "i", ",", "my_ema_filtered", ",", "my_mfcc", ")", ":", "\n", "        ", "\"\"\"\n        :param i: index of the ema traj (to get the moving average)\n        :param my_ema_filtered: the ema smoothed ema traj\n        :param my_mfcc: mfcc frames\n        :return: the normalized EMA et MFCC data\n        \"\"\"", "\n", "my_ema_VT", "=", "(", "my_ema_filtered", "-", "self", ".", "moving_average_ema", "[", "i", ",", ":", "]", ")", "/", "self", ".", "std_ema", "\n", "my_mfcc", "=", "(", "my_mfcc", "-", "self", ".", "mean_mfcc", ")", "/", "self", ".", "std_mfcc", "\n", "return", "my_ema_VT", ",", "my_mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.synchro_ema_mfcc": [[259, 268], ["scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "len"], "methods", ["None"], ["", "def", "synchro_ema_mfcc", "(", "self", ",", "my_ema", ",", "my_mfcc", ")", ":", "\n", "        ", "\"\"\"\n        :param my_ema: ema traj\n        :param my_mfcc: corresponding mfcc frames\n        :return: ema and mfcc synchronized\n        the ema traj is downsampled to have 1 position for 1 frame mfcc\n        \"\"\"", "\n", "my_ema", "=", "scipy", ".", "signal", ".", "resample", "(", "my_ema", ",", "num", "=", "len", "(", "my_mfcc", ")", ")", "\n", "return", "my_ema", ",", "my_mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.main_preprocessing.Preprocessing_general_per_corpus": [[16, 30], ["Preprocessing.preprocessing_mngu0.Preprocessing_general_mngu0", "Preprocessing.preprocessing_usc_timit.Preprocessing_general_usc", "Preprocessing.preprocessing_haskins.Preprocessing_general_haskins", "Preprocessing.preprocessing_mocha.Preprocessing_general_mocha"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Preprocessing_general_mngu0", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Preprocessing_general_usc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Preprocessing_general_haskins", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Preprocessing_general_mocha"], ["def", "Preprocessing_general_per_corpus", "(", "corp", ",", "max", ",", "path_to_corpus", ")", ":", "\n", "    ", "\"\"\"\n    :param corp: corpus we want to do the preprocess\n    :param max:  max of files to preprocess (useful for test), 0 to treat all files\n    perform the preprocess for the asked corpus\n     \"\"\"", "\n", "if", "corp", "==", "\"MNGU0\"", ":", "\n", "        ", "Preprocessing_general_mngu0", "(", "max", ",", "path_to_raw", "=", "path_to_corpus", ")", "\n", "", "elif", "corp", "==", "\"usc\"", ":", "\n", "        ", "Preprocessing_general_usc", "(", "max", ",", "path_to_raw", "=", "path_to_corpus", ")", "\n", "", "elif", "corp", "==", "\"Haskins\"", ":", "\n", "        ", "Preprocessing_general_haskins", "(", "max", ",", "path_to_raw", "=", "path_to_corpus", ")", "\n", "", "elif", "corp", "==", "\"mocha\"", ":", "\n", "        ", "Preprocessing_general_mocha", "(", "max", ",", "path_to_raw", "=", "path_to_corpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Speaker_MNGU0.__init__": [[43, 63], ["Preprocessing.class_corpus.Speaker.__init__", "os.path.join", "os.path.join", "sorted", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "name.endswith"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.__init__"], ["def", "__init__", "(", "self", ",", "path_to_raw", ",", "N_max", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        :param sp:  name of the speaker\n        :param N_max:  # max of files we want to preprocess (0 is for All files), variable useful for test\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "\"MNGU0\"", ")", "# gets the attributes of the Speaker class", "\n", "self", ".", "root_path", "=", "path_to_raw", "\n", "self", ".", "path_files_annotation", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "speaker", ",", "\"phone_labels\"", ")", "\n", "self", ".", "path_ema_files", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "speaker", ",", "\"ema\"", ")", "\n", "self", ".", "EMA_files", "=", "sorted", "(", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "os", ".", "listdir", "(", "self", ".", "path_ema_files", ")", "if", "name", ".", "endswith", "(", "'.ema'", ")", "]", ")", "\n", "self", ".", "path_files_treated", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ")", "\n", "self", ".", "path_files_brutes", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "speaker", ")", "\n", "self", ".", "path_wav_files", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "speaker", ",", "\"wav\"", ")", "\n", "\n", "self", ".", "N_max", "=", "N_max", "\n", "self", ".", "articulators_init", "=", "[", "\n", "'T1_py'", ",", "'T1_pz'", ",", "'T3_py'", ",", "'T3_pz'", ",", "'T2_py'", ",", "'T2_pz'", ",", "\n", "'jaw_py'", ",", "'jaw_pz'", ",", "'upperlip_py'", ",", "'upperlip_pz'", ",", "\n", "'lowerlip_py'", ",", "'lowerlip_pz'", "]", "\n", "self", ".", "n_columns", "=", "87", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Speaker_MNGU0.create_missing_dir": [[65, 82], ["glob.glob", "glob.glob", "glob.glob", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.remove", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "create_missing_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        delete all previous preprocessing, create needed directories\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", "\n", "\n", "", "files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ",", "\"*\"", ")", ")", "\n", "\n", "for", "f", "in", "files", ":", "\n", "            ", "os", ".", "remove", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Speaker_MNGU0.read_ema_file": [[84, 114], ["os.path.join", "open", "numpy.fromfile().reshape", "line.decode().strip.decode().strip.decode().strip", "column_names.index", "numpy.isnan().sum", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "numpy.argwhere().ravel", "line.decode().strip.decode().strip.startswith", "numpy.fromfile", "numpy.argwhere", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "line.decode().strip.decode().strip.decode", "int", "line.decode().strip.decode().strip.startswith", "numpy.isnan", "numpy.argwhere", "line.decode().strip.decode().strip.split", "numpy.isnan().ravel", "numpy.isnan", "line.decode().strip.decode().strip.rsplit", "numpy.isnan", "int", "numpy.isnan", "col_id.split"], "methods", ["None"], ["", "", "def", "read_ema_file", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        read the ema file, first preprocessing,\n        :param i: utterance index (wrt EMA files)\n        :return: npy array (K,12) , K depends on the duration of the recording, 12 trajectories\n        \"\"\"", "\n", "path_ema_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_ema_files", ",", "self", ".", "EMA_files", "[", "k", "]", "+", "\".ema\"", ")", "\n", "with", "open", "(", "path_ema_file", ",", "'rb'", ")", "as", "ema_annotation", ":", "\n", "            ", "column_names", "=", "[", "0", "]", "*", "self", ".", "n_columns", "\n", "for", "line", "in", "ema_annotation", ":", "\n", "                ", "line", "=", "line", ".", "decode", "(", "'latin-1'", ")", ".", "strip", "(", "\"\\n\"", ")", "\n", "if", "line", "==", "'EST_Header_End'", ":", "\n", "                    ", "break", "\n", "", "elif", "line", ".", "startswith", "(", "'NumFrames'", ")", ":", "\n", "                    ", "n_frames", "=", "int", "(", "line", ".", "rsplit", "(", "' '", ",", "1", ")", "[", "-", "1", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'Channel_'", ")", ":", "\n", "                    ", "col_id", ",", "col_name", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "\n", "column_names", "[", "int", "(", "col_id", ".", "split", "(", "'_'", ",", "1", ")", "[", "-", "1", "]", ")", "]", "=", "col_name", "\n", "\n", "", "", "ema_data", "=", "np", ".", "fromfile", "(", "ema_annotation", ",", "\"float32\"", ")", ".", "reshape", "(", "n_frames", ",", "self", ".", "n_columns", "+", "2", ")", "\n", "cols_index", "=", "[", "column_names", ".", "index", "(", "col", ")", "for", "col", "in", "self", ".", "articulators_init", "]", "\n", "ema_data", "=", "ema_data", "[", ":", ",", "cols_index", "]", "\n", "ema_data", "=", "ema_data", "*", "100", "#initial data in  10^-5m , we turn it to mm", "\n", "if", "np", ".", "isnan", "(", "ema_data", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "# Build a cubic spline out of non-NaN values.", "\n", "                ", "spline", "=", "scipy", ".", "interpolate", ".", "splrep", "(", "np", ".", "argwhere", "(", "~", "np", ".", "isnan", "(", "ema_data", ")", ".", "ravel", "(", ")", ")", ",", "ema_data", "[", "~", "np", ".", "isnan", "(", "ema_data", ")", "]", ",", "k", "=", "3", ")", "\n", "# Interpolate missing values and replace them.", "\n", "for", "j", "in", "np", ".", "argwhere", "(", "np", ".", "isnan", "(", "ema_data", ")", ")", ".", "ravel", "(", ")", ":", "\n", "                    ", "ema_data", "[", "j", "]", "=", "scipy", ".", "interpolate", ".", "splev", "(", "j", ",", "spline", ")", "\n", "", "", "return", "ema_data", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Speaker_MNGU0.remove_silences": [[115, 144], ["os.path.join", "open", "max", "int", "int", "int", "int", "next", "row.strip().strip().replace().split", "round", "numpy.floor", "min", "numpy.floor", "numpy.ceil", "float", "len", "row.strip().strip().replace", "numpy.floor", "row.strip().strip", "row.strip"], "methods", ["None"], ["", "", "def", "remove_silences", "(", "self", ",", "k", ",", "ema", ",", "mfcc", ")", ":", "\n", "        ", "\"\"\"\n        :param k:  utterance index (wrt the list EMA_files)\n        :param ema: the ema list of traj\n        :param mfcc: the mfcc features\n        :return: the data (ema and mfcc) without the silence at the beginning and end of the recording\n        reads the annotation file to get (in sec) the extremity of the voice,\n        calculates the equivalence in # of ema points and # of mfcc frames\n        \"\"\"", "\n", "marge", "=", "0", "\n", "path_annotation", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_annotation", ",", "self", ".", "EMA_files", "[", "k", "]", "+", "'.lab'", ")", "\n", "with", "open", "(", "path_annotation", ")", "as", "file", ":", "\n", "            ", "while", "next", "(", "file", ")", "!=", "'#\\n'", ":", "\n", "                ", "pass", "\n", "", "labels", "=", "[", "row", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", "'\\t'", ")", ".", "replace", "(", "' 26 '", ",", "''", ")", ".", "split", "(", "'\\t'", ")", "for", "row", "in", "file", "]", "\n", "", "labels", "=", "[", "(", "round", "(", "float", "(", "label", "[", "0", "]", ")", ",", "2", ")", ",", "label", "[", "1", "]", ")", "for", "label", "in", "labels", "]", "\n", "start_time", "=", "labels", "[", "0", "]", "[", "0", "]", "if", "labels", "[", "0", "]", "[", "1", "]", "==", "'#'", "else", "0", "\n", "end_time", "=", "labels", "[", "-", "2", "]", "[", "0", "]", "if", "labels", "[", "-", "1", "]", "[", "1", "]", "==", "'#'", "else", "labels", "[", "-", "1", "]", "[", "0", "]", "\n", "xtrm", "=", "[", "max", "(", "start_time", "-", "marge", ",", "0", ")", ",", "end_time", "+", "marge", "]", "\n", "\n", "xtrm_temp_ema", "=", "[", "int", "(", "np", ".", "floor", "(", "xtrm", "[", "0", "]", "*", "self", ".", "sampling_rate_ema", ")", ")", ",", "\n", "int", "(", "min", "(", "np", ".", "floor", "(", "xtrm", "[", "1", "]", "*", "self", ".", "sampling_rate_ema", ")", "+", "1", ",", "len", "(", "ema", ")", ")", ")", "]", "\n", "\n", "xtrm_temp_mfcc", "=", "[", "int", "(", "np", ".", "floor", "(", "xtrm", "[", "0", "]", "/", "self", ".", "hop_time", ")", ")", ",", "\n", "int", "(", "np", ".", "ceil", "(", "xtrm", "[", "1", "]", "/", "self", ".", "hop_time", ")", ")", "]", "\n", "\n", "mfcc", "=", "mfcc", "[", "xtrm_temp_mfcc", "[", "0", "]", ":", "xtrm_temp_mfcc", "[", "1", "]", "]", "\n", "ema", "=", "ema", "[", "xtrm_temp_ema", "[", "0", "]", ":", "xtrm_temp_ema", "[", "1", "]", ",", ":", "]", "\n", "return", "ema", ",", "mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Speaker_MNGU0.from_wav_to_mfcc": [[145, 164], ["Preprocessing.tools_preprocessing.get_delta_features", "Preprocessing.tools_preprocessing.get_delta_features", "numpy.concatenate", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "librosa.feature.mfcc", "range", "len"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features"], ["", "def", "from_wav_to_mfcc", "(", "self", ",", "wav", ")", ":", "\n", "        ", "\"\"\"\n        :param wav: list of intensity points of the wav file\n        :return: the acoustic features( K,429); where K in the # of frames.\n        calculations of the mfcc with librosa , + Delta and DeltaDelta, + 10 context frames\n        # of acoustic features per frame: 13 ==> 13*3 = 39 ==> 39*11 = 429.\n        parameters for mfcc calculation are defined in class_corpus\n        \"\"\"", "\n", "mfcc", "=", "librosa", ".", "feature", ".", "mfcc", "(", "y", "=", "wav", ",", "sr", "=", "self", ".", "sampling_rate_wav", ",", "n_mfcc", "=", "self", ".", "n_coeff", ",", "\n", "n_fft", "=", "self", ".", "frame_length", ",", "hop_length", "=", "self", ".", "hop_length", "\n", ")", ".", "T", "\n", "dyna_features", "=", "get_delta_features", "(", "mfcc", ")", "\n", "dyna_features_2", "=", "get_delta_features", "(", "dyna_features", ")", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "(", "mfcc", ",", "dyna_features", ",", "dyna_features_2", ")", ",", "axis", "=", "1", ")", "\n", "padding", "=", "np", ".", "zeros", "(", "(", "self", ".", "window", ",", "mfcc", ".", "shape", "[", "1", "]", ")", ")", "\n", "frames", "=", "np", ".", "concatenate", "(", "[", "padding", ",", "mfcc", ",", "padding", "]", ")", "\n", "full_window", "=", "1", "+", "2", "*", "self", ".", "window", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "[", "frames", "[", "i", ":", "i", "+", "len", "(", "mfcc", ")", "]", "for", "i", "in", "range", "(", "full_window", ")", "]", ",", "axis", "=", "1", ")", "\n", "return", "mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Speaker_MNGU0.Preprocessing_general_speaker": [[165, 209], ["preprocessing_mngu0.Speaker_MNGU0.create_missing_dir", "len", "range", "preprocessing_mngu0.Speaker_MNGU0.calculate_norm_values", "range", "Preprocessing.tools_preprocessing.get_fileset_names", "preprocessing_mngu0.Speaker_MNGU0.read_ema_file", "preprocessing_mngu0.Speaker_MNGU0.add_vocal_tract", "preprocessing_mngu0.Speaker_MNGU0.smooth_data", "os.path.join", "librosa.load", "preprocessing_mngu0.Speaker_MNGU0.from_wav_to_mfcc", "preprocessing_mngu0.Speaker_MNGU0.remove_silences", "preprocessing_mngu0.Speaker_MNGU0.synchro_ema_mfcc", "numpy.save", "numpy.save", "numpy.save", "preprocessing_mngu0.Speaker_MNGU0.list_EMA_traj.append", "preprocessing_mngu0.Speaker_MNGU0.list_MFCC_frames.append", "numpy.load", "numpy.load", "preprocessing_mngu0.Speaker_MNGU0.normalize_sentence", "numpy.save", "numpy.save", "numpy.max", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.create_missing_dir", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.calculate_norm_values", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_fileset_names", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.read_ema_file", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.add_vocal_tract", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.from_wav_to_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.remove_silences", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.synchro_ema_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.normalize_sentence"], ["", "def", "Preprocessing_general_speaker", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Go through the sentences one by one.\n            - reads ema data and turn it to a (K,18) array where arti are in a precise order, interploate missing values,\n        smooth the trajectories, remove silences at the beginning and the end, undersample to have 1 position per\n        frame mfcc, add it to the list of EMA traj for this speaker\n            - reads the wav file, calculate the associated acoustic features (mfcc+delta+ deltadelta+contextframes) ,\n        add it to the list of the MFCC FEATURES for this speaker.\n        Then calculate the normvalues based on the list of ema/mfcc data for this speaker\n        Finally : normalization and last smoothing of the trajectories.\n        Final data are in Preprocessed_data/speaker/ema_final.npy and  mfcc.npy\n        \"\"\"", "\n", "\n", "self", ".", "create_missing_dir", "(", ")", "\n", "N", "=", "len", "(", "self", ".", "EMA_files", ")", "\n", "if", "self", ".", "N_max", "!=", "0", ":", "\n", "            ", "N", "=", "self", ".", "N_max", "\n", "", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "ema", "=", "self", ".", "read_ema_file", "(", "i", ")", "\n", "ema_VT", "=", "self", ".", "add_vocal_tract", "(", "ema", ")", "\n", "ema_VT_smooth", "=", "self", ".", "smooth_data", "(", "ema_VT", ")", "\n", "path_wav", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_wav_files", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "'.wav'", ")", "\n", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "path_wav", ",", "sr", "=", "self", ".", "sampling_rate_wav", ")", "\n", "wav", "=", "0.5", "*", "wav", "/", "np", ".", "max", "(", "wav", ")", "\n", "mfcc", "=", "self", ".", "from_wav_to_mfcc", "(", "wav", ")", "\n", "ema_VT_smooth", ",", "mfcc", "=", "self", ".", "remove_silences", "(", "i", ",", "ema_VT_smooth", ",", "mfcc", ")", "\n", "ema_VT_smooth", ",", "mfcc", "=", "self", ".", "synchro_ema_mfcc", "(", "ema_VT_smooth", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "ema_VT", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "ema_VT_smooth", ")", "\n", "self", ".", "list_EMA_traj", ".", "append", "(", "ema_VT_smooth", ")", "\n", "self", ".", "list_MFCC_frames", ".", "append", "(", "mfcc", ")", "\n", "", "self", ".", "calculate_norm_values", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "ema_VT_smooth", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "mfcc", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "ema_VT_smooth_norma", ",", "mfcc", "=", "self", ".", "normalize_sentence", "(", "i", ",", "ema_VT_smooth", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "\n", "ema_VT_smooth_norma", ")", "\n", "#  split_sentences(speaker)", "\n", "", "get_fileset_names", "(", "self", ".", "speaker", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mngu0.Preprocessing_general_mngu0": [[211, 218], ["preprocessing_mngu0.Speaker_MNGU0", "preprocessing_mngu0.Speaker_MNGU0.Preprocessing_general_speaker", "print"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.Preprocessing_general_speaker"], ["", "", "def", "Preprocessing_general_mngu0", "(", "N_max", ",", "path_to_raw", ")", ":", "\n", "    ", "\"\"\"\n    :param N_max: #max of files to treat (0 to treat all files), useful for tests\n    \"\"\"", "\n", "speaker", "=", "Speaker_MNGU0", "(", "path_to_raw", "=", "path_to_raw", ",", "N_max", "=", "N_max", ")", "\n", "speaker", ".", "Preprocessing_general_speaker", "(", ")", "\n", "print", "(", "\"Done MNGU0 \"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features": [[26, 43], ["range", "numpy.array", "numpy.ones", "numpy.concatenate", "numpy.concatenate", "all_diff.append", "numpy.sum", "numpy.sum", "range", "range"], "function", ["None"], ["def", "get_delta_features", "(", "array", ",", "window", "=", "5", ")", ":", "\n", "    ", "\"\"\"\n    :param array: nparray (K,N) N features per frame, K frames.\n    :param window: size of the window to calculate the average speed of the features\n    :return: the speed of each feature wrt 5 future and 5 past frames\n\n    \"\"\"", "\n", "all_diff", "=", "[", "]", "\n", "for", "lag", "in", "range", "(", "1", ",", "window", "+", "1", ")", ":", "\n", "        ", "padding", "=", "np", ".", "ones", "(", "(", "lag", ",", "array", ".", "shape", "[", "1", "]", ")", ")", "\n", "past", "=", "np", ".", "concatenate", "(", "[", "padding", "*", "array", "[", "0", "]", ",", "array", "[", ":", "-", "lag", "]", "]", ")", "\n", "future", "=", "np", ".", "concatenate", "(", "[", "array", "[", "lag", ":", "]", ",", "padding", "*", "array", "[", "-", "1", "]", "]", ")", "\n", "all_diff", ".", "append", "(", "future", "-", "past", ")", "\n", "", "tempo", "=", "np", ".", "array", "(", "[", "all_diff", "[", "lag", "]", "*", "lag", "for", "lag", "in", "range", "(", "window", ")", "]", ")", "\n", "norm", "=", "2", "*", "np", ".", "sum", "(", "i", "**", "2", "for", "i", "in", "range", "(", "1", ",", "window", "+", "1", ")", ")", "\n", "delta_features", "=", "np", ".", "sum", "(", "tempo", ",", "axis", "=", "0", ")", "/", "norm", "\n", "return", "delta_features", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_speakers_per_corpus": [[44, 61], ["NameError"], "function", ["None"], ["", "def", "get_speakers_per_corpus", "(", "corpus", ")", ":", "\n", "    ", "\"\"\"\n    :param corpus: name of the corpus\n    :return: list of the speakers in the corpus\n    return the list of the speakers names corresponding to the corpus\n    \"\"\"", "\n", "if", "corpus", "==", "\"MNGU0\"", ":", "\n", "        ", "speakers", "=", "[", "\"MNGU0\"", "]", "\n", "", "elif", "corpus", "==", "\"usc\"", ":", "\n", "        ", "speakers", "=", "[", "\"F1\"", ",", "\"F5\"", ",", "\"M1\"", ",", "\"M3\"", "]", "\n", "", "elif", "corpus", "==", "\"Haskins\"", ":", "\n", "        ", "speakers", "=", "[", "\"F01\"", ",", "\"F02\"", ",", "\"F03\"", ",", "\"F04\"", ",", "\"M01\"", ",", "\"M02\"", ",", "\"M03\"", ",", "\"M04\"", "]", "\n", "", "elif", "corpus", "==", "\"mocha\"", ":", "\n", "        ", "speakers", "=", "[", "\"fsew0\"", ",", "\"msak0\"", ",", "\"faet0\"", ",", "\"ffes0\"", ",", "\"maps0\"", ",", "\"mjjn0\"", ",", "\"falh0\"", "]", "\n", "", "else", ":", "\n", "        ", "raise", "NameError", "(", "\"vous navez pas choisi un des corpus\"", ")", "\n", "", "return", "speakers", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_fileset_names": [[63, 95], ["os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "random.shuffle", "int", "int", "open", "open.write", "open.close", "open", "open.write", "open.close", "open", "open.write", "open.close", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "os.listdir", "name.endswith", "os.path.join", "os.path.join"], "function", ["None"], ["", "def", "get_fileset_names", "(", "speaker", ")", ":", "\n", "    ", "\"\"\"\n    :param speaker: name of a speaker\n    once the data are preprocessed, this function split the dataset for a speaker into train/valid/test.\n    The repartition is 70% 10% 20%, and the split is random.\n    write 3 txt files (sp_train, sp_test, and sp_valid) containing the names of the files concerned.\n    These txt files\n    \"\"\"", "\n", "donnees_path", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessed_data\"", ")", "\n", "files_path", "=", "os", ".", "path", ".", "join", "(", "donnees_path", ",", "speaker", ")", "\n", "EMA_files_names", "=", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "files_path", ",", "\"ema_final\"", ")", ")", "if", "name", ".", "endswith", "(", "'.npy'", ")", "]", "\n", "N", "=", "len", "(", "EMA_files_names", ")", "\n", "shuffle", "(", "EMA_files_names", ")", "\n", "pourcent_train", "=", "0.7", "\n", "pourcent_test", "=", "0.2", "\n", "n_train", "=", "int", "(", "N", "*", "pourcent_train", ")", "\n", "n_test", "=", "int", "(", "N", "*", "pourcent_test", ")", "\n", "train_files", "=", "EMA_files_names", "[", ":", "n_train", "]", "\n", "test_files", "=", "EMA_files_names", "[", "n_train", ":", "n_train", "+", "n_test", "]", "\n", "valid_files", "=", "EMA_files_names", "[", "n_train", "+", "n_test", ":", "]", "\n", "\n", "outF", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessed_data\"", ",", "\"fileset\"", ",", "speaker", "+", "\"_train.txt\"", ")", ",", "\"w\"", ")", "\n", "outF", ".", "write", "(", "'\\n'", ".", "join", "(", "train_files", ")", "+", "'\\n'", ")", "\n", "outF", ".", "close", "(", ")", "\n", "\n", "outF", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessed_data\"", ",", "\"fileset\"", ",", "speaker", "+", "\"_test.txt\"", ")", ",", "\"w\"", ")", "\n", "outF", ".", "write", "(", "'\\n'", ".", "join", "(", "test_files", ")", "+", "'\\n'", ")", "\n", "outF", ".", "close", "(", ")", "\n", "\n", "outF", "=", "open", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessed_data\"", ",", "\"fileset\"", ",", "speaker", "+", "\"_valid.txt\"", ")", ",", "\"w\"", ")", "\n", "outF", ".", "write", "(", "'\\n'", ".", "join", "(", "valid_files", ")", "+", "'\\n'", ")", "\n", "outF", ".", "close", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.read_csv_arti_ok_per_speaker": [[97, 128], ["os.path.join", "os.path.join", "csv.register_dialect", "dict", "dict.keys", "open", "csv.reader", "next", "print", "print", "open", "json.dump", "dict", "[].append", "os.path.join", "os.path.join", "print"], "function", ["None"], ["", "def", "read_csv_arti_ok_per_speaker", "(", ")", ":", "\n", "    ", "\"\"\"\n    create a dictionnary , with different categories as keys (from A to F).\n    For a category the value is another dictionnary {\"articulators\" : list of 18 digit with 1 if arti is\n    available for this category,\"speakers\" : list of speakers in this category}\n    The dict is created based on the csv file \"articulators_per_speaer\"\n    \"\"\"", "\n", "arti_per_speaker", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessing\"", ",", "\"articulators_per_speaker.csv\"", ")", "\n", "csv", ".", "register_dialect", "(", "'myDialect'", ",", "delimiter", "=", "';'", ")", "\n", "categ_of_speakers", "=", "dict", "(", ")", "\n", "with", "open", "(", "arti_per_speaker", ",", "'r'", ")", "as", "csvFile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "csvFile", ",", "dialect", "=", "\"myDialect\"", ")", "\n", "next", "(", "reader", ")", "\n", "for", "categ", "in", "[", "\"A\"", ",", "\"B\"", ",", "\"C\"", ",", "\"D\"", ",", "\"E\"", ",", "\"F\"", "]", ":", "\n", "            ", "categ_of_speakers", "[", "categ", "]", "=", "dict", "(", ")", "\n", "categ_of_speakers", "[", "categ", "]", "[", "\"sp\"", "]", "=", "[", "]", "\n", "categ_of_speakers", "[", "categ", "]", "[", "\"arti\"", "]", "=", "None", "\n", "", "for", "row", "in", "reader", ":", "\n", "            ", "categ_of_speakers", "[", "row", "[", "19", "]", "]", "[", "\"sp\"", "]", ".", "append", "(", "row", "[", "0", "]", ")", "\n", "if", "categ_of_speakers", "[", "row", "[", "19", "]", "]", "[", "\"arti\"", "]", ":", "\n", "                ", "if", "categ_of_speakers", "[", "row", "[", "19", "]", "]", "[", "\"arti\"", "]", "!=", "row", "[", "1", ":", "19", "]", ":", "\n", "                    ", "print", "(", "\"check arti and category for categ {}\"", ".", "format", "(", "row", "[", "19", "]", ")", ")", "\n", "", "", "else", ":", "\n", "                ", "categ_of_speakers", "[", "row", "[", "19", "]", "]", "[", "\"arti\"", "]", "=", "row", "[", "1", ":", "19", "]", "\n", "\n", "", "", "", "for", "cle", "in", "categ_of_speakers", ".", "keys", "(", ")", ":", "\n", "        ", "print", "(", "\"categ \"", ",", "cle", ")", "\n", "print", "(", "categ_of_speakers", "[", "cle", "]", ")", "\n", "\n", "", "with", "open", "(", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Training\"", ",", "\"categ_of_speakers.json\"", ")", ",", "'w'", ")", "as", "dico", ":", "\n", "        ", "json", ".", "dump", "(", "categ_of_speakers", ",", "dico", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.add_voicing": [[130, 145], ["int", "int", "scipy.signal.get_window", "scipy.signal.convolve", "numpy.max", "len", "min"], "function", ["None"], ["", "", "def", "add_voicing", "(", "wav", ",", "sr", ")", ":", "\n", "    ", "\"\"\"\n    estimation of voicing using the short term energy threshold between 0 and 1. This function is not used\n    for the moment but voicing could be added to the articulatory representation\n    :param wav: wav file\n    :param sr:  sampling rate\n    :return:  an estimation of the voicing for each point in the wav\n    \"\"\"", "\n", "hop_time", "=", "10", "/", "1000", "# en ms", "\n", "hop_length", "=", "int", "(", "(", "hop_time", "*", "sr", ")", ")", "\n", "N_frames", "=", "int", "(", "len", "(", "wav", ")", "/", "hop_length", ")", "\n", "window", "=", "scipy", ".", "signal", ".", "get_window", "(", "\"hanning\"", ",", "N_frames", ")", "\n", "ste", "=", "scipy", ".", "signal", ".", "convolve", "(", "wav", "**", "2", ",", "window", "**", "2", ",", "mode", "=", "\"same\"", ")", "\n", "ste", "=", "[", "np", ".", "max", "(", "min", "(", "x", ",", "1", ")", ",", "0", ")", "for", "x", "in", "ste", "]", "\n", "return", "ste", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.low_pass_filter_weight": [[148, 169], ["int", "numpy.arange", "numpy.sinc", "Exception", "numpy.ceil", "numpy.sum", "numpy.cos"], "function", ["None"], ["", "def", "low_pass_filter_weight", "(", "cut_off", ",", "sampling_rate", ")", ":", "\n", "    ", "\"\"\"\n    :param cut_off:  cutoff of the filter\n    :param sampling_rate:  sampling rate of the data \n    :return: the weights of the lowpass filter\n    implementation of the weights of a low pass filter windowed with a hanning winow.\n    The filter is normalized (gain 1)\n    \"\"\"", "\n", "fc", "=", "cut_off", "/", "sampling_rate", "# Cutoff frequency as a fraction of the sampling rate (in (0, 0.5)).", "\n", "if", "fc", ">", "0.5", ":", "\n", "        ", "raise", "Exception", "(", "\"La frequence de coupure doit etre au moins deux fois la frequence dechantillonnage\"", ")", "\n", "", "b", "=", "0.08", "# Transition band, as a fraction of the sampling rate (in (0, 0.5)).", "\n", "N", "=", "int", "(", "np", ".", "ceil", "(", "(", "4", "/", "b", ")", ")", ")", "# window", "\n", "if", "not", "N", "%", "2", ":", "\n", "        ", "N", "+=", "1", "# Make sure that N is odd.", "\n", "", "n", "=", "np", ".", "arange", "(", "N", ")", "\n", "h", "=", "np", ".", "sinc", "(", "2", "*", "fc", "*", "(", "n", "-", "(", "N", "-", "1", ")", "/", "2", ")", ")", "# Compute sinc filter.", "\n", "w", "=", "0.5", "*", "(", "1", "-", "np", ".", "cos", "(", "2", "*", "np", ".", "pi", "*", "n", "/", "(", "N", "-", "1", ")", ")", ")", "# Compute hanning window.", "\n", "h", "=", "h", "*", "w", "# Multiply sinc filter with window.", "\n", "h", "=", "h", "/", "np", ".", "sum", "(", "h", ")", "\n", "return", "h", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.split_sentences": [[171, 211], ["os.path.join", "os.path.join", "os.listdir", "os.listdir", "len", "os.path.join", "os.path.join", "numpy.load", "numpy.load", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "int", "int", "range", "numpy.save", "numpy.save", "os.remove", "os.remove", "os.remove", "os.remove", "numpy.save", "numpy.save", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "len", "len", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "str", "str", "str", "str"], "function", ["None"], ["", "def", "split_sentences", "(", "speaker", ",", "max_length", "=", "300", ")", ":", "\n", "    ", "\"\"\"\n    :param speaker:\n    :param max_length: max points we want in sentences features (duration = max_lenghts*100sec)\n    :return: rien.\n    run through all the treated acou and arti features, if lenght > max lenght divide in K slices so that each one has\n    less than max_lenght points.\n    Warning : when split the original file is removed\n              ema files are split only in ema_final (those used for the training)\n    \"\"\"", "\n", "Preprocessed_data_path", "=", "os", ".", "path", ".", "join", "(", "root_folder", ",", "\"Preprocessed_data\"", ")", "\n", "file_names", "=", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"ema_final\"", ")", ")", "\n", "file_names", "=", "[", "f", "for", "f", "in", "file_names", "if", "'split'", "not", "in", "f", "]", "\n", "\n", "N", "=", "len", "(", "file_names", ")", "\n", "file_names", "=", "file_names", "[", "0", ":", "N", "]", "\n", "Number_cut", "=", "0", "\n", "for", "f", "in", "file_names", ":", "\n", "        ", "mfcc", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"mfcc\"", ",", "f", ")", ")", "\n", "ema_VT", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"ema_final\"", ",", "f", ")", ")", "\n", "cut_in_N", "=", "int", "(", "len", "(", "mfcc", ")", "/", "max_length", ")", "+", "1", "\n", "if", "cut_in_N", ">", "1", ":", "\n", "            ", "Number_cut", "+=", "1", "\n", "temp", "=", "0", "\n", "cut_size", "=", "int", "(", "len", "(", "mfcc", ")", "/", "cut_in_N", ")", "\n", "for", "k", "in", "range", "(", "cut_in_N", "-", "1", ")", ":", "\n", "                ", "mfcc_k", "=", "mfcc", "[", "temp", ":", "temp", "+", "cut_size", "]", "\n", "ema_k_vt", "=", "ema_VT", "[", "temp", ":", "temp", "+", "cut_size", ",", ":", "]", "\n", "\n", "temp", "=", "temp", "+", "cut_size", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"mfcc\"", ",", "f", "[", ":", "-", "4", "]", "+", "\"_split_\"", "+", "str", "(", "k", ")", ")", ",", "mfcc_k", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"ema_final\"", ",", "f", "[", ":", "-", "4", "]", "+", "\"_split_\"", "+", "str", "(", "k", ")", ")", ",", "ema_k_vt", ")", "\n", "\n", "", "mfcc_last", "=", "mfcc", "[", "temp", ":", "]", "\n", "ema_last_vt", "=", "ema_VT", "[", "temp", ":", ",", ":", "]", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"mfcc\"", ",", "f", "[", ":", "-", "4", "]", "+", "\"_split_\"", "+", "str", "(", "cut_in_N", "-", "1", ")", ")", ",", "mfcc_last", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"ema_final\"", ",", "f", "[", ":", "-", "4", "]", "+", "\"_split_\"", "+", "str", "(", "cut_in_N", "-", "1", ")", ")", ",", "ema_last_vt", ")", "\n", "\n", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"mfcc\"", ",", "f", ")", ")", "\n", "os", ".", "remove", "(", "os", ".", "path", ".", "join", "(", "Preprocessed_data_path", ",", "speaker", ",", "\"ema_final\"", ",", "f", ")", ")", "\n", "", "", "", ""]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.__init__": [[38, 52], ["Preprocessing.class_corpus.Speaker.__init__", "os.path.join", "os.path.join", "os.path.join", "sorted", "os.listdir", "name.endswith", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.__init__"], ["def", "__init__", "(", "self", ",", "sp", ",", "path_to_raw", ",", "N_max", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        :param sp:  name of the speaker\n        :param N_max:  # max of files we want to preprocess (0 is for All files), variable useful for test\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "sp", ")", "# gets the attributes of the Speaker class", "\n", "self", ".", "root_path", "=", "path_to_raw", "\n", "self", ".", "N_max", "=", "N_max", "\n", "self", ".", "path_files_treated", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ")", "\n", "self", ".", "path_files_brutes", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ")", "\n", "self", ".", "path_files_annotation", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ",", "\"trans\"", ")", "\n", "self", ".", "EMA_files", "=", "sorted", "(", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "os", ".", "listdir", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat\"", ")", ")", "if", "name", ".", "endswith", "(", "\".mat\"", ")", "]", ")", "\n", "self", ".", "EMA_files_2", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.create_missing_dir": [[53, 76], ["glob.glob", "glob.glob", "glob.glob", "glob.glob", "glob.glob", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.remove", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "create_missing_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        delete all previous preprocessing, create needed directories\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat_cut\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat_cut\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ")", ")", "\n", "\n", "", "files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat_cut\"", ",", "\"*\"", ")", ")", "\n", "\n", "for", "f", "in", "files", ":", "\n", "            ", "os", ".", "remove", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.get_data_per_sentence": [[77, 148], ["len", "range", "max", "os.path.join", "librosa.load", "scipy.loadmat", "scipy.loadmat", "scipy.loadmat", "scipy.loadmat", "scipy.loadmat", "numpy.concatenate", "min", "numpy.max", "os.path.join", "open", "numpy.array", "set", "sorted.remove", "sorted", "int", "os.path.join", "os.path.exists", "numpy.save", "librosa.output.write_wav", "range", "row.strip().split", "int", "max", "int", "int", "int", "int", "os.path.join", "numpy.load", "numpy.concatenate", "librosa.load", "numpy.concatenate", "os.path.join", "os.path.join", "float", "numpy.floor", "min", "int", "min", "os.path.join", "os.path.join", "row.strip", "str", "float", "len", "numpy.floor", "int", "len", "str", "numpy.floor", "str", "str", "numpy.floor", "str", "str"], "methods", ["None"], ["", "", "def", "get_data_per_sentence", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Initially 1 file for several sentences pronounced successively (with silence between them).\n        The scripts reads the transcription file and generates new files to have 1 EMA and 1 WAV per sentence.\n\n        For the sentence with id 7 the names of the files will be \"usctimit_ema_sp_7\". Sometimes one sentence is\n        pronounced over 2 files. If we want to save a file with a name already in our directory it means that we are\n        in that case. So we just concatenate the 2 ema and the 2 MFCC files.\n\n        After this function in ema_cut and in wav_cut we have 1 file per sentence, just as in other corpus\n\n        \"\"\"", "\n", "N", "=", "len", "(", "self", ".", "EMA_files", ")", "\n", "if", "self", ".", "N_max", "!=", "0", ":", "\n", "            ", "N", "=", "max", "(", "min", "(", "int", "(", "self", ".", "N_max", "/", "3", ")", ",", "N", ")", ",", "1", ")", "# 1 file contains several sentences", "\n", "", "marge", "=", "0", "\n", "for", "j", "in", "range", "(", "N", ")", ":", "# run through the files", "\n", "            ", "path_wav", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav\"", ",", "self", ".", "EMA_files", "[", "j", "]", "+", "'.wav'", ")", "\n", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "path_wav", ",", "sr", "=", "self", ".", "sampling_rate_wav_wanted", ")", "# 1 wav containing several sentences", "\n", "wav", "=", "0.5", "*", "wav", "/", "np", ".", "max", "(", "wav", ")", "\n", "\n", "ema", "=", "sio", ".", "loadmat", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat\"", ",", "\n", "self", ".", "EMA_files", "[", "j", "]", "+", "\".mat\"", ")", ")", "# 1 ema containing several sentnces", "\n", "\n", "# two lines of code to obtain the ema traj as a np array", "\n", "ema", "=", "ema", "[", "self", ".", "EMA_files", "[", "j", "]", "]", "[", "0", "]", "\n", "ema", "=", "np", ".", "concatenate", "(", "[", "ema", "[", "arti", "]", "[", "2", "]", "[", ":", ",", "[", "0", ",", "1", "]", "]", "for", "arti", "in", "range", "(", "1", ",", "7", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "with", "open", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_annotation", ",", "self", ".", "EMA_files", "[", "j", "]", "+", "\".trans\"", ")", ")", "as", "file", ":", "\n", "                ", "labels", "=", "np", ".", "array", "(", "[", "row", ".", "strip", "(", "\"\\n\"", ")", ".", "split", "(", "\",\"", ")", "for", "row", "in", "file", "]", ")", "\n", "phone_details", "=", "labels", "[", ":", ",", "[", "0", ",", "1", ",", "-", "1", "]", "]", "# all the info about bebginning/end of sentences if here", "\n", "\n", "# 3 lines of code to get the id of the sentences of this file", "\n", "id_sentence", "=", "set", "(", "phone_details", "[", ":", ",", "2", "]", ")", "\n", "id_sentence", ".", "remove", "(", "\"\"", ")", "\n", "id_sentence", "=", "sorted", "(", "[", "int", "(", "id", ")", "for", "id", "in", "id_sentence", "]", ")", "\n", "\n", "for", "k", "in", "id_sentence", ":", "\n", "                    ", "temp", "=", "phone_details", "[", "phone_details", "[", ":", ",", "2", "]", "==", "str", "(", "k", ")", "]", "# we focus on one sentence", "\n", "xtrm", "=", "[", "max", "(", "float", "(", "temp", "[", ":", ",", "0", "]", "[", "0", "]", ")", "-", "marge", ",", "0", ")", ",", "\n", "float", "(", "temp", "[", ":", ",", "1", "]", "[", "-", "1", "]", ")", "+", "marge", "]", "# beginning and end of the sentences in second", "\n", "\n", "xtrm_temp_ema", "=", "[", "int", "(", "np", ".", "floor", "(", "xtrm", "[", "0", "]", "*", "self", ".", "sampling_rate_ema", ")", ")", ",", "int", "(", "\n", "min", "(", "np", ".", "floor", "(", "xtrm", "[", "1", "]", "*", "self", ".", "sampling_rate_ema", ")", "+", "1", ",", "len", "(", "ema", ")", ")", ")", "]", "\n", "xtrm_temp_wav", "=", "[", "int", "(", "int", "(", "np", ".", "floor", "(", "xtrm", "[", "0", "]", "*", "self", ".", "sampling_rate_wav_wanted", ")", ")", ")", ",", "\n", "int", "(", "min", "(", "int", "(", "np", ".", "floor", "(", "xtrm", "[", "1", "]", "*", "self", ".", "sampling_rate_wav_wanted", ")", "+", "1", ")", ",", "len", "(", "wav", ")", ")", ")", "]", "\n", "\n", "ema_temp", "=", "ema", "[", "xtrm_temp_ema", "[", "0", "]", ":", "xtrm_temp_ema", "[", "1", "]", ",", ":", "]", "\n", "wav_temp", "=", "wav", "[", "xtrm_temp_wav", "[", "0", "]", ":", "xtrm_temp_wav", "[", "1", "]", "]", "\n", "\n", "# if we already have a file for id k it means that the sentence was pronounced over the 2 files", "\n", "# we have to concatenante the previous and current data.", "\n", "if", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat_cut\"", ",", "\n", "self", ".", "EMA_files", "[", "j", "]", "[", ":", "-", "7", "]", "+", "str", "(", "k", ")", "+", "\".npy\"", ")", ")", ":", "\n", "\n", "                        ", "premiere_partie_ema", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat_cut\"", ",", "\n", "self", ".", "EMA_files", "[", "j", "]", "[", ":", "-", "7", "]", "+", "str", "(", "k", ")", "+", "\".npy\"", ")", ")", "\n", "\n", "ema_temp", "=", "np", ".", "concatenate", "(", "(", "ema_temp", ",", "premiere_partie_ema", ")", ",", "axis", "=", "0", ")", "# Final ema for id k", "\n", "\n", "premiere_partie_wav", ",", "sr", "=", "librosa", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ",", "\n", "self", ".", "EMA_files", "[", "j", "]", "[", ":", "-", "7", "]", "+", "str", "(", "k", ")", "+", "\".wav\"", ")", ",", "\n", "sr", "=", "self", ".", "sampling_rate_wav_wanted", ")", "\n", "wav_temp", "=", "np", ".", "concatenate", "(", "(", "wav_temp", ",", "premiere_partie_wav", ")", ",", "axis", "=", "0", ")", "# Final wav for id k", "\n", "\n", "", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat_cut\"", ",", "self", ".", "EMA_files", "[", "j", "]", "[", ":", "-", "7", "]", "+", "str", "(", "k", ")", ")", ",", "\n", "ema_temp", ")", "\n", "\n", "librosa", ".", "output", ".", "write_wav", "(", "\n", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ",", "self", ".", "EMA_files", "[", "j", "]", "[", ":", "-", "7", "]", "+", "str", "(", "k", ")", "+", "\".wav\"", ")", ",", "\n", "wav_temp", ",", "self", ".", "sampling_rate_wav_wanted", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.read_ema_file": [[149, 174], ["numpy.load", "articulators.index", "os.path.join", "numpy.isnan().sum", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "numpy.argwhere().ravel", "numpy.argwhere", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "numpy.isnan", "numpy.argwhere", "numpy.isnan().ravel", "numpy.isnan", "numpy.isnan", "numpy.isnan"], "methods", ["None"], ["", "", "", "", "def", "read_ema_file", "(", "self", ",", "m", ")", ":", "\n", "        ", "\"\"\"\n        read the ema file, first preprocessing,\n        :param m: utterance index (wrt the list \"EMA_files\")\n        :return: npy array (K,12) , K depends on the duration of the recording, 12 trajectories\n        \"\"\"", "\n", "\n", "articulators", "=", "[", "\"ul_x\"", ",", "\"ul_y\"", ",", "\"ll_x\"", ",", "\"ll_y\"", ",", "\"li_x\"", ",", "\"li_y\"", ",", "\"td_x\"", ",", "\"td_y\"", ",", "\"tb_x\"", ",", "\"tb_y\"", ",", "\"tt_x\"", ",", "\n", "\"tt_y\"", "]", "\n", "\n", "order_arti_usctimit", "=", "[", "\n", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", ",", "\n", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", "]", "\n", "\n", "new_order_arti", "=", "[", "articulators", ".", "index", "(", "col", ")", "for", "col", "in", "order_arti_usctimit", "]", "# change the order from the initial", "\n", "\n", "ema", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat_cut\"", ",", "self", ".", "EMA_files_2", "[", "m", "]", "+", "\".npy\"", ")", ")", "\n", "\n", "if", "np", ".", "isnan", "(", "ema", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "#        print(np.isnan(ema).sum())", "\n", "            ", "spline", "=", "scipy", ".", "interpolate", ".", "splrep", "(", "np", ".", "argwhere", "(", "~", "np", ".", "isnan", "(", "ema", ")", ".", "ravel", "(", ")", ")", ",", "ema", "[", "~", "np", ".", "isnan", "(", "ema", ")", "]", ",", "k", "=", "3", ")", "\n", "for", "j", "in", "np", ".", "argwhere", "(", "np", ".", "isnan", "(", "ema", ")", ")", ".", "ravel", "(", ")", ":", "\n", "                ", "ema", "[", "j", "]", "=", "scipy", ".", "interpolate", ".", "splev", "(", "j", ",", "spline", ")", "\n", "", "", "ema", "=", "ema", "[", ":", ",", "new_order_arti", "]", "# change order of arti to have the one wanted", "\n", "return", "ema", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.from_wav_to_mfcc": [[175, 195], ["os.path.join", "librosa.load", "Preprocessing.tools_preprocessing.get_delta_features", "Preprocessing.tools_preprocessing.get_delta_features", "numpy.concatenate", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "librosa.feature.mfcc", "range", "len"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features"], ["", "def", "from_wav_to_mfcc", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n          :param k: index of the sentence (wrt the list 'EMA_files'\n          :return: the acoustic features( K,429); where K in the # of frames.\n          calculations of the mfcc with librosa , + Delta and DeltaDelta, + 10 context frames\n          # of acoustic features per frame: 13 ==> 13*3 = 39 ==> 39*11 = 429.\n          parameters for mfcc calculation are defined in class_corpus\n          \"\"\"", "\n", "path_wav", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ",", "self", ".", "EMA_files_2", "[", "k", "]", "+", "'.wav'", ")", "\n", "data", ",", "sr", "=", "librosa", ".", "load", "(", "path_wav", ",", "sr", "=", "self", ".", "sampling_rate_wav_wanted", ")", "# chargement de donn\u00e9es", "\n", "mfcc", "=", "librosa", ".", "feature", ".", "mfcc", "(", "y", "=", "data", ",", "sr", "=", "self", ".", "sampling_rate_wav_wanted", ",", "n_mfcc", "=", "self", ".", "n_coeff", ",", "\n", "n_fft", "=", "self", ".", "frame_length", ",", "hop_length", "=", "self", ".", "hop_length", ")", ".", "T", "\n", "dyna_features", "=", "get_delta_features", "(", "mfcc", ")", "\n", "dyna_features_2", "=", "get_delta_features", "(", "dyna_features", ")", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "(", "mfcc", ",", "dyna_features", ",", "dyna_features_2", ")", ",", "axis", "=", "1", ")", "\n", "padding", "=", "np", ".", "zeros", "(", "(", "self", ".", "window", ",", "mfcc", ".", "shape", "[", "1", "]", ")", ")", "\n", "frames", "=", "np", ".", "concatenate", "(", "[", "padding", ",", "mfcc", ",", "padding", "]", ")", "\n", "full_window", "=", "1", "+", "2", "*", "self", ".", "window", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "[", "frames", "[", "j", ":", "j", "+", "len", "(", "mfcc", ")", "]", "for", "j", "in", "range", "(", "full_window", ")", "]", ",", "axis", "=", "1", ")", "\n", "return", "mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.remove_silences": [[196, 216], ["int", "int", "numpy.floor", "numpy.floor", "len", "len"], "methods", ["None"], ["", "def", "remove_silences", "(", "self", ",", "k", ",", "ema", ",", "mfcc", ")", ":", "\n", "        ", "\"\"\"\n       :param k:  utterance index (wrt the list EMA_files)\n       :param ema: the ema list of traj\n       :param mfcc: the mfcc features\n       :return: the data (ema and mfcc) without the silence at the beginning and end of the recording\n\n       \"\"\"", "\n", "\n", "marge", "=", "0", "\n", "n_points_de_silences_ema", "=", "int", "(", "np", ".", "floor", "(", "marge", "*", "self", ".", "sampling_rate_ema", ")", ")", "\n", "xtrm_temp_ema", "=", "[", "n_points_de_silences_ema", ",", "len", "(", "ema", ")", "-", "n_points_de_silences_ema", "]", "\n", "\n", "n_frames_de_silences_mfcc", "=", "int", "(", "np", ".", "floor", "(", "marge", "/", "self", ".", "hop_time", ")", ")", "\n", "xtrm_temp_mfcc", "=", "[", "n_frames_de_silences_mfcc", ",", "len", "(", "mfcc", ")", "-", "n_frames_de_silences_mfcc", "]", "\n", "#   print(\"avant \",mfcc.shape)", "\n", "mfcc", "=", "mfcc", "[", "xtrm_temp_mfcc", "[", "0", "]", ":", "xtrm_temp_mfcc", "[", "1", "]", "]", "\n", "ema", "=", "ema", "[", "xtrm_temp_ema", "[", "0", "]", ":", "xtrm_temp_ema", "[", "1", "]", ",", ":", "]", "\n", "# print(\"apres\",mfcc.shape)", "\n", "return", "ema", ",", "mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.Preprocessing_general_speaker": [[217, 274], ["preprocessing_usc_timit.Speaker_usc.create_missing_dir", "sorted", "len", "preprocessing_usc_timit.Speaker_usc.get_data_per_sentence", "sorted", "len", "range", "preprocessing_usc_timit.Speaker_usc.calculate_norm_values", "range", "Preprocessing.tools_preprocessing.get_fileset_names", "min", "min", "preprocessing_usc_timit.Speaker_usc.read_ema_file", "preprocessing_usc_timit.Speaker_usc.add_vocal_tract", "preprocessing_usc_timit.Speaker_usc.smooth_data", "preprocessing_usc_timit.Speaker_usc.from_wav_to_mfcc", "preprocessing_usc_timit.Speaker_usc.remove_silences", "preprocessing_usc_timit.Speaker_usc.synchro_ema_mfcc", "numpy.save", "numpy.save", "numpy.save", "preprocessing_usc_timit.Speaker_usc.list_EMA_traj.append", "preprocessing_usc_timit.Speaker_usc.list_MFCC_frames.append", "numpy.load", "numpy.load", "preprocessing_usc_timit.Speaker_usc.normalize_sentence", "preprocessing_usc_timit.Speaker_usc.smooth_data", "numpy.save", "numpy.save", "int", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.listdir", "name.endswith", "os.listdir", "name.endswith", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.create_missing_dir", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Speaker_usc.get_data_per_sentence", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.calculate_norm_values", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_fileset_names", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.read_ema_file", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.add_vocal_tract", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.from_wav_to_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.remove_silences", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.synchro_ema_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.normalize_sentence", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data"], ["", "def", "Preprocessing_general_speaker", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Go through the sentences one by one.\n            - reads ema data and turn it to a (K,18) array where arti are in a precise order, interploate missing values,\n        smooth the trajectories, remove silences at the beginning and the end, undersample to have 1 position per\n        frame mfcc, add it to the list of EMA traj for this speaker\n            - reads the wav file, calculate the associated acoustic features (mfcc+delta+ deltadelta+contextframes) ,\n        add it to the list of the MFCC FEATURES for this speaker.\n        Then calculate the normvalues based on the list of ema/mfcc data for this speaker\n        Finally : normalization and last smoothing of the trajectories.\n        Final data are in Preprocessed_data/speaker/ema_final.npy and  mfcc.npy\n        \"\"\"", "\n", "\n", "self", ".", "create_missing_dir", "(", ")", "\n", "EMA_files", "=", "sorted", "(", "\n", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"mat\"", ")", ")", "if", "name", ".", "endswith", "(", "\".mat\"", ")", "]", ")", "\n", "\n", "N", "=", "len", "(", "EMA_files", ")", "\n", "if", "self", ".", "N_max", "!=", "0", ":", "\n", "            ", "N", "=", "min", "(", "int", "(", "self", ".", "N_max", "/", "3", ")", ",", "N", ")", "# majoration:if we want to preprocess N_max sentences, about N_max/6 files", "\n", "\n", "", "self", ".", "get_data_per_sentence", "(", ")", "# one file contains several sentences, this create one file per sentence", "\n", "self", ".", "EMA_files_2", "=", "sorted", "(", "\n", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "os", ".", "listdir", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ")", ")", "if", "name", ".", "endswith", "(", "\".wav\"", ")", "]", ")", "\n", "N_2", "=", "len", "(", "self", ".", "EMA_files_2", ")", "\n", "if", "self", ".", "N_max", "!=", "0", ":", "\n", "            ", "N_2", "=", "min", "(", "self", ".", "N_max", ",", "N_2", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "N_2", ")", ":", "\n", "            ", "ema", "=", "self", ".", "read_ema_file", "(", "i", ")", "\n", "ema_VT", "=", "self", ".", "add_vocal_tract", "(", "ema", ")", "\n", "ema_VT_smooth", "=", "self", ".", "smooth_data", "(", "ema_VT", ")", "# smooth for better calculation of norm values", "\n", "mfcc", "=", "self", ".", "from_wav_to_mfcc", "(", "i", ")", "\n", "ema_VT_smooth", ",", "mfcc", "=", "self", ".", "remove_silences", "(", "i", ",", "ema_VT_smooth", ",", "mfcc", ")", "\n", "ema_VT_smooth", ",", "mfcc", "=", "self", ".", "synchro_ema_mfcc", "(", "ema_VT_smooth", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema\"", ",", "self", ".", "EMA_files_2", "[", "i", "]", ")", ",", "ema_VT", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files_2", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "\n", "self", ".", "EMA_files_2", "[", "i", "]", ")", ",", "ema_VT_smooth", ")", "\n", "self", ".", "list_EMA_traj", ".", "append", "(", "ema_VT_smooth", ")", "\n", "self", ".", "list_MFCC_frames", ".", "append", "(", "mfcc", ")", "\n", "", "self", ".", "calculate_norm_values", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "N_2", ")", ":", "\n", "            ", "ema_VT_smooth", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files_2", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "mfcc", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "\n", "self", ".", "EMA_files_2", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "ema_VT_smooth_norma", ",", "mfcc", "=", "self", ".", "normalize_sentence", "(", "i", ",", "ema_VT_smooth", ",", "mfcc", ")", "\n", "new_sr", "=", "1", "/", "self", ".", "hop_time", "\n", "ema_VT_smooth_norma", "=", "self", ".", "smooth_data", "(", "ema_VT_smooth_norma", ",", "new_sr", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files_2", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files_2", "[", "i", "]", ")", ",", "\n", "ema_VT_smooth_norma", ")", "\n", "\n", "#  split_sentences(self.speaker)", "\n", "", "get_fileset_names", "(", "self", ".", "speaker", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_usc_timit.Preprocessing_general_usc": [[276, 288], ["Preprocessing.tools_preprocessing.get_speakers_per_corpus", "print", "preprocessing_usc_timit.Speaker_usc", "preprocessing_usc_timit.Speaker_usc.Preprocessing_general_speaker", "print"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_speakers_per_corpus", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.Preprocessing_general_speaker"], ["", "", "def", "Preprocessing_general_usc", "(", "N_max", ",", "path_to_raw", ")", ":", "\n", "    ", "\"\"\"\n    :param N_max: #max of files to treat (0 to treat all files), useful for test\n    go through all the speakers of Haskins\n    \"\"\"", "\n", "corpus", "=", "'usc'", "\n", "speakers_usc", "=", "get_speakers_per_corpus", "(", "corpus", ")", "\n", "for", "sp", "in", "speakers_usc", ":", "\n", "        ", "print", "(", "\"In progress usc \"", ",", "sp", ")", "\n", "speaker", "=", "Speaker_usc", "(", "sp", ",", "path_to_raw", "=", "path_to_raw", ",", "N_max", "=", "N_max", ")", "\n", "speaker", ".", "Preprocessing_general_speaker", "(", ")", "\n", "print", "(", "\"Done usc \"", ",", "sp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.__init__": [[37, 53], ["Preprocessing.class_corpus.Speaker.__init__", "os.path.join", "os.path.join", "sorted", "sorted", "sorted", "os.listdir", "name.endswith", "os.listdir", "name.endswith"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.__init__"], ["def", "__init__", "(", "self", ",", "sp", ",", "path_to_raw", ",", "N_max", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        :param sp:  name of the speaker\n        :param N_max:  # max of files we want to preprocess (0 is for All files), variable useful for test\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "sp", ")", "# gets the attributes of the Speaker class", "\n", "self", ".", "root_path", "=", "path_to_raw", "\n", "self", ".", "N_max", "=", "N_max", "\n", "self", ".", "path_files_treated", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ")", "\n", "self", ".", "path_files_brutes", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "\"mocha\"", ",", "self", ".", "speaker", ")", "\n", "\n", "self", ".", "EMA_files", "=", "sorted", "(", "[", "name", "for", "name", "in", "os", ".", "listdir", "(", "self", ".", "path_files_brutes", ")", "if", "\"palate\"", "not", "in", "name", "]", ")", "\n", "self", ".", "EMA_files", "=", "sorted", "(", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "self", ".", "EMA_files", "if", "name", ".", "endswith", "(", "'.ema'", ")", "]", ")", "\n", "self", ".", "n_columns", "=", "20", "\n", "self", ".", "wav_files", "=", "sorted", "(", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "os", ".", "listdir", "(", "self", ".", "path_files_brutes", ")", "if", "name", ".", "endswith", "(", "'.wav'", ")", "]", ")", "\n", "self", ".", "sp_with_trans", "=", "[", "\"fsew0\"", ",", "\"msak0\"", ",", "\"mjjn0\"", ",", "\"ffes0\"", "]", "#speakers for which we have transcription ( ie we can remove silence)", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.create_missing_dir": [[55, 75], ["glob.glob", "glob.glob", "glob.glob", "glob.glob", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.remove", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "create_missing_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        delete all previous preprocessing, create needed directories\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", "\n", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ")", ")", "\n", "", "files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "\"wav_cut\"", ",", "\"*\"", ")", ")", "\n", "\n", "for", "f", "in", "files", ":", "\n", "            ", "os", ".", "remove", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.read_ema_file": [[76, 109], ["os.path.join", "open", "numpy.fromfile().reshape", "line.decode().strip.decode().strip.decode().strip", "column_names.index", "numpy.isnan().sum", "print", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "scipy.interpolate.splrep", "numpy.argwhere().ravel", "line.decode().strip.decode().strip.startswith", "numpy.fromfile", "numpy.isnan().sum", "numpy.argwhere", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "scipy.interpolate.splev", "line.decode().strip.decode().strip.decode", "int", "line.decode().strip.decode().strip.startswith", "numpy.isnan", "numpy.argwhere", "line.decode().strip.decode().strip.split", "col_name.replace", "numpy.isnan", "numpy.isnan().ravel", "numpy.isnan", "line.decode().strip.decode().strip.rsplit", "numpy.isnan", "int", "numpy.isnan", "col_id.split"], "methods", ["None"], ["", "", "def", "read_ema_file", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        read the ema file, first preprocessing,\n        :param k: utterance index (wrt the list \"EMA_files\")\n        :return: npy array (K,12 or 14) , K depends on the duration of the recording, 12 trajectories (or 14 when\n        the velum is provided , ie for 4 speakers)\n        \"\"\"", "\n", "path_ema_file", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "self", ".", "EMA_files", "[", "k", "]", "+", "\".ema\"", ")", "\n", "with", "open", "(", "path_ema_file", ",", "'rb'", ")", "as", "ema_annotation", ":", "\n", "            ", "column_names", "=", "[", "0", "]", "*", "self", ".", "n_columns", "\n", "for", "line", "in", "ema_annotation", ":", "\n", "                ", "line", "=", "line", ".", "decode", "(", "'latin-1'", ")", ".", "strip", "(", "\"\\n\"", ")", "\n", "if", "line", "==", "'EST_Header_End'", ":", "\n", "                    ", "break", "\n", "", "elif", "line", ".", "startswith", "(", "'NumFrames'", ")", ":", "\n", "                    ", "n_frames", "=", "int", "(", "line", ".", "rsplit", "(", "' '", ",", "1", ")", "[", "-", "1", "]", ")", "\n", "", "elif", "line", ".", "startswith", "(", "'Channel_'", ")", ":", "\n", "                    ", "col_id", ",", "col_name", "=", "line", ".", "split", "(", "' '", ",", "1", ")", "\n", "column_names", "[", "int", "(", "col_id", ".", "split", "(", "'_'", ",", "1", ")", "[", "-", "1", "]", ")", "]", "=", "col_name", ".", "replace", "(", "\" \"", ",", "\n", "\"\"", ")", "# v_x has sometimes a space", "\n", "", "", "ema_data", "=", "np", ".", "fromfile", "(", "ema_annotation", ",", "\"float32\"", ")", ".", "reshape", "(", "n_frames", ",", "-", "1", ")", "\n", "cols_index", "=", "[", "column_names", ".", "index", "(", "col", ")", "for", "col", "in", "self", ".", "articulators", "]", "\n", "ema_data", "=", "ema_data", "[", ":", ",", "cols_index", "]", "\n", "ema_data", "=", "ema_data", "/", "100", "# met en mm, initallement en 10^-1m", "\n", "if", "np", ".", "isnan", "(", "ema_data", ")", ".", "sum", "(", ")", "!=", "0", ":", "\n", "                ", "print", "(", "\"nombre de nan \"", ",", "np", ".", "isnan", "(", "ema_data", ")", ".", "sum", "(", ")", ")", "\n", "# Build a cubic spline out of non-NaN values.", "\n", "spline", "=", "scipy", ".", "interpolate", ".", "splrep", "(", "np", ".", "argwhere", "(", "~", "np", ".", "isnan", "(", "ema_data", ")", ".", "ravel", "(", ")", ")", ",", "\n", "ema_data", "[", "~", "np", ".", "isnan", "(", "ema_data", ")", "]", ",", "k", "=", "3", ")", "\n", "# Interpolate missing values and replace them.", "\n", "for", "j", "in", "np", ".", "argwhere", "(", "np", ".", "isnan", "(", "ema_data", ")", ")", ".", "ravel", "(", ")", ":", "\n", "                    ", "ema_data", "[", "j", "]", "=", "scipy", ".", "interpolate", ".", "splev", "(", "j", ",", "spline", ")", "\n", "", "", "return", "ema_data", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.remove_silences": [[110, 139], ["os.path.join", "open", "max", "int", "min", "int", "int", "row.strip().strip().replace().split", "float", "int", "len", "numpy.ceil", "float", "row.strip().strip().replace", "row.strip().strip", "row.strip"], "methods", ["None"], ["", "", "def", "remove_silences", "(", "self", ",", "ema", ",", "mfcc", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n          :param k:  utterance index (wrt the list EMA_files)\n          :param ema: the ema list of traj\n          :param mfcc: the mfcc features\n          :return: the data (ema and mfcc) without the silence at the beginning and end of the recording\n         For some speakers we have annotation that gives in second when the voice starts and ends.\n         For those speakers : get those extremity , calculates the equivalence in # of ema points and # of mfcc frames\n          \"\"\"", "\n", "marge", "=", "0", "\n", "if", "self", ".", "speaker", "in", "self", ".", "sp_with_trans", ":", "\n", "            ", "path_annotation", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "self", ".", "wav_files", "[", "k", "]", "+", "'.lab'", ")", "\n", "with", "open", "(", "path_annotation", ")", "as", "file", ":", "\n", "                ", "labels", "=", "[", "\n", "row", ".", "strip", "(", "'\\n'", ")", ".", "strip", "(", "'\\t'", ")", ".", "replace", "(", "' 26 '", ",", "''", ")", ".", "split", "(", "' '", ")", "\n", "for", "row", "in", "file", "\n", "]", "\n", "", "xtrm", "=", "[", "max", "(", "float", "(", "labels", "[", "0", "]", "[", "1", "]", ")", "-", "marge", ",", "0", ")", ",", "float", "(", "labels", "[", "-", "1", "]", "[", "0", "]", ")", "+", "marge", "]", "\n", "xtrm_temp_ema", "=", "[", "int", "(", "xtrm", "[", "0", "]", "*", "self", ".", "sampling_rate_ema", ")", ",", "\n", "min", "(", "int", "(", "(", "xtrm", "[", "1", "]", "*", "self", ".", "sampling_rate_ema", ")", "+", "1", ")", ",", "len", "(", "ema", ")", ")", "]", "\n", "\n", "xtrm_temp_mfcc", "=", "[", "int", "(", "xtrm", "[", "0", "]", "/", "self", ".", "hop_time", ")", ",", "\n", "int", "(", "np", ".", "ceil", "(", "xtrm", "[", "1", "]", "/", "self", ".", "hop_time", ")", ")", "]", "\n", "\n", "mfcc", "=", "mfcc", "[", "xtrm_temp_mfcc", "[", "0", "]", ":", "xtrm_temp_mfcc", "[", "1", "]", "]", "\n", "\n", "ema", "=", "ema", "[", "xtrm_temp_ema", "[", "0", "]", ":", "xtrm_temp_ema", "[", "1", "]", ",", ":", "]", "\n", "\n", "", "return", "ema", ",", "mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.from_wav_to_mfcc": [[140, 159], ["Preprocessing.tools_preprocessing.get_delta_features", "Preprocessing.tools_preprocessing.get_delta_features", "numpy.concatenate", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "librosa.feature.mfcc", "range", "len"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features"], ["", "def", "from_wav_to_mfcc", "(", "self", ",", "wav", ")", ":", "\n", "        ", "\"\"\"\n       :param wav: list of intensity points of the wav file\n       :return: the acoustic features( K,429); where K in the # of frames.\n       calculations of the mfcc with librosa , + Delta and DeltaDelta, + 10 context frames\n       # of acoustic features per frame: 13 ==> 13*3 = 39 ==> 39*11 = 429.\n       parameters for mfcc calculation are defined in class_corpus\n       \"\"\"", "\n", "mfcc", "=", "librosa", ".", "feature", ".", "mfcc", "(", "y", "=", "wav", ",", "sr", "=", "self", ".", "sampling_rate_wav", ",", "n_mfcc", "=", "self", ".", "n_coeff", ",", "\n", "n_fft", "=", "self", ".", "frame_length", ",", "hop_length", "=", "self", ".", "hop_length", "\n", ")", ".", "T", "\n", "dyna_features", "=", "get_delta_features", "(", "mfcc", ")", "\n", "dyna_features_2", "=", "get_delta_features", "(", "dyna_features", ")", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "(", "mfcc", ",", "dyna_features", ",", "dyna_features_2", ")", ",", "axis", "=", "1", ")", "\n", "padding", "=", "np", ".", "zeros", "(", "(", "self", ".", "window", ",", "mfcc", ".", "shape", "[", "1", "]", ")", ")", "\n", "frames", "=", "np", ".", "concatenate", "(", "[", "padding", ",", "mfcc", ",", "padding", "]", ")", "\n", "full_window", "=", "1", "+", "2", "*", "self", ".", "window", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "[", "frames", "[", "j", ":", "j", "+", "len", "(", "mfcc", ")", "]", "for", "j", "in", "range", "(", "full_window", ")", "]", ",", "axis", "=", "1", ")", "# add context", "\n", "return", "mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.Preprocessing_general_speaker": [[160, 218], ["preprocessing_mocha.Speaker_mocha.create_missing_dir", "len", "range", "preprocessing_mocha.Speaker_mocha.calculate_norm_values", "range", "Preprocessing.tools_preprocessing.get_fileset_names", "preprocessing_mocha.Speaker_mocha.read_ema_file", "preprocessing_mocha.Speaker_mocha.add_vocal_tract", "preprocessing_mocha.Speaker_mocha.smooth_data", "os.path.join", "librosa.load", "preprocessing_mocha.Speaker_mocha.from_wav_to_mfcc", "preprocessing_mocha.Speaker_mocha.remove_silences", "preprocessing_mocha.Speaker_mocha.synchro_ema_mfcc", "preprocessing_mocha.Speaker_mocha.remove_silences", "preprocessing_mocha.Speaker_mocha.synchro_ema_mfcc", "numpy.save", "numpy.save", "numpy.save", "preprocessing_mocha.Speaker_mocha.list_EMA_traj.append", "preprocessing_mocha.Speaker_mocha.list_MFCC_frames.append", "numpy.load", "numpy.load", "numpy.load", "preprocessing_mocha.Speaker_mocha.normalize_sentence", "preprocessing_mocha.Speaker_mocha.normalize_sentence", "preprocessing_mocha.Speaker_mocha.smooth_data", "numpy.save", "numpy.save", "numpy.save", "numpy.max", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.create_missing_dir", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.calculate_norm_values", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_fileset_names", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.read_ema_file", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.add_vocal_tract", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.from_wav_to_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.remove_silences", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.synchro_ema_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Speaker_mocha.remove_silences", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.synchro_ema_mfcc", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.normalize_sentence", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.normalize_sentence", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data"], ["", "def", "Preprocessing_general_speaker", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Go through the sentences one by one.\n            - reads ema data and turn it to a (K,18) array where arti are in a precise order, interploate missing values,\n        smooth the trajectories, remove silences at the beginning and the end, undersample to have 1 position per\n        frame mfcc, add it to the list of EMA traj for this speaker\n            - reads the wav file, calculate the associated acoustic features (mfcc+delta+ deltadelta+contextframes) ,\n        add it to the list of the MFCC FEATURES for this speaker.\n        Then calculate the normvalues based on the list of ema/mfcc data for this speaker\n        Finally : normalization and last smoothing of the trajectories.\n        Final data are in Preprocessed_data/speaker/ema_final.npy and  mfcc.npy\n        \"\"\"", "\n", "self", ".", "create_missing_dir", "(", ")", "\n", "\n", "N", "=", "len", "(", "self", ".", "EMA_files", ")", "\n", "if", "self", ".", "N_max", "!=", "0", ":", "\n", "            ", "N", "=", "self", ".", "N_max", "\n", "\n", "", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "ema", "=", "self", ".", "read_ema_file", "(", "i", ")", "\n", "ema_VT", "=", "self", ".", "add_vocal_tract", "(", "ema", ")", "\n", "ema_VT_smooth", "=", "self", ".", "smooth_data", "(", "ema_VT", ")", "# smooth for a better calculation of norm values", "\n", "path_wav", "=", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "self", ".", "wav_files", "[", "i", "]", "+", "'.wav'", ")", "\n", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "path_wav", ",", "sr", "=", "None", ")", "\n", "wav", "=", "0.5", "*", "wav", "/", "np", ".", "max", "(", "wav", ")", "\n", "mfcc", "=", "self", ".", "from_wav_to_mfcc", "(", "wav", ")", "\n", "ema_VT_smooth", ",", "mfcc", "=", "self", ".", "remove_silences", "(", "ema_VT_smooth", ",", "mfcc", ",", "i", ")", "\n", "ema_VT_smooth", ",", "mfcc", "=", "self", ".", "synchro_ema_mfcc", "(", "ema_VT_smooth", ",", "mfcc", ")", "\n", "\n", "ema_VT", ",", "rien", "=", "self", ".", "remove_silences", "(", "ema_VT", ",", "mfcc", ",", "i", ")", "\n", "ema_VT", ",", "rien", "=", "self", ".", "synchro_ema_mfcc", "(", "ema_VT", ",", "mfcc", ")", "\n", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "ema_VT", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "ema_VT_smooth", ")", "\n", "self", ".", "list_EMA_traj", ".", "append", "(", "ema_VT_smooth", ")", "\n", "self", ".", "list_MFCC_frames", ".", "append", "(", "mfcc", ")", "\n", "\n", "", "self", ".", "calculate_norm_values", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "ema_pas_smooth", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema\"", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "ema_VT_smooth", "=", "np", ".", "load", "(", "\n", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "mfcc", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "ema_VT_smooth_norma", ",", "mfcc", "=", "self", ".", "normalize_sentence", "(", "i", ",", "ema_VT_smooth", ",", "mfcc", ")", "\n", "ema_pas_smooth_norma", ",", "rien", "=", "self", ".", "normalize_sentence", "(", "i", ",", "ema_pas_smooth", ",", "mfcc", ")", "\n", "new_sr", "=", "1", "/", "self", ".", "hop_time", "# we did undersampling of ema traj for 1 point per frame mfcc", "\n", "# so about 1 point every hoptime sec.", "\n", "ema_VT_smooth_norma", "=", "self", ".", "smooth_data", "(", "ema_VT_smooth_norma", ",", "new_sr", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "ema_pas_smooth_norma", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "\n", "ema_VT_smooth_norma", ")", "\n", "\n", "#  split_sentences(speaker)   #possibility to cut to long sentences", "\n", "", "get_fileset_names", "(", "self", ".", "speaker", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_mocha.Preprocessing_general_mocha": [[220, 232], ["Preprocessing.tools_preprocessing.get_speakers_per_corpus", "print", "preprocessing_mocha.Speaker_mocha", "preprocessing_mocha.Speaker_mocha.Preprocessing_general_speaker", "print"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_speakers_per_corpus", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.Preprocessing_general_speaker"], ["", "", "def", "Preprocessing_general_mocha", "(", "N_max", ",", "path_to_raw", ")", ":", "\n", "    ", "\"\"\"\n    :param N_max: #max of files to treat (0 to treat all files), useful for test\n    go through all the speakers of Haskins\n    \"\"\"", "\n", "corpus", "=", "'mocha'", "\n", "speakers_mocha", "=", "get_speakers_per_corpus", "(", "corpus", ")", "\n", "for", "sp", "in", "speakers_mocha", ":", "\n", "        ", "print", "(", "\"In progress mocha \"", ",", "sp", ")", "\n", "speaker", "=", "Speaker_mocha", "(", "sp", ",", "path_to_raw", "=", "path_to_raw", ",", "N_max", "=", "N_max", ")", "\n", "speaker", ".", "Preprocessing_general_speaker", "(", ")", "\n", "print", "(", "\"Done mocha \"", ",", "sp", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.__init__": [[57, 68], ["Preprocessing.class_corpus.Speaker.__init__", "os.path.join", "os.path.join", "sorted", "os.listdir"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.__init__"], ["def", "__init__", "(", "self", ",", "sp", ",", "path_to_raw", ",", "N_max", "=", "0", ")", ":", "\n", "        ", "\"\"\"\n        :param sp:  name of the speaker\n        :param N_max:  # max of files we want to preprocess (0 is for All files), variable useful for test\n        \"\"\"", "\n", "super", "(", ")", ".", "__init__", "(", "sp", ")", "# gets the attributes of the Speaker class", "\n", "self", ".", "root_path", "=", "path_to_raw", "\n", "self", ".", "path_files_treated", "=", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ")", "\n", "self", ".", "path_files_brutes", "=", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ",", "\"data\"", ")", "\n", "self", ".", "EMA_files", "=", "sorted", "(", "[", "name", "[", ":", "-", "4", "]", "for", "name", "in", "os", ".", "listdir", "(", "self", ".", "path_files_brutes", ")", "if", "\"palate\"", "not", "in", "name", "]", ")", "\n", "self", ".", "N_max", "=", "N_max", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.create_missing_dir": [[70, 91], ["glob.glob", "glob.glob", "glob.glob", "glob.glob", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.exists", "os.makedirs", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.remove", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["None"], ["", "def", "create_missing_dir", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        delete all previous preprocessing, create needed directories\n        \"\"\"", "\n", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ")", ")", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ")", ")", "\n", "\n", "# We are going tp create the wav files form the matlab format files given for haskins", "\n", "", "if", "not", "os", ".", "path", ".", "exists", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ",", "\"wav\"", ")", ")", ":", "\n", "            ", "os", ".", "makedirs", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ",", "\"wav\"", ")", ")", "\n", "\n", "", "files", "=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"mfcc\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_treated", ",", "\"ema_final\"", ",", "\"*\"", ")", ")", "\n", "files", "+=", "glob", ".", "glob", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ",", "\"wav\"", ",", "\"*\"", ")", ")", "\n", "for", "f", "in", "files", ":", "\n", "            ", "os", ".", "remove", "(", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.read_ema_and_wav": [[92, 149], ["numpy.zeros", "range", "librosa.output.write_wav", "librosa.load", "Preprocessing.tools_preprocessing.get_delta_features", "Preprocessing.tools_preprocessing.get_delta_features", "numpy.concatenate", "numpy.zeros", "numpy.concatenate", "numpy.concatenate", "preprocessing_haskins.detect_silence", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "scipy.signal.resample", "len", "order_arti_haskins.index", "os.path.join", "os.path.join", "numpy.max", "librosa.feature.mfcc", "max", "int", "int", "int", "int", "scipy.loadmat", "scipy.loadmat", "scipy.loadmat", "scipy.loadmat", "scipy.loadmat", "len", "len", "numpy.floor", "min", "numpy.floor", "numpy.ceil", "os.path.join", "range", "len", "numpy.floor", "len"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_delta_features", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.detect_silence"], ["", "", "def", "read_ema_and_wav", "(", "self", ",", "k", ")", ":", "\n", "        ", "\"\"\"\n        :param k: index wrt EMA_files list of the file to read\n        :return: ema positions for 12 arti (K',12) , acoustic features (K,429); where K in the # of frames.\n        read and reorganize the ema traj,\n        calculations of the mfcc with librosa , + Delta and DeltaDelta, + 10 context frames\n        # of acoustic features per frame: 13 ==> 13*3 = 39 ==> 39*11 = 429.\n        parameters for mfcc calculation are defined in class_corpus\n        \"\"\"", "\n", "order_arti_haskins", "=", "[", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'tt_x'", ",", "'tt_y'", ",", "'ul_x'", ",", "'ul_y'", ",", "\"ll_x\"", ",", "\"ll_y\"", ",", "\n", "\"ml_x\"", ",", "\"ml_y\"", ",", "\"li_x\"", ",", "\"li_y\"", ",", "\"jl_x\"", ",", "\"jl_y\"", "]", "\n", "\n", "order_arti", "=", "[", "'tt_x'", ",", "'tt_y'", ",", "'td_x'", ",", "'td_y'", ",", "'tb_x'", ",", "'tb_y'", ",", "'li_x'", ",", "'li_y'", ",", "\n", "'ul_x'", ",", "'ul_y'", ",", "'ll_x'", ",", "'ll_y'", "]", "\n", "\n", "data", "=", "sio", ".", "loadmat", "(", "os", ".", "path", ".", "join", "(", "self", ".", "path_files_brutes", ",", "self", ".", "EMA_files", "[", "k", "]", "+", "\".mat\"", ")", ")", "[", "self", ".", "EMA_files", "[", "k", "]", "]", "[", "0", "]", "\n", "ema", "=", "np", ".", "zeros", "(", "(", "len", "(", "data", "[", "1", "]", "[", "2", "]", ")", ",", "len", "(", "order_arti_haskins", ")", ")", ")", "\n", "\n", "for", "arti", "in", "range", "(", "1", ",", "len", "(", "data", ")", ")", ":", "# lecture des trajectoires articulatoires dans le dicionnaire", "\n", "            ", "ema", "[", ":", ",", "(", "arti", "-", "1", ")", "*", "2", "]", "=", "data", "[", "arti", "]", "[", "2", "]", "[", ":", ",", "0", "]", "\n", "ema", "[", ":", ",", "arti", "*", "2", "-", "1", "]", "=", "data", "[", "arti", "]", "[", "2", "]", "[", ":", ",", "2", "]", "\n", "", "new_order_arti", "=", "[", "order_arti_haskins", ".", "index", "(", "col", ")", "for", "col", "in", "order_arti", "]", "\n", "ema", "=", "ema", "[", ":", ",", "new_order_arti", "]", "\n", "\n", "# We create wav files form intensity matlab files", "\n", "wav_data", "=", "data", "[", "0", "]", "[", "2", "]", "[", ":", ",", "0", "]", "\n", "librosa", ".", "output", ".", "write_wav", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ",", "\n", "\"wav\"", ",", "self", ".", "EMA_files", "[", "k", "]", "+", "\".wav\"", ")", ",", "wav_data", ",", "self", ".", "sampling_rate_wav", ")", "\n", "wav", ",", "sr", "=", "librosa", ".", "load", "(", "os", ".", "path", ".", "join", "(", "self", ".", "root_path", ",", "\"Raw_data\"", ",", "self", ".", "corpus", ",", "self", ".", "speaker", ",", "\"wav\"", ",", "\n", "self", ".", "EMA_files", "[", "k", "]", "+", "\".wav\"", ")", ",", "sr", "=", "self", ".", "sampling_rate_wav_wanted", ")", "\n", "# np.save(os.path.join(root_path, \"Raw_data\", corpus, speaker, \"wav\",", "\n", "#                      EMA_files[k]), wav)", "\n", "wav", "=", "0.5", "*", "wav", "/", "np", ".", "max", "(", "wav", ")", "\n", "mfcc", "=", "librosa", ".", "feature", ".", "mfcc", "(", "y", "=", "wav", ",", "sr", "=", "self", ".", "sampling_rate_wav_wanted", ",", "n_mfcc", "=", "self", ".", "n_coeff", ",", "\n", "n_fft", "=", "self", ".", "frame_length", ",", "hop_length", "=", "self", ".", "hop_length", ")", ".", "T", "\n", "dyna_features", "=", "get_delta_features", "(", "mfcc", ")", "\n", "dyna_features_2", "=", "get_delta_features", "(", "dyna_features", ")", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "(", "mfcc", ",", "dyna_features", ",", "dyna_features_2", ")", ",", "axis", "=", "1", ")", "\n", "padding", "=", "np", ".", "zeros", "(", "(", "self", ".", "window", ",", "mfcc", ".", "shape", "[", "1", "]", ")", ")", "\n", "frames", "=", "np", ".", "concatenate", "(", "[", "padding", ",", "mfcc", ",", "padding", "]", ")", "\n", "full_window", "=", "1", "+", "2", "*", "self", ".", "window", "\n", "mfcc", "=", "np", ".", "concatenate", "(", "[", "frames", "[", "i", ":", "i", "+", "len", "(", "mfcc", ")", "]", "for", "i", "in", "range", "(", "full_window", ")", "]", ",", "axis", "=", "1", ")", "\n", "\n", "marge", "=", "0", "\n", "xtrm", "=", "detect_silence", "(", "data", ")", "\n", "xtrm", "=", "[", "max", "(", "xtrm", "[", "0", "]", "-", "marge", ",", "0", ")", ",", "xtrm", "[", "1", "]", "+", "marge", "]", "\n", "\n", "xtrm_temp_ema", "=", "[", "int", "(", "np", ".", "floor", "(", "xtrm", "[", "0", "]", "*", "self", ".", "sampling_rate_ema", ")", ")", ",", "\n", "int", "(", "min", "(", "np", ".", "floor", "(", "xtrm", "[", "1", "]", "*", "self", ".", "sampling_rate_ema", ")", "+", "1", ",", "len", "(", "ema", ")", ")", ")", "]", "\n", "xtrm_temp_mfcc", "=", "[", "int", "(", "np", ".", "floor", "(", "xtrm", "[", "0", "]", "/", "self", ".", "hop_time", ")", ")", ",", "\n", "int", "(", "np", ".", "ceil", "(", "xtrm", "[", "1", "]", "/", "self", ".", "hop_time", ")", ")", "]", "\n", "ema", "=", "ema", "[", "xtrm_temp_ema", "[", "0", "]", ":", "xtrm_temp_ema", "[", "1", "]", ",", ":", "]", "\n", "mfcc", "=", "mfcc", "[", "xtrm_temp_mfcc", "[", "0", "]", ":", "xtrm_temp_mfcc", "[", "1", "]", "]", "\n", "\n", "n_frames_wanted", "=", "mfcc", ".", "shape", "[", "0", "]", "\n", "ema", "=", "scipy", ".", "signal", ".", "resample", "(", "ema", ",", "num", "=", "n_frames_wanted", ")", "\n", "return", "ema", ",", "mfcc", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.Preprocessing_general_speaker": [[150, 194], ["preprocessing_haskins.Speaker_Haskins.create_missing_dir", "len", "range", "preprocessing_haskins.Speaker_Haskins.calculate_norm_values", "range", "Preprocessing.tools_preprocessing.get_fileset_names", "int", "preprocessing_haskins.Speaker_Haskins.read_ema_and_wav", "preprocessing_haskins.Speaker_Haskins.add_vocal_tract", "preprocessing_haskins.Speaker_Haskins.smooth_data", "numpy.save", "numpy.save", "numpy.save", "preprocessing_haskins.Speaker_Haskins.list_EMA_traj.append", "preprocessing_haskins.Speaker_Haskins.list_MFCC_frames.append", "numpy.load", "numpy.load", "preprocessing_haskins.Speaker_Haskins.normalize_sentence", "preprocessing_haskins.Speaker_Haskins.smooth_data", "numpy.save", "numpy.save", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join", "os.path.join"], "methods", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.create_missing_dir", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.calculate_norm_values", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_fileset_names", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.read_ema_and_wav", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.add_vocal_tract", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.normalize_sentence", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.class_corpus.Speaker.smooth_data"], ["", "def", "Preprocessing_general_speaker", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Go through the sentences one by one.\n            - reads ema data and turn it to a (K,18) array where arti are in a precise order, interploate missing values,\n        smooth the trajectories, remove silences at the beginning and the end, undersample to have 1 position per\n        frame mfcc, add it to the list of EMA traj for this speaker\n            - reads the wav file, calculate the associated acoustic features (mfcc+delta+ deltadelta+contextframes) ,\n        add it to the list of the MFCC FEATURES for this speaker.\n        Then calculate the normvalues based on the list of ema/mfcc data for this speaker\n        Finally : normalization and last smoothing of the trajectories.\n        Final data are in Preprocessed_data/speaker/ema_final.npy and  mfcc.npy\n        \"\"\"", "\n", "\n", "self", ".", "create_missing_dir", "(", ")", "\n", "N", "=", "len", "(", "self", ".", "EMA_files", ")", "\n", "if", "self", ".", "N_max", "!=", "0", ":", "\n", "            ", "N", "=", "int", "(", "self", ".", "N_max", ")", "\n", "\n", "", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "ema", ",", "mfcc", "=", "self", ".", "read_ema_and_wav", "(", "i", ")", "\n", "ema_VT", "=", "self", ".", "add_vocal_tract", "(", "ema", ")", "\n", "ema_VT_smooth", "=", "self", ".", "smooth_data", "(", "ema_VT", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "ema_VT", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "\n", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "ema_VT_smooth", ")", "\n", "self", ".", "list_EMA_traj", ".", "append", "(", "ema_VT_smooth", ")", "\n", "self", ".", "list_MFCC_frames", ".", "append", "(", "mfcc", ")", "\n", "", "self", ".", "calculate_norm_values", "(", ")", "\n", "\n", "for", "i", "in", "range", "(", "N", ")", ":", "\n", "            ", "ema_VT_smooth", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "\n", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "mfcc", "=", "np", ".", "load", "(", "os", ".", "path", ".", "join", "(", "\n", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", "+", "\".npy\"", ")", ")", "\n", "ema_VT_smooth_norma", ",", "mfcc", "=", "self", ".", "normalize_sentence", "(", "i", ",", "ema_VT_smooth", ",", "mfcc", ")", "\n", "new_sr", "=", "1", "/", "self", ".", "hop_time", "\n", "ema_VT_smooth_norma", "=", "self", ".", "smooth_data", "(", "ema_VT_smooth_norma", ",", "new_sr", ")", "\n", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"mfcc\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "mfcc", ")", "\n", "np", ".", "save", "(", "os", ".", "path", ".", "join", "(", "root_path", ",", "\"Preprocessed_data\"", ",", "self", ".", "speaker", ",", "\"ema_final\"", ",", "self", ".", "EMA_files", "[", "i", "]", ")", ",", "\n", "ema_VT_smooth_norma", ")", "\n", "#  split_sentences(speaker)", "\n", "", "get_fileset_names", "(", "self", ".", "speaker", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.detect_silence": [[37, 50], ["None"], "function", ["None"], ["def", "detect_silence", "(", "ma_data", ")", ":", "\n", "    ", "\"\"\"\n    :param ma_data: one \"data\" file containing the beginning and end of one sentence\n    :return: the beginning and end (in seconds) of the entence\n    We test 2 cases since the \"ma_data\" are not all organized in the same order.\n    \"\"\"", "\n", "for", "k", "in", "[", "5", ",", "6", "]", ":", "\n", "        ", "try", ":", "\n", "            ", "mon_debut", "=", "ma_data", "[", "0", "]", "[", "k", "]", "[", "0", "]", "[", "0", "]", "[", "1", "]", "[", "0", "]", "[", "1", "]", "\n", "ma_fin", "=", "ma_data", "[", "0", "]", "[", "k", "]", "[", "0", "]", "[", "-", "1", "]", "[", "1", "]", "[", "0", "]", "[", "0", "]", "\n", "", "except", ":", "\n", "            ", "pass", "\n", "", "", "return", "[", "mon_debut", ",", "ma_fin", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Preprocessing_general_haskins": [[196, 208], ["Preprocessing.tools_preprocessing.get_speakers_per_corpus", "print", "preprocessing_haskins.Speaker_Haskins", "preprocessing_haskins.Speaker_Haskins.Preprocessing_general_speaker", "print"], "function", ["home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.tools_preprocessing.get_speakers_per_corpus", "home.repos.pwc.inspect_result.bootphon_articulatory_inversion.Preprocessing.preprocessing_haskins.Speaker_Haskins.Preprocessing_general_speaker"], ["", "", "def", "Preprocessing_general_haskins", "(", "N_max", ",", "path_to_raw", ")", ":", "\n", "    ", "\"\"\"\n    :param N_max: #max of files to treat (0 to treat all files), useful for test\n    go through all the speakers of Haskins\n    \"\"\"", "\n", "corpus", "=", "'Haskins'", "\n", "speakers_Has", "=", "get_speakers_per_corpus", "(", "corpus", ")", "\n", "for", "sp", "in", "speakers_Has", ":", "\n", "        ", "print", "(", "\"In progress Haskins \"", ",", "sp", ")", "\n", "speaker", "=", "Speaker_Haskins", "(", "sp", ",", "path_to_raw", "=", "path_to_raw", ",", "N_max", "=", "N_max", ")", "\n", "speaker", ".", "Preprocessing_general_speaker", "(", ")", "\n", "print", "(", "\"Done Haskins \"", ",", "sp", ")", "\n", "\n"]]}