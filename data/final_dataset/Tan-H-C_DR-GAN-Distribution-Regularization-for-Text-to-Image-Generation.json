{"home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm.__init__": [[15, 22], ["torch.nn.Module.__init__", "spectral.SpectralNorm._made_params", "spectral.SpectralNorm._make_params"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm._made_params", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm._make_params"], ["    ", "def", "__init__", "(", "self", ",", "module", ",", "name", "=", "'weight'", ",", "power_iterations", "=", "1", ")", ":", "\n", "        ", "super", "(", "SpectralNorm", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "module", "=", "module", "\n", "self", ".", "name", "=", "name", "\n", "self", ".", "power_iterations", "=", "power_iterations", "\n", "if", "not", "self", ".", "_made_params", "(", ")", ":", "\n", "            ", "self", ".", "_make_params", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm._update_u_v": [[23, 36], ["getattr", "getattr", "getattr", "range", "getattr.dot", "setattr", "spectral.l2normalize", "spectral.l2normalize", "getattr.view().mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "torch.mv", "getattr.dot.expand_as", "torch.t", "torch.t", "torch.t", "torch.t", "getattr.view", "getattr.view", "getattr.view"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.l2normalize", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.l2normalize"], ["", "", "def", "_update_u_v", "(", "self", ")", ":", "\n", "        ", "u", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_u\"", ")", "\n", "v", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_v\"", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_bar\"", ")", "\n", "\n", "height", "=", "w", ".", "data", ".", "shape", "[", "0", "]", "\n", "for", "_", "in", "range", "(", "self", ".", "power_iterations", ")", ":", "\n", "            ", "v", ".", "data", "=", "l2normalize", "(", "torch", ".", "mv", "(", "torch", ".", "t", "(", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "data", ")", ",", "u", ".", "data", ")", ")", "\n", "u", ".", "data", "=", "l2normalize", "(", "torch", ".", "mv", "(", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "data", ",", "v", ".", "data", ")", ")", "\n", "\n", "# sigma = torch.dot(u.data, torch.mv(w.view(height,-1).data, v.data))", "\n", "", "sigma", "=", "u", ".", "dot", "(", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "mv", "(", "v", ")", ")", "\n", "setattr", "(", "self", ".", "module", ",", "self", ".", "name", ",", "w", "/", "sigma", ".", "expand_as", "(", "w", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm._made_params": [[37, 45], ["getattr", "getattr", "getattr"], "methods", ["None"], ["", "def", "_made_params", "(", "self", ")", ":", "\n", "        ", "try", ":", "\n", "            ", "u", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_u\"", ")", "\n", "v", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_v\"", ")", "\n", "w", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", "+", "\"_bar\"", ")", "\n", "return", "True", "\n", "", "except", "AttributeError", ":", "\n", "            ", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm._make_params": [[47, 64], ["getattr", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "torch.nn.Parameter", "spectral.l2normalize", "spectral.l2normalize", "torch.nn.Parameter", "torch.nn.Parameter", "spectral.SpectralNorm.module.register_parameter", "spectral.SpectralNorm.module.register_parameter", "spectral.SpectralNorm.module.register_parameter", "getattr.data.new().normal_", "getattr.data.new().normal_", "getattr.view", "getattr.data.new", "getattr.data.new"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.l2normalize", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.l2normalize"], ["", "", "def", "_make_params", "(", "self", ")", ":", "\n", "        ", "w", "=", "getattr", "(", "self", ".", "module", ",", "self", ".", "name", ")", "\n", "\n", "height", "=", "w", ".", "data", ".", "shape", "[", "0", "]", "\n", "width", "=", "w", ".", "view", "(", "height", ",", "-", "1", ")", ".", "data", ".", "shape", "[", "1", "]", "\n", "\n", "u", "=", "Parameter", "(", "w", ".", "data", ".", "new", "(", "height", ")", ".", "normal_", "(", "0", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "v", "=", "Parameter", "(", "w", ".", "data", ".", "new", "(", "width", ")", ".", "normal_", "(", "0", ",", "1", ")", ",", "requires_grad", "=", "False", ")", "\n", "u", ".", "data", "=", "l2normalize", "(", "u", ".", "data", ")", "\n", "v", ".", "data", "=", "l2normalize", "(", "v", ".", "data", ")", "\n", "w_bar", "=", "Parameter", "(", "w", ".", "data", ")", "\n", "\n", "del", "self", ".", "module", ".", "_parameters", "[", "self", ".", "name", "]", "\n", "\n", "self", ".", "module", ".", "register_parameter", "(", "self", ".", "name", "+", "\"_u\"", ",", "u", ")", "\n", "self", ".", "module", ".", "register_parameter", "(", "self", ".", "name", "+", "\"_v\"", ",", "v", ")", "\n", "self", ".", "module", ".", "register_parameter", "(", "self", ".", "name", "+", "\"_bar\"", ",", "w_bar", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm.forward": [[66, 69], ["spectral.SpectralNorm._update_u_v", "spectral.SpectralNorm.module.forward"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.SpectralNorm._update_u_v", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.forward"], ["", "def", "forward", "(", "self", ",", "*", "args", ")", ":", "\n", "        ", "self", ".", "_update_u_v", "(", ")", "\n", "return", "self", ".", "module", ".", "forward", "(", "*", "args", ")", "", "", "", ""]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.spectral.l2normalize": [[10, 12], ["v.norm"], "function", ["None"], ["def", "l2normalize", "(", "v", ",", "eps", "=", "1e-12", ")", ":", "\n", "    ", "return", "v", "/", "(", "v", ".", "norm", "(", ")", "+", "eps", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.GlobalAttention.GlobalAttentionGeneral.__init__": [[78, 83], ["torch.Module.__init__", "GlobalAttention.conv1x1", "torch.Softmax", "torch.Softmax"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv1x1"], ["    ", "def", "__init__", "(", "self", ",", "idf", ",", "cdf", ")", ":", "\n", "        ", "super", "(", "GlobalAttentionGeneral", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "conv_context", "=", "conv1x1", "(", "cdf", ",", "idf", ")", "\n", "self", ".", "sm", "=", "nn", ".", "Softmax", "(", ")", "\n", "self", ".", "mask", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.GlobalAttention.GlobalAttentionGeneral.applyMask": [[84, 86], ["None"], "methods", ["None"], ["", "def", "applyMask", "(", "self", ",", "mask", ")", ":", "\n", "        ", "self", ".", "mask", "=", "mask", "# batch x sourceL", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.GlobalAttention.GlobalAttentionGeneral.forward": [[87, 127], ["input.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "context.unsqueeze", "GlobalAttention.GlobalAttentionGeneral.conv_context().squeeze", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "attn.view.view.view", "GlobalAttention.GlobalAttentionGeneral.sm", "attn.view.view.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.bmm", "torch.bmm", "torch.bmm", "torch.bmm", "weightedContext.view.view.view", "attn.view.view.view", "input.size", "input.size", "context.size", "context.size", "GlobalAttention.GlobalAttentionGeneral.mask.repeat", "attn.view.view.data.masked_fill_", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "GlobalAttention.GlobalAttentionGeneral.conv_context", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "float"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "input", ",", "context", ")", ":", "\n", "        ", "\"\"\"\n            input: batch x idf x ih x iw (queryL=ihxiw)\n            context: batch x cdf x sourceL\n        \"\"\"", "\n", "ih", ",", "iw", "=", "input", ".", "size", "(", "2", ")", ",", "input", ".", "size", "(", "3", ")", "\n", "queryL", "=", "ih", "*", "iw", "\n", "batch_size", ",", "sourceL", "=", "context", ".", "size", "(", "0", ")", ",", "context", ".", "size", "(", "2", ")", "\n", "\n", "# --> batch x queryL x idf", "\n", "target", "=", "input", ".", "view", "(", "batch_size", ",", "-", "1", ",", "queryL", ")", "\n", "targetT", "=", "torch", ".", "transpose", "(", "target", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "# batch x cdf x sourceL --> batch x cdf x sourceL x 1", "\n", "sourceT", "=", "context", ".", "unsqueeze", "(", "3", ")", "\n", "# --> batch x idf x sourceL", "\n", "sourceT", "=", "self", ".", "conv_context", "(", "sourceT", ")", ".", "squeeze", "(", "3", ")", "\n", "\n", "# Get attention", "\n", "# (batch x queryL x idf)(batch x idf x sourceL)", "\n", "# -->batch x queryL x sourceL", "\n", "attn", "=", "torch", ".", "bmm", "(", "targetT", ",", "sourceT", ")", "\n", "# --> batch*queryL x sourceL", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", "*", "queryL", ",", "sourceL", ")", "\n", "if", "self", ".", "mask", "is", "not", "None", ":", "\n", "# batch_size x sourceL --> batch_size*queryL x sourceL", "\n", "            ", "mask", "=", "self", ".", "mask", ".", "repeat", "(", "queryL", ",", "1", ")", "\n", "attn", ".", "data", ".", "masked_fill_", "(", "mask", ".", "data", ",", "-", "float", "(", "'inf'", ")", ")", "\n", "", "attn", "=", "self", ".", "sm", "(", "attn", ")", "# Eq. (2)", "\n", "# --> batch x queryL x sourceL", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", ",", "queryL", ",", "sourceL", ")", "\n", "# --> batch x sourceL x queryL", "\n", "attn", "=", "torch", ".", "transpose", "(", "attn", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# (batch x idf x sourceL)(batch x sourceL x queryL)", "\n", "# --> batch x idf x queryL", "\n", "weightedContext", "=", "torch", ".", "bmm", "(", "sourceT", ",", "attn", ")", "\n", "weightedContext", "=", "weightedContext", ".", "view", "(", "batch_size", ",", "-", "1", ",", "ih", ",", "iw", ")", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", ",", "-", "1", ",", "ih", ",", "iw", ")", "\n", "\n", "return", "weightedContext", ",", "attn", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.GlobalAttention.conv1x1": [[25, 29], ["torch.Conv2d"], "function", ["None"], ["def", "conv1x1", "(", "in_planes", ",", "out_planes", ")", ":", "\n", "    ", "\"1x1 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "\n", "padding", "=", "0", ",", "bias", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.GlobalAttention.func_attention": [[31, 75], ["context.view.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.bmm", "torch.bmm", "attn.view.view", "attn.view.view", "torch.transpose().contiguous", "torch.transpose().contiguous", "attn.view.view", "attn.view.view", "torch.tensor", "torch.tensor", "torch.tensor.transpose", "torch.matmul", "torch.matmul", "torch.transpose().contiguous", "torch.transpose().contiguous", "torch.bmm", "torch.bmm", "query.size", "query.size", "context.view.size", "context.view.size", "torch.Softmax", "torch.Softmax", "attn.view.view", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose", "torch.transpose"], "function", ["None"], ["", "def", "func_attention", "(", "query", ",", "context", ",", "gamma1", ")", ":", "\n", "    ", "\"\"\"\n    query: batch x ndf x queryL\n    context: batch x ndf x ih x iw (sourceL=ihxiw)\n    mask: batch_size x sourceL\n    \"\"\"", "\n", "batch_size", ",", "queryL", "=", "query", ".", "size", "(", "0", ")", ",", "query", ".", "size", "(", "2", ")", "\n", "ih", ",", "iw", "=", "context", ".", "size", "(", "2", ")", ",", "context", ".", "size", "(", "3", ")", "\n", "sourceL", "=", "ih", "*", "iw", "\n", "\n", "# --> batch x sourceL x ndf", "\n", "context", "=", "context", ".", "view", "(", "batch_size", ",", "-", "1", ",", "sourceL", ")", "\n", "contextT", "=", "torch", ".", "transpose", "(", "context", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# Get attention", "\n", "# (batch x sourceL x ndf)(batch x ndf x queryL)", "\n", "# -->batch x sourceL x queryL", "\n", "attn", "=", "torch", ".", "bmm", "(", "contextT", ",", "query", ")", "# Eq. (7) in AttnGAN paper", "\n", "# --> batch*sourceL x queryL", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", "*", "sourceL", ",", "queryL", ")", "\n", "attn", "=", "nn", ".", "Softmax", "(", ")", "(", "attn", ")", "# Eq. (8)", "\n", "\n", "# --> batch x sourceL x queryL", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", ",", "sourceL", ",", "queryL", ")", "\n", "# --> batch*queryL x sourceL", "\n", "attn", "=", "torch", ".", "transpose", "(", "attn", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", "*", "queryL", ",", "sourceL", ")", "\n", "\n", "#  Eq. (9)", "\n", "attn", "=", "attn", "*", "gamma1", "\n", "attn", "=", "nn", ".", "Softmax", "(", ")", "(", "attn", ")", "\n", "attn", "=", "attn", ".", "view", "(", "batch_size", ",", "queryL", ",", "sourceL", ")", "\n", "attn1", "=", "torch", ".", "tensor", "(", "attn", ")", "\n", "attn2", "=", "attn1", ".", "transpose", "(", "2", ",", "1", ")", "\n", "sparse", "=", "torch", ".", "matmul", "(", "attn1", ",", "attn2", ")", "\n", "#print(sparse.shape)", "\n", "# --> batch x sourceL x queryL", "\n", "attnT", "=", "torch", ".", "transpose", "(", "attn", ",", "1", ",", "2", ")", ".", "contiguous", "(", ")", "\n", "\n", "# (batch x ndf x sourceL)(batch x sourceL x queryL)", "\n", "# --> batch x ndf x queryL", "\n", "weightedContext", "=", "torch", ".", "bmm", "(", "context", ",", "attnT", ")", "\n", "\n", "return", "weightedContext", ",", "attn", ".", "view", "(", "batch_size", ",", "-", "1", ",", "ih", ",", "iw", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.pretrain_DAMSM.parse_args": [[37, 47], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.main.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a DAMSM network'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "dest", "=", "'cfg_file'", ",", "\n", "help", "=", "'optional config file'", ",", "\n", "default", "=", "'cfg/DAMSM/bird.yml'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "dest", "=", "'gpu_id'", ",", "type", "=", "int", ",", "default", "=", "0", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "dest", "=", "'data_dir'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--manualSeed'", ",", "type", "=", "int", ",", "help", "=", "'manual seed'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.pretrain_DAMSM.train": [[49, 131], ["cnn_model.train", "rnn_model.train", "time.time", "enumerate", "len", "rnn_model.zero_grad", "cnn_model.zero_grad", "datasets.prepare_data", "cnn_model", "rnn_model.init_hidden", "rnn_model", "miscc.losses.words_loss", "miscc.losses.sent_loss", "loss.backward", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "torch.nn.utils.clip_grad_norm", "optimizer.step", "words_features.size", "words_features.size", "rnn_model.parameters", "print", "time.time", "miscc.utils.build_super_images", "time.time", "imgs[].cpu", "PIL.Image.fromarray", "Image.fromarray.save", "len", "len"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.train", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.train", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.prepare_data", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.init_hidden"], ["", "def", "train", "(", "dataloader", ",", "cnn_model", ",", "rnn_model", ",", "batch_size", ",", "\n", "labels", ",", "optimizer", ",", "epoch", ",", "ixtoword", ",", "image_dir", ")", ":", "\n", "    ", "cnn_model", ".", "train", "(", ")", "\n", "rnn_model", ".", "train", "(", ")", "\n", "s_total_loss0", "=", "0", "\n", "s_total_loss1", "=", "0", "\n", "w_total_loss0", "=", "0", "\n", "w_total_loss1", "=", "0", "\n", "count", "=", "(", "epoch", "+", "1", ")", "*", "len", "(", "dataloader", ")", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "for", "step", ",", "data", "in", "enumerate", "(", "dataloader", ",", "0", ")", ":", "\n", "# print('step', step)", "\n", "        ", "rnn_model", ".", "zero_grad", "(", ")", "\n", "cnn_model", ".", "zero_grad", "(", ")", "\n", "\n", "imgs", ",", "captions", ",", "cap_lens", ",", "class_ids", ",", "keys", "=", "prepare_data", "(", "data", ")", "\n", "\n", "\n", "# words_features: batch_size x nef x 17 x 17", "\n", "# sent_code: batch_size x nef", "\n", "words_features", ",", "sent_code", "=", "cnn_model", "(", "imgs", "[", "-", "1", "]", ")", "\n", "# --> batch_size x nef x 17*17", "\n", "nef", ",", "att_sze", "=", "words_features", ".", "size", "(", "1", ")", ",", "words_features", ".", "size", "(", "2", ")", "\n", "# words_features = words_features.view(batch_size, nef, -1)", "\n", "\n", "hidden", "=", "rnn_model", ".", "init_hidden", "(", "batch_size", ")", "\n", "# words_emb: batch_size x nef x seq_len", "\n", "# sent_emb: batch_size x nef", "\n", "words_emb", ",", "sent_emb", "=", "rnn_model", "(", "captions", ",", "cap_lens", ",", "hidden", ")", "\n", "\n", "w_loss0", ",", "w_loss1", ",", "attn_maps", "=", "words_loss", "(", "words_features", ",", "words_emb", ",", "labels", ",", "\n", "cap_lens", ",", "class_ids", ",", "batch_size", ")", "\n", "w_total_loss0", "+=", "w_loss0", ".", "data", "\n", "w_total_loss1", "+=", "w_loss1", ".", "data", "\n", "loss", "=", "w_loss0", "+", "w_loss1", "\n", "\n", "s_loss0", ",", "s_loss1", "=", "sent_loss", "(", "sent_code", ",", "sent_emb", ",", "labels", ",", "class_ids", ",", "batch_size", ")", "\n", "loss", "+=", "s_loss0", "+", "s_loss1", "\n", "s_total_loss0", "+=", "s_loss0", ".", "data", "\n", "s_total_loss1", "+=", "s_loss1", ".", "data", "\n", "#", "\n", "loss", ".", "backward", "(", ")", "\n", "#", "\n", "# `clip_grad_norm` helps prevent", "\n", "# the exploding gradient problem in RNNs / LSTMs.", "\n", "torch", ".", "nn", ".", "utils", ".", "clip_grad_norm", "(", "rnn_model", ".", "parameters", "(", ")", ",", "\n", "cfg", ".", "TRAIN", ".", "RNN_GRAD_CLIP", ")", "\n", "optimizer", ".", "step", "(", ")", "\n", "\n", "if", "step", "%", "UPDATE_INTERVAL", "==", "0", ":", "\n", "            ", "count", "=", "epoch", "*", "len", "(", "dataloader", ")", "+", "step", "\n", "\n", "s_cur_loss0", "=", "s_total_loss0", "[", "0", "]", "/", "UPDATE_INTERVAL", "\n", "s_cur_loss1", "=", "s_total_loss1", "[", "0", "]", "/", "UPDATE_INTERVAL", "\n", "\n", "w_cur_loss0", "=", "w_total_loss0", "[", "0", "]", "/", "UPDATE_INTERVAL", "\n", "w_cur_loss1", "=", "w_total_loss1", "[", "0", "]", "/", "UPDATE_INTERVAL", "\n", "\n", "elapsed", "=", "time", ".", "time", "(", ")", "-", "start_time", "\n", "print", "(", "'| epoch {:3d} | {:5d}/{:5d} batches | ms/batch {:5.2f} | '", "\n", "'s_loss {:5.2f} {:5.2f} | '", "\n", "'w_loss {:5.2f} {:5.2f}'", "\n", ".", "format", "(", "epoch", ",", "step", ",", "len", "(", "dataloader", ")", ",", "\n", "elapsed", "*", "1000.", "/", "UPDATE_INTERVAL", ",", "\n", "s_cur_loss0", ",", "s_cur_loss1", ",", "\n", "w_cur_loss0", ",", "w_cur_loss1", ")", ")", "\n", "s_total_loss0", "=", "0", "\n", "s_total_loss1", "=", "0", "\n", "w_total_loss0", "=", "0", "\n", "w_total_loss1", "=", "0", "\n", "start_time", "=", "time", ".", "time", "(", ")", "\n", "# attention Maps", "\n", "img_set", ",", "_", "=", "build_super_images", "(", "imgs", "[", "-", "1", "]", ".", "cpu", "(", ")", ",", "captions", ",", "\n", "ixtoword", ",", "attn_maps", ",", "att_sze", ")", "\n", "if", "img_set", "is", "not", "None", ":", "\n", "                ", "im", "=", "Image", ".", "fromarray", "(", "img_set", ")", "\n", "fullpath", "=", "'%s/attention_maps%d.png'", "%", "(", "image_dir", ",", "step", ")", "\n", "im", ".", "save", "(", "fullpath", ")", "\n", "", "", "", "return", "count", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.pretrain_DAMSM.evaluate": [[133, 164], ["cnn_model.eval", "rnn_model.eval", "enumerate", "datasets.prepare_data", "cnn_model", "rnn_model.init_hidden", "rnn_model", "miscc.losses.words_loss", "miscc.losses.sent_loss"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.prepare_data", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.init_hidden"], ["", "def", "evaluate", "(", "dataloader", ",", "cnn_model", ",", "rnn_model", ",", "batch_size", ")", ":", "\n", "    ", "cnn_model", ".", "eval", "(", ")", "\n", "rnn_model", ".", "eval", "(", ")", "\n", "s_total_loss", "=", "0", "\n", "w_total_loss", "=", "0", "\n", "for", "step", ",", "data", "in", "enumerate", "(", "dataloader", ",", "0", ")", ":", "\n", "        ", "real_imgs", ",", "captions", ",", "cap_lens", ",", "class_ids", ",", "keys", "=", "prepare_data", "(", "data", ")", "\n", "\n", "words_features", ",", "sent_code", "=", "cnn_model", "(", "real_imgs", "[", "-", "1", "]", ")", "\n", "# nef = words_features.size(1)", "\n", "# words_features = words_features.view(batch_size, nef, -1)", "\n", "\n", "hidden", "=", "rnn_model", ".", "init_hidden", "(", "batch_size", ")", "\n", "words_emb", ",", "sent_emb", "=", "rnn_model", "(", "captions", ",", "cap_lens", ",", "hidden", ")", "\n", "\n", "w_loss0", ",", "w_loss1", ",", "attn", "=", "words_loss", "(", "words_features", ",", "words_emb", ",", "labels", ",", "\n", "cap_lens", ",", "class_ids", ",", "batch_size", ")", "\n", "w_total_loss", "+=", "(", "w_loss0", "+", "w_loss1", ")", ".", "data", "\n", "\n", "s_loss0", ",", "s_loss1", "=", "sent_loss", "(", "sent_code", ",", "sent_emb", ",", "labels", ",", "class_ids", ",", "batch_size", ")", "\n", "s_total_loss", "+=", "(", "s_loss0", "+", "s_loss1", ")", ".", "data", "\n", "\n", "if", "step", "==", "50", ":", "\n", "            ", "break", "\n", "\n", "", "", "s_cur_loss", "=", "s_total_loss", "[", "0", "]", "/", "step", "\n", "w_cur_loss", "=", "w_total_loss", "[", "0", "]", "/", "step", "\n", "\n", "return", "s_cur_loss", ",", "w_cur_loss", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.pretrain_DAMSM.build_models": [[166, 193], ["model.RNN_ENCODER", "model.CNN_ENCODER", "torch.autograd.Variable", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.load", "torch.load", "torch.load", "torch.load", "text_encoder.cuda.load_state_dict", "print", "miscc.config.cfg.TRAIN.NET_E.replace", "torch.load", "torch.load", "torch.load", "torch.load", "image_encoder.cuda.load_state_dict", "print", "miscc.config.cfg.TRAIN.NET_E.rfind", "print", "text_encoder.cuda.cuda", "image_encoder.cuda.cuda", "labels.cuda.cuda", "range", "miscc.config.cfg.TRAIN.NET_E.rfind", "int"], "function", ["None"], ["", "def", "build_models", "(", ")", ":", "\n", "# build model ############################################################", "\n", "    ", "text_encoder", "=", "RNN_ENCODER", "(", "dataset", ".", "n_words", ",", "nhidden", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", ")", "\n", "image_encoder", "=", "CNN_ENCODER", "(", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", ")", "\n", "labels", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "range", "(", "batch_size", ")", ")", ")", "\n", "start_epoch", "=", "0", "\n", "if", "cfg", ".", "TRAIN", ".", "NET_E", "!=", "''", ":", "\n", "        ", "state_dict", "=", "torch", ".", "load", "(", "cfg", ".", "TRAIN", ".", "NET_E", ")", "\n", "text_encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "print", "(", "'Load '", ",", "cfg", ".", "TRAIN", ".", "NET_E", ")", "\n", "#", "\n", "name", "=", "cfg", ".", "TRAIN", ".", "NET_E", ".", "replace", "(", "'text_encoder'", ",", "'image_encoder'", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "name", ")", "\n", "image_encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "print", "(", "'Load '", ",", "name", ")", "\n", "\n", "istart", "=", "cfg", ".", "TRAIN", ".", "NET_E", ".", "rfind", "(", "'_'", ")", "+", "8", "\n", "iend", "=", "cfg", ".", "TRAIN", ".", "NET_E", ".", "rfind", "(", "'.'", ")", "\n", "start_epoch", "=", "cfg", ".", "TRAIN", ".", "NET_E", "[", "istart", ":", "iend", "]", "\n", "start_epoch", "=", "int", "(", "start_epoch", ")", "+", "1", "\n", "print", "(", "'start_epoch'", ",", "start_epoch", ")", "\n", "", "if", "cfg", ".", "CUDA", ":", "\n", "        ", "text_encoder", "=", "text_encoder", ".", "cuda", "(", ")", "\n", "image_encoder", "=", "image_encoder", ".", "cuda", "(", ")", "\n", "labels", "=", "labels", ".", "cuda", "(", ")", "\n", "\n", "", "return", "text_encoder", ",", "image_encoder", ",", "labels", ",", "start_epoch", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.main.parse_args": [[24, 35], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.main.parse_args"], ["def", "parse_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "'Train a AttnGAN network'", ")", "\n", "parser", ".", "add_argument", "(", "'--cfg'", ",", "dest", "=", "'cfg_file'", ",", "\n", "help", "=", "'optional config file'", ",", "\n", "default", "=", "'cfg/bird_DMGAN.yml'", ",", "type", "=", "str", ")", "\n", "parser", ".", "add_argument", "(", "'--gpu'", ",", "dest", "=", "'gpu_id'", ",", "type", "=", "int", ",", "default", "=", "-", "1", ")", "\n", "parser", ".", "add_argument", "(", "'--data_dir'", ",", "dest", "=", "'data_dir'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--NET_G'", ",", "type", "=", "str", ",", "default", "=", "''", ")", "\n", "parser", ".", "add_argument", "(", "'--manualSeed'", ",", "type", "=", "int", ",", "help", "=", "'manual seed'", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.main.gen_example": [[37, 85], ["algo.gen_example", "open", "f.read().split", "numpy.max", "numpy.asarray", "numpy.zeros", "range", "f.read", "len", "open", "print", "f.read().split", "numpy.argsort", "len", "len", "sent.replace.replace", "RegexpTokenizer", "RegexpTokenizer.tokenize", "captions.append", "np.asarray.append", "len", "f.read", "len", "sent.replace.lower", "len", "print", "t.encode().decode.encode().decode", "len", "name.rfind", "rev.append", "t.encode().decode.encode", "len"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.main.gen_example", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.encode"], ["", "def", "gen_example", "(", "wordtoix", ",", "algo", ")", ":", "\n", "    ", "'''generate images from example sentences'''", "\n", "from", "nltk", ".", "tokenize", "import", "RegexpTokenizer", "\n", "filepath", "=", "'%s/example_filenames.txt'", "%", "(", "cfg", ".", "DATA_DIR", ")", "\n", "data_dic", "=", "{", "}", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "filenames", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "for", "name", "in", "filenames", ":", "\n", "            ", "if", "len", "(", "name", ")", "==", "0", ":", "\n", "                ", "continue", "\n", "", "filepath", "=", "'%s/%s.txt'", "%", "(", "cfg", ".", "DATA_DIR", ",", "name", ")", "\n", "with", "open", "(", "filepath", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "print", "(", "'Load from:'", ",", "name", ")", "\n", "sentences", "=", "f", ".", "read", "(", ")", ".", "split", "(", "'\\n'", ")", "\n", "# a list of indices for a sentence", "\n", "captions", "=", "[", "]", "\n", "cap_lens", "=", "[", "]", "\n", "for", "sent", "in", "sentences", ":", "\n", "                    ", "if", "len", "(", "sent", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "sent", "=", "sent", ".", "replace", "(", "\"\\ufffd\\ufffd\"", ",", "\" \"", ")", "\n", "tokenizer", "=", "RegexpTokenizer", "(", "r'\\w+'", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "sent", ".", "lower", "(", ")", ")", "\n", "if", "len", "(", "tokens", ")", "==", "0", ":", "\n", "                        ", "print", "(", "'sent'", ",", "sent", ")", "\n", "continue", "\n", "\n", "", "rev", "=", "[", "]", "\n", "for", "t", "in", "tokens", ":", "\n", "                        ", "t", "=", "t", ".", "encode", "(", "'ascii'", ",", "'ignore'", ")", ".", "decode", "(", "'ascii'", ")", "\n", "if", "len", "(", "t", ")", ">", "0", "and", "t", "in", "wordtoix", ":", "\n", "                            ", "rev", ".", "append", "(", "wordtoix", "[", "t", "]", ")", "\n", "", "", "captions", ".", "append", "(", "rev", ")", "\n", "cap_lens", ".", "append", "(", "len", "(", "rev", ")", ")", "\n", "", "", "max_len", "=", "np", ".", "max", "(", "cap_lens", ")", "\n", "\n", "sorted_indices", "=", "np", ".", "argsort", "(", "cap_lens", ")", "[", ":", ":", "-", "1", "]", "\n", "cap_lens", "=", "np", ".", "asarray", "(", "cap_lens", ")", "\n", "cap_lens", "=", "cap_lens", "[", "sorted_indices", "]", "\n", "cap_array", "=", "np", ".", "zeros", "(", "(", "len", "(", "captions", ")", ",", "max_len", ")", ",", "dtype", "=", "'int64'", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "captions", ")", ")", ":", "\n", "                ", "idx", "=", "sorted_indices", "[", "i", "]", "\n", "cap", "=", "captions", "[", "idx", "]", "\n", "c_len", "=", "len", "(", "cap", ")", "\n", "cap_array", "[", "i", ",", ":", "c_len", "]", "=", "cap", "\n", "", "key", "=", "name", "[", "(", "name", ".", "rfind", "(", "'/'", ")", "+", "1", ")", ":", "]", "\n", "data_dic", "[", "key", "]", "=", "[", "cap_array", ",", "cap_lens", ",", "sorted_indices", "]", "\n", "", "", "algo", ".", "gen_example", "(", "data_dic", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.__init__": [[33, 52], ["len", "os.path.join", "os.path.join", "miscc.utils.mkdir_p", "miscc.utils.mkdir_p"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "output_dir", ",", "data_loader", ",", "n_words", ",", "ixtoword", ",", "dataset", ")", ":", "\n", "        ", "if", "cfg", ".", "TRAIN", ".", "FLAG", ":", "\n", "            ", "self", ".", "model_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'Model'", ")", "\n", "self", ".", "image_dir", "=", "os", ".", "path", ".", "join", "(", "output_dir", ",", "'Image'", ")", "\n", "mkdir_p", "(", "self", ".", "model_dir", ")", "\n", "mkdir_p", "(", "self", ".", "image_dir", ")", "\n", "\n", "#torch.cuda.set_device(cfg.GPU_ID)", "\n", "#cudnn.benchmark = True", "\n", "\n", "", "self", ".", "batch_size", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "\n", "self", ".", "max_epoch", "=", "cfg", ".", "TRAIN", ".", "MAX_EPOCH", "\n", "self", ".", "snapshot_interval", "=", "cfg", ".", "TRAIN", ".", "SNAPSHOT_INTERVAL", "\n", "\n", "self", ".", "n_words", "=", "n_words", "\n", "self", ".", "ixtoword", "=", "ixtoword", "\n", "self", ".", "data_loader", "=", "data_loader", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "num_batches", "=", "len", "(", "self", ".", "data_loader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.build_models": [[53, 152], ["model.CNN_ENCODER", "miscc.config.cfg.TRAIN.NET_E.replace", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "image_encoder.cuda.cuda.load_state_dict", "image_encoder.cuda.cuda.parameters", "print", "image_encoder.cuda.cuda.eval", "model.RNN_ENCODER", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "text_encoder.cuda.cuda.load_state_dict", "text_encoder.cuda.cuda.parameters", "print", "text_encoder.cuda.cuda.eval", "print", "print", "model.G_NET.apply", "six.moves.range", "print", "model.named_parameters", "print", "model.G_DCGAN", "model.G_NET", "trainer.condGANTrainer.build_models.count_parameters"], "methods", ["None"], ["", "def", "build_models", "(", "self", ")", ":", "\n", "        ", "def", "count_parameters", "(", "model", ")", ":", "\n", "            ", "total_param", "=", "0", "\n", "for", "name", ",", "param", "in", "model", ".", "named_parameters", "(", ")", ":", "\n", "                ", "if", "param", ".", "requires_grad", ":", "\n", "                    ", "num_param", "=", "np", ".", "prod", "(", "param", ".", "size", "(", ")", ")", "\n", "if", "param", ".", "dim", "(", ")", ">", "1", ":", "\n", "                        ", "print", "(", "name", ",", "':'", ",", "'x'", ".", "join", "(", "str", "(", "x", ")", "for", "x", "in", "list", "(", "param", ".", "size", "(", ")", ")", ")", ",", "'='", ",", "num_param", ")", "\n", "", "else", ":", "\n", "                        ", "print", "(", "name", ",", "':'", ",", "num_param", ")", "\n", "", "total_param", "+=", "num_param", "\n", "", "", "return", "total_param", "\n", "\n", "# ###################encoders######################################## #", "\n", "", "if", "cfg", ".", "TRAIN", ".", "NET_E", "==", "''", ":", "\n", "            ", "print", "(", "'Error: no pretrained text-image encoders'", ")", "\n", "return", "\n", "\n", "", "image_encoder", "=", "CNN_ENCODER", "(", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", ")", "\n", "img_encoder_path", "=", "cfg", ".", "TRAIN", ".", "NET_E", ".", "replace", "(", "'text_encoder'", ",", "'image_encoder'", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "img_encoder_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "image_encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "for", "p", "in", "image_encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "print", "(", "'Load image encoder from:'", ",", "img_encoder_path", ")", "\n", "image_encoder", ".", "eval", "(", ")", "\n", "\n", "text_encoder", "=", "RNN_ENCODER", "(", "self", ".", "n_words", ",", "nhidden", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "cfg", ".", "TRAIN", ".", "NET_E", ",", "\n", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "text_encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "for", "p", "in", "text_encoder", ".", "parameters", "(", ")", ":", "\n", "            ", "p", ".", "requires_grad", "=", "False", "\n", "", "print", "(", "'Load text encoder from:'", ",", "cfg", ".", "TRAIN", ".", "NET_E", ")", "\n", "text_encoder", ".", "eval", "(", ")", "\n", "\n", "# #######################generator and discriminators############## #", "\n", "netsD", "=", "[", "]", "\n", "if", "cfg", ".", "GAN", ".", "B_DCGAN", ":", "\n", "            ", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", "==", "1", ":", "\n", "                ", "from", "model", "import", "D_NET64", "as", "D_NET", "\n", "", "elif", "cfg", ".", "TREE", ".", "BRANCH_NUM", "==", "2", ":", "\n", "                ", "from", "model", "import", "D_NET128", "as", "D_NET", "\n", "", "else", ":", "# cfg.TREE.BRANCH_NUM == 3:", "\n", "                ", "from", "model", "import", "D_NET256", "as", "D_NET", "\n", "# TODO: elif cfg.TREE.BRANCH_NUM > 3:", "\n", "", "netG", "=", "G_DCGAN", "(", ")", "\n", "netsD", "=", "[", "D_NET", "(", "b_jcu", "=", "False", ")", "]", "\n", "", "else", ":", "\n", "            ", "from", "model", "import", "D_NET64", ",", "D_NET128", ",", "D_NET256", "\n", "netG", "=", "G_NET", "(", ")", "\n", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "0", ":", "\n", "                ", "netsD", ".", "append", "(", "D_NET64", "(", ")", ")", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "1", ":", "\n", "                ", "netsD", ".", "append", "(", "D_NET128", "(", ")", ")", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "2", ":", "\n", "                ", "netsD", ".", "append", "(", "D_NET256", "(", ")", ")", "\n", "# TODO: if cfg.TREE.BRANCH_NUM > 3:", "\n", "\n", "", "", "print", "(", "'number of trainable parameters ='", ",", "count_parameters", "(", "netG", ")", ")", "\n", "print", "(", "'number of trainable parameters ='", ",", "count_parameters", "(", "netsD", "[", "-", "1", "]", ")", ")", "\n", "\n", "netG", ".", "apply", "(", "weights_init", ")", "\n", "# print(netG)", "\n", "for", "i", "in", "range", "(", "len", "(", "netsD", ")", ")", ":", "\n", "            ", "netsD", "[", "i", "]", ".", "apply", "(", "weights_init", ")", "\n", "# print(netsD[i])", "\n", "", "print", "(", "'# of netsD'", ",", "len", "(", "netsD", ")", ")", "\n", "#", "\n", "epoch", "=", "0", "\n", "if", "cfg", ".", "TRAIN", ".", "NET_G", "!=", "''", ":", "\n", "            ", "state_dict", "=", "torch", ".", "load", "(", "cfg", ".", "TRAIN", ".", "NET_G", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "netG", ".", "load_state_dict", "(", "state_dict", ")", "\n", "print", "(", "'Load G from: '", ",", "cfg", ".", "TRAIN", ".", "NET_G", ")", "\n", "istart", "=", "cfg", ".", "TRAIN", ".", "NET_G", ".", "rfind", "(", "'_'", ")", "+", "1", "\n", "iend", "=", "cfg", ".", "TRAIN", ".", "NET_G", ".", "rfind", "(", "'.'", ")", "\n", "epoch", "=", "cfg", ".", "TRAIN", ".", "NET_G", "[", "istart", ":", "iend", "]", "\n", "epoch", "=", "int", "(", "epoch", ")", "+", "1", "\n", "if", "cfg", ".", "TRAIN", ".", "B_NET_D", ":", "\n", "                ", "Gname", "=", "cfg", ".", "TRAIN", ".", "NET_G", "\n", "for", "i", "in", "range", "(", "len", "(", "netsD", ")", ")", ":", "\n", "                    ", "s_tmp", "=", "Gname", "[", ":", "Gname", ".", "rfind", "(", "'/'", ")", "]", "\n", "Dname", "=", "'%s/netD%d.pth'", "%", "(", "s_tmp", ",", "i", ")", "\n", "print", "(", "'Load D from: '", ",", "Dname", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "Dname", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "netsD", "[", "i", "]", ".", "load_state_dict", "(", "state_dict", ")", "\n", "# ########################################################### #", "\n", "", "", "", "if", "cfg", ".", "CUDA", ":", "\n", "            ", "text_encoder", "=", "text_encoder", ".", "cuda", "(", ")", "\n", "image_encoder", "=", "image_encoder", ".", "cuda", "(", ")", "\n", "netG", ".", "cuda", "(", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "netsD", ")", ")", ":", "\n", "                ", "netsD", "[", "i", "]", ".", "cuda", "(", ")", "\n", "", "", "return", "[", "text_encoder", ",", "image_encoder", ",", "netG", ",", "netsD", ",", "epoch", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.define_optimizers": [[153, 167], ["len", "six.moves.range", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "torch.Adam", "optimizersD.append", "netG.parameters", "filter", "netsD[].parameters"], "methods", ["None"], ["", "def", "define_optimizers", "(", "self", ",", "netG", ",", "netsD", ")", ":", "\n", "        ", "optimizersD", "=", "[", "]", "\n", "num_Ds", "=", "len", "(", "netsD", ")", "\n", "for", "i", "in", "range", "(", "num_Ds", ")", ":", "\n", "            ", "opt", "=", "optim", ".", "Adam", "(", "filter", "(", "lambda", "p", ":", "p", ".", "requires_grad", ",", "netsD", "[", "i", "]", ".", "parameters", "(", ")", ")", ",", "\n", "lr", "=", "cfg", ".", "TRAIN", ".", "DISCRIMINATOR_LR", ",", "\n", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "optimizersD", ".", "append", "(", "opt", ")", "\n", "\n", "", "optimizerG", "=", "optim", ".", "Adam", "(", "netG", ".", "parameters", "(", ")", ",", "\n", "lr", "=", "cfg", ".", "TRAIN", ".", "GENERATOR_LR", ",", "\n", "betas", "=", "(", "0.5", ",", "0.999", ")", ")", "\n", "\n", "return", "optimizerG", ",", "optimizersD", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.prepare_labels": [[168, 179], ["torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.FloatTensor().fill_", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "torch.LongTensor", "real_labels.cuda.cuda.cuda", "fake_labels.cuda.cuda.cuda", "match_labels.cuda.cuda.cuda", "six.moves.range", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor"], "methods", ["None"], ["", "def", "prepare_labels", "(", "self", ")", ":", "\n", "        ", "batch_size", "=", "self", ".", "batch_size", "\n", "real_labels", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "batch_size", ")", ".", "fill_", "(", "1", ")", ")", "\n", "fake_labels", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "batch_size", ")", ".", "fill_", "(", "0", ")", ")", "\n", "match_labels", "=", "Variable", "(", "torch", ".", "LongTensor", "(", "range", "(", "batch_size", ")", ")", ")", "\n", "if", "cfg", ".", "CUDA", ":", "\n", "            ", "real_labels", "=", "real_labels", ".", "cuda", "(", ")", "\n", "fake_labels", "=", "fake_labels", ".", "cuda", "(", ")", "\n", "match_labels", "=", "match_labels", ".", "cuda", "(", ")", "\n", "\n", "", "return", "real_labels", ",", "fake_labels", ",", "match_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.save_model": [[180, 192], ["miscc.utils.copy_G_params", "miscc.utils.load_params", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "miscc.utils.load_params", "six.moves.range", "print", "netG.state_dict", "len", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "torch.save", "netD.state_dict"], "methods", ["None"], ["", "def", "save_model", "(", "self", ",", "netG", ",", "avg_param_G", ",", "netsD", ",", "epoch", ")", ":", "\n", "        ", "backup_para", "=", "copy_G_params", "(", "netG", ")", "\n", "load_params", "(", "netG", ",", "avg_param_G", ")", "\n", "torch", ".", "save", "(", "netG", ".", "state_dict", "(", ")", ",", "\n", "'%s/netG_epoch_%d.pth'", "%", "(", "self", ".", "model_dir", ",", "epoch", ")", ")", "\n", "load_params", "(", "netG", ",", "backup_para", ")", "\n", "#", "\n", "for", "i", "in", "range", "(", "len", "(", "netsD", ")", ")", ":", "\n", "            ", "netD", "=", "netsD", "[", "i", "]", "\n", "torch", ".", "save", "(", "netD", ".", "state_dict", "(", ")", ",", "\n", "'%s/netD%d.pth'", "%", "(", "self", ".", "model_dir", ",", "i", ")", ")", "\n", "", "print", "(", "'Save G/Ds models.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.set_requires_grad_value": [[193, 197], ["six.moves.range", "len", "models_list[].parameters"], "methods", ["None"], ["", "def", "set_requires_grad_value", "(", "self", ",", "models_list", ",", "brequires", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "len", "(", "models_list", ")", ")", ":", "\n", "            ", "for", "p", "in", "models_list", "[", "i", "]", ".", "parameters", "(", ")", ":", "\n", "                ", "p", ".", "requires_grad", "=", "brequires", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.save_img_results": [[198, 237], ["netG", "six.moves.range", "fake_imgs[].detach", "image_encoder", "region_features.size", "miscc.losses.words_loss", "miscc.utils.build_super_images", "len", "attn_maps.size", "miscc.utils.build_super_images", "region_features.detach", "words_embs.detach", "fake_imgs[].detach().cpu", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "len", "fake_imgs[].detach().cpu", "fake_imgs[].detach().cpu", "fake_imgs[].detach().cpu", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "fake_imgs[].detach", "fake_imgs[].detach", "fake_imgs[].detach", "fake_imgs[].detach"], "methods", ["None"], ["", "", "", "def", "save_img_results", "(", "self", ",", "netG", ",", "noise", ",", "sent_emb", ",", "words_embs", ",", "mask", ",", "\n", "image_encoder", ",", "captions", ",", "cap_lens", ",", "\n", "gen_iterations", ",", "imgs", ",", "name", "=", "'current'", ")", ":", "\n", "# Save images", "\n", "        ", "fake_imgs", ",", "attention_maps", ",", "_", ",", "_", ",", "_", ",", "I_P", ",", "I_star", "=", "netG", "(", "noise", ",", "sent_emb", ",", "words_embs", ",", "mask", ",", "imgs", ")", "\n", "for", "i", "in", "range", "(", "len", "(", "attention_maps", ")", ")", ":", "\n", "            ", "if", "len", "(", "fake_imgs", ")", ">", "1", ":", "\n", "                ", "img", "=", "fake_imgs", "[", "i", "+", "1", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "lr_img", "=", "fake_imgs", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "", "else", ":", "\n", "                ", "img", "=", "fake_imgs", "[", "0", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "lr_img", "=", "None", "\n", "", "attn_maps", "=", "attention_maps", "[", "i", "]", "\n", "att_sze", "=", "attn_maps", ".", "size", "(", "2", ")", "\n", "img_set", ",", "_", "=", "build_super_images", "(", "img", ",", "captions", ",", "self", ".", "ixtoword", ",", "\n", "attn_maps", ",", "att_sze", ",", "lr_imgs", "=", "lr_img", ")", "\n", "if", "img_set", "is", "not", "None", ":", "\n", "                ", "im", "=", "Image", ".", "fromarray", "(", "img_set", ")", "\n", "fullpath", "=", "'%s/G_%s_%d_%d.png'", "%", "(", "self", ".", "image_dir", ",", "name", ",", "gen_iterations", ",", "i", ")", "\n", "im", ".", "save", "(", "fullpath", ")", "\n", "\n", "# for i in range(len(netsD)):", "\n", "", "", "i", "=", "-", "1", "\n", "img", "=", "fake_imgs", "[", "i", "]", ".", "detach", "(", ")", "\n", "region_features", ",", "_", "=", "image_encoder", "(", "img", ")", "\n", "att_sze", "=", "region_features", ".", "size", "(", "2", ")", "\n", "_", ",", "_", ",", "att_maps", "=", "words_loss", "(", "region_features", ".", "detach", "(", ")", ",", "\n", "words_embs", ".", "detach", "(", ")", ",", "\n", "None", ",", "cap_lens", ",", "\n", "None", ",", "self", ".", "batch_size", ")", "\n", "img_set", ",", "_", "=", "build_super_images", "(", "fake_imgs", "[", "i", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "captions", ",", "self", ".", "ixtoword", ",", "att_maps", ",", "att_sze", ")", "\n", "if", "img_set", "is", "not", "None", ":", "\n", "            ", "im", "=", "Image", ".", "fromarray", "(", "img_set", ")", "\n", "fullpath", "=", "'%s/D_%s_%d.png'", "%", "(", "self", ".", "image_dir", ",", "name", ",", "gen_iterations", ")", "\n", "im", ".", "save", "(", "fullpath", ")", "\n", "#print(real_image.type)", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.train": [[240, 327], ["trainer.condGANTrainer.build_models", "miscc.utils.copy_G_params", "trainer.condGANTrainer.define_optimizers", "trainer.condGANTrainer.prepare_labels", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "six.moves.range", "trainer.condGANTrainer.save_model", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "time.time", "iter", "time.time", "print", "print", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "torch.autograd.Variable.cuda", "iter.next", "datasets.prepare_data", "text_encoder.init_hidden", "text_encoder", "words_embs.size", "torch.autograd.Variable.data.normal_", "torch.autograd.Variable.data.normal_", "torch.autograd.Variable.data.normal_", "torch.autograd.Variable.data.normal_", "netG", "six.moves.range", "netG.zero_grad", "miscc.losses.generator_loss", "miscc.losses.KL_loss", "errG_total.backward", "optimizerG.step", "zip", "trainer.condGANTrainer.save_model", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "words_embs.detach", "sent_emb.detach", "mask.size", "len", "netsD[].zero_grad", "miscc.losses.discriminator_loss", "errD.backward", "optimizersD[].step", "miscc.losses.KL_loss.item", "netG.parameters", "avg_p.mul_().add_", "print", "miscc.utils.copy_G_params", "miscc.utils.load_params", "miscc.utils.load_params", "errD_total.item", "errG_total.item", "errD.item", "avg_p.mul_"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.build_models", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.define_optimizers", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.prepare_labels", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.save_model", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.prepare_data", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.init_hidden", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.save_model"], ["", "", "def", "train", "(", "self", ")", ":", "\n", "        ", "text_encoder", ",", "image_encoder", ",", "netG", ",", "netsD", ",", "start_epoch", "=", "self", ".", "build_models", "(", ")", "\n", "avg_param_G", "=", "copy_G_params", "(", "netG", ")", "\n", "optimizerG", ",", "optimizersD", "=", "self", ".", "define_optimizers", "(", "netG", ",", "netsD", ")", "\n", "real_labels", ",", "fake_labels", ",", "match_labels", "=", "self", ".", "prepare_labels", "(", ")", "\n", "\n", "batch_size", "=", "self", ".", "batch_size", "\n", "nz", "=", "cfg", ".", "GAN", ".", "Z_DIM", "\n", "noise", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "batch_size", ",", "nz", ")", ")", "\n", "fixed_noise", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "batch_size", ",", "nz", ")", ".", "normal_", "(", "0", ",", "1", ")", ")", "\n", "if", "cfg", ".", "CUDA", ":", "\n", "            ", "noise", ",", "fixed_noise", "=", "noise", ".", "cuda", "(", ")", ",", "fixed_noise", ".", "cuda", "(", ")", "\n", "\n", "", "gen_iterations", "=", "0", "\n", "\n", "for", "epoch", "in", "range", "(", "start_epoch", ",", "self", ".", "max_epoch", ")", ":", "\n", "            ", "start_t", "=", "time", ".", "time", "(", ")", "\n", "\n", "data_iter", "=", "iter", "(", "self", ".", "data_loader", ")", "\n", "step", "=", "0", "\n", "while", "step", "<", "self", ".", "num_batches", ":", "\n", "                ", "data", "=", "data_iter", ".", "next", "(", ")", "\n", "imgs", ",", "captions", ",", "cap_lens", ",", "class_ids", ",", "keys", "=", "prepare_data", "(", "data", ")", "\n", "\n", "hidden", "=", "text_encoder", ".", "init_hidden", "(", "batch_size", ")", "\n", "\n", "words_embs", ",", "sent_emb", "=", "text_encoder", "(", "captions", ",", "cap_lens", ",", "hidden", ")", "\n", "words_embs", ",", "sent_emb", "=", "words_embs", ".", "detach", "(", ")", ",", "sent_emb", ".", "detach", "(", ")", "\n", "mask", "=", "(", "captions", "==", "0", ")", "\n", "num_words", "=", "words_embs", ".", "size", "(", "2", ")", "\n", "if", "mask", ".", "size", "(", "1", ")", ">", "num_words", ":", "\n", "                    ", "mask", "=", "mask", "[", ":", ",", ":", "num_words", "]", "\n", "\n", "", "noise", ".", "data", ".", "normal_", "(", "0", ",", "1", ")", "\n", "fake_imgs", ",", "_", ",", "mu", ",", "logvar", ",", "erreorx", ",", "I_P", ",", "I_star", "=", "netG", "(", "noise", ",", "sent_emb", ",", "words_embs", ",", "mask", ",", "imgs", ")", "\n", "\n", "\n", "errD_total", "=", "0", "\n", "D_logs", "=", "''", "\n", "for", "i", "in", "range", "(", "len", "(", "netsD", ")", ")", ":", "\n", "                    ", "netsD", "[", "i", "]", ".", "zero_grad", "(", ")", "\n", "errD", ",", "log", "=", "discriminator_loss", "(", "netsD", "[", "i", "]", ",", "imgs", "[", "i", "]", ",", "fake_imgs", "[", "i", "]", ",", "\n", "sent_emb", ",", "real_labels", ",", "fake_labels", ",", "words_embs", ",", "mask", ",", "fake_imgs", "[", "0", "]", ",", "imgs", "[", "0", "]", ",", "noise", ")", "\n", "# backward and update parameters", "\n", "errD", ".", "backward", "(", ")", "\n", "optimizersD", "[", "i", "]", ".", "step", "(", ")", "\n", "errD_total", "+=", "errD", "\n", "D_logs", "+=", "'errD%d: %.2f '", "%", "(", "i", ",", "errD", ".", "item", "(", ")", ")", "\n", "D_logs", "+=", "log", "\n", "\n", "\n", "", "step", "+=", "1", "\n", "gen_iterations", "+=", "1", "\n", "\n", "\n", "netG", ".", "zero_grad", "(", ")", "\n", "errG_total", ",", "G_logs", "=", "generator_loss", "(", "netsD", ",", "image_encoder", ",", "fake_imgs", ",", "real_labels", ",", "\n", "words_embs", ",", "sent_emb", ",", "match_labels", ",", "cap_lens", ",", "class_ids", ",", "mask", ",", "imgs", ",", "erreorx", ",", "I_P", ",", "I_star", ",", "noise", ")", "\n", "kl_loss", "=", "KL_loss", "(", "mu", ",", "logvar", ")", "\n", "errG_total", "+=", "kl_loss", "\n", "G_logs", "+=", "'kl_loss: %.2f '", "%", "kl_loss", ".", "item", "(", ")", "\n", "# backward and update parameters", "\n", "errG_total", ".", "backward", "(", ")", "\n", "optimizerG", ".", "step", "(", ")", "\n", "for", "p", ",", "avg_p", "in", "zip", "(", "netG", ".", "parameters", "(", ")", ",", "avg_param_G", ")", ":", "\n", "                    ", "avg_p", ".", "mul_", "(", "0.999", ")", ".", "add_", "(", "0.001", ",", "p", ".", "data", ")", "\n", "\n", "", "if", "gen_iterations", "%", "100", "==", "0", ":", "\n", "                    ", "print", "(", "'Epoch [{}/{}] Step [{}/{}]'", ".", "format", "(", "epoch", ",", "self", ".", "max_epoch", ",", "step", ",", "\n", "self", ".", "num_batches", ")", "+", "' '", "+", "D_logs", "+", "' '", "+", "G_logs", ")", "\n", "# save images", "\n", "", "if", "gen_iterations", "%", "10000", "==", "0", ":", "\n", "                    ", "backup_para", "=", "copy_G_params", "(", "netG", ")", "\n", "load_params", "(", "netG", ",", "avg_param_G", ")", "\n", "\n", "load_params", "(", "netG", ",", "backup_para", ")", "\n", "\n", "", "", "end_t", "=", "time", ".", "time", "(", ")", "\n", "\n", "print", "(", "'''[%d/%d] Loss_D: %.2f Loss_G: %.2f Time: %.2fs'''", "%", "(", "\n", "epoch", ",", "self", ".", "max_epoch", ",", "errD_total", ".", "item", "(", ")", ",", "errG_total", ".", "item", "(", ")", ",", "end_t", "-", "start_t", ")", ")", "\n", "print", "(", "'-'", "*", "89", ")", "\n", "if", "epoch", "%", "cfg", ".", "TRAIN", ".", "SNAPSHOT_INTERVAL", "==", "0", ":", "# and epoch != 0:", "\n", "                ", "self", ".", "save_model", "(", "netG", ",", "avg_param_G", ",", "netsD", ",", "epoch", ")", "\n", "\n", "", "", "self", ".", "save_model", "(", "netG", ",", "avg_param_G", ",", "netsD", ",", "self", ".", "max_epoch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.save_singleimages": [[328, 346], ["six.moves.range", "images.size", "images[].add().div().mul().clamp().byte", "images[].add().div().mul().clamp().byte.permute().data.cpu().numpy", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "os.path.isdir", "print", "miscc.utils.mkdir_p", "s_tmp.rfind", "images[].add().div().mul().clamp", "images[].add().div().mul().clamp().byte.permute().data.cpu", "images[].add().div().mul", "images[].add().div().mul().clamp().byte.permute", "images[].add().div", "images[].add"], "methods", ["None"], ["", "def", "save_singleimages", "(", "self", ",", "images", ",", "filenames", ",", "save_dir", ",", "\n", "split_dir", ",", "sentenceID", "=", "0", ")", ":", "\n", "        ", "for", "i", "in", "range", "(", "images", ".", "size", "(", "0", ")", ")", ":", "\n", "            ", "s_tmp", "=", "'%s/single_samples/%s/%s'", "%", "(", "save_dir", ",", "split_dir", ",", "filenames", "[", "i", "]", ")", "\n", "folder", "=", "s_tmp", "[", ":", "s_tmp", ".", "rfind", "(", "'/'", ")", "]", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "folder", ")", ":", "\n", "                ", "print", "(", "'Make a new folder: '", ",", "folder", ")", "\n", "mkdir_p", "(", "folder", ")", "\n", "\n", "", "fullpath", "=", "'%s_%d.jpg'", "%", "(", "s_tmp", ",", "sentenceID", ")", "\n", "# range from [-1, 1] to [0, 1]", "\n", "# img = (images[i] + 1.0) / 2", "\n", "img", "=", "images", "[", "i", "]", ".", "add", "(", "1", ")", ".", "div", "(", "2", ")", ".", "mul", "(", "255", ")", ".", "clamp", "(", "0", ",", "255", ")", ".", "byte", "(", ")", "\n", "# range from [0, 1] to [0, 255]", "\n", "ndarr", "=", "img", ".", "permute", "(", "1", ",", "2", ",", "0", ")", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "im", "=", "Image", ".", "fromarray", "(", "ndarr", ")", "\n", "im", ".", "save", "(", "fullpath", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.trainer.condGANTrainer.sampling": [[347, 439], ["print", "model.G_NET.apply", "model.G_NET.cuda", "model.G_NET.eval", "model.RNN_ENCODER", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "text_encoder.cuda.cuda.load_state_dict", "print", "text_encoder.cuda.cuda.cuda", "text_encoder.cuda.cuda.eval", "model.CNN_ENCODER", "miscc.config.cfg.TRAIN.NET_E.replace", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "image_encoder.cuda.cuda.load_state_dict", "print", "image_encoder.cuda.cuda.cuda", "image_encoder.cuda.cuda.eval", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "noise.cuda.cuda.cuda", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "torch.load", "model.G_NET.load_state_dict", "print", "miscc.utils.mkdir_p", "numpy.zeros", "six.moves.range", "model.G_DCGAN", "model.G_NET", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "enumerate", "model_dir.rfind", "datasets.prepare_data", "text_encoder.cuda.cuda.init_hidden", "text_encoder.cuda.cuda.", "words_embs.size", "noise.cuda.cuda.data.normal_", "model.G_NET.", "six.moves.range", "print", "words_embs.detach", "sent_emb.detach", "mask.size", "[].data.cpu().numpy", "PIL.Image.fromarray.astype", "numpy.transpose", "PIL.Image.fromarray", "PIL.Image.fromarray.save", "os.path.isdir", "miscc.utils.mkdir_p", "s_tmp.rfind", "[].data.cpu"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.prepare_data", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.init_hidden"], ["", "", "def", "sampling", "(", "self", ",", "split_dir", ")", ":", "\n", "        ", "if", "cfg", ".", "TRAIN", ".", "NET_G", "==", "''", ":", "\n", "            ", "print", "(", "'Error: the path for morels is not found!'", ")", "\n", "", "else", ":", "\n", "            ", "if", "split_dir", "==", "'test'", ":", "\n", "                ", "split_dir", "=", "'valid'", "\n", "# Build and load the generator", "\n", "", "if", "cfg", ".", "GAN", ".", "B_DCGAN", ":", "\n", "                ", "netG", "=", "G_DCGAN", "(", ")", "\n", "", "else", ":", "\n", "                ", "netG", "=", "G_NET", "(", ")", "\n", "", "netG", ".", "apply", "(", "weights_init", ")", "\n", "netG", ".", "cuda", "(", ")", "\n", "netG", ".", "eval", "(", ")", "\n", "\n", "# load text encoder", "\n", "text_encoder", "=", "RNN_ENCODER", "(", "self", ".", "n_words", ",", "nhidden", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "cfg", ".", "TRAIN", ".", "NET_E", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "text_encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "print", "(", "'Load text encoder from:'", ",", "cfg", ".", "TRAIN", ".", "NET_E", ")", "\n", "text_encoder", "=", "text_encoder", ".", "cuda", "(", ")", "\n", "text_encoder", ".", "eval", "(", ")", "\n", "\n", "#load image encoder", "\n", "image_encoder", "=", "CNN_ENCODER", "(", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", ")", "\n", "img_encoder_path", "=", "cfg", ".", "TRAIN", ".", "NET_E", ".", "replace", "(", "'text_encoder'", ",", "'image_encoder'", ")", "\n", "state_dict", "=", "torch", ".", "load", "(", "img_encoder_path", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "image_encoder", ".", "load_state_dict", "(", "state_dict", ")", "\n", "print", "(", "'Load image encoder from:'", ",", "img_encoder_path", ")", "\n", "image_encoder", "=", "image_encoder", ".", "cuda", "(", ")", "\n", "image_encoder", ".", "eval", "(", ")", "\n", "\n", "batch_size", "=", "self", ".", "batch_size", "\n", "nz", "=", "cfg", ".", "GAN", ".", "Z_DIM", "\n", "noise", "=", "Variable", "(", "torch", ".", "FloatTensor", "(", "batch_size", ",", "nz", ")", ",", "volatile", "=", "True", ")", "\n", "noise", "=", "noise", ".", "cuda", "(", ")", "\n", "\n", "model_dir", "=", "cfg", ".", "TRAIN", ".", "NET_G", "\n", "state_dict", "=", "torch", ".", "load", "(", "model_dir", ",", "map_location", "=", "lambda", "storage", ",", "loc", ":", "storage", ")", "\n", "# state_dict = torch.load(cfg.TRAIN.NET_G)", "\n", "netG", ".", "load_state_dict", "(", "state_dict", ")", "\n", "print", "(", "'Load G from: '", ",", "model_dir", ")", "\n", "\n", "# the path to save generated images", "\n", "s_tmp", "=", "model_dir", "[", ":", "model_dir", ".", "rfind", "(", "'.pth'", ")", "]", "\n", "save_dir", "=", "'%s/%s'", "%", "(", "s_tmp", ",", "split_dir", ")", "\n", "mkdir_p", "(", "save_dir", ")", "\n", "\n", "cnt", "=", "0", "\n", "R_count", "=", "0", "\n", "R", "=", "np", ".", "zeros", "(", "30000", ")", "\n", "cont", "=", "True", "\n", "for", "ii", "in", "range", "(", "1", ")", ":", "# (cfg.TEXT.CAPTIONS_PER_IMAGE):", "\n", "                ", "if", "(", "cont", "==", "False", ")", ":", "\n", "                    ", "break", "\n", "", "for", "step", ",", "data", "in", "enumerate", "(", "self", ".", "data_loader", ",", "0", ")", ":", "\n", "                    ", "cnt", "+=", "batch_size", "\n", "if", "(", "cont", "==", "False", ")", ":", "\n", "                        ", "break", "\n", "", "if", "step", "%", "100", "==", "0", ":", "\n", "                       ", "print", "(", "'cnt: '", ",", "cnt", ")", "\n", "\n", "", "imgs", ",", "captions", ",", "cap_lens", ",", "class_ids", ",", "keys", "=", "prepare_data", "(", "data", ")", "\n", "\n", "hidden", "=", "text_encoder", ".", "init_hidden", "(", "batch_size", ")", "\n", "words_embs", ",", "sent_emb", "=", "text_encoder", "(", "captions", ",", "cap_lens", ",", "hidden", ")", "\n", "words_embs", ",", "sent_emb", "=", "words_embs", ".", "detach", "(", ")", ",", "sent_emb", ".", "detach", "(", ")", "\n", "mask", "=", "(", "captions", "==", "0", ")", "\n", "num_words", "=", "words_embs", ".", "size", "(", "2", ")", "\n", "if", "mask", ".", "size", "(", "1", ")", ">", "num_words", ":", "\n", "                        ", "mask", "=", "mask", "[", ":", ",", ":", "num_words", "]", "\n", "", "noise", ".", "data", ".", "normal_", "(", "0", ",", "1", ")", "\n", "fake_imgs", ",", "_", ",", "_", ",", "_", ",", "_", ",", "I_P", ",", "I_star", "=", "netG", "(", "noise", ",", "sent_emb", ",", "words_embs", ",", "mask", ",", "imgs", ")", "\n", "for", "j", "in", "range", "(", "batch_size", ")", ":", "\n", "                        ", "s_tmp", "=", "'%s/single/%s'", "%", "(", "save_dir", ",", "keys", "[", "j", "]", ")", "\n", "folder", "=", "s_tmp", "[", ":", "s_tmp", ".", "rfind", "(", "'/'", ")", "]", "\n", "if", "not", "os", ".", "path", ".", "isdir", "(", "folder", ")", ":", "\n", "#print('Make a new folder: ', folder)", "\n", "                            ", "mkdir_p", "(", "folder", ")", "\n", "", "k", "=", "-", "1", "\n", "# for k in range(len(fake_imgs)):", "\n", "im", "=", "fake_imgs", "[", "k", "]", "[", "j", "]", ".", "data", ".", "cpu", "(", ")", ".", "numpy", "(", ")", "\n", "# [-1, 1] --> [0, 255]", "\n", "im", "=", "(", "im", "+", "1.0", ")", "*", "127.5", "\n", "im", "=", "im", ".", "astype", "(", "np", ".", "uint8", ")", "\n", "im", "=", "np", ".", "transpose", "(", "im", ",", "(", "1", ",", "2", ",", "0", ")", ")", "\n", "im", "=", "Image", ".", "fromarray", "(", "im", ")", "\n", "fullpath", "=", "'%s_s%d_%d.png'", "%", "(", "s_tmp", ",", "k", ",", "ii", ")", "\n", "im", ".", "save", "(", "fullpath", ")", "\n", "\n", "", "if", "cnt", ">=", "30000", ":", "\n", "                        ", "cont", "=", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.GLU.__init__": [[17, 19], ["torch.Module.__init__"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "GLU", ",", "self", ")", ".", "__init__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.GLU.forward": [[20, 25], ["x.size", "int", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "nc", "=", "x", ".", "size", "(", "1", ")", "\n", "assert", "nc", "%", "2", "==", "0", ",", "'channels dont divide 2!'", "\n", "nc", "=", "int", "(", "nc", "/", "2", ")", "\n", "return", "x", "[", ":", ",", ":", "nc", "]", "*", "F", ".", "sigmoid", "(", "x", "[", ":", ",", "nc", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.ResBlock.__init__": [[57, 65], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "model.GLU", "model.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "channel_num", ")", ":", "\n", "        ", "super", "(", "ResBlock", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "block", "=", "nn", ".", "Sequential", "(", "\n", "conv3x3", "(", "channel_num", ",", "channel_num", "*", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "channel_num", "*", "2", ")", ",", "\n", "GLU", "(", ")", ",", "\n", "conv3x3", "(", "channel_num", ",", "channel_num", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "channel_num", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.ResBlock.forward": [[66, 71], ["model.ResBlock.block"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "residual", "=", "x", "\n", "out", "=", "self", ".", "block", "(", "x", ")", "\n", "out", "+=", "residual", "\n", "return", "out", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.__init__": [[75, 94], ["torch.Module.__init__", "model.RNN_ENCODER.define_module", "model.RNN_ENCODER.init_weights"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.define_module", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.init_weights"], ["    ", "def", "__init__", "(", "self", ",", "ntoken", ",", "ninput", "=", "300", ",", "drop_prob", "=", "0.5", ",", "\n", "nhidden", "=", "128", ",", "nlayers", "=", "1", ",", "bidirectional", "=", "True", ")", ":", "\n", "        ", "super", "(", "RNN_ENCODER", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "n_steps", "=", "cfg", ".", "TEXT", ".", "WORDS_NUM", "\n", "self", ".", "ntoken", "=", "ntoken", "# size of the dictionary", "\n", "self", ".", "ninput", "=", "ninput", "# size of each embedding vector", "\n", "self", ".", "drop_prob", "=", "drop_prob", "# probability of an element to be zeroed", "\n", "self", ".", "nlayers", "=", "nlayers", "# Number of recurrent layers", "\n", "self", ".", "bidirectional", "=", "bidirectional", "\n", "self", ".", "rnn_type", "=", "cfg", ".", "RNN_TYPE", "\n", "if", "bidirectional", ":", "\n", "            ", "self", ".", "num_directions", "=", "2", "\n", "", "else", ":", "\n", "            ", "self", ".", "num_directions", "=", "1", "\n", "# number of features in the hidden state", "\n", "", "self", ".", "nhidden", "=", "nhidden", "//", "self", ".", "num_directions", "\n", "\n", "self", ".", "define_module", "(", ")", "\n", "self", ".", "init_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.define_module": [[95, 112], ["torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Embedding", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.Dropout", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.LSTM", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU", "torch.GRU"], "methods", ["None"], ["", "def", "define_module", "(", "self", ")", ":", "\n", "        ", "self", ".", "encoder", "=", "nn", ".", "Embedding", "(", "self", ".", "ntoken", ",", "self", ".", "ninput", ")", "\n", "self", ".", "drop", "=", "nn", ".", "Dropout", "(", "self", ".", "drop_prob", ")", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "# dropout: If non-zero, introduces a dropout layer on", "\n", "# the outputs of each RNN layer except the last layer", "\n", "            ", "self", ".", "rnn", "=", "nn", ".", "LSTM", "(", "self", ".", "ninput", ",", "self", ".", "nhidden", ",", "\n", "self", ".", "nlayers", ",", "batch_first", "=", "True", ",", "\n", "dropout", "=", "self", ".", "drop_prob", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ")", "\n", "", "elif", "self", ".", "rnn_type", "==", "'GRU'", ":", "\n", "            ", "self", ".", "rnn", "=", "nn", ".", "GRU", "(", "self", ".", "ninput", ",", "self", ".", "nhidden", ",", "\n", "self", ".", "nlayers", ",", "batch_first", "=", "True", ",", "\n", "dropout", "=", "self", ".", "drop_prob", ",", "\n", "bidirectional", "=", "self", ".", "bidirectional", ")", "\n", "", "else", ":", "\n", "            ", "raise", "NotImplementedError", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.init_weights": [[113, 116], ["model.RNN_ENCODER.encoder.weight.data.uniform_"], "methods", ["None"], ["", "", "def", "init_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "encoder", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "# Do not need to initialize RNN parameters, which have been initialized", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.init_hidden": [[121, 128], ["next", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "model.RNN_ENCODER.parameters", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "weight.new().zero_", "weight.new().zero_", "weight.new().zero_", "weight.new", "weight.new", "weight.new"], "methods", ["None"], ["", "def", "init_hidden", "(", "self", ",", "bsz", ")", ":", "\n", "        ", "weight", "=", "next", "(", "self", ".", "parameters", "(", ")", ")", ".", "data", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "return", "(", "Variable", "(", "weight", ".", "new", "(", "self", ".", "nlayers", "*", "self", ".", "num_directions", ",", "bsz", ",", "self", ".", "nhidden", ")", ".", "zero_", "(", ")", ")", ",", "\n", "Variable", "(", "weight", ".", "new", "(", "self", ".", "nlayers", "*", "self", ".", "num_directions", ",", "bsz", ",", "self", ".", "nhidden", ")", ".", "zero_", "(", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "return", "Variable", "(", "weight", ".", "new", "(", "self", ".", "nlayers", "*", "self", ".", "num_directions", ",", "bsz", ",", "self", ".", "nhidden", ")", ".", "zero_", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.RNN_ENCODER.forward": [[129, 156], ["model.RNN_ENCODER.drop", "cap_lens.data.tolist.data.tolist.data.tolist", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "torch.nn.utils.rnn.pack_padded_sequence", "model.RNN_ENCODER.rnn", "output.transpose", "hidden.transpose().contiguous.view", "model.RNN_ENCODER.encoder", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "torch.nn.utils.rnn.pad_packed_sequence", "hidden[].transpose().contiguous", "hidden.transpose().contiguous", "hidden[].transpose", "hidden.transpose"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "captions", ",", "cap_lens", ",", "hidden", ",", "mask", "=", "None", ")", ":", "\n", "# input: torch.LongTensor of size batch x n_steps", "\n", "# --> emb: batch x n_steps x ninput", "\n", "        ", "emb", "=", "self", ".", "drop", "(", "self", ".", "encoder", "(", "captions", ")", ")", "\n", "#", "\n", "# Returns: a PackedSequence object", "\n", "cap_lens", "=", "cap_lens", ".", "data", ".", "tolist", "(", ")", "\n", "emb", "=", "pack_padded_sequence", "(", "emb", ",", "cap_lens", ",", "batch_first", "=", "True", ")", "\n", "# #hidden and memory (num_layers * num_directions, batch, hidden_size):", "\n", "# tensor containing the initial hidden state for each element in batch.", "\n", "# #output (batch, seq_len, hidden_size * num_directions)", "\n", "# #or a PackedSequence object:", "\n", "# tensor containing output features (h_t) from the last layer of RNN", "\n", "output", ",", "hidden", "=", "self", ".", "rnn", "(", "emb", ",", "hidden", ")", "\n", "# PackedSequence object", "\n", "# --> (batch, seq_len, hidden_size * num_directions)", "\n", "output", "=", "pad_packed_sequence", "(", "output", ",", "batch_first", "=", "True", ")", "[", "0", "]", "\n", "# output = self.drop(output)", "\n", "# --> batch x hidden_size*num_directions x seq_len", "\n", "words_emb", "=", "output", ".", "transpose", "(", "1", ",", "2", ")", "\n", "# --> batch x num_directions*hidden_size", "\n", "if", "self", ".", "rnn_type", "==", "'LSTM'", ":", "\n", "            ", "sent_emb", "=", "hidden", "[", "0", "]", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "else", ":", "\n", "            ", "sent_emb", "=", "hidden", ".", "transpose", "(", "0", ",", "1", ")", ".", "contiguous", "(", ")", "\n", "", "sent_emb", "=", "sent_emb", ".", "view", "(", "-", "1", ",", "self", ".", "nhidden", "*", "self", ".", "num_directions", ")", "\n", "return", "words_emb", ",", "sent_emb", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CNN_ENCODER.__init__": [[159, 176], ["torch.Module.__init__", "torchvision.models.inception_v3", "torchvision.models.inception_v3.load_state_dict", "torchvision.models.inception_v3.parameters", "print", "models.inception_v3.CNN_ENCODER.define_module", "models.inception_v3.CNN_ENCODER.init_trainable_weights", "torch.load_url", "torch.load_url", "torch.load_url", "torch.load_url", "torch.load_url"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.define_module", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CNN_ENCODER.init_trainable_weights"], ["    ", "def", "__init__", "(", "self", ",", "nef", ")", ":", "\n", "        ", "super", "(", "CNN_ENCODER", ",", "self", ")", ".", "__init__", "(", ")", "\n", "if", "cfg", ".", "TRAIN", ".", "FLAG", ":", "\n", "            ", "self", ".", "nef", "=", "nef", "\n", "", "else", ":", "\n", "            ", "self", ".", "nef", "=", "256", "# define a uniform ranker", "\n", "\n", "", "model", "=", "models", ".", "inception_v3", "(", ")", "\n", "url", "=", "'https://download.pytorch.org/models/inception_v3_google-1a9a5a14.pth'", "\n", "model", ".", "load_state_dict", "(", "model_zoo", ".", "load_url", "(", "url", ")", ")", "\n", "for", "param", "in", "model", ".", "parameters", "(", ")", ":", "\n", "            ", "param", ".", "requires_grad", "=", "False", "\n", "", "print", "(", "'Load pretrained model from '", ",", "url", ")", "\n", "# print(model)", "\n", "\n", "self", ".", "define_module", "(", "model", ")", "\n", "self", ".", "init_trainable_weights", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CNN_ENCODER.define_module": [[177, 197], ["model.conv1x1", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv1x1"], ["", "def", "define_module", "(", "self", ",", "model", ")", ":", "\n", "        ", "self", ".", "Conv2d_1a_3x3", "=", "model", ".", "Conv2d_1a_3x3", "\n", "self", ".", "Conv2d_2a_3x3", "=", "model", ".", "Conv2d_2a_3x3", "\n", "self", ".", "Conv2d_2b_3x3", "=", "model", ".", "Conv2d_2b_3x3", "\n", "self", ".", "Conv2d_3b_1x1", "=", "model", ".", "Conv2d_3b_1x1", "\n", "self", ".", "Conv2d_4a_3x3", "=", "model", ".", "Conv2d_4a_3x3", "\n", "self", ".", "Mixed_5b", "=", "model", ".", "Mixed_5b", "\n", "self", ".", "Mixed_5c", "=", "model", ".", "Mixed_5c", "\n", "self", ".", "Mixed_5d", "=", "model", ".", "Mixed_5d", "\n", "self", ".", "Mixed_6a", "=", "model", ".", "Mixed_6a", "\n", "self", ".", "Mixed_6b", "=", "model", ".", "Mixed_6b", "\n", "self", ".", "Mixed_6c", "=", "model", ".", "Mixed_6c", "\n", "self", ".", "Mixed_6d", "=", "model", ".", "Mixed_6d", "\n", "self", ".", "Mixed_6e", "=", "model", ".", "Mixed_6e", "\n", "self", ".", "Mixed_7a", "=", "model", ".", "Mixed_7a", "\n", "self", ".", "Mixed_7b", "=", "model", ".", "Mixed_7b", "\n", "self", ".", "Mixed_7c", "=", "model", ".", "Mixed_7c", "\n", "\n", "self", ".", "emb_features", "=", "conv1x1", "(", "768", ",", "self", ".", "nef", ")", "\n", "self", ".", "emb_cnn_code", "=", "nn", ".", "Linear", "(", "2048", ",", "self", ".", "nef", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CNN_ENCODER.init_trainable_weights": [[198, 202], ["model.CNN_ENCODER.emb_features.weight.data.uniform_", "model.CNN_ENCODER.emb_cnn_code.weight.data.uniform_"], "methods", ["None"], ["", "def", "init_trainable_weights", "(", "self", ")", ":", "\n", "        ", "initrange", "=", "0.1", "\n", "self", ".", "emb_features", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "self", ".", "emb_cnn_code", ".", "weight", ".", "data", ".", "uniform_", "(", "-", "initrange", ",", "initrange", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CNN_ENCODER.forward": [[203, 264], ["model.CNN_ENCODER.Conv2d_1a_3x3", "model.CNN_ENCODER.Conv2d_2a_3x3", "model.CNN_ENCODER.Conv2d_2b_3x3", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "model.CNN_ENCODER.Conv2d_3b_1x1", "model.CNN_ENCODER.Conv2d_4a_3x3", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "torch.max_pool2d", "model.CNN_ENCODER.Mixed_5b", "model.CNN_ENCODER.Mixed_5c", "model.CNN_ENCODER.Mixed_5d", "model.CNN_ENCODER.Mixed_6a", "model.CNN_ENCODER.Mixed_6b", "model.CNN_ENCODER.Mixed_6c", "model.CNN_ENCODER.Mixed_6d", "model.CNN_ENCODER.Mixed_6e", "model.CNN_ENCODER.Mixed_7a", "model.CNN_ENCODER.Mixed_7b", "model.CNN_ENCODER.Mixed_7c", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "torch.avg_pool2d", "x.view.view.view", "model.CNN_ENCODER.emb_cnn_code", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "torch.Upsample", "x.view.view.size", "model.CNN_ENCODER.emb_features"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x", ")", ":", "\n", "        ", "features", "=", "None", "\n", "# --> fixed-size input: batch x 3 x 299 x 299", "\n", "x", "=", "nn", ".", "Upsample", "(", "size", "=", "(", "299", ",", "299", ")", ",", "mode", "=", "'bilinear'", ",", "align_corners", "=", "True", ")", "(", "x", ")", "\n", "# 299 x 299 x 3", "\n", "x", "=", "self", ".", "Conv2d_1a_3x3", "(", "x", ")", "\n", "# 149 x 149 x 32", "\n", "x", "=", "self", ".", "Conv2d_2a_3x3", "(", "x", ")", "\n", "# 147 x 147 x 32", "\n", "x", "=", "self", ".", "Conv2d_2b_3x3", "(", "x", ")", "\n", "# 147 x 147 x 64", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "# 73 x 73 x 64", "\n", "x", "=", "self", ".", "Conv2d_3b_1x1", "(", "x", ")", "\n", "# 73 x 73 x 80", "\n", "x", "=", "self", ".", "Conv2d_4a_3x3", "(", "x", ")", "\n", "# 71 x 71 x 192", "\n", "\n", "x", "=", "F", ".", "max_pool2d", "(", "x", ",", "kernel_size", "=", "3", ",", "stride", "=", "2", ")", "\n", "# 35 x 35 x 192", "\n", "x", "=", "self", ".", "Mixed_5b", "(", "x", ")", "\n", "# 35 x 35 x 256", "\n", "x", "=", "self", ".", "Mixed_5c", "(", "x", ")", "\n", "# 35 x 35 x 288", "\n", "x", "=", "self", ".", "Mixed_5d", "(", "x", ")", "\n", "# 35 x 35 x 288", "\n", "\n", "x", "=", "self", ".", "Mixed_6a", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "Mixed_6b", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "Mixed_6c", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "Mixed_6d", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "x", "=", "self", ".", "Mixed_6e", "(", "x", ")", "\n", "# 17 x 17 x 768", "\n", "\n", "# image region features", "\n", "features", "=", "x", "\n", "# 17 x 17 x 768", "\n", "\n", "x", "=", "self", ".", "Mixed_7a", "(", "x", ")", "\n", "# 8 x 8 x 1280", "\n", "x", "=", "self", ".", "Mixed_7b", "(", "x", ")", "\n", "# 8 x 8 x 2048", "\n", "x", "=", "self", ".", "Mixed_7c", "(", "x", ")", "\n", "# 8 x 8 x 2048", "\n", "x", "=", "F", ".", "avg_pool2d", "(", "x", ",", "kernel_size", "=", "8", ")", "\n", "# 1 x 1 x 2048", "\n", "# x = F.dropout(x, training=self.training)", "\n", "# 1 x 1 x 2048", "\n", "x", "=", "x", ".", "view", "(", "x", ".", "size", "(", "0", ")", ",", "-", "1", ")", "\n", "# 2048", "\n", "\n", "# global image features", "\n", "cnn_code", "=", "self", ".", "emb_cnn_code", "(", "x", ")", "\n", "# 512", "\n", "if", "features", "is", "not", "None", ":", "\n", "            ", "features", "=", "self", ".", "emb_features", "(", "features", ")", "\n", "", "return", "features", ",", "cnn_code", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.__init__": [[270, 276], ["torch.Module.__init__", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "model.GLU"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "CA_NET", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "t_dim", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "self", ".", "c_dim", "=", "cfg", ".", "GAN", ".", "CONDITION_DIM", "\n", "self", ".", "fc", "=", "nn", ".", "Linear", "(", "self", ".", "t_dim", ",", "self", ".", "c_dim", "*", "4", ",", "bias", "=", "True", ")", "\n", "self", ".", "relu", "=", "GLU", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.encode": [[277, 282], ["model.CA_NET.relu", "model.CA_NET.fc"], "methods", ["None"], ["", "def", "encode", "(", "self", ",", "text_embedding", ")", ":", "\n", "        ", "x", "=", "self", ".", "relu", "(", "self", ".", "fc", "(", "text_embedding", ")", ")", "\n", "mu", "=", "x", "[", ":", ",", ":", "self", ".", "c_dim", "]", "\n", "logvar", "=", "x", "[", ":", ",", "self", ".", "c_dim", ":", "]", "\n", "return", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.reparametrize": [[283, 291], ["logvar.mul().exp_", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.FloatTensor().normal_.mul().add_", "torch.FloatTensor().normal_.mul().add_", "torch.FloatTensor().normal_.mul().add_", "torch.FloatTensor().normal_.mul().add_", "torch.FloatTensor().normal_.mul().add_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.cuda.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "torch.FloatTensor().normal_", "logvar.mul", "torch.FloatTensor().normal_.mul", "torch.FloatTensor().normal_.mul", "torch.FloatTensor().normal_.mul", "torch.FloatTensor().normal_.mul", "torch.FloatTensor().normal_.mul", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.cuda.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "torch.FloatTensor", "logvar.mul().exp_.size", "logvar.mul().exp_.size"], "methods", ["None"], ["", "def", "reparametrize", "(", "self", ",", "mu", ",", "logvar", ")", ":", "\n", "        ", "std", "=", "logvar", ".", "mul", "(", "0.5", ")", ".", "exp_", "(", ")", "\n", "if", "cfg", ".", "CUDA", ":", "\n", "            ", "eps", "=", "torch", ".", "cuda", ".", "FloatTensor", "(", "std", ".", "size", "(", ")", ")", ".", "normal_", "(", ")", "\n", "", "else", ":", "\n", "            ", "eps", "=", "torch", ".", "FloatTensor", "(", "std", ".", "size", "(", ")", ")", ".", "normal_", "(", ")", "\n", "", "eps", "=", "Variable", "(", "eps", ")", "\n", "return", "eps", ".", "mul", "(", "std", ")", ".", "add_", "(", "mu", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.forward": [[292, 297], ["model.CA_NET.encode", "model.CA_NET.reparametrize"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.encode", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.reparametrize"], ["", "def", "forward", "(", "self", ",", "text_embedding", ")", ":", "\n", "        ", "mu", ",", "logvar", "=", "self", ".", "encode", "(", "text_embedding", ")", "\n", "c_code", "=", "self", ".", "reparametrize", "(", "mu", ",", "logvar", ")", "\n", "# print(mu.shape)", "\n", "return", "c_code", ",", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.INIT_STAGE_G.__init__": [[300, 306], ["torch.Module.__init__", "model.INIT_STAGE_G.define_module"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.define_module"], ["    ", "def", "__init__", "(", "self", ",", "ngf", ",", "ncf", ")", ":", "\n", "        ", "super", "(", "INIT_STAGE_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gf_dim", "=", "ngf", "\n", "self", ".", "in_dim", "=", "cfg", ".", "GAN", ".", "Z_DIM", "+", "ncf", "# cfg.TEXT.EMBEDDING_DIM", "\n", "\n", "self", ".", "define_module", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.INIT_STAGE_G.define_module": [[307, 318], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.upBlock", "model.upBlock", "model.upBlock", "model.upBlock", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "model.GLU"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock"], ["", "def", "define_module", "(", "self", ")", ":", "\n", "        ", "nz", ",", "ngf", "=", "self", ".", "in_dim", ",", "self", ".", "gf_dim", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "nz", ",", "ngf", "*", "4", "*", "4", "*", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "ngf", "*", "4", "*", "4", "*", "2", ")", ",", "\n", "GLU", "(", ")", ")", "\n", "\n", "self", ".", "upsample1", "=", "upBlock", "(", "ngf", ",", "ngf", "//", "2", ")", "\n", "self", ".", "upsample2", "=", "upBlock", "(", "ngf", "//", "2", ",", "ngf", "//", "4", ")", "\n", "self", ".", "upsample3", "=", "upBlock", "(", "ngf", "//", "4", ",", "ngf", "//", "8", ")", "\n", "self", ".", "upsample4", "=", "upBlock", "(", "ngf", "//", "8", ",", "ngf", "//", "16", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.INIT_STAGE_G.forward": [[319, 339], ["torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.INIT_STAGE_G.fc", "model.INIT_STAGE_G.view", "model.INIT_STAGE_G.upsample1", "model.INIT_STAGE_G.upsample2", "model.INIT_STAGE_G.upsample3", "model.INIT_STAGE_G.upsample4"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z_code", ",", "c_code", ")", ":", "\n", "        ", "\"\"\"\n        :param z_code: batch x cfg.GAN.Z_DIM\n        :param c_code: batch x cfg.TEXT.EMBEDDING_DIM\n        :return: batch x ngf/16 x 64 x 64\n        \"\"\"", "\n", "c_z_code", "=", "torch", ".", "cat", "(", "(", "c_code", ",", "z_code", ")", ",", "1", ")", "\n", "# state size ngf x 4 x 4", "\n", "out_code", "=", "self", ".", "fc", "(", "c_z_code", ")", "\n", "out_code", "=", "out_code", ".", "view", "(", "-", "1", ",", "self", ".", "gf_dim", ",", "4", ",", "4", ")", "\n", "# state size ngf/3 x 8 x 8", "\n", "out_code", "=", "self", ".", "upsample1", "(", "out_code", ")", "\n", "# state size ngf/4 x 16 x 16", "\n", "out_code", "=", "self", ".", "upsample2", "(", "out_code", ")", "\n", "# state size ngf/8 x 32 x 32", "\n", "out_code32", "=", "self", ".", "upsample3", "(", "out_code", ")", "\n", "# state size ngf/16 x 64 x 64", "\n", "out_code64", "=", "self", ".", "upsample4", "(", "out_code32", ")", "\n", "\n", "return", "out_code64", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.NEXT_STAGE_G.__init__": [[439, 472], ["torch.Module.__init__", "model.NEXT_STAGE_G.define_module", "model.encode_non_local", "model.encode_non_local2", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "copy.deepcopy", "model.NEXT_STAGE_G.global_reduction.apply", "model.encode_image_by_2timesxx", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.Softmax", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "copy.deepcopy", "model.NEXT_STAGE_G.global_reductionxx.apply", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.define_module", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_non_local", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_non_local2", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_2timesxx"], ["    ", "def", "__init__", "(", "self", ",", "ngf", ",", "nef", ",", "ncf", ")", ":", "\n", "        ", "super", "(", "NEXT_STAGE_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gf_dim", "=", "ngf", "\n", "self", ".", "ef_dim", "=", "nef", "\n", "self", ".", "cf_dim", "=", "ncf", "\n", "self", ".", "num_residual", "=", "cfg", ".", "GAN", ".", "R_NUM", "\n", "self", ".", "define_module", "(", ")", "\n", "self", ".", "reduct_demension", "=", "encode_non_local", "(", "64", ")", "\n", "self", ".", "reduct_demension2", "=", "encode_non_local2", "(", "64", ")", "\n", "reduction", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "\n", "self", ".", "global_reduction", "=", "copy", ".", "deepcopy", "(", "reduction", ")", "\n", "self", ".", "global_reduction", ".", "apply", "(", "weights_init_kaiming", ")", "\n", "self", ".", "img_code_sxx", "=", "encode_image_by_2timesxx", "(", "3", ")", "\n", "self", ".", "softmax", "=", "nn", ".", "Softmax", "(", "dim", "=", "1", ")", "\n", "\n", "self", ".", "global_avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "\n", "reductionxx", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "64", ",", "256", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "\n", "\n", "self", ".", "global_reductionxx", "=", "copy", ".", "deepcopy", "(", "reductionxx", ")", "\n", "self", ".", "global_reductionxx", ".", "apply", "(", "weights_init_kaiming", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.NEXT_STAGE_G._make_layer": [[474, 479], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "channel_num", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cfg", ".", "GAN", ".", "R_NUM", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "channel_num", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.NEXT_STAGE_G.define_module": [[480, 486], ["GlobalAttention.GlobalAttentionGeneral", "model.NEXT_STAGE_G._make_layer", "model.NEXT_STAGE_G._make_layer", "model.upBlock"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256._make_layer", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256._make_layer", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock"], ["", "def", "define_module", "(", "self", ")", ":", "\n", "        ", "ngf", "=", "self", ".", "gf_dim", "\n", "self", ".", "att", "=", "ATT_NET", "(", "ngf", ",", "self", ".", "ef_dim", ")", "\n", "self", ".", "residual", "=", "self", ".", "_make_layer", "(", "ResBlock", ",", "ngf", "*", "2", ")", "\n", "self", ".", "residual0", "=", "self", ".", "_make_layer", "(", "ResBlock", ",", "ngf", ")", "\n", "self", ".", "upsample", "=", "upBlock", "(", "ngf", "*", "2", ",", "ngf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.NEXT_STAGE_G.forward": [[487, 580], ["model.NEXT_STAGE_G.att.applyMask", "model.NEXT_STAGE_G.img_code_sxx", "model.NEXT_STAGE_G.att", "model.NEXT_STAGE_G.residual0", "model.NEXT_STAGE_G.mul", "h_code.mul", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.NEXT_STAGE_G.residual", "model.NEXT_STAGE_G.upsample", "model.NEXT_STAGE_G.global_reductionxx().squeeze", "model.NEXT_STAGE_G.global_reductionxx().squeeze", "model.NEXT_STAGE_G.global_reduction().squeeze", "model.NEXT_STAGE_G.global_reduction().squeeze", "model.NEXT_STAGE_G.global_reduction().squeeze", "model.NEXT_STAGE_G.global_reduction().squeeze", "model.NEXT_STAGE_G.global_reduction().squeeze", "vx11mean.unsqueeze().repeat", "rx11mean.unsqueeze().repeat", "vx12mean.unsqueeze().repeat", "rx12mean.unsqueeze().repeat", "imgsmean.unsqueeze().repeat", "model.NEXT_STAGE_G.reduct_demension", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "model.NEXT_STAGE_G.reduct_demension2", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sigmoid", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "pow", "pow", "pow", "pow", "pow", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.log", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "model.NEXT_STAGE_G.global_reductionxx", "model.NEXT_STAGE_G.global_reductionxx", "model.NEXT_STAGE_G.global_reduction", "model.NEXT_STAGE_G.global_reduction", "model.NEXT_STAGE_G.global_reduction", "model.NEXT_STAGE_G.global_reduction", "model.NEXT_STAGE_G.global_reduction", "pow", "pow", "pow", "pow", "vx11mean.unsqueeze", "rx11mean.unsqueeze", "vx12mean.unsqueeze", "rx12mean.unsqueeze", "imgsmean.unsqueeze", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "pow", "pow", "pow", "pow", "model.NEXT_STAGE_G.global_avgpool", "model.NEXT_STAGE_G.global_avgpool", "model.NEXT_STAGE_G.global_avgpool", "model.NEXT_STAGE_G.global_avgpool", "model.NEXT_STAGE_G.global_avgpool", "model.NEXT_STAGE_G.global_avgpool", "model.NEXT_STAGE_G.global_avgpool", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp", "torch.exp"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.GlobalAttention.GlobalAttentionGeneral.applyMask"], ["", "def", "forward", "(", "self", ",", "h_code", ",", "c_code", ",", "word_embs", ",", "mask", ",", "imgs", ",", "a", ",", "b", ",", "c", ",", "sent_emb", ")", ":", "\n", "\n", "\n", "\n", "        ", "thc", "=", "c", "\n", "batch_size", "=", "c_code", ".", "shape", "[", "0", "]", "\n", "self", ".", "att", ".", "applyMask", "(", "mask", ")", "\n", "imgs0", "=", "self", ".", "img_code_sxx", "(", "imgs", ")", "\n", "imgs", "=", "imgs0", "\n", "\n", "\n", "c_code0", ",", "att", "=", "self", ".", "att", "(", "h_code", ",", "word_embs", ")", "\n", "c_code1", "=", "self", ".", "residual0", "(", "c_code0", ")", "\n", "\n", "\n", "\n", "sita", "=", "c_code1", "\n", "sita", "=", "1.0", "/", "batch_size", "*", "self", ".", "reduct_demension", "(", "sita", ")", "\n", "x11", "=", "c_code1", ".", "mul", "(", "torch", ".", "sigmoid", "(", "sita", ")", ")", "\n", "r11", "=", "c_code1", "-", "x11", "\n", "\n", "\n", "\n", "\n", "sitaa", "=", "h_code", "\n", "sitaa", "=", "1.0", "/", "batch_size", "*", "self", ".", "reduct_demension2", "(", "sitaa", ")", "\n", "x12", "=", "h_code", ".", "mul", "(", "torch", ".", "sigmoid", "(", "sitaa", ")", ")", "\n", "r12", "=", "h_code", "-", "x12", "\n", "\n", "\n", "\n", "\n", "\n", "\n", "h_c_code", "=", "torch", ".", "cat", "(", "(", "x12", ",", "x11", ")", ",", "1", ")", "\n", "out_code", "=", "self", ".", "residual", "(", "h_c_code", ")", "\n", "out_code", "=", "self", ".", "upsample", "(", "out_code", ")", "\n", "\n", "\n", "\n", "\n", "I_P", "=", "self", ".", "global_reductionxx", "(", "self", ".", "global_avgpool", "(", "imgs", ")", ")", ".", "squeeze", "(", ")", "\n", "I_star", "=", "self", ".", "global_reductionxx", "(", "self", ".", "global_avgpool", "(", "out_code", ")", ")", ".", "squeeze", "(", ")", "\n", "\n", "\n", "\n", "vx11", "=", "self", ".", "global_reduction", "(", "self", ".", "global_avgpool", "(", "x11", ")", ")", ".", "squeeze", "(", ")", "\n", "rx11", "=", "self", ".", "global_reduction", "(", "self", ".", "global_avgpool", "(", "r11", ")", ")", ".", "squeeze", "(", ")", "\n", "vx12", "=", "self", ".", "global_reduction", "(", "self", ".", "global_avgpool", "(", "x12", ")", ")", ".", "squeeze", "(", ")", "\n", "rx12", "=", "self", ".", "global_reduction", "(", "self", ".", "global_avgpool", "(", "r12", ")", ")", ".", "squeeze", "(", ")", "\n", "imgs", "=", "self", ".", "global_reduction", "(", "self", ".", "global_avgpool", "(", "imgs", ")", ")", ".", "squeeze", "(", ")", "\n", "\n", "\n", "\n", "vx11mean", "=", "1.0", "/", "batch_size", "*", "torch", ".", "sum", "(", "vx11", ",", "0", ")", "\n", "rx11mean", "=", "1.0", "/", "batch_size", "*", "torch", ".", "sum", "(", "rx11", ",", "0", ")", "\n", "vx12mean", "=", "1.0", "/", "batch_size", "*", "torch", ".", "sum", "(", "vx12", ",", "0", ")", "\n", "rx12mean", "=", "1.0", "/", "batch_size", "*", "torch", ".", "sum", "(", "rx12", ",", "0", ")", "\n", "imgsmean", "=", "1.0", "/", "batch_size", "*", "torch", ".", "sum", "(", "imgs", ",", "0", ")", "\n", "\n", "\n", "vx11ap", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "vx11mean", "-", "imgsmean", ")", ",", "2.0", ")", ")", "\n", "rx11an", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "rx11mean", "-", "imgsmean", ")", ",", "2.0", ")", ")", "\n", "vx12ap", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "vx12mean", "-", "imgsmean", ")", ",", "2.0", ")", ")", "\n", "rx12an", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "rx12mean", "-", "imgsmean", ")", ",", "2.0", ")", ")", "\n", "\n", "loss1", "=", "torch", ".", "log", "(", "1.0", "+", "torch", ".", "exp", "(", "vx11ap", "-", "rx11an", ")", ")", "+", "torch", ".", "log", "(", "1.0", "+", "torch", ".", "exp", "(", "vx12ap", "-", "rx12an", ")", ")", "\n", "loss10", "=", "torch", ".", "exp", "(", "vx11ap", ")", "+", "torch", ".", "exp", "(", "vx12ap", ")", "\n", "\n", "\n", "vx11mean0", "=", "vx11mean", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "1", ")", "\n", "rx11mean0", "=", "rx11mean", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "1", ")", "\n", "vx12mean0", "=", "vx12mean", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "1", ")", "\n", "rx12mean0", "=", "rx12mean", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "1", ")", "\n", "imgsmean0", "=", "imgsmean", ".", "unsqueeze", "(", "0", ")", ".", "repeat", "(", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", ",", "1", ")", "\n", "\n", "\n", "vx11var", "=", "1.0", "/", "batch_size", "*", "pow", "(", "(", "torch", ".", "sum", "(", "vx11", "-", "vx11mean0", ",", "0", ")", ")", ",", "2.0", ")", "\n", "rx11var", "=", "1.0", "/", "batch_size", "*", "pow", "(", "(", "torch", ".", "sum", "(", "rx11", "-", "rx11mean0", ",", "0", ")", ")", ",", "2.0", ")", "\n", "vx12var", "=", "1.0", "/", "batch_size", "*", "pow", "(", "(", "torch", ".", "sum", "(", "vx12", "-", "vx12mean0", ",", "0", ")", ")", ",", "2.0", ")", "\n", "rx12var", "=", "1.0", "/", "batch_size", "*", "pow", "(", "(", "torch", ".", "sum", "(", "rx12", "-", "rx12mean0", ",", "0", ")", ")", ",", "2.0", ")", "\n", "imgsvar", "=", "1.0", "/", "batch_size", "*", "pow", "(", "(", "torch", ".", "sum", "(", "imgs", "-", "imgsmean0", ",", "0", ")", ")", ",", "2.0", ")", "\n", "\n", "vx11ap1", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "vx11var", "-", "imgsvar", ")", ",", "2.0", ")", ")", "\n", "rx11an1", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "rx11var", "-", "imgsvar", ")", ",", "2.0", ")", ")", "\n", "vx12ap1", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "vx12var", "-", "imgsvar", ")", ",", "2.0", ")", ")", "\n", "rx12an1", "=", "1.0", "/", "b", "*", "torch", ".", "sum", "(", "pow", "(", "(", "rx12var", "-", "imgsvar", ")", ",", "2.0", ")", ")", "\n", "\n", "loss2", "=", "torch", ".", "log", "(", "1.0", "+", "torch", ".", "exp", "(", "vx11ap1", "-", "rx11an1", ")", ")", "+", "torch", ".", "log", "(", "1.0", "+", "torch", ".", "exp", "(", "vx12ap1", "-", "rx12an1", ")", ")", "\n", "loss20", "=", "torch", ".", "exp", "(", "vx11ap1", ")", "+", "torch", ".", "exp", "(", "vx12ap1", ")", "\n", "\n", "\n", "return", "out_code", ",", "att", ",", "loss2", "+", "loss1", "+", "loss10", "+", "loss20", ",", "I_P", ",", "I_star", ",", "imgs0", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.GET_IMAGE_G1.__init__": [[592, 598], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.conv3x3", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "ngf", ")", ":", "\n", "        ", "super", "(", "GET_IMAGE_G1", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gf_dim", "=", "ngf", "\n", "self", ".", "img", "=", "nn", ".", "Sequential", "(", "\n", "conv3x3", "(", "ngf", ",", "3", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.GET_IMAGE_G1.forward": [[600, 605], ["model.GET_IMAGE_G1.img"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h_code", ")", ":", "\n", "        ", "out_img", "=", "self", ".", "img", "(", "h_code", ")", "\n", "#print(h_code.shape)", "\n", "#print(out_img.shape)", "\n", "return", "out_img", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.GET_IMAGE_G.__init__": [[610, 622], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "model.conv3x3", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "model.conv3x3", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh", "torch.Tanh"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3"], ["    ", "def", "__init__", "(", "self", ",", "ngf", ")", ":", "\n", "        ", "super", "(", "GET_IMAGE_G", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "gf_dim", "=", "ngf", "\n", "self", ".", "img", "=", "nn", ".", "Sequential", "(", "\n", "conv3x3", "(", "ngf", ",", "ngf", "//", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ngf", "//", "2", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "conv3x3", "(", "ngf", "//", "2", ",", "ngf", "//", "4", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ngf", "//", "4", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", ",", "\n", "conv3x3", "(", "ngf", "//", "4", ",", "3", ")", ",", "\n", "nn", ".", "Tanh", "(", ")", "\n", ")", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.GET_IMAGE_G.forward": [[624, 628], ["model.GET_IMAGE_G.img"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h_code", ")", ":", "\n", "        ", "out_img", "=", "self", ".", "img", "(", "h_code", ")", "\n", "#print(out_img.shape)", "\n", "return", "out_img", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.G_NET.__init__": [[632, 649], ["torch.Module.__init__", "model.CA_NET", "model.INIT_STAGE_G", "model.GET_IMAGE_G", "model.NEXT_STAGE_G", "model.GET_IMAGE_G", "model.NEXT_STAGE_G", "model.GET_IMAGE_G"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "G_NET", ",", "self", ")", ".", "__init__", "(", ")", "\n", "ngf", "=", "cfg", ".", "GAN", ".", "GF_DIM", "\n", "nef", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "ncf", "=", "cfg", ".", "GAN", ".", "CONDITION_DIM", "\n", "self", ".", "ca_net", "=", "CA_NET", "(", ")", "\n", "\n", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "0", ":", "\n", "            ", "self", ".", "h_net1", "=", "INIT_STAGE_G", "(", "ngf", "*", "16", ",", "ncf", ")", "\n", "self", ".", "img_net1", "=", "GET_IMAGE_G", "(", "ngf", ")", "\n", "# gf x 64 x 64", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "1", ":", "\n", "            ", "self", ".", "h_net2", "=", "NEXT_STAGE_G", "(", "ngf", ",", "nef", ",", "ncf", ")", "\n", "self", ".", "img_net2", "=", "GET_IMAGE_G", "(", "ngf", ")", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "2", ":", "\n", "            ", "self", ".", "h_net3", "=", "NEXT_STAGE_G", "(", "ngf", ",", "nef", ",", "ncf", ")", "\n", "self", ".", "img_net3", "=", "GET_IMAGE_G", "(", "ngf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.G_NET.forward": [[650, 695], ["model.G_NET.ca_net", "model.G_NET.h_net1", "model.G_NET.img_net1", "fake_imgs.append", "model.G_NET.h_net2", "model.G_NET.img_net2", "model.G_NET.img_net1", "fake_imgs.append", "I_P.append", "I_star.append", "model.G_NET.h_net3", "model.G_NET.img_net3", "model.G_NET.img_net2", "fake_imgs.append", "I_P.append", "I_star.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "att_maps.append", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "att_maps.append", "pow", "pow"], "methods", ["None"], ["", "", "def", "forward", "(", "self", ",", "z_code", ",", "sent_emb", ",", "word_embs", ",", "mask", ",", "imgs", ")", ":", "\n", "        ", "\"\"\"\n            :param z_code: batch x cfg.GAN.Z_DIM\n            :param sent_emb: batch x cfg.TEXT.EMBEDDING_DIM\n            :param word_embs: batch x cdf x seq_len\n            :param mask: batch x seq_len\n            :return:\n        \"\"\"", "\n", "thc", "=", "cfg", ".", "TRAIN", ".", "BATCH_SIZE", "\n", "fake_imgs", "=", "[", "]", "\n", "att_maps", "=", "[", "]", "\n", "#errorxx = 0.000001 ", "\n", "I_P", "=", "[", "]", "\n", "I_star", "=", "[", "]", "\n", "c_code", ",", "mu", ",", "logvar", "=", "self", ".", "ca_net", "(", "sent_emb", ")", "\n", "\n", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "0", ":", "\n", "            ", "h_code1", "=", "self", ".", "h_net1", "(", "z_code", ",", "c_code", ")", "\n", "fake_img1", "=", "self", ".", "img_net1", "(", "h_code1", ")", "\n", "fake_imgs", ".", "append", "(", "fake_img1", ")", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "1", ":", "\n", "            ", "h_code2", ",", "att1", ",", "loss1", ",", "I_P1", ",", "I_star1", ",", "I_image1", "=", "self", ".", "h_net2", "(", "h_code1", ",", "c_code", ",", "word_embs", ",", "mask", ",", "imgs", "[", "0", "]", ",", "64", ",", "64", ",", "thc", ",", "sent_emb", ")", "\n", "fake_img2", "=", "self", ".", "img_net2", "(", "h_code2", ")", "\n", "GT_img2", "=", "self", ".", "img_net1", "(", "I_image1", ")", "\n", "loss_gtimage1", "=", "(", "1.0", "/", "(", "64.0", "*", "64.0", ")", ")", "*", "torch", ".", "sum", "(", "pow", "(", "(", "imgs", "[", "0", "]", "-", "GT_img2", ")", ",", "2.0", ")", ")", "\n", "fake_imgs", ".", "append", "(", "fake_img2", ")", "\n", "I_P", ".", "append", "(", "I_P1", ")", "\n", "I_star", ".", "append", "(", "I_star1", ")", "\n", "if", "att1", "is", "not", "None", ":", "\n", "                ", "att_maps", ".", "append", "(", "att1", ")", "\n", "# print(errorxx)", "\n", "", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "2", ":", "\n", "            ", "h_code3", ",", "att2", ",", "loss2", ",", "I_P2", ",", "I_star2", ",", "I_image2", "=", "self", ".", "h_net3", "(", "h_code2", ",", "c_code", ",", "word_embs", ",", "mask", ",", "imgs", "[", "1", "]", ",", "64", ",", "128", ",", "thc", ",", "sent_emb", ")", "\n", "fake_img3", "=", "self", ".", "img_net3", "(", "h_code3", ")", "\n", "GT_img3", "=", "self", ".", "img_net2", "(", "I_image2", ")", "\n", "loss_gtimage2", "=", "(", "1.0", "/", "(", "128.0", "*", "128.0", ")", ")", "*", "torch", ".", "sum", "(", "pow", "(", "(", "imgs", "[", "1", "]", "-", "GT_img3", ")", ",", "2.0", ")", ")", "\n", "fake_imgs", ".", "append", "(", "fake_img3", ")", "\n", "I_P", ".", "append", "(", "I_P2", ")", "\n", "I_star", ".", "append", "(", "I_star2", ")", "\n", "if", "att2", "is", "not", "None", ":", "\n", "                ", "att_maps", ".", "append", "(", "att2", ")", "\n", "", "loss", "=", "10.1", "**", "(", "1.0", "/", "(", "64.0", "*", "64.0", ")", "*", "loss1", "+", "1.0", "/", "(", "128.0", "*", "128.0", ")", "*", "loss2", ")", "+", "0.00001", "*", "(", "loss_gtimage2", "+", "loss_gtimage1", ")", "\n", "", "return", "fake_imgs", ",", "att_maps", ",", "mu", ",", "logvar", ",", "loss", ",", "I_P", ",", "I_star", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.G_DCGAN.__init__": [[700, 716], ["torch.Module.__init__", "model.CA_NET", "model.GET_IMAGE_G", "model.INIT_STAGE_G", "model.NEXT_STAGE_G", "model.NEXT_STAGE_G"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__"], ["    ", "def", "__init__", "(", "self", ")", ":", "\n", "        ", "super", "(", "G_DCGAN", ",", "self", ")", ".", "__init__", "(", ")", "\n", "ngf", "=", "cfg", ".", "GAN", ".", "GF_DIM", "\n", "nef", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "ncf", "=", "cfg", ".", "GAN", ".", "CONDITION_DIM", "\n", "self", ".", "ca_net", "=", "CA_NET", "(", ")", "\n", "\n", "# 16gf x 64 x 64 --> gf x 64 x 64 --> 3 x 64 x 64", "\n", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "0", ":", "\n", "            ", "self", ".", "h_net1", "=", "INIT_STAGE_G", "(", "ngf", "*", "16", ",", "ncf", ")", "\n", "# gf x 64 x 64", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "1", ":", "\n", "            ", "self", ".", "h_net2", "=", "NEXT_STAGE_G", "(", "ngf", ",", "nef", ",", "ncf", ")", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "2", ":", "\n", "            ", "self", ".", "h_net3", "=", "NEXT_STAGE_G", "(", "ngf", ",", "nef", ",", "ncf", ")", "\n", "", "self", ".", "img_net", "=", "GET_IMAGE_G", "(", "ngf", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.G_DCGAN.forward": [[717, 740], ["model.G_DCGAN.ca_net", "model.G_DCGAN.img_net", "model.G_DCGAN.h_net1", "model.G_DCGAN.h_net2", "model.G_DCGAN.h_net3", "att_maps.append", "att_maps.append"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "z_code", ",", "sent_emb", ",", "word_embs", ",", "mask", ")", ":", "\n", "        ", "\"\"\"\n            :param z_code: batch x cfg.GAN.Z_DIM\n            :param sent_emb: batch x cfg.TEXT.EMBEDDING_DIM\n            :param word_embs: batch x cdf x seq_len\n            :param mask: batch x seq_len\n            :return:\n        \"\"\"", "\n", "att_maps", "=", "[", "]", "\n", "c_code", ",", "mu", ",", "logvar", "=", "self", ".", "ca_net", "(", "sent_emb", ")", "\n", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "0", ":", "\n", "            ", "h_code", "=", "self", ".", "h_net1", "(", "z_code", ",", "c_code", ")", "\n", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "1", ":", "\n", "            ", "h_code", ",", "att1", "=", "self", ".", "h_net2", "(", "h_code", ",", "c_code", ",", "word_embs", ",", "mask", ")", "\n", "if", "att1", "is", "not", "None", ":", "\n", "                ", "att_maps", ".", "append", "(", "att1", ")", "\n", "", "", "if", "cfg", ".", "TREE", ".", "BRANCH_NUM", ">", "2", ":", "\n", "            ", "h_code", ",", "att2", "=", "self", ".", "h_net3", "(", "h_code", ",", "c_code", ",", "word_embs", ",", "mask", ")", "\n", "if", "att2", "is", "not", "None", ":", "\n", "                ", "att_maps", ".", "append", "(", "att2", ")", "\n", "\n", "", "", "fake_imgs", "=", "self", ".", "img_net", "(", "h_code", ")", "\n", "return", "[", "fake_imgs", "]", ",", "att_maps", ",", "mu", ",", "logvar", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_GET_LOGITS.__init__": [[774, 785], ["torch.Module.__init__", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.Block3x3_leakRelu", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid", "torch.Sigmoid"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.Block3x3_leakRelu"], ["    ", "def", "__init__", "(", "self", ",", "ndf", ",", "nef", ",", "bcondition", "=", "False", ")", ":", "\n", "        ", "super", "(", "D_GET_LOGITS", ",", "self", ")", ".", "__init__", "(", ")", "\n", "self", ".", "df_dim", "=", "ndf", "\n", "self", ".", "ef_dim", "=", "nef", "\n", "self", ".", "bcondition", "=", "bcondition", "\n", "if", "self", ".", "bcondition", ":", "\n", "            ", "self", ".", "jointConv", "=", "Block3x3_leakRelu", "(", "ndf", "*", "8", "+", "nef", ",", "ndf", "*", "8", ")", "\n", "\n", "", "self", ".", "outlogits", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "8", ",", "1", ",", "kernel_size", "=", "4", ",", "stride", "=", "4", ")", ",", "\n", "nn", ".", "Sigmoid", "(", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_GET_LOGITS.forward": [[786, 802], ["model.D_GET_LOGITS.outlogits", "model.D_GET_LOGITS.view", "c_code.repeat.repeat.view", "c_code.repeat.repeat.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "model.D_GET_LOGITS.jointConv"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "h_code", ",", "c_code", "=", "None", ")", ":", "\n", "        ", "if", "self", ".", "bcondition", "and", "c_code", "is", "not", "None", ":", "\n", "# conditioning output", "\n", "            ", "c_code", "=", "c_code", ".", "view", "(", "-", "1", ",", "self", ".", "ef_dim", ",", "1", ",", "1", ")", "\n", "c_code", "=", "c_code", ".", "repeat", "(", "1", ",", "1", ",", "4", ",", "4", ")", "\n", "# state size (ngf+egf) x 4 x 4", "\n", "# print(c_code.shape)", "\n", "#print(h_code.shape)", "\n", "h_c_code", "=", "torch", ".", "cat", "(", "(", "h_code", ",", "c_code", ")", ",", "1", ")", "\n", "# state size ngf x in_size x in_size", "\n", "h_c_code", "=", "self", ".", "jointConv", "(", "h_c_code", ")", "\n", "", "else", ":", "\n", "            ", "h_c_code", "=", "h_code", "\n", "\n", "", "output", "=", "self", ".", "outlogits", "(", "h_c_code", ")", "\n", "return", "output", ".", "view", "(", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET64.__init__": [[810, 831], ["torch.Module.__init__", "model.CA_NET", "model.encode_image_by_16times", "model.INIT_STAGE_G", "model.encode_image_by_1times", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "model.D_GET_LOGITS", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "copy.deepcopy", "model.D_GET_LOGITS", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_16times", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_1times"], ["    ", "def", "__init__", "(", "self", ",", "b_jcu", "=", "True", ")", ":", "\n", "        ", "super", "(", "D_NET64", ",", "self", ")", ".", "__init__", "(", ")", "\n", "ndf", "=", "cfg", ".", "GAN", ".", "DF_DIM", "\n", "self", ".", "ca_net", "=", "CA_NET", "(", ")", "\n", "nef", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "self", ".", "img_code_s16", "=", "encode_image_by_16times", "(", "ndf", ")", "\n", "self", ".", "h_net1", "=", "INIT_STAGE_G", "(", "32", "*", "16", ",", "100", ")", "\n", "self", ".", "img_code_s1", "=", "encode_image_by_1times", "(", "ndf", ")", "\n", "self", ".", "global_avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "if", "b_jcu", ":", "\n", "            ", "self", ".", "UNCOND_DNET", "=", "D_GET_LOGITS", "(", "ndf", ",", "nef", ",", "bcondition", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "UNCOND_DNET", "=", "None", "\n", "", "self", ".", "COND_DNET", "=", "D_GET_LOGITS", "(", "ndf", ",", "nef", ",", "bcondition", "=", "True", ")", "\n", "reduction", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "self", ".", "global_reduction", "=", "copy", ".", "deepcopy", "(", "reduction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET64.forward": [[832, 843], ["model.D_NET64.img_code_s16", "model.D_NET64.global_avgpool", "model.D_NET64.global_reduction().squeeze", "model.D_NET64.ca_net", "model.D_NET64.ca_net", "model.D_NET64.h_net1", "model.D_NET64.img_code_s1", "model.D_NET64.global_reduction"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_var", ",", "sent_emb", ",", "word_embs", ",", "mask", ",", "noise", ")", ":", "\n", "\n", "        ", "x_code4", "=", "self", ".", "img_code_s16", "(", "x_var", ")", "# 4 x 4 x 8df", "\n", "x_code41", "=", "self", ".", "global_avgpool", "(", "x_code4", ")", "\n", "image_code", "=", "self", ".", "global_reduction", "(", "x_code41", ")", ".", "squeeze", "(", ")", "\n", "c_code", ",", "_", ",", "_", "=", "self", ".", "ca_net", "(", "sent_emb", ")", "\n", "\n", "image_code", ",", "muD", ",", "logvarD", "=", "self", ".", "ca_net", "(", "image_code", ")", "\n", "h_code1", "=", "self", ".", "h_net1", "(", "image_code", ",", "c_code", ")", "\n", "out_code", "=", "self", ".", "img_code_s1", "(", "h_code1", ")", "\n", "return", "x_code4", ",", "out_code", ",", "muD", ",", "logvarD", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET128.__init__": [[847, 870], ["torch.Module.__init__", "model.CA_NET", "model.encode_image_by_16times", "model.downBlock", "model.Block3x3_leakRelu", "model.INIT_STAGE_G", "model.encode_image_by_1times", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "model.D_GET_LOGITS", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "copy.deepcopy", "model.D_GET_LOGITS", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_16times", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.downBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.Block3x3_leakRelu", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_1times"], ["    ", "def", "__init__", "(", "self", ",", "b_jcu", "=", "True", ")", ":", "\n", "        ", "super", "(", "D_NET128", ",", "self", ")", ".", "__init__", "(", ")", "\n", "ndf", "=", "cfg", ".", "GAN", ".", "DF_DIM", "\n", "self", ".", "ca_net", "=", "CA_NET", "(", ")", "\n", "nef", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "self", ".", "img_code_s16", "=", "encode_image_by_16times", "(", "ndf", ")", "\n", "self", ".", "img_code_s32", "=", "downBlock", "(", "ndf", "*", "8", ",", "ndf", "*", "16", ")", "\n", "self", ".", "img_code_s32_1", "=", "Block3x3_leakRelu", "(", "ndf", "*", "16", ",", "ndf", "*", "8", ")", "\n", "self", ".", "h_net1", "=", "INIT_STAGE_G", "(", "32", "*", "16", ",", "100", ")", "\n", "self", ".", "img_code_s1", "=", "encode_image_by_1times", "(", "ndf", ")", "\n", "self", ".", "global_avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "if", "b_jcu", ":", "\n", "            ", "self", ".", "UNCOND_DNET", "=", "D_GET_LOGITS", "(", "ndf", ",", "nef", ",", "bcondition", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "UNCOND_DNET", "=", "None", "\n", "", "self", ".", "COND_DNET", "=", "D_GET_LOGITS", "(", "ndf", ",", "nef", ",", "bcondition", "=", "True", ")", "\n", "reduction", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "512", ",", "256", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "self", ".", "global_reduction", "=", "copy", ".", "deepcopy", "(", "reduction", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET128.forward": [[872, 887], ["model.D_NET128.img_code_s16", "model.D_NET128.img_code_s32", "model.D_NET128.img_code_s32_1", "model.D_NET128.global_avgpool", "model.D_NET128.global_reduction().squeeze", "model.D_NET128.ca_net", "model.D_NET128.ca_net", "model.D_NET128.h_net1", "model.D_NET128.img_code_s1", "model.D_NET128.global_reduction"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_var", ",", "sent_emb", ",", "word_embs", ",", "mask", ",", "noise", ")", ":", "\n", "\n", "        ", "x_code8", "=", "self", ".", "img_code_s16", "(", "x_var", ")", "# 8 x 8 x 8df", "\n", "x_code40", "=", "self", ".", "img_code_s32", "(", "x_code8", ")", "# 4 x 4 x 16df", "\n", "x_code4", "=", "self", ".", "img_code_s32_1", "(", "x_code40", ")", "# 4 x 4 x 8df", "\n", "\n", "\n", "\n", "x_code41", "=", "self", ".", "global_avgpool", "(", "x_code40", ")", "\n", "image_code", "=", "self", ".", "global_reduction", "(", "x_code41", ")", ".", "squeeze", "(", ")", "\n", "c_code", ",", "_", ",", "_", "=", "self", ".", "ca_net", "(", "sent_emb", ")", "\n", "image_code", ",", "muD", ",", "logvarD", "=", "self", ".", "ca_net", "(", "image_code", ")", "\n", "h_code1", "=", "self", ".", "h_net1", "(", "image_code", ",", "c_code", ")", "\n", "out_code", "=", "self", ".", "img_code_s1", "(", "h_code1", ")", "\n", "return", "x_code4", ",", "out_code", ",", "muD", ",", "logvarD", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.__init__": [[905, 944], ["torch.Module.__init__", "model.CA_NET", "model.INIT_STAGE_G", "model.NEXT_STAGE_G", "model.NEXT_STAGE_G", "model.encode_image_by_16times", "model.encode_image_by_1times", "model.downBlock", "model.downBlock", "model.Block3x3_leakRelu", "model.Block3x3_leakRelu", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "torch.AdaptiveAvgPool2d", "model.D_GET_LOGITS", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "copy.deepcopy", "model.D_NET256.define_module", "model.D_GET_LOGITS", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.BatchNorm2d", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU", "torch.ReLU"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_16times", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_1times", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.downBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.downBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.Block3x3_leakRelu", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.Block3x3_leakRelu", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.define_module"], ["    ", "def", "__init__", "(", "self", ",", "b_jcu", "=", "True", ")", ":", "\n", "        ", "super", "(", "D_NET256", ",", "self", ")", ".", "__init__", "(", ")", "\n", "ndf", "=", "cfg", ".", "GAN", ".", "DF_DIM", "\n", "nef", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "self", ".", "ca_net", "=", "CA_NET", "(", ")", "\n", "ngf", "=", "cfg", ".", "GAN", ".", "GF_DIM", "\n", "nef", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "ncf", "=", "cfg", ".", "GAN", ".", "CONDITION_DIM", "\n", "self", ".", "gf_dim", "=", "ngf", "\n", "self", ".", "in_dim", "=", "cfg", ".", "GAN", ".", "Z_DIM", "+", "ncf", "# cfg.TEXT.EMBEDDING_DIM", "\n", "self", ".", "num_residual", "=", "cfg", ".", "GAN", ".", "R_NUM", "\n", "\n", "self", ".", "ef_dim", "=", "cfg", ".", "TEXT", ".", "EMBEDDING_DIM", "\n", "self", ".", "h_net1", "=", "INIT_STAGE_G", "(", "32", "*", "16", ",", "100", ")", "\n", "self", ".", "h_net2", "=", "NEXT_STAGE_G", "(", "32", ",", "256", ",", "100", ")", "\n", "self", ".", "h_net3", "=", "NEXT_STAGE_G", "(", "32", ",", "256", ",", "100", ")", "\n", "\n", "self", ".", "img_code_s16", "=", "encode_image_by_16times", "(", "ndf", ")", "\n", "self", ".", "img_code_s1", "=", "encode_image_by_1times", "(", "ndf", ")", "\n", "self", ".", "img_code_s32", "=", "downBlock", "(", "ndf", "*", "8", ",", "ndf", "*", "16", ")", "\n", "self", ".", "img_code_s64", "=", "downBlock", "(", "ndf", "*", "16", ",", "ndf", "*", "32", ")", "\n", "self", ".", "img_code_s64_1", "=", "Block3x3_leakRelu", "(", "ndf", "*", "32", ",", "ndf", "*", "16", ")", "\n", "self", ".", "img_code_s64_2", "=", "Block3x3_leakRelu", "(", "ndf", "*", "16", ",", "ndf", "*", "8", ")", "\n", "self", ".", "global_avgpool", "=", "nn", ".", "AdaptiveAvgPool2d", "(", "(", "1", ",", "1", ")", ")", "\n", "if", "b_jcu", ":", "\n", "            ", "self", ".", "UNCOND_DNET", "=", "D_GET_LOGITS", "(", "ndf", ",", "nef", ",", "bcondition", "=", "False", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "UNCOND_DNET", "=", "None", "\n", "", "self", ".", "COND_DNET", "=", "D_GET_LOGITS", "(", "ndf", ",", "nef", ",", "bcondition", "=", "True", ")", "\n", "\n", "reduction", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "1024", ",", "256", ",", "1", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "ReLU", "(", ")", "\n", ")", "\n", "\n", "self", ".", "global_reduction", "=", "copy", ".", "deepcopy", "(", "reduction", ")", "\n", "#self.global_reduction.apply(weights_init_kaiming)", "\n", "self", ".", "define_module", "(", ")", "\n", "", "def", "_make_layer", "(", "self", ",", "block", ",", "channel_num", ")", ":", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256._make_layer": [[944, 949], ["range", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "layers.append", "block"], "methods", ["None"], ["", "def", "_make_layer", "(", "self", ",", "block", ",", "channel_num", ")", ":", "\n", "        ", "layers", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cfg", ".", "GAN", ".", "R_NUM", ")", ":", "\n", "            ", "layers", ".", "append", "(", "block", "(", "channel_num", ")", ")", "\n", "", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.define_module": [[951, 967], ["torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "torch.Sequential", "model.upBlock", "model.upBlock", "model.upBlock", "model.upBlock", "GlobalAttention.GlobalAttentionGeneral", "model.D_NET256._make_layer", "model.upBlock", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.Linear", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "torch.BatchNorm1d", "model.GLU"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256._make_layer", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock"], ["", "def", "define_module", "(", "self", ")", ":", "\n", "        ", "nz", ",", "ngf", "=", "200", ",", "512", "\n", "\n", "self", ".", "fc", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Linear", "(", "nz", ",", "ngf", "*", "4", "*", "4", "*", "2", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm1d", "(", "ngf", "*", "4", "*", "4", "*", "2", ")", ",", "\n", "GLU", "(", ")", ")", "\n", "\n", "self", ".", "upsample1", "=", "upBlock", "(", "ngf", ",", "ngf", "//", "2", ")", "\n", "self", ".", "upsample2", "=", "upBlock", "(", "ngf", "//", "2", ",", "ngf", "//", "4", ")", "\n", "self", ".", "upsample3", "=", "upBlock", "(", "ngf", "//", "4", ",", "ngf", "//", "8", ")", "\n", "self", ".", "upsample4", "=", "upBlock", "(", "ngf", "//", "8", ",", "ngf", "//", "16", ")", "\n", "\n", "self", ".", "att", "=", "ATT_NET", "(", "ngf", ",", "self", ".", "ef_dim", ")", "\n", "self", ".", "residual", "=", "self", ".", "_make_layer", "(", "ResBlock", ",", "32", "*", "2", ")", "\n", "self", ".", "upsample", "=", "upBlock", "(", "64", ",", "32", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.D_NET256.forward": [[970, 989], ["model.D_NET256.img_code_s16", "model.D_NET256.img_code_s32", "model.D_NET256.img_code_s64", "model.D_NET256.img_code_s64_1", "model.D_NET256.img_code_s64_2", "model.D_NET256.global_avgpool", "model.D_NET256.global_reduction().squeeze", "model.D_NET256.ca_net", "model.D_NET256.ca_net", "model.D_NET256.h_net1", "model.D_NET256.img_code_s1", "model.D_NET256.global_reduction"], "methods", ["None"], ["", "def", "forward", "(", "self", ",", "x_var", ",", "sent_emb", ",", "word_embs", ",", "mask", ",", "noise", ")", ":", "\n", "\n", "        ", "x_code16", "=", "self", ".", "img_code_s16", "(", "x_var", ")", "\n", "x_code8", "=", "self", ".", "img_code_s32", "(", "x_code16", ")", "\n", "x_code40", "=", "self", ".", "img_code_s64", "(", "x_code8", ")", "\n", "x_code4", "=", "self", ".", "img_code_s64_1", "(", "x_code40", ")", "\n", "x_code4", "=", "self", ".", "img_code_s64_2", "(", "x_code4", ")", "\n", "x_code41", "=", "self", ".", "global_avgpool", "(", "x_code40", ")", "\n", "\n", "\n", "image_code", "=", "self", ".", "global_reduction", "(", "x_code41", ")", ".", "squeeze", "(", ")", "\n", "c_code", ",", "_", ",", "_", "=", "self", ".", "ca_net", "(", "sent_emb", ")", "\n", "image_code", ",", "muD", ",", "logvarD", "=", "self", ".", "ca_net", "(", "image_code", ")", "\n", "h_code1", "=", "self", ".", "h_net1", "(", "image_code", ",", "c_code", ")", "\n", "out_code", "=", "self", ".", "img_code_s1", "(", "h_code1", ")", "\n", "\n", "\n", "\n", "return", "x_code4", ",", "out_code", ",", "muD", ",", "logvarD", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv1x1": [[27, 30], ["torch.Conv2d"], "function", ["None"], ["", "", "def", "conv1x1", "(", "in_planes", ",", "out_planes", ",", "bias", "=", "False", ")", ":", "\n", "    ", "\"1x1 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "1", ",", "stride", "=", "1", ",", "padding", "=", "0", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3": [[32, 35], ["torch.Conv2d"], "function", ["None"], ["", "def", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "bias", "=", "False", ")", ":", "\n", "    ", "\"3x3 convolution with padding\"", "\n", "return", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "kernel_size", "=", "3", ",", "stride", "=", "1", ",", "padding", "=", "1", ",", "bias", "=", "bias", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.upBlock": [[38, 45], ["torch.Sequential", "torch.Upsample", "model.conv3x3", "torch.BatchNorm2d", "model.GLU"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3"], ["", "def", "upBlock", "(", "in_planes", ",", "out_planes", ")", ":", "\n", "    ", "block", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Upsample", "(", "scale_factor", "=", "2", ",", "mode", "=", "'nearest'", ")", ",", "\n", "conv3x3", "(", "in_planes", ",", "out_planes", "*", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_planes", "*", "2", ")", ",", "\n", "GLU", "(", ")", ")", "\n", "return", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.Block3x3_relu": [[48, 54], ["torch.Sequential", "model.conv3x3", "torch.BatchNorm2d", "model.GLU"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3"], ["", "def", "Block3x3_relu", "(", "in_planes", ",", "out_planes", ")", ":", "\n", "    ", "block", "=", "nn", ".", "Sequential", "(", "\n", "conv3x3", "(", "in_planes", ",", "out_planes", "*", "2", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "out_planes", "*", "2", ")", ",", "\n", "GLU", "(", ")", ")", "\n", "return", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_2timesxx": [[345, 355], ["torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.Conv2d", "torch.BatchNorm2d"], "function", ["None"], ["", "", "def", "encode_image_by_2timesxx", "(", "ndf", ")", ":", "\n", "    ", "encode_img", "=", "nn", ".", "Sequential", "(", "\n", "# --> state size. ndf x in_size/2 x in_size/2", "\n", "nn", ".", "Conv2d", "(", "3", ",", "32", ",", "2", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "32", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "32", ",", "64", ",", "2", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", ")", "\n", "return", "encode_img", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_non_local": [[357, 366], ["torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.Conv2d", "torch.BatchNorm2d"], "function", ["None"], ["", "def", "encode_non_local", "(", "ndf", ")", ":", "\n", "    ", "encode_img", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", ")", "\n", "return", "encode_img", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_non_local2": [[367, 376], ["torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.Conv2d", "torch.BatchNorm2d"], "function", ["None"], ["", "def", "encode_non_local2", "(", "ndf", ")", ":", "\n", "    ", "encode_img", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "3", ",", "1", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "64", ",", "64", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "64", ")", "\n", ")", "\n", "return", "encode_img", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_non_local0": [[378, 385], ["torch.Sequential", "torch.Conv2d", "torch.BatchNorm2d", "torch.Conv2d"], "function", ["None"], ["", "def", "encode_non_local0", "(", "ndf", ")", ":", "\n", "    ", "encode_img", "=", "nn", ".", "Sequential", "(", "\n", "nn", ".", "Conv2d", "(", "64", ",", "256", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "256", ")", ",", "\n", "nn", ".", "Conv2d", "(", "256", ",", "256", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", "\n", ")", "\n", "return", "encode_img", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_16timesxxx": [[387, 407], ["torch.Sequential", "torch.Conv2d", "torch.LeakyReLU", "torch.Conv2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.Conv2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.Conv2d", "torch.BatchNorm2d", "torch.LeakyReLU", "torch.Conv2d"], "function", ["None"], ["", "def", "encode_image_by_16timesxxx", "(", "ndf", ")", ":", "\n", "    ", "encode_img", "=", "nn", ".", "Sequential", "(", "\n", "# --> state size. ndf x in_size/2 x in_size/2", "\n", "nn", ".", "Conv2d", "(", "64", ",", "ndf", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "# --> state size 2ndf x x in_size/4 x in_size/4", "\n", "nn", ".", "Conv2d", "(", "ndf", ",", "ndf", "*", "2", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ndf", "*", "2", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "# --> state size 4ndf x in_size/8 x in_size/8", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "2", ",", "ndf", "*", "4", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ndf", "*", "4", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "# --> state size 8ndf x in_size/16 x in_size/16", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "4", ",", "ndf", "*", "8", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "BatchNorm2d", "(", "ndf", "*", "8", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", "nn", ".", "Conv2d", "(", "ndf", "*", "8", ",", "1", ",", "4", ",", "1", ",", "0", ",", "bias", "=", "False", ")", "\n", ")", "\n", "return", "encode_img", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.l2norm": [[408, 412], ["torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.pow().sum().sqrt", "torch.div", "torch.div", "torch.div", "torch.div", "torch.div", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow().sum", "torch.pow", "torch.pow", "torch.pow", "torch.pow", "torch.pow"], "function", ["None"], ["", "def", "l2norm", "(", "x", ")", ":", "\n", "  ", "\"\"\"L2-normalize columns of x\"\"\"", "\n", "norm", "=", "torch", ".", "pow", "(", "x", ",", "2", ")", ".", "sum", "(", "dim", "=", "-", "1", ",", "keepdim", "=", "True", ")", ".", "sqrt", "(", ")", "\n", "return", "torch", ".", "div", "(", "x", ",", "norm", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.weights_init_kaiming": [[414, 427], ["classname.find", "torch.init.kaiming_normal_", "torch.init.constant_", "classname.find", "torch.init.kaiming_normal_", "torch.init.constant_", "classname.find", "torch.init.normal_", "torch.init.constant_"], "function", ["None"], ["", "def", "weights_init_kaiming", "(", "m", ")", ":", "\n", "    ", "classname", "=", "m", ".", "__class__", ".", "__name__", "\n", "if", "classname", ".", "find", "(", "'Linear'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "a", "=", "0", ",", "mode", "=", "'fan_out'", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "elif", "classname", ".", "find", "(", "'Conv'", ")", "!=", "-", "1", ":", "\n", "        ", "nn", ".", "init", ".", "kaiming_normal_", "(", "m", ".", "weight", ",", "a", "=", "0", ",", "mode", "=", "'fan_in'", ")", "\n", "if", "m", ".", "bias", "is", "not", "None", ":", "\n", "            ", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "", "", "elif", "classname", ".", "find", "(", "'BatchNorm'", ")", "!=", "-", "1", ":", "\n", "        ", "if", "m", ".", "affine", ":", "\n", "            ", "nn", ".", "init", ".", "normal_", "(", "m", ".", "weight", ",", "1.0", ",", "0.02", ")", "\n", "nn", ".", "init", ".", "constant_", "(", "m", ".", "bias", ",", "0.0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.cosine_similarity": [[428, 435], ["torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm", "torch.norm"], "function", ["None"], ["", "", "", "def", "cosine_similarity", "(", "x1", ",", "x2", ",", "dim", "=", "1", ",", "eps", "=", "1e-8", ")", ":", "\n", "    ", "\"\"\"Returns cosine similarity between x1 and x2, computed along dim.\n    \"\"\"", "\n", "w12", "=", "torch", ".", "sum", "(", "x1", "*", "x2", ",", "dim", ")", "\n", "w1", "=", "torch", ".", "norm", "(", "x1", ",", "2", ",", "dim", ")", "\n", "w2", "=", "torch", ".", "norm", "(", "x2", ",", "2", ",", "dim", ")", "\n", "return", "(", "w12", "/", "(", "w1", "*", "w2", ")", ".", "clamp", "(", "min", "=", "eps", ")", ")", ".", "squeeze", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.Block3x3_leakRelu": [[743, 749], ["torch.Sequential", "spectral.SpectralNorm", "torch.LeakyReLU", "model.conv3x3"], "function", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.conv3x3"], ["", "", "def", "Block3x3_leakRelu", "(", "in_planes", ",", "out_planes", ")", ":", "\n", "    ", "block", "=", "nn", ".", "Sequential", "(", "\n", "SpectralNorm", "(", "conv3x3", "(", "in_planes", ",", "out_planes", ",", "bias", "=", "True", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", ")", "\n", "return", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.downBlock": [[752, 758], ["torch.Sequential", "spectral.SpectralNorm", "torch.LeakyReLU", "torch.Conv2d"], "function", ["None"], ["", "def", "downBlock", "(", "in_planes", ",", "out_planes", ")", ":", "\n", "    ", "block", "=", "nn", ".", "Sequential", "(", "\n", "SpectralNorm", "(", "nn", ".", "Conv2d", "(", "in_planes", ",", "out_planes", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "True", ")", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", "\n", ")", "\n", "return", "block", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_16times": [[760, 771], ["layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "layers.append", "torch.Sequential", "spectral.SpectralNorm", "torch.LeakyReLU", "spectral.SpectralNorm", "torch.LeakyReLU", "spectral.SpectralNorm", "torch.LeakyReLU", "spectral.SpectralNorm", "torch.LeakyReLU", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d", "torch.Conv2d"], "function", ["None"], ["", "def", "encode_image_by_16times", "(", "ndf", ")", ":", "\n", "    ", "layers", "=", "[", "]", "\n", "layers", ".", "append", "(", "SpectralNorm", "(", "nn", ".", "Conv2d", "(", "3", ",", "ndf", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "True", ")", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", ")", "\n", "layers", ".", "append", "(", "SpectralNorm", "(", "nn", ".", "Conv2d", "(", "ndf", ",", "ndf", "*", "2", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "True", ")", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "SpectralNorm", "(", "nn", ".", "Conv2d", "(", "ndf", "*", "2", ",", "ndf", "*", "4", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "True", ")", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ")", "\n", "layers", ".", "append", "(", "SpectralNorm", "(", "nn", ".", "Conv2d", "(", "ndf", "*", "4", ",", "ndf", "*", "8", ",", "4", ",", "2", ",", "1", ",", "bias", "=", "True", ")", ")", ")", "\n", "layers", ".", "append", "(", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ")", "\n", "return", "nn", ".", "Sequential", "(", "*", "layers", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.encode_image_by_1times": [[892, 899], ["torch.Sequential", "torch.Conv2d", "torch.LeakyReLU"], "function", ["None"], ["", "", "def", "encode_image_by_1times", "(", "ndf", ")", ":", "\n", "    ", "encode_img", "=", "nn", ".", "Sequential", "(", "\n", "# --> state size. ndf x in_size/2 x in_size/2", "\n", "nn", ".", "Conv2d", "(", "32", ",", "3", ",", "1", ",", "1", ",", "0", ",", "bias", "=", "False", ")", ",", "\n", "nn", ".", "LeakyReLU", "(", "0.2", ",", "inplace", "=", "True", ")", ",", "\n", ")", "\n", "return", "encode_img", "\n", "# For 256 x 256 images", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__init__": [[92, 120], ["torchvision.Compose", "range", "os.path.join", "datasets.TextDataset.load_text_data", "datasets.TextDataset.load_class_id", "len", "datasets.TextDataset.imsize.append", "data_dir.find", "datasets.TextDataset.load_bbox", "len", "torchvision.ToTensor", "torchvision.Normalize"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_text_data", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_class_id", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_bbox"], ["    ", "def", "__init__", "(", "self", ",", "data_dir", ",", "split", "=", "'train'", ",", "\n", "base_size", "=", "64", ",", "\n", "transform", "=", "None", ",", "target_transform", "=", "None", ")", ":", "\n", "        ", "self", ".", "transform", "=", "transform", "\n", "self", ".", "norm", "=", "transforms", ".", "Compose", "(", "[", "\n", "transforms", ".", "ToTensor", "(", ")", ",", "\n", "transforms", ".", "Normalize", "(", "(", "0.5", ",", "0.5", ",", "0.5", ")", ",", "(", "0.5", ",", "0.5", ",", "0.5", ")", ")", "]", ")", "\n", "self", ".", "target_transform", "=", "target_transform", "\n", "self", ".", "embeddings_num", "=", "cfg", ".", "TEXT", ".", "CAPTIONS_PER_IMAGE", "\n", "\n", "self", ".", "imsize", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "cfg", ".", "TREE", ".", "BRANCH_NUM", ")", ":", "\n", "            ", "self", ".", "imsize", ".", "append", "(", "base_size", ")", "\n", "base_size", "=", "base_size", "*", "2", "\n", "\n", "", "self", ".", "data", "=", "[", "]", "\n", "self", ".", "data_dir", "=", "data_dir", "\n", "if", "data_dir", ".", "find", "(", "'birds'", ")", "!=", "-", "1", ":", "\n", "            ", "self", ".", "bbox", "=", "self", ".", "load_bbox", "(", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "bbox", "=", "None", "\n", "", "split_dir", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "split", ")", "\n", "\n", "self", ".", "filenames", ",", "self", ".", "captions", ",", "self", ".", "ixtoword", ",", "self", ".", "wordtoix", ",", "self", ".", "n_words", "=", "self", ".", "load_text_data", "(", "data_dir", ",", "split", ")", "\n", "\n", "self", ".", "class_id", "=", "self", ".", "load_class_id", "(", "split_dir", ",", "len", "(", "self", ".", "filenames", ")", ")", "\n", "self", ".", "number_example", "=", "len", "(", "self", ".", "filenames", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_bbox": [[121, 144], ["os.path.join", "pandas.read_csv().astype", "os.path.join", "pandas.read_csv", "df_filenames[].tolist", "print", "len", "range", "len", "[].tolist", "pandas.read_csv"], "methods", ["None"], ["", "def", "load_bbox", "(", "self", ")", ":", "\n", "        ", "data_dir", "=", "self", ".", "data_dir", "\n", "bbox_path", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'CUB_200_2011/bounding_boxes.txt'", ")", "\n", "df_bounding_boxes", "=", "pd", ".", "read_csv", "(", "bbox_path", ",", "\n", "delim_whitespace", "=", "True", ",", "\n", "header", "=", "None", ")", ".", "astype", "(", "int", ")", "\n", "#", "\n", "filepath", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'CUB_200_2011/images.txt'", ")", "\n", "df_filenames", "=", "pd", ".", "read_csv", "(", "filepath", ",", "delim_whitespace", "=", "True", ",", "header", "=", "None", ")", "\n", "filenames", "=", "df_filenames", "[", "1", "]", ".", "tolist", "(", ")", "\n", "print", "(", "'Total filenames: '", ",", "len", "(", "filenames", ")", ",", "filenames", "[", "0", "]", ")", "\n", "#", "\n", "filename_bbox", "=", "{", "img_file", "[", ":", "-", "4", "]", ":", "[", "]", "for", "img_file", "in", "filenames", "}", "\n", "numImgs", "=", "len", "(", "filenames", ")", "\n", "for", "i", "in", "range", "(", "0", ",", "numImgs", ")", ":", "\n", "# bbox = [x-left, y-top, width, height]", "\n", "            ", "bbox", "=", "df_bounding_boxes", ".", "iloc", "[", "i", "]", "[", "1", ":", "]", ".", "tolist", "(", ")", "\n", "\n", "key", "=", "filenames", "[", "i", "]", "[", ":", "-", "4", "]", "\n", "filename_bbox", "[", "key", "]", "=", "bbox", "\n", "#", "\n", "", "return", "filename_bbox", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_captions": [[145, 178], ["range", "len", "open", "f.read().decode().split", "cap.replace.replace.replace", "nltk.tokenize.RegexpTokenizer", "nltk.tokenize.RegexpTokenizer.tokenize", "all_captions.append", "print", "f.read().decode", "len", "cap.replace.replace.lower", "len", "print", "t.encode().decode.encode().decode.encode().decode", "len", "tokens_new.append", "f.read", "t.encode().decode.encode().decode.encode"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.model.CA_NET.encode"], ["", "def", "load_captions", "(", "self", ",", "data_dir", ",", "filenames", ")", ":", "\n", "        ", "all_captions", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "filenames", ")", ")", ":", "\n", "            ", "cap_path", "=", "'%s/text/%s.txt'", "%", "(", "data_dir", ",", "filenames", "[", "i", "]", ")", "\n", "with", "open", "(", "cap_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "                ", "captions", "=", "f", ".", "read", "(", ")", ".", "decode", "(", "'utf8'", ")", ".", "split", "(", "'\\n'", ")", "\n", "cnt", "=", "0", "\n", "for", "cap", "in", "captions", ":", "\n", "                    ", "if", "len", "(", "cap", ")", "==", "0", ":", "\n", "                        ", "continue", "\n", "", "cap", "=", "cap", ".", "replace", "(", "\"\\ufffd\\ufffd\"", ",", "\" \"", ")", "\n", "# picks out sequences of alphanumeric characters as tokens", "\n", "# and drops everything else", "\n", "tokenizer", "=", "RegexpTokenizer", "(", "r'\\w+'", ")", "\n", "tokens", "=", "tokenizer", ".", "tokenize", "(", "cap", ".", "lower", "(", ")", ")", "\n", "# print('tokens', tokens)", "\n", "if", "len", "(", "tokens", ")", "==", "0", ":", "\n", "                        ", "print", "(", "'cap'", ",", "cap", ")", "\n", "continue", "\n", "\n", "", "tokens_new", "=", "[", "]", "\n", "for", "t", "in", "tokens", ":", "\n", "                        ", "t", "=", "t", ".", "encode", "(", "'ascii'", ",", "'ignore'", ")", ".", "decode", "(", "'ascii'", ")", "\n", "if", "len", "(", "t", ")", ">", "0", ":", "\n", "                            ", "tokens_new", ".", "append", "(", "t", ")", "\n", "", "", "all_captions", ".", "append", "(", "tokens_new", ")", "\n", "cnt", "+=", "1", "\n", "if", "cnt", "==", "self", ".", "embeddings_num", ":", "\n", "                        ", "break", "\n", "", "", "if", "cnt", "<", "self", ".", "embeddings_num", ":", "\n", "                    ", "print", "(", "'ERROR: the captions for %s less than %d'", "\n", "%", "(", "filenames", "[", "i", "]", ",", "cnt", ")", ")", "\n", "", "", "", "return", "all_captions", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.build_dictionary": [[179, 218], ["collections.defaultdict", "train_captions_new.append", "test_captions_new.append", "len", "rev.append", "rev.append"], "methods", ["None"], ["", "def", "build_dictionary", "(", "self", ",", "train_captions", ",", "test_captions", ")", ":", "\n", "        ", "word_counts", "=", "defaultdict", "(", "float", ")", "\n", "captions", "=", "train_captions", "+", "test_captions", "\n", "for", "sent", "in", "captions", ":", "\n", "            ", "for", "word", "in", "sent", ":", "\n", "                ", "word_counts", "[", "word", "]", "+=", "1", "\n", "\n", "", "", "vocab", "=", "[", "w", "for", "w", "in", "word_counts", "if", "word_counts", "[", "w", "]", ">=", "0", "]", "\n", "\n", "ixtoword", "=", "{", "}", "\n", "ixtoword", "[", "0", "]", "=", "'<end>'", "\n", "wordtoix", "=", "{", "}", "\n", "wordtoix", "[", "'<end>'", "]", "=", "0", "\n", "ix", "=", "1", "\n", "for", "w", "in", "vocab", ":", "\n", "            ", "wordtoix", "[", "w", "]", "=", "ix", "\n", "ixtoword", "[", "ix", "]", "=", "w", "\n", "ix", "+=", "1", "\n", "\n", "", "train_captions_new", "=", "[", "]", "\n", "for", "t", "in", "train_captions", ":", "\n", "            ", "rev", "=", "[", "]", "\n", "for", "w", "in", "t", ":", "\n", "                ", "if", "w", "in", "wordtoix", ":", "\n", "                    ", "rev", ".", "append", "(", "wordtoix", "[", "w", "]", ")", "\n", "# rev.append(0)  # do not need '<end>' token", "\n", "", "", "train_captions_new", ".", "append", "(", "rev", ")", "\n", "\n", "", "test_captions_new", "=", "[", "]", "\n", "for", "t", "in", "test_captions", ":", "\n", "            ", "rev", "=", "[", "]", "\n", "for", "w", "in", "t", ":", "\n", "                ", "if", "w", "in", "wordtoix", ":", "\n", "                    ", "rev", ".", "append", "(", "wordtoix", "[", "w", "]", ")", "\n", "# rev.append(0)  # do not need '<end>' token", "\n", "", "", "test_captions_new", ".", "append", "(", "rev", ")", "\n", "\n", "", "return", "[", "train_captions_new", ",", "test_captions_new", ",", "\n", "ixtoword", ",", "wordtoix", ",", "len", "(", "ixtoword", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_text_data": [[219, 250], ["os.path.join", "datasets.TextDataset.load_filenames", "datasets.TextDataset.load_filenames", "os.path.isfile", "datasets.TextDataset.load_captions", "datasets.TextDataset.load_captions", "datasets.TextDataset.build_dictionary", "open", "pickle.dump", "print", "open", "pickle.load", "len", "print"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_filenames", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_filenames", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_captions", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_captions", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.build_dictionary"], ["", "def", "load_text_data", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "filepath", "=", "os", ".", "path", ".", "join", "(", "data_dir", ",", "'captions.pickle'", ")", "\n", "train_names", "=", "self", ".", "load_filenames", "(", "data_dir", ",", "'train'", ")", "\n", "test_names", "=", "self", ".", "load_filenames", "(", "data_dir", ",", "'test'", ")", "\n", "if", "not", "os", ".", "path", ".", "isfile", "(", "filepath", ")", ":", "\n", "            ", "train_captions", "=", "self", ".", "load_captions", "(", "data_dir", ",", "train_names", ")", "\n", "test_captions", "=", "self", ".", "load_captions", "(", "data_dir", ",", "test_names", ")", "\n", "\n", "train_captions", ",", "test_captions", ",", "ixtoword", ",", "wordtoix", ",", "n_words", "=", "self", ".", "build_dictionary", "(", "train_captions", ",", "test_captions", ")", "\n", "with", "open", "(", "filepath", ",", "'wb'", ")", "as", "f", ":", "\n", "                ", "pickle", ".", "dump", "(", "[", "train_captions", ",", "test_captions", ",", "\n", "ixtoword", ",", "wordtoix", "]", ",", "f", ",", "protocol", "=", "2", ")", "\n", "print", "(", "'Save to: '", ",", "filepath", ")", "\n", "", "", "else", ":", "\n", "            ", "with", "open", "(", "filepath", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "x", "=", "pickle", ".", "load", "(", "f", ")", "\n", "train_captions", ",", "test_captions", "=", "x", "[", "0", "]", ",", "x", "[", "1", "]", "\n", "ixtoword", ",", "wordtoix", "=", "x", "[", "2", "]", ",", "x", "[", "3", "]", "\n", "del", "x", "\n", "n_words", "=", "len", "(", "ixtoword", ")", "\n", "print", "(", "'Load from: '", ",", "filepath", ")", "\n", "", "", "if", "split", "==", "'train'", ":", "\n", "# a list of list: each list contains", "\n", "# the indices of words in a sentence", "\n", "            ", "captions", "=", "train_captions", "\n", "filenames", "=", "train_names", "\n", "", "else", ":", "# split=='test'", "\n", "            ", "captions", "=", "test_captions", "\n", "filenames", "=", "test_names", "\n", "", "return", "filenames", ",", "captions", ",", "ixtoword", ",", "wordtoix", ",", "n_words", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_class_id": [[251, 258], ["os.path.isfile", "numpy.arange", "numpy.arange", "open", "pickle.load"], "methods", ["None"], ["", "def", "load_class_id", "(", "self", ",", "data_dir", ",", "total_num", ")", ":", "\n", "        ", "if", "os", ".", "path", ".", "isfile", "(", "data_dir", "+", "'/class_info.pickle'", ")", ":", "\n", "            ", "with", "open", "(", "data_dir", "+", "'/class_info.pickle'", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "class_id", "=", "pickle", ".", "load", "(", "f", ")", "#, encoding='bytes'", "\n", "", "", "else", ":", "\n", "            ", "class_id", "=", "np", ".", "arange", "(", "total_num", ")", "\n", "", "return", "class_id", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.load_filenames": [[259, 268], ["os.path.isfile", "print", "open", "pickle.load", "len"], "methods", ["None"], ["", "def", "load_filenames", "(", "self", ",", "data_dir", ",", "split", ")", ":", "\n", "        ", "filepath", "=", "'%s/%s/filenames.pickle'", "%", "(", "data_dir", ",", "split", ")", "\n", "if", "os", ".", "path", ".", "isfile", "(", "filepath", ")", ":", "\n", "            ", "with", "open", "(", "filepath", ",", "'rb'", ")", "as", "f", ":", "\n", "                ", "filenames", "=", "pickle", ".", "load", "(", "f", ")", "\n", "", "print", "(", "'Load filenames from: %s (%d)'", "%", "(", "filepath", ",", "len", "(", "filenames", ")", ")", ")", "\n", "", "else", ":", "\n", "            ", "filenames", "=", "[", "]", "\n", "", "return", "filenames", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.get_caption": [[269, 288], ["numpy.asarray().astype", "numpy.asarray().astype", "len", "numpy.zeros", "numpy.zeros", "print", "list", "numpy.random.shuffle", "numpy.random.shuffle", "numpy.sort", "numpy.sort", "numpy.asarray", "numpy.asarray", "numpy.arange", "numpy.arange"], "methods", ["None"], ["", "def", "get_caption", "(", "self", ",", "sent_ix", ")", ":", "\n", "# a list of indices for a sentence", "\n", "        ", "sent_caption", "=", "np", ".", "asarray", "(", "self", ".", "captions", "[", "sent_ix", "]", ")", ".", "astype", "(", "'int64'", ")", "\n", "if", "(", "sent_caption", "==", "0", ")", ".", "sum", "(", ")", ">", "0", ":", "\n", "            ", "print", "(", "'ERROR: do not need END (0) token'", ",", "sent_caption", ")", "\n", "", "num_words", "=", "len", "(", "sent_caption", ")", "\n", "# pad with 0s (i.e., '<end>')", "\n", "x", "=", "np", ".", "zeros", "(", "(", "cfg", ".", "TEXT", ".", "WORDS_NUM", ",", "1", ")", ",", "dtype", "=", "'int64'", ")", "\n", "x_len", "=", "num_words", "\n", "if", "num_words", "<=", "cfg", ".", "TEXT", ".", "WORDS_NUM", ":", "\n", "            ", "x", "[", ":", "num_words", ",", "0", "]", "=", "sent_caption", "\n", "", "else", ":", "\n", "            ", "ix", "=", "list", "(", "np", ".", "arange", "(", "num_words", ")", ")", "# 1, 2, 3,..., maxNum", "\n", "np", ".", "random", ".", "shuffle", "(", "ix", ")", "\n", "ix", "=", "ix", "[", ":", "cfg", ".", "TEXT", ".", "WORDS_NUM", "]", "\n", "ix", "=", "np", ".", "sort", "(", "ix", ")", "\n", "x", "[", ":", ",", "0", "]", "=", "sent_caption", "[", "ix", "]", "\n", "x_len", "=", "cfg", ".", "TEXT", ".", "WORDS_NUM", "\n", "", "return", "x", ",", "x_len", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__getitem__": [[289, 309], ["datasets.get_imgs", "numpy.randint", "numpy.randint", "datasets.TextDataset.get_caption"], "methods", ["home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.get_imgs", "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.get_caption"], ["", "def", "__getitem__", "(", "self", ",", "index", ")", ":", "\n", "#", "\n", "        ", "key", "=", "self", ".", "filenames", "[", "index", "]", "\n", "cls_id", "=", "self", ".", "class_id", "[", "index", "]", "\n", "#", "\n", "if", "self", ".", "bbox", "is", "not", "None", ":", "\n", "            ", "bbox", "=", "self", ".", "bbox", "[", "key", "]", "\n", "data_dir", "=", "'%s/CUB_200_2011'", "%", "self", ".", "data_dir", "\n", "", "else", ":", "\n", "            ", "bbox", "=", "None", "\n", "data_dir", "=", "self", ".", "data_dir", "\n", "#", "\n", "", "img_name", "=", "'%s/images/%s.jpg'", "%", "(", "data_dir", ",", "key", ")", "\n", "imgs", "=", "get_imgs", "(", "img_name", ",", "self", ".", "imsize", ",", "\n", "bbox", ",", "self", ".", "transform", ",", "normalize", "=", "self", ".", "norm", ")", "\n", "# random select a sentence", "\n", "sent_ix", "=", "random", ".", "randint", "(", "0", ",", "self", ".", "embeddings_num", ")", "\n", "new_sent_ix", "=", "index", "*", "self", ".", "embeddings_num", "+", "sent_ix", "\n", "caps", ",", "cap_len", "=", "self", ".", "get_caption", "(", "new_sent_ix", ")", "\n", "return", "imgs", ",", "caps", ",", "cap_len", ",", "cls_id", ",", "key", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.TextDataset.__len__": [[311, 313], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "filenames", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.prepare_data": [[28, 57], ["torch.sort", "torch.sort", "range", "captions[].squeeze", "class_ids[].numpy", "len", "torch.autograd.Variable().cuda", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "real_imgs.append", "real_imgs.append", "sorted_cap_indices.numpy", "torch.autograd.Variable().cuda", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable", "torch.autograd.Variable"], "function", ["None"], ["", "def", "prepare_data", "(", "data", ")", ":", "\n", "    ", "imgs", ",", "captions", ",", "captions_lens", ",", "class_ids", ",", "keys", "=", "data", "\n", "\n", "# sort data by the length in a decreasing order", "\n", "sorted_cap_lens", ",", "sorted_cap_indices", "=", "torch", ".", "sort", "(", "captions_lens", ",", "0", ",", "True", ")", "\n", "\n", "real_imgs", "=", "[", "]", "\n", "for", "i", "in", "range", "(", "len", "(", "imgs", ")", ")", ":", "\n", "        ", "imgs", "[", "i", "]", "=", "imgs", "[", "i", "]", "[", "sorted_cap_indices", "]", "\n", "if", "cfg", ".", "CUDA", ":", "\n", "            ", "real_imgs", ".", "append", "(", "Variable", "(", "imgs", "[", "i", "]", ")", ".", "cuda", "(", ")", ")", "\n", "", "else", ":", "\n", "            ", "real_imgs", ".", "append", "(", "Variable", "(", "imgs", "[", "i", "]", ")", ")", "\n", "\n", "", "", "captions", "=", "captions", "[", "sorted_cap_indices", "]", ".", "squeeze", "(", ")", "\n", "class_ids", "=", "class_ids", "[", "sorted_cap_indices", "]", ".", "numpy", "(", ")", "\n", "# sent_indices = sent_indices[sorted_cap_indices]", "\n", "keys", "=", "[", "keys", "[", "i", "]", "for", "i", "in", "sorted_cap_indices", ".", "numpy", "(", ")", "]", "\n", "# print('keys', type(keys), keys[-1])  # list", "\n", "if", "cfg", ".", "CUDA", ":", "\n", "        ", "captions", "=", "Variable", "(", "captions", ")", ".", "cuda", "(", ")", "\n", "sorted_cap_lens", "=", "Variable", "(", "sorted_cap_lens", ")", ".", "cuda", "(", ")", "\n", "", "else", ":", "\n", "        ", "captions", "=", "Variable", "(", "captions", ")", "\n", "sorted_cap_lens", "=", "Variable", "(", "sorted_cap_lens", ")", "\n", "\n", "", "return", "[", "real_imgs", ",", "captions", ",", "sorted_cap_lens", ",", "\n", "class_ids", ",", "keys", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.Tan-H-C_DR-GAN-Distribution-Regularization-for-Text-to-Image-Generation.None.datasets.get_imgs": [[59, 89], ["PIL.Image.open().convert", "int", "int", "int", "numpy.maximum", "numpy.minimum", "numpy.maximum", "numpy.minimum", "transform.crop", "transform", "range", "PIL.Image.open", "normalize", "ret.append", "numpy.maximum", "normalize", "torchvision.Scale"], "function", ["None"], ["", "def", "get_imgs", "(", "img_path", ",", "imsize", ",", "bbox", "=", "None", ",", "\n", "transform", "=", "None", ",", "normalize", "=", "None", ")", ":", "\n", "    ", "img", "=", "Image", ".", "open", "(", "img_path", ")", ".", "convert", "(", "'RGB'", ")", "\n", "width", ",", "height", "=", "img", ".", "size", "\n", "if", "bbox", "is", "not", "None", ":", "\n", "        ", "r", "=", "int", "(", "np", ".", "maximum", "(", "bbox", "[", "2", "]", ",", "bbox", "[", "3", "]", ")", "*", "0.75", ")", "\n", "center_x", "=", "int", "(", "(", "2", "*", "bbox", "[", "0", "]", "+", "bbox", "[", "2", "]", ")", "/", "2", ")", "\n", "center_y", "=", "int", "(", "(", "2", "*", "bbox", "[", "1", "]", "+", "bbox", "[", "3", "]", ")", "/", "2", ")", "\n", "y1", "=", "np", ".", "maximum", "(", "0", ",", "center_y", "-", "r", ")", "\n", "y2", "=", "np", ".", "minimum", "(", "height", ",", "center_y", "+", "r", ")", "\n", "x1", "=", "np", ".", "maximum", "(", "0", ",", "center_x", "-", "r", ")", "\n", "x2", "=", "np", ".", "minimum", "(", "width", ",", "center_x", "+", "r", ")", "\n", "img", "=", "img", ".", "crop", "(", "[", "x1", ",", "y1", ",", "x2", ",", "y2", "]", ")", "\n", "\n", "", "if", "transform", "is", "not", "None", ":", "\n", "        ", "img", "=", "transform", "(", "img", ")", "\n", "\n", "", "ret", "=", "[", "]", "\n", "if", "cfg", ".", "GAN", ".", "B_DCGAN", ":", "\n", "        ", "ret", "=", "[", "normalize", "(", "img", ")", "]", "\n", "", "else", ":", "\n", "        ", "for", "i", "in", "range", "(", "cfg", ".", "TREE", ".", "BRANCH_NUM", ")", ":", "\n", "# print(imsize[i])", "\n", "            ", "if", "i", "<", "(", "cfg", ".", "TREE", ".", "BRANCH_NUM", "-", "1", ")", ":", "\n", "                ", "re_img", "=", "transforms", ".", "Scale", "(", "imsize", "[", "i", "]", ")", "(", "img", ")", "\n", "", "else", ":", "\n", "                ", "re_img", "=", "img", "\n", "", "ret", ".", "append", "(", "normalize", "(", "re_img", ")", ")", "\n", "\n", "", "", "return", "ret", "\n", "\n"]]}