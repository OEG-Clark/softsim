{"home.repos.pwc.inspect_result.dwadden_dygiepp.predictors.dygie.DyGIEPredictor.__init__": [[26, 29], ["allennlp.predictors.predictor.Predictor.__init__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["def", "__init__", "(", "\n", "self", ",", "model", ":", "Model", ",", "dataset_reader", ":", "DatasetReader", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "model", ",", "dataset_reader", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.predictors.dygie.DyGIEPredictor.predict": [[30, 32], ["dygie.DyGIEPredictor.predict_json"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "document", ")", ":", "\n", "        ", "return", "self", ".", "predict_json", "(", "{", "\"document\"", ":", "document", "}", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.predictors.dygie.DyGIEPredictor.predict_tokenized": [[33, 36], ["dygie.DyGIEPredictor._words_list_to_instance", "dygie.DyGIEPredictor.predict_instance"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.predictors.dygie.DyGIEPredictor.predict_instance"], ["", "def", "predict_tokenized", "(", "self", ",", "tokenized_document", ":", "List", "[", "str", "]", ")", "->", "JsonDict", ":", "\n", "        ", "instance", "=", "self", ".", "_words_list_to_instance", "(", "tokenized_document", ")", "\n", "return", "self", ".", "predict_instance", "(", "instance", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.predictors.dygie.DyGIEPredictor.dump_line": [[37, 41], ["json.dumps"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "dump_line", "(", "self", ",", "outputs", ")", ":", "\n", "# Need to override to tell Python how to deal with Numpy ints.", "\n", "        ", "return", "json", ".", "dumps", "(", "outputs", ",", "default", "=", "int", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.predictors.dygie.DyGIEPredictor.predict_instance": [[43, 70], ["model._get_prediction_device", "allennlp.data.Batch", "allennlp.data.Batch.index_instances", "allennlp.nn.util.move_to_device", "model.make_output_human_readable().to_json", "allennlp.data.Batch.as_tensor_dict", "warnings.warn", "metadata.to_json", "model.make_output_human_readable", "model"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.make_output_human_readable"], ["", "@", "overrides", "\n", "def", "predict_instance", "(", "self", ",", "instance", ")", ":", "\n", "        ", "\"\"\"\n        An instance is an entire document, represented as a list of sentences.\n        \"\"\"", "\n", "model", "=", "self", ".", "_model", "\n", "cuda_device", "=", "model", ".", "_get_prediction_device", "(", ")", "\n", "\n", "# Try to predict this batch.", "\n", "try", ":", "\n", "            ", "dataset", "=", "Batch", "(", "[", "instance", "]", ")", "\n", "dataset", ".", "index_instances", "(", "model", ".", "vocab", ")", "\n", "model_input", "=", "util", ".", "move_to_device", "(", "dataset", ".", "as_tensor_dict", "(", ")", ",", "cuda_device", ")", "\n", "prediction", "=", "model", ".", "make_output_human_readable", "(", "model", "(", "**", "model_input", ")", ")", ".", "to_json", "(", ")", "\n", "# If we run out of GPU memory, warn user and indicate that this document failed.", "\n", "# This way, prediction doesn't grind to a halt every time we run out of GPU.", "\n", "", "except", "RuntimeError", "as", "err", ":", "\n", "# doc_key, dataset, sentences, message", "\n", "            ", "metadata", "=", "instance", "[", "\"metadata\"", "]", ".", "metadata", "\n", "doc_key", "=", "metadata", ".", "doc_key", "\n", "msg", "=", "(", "f\"Encountered a RunTimeError on document {doc_key}. Skipping this example.\"", "\n", "f\" Error message:\\n{err.args[0]}.\"", ")", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "prediction", "=", "metadata", ".", "to_json", "(", ")", "\n", "prediction", "[", "\"_FAILED_PREDICTION\"", "]", "=", "True", "\n", "\n", "", "return", "prediction", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics.__init__": [[30, 32], ["event_metrics.EventMetrics.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics.__call__": [[33, 46], ["zip", "event_metrics.EventMetrics._score_triggers", "event_metrics.EventMetrics._score_arguments"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics._score_triggers", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics._score_arguments"], ["", "@", "overrides", "\n", "def", "__call__", "(", "self", ",", "predicted_events_list", ",", "metadata_list", ")", ":", "\n", "        ", "for", "predicted_events", ",", "metadata", "in", "zip", "(", "predicted_events_list", ",", "metadata_list", ")", ":", "\n", "# Trigger scoring.", "\n", "            ", "predicted_triggers", "=", "predicted_events", "[", "\"trigger_dict\"", "]", "\n", "gold_triggers", "=", "metadata", ".", "events", ".", "trigger_dict", "\n", "self", ".", "_score_triggers", "(", "predicted_triggers", ",", "gold_triggers", ")", "\n", "\n", "# Argument scoring.", "\n", "predicted_arguments", "=", "predicted_events", "[", "\"argument_dict\"", "]", "\n", "gold_arguments", "=", "metadata", ".", "events", ".", "argument_dict", "\n", "self", ".", "_score_arguments", "(", "\n", "predicted_triggers", ",", "gold_triggers", ",", "predicted_arguments", ",", "gold_arguments", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics._score_triggers": [[47, 57], ["len", "len", "predicted_triggers.items"], "methods", ["None"], ["", "", "def", "_score_triggers", "(", "self", ",", "predicted_triggers", ",", "gold_triggers", ")", ":", "\n", "        ", "self", ".", "_gold_triggers", "+=", "len", "(", "gold_triggers", ")", "\n", "self", ".", "_predicted_triggers", "+=", "len", "(", "predicted_triggers", ")", "\n", "for", "token_ix", ",", "pred", "in", "predicted_triggers", ".", "items", "(", ")", ":", "\n", "            ", "label", "=", "pred", "[", "0", "]", "\n", "# Check whether the offsets match, and whether the labels match.", "\n", "if", "token_ix", "in", "gold_triggers", ":", "\n", "                ", "self", ".", "_matched_trigger_ids", "+=", "1", "\n", "if", "gold_triggers", "[", "token_ix", "]", "==", "label", ":", "\n", "                    ", "self", ".", "_matched_trigger_classes", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics._score_arguments": [[58, 90], ["event_metrics.EventMetrics._score_arguments.format"], "methods", ["None"], ["", "", "", "", "def", "_score_arguments", "(", "self", ",", "predicted_triggers", ",", "gold_triggers", ",", "predicted_arguments", ",", "gold_arguments", ")", ":", "\n", "# Note that the index of the trigger doesn't actually need to be correct to get full credit;", "\n", "# the event type and event role need to be correct (see Sec. 3 of paper).", "\n", "        ", "def", "format", "(", "arg_dict", ",", "trigger_dict", ",", "prediction", "=", "False", ")", ":", "\n", "# Make it a list of [index, event_type, arg_label].", "\n", "            ", "res", "=", "[", "]", "\n", "for", "(", "trigger_ix", ",", "arg_ix", ")", ",", "label", "in", "arg_dict", ".", "items", "(", ")", ":", "\n", "# If it doesn't match a trigger, don't predict it (enforced in decoding).", "\n", "                ", "if", "trigger_ix", "not", "in", "trigger_dict", ":", "\n", "                    ", "continue", "\n", "", "event_type", "=", "trigger_dict", "[", "trigger_ix", "]", "\n", "# TODO(dwadden) This is clunky; it's because predictions have confidence scores.", "\n", "if", "prediction", ":", "\n", "                    ", "event_type", "=", "event_type", "[", "0", "]", "\n", "label", "=", "label", "[", "0", "]", "\n", "", "res", ".", "append", "(", "(", "arg_ix", ",", "event_type", ",", "label", ")", ")", "\n", "", "return", "res", "\n", "\n", "", "formatted_gold_arguments", "=", "format", "(", "gold_arguments", ",", "gold_triggers", ",", "prediction", "=", "False", ")", "\n", "formatted_predicted_arguments", "=", "format", "(", "predicted_arguments", ",", "predicted_triggers", ",", "prediction", "=", "True", ")", "\n", "\n", "self", ".", "_gold_arguments", "+=", "len", "(", "formatted_gold_arguments", ")", "\n", "self", ".", "_predicted_arguments", "+=", "len", "(", "formatted_predicted_arguments", ")", "\n", "\n", "# Go through each predicted arg and look for a match.", "\n", "for", "entry", "in", "formatted_predicted_arguments", ":", "\n", "# No credit if not associated with a predicted trigger.", "\n", "            ", "class_match", "=", "int", "(", "any", "(", "[", "entry", "==", "gold", "for", "gold", "in", "formatted_gold_arguments", "]", ")", ")", "\n", "id_match", "=", "int", "(", "any", "(", "[", "entry", "[", ":", "2", "]", "==", "gold", "[", ":", "2", "]", "for", "gold", "in", "formatted_gold_arguments", "]", ")", ")", "\n", "\n", "self", ".", "_matched_argument_classes", "+=", "class_match", "\n", "self", ".", "_matched_argument_ids", "+=", "id_match", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics.get_metric": [[92, 113], ["dygie.training.f1.compute_f1", "dygie.training.f1.compute_f1", "dygie.training.f1.compute_f1", "dygie.training.f1.compute_f1", "event_metrics.EventMetrics.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.compute_f1", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.compute_f1", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.compute_f1", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.compute_f1", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["", "", "@", "overrides", "\n", "def", "get_metric", "(", "self", ",", "reset", "=", "False", ")", ":", "\n", "        ", "res", "=", "{", "}", "\n", "\n", "# Triggers", "\n", "res", "[", "\"trig_id_precision\"", "]", ",", "res", "[", "\"trig_id_recall\"", "]", ",", "res", "[", "\"trig_id_f1\"", "]", "=", "compute_f1", "(", "\n", "self", ".", "_predicted_triggers", ",", "self", ".", "_gold_triggers", ",", "self", ".", "_matched_trigger_ids", ")", "\n", "res", "[", "\"trig_class_precision\"", "]", ",", "res", "[", "\"trig_class_recall\"", "]", ",", "res", "[", "\"trig_class_f1\"", "]", "=", "compute_f1", "(", "\n", "self", ".", "_predicted_triggers", ",", "self", ".", "_gold_triggers", ",", "self", ".", "_matched_trigger_classes", ")", "\n", "\n", "# Arguments", "\n", "res", "[", "\"arg_id_precision\"", "]", ",", "res", "[", "\"arg_id_recall\"", "]", ",", "res", "[", "\"arg_id_f1\"", "]", "=", "compute_f1", "(", "\n", "self", ".", "_predicted_arguments", ",", "self", ".", "_gold_arguments", ",", "self", ".", "_matched_argument_ids", ")", "\n", "res", "[", "\"arg_class_precision\"", "]", ",", "res", "[", "\"arg_class_recall\"", "]", ",", "res", "[", "\"arg_class_f1\"", "]", "=", "compute_f1", "(", "\n", "self", ".", "_predicted_arguments", ",", "self", ".", "_gold_arguments", ",", "self", ".", "_matched_argument_classes", ")", "\n", "\n", "# Reset counts if at end of epoch.", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.EventMetrics.reset": [[114, 124], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_gold_triggers", "=", "0", "\n", "self", ".", "_predicted_triggers", "=", "0", "\n", "self", ".", "_matched_trigger_ids", "=", "0", "\n", "self", ".", "_matched_trigger_classes", "=", "0", "\n", "self", ".", "_gold_arguments", "=", "0", "\n", "self", ".", "_predicted_arguments", "=", "0", "\n", "self", ".", "_matched_argument_ids", "=", "0", "\n", "self", ".", "_matched_argument_classes", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.ArgumentStats.__init__": [[130, 132], ["event_metrics.ArgumentStats.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.ArgumentStats.__call__": [[133, 146], ["event_metrics._invert_arguments", "collections.Counter", "len", "len", "collections.Counter.items"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics._invert_arguments"], ["", "@", "overrides", "\n", "def", "__call__", "(", "self", ",", "predicted_events_list", ")", ":", "\n", "        ", "for", "predicted_events", "in", "predicted_events_list", ":", "\n", "            ", "predicted_arguments", "=", "_invert_arguments", "(", "predicted_events", "[", "\"argument_dict\"", "]", ",", "\n", "predicted_events", "[", "\"trigger_dict\"", "]", ")", "\n", "# Count how many times each span appears as an argument.", "\n", "span_counts", "=", "Counter", "(", ")", "\n", "for", "prediction", "in", "predicted_arguments", ":", "\n", "                ", "span_counts", "[", "prediction", "[", "0", "]", "]", "+=", "1", "\n", "# Count how many spans appear more than once.", "\n", "", "repeated", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "span_counts", ".", "items", "(", ")", "if", "v", ">", "1", "}", "\n", "self", ".", "_total_arguments", "+=", "len", "(", "span_counts", ")", "\n", "self", ".", "_repeated_arguments", "+=", "len", "(", "repeated", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.ArgumentStats.get_metric": [[147, 159], ["dict", "event_metrics.ArgumentStats.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["", "", "@", "overrides", "\n", "def", "get_metric", "(", "self", ",", "reset", "=", "False", ")", ":", "\n", "# Fraction of event arguments associated with multiple triggers.", "\n", "        ", "args_multiple", "=", "(", "self", ".", "_repeated_arguments", "/", "self", ".", "_total_arguments", "\n", "if", "self", ".", "_total_arguments", "\n", "else", "0", ")", "\n", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "res", "=", "dict", "(", "args_multiple", "=", "args_multiple", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics.ArgumentStats.reset": [[160, 164], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_total_arguments", "=", "0", "\n", "self", ".", "_repeated_arguments", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.event_metrics._invert_arguments": [[9, 23], ["set", "arguments.items", "set.add"], "function", ["None"], ["def", "_invert_arguments", "(", "arguments", ",", "triggers", ")", ":", "\n", "    ", "\"\"\"\n    For scoring the argument, we don't need the trigger spans to match exactly. We just need the\n    trigger label corresponding to the predicted trigger span to be correct.\n    \"\"\"", "\n", "# Can't use a dict because multiple triggers could share the same argument.", "\n", "inverted", "=", "set", "(", ")", "\n", "for", "k", ",", "v", "in", "arguments", ".", "items", "(", ")", ":", "\n", "        ", "if", "k", "[", "0", "]", "in", "triggers", ":", "# If it's not, the trigger this arg points to is null. TODO(dwadden) check.", "\n", "            ", "trigger_label", "=", "triggers", "[", "k", "[", "0", "]", "]", "\n", "to_append", "=", "(", "k", "[", "1", "]", ",", "trigger_label", ",", "v", ")", "\n", "inverted", ".", "add", "(", "to_append", ")", "\n", "\n", "", "", "return", "inverted", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.relation_metrics.RelationMetrics.__init__": [[12, 14], ["relation_metrics.RelationMetrics.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["def", "__init__", "(", "self", ")", ":", "\n", "        ", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.relation_metrics.RelationMetrics.__call__": [[18, 28], ["zip", "len", "len", "predicted_relations.items"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "__call__", "(", "self", ",", "predicted_relation_list", ",", "metadata_list", ")", ":", "\n", "        ", "for", "predicted_relations", ",", "metadata", "in", "zip", "(", "predicted_relation_list", ",", "metadata_list", ")", ":", "\n", "            ", "gold_relations", "=", "metadata", ".", "relation_dict", "\n", "self", ".", "_total_gold", "+=", "len", "(", "gold_relations", ")", "\n", "self", ".", "_total_predicted", "+=", "len", "(", "predicted_relations", ")", "\n", "for", "(", "span_1", ",", "span_2", ")", ",", "label", "in", "predicted_relations", ".", "items", "(", ")", ":", "\n", "                ", "ix", "=", "(", "span_1", ",", "span_2", ")", "\n", "if", "ix", "in", "gold_relations", "and", "gold_relations", "[", "ix", "]", "==", "label", ":", "\n", "                    ", "self", ".", "_total_matched", "+=", "1", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.relation_metrics.RelationMetrics.get_metric": [[29, 38], ["dygie.training.f1.compute_f1", "relation_metrics.RelationMetrics.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.compute_f1", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["", "", "", "", "@", "overrides", "\n", "def", "get_metric", "(", "self", ",", "reset", "=", "False", ")", ":", "\n", "        ", "precision", ",", "recall", ",", "f1", "=", "compute_f1", "(", "self", ".", "_total_predicted", ",", "self", ".", "_total_gold", ",", "self", ".", "_total_matched", ")", "\n", "\n", "# Reset counts if at end of epoch.", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "return", "precision", ",", "recall", ",", "f1", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.relation_metrics.RelationMetrics.reset": [[39, 44], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_total_gold", "=", "0", "\n", "self", ".", "_total_predicted", "=", "0", "\n", "self", ".", "_total_matched", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.safe_div": [[6, 11], ["None"], "function", ["None"], ["def", "safe_div", "(", "num", ",", "denom", ")", ":", "\n", "    ", "if", "denom", ">", "0", ":", "\n", "        ", "return", "num", "/", "denom", "\n", "", "else", ":", "\n", "        ", "return", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.compute_f1": [[13, 18], ["f1.safe_div", "f1.safe_div", "f1.safe_div"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.safe_div", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.safe_div", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.safe_div"], ["", "", "def", "compute_f1", "(", "predicted", ",", "gold", ",", "matched", ")", ":", "\n", "    ", "precision", "=", "safe_div", "(", "matched", ",", "predicted", ")", "\n", "recall", "=", "safe_div", "(", "matched", ",", "gold", ")", "\n", "f1", "=", "safe_div", "(", "2", "*", "precision", "*", "recall", ",", "precision", "+", "recall", ")", "\n", "return", "precision", ",", "recall", ",", "f1", "\n", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.__init__": [[17, 21], ["ner_metrics.NERMetrics.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["def", "__init__", "(", "self", ",", "number_of_classes", ":", "int", ",", "none_label", ":", "int", "=", "0", ")", ":", "\n", "        ", "self", ".", "number_of_classes", "=", "number_of_classes", "\n", "self", ".", "none_label", "=", "none_label", "\n", "self", ".", "reset", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.__call__": [[22, 37], ["predictions.cpu.cpu.cpu", "gold_labels.cpu.cpu.cpu", "mask.cpu.cpu.cpu", "range", "mask.cpu.cpu.bool", "mask.cpu.cpu.bool", "mask.cpu.cpu.bool", "mask.cpu.cpu.bool"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "__call__", "(", "self", ",", "\n", "predictions", ":", "torch", ".", "Tensor", ",", "\n", "gold_labels", ":", "torch", ".", "Tensor", ",", "\n", "mask", ":", "Optional", "[", "torch", ".", "Tensor", "]", "=", "None", ")", ":", "\n", "        ", "predictions", "=", "predictions", ".", "cpu", "(", ")", "\n", "gold_labels", "=", "gold_labels", ".", "cpu", "(", ")", "\n", "mask", "=", "mask", ".", "cpu", "(", ")", "\n", "for", "i", "in", "range", "(", "self", ".", "number_of_classes", ")", ":", "\n", "            ", "if", "i", "==", "self", ".", "none_label", ":", "\n", "                ", "continue", "\n", "", "self", ".", "_true_positives", "+=", "(", "(", "predictions", "==", "i", ")", "*", "(", "gold_labels", "==", "i", ")", "*", "mask", ".", "bool", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "_false_positives", "+=", "(", "(", "predictions", "==", "i", ")", "*", "(", "gold_labels", "!=", "i", ")", "*", "mask", ".", "bool", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "_true_negatives", "+=", "(", "(", "predictions", "!=", "i", ")", "*", "(", "gold_labels", "!=", "i", ")", "*", "mask", ".", "bool", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "self", ".", "_false_negatives", "+=", "(", "(", "predictions", "!=", "i", ")", "*", "(", "gold_labels", "==", "i", ")", "*", "mask", ".", "bool", "(", ")", ")", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.get_metric": [[38, 58], ["dygie.training.f1.compute_f1", "ner_metrics.NERMetrics.reset"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.f1.compute_f1", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset"], ["", "", "@", "overrides", "\n", "def", "get_metric", "(", "self", ",", "reset", "=", "False", ")", ":", "\n", "        ", "\"\"\"\n        Returns\n        -------\n        A tuple of the following metrics based on the accumulated count statistics:\n        precision : float\n        recall : float\n        f1-measure : float\n        \"\"\"", "\n", "predicted", "=", "self", ".", "_true_positives", "+", "self", ".", "_false_positives", "\n", "gold", "=", "self", ".", "_true_positives", "+", "self", ".", "_false_negatives", "\n", "matched", "=", "self", ".", "_true_positives", "\n", "precision", ",", "recall", ",", "f1_measure", "=", "compute_f1", "(", "predicted", ",", "gold", ",", "matched", ")", "\n", "\n", "# Reset counts if at end of epoch.", "\n", "if", "reset", ":", "\n", "            ", "self", ".", "reset", "(", ")", "\n", "\n", "", "return", "precision", ",", "recall", ",", "f1_measure", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.reset": [[59, 65], ["None"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "reset", "(", "self", ")", ":", "\n", "        ", "self", ".", "_true_positives", "=", "0", "\n", "self", ".", "_false_positives", "=", "0", "\n", "self", ".", "_true_negatives", "=", "0", "\n", "self", ".", "_false_negatives", "=", "0", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE.__init__": [[56, 139], ["allennlp.nn.InitializerApplicator", "allennlp.nn.InitializerApplicator", "allennlp.models.model.Model.__init__", "allennlp.modules.span_extractors.EndpointSpanExtractor", "dygie.DyGIE._get_display_metrics", "dygie.DyGIE._embedder.get_output_dim", "dygie.DyGIE._endpoint_span_extractor.get_output_dim", "allennlp.common.params.Params", "dygie.models.ner.NERTagger.from_params", "dygie.models.coref.CorefResolver.from_params", "dygie.models.relation.RelationExtractor.from_params", "dygie.models.events.EventExtractor.from_params", "initializer", "embedder.get_output_dim", "allennlp.modules.FeedForward", "module_initializer", "allennlp.common.params.Params.pop", "allennlp.common.params.Params.pop", "allennlp.common.params.Params.pop", "allennlp.common.params.Params.pop", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU", "torch.nn.ReLU"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._get_display_metrics"], ["prediction", "=", "model", ".", "make_output_human_readable", "(", "model", "(", "**", "model_input", ")", ")", ".", "to_json", "(", ")", "\n", "# If we run out of GPU memory, warn user and indicate that this document failed.", "\n", "# This way, prediction doesn't grind to a halt every time we run out of GPU.", "\n", "", "except", "RuntimeError", "as", "err", ":", "\n", "# doc_key, dataset, sentences, message", "\n", "            ", "metadata", "=", "instance", "[", "\"metadata\"", "]", ".", "metadata", "\n", "doc_key", "=", "metadata", ".", "doc_key", "\n", "msg", "=", "(", "f\"Encountered a RunTimeError on document {doc_key}. Skipping this example.\"", "\n", "f\" Error message:\\n{err.args[0]}.\"", ")", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "prediction", "=", "metadata", ".", "to_json", "(", ")", "\n", "prediction", "[", "\"_FAILED_PREDICTION\"", "]", "=", "True", "\n", "\n", "", "return", "prediction", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._get_display_metrics": [[140, 157], ["ValueError"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch": [[158, 162], ["x.squeeze"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE.forward": [[163, 275], ["dygie.DyGIE._debatch", "dygie.DyGIE._debatch", "dygie.DyGIE._debatch", "dygie.DyGIE._debatch", "dygie.DyGIE._debatch", "dygie.DyGIE._debatch", "dygie.DyGIE._embedder", "dygie.DyGIE._debatch", "dygie.DyGIE._debatch", "dygie.DyGIE.sum().long", "torch.relu().long", "torch.relu().long", "dygie.DyGIE._endpoint_span_extractor", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "dict", "relation_labels.long.long.long", "argument_labels.long.long.long", "len", "NotImplementedError", "allennlp.nn.util.get_text_field_mask().float", "dygie.DyGIE._coref.compute_representations", "dygie.DyGIE._coref.coref_propagation", "dygie.DyGIE._coref.update_spans", "dygie.DyGIE._ner", "dygie.DyGIE._coref.predict_labels", "dygie.DyGIE._relation", "dygie.DyGIE._events", "dygie.DyGIE.sum", "torch.relu", "torch.relu", "dygie.DyGIE.get", "allennlp.nn.util.get_text_field_mask", "torch.relu().long.float", "dygie.DyGIE.get", "dygie.DyGIE.get", "dygie.DyGIE.get"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE._debatch", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.compute_representations", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.coref_propagation", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.update_spans", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.predict_labels"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE.update_span_embeddings": [[276, 288], ["span_embeddings.clone", "range", "len", "enumerate"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE.make_output_human_readable": [[289, 335], ["copy.deepcopy", "zip", "zip", "zip", "dygie.data.dataset_readers.document.Cluster", "dygie.DyGIE._coref.make_output_human_readable", "enumerate"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.make_output_human_readable"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie.DyGIE.get_metrics": [[336, 367], ["dygie.DyGIE._coref.get_metrics", "dygie.DyGIE._ner.get_metrics", "dygie.DyGIE._relation.get_metrics", "dygie.DyGIE._events.get_metrics", "dict", "dict.items", "list", "len", "len", "list", "dygie.DyGIE.keys", "set", "list", "list", "list", "dygie.DyGIE.keys", "list", "dygie.DyGIE.items", "dygie.DyGIE.keys", "dygie.DyGIE.keys", "list", "list", "dygie.DyGIE.items", "dygie.DyGIE.items", "dygie.DyGIE.items"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_metrics", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_metrics", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_metrics", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_metrics"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.shared.cumsum_shifted": [[8, 17], ["xs.cumsum", "torch.zeros", "torch.cat"], "function", ["None"], ["def", "cumsum_shifted", "(", "xs", ")", ":", "\n", "    ", "\"\"\"\n    Assumes `xs` is a 1-d array.\n    The usual cumsum has elements [x[1], x[1] + x[2], ...]. This one has elements\n    [0, x[1], x[1] + x[2], ...]. Useful for calculating sentence offsets.\n    \"\"\"", "\n", "cs", "=", "xs", ".", "cumsum", "(", "dim", "=", "0", ")", "\n", "shift", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "cs", ".", "device", ")", "# Put on correct device.", "\n", "return", "torch", ".", "cat", "(", "[", "shift", ",", "cs", "[", ":", "-", "1", "]", "]", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.shared.batch_identity": [[19, 26], ["torch.eye().unsqueeze", "torch.eye().unsqueeze.repeat", "torch.eye"], "function", ["None"], ["", "def", "batch_identity", "(", "batch_size", ",", "matrix_size", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    ", "\"\"\"\n    Tile the identity matrix along axis 0, `batch_size` times.\n    \"\"\"", "\n", "ident", "=", "torch", ".", "eye", "(", "matrix_size", ",", "*", "args", ",", "**", "kwargs", ")", ".", "unsqueeze", "(", "0", ")", "\n", "res", "=", "ident", ".", "repeat", "(", "batch_size", ",", "1", ",", "1", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.shared.fields_to_batches": [[28, 51], ["len", "len", "ValueError", "list", "d.keys", "set", "lengths.values", "range", "lengths.values"], "function", ["None"], ["", "def", "fields_to_batches", "(", "d", ",", "keys_to_ignore", "=", "[", "]", ")", ":", "\n", "    ", "\"\"\"\n    The input is a dict whose items are batched tensors. The output is a list of dictionaries - one\n    per entry in the batch - with the slices of the tensors for that entry. Here's an example.\n    Input:\n    d = {\"a\": [[1, 2], [3,4]], \"b\": [1, 2]}\n    Output:\n    res = [{\"a\": [1, 2], \"b\": 1}, {\"a\": [3, 4], \"b\": 2}].\n    \"\"\"", "\n", "keys", "=", "[", "key", "for", "key", "in", "d", ".", "keys", "(", ")", "if", "key", "not", "in", "keys_to_ignore", "]", "\n", "\n", "# Make sure all input dicts have same length. If they don't, there's a problem.", "\n", "lengths", "=", "{", "k", ":", "len", "(", "d", "[", "k", "]", ")", "for", "k", "in", "keys", "}", "\n", "if", "len", "(", "set", "(", "lengths", ".", "values", "(", ")", ")", ")", "!=", "1", ":", "\n", "        ", "msg", "=", "f\"fields have different lengths: {lengths}.\"", "\n", "# If there's a doc key, add it to specify where the error is.", "\n", "if", "\"doc_key\"", "in", "d", ":", "\n", "            ", "msg", "=", "f\"For document {d['doc_key']}, \"", "+", "msg", "\n", "", "raise", "ValueError", "(", "msg", ")", "\n", "\n", "", "length", "=", "list", "(", "lengths", ".", "values", "(", ")", ")", "[", "0", "]", "\n", "res", "=", "[", "{", "k", ":", "d", "[", "k", "]", "[", "i", "]", "for", "k", "in", "keys", "}", "for", "i", "in", "range", "(", "length", ")", "]", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.shared.batches_to_fields": [[53, 69], ["batches[].keys", "batch.items", "set", "set", "ValueError", "res[].append", "entry.keys"], "function", ["None"], ["", "def", "batches_to_fields", "(", "batches", ")", ":", "\n", "    ", "\"\"\"\n    The inverse of `fields_to_batches`.\n    \"\"\"", "\n", "# Make sure all the keys match.", "\n", "first_keys", "=", "batches", "[", "0", "]", ".", "keys", "(", ")", "\n", "for", "entry", "in", "batches", "[", "1", ":", "]", ":", "\n", "        ", "if", "set", "(", "entry", ".", "keys", "(", ")", ")", "!=", "set", "(", "first_keys", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Keys to not match on all entries.\"", ")", "\n", "\n", "", "", "res", "=", "{", "k", ":", "[", "]", "for", "k", "in", "first_keys", "}", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", ":", "\n", "            ", "res", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n", "", "", "return", "res", "\n", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor.__init__": [[30, 112], ["allennlp.models.model.Model.__init__", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "allennlp.modules.token_embedders.Embedding", "set", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "vocab.get_vocab_size", "vocab.get_vocab_size", "vocab.get_token_index", "make_feedforward", "dygie.models.entity_beam_pruner.make_pruner", "make_feedforward", "torch.nn.Sequential", "make_feedforward", "dygie.models.entity_beam_pruner.make_pruner", "make_feedforward", "torch.nn.Linear", "dygie.training.event_metrics.EventMetrics", "vocab.get_namespaces", "vocab.get_namespaces", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "make_feedforward.get_output_dim", "torch.nn.Linear", "x.split", "make_feedforward.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.entity_beam_pruner.make_pruner", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.entity_beam_pruner.make_pruner", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "make_feedforward", ":", "Callable", ",", "\n", "token_emb_dim", ":", "int", ",", "# Triggers are represented via token embeddings.", "\n", "span_emb_dim", ":", "int", ",", "# Arguments are represented via span embeddings.", "\n", "feature_size", ":", "int", ",", "\n", "trigger_spans_per_word", ":", "float", ",", "\n", "argument_spans_per_word", ":", "float", ",", "\n", "loss_weights", ":", "Dict", "[", "str", ",", "float", "]", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "EventExtractor", ",", "self", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "_trigger_namespaces", "=", "[", "entry", "for", "entry", "in", "vocab", ".", "get_namespaces", "(", ")", "\n", "if", "\"trigger_labels\"", "in", "entry", "]", "\n", "self", ".", "_argument_namespaces", "=", "[", "entry", "for", "entry", "in", "vocab", ".", "get_namespaces", "(", ")", "\n", "if", "\"argument_labels\"", "in", "entry", "]", "\n", "\n", "self", ".", "_n_trigger_labels", "=", "{", "name", ":", "vocab", ".", "get_vocab_size", "(", "name", ")", "\n", "for", "name", "in", "self", ".", "_trigger_namespaces", "}", "\n", "self", ".", "_n_argument_labels", "=", "{", "name", ":", "vocab", ".", "get_vocab_size", "(", "name", ")", "\n", "for", "name", "in", "self", ".", "_argument_namespaces", "}", "\n", "\n", "# Make sure the null trigger label is always 0.", "\n", "for", "namespace", "in", "self", ".", "_trigger_namespaces", ":", "\n", "            ", "null_label", "=", "vocab", ".", "get_token_index", "(", "\"\"", ",", "namespace", ")", "\n", "assert", "null_label", "==", "0", "# If not, the dummy class won't correspond to the null label.", "\n", "\n", "# Create trigger scorers and pruners.", "\n", "", "self", ".", "_trigger_scorers", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "_trigger_pruners", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "for", "trigger_namespace", "in", "self", ".", "_trigger_namespaces", ":", "\n", "# The trigger pruner.", "\n", "            ", "trigger_candidate_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "token_emb_dim", ")", "\n", "self", ".", "_trigger_pruners", "[", "trigger_namespace", "]", "=", "make_pruner", "(", "trigger_candidate_feedforward", ")", "\n", "# The trigger scorer.", "\n", "trigger_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "token_emb_dim", ")", "\n", "self", ".", "_trigger_scorers", "[", "trigger_namespace", "]", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "trigger_feedforward", ")", ",", "\n", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "trigger_feedforward", ".", "get_output_dim", "(", ")", ",", "\n", "self", ".", "_n_trigger_labels", "[", "trigger_namespace", "]", "-", "1", ")", ")", ")", "\n", "\n", "# Creater argument scorers and pruners.", "\n", "", "self", ".", "_mention_pruners", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "_argument_feedforwards", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "_argument_scorers", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "for", "argument_namespace", "in", "self", ".", "_argument_namespaces", ":", "\n", "# The argument pruner.", "\n", "            ", "mention_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "span_emb_dim", ")", "\n", "self", ".", "_mention_pruners", "[", "argument_namespace", "]", "=", "make_pruner", "(", "mention_feedforward", ")", "\n", "# The argument scorer. The `+ 2` is there because I include indicator features for", "\n", "# whether the trigger is before or inside the arg span.", "\n", "\n", "# TODO(dwadden) Here", "\n", "argument_feedforward_dim", "=", "token_emb_dim", "+", "span_emb_dim", "+", "feature_size", "+", "2", "\n", "argument_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "argument_feedforward_dim", ")", "\n", "self", ".", "_argument_feedforwards", "[", "argument_namespace", "]", "=", "argument_feedforward", "\n", "self", ".", "_argument_scorers", "[", "argument_namespace", "]", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "argument_feedforward", ".", "get_output_dim", "(", ")", ",", "self", ".", "_n_argument_labels", "[", "argument_namespace", "]", ")", "\n", "\n", "# Weight on trigger labeling and argument labeling.", "\n", "", "self", ".", "_loss_weights", "=", "loss_weights", "\n", "\n", "# Distance embeddings.", "\n", "self", ".", "_num_distance_buckets", "=", "10", "# Just use 10 which is the default.", "\n", "self", ".", "_distance_embedding", "=", "Embedding", "(", "embedding_dim", "=", "feature_size", ",", "\n", "num_embeddings", "=", "self", ".", "_num_distance_buckets", ")", "\n", "\n", "self", ".", "_trigger_spans_per_word", "=", "trigger_spans_per_word", "\n", "self", ".", "_argument_spans_per_word", "=", "argument_spans_per_word", "\n", "\n", "# Metrics", "\n", "# Make a metric for each dataset (not each namespace).", "\n", "namespaces", "=", "self", ".", "_trigger_namespaces", "+", "self", ".", "_argument_namespaces", "\n", "datasets", "=", "set", "(", "[", "x", ".", "split", "(", "\"__\"", ")", "[", "0", "]", "for", "x", "in", "namespaces", "]", ")", "\n", "self", ".", "_metrics", "=", "{", "dataset", ":", "EventMetrics", "(", ")", "for", "dataset", "in", "datasets", "}", "\n", "\n", "self", ".", "_active_namespaces", "=", "{", "\"trigger\"", ":", "None", ",", "\"argument\"", ":", "None", "}", "\n", "self", ".", "_active_dataset", "=", "None", "\n", "\n", "# Trigger and argument loss.", "\n", "self", ".", "_trigger_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ")", "\n", "self", ".", "_argument_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ",", "ignore_index", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor.forward": [[115, 217], ["events.EventExtractor._compute_trigger_scores", "torch.floor().long", "torch.max", "torch.min", "trigger_pruner", "top_trig_mask.unsqueeze.unsqueeze.unsqueeze", "torch.floor().long", "torch.max", "torch.min", "mention_pruner", "top_arg_mask.unsqueeze.unsqueeze.unsqueeze", "allennlp.nn.util.batched_index_select", "events.EventExtractor._compute_trig_arg_embeddings", "events.EventExtractor._compute_argument_scores", "events.EventExtractor.predict", "torch.ones_like", "torch.ones_like", "events.EventExtractor._get_trigger_loss", "events.EventExtractor._get_pruned_gold_arguments", "events.EventExtractor._get_argument_loss", "metrics", "torch.floor", "torch.ones_like", "torch.floor", "torch.ones_like", "len", "len", "sentence_lengths.float", "sentence_lengths.float"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_trigger_scores", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_trig_arg_embeddings", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_argument_scores", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.ner.NERTagger.predict", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._get_trigger_loss", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._get_pruned_gold_arguments", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._get_argument_loss"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "trigger_mask", ",", "\n", "trigger_embeddings", ",", "\n", "spans", ",", "\n", "span_mask", ",", "\n", "span_embeddings", ",", "# TODO(dwadden) add type.", "\n", "sentence_lengths", ",", "\n", "trigger_labels", ",", "\n", "argument_labels", ",", "\n", "ner_labels", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        The trigger embeddings are just the contextualized token embeddings, and the trigger mask is\n        the text mask. For the arguments, we consider all the spans.\n        \"\"\"", "\n", "self", ".", "_active_dataset", "=", "metadata", ".", "dataset", "\n", "self", ".", "_active_namespaces", "=", "{", "\"trigger\"", ":", "f\"{self._active_dataset}__trigger_labels\"", ",", "\n", "\"argument\"", ":", "f\"{self._active_dataset}__argument_labels\"", "}", "\n", "\n", "if", "self", ".", "_active_namespaces", "[", "\"trigger\"", "]", "not", "in", "self", ".", "_trigger_scorers", ":", "\n", "            ", "return", "{", "\"loss\"", ":", "0", "}", "\n", "\n", "# Compute trigger scores.", "\n", "", "trigger_scores", "=", "self", ".", "_compute_trigger_scores", "(", "\n", "trigger_embeddings", ",", "trigger_mask", ")", "\n", "\n", "# Get trigger candidates for event argument labeling.", "\n", "num_trigs_to_keep", "=", "torch", ".", "floor", "(", "\n", "sentence_lengths", ".", "float", "(", ")", "*", "self", ".", "_trigger_spans_per_word", ")", ".", "long", "(", ")", "\n", "num_trigs_to_keep", "=", "torch", ".", "max", "(", "num_trigs_to_keep", ",", "\n", "torch", ".", "ones_like", "(", "num_trigs_to_keep", ")", ")", "\n", "num_trigs_to_keep", "=", "torch", ".", "min", "(", "num_trigs_to_keep", ",", "\n", "15", "*", "torch", ".", "ones_like", "(", "num_trigs_to_keep", ")", ")", "\n", "\n", "trigger_pruner", "=", "self", ".", "_trigger_pruners", "[", "self", ".", "_active_namespaces", "[", "\"trigger\"", "]", "]", "\n", "(", "top_trig_embeddings", ",", "top_trig_mask", ",", "\n", "top_trig_indices", ",", "top_trig_scores", ",", "num_trigs_kept", ")", "=", "trigger_pruner", "(", "\n", "trigger_embeddings", ",", "trigger_mask", ",", "num_trigs_to_keep", ",", "trigger_scores", ")", "\n", "top_trig_mask", "=", "top_trig_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "# Compute the number of argument spans to keep.", "\n", "num_arg_spans_to_keep", "=", "torch", ".", "floor", "(", "\n", "sentence_lengths", ".", "float", "(", ")", "*", "self", ".", "_argument_spans_per_word", ")", ".", "long", "(", ")", "\n", "num_arg_spans_to_keep", "=", "torch", ".", "max", "(", "num_arg_spans_to_keep", ",", "\n", "torch", ".", "ones_like", "(", "num_arg_spans_to_keep", ")", ")", "\n", "num_arg_spans_to_keep", "=", "torch", ".", "min", "(", "num_arg_spans_to_keep", ",", "\n", "30", "*", "torch", ".", "ones_like", "(", "num_arg_spans_to_keep", ")", ")", "\n", "\n", "# If we're using gold event arguments, include the gold labels.", "\n", "mention_pruner", "=", "self", ".", "_mention_pruners", "[", "self", ".", "_active_namespaces", "[", "\"argument\"", "]", "]", "\n", "gold_labels", "=", "None", "\n", "(", "top_arg_embeddings", ",", "top_arg_mask", ",", "\n", "top_arg_indices", ",", "top_arg_scores", ",", "num_arg_spans_kept", ")", "=", "mention_pruner", "(", "\n", "span_embeddings", ",", "span_mask", ",", "num_arg_spans_to_keep", ",", "gold_labels", ")", "\n", "\n", "top_arg_mask", "=", "top_arg_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "top_arg_spans", "=", "util", ".", "batched_index_select", "(", "spans", ",", "\n", "top_arg_indices", ")", "\n", "\n", "# Compute trigger / argument pair embeddings.", "\n", "trig_arg_embeddings", "=", "self", ".", "_compute_trig_arg_embeddings", "(", "\n", "top_trig_embeddings", ",", "top_arg_embeddings", ",", "top_trig_indices", ",", "top_arg_spans", ")", "\n", "argument_scores", "=", "self", ".", "_compute_argument_scores", "(", "\n", "trig_arg_embeddings", ",", "top_trig_scores", ",", "top_arg_scores", ",", "top_arg_mask", ")", "\n", "\n", "# Assemble inputs to do prediction.", "\n", "output_dict", "=", "{", "\"top_trigger_indices\"", ":", "top_trig_indices", ",", "\n", "\"top_argument_spans\"", ":", "top_arg_spans", ",", "\n", "\"trigger_scores\"", ":", "trigger_scores", ",", "\n", "\"argument_scores\"", ":", "argument_scores", ",", "\n", "\"num_triggers_kept\"", ":", "num_trigs_kept", ",", "\n", "\"num_argument_spans_kept\"", ":", "num_arg_spans_kept", ",", "\n", "\"sentence_lengths\"", ":", "sentence_lengths", "}", "\n", "\n", "prediction_dicts", ",", "predictions", "=", "self", ".", "predict", "(", "output_dict", ",", "metadata", ")", "\n", "\n", "output_dict", "=", "{", "\"predictions\"", ":", "predictions", "}", "\n", "\n", "# Evaluate loss and F1 if labels were provided.", "\n", "if", "trigger_labels", "is", "not", "None", "and", "argument_labels", "is", "not", "None", ":", "\n", "# Compute the loss for both triggers and arguments.", "\n", "            ", "trigger_loss", "=", "self", ".", "_get_trigger_loss", "(", "trigger_scores", ",", "trigger_labels", ",", "trigger_mask", ")", "\n", "\n", "gold_arguments", "=", "self", ".", "_get_pruned_gold_arguments", "(", "\n", "argument_labels", ",", "top_trig_indices", ",", "top_arg_indices", ",", "top_trig_mask", ",", "top_arg_mask", ")", "\n", "\n", "argument_loss", "=", "self", ".", "_get_argument_loss", "(", "argument_scores", ",", "gold_arguments", ")", "\n", "\n", "# Compute F1.", "\n", "assert", "len", "(", "prediction_dicts", ")", "==", "len", "(", "metadata", ")", "# Make sure length of predictions is right.", "\n", "\n", "# Compute metrics for this label namespace.", "\n", "metrics", "=", "self", ".", "_metrics", "[", "self", ".", "_active_dataset", "]", "\n", "metrics", "(", "prediction_dicts", ",", "metadata", ")", "\n", "\n", "loss", "=", "(", "self", ".", "_loss_weights", "[", "\"trigger\"", "]", "*", "trigger_loss", "+", "\n", "self", ".", "_loss_weights", "[", "\"arguments\"", "]", "*", "argument_loss", ")", "\n", "\n", "output_dict", "[", "\"loss\"", "]", "=", "loss", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_trig_arg_embeddings": [[222, 248], ["top_trig_embeddings.size", "top_arg_embeddings.size", "top_trig_embeddings.unsqueeze", "top_trig_embeddings.unsqueeze.repeat", "top_arg_embeddings.unsqueeze", "top_arg_embeddings.unsqueeze.repeat", "events.EventExtractor._compute_distance_embeddings", "torch.cat"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_distance_embeddings"], ["", "def", "_compute_trig_arg_embeddings", "(", "self", ",", "\n", "top_trig_embeddings", ",", "\n", "top_arg_embeddings", ",", "\n", "top_trig_indices", ",", "\n", "top_arg_spans", ")", ":", "\n", "        ", "\"\"\"\n        Create trigger / argument pair embeddings, consisting of:\n        - The embeddings of the trigger and argument pair.\n        - Optionally, the embeddings of the trigger and argument labels.\n        - Optionally, embeddings of the words surrounding the trigger and argument.\n        \"\"\"", "\n", "num_trigs", "=", "top_trig_embeddings", ".", "size", "(", "1", ")", "\n", "num_args", "=", "top_arg_embeddings", ".", "size", "(", "1", ")", "\n", "\n", "trig_emb_expanded", "=", "top_trig_embeddings", ".", "unsqueeze", "(", "2", ")", "\n", "trig_emb_tiled", "=", "trig_emb_expanded", ".", "repeat", "(", "1", ",", "1", ",", "num_args", ",", "1", ")", "\n", "\n", "arg_emb_expanded", "=", "top_arg_embeddings", ".", "unsqueeze", "(", "1", ")", "\n", "arg_emb_tiled", "=", "arg_emb_expanded", ".", "repeat", "(", "1", ",", "num_trigs", ",", "1", ",", "1", ")", "\n", "\n", "distance_embeddings", "=", "self", ".", "_compute_distance_embeddings", "(", "top_trig_indices", ",", "top_arg_spans", ")", "\n", "\n", "pair_embeddings_list", "=", "[", "trig_emb_tiled", ",", "arg_emb_tiled", ",", "distance_embeddings", "]", "\n", "pair_embeddings", "=", "torch", ".", "cat", "(", "pair_embeddings_list", ",", "dim", "=", "3", ")", "\n", "\n", "return", "pair_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_distance_embeddings": [[249, 267], ["top_trig_indices.unsqueeze", "top_arg_spans[].unsqueeze", "top_arg_spans[].unsqueeze", "torch.min", "allennlp.nn.util.bucket_values", "events.EventExtractor._distance_embedding", "trigger_inside.float().unsqueeze", "torch.cat", "dist_from_start.abs", "dist_from_end.abs", "trigger_inside.float"], "methods", ["None"], ["", "def", "_compute_distance_embeddings", "(", "self", ",", "top_trig_indices", ",", "top_arg_spans", ")", ":", "\n", "        ", "top_trig_ixs", "=", "top_trig_indices", ".", "unsqueeze", "(", "2", ")", "\n", "arg_span_starts", "=", "top_arg_spans", "[", ":", ",", ":", ",", "0", "]", ".", "unsqueeze", "(", "1", ")", "\n", "arg_span_ends", "=", "top_arg_spans", "[", ":", ",", ":", ",", "1", "]", ".", "unsqueeze", "(", "1", ")", "\n", "dist_from_start", "=", "top_trig_ixs", "-", "arg_span_starts", "\n", "dist_from_end", "=", "top_trig_ixs", "-", "arg_span_ends", "\n", "# Distance from trigger to arg.", "\n", "dist", "=", "torch", ".", "min", "(", "dist_from_start", ".", "abs", "(", ")", ",", "dist_from_end", ".", "abs", "(", ")", ")", "\n", "# When the trigger is inside the arg span, also set the distance to zero.", "\n", "trigger_inside", "=", "(", "top_trig_ixs", ">=", "arg_span_starts", ")", "&", "(", "top_trig_ixs", "<=", "arg_span_ends", ")", "\n", "dist", "[", "trigger_inside", "]", "=", "0", "\n", "dist_buckets", "=", "util", ".", "bucket_values", "(", "dist", ",", "self", ".", "_num_distance_buckets", ")", "\n", "dist_emb", "=", "self", ".", "_distance_embedding", "(", "dist_buckets", ")", "\n", "trigger_before_feature", "=", "(", "top_trig_ixs", "<", "arg_span_starts", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "trigger_inside_feature", "=", "trigger_inside", ".", "float", "(", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "res", "=", "torch", ".", "cat", "(", "[", "dist_emb", ",", "trigger_before_feature", ",", "trigger_inside_feature", "]", ",", "dim", "=", "-", "1", ")", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_trigger_scores": [[272, 286], ["trigger_scorer", "trigger_mask.unsqueeze", "allennlp.nn.util.replace_masked_values", "torch.cat.new_zeros", "torch.cat", "trigger_mask.unsqueeze.bool", "torch.cat.size", "torch.cat.size"], "methods", ["None"], ["", "def", "_compute_trigger_scores", "(", "self", ",", "trigger_embeddings", ",", "trigger_mask", ")", ":", "\n", "        ", "\"\"\"\n        Compute trigger scores for all tokens.\n        \"\"\"", "\n", "trigger_scorer", "=", "self", ".", "_trigger_scorers", "[", "self", ".", "_active_namespaces", "[", "\"trigger\"", "]", "]", "\n", "trigger_scores", "=", "trigger_scorer", "(", "trigger_embeddings", ")", "\n", "# Give large negative scores to masked-out elements.", "\n", "mask", "=", "trigger_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "trigger_scores", "=", "util", ".", "replace_masked_values", "(", "trigger_scores", ",", "mask", ".", "bool", "(", ")", ",", "-", "1e20", ")", "\n", "dummy_dims", "=", "[", "trigger_scores", ".", "size", "(", "0", ")", ",", "trigger_scores", ".", "size", "(", "1", ")", ",", "1", "]", "\n", "dummy_scores", "=", "trigger_scores", ".", "new_zeros", "(", "*", "dummy_dims", ")", "\n", "trigger_scores", "=", "torch", ".", "cat", "(", "(", "dummy_scores", ",", "trigger_scores", ")", ",", "-", "1", ")", "\n", "# Give large negative scores to the masked-out values.", "\n", "return", "trigger_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._compute_argument_scores": [[287, 315], ["pairwise_embeddings.size", "pairwise_embeddings.size", "pairwise_embeddings.size", "pairwise_embeddings.view", "argument_feedforward", "argument_scorer", "argument_scorer.view", "torch.cat.new_zeros", "top_trig_scores.unsqueeze", "top_arg_scores.transpose().unsqueeze", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat", "top_arg_scores.transpose"], "methods", ["None"], ["", "def", "_compute_argument_scores", "(", "self", ",", "pairwise_embeddings", ",", "top_trig_scores", ",", "top_arg_scores", ",", "\n", "top_arg_mask", ",", "prepend_zeros", "=", "True", ")", ":", "\n", "        ", "batch_size", "=", "pairwise_embeddings", ".", "size", "(", "0", ")", "\n", "max_num_trigs", "=", "pairwise_embeddings", ".", "size", "(", "1", ")", "\n", "max_num_args", "=", "pairwise_embeddings", ".", "size", "(", "2", ")", "\n", "argument_feedforward", "=", "self", ".", "_argument_feedforwards", "[", "self", ".", "_active_namespaces", "[", "\"argument\"", "]", "]", "\n", "\n", "feature_dim", "=", "argument_feedforward", ".", "input_dim", "\n", "embeddings_flat", "=", "pairwise_embeddings", ".", "view", "(", "-", "1", ",", "feature_dim", ")", "\n", "\n", "arguments_projected_flat", "=", "argument_feedforward", "(", "embeddings_flat", ")", "\n", "\n", "argument_scorer", "=", "self", ".", "_argument_scorers", "[", "self", ".", "_active_namespaces", "[", "\"argument\"", "]", "]", "\n", "argument_scores_flat", "=", "argument_scorer", "(", "arguments_projected_flat", ")", "\n", "\n", "argument_scores", "=", "argument_scores_flat", ".", "view", "(", "batch_size", ",", "max_num_trigs", ",", "max_num_args", ",", "-", "1", ")", "\n", "\n", "# Add the mention scores for each of the candidates.", "\n", "\n", "argument_scores", "+=", "(", "top_trig_scores", ".", "unsqueeze", "(", "-", "1", ")", "+", "\n", "top_arg_scores", ".", "transpose", "(", "1", ",", "2", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "shape", "=", "[", "argument_scores", ".", "size", "(", "0", ")", ",", "argument_scores", ".", "size", "(", "1", ")", ",", "argument_scores", ".", "size", "(", "2", ")", ",", "1", "]", "\n", "dummy_scores", "=", "argument_scores", ".", "new_zeros", "(", "*", "shape", ")", "\n", "\n", "if", "prepend_zeros", ":", "\n", "            ", "argument_scores", "=", "torch", ".", "cat", "(", "[", "dummy_scores", ",", "argument_scores", "]", ",", "-", "1", ")", "\n", "", "return", "argument_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor.predict": [[320, 340], ["dygie.models.shared.fields_to_batches", "zip", "events.EventExtractor._decode_trigger", "events.EventExtractor._decode_arguments", "events.EventExtractor._assemble_predictions", "prediction_dicts.append", "predictions.append", "v.detach().cpu", "output_dict.items", "v.detach"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.fields_to_batches", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._decode_trigger", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._decode_arguments", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._assemble_predictions"], ["", "def", "predict", "(", "self", ",", "output_dict", ",", "document", ")", ":", "\n", "        ", "\"\"\"\n        Take the output and convert it into a list of dicts. Each entry is a sentence. Each key is a\n        pair of span indices for that sentence, and each value is the relation label on that span\n        pair.\n        \"\"\"", "\n", "outputs", "=", "fields_to_batches", "(", "{", "k", ":", "v", ".", "detach", "(", ")", ".", "cpu", "(", ")", "for", "k", ",", "v", "in", "output_dict", ".", "items", "(", ")", "}", ")", "\n", "\n", "prediction_dicts", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "\n", "# Collect predictions for each sentence in minibatch.", "\n", "for", "output", ",", "sentence", "in", "zip", "(", "outputs", ",", "document", ")", ":", "\n", "            ", "decoded_trig", "=", "self", ".", "_decode_trigger", "(", "output", ")", "\n", "decoded_args", "=", "self", ".", "_decode_arguments", "(", "output", ",", "decoded_trig", ")", "\n", "predicted_events", "=", "self", ".", "_assemble_predictions", "(", "decoded_trig", ",", "decoded_args", ",", "sentence", ")", "\n", "prediction_dicts", ".", "append", "(", "{", "\"trigger_dict\"", ":", "decoded_trig", ",", "\"argument_dict\"", ":", "decoded_args", "}", ")", "\n", "predictions", ".", "append", "(", "predicted_events", ")", "\n", "\n", "", "return", "prediction_dicts", ",", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._decode_trigger": [[341, 358], ["trigger_scores.max", "torch.nn.functional.softmax", "torch.nn.functional.softmax.max", "range", "predicted_triggers[].item", "events.EventExtractor.vocab.get_token_from_index", "predicted_scores_raw[].item", "predicted_scores_softmax[].item"], "methods", ["None"], ["", "def", "_decode_trigger", "(", "self", ",", "output", ")", ":", "\n", "        ", "trigger_scores", "=", "output", "[", "\"trigger_scores\"", "]", "\n", "predicted_scores_raw", ",", "predicted_triggers", "=", "trigger_scores", ".", "max", "(", "dim", "=", "1", ")", "\n", "softmax_scores", "=", "F", ".", "softmax", "(", "trigger_scores", ",", "dim", "=", "1", ")", "\n", "predicted_scores_softmax", ",", "_", "=", "softmax_scores", ".", "max", "(", "dim", "=", "1", ")", "\n", "trigger_dict", "=", "{", "}", "\n", "# TODO(dwadden) Can speed this up with array ops.", "\n", "for", "i", "in", "range", "(", "output", "[", "\"sentence_lengths\"", "]", ")", ":", "\n", "            ", "trig_label", "=", "predicted_triggers", "[", "i", "]", ".", "item", "(", ")", "\n", "if", "trig_label", ">", "0", ":", "\n", "                ", "predicted_label", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "\n", "trig_label", ",", "namespace", "=", "self", ".", "_active_namespaces", "[", "\"trigger\"", "]", ")", "\n", "trigger_dict", "[", "i", "]", "=", "(", "predicted_label", ",", "\n", "predicted_scores_raw", "[", "i", "]", ".", "item", "(", ")", ",", "\n", "predicted_scores_softmax", "[", "i", "]", ".", "item", "(", ")", ")", "\n", "\n", "", "", "return", "trigger_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._decode_arguments": [[359, 383], ["argument_scores.max", "torch.nn.functional.softmax", "torch.nn.functional.softmax.max", "itertools.product", "range", "range", "[].item", "tuple", "predicted_arguments[].item", "[].tolist", "predicted_scores_raw[].item", "predicted_scores_softmax[].item", "events.EventExtractor.vocab.get_token_from_index"], "methods", ["None"], ["", "def", "_decode_arguments", "(", "self", ",", "output", ",", "decoded_trig", ")", ":", "\n", "# TODO(dwadden) Vectorize.", "\n", "        ", "argument_dict", "=", "{", "}", "\n", "argument_scores", "=", "output", "[", "\"argument_scores\"", "]", "\n", "predicted_scores_raw", ",", "predicted_arguments", "=", "argument_scores", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "# The null argument has label -1.", "\n", "predicted_arguments", "-=", "1", "\n", "softmax_scores", "=", "F", ".", "softmax", "(", "argument_scores", ",", "dim", "=", "-", "1", ")", "\n", "predicted_scores_softmax", ",", "_", "=", "softmax_scores", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "\n", "for", "i", ",", "j", "in", "itertools", ".", "product", "(", "range", "(", "output", "[", "\"num_triggers_kept\"", "]", ")", ",", "\n", "range", "(", "output", "[", "\"num_argument_spans_kept\"", "]", ")", ")", ":", "\n", "            ", "trig_ix", "=", "output", "[", "\"top_trigger_indices\"", "]", "[", "i", "]", ".", "item", "(", ")", "\n", "arg_span", "=", "tuple", "(", "output", "[", "\"top_argument_spans\"", "]", "[", "j", "]", ".", "tolist", "(", ")", ")", "\n", "arg_label", "=", "predicted_arguments", "[", "i", ",", "j", "]", ".", "item", "(", ")", "\n", "# Only include the argument if its putative trigger is predicted as a real trigger.", "\n", "if", "arg_label", ">=", "0", "and", "trig_ix", "in", "decoded_trig", ":", "\n", "                ", "arg_score_raw", "=", "predicted_scores_raw", "[", "i", ",", "j", "]", ".", "item", "(", ")", "\n", "arg_score_softmax", "=", "predicted_scores_softmax", "[", "i", ",", "j", "]", ".", "item", "(", ")", "\n", "label_name", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "\n", "arg_label", ",", "namespace", "=", "self", ".", "_active_namespaces", "[", "\"argument\"", "]", ")", "\n", "argument_dict", "[", "(", "trig_ix", ",", "arg_span", ")", "]", "=", "(", "label_name", ",", "arg_score_raw", ",", "arg_score_softmax", ")", "\n", "\n", "", "", "return", "argument_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._assemble_predictions": [[384, 401], ["trigger_dict.items", "dygie.data.dataset_readers.document.PredictedEvents", "this_event.append", "event_arguments.items", "sorted", "this_event.extend", "events_json.append", "sorted.append", "list", "argument_dict.items", "list", "list"], "methods", ["None"], ["", "def", "_assemble_predictions", "(", "self", ",", "trigger_dict", ",", "argument_dict", ",", "sentence", ")", ":", "\n", "        ", "events_json", "=", "[", "]", "\n", "for", "trigger_ix", ",", "trigger_label", "in", "trigger_dict", ".", "items", "(", ")", ":", "\n", "            ", "this_event", "=", "[", "]", "\n", "this_event", ".", "append", "(", "[", "trigger_ix", "]", "+", "list", "(", "trigger_label", ")", ")", "\n", "event_arguments", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "argument_dict", ".", "items", "(", ")", "if", "k", "[", "0", "]", "==", "trigger_ix", "}", "\n", "this_event_args", "=", "[", "]", "\n", "for", "k", ",", "v", "in", "event_arguments", ".", "items", "(", ")", ":", "\n", "                ", "entry", "=", "list", "(", "k", "[", "1", "]", ")", "+", "list", "(", "v", ")", "\n", "this_event_args", ".", "append", "(", "entry", ")", "\n", "", "this_event_args", "=", "sorted", "(", "this_event_args", ",", "key", "=", "lambda", "entry", ":", "entry", "[", "0", "]", ")", "\n", "this_event", ".", "extend", "(", "this_event_args", ")", "\n", "events_json", ".", "append", "(", "this_event", ")", "\n", "\n", "", "events", "=", "document", ".", "PredictedEvents", "(", "events_json", ",", "sentence", ",", "sentence_offsets", "=", "True", ")", "\n", "\n", "return", "events", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._get_pruned_gold_arguments": [[406, 428], ["zip", "torch.cat", "top_trig_masks.bool", "top_arg_masks.bool", "[].unsqueeze", "arguments.append", "arg_mask.transpose().unsqueeze", "arg_mask.transpose"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_pruned_gold_arguments", "(", "argument_labels", ",", "top_trig_indices", ",", "top_arg_indices", ",", "\n", "top_trig_masks", ",", "top_arg_masks", ")", ":", "\n", "        ", "\"\"\"\n        Loop over each slice and get the labels for the spans from that slice.\n        All labels are offset by 1 so that the \"null\" label gets class zero. This is the desired\n        behavior for the softmax. Labels corresponding to masked relations keep the label -1, which\n        the softmax loss ignores.\n        \"\"\"", "\n", "arguments", "=", "[", "]", "\n", "\n", "zipped", "=", "zip", "(", "argument_labels", ",", "top_trig_indices", ",", "top_arg_indices", ",", "\n", "top_trig_masks", ".", "bool", "(", ")", ",", "top_arg_masks", ".", "bool", "(", ")", ")", "\n", "\n", "for", "sliced", ",", "trig_ixs", ",", "arg_ixs", ",", "trig_mask", ",", "arg_mask", "in", "zipped", ":", "\n", "            ", "entry", "=", "sliced", "[", "trig_ixs", "]", "[", ":", ",", "arg_ixs", "]", ".", "unsqueeze", "(", "0", ")", "\n", "mask_entry", "=", "trig_mask", "&", "arg_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "entry", "[", "mask_entry", "]", "+=", "1", "\n", "entry", "[", "~", "mask_entry", "]", "=", "-", "1", "\n", "arguments", ".", "append", "(", "entry", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "arguments", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._get_trigger_loss": [[429, 437], ["trigger_scores.view", "trigger_labels.view", "trigger_mask.view().bool", "events.EventExtractor._trigger_loss", "trigger_mask.view"], "methods", ["None"], ["", "def", "_get_trigger_loss", "(", "self", ",", "trigger_scores", ",", "trigger_labels", ",", "trigger_mask", ")", ":", "\n", "        ", "n_trigger_labels", "=", "self", ".", "_n_trigger_labels", "[", "self", ".", "_active_namespaces", "[", "\"trigger\"", "]", "]", "\n", "trigger_scores_flat", "=", "trigger_scores", ".", "view", "(", "-", "1", ",", "n_trigger_labels", ")", "\n", "trigger_labels_flat", "=", "trigger_labels", ".", "view", "(", "-", "1", ")", "\n", "mask_flat", "=", "trigger_mask", ".", "view", "(", "-", "1", ")", ".", "bool", "(", ")", "\n", "\n", "loss", "=", "self", ".", "_trigger_loss", "(", "trigger_scores_flat", "[", "mask_flat", "]", ",", "trigger_labels_flat", "[", "mask_flat", "]", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor._get_argument_loss": [[438, 450], ["argument_scores.view", "argument_labels.view", "events.EventExtractor._argument_loss"], "methods", ["None"], ["", "def", "_get_argument_loss", "(", "self", ",", "argument_scores", ",", "argument_labels", ")", ":", "\n", "        ", "\"\"\"\n        Compute cross-entropy loss on argument labels.\n        \"\"\"", "\n", "n_argument_labels", "=", "self", ".", "_n_argument_labels", "[", "self", ".", "_active_namespaces", "[", "\"argument\"", "]", "]", "\n", "# Need to add one for the null class.", "\n", "scores_flat", "=", "argument_scores", ".", "view", "(", "-", "1", ",", "n_argument_labels", "+", "1", ")", "\n", "# Need to add 1 so that the null label is 0, to line up with indices into prediction matrix.", "\n", "labels_flat", "=", "argument_labels", ".", "view", "(", "-", "1", ")", "\n", "# Compute cross-entropy loss.", "\n", "loss", "=", "self", ".", "_argument_loss", "(", "scores_flat", ",", "labels_flat", ")", "\n", "return", "loss", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.events.EventExtractor.get_metrics": [[451, 470], ["events.EventExtractor._metrics.items", "itertools.product", "metrics.get_metric", "res.update", "res.update", "metrics.get_metric.items", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "res", "=", "{", "}", "\n", "for", "namespace", ",", "metrics", "in", "self", ".", "_metrics", ".", "items", "(", ")", ":", "\n", "            ", "f1_metrics", "=", "metrics", ".", "get_metric", "(", "reset", ")", "\n", "f1_metrics", "=", "{", "f\"{namespace}_{k}\"", ":", "v", "for", "k", ",", "v", "in", "f1_metrics", ".", "items", "(", ")", "}", "\n", "res", ".", "update", "(", "f1_metrics", ")", "\n", "\n", "", "prod", "=", "itertools", ".", "product", "(", "[", "\"trig_id\"", ",", "\"trig_class\"", ",", "\"arg_id\"", ",", "\"arg_class\"", "]", ",", "\n", "[", "\"precision\"", ",", "\"recall\"", ",", "\"f1\"", "]", ")", "\n", "names", "=", "[", "f\"{task}_{metric}\"", "for", "task", ",", "metric", "in", "prod", "]", "\n", "\n", "res_avg", "=", "{", "}", "\n", "for", "name", "in", "names", ":", "\n", "            ", "values", "=", "[", "res", "[", "key", "]", "for", "key", "in", "res", "if", "name", "in", "key", "]", "\n", "res_avg", "[", "f\"MEAN__{name}\"", "]", "=", "sum", "(", "values", ")", "/", "len", "(", "values", ")", "if", "values", "else", "0", "\n", "res", ".", "update", "(", "res_avg", ")", "\n", "\n", "", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor.__init__": [[29, 67], ["allennlp.models.model.Model.__init__", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.ModuleDict", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "torch.nn.CrossEntropyLoss", "vocab.get_vocab_size", "make_feedforward", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "dygie.models.entity_beam_pruner.Pruner", "make_feedforward", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "dygie.training.relation_metrics.RelationMetrics", "vocab.get_namespaces", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "make_feedforward.get_output_dim", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "make_feedforward.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "make_feedforward", ":", "Callable", ",", "\n", "span_emb_dim", ":", "int", ",", "\n", "feature_size", ":", "int", ",", "\n", "spans_per_word", ":", "float", ",", "\n", "positive_label_weight", ":", "float", "=", "1.0", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "_namespaces", "=", "[", "entry", "for", "entry", "in", "vocab", ".", "get_namespaces", "(", ")", "if", "\"relation_labels\"", "in", "entry", "]", "\n", "self", ".", "_n_labels", "=", "{", "name", ":", "vocab", ".", "get_vocab_size", "(", "name", ")", "for", "name", "in", "self", ".", "_namespaces", "}", "\n", "\n", "self", ".", "_mention_pruners", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "_relation_feedforwards", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "_relation_scorers", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "_relation_metrics", "=", "{", "}", "\n", "\n", "for", "namespace", "in", "self", ".", "_namespaces", ":", "\n", "            ", "mention_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "span_emb_dim", ")", "\n", "feedforward_scorer", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "mention_feedforward", ")", ",", "\n", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "mention_feedforward", ".", "get_output_dim", "(", ")", ",", "1", ")", ")", ")", "\n", "self", ".", "_mention_pruners", "[", "namespace", "]", "=", "Pruner", "(", "feedforward_scorer", ")", "\n", "\n", "relation_scorer_dim", "=", "3", "*", "span_emb_dim", "\n", "relation_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "relation_scorer_dim", ")", "\n", "self", ".", "_relation_feedforwards", "[", "namespace", "]", "=", "relation_feedforward", "\n", "relation_scorer", "=", "torch", ".", "nn", ".", "Linear", "(", "\n", "relation_feedforward", ".", "get_output_dim", "(", ")", ",", "self", ".", "_n_labels", "[", "namespace", "]", ")", "\n", "self", ".", "_relation_scorers", "[", "namespace", "]", "=", "relation_scorer", "\n", "\n", "self", ".", "_relation_metrics", "[", "namespace", "]", "=", "RelationMetrics", "(", ")", "\n", "\n", "", "self", ".", "_spans_per_word", "=", "spans_per_word", "\n", "self", ".", "_active_namespace", "=", "None", "\n", "\n", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ",", "ignore_index", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor.forward": [[68, 114], ["relation.RelationExtractor._prune_spans", "relation.RelationExtractor._compute_relation_scores", "relation.RelationExtractor.predict", "relation.RelationExtractor._compute_span_pair_embeddings", "top_spans.detach().cpu", "relation.RelationExtractor.detach().cpu", "num_spans_to_keep.detach().cpu", "relation.RelationExtractor._get_pruned_gold_relations", "relation.RelationExtractor._get_cross_entropy_loss", "relation_metrics", "len", "len", "top_spans.detach", "relation.RelationExtractor.detach", "num_spans_to_keep.detach"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._prune_spans", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._compute_relation_scores", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.ner.NERTagger.predict", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_span_pair_embeddings", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._get_pruned_gold_relations", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._get_cross_entropy_loss"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "spans", ":", "torch", ".", "IntTensor", ",", "\n", "span_mask", ",", "\n", "span_embeddings", ",", "# TODO(dwadden) add type.", "\n", "sentence_lengths", ",", "\n", "relation_labels", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        TODO(dwadden) Write documentation.\n        \"\"\"", "\n", "self", ".", "_active_namespace", "=", "f\"{metadata.dataset}__relation_labels\"", "\n", "\n", "if", "self", ".", "_active_namespace", "not", "in", "self", ".", "_relation_scorers", ":", "\n", "            ", "return", "{", "\"loss\"", ":", "0", "}", "\n", "\n", "", "(", "top_span_embeddings", ",", "top_span_mention_scores", ",", "\n", "num_spans_to_keep", ",", "top_span_mask", ",", "\n", "top_span_indices", ",", "top_spans", ")", "=", "self", ".", "_prune_spans", "(", "\n", "spans", ",", "span_mask", ",", "span_embeddings", ",", "sentence_lengths", ")", "\n", "\n", "relation_scores", "=", "self", ".", "_compute_relation_scores", "(", "\n", "self", ".", "_compute_span_pair_embeddings", "(", "top_span_embeddings", ")", ",", "top_span_mention_scores", ")", "\n", "\n", "prediction_dict", ",", "predictions", "=", "self", ".", "predict", "(", "top_spans", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "relation_scores", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "num_spans_to_keep", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "metadata", ")", "\n", "\n", "output_dict", "=", "{", "\"predictions\"", ":", "predictions", "}", "\n", "\n", "# Evaluate loss and F1 if labels were provided.", "\n", "if", "relation_labels", "is", "not", "None", ":", "\n", "# Compute cross-entropy loss.", "\n", "            ", "gold_relations", "=", "self", ".", "_get_pruned_gold_relations", "(", "\n", "relation_labels", ",", "top_span_indices", ",", "top_span_mask", ")", "\n", "\n", "cross_entropy", "=", "self", ".", "_get_cross_entropy_loss", "(", "relation_scores", ",", "gold_relations", ")", "\n", "\n", "# Compute F1.", "\n", "assert", "len", "(", "prediction_dict", ")", "==", "len", "(", "metadata", ")", "# Make sure length of predictions is right.", "\n", "relation_metrics", "=", "self", ".", "_relation_metrics", "[", "self", ".", "_active_namespace", "]", "\n", "relation_metrics", "(", "prediction_dict", ",", "metadata", ")", "\n", "\n", "output_dict", "[", "\"loss\"", "]", "=", "cross_entropy", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._prune_spans": [[115, 135], ["spans.size", "torch.ceil().long", "torch.ceil().long", "torch.ceil().long", "torch.ceil().long", "pruner", "top_span_mask.unsqueeze.unsqueeze.unsqueeze", "allennlp.nn.util.flatten_and_batch_shift_indices", "allennlp.nn.util.batched_index_select", "torch.ceil", "torch.ceil", "torch.ceil", "torch.ceil", "sentence_lengths.float"], "methods", ["None"], ["", "def", "_prune_spans", "(", "self", ",", "spans", ",", "span_mask", ",", "span_embeddings", ",", "sentence_lengths", ")", ":", "\n", "# Prune", "\n", "        ", "num_spans", "=", "spans", ".", "size", "(", "1", ")", "# Max number of spans for the minibatch.", "\n", "\n", "# Keep different number of spans for each minibatch entry.", "\n", "num_spans_to_keep", "=", "torch", ".", "ceil", "(", "sentence_lengths", ".", "float", "(", ")", "*", "self", ".", "_spans_per_word", ")", ".", "long", "(", ")", "\n", "\n", "pruner", "=", "self", ".", "_mention_pruners", "[", "self", ".", "_active_namespace", "]", "\n", "(", "top_span_embeddings", ",", "top_span_mask", ",", "\n", "top_span_indices", ",", "top_span_mention_scores", ",", "num_spans_kept", ")", "=", "pruner", "(", "\n", "span_embeddings", ",", "span_mask", ",", "num_spans_to_keep", ")", "\n", "\n", "top_span_mask", "=", "top_span_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "flat_top_span_indices", "=", "util", ".", "flatten_and_batch_shift_indices", "(", "top_span_indices", ",", "num_spans", ")", "\n", "top_spans", "=", "util", ".", "batched_index_select", "(", "spans", ",", "\n", "top_span_indices", ",", "\n", "flat_top_span_indices", ")", "\n", "\n", "return", "top_span_embeddings", ",", "top_span_mention_scores", ",", "num_spans_to_keep", ",", "top_span_mask", ",", "top_span_indices", ",", "top_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor.predict": [[136, 148], ["zip", "relation.RelationExtractor._predict_sentence", "preds_dict.append", "predictions.append"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._predict_sentence"], ["", "def", "predict", "(", "self", ",", "top_spans", ",", "relation_scores", ",", "num_spans_to_keep", ",", "metadata", ")", ":", "\n", "        ", "preds_dict", "=", "[", "]", "\n", "predictions", "=", "[", "]", "\n", "zipped", "=", "zip", "(", "top_spans", ",", "relation_scores", ",", "num_spans_to_keep", ",", "metadata", ")", "\n", "\n", "for", "top_spans_sent", ",", "relation_scores_sent", ",", "num_spans_sent", ",", "sentence", "in", "zipped", ":", "\n", "            ", "pred_dict_sent", ",", "predictions_sent", "=", "self", ".", "_predict_sentence", "(", "\n", "top_spans_sent", ",", "relation_scores_sent", ",", "num_spans_sent", ",", "sentence", ")", "\n", "preds_dict", ".", "append", "(", "pred_dict_sent", ")", "\n", "predictions", ".", "append", "(", "predictions_sent", ")", "\n", "\n", "", "return", "preds_dict", ",", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._predict_sentence": [[149, 181], ["num_spans_to_keep.item", "relation_scores.max", "torch.softmax", "torch.softmax", "torch.softmax.max", "torch.zeros", "torch.zeros", "torch.zeros", "torch.zeros", "keep_mask.bool.bool.bool", "ix.nonzero", "tuple", "len", "predicted_labels[].item", "predicted_scores_raw[].item", "predicted_scores_softmax[].item", "relation.RelationExtractor.vocab.get_token_from_index", "predictions.append", "top_spans.tolist", "dygie.data.dataset_readers.document.PredictedRelation"], "methods", ["None"], ["", "def", "_predict_sentence", "(", "self", ",", "top_spans", ",", "relation_scores", ",", "num_spans_to_keep", ",", "sentence", ")", ":", "\n", "        ", "keep", "=", "num_spans_to_keep", ".", "item", "(", ")", "\n", "top_spans", "=", "[", "tuple", "(", "x", ")", "for", "x", "in", "top_spans", ".", "tolist", "(", ")", "]", "\n", "\n", "# Iterate over all span pairs and labels. Record the span if the label isn't null.", "\n", "predicted_scores_raw", ",", "predicted_labels", "=", "relation_scores", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "softmax_scores", "=", "F", ".", "softmax", "(", "relation_scores", ",", "dim", "=", "-", "1", ")", "\n", "predicted_scores_softmax", ",", "_", "=", "softmax_scores", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "predicted_labels", "-=", "1", "# Subtract 1 so that null labels get -1.", "\n", "\n", "keep_mask", "=", "torch", ".", "zeros", "(", "len", "(", "top_spans", ")", ")", "\n", "keep_mask", "[", ":", "keep", "]", "=", "1", "\n", "keep_mask", "=", "keep_mask", ".", "bool", "(", ")", "\n", "\n", "ix", "=", "(", "predicted_labels", ">=", "0", ")", "&", "keep_mask", "\n", "\n", "res_dict", "=", "{", "}", "\n", "predictions", "=", "[", "]", "\n", "\n", "for", "i", ",", "j", "in", "ix", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ":", "\n", "            ", "span_1", "=", "top_spans", "[", "i", "]", "\n", "span_2", "=", "top_spans", "[", "j", "]", "\n", "label", "=", "predicted_labels", "[", "i", ",", "j", "]", ".", "item", "(", ")", "\n", "raw_score", "=", "predicted_scores_raw", "[", "i", ",", "j", "]", ".", "item", "(", ")", "\n", "softmax_score", "=", "predicted_scores_softmax", "[", "i", ",", "j", "]", ".", "item", "(", ")", "\n", "\n", "label_name", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "label", ",", "namespace", "=", "self", ".", "_active_namespace", ")", "\n", "res_dict", "[", "(", "span_1", ",", "span_2", ")", "]", "=", "label_name", "\n", "list_entry", "=", "(", "span_1", "[", "0", "]", ",", "span_1", "[", "1", "]", ",", "span_2", "[", "0", "]", ",", "span_2", "[", "1", "]", ",", "label_name", ",", "raw_score", ",", "softmax_score", ")", "\n", "predictions", ".", "append", "(", "document", ".", "PredictedRelation", "(", "list_entry", ",", "sentence", ",", "sentence_offsets", "=", "True", ")", ")", "\n", "\n", "", "return", "res_dict", ",", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor.get_metrics": [[183, 202], ["relation.RelationExtractor._relation_metrics.items", "metrics.get_metric", "namespace.replace", "res.update", "res.update", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"Loop over the metrics for all namespaces, and return as dict.\"", "\n", "res", "=", "{", "}", "\n", "for", "namespace", ",", "metrics", "in", "self", ".", "_relation_metrics", ".", "items", "(", ")", ":", "\n", "            ", "precision", ",", "recall", ",", "f1", "=", "metrics", ".", "get_metric", "(", "reset", ")", "\n", "prefix", "=", "namespace", ".", "replace", "(", "\"_labels\"", ",", "\"\"", ")", "\n", "to_update", "=", "{", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1\"", ":", "f1", "}", "\n", "res", ".", "update", "(", "to_update", ")", "\n", "\n", "", "res_avg", "=", "{", "}", "\n", "for", "name", "in", "[", "\"precision\"", ",", "\"recall\"", ",", "\"f1\"", "]", ":", "\n", "            ", "values", "=", "[", "res", "[", "key", "]", "for", "key", "in", "res", "if", "name", "in", "key", "]", "\n", "res_avg", "[", "f\"MEAN__relation_{name}\"", "]", "=", "sum", "(", "values", ")", "/", "len", "(", "values", ")", "if", "values", "else", "0", "\n", "res", ".", "update", "(", "res_avg", ")", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._compute_span_pair_embeddings": [[203, 223], ["top_span_embeddings.size", "top_span_embeddings.unsqueeze", "top_span_embeddings.unsqueeze.repeat", "top_span_embeddings.unsqueeze", "top_span_embeddings.unsqueeze.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_span_pair_embeddings", "(", "top_span_embeddings", ":", "torch", ".", "FloatTensor", ")", ":", "\n", "        ", "\"\"\"\n        TODO(dwadden) document me and add comments.\n        \"\"\"", "\n", "# Shape: (batch_size, num_spans_to_keep, num_spans_to_keep, embedding_size)", "\n", "num_candidates", "=", "top_span_embeddings", ".", "size", "(", "1", ")", "\n", "\n", "embeddings_1_expanded", "=", "top_span_embeddings", ".", "unsqueeze", "(", "2", ")", "\n", "embeddings_1_tiled", "=", "embeddings_1_expanded", ".", "repeat", "(", "1", ",", "1", ",", "num_candidates", ",", "1", ")", "\n", "\n", "embeddings_2_expanded", "=", "top_span_embeddings", ".", "unsqueeze", "(", "1", ")", "\n", "embeddings_2_tiled", "=", "embeddings_2_expanded", ".", "repeat", "(", "1", ",", "num_candidates", ",", "1", ",", "1", ")", "\n", "\n", "similarity_embeddings", "=", "embeddings_1_expanded", "*", "embeddings_2_expanded", "\n", "\n", "pair_embeddings_list", "=", "[", "embeddings_1_tiled", ",", "embeddings_2_tiled", ",", "similarity_embeddings", "]", "\n", "pair_embeddings", "=", "torch", ".", "cat", "(", "pair_embeddings_list", ",", "dim", "=", "3", ")", "\n", "\n", "return", "pair_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._compute_relation_scores": [[224, 249], ["pairwise_embeddings.size", "pairwise_embeddings.size", "pairwise_embeddings.view", "relation_feedforward", "relation_scorer", "relation_scorer.view", "torch.cat.new_zeros", "torch.cat.new_zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "top_span_mention_scores.unsqueeze", "top_span_mention_scores.transpose().unsqueeze", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "torch.cat.size", "top_span_mention_scores.transpose"], "methods", ["None"], ["", "def", "_compute_relation_scores", "(", "self", ",", "pairwise_embeddings", ",", "top_span_mention_scores", ")", ":", "\n", "        ", "relation_feedforward", "=", "self", ".", "_relation_feedforwards", "[", "self", ".", "_active_namespace", "]", "\n", "relation_scorer", "=", "self", ".", "_relation_scorers", "[", "self", ".", "_active_namespace", "]", "\n", "\n", "batch_size", "=", "pairwise_embeddings", ".", "size", "(", "0", ")", "\n", "max_num_spans", "=", "pairwise_embeddings", ".", "size", "(", "1", ")", "\n", "feature_dim", "=", "relation_feedforward", ".", "input_dim", "\n", "\n", "embeddings_flat", "=", "pairwise_embeddings", ".", "view", "(", "-", "1", ",", "feature_dim", ")", "\n", "\n", "relation_projected_flat", "=", "relation_feedforward", "(", "embeddings_flat", ")", "\n", "relation_scores_flat", "=", "relation_scorer", "(", "relation_projected_flat", ")", "\n", "\n", "relation_scores", "=", "relation_scores_flat", ".", "view", "(", "batch_size", ",", "max_num_spans", ",", "max_num_spans", ",", "-", "1", ")", "\n", "\n", "# Add the mention scores for each of the candidates.", "\n", "\n", "relation_scores", "+=", "(", "top_span_mention_scores", ".", "unsqueeze", "(", "-", "1", ")", "+", "\n", "top_span_mention_scores", ".", "transpose", "(", "1", ",", "2", ")", ".", "unsqueeze", "(", "-", "1", ")", ")", "\n", "\n", "shape", "=", "[", "relation_scores", ".", "size", "(", "0", ")", ",", "relation_scores", ".", "size", "(", "1", ")", ",", "relation_scores", ".", "size", "(", "2", ")", ",", "1", "]", "\n", "dummy_scores", "=", "relation_scores", ".", "new_zeros", "(", "*", "shape", ")", "\n", "\n", "relation_scores", "=", "torch", ".", "cat", "(", "[", "dummy_scores", ",", "relation_scores", "]", ",", "-", "1", ")", "\n", "return", "relation_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._get_pruned_gold_relations": [[250, 270], ["zip", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "top_span_masks.bool", "[].unsqueeze", "relations.append", "top_span_mask.transpose().unsqueeze", "top_span_mask.transpose"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_pruned_gold_relations", "(", "relation_labels", ",", "top_span_indices", ",", "top_span_masks", ")", ":", "\n", "        ", "\"\"\"\n        Loop over each slice and get the labels for the spans from that slice.\n        All labels are offset by 1 so that the \"null\" label gets class zero. This is the desired\n        behavior for the softmax. Labels corresponding to masked relations keep the label -1, which\n        the softmax loss ignores.\n        \"\"\"", "\n", "# TODO(dwadden) Test and possibly optimize.", "\n", "relations", "=", "[", "]", "\n", "\n", "zipped", "=", "zip", "(", "relation_labels", ",", "top_span_indices", ",", "top_span_masks", ".", "bool", "(", ")", ")", "\n", "for", "sliced", ",", "ixs", ",", "top_span_mask", "in", "zipped", ":", "\n", "            ", "entry", "=", "sliced", "[", "ixs", "]", "[", ":", ",", "ixs", "]", ".", "unsqueeze", "(", "0", ")", "\n", "mask_entry", "=", "top_span_mask", "&", "top_span_mask", ".", "transpose", "(", "0", ",", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "entry", "[", "mask_entry", "]", "+=", "1", "\n", "entry", "[", "~", "mask_entry", "]", "=", "-", "1", "\n", "relations", ".", "append", "(", "entry", ")", "\n", "\n", "", "return", "torch", ".", "cat", "(", "relations", ",", "dim", "=", "0", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._get_cross_entropy_loss": [[271, 284], ["relation_scores.view", "relation_labels.view", "relation.RelationExtractor._loss"], "methods", ["None"], ["", "def", "_get_cross_entropy_loss", "(", "self", ",", "relation_scores", ",", "relation_labels", ")", ":", "\n", "        ", "\"\"\"\n        Compute cross-entropy loss on relation labels. Ignore diagonal entries and entries giving\n        relations between masked out spans.\n        \"\"\"", "\n", "# Need to add one for the null class.", "\n", "n_labels", "=", "self", ".", "_n_labels", "[", "self", ".", "_active_namespace", "]", "+", "1", "\n", "scores_flat", "=", "relation_scores", ".", "view", "(", "-", "1", ",", "n_labels", ")", "\n", "# Need to add 1 so that the null label is 0, to line up with indices into prediction matrix.", "\n", "labels_flat", "=", "relation_labels", ".", "view", "(", "-", "1", ")", "\n", "# Compute cross-entropy loss.", "\n", "loss", "=", "self", ".", "_loss", "(", "scores_flat", ",", "labels_flat", ")", "\n", "return", "loss", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.ner.NERTagger.__init__": [[36, 73], ["allennlp.models.model.Model.__init__", "torch.nn.ModuleDict", "torch.nn.CrossEntropyLoss", "vocab.get_vocab_size", "vocab.get_token_index", "make_feedforward", "torch.nn.Sequential", "dygie.training.ner_metrics.NERMetrics", "vocab.get_namespaces", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "torch.nn.Linear", "make_feedforward.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "make_feedforward", ":", "Callable", ",", "\n", "span_emb_dim", ":", "int", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "NERTagger", ",", "self", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "self", ".", "_namespaces", "=", "[", "entry", "for", "entry", "in", "vocab", ".", "get_namespaces", "(", ")", "if", "\"ner_labels\"", "in", "entry", "]", "\n", "\n", "# Number of classes determine the output dimension of the final layer", "\n", "self", ".", "_n_labels", "=", "{", "name", ":", "vocab", ".", "get_vocab_size", "(", "name", ")", "for", "name", "in", "self", ".", "_namespaces", "}", "\n", "\n", "# Null label is needed to keep track of when calculating the metrics", "\n", "for", "namespace", "in", "self", ".", "_namespaces", ":", "\n", "            ", "null_label", "=", "vocab", ".", "get_token_index", "(", "\"\"", ",", "namespace", ")", "\n", "assert", "null_label", "==", "0", "# If not, the dummy class won't correspond to the null label.", "\n", "\n", "# The output dim is 1 less than the number of labels because we don't score the null label;", "\n", "# we just give it a score of 0 by default.", "\n", "\n", "# Create a separate scorer and metric for each dataset we're dealing with.", "\n", "", "self", ".", "_ner_scorers", "=", "torch", ".", "nn", ".", "ModuleDict", "(", ")", "\n", "self", ".", "_ner_metrics", "=", "{", "}", "\n", "\n", "for", "namespace", "in", "self", ".", "_namespaces", ":", "\n", "            ", "mention_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "span_emb_dim", ")", "\n", "self", ".", "_ner_scorers", "[", "namespace", "]", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "mention_feedforward", ")", ",", "\n", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "\n", "mention_feedforward", ".", "get_output_dim", "(", ")", ",", "\n", "self", ".", "_n_labels", "[", "namespace", "]", "-", "1", ")", ")", ")", "\n", "\n", "self", ".", "_ner_metrics", "[", "namespace", "]", "=", "NERMetrics", "(", "self", ".", "_n_labels", "[", "namespace", "]", ",", "null_label", ")", "\n", "\n", "", "self", ".", "_active_namespace", "=", "None", "\n", "\n", "self", ".", "_loss", "=", "torch", ".", "nn", ".", "CrossEntropyLoss", "(", "reduction", "=", "\"sum\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.ner.NERTagger.forward": [[74, 124], ["scorer", "span_mask.unsqueeze", "allennlp.nn.util.replace_masked_values", "torch.cat.new_zeros", "torch.cat", "torch.cat.max", "ner.NERTagger.predict", "span_mask.unsqueeze.bool", "torch.cat.size", "torch.cat.size", "torch.cat.detach().cpu", "spans.detach().cpu", "span_mask.detach().cpu", "metrics", "torch.cat.view", "ner_labels.view", "span_mask.view().bool", "ner.NERTagger._loss", "torch.cat.detach", "spans.detach", "span_mask.detach", "span_mask.view"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.ner.NERTagger.predict"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# type: ignore", "\n", "spans", ":", "torch", ".", "IntTensor", ",", "\n", "span_mask", ":", "torch", ".", "IntTensor", ",", "\n", "span_embeddings", ":", "torch", ".", "IntTensor", ",", "\n", "sentence_lengths", ":", "torch", ".", "Tensor", ",", "\n", "ner_labels", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        TODO(dwadden) Write documentation.\n        \"\"\"", "\n", "\n", "# Shape: (Batch size, Number of Spans, Span Embedding Size)", "\n", "# span_embeddings", "\n", "\n", "self", ".", "_active_namespace", "=", "f\"{metadata.dataset}__ner_labels\"", "\n", "if", "self", ".", "_active_namespace", "not", "in", "self", ".", "_ner_scorers", ":", "\n", "            ", "return", "{", "\"loss\"", ":", "0", "}", "\n", "\n", "", "scorer", "=", "self", ".", "_ner_scorers", "[", "self", ".", "_active_namespace", "]", "\n", "\n", "ner_scores", "=", "scorer", "(", "span_embeddings", ")", "\n", "# Give large negative scores to masked-out elements.", "\n", "mask", "=", "span_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "ner_scores", "=", "util", ".", "replace_masked_values", "(", "ner_scores", ",", "mask", ".", "bool", "(", ")", ",", "-", "1e20", ")", "\n", "# The dummy_scores are the score for the null label.", "\n", "dummy_dims", "=", "[", "ner_scores", ".", "size", "(", "0", ")", ",", "ner_scores", ".", "size", "(", "1", ")", ",", "1", "]", "\n", "dummy_scores", "=", "ner_scores", ".", "new_zeros", "(", "*", "dummy_dims", ")", "\n", "ner_scores", "=", "torch", ".", "cat", "(", "(", "dummy_scores", ",", "ner_scores", ")", ",", "-", "1", ")", "\n", "\n", "_", ",", "predicted_ner", "=", "ner_scores", ".", "max", "(", "2", ")", "\n", "\n", "predictions", "=", "self", ".", "predict", "(", "ner_scores", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "spans", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "span_mask", ".", "detach", "(", ")", ".", "cpu", "(", ")", ",", "\n", "metadata", ")", "\n", "output_dict", "=", "{", "\"predictions\"", ":", "predictions", "}", "\n", "\n", "if", "ner_labels", "is", "not", "None", ":", "\n", "            ", "metrics", "=", "self", ".", "_ner_metrics", "[", "self", ".", "_active_namespace", "]", "\n", "metrics", "(", "predicted_ner", ",", "ner_labels", ",", "span_mask", ")", "\n", "ner_scores_flat", "=", "ner_scores", ".", "view", "(", "-", "1", ",", "self", ".", "_n_labels", "[", "self", ".", "_active_namespace", "]", ")", "\n", "ner_labels_flat", "=", "ner_labels", ".", "view", "(", "-", "1", ")", "\n", "mask_flat", "=", "span_mask", ".", "view", "(", "-", "1", ")", ".", "bool", "(", ")", "\n", "\n", "loss", "=", "self", ".", "_loss", "(", "ner_scores_flat", "[", "mask_flat", "]", ",", "ner_labels_flat", "[", "mask_flat", "]", ")", "\n", "\n", "output_dict", "[", "\"loss\"", "]", "=", "loss", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.ner.NERTagger.predict": [[125, 151], ["zip", "ner_scores_sent.max", "torch.nn.functional.softmax", "torch.nn.functional.softmax.max", "zip", "predictions.append", "span_mask_sent.bool", "ner.NERTagger.vocab.get_token_from_index", "label_span.tolist", "dygie.data.dataset_readers.document.PredictedNER", "predictions_sent.append", "label.item", "label_score_raw.item", "label_score_softmax.item"], "methods", ["None"], ["", "def", "predict", "(", "self", ",", "ner_scores", ",", "spans", ",", "span_mask", ",", "metadata", ")", ":", "\n", "# TODO(dwadden) Make sure the iteration works in documents with a single sentence.", "\n", "# Zipping up and iterating iterates over the zeroth dimension of each tensor; this", "\n", "# corresponds to iterating over sentences.", "\n", "        ", "predictions", "=", "[", "]", "\n", "zipped", "=", "zip", "(", "ner_scores", ",", "spans", ",", "span_mask", ",", "metadata", ")", "\n", "for", "ner_scores_sent", ",", "spans_sent", ",", "span_mask_sent", ",", "sentence", "in", "zipped", ":", "\n", "            ", "predicted_scores_raw", ",", "predicted_labels", "=", "ner_scores_sent", ".", "max", "(", "dim", "=", "1", ")", "\n", "softmax_scores", "=", "F", ".", "softmax", "(", "ner_scores_sent", ",", "dim", "=", "1", ")", "\n", "predicted_scores_softmax", ",", "_", "=", "softmax_scores", ".", "max", "(", "dim", "=", "1", ")", "\n", "ix", "=", "(", "predicted_labels", "!=", "0", ")", "&", "span_mask_sent", ".", "bool", "(", ")", "\n", "\n", "predictions_sent", "=", "[", "]", "\n", "zip_pred", "=", "zip", "(", "predicted_labels", "[", "ix", "]", ",", "predicted_scores_raw", "[", "ix", "]", ",", "\n", "predicted_scores_softmax", "[", "ix", "]", ",", "spans_sent", "[", "ix", "]", ")", "\n", "for", "label", ",", "label_score_raw", ",", "label_score_softmax", ",", "label_span", "in", "zip_pred", ":", "\n", "                ", "label_str", "=", "self", ".", "vocab", ".", "get_token_from_index", "(", "label", ".", "item", "(", ")", ",", "self", ".", "_active_namespace", ")", "\n", "span_start", ",", "span_end", "=", "label_span", ".", "tolist", "(", ")", "\n", "ner", "=", "[", "span_start", ",", "span_end", ",", "label_str", ",", "label_score_raw", ".", "item", "(", ")", ",", "\n", "label_score_softmax", ".", "item", "(", ")", "]", "\n", "prediction", "=", "document", ".", "PredictedNER", "(", "ner", ",", "sentence", ",", "sentence_offsets", "=", "True", ")", "\n", "predictions_sent", ".", "append", "(", "prediction", ")", "\n", "\n", "", "predictions", ".", "append", "(", "predictions_sent", ")", "\n", "\n", "", "return", "predictions", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.ner.NERTagger.get_metrics": [[153, 172], ["ner.NERTagger._ner_metrics.items", "metrics.get_metric", "namespace.replace", "res.update", "res.update", "sum", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "\"Loop over the metrics for all namespaces, and return as dict.\"", "\n", "res", "=", "{", "}", "\n", "for", "namespace", ",", "metrics", "in", "self", ".", "_ner_metrics", ".", "items", "(", ")", ":", "\n", "            ", "precision", ",", "recall", ",", "f1", "=", "metrics", ".", "get_metric", "(", "reset", ")", "\n", "prefix", "=", "namespace", ".", "replace", "(", "\"_labels\"", ",", "\"\"", ")", "\n", "to_update", "=", "{", "f\"{prefix}_precision\"", ":", "precision", ",", "\n", "f\"{prefix}_recall\"", ":", "recall", ",", "\n", "f\"{prefix}_f1\"", ":", "f1", "}", "\n", "res", ".", "update", "(", "to_update", ")", "\n", "\n", "", "res_avg", "=", "{", "}", "\n", "for", "name", "in", "[", "\"precision\"", ",", "\"recall\"", ",", "\"f1\"", "]", ":", "\n", "            ", "values", "=", "[", "res", "[", "key", "]", "for", "key", "in", "res", "if", "name", "in", "key", "]", "\n", "res_avg", "[", "f\"MEAN__ner_{name}\"", "]", "=", "sum", "(", "values", ")", "/", "len", "(", "values", ")", "if", "values", "else", "0", "\n", "res", ".", "update", "(", "res_avg", ")", "\n", "\n", "", "return", "res", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.__init__": [[48, 91], ["allennlp.models.model.Model.__init__", "allennlp.modules.token_embedders.Embedding", "make_feedforward", "allennlp.modules.TimeDistributed", "make_feedforward", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "torch.nn.Sequential", "dygie.models.entity_beam_pruner.Pruner", "allennlp.modules.TimeDistributed", "allennlp_models.coref.metrics.mention_recall.MentionRecall", "allennlp_models.coref.metrics.conll_coref_scores.ConllCorefScores", "allennlp.modules.FeedForward", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "torch.nn.Softmax", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "torch.nn.Linear", "make_feedforward.get_output_dim", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "torch.nn.Sigmoid", "make_feedforward.get_output_dim"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["def", "__init__", "(", "self", ",", "\n", "vocab", ":", "Vocabulary", ",", "\n", "make_feedforward", ":", "Callable", ",", "\n", "span_emb_dim", ":", "int", ",", "\n", "feature_size", ":", "int", ",", "\n", "spans_per_word", ":", "float", ",", "\n", "max_antecedents", ":", "int", ",", "\n", "coref_prop", ":", "int", "=", "0", ",", "\n", "coref_prop_dropout_f", ":", "float", "=", "0.0", ",", "\n", "regularizer", ":", "Optional", "[", "RegularizerApplicator", "]", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", "CorefResolver", ",", "self", ")", ".", "__init__", "(", "vocab", ",", "regularizer", ")", "\n", "\n", "# 10 possible distance buckets.", "\n", "self", ".", "_num_distance_buckets", "=", "10", "\n", "self", ".", "_spans_per_word", "=", "spans_per_word", "\n", "self", ".", "_max_antecedents", "=", "max_antecedents", "\n", "\n", "self", ".", "_distance_embedding", "=", "Embedding", "(", "embedding_dim", "=", "feature_size", ",", "\n", "num_embeddings", "=", "self", ".", "_num_distance_buckets", ")", "\n", "\n", "antecedent_input_dim", "=", "3", "*", "span_emb_dim", "+", "feature_size", "\n", "antecedent_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "antecedent_input_dim", ")", "\n", "self", ".", "_antecedent_feedforward", "=", "TimeDistributed", "(", "antecedent_feedforward", ")", "\n", "\n", "mention_feedforward", "=", "make_feedforward", "(", "input_dim", "=", "span_emb_dim", ")", "\n", "feedforward_scorer", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "mention_feedforward", ")", ",", "\n", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "mention_feedforward", ".", "get_output_dim", "(", ")", ",", "1", ")", ")", ")", "\n", "self", ".", "_mention_pruner", "=", "Pruner", "(", "feedforward_scorer", ")", "\n", "self", ".", "_antecedent_scorer", "=", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "\n", "antecedent_feedforward", ".", "get_output_dim", "(", ")", ",", "1", ")", ")", "\n", "\n", "self", ".", "_mention_recall", "=", "MentionRecall", "(", ")", "\n", "self", ".", "_conll_coref_scores", "=", "ConllCorefScores", "(", ")", "\n", "\n", "self", ".", "coref_prop", "=", "coref_prop", "\n", "self", ".", "_f_network", "=", "FeedForward", "(", "input_dim", "=", "2", "*", "span_emb_dim", ",", "\n", "num_layers", "=", "1", ",", "\n", "hidden_dims", "=", "span_emb_dim", ",", "\n", "activations", "=", "torch", ".", "nn", ".", "Sigmoid", "(", ")", ",", "\n", "dropout", "=", "coref_prop_dropout_f", ")", "\n", "\n", "self", ".", "antecedent_softmax", "=", "torch", ".", "nn", ".", "Softmax", "(", "dim", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.update_spans": [[92, 113], ["span_embeddings_batched.clone", "enumerate", "[].view"], "methods", ["None"], ["", "def", "update_spans", "(", "self", ",", "output_dict", ",", "span_embeddings_batched", ",", "indices", ")", ":", "\n", "        ", "new_span_embeddings_batched", "=", "span_embeddings_batched", ".", "clone", "(", ")", "\n", "offsets", "=", "{", "}", "\n", "for", "key", "in", "indices", ":", "\n", "            ", "offset", "=", "0", "\n", "while", "indices", "[", "key", "]", "[", "offset", "]", "==", "0", ":", "\n", "                ", "offset", "+=", "1", "\n", "", "offsets", "[", "key", "]", "=", "offset", "\n", "", "for", "doc_key", "in", "output_dict", ":", "\n", "            ", "span_ix", "=", "output_dict", "[", "doc_key", "]", "[", "\"span_ix\"", "]", "\n", "top_span_embeddings", "=", "output_dict", "[", "doc_key", "]", "[", "\"top_span_embeddings\"", "]", "\n", "for", "ix", ",", "el", "in", "enumerate", "(", "output_dict", "[", "doc_key", "]", "[", "\"top_span_indices\"", "]", ".", "view", "(", "-", "1", ")", ")", ":", "\n", "# This floor division is correct. We're doing division with a remainder, where", "\n", "# `row_ix` is the quotient (plus an offset added at the end) and `col_ix` is the", "\n", "# remainder. This converts from a span index to a row and column index in the span", "\n", "# embedding matrix.", "\n", "                ", "row_ix", "=", "span_ix", "[", "el", "]", "//", "span_embeddings_batched", ".", "shape", "[", "1", "]", "+", "offsets", "[", "doc_key", "]", "\n", "col_ix", "=", "span_ix", "[", "el", "]", "%", "span_embeddings_batched", ".", "shape", "[", "1", "]", "\n", "new_span_embeddings_batched", "[", "row_ix", ",", "col_ix", "]", "=", "top_span_embeddings", "[", "0", ",", "ix", "]", "\n", "\n", "", "", "return", "new_span_embeddings_batched", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.coref_propagation": [[114, 118], ["coref.CorefResolver.coref_propagation_doc"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.coref_propagation_doc"], ["", "def", "coref_propagation", "(", "self", ",", "output_dict", ")", ":", "\n", "        ", "for", "doc_key", "in", "output_dict", ":", "\n", "            ", "output_dict", "[", "doc_key", "]", "=", "self", ".", "coref_propagation_doc", "(", "output_dict", "[", "doc_key", "]", ")", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.coref_propagation_doc": [[119, 158], ["range", "top_span_embeddings.repeat", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "coref.CorefResolver._f_network", "coref.CorefResolver.get_coref_scores", "antecedent_indices.max", "coref.CorefResolver.antecedent_softmax", "allennlp.nn.util.batched_index_select().unsqueeze", "antecedent_indices.unsqueeze().unsqueeze().repeat", "top_span_embeddings.unsqueeze().repeat", "coref.CorefResolver._mention_pruner._scorer", "allennlp.nn.util.batched_index_select", "antecedent_indices.unsqueeze().unsqueeze", "top_span_embeddings.unsqueeze", "antecedent_indices.unsqueeze", "allennlp.nn.util.batched_index_select().unsqueeze.permute", "torch.gather().permute", "torch.gather().permute", "torch.gather().permute", "torch.gather().permute", "torch.gather", "torch.gather", "torch.gather", "torch.gather"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_coref_scores"], ["", "def", "coref_propagation_doc", "(", "self", ",", "output_dict", ")", ":", "\n", "        ", "coreference_scores", "=", "output_dict", "[", "\"coreference_scores\"", "]", "\n", "top_span_embeddings", "=", "output_dict", "[", "\"top_span_embeddings\"", "]", "\n", "antecedent_indices", "=", "output_dict", "[", "\"antecedent_indices\"", "]", "\n", "for", "t", "in", "range", "(", "self", ".", "coref_prop", ")", ":", "\n", "            ", "assert", "coreference_scores", ".", "shape", "[", "1", "]", "==", "antecedent_indices", ".", "shape", "[", "0", "]", "\n", "assert", "coreference_scores", ".", "shape", "[", "2", "]", "-", "1", "==", "antecedent_indices", ".", "shape", "[", "1", "]", "\n", "assert", "top_span_embeddings", ".", "shape", "[", "1", "]", "==", "coreference_scores", ".", "shape", "[", "1", "]", "\n", "assert", "antecedent_indices", ".", "max", "(", ")", "<=", "top_span_embeddings", ".", "shape", "[", "1", "]", "\n", "\n", "antecedent_distribution", "=", "self", ".", "antecedent_softmax", "(", "coreference_scores", ")", "[", ":", ",", ":", ",", "1", ":", "]", "\n", "top_span_emb_repeated", "=", "top_span_embeddings", ".", "repeat", "(", "\n", "antecedent_distribution", ".", "shape", "[", "2", "]", ",", "1", ",", "1", ")", "\n", "if", "antecedent_indices", ".", "shape", "[", "0", "]", "==", "antecedent_indices", ".", "shape", "[", "1", "]", ":", "\n", "                ", "selected_top_span_embs", "=", "util", ".", "batched_index_select", "(", "\n", "top_span_emb_repeated", ",", "antecedent_indices", ")", ".", "unsqueeze", "(", "0", ")", "\n", "entity_embs", "=", "(", "selected_top_span_embs", ".", "permute", "(", "\n", "[", "3", ",", "0", ",", "1", ",", "2", "]", ")", "*", "antecedent_distribution", ")", ".", "permute", "(", "[", "1", ",", "2", ",", "3", ",", "0", "]", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "", "else", ":", "\n", "                ", "ant_var1", "=", "antecedent_indices", ".", "unsqueeze", "(", "\n", "0", ")", ".", "unsqueeze", "(", "-", "1", ")", ".", "repeat", "(", "1", ",", "1", ",", "1", ",", "top_span_embeddings", ".", "shape", "[", "-", "1", "]", ")", "\n", "top_var1", "=", "top_span_embeddings", ".", "unsqueeze", "(", "1", ")", ".", "repeat", "(", "\n", "1", ",", "antecedent_distribution", ".", "shape", "[", "1", "]", ",", "1", ",", "1", ")", "\n", "entity_embs", "=", "(", "torch", ".", "gather", "(", "top_var1", ",", "2", ",", "ant_var1", ")", ".", "permute", "(", "\n", "[", "3", ",", "0", ",", "1", ",", "2", "]", ")", "*", "antecedent_distribution", ")", ".", "permute", "(", "[", "1", ",", "2", ",", "3", ",", "0", "]", ")", ".", "sum", "(", "dim", "=", "2", ")", "\n", "\n", "", "f_network_input", "=", "torch", ".", "cat", "(", "[", "top_span_embeddings", ",", "entity_embs", "]", ",", "dim", "=", "-", "1", ")", "\n", "f_weights", "=", "self", ".", "_f_network", "(", "f_network_input", ")", "\n", "top_span_embeddings", "=", "f_weights", "*", "top_span_embeddings", "+", "(", "1.0", "-", "f_weights", ")", "*", "entity_embs", "\n", "\n", "coreference_scores", "=", "self", ".", "get_coref_scores", "(", "\n", "top_span_embeddings", ",", "\n", "self", ".", "_mention_pruner", ".", "_scorer", "(", "\n", "top_span_embeddings", ")", ",", "output_dict", "[", "\"antecedent_indices\"", "]", ",", "\n", "output_dict", "[", "\"valid_antecedent_offsets\"", "]", ",", "output_dict", "[", "\"valid_antecedent_log_mask\"", "]", ")", "\n", "\n", "", "output_dict", "[", "\"coreference_scores\"", "]", "=", "coreference_scores", "\n", "output_dict", "[", "\"top_span_embeddings\"", "]", "=", "top_span_embeddings", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.compute_representations": [[161, 196], ["len", "torch.tensor", "torch.tensor", "torch.tensor", "torch.tensor", "uniq_keys.append", "sentence_lengths[].sum().item", "coref.CorefResolver._compute_representations_doc", "sentence_lengths[].sum"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_representations_doc"], ["", "def", "compute_representations", "(", "self", ",", "# type: ignore", "\n", "spans_batched", ":", "torch", ".", "IntTensor", ",", "\n", "span_mask_batched", ",", "\n", "span_embeddings_batched", ",", "# TODO(dwadden) add type.", "\n", "sentence_lengths", ",", "\n", "coref_labels_batched", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "        ", "\"\"\"\n        Run the forward pass. Since we can only have coreferences between spans in the same\n        document, we loop over the documents in the batch. This function assumes that the inputs are\n        in order, but may go across documents.\n        \"\"\"", "\n", "output_docs", "=", "{", "}", "\n", "# TODO(dwadden) Update this when I implement multiple documents per minibatch.", "\n", "doc_keys", "=", "[", "metadata", ".", "doc_key", "]", "*", "len", "(", "metadata", ")", "\n", "uniq_keys", "=", "[", "]", "\n", "for", "entry", "in", "doc_keys", ":", "\n", "            ", "if", "entry", "not", "in", "uniq_keys", ":", "\n", "                ", "uniq_keys", ".", "append", "(", "entry", ")", "\n", "\n", "", "", "indices", "=", "{", "}", "\n", "for", "key", "in", "uniq_keys", ":", "\n", "            ", "ix_list", "=", "[", "1", "if", "entry", "==", "key", "else", "0", "for", "entry", "in", "doc_keys", "]", "\n", "indices", "[", "key", "]", "=", "ix_list", "\n", "doc_metadata", "=", "metadata", "\n", "ix", "=", "torch", ".", "tensor", "(", "ix_list", ",", "dtype", "=", "torch", ".", "bool", ")", "\n", "# If we don't have coref labels, leave as None; else get the right batch.", "\n", "coref_labels", "=", "(", "coref_labels_batched", "[", "ix", "]", "\n", "if", "coref_labels_batched", "is", "not", "None", "\n", "else", "coref_labels_batched", ")", "\n", "if", "sentence_lengths", "[", "ix", "]", ".", "sum", "(", ")", ".", "item", "(", ")", ">", "1", ":", "\n", "                ", "output_docs", "[", "key", "]", "=", "self", ".", "_compute_representations_doc", "(", "\n", "spans_batched", "[", "ix", "]", ",", "span_mask_batched", "[", "ix", "]", ",", "span_embeddings_batched", "[", "ix", "]", ",", "\n", "sentence_lengths", "[", "ix", "]", ",", "ix", ",", "coref_labels", ",", "doc_metadata", ")", "\n", "", "", "return", "output_docs", ",", "indices", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.predict_labels": [[197, 201], ["coref.CorefResolver.collect_losses", "coref.CorefResolver.predict_labels_doc"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.collect_losses", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.predict_labels_doc"], ["", "def", "predict_labels", "(", "self", ",", "output_docs", ",", "metadata", ")", ":", "\n", "        ", "for", "key", "in", "output_docs", ":", "\n", "            ", "output_docs", "[", "key", "]", "=", "self", ".", "predict_labels_doc", "(", "output_docs", "[", "key", "]", ")", "\n", "", "return", "self", ".", "collect_losses", "(", "output_docs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.collect_losses": [[202, 232], ["entry.get", "any", "ValueError", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "torch.sum", "torch.sum", "torch.sum", "torch.sum", "output_docs.values", "all", "len", "entry[].unsqueeze", "output_docs.values"], "methods", ["None"], ["", "def", "collect_losses", "(", "self", ",", "output_docs", ")", ":", "\n", "        ", "uniq_keys", "=", "[", "el", "for", "el", "in", "output_docs", "]", "\n", "losses", "=", "[", "entry", ".", "get", "(", "\"loss\"", ")", "for", "entry", "in", "output_docs", ".", "values", "(", ")", "]", "\n", "# If we're predicting, there won't be a loss.", "\n", "no_loss", "=", "[", "loss", "is", "None", "for", "loss", "in", "losses", "]", "\n", "if", "any", "(", "no_loss", ")", "and", "not", "all", "(", "no_loss", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"All docs in batch should either have a loss, or not have one.\"", ")", "\n", "", "no_loss", "=", "no_loss", "[", "0", "]", "\n", "\n", "if", "no_loss", ":", "\n", "            ", "loss", "=", "None", "\n", "", "else", ":", "\n", "            ", "losses", "=", "torch", ".", "cat", "(", "[", "entry", "[", "\"loss\"", "]", ".", "unsqueeze", "(", "0", ")", "for", "entry", "in", "output_docs", ".", "values", "(", ")", "]", ")", "\n", "loss", "=", "torch", ".", "sum", "(", "losses", ")", "\n", "\n", "# At train time, return a separate output dict for each document.", "\n", "", "if", "self", ".", "training", ":", "\n", "            ", "output", "=", "{", "\"doc\"", ":", "output_docs", "}", "\n", "# At test time, we evaluate a whole document at a time. Just return the results for that", "\n", "# document.", "\n", "", "else", ":", "\n", "            ", "assert", "len", "(", "uniq_keys", ")", "==", "1", "\n", "key", "=", "uniq_keys", "[", "0", "]", "\n", "output", "=", "output_docs", "[", "key", "]", "\n", "\n", "# Add the loss if we have one.", "\n", "", "if", "loss", "is", "not", "None", ":", "\n", "            ", "output", "[", "\"loss\"", "]", "=", "loss", "\n", "\n", "", "return", "output", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_representations_doc": [[233, 308], ["span_mask_batched.view().nonzero().squeeze", "coref.CorefResolver._flatten_spans", "coref.CorefResolver._flatten_coref_labels", "sentence_lengths.sum().item", "spans.size", "max", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "torch.ones().unsqueeze", "coref.CorefResolver._mention_pruner", "top_span_mask.unsqueeze.unsqueeze.unsqueeze", "allennlp.nn.util.flatten_and_batch_shift_indices", "allennlp.nn.util.batched_index_select", "min", "coref.CorefResolver._generate_valid_antecedents", "coref.CorefResolver.get_coref_scores", "int", "allennlp.nn.util.get_device_of", "span_mask_batched.view().nonzero", "sentence_lengths.sum", "math.ceil", "torch.ones", "torch.ones", "torch.ones", "torch.ones", "span_mask_batched.view"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._flatten_spans", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._flatten_coref_labels", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._generate_valid_antecedents", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_coref_scores"], ["", "def", "_compute_representations_doc", "(", "\n", "self", ",", "# type: ignore", "\n", "spans_batched", ":", "torch", ".", "IntTensor", ",", "\n", "span_mask_batched", ",", "\n", "span_embeddings_batched", ",", "# TODO(dwadden) add type.", "\n", "sentence_lengths", ",", "\n", "ix", ",", "\n", "coref_labels_batched", ":", "torch", ".", "IntTensor", "=", "None", ",", "\n", "metadata", ":", "List", "[", "Dict", "[", "str", ",", "Any", "]", "]", "=", "None", ")", "->", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ":", "\n", "# pylint: disable=arguments-differ", "\n", "        ", "\"\"\"\n        Run the forward pass for a single document.\n\n        Important: This function assumes that sentences are going to be passed in in sorted order,\n        from the same document.\n        \"\"\"", "\n", "# TODO(dwadden) How to handle case where only one span from a cluster makes it into the", "\n", "# minibatch? Should I get rid of the cluster?", "\n", "# TODO(dwadden) Write quick unit tests for correctness, time permitting.", "\n", "span_ix", "=", "span_mask_batched", ".", "view", "(", "-", "1", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", ")", "# Indices of the spans to keep.", "\n", "spans", ",", "span_embeddings", "=", "self", ".", "_flatten_spans", "(", "\n", "spans_batched", ",", "span_ix", ",", "span_embeddings_batched", ",", "sentence_lengths", ")", "\n", "coref_labels", "=", "self", ".", "_flatten_coref_labels", "(", "coref_labels_batched", ",", "span_ix", ")", "\n", "\n", "document_length", "=", "sentence_lengths", ".", "sum", "(", ")", ".", "item", "(", ")", "\n", "num_spans", "=", "spans", ".", "size", "(", "1", ")", "\n", "\n", "# Prune based on mention scores. Make sure we keep at least 1.", "\n", "num_spans_to_keep", "=", "max", "(", "2", ",", "int", "(", "math", ".", "ceil", "(", "self", ".", "_spans_per_word", "*", "document_length", ")", ")", ")", "\n", "\n", "# Since there's only one minibatch, there aren't any masked spans for us. The span mask is", "\n", "# always 1.", "\n", "span_mask", "=", "torch", ".", "ones", "(", "num_spans", ",", "device", "=", "spans_batched", ".", "device", ")", ".", "unsqueeze", "(", "0", ")", "\n", "(", "top_span_embeddings", ",", "top_span_mask", ",", "\n", "top_span_indices", ",", "top_span_mention_scores", ",", "num_items_kept", ")", "=", "self", ".", "_mention_pruner", "(", "\n", "span_embeddings", ",", "span_mask", ",", "num_spans_to_keep", ")", "\n", "top_span_mask", "=", "top_span_mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# Shape: (batch_size * num_spans_to_keep)", "\n", "flat_top_span_indices", "=", "util", ".", "flatten_and_batch_shift_indices", "(", "top_span_indices", ",", "num_spans", ")", "\n", "\n", "# Compute final predictions for which spans to consider as mentions.", "\n", "# Shape: (batch_size, num_spans_to_keep, 2)", "\n", "top_spans", "=", "util", ".", "batched_index_select", "(", "spans", ",", "\n", "top_span_indices", ",", "\n", "flat_top_span_indices", ")", "\n", "\n", "# Compute indices for antecedent spans to consider.", "\n", "max_antecedents", "=", "min", "(", "self", ".", "_max_antecedents", ",", "num_spans_to_keep", ")", "\n", "\n", "# Shapes:", "\n", "# (num_spans_to_keep, max_antecedents),", "\n", "# (1, max_antecedents),", "\n", "# (1, num_spans_to_keep, max_antecedents)", "\n", "valid_antecedent_indices", ",", "valid_antecedent_offsets", ",", "valid_antecedent_log_mask", "=", "self", ".", "_generate_valid_antecedents", "(", "num_spans_to_keep", ",", "max_antecedents", ",", "util", ".", "get_device_of", "(", "span_embeddings", ")", ")", "\n", "\n", "coreference_scores", "=", "self", ".", "get_coref_scores", "(", "\n", "top_span_embeddings", ",", "top_span_mention_scores", ",", "valid_antecedent_indices", ",", "\n", "valid_antecedent_offsets", ",", "valid_antecedent_log_mask", ")", "\n", "\n", "output_dict", "=", "{", "\"top_spans\"", ":", "top_spans", ",", "\n", "\"antecedent_indices\"", ":", "valid_antecedent_indices", ",", "\n", "\"valid_antecedent_log_mask\"", ":", "valid_antecedent_log_mask", ",", "\n", "\"valid_antecedent_offsets\"", ":", "valid_antecedent_offsets", ",", "\n", "\"top_span_indices\"", ":", "top_span_indices", ",", "\n", "\"top_span_mask\"", ":", "top_span_mask", ",", "\n", "\"top_span_embeddings\"", ":", "top_span_embeddings", ",", "\n", "\"flat_top_span_indices\"", ":", "flat_top_span_indices", ",", "\n", "\"coref_labels\"", ":", "coref_labels", ",", "\n", "\"coreference_scores\"", ":", "coreference_scores", ",", "\n", "\"sentence_lengths\"", ":", "sentence_lengths", ",", "\n", "\"span_ix\"", ":", "span_ix", ",", "\n", "\"metadata\"", ":", "metadata", "}", "\n", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_coref_scores": [[309, 331], ["allennlp.nn.util.flattened_index_select", "allennlp.nn.util.flattened_index_select().squeeze", "coref.CorefResolver._compute_span_pair_embeddings", "coref.CorefResolver._compute_coreference_scores", "allennlp.nn.util.flattened_index_select"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_span_pair_embeddings", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_coreference_scores"], ["", "def", "get_coref_scores", "(", "self", ",", "\n", "top_span_embeddings", ",", "\n", "top_span_mention_scores", ",", "\n", "valid_antecedent_indices", ",", "\n", "valid_antecedent_offsets", ",", "\n", "valid_antecedent_log_mask", ")", ":", "\n", "        ", "candidate_antecedent_embeddings", "=", "util", ".", "flattened_index_select", "(", "top_span_embeddings", ",", "\n", "valid_antecedent_indices", ")", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents)", "\n", "candidate_antecedent_mention_scores", "=", "util", ".", "flattened_index_select", "(", "top_span_mention_scores", ",", "\n", "valid_antecedent_indices", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# Compute antecedent scores.", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents, embedding_size)", "\n", "span_pair_embeddings", "=", "self", ".", "_compute_span_pair_embeddings", "(", "top_span_embeddings", ",", "\n", "candidate_antecedent_embeddings", ",", "\n", "valid_antecedent_offsets", ")", "\n", "# Shape: (batch_size, num_spans_to_keep, 1 + max_antecedents)", "\n", "coreference_scores", "=", "self", ".", "_compute_coreference_scores", "(", "span_pair_embeddings", ",", "\n", "top_span_mention_scores", ",", "\n", "candidate_antecedent_mention_scores", ",", "\n", "valid_antecedent_log_mask", ")", "\n", "return", "coreference_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.predict_labels_doc": [[332, 386], ["coreference_scores.max", "allennlp.nn.util.batched_index_select", "allennlp.nn.util.flattened_index_select().squeeze", "valid_antecedent_log_mask.long", "coref.CorefResolver._compute_antecedent_gold_labels", "allennlp.nn.util.masked_log_softmax", "coref.CorefResolver._make_evaluation_metadata", "coref.CorefResolver._mention_recall", "coref.CorefResolver._conll_coref_scores", "coref_labels.unsqueeze", "coref.CorefResolver.log", "allennlp.nn.util.logsumexp().sum", "valid_antecedent_indices.unsqueeze", "allennlp.nn.util.flattened_index_select", "allennlp.nn.util.logsumexp"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_antecedent_gold_labels", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._make_evaluation_metadata"], ["", "def", "predict_labels_doc", "(", "self", ",", "output_dict", ")", ":", "\n", "# Shape: (batch_size, num_spans_to_keep)", "\n", "        ", "coref_labels", "=", "output_dict", "[", "\"coref_labels\"", "]", "\n", "coreference_scores", "=", "output_dict", "[", "\"coreference_scores\"", "]", "\n", "_", ",", "predicted_antecedents", "=", "coreference_scores", ".", "max", "(", "2", ")", "\n", "# Subtract one here because index 0 is the \"no antecedent\" class,", "\n", "# so this makes the indices line up with actual spans if the prediction", "\n", "# is greater than -1.", "\n", "predicted_antecedents", "-=", "1", "\n", "\n", "output_dict", "[", "\"predicted_antecedents\"", "]", "=", "predicted_antecedents", "\n", "\n", "top_span_indices", "=", "output_dict", "[", "\"top_span_indices\"", "]", "\n", "flat_top_span_indices", "=", "output_dict", "[", "\"flat_top_span_indices\"", "]", "\n", "valid_antecedent_indices", "=", "output_dict", "[", "\"antecedent_indices\"", "]", "\n", "valid_antecedent_log_mask", "=", "output_dict", "[", "\"valid_antecedent_log_mask\"", "]", "\n", "top_spans", "=", "output_dict", "[", "\"top_spans\"", "]", "\n", "top_span_mask", "=", "output_dict", "[", "\"top_span_mask\"", "]", "\n", "metadata", "=", "output_dict", "[", "\"metadata\"", "]", "\n", "sentence_lengths", "=", "output_dict", "[", "\"sentence_lengths\"", "]", "\n", "\n", "if", "coref_labels", "is", "not", "None", ":", "\n", "# Find the gold labels for the spans which we kept.", "\n", "            ", "pruned_gold_labels", "=", "util", ".", "batched_index_select", "(", "coref_labels", ".", "unsqueeze", "(", "-", "1", ")", ",", "\n", "top_span_indices", ",", "\n", "flat_top_span_indices", ")", "\n", "\n", "antecedent_labels", "=", "util", ".", "flattened_index_select", "(", "pruned_gold_labels", ",", "\n", "valid_antecedent_indices", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "# There's an integer wrap-around happening here. It occurs in the original code.", "\n", "antecedent_labels", "+=", "valid_antecedent_log_mask", ".", "long", "(", ")", "\n", "\n", "# Compute labels.", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents + 1)", "\n", "gold_antecedent_labels", "=", "self", ".", "_compute_antecedent_gold_labels", "(", "pruned_gold_labels", ",", "\n", "antecedent_labels", ")", "\n", "# Now, compute the loss using the negative marginal log-likelihood.", "\n", "coreference_log_probs", "=", "util", ".", "masked_log_softmax", "(", "coreference_scores", ",", "top_span_mask", ")", "\n", "correct_antecedent_log_probs", "=", "coreference_log_probs", "+", "gold_antecedent_labels", ".", "log", "(", ")", "\n", "negative_marginal_log_likelihood", "=", "-", "util", ".", "logsumexp", "(", "correct_antecedent_log_probs", ")", ".", "sum", "(", ")", "\n", "\n", "# Need to get cluster data in same form as for original AllenNLP coref code so that the", "\n", "# evaluation code works.", "\n", "evaluation_metadata", "=", "self", ".", "_make_evaluation_metadata", "(", "metadata", ",", "sentence_lengths", ")", "\n", "\n", "self", ".", "_mention_recall", "(", "top_spans", ",", "evaluation_metadata", ")", "\n", "\n", "# TODO(dwadden) Shouldnt need to do the unsqueeze here; figure out what's happening.", "\n", "self", ".", "_conll_coref_scores", "(", "\n", "top_spans", ",", "valid_antecedent_indices", ".", "unsqueeze", "(", "0", ")", ",", "predicted_antecedents", ",", "evaluation_metadata", ")", "\n", "\n", "output_dict", "[", "\"loss\"", "]", "=", "negative_marginal_log_likelihood", "\n", "\n", "", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.make_output_human_readable": [[387, 460], ["output_dict[].detach().cpu", "output_dict[].detach().cpu", "output_dict[].detach().cpu", "zip", "enumerate", "batch_clusters.append", "output_dict[].detach", "output_dict[].detach", "output_dict[].detach", "zip", "clusters[].append", "top_spans[].item", "top_spans[].item", "len", "clusters.append", "span[].item", "span[].item"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "make_output_human_readable", "(", "self", ",", "output_dict", ":", "Dict", "[", "str", ",", "torch", ".", "Tensor", "]", ")", ":", "\n", "        ", "\"\"\"\n        Converts the list of spans and predicted antecedent indices into clusters\n        of spans for each element in the batch.\n\n        Parameters\n        ----------\n        output_dict : ``Dict[str, torch.Tensor]``, required.\n            The result of calling :func:`forward` on an instance or batch of instances.\n\n        Returns\n        -------\n        The same output dictionary, but with an additional ``clusters`` key:\n\n        clusters : ``List[List[List[Tuple[int, int]]]]``\n            A nested list, representing, for each instance in the batch, the list of clusters,\n            which are in turn comprised of a list of (start, end) inclusive spans into the\n            original document.\n        \"\"\"", "\n", "\n", "# A tensor of shape (batch_size, num_spans_to_keep, 2), representing", "\n", "# the start and end indices of each span.", "\n", "batch_top_spans", "=", "output_dict", "[", "\"top_spans\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "# A tensor of shape (batch_size, num_spans_to_keep) representing, for each span,", "\n", "# the index into ``antecedent_indices`` which specifies the antecedent span. Additionally,", "\n", "# the index can be -1, specifying that the span has no predicted antecedent.", "\n", "batch_predicted_antecedents", "=", "output_dict", "[", "\"predicted_antecedents\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "\n", "# A tensor of shape (num_spans_to_keep, max_antecedents), representing the indices", "\n", "# of the predicted antecedents with respect to the 2nd dimension of ``batch_top_spans``", "\n", "# for each antecedent we considered.", "\n", "antecedent_indices", "=", "output_dict", "[", "\"antecedent_indices\"", "]", ".", "detach", "(", ")", ".", "cpu", "(", ")", "\n", "batch_clusters", ":", "List", "[", "List", "[", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "]", "]", "=", "[", "]", "\n", "\n", "# Calling zip() on two tensors results in an iterator over their", "\n", "# first dimension. This is iterating over instances in the batch.", "\n", "for", "top_spans", ",", "predicted_antecedents", "in", "zip", "(", "batch_top_spans", ",", "batch_predicted_antecedents", ")", ":", "\n", "            ", "spans_to_cluster_ids", ":", "Dict", "[", "Tuple", "[", "int", ",", "int", "]", ",", "int", "]", "=", "{", "}", "\n", "clusters", ":", "List", "[", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "]", "=", "[", "]", "\n", "\n", "for", "i", ",", "(", "span", ",", "predicted_antecedent", ")", "in", "enumerate", "(", "zip", "(", "top_spans", ",", "predicted_antecedents", ")", ")", ":", "\n", "                ", "if", "predicted_antecedent", "<", "0", ":", "\n", "# We don't care about spans which are", "\n", "# not co-referent with anything.", "\n", "                    ", "continue", "\n", "\n", "# Find the right cluster to update with this span.", "\n", "", "predicted_index", "=", "antecedent_indices", "[", "i", ",", "predicted_antecedent", "]", "\n", "\n", "antecedent_span", "=", "(", "top_spans", "[", "predicted_index", ",", "0", "]", ".", "item", "(", ")", ",", "\n", "top_spans", "[", "predicted_index", ",", "1", "]", ".", "item", "(", ")", ")", "\n", "\n", "# Check if we've seen the span before.", "\n", "if", "antecedent_span", "in", "spans_to_cluster_ids", ":", "\n", "                    ", "predicted_cluster_id", ":", "int", "=", "spans_to_cluster_ids", "[", "antecedent_span", "]", "\n", "", "else", ":", "\n", "# We start a new cluster.", "\n", "                    ", "predicted_cluster_id", "=", "len", "(", "clusters", ")", "\n", "# Append a new cluster containing only this span.", "\n", "clusters", ".", "append", "(", "[", "antecedent_span", "]", ")", "\n", "# Record the new id of this span.", "\n", "spans_to_cluster_ids", "[", "antecedent_span", "]", "=", "predicted_cluster_id", "\n", "\n", "# Now add the span we are currently considering.", "\n", "", "span_start", ",", "span_end", "=", "span", "[", "0", "]", ".", "item", "(", ")", ",", "span", "[", "1", "]", ".", "item", "(", ")", "\n", "clusters", "[", "predicted_cluster_id", "]", ".", "append", "(", "(", "span_start", ",", "span_end", ")", ")", "\n", "spans_to_cluster_ids", "[", "(", "span_start", ",", "span_end", ")", "]", "=", "predicted_cluster_id", "\n", "", "batch_clusters", ".", "append", "(", "clusters", ")", "\n", "\n", "", "output_dict", "[", "\"predicted_clusters\"", "]", "=", "batch_clusters", "\n", "return", "output_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.get_metrics": [[461, 470], ["coref.CorefResolver._mention_recall.get_metric", "coref.CorefResolver._conll_coref_scores.get_metric"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.get_metric", "home.repos.pwc.inspect_result.dwadden_dygiepp.training.ner_metrics.NERMetrics.get_metric"], ["", "@", "overrides", "\n", "def", "get_metrics", "(", "self", ",", "reset", ":", "bool", "=", "False", ")", "->", "Dict", "[", "str", ",", "float", "]", ":", "\n", "        ", "mention_recall", "=", "self", ".", "_mention_recall", ".", "get_metric", "(", "reset", ")", "\n", "coref_precision", ",", "coref_recall", ",", "coref_f1", "=", "self", ".", "_conll_coref_scores", ".", "get_metric", "(", "reset", ")", "\n", "\n", "return", "{", "\"coref_precision\"", ":", "coref_precision", ",", "\n", "\"coref_recall\"", ":", "coref_recall", ",", "\n", "\"coref_f1\"", ":", "coref_f1", ",", "\n", "\"coref_mention_recall\"", ":", "mention_recall", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._generate_valid_antecedents": [[471, 527], ["allennlp.nn.util.get_range_vector().unsqueeze", "torch.relu().long", "torch.relu().long", "allennlp.nn.util.get_range_vector", "torch.relu", "torch.relu", "allennlp.nn.util.get_range_vector", "raw_antecedent_indices.float"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_generate_valid_antecedents", "(", "num_spans_to_keep", ":", "int", ",", "\n", "max_antecedents", ":", "int", ",", "\n", "device", ":", "int", ")", "->", "Tuple", "[", "torch", ".", "IntTensor", ",", "\n", "torch", ".", "IntTensor", ",", "\n", "torch", ".", "FloatTensor", "]", ":", "\n", "        ", "\"\"\"\n        This method generates possible antecedents per span which survived the pruning\n        stage. This procedure is `generic across the batch`. The reason this is the case is\n        that each span in a batch can be coreferent with any previous span, but here we\n        are computing the possible `indices` of these spans. So, regardless of the batch,\n        the 1st span _cannot_ have any antecedents, because there are none to select from.\n        Similarly, each element can only predict previous spans, so this returns a matrix\n        of shape (num_spans_to_keep, max_antecedents), where the (i,j)-th index is equal to\n        (i - 1) - j if j <= i, or zero otherwise.\n\n        Parameters\n        ----------\n        num_spans_to_keep : ``int``, required.\n            The number of spans that were kept while pruning.\n        max_antecedents : ``int``, required.\n            The maximum number of antecedent spans to consider for every span.\n        device: ``int``, required.\n            The CUDA device to use.\n\n        Returns\n        -------\n        valid_antecedent_indices : ``torch.IntTensor``\n            The indices of every antecedent to consider with respect to the top k spans.\n            Has shape ``(num_spans_to_keep, max_antecedents)``.\n        valid_antecedent_offsets : ``torch.IntTensor``\n            The distance between the span and each of its antecedents in terms of the number\n            of considered spans (i.e not the word distance between the spans).\n            Has shape ``(1, max_antecedents)``.\n        valid_antecedent_log_mask : ``torch.FloatTensor``\n            The logged mask representing whether each antecedent span is valid. Required since\n            different spans have different numbers of valid antecedents. For example, the first\n            span in the document should have no valid antecedents.\n            Has shape ``(1, num_spans_to_keep, max_antecedents)``.\n        \"\"\"", "\n", "# Shape: (num_spans_to_keep, 1)", "\n", "target_indices", "=", "util", ".", "get_range_vector", "(", "num_spans_to_keep", ",", "device", ")", ".", "unsqueeze", "(", "1", ")", "\n", "\n", "# Shape: (1, max_antecedents)", "\n", "valid_antecedent_offsets", "=", "(", "util", ".", "get_range_vector", "(", "max_antecedents", ",", "device", ")", "+", "1", ")", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# This is a broadcasted subtraction.", "\n", "# Shape: (num_spans_to_keep, max_antecedents)", "\n", "raw_antecedent_indices", "=", "target_indices", "-", "valid_antecedent_offsets", "\n", "\n", "# Shape: (1, num_spans_to_keep, max_antecedents)", "\n", "valid_antecedent_log_mask", "=", "(", "raw_antecedent_indices", ">=", "0", ")", ".", "float", "(", ")", ".", "unsqueeze", "(", "0", ")", ".", "log", "(", ")", "\n", "\n", "# Shape: (num_spans_to_keep, max_antecedents)", "\n", "valid_antecedent_indices", "=", "F", ".", "relu", "(", "raw_antecedent_indices", ".", "float", "(", ")", ")", ".", "long", "(", ")", "\n", "return", "valid_antecedent_indices", ",", "valid_antecedent_offsets", ",", "valid_antecedent_log_mask", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_span_pair_embeddings": [[528, 581], ["top_span_embeddings.unsqueeze().expand_as", "coref.CorefResolver._distance_embedding", "antecedent_distance_embeddings.expand.expand.unsqueeze", "antecedent_distance_embeddings.expand.expand.expand", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "allennlp.nn.util.bucket_values", "antecedent_embeddings.size", "antecedent_embeddings.size", "antecedent_embeddings.size", "antecedent_distance_embeddings.expand.expand.size", "top_span_embeddings.unsqueeze"], "methods", ["None"], ["", "def", "_compute_span_pair_embeddings", "(", "self", ",", "\n", "top_span_embeddings", ":", "torch", ".", "FloatTensor", ",", "\n", "antecedent_embeddings", ":", "torch", ".", "FloatTensor", ",", "\n", "antecedent_offsets", ":", "torch", ".", "FloatTensor", ")", ":", "\n", "        ", "\"\"\"\n        Computes an embedding representation of pairs of spans for the pairwise scoring function\n        to consider. This includes both the original span representations, the element-wise\n        similarity of the span representations, and an embedding representation of the distance\n        between the two spans.\n\n        Parameters\n        ----------\n        top_span_embeddings : ``torch.FloatTensor``, required.\n            Embedding representations of the top spans. Has shape\n            (batch_size, num_spans_to_keep, embedding_size).\n        antecedent_embeddings : ``torch.FloatTensor``, required.\n            Embedding representations of the antecedent spans we are considering\n            for each top span. Has shape\n            (batch_size, num_spans_to_keep, max_antecedents, embedding_size).\n        antecedent_offsets : ``torch.IntTensor``, required.\n            The offsets between each top span and its antecedent spans in terms\n            of spans we are considering. Has shape (1, max_antecedents).\n\n        Returns\n        -------\n        span_pair_embeddings : ``torch.FloatTensor``\n            Embedding representation of the pair of spans to consider. Has shape\n            (batch_size, num_spans_to_keep, max_antecedents, embedding_size)\n        \"\"\"", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents, embedding_size)", "\n", "target_embeddings", "=", "top_span_embeddings", ".", "unsqueeze", "(", "2", ")", ".", "expand_as", "(", "antecedent_embeddings", ")", "\n", "\n", "# Shape: (1, max_antecedents, embedding_size)", "\n", "antecedent_distance_embeddings", "=", "self", ".", "_distance_embedding", "(", "\n", "util", ".", "bucket_values", "(", "antecedent_offsets", ",", "\n", "num_total_buckets", "=", "self", ".", "_num_distance_buckets", ")", ")", "\n", "\n", "# Shape: (1, 1, max_antecedents, embedding_size)", "\n", "antecedent_distance_embeddings", "=", "antecedent_distance_embeddings", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "expanded_distance_embeddings_shape", "=", "(", "antecedent_embeddings", ".", "size", "(", "0", ")", ",", "\n", "antecedent_embeddings", ".", "size", "(", "1", ")", ",", "\n", "antecedent_embeddings", ".", "size", "(", "2", ")", ",", "\n", "antecedent_distance_embeddings", ".", "size", "(", "-", "1", ")", ")", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents, embedding_size)", "\n", "antecedent_distance_embeddings", "=", "antecedent_distance_embeddings", ".", "expand", "(", "*", "expanded_distance_embeddings_shape", ")", "\n", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents, embedding_size)", "\n", "span_pair_embeddings", "=", "torch", ".", "cat", "(", "[", "target_embeddings", ",", "\n", "antecedent_embeddings", ",", "\n", "antecedent_embeddings", "*", "target_embeddings", ",", "\n", "antecedent_distance_embeddings", "]", ",", "-", "1", ")", "\n", "return", "span_pair_embeddings", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_antecedent_gold_labels": [[582, 621], ["top_coref_labels.expand_as", "torch.cat", "torch.cat", "torch.cat", "torch.cat"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_compute_antecedent_gold_labels", "(", "top_coref_labels", ":", "torch", ".", "IntTensor", ",", "\n", "antecedent_labels", ":", "torch", ".", "IntTensor", ")", ":", "\n", "        ", "\"\"\"\n        Generates a binary indicator for every pair of spans. This label is one if and\n        only if the pair of spans belong to the same cluster. The labels are augmented\n        with a dummy antecedent at the zeroth position, which represents the prediction\n        that a span does not have any antecedent.\n\n        Parameters\n        ----------\n        top_coref_labels : ``torch.IntTensor``, required.\n            The cluster id label for every span. The id is arbitrary,\n            as we just care about the clustering. Has shape (batch_size, num_spans_to_keep).\n        antecedent_labels : ``torch.IntTensor``, required.\n            The cluster id label for every antecedent span. The id is arbitrary,\n            as we just care about the clustering. Has shape\n            (batch_size, num_spans_to_keep, max_antecedents).\n\n        Returns\n        -------\n        pairwise_labels_with_dummy_label : ``torch.FloatTensor``\n            A binary tensor representing whether a given pair of spans belong to\n            the same cluster in the gold clustering.\n            Has shape (batch_size, num_spans_to_keep, max_antecedents + 1).\n\n        \"\"\"", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents)", "\n", "target_labels", "=", "top_coref_labels", ".", "expand_as", "(", "antecedent_labels", ")", "\n", "same_cluster_indicator", "=", "(", "target_labels", "==", "antecedent_labels", ")", ".", "float", "(", ")", "\n", "non_dummy_indicator", "=", "(", "target_labels", ">=", "0", ")", ".", "float", "(", ")", "\n", "pairwise_labels", "=", "same_cluster_indicator", "*", "non_dummy_indicator", "\n", "\n", "# Shape: (batch_size, num_spans_to_keep, 1)", "\n", "dummy_labels", "=", "(", "1", "-", "pairwise_labels", ")", ".", "prod", "(", "-", "1", ",", "keepdim", "=", "True", ")", "\n", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents + 1)", "\n", "pairwise_labels_with_dummy_label", "=", "torch", ".", "cat", "(", "[", "dummy_labels", ",", "pairwise_labels", "]", ",", "-", "1", ")", "\n", "return", "pairwise_labels_with_dummy_label", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_coreference_scores": [[622, 670], ["coref.CorefResolver._antecedent_scorer().squeeze", "coref.CorefResolver.new_zeros", "torch.cat", "torch.cat", "torch.cat", "torch.cat", "coref.CorefResolver.size", "coref.CorefResolver.size", "coref.CorefResolver._antecedent_scorer", "coref.CorefResolver._antecedent_feedforward"], "methods", ["None"], ["", "def", "_compute_coreference_scores", "(", "self", ",", "\n", "pairwise_embeddings", ":", "torch", ".", "FloatTensor", ",", "\n", "top_span_mention_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "antecedent_mention_scores", ":", "torch", ".", "FloatTensor", ",", "\n", "antecedent_log_mask", ":", "torch", ".", "FloatTensor", ")", "->", "torch", ".", "FloatTensor", ":", "\n", "        ", "\"\"\"\n        Computes scores for every pair of spans. Additionally, a dummy label is included,\n        representing the decision that the span is not coreferent with anything. For the dummy\n        label, the score is always zero. For the true antecedent spans, the score consists of\n        the pairwise antecedent score and the unary mention scores for the span and its\n        antecedent. The factoring allows the model to blame many of the absent links on bad\n        spans, enabling the pruning strategy used in the forward pass.\n\n        Parameters\n        ----------\n        pairwise_embeddings: ``torch.FloatTensor``, required.\n            Embedding representations of pairs of spans. Has shape\n            (batch_size, num_spans_to_keep, max_antecedents, encoding_dim)\n        top_span_mention_scores: ``torch.FloatTensor``, required.\n            Mention scores for every span. Has shape\n            (batch_size, num_spans_to_keep, max_antecedents).\n        antecedent_mention_scores: ``torch.FloatTensor``, required.\n            Mention scores for every antecedent. Has shape\n            (batch_size, num_spans_to_keep, max_antecedents).\n        antecedent_log_mask: ``torch.FloatTensor``, required.\n            The log of the mask for valid antecedents.\n\n        Returns\n        -------\n        coreference_scores: ``torch.FloatTensor``\n            A tensor of shape (batch_size, num_spans_to_keep, max_antecedents + 1),\n            representing the unormalised score for each (span, antecedent) pair\n            we considered.\n\n        \"\"\"", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents)", "\n", "antecedent_scores", "=", "self", ".", "_antecedent_scorer", "(", "\n", "self", ".", "_antecedent_feedforward", "(", "pairwise_embeddings", ")", ")", ".", "squeeze", "(", "-", "1", ")", "\n", "antecedent_scores", "+=", "top_span_mention_scores", "+", "antecedent_mention_scores", "\n", "antecedent_scores", "+=", "antecedent_log_mask", "\n", "\n", "# Shape: (batch_size, num_spans_to_keep, 1)", "\n", "shape", "=", "[", "antecedent_scores", ".", "size", "(", "0", ")", ",", "antecedent_scores", ".", "size", "(", "1", ")", ",", "1", "]", "\n", "dummy_scores", "=", "antecedent_scores", ".", "new_zeros", "(", "*", "shape", ")", "\n", "\n", "# Shape: (batch_size, num_spans_to_keep, max_antecedents + 1)", "\n", "coreference_scores", "=", "torch", ".", "cat", "(", "[", "dummy_scores", ",", "antecedent_scores", "]", ",", "-", "1", ")", "\n", "return", "coreference_scores", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._flatten_spans": [[671, 690], ["dygie.models.shared.cumsum_shifted().unsqueeze().unsqueeze", "spans_offset.view", "spans_flat[].unsqueeze", "span_embeddings_batched.view", "emb_flat[].unsqueeze", "dygie.models.shared.cumsum_shifted().unsqueeze", "dygie.models.shared.cumsum_shifted"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.shared.cumsum_shifted"], ["", "def", "_flatten_spans", "(", "self", ",", "spans_batched", ",", "span_ix", ",", "span_embeddings_batched", ",", "sentence_lengths", ")", ":", "\n", "        ", "\"\"\"\n        Spans are input with each minibatch as a sentence. For coref, it's easier to flatten them out\n        and consider all sentences together as a document.\n        \"\"\"", "\n", "# Get feature size and indices of good spans", "\n", "feature_size", "=", "self", ".", "_mention_pruner", ".", "_scorer", "[", "0", "]", ".", "_module", ".", "input_dim", "\n", "\n", "# Change the span offsets to document-level, flatten, and keep good ones.", "\n", "sentence_offset", "=", "shared", ".", "cumsum_shifted", "(", "sentence_lengths", ")", ".", "unsqueeze", "(", "1", ")", ".", "unsqueeze", "(", "2", ")", "\n", "spans_offset", "=", "spans_batched", "+", "sentence_offset", "\n", "spans_flat", "=", "spans_offset", ".", "view", "(", "-", "1", ",", "2", ")", "\n", "spans_flat", "=", "spans_flat", "[", "span_ix", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "# Flatten the span embeddings and keep the good ones.", "\n", "emb_flat", "=", "span_embeddings_batched", ".", "view", "(", "-", "1", ",", "feature_size", ")", "\n", "span_embeddings_flat", "=", "emb_flat", "[", "span_ix", "]", ".", "unsqueeze", "(", "0", ")", "\n", "\n", "return", "spans_flat", ",", "span_embeddings_flat", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._flatten_coref_labels": [[691, 701], ["labels_flat.unsqueeze.unsqueeze.unsqueeze", "coref_labels_batched.view"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_flatten_coref_labels", "(", "coref_labels_batched", ",", "span_ix", ")", ":", "\n", "        ", "\"Flatten the coref labels.\"", "\n", "# If we don't have labels, return None.", "\n", "if", "coref_labels_batched", "is", "None", ":", "\n", "            ", "return", "coref_labels_batched", "\n", "\n", "", "labels_flat", "=", "coref_labels_batched", ".", "view", "(", "-", "1", ")", "[", "span_ix", "]", "\n", "labels_flat", "=", "labels_flat", ".", "unsqueeze", "(", "0", ")", "\n", "return", "labels_flat", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._make_evaluation_metadata": [[702, 727], ["dygie.models.shared.cumsum_shifted().tolist", "zip", "entry.cluster_dict.items", "dict", "dygie.models.shared.cumsum_shifted", "cluster_dict.values", "cluster_dict[].append"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.shared.cumsum_shifted"], ["", "@", "staticmethod", "\n", "def", "_make_evaluation_metadata", "(", "metadata", ",", "sentence_lengths", ")", ":", "\n", "        ", "\"\"\"\n        Get cluster metadata in form to feed into evaluation scripts. For each entry in minibatch,\n        return a dict with a metadata field, which is a list whose entries are lists specifying the\n        spans involved in a given cluster.\n        For coreference evaluation, we need to make the span indices with respect to the entire\n        \"document\" (i.e. all sentences in minibatch), rather than with respect to each sentence.\n        \"\"\"", "\n", "# TODO(dwadden) Write tests to make sure sentence starts match lengths of sentences in", "\n", "# metadata.", "\n", "# As elsewhere, we assume the batch size will always be 1.", "\n", "cluster_dict", "=", "{", "}", "\n", "sentence_offset", "=", "shared", ".", "cumsum_shifted", "(", "sentence_lengths", ")", ".", "tolist", "(", ")", "\n", "for", "entry", ",", "sentence_start", "in", "zip", "(", "metadata", ",", "sentence_offset", ")", ":", "\n", "            ", "for", "span", ",", "cluster_id", "in", "entry", ".", "cluster_dict", ".", "items", "(", ")", ":", "\n", "                ", "span_offset", "=", "(", "span", "[", "0", "]", "+", "sentence_start", ",", "span", "[", "1", "]", "+", "sentence_start", ")", "\n", "if", "cluster_id", "in", "cluster_dict", ":", "\n", "                    ", "cluster_dict", "[", "cluster_id", "]", ".", "append", "(", "span_offset", ")", "\n", "", "else", ":", "\n", "                    ", "cluster_dict", "[", "cluster_id", "]", "=", "[", "span_offset", "]", "\n", "\n", "# The `values` method returns an iterator, and I need a list.", "\n", "", "", "", "clusters", "=", "[", "val", "for", "val", "in", "cluster_dict", ".", "values", "(", ")", "]", "\n", "return", "[", "dict", "(", "clusters", "=", "clusters", ")", "]", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.entity_beam_pruner.Pruner.__init__": [[45, 54], ["super().__init__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["def", "__init__", "(", "self", ",", "scorer", ":", "torch", ".", "nn", ".", "Module", ",", "entity_beam", ":", "bool", "=", "False", ",", "gold_beam", ":", "bool", "=", "False", ",", "\n", "min_score_to_keep", ":", "float", "=", "None", ")", "->", "None", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", ")", "\n", "# If gold beam is on, then entity beam must be off and min_score_to_keep must be None.", "\n", "assert", "not", "(", "gold_beam", "and", "(", "(", "min_score_to_keep", "is", "not", "None", ")", "or", "entity_beam", ")", ")", "\n", "self", ".", "_scorer", "=", "scorer", "\n", "self", ".", "_entity_beam", "=", "entity_beam", "\n", "self", ".", "_gold_beam", "=", "gold_beam", "\n", "self", ".", "_min_score_to_keep", "=", "min_score_to_keep", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.entity_beam_pruner.Pruner.forward": [[55, 193], ["isinstance", "mask.unsqueeze.unsqueeze.unsqueeze", "embeddings.size", "max", "allennlp.nn.util.replace_masked_values", "entity_beam_pruner.Pruner.topk", "allennlp.nn.util.get_mask_from_sequence_lengths", "top_indices_mask.bool.bool.bool", "torch.where.squeeze", "torch.where.max", "fill_value.unsqueeze.unsqueeze.unsqueeze", "torch.where", "torch.sort", "allennlp.nn.util.flatten_and_batch_shift_indices", "allennlp.nn.util.batched_index_select", "allennlp.nn.util.batched_index_select", "sequence_mask.squeeze().bool.squeeze().bool.squeeze().bool", "top_mask.long.long.long", "allennlp.nn.util.batched_index_select", "mask.unsqueeze.unsqueeze.size", "class_scores.max", "entity_beam_pruner.Pruner.unsqueeze", "torch.sum().squeeze", "torch.min", "torch.sum", "torch.sum.max().item", "ValueError", "mask.unsqueeze.unsqueeze.bool", "torch.ones", "torch.where", "entity_beam_pruner.Pruner.unsqueeze", "entity_beam_pruner.Pruner._scorer", "entity_beam_pruner.Pruner.size", "entity_beam_pruner.Pruner.dim", "sequence_mask.squeeze().bool.squeeze().bool.squeeze", "torch.zeros_like", "torch.sum", "torch.sum.max", "torch.ones_like", "entity_beam_pruner.Pruner.size"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "forward", "(", "self", ",", "# pylint: disable=arguments-differ", "\n", "embeddings", ":", "torch", ".", "FloatTensor", ",", "\n", "mask", ":", "torch", ".", "LongTensor", ",", "\n", "num_items_to_keep", ":", "Union", "[", "int", ",", "torch", ".", "LongTensor", "]", ",", "\n", "class_scores", ":", "torch", ".", "FloatTensor", "=", "None", ",", "\n", "gold_labels", ":", "torch", ".", "long", "=", "None", ")", "->", "Tuple", "[", "torch", ".", "FloatTensor", ",", "torch", ".", "LongTensor", ",", "\n", "torch", ".", "LongTensor", ",", "torch", ".", "FloatTensor", "]", ":", "\n", "        ", "\"\"\"\n        Extracts the top-k scoring items with respect to the scorer. We additionally return\n        the indices of the top-k in their original order, not ordered by score, so that downstream\n        components can rely on the original ordering (e.g., for knowing what spans are valid\n        antecedents in a coreference resolution model). May use the same k for all sentences in\n        minibatch, or different k for each.\n\n        Parameters\n        ----------\n        embeddings : ``torch.FloatTensor``, required.\n            A tensor of shape (batch_size, num_items, embedding_size), containing an embedding for\n            each item in the list that we want to prune.\n        mask : ``torch.LongTensor``, required.\n            A tensor of shape (batch_size, num_items), denoting unpadded elements of\n            ``embeddings``.\n        num_items_to_keep : ``Union[int, torch.LongTensor]``, required.\n            If a tensor of shape (batch_size), specifies the number of items to keep for each\n            individual sentence in minibatch.\n            If an int, keep the same number of items for all sentences.\n        class_scores:\n           Class scores to be used with entity beam.\n        candidate_labels: If in debugging mode, use gold labels to get beam.\n\n        Returns\n        -------\n        top_embeddings : ``torch.FloatTensor``\n            The representations of the top-k scoring items.\n            Has shape (batch_size, max_num_items_to_keep, embedding_size).\n        top_mask : ``torch.LongTensor``\n            The corresponding mask for ``top_embeddings``.\n            Has shape (batch_size, max_num_items_to_keep).\n        top_indices : ``torch.IntTensor``\n            The indices of the top-k scoring items into the original ``embeddings``\n            tensor. This is returned because it can be useful to retain pointers to\n            the original items, if each item is being scored by multiple distinct\n            scorers, for instance. Has shape (batch_size, max_num_items_to_keep).\n        top_item_scores : ``torch.FloatTensor``\n            The values of the top-k scoring items.\n            Has shape (batch_size, max_num_items_to_keep, 1).\n        num_items_kept\n        \"\"\"", "\n", "# If an int was given for number of items to keep, construct tensor by repeating the value.", "\n", "if", "isinstance", "(", "num_items_to_keep", ",", "int", ")", ":", "\n", "            ", "batch_size", "=", "mask", ".", "size", "(", "0", ")", "\n", "# Put the tensor on same device as the mask.", "\n", "num_items_to_keep", "=", "num_items_to_keep", "*", "torch", ".", "ones", "(", "[", "batch_size", "]", ",", "dtype", "=", "torch", ".", "long", ",", "\n", "device", "=", "mask", ".", "device", ")", "\n", "\n", "", "mask", "=", "mask", ".", "unsqueeze", "(", "-", "1", ")", "\n", "num_items", "=", "embeddings", ".", "size", "(", "1", ")", "\n", "\n", "# Shape: (batch_size, num_items, 1)", "\n", "# If entity beam is one, use the class scores. Else ignore them and use the scorer.", "\n", "if", "self", ".", "_entity_beam", ":", "\n", "            ", "scores", ",", "_", "=", "class_scores", ".", "max", "(", "dim", "=", "-", "1", ")", "\n", "scores", "=", "scores", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# If gold beam is one, give a score of 0 wherever the gold label is non-zero (indicating a", "\n", "# non-null label), otherwise give a large negative number.", "\n", "", "elif", "self", ".", "_gold_beam", ":", "\n", "            ", "scores", "=", "torch", ".", "where", "(", "gold_labels", ">", "0", ",", "\n", "torch", ".", "zeros_like", "(", "gold_labels", ",", "dtype", "=", "torch", ".", "float", ")", ",", "\n", "-", "1e20", "*", "torch", ".", "ones_like", "(", "gold_labels", ",", "dtype", "=", "torch", ".", "float", ")", ")", "\n", "scores", "=", "scores", ".", "unsqueeze", "(", "-", "1", ")", "\n", "", "else", ":", "\n", "            ", "scores", "=", "self", ".", "_scorer", "(", "embeddings", ")", "\n", "\n", "# If we're only keeping items that score above a given threshold, change the number of kept", "\n", "# items here.", "\n", "", "if", "self", ".", "_min_score_to_keep", "is", "not", "None", ":", "\n", "            ", "num_good_items", "=", "torch", ".", "sum", "(", "scores", ">", "self", ".", "_min_score_to_keep", ",", "dim", "=", "1", ")", ".", "squeeze", "(", ")", "\n", "num_items_to_keep", "=", "torch", ".", "min", "(", "num_items_to_keep", ",", "num_good_items", ")", "\n", "# If gold beam is on, keep the gold items.", "\n", "", "if", "self", ".", "_gold_beam", ":", "\n", "            ", "num_items_to_keep", "=", "torch", ".", "sum", "(", "gold_labels", ">", "0", ",", "dim", "=", "1", ")", "\n", "\n", "# Always keep at least one item to avoid edge case with empty matrix.", "\n", "", "max_items_to_keep", "=", "max", "(", "num_items_to_keep", ".", "max", "(", ")", ".", "item", "(", ")", ",", "1", ")", "\n", "\n", "if", "scores", ".", "size", "(", "-", "1", ")", "!=", "1", "or", "scores", ".", "dim", "(", ")", "!=", "3", ":", "\n", "            ", "raise", "ValueError", "(", "f\"The scorer passed to Pruner must produce a tensor of shape\"", "\n", "f\"(batch_size, num_items, 1), but found shape {scores.size()}\"", ")", "\n", "# Make sure that we don't select any masked items by setting their scores to be very", "\n", "# negative.  These are logits, typically, so -1e20 should be plenty negative.", "\n", "# NOTE(`mask` needs to be a byte tensor now.)", "\n", "", "scores", "=", "util", ".", "replace_masked_values", "(", "scores", ",", "mask", ".", "bool", "(", ")", ",", "-", "1e20", ")", "\n", "\n", "# Shape: (batch_size, max_num_items_to_keep, 1)", "\n", "_", ",", "top_indices", "=", "scores", ".", "topk", "(", "max_items_to_keep", ",", "1", ")", "\n", "\n", "# Mask based on number of items to keep for each sentence.", "\n", "# Shape: (batch_size, max_num_items_to_keep)", "\n", "top_indices_mask", "=", "util", ".", "get_mask_from_sequence_lengths", "(", "num_items_to_keep", ",", "max_items_to_keep", ")", "\n", "top_indices_mask", "=", "top_indices_mask", ".", "bool", "(", ")", "\n", "\n", "# Shape: (batch_size, max_num_items_to_keep)", "\n", "top_indices", "=", "top_indices", ".", "squeeze", "(", "-", "1", ")", "\n", "\n", "# Fill all masked indices with largest \"top\" index for that sentence, so that all masked", "\n", "# indices will be sorted to the end.", "\n", "# Shape: (batch_size, 1)", "\n", "fill_value", ",", "_", "=", "top_indices", ".", "max", "(", "dim", "=", "1", ")", "\n", "fill_value", "=", "fill_value", ".", "unsqueeze", "(", "-", "1", ")", "\n", "# Shape: (batch_size, max_num_items_to_keep)", "\n", "top_indices", "=", "torch", ".", "where", "(", "top_indices_mask", ",", "top_indices", ",", "fill_value", ")", "\n", "\n", "# Now we order the selected indices in increasing order with", "\n", "# respect to their indices (and hence, with respect to the", "\n", "# order they originally appeared in the ``embeddings`` tensor).", "\n", "top_indices", ",", "_", "=", "torch", ".", "sort", "(", "top_indices", ",", "1", ")", "\n", "\n", "# Shape: (batch_size * max_num_items_to_keep)", "\n", "# torch.index_select only accepts 1D indices, but here", "\n", "# we need to select items for each element in the batch.", "\n", "flat_top_indices", "=", "util", ".", "flatten_and_batch_shift_indices", "(", "top_indices", ",", "num_items", ")", "\n", "\n", "# Shape: (batch_size, max_num_items_to_keep, embedding_size)", "\n", "top_embeddings", "=", "util", ".", "batched_index_select", "(", "embeddings", ",", "top_indices", ",", "flat_top_indices", ")", "\n", "\n", "# Combine the masks on spans that are out-of-bounds, and the mask on spans that are outside", "\n", "# the top k for each sentence.", "\n", "# Shape: (batch_size, max_num_items_to_keep)", "\n", "sequence_mask", "=", "util", ".", "batched_index_select", "(", "mask", ",", "top_indices", ",", "flat_top_indices", ")", "\n", "sequence_mask", "=", "sequence_mask", ".", "squeeze", "(", "-", "1", ")", ".", "bool", "(", ")", "\n", "top_mask", "=", "top_indices_mask", "&", "sequence_mask", "\n", "top_mask", "=", "top_mask", ".", "long", "(", ")", "\n", "\n", "# Shape: (batch_size, max_num_items_to_keep, 1)", "\n", "top_scores", "=", "util", ".", "batched_index_select", "(", "scores", ",", "top_indices", ",", "flat_top_indices", ")", "\n", "\n", "return", "top_embeddings", ",", "top_mask", ",", "top_indices", ",", "top_scores", ",", "num_items_to_keep", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.entity_beam_pruner.make_pruner": [[14, 25], ["torch.nn.Sequential", "entity_beam_pruner.Pruner", "allennlp.modules.TimeDistributed", "allennlp.modules.TimeDistributed", "torch.nn.Linear", "scorer.get_output_dim"], "function", ["None"], ["def", "make_pruner", "(", "scorer", ",", "entity_beam", "=", "False", ",", "gold_beam", "=", "False", ")", ":", "\n", "    ", "\"\"\"\n    Create a pruner that either takes outputs of other scorers (i.e. entity beam), or uses its own\n    scorer (the `default_scorer`).\n    \"\"\"", "\n", "item_scorer", "=", "torch", ".", "nn", ".", "Sequential", "(", "\n", "TimeDistributed", "(", "scorer", ")", ",", "\n", "TimeDistributed", "(", "torch", ".", "nn", ".", "Linear", "(", "scorer", ".", "get_output_dim", "(", ")", ",", "1", ")", ")", ")", "\n", "min_score_to_keep", "=", "1e-10", "if", "entity_beam", "else", "None", "\n", "\n", "return", "Pruner", "(", "item_scorer", ",", "entity_beam", ",", "gold_beam", ",", "min_score_to_keep", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie_test.TestDyGIE.setUp": [[11, 17], ["super().setUp", "dygie_test.TestDyGIE.set_up_model"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.setUp"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "# TODO(dwadden) create smaller model for testing.", "\n", "        ", "super", "(", "TestDyGIE", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "config_file", "=", "\"tests/fixtures/dygie_test_full.jsonnet\"", "\n", "self", ".", "data_file", "=", "\"tests/fixtures/scierc_article.json\"", "\n", "self", ".", "set_up_model", "(", "self", ".", "config_file", ",", "self", ".", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.dygie_test.TestDyGIE.test_dygie_model_can_train_save_and_load": [[18, 20], ["dygie_test.TestDyGIE.ensure_model_can_train_save_and_load"], "methods", ["None"], ["", "def", "test_dygie_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref_test.TestCoref.setUp": [[15, 21], ["super().setUp", "coref_test.TestCoref.set_up_model"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.setUp"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "# TODO(dwadden) create smaller model for testing.", "\n", "        ", "super", "(", "TestCoref", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "config_file", "=", "\"tests/fixtures/dygie_test.jsonnet\"", "\n", "self", ".", "data_file", "=", "\"tests/fixtures/scierc_article.json\"", "\n", "self", ".", "set_up_model", "(", "self", ".", "config_file", ",", "self", ".", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref_test.TestCoref.get_raw_data": [[22, 28], ["open", "lines.append", "json.loads"], "methods", ["None"], ["", "def", "get_raw_data", "(", "self", ")", ":", "\n", "        ", "lines", "=", "[", "]", "\n", "with", "open", "(", "self", ".", "data_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "lines", ".", "append", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "", "", "return", "lines", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref_test.TestCoref.test_coref_make_evaluation_metadata": [[29, 55], ["coref_test.TestCoref.dataset.as_tensor_dict", "allennlp.nn.util.get_text_field_mask().float", "allennlp.nn.util.get_text_field_mask().float.sum().long", "coref_test.TestCoref.model._coref._make_evaluation_metadata", "sorted", "util.get_text_field_mask().float.sum().long.tolist", "allennlp.nn.util.get_text_field_mask", "allennlp.nn.util.get_text_field_mask().float.sum", "len", "list", "coref_test.TestCoref.get_raw_data"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._make_evaluation_metadata", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref_test.TestCoref.get_raw_data"], ["", "def", "test_coref_make_evaluation_metadata", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        To compute coreference evaluation metrics, the evaluator needs access to the list of\n        coreference clusters, given in the same form as the original input. I check to make sure\n        that the clusters I pass in are indeed equivalent to the original input.\n        \"\"\"", "\n", "# Pull together the relevant training data.", "\n", "data", "=", "self", ".", "dataset", ".", "as_tensor_dict", "(", ")", "\n", "metadata", "=", "data", "[", "\"metadata\"", "]", "\n", "text_mask", "=", "util", ".", "get_text_field_mask", "(", "data", "[", "\"text\"", "]", ")", ".", "float", "(", ")", "\n", "sentence_lengths", "=", "text_mask", ".", "sum", "(", "dim", "=", "1", ")", ".", "long", "(", ")", "\n", "# Make sure the sentence lengths from the text mask are the same as the number of tokens.", "\n", "assert", "sentence_lengths", ".", "tolist", "(", ")", "==", "[", "len", "(", "entry", "[", "\"sentence\"", "]", ")", "for", "entry", "in", "metadata", "]", "\n", "\n", "# Convert metadata back to form used for coref evaluation", "\n", "evaluation_metadata", "=", "self", ".", "model", ".", "_coref", ".", "_make_evaluation_metadata", "(", "metadata", ",", "sentence_lengths", ")", "\n", "clusters_metadata", "=", "evaluation_metadata", "[", "0", "]", "[", "\"clusters\"", "]", "\n", "# Convert from tuples to list to facilitate comparison.", "\n", "clusters_metadata", "=", "[", "[", "list", "(", "span", ")", "for", "span", "in", "cluster", "]", "for", "cluster", "in", "clusters_metadata", "]", "\n", "\n", "# Get the raw data, and sort to match the metadata.", "\n", "clusters_raw", "=", "self", ".", "get_raw_data", "(", ")", "[", "0", "]", "[", "\"clusters\"", "]", "\n", "clusters_raw", "=", "sorted", "(", "clusters_raw", ",", "key", "=", "lambda", "entry", ":", "entry", "[", "0", "]", "[", "0", "]", ")", "\n", "\n", "# Compare the raw data to the converted metadata I have.", "\n", "assert", "clusters_metadata", "==", "clusters_raw", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation_test.TestRelation.setUp": [[17, 22], ["super().setUp", "relation_test.TestRelation.set_up_model"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.setUp"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "super", "(", "TestRelation", ",", "self", ")", ".", "setUp", "(", ")", "\n", "self", ".", "config_file", "=", "\"tests/fixtures/dygie_test.jsonnet\"", "\n", "self", ".", "data_file", "=", "\"tests/fixtures/scierc_article.json\"", "\n", "self", ".", "set_up_model", "(", "self", ".", "config_file", ",", "self", ".", "data_file", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation_test.TestRelation.test_decode": [[23, 50], ["torch.tensor", "torch.tensor", "torch.tensor", "relation_test.TestRelation.model._relation.decode", "relation_test.TestRelation.model.vocab.get_token_from_index", "relation_test.TestRelation.test_decode.convert"], "methods", ["None"], ["", "def", "test_decode", "(", "self", ")", ":", "\n", "        ", "def", "convert", "(", "x", ")", ":", "\n", "            ", "return", "self", ".", "model", ".", "vocab", ".", "get_token_from_index", "(", "x", ",", "namespace", "=", "\"relation_labels\"", ")", "\n", "\n", "", "top_spans", "=", "torch", ".", "tensor", "(", "[", "[", "[", "0", ",", "2", "]", ",", "[", "1", ",", "3", "]", ",", "[", "1", ",", "3", "]", "]", ",", "\n", "[", "[", "1", ",", "6", "]", ",", "[", "2", ",", "4", "]", ",", "[", "3", ",", "8", "]", "]", ",", "\n", "[", "[", "0", ",", "1", "]", ",", "[", "0", ",", "1", "]", ",", "[", "0", ",", "1", "]", "]", "]", ")", "\n", "predicted_relations", "=", "torch", ".", "tensor", "(", "[", "[", "[", "-", "1", ",", "-", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "-", "1", ",", "-", "1", "]", ",", "\n", "[", "-", "1", ",", "0", ",", "-", "1", "]", "]", ",", "\n", "[", "[", "-", "1", ",", "-", "1", ",", "-", "1", "]", ",", "\n", "[", "1", ",", "-", "1", ",", "2", "]", ",", "\n", "[", "-", "1", ",", "-", "1", ",", "4", "]", "]", ",", "\n", "[", "[", "1", ",", "1", ",", "2", "]", ",", "\n", "[", "1", ",", "3", ",", "2", "]", ",", "\n", "[", "-", "1", ",", "2", ",", "1", "]", "]", "]", ")", "\n", "num_spans_to_keep", "=", "torch", ".", "tensor", "(", "[", "2", ",", "3", ",", "0", "]", ")", "\n", "predict_dict", "=", "{", "\"top_spans\"", ":", "top_spans", ",", "\n", "\"predicted_relations\"", ":", "predicted_relations", ",", "\n", "\"num_spans_to_keep\"", ":", "num_spans_to_keep", "}", "\n", "decoded", "=", "self", ".", "model", ".", "_relation", ".", "decode", "(", "predict_dict", ")", "\n", "expected", "=", "[", "{", "(", "(", "1", ",", "3", ")", ",", "(", "0", ",", "2", ")", ")", ":", "convert", "(", "1", ")", "}", ",", "\n", "{", "(", "(", "2", ",", "4", ")", ",", "(", "1", ",", "6", ")", ")", ":", "convert", "(", "1", ")", ",", "\n", "(", "(", "2", ",", "4", ")", ",", "(", "3", ",", "8", ")", ")", ":", "convert", "(", "2", ")", ",", "\n", "(", "(", "3", ",", "8", ")", ",", "(", "3", ",", "8", ")", ")", ":", "convert", "(", "4", ")", "}", ",", "\n", "{", "}", "]", "\n", "assert", "expected", "==", "decoded", "[", "\"decoded_relations_dict\"", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation_test.TestRelation.test_compute_span_pair_embeddings": [[51, 65], ["torch.randn", "relation_test.TestRelation.model._relation._compute_span_pair_embeddings", "torch.cat", "torch.allclose"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver._compute_span_pair_embeddings"], ["", "def", "test_compute_span_pair_embeddings", "(", "self", ")", ":", "\n", "        ", "top_span_embeddings", "=", "torch", ".", "randn", "(", "[", "3", ",", "51", ",", "1160", "]", ")", "# Make up random embeddings.", "\n", "\n", "embeddings", "=", "self", ".", "model", ".", "_relation", ".", "_compute_span_pair_embeddings", "(", "top_span_embeddings", ")", "\n", "\n", "batch_ix", "=", "1", "\n", "ix1", "=", "22", "\n", "ix2", "=", "43", "\n", "emb1", "=", "top_span_embeddings", "[", "batch_ix", ",", "ix1", "]", "\n", "emb2", "=", "top_span_embeddings", "[", "batch_ix", ",", "ix2", "]", "\n", "emb_prod", "=", "emb1", "*", "emb2", "\n", "emb", "=", "torch", ".", "cat", "(", "[", "emb1", ",", "emb2", ",", "emb_prod", "]", ")", "\n", "\n", "assert", "torch", ".", "allclose", "(", "emb", ",", "embeddings", "[", "batch_ix", ",", "ix1", ",", "ix2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation_test.TestRelation.test_compute_relation_scores": [[66, 84], ["relation_test.TestRelation.model.eval", "torch.randn", "torch.randn", "relation._compute_relation_scores", "relation._relation_scorer", "torch.cat", "torch.allclose", "relation._relation_feedforward", "pairwise_embeddings[].unsqueeze", "torch.tensor", "torch.cat.squeeze"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._compute_relation_scores"], ["", "def", "test_compute_relation_scores", "(", "self", ")", ":", "\n", "        ", "self", ".", "model", ".", "eval", "(", ")", "# Need eval on in order to reproduce.", "\n", "relation", "=", "self", ".", "model", ".", "_relation", "\n", "pairwise_embeddings", "=", "torch", ".", "randn", "(", "3", ",", "46", ",", "46", ",", "3480", ",", "requires_grad", "=", "True", ")", "\n", "top_span_mention_scores", "=", "torch", ".", "randn", "(", "3", ",", "46", ",", "1", ",", "requires_grad", "=", "True", ")", "\n", "\n", "scores", "=", "relation", ".", "_compute_relation_scores", "(", "pairwise_embeddings", ",", "top_span_mention_scores", ")", "\n", "\n", "batch_ix", "=", "0", "\n", "ix1", "=", "31", "\n", "ix2", "=", "4", "\n", "\n", "score", "=", "relation", ".", "_relation_scorer", "(", "\n", "relation", ".", "_relation_feedforward", "(", "pairwise_embeddings", "[", "batch_ix", ",", "ix1", ",", "ix2", "]", ".", "unsqueeze", "(", "0", ")", ")", ")", "\n", "score", "+=", "top_span_mention_scores", "[", "batch_ix", ",", "ix1", "]", "+", "top_span_mention_scores", "[", "batch_ix", ",", "ix2", "]", "\n", "score", "=", "torch", ".", "cat", "(", "[", "torch", ".", "tensor", "(", "[", "0.0", "]", ")", ",", "score", ".", "squeeze", "(", ")", "]", ")", "\n", "\n", "assert", "torch", ".", "allclose", "(", "scores", "[", "batch_ix", ",", "ix1", ",", "ix2", "]", ",", "score", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation_test.TestRelation.test_get_pruned_gold_relations": [[85, 112], ["torch.tensor", "torch.tensor", "torch.tensor().unsqueeze", "relation_test.TestRelation.model._relation._get_pruned_gold_relations", "torch.tensor", "torch.equal", "torch.tensor"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._get_pruned_gold_relations"], ["", "def", "test_get_pruned_gold_relations", "(", "self", ")", ":", "\n", "# Getting the pruned gold labels should add one to the input relation labels, then set all", "\n", "# the masked entries to -1.", "\n", "        ", "relation_labels", "=", "torch", ".", "tensor", "(", "[", "[", "[", "-", "1", ",", "-", "1", ",", "2", ",", "3", "]", ",", "\n", "[", "1", ",", "-", "1", ",", "-", "1", ",", "0", "]", ",", "\n", "[", "-", "1", ",", "3", ",", "-", "1", ",", "1", "]", ",", "\n", "[", "0", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", "]", ",", "\n", "[", "[", "0", ",", "2", ",", "1", ",", "2", "]", ",", "\n", "[", "-", "1", ",", "-", "1", ",", "-", "1", ",", "-", "1", "]", ",", "\n", "[", "3", ",", "0", ",", "-", "1", ",", "-", "1", "]", ",", "\n", "[", "-", "1", ",", "0", ",", "1", ",", "-", "1", "]", "]", "]", ")", "\n", "top_span_indices", "=", "torch", ".", "tensor", "(", "[", "[", "0", ",", "1", ",", "3", "]", ",", "\n", "[", "0", ",", "2", ",", "2", "]", "]", ")", "\n", "top_span_masks", "=", "torch", ".", "tensor", "(", "[", "[", "1", ",", "1", ",", "1", "]", ",", "\n", "[", "1", ",", "1", ",", "0", "]", "]", ")", ".", "unsqueeze", "(", "-", "1", ")", "\n", "\n", "labels", "=", "self", ".", "model", ".", "_relation", ".", "_get_pruned_gold_relations", "(", "\n", "relation_labels", ",", "top_span_indices", ",", "top_span_masks", ")", "\n", "\n", "expected_labels", "=", "torch", ".", "tensor", "(", "[", "[", "[", "0", ",", "0", ",", "4", "]", ",", "\n", "[", "2", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", "]", "]", ",", "\n", "[", "[", "1", ",", "2", ",", "-", "1", "]", ",", "\n", "[", "4", ",", "0", ",", "-", "1", "]", ",", "\n", "[", "-", "1", ",", "-", "1", ",", "-", "1", "]", "]", "]", ")", "\n", "\n", "assert", "torch", ".", "equal", "(", "labels", ",", "expected_labels", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation_test.TestRelation.test_cross_entropy_ignore_index": [[113, 137], ["torch.randn", "torch.tensor", "torch.tensor", "relation_test.TestRelation.model._relation._get_cross_entropy_loss", "torch.allclose", "range", "range", "relation_scores[].unsqueeze", "gold_relations[].unsqueeze", "relation_test.TestRelation.model._relation._loss"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.relation.RelationExtractor._get_cross_entropy_loss"], ["", "def", "test_cross_entropy_ignore_index", "(", "self", ")", ":", "\n", "# Make sure that the cross entropy loss is ignoring entries whose gold label is -1, which", "\n", "# corresponds, to masked-out entries.", "\n", "        ", "relation_scores", "=", "torch", ".", "randn", "(", "2", ",", "3", ",", "3", ",", "self", ".", "model", ".", "_relation", ".", "_n_labels", "+", "1", ")", "\n", "gold_relations", "=", "torch", ".", "tensor", "(", "[", "[", "[", "0", ",", "0", ",", "4", "]", ",", "\n", "[", "2", ",", "0", ",", "1", "]", ",", "\n", "[", "1", ",", "0", ",", "0", "]", "]", ",", "\n", "[", "[", "1", ",", "2", ",", "-", "1", "]", ",", "\n", "[", "4", ",", "0", ",", "-", "1", "]", ",", "\n", "[", "-", "1", ",", "-", "1", ",", "-", "1", "]", "]", "]", ")", "\n", "\n", "# Calculate the loss with a loop over entries.", "\n", "total_loss", "=", "torch", ".", "tensor", "(", "[", "0.0", "]", ")", "\n", "for", "fold", "in", "[", "0", ",", "1", "]", ":", "\n", "            ", "for", "i", "in", "range", "(", "3", ")", ":", "\n", "                ", "for", "j", "in", "range", "(", "3", ")", ":", "\n", "                    ", "scores_entry", "=", "relation_scores", "[", "fold", ",", "i", ",", "j", "]", ".", "unsqueeze", "(", "0", ")", "\n", "gold_entry", "=", "gold_relations", "[", "fold", ",", "i", ",", "j", "]", ".", "unsqueeze", "(", "0", ")", "\n", "if", "gold_entry", ">=", "0", ":", "\n", "                        ", "loss_entry", "=", "self", ".", "model", ".", "_relation", ".", "_loss", "(", "scores_entry", ",", "gold_entry", ")", "\n", "total_loss", "+=", "loss_entry", "\n", "\n", "", "", "", "", "model_loss", "=", "self", ".", "model", ".", "_relation", ".", "_get_cross_entropy_loss", "(", "relation_scores", ",", "gold_relations", ")", "\n", "assert", "torch", ".", "allclose", "(", "total_loss", ",", "model_loss", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.spacy_interface.spacy_interface.DygieppPipe.__init__": [[112, 135], ["allennlp.models.archival.load_archive", "spacy_interface.DygieppPipe._model.eval", "allennlp.models.archival.load_archive.config[].pop", "dygie.data.dataset_readers.dygie.DyGIEReader.from_params"], "methods", ["None"], ["def", "__init__", "(", "\n", "self", ",", "\n", "nlp", ":", "Language", ",", "\n", "pretrained_filepath", ":", "str", "=", "\"./pretrained/scierc-lightweight.tar.gz\"", ",", "\n", "dataset_name", ":", "str", "=", "\"scierc\"", ",", "\n", ")", "->", "None", ":", "\n", "        ", "\"\"\"spacy factory class for adding information to spacy document. For now just entities and relations.\n        It adds entities to doc.ents and relations to doc._.rels: List[List[Token,Token,str]] which is a list of relations\n        as  entity1, entity2, relation name\n\n        Args:\n            nlp (Language): Spacy Language instance\n            name (str, optional): Pipe name. Defaults to \"dygiepp\".\n            pretrained_filepath (str, optional): Address of pre-trained model to extract information. Defaults to \"./pretrained/scierc-lightweight.tar.gz\".\n            dataset_name (str, optional): Dataset name used for model. Defaults to \"scierc\".\n        \"\"\"", "\n", "# TODO add events and cluster information to spacy doc too", "\n", "archive", "=", "load_archive", "(", "pretrained_filepath", ")", "\n", "self", ".", "_model", "=", "archive", ".", "model", "\n", "self", ".", "_model", ".", "eval", "(", ")", "\n", "archive", ".", "config", "[", "\"dataset_reader\"", "]", ".", "pop", "(", "\"type\"", ")", "# it's stupid but was necessary!", "\n", "self", ".", "_dataset_reader", "=", "DyGIEReader", ".", "from_params", "(", "archive", ".", "config", "[", "\"dataset_reader\"", "]", ")", "\n", "self", ".", "dataset_name", "=", "dataset_name", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.spacy_interface.spacy_interface.DygieppPipe.__call__": [[136, 150], ["spacy_interface.DygieppPipe._model._get_prediction_device", "spacy_interface.DygieppPipe._dataset_reader.text_to_instance", "allennlp.data.Batch", "allennlp.data.Batch.index_instances", "allennlp.nn.util.move_to_device", "spacy_interface.DygieppPipe._model.make_output_human_readable().to_json", "spacy_interface.prepare_spacy_doc", "allennlp.data.Batch.as_tensor_dict", "spacy_interface.DygieppPipe._model.make_output_human_readable", "spacy_interface.DygieppPipe._model"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader.text_to_instance", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.spacy_interface.spacy_interface.prepare_spacy_doc", "home.repos.pwc.inspect_result.dwadden_dygiepp.models.coref.CorefResolver.make_output_human_readable"], ["", "def", "__call__", "(", "self", ",", "doc", ":", "Doc", ")", "->", "Doc", ":", "\n", "        ", "cuda_device", "=", "self", ".", "_model", ".", "_get_prediction_device", "(", ")", "\n", "sentences", "=", "[", "[", "tok", ".", "text", "for", "tok", "in", "sent", "]", "for", "sent", "in", "doc", ".", "sents", "]", "\n", "ins", "=", "self", ".", "_dataset_reader", ".", "text_to_instance", "(", "\n", "{", "\"sentences\"", ":", "sentences", ",", "\"doc_key\"", ":", "\"test\"", ",", "\"dataset\"", ":", "self", ".", "dataset_name", "}", "\n", ")", "\n", "dataset", "=", "Batch", "(", "[", "ins", "]", ")", "\n", "dataset", ".", "index_instances", "(", "self", ".", "_model", ".", "vocab", ")", "\n", "model_input", "=", "util", ".", "move_to_device", "(", "dataset", ".", "as_tensor_dict", "(", ")", ",", "cuda_device", ")", "\n", "prediction", "=", "self", ".", "_model", ".", "make_output_human_readable", "(", "\n", "self", ".", "_model", "(", "**", "model_input", ")", "\n", ")", ".", "to_json", "(", ")", "\n", "# prepare and store ent/relation information to spacy Doc", "\n", "return", "prepare_spacy_doc", "(", "doc", ",", "prediction", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.spacy_interface.spacy_interface.prepare_spacy_doc": [[20, 107], ["zip", "zip", "enumerate", "prediction.get", "doc_evs.append", "prediction.get", "doc_rels.append", "span_ents.append", "enumerate", "dist_ents.append", "sent_rels.append", "prediction.get", "ent_sent.append", "len", "res.append", "doc.char_span", "len", "t.append", "prc.append", "len", "res.append", "sel_ents.append", "print", "sent_evs.append", "min"], "function", ["None"], ["def", "prepare_spacy_doc", "(", "doc", ":", "Doc", ",", "prediction", ":", "Dict", ")", "->", "Doc", ":", "\n", "    ", "doc_rels", "=", "[", "]", "\n", "doc_evs", "=", "[", "]", "\n", "# store events as relations. include confidence scores in the relation tuple (TODO: add relation property)", "\n", "for", "evs", ",", "ds", "in", "zip", "(", "prediction", ".", "get", "(", "\"predicted_events\"", ",", "[", "]", ")", ",", "doc", ".", "sents", ")", ":", "\n", "        ", "sent_evs", "=", "[", "]", "\n", "for", "ev", "in", "evs", ":", "\n", "            ", "if", "len", "(", "ev", ")", ">=", "3", ":", "\n", "                ", "trig", "=", "[", "r", "for", "r", "in", "ev", "if", "r", "[", "1", "]", "==", "\"TRIGGER\"", "]", "\n", "arg0s", "=", "[", "r", "for", "r", "in", "ev", "if", "r", "[", "2", "]", "==", "\"ARG0\"", "]", "\n", "#example arg0s: [[40, 43, 'ARG0', 12.1145, 1.0], [45, 45, 'ARG0', 11.3498, 1.0]]", "\n", "arg1s", "=", "[", "r", "for", "r", "in", "ev", "if", "r", "[", "2", "]", "==", "\"ARG1\"", "]", "\n", "e_trig", "=", "doc", "[", "trig", "[", "0", "]", "[", "0", "]", ":", "trig", "[", "0", "]", "[", "0", "]", "+", "1", "]", "\n", "for", "arg0", "in", "arg0s", ":", "\n", "                    ", "e_arg0", "=", "doc", "[", "arg0", "[", "0", "]", ":", "arg0", "[", "1", "]", "+", "1", "]", "\n", "for", "arg1", "in", "arg1s", ":", "\n", "                        ", "e_arg1", "=", "doc", "[", "arg1", "[", "0", "]", ":", "arg1", "[", "1", "]", "+", "1", "]", "\n", "#here confidence is set as the minimum among {trigger,args}, as a conservative measure.", "\n", "sent_evs", ".", "append", "(", "{", "\"ARG0\"", ":", "e_arg0", ",", "\"ARG1\"", ":", "e_arg1", ",", "\"RELATION_TRIGGER\"", ":", "e_trig", ",", "\"CONF\"", ":", "min", "(", "[", "arg0", "[", "4", "]", ",", "arg1", "[", "4", "]", ",", "trig", "[", "0", "]", "[", "3", "]", "]", ")", "}", ")", "\n", "\n", "", "", "", "", "doc_evs", ".", "append", "(", "sent_evs", ")", "\n", "ds", ".", "_", ".", "events", "=", "sent_evs", "\n", "", "doc", ".", "_", ".", "events", "=", "doc_evs", "\n", "#TODO add doc._.span_ents too. ", "\n", "\n", "for", "rels", ",", "ds", "in", "zip", "(", "prediction", ".", "get", "(", "\"predicted_relations\"", ",", "[", "]", ")", ",", "doc", ".", "sents", ")", ":", "\n", "        ", "sent_rels", "=", "[", "]", "\n", "for", "rel", "in", "rels", ":", "\n", "            ", "e1", "=", "doc", "[", "rel", "[", "0", "]", ":", "rel", "[", "1", "]", "+", "1", "]", "\n", "e2", "=", "doc", "[", "rel", "[", "2", "]", ":", "rel", "[", "3", "]", "+", "1", "]", "\n", "tag", "=", "rel", "[", "4", "]", "\n", "sent_rels", ".", "append", "(", "(", "e1", ",", "e2", ",", "tag", ")", ")", "\n", "", "doc_rels", ".", "append", "(", "sent_rels", ")", "\n", "ds", ".", "_", ".", "rels", "=", "sent_rels", "\n", "", "doc", ".", "_", ".", "rels", "=", "doc_rels", "\n", "if", "\"predicted_ner\"", "not", "in", "prediction", ":", "\n", "        ", "return", "doc", "\n", "", "preds", "=", "[", "p", "for", "r", "in", "prediction", ".", "get", "(", "\"predicted_ner\"", ",", "[", "]", ")", "for", "p", "in", "r", "]", "\n", "# storing all span based entitis to doc._.span_ents", "\n", "span_ents", "=", "[", "]", "\n", "for", "sent", "in", "prediction", "[", "\"predicted_ner\"", "]", ":", "\n", "        ", "ent_sent", "=", "[", "]", "\n", "for", "ent", "in", "sent", ":", "\n", "            ", "d", "=", "doc", "[", "ent", "[", "0", "]", ":", "ent", "[", "1", "]", "+", "1", "]", "\n", "d", ".", "_", ".", "label_", "=", "ent", "[", "2", "]", "\n", "ent_sent", ".", "append", "(", "d", ")", "\n", "", "span_ents", ".", "append", "(", "ent_sent", ")", "\n", "", "doc", ".", "_", ".", "span_ents", "=", "span_ents", "\n", "# store entities to doc.ents of spacy", "\n", "# because spacy can't support the overlapped entities we have to merge overlapped entities", "\n", "# to the longest ones.", "\n", "dist_ents", "=", "[", "]", "\n", "prc", "=", "[", "]", "\n", "for", "i", ",", "p1", "in", "enumerate", "(", "preds", ")", ":", "\n", "        ", "t", "=", "[", "p1", "]", "\n", "if", "i", "in", "prc", ":", "\n", "            ", "continue", "\n", "", "for", "j", ",", "p2", "in", "enumerate", "(", "preds", "[", "i", "+", "1", ":", "]", ")", ":", "\n", "            ", "if", "p2", "[", "0", "]", "<=", "p1", "[", "1", "]", ":", "\n", "                ", "t", ".", "append", "(", "p1", ")", "\n", "prc", ".", "append", "(", "j", "+", "i", "+", "1", ")", "\n", "", "", "dist_ents", ".", "append", "(", "t", ")", "\n", "", "res", "=", "[", "]", "\n", "for", "t", "in", "dist_ents", ":", "\n", "        ", "if", "len", "(", "t", ")", "==", "1", ":", "\n", "            ", "res", ".", "append", "(", "t", "[", "0", "]", ")", "\n", "", "elif", "len", "(", "t", ")", ">", "1", ":", "\n", "            ", "mn", "=", "t", "[", "0", "]", "[", "0", "]", "\n", "mx", "=", "t", "[", "0", "]", "[", "1", "]", "\n", "for", "p", "in", "t", "[", "1", ":", "]", ":", "\n", "                ", "if", "p", "[", "0", "]", "<", "mn", ":", "\n", "                    ", "mn", "=", "p", "[", "0", "]", "\n", "", "if", "p", "[", "1", "]", ">", "mx", ":", "\n", "                    ", "mx", "=", "p", "[", "1", "]", "\n", "", "", "res", ".", "append", "(", "[", "mn", ",", "mx", ",", "t", "[", "0", "]", "[", "2", "]", ",", "t", "[", "0", "]", "[", "3", "]", ",", "t", "[", "0", "]", "[", "4", "]", "]", ")", "\n", "", "", "sel_ents", "=", "[", "]", "\n", "for", "ent", "in", "res", ":", "\n", "        ", "try", ":", "\n", "            ", "d", "=", "doc", "[", "ent", "[", "0", "]", ":", "ent", "[", "1", "]", "+", "1", "]", "\n", "s", "=", "doc", ".", "char_span", "(", "d", ".", "start_char", ",", "d", ".", "end_char", ",", "label", "=", "ent", "[", "2", "]", ")", "\n", "if", "s", ":", "\n", "                ", "sel_ents", ".", "append", "(", "s", ")", "\n", "", "", "except", "Exception", "as", "e", ":", "\n", "            ", "print", "(", "\"error in spacy span\"", ",", "e", ")", "\n", "raise", "e", "\n", "", "", "doc", ".", "ents", "=", "sel_ents", "\n", "return", "doc", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.setUp": [[33, 38], ["os.makedirs", "os.makedirs"], "methods", ["None"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "collated_dir", "=", "\"tmp/collated\"", "\n", "self", ".", "uncollated_dir", "=", "\"tmp/uncollated\"", "\n", "os", ".", "makedirs", "(", "self", ".", "collated_dir", ",", "exist_ok", "=", "True", ")", "\n", "os", ".", "makedirs", "(", "self", ".", "uncollated_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.tearDown": [[39, 41], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "\"tmp\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.is_same": [[42, 56], ["sorted", "sorted", "x1.keys", "x2.keys"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_same", "(", "x1", ",", "x2", ")", ":", "\n", "        ", "\"Compare the fields in two dicts loaded from json.\"", "\n", "# Check if keys are same.", "\n", "if", "sorted", "(", "x1", ".", "keys", "(", ")", ")", "!=", "sorted", "(", "x2", ".", "keys", "(", ")", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "# Loop over all fields. If not same, return False.", "\n", "", "for", "key", "in", "x1", ":", "\n", "            ", "if", "x1", "[", "key", "]", "!=", "x2", "[", "key", "]", ":", "\n", "                ", "return", "False", "\n", "\n", "# If we get to the end, they're the same.", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.files_same": [[57, 81], ["collate_test.load_jsonl", "collate_test.load_jsonl", "zip", "len", "len", "collate_test.TestCollate.is_same"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.load_jsonl", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.load_jsonl", "home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.is_same"], ["", "def", "files_same", "(", "self", ",", "f1", ",", "f2", ")", ":", "\n", "        ", "\"Check that contests of two files are the same.\"", "\n", "data1", "=", "load_jsonl", "(", "f1", ")", "\n", "data2", "=", "load_jsonl", "(", "f2", ")", "\n", "\n", "# Ignore these in the comparison; `dataset` gets added, while `sentence_start` and", "\n", "# `clusters` get removed.", "\n", "fields_to_ignore", "=", "[", "\"dataset\"", ",", "\"sentence_start\"", ",", "\"clusters\"", "]", "\n", "for", "data", "in", "[", "data1", ",", "data2", "]", ":", "\n", "            ", "for", "entry", "in", "data", ":", "\n", "# Since the input data doesn't have a `dataset` field, we don't want to compare on", "\n", "# this.", "\n", "                ", "for", "field_to_ignore", "in", "fields_to_ignore", ":", "\n", "                    ", "if", "field_to_ignore", "in", "entry", ":", "\n", "                        ", "del", "entry", "[", "field_to_ignore", "]", "\n", "\n", "", "", "", "", "if", "len", "(", "data1", ")", "!=", "len", "(", "data2", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "", "for", "entry1", ",", "entry2", "in", "zip", "(", "data1", ",", "data2", ")", ":", "\n", "            ", "if", "not", "self", ".", "is_same", "(", "entry1", ",", "entry2", ")", ":", "\n", "                ", "return", "False", "\n", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.check_collate": [[82, 102], ["collate.get_args", "collate.CollateRunner", "uncollate.get_args", "uncollate.UnCollateRunner", "collate.CollateRunner.run", "uncollate.UnCollateRunner.run", "collate_test.TestCollate.files_same", "vars", "vars"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.run", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.run", "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.files_same"], ["", "def", "check_collate", "(", "self", ",", "dirname", ")", ":", "\n", "        ", "input_dir", "=", "f\"fixtures/collate/{dirname}\"", "\n", "\n", "# Make the collator.", "\n", "collator_args", "=", "collate", ".", "get_args", "(", "[", "input_dir", ",", "self", ".", "collated_dir", ",", "\"--file_extension=json\"", ",", "\n", "f\"--dataset={dirname}\"", "]", ")", "\n", "collator_runner", "=", "collate", ".", "CollateRunner", "(", "**", "vars", "(", "collator_args", ")", ")", "\n", "\n", "# Make the uncollator.", "\n", "uncollator_args", "=", "uncollate", ".", "get_args", "(", "\n", "[", "self", ".", "collated_dir", ",", "self", ".", "uncollated_dir", ",", "f\"--order_like_directory={input_dir}\"", ",", "\n", "\"--file_extension=json\"", "]", ")", "\n", "uncollator_runner", "=", "uncollate", ".", "UnCollateRunner", "(", "**", "vars", "(", "uncollator_args", ")", ")", "\n", "\n", "# Run both.", "\n", "collator_runner", ".", "run", "(", ")", "\n", "uncollator_runner", ".", "run", "(", ")", "\n", "\n", "for", "name", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", ":", "\n", "            ", "assert", "self", ".", "files_same", "(", "f\"{input_dir}/{name}.json\"", ",", "f\"{self.uncollated_dir}/{name}.json\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.test_collate": [[103, 107], ["collate_test.TestCollate.check_collate"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.TestCollate.check_collate"], ["", "", "def", "test_collate", "(", "self", ")", ":", "\n", "        ", "\"Make sure that our Document class can read and write data without changing it.\"", "\n", "for", "dirname", "in", "[", "\"ace-event\"", ",", "\"scierc\"", "]", ":", "\n", "            ", "self", ".", "check_collate", "(", "dirname", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.collate_test.load_jsonl": [[26, 29], ["open", "json.loads"], "function", ["None"], ["def", "load_jsonl", "(", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ")", "as", "f", ":", "\n", "        ", "return", "[", "json", ".", "loads", "(", "x", ")", "for", "x", "in", "f", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.dygie_test.TestDygieReader.setUp": [[14, 20], ["dygie.data.DyGIEReader", "dygie_test.TestDygieReader.reader.read"], "methods", ["None"], ["self", ".", "config_file", "=", "\"tests/fixtures/dygie_test_full.jsonnet\"", "\n", "self", ".", "data_file", "=", "\"tests/fixtures/scierc_article.json\"", "\n", "self", ".", "set_up_model", "(", "self", ".", "config_file", ",", "self", ".", "data_file", ")", "\n", "\n", "", "def", "test_dygie_model_can_train_save_and_load", "(", "self", ")", ":", "\n", "        ", "self", ".", "ensure_model_can_train_save_and_load", "(", "self", ".", "param_file", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.dygie_test.TestDygieReader.tearDown": [[21, 23], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.dygie_test.TestDygieReader.test_tokens_correct_scierc": [[24, 31], ["len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.dygie_test.TestDygieReader.test_ner_correct_scierc": [[32, 45], ["zip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.dygie_test.TestDygieReader.test_relation_correct_scierc": [[46, 63], ["len", "len"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.dygie_test.TestDygieReader.test_coref_correct_scierc": [[64, 88], ["zip", "zip"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.dygie_test.TestDygieReader.test_vocab_size_correct_scierc": [[89, 98], ["allennlp.data.vocabulary.Vocabulary.from_instances", "allennlp.data.vocabulary.Vocabulary.from_instances.get_vocab_size", "allennlp.data.vocabulary.Vocabulary.from_instances.get_vocab_size", "allennlp.data.vocabulary.Vocabulary.from_instances.get_vocab_size"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.setUp": [[14, 17], ["os.makedirs"], "methods", ["None"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "        ", "self", ".", "tmpdir", "=", "\"tmp\"", "\n", "os", ".", "makedirs", "(", "self", ".", "tmpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.tearDown": [[18, 20], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "tmpdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.is_same": [[21, 35], ["x1.keys", "x2.keys"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "is_same", "(", "x1", ",", "x2", ")", ":", "\n", "        ", "\"Compare the fields in two dicts loaded from json.\"", "\n", "# Check if keys are same.", "\n", "if", "x1", ".", "keys", "(", ")", "!=", "x2", ".", "keys", "(", ")", ":", "\n", "            ", "return", "False", "\n", "\n", "# Loop over all fields. If not same, return False.", "\n", "", "for", "key", "in", "x1", ":", "\n", "            ", "if", "x1", "[", "key", "]", "!=", "x2", "[", "key", "]", ":", "\n", "                ", "return", "False", "\n", "\n", "# If we get to the end, they're the same.", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.check_document": [[36, 52], ["dygie.data.Document.from_json", "dygie.data.Document.from_json.to_json", "document_test.TestDocument.is_same", "open", "json.load", "open", "json.dump", "open", "json.load"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.from_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.is_same"], ["", "def", "check_document", "(", "self", ",", "document_name", ")", ":", "\n", "# Load the original file.", "\n", "        ", "with", "open", "(", "f\"fixtures/{document_name}.json\"", ")", "as", "f", ":", "\n", "            ", "js", "=", "json", ".", "load", "(", "f", ")", "\n", "", "doc", "=", "Document", ".", "from_json", "(", "js", ")", "\n", "\n", "# Dump to file.", "\n", "tmpfile", "=", "f\"{self.tmpdir}/{document_name}.json\"", "\n", "dumped", "=", "doc", ".", "to_json", "(", ")", "\n", "with", "open", "(", "tmpfile", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "json", ".", "dump", "(", "dumped", ",", "f", ")", "\n", "\n", "# Reload and compare.", "\n", "", "with", "open", "(", "tmpfile", ")", "as", "f", ":", "\n", "            ", "reloaded", "=", "json", ".", "load", "(", "f", ")", "\n", "", "assert", "self", ".", "is_same", "(", "js", ",", "reloaded", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.test_document": [[53, 57], ["document_test.TestDocument.check_document"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.data.document_test.TestDocument.check_document"], ["", "def", "test_document", "(", "self", ")", ":", "\n", "        ", "\"Make sure that our Document class can read and write data without changing it.\"", "\n", "for", "document_name", "in", "[", "\"ace_event_article\"", ",", "\"scierc_article\"", ",", "\"ace_event_coref_article\"", "]", ":", "\n", "            ", "self", ".", "check_document", "(", "document_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.spacy_interface_test.TestSpacyInterface.setUp": [[7, 25], ["spacy.load", "spacy.load.", "super().setUp"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.setUp"], ["    ", "def", "setUp", "(", "self", ")", "->", "None", ":", "\n", "        ", "nlp", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "text", "=", "\"Title: VocGAN: A High-Fidelity Real-time Vocoder with a Hierarchically-nested Adversarial Network\\nSection:\"", "\n", "doc", "=", "nlp", "(", "text", ")", "\n", "sentences", "=", "[", "[", "tok", ".", "text", "for", "tok", "in", "sent", "]", "for", "sent", "in", "doc", ".", "sents", "]", "\n", "self", ".", "prediction", "=", "{", "'doc_key'", ":", "'test'", ",", "\n", "'dataset'", ":", "'scierc'", ",", "\n", "'sentences'", ":", "sentences", ",", "\n", "'predicted_ner'", ":", "[", "[", "[", "2", ",", "2", ",", "'Method'", ",", "15.5283", ",", "1.0", "]", ",", "\n", "[", "5", ",", "11", ",", "'Method'", ",", "3.0847", ",", "0.9563", "]", ",", "\n", "[", "6", ",", "11", ",", "'Method'", ",", "3.8185", ",", "0.9672", "]", ",", "\n", "[", "14", ",", "18", ",", "'Method'", ",", "3.4321", ",", "0.9686", "]", ",", "\n", "[", "15", ",", "18", ",", "'Method'", ",", "11.8431", ",", "1.0", "]", ",", "\n", "[", "19", ",", "19", ",", "'Generic'", ",", "4.7359", ",", "0.7531", "]", "]", "]", ",", "\n", "'predicted_relations'", ":", "[", "[", "[", "2", ",", "2", ",", "6", ",", "11", ",", "'HYPONYM-OF'", ",", "2.0108", ",", "0.8819", "]", ",", "\n", "[", "19", ",", "19", ",", "19", ",", "19", ",", "'USED-FOR'", ",", "0.8034", ",", "0.2309", "]", "]", "]", "}", "\n", "self", ".", "doc", "=", "doc", "\n", "return", "super", "(", ")", ".", "setUp", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.spacy_interface_test.TestSpacyInterface.test_relation": [[26, 35], ["dygie.spacy_interface.spacy_interface.prepare_spacy_doc", "spacy_interface_test.TestSpacyInterface.assertEqual", "spacy_interface_test.TestSpacyInterface.assertEqual", "spacy_interface_test.TestSpacyInterface.assertEqual", "spacy_interface_test.TestSpacyInterface.assertEqual", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.spacy_interface.spacy_interface.prepare_spacy_doc"], ["", "def", "test_relation", "(", "self", ")", ":", "\n", "        ", "doc", "=", "prepare_spacy_doc", "(", "self", ".", "doc", ",", "self", ".", "prediction", ")", "\n", "# number of sentences", "\n", "self", ".", "assertEqual", "(", "len", "(", "doc", ".", "_", ".", "rels", ")", ",", "1", ")", "\n", "# number of relations", "\n", "self", ".", "assertEqual", "(", "len", "(", "doc", ".", "_", ".", "rels", "[", "0", "]", ")", ",", "2", ")", "\n", "# type of relations", "\n", "self", ".", "assertEqual", "(", "doc", ".", "_", ".", "rels", "[", "0", "]", "[", "0", "]", "[", "2", "]", ",", "'HYPONYM-OF'", ")", "\n", "self", ".", "assertEqual", "(", "doc", ".", "_", ".", "rels", "[", "0", "]", "[", "1", "]", "[", "2", "]", ",", "'USED-FOR'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.spacy_interface_test.TestSpacyInterface.test_span_based_entity": [[37, 43], ["dygie.spacy_interface.spacy_interface.prepare_spacy_doc", "spacy_interface_test.TestSpacyInterface.assertEqual", "spacy_interface_test.TestSpacyInterface.assertEqual", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.spacy_interface.spacy_interface.prepare_spacy_doc"], ["", "def", "test_span_based_entity", "(", "self", ")", ":", "\n", "        ", "doc", "=", "prepare_spacy_doc", "(", "self", ".", "doc", ",", "self", ".", "prediction", ")", "\n", "# number of sentences", "\n", "self", ".", "assertEqual", "(", "len", "(", "doc", ".", "_", ".", "span_ents", ")", ",", "1", ")", "\n", "# number of span based entities ", "\n", "self", ".", "assertEqual", "(", "len", "(", "doc", ".", "_", ".", "span_ents", "[", "0", "]", ")", ",", "6", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.spacy_interface_test.TestSpacyInterface.test_spacy_entity": [[44, 48], ["dygie.spacy_interface.spacy_interface.prepare_spacy_doc", "spacy_interface_test.TestSpacyInterface.assertEqual", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.spacy_interface.spacy_interface.prepare_spacy_doc"], ["", "def", "test_spacy_entity", "(", "self", ")", ":", "\n", "        ", "doc", "=", "prepare_spacy_doc", "(", "self", ".", "doc", ",", "self", ".", "prediction", ")", "\n", "# number of proned merged entities", "\n", "self", ".", "assertEqual", "(", "len", "(", "doc", ".", "ents", ")", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEnt.setUp": [[21, 63], ["os.makedirs", "spacy.load", "annotated_doc.AnnotatedDoc.parse_ann", "annotated_doc_test.TestEnt.annotated_doc.char_to_token", "open", "f.write", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "\n", "# Set up tempdir", "\n", "        ", "self", ".", "tmpdir", "=", "\"tmp\"", "\n", "os", ".", "makedirs", "(", "self", ".", "tmpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Set up document text", "\n", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "dataset", "=", "'scierc'", "\n", "text", "=", "(", "\"Seattle is a rainy city. Jenny Durkan is the city's mayor. \"", "\n", "\"She was elected in 2017.\"", ")", "\n", "text_path", "=", "f'{self.tmpdir}/myfile.txt'", "\n", "with", "open", "(", "text_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "text", ")", "\n", "", "ann", "=", "(", "\"T1\\tCity 0 7\\tSeattle\\n\"", "\n", "\"T2\\tPerson 25 37\\tJenny Durkan\\n\"", "\n", "\"T3\\tCity 41 51\\tthe city's\\n\"", "\n", "\"T4\\tPerson 59 62\\tShe\\n\"", "\n", "\"T5\\tPersonnel.Election 67 74\\telected\\n\"", "\n", "\"T6\\tYear 78 82\\t2017\\n\"", "\n", "\"R1\\tMayor-Of Arg1:T2 Arg2:T3\\n\"", "\n", "\"E1\\tPersonnel.Election:T5 Person:T4 Year:T6\\n\"", "\n", "\"*\\tEQUIV T1 T3\\n\"", "\n", "\"*\\tEQUIV T2 T4\\n\"", ")", "\n", "ann_path", "=", "f'{self.tmpdir}/myfile.ann'", "\n", "with", "open", "(", "ann_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "ann", ")", "\n", "", "self", ".", "sent_idx_tups", "=", "[", "(", "0", ",", "6", ")", ",", "(", "6", ",", "14", ")", ",", "(", "14", ",", "19", ")", "]", "\n", "# NOTE: spacy tokenizes words with apostrophes into separate words.", "\n", "\n", "# Set up annotated_doc object", "\n", "self", ".", "annotated_doc", "=", "ad", ".", "AnnotatedDoc", ".", "parse_ann", "(", "text_path", ",", "\n", "ann_path", ",", "\n", "nlp", ",", "\n", "dataset", ",", "\n", "coref", "=", "True", ")", "\n", "self", ".", "annotated_doc", ".", "char_to_token", "(", ")", "\n", "\n", "# Right answer", "\n", "self", ".", "ner", "=", "[", "[", "[", "0", ",", "0", ",", "\"City\"", "]", "]", ",", "[", "[", "6", ",", "7", ",", "\"Person\"", "]", ",", "[", "9", ",", "11", ",", "\"City\"", "]", "]", ",", "\n", "[", "[", "14", ",", "14", ",", "\"Person\"", "]", ",", "[", "16", ",", "16", ",", "\"Personnel.Election\"", "]", ",", "\n", "[", "18", ",", "18", ",", "\"Year\"", "]", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEnt.tearDown": [[64, 67], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "tmpdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEnt.test_format_ner_dygiepp": [[68, 74], ["annotated_doc.Ent.format_ner_dygiepp", "annotated_doc_test.TestEnt.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Ent.format_ner_dygiepp"], ["", "def", "test_format_ner_dygiepp", "(", "self", ")", ":", "\n", "\n", "        ", "ner", "=", "ad", ".", "Ent", ".", "format_ner_dygiepp", "(", "self", ".", "annotated_doc", ".", "ents", ",", "\n", "self", ".", "sent_idx_tups", ")", "\n", "\n", "self", ".", "assertEqual", "(", "ner", ",", "self", ".", "ner", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestBinRel.setUp": [[77, 120], ["os.makedirs", "spacy.load", "annotated_doc.AnnotatedDoc.parse_ann", "annotated_doc_test.TestBinRel.annotated_doc.char_to_token", "annotated_doc.BinRel", "open", "f.write", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "\n", "# Set up tempdir", "\n", "        ", "self", ".", "tmpdir", "=", "\"tmp\"", "\n", "os", ".", "makedirs", "(", "self", ".", "tmpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Set up document text", "\n", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "dataset", "=", "'scierc'", "\n", "text", "=", "(", "\"Seattle is a rainy city. Jenny Durkan is the city's mayor. \"", "\n", "\"She was elected in 2017.\"", ")", "\n", "text_path", "=", "f'{self.tmpdir}/myfile.txt'", "\n", "with", "open", "(", "text_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "text", ")", "\n", "", "ann", "=", "(", "\"T1\\tCity 0 7\\tSeattle\\n\"", "\n", "\"T2\\tPerson 25 37\\tJenny Durkan\\n\"", "\n", "\"T3\\tCity 41 51\\tthe city's\\n\"", "\n", "\"T4\\tPerson 59 62\\tShe\\n\"", "\n", "\"T5\\tPersonnel.Election 67 74\\telected\\n\"", "\n", "\"T6\\tYear 78 82\\t2017\\n\"", "\n", "\"R1\\tMayor-Of Arg1:T2 Arg2:T3\\n\"", "\n", "\"E1\\tPersonnel.Election:T5 Person:T4 Year:T6\\n\"", "\n", "\"*\\tEQUIV T1 T3\\n\"", "\n", "\"*\\tEQUIV T2 T4\\n\"", ")", "\n", "ann_path", "=", "f'{self.tmpdir}/myfile.ann'", "\n", "with", "open", "(", "ann_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "ann", ")", "\n", "", "self", ".", "sent_idx_tups", "=", "[", "(", "0", ",", "6", ")", ",", "(", "6", ",", "14", ")", ",", "(", "14", ",", "19", ")", "]", "\n", "# NOTE: spacy tokenizes words with apostrophes into separate words.", "\n", "\n", "# Set up annotated_doc object", "\n", "self", ".", "annotated_doc", "=", "ad", ".", "AnnotatedDoc", ".", "parse_ann", "(", "text_path", ",", "\n", "ann_path", ",", "\n", "nlp", ",", "\n", "dataset", ",", "\n", "coref", "=", "True", ")", "\n", "self", ".", "annotated_doc", ".", "char_to_token", "(", ")", "\n", "\n", "# Set up relation", "\n", "self", ".", "rel1", "=", "ad", ".", "BinRel", "(", "\"R1\\tMayor-Of Arg1:T2 Arg2:T3\"", ".", "split", "(", ")", ")", "\n", "\n", "# Right answer", "\n", "self", ".", "relations", "=", "[", "[", "]", ",", "[", "[", "6", ",", "7", ",", "9", ",", "11", ",", "\"Mayor-Of\"", "]", "]", ",", "[", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestBinRel.tearDown": [[121, 124], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "tmpdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestBinRel.test_set_arg_objects": [[125, 131], ["annotated_doc_test.TestBinRel.rel1.set_arg_objects", "annotated_doc_test.TestBinRel.assertEqual", "annotated_doc_test.TestBinRel.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects"], ["", "def", "test_set_arg_objects", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "rel1", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "\n", "self", ".", "assertEqual", "(", "self", ".", "rel1", ".", "arg1", ",", "self", ".", "annotated_doc", ".", "ents", "[", "1", "]", ")", "\n", "self", ".", "assertEqual", "(", "self", ".", "rel1", ".", "arg2", ",", "self", ".", "annotated_doc", ".", "ents", "[", "2", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestBinRel.test_format_bin_rels_dygiepp": [[132, 139], ["annotated_doc_test.TestBinRel.rel1.set_arg_objects", "annotated_doc.BinRel.format_bin_rels_dygiepp", "annotated_doc_test.TestBinRel.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.BinRel.format_bin_rels_dygiepp"], ["", "def", "test_format_bin_rels_dygiepp", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "rel1", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "relations", "=", "ad", ".", "BinRel", ".", "format_bin_rels_dygiepp", "(", "[", "self", ".", "rel1", "]", ",", "\n", "self", ".", "sent_idx_tups", ")", "\n", "\n", "self", ".", "assertEqual", "(", "relations", ",", "self", ".", "relations", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEvent.setUp": [[142, 188], ["os.makedirs", "spacy.load", "annotated_doc.AnnotatedDoc.parse_ann", "annotated_doc_test.TestEvent.annotated_doc.char_to_token", "annotated_doc.Event", "open", "f.write", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "\n", "# Set up tempdir", "\n", "        ", "self", ".", "tmpdir", "=", "\"tmp\"", "\n", "os", ".", "makedirs", "(", "self", ".", "tmpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Set up document text", "\n", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "dataset", "=", "'scierc'", "\n", "text", "=", "(", "\"Seattle is a rainy city. Jenny Durkan is the city's mayor. \"", "\n", "\"She was elected in 2017.\"", ")", "\n", "text_path", "=", "f'{self.tmpdir}/myfile.txt'", "\n", "with", "open", "(", "text_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "text", ")", "\n", "", "ann", "=", "(", "\"T1\\tCity 0 7\\tSeattle\\n\"", "\n", "\"T2\\tPerson 25 37\\tJenny Durkan\\n\"", "\n", "\"T3\\tCity 41 51\\tthe city's\\n\"", "\n", "\"T4\\tPerson 59 62\\tShe\\n\"", "\n", "\"T5\\tPersonnel.Election 67 74\\telected\\n\"", "\n", "\"T6\\tYear 78 82\\t2017\\n\"", "\n", "\"R1\\tMayor-Of Arg1:T2 Arg2:T3\\n\"", "\n", "\"E1\\tPersonnel.Election:T5 Person:T4 Year:T6\\n\"", "\n", "\"*\\tEQUIV T1 T3\\n\"", "\n", "\"*\\tEQUIV T2 T4\\n\"", ")", "\n", "ann_path", "=", "f'{self.tmpdir}/myfile.ann'", "\n", "with", "open", "(", "ann_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "ann", ")", "\n", "", "self", ".", "sent_idx_tups", "=", "[", "(", "0", ",", "6", ")", ",", "(", "6", ",", "14", ")", ",", "(", "14", ",", "19", ")", "]", "\n", "# NOTE: spacy tokenizes words with apostrophes into separate words.", "\n", "\n", "# Set up annotated_doc object", "\n", "self", ".", "annotated_doc", "=", "ad", ".", "AnnotatedDoc", ".", "parse_ann", "(", "text_path", ",", "\n", "ann_path", ",", "\n", "nlp", ",", "\n", "dataset", ",", "\n", "coref", "=", "True", ")", "\n", "self", ".", "annotated_doc", ".", "char_to_token", "(", ")", "\n", "\n", "# Set up events", "\n", "self", ".", "event1", "=", "ad", ".", "Event", "(", "\n", "\"E1\\tPersonnel.Election:T5 Person:T4 Year:T6\"", ".", "split", "(", ")", ")", "\n", "\n", "# Right answer", "\n", "self", ".", "events", "=", "[", "[", "]", ",", "[", "]", ",", "\n", "[", "[", "[", "16", ",", "\"Personnel.Election\"", "]", ",", "[", "14", ",", "14", ",", "\"Person\"", "]", ",", "\n", "[", "18", ",", "18", ",", "\"Year\"", "]", "]", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEvent.tearDown": [[189, 192], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "tmpdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEvent.test_set_arg_objects": [[193, 201], ["annotated_doc_test.TestEvent.event1.set_arg_objects", "annotated_doc_test.TestEvent.assertEqual", "annotated_doc_test.TestEvent.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects"], ["", "def", "test_set_arg_objects", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "event1", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "\n", "self", ".", "assertEqual", "(", "self", ".", "event1", ".", "trigger", ",", "self", ".", "annotated_doc", ".", "ents", "[", "4", "]", ")", "\n", "self", ".", "assertEqual", "(", "\n", "self", ".", "event1", ".", "args", ",", "\n", "[", "self", ".", "annotated_doc", ".", "ents", "[", "3", "]", ",", "self", ".", "annotated_doc", ".", "ents", "[", "5", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEvent.test_format_events_dygiepp": [[202, 209], ["annotated_doc_test.TestEvent.event1.set_arg_objects", "annotated_doc.Event.format_events_dygiepp", "annotated_doc_test.TestEvent.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Event.format_events_dygiepp"], ["", "def", "test_format_events_dygiepp", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "event1", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "events", "=", "ad", ".", "Event", ".", "format_events_dygiepp", "(", "[", "self", ".", "event1", "]", ",", "\n", "self", ".", "sent_idx_tups", ")", "\n", "\n", "self", ".", "assertEqual", "(", "events", ",", "self", ".", "events", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEquivRel.setUp": [[212, 254], ["os.makedirs", "spacy.load", "annotated_doc.AnnotatedDoc.parse_ann", "annotated_doc_test.TestEquivRel.annotated_doc.char_to_token", "annotated_doc.EquivRel", "annotated_doc.EquivRel", "open", "f.write", "open", "f.write"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token"], ["    ", "def", "setUp", "(", "self", ")", ":", "\n", "\n", "# Set up tempdir", "\n", "        ", "self", ".", "tmpdir", "=", "\"tmp\"", "\n", "os", ".", "makedirs", "(", "self", ".", "tmpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Set up document text", "\n", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "dataset", "=", "'scierc'", "\n", "text", "=", "(", "\"Seattle is a rainy city. Jenny Durkan is the city's mayor. \"", "\n", "\"She was elected in 2017.\"", ")", "\n", "text_path", "=", "f'{self.tmpdir}/myfile.txt'", "\n", "with", "open", "(", "text_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "text", ")", "\n", "", "ann", "=", "(", "\"T1\\tCity 0 7\\tSeattle\\n\"", "\n", "\"T2\\tPerson 25 37\\tJenny Durkan\\n\"", "\n", "\"T3\\tCity 41 51\\tthe city's\\n\"", "\n", "\"T4\\tPerson 59 62\\tShe\\n\"", "\n", "\"T5\\tPersonnel.Election 67 74\\telected\\n\"", "\n", "\"T6\\tYear 78 82\\t2017\\n\"", "\n", "\"R1\\tMayor-Of Arg1:T2 Arg2:T3\\n\"", "\n", "\"E1\\tPersonnel.Election:T5 Person:T4 Year:T6\\n\"", "\n", "\"*\\tEQUIV T1 T3\\n\"", "\n", "\"*\\tEQUIV T2 T4\\n\"", ")", "\n", "ann_path", "=", "f'{self.tmpdir}/myfile.ann'", "\n", "with", "open", "(", "ann_path", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "ann", ")", "\n", "\n", "# Set up annotated_doc object", "\n", "", "self", ".", "annotated_doc", "=", "ad", ".", "AnnotatedDoc", ".", "parse_ann", "(", "text_path", ",", "\n", "ann_path", ",", "\n", "nlp", ",", "\n", "dataset", ",", "\n", "coref", "=", "True", ")", "\n", "self", ".", "annotated_doc", ".", "char_to_token", "(", ")", "\n", "\n", "# Set up equivalence relations", "\n", "self", ".", "equivrel1", "=", "ad", ".", "EquivRel", "(", "\"*\\tEQUIV T1 T3\"", ".", "split", "(", ")", ")", "\n", "self", ".", "equivrel2", "=", "ad", ".", "EquivRel", "(", "\"*\\tEQUIV T2 T4\"", ".", "split", "(", ")", ")", "\n", "\n", "# The dygiepp-formatted correct answer", "\n", "self", ".", "corefs", "=", "[", "[", "[", "0", ",", "0", "]", ",", "[", "9", ",", "11", "]", "]", ",", "[", "[", "6", ",", "7", "]", ",", "[", "14", ",", "14", "]", "]", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEquivRel.tearDown": [[255, 258], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "tmpdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEquivRel.test_set_arg_objects": [[259, 270], ["annotated_doc_test.TestEquivRel.equivrel1.set_arg_objects", "annotated_doc_test.TestEquivRel.equivrel2.set_arg_objects", "annotated_doc_test.TestEquivRel.assertEqual", "annotated_doc_test.TestEquivRel.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects"], ["", "def", "test_set_arg_objects", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "equivrel1", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "self", ".", "equivrel2", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "\n", "self", ".", "assertEqual", "(", "\n", "self", ".", "equivrel1", ".", "args", ",", "\n", "[", "self", ".", "annotated_doc", ".", "ents", "[", "0", "]", ",", "self", ".", "annotated_doc", ".", "ents", "[", "2", "]", "]", ")", "\n", "self", ".", "assertEqual", "(", "\n", "self", ".", "equivrel2", ".", "args", ",", "\n", "[", "self", ".", "annotated_doc", ".", "ents", "[", "1", "]", ",", "self", ".", "annotated_doc", ".", "ents", "[", "3", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestEquivRel.test_format_corefs_dygiepp": [[271, 279], ["annotated_doc_test.TestEquivRel.equivrel1.set_arg_objects", "annotated_doc_test.TestEquivRel.equivrel2.set_arg_objects", "annotated_doc.EquivRel.format_corefs_dygiepp", "annotated_doc_test.TestEquivRel.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.format_corefs_dygiepp"], ["", "def", "test_format_corefs_dygiepp", "(", "self", ")", ":", "\n", "\n", "        ", "self", ".", "equivrel1", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "self", ".", "equivrel2", ".", "set_arg_objects", "(", "self", ".", "annotated_doc", ".", "ents", ")", "\n", "corefs", "=", "ad", ".", "EquivRel", ".", "format_corefs_dygiepp", "(", "\n", "[", "self", ".", "equivrel1", ",", "self", ".", "equivrel2", "]", ")", "\n", "\n", "self", ".", "assertEqual", "(", "corefs", ",", "self", ".", "corefs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.setUp": [[285, 333], ["os.makedirs", "spacy.load", "open", "f.write", "open", "f.write", "annotated_doc_test.TestAnnotatedDoc.nlp"], "methods", ["None"], ["def", "setUp", "(", "self", ")", ":", "\n", "\n", "# Set up temp dir and test docs", "\n", "        ", "self", ".", "tmpdir", "=", "\"tmp\"", "\n", "os", ".", "makedirs", "(", "self", ".", "tmpdir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "txt", "=", "(", "\"Seattle is a rainy city. Jenny Durkan is the city's mayor. \"", "\n", "\"She was elected in 2017.\"", ")", "\n", "\n", "self", ".", "txt", "=", "f'{self.tmpdir}/myfile.txt'", "\n", "with", "open", "(", "self", ".", "txt", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "txt", ")", "\n", "\n", "", "ann", "=", "(", "\"T1\\tCity 0 7\\tSeattle\\n\"", "\n", "\"T2\\tPerson 25 37\\tJenny Durkan\\n\"", "\n", "\"T3\\tCity 41 51\\tthe city's\\n\"", "\n", "\"T4\\tPerson 59 62\\tShe\\n\"", "\n", "\"T5\\tPersonnel.Election 67 74\\telected\\n\"", "\n", "\"T6\\tYear 78 82\\t2017\\n\"", "\n", "\"R1\\tMayor-Of Arg1:T2 Arg2:T3\\n\"", "\n", "\"E1\\tPersonnel.Election:T5 Person:T4 Year:T6\\n\"", "\n", "\"*\\tEQUIV T1 T3\\n\"", "\n", "\"*\\tEQUIV T2 T4\\n\"", ")", "\n", "\n", "self", ".", "ann", "=", "f'{self.tmpdir}/myfile.ann'", "\n", "with", "open", "(", "self", ".", "ann", ",", "'w'", ")", "as", "f", ":", "\n", "            ", "f", ".", "write", "(", "ann", ")", "\n", "\n", "# Define other attributes", "\n", "", "self", ".", "nlp", "=", "spacy", ".", "load", "(", "\"en_core_web_sm\"", ")", "\n", "self", ".", "dataset", "=", "'scierc'", "\n", "\n", "# Define right answer", "\n", "self", ".", "dygiepp_dict", "=", "{", "\n", "\"doc_key\"", ":", "\n", "\"myfile\"", ",", "\n", "\"dataset\"", ":", "\n", "self", ".", "dataset", ",", "\n", "\"sentences\"", ":", "\n", "[", "[", "tok", ".", "text", "for", "tok", "in", "sent", "]", "for", "sent", "in", "self", ".", "nlp", "(", "txt", ")", ".", "sents", "]", ",", "\n", "\"ner\"", ":", "[", "[", "[", "0", ",", "0", ",", "\"City\"", "]", "]", ",", "[", "[", "6", ",", "7", ",", "\"Person\"", "]", ",", "[", "9", ",", "11", ",", "\"City\"", "]", "]", ",", "\n", "[", "[", "14", ",", "14", ",", "\"Person\"", "]", ",", "[", "16", ",", "16", ",", "\"Personnel.Election\"", "]", ",", "\n", "[", "18", ",", "18", ",", "\"Year\"", "]", "]", "]", ",", "\n", "\"relations\"", ":", "[", "[", "]", ",", "[", "[", "6", ",", "7", ",", "9", ",", "11", ",", "\"Mayor-Of\"", "]", "]", ",", "[", "]", "]", ",", "\n", "\"clusters\"", ":", "[", "[", "[", "0", ",", "0", "]", ",", "[", "9", ",", "11", "]", "]", ",", "[", "[", "6", ",", "7", "]", ",", "[", "14", ",", "14", "]", "]", "]", ",", "\n", "\"events\"", ":", "[", "[", "]", ",", "[", "]", ",", "\n", "[", "[", "[", "16", ",", "\"Personnel.Election\"", "]", ",", "[", "14", ",", "14", ",", "\"Person\"", "]", ",", "\n", "[", "18", ",", "18", ",", "\"Year\"", "]", "]", "]", "]", "\n", "}", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.tearDown": [[335, 338], ["shutil.rmtree"], "methods", ["None"], ["", "def", "tearDown", "(", "self", ")", ":", "\n", "\n", "        ", "shutil", ".", "rmtree", "(", "self", ".", "tmpdir", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.test_char_to_token": [[339, 355], ["ad.AnnotatedDoc.parse_ann.AnnotatedDoc.parse_ann", "annotated_doc.AnnotatedDoc.parse_ann.char_to_token", "annotated_doc_test.TestAnnotatedDoc.assertEqual", "annotated_doc_test.TestAnnotatedDoc.assertEqual", "annotated_doc_test.TestAnnotatedDoc.assertEqual", "annotated_doc_test.TestAnnotatedDoc.assertEqual", "annotated_doc_test.TestAnnotatedDoc.assertEqual", "annotated_doc_test.TestAnnotatedDoc.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token"], ["", "def", "test_char_to_token", "(", "self", ")", ":", "\n", "\n", "        ", "annotated_doc", "=", "ad", ".", "AnnotatedDoc", ".", "parse_ann", "(", "self", ".", "txt", ",", "\n", "self", ".", "ann", ",", "\n", "self", ".", "nlp", ",", "\n", "self", ".", "dataset", ",", "\n", "coref", "=", "True", ")", "\n", "annotated_doc", ".", "char_to_token", "(", ")", "\n", "\n", "self", ".", "assertEqual", "(", "annotated_doc", ".", "ents", "[", "0", "]", ".", "tok_start", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "annotated_doc", ".", "ents", "[", "1", "]", ".", "tok_start", ",", "6", ")", "\n", "self", ".", "assertEqual", "(", "annotated_doc", ".", "ents", "[", "2", "]", ".", "tok_start", ",", "9", ")", "\n", "\n", "self", ".", "assertEqual", "(", "annotated_doc", ".", "ents", "[", "0", "]", ".", "tok_end", ",", "0", ")", "\n", "self", ".", "assertEqual", "(", "annotated_doc", ".", "ents", "[", "1", "]", ".", "tok_end", ",", "7", ")", "\n", "self", ".", "assertEqual", "(", "annotated_doc", ".", "ents", "[", "2", "]", ".", "tok_end", ",", "11", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.data.annotated_doc_test.TestAnnotatedDoc.test_format_dygiepp": [[356, 367], ["ad.AnnotatedDoc.parse_ann.AnnotatedDoc.parse_ann", "annotated_doc.AnnotatedDoc.parse_ann.char_to_token", "annotated_doc.AnnotatedDoc.parse_ann.format_dygiepp", "annotated_doc_test.TestAnnotatedDoc.assertEqual"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.format_dygiepp"], ["", "def", "test_format_dygiepp", "(", "self", ")", ":", "\n", "\n", "        ", "annotated_doc", "=", "ad", ".", "AnnotatedDoc", ".", "parse_ann", "(", "self", ".", "txt", ",", "\n", "self", ".", "ann", ",", "\n", "self", ".", "nlp", ",", "\n", "self", ".", "dataset", ",", "\n", "coref", "=", "True", ")", "\n", "annotated_doc", ".", "char_to_token", "(", ")", "\n", "res", "=", "annotated_doc", ".", "format_dygiepp", "(", ")", "\n", "\n", "self", ".", "assertEqual", "(", "res", ",", "self", ".", "dygiepp_dict", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.__init__": [[65, 67], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "documents", ")", ":", "\n", "        ", "self", ".", "documents", "=", "documents", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.__getitem__": [[68, 70], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "documents", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.__len__": [[71, 73], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "documents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.__repr__": [[74, 76], ["document.Dataset.__len__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Cluster.__len__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"Dataset with {self.__len__()} documents.\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.from_jsonl": [[77, 86], ["cls", "open", "document.Document.from_json", "documents.append", "json.loads"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.from_json"], ["", "@", "classmethod", "\n", "def", "from_jsonl", "(", "cls", ",", "fname", ")", ":", "\n", "        ", "documents", "=", "[", "]", "\n", "with", "open", "(", "fname", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "for", "line", "in", "f", ":", "\n", "                ", "doc", "=", "Document", ".", "from_json", "(", "json", ".", "loads", "(", "line", ")", ")", "\n", "documents", ".", "append", "(", "doc", ")", "\n", "\n", "", "", "return", "cls", "(", "documents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.to_jsonl": [[87, 92], ["doc.to_json", "open", "print", "json.dumps"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "def", "to_jsonl", "(", "self", ",", "fname", ")", ":", "\n", "        ", "to_write", "=", "[", "doc", ".", "to_json", "(", ")", "for", "doc", "in", "self", "]", "\n", "with", "open", "(", "fname", ",", "\"w\"", ")", "as", "f", ":", "\n", "            ", "for", "entry", "in", "to_write", ":", "\n", "                ", "print", "(", "json", ".", "dumps", "(", "entry", ")", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.__init__": [[95, 105], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "doc_key", ",", "dataset", ",", "sentences", ",", "\n", "clusters", "=", "None", ",", "predicted_clusters", "=", "None", ",", "event_clusters", "=", "None", ",", "predicted_event_clusters", "=", "None", ",", "weight", "=", "None", ")", ":", "\n", "        ", "self", ".", "doc_key", "=", "doc_key", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "sentences", "=", "sentences", "\n", "self", ".", "clusters", "=", "clusters", "\n", "self", ".", "predicted_clusters", "=", "predicted_clusters", "\n", "self", ".", "event_clusters", "=", "event_clusters", "\n", "self", ".", "predicted_event_clusters", "=", "predicted_event_clusters", "\n", "self", ".", "weight", "=", "weight", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.from_json": [[106, 159], ["cls._check_fields", "js.get", "dygie.models.shared.fields_to_batches", "numpy.cumsum", "numpy.roll", "sentence_starts.tolist.tolist.tolist", "document.update_sentences_with_clusters", "document.update_sentences_with_event_clusters", "js.get", "cls", "len", "document.Sentence", "enumerate", "document.Cluster", "document.Cluster", "document.Cluster", "document.Cluster", "zip", "enumerate", "enumerate", "enumerate", "enumerate"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document._check_fields", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.fields_to_batches", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.update_sentences_with_clusters", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.update_sentences_with_event_clusters"], ["", "@", "classmethod", "\n", "def", "from_json", "(", "cls", ",", "js", ")", ":", "\n", "        ", "\"Read in from json-loaded dict.\"", "\n", "cls", ".", "_check_fields", "(", "js", ")", "\n", "doc_key", "=", "js", "[", "\"doc_key\"", "]", "\n", "dataset", "=", "js", ".", "get", "(", "\"dataset\"", ")", "\n", "entries", "=", "fields_to_batches", "(", "js", ",", "[", "\"doc_key\"", ",", "\"dataset\"", ",", "\"clusters\"", ",", "\"predicted_clusters\"", ",", "\n", "\"weight\"", ",", "\"event_clusters\"", ",", "\"predicted_event_clusters\"", "]", ")", "\n", "sentence_lengths", "=", "[", "len", "(", "entry", "[", "\"sentences\"", "]", ")", "for", "entry", "in", "entries", "]", "\n", "sentence_starts", "=", "np", ".", "cumsum", "(", "sentence_lengths", ")", "\n", "sentence_starts", "=", "np", ".", "roll", "(", "sentence_starts", ",", "1", ")", "\n", "sentence_starts", "[", "0", "]", "=", "0", "\n", "sentence_starts", "=", "sentence_starts", ".", "tolist", "(", ")", "\n", "sentences", "=", "[", "Sentence", "(", "entry", ",", "sentence_start", ",", "sentence_ix", ")", "\n", "for", "sentence_ix", ",", "(", "entry", ",", "sentence_start", ")", "\n", "in", "enumerate", "(", "zip", "(", "entries", ",", "sentence_starts", ")", ")", "]", "\n", "# Store cofereference annotations.", "\n", "if", "\"clusters\"", "in", "js", ":", "\n", "            ", "clusters", "=", "[", "Cluster", "(", "entry", ",", "i", ",", "sentences", ",", "sentence_starts", ")", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "js", "[", "\"clusters\"", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "clusters", "=", "None", "\n", "# TODO(dwadden) Need to treat predicted clusters differently and update sentences", "\n", "# appropriately.", "\n", "\n", "", "if", "\"predicted_clusters\"", "in", "js", ":", "\n", "            ", "predicted_clusters", "=", "[", "Cluster", "(", "entry", ",", "i", ",", "sentences", ",", "sentence_starts", ")", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "js", "[", "\"predicted_clusters\"", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "predicted_clusters", "=", "None", "\n", "\n", "# adapt from entity clusters", "\n", "", "if", "\"event_clusters\"", "in", "js", ":", "\n", "            ", "event_clusters", "=", "[", "Cluster", "(", "entry", ",", "i", ",", "sentences", ",", "sentence_starts", ")", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "js", "[", "\"event_clusters\"", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "event_clusters", "=", "None", "\n", "# TODO(dwadden) Need to treat predicted clusters differently and update sentences", "\n", "# appropriately.", "\n", "", "if", "\"predicted_event_clusters\"", "in", "js", ":", "\n", "            ", "predicted_event_clusters", "=", "[", "Cluster", "(", "entry", ",", "i", ",", "sentences", ",", "sentence_starts", ")", "\n", "for", "i", ",", "entry", "in", "enumerate", "(", "js", "[", "\"predicted_event_clusters\"", "]", ")", "]", "\n", "", "else", ":", "\n", "            ", "predicted_event_clusters", "=", "None", "\n", "\n", "# Update the sentences with coreference cluster labels.", "\n", "", "sentences", "=", "update_sentences_with_clusters", "(", "sentences", ",", "clusters", ")", "\n", "sentences", "=", "update_sentences_with_event_clusters", "(", "sentences", ",", "event_clusters", ")", "\n", "# Get the loss weight for this document.", "\n", "weight", "=", "js", ".", "get", "(", "\"weight\"", ",", "None", ")", "\n", "\n", "return", "cls", "(", "doc_key", ",", "dataset", ",", "sentences", ",", "clusters", ",", "predicted_clusters", ",", "event_clusters", ",", "\n", "predicted_event_clusters", ",", "weight", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document._check_fields": [[160, 174], ["re.compile", "js.keys", "ValueError", "re.compile.match", "unexpected.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_check_fields", "(", "js", ")", ":", "\n", "        ", "\"Make sure we only have allowed fields.\"", "\n", "allowed_field_regex", "=", "(", "\"doc_key|dataset|sentences|weight|.*ner$|\"", "\n", "\".*relations$|.*clusters$|.*events$|^_.*\"", ")", "\n", "allowed_field_regex", "=", "re", ".", "compile", "(", "allowed_field_regex", ")", "\n", "unexpected", "=", "[", "]", "\n", "for", "field", "in", "js", ".", "keys", "(", ")", ":", "\n", "            ", "if", "not", "allowed_field_regex", ".", "match", "(", "field", ")", ":", "\n", "                ", "unexpected", ".", "append", "(", "field", ")", "\n", "\n", "", "", "if", "unexpected", ":", "\n", "            ", "msg", "=", "f\"The following unexpected fields should be prefixed with an underscore: {', '.join(unexpected)}.\"", "\n", "raise", "ValueError", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.to_json": [[175, 195], ["dygie.models.shared.batches_to_fields", "res.update", "sent.to_json", "cluster.to_json", "cluster.to_json", "cluster.to_json", "cluster.to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.models.shared.batches_to_fields", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "\"Write to json dict.\"", "\n", "res", "=", "{", "\"doc_key\"", ":", "self", ".", "doc_key", ",", "\n", "\"dataset\"", ":", "self", ".", "dataset", "}", "\n", "sents_json", "=", "[", "sent", ".", "to_json", "(", ")", "for", "sent", "in", "self", "]", "\n", "fields_json", "=", "batches_to_fields", "(", "sents_json", ")", "\n", "res", ".", "update", "(", "fields_json", ")", "\n", "if", "self", ".", "clusters", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"clusters\"", "]", "=", "[", "cluster", ".", "to_json", "(", ")", "for", "cluster", "in", "self", ".", "clusters", "]", "\n", "", "if", "self", ".", "predicted_clusters", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"predicted_clusters\"", "]", "=", "[", "cluster", ".", "to_json", "(", ")", "for", "cluster", "in", "self", ".", "predicted_clusters", "]", "\n", "", "if", "self", ".", "event_clusters", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"event_clusters\"", "]", "=", "[", "cluster", ".", "to_json", "(", ")", "for", "cluster", "in", "self", ".", "event_clusters", "]", "\n", "", "if", "self", ".", "predicted_event_clusters", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"predicted_event_clusters\"", "]", "=", "[", "cluster", ".", "to_json", "(", ")", "for", "cluster", "in", "self", ".", "predicted_event_clusters", "]", "\n", "\n", "", "if", "self", ".", "weight", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"weight\"", "]", "=", "self", ".", "weight", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split": [[197, 252], ["copy.deepcopy", "sentence_groups.append", "NotImplementedError", "NotImplementedError", "document.Document.__class__", "len", "ValueError", "current_group.append", "len", "sentence_groups.append", "len", "range", "zip", "len", "len"], "methods", ["None"], ["", "def", "split", "(", "self", ",", "max_tokens_per_doc", ")", ":", "\n", "        ", "\"\"\"\n        Greedily split a long document into smaller documents, each shorter than\n        `max_tokens_per_doc`. Each split document will get the same weight as its parent.\n        \"\"\"", "\n", "# TODO(dwadden) Implement splitting when there's coref annotations. This is more difficult", "\n", "# because coreference clusters have to be split across documents.", "\n", "if", "self", ".", "clusters", "is", "not", "None", "or", "self", ".", "predicted_clusters", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Splitting documents with coreference annotations not implemented.\"", ")", "\n", "", "if", "self", ".", "event_clusters", "is", "not", "None", "or", "self", ".", "predicted_event_clusters", "is", "not", "None", ":", "\n", "            ", "raise", "NotImplementedError", "(", "\"Splitting documents with event coreference annotations not implemented.\"", ")", "\n", "\n", "# If the document is already short enough, return it as a list with a single item.", "\n", "", "if", "self", ".", "n_tokens", "<=", "max_tokens_per_doc", ":", "\n", "            ", "return", "[", "self", "]", "\n", "\n", "", "sentences", "=", "copy", ".", "deepcopy", "(", "self", ".", "sentences", ")", "\n", "\n", "sentence_groups", "=", "[", "]", "\n", "current_group", "=", "[", "]", "\n", "group_length", "=", "0", "\n", "sentence_tok_offset", "=", "0", "\n", "sentence_ix_offset", "=", "0", "\n", "for", "sentence", "in", "sentences", ":", "\n", "# Can't deal with single sentences longer than the limit.", "\n", "            ", "if", "len", "(", "sentence", ")", ">", "max_tokens_per_doc", ":", "\n", "                ", "msg", "=", "f\"Sentence \\\"{''.join(sentence.text)}\\\" has more than {max_tokens_per_doc} tokens. Please split this sentence.\"", "\n", "raise", "ValueError", "(", "msg", ")", "\n", "\n", "", "if", "group_length", "+", "len", "(", "sentence", ")", "<=", "max_tokens_per_doc", ":", "\n", "# If we're not at the limit, add it to the current sentence group.", "\n", "                ", "sentence", ".", "sentence_start", "-=", "sentence_tok_offset", "\n", "sentence", ".", "sentence_ix", "-=", "sentence_ix_offset", "\n", "current_group", ".", "append", "(", "sentence", ")", "\n", "group_length", "+=", "len", "(", "sentence", ")", "\n", "", "else", ":", "\n", "# Otherwise, start a new sentence group and adjust sentence offsets.", "\n", "                ", "sentence_groups", ".", "append", "(", "current_group", ")", "\n", "sentence_tok_offset", "=", "sentence", ".", "sentence_start", "\n", "sentence_ix_offset", "=", "sentence", ".", "sentence_ix", "\n", "sentence", ".", "sentence_start", "-=", "sentence_tok_offset", "\n", "sentence", ".", "sentence_ix", "-=", "sentence_ix_offset", "\n", "current_group", "=", "[", "sentence", "]", "\n", "group_length", "=", "len", "(", "sentence", ")", "\n", "\n", "# Add the final sentence group.", "\n", "", "", "sentence_groups", ".", "append", "(", "current_group", ")", "\n", "\n", "# Create a separate document for each sentence group.", "\n", "doc_keys", "=", "[", "f\"{self.doc_key}_SPLIT_{i}\"", "for", "i", "in", "range", "(", "len", "(", "sentence_groups", ")", ")", "]", "\n", "res", "=", "[", "self", ".", "__class__", "(", "doc_key", ",", "self", ".", "dataset", ",", "sentence_group", ",", "\n", "self", ".", "clusters", ",", "self", ".", "predicted_clusters", ",", "self", ".", "weight", ")", "\n", "for", "doc_key", ",", "sentence_group", "in", "zip", "(", "doc_keys", ",", "sentence_groups", ")", "]", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.__repr__": [[253, 255], ["enumerate", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"\\n\"", ".", "join", "(", "[", "str", "(", "i", ")", "+", "\": \"", "+", "\" \"", ".", "join", "(", "sent", ".", "text", ")", "for", "i", ",", "sent", "in", "enumerate", "(", "self", ".", "sentences", ")", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.__getitem__": [[256, 258], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "ix", ")", ":", "\n", "        ", "return", "self", ".", "sentences", "[", "ix", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.__len__": [[259, 261], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "sentences", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.print_plaintext": [[262, 265], ["print"], "methods", ["None"], ["", "def", "print_plaintext", "(", "self", ")", ":", "\n", "        ", "for", "sent", "in", "self", ":", "\n", "            ", "print", "(", "\" \"", ".", "join", "(", "sent", ".", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.n_tokens": [[282, 285], ["sum", "len"], "methods", ["None"], ["", "@", "property", "\n", "def", "n_tokens", "(", "self", ")", ":", "\n", "        ", "return", "sum", "(", "[", "len", "(", "sent", ")", "for", "sent", "in", "self", ".", "sentences", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.find_cluster": [[270, 281], ["None"], "methods", ["None"], ["", "def", "find_cluster", "(", "self", ",", "entity", ")", ":", "\n", "        ", "\"\"\"\n        Search through coreference clusters and return the one containing the query entity, if it's\n        part of a cluster. If we don't find a match, return None.\n        \"\"\"", "\n", "for", "clust", "in", "self", ".", "clusters", ":", "\n", "            ", "for", "entry", "in", "clust", ":", "\n", "                ", "if", "entry", ".", "span", "==", "entity", ".", "span", ":", "\n", "                    ", "return", "clust", "\n", "\n", "", "", "", "return", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Sentence.__init__": [[288, 343], ["document.Events", "document.PredictedEvents", "entry.items", "re.match", "document.NER", "document.PredictedNER", "document.Relation", "document.PredictedRelation"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "entry", ",", "sentence_start", ",", "sentence_ix", ")", ":", "\n", "        ", "self", ".", "sentence_start", "=", "sentence_start", "\n", "self", ".", "sentence_ix", "=", "sentence_ix", "\n", "self", ".", "text", "=", "entry", "[", "\"sentences\"", "]", "\n", "\n", "# Metadata fields are prefixed with a `_`.", "\n", "self", ".", "metadata", "=", "{", "k", ":", "v", "for", "k", ",", "v", "in", "entry", ".", "items", "(", ")", "if", "re", ".", "match", "(", "\"^_\"", ",", "k", ")", "}", "\n", "\n", "# Store events.", "\n", "if", "\"ner\"", "in", "entry", ":", "\n", "            ", "self", ".", "ner", "=", "[", "NER", "(", "this_ner", ",", "self", ")", "\n", "for", "this_ner", "in", "entry", "[", "\"ner\"", "]", "]", "\n", "self", ".", "ner_dict", "=", "{", "entry", ".", "span", ".", "span_sent", ":", "entry", ".", "label", "for", "entry", "in", "self", ".", "ner", "}", "\n", "", "else", ":", "\n", "            ", "self", ".", "ner", "=", "None", "\n", "self", ".", "ner_dict", "=", "None", "\n", "\n", "# Predicted ner.", "\n", "", "if", "\"predicted_ner\"", "in", "entry", ":", "\n", "            ", "self", ".", "predicted_ner", "=", "[", "PredictedNER", "(", "this_ner", ",", "self", ")", "\n", "for", "this_ner", "in", "entry", "[", "\"predicted_ner\"", "]", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "predicted_ner", "=", "None", "\n", "\n", "# Store relations.", "\n", "", "if", "\"relations\"", "in", "entry", ":", "\n", "            ", "self", ".", "relations", "=", "[", "Relation", "(", "this_relation", ",", "self", ")", "for", "\n", "this_relation", "in", "entry", "[", "\"relations\"", "]", "]", "\n", "relation_dict", "=", "{", "}", "\n", "for", "rel", "in", "self", ".", "relations", ":", "\n", "                ", "key", "=", "(", "rel", ".", "pair", "[", "0", "]", ".", "span_sent", ",", "rel", ".", "pair", "[", "1", "]", ".", "span_sent", ")", "\n", "relation_dict", "[", "key", "]", "=", "rel", ".", "label", "\n", "", "self", ".", "relation_dict", "=", "relation_dict", "\n", "", "else", ":", "\n", "            ", "self", ".", "relations", "=", "None", "\n", "self", ".", "relation_dict", "=", "None", "\n", "\n", "# Predicted relations.", "\n", "", "if", "\"predicted_relations\"", "in", "entry", ":", "\n", "            ", "self", ".", "predicted_relations", "=", "[", "PredictedRelation", "(", "this_relation", ",", "self", ")", "for", "\n", "this_relation", "in", "entry", "[", "\"predicted_relations\"", "]", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "predicted_relations", "=", "None", "\n", "\n", "# Store events.", "\n", "", "if", "\"events\"", "in", "entry", ":", "\n", "            ", "self", ".", "events", "=", "Events", "(", "entry", "[", "\"events\"", "]", ",", "self", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "events", "=", "None", "\n", "\n", "# Predicted events.", "\n", "", "if", "\"predicted_events\"", "in", "entry", ":", "\n", "            ", "self", ".", "predicted_events", "=", "PredictedEvents", "(", "entry", "[", "\"predicted_events\"", "]", ",", "self", ")", "\n", "", "else", ":", "\n", "            ", "self", ".", "predicted_events", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Sentence.to_json": [[344, 363], ["document.Sentence.metadata.items", "document.Sentence.events.to_json", "document.Sentence.predicted_events.to_json", "entry.to_json", "entry.to_json", "entry.to_json", "entry.to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "res", "=", "{", "\"sentences\"", ":", "self", ".", "text", "}", "\n", "if", "self", ".", "ner", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"ner\"", "]", "=", "[", "entry", ".", "to_json", "(", ")", "for", "entry", "in", "self", ".", "ner", "]", "\n", "", "if", "self", ".", "predicted_ner", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"predicted_ner\"", "]", "=", "[", "entry", ".", "to_json", "(", ")", "for", "entry", "in", "self", ".", "predicted_ner", "]", "\n", "", "if", "self", ".", "relations", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"relations\"", "]", "=", "[", "entry", ".", "to_json", "(", ")", "for", "entry", "in", "self", ".", "relations", "]", "\n", "", "if", "self", ".", "predicted_relations", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"predicted_relations\"", "]", "=", "[", "entry", ".", "to_json", "(", ")", "for", "entry", "in", "self", ".", "predicted_relations", "]", "\n", "", "if", "self", ".", "events", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"events\"", "]", "=", "self", ".", "events", ".", "to_json", "(", ")", "\n", "", "if", "self", ".", "predicted_events", "is", "not", "None", ":", "\n", "            ", "res", "[", "\"predicted_events\"", "]", "=", "self", ".", "predicted_events", ".", "to_json", "(", ")", "\n", "\n", "", "for", "k", ",", "v", "in", "self", ".", "metadata", ".", "items", "(", ")", ":", "\n", "            ", "res", "[", "k", "]", "=", "v", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Sentence.__repr__": [[364, 374], ["enumerate", "len", "str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "the_text", "=", "\" \"", ".", "join", "(", "self", ".", "text", ")", "\n", "the_lengths", "=", "[", "len", "(", "x", ")", "for", "x", "in", "self", ".", "text", "]", "\n", "tok_ixs", "=", "\"\"", "\n", "for", "i", ",", "offset", "in", "enumerate", "(", "the_lengths", ")", ":", "\n", "            ", "true_offset", "=", "offset", "if", "i", "<", "10", "else", "offset", "-", "1", "\n", "tok_ixs", "+=", "str", "(", "i", ")", "\n", "tok_ixs", "+=", "\" \"", "*", "true_offset", "\n", "\n", "", "return", "the_text", "+", "\"\\n\"", "+", "tok_ixs", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Sentence.__len__": [[375, 377], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "text", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.__init__": [[380, 388], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "start", ",", "end", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "# The `start` and `end` are relative to the document. We convert them to be relative to the", "\n", "# sentence.", "\n", "        ", "self", ".", "sentence", "=", "sentence", "\n", "# Need to store the sentence text to make span objects hashable.", "\n", "self", ".", "sentence_text", "=", "\" \"", ".", "join", "(", "sentence", ".", "text", ")", "\n", "self", ".", "start_sent", "=", "start", "if", "sentence_offsets", "else", "start", "-", "sentence", ".", "sentence_start", "\n", "self", ".", "end_sent", "=", "end", "if", "sentence_offsets", "else", "end", "-", "sentence", ".", "sentence_start", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.start_doc": [[389, 392], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "start_doc", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "start_sent", "+", "self", ".", "sentence", ".", "sentence_start", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.end_doc": [[393, 396], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "end_doc", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "end_sent", "+", "self", ".", "sentence", ".", "sentence_start", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.span_doc": [[397, 400], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "span_doc", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "start_doc", ",", "self", ".", "end_doc", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.span_sent": [[401, 404], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "span_sent", "(", "self", ")", ":", "\n", "        ", "return", "(", "self", ".", "start_sent", ",", "self", ".", "end_sent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.text": [[405, 408], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "text", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sentence", ".", "text", "[", "self", ".", "start_sent", ":", "self", ".", "end_sent", "+", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.__repr__": [[409, 411], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "(", "self", ".", "start_sent", ",", "self", ".", "end_sent", ",", "self", ".", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.__eq__": [[412, 416], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "self", ".", "span_doc", "==", "other", ".", "span_doc", "and", "\n", "self", ".", "span_sent", "==", "other", ".", "span_sent", "and", "\n", "self", ".", "sentence", "==", "other", ".", "sentence", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Span.__hash__": [[417, 420], ["hash"], "methods", ["None"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "tup", "=", "self", ".", "span_sent", "+", "(", "self", ".", "sentence_text", ",", ")", "\n", "return", "hash", "(", "tup", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Token.__init__": [[423, 426], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ix", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "        ", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "ix_sent", "=", "ix", "if", "sentence_offsets", "else", "ix", "-", "sentence", ".", "sentence_start", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Token.ix_doc": [[427, 430], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "ix_doc", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "ix_sent", "+", "self", ".", "sentence", ".", "sentence_start", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Token.text": [[431, 434], ["None"], "methods", ["None"], ["", "@", "property", "\n", "def", "text", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "sentence", ".", "text", "[", "self", ".", "ix_sent", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Token.__repr__": [[435, 437], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "str", "(", "(", "self", ".", "ix_sent", ",", "self", ".", "text", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Trigger.__init__": [[440, 445], ["document.Token"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "trig", ",", "sentence", ",", "sentence_offsets", ")", ":", "\n", "        ", "token", "=", "Token", "(", "trig", "[", "0", "]", ",", "sentence", ",", "sentence_offsets", ")", "\n", "label", "=", "trig", "[", "1", "]", "\n", "self", ".", "token", "=", "token", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Trigger.__repr__": [[446, 448], ["document.Trigger.token.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "token", ".", "__repr__", "(", ")", "[", ":", "-", "1", "]", "+", "\", \"", "+", "self", ".", "label", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Trigger.to_json": [[449, 451], ["None"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "[", "self", ".", "token", ".", "ix_doc", ",", "self", ".", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedTrigger.__init__": [[454, 458], ["document.Trigger.__init__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "trig", ",", "sentence", ",", "sentence_offsets", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "trig", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "raw_score", "=", "trig", "[", "2", "]", "\n", "self", ".", "softmax_score", "=", "trig", "[", "3", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedTrigger.__repr__": [[459, 461], ["document.Trigger.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__repr__", "(", ")", "+", "f\" with confidence {self.softmax_score:0.4f}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedTrigger.to_json": [[462, 464], ["document.Trigger.to_json", "document.format_float", "document.format_float"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "to_json", "(", ")", "+", "[", "format_float", "(", "self", ".", "raw_score", ")", ",", "format_float", "(", "self", ".", "softmax_score", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Argument.__init__": [[467, 471], ["document.Span"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "arg", ",", "event_type", ",", "sentence", ",", "sentence_offsets", ")", ":", "\n", "        ", "self", ".", "span", "=", "Span", "(", "arg", "[", "0", "]", ",", "arg", "[", "1", "]", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "role", "=", "arg", "[", "2", "]", "\n", "self", ".", "event_type", "=", "event_type", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Argument.__repr__": [[472, 474], ["document.Argument.span.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "span", ".", "__repr__", "(", ")", "[", ":", "-", "1", "]", "+", "\", \"", "+", "self", ".", "event_type", "+", "\", \"", "+", "self", ".", "role", "+", "\")\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Argument.__eq__": [[475, 479], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "self", ".", "span", "==", "other", ".", "span", "and", "\n", "self", ".", "role", "==", "other", ".", "role", "and", "\n", "self", ".", "event_type", "==", "other", ".", "event_type", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Argument.__hash__": [[480, 482], ["document.Argument.span.__hash__", "hash"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Argument.__hash__"], ["", "def", "__hash__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "span", ".", "__hash__", "(", ")", "+", "hash", "(", "(", "self", ".", "role", ",", "self", ".", "event_type", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Argument.to_json": [[483, 485], ["list"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "span", ".", "span_doc", ")", "+", "[", "self", ".", "role", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedArgument.__init__": [[488, 492], ["document.Argument.__init__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "arg", ",", "event_type", ",", "sentence", ",", "sentence_offsets", ")", ":", "\n", "        ", "super", "(", ")", ".", "__init__", "(", "arg", ",", "event_type", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "raw_score", "=", "arg", "[", "3", "]", "\n", "self", ".", "softmax_score", "=", "arg", "[", "4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedArgument.__repr__": [[493, 495], ["document.Argument.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__repr__", "(", ")", "+", "f\" with confidence {self.softmax_score:0.4f}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedArgument.to_json": [[496, 498], ["document.Argument.to_json", "document.format_float", "document.format_float"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "to_json", "(", ")", "+", "[", "format_float", "(", "self", ".", "raw_score", ")", ",", "format_float", "(", "self", ".", "softmax_score", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.NER.__init__": [[501, 504], ["document.Span"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "ner", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "        ", "self", ".", "span", "=", "Span", "(", "ner", "[", "0", "]", ",", "ner", "[", "1", "]", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "label", "=", "ner", "[", "2", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.NER.__repr__": [[505, 507], ["document.NER.span.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.span.__repr__()}: {self.label}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.NER.__eq__": [[508, 511], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "self", ".", "span", "==", "other", ".", "span", "and", "\n", "self", ".", "label", "==", "other", ".", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.NER.to_json": [[512, 514], ["list"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "span", ".", "span_doc", ")", "+", "[", "self", ".", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedNER.__init__": [[517, 522], ["document.NER.__init__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "ner", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "        ", "\"The input should be a list: [span_start, span_end, label, raw_score, softmax_score].\"", "\n", "super", "(", ")", ".", "__init__", "(", "ner", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "raw_score", "=", "ner", "[", "3", "]", "\n", "self", ".", "softmax_score", "=", "ner", "[", "4", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedNER.__repr__": [[523, 525], ["document.NER.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__repr__", "(", ")", "+", "f\" with confidence {self.softmax_score:0.4f}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedNER.to_json": [[526, 528], ["document.NER.to_json", "document.format_float", "document.format_float"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "to_json", "(", ")", "+", "[", "format_float", "(", "self", ".", "raw_score", ")", ",", "format_float", "(", "self", ".", "softmax_score", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Relation.__init__": [[531, 539], ["document.Span", "document.Span"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "relation", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "        ", "start1", ",", "end1", "=", "relation", "[", "0", "]", ",", "relation", "[", "1", "]", "\n", "start2", ",", "end2", "=", "relation", "[", "2", "]", ",", "relation", "[", "3", "]", "\n", "label", "=", "relation", "[", "4", "]", "\n", "span1", "=", "Span", "(", "start1", ",", "end1", ",", "sentence", ",", "sentence_offsets", ")", "\n", "span2", "=", "Span", "(", "start2", ",", "end2", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "pair", "=", "(", "span1", ",", "span2", ")", "\n", "self", ".", "label", "=", "label", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Relation.__repr__": [[540, 542], ["document.Relation.pair[].__repr__", "document.Relation.pair[].__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.pair[0].__repr__()}, {self.pair[1].__repr__()}: {self.label}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Relation.__eq__": [[543, 545], ["None"], "methods", ["None"], ["", "def", "__eq__", "(", "self", ",", "other", ")", ":", "\n", "        ", "return", "(", "self", ".", "pair", "==", "other", ".", "pair", ")", "and", "(", "self", ".", "label", "==", "other", ".", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Relation.to_json": [[546, 548], ["list", "list"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "list", "(", "self", ".", "pair", "[", "0", "]", ".", "span_doc", ")", "+", "list", "(", "self", ".", "pair", "[", "1", "]", ".", "span_doc", ")", "+", "[", "self", ".", "label", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedRelation.__init__": [[551, 556], ["document.Relation.__init__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["    ", "def", "__init__", "(", "self", ",", "relation", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "        ", "\"Input format: [start_1, end_1, start_2, end_2, label, raw_score, softmax_score].\"", "\n", "super", "(", ")", ".", "__init__", "(", "relation", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "raw_score", "=", "relation", "[", "5", "]", "\n", "self", ".", "softmax_score", "=", "relation", "[", "6", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedRelation.__repr__": [[557, 559], ["document.Relation.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "__repr__", "(", ")", "+", "f\" with confidence {self.softmax_score:0.4f}\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.PredictedRelation.to_json": [[560, 562], ["document.Relation.to_json", "document.format_float", "document.format_float"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "super", "(", ")", ".", "to_json", "(", ")", "+", "[", "format_float", "(", "self", ".", "raw_score", ")", ",", "format_float", "(", "self", ".", "softmax_score", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventBase.__init__": [[568, 577], ["document.EventBase.trigger_constructor", "document.EventBase.argument_constructor", "document.EventBase.arguments.append"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "event", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "        ", "trig", "=", "event", "[", "0", "]", "\n", "args", "=", "event", "[", "1", ":", "]", "\n", "self", ".", "trigger", "=", "self", ".", "trigger_constructor", "(", "trig", ",", "sentence", ",", "sentence_offsets", ")", "\n", "\n", "self", ".", "arguments", "=", "[", "]", "\n", "for", "arg", "in", "args", ":", "\n", "            ", "this_arg", "=", "self", ".", "argument_constructor", "(", "arg", ",", "self", ".", "trigger", ".", "label", ",", "sentence", ",", "sentence_offsets", ")", "\n", "self", ".", "arguments", ".", "append", "(", "this_arg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventBase.to_json": [[578, 583], ["document.EventBase.trigger.to_json", "arg.to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "trig_json", "=", "self", ".", "trigger", ".", "to_json", "(", ")", "\n", "arg_json", "=", "[", "arg", ".", "to_json", "(", ")", "for", "arg", "in", "self", ".", "arguments", "]", "\n", "res", "=", "[", "trig_json", "]", "+", "arg_json", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventBase.__repr__": [[584, 591], ["document.EventBase.trigger.__repr__", "arg.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "res", "=", "\"<\"", "\n", "res", "+=", "self", ".", "trigger", ".", "__repr__", "(", ")", "+", "\":\\n\"", "\n", "for", "arg", "in", "self", ".", "arguments", ":", "\n", "            ", "res", "+=", "6", "*", "\" \"", "+", "arg", ".", "__repr__", "(", ")", "+", "\";\\n\"", "\n", "", "res", "=", "res", "[", ":", "-", "2", "]", "+", "\">\"", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.__init__": [[605, 625], ["set", "set", "document.EventsBase.event_constructor"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "events_json", ",", "sentence", ",", "sentence_offsets", "=", "False", ")", ":", "\n", "        ", "self", ".", "event_list", "=", "[", "self", ".", "event_constructor", "(", "this_event", ",", "sentence", ",", "sentence_offsets", ")", "\n", "for", "this_event", "in", "events_json", "]", "\n", "self", ".", "triggers", "=", "set", "(", "[", "event", ".", "trigger", "for", "event", "in", "self", ".", "event_list", "]", ")", "\n", "self", ".", "arguments", "=", "set", "(", "[", "arg", "for", "event", "in", "self", ".", "event_list", "for", "arg", "in", "event", ".", "arguments", "]", ")", "\n", "\n", "# Store trigger and argument dictionaries.", "\n", "trigger_dict", "=", "{", "}", "\n", "argument_dict", "=", "{", "}", "\n", "for", "event", "in", "self", ".", "event_list", ":", "\n", "            ", "trigger_key", "=", "event", ".", "trigger", ".", "token", ".", "ix_sent", "# integer index", "\n", "trigger_val", "=", "event", ".", "trigger", ".", "label", "# trigger label", "\n", "trigger_dict", "[", "trigger_key", "]", "=", "trigger_val", "\n", "for", "argument", "in", "event", ".", "arguments", ":", "\n", "                ", "arg_key", "=", "(", "trigger_key", ",", "argument", ".", "span", ".", "span_sent", ")", "# (trigger_ix, (arg_start, arg_end))", "\n", "arg_value", "=", "argument", ".", "role", "# argument label", "\n", "argument_dict", "[", "arg_key", "]", "=", "arg_value", "\n", "\n", "", "", "self", ".", "trigger_dict", "=", "trigger_dict", "\n", "self", ".", "argument_dict", "=", "argument_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.to_json": [[626, 628], ["event.to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "[", "event", ".", "to_json", "(", ")", "for", "event", "in", "self", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.__len__": [[629, 631], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "event_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.__getitem__": [[632, 634], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "i", ")", ":", "\n", "        ", "return", "self", ".", "event_list", "[", "i", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.__repr__": [[635, 637], ["event.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "\"\\n\\n\"", ".", "join", "(", "[", "event", ".", "__repr__", "(", ")", "for", "event", "in", "self", ".", "event_list", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.span_matches": [[638, 641], ["set"], "methods", ["None"], ["", "def", "span_matches", "(", "self", ",", "argument", ")", ":", "\n", "        ", "return", "set", "(", "[", "candidate", "for", "candidate", "in", "self", ".", "arguments", "\n", "if", "candidate", ".", "span", ".", "span_sent", "==", "argument", ".", "span", ".", "span_sent", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.event_type_matches": [[642, 645], ["set", "document.EventsBase.span_matches"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.span_matches"], ["", "def", "event_type_matches", "(", "self", ",", "argument", ")", ":", "\n", "        ", "return", "set", "(", "[", "candidate", "for", "candidate", "in", "self", ".", "span_matches", "(", "argument", ")", "\n", "if", "candidate", ".", "event_type", "==", "argument", ".", "event_type", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.matches_except_event_type": [[646, 651], ["set", "document.EventsBase.span_matches"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.span_matches"], ["", "def", "matches_except_event_type", "(", "self", ",", "argument", ")", ":", "\n", "        ", "matched", "=", "[", "candidate", "for", "candidate", "in", "self", ".", "span_matches", "(", "argument", ")", "\n", "if", "candidate", ".", "event_type", "!=", "argument", ".", "event_type", "\n", "and", "candidate", ".", "role", "==", "argument", ".", "role", "]", "\n", "return", "set", "(", "matched", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.EventsBase.exact_match": [[652, 657], ["None"], "methods", ["None"], ["", "def", "exact_match", "(", "self", ",", "argument", ")", ":", "\n", "        ", "for", "candidate", "in", "self", ".", "arguments", ":", "\n", "            ", "if", "candidate", "==", "argument", ":", "\n", "                ", "return", "True", "\n", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Cluster.__init__": [[668, 693], ["sum", "isinstance", "TypeError", "print", "len", "document.get_sentence_of_span", "document.Span", "document.ClusterMember", "members.append", "members_crossing_sentences.append"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.get_sentence_of_span"], ["    ", "def", "__init__", "(", "self", ",", "cluster", ",", "cluster_id", ",", "sentences", ",", "sentence_starts", ")", ":", "\n", "# Make sure the cluster ID is an int.", "\n", "        ", "if", "not", "isinstance", "(", "cluster_id", ",", "int", ")", ":", "\n", "            ", "raise", "TypeError", "(", "\"Coreference cluster ID's must be ints.\"", ")", "\n", "\n", "", "n_tokens", "=", "sum", "(", "[", "len", "(", "x", ")", "for", "x", "in", "sentences", "]", ")", "\n", "\n", "members", "=", "[", "]", "\n", "members_crossing_sentences", "=", "[", "]", "\n", "\n", "for", "entry", "in", "cluster", ":", "\n", "            ", "try", ":", "\n", "                ", "sentence_ix", "=", "get_sentence_of_span", "(", "entry", ",", "sentence_starts", ",", "n_tokens", ")", "\n", "sentence", "=", "sentences", "[", "sentence_ix", "]", "\n", "span", "=", "Span", "(", "entry", "[", "0", "]", ",", "entry", "[", "1", "]", ",", "sentence", ")", "\n", "to_append", "=", "ClusterMember", "(", "span", ",", "sentence", ",", "cluster_id", ")", "\n", "members", ".", "append", "(", "to_append", ")", "\n", "", "except", "SpanCrossesSentencesError", ":", "\n", "                ", "members_crossing_sentences", ".", "append", "(", "entry", ")", "\n", "\n", "", "", "if", "members_crossing_sentences", ":", "\n", "            ", "print", "(", "\"Found a coreference cluster member that crosses sentence boundaries; skipping.\"", ")", "\n", "\n", "", "self", ".", "members", "=", "members", "\n", "self", ".", "cluster_id", "=", "cluster_id", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Cluster.to_json": [[694, 696], ["list"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "[", "list", "(", "member", ".", "span", ".", "span_doc", ")", "for", "member", "in", "self", ".", "members", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Cluster.__repr__": [[697, 699], ["document.Cluster.members.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"{self.cluster_id}: \"", "+", "self", ".", "members", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Cluster.__getitem__": [[700, 702], ["None"], "methods", ["None"], ["", "def", "__getitem__", "(", "self", ",", "ix", ")", ":", "\n", "        ", "return", "self", ".", "members", "[", "ix", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Cluster.__len__": [[703, 705], ["len"], "methods", ["None"], ["", "def", "__len__", "(", "self", ")", ":", "\n", "        ", "return", "len", "(", "self", ".", "members", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.ClusterMember.__init__": [[708, 712], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "span", ",", "sentence", ",", "cluster_id", ")", ":", "\n", "        ", "self", ".", "span", "=", "span", "\n", "self", ".", "sentence", "=", "sentence", "\n", "self", ".", "cluster_id", "=", "cluster_id", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.ClusterMember.__repr__": [[713, 715], ["document.ClusterMember.span.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "f\"<{self.sentence.sentence_ix}> \"", "+", "self", ".", "span", ".", "__repr__", "(", ")", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.format_float": [[10, 12], ["round"], "function", ["None"], ["def", "format_float", "(", "x", ")", ":", "\n", "    ", "return", "round", "(", "x", ",", "4", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.get_sentence_of_span": [[18, 30], ["in_between.index", "sum", "zip"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["", "def", "get_sentence_of_span", "(", "span", ",", "sentence_starts", ",", "doc_tokens", ")", ":", "\n", "    ", "\"\"\"\n    Return the index of the sentence that the span is part of.\n    \"\"\"", "\n", "# Inclusive sentence ends", "\n", "sentence_ends", "=", "[", "x", "-", "1", "for", "x", "in", "sentence_starts", "[", "1", ":", "]", "]", "+", "[", "doc_tokens", "-", "1", "]", "\n", "in_between", "=", "[", "span", "[", "0", "]", ">=", "start", "and", "span", "[", "1", "]", "<=", "end", "\n", "for", "start", ",", "end", "in", "zip", "(", "sentence_starts", ",", "sentence_ends", ")", "]", "\n", "if", "sum", "(", "in_between", ")", "!=", "1", ":", "\n", "        ", "raise", "SpanCrossesSentencesError", "\n", "", "the_sentence", "=", "in_between", ".", "index", "(", "True", ")", "\n", "return", "the_sentence", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.update_sentences_with_clusters": [[32, 46], ["None"], "function", ["None"], ["", "def", "update_sentences_with_clusters", "(", "sentences", ",", "clusters", ")", ":", "\n", "    ", "\"Add cluster dictionary to each sentence, if there are coreference clusters.\"", "\n", "for", "sent", "in", "sentences", ":", "\n", "        ", "sent", ".", "cluster_dict", "=", "{", "}", "if", "clusters", "is", "not", "None", "else", "None", "\n", "\n", "", "if", "clusters", "is", "None", ":", "\n", "        ", "return", "sentences", "\n", "\n", "", "for", "clust", "in", "clusters", ":", "\n", "        ", "for", "member", "in", "clust", ".", "members", ":", "\n", "            ", "sent", "=", "member", ".", "sentence", "\n", "sent", ".", "cluster_dict", "[", "member", ".", "span", ".", "span_sent", "]", "=", "member", ".", "cluster_id", "\n", "\n", "", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.update_sentences_with_event_clusters": [[48, 62], ["None"], "function", ["None"], ["", "def", "update_sentences_with_event_clusters", "(", "sentences", ",", "event_clusters", ")", ":", "\n", "    ", "\"Add event cluster dictionary to each sentence, if there are event coreference clusters.\"", "\n", "for", "sent", "in", "sentences", ":", "\n", "        ", "sent", ".", "event_cluster_dict", "=", "{", "}", "if", "event_clusters", "is", "not", "None", "else", "None", "\n", "\n", "", "if", "event_clusters", "is", "None", ":", "\n", "        ", "return", "sentences", "\n", "\n", "", "for", "event_clust", "in", "event_clusters", ":", "\n", "        ", "for", "member", "in", "event_clust", ".", "members", ":", "\n", "            ", "sent", "=", "member", ".", "sentence", "\n", "sent", ".", "event_cluster_dict", "[", "member", ".", "span", ".", "span_sent", "]", "=", "member", ".", "cluster_id", "\n", "\n", "", "", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader.__init__": [[34, 41], ["allennlp.data.dataset_readers.dataset_reader.DatasetReader.__init__", "allennlp.data.token_indexers.SingleIdTokenIndexer"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__"], ["        ", "instance", "=", "self", ".", "_words_list_to_instance", "(", "tokenized_document", ")", "\n", "return", "self", ".", "predict_instance", "(", "instance", ")", "\n", "\n", "", "@", "overrides", "\n", "def", "dump_line", "(", "self", ",", "outputs", ")", ":", "\n", "# Need to override to tell Python how to deal with Numpy ints.", "\n", "        ", "return", "json", ".", "dumps", "(", "outputs", ",", "default", "=", "int", ")", "+", "\"\\n\"", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._read": [[42, 55], ["allennlp.common.file_utils.cached_path", "open", "f.readlines", "json.loads", "dygie.DyGIEReader.text_to_instance"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader.text_to_instance"], ["# TODO(dwadden) Can this be implemented in `forward_on_instance`  instead?", "\n", "", "@", "overrides", "\n", "def", "predict_instance", "(", "self", ",", "instance", ")", ":", "\n", "        ", "\"\"\"\n        An instance is an entire document, represented as a list of sentences.\n        \"\"\"", "\n", "model", "=", "self", ".", "_model", "\n", "cuda_device", "=", "model", ".", "_get_prediction_device", "(", ")", "\n", "\n", "# Try to predict this batch.", "\n", "try", ":", "\n", "            ", "dataset", "=", "Batch", "(", "[", "instance", "]", ")", "\n", "dataset", ".", "index_instances", "(", "model", ".", "vocab", ")", "\n", "model_input", "=", "util", ".", "move_to_device", "(", "dataset", ".", "as_tensor_dict", "(", ")", ",", "cuda_device", ")", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._too_long": [[56, 58], ["None"], "methods", ["None"], ["prediction", "=", "model", ".", "make_output_human_readable", "(", "model", "(", "**", "model_input", ")", ")", ".", "to_json", "(", ")", "\n", "# If we run out of GPU memory, warn user and indicate that this document failed.", "\n", "# This way, prediction doesn't grind to a halt every time we run out of GPU.", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_ner": [[59, 69], ["sent.ner_dict.items", "len", "dygie.DyGIEReader._too_long", "span_tuples.index"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._too_long", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["", "except", "RuntimeError", "as", "err", ":", "\n", "# doc_key, dataset, sentences, message", "\n", "            ", "metadata", "=", "instance", "[", "\"metadata\"", "]", ".", "metadata", "\n", "doc_key", "=", "metadata", ".", "doc_key", "\n", "msg", "=", "(", "f\"Encountered a RunTimeError on document {doc_key}. Skipping this example.\"", "\n", "f\" Error message:\\n{err.args[0]}.\"", ")", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "prediction", "=", "metadata", ".", "to_json", "(", ")", "\n", "prediction", "[", "\"_FAILED_PREDICTION\"", "]", "=", "True", "\n", "\n", "", "return", "prediction", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_coref": [[70, 79], ["sent.cluster_dict.items", "len", "dygie.DyGIEReader._too_long", "span_tuples.index"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._too_long", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_relations": [[80, 96], ["sent.relation_dict.items", "span_tuples.index", "span_tuples.index", "relation_indices.append", "relations.append", "dygie.DyGIEReader._too_long", "dygie.DyGIEReader._too_long"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._too_long", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._too_long"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_events": [[97, 115], ["len", "sent.events.trigger_dict.items", "sent.events.argument_dict.items", "dygie.DyGIEReader._too_long", "span_tuples.index", "argument_indices.append", "arguments.append"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._too_long", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_sentence": [[116, 162], ["allennlp.data.fields.TextField", "allennlp.data.dataset_readers.dataset_utils.enumerate_spans", "allennlp.data.fields.ListField", "dygie.DyGIEReader._normalize_word", "spans.append", "dygie.DyGIEReader._process_ner", "allennlp.data.fields.ListField", "dygie.DyGIEReader._process_coref", "allennlp.data.fields.ListField", "dygie.DyGIEReader._process_relations", "allennlp.data.fields.AdjacencyField", "dygie.DyGIEReader._process_events", "allennlp.data.fields.SequenceLabelField", "dygie.data.fields.adjacency_field_assym.AdjacencyFieldAssym", "allennlp.data.tokenizers.Token", "allennlp.data.fields.SpanField", "allennlp.data.fields.LabelField", "allennlp.data.fields.LabelField"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._normalize_word", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_ner", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_coref", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_relations", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_events"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_sentence_fields": [[163, 182], ["set", "sentence_fields[].keys", "dygie.DyGIEReader._process_sentence", "sentence_fields[].keys", "allennlp.data.fields.ListField", "set", "dygie.DyGIEDataException", "entry.keys"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_sentence"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader.text_to_instance": [[183, 201], ["dygie.data.dataset_readers.document.Document.from_json", "dygie.DyGIEReader._process_sentence_fields", "allennlp.data.fields.MetadataField", "allennlp.data.instance.Instance", "len", "min", "warnings.warn"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.from_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._process_sentence_fields"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._instances_from_cache_file": [[202, 207], ["open", "pickle.load"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._instances_to_cache_file": [[208, 212], ["open", "pickle.dump"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.dygie.DyGIEReader._normalize_word": [[213, 219], ["None"], "methods", ["None"], []], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.__init__": [[43, 71], ["adjacency_field_assym.AdjacencyFieldAssym._maybe_warn_for_namespace", "row_field.sequence_length", "col_field.sequence_length", "len", "len", "allennlp.common.checks.ConfigurationError", "all", "allennlp.common.checks.ConfigurationError", "allennlp.common.checks.ConfigurationError", "set", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym._maybe_warn_for_namespace"], ["def", "__init__", "(", "self", ",", "\n", "indices", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", ",", "\n", "row_field", ":", "SequenceField", ",", "\n", "col_field", ":", "SequenceField", ",", "\n", "labels", ":", "List", "[", "str", "]", "=", "None", ",", "\n", "label_namespace", ":", "str", "=", "'labels'", ",", "\n", "padding_value", ":", "int", "=", "-", "1", ")", "->", "None", ":", "\n", "        ", "self", ".", "indices", "=", "indices", "\n", "self", ".", "labels", "=", "labels", "\n", "self", ".", "row_field", "=", "row_field", "\n", "self", ".", "col_field", "=", "col_field", "\n", "self", ".", "_label_namespace", "=", "label_namespace", "\n", "self", ".", "_padding_value", "=", "padding_value", "\n", "self", ".", "_indexed_labels", ":", "List", "[", "int", "]", "=", "None", "\n", "\n", "self", ".", "_maybe_warn_for_namespace", "(", "label_namespace", ")", "\n", "row_length", "=", "row_field", ".", "sequence_length", "(", ")", "\n", "col_length", "=", "col_field", ".", "sequence_length", "(", ")", "\n", "\n", "if", "len", "(", "set", "(", "indices", ")", ")", "!=", "len", "(", "indices", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"Indices must be unique, but found {indices}\"", ")", "\n", "\n", "", "if", "not", "all", "(", "[", "0", "<=", "index", "[", "1", "]", "<", "col_length", "and", "0", "<=", "index", "[", "0", "]", "<", "row_length", "for", "index", "in", "indices", "]", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"Label indices and sequence length \"", "\n", "f\"are incompatible: {indices} and {row_length} or {col_length}\"", ")", "\n", "\n", "", "if", "labels", "is", "not", "None", "and", "len", "(", "indices", ")", "!=", "len", "(", "labels", ")", ":", "\n", "            ", "raise", "ConfigurationError", "(", "f\"Labelled indices were passed, but their lengths do not match: \"", "\n", "f\" {labels}, {indices}\"", ")", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym._maybe_warn_for_namespace": [[73, 82], ["adjacency_field_assym.AdjacencyFieldAssym._label_namespace.endswith", "adjacency_field_assym.AdjacencyFieldAssym._label_namespace.endswith", "logger.warning", "adjacency_field_assym.AdjacencyFieldAssym._already_warned_namespaces.add"], "methods", ["None"], ["", "", "def", "_maybe_warn_for_namespace", "(", "self", ",", "label_namespace", ":", "str", ")", "->", "None", ":", "\n", "        ", "if", "not", "(", "self", ".", "_label_namespace", ".", "endswith", "(", "\"labels\"", ")", "or", "self", ".", "_label_namespace", ".", "endswith", "(", "\"tags\"", ")", ")", ":", "\n", "            ", "if", "label_namespace", "not", "in", "self", ".", "_already_warned_namespaces", ":", "\n", "                ", "logger", ".", "warning", "(", "\"Your label namespace was '%s'. We recommend you use a namespace \"", "\n", "\"ending with 'labels' or 'tags', so we don't add UNK and PAD tokens by \"", "\n", "\"default to your vocabulary.  See documentation for \"", "\n", "\"`non_padded_namespaces` parameter in Vocabulary.\"", ",", "\n", "self", ".", "_label_namespace", ")", "\n", "self", ".", "_already_warned_namespaces", ".", "add", "(", "label_namespace", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.count_vocab_items": [[83, 88], ["None"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "count_vocab_items", "(", "self", ",", "counter", ":", "Dict", "[", "str", ",", "Dict", "[", "str", ",", "int", "]", "]", ")", ":", "\n", "        ", "if", "self", ".", "_indexed_labels", "is", "None", "and", "self", ".", "labels", "is", "not", "None", ":", "\n", "            ", "for", "label", "in", "self", ".", "labels", ":", "\n", "                ", "counter", "[", "self", ".", "_label_namespace", "]", "[", "label", "]", "+=", "1", "# type: ignore", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index": [[89, 94], ["vocab.get_token_index"], "methods", ["None"], ["", "", "", "@", "overrides", "\n", "def", "index", "(", "self", ",", "vocab", ":", "Vocabulary", ")", ":", "\n", "        ", "if", "self", ".", "_indexed_labels", "is", "None", "and", "self", ".", "labels", "is", "not", "None", ":", "\n", "            ", "self", ".", "_indexed_labels", "=", "[", "vocab", ".", "get_token_index", "(", "label", ",", "self", ".", "_label_namespace", ")", "\n", "for", "label", "in", "self", ".", "labels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.get_padding_lengths": [[95, 99], ["adjacency_field_assym.AdjacencyFieldAssym.row_field.sequence_length", "adjacency_field_assym.AdjacencyFieldAssym.col_field.sequence_length"], "methods", ["None"], ["", "", "@", "overrides", "\n", "def", "get_padding_lengths", "(", "self", ")", "->", "Dict", "[", "str", ",", "int", "]", ":", "\n", "        ", "return", "{", "'num_rows'", ":", "self", ".", "row_field", ".", "sequence_length", "(", ")", ",", "\n", "'num_cols'", ":", "self", ".", "col_field", ".", "sequence_length", "(", ")", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.as_tensor": [[100, 110], ["zip", "torch.ones", "range", "len"], "methods", ["None"], ["", "@", "overrides", "\n", "def", "as_tensor", "(", "self", ",", "padding_lengths", ":", "Dict", "[", "str", ",", "int", "]", ")", "->", "torch", ".", "Tensor", ":", "\n", "        ", "desired_num_rows", "=", "padding_lengths", "[", "'num_rows'", "]", "\n", "desired_num_cols", "=", "padding_lengths", "[", "'num_cols'", "]", "\n", "tensor", "=", "torch", ".", "ones", "(", "desired_num_rows", ",", "desired_num_cols", ")", "*", "self", ".", "_padding_value", "\n", "labels", "=", "self", ".", "_indexed_labels", "or", "[", "1", "for", "_", "in", "range", "(", "len", "(", "self", ".", "indices", ")", ")", "]", "\n", "\n", "for", "index", ",", "label", "in", "zip", "(", "self", ".", "indices", ",", "labels", ")", ":", "\n", "            ", "tensor", "[", "index", "]", "=", "label", "\n", "", "return", "tensor", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.empty_field": [[111, 121], ["adjacency_field_assym.AdjacencyFieldAssym", "adjacency_field_assym.AdjacencyFieldAssym.row_field.empty_field", "adjacency_field_assym.AdjacencyFieldAssym.col_field.empty_field"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.empty_field", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.empty_field"], ["", "@", "overrides", "\n", "def", "empty_field", "(", "self", ")", "->", "'AdjacencyFieldAssym'", ":", "\n", "# pylint: disable=protected-access", "\n", "# The empty_list here is needed for mypy", "\n", "        ", "empty_list", ":", "List", "[", "Tuple", "[", "int", ",", "int", "]", "]", "=", "[", "]", "\n", "adjacency_field", "=", "AdjacencyFieldAssym", "(", "empty_list", ",", "\n", "self", ".", "row_field", ".", "empty_field", "(", ")", ",", "\n", "self", ".", "col_field", ".", "empty_field", "(", ")", ",", "\n", "padding_value", "=", "self", ".", "_padding_value", ")", "\n", "return", "adjacency_field", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.__str__": [[122, 130], ["adjacency_field_assym.AdjacencyFieldAssym.row_field.sequence_length", "adjacency_field_assym.AdjacencyFieldAssym.col_field.sequence_length", "textwrap.wrap", "textwrap.wrap", "repr", "repr"], "methods", ["None"], ["", "def", "__str__", "(", "self", ")", "->", "str", ":", "\n", "        ", "row_length", "=", "self", ".", "row_field", ".", "sequence_length", "(", ")", "\n", "col_length", "=", "self", ".", "col_field", ".", "sequence_length", "(", ")", "\n", "formatted_labels", "=", "\"\"", ".", "join", "(", "[", "\"\\t\\t\"", "+", "labels", "+", "\"\\n\"", "\n", "for", "labels", "in", "textwrap", ".", "wrap", "(", "repr", "(", "self", ".", "labels", ")", ",", "100", ")", "]", ")", "\n", "formatted_indices", "=", "\"\"", ".", "join", "(", "[", "\"\\t\\t\"", "+", "index", "+", "\"\\n\"", "\n", "for", "index", "in", "textwrap", ".", "wrap", "(", "repr", "(", "self", ".", "indices", ")", ",", "100", ")", "]", ")", "\n", "return", "f\"AdjacencyFieldAssym of row length {row_length} and col length {col_length}\\n\"", "f\"\\t\\twith indices:\\n {formatted_indices}\\n\""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.tuning.optuna_train.objective": [[26, 49], ["trial.suggest_int", "trial.suggest_float", "trial.suggest_float", "trial.suggest_float", "trial.suggest_int", "trial.suggest_int", "trial.suggest_int", "trial.suggest_float", "trial.suggest_float", "trial.suggest_float", "trial.suggest_float", "trial.suggest_float", "trial.suggest_float", "optuna.integration.allennlp.AllenNLPExecutor", "optuna.integration.allennlp.AllenNLPExecutor.run"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.run"], ["def", "objective", "(", "trial", ":", "optuna", ".", "Trial", ")", "->", "float", ":", "\n", "    ", "trial", ".", "suggest_int", "(", "\"max_span_width\"", ",", "6", ",", "10", ")", "\n", "trial", ".", "suggest_float", "(", "\"lossw_events\"", ",", "0.75", ",", "1.0", ")", "\n", "trial", ".", "suggest_float", "(", "\"lossw_relation\"", ",", "0.25", ",", "0.75", ")", "\n", "trial", ".", "suggest_float", "(", "\"lossw_ner\"", ",", "0.25", ",", "0.75", ")", "\n", "trial", ".", "suggest_int", "(", "\"feature_size\"", ",", "10", ",", "30", ")", "\n", "trial", ".", "suggest_int", "(", "\"ffwd_num_layers\"", ",", "1", ",", "3", ")", "\n", "trial", ".", "suggest_int", "(", "\"ffwd_hidden_dims\"", ",", "100", ",", "300", ")", "\n", "trial", ".", "suggest_float", "(", "\"ffwd_dropout\"", ",", "0.2", ",", "0.6", ")", "\n", "trial", ".", "suggest_float", "(", "\"relation_spans_per_word\"", ",", "0.3", ",", "0.7", ")", "\n", "trial", ".", "suggest_float", "(", "\"events_trigger_spans_per_word\"", ",", "0.1", ",", "0.8", ")", "\n", "trial", ".", "suggest_float", "(", "\"events_argument_spans_per_word\"", ",", "0.4", ",", "1.0", ")", "\n", "trial", ".", "suggest_float", "(", "\"events_lossw_trigger\"", ",", "0.1", ",", "0.4", ")", "\n", "trial", ".", "suggest_float", "(", "\"events_lossw_arguments\"", ",", "0.8", ",", "1.0", ")", "\n", "\n", "executor", "=", "optuna", ".", "integration", ".", "allennlp", ".", "AllenNLPExecutor", "(", "\n", "trial", "=", "trial", ",", "# trial object", "\n", "config_file", "=", "f\"./training_config/{args.config_name}.jsonnet\"", ",", "# jsonnet path", "\n", "serialization_dir", "=", "f\"./models/optuna/{trial.number}\"", ",", "# directory for snapshots and logs", "\n", "metrics", "=", "\"best_validation_MEAN__trig_class_f1\"", ",", "\n", "include_package", "=", "\"dygie\"", ",", "\n", ")", "\n", "return", "executor", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.debug.debug_forward_pass.get_args": [[13, 25], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "\"Debug forward pass of model.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"training_config\"", ",", "type", "=", "str", ",", "help", "=", "\"Path to the config file.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_bert\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If given, use the BERT model in the config. Else, use random embeddings.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_archive\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"If given, load an archived model instaed of initializing from scratch.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_instances\"", ",", "type", "=", "int", ",", "default", "=", "5", ",", "\n", "help", "=", "\"Maximum number of instances to load.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.debug.debug_forward_pass.main": [[27, 77], ["debug_forward_pass.get_args", "json.loads", "dygie.data.dataset_readers.dygie.DyGIEReader", "dygie.data.dataset_readers.dygie.DyGIEReader.read", "allennlp.data.vocabulary.Vocabulary.from_instances", "reader.read.index_with", "allennlp.data.dataloader.PyTorchDataLoader", "_jsonnet.evaluate_file", "allennlp.modules.token_embedders.PretrainedTransformerMismatchedEmbedder", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "allennlp.modules.token_embedders.Embedding", "allennlp.modules.text_field_embedders.BasicTextFieldEmbedder", "dygie.models.dygie.DyGIE", "dygie.models.dygie.DyGIE.from_archive", "dygie.DyGIE.from_archive.", "allennlp.data.token_indexers.PretrainedTransformerMismatchedIndexer", "allennlp.data.token_indexers.SingleIdTokenIndexer", "vocabulary.Vocabulary.from_instances.get_vocab_size"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "# Read config.", "\n", "file_dict", "=", "json", ".", "loads", "(", "evaluate_file", "(", "args", ".", "training_config", ")", ")", "\n", "model_dict", "=", "file_dict", "[", "\"model\"", "]", "\n", "\n", "if", "args", ".", "use_bert", ":", "\n", "        ", "bert_name", "=", "model_dict", "[", "\"embedder\"", "]", "[", "\"token_embedders\"", "]", "[", "\"bert\"", "]", "[", "\"model_name\"", "]", "\n", "", "else", ":", "\n", "        ", "bert_name", "=", "None", "\n", "\n", "# Hack to replace components that we're setting in the script.", "\n", "", "for", "name", "in", "[", "\"type\"", ",", "\"embedder\"", ",", "\"initializer\"", ",", "\"module_initializer\"", "]", ":", "\n", "        ", "del", "model_dict", "[", "name", "]", "\n", "\n", "# Create indexer.", "\n", "", "if", "args", ".", "use_bert", ":", "\n", "        ", "tok_indexers", "=", "{", "\"bert\"", ":", "token_indexers", ".", "PretrainedTransformerMismatchedIndexer", "(", "\n", "bert_name", ",", "max_length", "=", "512", ")", "}", "\n", "", "else", ":", "\n", "        ", "tok_indexers", "=", "{", "\"tokens\"", ":", "token_indexers", ".", "SingleIdTokenIndexer", "(", ")", "}", "\n", "\n", "# Read input data.", "\n", "", "reader", "=", "DyGIEReader", "(", "max_span_width", "=", "8", ",", "token_indexers", "=", "tok_indexers", ",", "max_instances", "=", "args", ".", "max_instances", ")", "\n", "data", "=", "reader", ".", "read", "(", "file_dict", "[", "\"train_data_path\"", "]", ")", "\n", "vocab", "=", "vocabulary", ".", "Vocabulary", ".", "from_instances", "(", "data", ")", "\n", "data", ".", "index_with", "(", "vocab", ")", "\n", "\n", "# Create embedder.", "\n", "if", "args", ".", "use_bert", ":", "\n", "        ", "token_embedder", "=", "token_embedders", ".", "PretrainedTransformerMismatchedEmbedder", "(", "\n", "bert_name", ",", "max_length", "=", "512", ")", "\n", "embedder", "=", "text_field_embedders", ".", "BasicTextFieldEmbedder", "(", "{", "\"bert\"", ":", "token_embedder", "}", ")", "\n", "", "else", ":", "\n", "        ", "token_embedder", "=", "token_embedders", ".", "Embedding", "(", "\n", "num_embeddings", "=", "vocab", ".", "get_vocab_size", "(", "\"tokens\"", ")", ",", "embedding_dim", "=", "100", ")", "\n", "embedder", "=", "text_field_embedders", ".", "BasicTextFieldEmbedder", "(", "{", "\"tokens\"", ":", "token_embedder", "}", ")", "\n", "\n", "# Create iterator and model.", "\n", "", "iterator", "=", "PyTorchDataLoader", "(", "batch_size", "=", "1", ",", "dataset", "=", "data", ")", "\n", "if", "args", ".", "model_archive", "is", "None", ":", "\n", "        ", "model", "=", "dygie", ".", "DyGIE", "(", "vocab", "=", "vocab", ",", "\n", "embedder", "=", "embedder", ",", "\n", "**", "model_dict", ")", "\n", "", "else", ":", "\n", "        ", "model", "=", "dygie", ".", "DyGIE", ".", "from_archive", "(", "args", ".", "model_archive", ")", "\n", "\n", "# Run forward pass over a single entry.", "\n", "", "for", "batch", "in", "iterator", ":", "\n", "        ", "output_dict", "=", "model", "(", "**", "batch", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.debug.print_label_namespaces.get_args": [[10, 22], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "textwrap.dedent"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "desc", "=", "\"\"\"\n    Print out the label namespaces available for a pretrained model.\n    Usage example: python scripts/debug/print_label_namespaces.py pretrained/scierc.tar.gz\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "dedent", "(", "desc", ")", ",", "\n", "formatter_class", "=", "argparse", ".", "RawTextHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"model_archive\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The `.tar.gz` archive containing the trained model.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.debug.print_label_namespaces.main": [[24, 34], ["print_label_namespaces.get_args", "tarfile.open", "tarfile.open.getmembers", "print", "print", "name.replace"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "model_archive", "=", "args", ".", "model_archive", "\n", "tar", "=", "tarfile", ".", "open", "(", "model_archive", ")", "\n", "members", "=", "tar", ".", "getmembers", "(", ")", "\n", "print", "(", "\"Available label namespaces:\"", ")", "\n", "for", "member", "in", "members", ":", "\n", "        ", "name", "=", "member", ".", "name", "\n", "if", "\"vocabulary\"", "in", "name", "and", "\".txt\"", "in", "name", "and", "\"non_padded_namespaces\"", "not", "in", "name", ":", "\n", "            ", "print", "(", "name", ".", "replace", "(", "\"vocabulary/\"", ",", "\"\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.preprocess.ace2json.parseAce": [[6, 34], ["open", "line.rstrip.rstrip", "line.rstrip.split", "tokens[].split", "rel_set.add", "line.rstrip.split", "int", "int", "lengths.append", "entity_set.add", "rels[].split", "rels[].split", "tokens[].split", "tokens[].split", "len", "keyphrase.split"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["def", "parseAce", "(", "annfn", ",", "entity_set", ",", "rel_set", ")", ":", "\n", "    ", "entity_dir", "=", "{", "}", "\n", "rel_dir", "=", "{", "}", "\n", "for", "line", "in", "open", "(", "annfn", ")", ":", "\n", "        ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "if", "'Arg1:'", "in", "line", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "key", "=", "tokens", "[", "0", "]", "\n", "rels", "=", "tokens", "[", "1", "]", ".", "split", "(", ")", "\n", "rel", "=", "rels", "[", "0", "]", "\n", "arg1", "=", "rels", "[", "1", "]", ".", "split", "(", "':'", ")", "[", "-", "1", "]", "\n", "arg2", "=", "rels", "[", "2", "]", ".", "split", "(", "':'", ")", "[", "-", "1", "]", "\n", "rel_dir", "[", "key", "]", "=", "{", "'relation'", ":", "rel", ",", "'arg1'", ":", "arg1", ",", "'arg2'", ":", "arg2", "}", "\n", "rel_set", ".", "add", "(", "rel", ")", "\n", "", "else", ":", "\n", "            ", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "key", "=", "tokens", "[", "0", "]", "\n", "offsets", "=", "tokens", "[", "1", "]", ".", "split", "(", ")", "[", "1", ":", "]", "\n", "offset0", "=", "int", "(", "offsets", "[", "0", "]", ")", "\n", "offset1", "=", "int", "(", "offsets", "[", "1", "]", ")", "\n", "ner", "=", "tokens", "[", "1", "]", ".", "split", "(", ")", "[", "0", "]", "\n", "keyphrase", "=", "tokens", "[", "2", "]", "\n", "global", "lengths", "\n", "lengths", ".", "append", "(", "len", "(", "keyphrase", ".", "split", "(", ")", ")", ")", "\n", "entity_dir", "[", "key", "]", "=", "{", "'ner'", ":", "ner", ",", "'offset'", ":", "[", "offset0", ",", "offset1", "]", ",", "'keyphrase'", ":", "keyphrase", "}", "\n", "entity_set", ".", "add", "(", "ner", ")", "\n", "\n", "", "", "return", "entity_dir", ",", "rel_dir", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.preprocess.ace2json.parseStanfordOld": [[35, 59], ["open", "line.rstrip.rstrip", "line.rstrip.split", "tokens[].startswith", "int", "int", "int", "int", "int", "int", "tokens[].split", "int", "[].split", "[].split", "tokens[].split", "tokens[].split", "tokens[].split", "tokens[].split"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "parseStanfordOld", "(", "stanfordfn", ")", ":", "\n", "    ", "doc", "=", "{", "}", "\n", "for", "line", "in", "open", "(", "stanfordfn", ")", ":", "\n", "        ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "if", "not", "line", ":", "continue", "\n", "if", "tokens", "[", "2", "]", ".", "startswith", "(", "'sentence'", ")", ":", "\n", "            ", "sentid", "=", "int", "(", "tokens", "[", "2", "]", ".", "split", "(", "'\"'", ")", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "offset0", "=", "int", "(", "tokens", "[", "0", "]", ")", "\n", "offset1", "=", "int", "(", "tokens", "[", "1", "]", ")", "\n", "doc", "[", "sentid", "]", "=", "{", "'offset'", ":", "[", "offset0", ",", "offset1", "]", ",", "'tokens'", ":", "{", "}", "}", "\n", "", "else", ":", "\n", "            ", "offset0", "=", "int", "(", "tokens", "[", "0", "]", ")", "\n", "offset1", "=", "int", "(", "tokens", "[", "1", "]", ")", "\n", "tokid", "=", "int", "(", "tokens", "[", "2", "]", ".", "split", "(", "'\"'", ")", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "dephead", "=", "tokens", "[", "2", "]", ".", "split", "(", "'\"'", ")", "[", "-", "2", "]", "\n", "if", "dephead", "==", "\"ROOT\"", ":", "\n", "                ", "dephead", "=", "0", "\n", "", "else", ":", "\n", "                ", "dephead", "=", "int", "(", "dephead", "[", "1", ":", "]", ")", "\n", "", "pos", "=", "tokens", "[", "2", "]", ".", "split", "(", ")", "[", "3", "]", ".", "split", "(", "'\"'", ")", "[", "1", "]", "\n", "deptype", "=", "tokens", "[", "2", "]", ".", "split", "(", ")", "[", "-", "1", "]", ".", "split", "(", "'='", ")", "[", "0", "]", "\n", "doc", "[", "sentid", "]", "[", "'tokens'", "]", "[", "tokid", "]", "=", "{", "'dephead'", ":", "dephead", ",", "\"pos\"", ":", "pos", ",", "\"deptype\"", ":", "deptype", ",", "\"offset\"", ":", "[", "offset0", ",", "offset1", "]", "}", "\n", "", "", "return", "doc", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.preprocess.ace2json.parseStanford": [[60, 88], ["open", "line.rstrip.rstrip", "line.rstrip.split", "tokens[].startswith", "int", "int", "int", "int", "int", "int", "tokens[].split", "int", "[].split", "[].split", "tokens[].split", "tokens[].split", "tokens[].split", "tokens[].split"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "parseStanford", "(", "stanfordfn", ")", ":", "\n", "    ", "doc", "=", "{", "}", "\n", "token_dict_offset0", "=", "{", "}", "\n", "token_dict_offset1", "=", "{", "}", "\n", "for", "line", "in", "open", "(", "stanfordfn", ")", ":", "\n", "        ", "line", "=", "line", ".", "rstrip", "(", ")", "\n", "tokens", "=", "line", ".", "split", "(", "'\\t'", ")", "\n", "if", "not", "line", ":", "continue", "\n", "if", "tokens", "[", "2", "]", ".", "startswith", "(", "'sentence'", ")", ":", "\n", "            ", "sentid", "=", "int", "(", "tokens", "[", "2", "]", ".", "split", "(", "'\"'", ")", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "offset0", "=", "int", "(", "tokens", "[", "0", "]", ")", "\n", "offset1", "=", "int", "(", "tokens", "[", "1", "]", ")", "\n", "doc", "[", "sentid", "]", "=", "{", "'offset'", ":", "[", "offset0", ",", "offset1", "]", ",", "'tokens'", ":", "{", "}", "}", "\n", "", "else", ":", "\n", "            ", "offset0", "=", "int", "(", "tokens", "[", "0", "]", ")", "\n", "offset1", "=", "int", "(", "tokens", "[", "1", "]", ")", "\n", "tokid", "=", "int", "(", "tokens", "[", "2", "]", ".", "split", "(", "'\"'", ")", "[", "1", "]", "[", "1", ":", "]", ")", "\n", "dephead", "=", "tokens", "[", "2", "]", ".", "split", "(", "'\"'", ")", "[", "-", "2", "]", "\n", "if", "dephead", "==", "\"ROOT\"", ":", "\n", "                ", "dephead", "=", "0", "\n", "", "else", ":", "\n", "                ", "dephead", "=", "int", "(", "dephead", "[", "1", ":", "]", ")", "\n", "", "pos", "=", "tokens", "[", "2", "]", ".", "split", "(", ")", "[", "3", "]", ".", "split", "(", "'\"'", ")", "[", "1", "]", "\n", "deptype", "=", "tokens", "[", "2", "]", ".", "split", "(", ")", "[", "-", "1", "]", ".", "split", "(", "'='", ")", "[", "0", "]", "\n", "token_dict_offset0", "[", "offset0", "]", "=", "{", "'dephead'", ":", "dephead", ",", "\"pos\"", ":", "pos", ",", "\"deptype\"", ":", "deptype", ",", "'sentid'", ":", "sentid", ",", "'tokenid'", ":", "tokid", "}", "\n", "token_dict_offset1", "[", "offset1", "]", "=", "{", "'dephead'", ":", "dephead", ",", "\"pos\"", ":", "pos", ",", "\"deptype\"", ":", "deptype", ",", "'sentid'", ":", "sentid", ",", "'tokenid'", ":", "tokid", "}", "\n", "\n", "", "", "return", "doc", ",", "token_dict_offset0", ",", "token_dict_offset1", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.preprocess.ace2json.Ace2json": [[91, 137], ["[].replace", "print", "open", "open.read", "text.rstrip.rstrip", "text.rstrip.split", "len", "docs.append", "line.split", "sentence_ids.append", "tuple", "ner[].append", "relations[].append", "ids.append", "range", "range", "pdb.set_trace", "pdb.set_trace", "txtfn.split", "len", "len"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "Ace2json", "(", "entity_dir", ",", "rel_dir", ",", "token_dict_offset1", ",", "token_dict_offset2", ",", "txtfn", ",", "docs", ",", "nercount", ",", "relcount", ",", "sentcount", ")", ":", "\n", "    ", "fn", "=", "txtfn", ".", "split", "(", "'/'", ")", "[", "-", "1", "]", ".", "replace", "(", "'.split.txt'", ",", "''", ")", "\n", "print", "(", "fn", ")", "\n", "fid", "=", "open", "(", "txtfn", ")", "\n", "text", "=", "fid", ".", "read", "(", ")", "\n", "text", "=", "text", ".", "rstrip", "(", ")", "\n", "sentences", "=", "text", ".", "split", "(", "'\\n'", ")", "\n", "sentences", "=", "[", "line", ".", "split", "(", ")", "for", "line", "in", "sentences", "]", "\n", "sentcount", "+=", "len", "(", "sentences", ")", "\n", "sentence_ids", "=", "[", "]", "\n", "i", "=", "0", "\n", "for", "sentence", "in", "sentences", ":", "\n", "        ", "ids", "=", "[", "]", "\n", "for", "word", "in", "sentence", ":", "\n", "            ", "ids", ".", "append", "(", "i", ")", "\n", "i", "+=", "1", "\n", "", "sentence_ids", ".", "append", "(", "ids", ")", "\n", "\n", "", "ner", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "sentences", ")", ")", "]", "\n", "relations", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "sentences", ")", ")", "]", "\n", "\n", "for", "entity", "in", "entity_dir", ":", "\n", "        ", "offsets", "=", "tuple", "(", "entity_dir", "[", "entity", "]", "[", "'offset'", "]", ")", "\n", "if", "offsets", "[", "0", "]", "in", "token_dict_offset1", ":", "\n", "            ", "offset0", "=", "token_dict_offset1", "[", "offsets", "[", "0", "]", "]", "\n", "tokenid0", "=", "offset0", "[", "'tokenid'", "]", "\n", "", "else", ":", "\n", "            ", "pdb", ".", "set_trace", "(", ")", "\n", "", "if", "offsets", "[", "1", "]", "in", "token_dict_offset2", ":", "\n", "            ", "offset1", "=", "token_dict_offset2", "[", "offsets", "[", "1", "]", "]", "\n", "tokenid1", "=", "offset1", "[", "'tokenid'", "]", "\n", "", "else", ":", "\n", "            ", "pdb", ".", "set_trace", "(", ")", "\n", "", "ner", "[", "offset0", "[", "'sentid'", "]", "]", ".", "append", "(", "[", "tokenid0", ",", "tokenid1", ",", "entity_dir", "[", "entity", "]", "[", "'ner'", "]", "]", ")", "\n", "nercount", "+=", "1", "\n", "", "for", "relation", "in", "rel_dir", ":", "\n", "        ", "arg1", "=", "rel_dir", "[", "relation", "]", "[", "'arg1'", "]", "\n", "arg2", "=", "rel_dir", "[", "relation", "]", "[", "'arg2'", "]", "\n", "tokid0", "=", "token_dict_offset1", "[", "entity_dir", "[", "arg1", "]", "[", "'offset'", "]", "[", "0", "]", "]", "[", "'tokenid'", "]", "\n", "tokid1", "=", "token_dict_offset2", "[", "entity_dir", "[", "arg1", "]", "[", "'offset'", "]", "[", "1", "]", "]", "[", "'tokenid'", "]", "\n", "tokid2", "=", "token_dict_offset1", "[", "entity_dir", "[", "arg2", "]", "[", "'offset'", "]", "[", "0", "]", "]", "[", "'tokenid'", "]", "\n", "tokid3", "=", "token_dict_offset2", "[", "entity_dir", "[", "arg2", "]", "[", "'offset'", "]", "[", "1", "]", "]", "[", "'tokenid'", "]", "\n", "relations", "[", "token_dict_offset1", "[", "entity_dir", "[", "arg1", "]", "[", "'offset'", "]", "[", "0", "]", "]", "[", "'sentid'", "]", "]", ".", "append", "(", "[", "tokid0", ",", "tokid1", ",", "tokid2", ",", "tokid3", ",", "rel_dir", "[", "relation", "]", "[", "'relation'", "]", "]", ")", "\n", "relcount", "+=", "1", "\n", "", "docs", ".", "append", "(", "{", "\"sentences\"", ":", "sentences", ",", "\"ner\"", ":", "ner", ",", "\"relations\"", ":", "relations", ",", "\"clusters\"", ":", "[", "]", ",", "\"doc_key\"", ":", "fn", "}", ")", "\n", "return", "nercount", ",", "relcount", ",", "sentcount", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.preprocess.ace2json.WriteDocs": [[138, 143], ["open", "f.write", "f.write", "json.dumps"], "function", ["None"], ["", "def", "WriteDocs", "(", "docs", ",", "outfn", ")", ":", "\n", "    ", "with", "open", "(", "outfn", ",", "'w'", ")", "as", "f", ":", "\n", "        ", "for", "relation", "in", "docs", ":", "\n", "            ", "f", ".", "write", "(", "json", ".", "dumps", "(", "relation", ")", ")", "\n", "f", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.TokSpan.align": [[44, 49], ["parse_ace_event.get_token_indices", "parse_ace_event.get_token_indices", "parse_ace_event.get_token_indices", "str", "sent.as_doc", "sent.as_doc"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.get_token_indices", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.get_token_indices", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.get_token_indices"], ["def", "align", "(", "self", ",", "sent", ")", ":", "\n", "        ", "self", ".", "span_doc", "=", "get_token_indices", "(", "self", ",", "sent", ")", "\n", "self", ".", "span_sentence", "=", "get_token_indices", "(", "self", ",", "sent", ".", "as_doc", "(", ")", ")", "\n", "self", ".", "adjusted_span_sentence", "=", "get_token_indices", "(", "self", ",", "sent", ".", "as_doc", "(", ")", ")", "\n", "self", ".", "adjusted_text_string", "=", "str", "(", "self", ".", "text_string", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.TokSpan.adjust": [[50, 58], ["parse_ace_event.in_between", "parse_ace_event.TokSpan.adjusted_text_string.replace", "tuple"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.in_between"], ["", "def", "adjust", "(", "self", ",", "tok", ")", ":", "\n", "        ", "if", "in_between", "(", "tok", ".", "i", ",", "self", ".", "span_sentence", ")", ":", "\n", "            ", "assert", "tok", ".", "text", "==", "\"\\n\"", "or", "tok", ".", "text", "==", "\" \"", "# Either a newline or an occasional whitespace.", "\n", "self", ".", "adjusted_text_string", "=", "self", ".", "adjusted_text_string", ".", "replace", "(", "\"\\n\"", ",", "\" \"", ")", "\n", "self", ".", "adjusted_span_sentence", "=", "(", "self", ".", "adjusted_span_sentence", "[", "0", "]", ",", "\n", "self", ".", "adjusted_span_sentence", "[", "1", "]", "-", "1", ")", "\n", "", "elif", "tok", ".", "i", "<", "self", ".", "span_sentence", "[", "0", "]", ":", "\n", "            ", "self", ".", "adjusted_span_sentence", "=", "tuple", "(", "[", "x", "-", "1", "for", "x", "in", "self", ".", "adjusted_span_sentence", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.TokSpan.adjust_spans_doc": [[59, 61], ["tuple"], "methods", ["None"], ["", "", "def", "adjust_spans_doc", "(", "self", ",", "entry_start", ")", ":", "\n", "        ", "self", ".", "adjusted_span_doc", "=", "tuple", "(", "[", "x", "+", "entry_start", "for", "x", "in", "self", ".", "adjusted_span_sentence", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entity.to_json": [[69, 71], ["None"], "methods", ["None"], ["def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "[", "*", "self", ".", "adjusted_span_doc", ",", "self", ".", "mention_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Relation.align": [[85, 88], ["parse_ace_event.Relation.arg1.align", "parse_ace_event.Relation.arg2.align"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align"], ["def", "align", "(", "self", ",", "sent", ")", ":", "\n", "        ", "self", ".", "arg1", ".", "align", "(", "sent", ")", "\n", "self", ".", "arg2", ".", "align", "(", "sent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Relation.adjust": [[89, 92], ["parse_ace_event.Relation.arg1.adjust", "parse_ace_event.Relation.arg2.adjust"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust"], ["", "def", "adjust", "(", "self", ",", "tok", ")", ":", "\n", "        ", "self", ".", "arg1", ".", "adjust", "(", "tok", ")", "\n", "self", ".", "arg2", ".", "adjust", "(", "tok", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Relation.adjust_spans_doc": [[93, 96], ["parse_ace_event.Relation.arg1.adjust_spans_doc", "parse_ace_event.Relation.arg2.adjust_spans_doc"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc"], ["", "def", "adjust_spans_doc", "(", "self", ",", "entry_start", ")", ":", "\n", "        ", "self", ".", "arg1", ".", "adjust_spans_doc", "(", "entry_start", ")", "\n", "self", ".", "arg2", ".", "adjust_spans_doc", "(", "entry_start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Relation.to_json": [[97, 99], ["None"], "methods", ["None"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "return", "[", "*", "self", ".", "arg1", ".", "adjusted_span_doc", ",", "*", "self", ".", "arg2", ".", "adjusted_span_doc", ",", "self", ".", "relation_type", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Event.align": [[118, 122], ["parse_ace_event.Event.trigger.align", "arg.align"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align"], ["def", "align", "(", "self", ",", "sent", ")", ":", "\n", "        ", "self", ".", "trigger", ".", "align", "(", "sent", ")", "\n", "for", "arg", "in", "self", ".", "arguments", ":", "\n", "            ", "arg", ".", "align", "(", "sent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Event.adjust": [[123, 127], ["parse_ace_event.Event.trigger.adjust", "arg.adjust"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust"], ["", "", "def", "adjust", "(", "self", ",", "tok", ")", ":", "\n", "        ", "self", ".", "trigger", ".", "adjust", "(", "tok", ")", "\n", "for", "arg", "in", "self", ".", "arguments", ":", "\n", "            ", "arg", ".", "adjust", "(", "tok", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Event.adjust_spans_doc": [[128, 132], ["parse_ace_event.Event.trigger.adjust_spans_doc", "arg.adjust_spans_doc"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc"], ["", "", "def", "adjust_spans_doc", "(", "self", ",", "entry_start", ")", ":", "\n", "        ", "self", ".", "trigger", ".", "adjust_spans_doc", "(", "entry_start", ")", "\n", "for", "arg", "in", "self", ".", "arguments", ":", "\n", "            ", "arg", ".", "adjust_spans_doc", "(", "entry_start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Event.to_json": [[133, 144], ["args.append", "sorted"], "methods", ["None"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "trigger_span", "=", "self", ".", "trigger", ".", "adjusted_span_doc", "\n", "assert", "trigger_span", "[", "0", "]", "==", "trigger_span", "[", "1", "]", "\n", "trigger", "=", "[", "[", "trigger_span", "[", "0", "]", ",", "self", ".", "trigger", ".", "trigger_type", "]", "]", "\n", "args", "=", "[", "]", "\n", "for", "arg", "in", "self", ".", "arguments", ":", "\n", "# Collapse time argument roles following Bishan.", "\n", "            ", "arg_role", "=", "\"Time\"", "if", "\"Time\"", "in", "arg", ".", "argument_role", "else", "arg", ".", "argument_role", "\n", "args", ".", "append", "(", "[", "*", "arg", ".", "adjusted_span_doc", ",", "arg_role", "]", ")", "\n", "", "res", "=", "trigger", "+", "sorted", "(", "args", ")", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align": [[153, 160], ["entity.align", "relation.align", "event.align"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align"], ["def", "align", "(", "self", ")", ":", "\n", "        ", "for", "entity", "in", "self", ".", "entities", ":", "\n", "            ", "entity", ".", "align", "(", "self", ".", "sent", ")", "\n", "", "for", "relation", "in", "self", ".", "relations", ":", "\n", "            ", "relation", ".", "align", "(", "self", ".", "sent", ")", "\n", "", "for", "event", "in", "self", ".", "events", ":", "\n", "            ", "event", ".", "align", "(", "self", ".", "sent", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.remove_whitespace": [[161, 170], ["parse_ace_event.Entry.align", "parse_ace_event.Entry.sent.as_doc", "parse_ace_event.Entry.adjust", "final_toks.append"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.align", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust"], ["", "", "def", "remove_whitespace", "(", "self", ")", ":", "\n", "        ", "final_toks", "=", "[", "]", "\n", "self", ".", "align", "(", ")", "\n", "for", "tok", "in", "self", ".", "sent", ".", "as_doc", "(", ")", ":", "\n", "            ", "if", "tok", ".", "is_space", ":", "\n", "                ", "self", ".", "adjust", "(", "tok", ")", "\n", "", "else", ":", "\n", "                ", "final_toks", ".", "append", "(", "tok", ")", "\n", "", "", "self", ".", "final_toks", "=", "final_toks", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust": [[171, 178], ["entity.adjust", "relation.adjust", "event.adjust"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust"], ["", "def", "adjust", "(", "self", ",", "tok", ")", ":", "\n", "        ", "for", "entity", "in", "self", ".", "entities", ":", "\n", "            ", "entity", ".", "adjust", "(", "tok", ")", "\n", "", "for", "relation", "in", "self", ".", "relations", ":", "\n", "            ", "relation", ".", "adjust", "(", "tok", ")", "\n", "", "for", "event", "in", "self", ".", "events", ":", "\n", "            ", "event", ".", "adjust", "(", "tok", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.adjust_spans_doc": [[179, 187], ["entity.adjust_spans_doc", "relation.adjust_spans_doc", "event.adjust_spans_doc"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc"], ["", "", "def", "adjust_spans_doc", "(", "self", ",", "entry_start", ")", ":", "\n", "        ", "self", ".", "adjusted_start", "=", "entry_start", "\n", "for", "entity", "in", "self", ".", "entities", ":", "\n", "            ", "entity", ".", "adjust_spans_doc", "(", "entry_start", ")", "\n", "", "for", "relation", "in", "self", ".", "relations", ":", "\n", "            ", "relation", ".", "adjust_spans_doc", "(", "entry_start", ")", "\n", "", "for", "event", "in", "self", ".", "events", ":", "\n", "            ", "event", ".", "adjust_spans_doc", "(", "entry_start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.to_json": [[188, 197], ["sorted", "sorted", "sorted", "dict", "entity.to_json", "relation.to_json", "event.to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "self", ".", "entities", "=", "sorted", "(", "self", ".", "entities", ",", "key", "=", "lambda", "x", ":", "x", ".", "span_sentence", ")", "\n", "ner", "=", "[", "entity", ".", "to_json", "(", ")", "for", "entity", "in", "self", ".", "entities", "]", "\n", "ner_flavors", "=", "[", "entity", ".", "flavor", "for", "entity", "in", "self", ".", "entities", "]", "\n", "relations", "=", "sorted", "(", "[", "relation", ".", "to_json", "(", ")", "for", "relation", "in", "self", ".", "relations", "]", ")", "\n", "events", "=", "sorted", "(", "[", "event", ".", "to_json", "(", ")", "for", "event", "in", "self", ".", "events", "]", ")", "\n", "sentences", "=", "[", "tok", ".", "text", "for", "tok", "in", "self", ".", "final_toks", "]", "\n", "return", "dict", "(", "sentences", "=", "sentences", ",", "ner", "=", "ner", ",", "relations", "=", "relations", ",", "\n", "events", "=", "events", ",", "_sentence_start", "=", "self", ".", "adjusted_start", ",", "ner_flavor", "=", "ner_flavors", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.is_real": [[198, 210], ["len", "len", "len", "len"], "methods", ["None"], ["", "def", "is_real", "(", "self", ")", ":", "\n", "# If no tokens, make sure it's got no entities or anything.", "\n", "        ", "n_toks", "=", "len", "(", "self", ".", "final_toks", ")", "\n", "# Get rid of empty sentences", "\n", "n_entities", "=", "len", "(", "self", ".", "entities", ")", "\n", "n_relations", "=", "len", "(", "self", ".", "relations", ")", "\n", "n_events", "=", "len", "(", "self", ".", "events", ")", "\n", "if", "n_toks", "==", "0", ":", "\n", "            ", "assert", "n_entities", "==", "n_relations", "==", "n_events", "==", "0", "\n", "return", "False", "\n", "", "else", ":", "\n", "            ", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.__init__": [[213, 216], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "entries", ",", "doc_key", ")", ":", "\n", "        ", "self", ".", "entries", "=", "entries", "\n", "self", ".", "doc_key", "=", "doc_key", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.remove_whitespace": [[217, 221], ["entry.remove_whitespace", "entry.is_real"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.remove_whitespace", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Entry.is_real"], ["", "def", "remove_whitespace", "(", "self", ")", ":", "\n", "        ", "for", "entry", "in", "self", ".", "entries", ":", "\n", "            ", "entry", ".", "remove_whitespace", "(", ")", "\n", "", "self", ".", "entries", "=", "[", "entry", "for", "entry", "in", "self", ".", "entries", "if", "entry", ".", "is_real", "(", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc": [[222, 230], ["numpy.cumsum", "numpy.roll", "zip", "len", "entry.adjust_spans_doc"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc"], ["", "def", "adjust_spans_doc", "(", "self", ")", ":", "\n", "# Get the token starts of the sentence", "\n", "        ", "entry_lengths", "=", "[", "len", "(", "entry", ".", "final_toks", ")", "for", "entry", "in", "self", ".", "entries", "]", "\n", "entry_starts", "=", "np", ".", "cumsum", "(", "entry_lengths", ")", "\n", "entry_starts", "=", "np", ".", "roll", "(", "entry_starts", ",", "1", ")", "\n", "entry_starts", "[", "0", "]", "=", "0", "\n", "for", "entry", ",", "start", "in", "zip", "(", "self", ".", "entries", ",", "entry_starts", ")", ":", "\n", "            ", "entry", ".", "adjust_spans_doc", "(", "start", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.to_json": [[231, 241], ["parse_ace_event.Doc.remove_whitespace", "parse_ace_event.Doc.adjust_spans_doc", "entry.to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.remove_whitespace", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Doc.adjust_spans_doc", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "self", ".", "remove_whitespace", "(", ")", "\n", "self", ".", "adjust_spans_doc", "(", ")", "\n", "by_entry", "=", "[", "entry", ".", "to_json", "(", ")", "for", "entry", "in", "self", ".", "entries", "]", "\n", "res", "=", "{", "}", "\n", "for", "field", "in", "[", "\"sentences\"", ",", "\"ner\"", ",", "\"relations\"", ",", "\"events\"", ",", "\"_sentence_start\"", "]", ":", "\n", "            ", "res", "[", "field", "]", "=", "[", "entry", "[", "field", "]", "for", "entry", "in", "by_entry", "]", "\n", "", "res", "[", "\"doc_key\"", "]", "=", "self", ".", "doc_key", "\n", "res", "[", "\"dataset\"", "]", "=", "\"ace-event\"", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.__init__": [[271, 301], ["xml.parse", "parse_ace_event.Document._load_text", "parse_ace_event.Document._make_nlp", "collections.defaultdict", "collections.defaultdict", "parse_ace_event.Document._populate_entity_list", "parse_ace_event.Document._populate_entity_lookup", "parse_ace_event.Document._populate_event_list", "parse_ace_event.Document._populate_relation_list"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._load_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._make_nlp", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_entity_list", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_entity_lookup", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_event_list", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_relation_list"], ["    ", "def", "__init__", "(", "self", ",", "annotation_path", ",", "text_path", ",", "doc_key", ",", "fold", ",", "heads_only", "=", "True", ",", "\n", "real_entities_only", "=", "True", ",", "include_pronouns", "=", "False", ",", "include_entity_coreference", "=", "False", ",", "include_event_coreference", "=", "False", ")", ":", "\n", "        ", "'''\n        A base class for ACE xml annotation\n        :param annotation_path:\n        :param text_path:\n        '''", "\n", "self", ".", "_heads_only", "=", "heads_only", "\n", "self", ".", "_real_entities_only", "=", "real_entities_only", "\n", "self", ".", "_include_entity_coreference", "=", "include_entity_coreference", "\n", "self", ".", "_include_event_coreference", "=", "include_event_coreference", "\n", "self", ".", "_doc_key", "=", "doc_key", "\n", "self", ".", "_annotation_path", "=", "annotation_path", "\n", "self", ".", "_annotation_xml", "=", "ET", ".", "parse", "(", "self", ".", "_annotation_path", ")", "\n", "self", ".", "_text_path", "=", "text_path", "\n", "self", ".", "_text", "=", "self", ".", "_load_text", "(", "text_path", ")", "\n", "self", ".", "doc", "=", "self", ".", "_make_nlp", "(", "self", ".", "_text", ")", "\n", "assert", "self", ".", "doc", ".", "text", "==", "self", ".", "_text", "\n", "self", ".", "entity_mention_clusters", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "event_mention_clusters", "=", "defaultdict", "(", "list", ")", "\n", "self", ".", "entity_list", ",", "self", ".", "entity_ids", "=", "self", ".", "_populate_entity_list", "(", ")", "\n", "self", ".", "entity_lookup", "=", "self", ".", "_populate_entity_lookup", "(", ")", "\n", "if", "self", ".", "_real_entities_only", ":", "\n", "            ", "self", ".", "_allowed_flavors", "=", "[", "\"entity\"", ",", "\"pronoun\"", "]", "if", "include_pronouns", "else", "[", "\"entity\"", "]", "\n", "self", ".", "entity_list", "=", "[", "x", "for", "x", "in", "self", ".", "entity_list", "if", "x", ".", "flavor", "in", "self", ".", "_allowed_flavors", "]", "\n", "", "else", ":", "\n", "            ", "self", ".", "_allowed_flavors", "=", "None", "\n", "", "self", ".", "event_list", "=", "self", ".", "_populate_event_list", "(", ")", "\n", "self", ".", "relation_list", "=", "self", ".", "_populate_relation_list", "(", ")", "\n", "self", ".", "_fold", "=", "fold", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._make_nlp": [[302, 384], ["spacy.load", "spacy.load.add_pipe", "spacy.load.", "enumerate", "spacy.load.tokenizer.add_special_case", "special_case.upper", "spacy.load.tokenizer.add_special_case", "special_case.capitalize", "spacy.load.tokenizer.add_special_case", "dict", "dict", "dict", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "_make_nlp", "(", "self", ",", "text", ")", ":", "\n", "        ", "'''\n        Add a few special cases to spacy tokenizer so it works with ACe mistakes.\n        '''", "\n", "# Prevent edge case where there are sentence breaks in bad places", "\n", "def", "custom_seg", "(", "doc", ")", ":", "\n", "            ", "for", "index", ",", "token", "in", "enumerate", "(", "doc", ")", ":", "\n", "                ", "if", "self", ".", "_doc_key", "==", "\"AFP_ENG_20030417.0307\"", ":", "\n", "                    ", "if", "token", ".", "text", "==", "\"Ivanov\"", ":", "\n", "                        ", "token", ".", "sent_start", "=", "False", "\n", "", "", "if", "'--'", "in", "token", ".", "text", ":", "\n", "                    ", "doc", "[", "index", "]", ".", "sent_start", "=", "False", "\n", "doc", "[", "index", "+", "1", "]", ".", "sent_start", "=", "False", "\n", "", "if", "token", ".", "text", "==", "\"things\"", "and", "doc", "[", "index", "+", "1", "]", ".", "text", "==", "\"their\"", ":", "\n", "                    ", "doc", "[", "index", "+", "1", "]", ".", "sent_start", "=", "False", "\n", "", "if", "(", "token", ".", "text", "==", "\"Explosions\"", "and", "\n", "token", ".", "i", "<", "len", "(", "doc", ")", "and", "\n", "doc", "[", "index", "-", "1", "]", ".", "text", "==", "\".\"", "and", "\n", "doc", "[", "index", "-", "2", "]", ".", "text", "==", "\"Baghdad\"", ")", ":", "\n", "                    ", "token", ".", "sent_start", "=", "True", "\n", "# Comma followed by whitespace doesn't end a sentence.", "\n", "", "if", "token", ".", "text", "==", "\",\"", "and", "doc", "[", "index", "+", "1", "]", ".", "is_space", ":", "\n", "                    ", "doc", "[", "index", "+", "2", "]", ".", "sent_start", "=", "False", "\n", "# \"And\" only starts a sentence if preceded by period or question mark.", "\n", "", "if", "token", ".", "text", "in", "[", "\"and\"", ",", "\"but\"", "]", "and", "doc", "[", "index", "-", "1", "]", ".", "text", "not", "in", "[", "\".\"", ",", "\"?\"", ",", "\"!\"", "]", ":", "\n", "                    ", "doc", "[", "index", "]", ".", "sent_start", "=", "False", "\n", "", "if", "(", "not", "(", "(", "token", ".", "is_punct", "and", "token", ".", "text", "not", "in", "[", "\",\"", ",", "\"_\"", ",", "\";\"", ",", "\"...\"", ",", "\":\"", ",", "\"(\"", ",", "\")\"", ",", "'\"'", "]", ")", "or", "token", ".", "is_space", ")", "\n", "and", "index", "<", "len", "(", "doc", ")", "-", "1", ")", ":", "\n", "                    ", "doc", "[", "index", "+", "1", "]", ".", "sent_start", "=", "False", "\n", "", "if", "\"\\n\"", "in", "token", ".", "text", ":", "\n", "                    ", "if", "index", "+", "1", "<", "len", "(", "doc", ")", ":", "\n", "                        ", "next_token", "=", "doc", "[", "index", "+", "1", "]", "\n", "if", "len", "(", "token", ")", ">", "1", ":", "\n", "                            ", "next_token", ".", "sent_start", "=", "True", "\n", "", "else", ":", "\n", "                            ", "next_token", ".", "sent_start", "=", "False", "\n", "", "", "", "if", "token", ".", "text", "==", "\"-\"", ":", "\n", "                    ", "before", "=", "doc", "[", "index", "-", "1", "]", "\n", "after", "=", "doc", "[", "index", "+", "1", "]", "\n", "if", "not", "(", "before", ".", "is_space", "or", "before", ".", "is_punct", "or", "after", ".", "is_space", "or", "after", ".", "is_punct", ")", ":", "\n", "                        ", "after", ".", "sent_start", "=", "False", "\n", "", "", "", "return", "doc", "\n", "\n", "", "nlp", "=", "spacy", ".", "load", "(", "'en_core_web_sm'", ")", "\n", "nlp", ".", "add_pipe", "(", "custom_seg", ",", "before", "=", "'parser'", ")", "\n", "\n", "single_tokens", "=", "[", "'sgt.'", ",", "\n", "'sen.'", ",", "\n", "'col.'", ",", "\n", "'brig.'", ",", "\n", "'gen.'", ",", "\n", "'maj.'", ",", "\n", "'sr.'", ",", "\n", "'lt.'", ",", "\n", "'cmdr.'", ",", "\n", "'u.s.'", ",", "\n", "'mr.'", ",", "\n", "'p.o.w.'", ",", "\n", "'u.k.'", ",", "\n", "'u.n.'", ",", "\n", "'ft.'", ",", "\n", "'dr.'", ",", "\n", "'d.c.'", ",", "\n", "'mt.'", ",", "\n", "'st.'", ",", "\n", "'snr.'", ",", "\n", "'rep.'", ",", "\n", "'ms.'", ",", "\n", "'capt.'", ",", "\n", "'sq.'", ",", "\n", "'jr.'", ",", "\n", "'ave.'", "]", "\n", "for", "special_case", "in", "single_tokens", ":", "\n", "            ", "nlp", ".", "tokenizer", ".", "add_special_case", "(", "special_case", ",", "[", "dict", "(", "ORTH", "=", "special_case", ")", "]", ")", "\n", "upped", "=", "special_case", ".", "upper", "(", ")", "\n", "nlp", ".", "tokenizer", ".", "add_special_case", "(", "upped", ",", "[", "dict", "(", "ORTH", "=", "upped", ")", "]", ")", "\n", "capped", "=", "special_case", ".", "capitalize", "(", ")", "\n", "nlp", ".", "tokenizer", ".", "add_special_case", "(", "capped", ",", "[", "dict", "(", "ORTH", "=", "capped", ")", "]", ")", "\n", "\n", "", "doc", "=", "nlp", "(", "text", ")", "\n", "assert", "doc", ".", "text", "==", "text", "\n", "return", "doc", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._load_text": [[385, 405], ["re.compile", "re.compile.sub", "text_data.replace.replace.replace", "text_data.replace.replace.replace", "open", "f.read", "text_data.replace.replace.replace"], "methods", ["None"], ["", "def", "_load_text", "(", "self", ",", "text_path", ")", ":", "\n", "        ", "'''\n        Load in text and strip out tags.\n        '''", "\n", "with", "open", "(", "text_path", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "text_data", "=", "f", ".", "read", "(", ")", "\n", "\n", "# Get rid of XML tags.", "\n", "", "remove_tags", "=", "re", ".", "compile", "(", "'<.*?>'", ",", "re", ".", "DOTALL", ")", "# Also match expressions with a newline in the middle.", "\n", "text_data", "=", "remove_tags", ".", "sub", "(", "\"\"", ",", "text_data", ")", "\n", "\n", "# Fix errors in ACE.", "\n", "text_data", "=", "text_data", ".", "replace", "(", "\"dr. germ. the\"", ",", "\"dr. germ, the\"", ")", "\n", "text_data", "=", "text_data", ".", "replace", "(", "\"arms inspectors. 300 miles west\"", ",", "\n", "\"arms inspectors, 300 miles west\"", ")", "\n", "\n", "if", "self", ".", "_doc_key", "in", "[", "\"APW_ENG_20030327.0376\"", ",", "\"APW_ENG_20030519.0367\"", "]", ":", "\n", "            ", "text_data", "=", "text_data", ".", "replace", "(", "\"_\"", ",", "\"-\"", ")", "\n", "\n", "", "return", "text_data", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_chars": [[406, 424], ["parse_ace_event.Document.doc.char_span", "parse_ace_event.get_token_of", "parse_ace_event.get_token_of", "parse_ace_event.MultiTokenTrigerException", "parse_ace_event.Document.doc.char_span", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.get_token_of", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.get_token_of"], ["", "def", "_get_chars", "(", "self", ",", "start_char", ",", "end_char", ",", "trigger", "=", "False", ")", ":", "\n", "        ", "the_text", "=", "self", ".", "doc", ".", "char_span", "(", "start_char", ",", "end_char", "+", "1", ")", "\n", "start_tok", "=", "get_token_of", "(", "self", ".", "doc", ",", "start_char", ")", "\n", "end_tok", "=", "get_token_of", "(", "self", ".", "doc", ",", "end_char", ")", "\n", "if", "trigger", "and", "start_tok", "!=", "end_tok", ":", "\n", "            ", "raise", "MultiTokenTrigerException", "(", ")", "\n", "# # If the trigger is multiple words, get the highest token in the dependency parse.", "\n", "# the_root = self.doc[start_tok.i:end_tok.i + 1].root", "\n", "# start_char = the_root.idx", "\n", "# end_char = start_char + len(the_root) - 1", "\n", "# the_text = the_root.text", "\n", "", "elif", "the_text", "is", "None", ":", "\n", "# Otherwise, just take all spans containing the entity.", "\n", "            ", "start_char", "=", "start_tok", ".", "idx", "\n", "end_char", "=", "end_tok", ".", "idx", "+", "len", "(", "end_tok", ")", "-", "1", "\n", "the_text", "=", "self", ".", "doc", ".", "char_span", "(", "start_char", ",", "end_char", "+", "1", ")", "\n", "\n", "", "return", "start_char", ",", "end_char", ",", "the_text", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_entity_list": [[425, 503], ["parse_ace_event.Document._annotation_xml.getroot", "xml_root[].findall", "xml_root[].findall", "xml_root[].findall", "entity_ids.append", "one_entity.findall", "entity_ids.append", "one_value.findall", "entity_ids.append", "one_timex2.findall", "int", "int", "parse_ace_event.Document._get_chars", "parse_ace_event.Entity", "res.append", "parse_ace_event.Document.entity_mention_clusters[].append", "int", "int", "parse_ace_event.Document._get_chars", "parse_ace_event.Entity", "res.append", "int", "int", "parse_ace_event.Document._get_chars", "set", "parse_ace_event.Entity", "res.append", "one_entity_mention.find", "one_entity_mention.find", "one_value_mention.find", "one_value_mention.find", "one_timex2_mention.find", "one_timex2_mention.find"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_chars", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_chars", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_chars"], ["", "def", "_populate_entity_list", "(", "self", ")", ":", "\n", "        ", "entity_ids", "=", "[", "]", "\n", "res", "=", "[", "]", "\n", "xml_root", "=", "self", ".", "_annotation_xml", ".", "getroot", "(", ")", "\n", "field_to_find", "=", "\"head\"", "if", "self", ".", "_heads_only", "else", "\"extent\"", "\n", "for", "one_entity", "in", "xml_root", "[", "0", "]", ".", "findall", "(", "'entity'", ")", ":", "\n", "            ", "entity_id", "=", "one_entity", ".", "attrib", "[", "\"ID\"", "]", "\n", "entity_ids", ".", "append", "(", "entity_id", ")", "\n", "for", "one_entity_mention", "in", "one_entity", ".", "findall", "(", "'entity_mention'", ")", ":", "\n", "                ", "mention_id", "=", "one_entity_mention", ".", "attrib", "[", "'ID'", "]", "\n", "mention_type", "=", "one_entity", ".", "attrib", "[", "'TYPE'", "]", "\n", "# Others have only looked at the head.", "\n", "tentative_start", "=", "int", "(", "one_entity_mention", ".", "find", "(", "field_to_find", ")", "[", "0", "]", ".", "attrib", "[", "'START'", "]", ")", "\n", "tentative_end", "=", "int", "(", "one_entity_mention", ".", "find", "(", "field_to_find", ")", "[", "0", "]", ".", "attrib", "[", "'END'", "]", ")", "\n", "\n", "start_char", ",", "end_char", ",", "text_string", "=", "self", ".", "_get_chars", "(", "tentative_start", ",", "tentative_end", ")", "\n", "\n", "# Parser chokes on the space.", "\n", "if", "(", "self", ".", "_doc_key", "==", "\"soc.history.war.world-war-ii_20050127.2403\"", "and", "\n", "text_string", ".", "text", "==", "\"lesliemills2002@netscape. net\"", ")", ":", "\n", "                    ", "continue", "\n", "\n", "# Keep option to ignore pronouns.", "\n", "", "flavor", "=", "\"pronoun\"", "if", "one_entity_mention", ".", "attrib", "[", "\"TYPE\"", "]", "==", "\"PRO\"", "else", "\"entity\"", "\n", "\n", "entry", "=", "Entity", "(", "start_char", ",", "end_char", ",", "text_string", ",", "mention_id", "=", "mention_id", ",", "\n", "mention_type", "=", "mention_type", ",", "flavor", "=", "flavor", ")", "\n", "res", ".", "append", "(", "entry", ")", "\n", "self", ".", "entity_mention_clusters", "[", "entity_id", "]", ".", "append", "(", "mention_id", ")", "\n", "# Values. Values don't have heads.", "\n", "", "", "field_to_find", "=", "\"extent\"", "\n", "for", "one_value", "in", "xml_root", "[", "0", "]", ".", "findall", "(", "'value'", ")", ":", "\n", "            ", "value_id", "=", "one_value", ".", "attrib", "[", "\"ID\"", "]", "\n", "entity_ids", ".", "append", "(", "value_id", ")", "\n", "for", "one_value_mention", "in", "one_value", ".", "findall", "(", "'value_mention'", ")", ":", "\n", "                ", "mention_id", "=", "one_value_mention", ".", "attrib", "[", "'ID'", "]", "\n", "# In the AAAI 2019 paper, they lump all the values together into one label.", "\n", "mention_type", "=", "'VALUE'", "\n", "\n", "tentative_start", "=", "int", "(", "one_value_mention", ".", "find", "(", "field_to_find", ")", "[", "0", "]", ".", "attrib", "[", "'START'", "]", ")", "\n", "tentative_end", "=", "int", "(", "one_value_mention", ".", "find", "(", "field_to_find", ")", "[", "0", "]", ".", "attrib", "[", "'END'", "]", ")", "\n", "start_char", ",", "end_char", ",", "text_string", "=", "self", ".", "_get_chars", "(", "tentative_start", ",", "tentative_end", ")", "\n", "\n", "# Parser chokes on the space.", "\n", "if", "(", "self", ".", "_doc_key", "==", "\"soc.history.war.world-war-ii_20050127.2403\"", "and", "\n", "text_string", ".", "text", "==", "\"lesliemills2002@netscape. net\"", ")", ":", "\n", "                    ", "continue", "\n", "\n", "", "entry", "=", "Entity", "(", "start_char", ",", "end_char", ",", "text_string", ",", "mention_id", "=", "mention_id", ",", "\n", "mention_type", "=", "mention_type", ",", "flavor", "=", "\"value\"", ")", "\n", "res", ".", "append", "(", "entry", ")", "\n", "\n", "# Also timex2. These also don't have heads.", "\n", "", "", "field_to_find", "=", "\"extent\"", "\n", "for", "one_timex2", "in", "xml_root", "[", "0", "]", ".", "findall", "(", "'timex2'", ")", ":", "\n", "            ", "timex2_id", "=", "one_timex2", ".", "attrib", "[", "\"ID\"", "]", "\n", "entity_ids", ".", "append", "(", "timex2_id", ")", "\n", "for", "one_timex2_mention", "in", "one_timex2", ".", "findall", "(", "'timex2_mention'", ")", ":", "\n", "                ", "mention_id", "=", "one_timex2_mention", ".", "attrib", "[", "'ID'", "]", "\n", "mention_type", "=", "'TIMEX2'", "\n", "# Others have only looked at the head.", "\n", "tentative_start", "=", "int", "(", "one_timex2_mention", ".", "find", "(", "field_to_find", ")", "[", "0", "]", ".", "attrib", "[", "'START'", "]", ")", "\n", "tentative_end", "=", "int", "(", "one_timex2_mention", ".", "find", "(", "field_to_find", ")", "[", "0", "]", ".", "attrib", "[", "'END'", "]", ")", "\n", "start_char", ",", "end_char", ",", "text_string", "=", "self", ".", "_get_chars", "(", "tentative_start", ",", "tentative_end", ")", "\n", "\n", "# Crosses a sentence boundary.", "\n", "if", "self", ".", "_doc_key", "==", "\"CNN_ENG_20030508_210555.5\"", "and", "start_char", "==", "1316", "and", "end_char", "==", "1335", ":", "\n", "                    ", "continue", "\n", "# This is just ridiculous.", "\n", "", "weird_times", "=", "set", "(", "[", "\"BACONSREBELLION_20050127.1017\"", ",", "\"MARKBACKER_20041103.1300\"", "]", ")", "\n", "if", "self", ".", "_doc_key", "in", "weird_times", "and", "\"????\"", "in", "text_string", ".", "text", ":", "\n", "                    ", "continue", "\n", "\n", "", "entry", "=", "Entity", "(", "start_char", ",", "end_char", ",", "text_string", ",", "mention_id", "=", "mention_id", ",", "\n", "mention_type", "=", "mention_type", ",", "flavor", "=", "\"timex2\"", ")", "\n", "res", ".", "append", "(", "entry", ")", "\n", "\n", "", "", "return", "res", ",", "entity_ids", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_entity_lookup": [[504, 506], ["None"], "methods", ["None"], ["", "def", "_populate_entity_lookup", "(", "self", ")", ":", "\n", "        ", "return", "{", "entry", ".", "mention_id", ":", "entry", "for", "entry", "in", "self", ".", "entity_list", "}", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_event_list": [[507, 564], ["parse_ace_event.Document._annotation_xml.getroot", "xml_root[].findall", "one_event.findall", "one_event_mention.find", "parse_ace_event.EventTrigger", "one_event_mention.findall", "parse_ace_event.Document._get_chars", "parse_ace_event.EventArgument", "argument_list.append", "res.append", "parse_ace_event.Document.event_mention_clusters[].append", "int", "int", "one_event_mention_argument.find", "one_event_mention_argument.find", "parse_ace_event.Document._get_chars", "parse_ace_event.Event", "int", "int", "argument_id.split"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_chars", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_chars", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "_populate_event_list", "(", "self", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "xml_root", "=", "self", ".", "_annotation_xml", ".", "getroot", "(", ")", "\n", "for", "one_event", "in", "xml_root", "[", "0", "]", ".", "findall", "(", "'event'", ")", ":", "\n", "            ", "event_id", "=", "one_event", ".", "attrib", "[", "'ID'", "]", "\n", "for", "one_event_mention", "in", "one_event", ".", "findall", "(", "'event_mention'", ")", ":", "\n", "                ", "include", "=", "True", "\n", "trigger_id", "=", "one_event_mention", ".", "attrib", "[", "'ID'", "]", "\n", "trigger_type", "=", "'%s.%s'", "%", "(", "one_event", ".", "attrib", "[", "'TYPE'", "]", ",", "one_event", ".", "attrib", "[", "'SUBTYPE'", "]", ")", "\n", "trigger_tag", "=", "one_event_mention", ".", "find", "(", "'anchor'", ")", "\n", "try", ":", "\n", "                    ", "start_char", ",", "end_char", ",", "text_string", "=", "self", ".", "_get_chars", "(", "\n", "int", "(", "trigger_tag", "[", "0", "]", ".", "attrib", "[", "'START'", "]", ")", ",", "\n", "int", "(", "trigger_tag", "[", "0", "]", ".", "attrib", "[", "'END'", "]", ")", ",", "\n", "trigger", "=", "True", ")", "\n", "# If we hit a multi-token trigger, skip the event mention.", "\n", "", "except", "MultiTokenTrigerException", ":", "\n", "                    ", "continue", "\n", "# Buggy event. Crosses sentence. Skip it.", "\n", "", "if", "self", ".", "_doc_key", "==", "\"APW_ENG_20030308.0314\"", "and", "start_char", "==", "3263", "and", "end_char", "==", "3270", ":", "\n", "                    ", "continue", "\n", "", "if", "self", ".", "_doc_key", "==", "\"soc.history.what-if_20050129.1404\"", "and", "start_char", "==", "554", "and", "end_char", "==", "556", ":", "\n", "                    ", "continue", "\n", "", "event_trigger", "=", "EventTrigger", "(", "start_char", ",", "end_char", ",", "text_string", ",", "trigger_id", ",", "\n", "trigger_type", ")", "\n", "argument_list", "=", "[", "]", "\n", "for", "one_event_mention_argument", "in", "one_event_mention", ".", "findall", "(", "'event_mention_argument'", ")", ":", "\n", "                    ", "argument_id", "=", "one_event_mention_argument", ".", "attrib", "[", "'REFID'", "]", "\n", "if", "self", ".", "_heads_only", ":", "\n", "                        ", "assert", "argument_id", "in", "self", ".", "entity_lookup", "\n", "this_entity", "=", "self", ".", "entity_lookup", "[", "argument_id", "]", "\n", "# If we're only doing real entities and this isn't one, don't append.", "\n", "if", "self", ".", "_real_entities_only", "and", "this_entity", ".", "flavor", "not", "in", "self", ".", "_allowed_flavors", ":", "\n", "                            ", "continue", "\n", "", "start_char", ",", "end_char", ",", "text_string", "=", "(", "this_entity", ".", "start_char", ",", "\n", "this_entity", ".", "end_char", ",", "\n", "this_entity", ".", "text_string", ")", "\n", "", "else", ":", "\n", "                        ", "event_mention_argument_tag", "=", "one_event_mention_argument", ".", "find", "(", "'extent'", ")", "\n", "relation_mention_argument_tag", "=", "one_event_mention_argument", ".", "find", "(", "'extent'", ")", "\n", "start_char", ",", "end_char", ",", "text_string", "=", "self", ".", "_get_chars", "(", "\n", "int", "(", "event_mention_argument_tag", "[", "0", "]", ".", "attrib", "[", "'START'", "]", ")", ",", "\n", "int", "(", "event_mention_argument_tag", "[", "0", "]", ".", "attrib", "[", "'END'", "]", ")", ")", "\n", "\n", "# Check that we've seen the entity. If it's a value or timex, just skip it as an", "\n", "# argument.", "\n", "", "entity_id", "=", "\"-\"", ".", "join", "(", "argument_id", ".", "split", "(", "\"-\"", ")", "[", ":", "-", "1", "]", ")", "\n", "assert", "entity_id", "in", "self", ".", "entity_ids", "\n", "\n", "argument_role", "=", "one_event_mention_argument", ".", "attrib", "[", "'ROLE'", "]", "\n", "to_append", "=", "EventArgument", "(", "start_char", ",", "end_char", ",", "text_string", ",", "argument_id", ",", "\n", "argument_role", ")", "\n", "argument_list", ".", "append", "(", "to_append", ")", "\n", "", "if", "include", ":", "\n", "                    ", "res", ".", "append", "(", "Event", "(", "event_trigger", ",", "argument_list", ")", ")", "\n", "self", ".", "event_mention_clusters", "[", "event_id", "]", ".", "append", "(", "event_trigger", ".", "trigger_id", ")", "\n", "", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._populate_relation_list": [[565, 633], ["parse_ace_event.Document._annotation_xml.getroot", "xml_root[].findall", "one_relation.findall", "one_relation_mention.findall", "parse_ace_event.RelationArgument", "parse_ace_event.Relation", "one_relation_mention_argument.find", "parse_ace_event.Document._get_chars", "res.append", "int", "int", "argument_id.split"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_chars", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "_populate_relation_list", "(", "self", ")", ":", "\n", "        ", "res", "=", "[", "]", "\n", "xml_root", "=", "self", ".", "_annotation_xml", ".", "getroot", "(", ")", "\n", "for", "one_relation", "in", "xml_root", "[", "0", "]", ".", "findall", "(", "'relation'", ")", ":", "\n", "            ", "for", "one_relation_mention", "in", "one_relation", ".", "findall", "(", "'relation_mention'", ")", ":", "\n", "                ", "include", "=", "True", "\n", "relation_type", "=", "'%s.%s'", "%", "(", "one_relation", ".", "attrib", "[", "'TYPE'", "]", ",", "one_relation", ".", "attrib", "[", "'SUBTYPE'", "]", ")", "\n", "argument_dict", "=", "{", "}", "\n", "for", "one_relation_mention_argument", "in", "one_relation_mention", ".", "findall", "(", "\"relation_mention_argument\"", ")", ":", "\n", "                    ", "argument_id", "=", "one_relation_mention_argument", ".", "attrib", "[", "'REFID'", "]", "\n", "# If doing heads only, get the span by looking up the entity and getting its span.", "\n", "if", "self", ".", "_heads_only", ":", "\n", "                        ", "assert", "argument_id", "in", "self", ".", "entity_lookup", "\n", "this_entity", "=", "self", ".", "entity_lookup", "[", "argument_id", "]", "\n", "start_char", ",", "end_char", ",", "text_string", "=", "(", "this_entity", ".", "start_char", ",", "\n", "this_entity", ".", "end_char", ",", "\n", "this_entity", ".", "text_string", ")", "\n", "", "else", ":", "\n", "                        ", "relation_mention_argument_tag", "=", "one_relation_mention_argument", ".", "find", "(", "'extent'", ")", "\n", "start_char", ",", "end_char", ",", "text_string", "=", "self", ".", "_get_chars", "(", "\n", "int", "(", "relation_mention_argument_tag", "[", "0", "]", ".", "attrib", "[", "'START'", "]", ")", ",", "\n", "int", "(", "relation_mention_argument_tag", "[", "0", "]", ".", "attrib", "[", "'END'", "]", ")", ")", "\n", "\n", "# Check that we've seen the entity. If it's a value or timex, skip the event.", "\n", "", "entity_id", "=", "\"-\"", ".", "join", "(", "argument_id", ".", "split", "(", "\"-\"", ")", "[", ":", "-", "1", "]", ")", "\n", "assert", "entity_id", "in", "self", ".", "entity_ids", "\n", "\n", "relation_role", "=", "one_relation_mention_argument", ".", "attrib", "[", "'ROLE'", "]", "\n", "this_argument", "=", "RelationArgument", "(", "\n", "start_char", ",", "end_char", ",", "text_string", ",", "argument_id", ",", "relation_role", ")", "\n", "\n", "# Skip if not a real entity and we're only keeping real entities.", "\n", "if", "self", ".", "_heads_only", "and", "self", ".", "_real_entities_only", ":", "\n", "                        ", "this_entity", "=", "self", ".", "entity_lookup", "[", "this_argument", ".", "argument_id", "]", "\n", "if", "this_entity", ".", "flavor", "not", "in", "self", ".", "_allowed_flavors", ":", "\n", "                            ", "include", "=", "False", "\n", "\n", "", "", "if", "this_argument", ".", "relation_role", "==", "\"Arg-1\"", ":", "\n", "                        ", "argument_dict", "[", "\"arg1\"", "]", "=", "this_argument", "\n", "", "elif", "this_argument", ".", "relation_role", "==", "\"Arg-2\"", ":", "\n", "# This is a mis-annotated relation. Ignore it.", "\n", "                        ", "if", "(", "self", ".", "_doc_key", "==", "'CNN_ENG_20030430_093016.0'", "and", "\n", "text_string", ".", "text", "==", "\"the school in an\\nunderprivileged rural area\"", ")", ":", "\n", "                            ", "include", "=", "False", "\n", "", "if", "(", "self", ".", "_doc_key", "==", "\"CNN_ENG_20030430_093016.0\"", "and", "\n", "start_char", "==", "3091", "and", "end_char", "==", "3096", ")", ":", "\n", "                            ", "include", "=", "False", "\n", "# Crosses a sentence boundary.", "\n", "", "if", "(", "self", ".", "_doc_key", "==", "\"rec.travel.cruises_20050222.0313\"", "and", "\n", "start_char", "==", "1435", "and", "end_char", "==", "1442", ")", ":", "\n", "                            ", "include", "=", "False", "\n", "", "if", "(", "self", ".", "_doc_key", "==", "\"rec.travel.cruises_20050222.0313\"", "and", "\n", "start_char", "==", "1456", "and", "end_char", "==", "1458", ")", ":", "\n", "                            ", "include", "=", "False", "\n", "\n", "", "argument_dict", "[", "\"arg2\"", "]", "=", "this_argument", "\n", "", "else", ":", "\n", "                        ", "include", "=", "False", "\n", "", "", "if", "include", ":", "\n", "                    ", "relation", "=", "Relation", "(", "relation_type", ",", "argument_dict", "[", "\"arg1\"", "]", ",", "argument_dict", "[", "\"arg2\"", "]", ")", "\n", "# There are some examples where the identical relation mention shows up twice,", "\n", "# for instance \"young men and women in this country\" in", "\n", "# CNN_CF_20030304.1900.04.apf.xml. When this occurs, ignore it.", "\n", "if", "relation", "in", "res", ":", "\n", "                        ", "continue", "\n", "", "else", ":", "\n", "                        ", "res", ".", "append", "(", "relation", ")", "\n", "", "", "", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._check_in_range": [[634, 647], ["None"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_check_in_range", "(", "span", ",", "sent", ")", ":", "\n", "# The end character inequality must be string. since end character for spans are inclusive", "\n", "# and end characters for sentences are exclusive.", "\n", "# Raise an exception if the span crosses a sentence boundary.", "\n", "        ", "if", "span", ".", "start_char", ">=", "sent", ".", "start_char", "and", "span", ".", "end_char", "<", "sent", ".", "end_char", ":", "\n", "            ", "return", "True", "\n", "", "if", "span", ".", "end_char", "<=", "sent", ".", "start_char", ":", "\n", "            ", "return", "False", "\n", "", "if", "span", ".", "start_char", ">=", "sent", ".", "end_char", ":", "\n", "            ", "return", "False", "\n", "", "else", ":", "\n", "            ", "raise", "CrossSentenceException", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._sentence_get_ner": [[648, 675], ["parse_ace_event.Document.entity_list.remove", "parse_ace_event.Document._check_in_range", "parse_ace_event.debug_if", "parse_ace_event.Document._seen_so_far[].append", "entities.append", "to_remove.append", "print"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._check_in_range", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.debug_if"], ["", "", "def", "_sentence_get_ner", "(", "self", ",", "sent", ")", ":", "\n", "        ", "entities", "=", "[", "]", "\n", "to_remove", "=", "[", "]", "# Only relevant for full extents.", "\n", "for", "entity", "in", "self", ".", "entity_list", ":", "\n", "            ", "try", ":", "\n", "                ", "in_range", "=", "self", ".", "_check_in_range", "(", "entity", ",", "sent", ")", "\n", "# If the entity crosses a sentence boundary", "\n", "", "except", "CrossSentenceException", "as", "e", ":", "\n", "# This shouldn't happen if we're only using entity heads; raise an exception.", "\n", "                ", "if", "self", ".", "_heads_only", ":", "\n", "                    ", "raise", "e", "\n", "# With full extents this may happen; notify user and skip this example.", "\n", "", "else", ":", "\n", "# Add to list of entities that will be removed.", "\n", "                    ", "to_remove", ".", "append", "(", "entity", ")", "\n", "msg", "=", "f'Entity \"{entity.text_string}\" crosses sentence boundary. Skipping.'", "\n", "print", "(", "msg", ")", "\n", "continue", "\n", "", "", "if", "in_range", ":", "\n", "                ", "debug_if", "(", "entity", "in", "self", ".", "_seen_so_far", "[", "'entity'", "]", ")", "\n", "self", ".", "_seen_so_far", "[", "\"entity\"", "]", ".", "append", "(", "entity", ")", "\n", "entities", ".", "append", "(", "entity", ")", "\n", "# If doing full entity extents, remove entities that crossed sentence boundaries.", "\n", "", "", "for", "failure", "in", "to_remove", ":", "\n", "            ", "self", ".", "entity_list", ".", "remove", "(", "failure", ")", "\n", "\n", "", "return", "entities", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._sentence_get_relations": [[676, 694], ["all", "all", "parse_ace_event.Document._sentence_get_relations.in_range"], "methods", ["None"], ["", "def", "_sentence_get_relations", "(", "self", ",", "sent", ")", ":", "\n", "        ", "def", "in_range", "(", "candidate", ")", ":", "\n", "            ", "each_one", "=", "[", "self", ".", "_check_in_range", "(", "entry", ",", "sent", ")", "for", "entry", "in", "[", "candidate", ".", "arg1", ",", "candidate", ".", "arg2", "]", "]", "\n", "if", "all", "(", "each_one", ")", ":", "\n", "                ", "debug_if", "(", "candidate", "in", "self", ".", "_seen_so_far", "[", "'relation'", "]", ")", "\n", "return", "True", "\n", "", "if", "all", "(", "[", "not", "entry", "for", "entry", "in", "each_one", "]", ")", ":", "\n", "                ", "return", "False", "\n", "", "else", ":", "\n", "                ", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "", "relations", "=", "[", "]", "\n", "for", "relation", "in", "self", ".", "relation_list", ":", "\n", "# This is an annotation mistake and crosses sentence boundaries. Just ignore it.", "\n", "            ", "if", "in_range", "(", "relation", ")", ":", "\n", "                ", "self", ".", "_seen_so_far", "[", "\"relation\"", "]", ".", "append", "(", "relation", ")", "\n", "relations", ".", "append", "(", "relation", ")", "\n", "", "", "return", "relations", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._sentence_get_events": [[695, 716], ["all", "all", "parse_ace_event.Document._sentence_get_relations.in_range"], "methods", ["None"], ["", "def", "_sentence_get_events", "(", "self", ",", "sent", ")", ":", "\n", "        ", "def", "in_range", "(", "candidate", ")", ":", "\n", "            ", "each_one", "=", "(", "[", "self", ".", "_check_in_range", "(", "candidate", ".", "trigger", ",", "sent", ")", "]", "+", "\n", "[", "self", ".", "_check_in_range", "(", "entry", ",", "sent", ")", "for", "entry", "in", "candidate", ".", "arguments", "]", ")", "\n", "if", "all", "(", "each_one", ")", ":", "\n", "                ", "debug_if", "(", "candidate", "in", "self", ".", "_seen_so_far", "[", "'event'", "]", ")", "\n", "return", "True", "\n", "", "if", "all", "(", "[", "not", "entry", "for", "entry", "in", "each_one", "]", ")", ":", "\n", "                ", "return", "False", "\n", "", "else", ":", "\n", "                ", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "\n", "", "", "events", "=", "[", "]", "\n", "for", "event", "in", "self", ".", "event_list", ":", "\n", "# Event that crosses sentence.", "\n", "            ", "if", "in_range", "(", "event", ")", ":", "\n", "                ", "self", ".", "_seen_so_far", "[", "\"event\"", "]", ".", "append", "(", "event", ")", "\n", "trigger_span", "=", "get_token_indices", "(", "event", ".", "trigger", ",", "sent", ")", "\n", "debug_if", "(", "trigger_span", "[", "0", "]", "!=", "trigger_span", "[", "1", "]", ")", "\n", "events", ".", "append", "(", "event", ")", "\n", "", "", "return", "events", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_entry": [[717, 723], ["parse_ace_event.Document._sentence_get_ner", "parse_ace_event.Document._sentence_get_relations", "parse_ace_event.Document._sentence_get_events", "parse_ace_event.Entry"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._sentence_get_ner", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._sentence_get_relations", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._sentence_get_events"], ["", "def", "_get_entry", "(", "self", ",", "sent", ")", ":", "\n", "        ", "toks", "=", "[", "tok", "for", "tok", "in", "sent", "]", "\n", "ner", "=", "self", ".", "_sentence_get_ner", "(", "sent", ")", "\n", "rel", "=", "self", ".", "_sentence_get_relations", "(", "sent", ")", "\n", "events", "=", "self", ".", "_sentence_get_events", "(", "sent", ")", "\n", "return", "Entry", "(", "sent", "=", "sent", ",", "entities", "=", "ner", ",", "relations", "=", "rel", ",", "events", "=", "events", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._check_all_seen": [[724, 728], ["len", "len", "len", "len", "len", "len"], "methods", ["None"], ["", "def", "_check_all_seen", "(", "self", ")", ":", "\n", "        ", "assert", "len", "(", "self", ".", "_seen_so_far", "[", "\"entity\"", "]", ")", "==", "len", "(", "self", ".", "entity_list", ")", "\n", "assert", "len", "(", "self", ".", "_seen_so_far", "[", "\"relation\"", "]", ")", "==", "len", "(", "self", ".", "relation_list", ")", "\n", "assert", "len", "(", "self", ".", "_seen_so_far", "[", "\"event\"", "]", ")", "==", "len", "(", "self", ".", "event_list", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json": [[729, 778], ["dict", "parse_ace_event.Doc", "parse_ace_event.Document._check_all_seen", "parse_ace_event.Doc.to_json", "parse_ace_event.Document._get_entry", "parse_ace_event.Document.entity_mention_clusters.items", "parse_ace_event.Document.event_mention_clusters.items", "len", "mention_id2mention[].to_json", "cur_cluster.append", "len", "clusters.append", "len", "cur_cluster.append", "len", "clusters.append", "trigger_id2event_mention[].to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._check_all_seen", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document._get_entry", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "def", "to_json", "(", "self", ")", ":", "\n", "        ", "self", ".", "_seen_so_far", "=", "dict", "(", "entity", "=", "[", "]", ",", "relation", "=", "[", "]", ",", "event", "=", "[", "]", ")", "\n", "entries", "=", "[", "self", ".", "_get_entry", "(", "sent", ")", "for", "sent", "in", "self", ".", "doc", ".", "sents", "]", "\n", "doc", "=", "Doc", "(", "entries", ",", "self", ".", "_doc_key", ")", "\n", "self", ".", "_check_all_seen", "(", ")", "\n", "js", "=", "doc", ".", "to_json", "(", ")", "\n", "\n", "# create entity coreference clusters.", "\n", "if", "self", ".", "_include_entity_coreference", ":", "\n", "# mapping from mention_id to entity mention for faster computation.", "\n", "            ", "mention_id2mention", "=", "{", "entity", ".", "mention_id", ":", "entity", "for", "entry", "in", "doc", ".", "entries", "for", "entity", "in", "entry", ".", "entities", "}", "\n", "\n", "clusters", "=", "[", "]", "\n", "for", "entity_id", ",", "mention_ids", "in", "self", ".", "entity_mention_clusters", ".", "items", "(", ")", ":", "\n", "                ", "assert", "len", "(", "mention_ids", ")", ">=", "1", "\n", "cur_cluster", "=", "[", "]", "\n", "\n", "for", "mention_id", "in", "mention_ids", ":", "\n", "                    ", "if", "mention_id", "not", "in", "mention_id2mention", ":", "continue", "# invalid mention", "\n", "mention_json", "=", "mention_id2mention", "[", "mention_id", "]", ".", "to_json", "(", ")", "\n", "cur_cluster", ".", "append", "(", "mention_json", "[", ":", "2", "]", ")", "\n", "\n", "# this is indeed a cluster if cluster size > 2.", "\n", "", "if", "len", "(", "cur_cluster", ")", ">=", "2", ":", "\n", "                    ", "clusters", ".", "append", "(", "cur_cluster", ")", "\n", "", "", "js", "[", "'clusters'", "]", "=", "clusters", "\n", "\n", "# create event coreference clusters.", "\n", "", "if", "self", ".", "_include_event_coreference", ":", "\n", "\n", "# mapping from trigger id to event mention for faster computation.", "\n", "            ", "trigger_id2event_mention", "=", "{", "event", ".", "trigger", ".", "trigger_id", ":", "event", "for", "entry", "in", "doc", ".", "entries", "for", "event", "in", "entry", ".", "events", "}", "\n", "clusters", "=", "[", "]", "\n", "\n", "for", "event_id", ",", "mention_ids", "in", "self", ".", "event_mention_clusters", ".", "items", "(", ")", ":", "\n", "                ", "assert", "len", "(", "mention_ids", ")", ">=", "1", "\n", "cur_cluster", "=", "[", "]", "\n", "\n", "for", "mention_id", "in", "mention_ids", ":", "\n", "                    ", "if", "mention_id", "not", "in", "trigger_id2event_mention", ":", "continue", "# invalid mention", "\n", "trigger_index", "=", "trigger_id2event_mention", "[", "mention_id", "]", ".", "to_json", "(", ")", "[", "0", "]", "[", "0", "]", "\n", "# keep the event cluster the same format as entity cluster. Each mention is represented by its trigger span.", "\n", "cur_cluster", ".", "append", "(", "[", "trigger_index", ",", "trigger_index", "]", ")", "\n", "\n", "# this is indeed a cluster if cluster size > 2", "\n", "", "if", "len", "(", "cur_cluster", ")", ">=", "2", ":", "\n", "                    ", "clusters", ".", "append", "(", "cur_cluster", ")", "\n", "", "", "js", "[", "'event_clusters'", "]", "=", "clusters", "\n", "", "return", "js", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.in_between": [[33, 36], ["None"], "function", ["None"], ["", "def", "in_between", "(", "ix", ",", "pair", ")", ":", "\n", "    ", "assert", "ix", "!=", "pair", "[", "0", "]", "and", "ix", "!=", "pair", "[", "1", "]", "\n", "return", "ix", ">", "pair", "[", "0", "]", "and", "ix", "<", "pair", "[", "1", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.debug_if": [[243, 246], ["ipdb.set_trace"], "function", ["None"], ["", "", "def", "debug_if", "(", "cond", ")", ":", "\n", "    ", "if", "cond", ":", "\n", "        ", "import", "ipdb", ";", "ipdb", ".", "set_trace", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.get_token_indices": [[248, 258], ["parse_ace_event.debug_if", "parse_ace_event.debug_if", "len", "len", "len"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.debug_if", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.debug_if"], ["", "", "def", "get_token_indices", "(", "entity", ",", "sent", ")", ":", "\n", "    ", "start_token", "=", "[", "tok", "for", "tok", "in", "sent", "if", "tok", ".", "idx", "==", "entity", ".", "start_char", "]", "\n", "debug_if", "(", "len", "(", "start_token", ")", "!=", "1", ")", "\n", "start_token", "=", "start_token", "[", "0", "]", "\n", "end_token", "=", "[", "tok", "for", "tok", "in", "sent", "if", "tok", ".", "idx", "+", "len", "(", "tok", ")", "-", "1", "==", "entity", ".", "end_char", "]", "\n", "debug_if", "(", "len", "(", "end_token", ")", "!=", "1", ")", "\n", "end_token", "=", "end_token", "[", "0", "]", "\n", "start_ix", "=", "start_token", ".", "i", "\n", "end_ix", "=", "end_token", ".", "i", "\n", "return", "start_ix", ",", "end_ix", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.get_token_of": [[260, 266], ["Exception", "len"], "function", ["None"], ["", "def", "get_token_of", "(", "doc", ",", "char", ")", ":", "\n", "    ", "'Given a document and a character in the document, get the token that the char lives in.'", "\n", "for", "tok", "in", "doc", ":", "\n", "        ", "if", "char", ">=", "tok", ".", "idx", "and", "char", "<", "tok", ".", "idx", "+", "len", "(", "tok", ")", ":", "\n", "            ", "return", "doc", "[", "tok", ".", "i", "]", "\n", "", "", "raise", "Exception", "(", "'Should not get here.'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.one_fold": [[785, 804], ["open", "open", "os.path.join", "doc_keys.append", "os.path.join", "os.path.join", "os.path.join", "parse_ace_event.Document", "parse_ace_event.Document.to_json", "g.write", "line.strip", "json.dumps"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "", "def", "one_fold", "(", "fold", ",", "output_dir", ",", "heads_only", "=", "True", ",", "real_entities_only", "=", "True", ",", "include_pronouns", "=", "False", ",", "\n", "include_entity_coreference", "=", "False", ",", "include_event_coreference", "=", "False", ")", ":", "\n", "    ", "doc_path", "=", "\"./data/ace-event/raw-data\"", "\n", "split_path", "=", "\"./scripts/data/ace-event/event-split\"", "\n", "\n", "doc_keys", "=", "[", "]", "\n", "with", "open", "(", "path", ".", "join", "(", "split_path", ",", "fold", "+", "\".filelist\"", ")", ")", "as", "f", ":", "\n", "        ", "for", "line", "in", "f", ":", "\n", "            ", "doc_keys", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "\n", "", "", "with", "open", "(", "path", ".", "join", "(", "output_dir", ",", "fold", "+", "\".json\"", ")", ",", "\"w\"", ")", "as", "g", ":", "\n", "        ", "for", "doc_key", "in", "doc_keys", ":", "\n", "            ", "annotation_path", "=", "path", ".", "join", "(", "doc_path", ",", "doc_key", "+", "\".apf.xml\"", ")", "\n", "text_path", "=", "path", ".", "join", "(", "doc_path", ",", "doc_key", "+", "\".sgm\"", ")", "\n", "document", "=", "Document", "(", "annotation_path", ",", "text_path", ",", "doc_key", ",", "fold", ",", "heads_only", ",", "\n", "real_entities_only", ",", "include_pronouns", ",", "include_entity_coreference", ",", "\n", "include_event_coreference", ")", "\n", "js", "=", "document", ".", "to_json", "(", ")", "\n", "g", ".", "write", "(", "json", ".", "dumps", "(", "js", ",", "default", "=", "int", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.main": [[806, 841], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.makedirs", "print", "parse_ace_event.one_fold", "textwrap.dedent"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.one_fold"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "desc", "=", "\"\"\"\n    Preprocess ACE event data.\n\n    NOTE: Arguments marked with a '*' were added by a contributor and are not \"officially supported\".\n    \"\"\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "textwrap", ".", "dedent", "(", "desc", ")", ",", "\n", "formatter_class", "=", "argparse", ".", "RawTextHelpFormatter", ")", "\n", "parser", ".", "add_argument", "(", "\"output_name\"", ",", "help", "=", "\"Name for output directory.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use_span_extent\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Use full extent of entity mentions instead of just heads.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--include_times_and_values\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Treat times and values as entities and include them as event arguments.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--include_pronouns\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"Include pronouns as entities and include them as event arguments.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--include_entity_coreference\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"*Include entity coreference labels stored in 'clusters'.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--include_event_coreference\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"*Include event coreference labels stored in 'event_clusters'.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "output_dir", "=", "f\"./data/ace-event/processed-data/{args.output_name}/json\"", "\n", "os", ".", "makedirs", "(", "output_dir", ",", "exist_ok", "=", "True", ")", "\n", "\n", "# Process the documents.", "\n", "for", "fold", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", ":", "\n", "        ", "msg", "=", "f\"Parsing {fold} set.\"", "\n", "print", "(", "msg", ")", "\n", "one_fold", "(", "fold", ",", "\n", "output_dir", ",", "\n", "heads_only", "=", "(", "not", "args", ".", "use_span_extent", ")", ",", "\n", "real_entities_only", "=", "(", "not", "args", ".", "include_times_and_values", ")", ",", "\n", "include_pronouns", "=", "args", ".", "include_pronouns", ",", "\n", "include_entity_coreference", "=", "args", ".", "include_entity_coreference", ",", "\n", "include_event_coreference", "=", "args", ".", "include_event_coreference", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Token.__init__": [[30, 52], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "text", ",", "orig_text", ",", "start", ",", "end", ",", "after", ",", "before", ",", "postag", ",", "orig_postag", ")", ":", "\n", "        ", "'''Token object to faithfully represent a token\n\n        To be represented faithfully, a token needs to hold:\n        - text: The text it is covering, might be normalized\n        - orig_text: The original text it is covering, found in the original text\n        - start: The start index in the sentence it appears in\n        - end: The end index in the sentence it appears in\n        - after: The string that appear after this token, but before the next token\n        - before: The string that appear before this token, but after the previous token\n        - postag: The POS tag of this token, might be adjusted due to oversplitting\n        - orig_postag: The POS tag of the original token this token comes from\n        Inspired by CoreLabel in Stanford CoreNLP\n        '''", "\n", "self", ".", "text", "=", "text", "\n", "self", ".", "orig_text", "=", "orig_text", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "self", ".", "after", "=", "after", "\n", "self", ".", "before", "=", "before", "\n", "self", ".", "postag", "=", "postag", "\n", "self", ".", "orig_postag", "=", "orig_postag", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Span.__init__": [[54, 58], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "start", ",", "end", ")", ":", "\n", "        ", "'''Span object represents any span with start and end indices'''", "\n", "self", ".", "start", "=", "start", "\n", "self", ".", "end", "=", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Span.get_text": [[59, 61], ["None"], "methods", ["None"], ["", "def", "get_text", "(", "self", ",", "text", ")", ":", "\n", "        ", "return", "text", "[", "self", ".", "start", ":", "self", ".", "end", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Span.contains": [[62, 64], ["None"], "methods", ["None"], ["", "def", "contains", "(", "self", ",", "span2", ")", ":", "\n", "        ", "return", "self", ".", "start", "<=", "span2", ".", "start", "and", "self", ".", "end", ">=", "span2", ".", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Span.overlaps": [[65, 70], ["None"], "methods", ["None"], ["", "def", "overlaps", "(", "self", ",", "span2", ")", ":", "\n", "        ", "if", "(", "(", "self", ".", "start", ">=", "span2", ".", "start", "and", "self", ".", "start", "<", "span2", ".", "end", ")", "or", "\n", "(", "span2", ".", "start", ">=", "self", ".", "start", "and", "span2", ".", "start", "<", "self", ".", "end", ")", ")", ":", "\n", "            ", "return", "True", "\n", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Span.equals": [[71, 73], ["None"], "methods", ["None"], ["", "def", "equals", "(", "self", ",", "span2", ")", ":", "\n", "        ", "return", "self", ".", "start", "==", "span2", ".", "start", "and", "self", ".", "end", "==", "span2", ".", "end", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Span.__str__": [[74, 76], ["genia_xml_to_inline_sutd.Span.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Span.__repr__": [[77, 79], ["None"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{},{}'", ".", "format", "(", "self", ".", "start", ",", "self", ".", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__init__": [[81, 92], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "spans", ",", "label", ",", "text", "=", "None", ",", "parent", "=", "None", ")", ":", "\n", "        ", "'''Annotation object defines an annotation by a list of spans and its label.\n\n        Optionally, this object can hold the containing text, so that the text of this annotation can be recovered by calling get_text method.\n\n        If this annotation is discontiguous (more than one spans), the parent specifies the annotation that contains all the discontiguous entities in the same coordinated expression\n        '''", "\n", "self", ".", "spans", "=", "spans", "\n", "self", ".", "label", "=", "label", "\n", "self", ".", "text", "=", "text", "\n", "self", ".", "parent", "=", "parent", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text": [[93, 95], ["span.get_text"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text"], ["", "def", "get_text", "(", "self", ")", ":", "\n", "        ", "return", "' ... '", ".", "join", "(", "span", ".", "get_text", "(", "self", ".", "text", ")", "for", "span", "in", "self", ".", "spans", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.overlaps": [[96, 102], ["span.overlaps"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.overlaps"], ["", "def", "overlaps", "(", "self", ",", "ann2", ")", ":", "\n", "        ", "for", "span", "in", "self", ".", "spans", ":", "\n", "            ", "for", "span2", "in", "ann2", ".", "spans", ":", "\n", "                ", "if", "span", ".", "overlaps", "(", "span2", ")", ":", "\n", "                    ", "return", "True", "\n", "", "", "", "return", "False", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.contains": [[103, 113], ["span.contains"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.contains"], ["", "def", "contains", "(", "self", ",", "ann2", ")", ":", "\n", "        ", "for", "span2", "in", "ann2", ".", "spans", ":", "\n", "            ", "this_span_is_contained", "=", "False", "\n", "for", "span", "in", "self", ".", "spans", ":", "\n", "                ", "if", "span", ".", "contains", "(", "span2", ")", ":", "\n", "                    ", "this_span_is_contained", "=", "True", "\n", "break", "\n", "", "", "if", "not", "this_span_is_contained", ":", "\n", "                ", "return", "False", "\n", "", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.equals": [[114, 123], ["zip", "span.equals"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.equals"], ["", "def", "equals", "(", "self", ",", "ann2", ")", ":", "\n", "        ", "if", "ann2", "is", "None", ":", "\n", "            ", "return", "False", "\n", "", "for", "span", ",", "span2", "in", "zip", "(", "self", ".", "spans", ",", "ann2", ".", "spans", ")", ":", "\n", "            ", "if", "not", "span", ".", "equals", "(", "span2", ")", ":", "\n", "                ", "return", "False", "\n", "", "", "if", "self", ".", "label", "!=", "ann2", ".", "label", ":", "\n", "            ", "return", "False", "\n", "", "return", "True", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__str__": [[124, 126], ["genia_xml_to_inline_sutd.Annotation.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["", "def", "__str__", "(", "self", ")", ":", "\n", "        ", "return", "self", ".", "__repr__", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__": [[127, 129], ["str"], "methods", ["None"], ["", "def", "__repr__", "(", "self", ")", ":", "\n", "        ", "return", "'{} {}'", ".", "format", "(", "'+'", ".", "join", "(", "str", "(", "span", ")", "for", "span", "in", "self", ".", "spans", ")", ",", "self", ".", "label", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.__init__": [[131, 135], ["sentence_xml.get_text", "genia_xml_to_inline_sutd.Sentence.get_tokens", "genia_xml_to_inline_sutd.Sentence.get_annotations"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.get_tokens", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.get_annotations"], ["    ", "def", "__init__", "(", "self", ",", "sentence_xml", ")", ":", "\n", "        ", "self", ".", "text", "=", "sentence_xml", ".", "get_text", "(", ")", "\n", "self", ".", "tokens", ",", "self", ".", "orig_tokens", "=", "self", ".", "get_tokens", "(", "sentence_xml", ")", "\n", "self", ".", "span_annotations", ",", "self", ".", "token_annotations", "=", "self", ".", "get_annotations", "(", "sentence_xml", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.get_tokens": [[136, 179], ["sentence_xml.find_all", "orig_token.get_text", "text.find", "orig_tokens.append", "re.split", "before.strip", "print", "len", "genia_xml_to_inline_sutd.Token", "len", "text.find", "tokens.append", "len", "len", "genia_xml_to_inline_sutd.Token", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "get_tokens", "(", "self", ",", "sentence_xml", ")", ":", "\n", "        ", "'''Returns the list of tokens from a sentence\n\n        This method oversplits the tokens, so that, as much as possible, all entities can be composed by joining the tokens (so hopefully no entity that spans only part of a token)\n        '''", "\n", "text", "=", "self", ".", "text", "\n", "tokens", "=", "[", "]", "\n", "orig_tokens", "=", "[", "]", "\n", "idx", "=", "0", "\n", "orig_idx", "=", "0", "\n", "for", "orig_token", "in", "sentence_xml", ".", "find_all", "(", "'w'", ")", ":", "\n", "            ", "token_txt", "=", "orig_token", ".", "get_text", "(", ")", "\n", "postag", "=", "orig_token", "[", "'c'", "]", "\n", "token_orig_idx", "=", "text", ".", "find", "(", "token_txt", ",", "orig_idx", ")", "\n", "before", "=", "text", "[", "orig_idx", ":", "token_orig_idx", "]", "\n", "if", "before", ".", "strip", "(", ")", "!=", "''", ":", "\n", "                ", "print", "(", "'Missing <w> element for: {} ({})'", ".", "format", "(", "before", ",", "text", ")", ")", "\n", "", "if", "len", "(", "orig_tokens", ")", ">=", "1", ":", "\n", "                ", "orig_tokens", "[", "-", "1", "]", ".", "after", "=", "before", "\n", "", "orig_tokens", ".", "append", "(", "Token", "(", "token_txt", ",", "token_txt", ",", "token_orig_idx", ",", "token_orig_idx", "+", "len", "(", "token_txt", ")", ",", "''", ",", "before", ",", "postag", ",", "postag", ")", ")", "\n", "orig_idx", "=", "token_orig_idx", "+", "len", "(", "token_txt", ")", "\n", "\n", "# Do oversplitting of the tokens, so that instances like the token \"IL-2-mediated\"", "\n", "# as tokenized originally where only \"IL-2\" is an entity, can be represented as a", "\n", "# list of tokens instead of having the entity covering only part of a token", "\n", "for", "token", "in", "re", ".", "split", "(", "'([-/,.+])'", ",", "token_txt", ")", ":", "\n", "                ", "if", "token", "is", "None", "or", "len", "(", "token", ")", "==", "0", ":", "\n", "                    ", "continue", "\n", "", "token_idx", "=", "text", ".", "find", "(", "token", ",", "idx", ")", "\n", "before", "=", "text", "[", "idx", ":", "token_idx", "]", "\n", "if", "len", "(", "tokens", ")", ">=", "1", ":", "\n", "                    ", "tokens", "[", "-", "1", "]", ".", "after", "=", "before", "\n", "# The tokens resulting from an oversplitting with be given the POS tag '*'", "\n", "# Only the last token will retain the original POS tag", "\n", "", "tokens", ".", "append", "(", "Token", "(", "token", ",", "token", ",", "token_idx", ",", "token_idx", "+", "len", "(", "token", ")", ",", "''", ",", "before", ",", "'*'", ",", "postag", ")", ")", "\n", "idx", "=", "token_idx", "+", "len", "(", "token", ")", "\n", "", "tokens", "[", "-", "1", "]", ".", "postag", "=", "tokens", "[", "-", "1", "]", ".", "orig_postag", "# This makes the last token retains the original POS tag", "\n", "tok_idx", "=", "len", "(", "tokens", ")", "-", "2", "\n", "if", "postag", "!=", "'*'", ":", "\n", "                ", "while", "tok_idx", ">=", "0", "and", "tokens", "[", "tok_idx", "]", ".", "postag", "==", "'*'", ":", "\n", "                    ", "tokens", "[", "tok_idx", "]", ".", "orig_postag", "=", "postag", "\n", "tok_idx", "-=", "1", "\n", "", "", "", "return", "tokens", ",", "orig_tokens", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.get_annotations": [[180, 195], ["genia_xml_to_inline_sutd.Sentence.process_annotation", "genia_xml_to_inline_sutd.Annotation", "token_annotations.append", "span_tokens.append", "genia_xml_to_inline_sutd.Sentence.span_to_token"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.process_annotation", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.span_to_token"], ["", "def", "get_annotations", "(", "self", ",", "sentence_xml", ")", ":", "\n", "        ", "'''Extracts annotations from a sentence annotation'''", "\n", "text", "=", "self", ".", "text", "\n", "tokens", "=", "self", ".", "tokens", "\n", "span_annotations", "=", "[", "]", "\n", "Sentence", ".", "process_annotation", "(", "sentence_xml", ",", "text", ",", "span_annotations", ",", "0", ")", "\n", "token_annotations", "=", "[", "]", "\n", "# Converts the character-based annotations into token-based annotations", "\n", "for", "annotation", "in", "span_annotations", ":", "\n", "            ", "span_tokens", "=", "[", "]", "\n", "for", "span", "in", "annotation", ".", "spans", ":", "\n", "                ", "span_tokens", ".", "append", "(", "Sentence", ".", "span_to_token", "(", "span", ",", "tokens", ")", ")", "\n", "", "token_annotation", "=", "Annotation", "(", "span_tokens", ",", "annotation", ".", "label", ",", "annotation", ".", "text", ",", "annotation", ".", "parent", ")", "\n", "token_annotations", ".", "append", "(", "token_annotation", ")", "\n", "", "return", "span_annotations", ",", "token_annotations", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.span_to_token": [[196, 207], ["enumerate", "genia_xml_to_inline_sutd.Span"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "span_to_token", "(", "span", ",", "tokens", ")", ":", "\n", "        ", "'''Returns the list of tokens that covers the given list of character spans'''", "\n", "start", "=", "-", "1", "\n", "end", "=", "-", "1", "\n", "for", "idx", ",", "token", "in", "enumerate", "(", "tokens", ")", ":", "\n", "            ", "if", "span", ".", "start", "<", "token", ".", "end", "and", "start", "==", "-", "1", ":", "\n", "                ", "start", "=", "idx", "\n", "", "if", "token", ".", "end", "<=", "span", ".", "end", ":", "\n", "                ", "end", "=", "idx", "+", "1", "\n", "", "", "return", "Span", "(", "start", ",", "end", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.normalize_lex": [[208, 211], ["lex.replace().replace().replace().replace().replace().strip", "lex.replace().replace().replace().replace().replace", "lex.replace().replace().replace().replace", "lex.replace().replace().replace", "lex.replace().replace", "lex.replace"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "normalize_lex", "(", "lex", ")", ":", "\n", "        ", "return", "lex", ".", "replace", "(", "'-_'", ",", "'-'", ")", ".", "replace", "(", "'_-'", ",", "'-'", ")", ".", "replace", "(", "'__'", ",", "'_'", ")", ".", "replace", "(", "'*_'", ",", "'*'", ")", ".", "replace", "(", "'\\\\*'", ",", "'*'", ")", ".", "strip", "(", "'_'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.process_annotation": [[212, 263], ["parent_annotation.find_all", "annotation.get_text", "text.find", "genia_xml_to_inline_sutd.Sentence.process_annotation", "genia_xml_to_inline_sutd.Sentence.normalize_lex", "annotation.find_all", "ann_sem.startswith", "span_annotations.append", "genia_xml_to_inline_sutd.Annotation", "genia_xml_to_inline_sutd.Sentence.parse_lex", "len", "annotation.get_text", "annotation.get_text().replace", "genia_xml_to_inline_sutd.Annotation", "len", "ann_sem.startswith", "annotation.get_text().replace.startswith", "annotation.get_text().replace.endswith", "sub_con.get_text", "text.find", "sub_cons_ann.append", "genia_xml_to_inline_sutd.Sentence.find_spans", "span_annotations.append", "len", "genia_xml_to_inline_sutd.Span", "sub_con[].startswith", "print", "Exception", "len", "genia_xml_to_inline_sutd.Annotation", "annotation.get_text", "genia_xml_to_inline_sutd.Span", "genia_xml_to_inline_sutd.Sentence.normalize_lex", "genia_xml_to_inline_sutd.Span", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.process_annotation", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.normalize_lex", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.parse_lex", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.find_spans", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.normalize_lex"], ["", "@", "staticmethod", "\n", "def", "process_annotation", "(", "parent_annotation", ",", "text", ",", "span_annotations", ",", "idx", ")", ":", "\n", "        ", "'''The method that processes the children of a BeautifulSoup tag\n        '''", "\n", "for", "annotation", "in", "parent_annotation", ".", "find_all", "(", "'cons'", ",", "recursive", "=", "False", ")", ":", "\n", "            ", "ann_txt", "=", "annotation", ".", "get_text", "(", ")", "\n", "ann_idx", "=", "text", ".", "find", "(", "ann_txt", ",", "idx", ")", "\n", "if", "ann_idx", "==", "-", "1", ":", "\n", "                ", "raise", "(", "'1:Cannot find {} in {} at {} ({})'", ".", "format", "(", "annotation", ".", "get_text", "(", ")", ",", "text", "[", "idx", ":", "]", ",", "idx", ",", "text", ")", ")", "\n", "", "Sentence", ".", "process_annotation", "(", "annotation", ",", "text", ",", "span_annotations", ",", "ann_idx", ")", "\n", "try", ":", "\n", "                ", "ann_lex", "=", "annotation", "[", "'lex'", "]", "\n", "", "except", ":", "\n", "                ", "ann_lex", "=", "annotation", ".", "get_text", "(", ")", ".", "replace", "(", "' '", ",", "'_'", ")", "\n", "", "ann_lex", "=", "Sentence", ".", "normalize_lex", "(", "ann_lex", ")", "\n", "try", ":", "\n", "                ", "ann_sem", "=", "annotation", "[", "'sem'", "]", "\n", "", "except", ":", "\n", "# No sem means this is part of discontiguous entity, should have been handled by the discontiguous entity handler below when it processes the parent", "\n", "                ", "idx", "=", "ann_idx", "+", "len", "(", "ann_txt", ")", "\n", "continue", "\n", "", "if", "not", "ann_sem", ".", "startswith", "(", "'('", ")", ":", "\n", "# This is a contiguous entity", "\n", "# Just add it into the list of annotations", "\n", "                ", "span_annotations", ".", "append", "(", "Annotation", "(", "[", "Span", "(", "ann_idx", ",", "ann_idx", "+", "len", "(", "ann_txt", ")", ")", "]", ",", "ann_sem", ",", "text", ")", ")", "\n", "# Find all possible constituents of the discontiguous entities", "\n", "", "sub_cons", "=", "annotation", ".", "find_all", "(", "'cons'", ",", "recursive", "=", "True", ")", "\n", "if", "len", "(", "sub_cons", ")", ">", "1", "and", "(", "ann_sem", ".", "startswith", "(", "'('", ")", "or", "ann_lex", ".", "startswith", "(", "'*'", ")", "or", "ann_lex", ".", "endswith", "(", "'*'", ")", ")", ":", "\n", "# This contains a discontiguous entity", "\n", "# We need to find the spans of each discontiguous entity", "\n", "                ", "combined_ann", "=", "Annotation", "(", "[", "Span", "(", "ann_idx", ",", "ann_idx", "+", "len", "(", "ann_txt", ")", ")", "]", ",", "ann_sem", ",", "text", ")", "\n", "sub_anns", "=", "Sentence", ".", "parse_lex", "(", "ann_lex", ",", "ann_sem", ")", "\n", "sub_cons_ann", "=", "[", "]", "\n", "# Find the character span of each constituent", "\n", "for", "sub_con", "in", "sub_cons", ":", "\n", "                    ", "sub_con_txt", "=", "sub_con", ".", "get_text", "(", ")", "\n", "sub_con_idx", "=", "text", ".", "find", "(", "sub_con_txt", ",", "idx", ")", "\n", "if", "sub_con", "[", "'lex'", "]", ".", "startswith", "(", "'('", ")", "or", "'*'", "not", "in", "sub_con", "[", "'lex'", "]", ":", "\n", "# This is contiguous entity, should have been handled by case 1 above", "\n", "                        ", "continue", "\n", "", "if", "sub_con_idx", "==", "-", "1", ":", "\n", "# This means a constituent cannot be found in its parent constituent, a bug in this script", "\n", "                        ", "print", "(", "sub_cons_ann", ")", "\n", "raise", "Exception", "(", "'2:Cannot find {} in {} at {} ({})'", ".", "format", "(", "sub_con_txt", ",", "text", "[", "idx", ":", "]", ",", "idx", ",", "text", ")", ")", "\n", "", "sub_cons_ann", ".", "append", "(", "(", "Sentence", ".", "normalize_lex", "(", "sub_con", "[", "'lex'", "]", ")", ",", "Span", "(", "sub_con_idx", ",", "sub_con_idx", "+", "len", "(", "sub_con_txt", ")", ")", ")", ")", "\n", "idx", "=", "sub_con_idx", "+", "len", "(", "sub_con_txt", ")", "\n", "# Map each entity to its character span(s)", "\n", "", "for", "sub_lex", ",", "sub_sem", "in", "sub_anns", ":", "\n", "                    ", "spans", "=", "Sentence", ".", "find_spans", "(", "sub_lex", ",", "text", ",", "sub_cons_ann", ")", "\n", "span_annotations", ".", "append", "(", "Annotation", "(", "spans", ",", "sub_sem", ",", "text", ",", "combined_ann", ")", ")", "\n", "", "", "idx", "=", "ann_idx", "+", "len", "(", "ann_txt", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.parse_lex": [[264, 276], ["zip", "genia_xml_to_inline_sutd.Sentence.split_lex", "genia_xml_to_inline_sutd.Sentence.split_lex", "result.append", "genia_xml_to_inline_sutd.Sentence.normalize_lex"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.split_lex", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.split_lex", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.normalize_lex"], ["", "", "@", "staticmethod", "\n", "def", "parse_lex", "(", "lex", ",", "sem", ")", ":", "\n", "        ", "result", "=", "[", "]", "\n", "for", "sub_lex", ",", "sub_sem", "in", "zip", "(", "Sentence", ".", "split_lex", "(", "lex", ")", ",", "Sentence", ".", "split_lex", "(", "sem", ")", ")", ":", "\n", "            ", "if", "'#'", "in", "sub_sem", ":", "\n", "                ", "if", "sub_lex", "==", "'amino-terminal_(729-766)_region'", ":", "\n", "# Special case, since the text is:", "\n", "# \"Deletions of a relatively short amino- (729-766) or carboxy- terminal (940-984) region\"", "\n", "#", "\n", "                    ", "sub_lex", "=", "'amino-(729-766)_terminal_region'", "\n", "", "result", ".", "append", "(", "(", "Sentence", ".", "normalize_lex", "(", "sub_lex", ")", ",", "sub_sem", ")", ")", "\n", "", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.split_lex": [[277, 311], ["len", "re.match", "lex.find", "enumerate", "result.append", "result.extend", "len", "len", "genia_xml_to_inline_sutd.Sentence.split_lex"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.split_lex"], ["", "@", "staticmethod", "\n", "def", "split_lex", "(", "lex", ",", "idx", "=", "None", ")", ":", "\n", "        ", "'''Parses a lex attribute (might be nested) into a list of basic lex form (i.e., no nested lex)\n        '''", "\n", "if", "idx", "is", "None", ":", "\n", "            ", "idx", "=", "[", "0", "]", "\n", "", "result", "=", "[", "]", "\n", "if", "idx", "[", "0", "]", "==", "len", "(", "lex", ")", ":", "\n", "            ", "return", "result", "\n", "", "if", "lex", "[", "idx", "[", "0", "]", "]", "==", "'('", "and", "re", ".", "match", "(", "'^\\\\((AND|OR|BUT_NOT|AS_WELL_AS|VERSUS|TO|NOT_ONLY_BUT_ALSO|NEITHER_NOR|THAN) .+'", ",", "lex", ")", ":", "\n", "            ", "idx", "[", "0", "]", "=", "lex", ".", "find", "(", "' '", ",", "idx", "[", "0", "]", ")", "\n", "while", "idx", "[", "0", "]", "<", "len", "(", "lex", ")", "and", "lex", "[", "idx", "[", "0", "]", "]", "==", "' '", ":", "\n", "                ", "idx", "[", "0", "]", "+=", "1", "\n", "result", ".", "extend", "(", "Sentence", ".", "split_lex", "(", "lex", ",", "idx", ")", ")", "\n", "", "", "else", ":", "\n", "            ", "open_bracket_count", "=", "0", "\n", "end_of_lex", "=", "-", "1", "\n", "for", "pos", ",", "char", "in", "enumerate", "(", "lex", "[", "idx", "[", "0", "]", ":", "]", ")", ":", "\n", "                ", "if", "char", "==", "'('", ":", "\n", "                    ", "open_bracket_count", "+=", "1", "\n", "", "elif", "char", "==", "')'", ":", "\n", "                    ", "if", "open_bracket_count", ">", "0", ":", "\n", "                        ", "open_bracket_count", "-=", "1", "\n", "", "else", ":", "\n", "                        ", "end_of_lex", "=", "pos", "+", "idx", "[", "0", "]", "\n", "break", "\n", "", "", "elif", "char", "==", "' '", ":", "\n", "                    ", "end_of_lex", "=", "pos", "+", "idx", "[", "0", "]", "\n", "break", "\n", "", "", "if", "end_of_lex", "==", "-", "1", ":", "\n", "                ", "end_of_lex", "=", "len", "(", "lex", ")", "\n", "", "result", ".", "append", "(", "lex", "[", "idx", "[", "0", "]", ":", "end_of_lex", "]", ")", "\n", "idx", "[", "0", "]", "=", "end_of_lex", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Sentence.find_spans": [[312, 372], ["lex.lower().strip.lower().strip.lower().strip", "abs", "range", "con_lex.strip().lower.strip().lower.strip().lower", "lex.lower().strip.lower().strip.find", "print", "lex.lower().strip.lower().strip.lower", "lex.lower().strip.lower().strip.find", "spans.append", "con_lex.strip().lower.strip().lower.endswith", "len", "print", "print", "len", "con_lex.strip().lower.strip().lower.strip", "print", "spans.append", "con_lex.strip().lower.strip().lower.endswith", "genia_xml_to_inline_sutd.Span", "len", "lex.lower().strip.lower().strip.rstrip", "len", "genia_xml_to_inline_sutd.Span", "len", "spans[].get_text", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text"], ["", "@", "staticmethod", "\n", "def", "find_spans", "(", "lex", ",", "text", ",", "cons", ")", ":", "\n", "        ", "'''Given an entity from the lex attribute of cons, and the list of possible constituents (with their character spans), return the list of character spans that forms the entity\n\n        The search of the components of the discontiguous entities depends on the lex of the original discontiguous entity (e.g., in (AND class_I_interferon class_II_interferon)) by trying to match the string with the lex of the constituents found inside that tags (e.g., \"class*\", \"*I*\", \"*II*\", \"*interferon\" for the above case).\n\n        Various checks have been in place to ensure that the entire string is found, while allowing some minor differences.\n        '''", "\n", "spans", "=", "[", "]", "\n", "lex_idx", "=", "0", "\n", "prev_lex_idx", "=", "-", "1", "\n", "lex", "=", "lex", ".", "lower", "(", ")", ".", "strip", "(", "'*'", ")", "\n", "for", "con_lex", ",", "con_span", "in", "cons", ":", "\n", "            ", "con_lex", "=", "con_lex", ".", "strip", "(", "'*'", ")", ".", "lower", "(", ")", "\n", "con_lex_idx", "=", "lex", ".", "find", "(", "con_lex", ",", "lex_idx", ")", "\n", "if", "con_lex_idx", "-", "lex_idx", ">=", "2", ":", "\n", "# Ensure that we don't skip over too many characters", "\n", "                ", "con_lex_idx", "=", "-", "1", "\n", "", "if", "con_lex_idx", "-", "lex_idx", "==", "1", ":", "\n", "# Skipping one character might be permissible, given that it's not an important character", "\n", "                ", "if", "lex", "[", "lex_idx", "]", "not", "in", "' -_/*'", ":", "\n", "                    ", "con_lex_idx", "=", "-", "1", "\n", "", "", "if", "con_lex_idx", "==", "-", "1", ":", "\n", "# We didn't find this constituent in the parent string", "\n", "# Normally we would just skip this and continue checking the next constituent,", "\n", "# However, in some cases, a constituent is a prefix of the next constituent.", "\n", "# In that case, we might need to back-off the previous match, and try the longer constituent.", "\n", "# For example, when trying to match \"class_II_interferon\", we might match \"*I*\" to the first \"I\" of \"class_II_interferon\", which is incorrect, as it should be matched with \"*II*\" which comes after \"*I*\". So the following is the backing-off mechanism to try to match that.", "\n", "# Since this theoretically not 100% accurate, each back-off action is logged, and we need to check whether the back-off was correct.", "\n", "# For GENIA dataset, there are 53 cases of backing-off, and all of them have been verified correct", "\n", "                ", "con_lex_idx", "=", "lex", ".", "find", "(", "con_lex", ",", "prev_lex_idx", ")", "\n", "if", "con_lex_idx", "!=", "-", "1", "and", "con_lex_idx", "<", "lex_idx", "and", "len", "(", "con_lex", ")", ">", "spans", "[", "-", "1", "]", ".", "end", "-", "spans", "[", "-", "1", "]", ".", "start", ":", "\n", "                    ", "print", "(", "'Found {} from backing off from {} for {}, please check ({}) {}'", ".", "format", "(", "con_lex", ",", "spans", "[", "-", "1", "]", ".", "get_text", "(", "text", ")", ",", "lex", ",", "text", ",", "cons", ")", ")", "\n", "del", "(", "spans", "[", "len", "(", "spans", ")", "-", "1", "]", ")", "\n", "spans", ".", "append", "(", "Span", "(", "con_span", ".", "start", ",", "con_span", ".", "end", ")", ")", "\n", "prev_lex_idx", "=", "lex_idx", "\n", "lex_idx", "=", "con_lex_idx", "+", "len", "(", "con_lex", ")", "\n", "if", "con_lex", ".", "endswith", "(", "'-'", ")", ":", "\n", "                        ", "lex_idx", "-=", "1", "\n", "", "", "else", ":", "\n", "                    ", "continue", "\n", "", "", "else", ":", "\n", "                ", "spans", ".", "append", "(", "Span", "(", "con_span", ".", "start", ",", "con_span", ".", "end", ")", ")", "\n", "prev_lex_idx", "=", "lex_idx", "\n", "lex_idx", "=", "con_lex_idx", "+", "len", "(", "con_lex", ")", "\n", "if", "con_lex", ".", "endswith", "(", "'-'", ")", ":", "\n", "                    ", "lex_idx", "-=", "1", "\n", "", "", "", "diff", "=", "abs", "(", "lex_idx", "-", "len", "(", "lex", ".", "rstrip", "(", "'*'", ")", ")", ")", "\n", "if", "diff", ">=", "1", ":", "\n", "# To check whether the entity is completed", "\n", "            ", "print", "(", "'Cons: {}'", ".", "format", "(", "cons", ")", ")", "\n", "if", "diff", "==", "1", ":", "\n", "                ", "print", "(", "'WARNING: differ by one: \"{}\", found: \"{}\"'", ".", "format", "(", "lex", ",", "lex", "[", ":", "lex_idx", "]", ")", ")", "\n", "", "else", ":", "\n", "                ", "print", "(", "'\\n===\\nCannot find complete mention of \"{}\" in \"{}\", found only \"{}\"\\n===\\n'", ".", "format", "(", "lex", ",", "text", ",", "lex", "[", ":", "lex_idx", "]", ")", ")", "\n", "", "", "for", "idx", "in", "range", "(", "len", "(", "spans", ")", "-", "1", ",", "0", ",", "-", "1", ")", ":", "\n", "            ", "if", "spans", "[", "idx", "]", ".", "start", "==", "spans", "[", "idx", "-", "1", "]", ".", "end", "or", "text", "[", "spans", "[", "idx", "-", "1", "]", ".", "end", ":", "spans", "[", "idx", "]", ".", "start", "]", "==", "' '", ":", "\n", "                ", "spans", "[", "idx", "-", "1", "]", ".", "end", "=", "spans", "[", "idx", "]", ".", "end", "\n", "del", "(", "spans", "[", "idx", "]", ")", "\n", "", "", "return", "spans", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Article.__init__": [[375, 379], ["article_xml.get_text", "genia_xml_to_inline_sutd.Article.get_sentences", "genia_xml_to_inline_sutd.Article.get_doc_key"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Article.get_sentences", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Article.get_doc_key"], ["    ", "def", "__init__", "(", "self", ",", "article_xml", ")", ":", "\n", "        ", "self", ".", "text", "=", "article_xml", ".", "get_text", "(", ")", "\n", "self", ".", "sentences", "=", "self", ".", "get_sentences", "(", "article_xml", ")", "\n", "self", ".", "doc_key", "=", "self", ".", "get_doc_key", "(", "article_xml", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Article.get_sentences": [[380, 387], ["article_xml.find_all", "sentences_obj.append", "genia_xml_to_inline_sutd.Sentence"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_sentences", "(", "article_xml", ")", ":", "\n", "        ", "sentences", "=", "article_xml", ".", "find_all", "(", "'sentence'", ")", "\n", "sentences_obj", "=", "[", "]", "\n", "for", "sentence", "in", "sentences", ":", "\n", "            ", "sentences_obj", ".", "append", "(", "Sentence", "(", "sentence", ")", ")", "\n", "", "return", "sentences_obj", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Article.get_doc_key": [[388, 394], ["article_xml.find_all", "elem[].text.replace", "Exception", "len"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "get_doc_key", "(", "article_xml", ")", ":", "\n", "        ", "elem", "=", "article_xml", ".", "find_all", "(", "'bibliomisc'", ")", "\n", "if", "not", "len", "(", "elem", ")", "==", "1", ":", "\n", "            ", "raise", "Exception", "(", "'Wrong number of document IDs.'", ")", "\n", "", "return", "elem", "[", "0", "]", ".", "text", ".", "replace", "(", "'MEDLINE:'", ",", "''", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.split_train_dev_test": [[396, 404], ["len", "int", "int", "int", "math.ceil", "math.ceil"], "function", ["None"], ["", "", "def", "split_train_dev_test", "(", "sentences", ",", "train_pct", "=", "0.8", ",", "dev_pct", "=", "0.1", ",", "test_pct", "=", "0.1", ")", ":", "\n", "    ", "count", "=", "len", "(", "sentences", ")", "\n", "train_count", "=", "int", "(", "train_pct", "*", "count", ")", "\n", "dev_count", "=", "int", "(", "math", ".", "ceil", "(", "dev_pct", "*", "count", ")", ")", "\n", "test_count", "=", "int", "(", "math", ".", "ceil", "(", "test_pct", "*", "count", ")", ")", "\n", "train_count", "-=", "train_count", "+", "dev_count", "+", "test_count", "-", "count", "\n", "start_test_idx", "=", "train_count", "+", "dev_count", "\n", "return", "sentences", "[", ":", "train_count", "]", ",", "sentences", "[", "train_count", ":", "start_test_idx", "]", ",", "sentences", "[", "start_test_idx", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.filter_annotations": [[405, 434], ["genia_xml_to_inline_sutd.Annotation", "result.append", "reversed", "re.match", "len", "genia_xml_to_inline_sutd.Span", "range", "ann2.overlaps", "len", "ann2.contains", "Annotation.label.find", "genia_xml_to_inline_sutd.Annotation.contains"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.overlaps", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.contains", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.contains"], ["", "def", "filter_annotations", "(", "anns", ",", "remove_disc", ",", "remove_over", ",", "use_five_types", ")", ":", "\n", "    ", "result", "=", "[", "]", "\n", "for", "ann", "in", "anns", ":", "\n", "        ", "ann", "=", "Annotation", "(", "ann", ".", "spans", "[", ":", "]", ",", "ann", ".", "label", ",", "ann", ".", "text", ",", "ann", ".", "parent", ")", "\n", "if", "use_five_types", ":", "\n", "            ", "if", "not", "re", ".", "match", "(", "'G#(DNA|RNA|cell_line|cell_type|protein).*'", ",", "ann", ".", "label", ")", ":", "\n", "                ", "continue", "\n", "", "if", "ann", ".", "label", "not", "in", "[", "'G#cell_line'", ",", "'G#cell_type'", "]", ":", "\n", "                ", "ann", ".", "label", "=", "ann", ".", "label", "[", ":", "ann", ".", "label", ".", "find", "(", "'_'", ")", "]", "\n", "", "", "if", "remove_disc", "and", "len", "(", "ann", ".", "spans", ")", ">", "1", ":", "\n", "            ", "ann", ".", "spans", "=", "[", "Span", "(", "ann", ".", "spans", "[", "0", "]", ".", "start", ",", "ann", ".", "spans", "[", "-", "1", "]", ".", "end", ")", "]", "\n", "", "if", "remove_over", "or", "(", "remove_disc", "and", "ann", ".", "parent", "is", "not", "None", ")", ":", "\n", "            ", "need_to_be_removed", "=", "False", "\n", "for", "idx", "in", "reversed", "(", "range", "(", "len", "(", "result", ")", ")", ")", ":", "\n", "                ", "ann2", "=", "result", "[", "idx", "]", "\n", "if", "not", "remove_over", "and", "remove_disc", "and", "ann", ".", "parent", "is", "not", "None", "and", "ann", ".", "parent", "!=", "ann2", ".", "parent", ":", "\n", "                    ", "continue", "\n", "", "if", "ann2", ".", "overlaps", "(", "ann", ")", ":", "\n", "                    ", "if", "ann2", ".", "contains", "(", "ann", ")", ":", "\n", "                        ", "need_to_be_removed", "=", "True", "\n", "", "elif", "ann", ".", "contains", "(", "ann2", ")", ":", "\n", "                        ", "del", "(", "result", "[", "idx", "]", ")", "\n", "", "else", ":", "\n", "# Neither is contained within the other, not nested! Remove one arbitrarily, easier to remove the latter", "\n", "                        ", "need_to_be_removed", "=", "True", "\n", "", "", "", "if", "need_to_be_removed", ":", "\n", "                ", "continue", "\n", "", "", "result", ".", "append", "(", "ann", ")", "\n", "", "return", "result", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.main": [[435, 499], ["bs4.BeautifulSoup.find_all", "pandas.Series", "pd.Series.to_csv", "len", "print", "sys.exit", "len", "open", "bs4.BeautifulSoup", "articles_obj.append", "os.path.join", "infile.read", "genia_xml_to_inline_sutd.Article", "os.path.dirname", "open", "genia_xml_to_inline_sutd.filter_annotations", "outfile.write", "outfile.write", "outfile.write", "genia_xml_to_inline_sutd.filter_annotations", "outfile.write", "outfile.write", "outfile.write", "outfile.write", "outfile.write", "str", "str"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.filter_annotations", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.filter_annotations"], ["", "def", "main", "(", ")", ":", "\n", "    ", "if", "len", "(", "sys", ".", "argv", ")", "<", "3", ":", "\n", "        ", "print", "(", "'Usage: python {} <path_to_GENIA_POS_Corpus> <output_dir> (1|0:output original POS tag instead of *)'", ".", "format", "(", "sys", ".", "argv", "[", "0", "]", ")", ")", "\n", "sys", ".", "exit", "(", "0", ")", "\n", "", "xml_path", "=", "sys", ".", "argv", "[", "1", "]", "\n", "output_dir", "=", "sys", ".", "argv", "[", "2", "]", "\n", "use_orig_postag", "=", "True", "\n", "if", "len", "(", "sys", ".", "argv", ")", ">=", "4", ":", "\n", "        ", "if", "sys", ".", "argv", "[", "3", "]", "==", "'1'", ":", "\n", "            ", "use_orig_postag", "=", "True", "\n", "", "else", ":", "\n", "            ", "use_orig_postag", "=", "False", "\n", "", "", "with", "open", "(", "xml_path", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "soup", "=", "BS", "(", "infile", ".", "read", "(", ")", ",", "'lxml'", ")", "\n", "\n", "", "articles", "=", "soup", ".", "find_all", "(", "'article'", ")", "\n", "articles_obj", "=", "[", "]", "\n", "\n", "for", "article", "in", "articles", ":", "\n", "        ", "articles_obj", ".", "append", "(", "Article", "(", "article", ")", ")", "\n", "\n", "", "doc_keys", "=", "pd", ".", "Series", "(", "[", "entry", ".", "doc_key", "for", "entry", "in", "articles_obj", "]", ")", "\n", "doc_keys", ".", "name", "=", "\"doc_order\"", "\n", "doc_keys", ".", "to_csv", "(", "path", ".", "join", "(", "path", ".", "dirname", "(", "output_dir", ")", ",", "\"doc_order.csv\"", ")", ",", "index", "=", "False", ",", "header", "=", "False", ")", "\n", "\n", "for", "tokenized", "in", "[", "False", ",", "True", "]", ":", "\n", "        ", "if", "tokenized", ":", "\n", "            ", "tokenized_str", "=", "'.tok'", "\n", "", "else", ":", "\n", "            ", "tokenized_str", "=", "'.span'", "\n", "", "for", "level", "in", "[", "'all'", ",", "'no_disc'", ",", "'no_disc_no_over'", "]", ":", "\n", "            ", "if", "level", "==", "'no_disc'", ":", "\n", "                ", "remove_disc", "=", "True", "\n", "remove_over", "=", "False", "\n", "", "elif", "level", "==", "'no_disc_no_over'", ":", "\n", "                ", "remove_disc", "=", "True", "\n", "remove_over", "=", "True", "\n", "", "else", ":", "\n", "                ", "remove_disc", "=", "False", "\n", "remove_over", "=", "False", "\n", "", "for", "use_five_types", "in", "[", "True", ",", "False", "]", ":", "\n", "                ", "if", "use_five_types", ":", "\n", "                    ", "filtered", "=", "'5types'", "\n", "", "else", ":", "\n", "                    ", "filtered", "=", "'36types'", "\n", "\n", "", "for", "article", "in", "articles_obj", ":", "\n", "                    ", "filename", "=", "'{}{}.{}.{}.data'", ".", "format", "(", "article", ".", "doc_key", ",", "tokenized_str", ",", "filtered", ",", "level", ")", "\n", "with", "open", "(", "'{}/{}'", ".", "format", "(", "output_dir", ",", "filename", ")", ",", "'w'", ")", "as", "outfile", ":", "\n", "                        ", "for", "sentence", "in", "article", ".", "sentences", ":", "\n", "                            ", "if", "tokenized", ":", "\n", "                                ", "token_anns", "=", "filter_annotations", "(", "sentence", ".", "token_annotations", ",", "remove_disc", ",", "remove_over", ",", "use_five_types", ")", "\n", "outfile", ".", "write", "(", "'{}\\n'", ".", "format", "(", "' '", ".", "join", "(", "token", ".", "text", "for", "token", "in", "sentence", ".", "tokens", ")", ")", ")", "\n", "if", "use_orig_postag", ":", "\n", "                                    ", "outfile", ".", "write", "(", "'{}\\n'", ".", "format", "(", "' '", ".", "join", "(", "token", ".", "orig_postag", "for", "token", "in", "sentence", ".", "tokens", ")", ")", ")", "\n", "", "else", ":", "\n", "                                    ", "outfile", ".", "write", "(", "'{}\\n'", ".", "format", "(", "' '", ".", "join", "(", "token", ".", "postag", "for", "token", "in", "sentence", ".", "tokens", ")", ")", ")", "\n", "", "outfile", ".", "write", "(", "'{}\\n'", ".", "format", "(", "'|'", ".", "join", "(", "str", "(", "ann", ")", "for", "ann", "in", "token_anns", ")", ")", ")", "\n", "outfile", ".", "write", "(", "'\\n'", ")", "\n", "", "else", ":", "\n", "                                ", "span_anns", "=", "filter_annotations", "(", "sentence", ".", "span_annotations", ",", "remove_disc", ",", "remove_over", ",", "use_five_types", ")", "\n", "outfile", ".", "write", "(", "'{}\\n'", ".", "format", "(", "sentence", ".", "text", ")", ")", "\n", "outfile", ".", "write", "(", "'{}\\n'", ".", "format", "(", "'|'", ".", "join", "(", "str", "(", "ann", ")", "for", "ann", "in", "span_anns", ")", ")", ")", "\n", "outfile", ".", "write", "(", "'\\n'", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.save_list": [[3, 8], ["open", "f.write", "str"], "function", ["None"], ["\n", "\n", "import", "torch", "\n", "\n", "\n", "def", "cumsum_shifted", "(", "xs", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.load_list": [[10, 20], ["open", "res.append", "convert", "line.strip"], "function", ["None"], ["\n", "cs", "=", "xs", ".", "cumsum", "(", "dim", "=", "0", ")", "\n", "shift", "=", "torch", ".", "zeros", "(", "1", ",", "dtype", "=", "torch", ".", "long", ",", "device", "=", "cs", ".", "device", ")", "# Put on correct device.", "\n", "return", "torch", ".", "cat", "(", "[", "shift", ",", "cs", "[", ":", "-", "1", "]", "]", ",", "dim", "=", "0", ")", "\n", "\n", "\n", "", "def", "batch_identity", "(", "batch_size", ",", "matrix_size", ",", "*", "args", ",", "**", "kwargs", ")", ":", "\n", "    "]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.flatten": [[22, 28], ["None"], "function", ["None"], ["\n", "ident", "=", "torch", ".", "eye", "(", "matrix_size", ",", "*", "args", ",", "**", "kwargs", ")", ".", "unsqueeze", "(", "0", ")", "\n", "res", "=", "ident", ".", "repeat", "(", "batch_size", ",", "1", ",", "1", ")", "\n", "return", "res", "\n", "\n", "\n", "", "def", "fields_to_batches", "(", "d", ",", "keys_to_ignore", "=", "[", "]", ")", ":", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.find_sub_list": [[32, 39], ["len", "enumerate"], "function", ["None"], ["\n", "keys", "=", "[", "key", "for", "key", "in", "d", ".", "keys", "(", ")", "if", "key", "not", "in", "keys_to_ignore", "]", "\n", "\n", "# Make sure all input dicts have same length. If they don't, there's a problem.", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.find_sub_lists": [[41, 48], ["len", "enumerate", "results.append"], "function", ["None"], ["if", "len", "(", "set", "(", "lengths", ".", "values", "(", ")", ")", ")", "!=", "1", ":", "\n", "        ", "msg", "=", "f\"fields have different lengths: {lengths}.\"", "\n", "# If there's a doc key, add it to specify where the error is.", "\n", "if", "\"doc_key\"", "in", "d", ":", "\n", "            ", "msg", "=", "f\"For document {d['doc_key']}, \"", "+", "msg", "\n", "", "raise", "ValueError", "(", "msg", ")", "\n", "\n", "", "length", "=", "list", "(", "lengths", ".", "values", "(", ")", ")", "[", "0", "]", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.fields_to_batches": [[50, 67], ["d.keys", "len", "len", "d.values", "set", "range"], "function", ["None"], ["return", "res", "\n", "\n", "\n", "", "def", "batches_to_fields", "(", "batches", ")", ":", "\n", "    ", "\"\"\"\n    The inverse of `fields_to_batches`.\n    \"\"\"", "\n", "# Make sure all the keys match.", "\n", "first_keys", "=", "batches", "[", "0", "]", ".", "keys", "(", ")", "\n", "for", "entry", "in", "batches", "[", "1", ":", "]", ":", "\n", "        ", "if", "set", "(", "entry", ".", "keys", "(", ")", ")", "!=", "set", "(", "first_keys", ")", ":", "\n", "            ", "raise", "ValueError", "(", "\"Keys to not match on all entries.\"", ")", "\n", "\n", "", "", "res", "=", "{", "k", ":", "[", "]", "for", "k", "in", "first_keys", "}", "\n", "for", "batch", "in", "batches", ":", "\n", "        ", "for", "k", ",", "v", "in", "batch", ".", "items", "(", ")", ":", "\n", "            ", "res", "[", "k", "]", ".", "append", "(", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.align_articles.make_lookups": [[23, 60], ["bs4.BeautifulSoup.find_all", "dict", "glob.glob", "dict", "open", "bs4.BeautifulSoup", "article.find().text.strip", "open", "pickle.dump", "os.path.join", "open", "pickle.dump", "infile.read", "article.find", "align_articles.make_lookups.get_ner_info"], "function", ["None"], ["def", "make_lookups", "(", ")", ":", "\n", "    ", "\"\"\"\n    Need to match the ner data and the coref data by sentence. Create\n    dictionaries where the keys are the document ID's and the values are the\n    sentences. Save as .pkl files to match.\n    \"\"\"", "\n", "xml_path", "=", "f\"{genia_base}/raw-data/GENIAcorpus3.02p/GENIAcorpus3.02.merged.xml\"", "\n", "coref_path", "=", "f\"{genia_base}/raw-data/GENIA_MedCo_coreference_corpus_1.0\"", "\n", "\n", "with", "open", "(", "xml_path", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "soup", "=", "BS", "(", "infile", ".", "read", "(", ")", ",", "'lxml'", ")", "\n", "\n", "", "articles", "=", "soup", ".", "find_all", "(", "'article'", ")", "\n", "\n", "def", "get_ner_info", "(", "article", ")", ":", "\n", "        ", "medline_id", "=", "article", ".", "find", "(", "\"bibliomisc\"", ")", ".", "text", "\n", "title", "=", "article", ".", "find", "(", "\"title\"", ")", ".", "text", ".", "strip", "(", ")", "\n", "return", "(", "medline_id", ",", "title", ")", "\n", "\n", "", "ner_info", "=", "dict", "(", "[", "get_ner_info", "(", "entry", ")", "for", "entry", "in", "articles", "]", ")", "\n", "\n", "with", "open", "(", "f\"{genia_align}/ner_ids.pkl\"", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pkl", ".", "dump", "(", "ner_info", ",", "f", ",", "protocol", "=", "-", "1", ")", "\n", "\n", "", "coref_files", "=", "glob", ".", "glob", "(", "path", ".", "join", "(", "coref_path", ",", "\"*.xml\"", ")", ")", "\n", "\n", "def", "get_coref_info", "(", "name", ")", ":", "\n", "        ", "with", "open", "(", "name", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "this_soup", "=", "BS", "(", "f", ".", "read", "(", ")", ",", "'lxml'", ")", "\n", "pmid", "=", "this_soup", ".", "find", "(", "\"pmid\"", ")", ".", "text", "\n", "title", "=", "this_soup", ".", "find", "(", "\"articletitle\"", ")", ".", "text", ".", "strip", "(", ")", "\n", "return", "(", "pmid", ",", "title", ")", "\n", "\n", "", "", "coref_info", "=", "dict", "(", "[", "get_coref_info", "(", "entry", ")", "for", "entry", "in", "coref_files", "]", ")", "\n", "\n", "with", "open", "(", "f\"{genia_align}/coref_ids.pkl\"", ",", "\"wb\"", ")", "as", "f", ":", "\n", "        ", "pkl", ".", "dump", "(", "coref_info", ",", "f", ",", "protocol", "=", "-", "1", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.align_articles.create_matches": [[62, 106], ["align_articles.create_matches.make_comparator"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.make_comparator"], ["", "", "def", "create_matches", "(", ")", ":", "\n", "    ", "\"\"\"\n    Create a dataset mapping the ner id's to the coref id's and vice versa.\n    \"\"\"", "\n", "def", "make_comparator", "(", ")", ":", "\n", "        ", "matcher", "=", "StringMatcher", "(", ")", "\n", "\n", "def", "compare", "(", "str1", ",", "str2", ")", ":", "\n", "            ", "matcher", ".", "set_seqs", "(", "str1", ",", "str2", ")", "\n", "return", "matcher", ".", "distance", "(", ")", "\n", "", "return", "compare", "\n", "\n", "", "with", "open", "(", "f\"{genia_align}/coref_ids.pkl\"", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "coref", "=", "list", "(", "pkl", ".", "load", "(", "f", ")", ".", "items", "(", ")", ")", "\n", "", "with", "open", "(", "f\"{genia_align}/ner_ids.pkl\"", ",", "\"rb\"", ")", "as", "f", ":", "\n", "        ", "ner", "=", "list", "(", "pkl", ".", "load", "(", "f", ")", ".", "items", "(", ")", ")", "\n", "\n", "", "compare", "=", "make_comparator", "(", ")", "\n", "\n", "matched", "=", "set", "(", ")", "\n", "matches", "=", "[", "]", "\n", "# Loop over all the coref entries. Find the ner entry that's closest in edit", "\n", "# distance. If it's not 0 in edit distance, print it. Nonzero can happen", "\n", "# because of minor differences in editing.", "\n", "for", "article", "in", "coref", ":", "\n", "        ", "sentence", "=", "article", "[", "1", "]", "\n", "distance", "=", "[", "compare", "(", "sentence", ",", "entry", "[", "1", "]", ")", "for", "entry", "in", "ner", "]", "\n", "the_match", "=", "np", ".", "argmin", "(", "distance", ")", "\n", "match_article", "=", "ner", "[", "the_match", "]", "\n", "match_distance", "=", "distance", "[", "the_match", "]", "\n", "# Make sure we're not double-matching.", "\n", "if", "the_match", "in", "matched", ":", "\n", "            ", "raise", "Exception", "(", "\"Already matched.\"", ")", "\n", "", "if", "match_distance", ":", "\n", "            ", "print", "(", "sentence", ")", "\n", "print", "(", "match_article", "[", "1", "]", ")", "\n", "", "matches", ".", "append", "(", "dict", "(", "ner", "=", "match_article", "[", "0", "]", ".", "replace", "(", "\"MEDLINE:\"", ",", "\"\"", ")", ",", "\n", "coref", "=", "article", "[", "0", "]", ")", ")", "\n", "matched", ".", "add", "(", "the_match", ")", "\n", "\n", "", "matches", "=", "pd", ".", "DataFrame", "(", "matches", ")", "\n", "outfile", "=", "f\"{genia_align}/alignment.csv\"", "\n", "matches", ".", "to_csv", "(", "outfile", ",", "index", "=", "False", ")", "\n", "print", "(", "\"All done.\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.align_articles.main": [[108, 111], ["align_articles.make_lookups", "align_articles.create_matches"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.align_articles.make_lookups", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.align_articles.create_matches"], ["", "def", "main", "(", ")", ":", "\n", "    ", "make_lookups", "(", ")", "\n", "create_matches", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.make_comparator": [[20, 27], ["Levenshtein.StringMatcher.StringMatcher", "Levenshtein.StringMatcher.StringMatcher.set_seqs", "Levenshtein.StringMatcher.StringMatcher.distance"], "function", ["None"], ["def", "make_comparator", "(", ")", ":", "\n", "    ", "matcher", "=", "StringMatcher", "(", ")", "\n", "\n", "def", "compare", "(", "str1", ",", "str2", ")", ":", "\n", "        ", "matcher", ".", "set_seqs", "(", "str1", ",", "str2", ")", "\n", "return", "matcher", ".", "distance", "(", ")", "\n", "", "return", "compare", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.make_sentences": [[29, 39], ["enumerate", "sentences.append", "sentence.append", "sentences.append"], "function", ["None"], ["", "def", "make_sentences", "(", "lines", ")", ":", "\n", "    ", "sentences", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "if", "i", "and", "not", "i", "%", "4", ":", "\n", "            ", "sentences", ".", "append", "(", "sentence", ")", "\n", "sentence", "=", "[", "]", "\n", "", "sentence", ".", "append", "(", "line", ")", "\n", "", "sentences", ".", "append", "(", "sentence", ")", "# Get the last one.", "\n", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.get_matching_sentences": [[41, 47], ["len", "range", "resolve_differences.make_sentences", "sents_sutd.append", "sutd.readline"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.make_sentences"], ["", "def", "get_matching_sentences", "(", "sentences_article", ",", "sutd", ")", ":", "\n", "    ", "num_sentences", "=", "len", "(", "sentences_article", ")", "\n", "sents_sutd", "=", "[", "]", "\n", "for", "_", "in", "range", "(", "4", "*", "num_sentences", ")", ":", "\n", "        ", "sents_sutd", ".", "append", "(", "sutd", ".", "readline", "(", ")", ")", "\n", "", "return", "make_sentences", "(", "sents_sutd", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.fix_fold": [[49, 75], ["resolve_differences.make_comparator", "open", "os.path.join", "os.path.join", "shutil.copyfile", "os.path.join", "pandas.read_csv", "os.path.exists", "os.mkdir", "os.path.join", "os.path.join", "open", "os.path.join", "open", "resolve_differences.make_sentences", "resolve_differences.get_matching_sentences", "os.path.join", "article.readlines", "len", "len", "Exception", "make_comparator.", "max", "Exception", "zip", "f_out.write"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.make_comparator", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.make_sentences", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.get_matching_sentences"], ["", "def", "fix_fold", "(", "fold", ")", ":", "\n", "    ", "comparator", "=", "make_comparator", "(", ")", "\n", "sutd", "=", "open", "(", "path", ".", "join", "(", "sutd_dir", ",", "\"{0}.data\"", ".", "format", "(", "fold", ")", ")", ",", "\"r\"", ")", "\n", "doc_order_file", "=", "path", ".", "join", "(", "article_dir", ",", "\"{0}_order.csv\"", ".", "format", "(", "fold", ")", ")", "\n", "doc_order", "=", "pd", ".", "read_csv", "(", "doc_order_file", ",", "header", "=", "None", ",", "sep", "=", "\"\\t\"", ")", "[", "0", "]", "\n", "\n", "if", "not", "path", ".", "exists", "(", "path", ".", "join", "(", "out_dir", ",", "fold", ")", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "path", ".", "join", "(", "out_dir", ",", "fold", ")", ")", "\n", "\n", "", "doc_order_file_to_copy", "=", "path", ".", "join", "(", "out_dir", ",", "\"{0}_order.csv\"", ".", "format", "(", "fold", ")", ")", "\n", "copyfile", "(", "doc_order_file", ",", "doc_order_file_to_copy", ")", "\n", "\n", "for", "doc", "in", "doc_order", ":", "\n", "        ", "with", "open", "(", "path", ".", "join", "(", "article_dir", ",", "fold", ",", "\"{0}.data\"", ".", "format", "(", "doc", ")", ")", ",", "\"r\"", ")", "as", "article", ":", "\n", "            ", "with", "open", "(", "path", ".", "join", "(", "out_dir", ",", "fold", ",", "\"{0}.data\"", ".", "format", "(", "doc", ")", ")", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "                ", "sents_article", "=", "make_sentences", "(", "article", ".", "readlines", "(", ")", ")", "\n", "sents_sutd", "=", "get_matching_sentences", "(", "sents_article", ",", "sutd", ")", "\n", "if", "len", "(", "sents_article", ")", "!=", "len", "(", "sents_sutd", ")", ":", "\n", "                    ", "raise", "Exception", "(", "\"Wrong length.\"", ")", "\n", "", "dists", "=", "[", "comparator", "(", "sent_article", "[", "0", "]", ",", "sent_sutd", "[", "0", "]", ")", "\n", "for", "sent_article", ",", "sent_sutd", "in", "zip", "(", "sents_article", ",", "sents_sutd", ")", "]", "\n", "if", "max", "(", "dists", ")", ">", "15", ":", "\n", "                    ", "raise", "Exception", "(", "\"There's a problem with {0}.\"", ".", "format", "(", "doc", ")", ")", "\n", "", "for", "sent", "in", "sents_sutd", ":", "\n", "                    ", "for", "line", "in", "sent", ":", "\n", "                        ", "f_out", ".", "write", "(", "line", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.main": [[77, 83], ["os.path.exists", "os.mkdir", "resolve_differences.fix_fold"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.resolve_differences.fix_fold"], ["", "", "", "", "", "", "def", "main", "(", ")", ":", "\n", "    ", "if", "not", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "\n", "", "for", "fold", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", ":", "\n", "        ", "fix_fold", "(", "fold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Coref.__init__": [[58, 70], ["merge_coref.Coref._get_span", "re.split", "xml.attrs[].split"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Coref._get_span", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["def", "__init__", "(", "self", ",", "xml", ",", "soup_text", ",", "sents", ")", ":", "\n", "        ", "\"Get the text, id, referrent, and text span.\"", "\n", "self", ".", "xml", "=", "xml", "\n", "self", ".", "text", "=", "xml", ".", "text", "\n", "self", ".", "tokens", "=", "[", "tok", "for", "tok", "in", "re", ".", "split", "(", "'([ -/,.+])'", ",", "self", ".", "text", ")", "\n", "if", "tok", "not", "in", "[", "\"\"", ",", "\" \"", "]", "]", "\n", "self", ".", "id", "=", "xml", ".", "attrs", "[", "\"id\"", "]", "\n", "# A very small number of corefs have two parents. I'm going to just take the first parent.", "\n", "# TODO(dwadden) If time, go back and fix this.", "\n", "self", ".", "ref", "=", "xml", ".", "attrs", "[", "\"ref\"", "]", ".", "split", "(", "\" \"", ")", "[", "0", "]", "if", "\"ref\"", "in", "xml", ".", "attrs", "else", "None", "\n", "self", ".", "span", "=", "self", ".", "_get_span", "(", "sents", ",", "soup_text", ")", "\n", "self", ".", "type", "=", "xml", ".", "attrs", "[", "\"type\"", "]", "if", "\"type\"", "in", "xml", ".", "attrs", "else", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Coref._get_span": [[71, 107], ["shared.find_sub_lists", "len", "merge_coref.Coref.xml.__repr__", "shared.find_sub_lists", "shared.find_sub_lists", "text_inside.index", "list", "list", "len", "list", "list", "len", "sum"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.find_sub_lists", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.find_sub_lists", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.find_sub_lists", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["", "def", "_get_span", "(", "self", ",", "sents", ",", "soup_text", ")", ":", "\n", "        ", "\"\"\"Get text span of coref. We have inclusive endpoints.\"\"\"", "\n", "\n", "spans", "=", "shared", ".", "find_sub_lists", "(", "self", ".", "tokens", ",", "sents", ")", "\n", "n_matches", "=", "len", "(", "spans", ")", "\n", "# Case 1: If can't match the span, record and return. This doesn't happen", "\n", "# much.", "\n", "if", "n_matches", "==", "0", ":", "\n", "            ", "stats", "[", "\"no_matches\"", "]", "+=", "1", "\n", "return", "None", "\n", "# Case 2: IF there are multiple span matches, go back and look the original", "\n", "# XML tag to determine which match we want.", "\n", "", "elif", "n_matches", ">", "1", ":", "\n", "            ", "xml_tag", "=", "self", ".", "xml", ".", "__repr__", "(", ")", "\n", "tmp_ixs", "=", "shared", ".", "find_sub_lists", "(", "list", "(", "self", ".", "text", ")", ",", "list", "(", "soup_text", ")", ")", "\n", "text_ixs", "=", "[", "]", "\n", "# Last character of the match must be a dash or char after must be an", "\n", "# escape, else we're not at end of token.", "\n", "text_ixs", "=", "[", "ixs", "for", "ixs", "in", "tmp_ixs", "if", "\n", "soup_text", "[", "ixs", "[", "1", "]", "+", "1", "]", "in", "'([ -/,.+])<'", "or", "soup_text", "[", "ixs", "[", "1", "]", "]", "==", "\"-\"", "]", "\n", "if", "len", "(", "text_ixs", ")", "!=", "n_matches", ":", "\n", "# If the number of xml tag matches doesn't equal the number of span", "\n", "# matches, record and return.", "\n", "                ", "stats", "[", "\"different_num_matches\"", "]", "+=", "1", "\n", "return", "None", "\n", "", "tag_ix", "=", "shared", ".", "find_sub_lists", "(", "list", "(", "xml_tag", ")", ",", "list", "(", "soup_text", ")", ")", "\n", "assert", "len", "(", "tag_ix", ")", "==", "1", "\n", "tag_ix", "=", "tag_ix", "[", "0", "]", "\n", "text_inside", "=", "[", "x", "[", "0", "]", ">=", "tag_ix", "[", "0", "]", "and", "x", "[", "1", "]", "<=", "tag_ix", "[", "1", "]", "for", "x", "in", "text_ixs", "]", "\n", "assert", "sum", "(", "text_inside", ")", "==", "1", "\n", "match_ix", "=", "text_inside", ".", "index", "(", "True", ")", "\n", "", "else", ":", "\n", "            ", "match_ix", "=", "0", "\n", "", "stats", "[", "\"successful_matches\"", "]", "+=", "1", "\n", "span", "=", "spans", "[", "match_ix", "]", "\n", "return", "span", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs.__init__": [[112, 126], ["soup.find_all", "sorted", "merge_coref.Corefs._assign_parent_indices", "merge_coref.Corefs._get_coref_clusters", "merge_coref.Corefs._cleanup_coref_clusters", "merge_coref.Corefs._make_cluster_spans", "merge_coref.Coref", "soup.__repr__"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._assign_parent_indices", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._get_coref_clusters", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._cleanup_coref_clusters", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._make_cluster_spans", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.__repr__"], ["def", "__init__", "(", "self", ",", "soup", ",", "sents_flat", ",", "coref_types", ")", ":", "\n", "        ", "self", ".", "coref_types", "=", "coref_types", "\n", "coref_items", "=", "soup", ".", "find_all", "(", "\"coref\"", ")", "\n", "corefs", "=", "[", "Coref", "(", "item", ",", "soup", ".", "__repr__", "(", ")", ",", "sents_flat", ")", "for", "item", "in", "coref_items", "]", "\n", "# Put the cluster exemplars first.", "\n", "corefs", "=", "sorted", "(", "corefs", ",", "key", "=", "lambda", "coref", ":", "coref", ".", "ref", "is", "None", ",", "reverse", "=", "True", ")", "\n", "coref_ids", "=", "[", "coref", ".", "id", "for", "coref", "in", "corefs", "]", "\n", "corefs", "=", "self", ".", "_assign_parent_indices", "(", "corefs", ",", "coref_ids", ")", "\n", "clusters", "=", "self", ".", "_get_coref_clusters", "(", "corefs", ")", "\n", "clusters", "=", "self", ".", "_cleanup_coref_clusters", "(", "corefs", ",", "clusters", ")", "\n", "cluster_spans", "=", "self", ".", "_make_cluster_spans", "(", "clusters", ")", "\n", "self", ".", "corefs", "=", "corefs", "\n", "self", ".", "clusters", "=", "clusters", "\n", "self", ".", "cluster_spans", "=", "cluster_spans", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._assign_parent_indices": [[127, 136], ["coref_ids.index"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["", "@", "staticmethod", "\n", "def", "_assign_parent_indices", "(", "corefs", ",", "coref_ids", ")", ":", "\n", "        ", "\"\"\"Give each coref the index of it parent in the list of corefs.\"\"\"", "\n", "for", "coref", "in", "corefs", ":", "\n", "            ", "if", "coref", ".", "ref", "is", "None", ":", "\n", "                ", "coref", ".", "parent_ix", "=", "None", "\n", "", "else", ":", "\n", "                ", "coref", ".", "parent_ix", "=", "coref_ids", ".", "index", "(", "coref", ".", "ref", ")", "\n", "", "", "return", "corefs", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._get_coref_clusters": [[137, 162], ["set", "set", "set.add", "set", "merge_coref.Corefs._get_coref_clusters.get_cluster_assignment"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_coref_clusters", "(", "corefs", ")", ":", "\n", "        ", "def", "get_cluster_assignment", "(", "coref", ")", ":", "\n", "            ", "ids_so_far", "=", "set", "(", ")", "\n", "this_coref", "=", "coref", "\n", "while", "this_coref", ".", "ref", "is", "not", "None", ":", "\n", "# Condition to prevent self-loops.", "\n", "                ", "if", "this_coref", ".", "id", "in", "ids_so_far", "or", "this_coref", ".", "id", "==", "this_coref", ".", "ref", ":", "\n", "                    ", "return", "None", "\n", "", "ids_so_far", ".", "add", "(", "this_coref", ".", "id", ")", "\n", "parent", "=", "corefs", "[", "this_coref", ".", "parent_ix", "]", "\n", "this_coref", "=", "parent", "\n", "", "return", "this_coref", ".", "id", "\n", "\n", "", "clusters", "=", "{", "None", ":", "set", "(", ")", "}", "\n", "for", "coref", "in", "corefs", ":", "\n", "            ", "if", "coref", ".", "ref", "is", "None", ":", "\n", "# It's a cluster exemplar", "\n", "                ", "coref", ".", "cluster_assignment", "=", "coref", ".", "id", "\n", "clusters", "[", "coref", ".", "id", "]", "=", "set", "(", "[", "coref", "]", ")", "\n", "", "else", ":", "\n", "                ", "cluster_assignment", "=", "get_cluster_assignment", "(", "coref", ")", "\n", "coref", ".", "cluster_assignment", "=", "cluster_assignment", "\n", "clusters", "[", "cluster_assignment", "]", ".", "add", "(", "coref", ")", "\n", "", "", "return", "clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._cleanup_coref_clusters": [[163, 187], ["clusters.pop", "list", "clusters.keys", "len", "clusters.pop", "clusters.pop", "clusters[].remove"], "methods", ["None"], ["", "def", "_cleanup_coref_clusters", "(", "self", ",", "corefs", ",", "clusters", ")", ":", "\n", "        ", "\"\"\"\n        Remove items that didn't get spans, don't have an allowed coref type, or\n        weren't assigned a cluster\n        \"\"\"", "\n", "# Remove unassigned corefs.", "\n", "_", "=", "clusters", ".", "pop", "(", "None", ")", "\n", "for", "coref", "in", "corefs", ":", "\n", "# If the referent entity didn't get a span match, remove the cluster.", "\n", "            ", "if", "coref", ".", "ref", "is", "None", ":", "\n", "                ", "if", "coref", ".", "span", "is", "None", ":", "\n", "                    ", "_", "=", "clusters", ".", "pop", "(", "coref", ".", "id", ")", "\n", "# If a referring coref didn't have a span or isn't the right coref type, remove it.", "\n", "", "", "else", ":", "\n", "                ", "if", "coref", ".", "type", "not", "in", "self", ".", "coref_types", "or", "coref", ".", "span", "is", "None", ":", "\n", "# Check to make sure the cluster wasn't already removed.", "\n", "                    ", "if", "coref", ".", "cluster_assignment", "in", "clusters", ":", "\n", "                        ", "clusters", "[", "coref", ".", "cluster_assignment", "]", ".", "remove", "(", "coref", ")", "\n", "# Now remove singleton clusters.", "\n", "# Need to make it a list to avoid `dictionary size changed iteration` error.\"", "\n", "", "", "", "", "for", "key", "in", "list", "(", "clusters", ".", "keys", "(", ")", ")", ":", "\n", "            ", "if", "len", "(", "clusters", "[", "key", "]", ")", "==", "1", ":", "\n", "                ", "_", "=", "clusters", ".", "pop", "(", "key", ")", "\n", "", "", "return", "clusters", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.Corefs._make_cluster_spans": [[188, 198], ["clusters.items", "res.append", "cluster_spans.append", "sorted", "list"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_make_cluster_spans", "(", "clusters", ")", ":", "\n", "        ", "\"\"\"Convert to nested list of cluster spans, as in scierc data.\"\"\"", "\n", "res", "=", "[", "]", "\n", "for", "key", ",", "cluster", "in", "clusters", ".", "items", "(", ")", ":", "\n", "            ", "cluster_spans", "=", "[", "]", "\n", "for", "coref", "in", "cluster", ":", "\n", "                ", "cluster_spans", ".", "append", "(", "list", "(", "coref", ".", "span", ")", ")", "\n", "", "res", ".", "append", "(", "sorted", "(", "cluster_spans", ")", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.get_coref_types": [[33, 53], ["glob.glob", "collections.defaultdict", "enumerate", "pandas.DataFrame", "res.sort_values.sort_values", "res.sort_values.to_csv", "os.path.join", "collections.defaultdict.items", "open", "bs4.BeautifulSoup", "bs4.BeautifulSoup.find_all", "f.read().decode", "f.read"], "function", ["None"], ["def", "get_coref_types", "(", ")", ":", "\n", "    ", "\"\"\"\n    Get the different types of coref in the GENIA data set, and save to file. Once this is done\n    once, just hard-code the list of coref types.\n    \"\"\"", "\n", "coref_files", "=", "glob", ".", "glob", "(", "path", ".", "join", "(", "coref_dir", ",", "\"*xml\"", ")", ")", "\n", "coref_counts", "=", "defaultdict", "(", "lambda", ":", "0", ")", "\n", "for", "i", ",", "coref_file", "in", "enumerate", "(", "coref_files", ")", ":", "\n", "        ", "with", "open", "(", "coref_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "            ", "soup", "=", "BS", "(", "f", ".", "read", "(", ")", ".", "decode", "(", "\"utf-8\"", ")", ",", "\"lxml\"", ")", "\n", "corefs", "=", "soup", ".", "find_all", "(", "\"coref\"", ")", "\n", "for", "coref", "in", "corefs", ":", "\n", "                ", "coref_type", "=", "coref", ".", "attrs", "[", "\"type\"", "]", "if", "\"type\"", "in", "coref", ".", "attrs", "else", "\"NONE\"", "\n", "coref_counts", "[", "coref_type", "]", "+=", "1", "\n", "\n", "", "", "", "res", "=", "pd", ".", "DataFrame", "(", "coref_counts", ".", "items", "(", ")", ")", "\n", "res", ".", "columns", "=", "[", "\"label\"", ",", "\"count\"", "]", "\n", "res", "=", "res", ".", "sort_values", "(", "\"count\"", ",", "ascending", "=", "False", ")", "\n", "out_file", "=", "\"/data/dave/proj/scierc_coref/data/genia/stats/coref-counts.csv\"", "\n", "res", ".", "to_csv", "(", "out_file", ",", "index", "=", "False", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.get_excluded": [[200, 205], ["os.path.dirname", "os.path.realpath", "pandas.read_table"], "function", ["None"], ["", "", "def", "get_excluded", "(", ")", ":", "\n", "    ", "\"Get list of files that had random off-by-1-errors and will be excluded.\"", "\n", "current_path", "=", "os", ".", "path", ".", "dirname", "(", "os", ".", "path", ".", "realpath", "(", "__file__", ")", ")", "\n", "excluded", "=", "pd", ".", "read_table", "(", "f\"{current_path}/exclude.txt\"", ",", "header", "=", "None", ",", "squeeze", "=", "True", ")", ".", "values", "\n", "return", "excluded", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.one_fold": [[207, 226], ["print", "merge_coref.get_excluded", "open", "os.path.join", "open", "enumerate", "os.path.join", "json.loads", "int", "os.path.join", "shared.flatten", "open", "bs4.BeautifulSoup", "merge_coref.Corefs", "f_out.write", "doc[].split", "str", "f_xml.read", "json.dumps"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.get_excluded", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.shared.flatten", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "one_fold", "(", "fold", ",", "coref_types", ",", "out_dir", ",", "keep_excluded", ")", ":", "\n", "    ", "\"\"\"Add coref field to json, one fold.\"\"\"", "\n", "print", "(", "\"Running fold {0}.\"", ".", "format", "(", "fold", ")", ")", "\n", "excluded", "=", "get_excluded", "(", ")", "\n", "with", "open", "(", "path", ".", "join", "(", "json_dir", ",", "\"{0}.json\"", ".", "format", "(", "fold", ")", ")", ")", "as", "f_json", ":", "\n", "        ", "with", "open", "(", "path", ".", "join", "(", "out_dir", ",", "\"{0}.json\"", ".", "format", "(", "fold", ")", ")", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "            ", "for", "counter", ",", "line", "in", "enumerate", "(", "f_json", ")", ":", "\n", "                ", "doc", "=", "json", ".", "loads", "(", "line", ")", "\n", "pmid", "=", "int", "(", "doc", "[", "\"doc_key\"", "]", ".", "split", "(", "\"_\"", ")", "[", "0", "]", ")", "\n", "medline_id", "=", "alignment", ".", "loc", "[", "pmid", "]", "[", "0", "]", "\n", "xml_file", "=", "path", ".", "join", "(", "coref_dir", ",", "str", "(", "medline_id", ")", "+", "\".xml\"", ")", "\n", "sents_flat", "=", "shared", ".", "flatten", "(", "doc", "[", "\"sentences\"", "]", ")", "\n", "with", "open", "(", "xml_file", ",", "\"r\"", ")", "as", "f_xml", ":", "\n", "                    ", "soup", "=", "BS", "(", "f_xml", ".", "read", "(", ")", ",", "\"lxml\"", ")", "\n", "corefs", "=", "Corefs", "(", "soup", ",", "sents_flat", ",", "coref_types", ")", "\n", "", "doc", "[", "\"clusters\"", "]", "=", "corefs", ".", "cluster_spans", "\n", "# Save unless it's bad and we're excluding bad documents.", "\n", "if", "keep_excluded", "or", "doc", "[", "\"doc_key\"", "]", "not", "in", "excluded", ":", "\n", "                    ", "f_out", ".", "write", "(", "json", ".", "dumps", "(", "doc", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.get_clusters": [[228, 235], ["dict", "print", "merge_coref.one_fold"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.one_fold"], ["", "", "", "", "", "def", "get_clusters", "(", "coref_types", ",", "out_dir", ",", "keep_excluded", ")", ":", "\n", "    ", "\"\"\"Add coref to json, filtering to only keep coref roots and `coref_types`.\"\"\"", "\n", "global", "stats", "\n", "stats", "=", "dict", "(", "no_matches", "=", "0", ",", "successful_matches", "=", "0", ",", "different_num_matches", "=", "0", ")", "\n", "for", "fold", "in", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", ":", "\n", "        ", "one_fold", "(", "fold", ",", "coref_types", ",", "out_dir", ",", "keep_excluded", ")", "\n", "", "print", "(", "stats", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.main": [[237, 266], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "merge_coref.get_clusters", "os.path.exists", "os.mkdir"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.merge_coref.get_clusters"], ["", "def", "main", "(", ")", ":", "\n", "# get_coref_types()", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", ")", "\n", "parser", ".", "add_argument", "(", "\"--ident-only\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, only do `IDENT` coreferences.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--keep-excluded\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If true, keep training docs that were excluded due to off-by-1 errors.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "if", "args", ".", "ident_only", ":", "\n", "        ", "coref_types", "=", "[", "\"IDENT\"", "]", "\n", "", "else", ":", "\n", "        ", "coref_types", "=", "[", "\n", "\"IDENT\"", ",", "\n", "\"NONE\"", ",", "\n", "\"RELAT\"", ",", "\n", "\"PRON\"", ",", "\n", "\"APPOS\"", ",", "\n", "\"OTHER\"", ",", "\n", "\"PART-WHOLE\"", ",", "\n", "\"WHOLE-PART\"", "\n", "]", "\n", "\n", "", "coref_type_name", "=", "\"ident-only\"", "if", "args", ".", "ident_only", "else", "\"all\"", "\n", "out_dir", "=", "f\"{genia_processed}/json-coref-{coref_type_name}\"", "\n", "\n", "if", "not", "path", ".", "exists", "(", "out_dir", ")", ":", "\n", "        ", "os", ".", "mkdir", "(", "out_dir", ")", "\n", "\n", "", "get_clusters", "(", "coref_types", ",", "out_dir", ",", "args", ".", "keep_excluded", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.check_genia_xml_sutd.check_against_xml_source": [[13, 47], ["bs4.BeautifulSoup.find_all", "os.listdir", "random.shuffle", "open", "bs4.BeautifulSoup", "print", "infile.read", "open", "f.readlines", "article.get_text", "print", "print", "os.path.join", "print", "print", "print", "print", "print"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.genia_xml_to_inline_sutd.Annotation.get_text"], ["def", "check_against_xml_source", "(", ")", ":", "\n", "    ", "\"Make sure my processed documents are consistent with the source XML\"", "\n", "processed_dir", "=", "\"/data/dave/proj/scierc_coref/data/genia/sutd-article/final\"", "\n", "xml_file", "=", "\"/data/dave/proj/scierc_coref/data/genia/GENIAcorpus3.02p/GENIAcorpus3.02.merged.xml\"", "\n", "\n", "with", "open", "(", "xml_file", ",", "'r'", ")", "as", "infile", ":", "\n", "        ", "soup", "=", "BS", "(", "infile", ".", "read", "(", ")", ",", "'lxml'", ")", "\n", "", "articles", "=", "soup", ".", "find_all", "(", "'article'", ")", "\n", "\n", "# Check 5 random files", "\n", "\n", "files", "=", "os", ".", "listdir", "(", "processed_dir", ")", "\n", "random", ".", "shuffle", "(", "files", ")", "\n", "files", "=", "files", "[", ":", "5", "]", "\n", "\n", "for", "processed_file", "in", "files", ":", "\n", "        ", "with", "open", "(", "path", ".", "join", "(", "processed_dir", ",", "processed_file", ")", ",", "'r'", ")", "as", "f", ":", "\n", "            ", "lines", "=", "f", ".", "readlines", "(", ")", "\n", "art_text", "=", "\"\"", ".", "join", "(", "x", "for", "x", "in", "lines", "[", ":", ":", "4", "]", ")", ".", "replace", "(", "\" ,\"", ",", "\"\"", ")", "\n", "\n", "", "found_one", "=", "False", "\n", "for", "article", "in", "articles", ":", "\n", "            ", "this_text", "=", "article", ".", "get_text", "(", ")", "\n", "if", "art_text", "[", ":", "50", "]", "in", "this_text", "or", "art_text", "[", "200", ":", "250", "]", "in", "this_text", ":", "\n", "                ", "found_one", "=", "True", "\n", "print", "(", "\"Got one.\"", ")", "\n", "print", "(", "this_text", ")", "\n", "print", "(", ")", "\n", "print", "(", "art_text", ")", "\n", "print", "(", ")", "\n", "", "", "if", "not", "found_one", ":", "\n", "            ", "print", "(", "\"Didn't find one.\"", ")", "\n", "print", "(", "art_text", ")", "\n", "", "print", "(", "40", "*", "\"#\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.check_genia_xml_sutd.check_against_sutd_processed": [[49, 70], ["print", "print", "open", "f.readlines", "open", "f.readlines", "sum", "len", "zip", "enumerate", "len"], "function", ["None"], ["", "", "def", "check_against_sutd_processed", "(", ")", ":", "\n", "    ", "\"\"\"\n    Grab one of my processed documents. Make sure I can find a match in one of\n    the SUTD processed files.\n    \"\"\"", "\n", "theirs_file", "=", "\"/data/dave/proj/scierc_coref/data/genia/sutd/test.data\"", "\n", "with", "open", "(", "theirs_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "theirs", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "mine_file", "=", "\"/data/dave/proj/scierc_coref/data/genia/sutd-article/final/90244434.tok.5types.no_disc.data\"", "\n", "with", "open", "(", "mine_file", ",", "\"r\"", ")", "as", "f", ":", "\n", "        ", "mine", "=", "f", ".", "readlines", "(", ")", "\n", "\n", "", "my_first", "=", "mine", "[", "0", "]", "\n", "foo", "=", "[", "entry", "==", "my_first", "for", "entry", "in", "theirs", "]", "\n", "ix", "=", "[", "i", "for", "i", ",", "entry", "in", "enumerate", "(", "foo", ")", "if", "entry", "]", "[", "0", "]", "\n", "theirs_match", "=", "theirs", "[", "ix", ":", "ix", "+", "len", "(", "mine", ")", "]", "\n", "\n", "same", "=", "[", "x", "==", "y", "for", "x", ",", "y", "in", "zip", "(", "mine", ",", "theirs_match", ")", "]", "\n", "print", "(", "sum", "(", "same", ")", ")", "\n", "print", "(", "len", "(", "mine", ")", ")", "\n", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.save_list": [[13, 18], ["open", "f.write", "str"], "function", ["None"], ["def", "save_list", "(", "xs", ",", "name", ")", ":", "\n", "    ", "\"Save a list as text, one entry per line.\"", "\n", "with", "open", "(", "name", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "x", "in", "xs", ":", "\n", "            ", "f", ".", "write", "(", "str", "(", "x", ")", "+", "\"\\n\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.make_sentences": [[20, 30], ["enumerate", "sentences.append", "sentence.append", "sentences.append", "line.strip"], "function", ["None"], ["", "", "", "def", "make_sentences", "(", "lines", ")", ":", "\n", "    ", "sentences", "=", "[", "]", "\n", "sentence", "=", "[", "]", "\n", "for", "i", ",", "line", "in", "enumerate", "(", "lines", ")", ":", "\n", "        ", "if", "i", "and", "not", "i", "%", "4", ":", "\n", "            ", "sentences", ".", "append", "(", "sentence", ")", "\n", "sentence", "=", "[", "]", "\n", "", "sentence", ".", "append", "(", "line", ".", "strip", "(", ")", ")", "\n", "", "sentences", ".", "append", "(", "sentence", ")", "# Get the last one.", "\n", "return", "sentences", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.format_tag": [[32, 43], ["tag.split", "ixs.split", "name.replace.replace", "int", "int"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split"], ["", "def", "format_tag", "(", "tag", ",", "offset", ")", ":", "\n", "    ", "ixs", ",", "name", "=", "tag", ".", "split", "(", "\" \"", ")", "\n", "# TODO(dwadden) this is a hack. Shouldn't be happening, but uncommon enough", "\n", "# that not worth fixing.", "\n", "if", "not", "ixs", ":", "\n", "        ", "return", "None", "\n", "", "start_ix", ",", "end_ix", "=", "ixs", ".", "split", "(", "\",\"", ")", "\n", "start_ix", "=", "int", "(", "start_ix", ")", "+", "offset", "\n", "end_ix", "=", "int", "(", "end_ix", ")", "+", "offset", "-", "1", "# Our endpoints are inclusive, not exclusive.", "\n", "name", "=", "name", ".", "replace", "(", "\"G#\"", ",", "\"\"", ")", "\n", "return", "[", "start_ix", ",", "end_ix", ",", "name", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.no_tags": [[45, 47], ["len"], "function", ["None"], ["", "def", "no_tags", "(", "line", ")", ":", "\n", "    ", "return", "len", "(", "line", ")", "==", "1", "and", "line", "[", "0", "]", "==", "''", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.process_ner": [[49, 58], ["line.split", "convert_to_json.format_tag"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.format_tag"], ["", "def", "process_ner", "(", "line", ",", "offset", ")", ":", "\n", "# If not NER tags, return an empty list.", "\n", "    ", "if", "not", "line", ":", "\n", "        ", "return", "[", "]", "\n", "", "else", ":", "\n", "        ", "tags", "=", "line", ".", "split", "(", "\"|\"", ")", "\n", "formatted", "=", "[", "format_tag", "(", "tag", ",", "offset", ")", "for", "tag", "in", "tags", "]", "\n", "# TODO(dwadden) this continues the hack from above.", "\n", "return", "[", "entry", "for", "entry", "in", "formatted", "if", "entry", "is", "not", "None", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.sentence_to_json": [[60, 67], ["sent[].split", "convert_to_json.process_ner"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.process_ner"], ["", "", "def", "sentence_to_json", "(", "sent", ",", "offset", ")", ":", "\n", "    ", "\"\"\"Get the tokens and NER tags. Ignore the POS tags.\"\"\"", "\n", "# No doc keys in the statnlp paper. Start by ignoring.", "\n", "tokens", "=", "sent", "[", "0", "]", ".", "split", "(", "\" \"", ")", "\n", "ner_tags", "=", "process_ner", "(", "sent", "[", "2", "]", ",", "offset", ")", "\n", "res", "=", "tokens", ",", "ner_tags", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.doc_to_json": [[69, 88], ["dict", "convert_to_json.sentence_to_json", "res[].append", "res[].append", "res[].append", "res[].append", "len", "str"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.sentence_to_json"], ["", "def", "doc_to_json", "(", "sents", ",", "doc_id", ",", "fold", ")", ":", "\n", "    ", "\"\"\"A list of sentences (a document) to json.\"\"\"", "\n", "# Append fold info to doc_key since one doc appears in both train and dev;", "\n", "# ditto dev and test.", "\n", "res", "=", "dict", "(", "clusters", "=", "[", "]", ",", "\n", "sentences", "=", "[", "]", ",", "\n", "ner", "=", "[", "]", ",", "\n", "relations", "=", "[", "]", ",", "\n", "doc_key", "=", "str", "(", "doc_id", ")", "+", "'_'", "+", "fold", ")", "\n", "offset", "=", "0", "\n", "for", "sent", "in", "sents", ":", "\n", "        ", "tokens_sent", ",", "ner_tags_sent", "=", "sentence_to_json", "(", "sent", ",", "offset", ")", "\n", "res", "[", "\"clusters\"", "]", ".", "append", "(", "[", "]", ")", "\n", "res", "[", "\"sentences\"", "]", ".", "append", "(", "tokens_sent", ")", "\n", "res", "[", "\"ner\"", "]", ".", "append", "(", "ner_tags_sent", ")", "\n", "res", "[", "\"relations\"", "]", ".", "append", "(", "[", "]", ")", "\n", "# Start the next set of indices from this offset.", "\n", "offset", "+=", "len", "(", "tokens_sent", ")", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.get_unique_ner_labels": [[90, 97], ["set", "set.add"], "function", ["None"], ["", "def", "get_unique_ner_labels", "(", "jsonified", ")", ":", "\n", "    ", "\"Get unique NER labels.\"", "\n", "labels", "=", "set", "(", ")", "\n", "for", "sentence", "in", "jsonified", "[", "\"ner\"", "]", ":", "\n", "        ", "for", "entry", "in", "sentence", ":", "\n", "            ", "labels", ".", "add", "(", "entry", "[", "2", "]", ")", "\n", "", "", "return", "labels", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.format_fold": [[99, 121], ["os.path.join", "set", "open", "set", "pandas.read_csv", "set.add", "os.path.join", "open", "f_in.readlines", "convert_to_json.make_sentences", "convert_to_json.doc_to_json", "convert_to_json.get_unique_ner_labels", "f_out.write", "os.path.join", "json.dumps"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.make_sentences", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.doc_to_json", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.get_unique_ner_labels"], ["", "def", "format_fold", "(", "fold", ",", "in_dir", ",", "out_dir", ")", ":", "\n", "    ", "\"\"\"Take data SUTD-formatted documents and convert to our JSON format.\"\"\"", "\n", "out_name", "=", "path", ".", "join", "(", "out_dir", ",", "\"{0}.json\"", ".", "format", "(", "fold", ")", ")", "\n", "ner_labels", "=", "set", "(", ")", "\n", "with", "open", "(", "out_name", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "        ", "order", "=", "pd", ".", "read_csv", "(", "path", ".", "join", "(", "in_dir", ",", "\"{0}_order.csv\"", ".", "format", "(", "fold", ")", ")", ",", "header", "=", "None", ",", "sep", "=", "\"\\t\"", ")", "[", "0", "]", "\n", "already_written", "=", "set", "(", ")", "\n", "for", "doc_id", "in", "order", ":", "\n", "# I need this check because there is a duplicate document in the train", "\n", "# set, which makes elmo barf. This isn't a problem with my code, it's", "\n", "# upstream somewhere.", "\n", "            ", "if", "doc_id", "in", "already_written", ":", "\n", "                ", "continue", "\n", "", "already_written", ".", "add", "(", "doc_id", ")", "\n", "with", "open", "(", "path", ".", "join", "(", "in_dir", ",", "fold", ",", "\"{0}.data\"", ".", "format", "(", "doc_id", ")", ")", ",", "\"r\"", ")", "as", "f_in", ":", "\n", "                ", "lines", "=", "f_in", ".", "readlines", "(", ")", "\n", "sents", "=", "make_sentences", "(", "lines", ")", "\n", "jsonified", "=", "doc_to_json", "(", "sents", ",", "doc_id", ",", "fold", ")", "\n", "ner_labels_article", "=", "get_unique_ner_labels", "(", "jsonified", ")", "\n", "ner_labels", "=", "ner_labels", "|", "ner_labels_article", "\n", "f_out", ".", "write", "(", "json", ".", "dumps", "(", "jsonified", ")", "+", "\"\\n\"", ")", "\n", "", "", "", "return", "ner_labels", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.main": [[123, 138], ["os.makedirs", "set", "convert_to_json.save_list", "print", "convert_to_json.format_fold", "sorted", "os.path.join"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.save_list", "home.repos.pwc.inspect_result.dwadden_dygiepp.genia.convert_to_json.format_fold"], ["", "def", "main", "(", ")", ":", "\n", "    ", "in_prefix", "=", "\"./data/genia/raw-data/sutd-article\"", "\n", "in_dir", "=", "f\"{in_prefix}/split-corrected\"", "\n", "out_dir", "=", "\"./data/genia/processed-data/json-ner\"", "\n", "os", ".", "makedirs", "(", "out_dir", ")", "\n", "folds", "=", "[", "\"train\"", ",", "\"dev\"", ",", "\"test\"", "]", "\n", "ner_labels", "=", "set", "(", ")", "\n", "\n", "for", "fold", "in", "folds", ":", "\n", "        ", "msg", "=", "\"Formatting fold {0}.\"", ".", "format", "(", "fold", ")", "\n", "print", "(", "msg", ")", "\n", "ner_labels_fold", "=", "format_fold", "(", "fold", ",", "in_dir", ",", "out_dir", ")", "\n", "ner_labels", "=", "ner_labels", "|", "ner_labels_fold", "\n", "\n", "", "save_list", "(", "sorted", "(", "ner_labels", ")", ",", "path", ".", "join", "(", "in_prefix", ",", "\"ner-labels.txt\"", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.read_abstract": [[14, 29], ["open", "csv.reader", "int"], "function", ["None"], ["def", "read_abstract", "(", "file_name", ")", ":", "\n", "    ", "'''\n    Reads file and creates a dictionary to retrieve abstract information.\n    :param file_name: name of file that contains abstract info within the subdirectory\n    :return: abstracts_dict: a map of file_id to 'title' and 'abstract' inside that file\n    '''", "\n", "abstracts_dict", "=", "{", "}", "\n", "with", "open", "(", "file_name", ")", "as", "tsvfile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "tsvfile", ",", "delimiter", "=", "'\\t'", ")", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "abstracts_dict", "[", "int", "(", "row", "[", "0", "]", ")", "]", "=", "{", "\n", "'title'", ":", "row", "[", "1", "]", ",", "\n", "'abstract'", ":", "row", "[", "2", "]", "\n", "}", "\n", "", "", "return", "abstracts_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.save_abstract_info": [[31, 72], ["dict", "nlp", "abstracts_dict[].get", "sentence_lists.append", "list", "abstracts_dict[].get", "list"], "function", ["None"], ["", "def", "save_abstract_info", "(", "abstracts_dict", ")", ":", "\n", "    ", "'''\n    Takes initial abstract information and parses the document id, sentences, and tokens from it. Gets the token index\n    and line index of each token.\n    :param abstracts_dict: raw dictionary from the training file that maps file_id to title and abstract\n    :return: results: dictionary that will store all the information for each file, populated with doc_key, sentences,\n    and some meta info that will be used for later processing\n    '''", "\n", "results", "=", "{", "}", "\n", "for", "file_id", "in", "abstracts_dict", ":", "\n", "        ", "file_result", "=", "dict", "(", ")", "\n", "sentence_lists", "=", "[", "]", "\n", "token_dict", "=", "{", "}", "\n", "full_text", "=", "abstracts_dict", "[", "file_id", "]", ".", "get", "(", "'title'", ")", "+", "\" \"", "+", "abstracts_dict", "[", "file_id", "]", ".", "get", "(", "'abstract'", ")", "\n", "\n", "doc", "=", "nlp", "(", "full_text", ")", "\n", "\n", "sentence_index", "=", "0", "\n", "for", "sentence", "in", "doc", ".", "sents", ":", "\n", "# USED FOR MODEL: Create a list of sentences, each with a sublist of tokens", "\n", "            ", "tokens_list", "=", "[", "token", ".", "text", "for", "token", "in", "list", "(", "sentence", ")", "]", "\n", "sentence_lists", ".", "append", "(", "tokens_list", ")", "# Add list of tokens to overall list that contains all sentences", "\n", "\n", "# USED FOR LOGIC: Create a token lookup by character index, used in the next section", "\n", "previous_char_index", "=", "0", "\n", "for", "token", "in", "list", "(", "sentence", ")", ":", "\n", "                ", "token_dict", "[", "token", ".", "idx", "]", "=", "{", "# Store token by character index", "\n", "'text'", ":", "token", ".", "text", ",", "\n", "'token_index'", ":", "token", ".", "i", ",", "\n", "'line_index'", ":", "sentence_index", ",", "\n", "}", "\n", "token_dict", "[", "previous_char_index", "]", "[", "'next_char_index'", "]", "=", "token", ".", "idx", "\n", "previous_char_index", "=", "token", ".", "idx", "\n", "", "sentence_index", "+=", "1", "\n", "\n", "# Store all elements in overall dictionary", "\n", "", "file_result", "[", "\"doc_key\"", "]", "=", "file_id", "\n", "file_result", "[", "\"sentences\"", "]", "=", "sentence_lists", "\n", "file_result", "[", "\"token_dict\"", "]", "=", "token_dict", "\n", "results", "[", "file_id", "]", "=", "file_result", "\n", "", "return", "results", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.read_entities": [[74, 89], ["open", "csv.reader", "entities_dict.get().append", "int", "entities_dict.get", "int", "int", "int", "int"], "function", ["None"], ["", "def", "read_entities", "(", "file_name", ")", ":", "\n", "    ", "entities_dict", "=", "{", "}", "\n", "with", "open", "(", "file_name", ")", "as", "tsvfile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "tsvfile", ",", "delimiter", "=", "'\\t'", ")", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "if", "int", "(", "row", "[", "0", "]", ")", "not", "in", "entities_dict", ":", "\n", "                ", "entities_dict", "[", "int", "(", "row", "[", "0", "]", ")", "]", "=", "[", "]", "\n", "", "entities_dict", ".", "get", "(", "int", "(", "row", "[", "0", "]", ")", ")", ".", "append", "(", "{", "\n", "'term'", ":", "row", "[", "1", "]", ",", "\n", "'type'", ":", "row", "[", "2", "]", ",", "\n", "'start_char'", ":", "int", "(", "row", "[", "3", "]", ")", ",", "\n", "'end_char'", ":", "int", "(", "row", "[", "4", "]", ")", ",", "\n", "'text'", ":", "row", "[", "5", "]", "\n", "}", ")", "\n", "", "", "return", "entities_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.save_entities_info": [[91, 136], ["print", "print", "entities_dict.get", "token_dict.get", "range", "token_dict.get.get", "ner[].append", "len", "token_dict[].get", "print", "print", "print"], "function", ["None"], ["", "def", "save_entities_info", "(", "entities_dict", ",", "results", ")", ":", "\n", "    ", "special_case", "=", "0", "# Spacy did not successfully tokenize this sentence", "\n", "regular_case", "=", "0", "# Spacy did successfully tokenize this sentence", "\n", "merged_case", "=", "0", "# Entity token is a substring of Spacy token.", "\n", "for", "file_id", "in", "results", ":", "\n", "        ", "ner", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "results", "[", "file_id", "]", "[", "'sentences'", "]", ")", ")", "]", "# Create a list of lists equal to number of setences in text", "\n", "term_location", "=", "{", "}", "# Create a map of term number of start index, end index, and line number of that term", "\n", "token_dict", "=", "results", "[", "file_id", "]", "[", "'token_dict'", "]", "# Map of character offset to text, token index, and line index", "\n", "for", "token", "in", "entities_dict", ".", "get", "(", "file_id", ")", "or", "[", "]", ":", "\n", "            ", "start_token_info", "=", "token_dict", ".", "get", "(", "token", "[", "'start_char'", "]", ")", "\n", "if", "start_token_info", ":", "# If this entity's start char lines up with Spacy's tokenizer's starting char for a token", "\n", "                ", "start_index", "=", "start_token_info", "[", "'token_index'", "]", "\n", "tentative_end_char_index", "=", "token", "[", "'start_char'", "]", "\n", "next_start_char_index", "=", "start_token_info", ".", "get", "(", "'next_char_index'", ")", "\n", "while", "next_start_char_index", "and", "token", "[", "'end_char'", "]", ">", "next_start_char_index", ":", "\n", "                    ", "tentative_end_char_index", "=", "next_start_char_index", "\n", "next_start_char_index", "=", "token_dict", "[", "tentative_end_char_index", "]", ".", "get", "(", "'next_char_index'", ")", "\n", "\n", "", "end_token_info", "=", "token_dict", "[", "tentative_end_char_index", "]", "\n", "end_index", "=", "end_token_info", "[", "'token_index'", "]", "\n", "ner", "[", "end_token_info", "[", "'line_index'", "]", "]", ".", "append", "(", "[", "start_index", ",", "end_index", ",", "token", "[", "'type'", "]", "]", ")", "\n", "term_location", "[", "token", "[", "'term'", "]", "]", "=", "{", "\n", "'start_index'", ":", "start_index", ",", "\n", "'end_index'", ":", "end_index", ",", "\n", "'line_index'", ":", "end_token_info", "[", "'line_index'", "]", "\n", "}", "\n", "if", "token", "[", "\"text\"", "]", "!=", "start_token_info", "[", "\"text\"", "]", ":", "\n", "                    ", "print", "(", "token", "[", "\"text\"", "]", ")", "\n", "print", "(", "start_token_info", "[", "\"text\"", "]", ")", "\n", "print", "(", ")", "\n", "merged_case", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "regular_case", "+=", "1", "\n", "", "", "else", ":", "\n", "                ", "special_case", "+=", "1", "\n", "#ner = sorted(ner, key=lambda x: x[0])", "\n", "", "", "results", "[", "file_id", "]", "[", "'ner'", "]", "=", "ner", "\n", "results", "[", "file_id", "]", "[", "'term_location'", "]", "=", "term_location", "\n", "\n", "", "total", "=", "special_case", "+", "regular_case", "+", "merged_case", "\n", "frac_discarded", "=", "special_case", "/", "total", "\n", "frac_merged", "=", "merged_case", "/", "total", "\n", "# Throw out cases where the token didn't line up with an entity boundary.", "\n", "print", "(", "f\"Fraction entities discarded due to entity boundary / token index mismatch: {frac_discarded:0.4f}\"", ")", "\n", "print", "(", "f\"Fraction entities where entity token is substring of Spacy token: {frac_merged:0.4f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.read_relations": [[138, 151], ["open", "csv.reader", "relations_dict.get().append", "int", "relations_dict.get", "int", "int"], "function", ["None"], ["", "def", "read_relations", "(", "file_name", ")", ":", "\n", "    ", "relations_dict", "=", "{", "}", "\n", "with", "open", "(", "file_name", ")", "as", "tsvfile", ":", "\n", "        ", "reader", "=", "csv", ".", "reader", "(", "tsvfile", ",", "delimiter", "=", "'\\t'", ")", "\n", "for", "row", "in", "reader", ":", "\n", "            ", "if", "int", "(", "row", "[", "0", "]", ")", "not", "in", "relations_dict", ":", "\n", "                ", "relations_dict", "[", "int", "(", "row", "[", "0", "]", ")", "]", "=", "[", "]", "\n", "", "relations_dict", ".", "get", "(", "int", "(", "row", "[", "0", "]", ")", ")", ".", "append", "(", "{", "\n", "'relationship'", ":", "row", "[", "3", "]", ",", "\n", "'arg1'", ":", "row", "[", "4", "]", "[", "5", ":", "]", ",", "\n", "'arg2'", ":", "row", "[", "5", "]", "[", "5", ":", "]", ",", "\n", "}", ")", "\n", "", "", "return", "relations_dict", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.save_relations": [[153, 180], ["print", "relations_dict.get", "term_location_dict.get", "term_location_dict.get", "range", "len", "relation[].append"], "function", ["None"], ["", "def", "save_relations", "(", "relations_dict", ",", "results", ")", ":", "\n", "    ", "different_lines", "=", "0", "\n", "same_lines", "=", "0", "\n", "for", "file_id", "in", "results", ":", "\n", "        ", "relation", "=", "[", "[", "]", "for", "i", "in", "range", "(", "len", "(", "results", "[", "file_id", "]", "[", "'sentences'", "]", ")", ")", "]", "# Create a list of lists equal to number of setences in text", "\n", "term_location_dict", "=", "results", "[", "file_id", "]", "[", "'term_location'", "]", "\n", "for", "relation_entry", "in", "relations_dict", ".", "get", "(", "file_id", ")", "or", "[", "]", ":", "\n", "            ", "arg1_location", "=", "term_location_dict", ".", "get", "(", "relation_entry", "[", "'arg1'", "]", ")", "\n", "arg2_location", "=", "term_location_dict", ".", "get", "(", "relation_entry", "[", "'arg2'", "]", ")", "\n", "if", "arg1_location", "and", "arg2_location", ":", "# Only if we have term location information for both terms", "\n", "                ", "if", "arg1_location", "[", "'line_index'", "]", "==", "arg2_location", "[", "'line_index'", "]", ":", "\n", "                    ", "relation", "[", "arg1_location", "[", "'line_index'", "]", "]", ".", "append", "(", "[", "\n", "arg1_location", "[", "'start_index'", "]", ",", "\n", "arg1_location", "[", "'end_index'", "]", ",", "\n", "arg2_location", "[", "'start_index'", "]", ",", "\n", "arg2_location", "[", "'end_index'", "]", ",", "\n", "relation_entry", "[", "'relationship'", "]", ",", "\n", "]", ")", "\n", "same_lines", "+=", "1", "\n", "", "else", ":", "\n", "                    ", "different_lines", "+=", "1", "\n", "#relation = sorted(relation, key=lambda x: x[0])", "\n", "", "", "", "results", "[", "file_id", "]", "[", "'relations'", "]", "=", "relation", "\n", "", "frac_cross_sent", "=", "different_lines", "/", "(", "different_lines", "+", "same_lines", ")", "\n", "\n", "# Remove relations that cross sentence boundaries.", "\n", "print", "(", "f\"Fraction cross-sentence relations (discarded): {frac_cross_sent:0.4f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.process_fold": [[182, 200], ["print", "_old_02_chemprot_to_input.read_abstract", "_old_02_chemprot_to_input.save_abstract_info", "_old_02_chemprot_to_input.read_entities", "_old_02_chemprot_to_input.save_entities_info", "_old_02_chemprot_to_input.read_relations", "_old_02_chemprot_to_input.save_relations", "open", "print", "json.dumps", "results[].get", "results[].get", "results[].get", "results[].get"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.read_abstract", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.save_abstract_info", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.read_entities", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.save_entities_info", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.read_relations", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.save_relations"], ["", "def", "process_fold", "(", "fold", ")", ":", "\n", "    ", "print", "(", "f\"Processing fold {fold}.\"", ")", "\n", "raw_subdirectory", "=", "f\"/raw_data/ChemProt_Corpus/chemprot_{fold}/\"", "\n", "abstracts_dict", "=", "read_abstract", "(", "DIRECTORY", "+", "raw_subdirectory", "+", "f'chemprot_{fold}_abstracts.tsv'", ")", "\n", "results", "=", "save_abstract_info", "(", "abstracts_dict", ")", "\n", "entities_dict", "=", "read_entities", "(", "DIRECTORY", "+", "raw_subdirectory", "+", "f'chemprot_{fold}_entities.tsv'", ")", "\n", "save_entities_info", "(", "entities_dict", ",", "results", ")", "\n", "relations_dict", "=", "read_relations", "(", "DIRECTORY", "+", "raw_subdirectory", "+", "f'chemprot_{fold}_relations.tsv'", ")", "\n", "save_relations", "(", "relations_dict", ",", "results", ")", "\n", "\n", "with", "open", "(", "DIRECTORY", "+", "PROCESSED_SUBDIRECTORY", "+", "f'{fold}.jsonl'", ",", "'w'", ")", "as", "outfile", ":", "\n", "        ", "for", "file_id", "in", "results", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "{", "\n", "'doc_key'", ":", "results", "[", "file_id", "]", ".", "get", "(", "'doc_key'", ")", ",", "\n", "'sentences'", ":", "results", "[", "file_id", "]", ".", "get", "(", "'sentences'", ")", ",", "\n", "'ner'", ":", "results", "[", "file_id", "]", ".", "get", "(", "'ner'", ")", ",", "\n", "'relations'", ":", "results", "[", "file_id", "]", ".", "get", "(", "'relations'", ")", ",", "\n", "}", ")", ",", "file", "=", "outfile", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot._old_02_chemprot_to_input.main": [[202, 205], ["_old_02_chemprot_to_input.process_fold"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.process_fold"], ["", "", "", "def", "main", "(", ")", ":", "\n", "    ", "for", "fold", "in", "[", "\"training\"", ",", "\"development\"", ",", "\"test\"", "]", ":", "\n", "        ", "process_fold", "(", "fold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.03_spot_check.spot_check_fold": [[13, 49], ["print", "dygie.data.dataset_readers.document.Dataset.from_jsonl", "pandas.read_table", "pandas.read_table", "pandas.DataFrame().set_index", "print", "print", "collections.Counter", "pd.read_table.query", "pd.read_table.query", "len", "len", "pd.DataFrame().set_index.append", "res[].sum", "res[].sum", "res[].sum", "res[].sum", "len", "len", "pandas.DataFrame"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.from_jsonl"], ["def", "spot_check_fold", "(", "fold", ")", ":", "\n", "    ", "print", "(", "f\"Checking {fold}.\"", ")", "\n", "fname", "=", "f\"data/chemprot/processed_data/{fold}.jsonl\"", "\n", "data", "=", "Dataset", ".", "from_jsonl", "(", "fname", ")", "\n", "\n", "f_entity", "=", "f\"data/chemprot/raw_data/ChemProt_Corpus/chemprot_{fold}/chemprot_{fold}_entities.tsv\"", "\n", "entities", "=", "pd", ".", "read_table", "(", "f_entity", ",", "header", "=", "None", ")", "\n", "entities", ".", "columns", "=", "[", "\"doc_key\"", ",", "\"entity_id\"", ",", "\"label\"", ",", "\"start_char\"", ",", "\"end_char\"", ",", "\"text\"", "]", "\n", "\n", "f_relation", "=", "f\"data/chemprot/raw_data/ChemProt_Corpus/chemprot_{fold}/chemprot_{fold}_relations.tsv\"", "\n", "relations", "=", "pd", ".", "read_table", "(", "f_relation", ",", "header", "=", "None", ")", "\n", "relations", ".", "columns", "=", "[", "\"doc_key\"", ",", "\"rel_category\"", ",", "\"is_task\"", ",", "\"label\"", ",", "\"arg1\"", ",", "\"arg2\"", "]", "\n", "\n", "res", "=", "[", "]", "\n", "\n", "for", "entry", "in", "data", ":", "\n", "        ", "counts", "=", "Counter", "(", ")", "\n", "expected_entities", "=", "entities", ".", "query", "(", "f\"doc_key == {entry.doc_key}\"", ")", "\n", "expected_relations", "=", "relations", ".", "query", "(", "f\"doc_key == {entry.doc_key}\"", ")", "\n", "for", "sent", "in", "entry", ":", "\n", "            ", "counts", "[", "\"found_entities\"", "]", "+=", "len", "(", "sent", ".", "ner", ")", "\n", "counts", "[", "\"found_relations\"", "]", "+=", "len", "(", "sent", ".", "relations", ")", "\n", "\n", "", "counts", "[", "\"expected_entities\"", "]", "=", "len", "(", "expected_entities", ")", "\n", "counts", "[", "\"expected_relations\"", "]", "=", "len", "(", "expected_relations", ")", "\n", "\n", "counts", "[", "\"doc_key\"", "]", "=", "entry", ".", "doc_key", "\n", "res", ".", "append", "(", "counts", ")", "\n", "\n", "", "res", "=", "pd", ".", "DataFrame", "(", "res", ")", ".", "set_index", "(", "\"doc_key\"", ")", "\n", "\n", "frac_entities", "=", "res", "[", "\"found_entities\"", "]", ".", "sum", "(", ")", "/", "res", "[", "\"expected_entities\"", "]", ".", "sum", "(", ")", "\n", "frac_relations", "=", "res", "[", "\"found_relations\"", "]", ".", "sum", "(", ")", "/", "res", "[", "\"expected_relations\"", "]", ".", "sum", "(", ")", "\n", "\n", "print", "(", "f\"Fraction of entities preserved from original file: {frac_entities:0.2f}\"", ")", "\n", "print", "(", "f\"Fraction of relations preserved from original file: {frac_relations:0.2f}\"", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.03_spot_check.main": [[51, 54], ["03_spot_check.spot_check_fold"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.03_spot_check.spot_check_fold"], ["", "def", "main", "(", ")", ":", "\n", "    ", "for", "fold", "in", "[", "\"training\"", ",", "\"development\"", ",", "\"test\"", "]", ":", "\n", "        ", "spot_check_fold", "(", "fold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.get_entities_in_sent": [[15, 22], ["None"], "function", ["None"], ["def", "get_entities_in_sent", "(", "sent", ",", "entities", ")", ":", "\n", "    ", "start", ",", "end", "=", "sent", ".", "start_char", ",", "sent", ".", "end_char", "\n", "start_ok", "=", "entities", "[", "\"char_start\"", "]", ">=", "start", "\n", "end_ok", "=", "entities", "[", "\"char_end\"", "]", "<=", "end", "\n", "keep", "=", "start_ok", "&", "end_ok", "\n", "res", "=", "entities", "[", "keep", "]", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.align_one": [[24, 47], ["Exception", "len"], "function", ["None"], ["", "def", "align_one", "(", "sent", ",", "row", ")", ":", "\n", "# Don't distinguish b/w genes that can and can't be looked up in database.", "\n", "    ", "lookup", "=", "{", "\"GENE-Y\"", ":", "\"GENE\"", ",", "\n", "\"GENE-N\"", ":", "\"GENE\"", ",", "\n", "\"CHEMICAL\"", ":", "\"CHEMICAL\"", "}", "\n", "\n", "start_tok", "=", "None", "\n", "end_tok", "=", "None", "\n", "\n", "for", "tok", "in", "sent", ":", "\n", "        ", "if", "tok", ".", "idx", "==", "row", "[", "\"char_start\"", "]", ":", "\n", "            ", "start_tok", "=", "tok", "\n", "", "if", "tok", ".", "idx", "+", "len", "(", "tok", ")", "==", "row", "[", "\"char_end\"", "]", ":", "\n", "            ", "end_tok", "=", "tok", "\n", "\n", "", "", "if", "start_tok", "is", "None", "or", "end_tok", "is", "None", ":", "\n", "        ", "return", "None", "\n", "", "else", ":", "\n", "        ", "expected", "=", "sent", "[", "start_tok", ".", "i", "-", "sent", ".", "start", ":", "end_tok", ".", "i", "-", "sent", ".", "start", "+", "1", "]", "\n", "if", "expected", ".", "text", "!=", "row", ".", "text", ":", "\n", "            ", "raise", "Exception", "(", "\"Entity mismatch\"", ")", "\n", "\n", "", "return", "(", "start_tok", ".", "i", ",", "end_tok", ".", "i", ",", "lookup", "[", "row", "[", "\"label\"", "]", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.align_entities": [[49, 60], ["entities_sent.iterrows", "02_chemprot_to_input.align_one"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.align_one"], ["", "", "def", "align_entities", "(", "sent", ",", "entities_sent", ")", ":", "\n", "    ", "aligned_entities", "=", "{", "}", "\n", "missed_entities", "=", "{", "}", "\n", "for", "_", ",", "row", "in", "entities_sent", ".", "iterrows", "(", ")", ":", "\n", "        ", "aligned", "=", "align_one", "(", "sent", ",", "row", ")", "\n", "if", "aligned", "is", "not", "None", ":", "\n", "            ", "aligned_entities", "[", "row", "[", "\"entity_id\"", "]", "]", "=", "aligned", "\n", "", "else", ":", "\n", "            ", "missed_entities", "[", "row", "[", "\"entity_id\"", "]", "]", "=", "None", "\n", "\n", "", "", "return", "aligned_entities", ",", "missed_entities", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.format_relations": [[62, 72], ["relations.iterrows", "row[].replace", "row[].replace"], "function", ["None"], ["", "def", "format_relations", "(", "relations", ")", ":", "\n", "# Convert to dict.", "\n", "    ", "res", "=", "{", "}", "\n", "for", "_", ",", "row", "in", "relations", ".", "iterrows", "(", ")", ":", "\n", "        ", "ent1", "=", "row", "[", "\"arg1\"", "]", ".", "replace", "(", "\"Arg1:\"", ",", "\"\"", ")", "\n", "ent2", "=", "row", "[", "\"arg2\"", "]", ".", "replace", "(", "\"Arg2:\"", ",", "\"\"", ")", "\n", "key", "=", "(", "ent1", ",", "ent2", ")", "\n", "res", "[", "key", "]", "=", "row", "[", "\"label\"", "]", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.get_relations_in_sent": [[74, 87], ["set", "relations.items", "set.add", "res.append"], "function", ["None"], ["", "def", "get_relations_in_sent", "(", "aligned", ",", "relations", ")", ":", "\n", "    ", "res", "=", "[", "]", "\n", "keys", "=", "set", "(", ")", "\n", "# Loop over the relations, and keep the ones relating entities in this sentences.", "\n", "for", "ents", ",", "label", "in", "relations", ".", "items", "(", ")", ":", "\n", "        ", "if", "ents", "[", "0", "]", "in", "aligned", "and", "ents", "[", "1", "]", "in", "aligned", ":", "\n", "            ", "keys", ".", "add", "(", "ents", ")", "\n", "ent1", "=", "aligned", "[", "ents", "[", "0", "]", "]", "\n", "ent2", "=", "aligned", "[", "ents", "[", "1", "]", "]", "\n", "to_append", "=", "ent1", "[", ":", "2", "]", "+", "ent2", "[", ":", "2", "]", "+", "(", "label", ",", ")", "\n", "res", ".", "append", "(", "to_append", ")", "\n", "\n", "", "", "return", "res", ",", "keys", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.one_abstract": [[93, 145], ["df_entities.query", "02_chemprot_to_input.format_relations", "nlp", "set", "set", "set", "set", "len", "len", "len", "len", "len", "len", "len", "df_relations.query", "02_chemprot_to_input.get_entities_in_sent", "02_chemprot_to_input.align_entities", "02_chemprot_to_input.get_relations_in_sent", "scierc_format[].append", "scierc_format[].append", "scierc_format[].append", "set", "set", "set", "set", "set", "list", "aligned.keys", "missed.keys", "format_relations.keys", "aligned.values"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.format_relations", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.get_entities_in_sent", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.align_entities", "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.get_relations_in_sent"], ["", "def", "one_abstract", "(", "row", ",", "df_entities", ",", "df_relations", ")", ":", "\n", "    ", "doc", "=", "row", "[", "\"title\"", "]", "+", "\" \"", "+", "row", "[", "\"abstract\"", "]", "\n", "doc_key", "=", "row", "[", "\"doc_key\"", "]", "\n", "entities", "=", "df_entities", ".", "query", "(", "f\"doc_key == '{doc_key}'\"", ")", "\n", "relations", "=", "format_relations", "(", "df_relations", ".", "query", "(", "f\"doc_key == '{doc_key}'\"", ")", ")", "\n", "\n", "processed", "=", "nlp", "(", "doc", ")", "\n", "\n", "entities_seen", "=", "set", "(", ")", "\n", "entities_alignment", "=", "set", "(", ")", "\n", "entities_no_alignment", "=", "set", "(", ")", "\n", "relations_found", "=", "set", "(", ")", "\n", "\n", "scierc_format", "=", "{", "\"doc_key\"", ":", "doc_key", ",", "\"dataset\"", ":", "\"chemprot\"", ",", "\"sentences\"", ":", "[", "]", ",", "\"ner\"", ":", "[", "]", ",", "\n", "\"relations\"", ":", "[", "]", "}", "\n", "\n", "for", "sent", "in", "processed", ".", "sents", ":", "\n", "# Get the tokens.", "\n", "        ", "toks", "=", "[", "tok", ".", "text", "for", "tok", "in", "sent", "]", "\n", "\n", "# Align entities.", "\n", "entities_sent", "=", "get_entities_in_sent", "(", "sent", ",", "entities", ")", "\n", "aligned", ",", "missed", "=", "align_entities", "(", "sent", ",", "entities_sent", ")", "\n", "\n", "# Align relations.", "\n", "relations_sent", ",", "keys_found", "=", "get_relations_in_sent", "(", "aligned", ",", "relations", ")", "\n", "\n", "# Append to result list", "\n", "scierc_format", "[", "\"sentences\"", "]", ".", "append", "(", "toks", ")", "\n", "entities_to_scierc", "=", "[", "list", "(", "x", ")", "for", "x", "in", "aligned", ".", "values", "(", ")", "]", "\n", "scierc_format", "[", "\"ner\"", "]", ".", "append", "(", "entities_to_scierc", ")", "\n", "scierc_format", "[", "\"relations\"", "]", ".", "append", "(", "relations_sent", ")", "\n", "\n", "# Keep track of which entities and relations we've found and which we haven't.", "\n", "entities_seen", "|=", "set", "(", "entities_sent", "[", "\"entity_id\"", "]", ")", "\n", "entities_alignment", "|=", "set", "(", "aligned", ".", "keys", "(", ")", ")", "\n", "entities_no_alignment", "|=", "set", "(", "missed", ".", "keys", "(", ")", ")", "\n", "relations_found", "|=", "keys_found", "\n", "\n", "# Update counts.", "\n", "", "entities_missed", "=", "set", "(", "entities", "[", "\"entity_id\"", "]", ")", "-", "entities_seen", "\n", "relations_missed", "=", "set", "(", "relations", ".", "keys", "(", ")", ")", "-", "relations_found", "\n", "\n", "COUNTS", "[", "\"entities_correct\"", "]", "+=", "len", "(", "entities_alignment", ")", "\n", "COUNTS", "[", "\"entities_misaligned\"", "]", "+=", "len", "(", "entities_no_alignment", ")", "\n", "COUNTS", "[", "\"entities_missed\"", "]", "+=", "len", "(", "entities_missed", ")", "\n", "COUNTS", "[", "\"entities_total\"", "]", "+=", "len", "(", "entities", ")", "\n", "COUNTS", "[", "\"relations_found\"", "]", "+=", "len", "(", "relations_found", ")", "\n", "COUNTS", "[", "\"relations_missed\"", "]", "+=", "len", "(", "relations_missed", ")", "\n", "COUNTS", "[", "'relations_total'", "]", "+=", "len", "(", "relations", ")", "\n", "\n", "return", "scierc_format", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.one_fold": [[147, 171], ["print", "pandas.read_table", "pandas.read_table", "pandas.read_table", "tqdm.tqdm", "pd.read_table.iterrows", "02_chemprot_to_input.one_abstract", "res.append", "open", "len", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.chemprot.02_chemprot_to_input.one_abstract"], ["", "def", "one_fold", "(", "fold", ")", ":", "\n", "    ", "directory", "=", "\"data/chemprot\"", "\n", "print", "(", "f\"Processing fold {fold}.\"", ")", "\n", "raw_subdirectory", "=", "\"raw_data/ChemProt_Corpus\"", "\n", "df_abstracts", "=", "pd", ".", "read_table", "(", "f\"{directory}/{raw_subdirectory}/chemprot_{fold}/chemprot_{fold}_abstracts.tsv\"", ",", "\n", "header", "=", "None", ",", "keep_default_na", "=", "False", ",", "\n", "names", "=", "[", "\"doc_key\"", ",", "\"title\"", ",", "\"abstract\"", "]", ")", "\n", "df_entities", "=", "pd", ".", "read_table", "(", "f\"{directory}/{raw_subdirectory}/chemprot_{fold}/chemprot_{fold}_entities.tsv\"", ",", "\n", "header", "=", "None", ",", "keep_default_na", "=", "False", ",", "\n", "names", "=", "[", "\"doc_key\"", ",", "\"entity_id\"", ",", "\"label\"", ",", "\"char_start\"", ",", "\"char_end\"", ",", "\"text\"", "]", ")", "\n", "df_relations", "=", "pd", ".", "read_table", "(", "f\"{directory}/{raw_subdirectory}/chemprot_{fold}/chemprot_{fold}_relations.tsv\"", ",", "\n", "header", "=", "None", ",", "keep_default_na", "=", "False", ",", "\n", "names", "=", "[", "\"doc_key\"", ",", "\"cpr_group\"", ",", "\"eval_type\"", ",", "\"label\"", ",", "\"arg1\"", ",", "\"arg2\"", "]", ")", "\n", "\n", "res", "=", "[", "]", "\n", "for", "_", ",", "abstract", "in", "tqdm", "(", "df_abstracts", ".", "iterrows", "(", ")", ",", "total", "=", "len", "(", "df_abstracts", ")", ")", ":", "\n", "        ", "to_append", "=", "one_abstract", "(", "abstract", ",", "df_entities", ",", "df_relations", ")", "\n", "res", ".", "append", "(", "to_append", ")", "\n", "\n", "# Write to file.", "\n", "", "name_out", "=", "f\"{directory}/processed_data/{fold}.jsonl\"", "\n", "with", "open", "(", "name_out", ",", "\"w\"", ")", "as", "f_out", ":", "\n", "        ", "for", "line", "in", "res", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "line", ")", ",", "file", "=", "f_out", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator.__init__": [[12, 20], ["collate.Collator._get_dataset", "collate.Collator._get_weight", "collate.Collator._remove_clusters", "collate.Collator._reset_batch"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_dataset", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_weight", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._remove_clusters", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._reset_batch"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ",", "max_spans_per_doc", ",", "max_sentences_per_doc", ",", "dataset", ")", ":", "\n", "        ", "self", ".", "corpus", "=", "corpus", "\n", "self", ".", "max_spans_per_doc", "=", "max_spans_per_doc", "\n", "self", ".", "max_sentences_per_doc", "=", "max_sentences_per_doc", "\n", "self", ".", "dataset", "=", "self", ".", "_get_dataset", "(", "dataset", ")", "\n", "self", ".", "weight", "=", "self", ".", "_get_weight", "(", "corpus", ")", "\n", "self", ".", "_remove_clusters", "(", ")", "\n", "self", ".", "_reset_batch", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._reset_batch": [[21, 25], ["None"], "methods", ["None"], ["", "def", "_reset_batch", "(", "self", ")", ":", "\n", "        ", "self", ".", "sents_batch", "=", "[", "]", "\n", "self", ".", "sentence_ix", "=", "0", "\n", "self", ".", "sentence_start", "=", "0", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator.collate": [[26, 67], ["collate.Collator._reset_batch", "collate.Collator._sort_sentences", "dygie.data.dataset_readers.document.Document", "documents.append", "collate.Collator._reset_batch", "dygie.data.dataset_readers.document.Dataset", "collate.Collator.sents_batch.append", "len", "len", "len", "dygie.data.dataset_readers.document.Document", "documents.append", "collate.Collator._reset_batch", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._reset_batch", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._sort_sentences", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._reset_batch", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._reset_batch"], ["", "def", "collate", "(", "self", ")", ":", "\n", "        ", "self", ".", "_reset_batch", "(", ")", "\n", "sents", "=", "self", ".", "_sort_sentences", "(", ")", "\n", "documents", "=", "[", "]", "\n", "document_counter", "=", "0", "\n", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "sent_spans", "=", "len", "(", "sent", ")", "**", "2", "\n", "# How many spans will there be if we add this sentence to the batch?", "\n", "candidate_n_spans", "=", "sent_spans", "*", "len", "(", "self", ".", "sents_batch", ")", "+", "1", "\n", "# How many sentences?", "\n", "candidate_n_sents", "=", "len", "(", "self", ".", "sents_batch", ")", "+", "1", "\n", "# If adding a sentence makes the document too big, start a new one.", "\n", "start_new_doc", "=", "(", "(", "candidate_n_spans", ">", "self", ".", "max_spans_per_doc", ")", "or", "\n", "(", "candidate_n_sents", ">", "self", ".", "max_sentences_per_doc", ")", ")", "\n", "# If it would put us over, finish this document and start a new one.", "\n", "if", "start_new_doc", ":", "\n", "                ", "new_doc", "=", "document", ".", "Document", "(", "doc_key", "=", "document_counter", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "sentences", "=", "self", ".", "sents_batch", ")", "\n", "documents", ".", "append", "(", "new_doc", ")", "\n", "document_counter", "+=", "1", "\n", "\n", "self", ".", "_reset_batch", "(", ")", "\n", "\n", "# Reset the index of the sentence in the document, and its starting token.", "\n", "", "sent", ".", "sentence_ix", "=", "self", ".", "sentence_ix", "\n", "sent", ".", "sentence_start", "=", "self", ".", "sentence_start", "\n", "self", ".", "sents_batch", ".", "append", "(", "sent", ")", "\n", "self", ".", "sentence_ix", "+=", "1", "\n", "self", ".", "sentence_start", "+=", "len", "(", "sent", ")", "\n", "\n", "# At the end, get any docs that aren't left.", "\n", "", "new_doc", "=", "document", ".", "Document", "(", "doc_key", "=", "document_counter", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "sentences", "=", "self", ".", "sents_batch", ",", "\n", "weight", "=", "self", ".", "weight", ")", "\n", "documents", ".", "append", "(", "new_doc", ")", "\n", "self", ".", "_reset_batch", "(", ")", "\n", "\n", "return", "document", ".", "Dataset", "(", "documents", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._get_dataset": [[68, 78], ["len", "ValueError", "set"], "methods", ["None"], ["", "def", "_get_dataset", "(", "self", ",", "dataset", ")", ":", "\n", "        ", "if", "dataset", "is", "not", "None", ":", "\n", "            ", "return", "dataset", "\n", "\n", "", "datasets", "=", "[", "x", ".", "dataset", "for", "x", "in", "self", ".", "corpus", "]", "\n", "\n", "if", "len", "(", "set", "(", "datasets", ")", ")", "!=", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"The documents in the corpus must be from a single dataset.\"", ")", "\n", "\n", "", "return", "datasets", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._get_weight": [[79, 88], ["set", "len", "ValueError", "sorted"], "methods", ["None"], ["", "def", "_get_weight", "(", "self", ",", "corpus", ")", ":", "\n", "        ", "\"\"\"\n        Get document weight. Right now, can only handle corpora where all documents have same\n        weight.\n        \"\"\"", "\n", "weights", "=", "set", "(", "[", "x", ".", "weight", "for", "x", "in", "self", ".", "corpus", "]", ")", "\n", "if", "len", "(", "weights", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot collate documents with different instance weights.\"", ")", "\n", "", "return", "sorted", "(", "weights", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._remove_clusters": [[89, 96], ["None"], "methods", ["None"], ["", "def", "_remove_clusters", "(", "self", ")", ":", "\n", "        ", "\"Can't collate data with coreference information. Remove it.\"", "\n", "for", "doc", "in", "self", ".", "corpus", ":", "\n", "            ", "doc", ".", "clusters", "=", "None", "\n", "doc", ".", "predicted_clusters", "=", "None", "\n", "for", "sent", "in", "doc", ":", "\n", "                ", "sent", ".", "cluster_dic", "=", "None", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator._sort_sentences": [[97, 106], ["sorted", "enumerate", "all_sents.append", "len"], "methods", ["None"], ["", "", "", "def", "_sort_sentences", "(", "self", ")", ":", "\n", "        ", "all_sents", "=", "[", "]", "\n", "for", "doc", "in", "self", ".", "corpus", ":", "\n", "            ", "for", "i", ",", "sent", "in", "enumerate", "(", "doc", ")", ":", "\n", "                ", "sent", ".", "metadata", "=", "{", "\"_orig_doc_key\"", ":", "doc", ".", "doc_key", ",", "\n", "\"_orig_sent_ix\"", ":", "i", "}", "\n", "all_sents", ".", "append", "(", "sent", ")", "\n", "\n", "", "", "return", "sorted", "(", "all_sents", ",", "key", "=", "lambda", "x", ":", "len", "(", "x", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.CollateRunner.__init__": [[140, 143], ["kwargs.items", "setattr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.CollateRunner.run": [[144, 152], ["os.makedirs", "collate.CollateRunner.process_fold"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.process_fold"], ["", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "self", ".", "output_directory", ",", "exist_ok", "=", "True", ")", "\n", "fold_names", "=", "[", "self", ".", "train_name", ",", "self", ".", "dev_name", ",", "self", ".", "test_name", "]", "\n", "for", "fold", "in", "fold_names", ":", "\n", "            ", "if", "fold", "==", "\"skip\"", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "self", ".", "process_fold", "(", "fold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.CollateRunner.process_fold": [[153, 161], ["dygie.data.dataset_readers.document.Dataset.from_jsonl", "collate.Collator", "Collator.collate", "Collator.collate.to_jsonl"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.from_jsonl", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.Collator.collate", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.to_jsonl"], ["", "", "", "def", "process_fold", "(", "self", ",", "fold", ")", ":", "\n", "        ", "fname", "=", "f\"{self.input_directory}/{fold}.{self.file_extension}\"", "\n", "corpus", "=", "document", ".", "Dataset", ".", "from_jsonl", "(", "fname", ")", "\n", "collator", "=", "Collator", "(", "\n", "corpus", ",", "self", ".", "max_spans_per_doc", ",", "self", ".", "max_sentences_per_doc", ",", "self", ".", "dataset", ")", "\n", "res", "=", "collator", ".", "collate", "(", ")", "\n", "out_name", "=", "f\"{self.output_directory}/{fold}.{self.file_extension}\"", "\n", "res", ".", "to_jsonl", "(", "out_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.get_args": [[111, 137], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "get_args", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Collate a dataset. Re-organize into `documents` with sentences of similar length.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"input_directory\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory with train, dev, and test files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_directory\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory where the output files will go.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_extension\"", ",", "type", "=", "str", ",", "default", "=", "\"jsonl\"", ",", "\n", "help", "=", "\"File extension for data files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_name\"", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ",", "\n", "help", "=", "\"Name of the file with the training split. To skip this fold, enter `skip`.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_name\"", ",", "type", "=", "str", ",", "default", "=", "\"dev\"", ",", "\n", "help", "=", "\"Name of the file with the dev split. For instance, `validation`. Enter `skip` to skip.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_name\"", ",", "type", "=", "str", ",", "default", "=", "\"test\"", ",", "\n", "help", "=", "\"Name of the file with the test split. Enter `skip` to skip.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_spans_per_doc\"", ",", "type", "=", "int", ",", "default", "=", "50000", ",", "\n", "help", "=", "\"Heuristic for max spans, as square of longest sentence length\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_sentences_per_doc\"", ",", "type", "=", "int", ",", "default", "=", "16", ",", "\n", "help", "=", "\"Maximum number of sentences allowed in a document.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Dataset name.\"", ")", "\n", "\n", "# If args are given, parse them; otherwise use command line.", "\n", "if", "args", "is", "not", "None", ":", "\n", "        ", "return", "parser", ".", "parse_args", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.collate.main": [[163, 167], ["collate.get_args", "collate.CollateRunner", "collate.CollateRunner.run", "vars"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.run"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "runner", "=", "CollateRunner", "(", "**", "vars", "(", "args", ")", ")", "\n", "runner", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.Normalizer.__init__": [[40, 43], ["kwargs.items", "setattr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.Normalizer.normalize": [[44, 49], ["os.makedirs", "normalize.Normalizer.process_fold"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.process_fold"], ["", "", "def", "normalize", "(", "self", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "self", ".", "output_directory", ",", "exist_ok", "=", "True", ")", "\n", "fold_names", "=", "[", "self", ".", "train_name", ",", "self", ".", "dev_name", ",", "self", ".", "test_name", "]", "\n", "for", "fold", "in", "fold_names", ":", "\n", "            ", "self", ".", "process_fold", "(", "fold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.Normalizer.process_fold": [[50, 60], ["dygie.data.dataset_readers.document.Dataset.from_jsonl", "normalize.save_jsonl", "res.extend", "normalize.Normalizer.process_entry"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.from_jsonl", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.save_jsonl", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.Normalizer.process_entry"], ["", "", "def", "process_fold", "(", "self", ",", "fold", ")", ":", "\n", "        ", "fname", "=", "f\"{self.input_directory}/{fold}.{self.file_extension}\"", "\n", "dataset", "=", "Dataset", ".", "from_jsonl", "(", "fname", ")", "\n", "res", "=", "[", "]", "\n", "\n", "for", "doc", "in", "dataset", ":", "\n", "            ", "res", ".", "extend", "(", "self", ".", "process_entry", "(", "doc", ")", ")", "\n", "\n", "", "out_name", "=", "f\"{self.output_directory}/{fold}.{self.file_extension}\"", "\n", "save_jsonl", "(", "res", ",", "out_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.Normalizer.process_entry": [[61, 69], ["doc.split", "split.to_json"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.ace-event.parse_ace_event.Document.to_json"], ["", "def", "process_entry", "(", "self", ",", "doc", ")", ":", "\n", "        ", "doc", ".", "dataset", "=", "self", ".", "dataset", "\n", "if", "self", ".", "max_tokens_per_doc", ">", "0", ":", "\n", "            ", "splits", "=", "doc", ".", "split", "(", "self", ".", "max_tokens_per_doc", ")", "\n", "", "else", ":", "\n", "            ", "splits", "=", "[", "doc", "]", "\n", "\n", "", "return", "[", "split", ".", "to_json", "(", ")", "for", "split", "in", "splits", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.load_jsonl": [[8, 10], ["json.loads", "open"], "function", ["None"], ["def", "load_jsonl", "(", "fname", ")", ":", "\n", "    ", "return", "[", "json", ".", "loads", "(", "x", ")", "for", "x", "in", "open", "(", "fname", ")", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.save_jsonl": [[12, 16], ["open", "print", "json.dumps"], "function", ["None"], ["", "def", "save_jsonl", "(", "xs", ",", "fname", ")", ":", "\n", "    ", "with", "open", "(", "fname", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "x", "in", "xs", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "x", ")", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.get_args": [[18, 37], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "", "def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Normalize a dataset by adding a `dataset` field and splitting long documents.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"input_directory\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory with train, dev, and test files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_directory\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory where the output files will go.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_extension\"", ",", "type", "=", "str", ",", "default", "=", "\"jsonl\"", ",", "\n", "help", "=", "\"File extension for data files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_name\"", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ",", "\n", "help", "=", "\"Name of the file with the training split.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_name\"", ",", "type", "=", "str", ",", "default", "=", "\"dev\"", ",", "\n", "help", "=", "\"Name of the file with the dev split. For instance, `validation`.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_name\"", ",", "type", "=", "str", ",", "default", "=", "\"test\"", ",", "\n", "help", "=", "\"Name of the file with the test split.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--max_tokens_per_doc\"", ",", "type", "=", "int", ",", "default", "=", "500", ",", "\n", "help", "=", "\"Maximum tokens per document. Longer ones will be split. If set to 0, do not split documents.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dataset\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "help", "=", "\"Dataset name.\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.main": [[71, 75], ["normalize.get_args", "normalize.Normalizer", "Normalizer.normalize", "vars"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.normalize.Normalizer.normalize"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "normalizer", "=", "Normalizer", "(", "**", "vars", "(", "args", ")", ")", "\n", "normalizer", ".", "normalize", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator.__init__": [[13, 18], ["uncollate.UnCollator._get_dataset", "uncollate.UnCollator._get_order", "uncollate.UnCollator._get_weight"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_dataset", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_order", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_weight"], ["    ", "def", "__init__", "(", "self", ",", "corpus", ",", "order_like", "=", "None", ")", ":", "\n", "        ", "self", ".", "corpus", "=", "corpus", "\n", "self", ".", "dataset", "=", "self", ".", "_get_dataset", "(", "corpus", ")", "\n", "self", ".", "order", "=", "self", ".", "_get_order", "(", "order_like", ")", "\n", "self", ".", "weight", "=", "self", ".", "_get_weight", "(", "corpus", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_order": [[19, 34], ["set", "set", "set", "ValueError", "set.add"], "methods", ["None"], ["", "def", "_get_order", "(", "self", ",", "order_like", ")", ":", "\n", "        ", "if", "order_like", "is", "None", ":", "\n", "            ", "return", "None", "\n", "", "else", ":", "\n", "            ", "orig_doc_keys", "=", "set", "(", ")", "\n", "for", "doc", "in", "self", ".", "corpus", ":", "\n", "                ", "for", "sent", "in", "doc", ":", "\n", "                    ", "orig_doc_keys", ".", "add", "(", "sent", ".", "metadata", "[", "\"_orig_doc_key\"", "]", ")", "\n", "\n", "# Make sure the keys match.", "\n", "", "", "orig_order", "=", "[", "x", ".", "doc_key", "for", "x", "in", "order_like", "]", "\n", "if", "set", "(", "orig_doc_keys", ")", "!=", "set", "(", "orig_order", ")", ":", "\n", "                ", "raise", "ValueError", "(", "\"Doc keys don't match between corpus to decollate and corpus to use for ordering\"", ")", "\n", "\n", "", "return", "orig_order", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_weight": [[35, 44], ["set", "len", "ValueError", "sorted"], "methods", ["None"], ["", "", "def", "_get_weight", "(", "self", ",", "corpus", ")", ":", "\n", "        ", "\"\"\"\n        Get document weight. Right now, can only handle corpora where all documents have same\n        weight.\n        \"\"\"", "\n", "weights", "=", "set", "(", "[", "x", ".", "weight", "for", "x", "in", "self", ".", "corpus", "]", ")", "\n", "if", "len", "(", "weights", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Cannot uncollate documents with different instance weights.\"", ")", "\n", "", "return", "sorted", "(", "weights", ")", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._get_dataset": [[45, 52], ["len", "ValueError", "set"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "_get_dataset", "(", "corpus", ")", ":", "\n", "        ", "datasets", "=", "[", "x", ".", "dataset", "for", "x", "in", "corpus", "]", "\n", "if", "len", "(", "set", "(", "datasets", ")", ")", ">", "1", ":", "\n", "            ", "raise", "ValueError", "(", "\"Can only uncollate documents with the same `dataset` field.\"", ")", "\n", "\n", "", "return", "datasets", "[", "0", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator.uncollate": [[53, 69], ["collections.defaultdict", "dygie.data.dataset_readers.document.Dataset", "sorted", "uncollate.UnCollator._uncollate_doc", "docs.append", "doc_dict[].append"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._uncollate_doc"], ["", "def", "uncollate", "(", "self", ")", ":", "\n", "# Collect all the sentences for each document.", "\n", "        ", "doc_dict", "=", "defaultdict", "(", "list", ")", "\n", "for", "doc", "in", "self", ".", "corpus", ":", "\n", "            ", "for", "sent", "in", "doc", ":", "\n", "                ", "doc_key", "=", "sent", ".", "metadata", "[", "\"_orig_doc_key\"", "]", "\n", "doc_dict", "[", "doc_key", "]", ".", "append", "(", "sent", ")", "\n", "\n", "# Re-assemble the dataset.", "\n", "", "", "docs", "=", "[", "]", "\n", "order", "=", "self", ".", "order", "if", "self", ".", "order", "is", "not", "None", "else", "sorted", "(", "doc_dict", ")", "\n", "for", "doc_key", "in", "order", ":", "\n", "            ", "doc", "=", "self", ".", "_uncollate_doc", "(", "doc_key", ",", "doc_dict", "[", "doc_key", "]", ")", "\n", "docs", ".", "append", "(", "doc", ")", "\n", "\n", "", "return", "document", ".", "Dataset", "(", "docs", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator._uncollate_doc": [[70, 95], ["sorted", "dygie.data.dataset_readers.document.Document", "Exception", "sentences.append", "len", "range", "len"], "methods", ["None"], ["", "def", "_uncollate_doc", "(", "self", ",", "doc_key", ",", "sents", ")", ":", "\n", "# Uncollate the sentences in a single document", "\n", "        ", "sents", "=", "sorted", "(", "sents", ",", "key", "=", "lambda", "x", ":", "x", ".", "metadata", "[", "\"_orig_sent_ix\"", "]", ")", "\n", "if", "[", "x", ".", "metadata", "[", "\"_orig_sent_ix\"", "]", "for", "x", "in", "sents", "]", "!=", "[", "x", "for", "x", "in", "range", "(", "len", "(", "sents", ")", ")", "]", ":", "\n", "            ", "raise", "Exception", "(", "f\"Some sentences for {doc_key} are missing.\"", ")", "\n", "\n", "", "sentences", "=", "[", "]", "\n", "sentence_ix", "=", "0", "\n", "sentence_start", "=", "0", "\n", "\n", "for", "sent", "in", "sents", ":", "\n", "            ", "sent", ".", "sentence_ix", "=", "sentence_ix", "\n", "sent", ".", "sentence_start", "=", "sentence_start", "\n", "# Remove unnecessary metadata fields.", "\n", "for", "field", "in", "[", "\"_orig_sent_ix\"", ",", "\"_orig_doc_key\"", "]", ":", "\n", "                ", "del", "sent", ".", "metadata", "[", "field", "]", "\n", "", "sentences", ".", "append", "(", "sent", ")", "\n", "sentence_ix", "+=", "1", "\n", "sentence_start", "+=", "len", "(", "sent", ")", "\n", "\n", "", "new_doc", "=", "document", ".", "Document", "(", "doc_key", "=", "doc_key", ",", "\n", "dataset", "=", "self", ".", "dataset", ",", "\n", "sentences", "=", "sentences", ",", "\n", "weight", "=", "self", ".", "weight", ")", "\n", "return", "new_doc", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.__init__": [[126, 129], ["kwargs.items", "setattr"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "**", "kwargs", ")", ":", "\n", "        ", "for", "k", ",", "v", "in", "kwargs", ".", "items", "(", ")", ":", "\n", "            ", "setattr", "(", "self", ",", "k", ",", "v", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.run": [[130, 138], ["os.makedirs", "uncollate.UnCollateRunner.process_fold"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.process_fold"], ["", "", "def", "run", "(", "self", ")", ":", "\n", "        ", "os", ".", "makedirs", "(", "self", ".", "output_directory", ",", "exist_ok", "=", "True", ")", "\n", "fold_names", "=", "[", "self", ".", "train_name", ",", "self", ".", "dev_name", ",", "self", ".", "test_name", "]", "\n", "for", "fold", "in", "fold_names", ":", "\n", "            ", "if", "fold", "==", "\"skip\"", ":", "\n", "                ", "continue", "\n", "", "else", ":", "\n", "                ", "self", ".", "process_fold", "(", "fold", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.process_fold": [[139, 152], ["dygie.data.dataset_readers.document.Dataset.from_jsonl", "uncollate.UnCollator", "UnCollator.uncollate", "UnCollator.uncollate.to_jsonl", "dygie.data.dataset_readers.document.Dataset.from_jsonl"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.from_jsonl", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollator.uncollate", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.to_jsonl", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Dataset.from_jsonl"], ["", "", "", "def", "process_fold", "(", "self", ",", "fold", ")", ":", "\n", "        ", "fname", "=", "f\"{self.input_directory}/{fold}.{self.file_extension}\"", "\n", "corpus", "=", "document", ".", "Dataset", ".", "from_jsonl", "(", "fname", ")", "\n", "if", "self", ".", "order_like_directory", "is", "not", "None", ":", "\n", "            ", "order_fname", "=", "f\"{self.order_like_directory}/{fold}.{self.file_extension}\"", "\n", "order_like", "=", "document", ".", "Dataset", ".", "from_jsonl", "(", "order_fname", ")", "\n", "", "else", ":", "\n", "            ", "order_like", "=", "None", "\n", "", "uncollator", "=", "UnCollator", "(", "\n", "corpus", ",", "order_like", ")", "\n", "res", "=", "uncollator", ".", "uncollate", "(", ")", "\n", "out_name", "=", "f\"{self.output_directory}/{fold}.{self.file_extension}\"", "\n", "res", ".", "to_jsonl", "(", "out_name", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.get_args": [[100, 123], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "def", "get_args", "(", "args", "=", "None", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Un-collated a previously collated a dataset.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"input_directory\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory with train, dev, and test files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_directory\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"Directory where the output files will go.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--order_like_directory\"", ",", "type", "=", "str", ",", "default", "=", "None", ",", "\n", "help", "=", "\"If a directory is given, order the documents like in this directory.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--file_extension\"", ",", "type", "=", "str", ",", "default", "=", "\"jsonl\"", ",", "\n", "help", "=", "\"File extension for data files.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--train_name\"", ",", "type", "=", "str", ",", "default", "=", "\"train\"", ",", "\n", "help", "=", "\"Name of the file with the training split. Enter `skip` to skip this fold.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--dev_name\"", ",", "type", "=", "str", ",", "default", "=", "\"dev\"", ",", "\n", "help", "=", "\"Name of the file with the dev split. For instance, `validation`, of `skip` to skip\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--test_name\"", ",", "type", "=", "str", ",", "default", "=", "\"test\"", ",", "\n", "help", "=", "\"Name of the file with the test split.\"", ")", "\n", "\n", "# If args are given, parse them; otherwise use command line.", "\n", "if", "args", "is", "not", "None", ":", "\n", "        ", "return", "parser", ".", "parse_args", "(", "args", ")", "\n", "", "else", ":", "\n", "        ", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.main": [[154, 158], ["uncollate.get_args", "uncollate.UnCollateRunner", "uncollate.UnCollateRunner.run", "vars"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args", "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.uncollate.UnCollateRunner.run"], ["", "", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "runner", "=", "UnCollateRunner", "(", "**", "vars", "(", "args", ")", ")", "\n", "runner", ".", "run", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.check_sentence_length.get_args": [[9, 19], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["def", "get_args", "(", ")", ":", "\n", "    ", "parser", "=", "argparse", ".", "ArgumentParser", "(", "\n", "description", "=", "\"Check for sentences that are longer than the length limit of the encoder.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"input_file\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The dataset to check.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--model_name\"", ",", "type", "=", "str", ",", "default", "=", "\"bert-base-cased\"", ",", "\n", "help", "=", "\"The BERT model to be used.\"", ")", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.shared.check_sentence_length.main": [[21, 44], ["check_sentence_length.get_args", "transformers.AutoConfig.from_pretrained", "dygie.data.dataset_readers.dygie.DyGIEReader", "dygie.data.dataset_readers.dygie.DyGIEReader.read", "allennlp.data.vocabulary.Vocabulary.from_instances", "print", "allennlp.data.token_indexers.PretrainedTransformerMismatchedIndexer", "instance.index_fields", "instance.as_tensor_dict", "[].sum", "print", "zip"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "indexers", "=", "{", "\"bert\"", ":", "token_indexers", ".", "PretrainedTransformerMismatchedIndexer", "(", "args", ".", "model_name", ")", "}", "\n", "config", "=", "AutoConfig", ".", "from_pretrained", "(", "args", ".", "model_name", ")", "\n", "max_length", "=", "config", ".", "max_position_embeddings", "\n", "reader", "=", "DyGIEReader", "(", "max_span_width", "=", "8", ",", "token_indexers", "=", "indexers", ")", "\n", "data", "=", "reader", ".", "read", "(", "args", ".", "input_file", ")", "\n", "vocab", "=", "vocabulary", ".", "Vocabulary", ".", "from_instances", "(", "data", ")", "\n", "print", "(", "f\"The following documents have sentences over {max_length} tokens:\"", ")", "\n", "for", "instance", "in", "data", ":", "\n", "        ", "instance", ".", "index_fields", "(", "vocab", ")", "\n", "td", "=", "instance", ".", "as_tensor_dict", "(", ")", "\n", "n_wordpieces", "=", "td", "[", "\"text\"", "]", "[", "\"bert\"", "]", "[", "\"wordpiece_mask\"", "]", ".", "sum", "(", "dim", "=", "1", ")", "\n", "too_long", "=", "(", "n_wordpieces", ">", "max_length", ")", ".", "nonzero", "(", "as_tuple", "=", "False", ")", ".", "squeeze", "(", "-", "1", ")", ".", "tolist", "(", ")", "\n", "lengths", "=", "n_wordpieces", "[", "too_long", "]", "\n", "\n", "if", "too_long", ":", "\n", "            ", "msg_start", "=", "f\"Document {td['metadata'].doc_key}: \"", "\n", "msg_body", "=", "[", "f\"sentence {sentence_ix} ({sentence_length} tokens)\"", "\n", "for", "sentence_ix", ",", "sentence_length", "in", "zip", "(", "too_long", ",", "lengths", ")", "]", "\n", "msg_body", "=", "\", \"", ".", "join", "(", "msg_body", ")", "\n", "msg", "=", "msg_start", "+", "msg_body", "+", "\".\"", "\n", "print", "(", "msg", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.__init__": [[18, 37], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "text", ",", "sents", ",", "ents", ",", "bin_rels", ",", "events", ",", "equiv_rels", ",", "\n", "doc_key", ",", "dataset", ",", "coref", ",", "nlp", ",", "total_original_ents", ")", ":", "\n", "        ", "\"\"\"\n        Provides dual functionality for class construction. If this function is\n        used, be sure that the ents, bin_rels, events, and equiv_rels are\n        objects of the corresponding classes.\n        \"\"\"", "\n", "self", ".", "text", "=", "text", "\n", "self", ".", "sents", "=", "sents", "\n", "self", ".", "ents", "=", "ents", "\n", "self", ".", "bin_rels", "=", "bin_rels", "\n", "self", ".", "events", "=", "events", "\n", "self", ".", "equiv_rels", "=", "equiv_rels", "\n", "self", ".", "doc_key", "=", "doc_key", "\n", "self", ".", "dataset", "=", "dataset", "\n", "self", ".", "coref", "=", "coref", "# True if EquivRels should be treated as corefs", "\n", "self", ".", "nlp", "=", "nlp", "\n", "self", ".", "dropped_ents", "=", "0", "\n", "self", ".", "total_original_ents", "=", "total_original_ents", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann": [[39, 115], ["nlp", "AnnotatedDoc.AnnotatedDoc", "AnnotatedDoc.AnnotatedDoc.set_annotation_objects", "os.path.splitext", "open", "myf.read", "open", "myf.readlines", "line.split", "os.path.basename", "line.rfind", "lines_continuous.append", "ents.append", "warnings.warn", "lines_continuous.append", "AnnotatedDoc.Ent", "bin_rels.append", "AnnotatedDoc.BinRel", "events.append", "line.index", "AnnotatedDoc.Event", "equiv_rels.append", "AnnotatedDoc.EquivRel"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.set_annotation_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.dataset_readers.document.Document.split", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["", "@", "classmethod", "\n", "def", "parse_ann", "(", "cls", ",", "txt", ",", "ann", ",", "nlp", ",", "dataset", ",", "coref", ")", ":", "\n", "        ", "\"\"\"\n        Parses .ann file and creates a new AnnotatedDoc instance.\n\n        parameters:\n            txt, str: path to .txt file that corresponds to the .ann file\n            ann, str: path to .ann file to parse\n            nlp, spacy nlp object: nlp object to use for tokenization\n            dataset, str: name of the dataset that will be used in prediction\n            coref, bool: whether or not to treat equivalence rels as corefs\n\n        return:\n            annotated_doc, instance of AnnotatedDoc for this .ann file\n        \"\"\"", "\n", "# Get doc_id", "\n", "doc_key", "=", "splitext", "(", "basename", "(", "ann", ")", ")", "[", "0", "]", "\n", "\n", "# Get text as one string and tokenized sents", "\n", "with", "open", "(", "txt", ")", "as", "myf", ":", "\n", "            ", "text", "=", "myf", ".", "read", "(", ")", "\n", "\n", "", "doc", "=", "nlp", "(", "text", ")", "\n", "sents", "=", "[", "[", "tok", ".", "text", "for", "tok", "in", "sent", "]", "for", "sent", "in", "doc", ".", "sents", "]", "\n", "\n", "# Read in the lines from the file, each row is an annotation", "\n", "with", "open", "(", "ann", ")", "as", "myf", ":", "\n", "            ", "lines", "=", "myf", ".", "readlines", "(", ")", "\n", "\n", "# Drop discontinuous ents by looking for semicolons before second \\t", "\n", "", "lines_continuous", "=", "[", "]", "\n", "for", "line", "in", "lines", ":", "\n", "            ", "if", "line", "[", "0", "]", "==", "'T'", ":", "\n", "                ", "second_tab", "=", "line", ".", "rfind", "(", "'\\t'", ")", "\n", "if", "';'", "in", "line", "[", ":", "second_tab", "]", ":", "\n", "                    ", "idx", "=", "line", "[", ":", "line", ".", "index", "(", "\"\\t\"", ")", "]", "\n", "warnings", ".", "warn", "(", "f'Entity \"{line[second_tab:]}\" (ID: '", "\n", "f'{idx}) is disjoint, and will be dropped.'", ")", "\n", "", "else", ":", "\n", "                    ", "lines_continuous", ".", "append", "(", "line", ")", "\n", "", "", "else", ":", "\n", "                ", "lines_continuous", ".", "append", "(", "line", ")", "\n", "\n", "# Split on whitespace to get the separate elements of the annotation", "\n", "", "", "split_lines", "=", "[", "line", ".", "split", "(", ")", "for", "line", "in", "lines_continuous", "]", "\n", "\n", "# Make class instances for the different annotation types", "\n", "ents", "=", "[", "]", "\n", "bin_rels", "=", "[", "]", "\n", "events", "=", "[", "]", "\n", "equiv_rels", "=", "[", "]", "\n", "total_original_ents", "=", "0", "\n", "for", "line", "in", "split_lines", ":", "\n", "\n", "# The first character of the first element in the annotation", "\n", "# is the annotation type: T = entity, R = relation, E = event,", "\n", "# * = equivalence relation", "\n", "            ", "if", "line", "[", "0", "]", "[", "0", "]", "==", "'T'", ":", "\n", "                ", "ents", ".", "append", "(", "Ent", "(", "line", ")", ")", "\n", "total_original_ents", "+=", "1", "\n", "\n", "", "elif", "line", "[", "0", "]", "[", "0", "]", "==", "'R'", ":", "\n", "                ", "bin_rels", ".", "append", "(", "BinRel", "(", "line", ")", ")", "\n", "\n", "", "elif", "line", "[", "0", "]", "[", "0", "]", "==", "'E'", ":", "\n", "                ", "events", ".", "append", "(", "Event", "(", "line", ")", ")", "\n", "\n", "", "elif", "line", "[", "0", "]", "[", "0", "]", "==", "'*'", "and", "coref", ":", "\n", "                ", "equiv_rels", ".", "append", "(", "EquivRel", "(", "line", ")", ")", "\n", "\n", "", "", "annotated_doc", "=", "AnnotatedDoc", "(", "text", ",", "sents", ",", "ents", ",", "bin_rels", ",", "events", ",", "\n", "equiv_rels", ",", "doc_key", ",", "dataset", ",", "coref", ",", "nlp", ",", "\n", "total_original_ents", ")", "\n", "annotated_doc", ".", "set_annotation_objects", "(", ")", "\n", "\n", "return", "annotated_doc", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.set_annotation_objects": [[117, 125], ["bin_rel.set_arg_objects", "event.set_arg_objects", "equiv_rel.set_arg_objects"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects"], ["", "def", "set_annotation_objects", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        For each type of annotation, replace the string IDs with the\n        corresponding entity objects, using each class' respective method.\n        \"\"\"", "\n", "[", "bin_rel", ".", "set_arg_objects", "(", "self", ".", "ents", ")", "for", "bin_rel", "in", "self", ".", "bin_rels", "]", "\n", "[", "event", ".", "set_arg_objects", "(", "self", ".", "ents", ")", "for", "event", "in", "self", ".", "events", "]", "\n", "[", "equiv_rel", ".", "set_arg_objects", "(", "self", ".", "ents", ")", "for", "equiv_rel", "in", "self", ".", "equiv_rels", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.format_dygiepp": [[127, 168], ["annotated_doc.Ent.format_ner_dygiepp", "annotated_doc.BinRel.format_bin_rels_dygiepp", "sent_idx_tups.append", "annotated_doc.EquivRel.format_corefs_dygiepp", "len", "annotated_doc.Event.format_events_dygiepp", "len", "len", "len", "len"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Ent.format_ner_dygiepp", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.BinRel.format_bin_rels_dygiepp", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.format_corefs_dygiepp", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Event.format_events_dygiepp"], ["", "def", "format_dygiepp", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Creates a dygiepp-formatted json for the doc, using each class'\n        formatting method.\n        \"\"\"", "\n", "# Get the token start and end indices for each sentence", "\n", "sent_idx_tups", "=", "[", "]", "\n", "last_end_tok_plus_one", "=", "0", "\n", "for", "sent", "in", "self", ".", "sents", ":", "\n", "\n", "            ", "start_tok", "=", "last_end_tok_plus_one", "\n", "last_end_tok_plus_one", "=", "start_tok", "+", "len", "(", "\n", "sent", ")", "# End index of sentence is non-inclusive", "\n", "\n", "sent_idx_tups", ".", "append", "(", "(", "start_tok", ",", "last_end_tok_plus_one", ")", ")", "\n", "\n", "# Format data", "\n", "", "ner", "=", "Ent", ".", "format_ner_dygiepp", "(", "self", ".", "ents", ",", "sent_idx_tups", ")", "\n", "bin_rels", "=", "BinRel", ".", "format_bin_rels_dygiepp", "(", "self", ".", "bin_rels", ",", "sent_idx_tups", ")", "\n", "if", "len", "(", "self", ".", "equiv_rels", "\n", ")", ">", "0", "and", "self", ".", "coref", ":", "# Some datasets don't have coreferences", "\n", "            ", "corefs", "=", "EquivRel", ".", "format_corefs_dygiepp", "(", "self", ".", "equiv_rels", ")", "\n", "", "if", "len", "(", "self", ".", "events", ")", ">", "0", ":", "# Some datasets don't have events", "\n", "            ", "events", "=", "Event", ".", "format_events_dygiepp", "(", "self", ".", "events", ",", "sent_idx_tups", ")", "\n", "\n", "# Make dict", "\n", "", "res", "=", "{", "\n", "\"doc_key\"", ":", "self", ".", "doc_key", ",", "\n", "\"dataset\"", ":", "self", ".", "dataset", ",", "\n", "\"sentences\"", ":", "self", ".", "sents", ",", "\n", "\"ner\"", ":", "ner", ",", "\n", "\"relations\"", ":", "bin_rels", "\n", "}", "\n", "\n", "if", "len", "(", "self", ".", "equiv_rels", "\n", ")", ">", "0", "and", "self", ".", "coref", ":", "# Some datasets don't have coreferences", "\n", "            ", "res", "[", "\"clusters\"", "]", "=", "corefs", "\n", "", "if", "len", "(", "self", ".", "events", ")", ">", "0", ":", "# Some datasets don't have events", "\n", "            ", "res", "[", "\"events\"", "]", "=", "events", "\n", "\n", "", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token": [[170, 235], ["annotated_doc.AnnotatedDoc.nlp", "print", "len", "warnings.warn", "annotated_doc.AnnotatedDoc.nlp", "len", "ent.set_tok_start_end", "ent_list_tokens.append", "tok.text.lower", "tok.text.lower", "warnings.warn", "enumerate"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Ent.set_tok_start_end"], ["", "def", "char_to_token", "(", "self", ")", ":", "\n", "        ", "\"\"\"\n        Does the heavy lifting for converting brat format to dygiepp format.\n        Gets the token start and end indices for entities.  Raises a warning\n        if no alignment can be found for an entity, as the entity will be\n        dropped.\n\n        NOTE: End character indices from brat are non-inclusive, like the\n        indexing in python. This is different from DyGIE++'s token indexing,\n        where the end indices are inclusive.\n        \"\"\"", "\n", "# Tokenize the text with spacy", "\n", "tok_text", "=", "self", ".", "nlp", "(", "self", ".", "text", ")", "\n", "\n", "# Get the alignment for each entity", "\n", "ent_list_tokens", "=", "[", "]", "\n", "for", "ent", "in", "self", ".", "ents", ":", "\n", "\n", "# Find the start token", "\n", "            ", "start_tok", "=", "[", "tok", "for", "tok", "in", "tok_text", "if", "tok", ".", "idx", "==", "ent", ".", "char_start", "]", "\n", "\n", "if", "len", "(", "start_tok", ")", "==", "0", ":", "\n", "\n", "# If the entity can't be found because there isn't an exact", "\n", "# match in the list, warn that it will be dropped", "\n", "                ", "warnings", ".", "warn", "(", "f'The entity {ent.text} (ID: {ent.ID}) cannot '", "\n", "'be aligned to the tokenization, and will be dropped.'", ")", "\n", "self", ".", "dropped_ents", "+=", "1", "\n", "\n", "", "else", ":", "\n", "\n", "# Get token start index", "\n", "                ", "ent_tok_start", "=", "start_tok", "[", "0", "]", ".", "i", "\n", "\n", "# Get the number of tokens in ent", "\n", "processed_ent", "=", "self", ".", "nlp", "(", "ent", ".", "text", ")", "\n", "num_tok", "=", "len", "(", "processed_ent", ")", "\n", "if", "num_tok", ">", "1", ":", "\n", "                    ", "ent_tok_end", "=", "ent_tok_start", "+", "num_tok", "-", "1", "\n", "", "else", ":", "\n", "                    ", "ent_tok_end", "=", "ent_tok_start", "\n", "\n", "# Double-check that the tokens from the annotation file match up", "\n", "# with the tokens in the source text.", "\n", "", "ent_tok_text", "=", "[", "tok", ".", "text", ".", "lower", "(", ")", "for", "tok", "in", "processed_ent", "]", "\n", "doc_tok_text", "=", "[", "tok", ".", "text", ".", "lower", "(", ")", "for", "i", ",", "tok", "in", "enumerate", "(", "tok_text", ")", "\n", "if", "i", ">=", "ent_tok_start", "and", "i", "<=", "ent_tok_end", "]", "\n", "if", "ent_tok_text", "!=", "doc_tok_text", ":", "\n", "                    ", "msg", "=", "(", "'The annotation file and source document disagree '", "\n", "f'on the tokens for entity {ent.text} (ID: '", "\n", "f'{ent.ID}). This entity will be dropped.'", ")", "\n", "warnings", ".", "warn", "(", "msg", ")", "\n", "self", ".", "dropped_ents", "+=", "1", "\n", "continue", "\n", "\n", "# Set the token start and end chars", "\n", "", "ent", ".", "set_tok_start_end", "(", "ent_tok_start", ",", "ent_tok_end", ")", "\n", "\n", "# Append to list to keep", "\n", "ent_list_tokens", ".", "append", "(", "ent", ")", "\n", "\n", "# Set the list of entities that had token matches as ents for doc", "\n", "", "", "self", ".", "ents", "=", "ent_list_tokens", "\n", "\n", "print", "(", "f'Completed doc {self.doc_key}. {self.dropped_ents} of '", "\n", "f'{self.total_original_ents} entities '", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Ent.__init__": [[240, 256], ["int", "int"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "line", ")", ":", "\n", "        ", "\"\"\"\n        Does not account for discontinuous annotations, these should have\n        been removed before creating entity objects.\n        \"\"\"", "\n", "self", ".", "ID", "=", "line", "[", "0", "]", "\n", "self", ".", "label", "=", "line", "[", "1", "]", "\n", "\n", "# Since disjoint entities have been dropped, start and end indices will", "\n", "# always be at the same indices in the list", "\n", "\n", "self", ".", "char_start", "=", "int", "(", "line", "[", "2", "]", ")", "\n", "self", ".", "char_end", "=", "int", "(", "line", "[", "3", "]", ")", "\n", "self", ".", "tok_start", "=", "None", "\n", "self", ".", "tok_end", "=", "None", "\n", "self", ".", "text", "=", "\" \"", ".", "join", "(", "line", "[", "4", ":", "]", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Ent.set_tok_start_end": [[257, 269], ["None"], "methods", ["None"], ["", "def", "set_tok_start_end", "(", "self", ",", "tok_start", ",", "tok_end", ")", ":", "\n", "        ", "\"\"\"\n        Set the start_end_tups attribute. To be used to change out character\n        indices for token indices.\n\n        parameters:\n            start_end_tups, list of tuples: list of start and end token indices\n\n        returns: None\n        \"\"\"", "\n", "self", ".", "tok_start", "=", "tok_start", "\n", "self", ".", "tok_end", "=", "tok_end", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Ent.format_ner_dygiepp": [[270, 299], ["ner.append", "sent_ents.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "format_ner_dygiepp", "(", "ent_list", ",", "sent_idx_tups", ")", ":", "\n", "        ", "\"\"\"\n        Take a list of start and end tokens for entities and format them for\n        dygiepp. Assumes all entities are annotated within sentence boundaries\n        and that entity indices have been converted to tokens.\n\n        parameters:\n            ent_list, list of Ent obj: list of entities to format\n            sent_idx_tups, list of tuple: start, end indices for each sentence.\n                End indices are non-inclusive.\n\n        returns:\n            ner, list of list: dygiepp formatted ner\n        \"\"\"", "\n", "ner", "=", "[", "]", "\n", "# Go through each sentence to get the entities in that sentence", "\n", "for", "sent_start", ",", "sent_end", "in", "sent_idx_tups", ":", "\n", "\n", "# Check all entities to see if they're in this sentence", "\n", "            ", "sent_ents", "=", "[", "]", "\n", "for", "ent", "in", "ent_list", ":", "\n", "\n", "                ", "if", "sent_start", "<=", "ent", ".", "tok_start", "<", "sent_end", ":", "\n", "                    ", "sent_ents", ".", "append", "(", "[", "ent", ".", "tok_start", ",", "ent", ".", "tok_end", ",", "ent", ".", "label", "]", ")", "\n", "\n", "", "", "ner", ".", "append", "(", "sent_ents", ")", "\n", "\n", "", "return", "ner", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.BinRel.__init__": [[302, 309], ["line[].index", "line[].index"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["    ", "def", "__init__", "(", "self", ",", "line", ")", ":", "\n", "\n", "        ", "self", ".", "ID", "=", "line", "[", "0", "]", "\n", "self", ".", "label", "=", "line", "[", "1", "]", "\n", "self", ".", "arg1", "=", "line", "[", "2", "]", "[", "line", "[", "2", "]", ".", "index", "(", "':'", ")", "+", "\n", "1", ":", "]", "# ID of arg is after semicolon", "\n", "self", ".", "arg2", "=", "line", "[", "3", "]", "[", "line", "[", "3", "]", ".", "index", "(", "':'", ")", "+", "1", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.BinRel.set_arg_objects": [[310, 328], ["None"], "methods", ["None"], ["", "def", "set_arg_objects", "(", "self", ",", "arg_list", ")", ":", "\n", "        ", "\"\"\"\n        Given a list of Ent objects, replaces the string ID for arg1 and arg2\n        taken from the original annotation with the Ent object instance that\n        represents that entity.\n\n        parameters:\n            arg_list, list of Ent instances: entities from the same .ann file\n\n        returns: None\n        \"\"\"", "\n", "for", "ent", "in", "arg_list", ":", "\n", "\n", "            ", "if", "ent", ".", "ID", "==", "self", ".", "arg1", ":", "\n", "                ", "self", ".", "arg1", "=", "ent", "\n", "\n", "", "elif", "ent", ".", "ID", "==", "self", ".", "arg2", ":", "\n", "                ", "self", ".", "arg2", "=", "ent", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.BinRel.format_bin_rels_dygiepp": [[329, 361], ["bin_rels.append", "sent_rels.append"], "methods", ["None"], ["", "", "", "@", "staticmethod", "\n", "def", "format_bin_rels_dygiepp", "(", "rel_list", ",", "sent_idx_tups", ")", ":", "\n", "        ", "\"\"\"\n        Take a list of relations and format them for dygiepp. Assumes all\n        realtions are annotated within sentence boundaries and that entity\n        indices have been converted to tokens.\n\n        parameters:\n            rel_list, list of BinRel objects: list of relations to format\n            sent_idx_tups, list of tuple: start, end indices for each sentence.\n                End indices are non-inclusive.\n\n        returns:\n            bin_rels, list of list: dygiepp formatted relations\n        \"\"\"", "\n", "bin_rels", "=", "[", "]", "\n", "# Go through each sentence to get the relations in that sentence", "\n", "for", "sent_start", ",", "sent_end", "in", "sent_idx_tups", ":", "\n", "\n", "# Check first entity to see if relation is in this sentence", "\n", "            ", "sent_rels", "=", "[", "]", "\n", "for", "rel", "in", "rel_list", ":", "\n", "                ", "rel_start", "=", "rel", ".", "arg1", ".", "tok_start", "\n", "if", "sent_start", "<=", "rel_start", "<", "sent_end", ":", "\n", "                    ", "sent_rels", ".", "append", "(", "[", "\n", "rel", ".", "arg1", ".", "tok_start", ",", "rel", ".", "arg1", ".", "tok_end", ",", "\n", "rel", ".", "arg2", ".", "tok_start", ",", "rel", ".", "arg2", ".", "tok_end", ",", "rel", ".", "label", "\n", "]", ")", "\n", "\n", "", "", "bin_rels", ".", "append", "(", "sent_rels", ")", "\n", "\n", "", "return", "bin_rels", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Event.__init__": [[364, 376], ["annotated_doc.Event.args.append", "line[].index", "line[].index", "arg.index", "arg.index"], "methods", ["home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index", "home.repos.pwc.inspect_result.dwadden_dygiepp.fields.adjacency_field_assym.AdjacencyFieldAssym.index"], ["    ", "def", "__init__", "(", "self", ",", "line", ")", ":", "\n", "\n", "        ", "self", ".", "ID", "=", "line", "[", "0", "]", "\n", "# ID of arg is after semicolon", "\n", "self", ".", "trigger", "=", "line", "[", "1", "]", "[", "line", "[", "1", "]", ".", "index", "(", "':'", ")", "+", "1", ":", "]", "\n", "# Type of trigger is before semicolon", "\n", "self", ".", "trigger_type", "=", "line", "[", "1", "]", "[", ":", "line", "[", "1", "]", ".", "index", "(", "':'", ")", "]", "\n", "self", ".", "args", "=", "[", "]", "\n", "for", "arg", "in", "line", "[", "2", ":", "]", ":", "\n", "            ", "arg_ID", "=", "arg", "[", "arg", ".", "index", "(", "':'", ")", "+", "1", ":", "]", "\n", "arg_label", "=", "arg", "[", ":", "arg", ".", "index", "(", "':'", ")", "]", "\n", "self", ".", "args", ".", "append", "(", "(", "arg_ID", ",", "arg_label", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Event.set_arg_objects": [[377, 406], ["arg_objs.append"], "methods", ["None"], ["", "", "def", "set_arg_objects", "(", "self", ",", "arg_list", ")", ":", "\n", "        ", "\"\"\"\n        Given a list of entity objects, replaces the string ID for the trigger,\n        arg1 and arg2 taken from the original annotation with the Ent object\n        instance that represents that entity.\n\n        parameters:\n            arg_list, list of Ent instances: entities from the same .ann file\n\n        returns: None\n        \"\"\"", "\n", "# Format a dict with arg ID as key, Ent obj as value", "\n", "# for more efficient lookup", "\n", "ent_dict", "=", "{", "ent", ".", "ID", ":", "ent", "for", "ent", "in", "arg_list", "}", "\n", "\n", "# Replace trigger", "\n", "self", ".", "trigger", "=", "ent_dict", "[", "self", ".", "trigger", "]", "\n", "\n", "# Replace args", "\n", "arg_objs", "=", "[", "]", "\n", "for", "arg_ID", ",", "arg_label", "in", "self", ".", "args", ":", "\n", "\n", "# Get the arg from the ent list by ID", "\n", "            ", "arg_obj", "=", "ent_dict", "[", "arg_ID", "]", "\n", "\n", "# Add back to list with object in place of ID", "\n", "arg_objs", ".", "append", "(", "arg_obj", ")", "\n", "\n", "", "self", ".", "args", "=", "arg_objs", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.Event.format_events_dygiepp": [[407, 472], ["events.append", "sent_events.append", "print", "formatted_event.append", "formatted_event.append", "formatted_event.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "format_events_dygiepp", "(", "event_list", ",", "sent_idx_tups", ")", ":", "\n", "        ", "\"\"\"\n        Take a list of events and format them for dygiepp. Assumes all\n        events are annotated within sentence boundaries and that entity\n        indices have been converted to tokens.\n\n        NOTE: In ACE, triggers can only be one token long. As the specified\n        format in data.md only includes events with single token triggers,\n        this function will use only the first token (with a warning) if there\n        are multiple-token triggers in the dataset.\n\n        parameters:\n            event_list, list of Event objects: events to format\n            sent_idx_tups, list of tuple: start, end indices for each sentence.\n                End indices are non-inclusive.\n\n        returns:\n            events, list of list: dygiepp formatted events\n        \"\"\"", "\n", "events", "=", "[", "]", "\n", "# Go through each sentence to get the relations in that sentence", "\n", "for", "sent_start", ",", "sent_end", "in", "sent_idx_tups", ":", "\n", "\n", "# Check trigger to see if event is in this sentence and format", "\n", "            ", "sent_events", "=", "[", "]", "\n", "for", "event", "in", "event_list", ":", "\n", "\n", "# Check if event is in sentence", "\n", "                ", "trigger_start", "=", "event", ".", "trigger", ".", "tok_start", "\n", "\n", "if", "sent_start", "<=", "trigger_start", "<", "sent_end", ":", "\n", "\n", "                    ", "formatted_event", "=", "[", "]", "\n", "# Format trigger", "\n", "# TODO: Check if triggers can be more than one token for not ACE", "\n", "trigger_end", "=", "event", ".", "trigger", ".", "tok_end", "\n", "if", "trigger_start", "!=", "trigger_end", ":", "\n", "\n", "                        ", "print", "(", "f'Warning! Trigger \"{event.trigger.text}\" (ID: '", "\n", "f'{event.trigger.ID}) has multiple tokens. Only '", "\n", "'the first token will be used.'", ")", "\n", "\n", "trigger", "=", "[", "trigger_start", ",", "event", ".", "trigger_type", "]", "\n", "formatted_event", ".", "append", "(", "trigger", ")", "\n", "\n", "", "else", ":", "\n", "                        ", "trigger", "=", "[", "trigger_start", ",", "event", ".", "trigger_type", "]", "\n", "formatted_event", ".", "append", "(", "trigger", ")", "\n", "\n", "# Format args", "\n", "", "for", "arg_obj", "in", "event", ".", "args", ":", "\n", "\n", "                        ", "arg_start", "=", "arg_obj", ".", "tok_start", "\n", "arg_end", "=", "arg_obj", ".", "tok_end", "\n", "arg_label", "=", "arg_obj", ".", "label", "\n", "\n", "arg", "=", "[", "arg_start", ",", "arg_end", ",", "arg_label", "]", "\n", "formatted_event", ".", "append", "(", "arg", ")", "\n", "\n", "", "sent_events", ".", "append", "(", "formatted_event", ")", "\n", "\n", "", "", "events", ".", "append", "(", "sent_events", ")", "\n", "\n", "", "return", "events", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.__init__": [[475, 479], ["None"], "methods", ["None"], ["    ", "def", "__init__", "(", "self", ",", "line", ")", ":", "\n", "\n", "        ", "self", ".", "label", "=", "line", "[", "1", "]", "\n", "self", ".", "args", "=", "line", "[", "2", ":", "]", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.set_arg_objects": [[480, 497], ["ent_objs.append"], "methods", ["None"], ["", "def", "set_arg_objects", "(", "self", ",", "arg_list", ")", ":", "\n", "        ", "\"\"\"\n        Given a list of entity objects, replaces the string ID for all args\n        taken from the original annotation with the Ent object\n        instance that represents that entity.\n\n        parameters:\n            arg_list, list of Ent instances: entities from the same .ann file\n\n        returns: None\n        \"\"\"", "\n", "ent_objs", "=", "[", "]", "\n", "for", "ent", "in", "arg_list", ":", "\n", "            ", "if", "ent", ".", "ID", "in", "self", ".", "args", ":", "\n", "                ", "ent_objs", ".", "append", "(", "ent", ")", "\n", "\n", "", "", "self", ".", "args", "=", "ent_objs", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.EquivRel.format_corefs_dygiepp": [[498, 517], ["corefs.append"], "methods", ["None"], ["", "@", "staticmethod", "\n", "def", "format_corefs_dygiepp", "(", "equiv_rels_list", ")", ":", "\n", "        ", "\"\"\"\n        Format coreferences for dygiepp. Assumes that entity indices have been\n        converted to tokens. Coreferences can be annotated across sentence\n        boundaries.\n\n        parameters:\n            equiv_rels_list, list of EquivRel objects: coref clusters to format\n\n        returns:\n            corefs, list of list: dygiepp formatted coreference clusters\n        \"\"\"", "\n", "corefs", "=", "[", "]", "\n", "for", "equiv_rel", "in", "equiv_rels_list", ":", "\n", "            ", "cluster", "=", "[", "[", "arg", ".", "tok_start", ",", "arg", ".", "tok_end", "]", "for", "arg", "in", "equiv_rel", ".", "args", "]", "\n", "corefs", ".", "append", "(", "cluster", ")", "\n", "\n", "", "return", "corefs", "\n", "", "", ""]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.format_new_dataset.format_document": [[12, 21], ["open().read", "nlp", "os.path.basename().replace", "open", "os.path.basename"], "function", ["None"], ["def", "format_document", "(", "fname", ",", "dataset_name", ",", "nlp", ")", ":", "\n", "    ", "text", "=", "open", "(", "fname", ")", ".", "read", "(", ")", "\n", "doc", "=", "nlp", "(", "text", ")", "\n", "sentences", "=", "[", "[", "tok", ".", "text", "for", "tok", "in", "sent", "]", "for", "sent", "in", "doc", ".", "sents", "]", "\n", "doc_key", "=", "os", ".", "path", ".", "basename", "(", "fname", ")", ".", "replace", "(", "\".txt\"", ",", "\"\"", ")", "\n", "res", "=", "{", "\"doc_key\"", ":", "doc_key", ",", "\n", "\"dataset\"", ":", "dataset_name", ",", "\n", "\"sentences\"", ":", "sentences", "}", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.format_new_dataset.format_dataset": [[23, 32], ["spacy.load", "format_new_dataset.format_document", "open", "os.listdir", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.format_new_dataset.format_document"], ["", "def", "format_dataset", "(", "data_directory", ",", "output_file", ",", "dataset_name", ",", "use_scispacy", ")", ":", "\n", "    ", "nlp_name", "=", "\"en_core_sci_sm\"", "if", "use_scispacy", "else", "\"en_core_web_sm\"", "\n", "nlp", "=", "spacy", ".", "load", "(", "nlp_name", ")", "\n", "\n", "fnames", "=", "[", "f\"{data_directory}/{name}\"", "for", "name", "in", "os", ".", "listdir", "(", "data_directory", ")", "]", "\n", "res", "=", "[", "format_document", "(", "fname", ",", "dataset_name", ",", "nlp", ")", "for", "fname", "in", "fnames", "]", "\n", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "doc", "in", "res", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "doc", ")", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.format_new_dataset.get_args": [[34, 46], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args"], "function", ["None"], ["", "", "", "def", "get_args", "(", ")", ":", "\n", "    ", "description", "=", "\"Format an unlabled dataset, consisting of a directory of `.txt` files; one file per document.\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "description", ")", "\n", "parser", ".", "add_argument", "(", "\"data_directory\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"A directory with input `.txt files, one file per document.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_file\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The output file, `.jsonl` extension recommended.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"dataset_name\"", ",", "type", "=", "str", ",", "\n", "help", "=", "\"The name of the dataset. Should match the name of the model you'll use for prediction.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--use-scispacy\"", ",", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If provided, use scispacy to do the tokenization.\"", ")", "\n", "return", "parser", ".", "parse_args", "(", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.format_new_dataset.main": [[48, 51], ["format_new_dataset.get_args", "format_new_dataset.format_dataset", "vars"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.format_new_dataset.format_dataset"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "format_dataset", "(", "**", "vars", "(", "args", ")", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.format_annotated_document": [[23, 47], ["annotated_doc.AnnotatedDoc.parse_ann", "AnnotatedDoc.parse_ann.char_to_token", "AnnotatedDoc.parse_ann.format_dygiepp"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.parse_ann", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.char_to_token", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.annotated_doc.AnnotatedDoc.format_dygiepp"], ["def", "format_annotated_document", "(", "fname_pair", ",", "dataset_name", ",", "nlp", ",", "coref", ")", ":", "\n", "    ", "\"\"\"\n    Align the character indices with tokens to get a dygiepp formatted json.\n\n    parameters:\n        fname_pair, tuple of str: names of .ann and .txt files to use\n        dataset_name, str: name of dataset used for prediction downstream\n        nlp, spacy nlp object: model to use for tokenization\n        coref, bool: whether or not to treat equivalence relations as corefs\n\n    returns:\n        res, json dict: formatted data\n    \"\"\"", "\n", "# Make annotated doc object", "\n", "annotated_doc", "=", "AnnotatedDoc", ".", "parse_ann", "(", "fname_pair", "[", "0", "]", ",", "fname_pair", "[", "1", "]", ",", "nlp", ",", "\n", "dataset_name", ",", "coref", ")", "\n", "\n", "# Do the character to token conversion", "\n", "annotated_doc", ".", "char_to_token", "(", ")", "\n", "\n", "# Do the dygiepp conversion", "\n", "res", "=", "annotated_doc", ".", "format_dygiepp", "(", ")", "\n", "\n", "return", "res", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_paired_files": [[49, 88], ["set", "glob.glob", "paired_files.append", "os.path.splitext", "ValueError", "ValueError"], "function", ["None"], ["", "def", "get_paired_files", "(", "all_files", ")", ":", "\n", "    ", "\"\"\"\n    Check that there is both a .txt and .ann file for each filename, and return\n    a list of tuples of the form (\"myfile.txt\", \"myfile.ann\"). Triggers an\n    excpetion if one of the two files is missing, ignores any files that don't\n    have either a .txt or .ann extension.\n\n    parameters:\n        all_files, list of str: list of all filenames in directory\n\n    returns:\n        paired_files, list of tuple: list of file pairs\n    \"\"\"", "\n", "paired_files", "=", "[", "]", "\n", "\n", "# Get a set of all filenames without extensions", "\n", "basenames", "=", "set", "(", "[", "splitext", "(", "name", ")", "[", "0", "]", "for", "name", "in", "all_files", "]", ")", "\n", "\n", "# Check that there are two files with the right extenstions and put in list", "\n", "for", "name", "in", "basenames", ":", "\n", "\n", "# Get files with the same name", "\n", "        ", "matching_filenames", "=", "glob", "(", "f\"{name}.*\"", ")", "\n", "\n", "# Check that both .txt and .ann are present", "\n", "txt_present", "=", "True", "if", "f\"{name}.txt\"", "in", "matching_filenames", "else", "False", "\n", "ann_present", "=", "True", "if", "f\"{name}.ann\"", "in", "matching_filenames", "else", "False", "\n", "\n", "# Put in list or raise exception", "\n", "if", "txt_present", "and", "ann_present", ":", "\n", "            ", "paired_files", ".", "append", "(", "(", "f\"{name}.txt\"", ",", "f\"{name}.ann\"", ")", ")", "\n", "", "elif", "txt_present", "and", "not", "ann_present", ":", "\n", "            ", "raise", "ValueError", "(", "\"The .ann file is missing \"", "\n", "f\"for the basename {name}. Please fix or delete.\"", ")", "\n", "", "elif", "ann_present", "and", "not", "txt_present", ":", "\n", "            ", "raise", "ValueError", "(", "\"The .txt file is missing \"", "\n", "f\"for the basename {name}. Please fix or delete.\"", ")", "\n", "\n", "", "", "return", "paired_files", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.format_labeled_dataset": [[90, 113], ["spacy.load", "brat_to_input.get_paired_files", "brat_to_input.format_annotated_document", "open", "os.listdir", "print", "json.dumps"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_paired_files", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.format_annotated_document"], ["", "def", "format_labeled_dataset", "(", "data_directory", ",", "output_file", ",", "dataset_name", ",", "\n", "use_scispacy", ",", "coref", ")", ":", "\n", "\n", "# Get model to use for tokenization", "\n", "    ", "nlp_name", "=", "\"en_core_sci_sm\"", "if", "use_scispacy", "else", "\"en_core_web_sm\"", "\n", "nlp", "=", "spacy", ".", "load", "(", "nlp_name", ")", "\n", "\n", "# Get .txt/.ann file pairs", "\n", "all_files", "=", "[", "\n", "f\"{data_directory}/{name}\"", "for", "name", "in", "listdir", "(", "data_directory", ")", "\n", "]", "\n", "paired_files", "=", "get_paired_files", "(", "all_files", ")", "\n", "\n", "# Format doc file pairs", "\n", "res", "=", "[", "\n", "format_annotated_document", "(", "fname_pair", ",", "dataset_name", ",", "nlp", ",", "coref", ")", "\n", "for", "fname_pair", "in", "paired_files", "\n", "]", "\n", "\n", "# Write out doc dictionaries", "\n", "with", "open", "(", "output_file", ",", "\"w\"", ")", "as", "f", ":", "\n", "        ", "for", "doc", "in", "res", ":", "\n", "            ", "print", "(", "json", ".", "dumps", "(", "doc", ")", ",", "file", "=", "f", ")", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args": [[115, 145], ["argparse.ArgumentParser", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.add_argument", "argparse.ArgumentParser.parse_args", "os.path.abspath", "os.path.abspath"], "function", ["None"], ["", "", "", "def", "get_args", "(", ")", ":", "\n", "    ", "description", "=", "\"Format labeled dataset from brat standoff\"", "\n", "parser", "=", "argparse", ".", "ArgumentParser", "(", "description", "=", "description", ")", "\n", "\n", "parser", ".", "add_argument", "(", "\"data_directory\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"A directory with input .txt and .ann files, \"", "\n", "\"one .txt and one .ann for each file name.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"output_file\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The output file, .jsonl extension reccomended.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"dataset_name\"", ",", "\n", "type", "=", "str", ",", "\n", "help", "=", "\"The name of the dataset. Should match the name \"", "\n", "\"of the model you'll use for prediction.\"", ")", "\n", "parser", ".", "add_argument", "(", "\n", "\"--use-scispacy\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If provided, use scispacy to do the tokenization.\"", ")", "\n", "parser", ".", "add_argument", "(", "\"--coref\"", ",", "\n", "action", "=", "\"store_true\"", ",", "\n", "help", "=", "\"If provided, treat equivalence relations as \"", "\n", "\"coreference clusters.\"", ")", "\n", "\n", "args", "=", "parser", ".", "parse_args", "(", ")", "\n", "\n", "args", ".", "data_directory", "=", "abspath", "(", "args", ".", "data_directory", ")", "\n", "args", ".", "output_file", "=", "abspath", "(", "args", ".", "output_file", ")", "\n", "\n", "return", "args", "\n", "\n"]], "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.main": [[147, 150], ["brat_to_input.get_args", "brat_to_input.format_labeled_dataset", "vars"], "function", ["home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.get_args", "home.repos.pwc.inspect_result.dwadden_dygiepp.new-dataset.brat_to_input.format_labeled_dataset"], ["", "def", "main", "(", ")", ":", "\n", "    ", "args", "=", "get_args", "(", ")", "\n", "format_labeled_dataset", "(", "**", "vars", "(", "args", ")", ")", "\n", "\n"]]}